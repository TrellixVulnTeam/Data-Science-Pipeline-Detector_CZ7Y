{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Evaluating Student Writing \n# The classes being predicted are 'Claim','Counterclaim','Evidence','Position','Rebuttal','Concluding Statement' \n#and 'Lead'\n\n# Built this model using BERT. Starting with the 'bert-base-cased' model \n# I had also build a simple BOW model and TFIDF but the model was struggling with identifying certain classes \n# especially CounterClaims and Rebuttals (understandable given the types of words in them). \n# Initial testing with BERT has looked better.\n# I had also trained a BERT based model with just 5 classes - removed 'Concluding Statement' and 'Lead' from the train set\n# with a minor improvement in accuracy. The accuracy improvement was  not enough to justify a separate model.\n# This one uses all seven classes in one model\n\n# One area I am struggling with is classifying text as \"Evidence\". \"Evidence\" texts tend to be large bodies of text \n# with  Positions and Claims in the body. Often times, individual sentences get classified as Claims. \n# The prediction model returns a list of Probabilities and, in a lot of the cases, for text which is Evidence,\n# the second highest Probability has the correct one. Perhaps the output would be more accurate if I could provide \n# a couple of predictions for each piece of text. (That is against the rules of the Competition though)\n\n# Noticing a similar issue with \"Lead\" text though not as severe\n\n# Running this on Kaggle GPU and starting with the 'bert-base-cased' model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-27T15:21:40.844681Z","iopub.execute_input":"2022-01-27T15:21:40.845157Z","iopub.status.idle":"2022-01-27T15:21:40.867512Z","shell.execute_reply.started":"2022-01-27T15:21:40.845055Z","shell.execute_reply":"2022-01-27T15:21:40.866485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install transformers --upgrade --quiet","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:21:46.657754Z","iopub.execute_input":"2022-01-27T15:21:46.658009Z","iopub.status.idle":"2022-01-27T15:21:46.661729Z","shell.execute_reply.started":"2022-01-27T15:21:46.65798Z","shell.execute_reply":"2022-01-27T15:21:46.660826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n#from transformers import AutoModel, AutoTokenizer\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:21:48.906709Z","iopub.execute_input":"2022-01-27T15:21:48.906989Z","iopub.status.idle":"2022-01-27T15:21:56.330269Z","shell.execute_reply.started":"2022-01-27T15:21:48.906958Z","shell.execute_reply":"2022-01-27T15:21:56.329528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:00.731643Z","iopub.execute_input":"2022-01-27T15:22:00.731923Z","iopub.status.idle":"2022-01-27T15:22:00.736395Z","shell.execute_reply.started":"2022-01-27T15:22:00.731892Z","shell.execute_reply":"2022-01-27T15:22:00.735707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:03.157972Z","iopub.execute_input":"2022-01-27T15:22:03.158524Z","iopub.status.idle":"2022-01-27T15:22:03.169089Z","shell.execute_reply.started":"2022-01-27T15:22:03.158488Z","shell.execute_reply":"2022-01-27T15:22:03.168146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:08.045013Z","iopub.execute_input":"2022-01-27T15:22:08.045559Z","iopub.status.idle":"2022-01-27T15:22:08.103768Z","shell.execute_reply.started":"2022-01-27T15:22:08.045521Z","shell.execute_reply":"2022-01-27T15:22:08.102807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Train Data and EDA","metadata":{}},{"cell_type":"code","source":"#load training data\ndf = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\ndf[\"text_length\"] = df[\"discourse_text\"].str.len()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:10.988627Z","iopub.execute_input":"2022-01-27T15:22:10.988878Z","iopub.status.idle":"2022-01-27T15:22:12.779318Z","shell.execute_reply.started":"2022-01-27T15:22:10.988849Z","shell.execute_reply":"2022-01-27T15:22:12.778604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codes = {'Claim':0, 'Counterclaim':1, 'Evidence':2, 'Position':3, 'Rebuttal':4, 'Concluding Statement':5, 'Lead':6 }\ndf['discourse_type_num'] = df['discourse_type'].map(codes)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:16.67979Z","iopub.execute_input":"2022-01-27T15:22:16.680133Z","iopub.status.idle":"2022-01-27T15:22:16.734526Z","shell.execute_reply.started":"2022-01-27T15:22:16.680095Z","shell.execute_reply":"2022-01-27T15:22:16.733765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:19.298161Z","iopub.execute_input":"2022-01-27T15:22:19.298696Z","iopub.status.idle":"2022-01-27T15:22:19.381026Z","shell.execute_reply.started":"2022-01-27T15:22:19.298659Z","shell.execute_reply":"2022-01-27T15:22:19.380282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"discourse_type\").text_length.mean().plot.bar(ylim=0, title=\"Average text Length by type\")","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:22.242256Z","iopub.execute_input":"2022-01-27T15:22:22.242504Z","iopub.status.idle":"2022-01-27T15:22:22.679534Z","shell.execute_reply.started":"2022-01-27T15:22:22.242477Z","shell.execute_reply":"2022-01-27T15:22:22.678874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"discourse_type\").discourse_type.count().plot.bar(ylim=0, title=\"Count of data points by Class\")","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:25.717195Z","iopub.execute_input":"2022-01-27T15:22:25.717881Z","iopub.status.idle":"2022-01-27T15:22:25.945785Z","shell.execute_reply.started":"2022-01-27T15:22:25.717845Z","shell.execute_reply":"2022-01-27T15:22:25.94508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# see one essay\ndf_DBF7EB6A9E02 = df.loc[df.id.isin(['DBF7EB6A9E02'])]\ndf_DBF7EB6A9E02","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:29.524673Z","iopub.execute_input":"2022-01-27T15:22:29.525202Z","iopub.status.idle":"2022-01-27T15:22:29.554291Z","shell.execute_reply.started":"2022-01-27T15:22:29.525163Z","shell.execute_reply":"2022-01-27T15:22:29.553112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fn = '/kaggle/input/feedback-prize-2021/train/DBF7EB6A9E02.txt'\nwith open(fn) as f:\n    contents = f.read()\n    print(contents)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:33.219987Z","iopub.execute_input":"2022-01-27T15:22:33.220257Z","iopub.status.idle":"2022-01-27T15:22:33.234382Z","shell.execute_reply.started":"2022-01-27T15:22:33.220229Z","shell.execute_reply":"2022-01-27T15:22:33.233651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Conclusion = df.loc[df.discourse_type.isin(['Concluding Statement'])]\ndf_Conclusion.head(15)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:36.340721Z","iopub.execute_input":"2022-01-27T15:22:36.341364Z","iopub.status.idle":"2022-01-27T15:22:36.371234Z","shell.execute_reply.started":"2022-01-27T15:22:36.341326Z","shell.execute_reply":"2022-01-27T15:22:36.370557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Choosing MAX Sequence Length","metadata":{}},{"cell_type":"code","source":"max(df.text_length)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:41.183286Z","iopub.execute_input":"2022-01-27T15:22:41.183816Z","iopub.status.idle":"2022-01-27T15:22:41.206954Z","shell.execute_reply.started":"2022-01-27T15:22:41.183779Z","shell.execute_reply":"2022-01-27T15:22:41.206163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(df.text_length,  bins=500)  \nplt.ylabel('Count')\nplt.xlabel('Length of text');","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:43.416487Z","iopub.execute_input":"2022-01-27T15:22:43.416929Z","iopub.status.idle":"2022-01-27T15:22:44.486574Z","shell.execute_reply.started":"2022-01-27T15:22:43.416891Z","shell.execute_reply":"2022-01-27T15:22:44.485883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max length is 4099 but most are <100.\n#I'm a bit torn about what length to choose. Leads seem to be very long strings of text. So does Evidence\n# I might have trouble identifying Leads. Looking at some samples, Leads can be anything from a \n# couple of paragraphs up front to no Lead at all with the writer jumping straight into a Position.\n# I tried an initial model droping Leads and Conclusions from the corpus. This includes all the classes in one model\n#Pad to 100 words (tokens) and truncate ","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:47.174562Z","iopub.execute_input":"2022-01-27T15:22:47.174825Z","iopub.status.idle":"2022-01-27T15:22:47.178423Z","shell.execute_reply.started":"2022-01-27T15:22:47.174796Z","shell.execute_reply":"2022-01-27T15:22:47.177633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 100\nBATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:49.037724Z","iopub.execute_input":"2022-01-27T15:22:49.038604Z","iopub.status.idle":"2022-01-27T15:22:49.047065Z","shell.execute_reply.started":"2022-01-27T15:22:49.03856Z","shell.execute_reply":"2022-01-27T15:22:49.046094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = df\ndf.shape, df_final.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:51.629352Z","iopub.execute_input":"2022-01-27T15:22:51.629799Z","iopub.status.idle":"2022-01-27T15:22:51.635247Z","shell.execute_reply.started":"2022-01-27T15:22:51.62976Z","shell.execute_reply":"2022-01-27T15:22:51.634543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Datasets","metadata":{}},{"cell_type":"code","source":"# keeping case helps keep some info.\nPRE_TRAINED_MODEL_NAME = 'bert-base-cased'","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:53.968606Z","iopub.execute_input":"2022-01-27T15:22:53.96917Z","iopub.status.idle":"2022-01-27T15:22:53.97274Z","shell.execute_reply.started":"2022-01-27T15:22:53.969134Z","shell.execute_reply":"2022-01-27T15:22:53.972001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:22:56.876312Z","iopub.execute_input":"2022-01-27T15:22:56.876956Z","iopub.status.idle":"2022-01-27T15:23:09.11034Z","shell.execute_reply.started":"2022-01-27T15:22:56.87692Z","shell.execute_reply":"2022-01-27T15:23:09.109604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a Dataset\nclass MyDataset(Dataset):\n\n  def __init__(self, inputtext, targets, tokenizer, max_len):\n    self.inputtext = inputtext\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n\n  def __len__(self):\n    return len(self.inputtext)\n\n  def __getitem__(self, item):\n    inputtext = str(self.inputtext[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      inputtext,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      truncation=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n\n    return {\n      'input_text': inputtext,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:12.998149Z","iopub.execute_input":"2022-01-27T15:23:12.998809Z","iopub.status.idle":"2022-01-27T15:23:13.005949Z","shell.execute_reply.started":"2022-01-27T15:23:12.998768Z","shell.execute_reply":"2022-01-27T15:23:13.005282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = train_test_split(\n  df_final,\n  test_size=0.1,\n  random_state=42,\n  stratify=df_final.discourse_type.values\n)\n\ndf_val, df_test = train_test_split(\n  df_test,\n  test_size=0.5,\n  random_state=42,\n  stratify=df_test.discourse_type.values\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:16.109187Z","iopub.execute_input":"2022-01-27T15:23:16.109934Z","iopub.status.idle":"2022-01-27T15:23:16.417Z","shell.execute_reply.started":"2022-01-27T15:23:16.10989Z","shell.execute_reply":"2022-01-27T15:23:16.416279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.groupby(\"discourse_type\").discourse_type.count().plot.bar(ylim=0, title=\"Count of data points by Class\")","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:22.729838Z","iopub.execute_input":"2022-01-27T15:23:22.730113Z","iopub.status.idle":"2022-01-27T15:23:22.96358Z","shell.execute_reply.started":"2022-01-27T15:23:22.730082Z","shell.execute_reply":"2022-01-27T15:23:22.962898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape, df_val.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:26.204134Z","iopub.execute_input":"2022-01-27T15:23:26.204441Z","iopub.status.idle":"2022-01-27T15:23:26.215509Z","shell.execute_reply.started":"2022-01-27T15:23:26.204408Z","shell.execute_reply":"2022-01-27T15:23:26.214333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n\n  ds = MyDataset(\n    inputtext=df.discourse_text.to_numpy(),\n    targets=df.discourse_type_num.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:28.613676Z","iopub.execute_input":"2022-01-27T15:23:28.614211Z","iopub.status.idle":"2022-01-27T15:23:28.619094Z","shell.execute_reply.started":"2022-01-27T15:23:28.614174Z","shell.execute_reply":"2022-01-27T15:23:28.618155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:30.790386Z","iopub.execute_input":"2022-01-27T15:23:30.790644Z","iopub.status.idle":"2022-01-27T15:23:30.800204Z","shell.execute_reply.started":"2022-01-27T15:23:30.790614Z","shell.execute_reply":"2022-01-27T15:23:30.799382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a Model","metadata":{}},{"cell_type":"code","source":"class TheClassifier(nn.Module):\n\n  def __init__(self, n_classes):\n    super(TheClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n\n  def forward(self, input_ids, attention_mask):\n    returned = self.bert(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n    )\n    pooled_output = returned[\"pooler_output\"]\n    output = self.drop(pooled_output)\n    return self.out(output)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:37.785946Z","iopub.execute_input":"2022-01-27T15:23:37.786685Z","iopub.status.idle":"2022-01-27T15:23:37.794128Z","shell.execute_reply.started":"2022-01-27T15:23:37.786646Z","shell.execute_reply":"2022-01-27T15:23:37.793422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:44.70619Z","iopub.execute_input":"2022-01-27T15:23:44.706631Z","iopub.status.idle":"2022-01-27T15:23:44.711766Z","shell.execute_reply.started":"2022-01-27T15:23:44.706594Z","shell.execute_reply":"2022-01-27T15:23:44.710974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TheClassifier(7) # classifying to one of Claim, CounterClaim, Evidence, Position, Rebuttal, Concluding Statement, Lead\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:23:49.350979Z","iopub.execute_input":"2022-01-27T15:23:49.351248Z","iopub.status.idle":"2022-01-27T15:24:17.00302Z","shell.execute_reply.started":"2022-01-27T15:23:49.351221Z","shell.execute_reply":"2022-01-27T15:24:17.002334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\n\noptimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:25:01.330196Z","iopub.execute_input":"2022-01-27T15:25:01.330459Z","iopub.status.idle":"2022-01-27T15:25:01.341956Z","shell.execute_reply.started":"2022-01-27T15:25:01.33043Z","shell.execute_reply":"2022-01-27T15:25:01.341151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(\n  model,\n  data_loader,\n  loss_fn,\n  optimizer,\n  device,\n  scheduler,\n  n_examples\n):\n\n  model = model.train()\n  losses = []\n\n  correct_predictions = 0\n\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    \n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:25:04.265346Z","iopub.execute_input":"2022-01-27T15:25:04.265836Z","iopub.status.idle":"2022-01-27T15:25:04.273301Z","shell.execute_reply.started":"2022-01-27T15:25:04.265799Z","shell.execute_reply":"2022-01-27T15:25:04.272357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      _, preds = torch.max(outputs, dim=1)\n\n      loss = loss_fn(outputs, targets)\n\n      correct_predictions += torch.sum(preds == targets)\n\n      losses.append(loss.item())\n\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:25:07.600544Z","iopub.execute_input":"2022-01-27T15:25:07.600822Z","iopub.status.idle":"2022-01-27T15:25:07.608242Z","shell.execute_reply.started":"2022-01-27T15:25:07.600784Z","shell.execute_reply":"2022-01-27T15:25:07.60722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = defaultdict(list)\n\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    len(df_train)\n  )\n\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn,\n    device,\n    len(df_val)\n  )\n\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), '/kaggle/working/best_model_state.bin')\n    best_accuracy = val_acc","metadata":{"execution":{"iopub.status.busy":"2022-01-27T15:25:12.490554Z","iopub.execute_input":"2022-01-27T15:25:12.491013Z","iopub.status.idle":"2022-01-27T19:26:19.757541Z","shell.execute_reply.started":"2022-01-27T15:25:12.490976Z","shell.execute_reply":"2022-01-27T19:26:19.756125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Done')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:30:00.74701Z","iopub.execute_input":"2022-01-27T19:30:00.747911Z","iopub.status.idle":"2022-01-27T19:30:00.752791Z","shell.execute_reply.started":"2022-01-27T19:30:00.747827Z","shell.execute_reply":"2022-01-27T19:30:00.752091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.ylim([0, 1]);","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:30:04.934227Z","iopub.execute_input":"2022-01-27T19:30:04.934693Z","iopub.status.idle":"2022-01-27T19:30:05.157535Z","shell.execute_reply.started":"2022-01-27T19:30:04.934657Z","shell.execute_reply":"2022-01-27T19:30:05.156862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"#lead best model\nmodel_best = TheClassifier(7)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:31:47.749384Z","iopub.execute_input":"2022-01-27T19:31:47.749934Z","iopub.status.idle":"2022-01-27T19:31:51.099156Z","shell.execute_reply.started":"2022-01-27T19:31:47.749894Z","shell.execute_reply":"2022-01-27T19:31:51.098455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = torch.load('/kaggle/working/best_model_state.bin')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:32:24.607354Z","iopub.execute_input":"2022-01-27T19:32:24.607602Z","iopub.status.idle":"2022-01-27T19:32:24.838148Z","shell.execute_reply.started":"2022-01-27T19:32:24.607574Z","shell.execute_reply":"2022-01-27T19:32:24.836891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_best.load_state_dict(m)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:32:40.014007Z","iopub.execute_input":"2022-01-27T19:32:40.014709Z","iopub.status.idle":"2022-01-27T19:32:40.126781Z","shell.execute_reply.started":"2022-01-27T19:32:40.01467Z","shell.execute_reply":"2022-01-27T19:32:40.126012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained('/kaggle/working/saved_model/')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:34:29.879944Z","iopub.execute_input":"2022-01-27T19:34:29.880431Z","iopub.status.idle":"2022-01-27T19:34:29.91337Z","shell.execute_reply.started":"2022-01-27T19:34:29.880388Z","shell.execute_reply":"2022-01-27T19:34:29.912702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify a path\nPATH = \"/kaggle/working/saved_model/whole_model.pt\"\n\n# Save\ntorch.save(model_best, PATH)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:35:50.21388Z","iopub.execute_input":"2022-01-27T19:35:50.214474Z","iopub.status.idle":"2022-01-27T19:35:50.752276Z","shell.execute_reply.started":"2022-01-27T19:35:50.214436Z","shell.execute_reply":"2022-01-27T19:35:50.751522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_best = model_best.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:37:54.64876Z","iopub.execute_input":"2022-01-27T19:37:54.649016Z","iopub.status.idle":"2022-01-27T19:37:54.767206Z","shell.execute_reply.started":"2022-01-27T19:37:54.648986Z","shell.execute_reply":"2022-01-27T19:37:54.766543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc, _ = eval_model(\n  model_best,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\ntest_acc.item()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:37:57.092518Z","iopub.execute_input":"2022-01-27T19:37:57.092779Z","iopub.status.idle":"2022-01-27T19:38:22.220653Z","shell.execute_reply.started":"2022-01-27T19:37:57.092742Z","shell.execute_reply":"2022-01-27T19:38:22.219949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n  model = model.eval()\n  input_texts = []\n  predictions = []\n  prediction_probs = []\n  real_values = []\n\n  with torch.no_grad():\n    for d in data_loader:\n      texts = d[\"input_text\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      _, preds = torch.max(outputs, dim=1)\n      input_texts.extend(texts)\n      predictions.extend(preds)\n      prediction_probs.extend(outputs)\n      real_values.extend(targets)\n\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return input_texts, predictions, prediction_probs, real_values","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:38:32.212593Z","iopub.execute_input":"2022-01-27T19:38:32.213065Z","iopub.status.idle":"2022-01-27T19:38:32.221642Z","shell.execute_reply.started":"2022-01-27T19:38:32.213012Z","shell.execute_reply":"2022-01-27T19:38:32.220922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_input_texts, y_pred, y_pred_probs, y_test = get_predictions(\n  model_best,\n  test_data_loader\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:38:39.572252Z","iopub.execute_input":"2022-01-27T19:38:39.572701Z","iopub.status.idle":"2022-01-27T19:39:03.005155Z","shell.execute_reply.started":"2022-01-27T19:38:39.572664Z","shell.execute_reply":"2022-01-27T19:39:03.004266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Claim','Counterclaim','Evidence','Position','Rebuttal','Concluding Statement','Lead']\nprint(classification_report(y_test, y_pred, target_names=class_names))","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:39:03.007256Z","iopub.execute_input":"2022-01-27T19:39:03.007472Z","iopub.status.idle":"2022-01-27T19:39:03.030963Z","shell.execute_reply.started":"2022-01-27T19:39:03.007445Z","shell.execute_reply":"2022-01-27T19:39:03.030275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Retrieve Preds for 1 piece of text","metadata":{}},{"cell_type":"code","source":"input_text = \"The most detrimental outcome is death.\" #Claim\n#input_text = \"In conclusion, drivers should not be able to use\"","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:39:28.131886Z","iopub.execute_input":"2022-01-27T19:39:28.132547Z","iopub.status.idle":"2022-01-27T19:39:28.137622Z","shell.execute_reply.started":"2022-01-27T19:39:28.132507Z","shell.execute_reply":"2022-01-27T19:39:28.136779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_text = tokenizer.encode_plus(\n  input_text,\n  max_length=MAX_LEN,\n  add_special_tokens=True,\n  return_token_type_ids=False,\n  pad_to_max_length=True,\n  truncation=True,\n  return_attention_mask=True,\n  return_tensors='pt',\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:39:34.437391Z","iopub.execute_input":"2022-01-27T19:39:34.437876Z","iopub.status.idle":"2022-01-27T19:39:34.447233Z","shell.execute_reply.started":"2022-01-27T19:39:34.437837Z","shell.execute_reply":"2022-01-27T19:39:34.445768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = encoded_text['input_ids'].to(device)\nattention_mask = encoded_text['attention_mask'].to(device)\noutput = model_best(input_ids, attention_mask)\n\n_, prediction = torch.max(output, dim=1)\n\nprint(f'Review text: {input_text}')\nprint(f'Class  : {class_names[prediction]}')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:40:04.025377Z","iopub.execute_input":"2022-01-27T19:40:04.025658Z","iopub.status.idle":"2022-01-27T19:40:04.054502Z","shell.execute_reply.started":"2022-01-27T19:40:04.025627Z","shell.execute_reply":"2022-01-27T19:40:04.053706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, preds = torch.topk(output, 2)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:41:11.292782Z","iopub.execute_input":"2022-01-27T19:41:11.293058Z","iopub.status.idle":"2022-01-27T19:41:11.303788Z","shell.execute_reply.started":"2022-01-27T19:41:11.293012Z","shell.execute_reply":"2022-01-27T19:41:11.303023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Predicted Class  : {class_names[preds[0,0].tolist()]}')\nprint(f'Second Predicted Class  : {class_names[preds[0,1].tolist()]}')\n\n#class_names[preds[0,0].tolist()], class_names[preds[0,1].tolist()]","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:41:59.364734Z","iopub.execute_input":"2022-01-27T19:41:59.364995Z","iopub.status.idle":"2022-01-27T19:41:59.370408Z","shell.execute_reply.started":"2022-01-27T19:41:59.364967Z","shell.execute_reply":"2022-01-27T19:41:59.369591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:42:08.514114Z","iopub.execute_input":"2022-01-27T19:42:08.514936Z","iopub.status.idle":"2022-01-27T19:42:08.520057Z","shell.execute_reply.started":"2022-01-27T19:42:08.51489Z","shell.execute_reply":"2022-01-27T19:42:08.519399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(output)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:42:10.306393Z","iopub.execute_input":"2022-01-27T19:42:10.307203Z","iopub.status.idle":"2022-01-27T19:42:10.332139Z","shell.execute_reply.started":"2022-01-27T19:42:10.307151Z","shell.execute_reply":"2022-01-27T19:42:10.331405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classify a piece of text","metadata":{}},{"cell_type":"code","source":"def file_split_train(fname):\n    df_file = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\n    #print(fname)\n    fn = '/kaggle/input/feedback-prize-2021/train/' + fname +'.txt'\n    #print(fn)\n    with open(fn) as f:\n        contents = f.read()\n        #print(contents)\n    #print(contents)\n    curr_index = 0\n    after_split_by_newline = contents.split('\\n')\n    for para in after_split_by_newline:\n        if (len(para) > 0):\n            after_split_by_period = para.split(\". \")\n            #print(after_split_by_period)\n            #print(len(s))\n            for sent in  after_split_by_period:\n                if (len(sent) > 0):\n                    sent_with_period = sent + '. '\n                    index_list = ''\n                    split_by_space = sent.split(' ')\n                    for wrd in split_by_space:\n                        index_list = index_list + str(curr_index) + ' '\n                        curr_index = curr_index + 1\n                    #print(index_list)\n                    #print(len(phr))\n                    df_file.loc[len(df_file.index)] = [fname, \"\", index_list, sent_with_period] \n    return(df_file)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:42:49.747671Z","iopub.execute_input":"2022-01-27T19:42:49.747953Z","iopub.status.idle":"2022-01-27T19:42:49.756558Z","shell.execute_reply.started":"2022-01-27T19:42:49.747923Z","shell.execute_reply":"2022-01-27T19:42:49.755482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def file_split(fname):\n    df_file = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\n    #print(fname)\n    fn = '/kaggle/input/feedback-prize-2021/test/' + fname +'.txt'\n    #print(fn)\n    with open(fn) as f:\n        contents = f.read()\n        #print(contents)\n    #print(contents)\n    curr_index = 0\n    after_split_by_newline = contents.split('\\n')\n    for para in after_split_by_newline:\n        if (len(para) > 0):\n            after_split_by_period = para.split(\". \")\n            #print(after_split_by_period)\n            #print(len(s))\n            for sent in  after_split_by_period:\n                if (len(sent) > 0):\n                    sent_with_period = sent + '. '\n                    index_list = ''\n                    split_by_space = sent.split(' ')\n                    for wrd in split_by_space:\n                        index_list = index_list + str(curr_index) + ' '\n                        curr_index = curr_index + 1\n                    #print(index_list)\n                    #print(len(phr))\n                    df_file.loc[len(df_file.index)] = [fname, \"\", index_list, sent_with_period] \n    return(df_file)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:43:08.691809Z","iopub.execute_input":"2022-01-27T19:43:08.692078Z","iopub.status.idle":"2022-01-27T19:43:08.701462Z","shell.execute_reply.started":"2022-01-27T19:43:08.692042Z","shell.execute_reply":"2022-01-27T19:43:08.700712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission_train = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\ndf_submission_train = df_submission_train.append(file_split_train('A97DE0D49AEA'))\ndf_submission_train = df_submission_train.append(file_split_train('DBF7EB6A9E02'))\ndf_submission_train","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:45:18.538411Z","iopub.execute_input":"2022-01-27T19:45:18.538819Z","iopub.status.idle":"2022-01-27T19:45:18.765628Z","shell.execute_reply.started":"2022-01-27T19:45:18.538777Z","shell.execute_reply":"2022-01-27T19:45:18.764955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Claim','Counterclaim','Evidence','Position','Rebuttal','Concluding Statement','Lead']","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:45:36.909682Z","iopub.execute_input":"2022-01-27T19:45:36.909944Z","iopub.status.idle":"2022-01-27T19:45:36.914Z","shell.execute_reply.started":"2022-01-27T19:45:36.90991Z","shell.execute_reply":"2022-01-27T19:45:36.9131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names = []\nfile_names.append('A97DE0D49AEA')\nfile_names.append('DBF7EB6A9E02')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:46:22.252857Z","iopub.execute_input":"2022-01-27T19:46:22.25313Z","iopub.status.idle":"2022-01-27T19:46:22.25672Z","shell.execute_reply.started":"2022-01-27T19:46:22.253101Z","shell.execute_reply":"2022-01-27T19:46:22.256087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names ","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:49:38.313911Z","iopub.execute_input":"2022-01-27T19:49:38.314486Z","iopub.status.idle":"2022-01-27T19:49:38.320025Z","shell.execute_reply.started":"2022-01-27T19:49:38.314447Z","shell.execute_reply":"2022-01-27T19:49:38.319155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make Predictions From Train\ndf_out = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\",\"raw_output\",\"seondaryclass\"])\n\nfor fnm in file_names:\n    df_split = df_submission_train.loc[(df_submission_train.id == fnm)].reset_index()\n    o_index_list = ''\n    o_input_text = ''\n    reached_conc = False\n    ctr = 0\n    for index, row in df_split.iterrows():\n        input_text = row['phrase']\n        prev_index_list = row['predictionstring']\n        ctr = ctr + 1\n        #call model\n        #output = torch.randn(1, 7)\n        \n        encoded_text = tokenizer.encode_plus(\n              input_text,\n              max_length=MAX_LEN,\n              add_special_tokens=True,\n              return_token_type_ids=False,\n              pad_to_max_length=True,\n              truncation=True,\n              return_attention_mask=True,\n              return_tensors='pt',\n        )\n        input_ids = encoded_text['input_ids'].to(device)\n        attention_mask = encoded_text['attention_mask'].to(device)\n        output = model(input_ids, attention_mask)\n        _, preds = torch.topk(output, 2)\n        curr_pred = class_names[preds[0,0].tolist()]  #\"Claim\"\n        sec_pred = class_names[preds[0,1].tolist()] #\"Evidence\"\n        if (curr_pred == \"Concluding Statement\"):\n            reached_conc = True\n        if(reached_conc):\n            curr_pred = \"Concluding Statement\"\n            o_index_list = o_index_list + prev_index_list \n            o_input_text = o_input_text + input_text\n        else:\n            df_out.loc[len(df_out.index)] = [fnm, curr_pred, prev_index_list , input_text, output, sec_pred] \n        #if (ctr == 10):\n            #curr_pred = \"Concluding Statement\"\n            #print(curr_pred)\n    if(reached_conc):\n        df_out.loc[len(df_out.index)] = [fnm, \"Concluding Statement\", o_index_list , o_input_text, \"\", \"\"] ","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:50:01.330642Z","iopub.execute_input":"2022-01-27T19:50:01.330893Z","iopub.status.idle":"2022-01-27T19:50:02.656026Z","shell.execute_reply.started":"2022-01-27T19:50:01.330866Z","shell.execute_reply":"2022-01-27T19:50:02.655323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_out","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:50:12.496811Z","iopub.execute_input":"2022-01-27T19:50:12.497077Z","iopub.status.idle":"2022-01-27T19:50:12.588639Z","shell.execute_reply.started":"2022-01-27T19:50:12.497043Z","shell.execute_reply":"2022-01-27T19:50:12.587746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_out.to_csv('/kaggle/working/out-tain_set.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:50:59.966982Z","iopub.execute_input":"2022-01-27T19:50:59.967672Z","iopub.status.idle":"2022-01-27T19:51:00.020073Z","shell.execute_reply.started":"2022-01-27T19:50:59.967634Z","shell.execute_reply":"2022-01-27T19:51:00.019319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run on Test Set","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\n#df_submission = df_submission.append(file_split('A97DE0D49AEA'))\n#df_submission = df_submission.append(file_split('DBF7EB6A9E02'))\n\nfile_names = []\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/feedback-prize-2021/test'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        #print(filename.split(\".\")[0])\n        DOC_ID = filename.split(\".\")[0]\n        fn = '/kaggle/input/feedback-prize-2021/test/' + DOC_ID +'.txt'\n        file_names.append(DOC_ID)\n        #file_split(DOC_ID)\n        df_submission = df_submission.append(file_split(DOC_ID))\n        #with open(fn) as f:\n            #contents = f.read()\n            #print(contents)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:51:51.419924Z","iopub.execute_input":"2022-01-27T19:51:51.42019Z","iopub.status.idle":"2022-01-27T19:51:51.785168Z","shell.execute_reply.started":"2022-01-27T19:51:51.420161Z","shell.execute_reply":"2022-01-27T19:51:51.784532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:52:23.52432Z","iopub.execute_input":"2022-01-27T19:52:23.524568Z","iopub.status.idle":"2022-01-27T19:52:23.537675Z","shell.execute_reply.started":"2022-01-27T19:52:23.524541Z","shell.execute_reply":"2022-01-27T19:52:23.536825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:52:36.267326Z","iopub.execute_input":"2022-01-27T19:52:36.267572Z","iopub.status.idle":"2022-01-27T19:52:36.27268Z","shell.execute_reply.started":"2022-01-27T19:52:36.267543Z","shell.execute_reply":"2022-01-27T19:52:36.271896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('/kaggle/working/test_sub_only_split_by_period.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:52:41.170855Z","iopub.execute_input":"2022-01-27T19:52:41.171119Z","iopub.status.idle":"2022-01-27T19:52:41.179048Z","shell.execute_reply.started":"2022-01-27T19:52:41.17109Z","shell.execute_reply":"2022-01-27T19:52:41.178332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make Predictions From Test\ndf_out = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\",\"raw_output\",\"seondaryclass\"])\n\nfor fnm in file_names:\n    df_split = df_submission.loc[(df_submission.id == fnm)].reset_index()\n    o_index_list = ''\n    o_input_text = ''\n    reached_conc = False\n    ctr = 0\n    for index, row in df_split.iterrows():\n        input_text = row['phrase']\n        prev_index_list = row['predictionstring']\n        ctr = ctr + 1\n        #call model\n        #output = torch.randn(1, 7)\n        \n        encoded_text = tokenizer.encode_plus(\n              input_text,\n              max_length=MAX_LEN,\n              add_special_tokens=True,\n              return_token_type_ids=False,\n              pad_to_max_length=True,\n              truncation=True,\n              return_attention_mask=True,\n              return_tensors='pt',\n        )\n        input_ids = encoded_text['input_ids'].to(device)\n        attention_mask = encoded_text['attention_mask'].to(device)\n        output = model(input_ids, attention_mask)\n        _, preds = torch.topk(output, 2)\n        curr_pred = class_names[preds[0,0].tolist()]  #\"Claim\"\n        sec_pred = class_names[preds[0,1].tolist()] #\"Evidence\"\n        if (curr_pred == \"Concluding Statement\"):\n            reached_conc = True\n        if(reached_conc):\n            curr_pred = \"Concluding Statement\"\n            o_index_list = o_index_list + prev_index_list \n            o_input_text = o_input_text + input_text\n        else:\n            df_out.loc[len(df_out.index)] = [fnm, curr_pred, prev_index_list , input_text, output, sec_pred] \n        #if (ctr == 10):\n            #curr_pred = \"Concluding Statement\"\n            #print(curr_pred)\n    if(reached_conc):\n        df_out.loc[len(df_out.index)] = [fnm, \"Concluding Statement\", o_index_list , o_input_text, \"\", \"\"] ","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:53:29.197597Z","iopub.execute_input":"2022-01-27T19:53:29.197864Z","iopub.status.idle":"2022-01-27T19:53:31.653704Z","shell.execute_reply.started":"2022-01-27T19:53:29.197833Z","shell.execute_reply":"2022-01-27T19:53:31.653003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" df_out.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:53:58.969364Z","iopub.execute_input":"2022-01-27T19:53:58.969908Z","iopub.status.idle":"2022-01-27T19:53:59.009953Z","shell.execute_reply.started":"2022-01-27T19:53:58.969866Z","shell.execute_reply":"2022-01-27T19:53:59.009292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_out","metadata":{"execution":{"iopub.status.busy":"2022-01-27T19:54:15.707696Z","iopub.execute_input":"2022-01-27T19:54:15.708484Z","iopub.status.idle":"2022-01-27T19:54:16.071149Z","shell.execute_reply.started":"2022-01-27T19:54:15.70843Z","shell.execute_reply":"2022-01-27T19:54:16.070443Z"},"trusted":true},"execution_count":null,"outputs":[]}]}