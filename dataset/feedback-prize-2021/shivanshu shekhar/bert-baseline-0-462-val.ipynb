{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tqdm import tqdm\nimport pandas as pd\nfrom tensorflow import keras\nfrom transformers import *\nfrom tensorflow.data import Dataset\nMODEL_NAME = \"../input/huggingface-bert-variants/bert-base-cased/bert-base-cased\"\nTRAIN_CSV = \"../input/feedback-prize-2021/train.csv\"\nTRAIN_DIR = \"../input/feedback-prize-2021/train/\"\n\n###Insipred from CHRIS DEOTTE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-05T03:04:34.576453Z","iopub.execute_input":"2022-02-05T03:04:34.576789Z","iopub.status.idle":"2022-02-05T03:04:45.518594Z","shell.execute_reply.started":"2022-02-05T03:04:34.576704Z","shell.execute_reply":"2022-02-05T03:04:45.517662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\nMaking the data pipeline for training ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(TRAIN_CSV)\nIDS = train.id.unique()\nprint(f\"Number of train samples are: {len(IDS)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:04:45.521072Z","iopub.execute_input":"2022-02-05T03:04:45.521543Z","iopub.status.idle":"2022-02-05T03:04:47.512449Z","shell.execute_reply.started":"2022-02-05T03:04:45.521501Z","shell.execute_reply":"2022-02-05T03:04:47.511515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512 # BERT limit\n\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\n# HELPER VARIABLES\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:04:47.513896Z","iopub.execute_input":"2022-02-05T03:04:47.514659Z","iopub.status.idle":"2022-02-05T03:04:47.613056Z","shell.execute_reply.started":"2022-02-05T03:04:47.514616Z","shell.execute_reply":"2022-02-05T03:04:47.612227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for id_num in tqdm(range(len(IDS))):\n\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = IDS[id_num]\n    name = f'../input/feedback-prize-2021/train/{n}.txt'\n    txt = open(name, 'r').read()\n    train_lens.append( len(txt.split()))\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    train_tokens[id_num,] = tokens['input_ids']\n    train_attention[id_num,] = tokens['attention_mask']\n    \n    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id==n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index>len(offsets)-1:\n            break\n        c = offsets[offset_index][0]\n        d = offsets[offset_index][1]\n        beginning = True\n        while b>c:\n            if (c>=a)&(b>=d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index>len(offsets)-1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:04:47.614265Z","iopub.execute_input":"2022-02-05T03:04:47.614648Z","iopub.status.idle":"2022-02-05T03:13:17.572586Z","shell.execute_reply.started":"2022-02-05T03:04:47.614595Z","shell.execute_reply":"2022-02-05T03:13:17.571887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_len = [x for x in train_lens if x <=512]\nprint(f\"{len(train_len)/len(IDS) * 100}% of train data has equal or less than 512 tokens\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:14:51.556414Z","iopub.execute_input":"2022-02-05T03:14:51.55669Z","iopub.status.idle":"2022-02-05T03:14:51.562807Z","shell.execute_reply.started":"2022-02-05T03:14:51.556659Z","shell.execute_reply":"2022-02-05T03:14:51.562058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\nfor k in range(7):\n    targets[:,:,2*k] = targets_b[k]\n    targets[:,:,2*k+1] = targets_i[k]\ntargets[:,:,14] = 1-np.max(targets,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:14:57.053778Z","iopub.execute_input":"2022-02-05T03:14:57.05465Z","iopub.status.idle":"2022-02-05T03:14:58.407773Z","shell.execute_reply.started":"2022-02-05T03:14:57.054588Z","shell.execute_reply":"2022-02-05T03:14:58.406975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.95*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:14:58.409411Z","iopub.execute_input":"2022-02-05T03:14:58.409672Z","iopub.status.idle":"2022-02-05T03:14:58.420857Z","shell.execute_reply.started":"2022-02-05T03:14:58.409637Z","shell.execute_reply":"2022-02-05T03:14:58.420013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\"../input/bert-weights/model.h5\")\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:12.442208Z","iopub.execute_input":"2022-02-05T03:15:12.442594Z","iopub.status.idle":"2022-02-05T03:15:29.516023Z","shell.execute_reply.started":"2022-02-05T03:15:12.442559Z","shell.execute_reply":"2022-02-05T03:15:29.5153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:29.517659Z","iopub.execute_input":"2022-02-05T03:15:29.517926Z","iopub.status.idle":"2022-02-05T03:15:29.522208Z","shell.execute_reply.started":"2022-02-05T03:15:29.517888Z","shell.execute_reply":"2022-02-05T03:15:29.521496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=1)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:29.523652Z","iopub.execute_input":"2022-02-05T03:15:29.524157Z","iopub.status.idle":"2022-02-05T03:15:50.480921Z","shell.execute_reply.started":"2022-02-05T03:15:29.524118Z","shell.execute_reply":"2022-02-05T03:15:50.480153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VALIDATION AND CV","metadata":{}},{"cell_type":"code","source":"def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n    \n        # GET ID\n        if (id_num%100==0)&(verbose): \n            print(id_num,', ',end='')\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i<MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>4:\n                all_predictions.append( (n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:50.48328Z","iopub.execute_input":"2022-02-05T03:15:50.483617Z","iopub.status.idle":"2022-02-05T03:15:50.502571Z","shell.execute_reply.started":"2022-02-05T03:15:50.483558Z","shell.execute_reply":"2022-02-05T03:15:50.50179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx])\noof.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:50.503847Z","iopub.execute_input":"2022-02-05T03:15:50.504258Z","iopub.status.idle":"2022-02-05T03:15:55.491165Z","shell.execute_reply.started":"2022-02-05T03:15:50.504219Z","shell.execute_reply":"2022-02-05T03:15:55.490488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:55.492545Z","iopub.execute_input":"2022-02-05T03:15:55.492801Z","iopub.status.idle":"2022-02-05T03:15:55.508424Z","shell.execute_reply.started":"2022-02-05T03:15:55.492768Z","shell.execute_reply":"2022-02-05T03:15:55.507776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = train.loc[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:55.509901Z","iopub.execute_input":"2022-02-05T03:15:55.510159Z","iopub.status.idle":"2022-02-05T03:15:55.545374Z","shell.execute_reply.started":"2022-02-05T03:15:55.51012Z","shell.execute_reply":"2022-02-05T03:15:55.544655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PRE PROCESSING","metadata":{}},{"cell_type":"code","source":"oof['len'] = oof['predictionstring'].apply(lambda x:len(x.split()))\ntrain['len'] = train['predictionstring'].apply(lambda x:len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:56.271968Z","iopub.execute_input":"2022-02-05T03:15:56.272505Z","iopub.status.idle":"2022-02-05T03:15:56.846342Z","shell.execute_reply.started":"2022-02-05T03:15:56.272463Z","shell.execute_reply":"2022-02-05T03:15:56.845568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('discourse_type')['len'].describe(percentiles = [0.02, 0.25, 0.50, 0.75, 0.98])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:56.849485Z","iopub.execute_input":"2022-02-05T03:15:56.849729Z","iopub.status.idle":"2022-02-05T03:15:56.905179Z","shell.execute_reply.started":"2022-02-05T03:15:56.849701Z","shell.execute_reply":"2022-02-05T03:15:56.904328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_clip = {'Lead':9, 'Position':5, 'Evidence':14, 'Claim':3, 'Concluding Statement':11,\n             'Counterclaim':6, 'Rebuttal':4}\n\ndef threshold(df):\n    df = df.copy()\n    for key, value in map_clip.items():\n    # if df.loc[df['class']==key,'len'] < value \n        index = df.loc[df['class']==key].query(f'len<{value}').index\n        df.drop(index, inplace = True)\n    return df\n\noof_2 = threshold(oof)\noof_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:56.906797Z","iopub.execute_input":"2022-02-05T03:15:56.907086Z","iopub.status.idle":"2022-02-05T03:15:56.953009Z","shell.execute_reply.started":"2022-02-05T03:15:56.907037Z","shell.execute_reply":"2022-02-05T03:15:56.952193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall_before',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:56.954469Z","iopub.execute_input":"2022-02-05T03:15:56.954751Z","iopub.status.idle":"2022-02-05T03:15:57.847474Z","shell.execute_reply.started":"2022-02-05T03:15:56.954712Z","shell.execute_reply":"2022-02-05T03:15:57.845816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof_2.loc[oof_2['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall_after',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T03:15:57.848656Z","iopub.execute_input":"2022-02-05T03:15:57.848892Z","iopub.status.idle":"2022-02-05T03:15:58.721584Z","shell.execute_reply.started":"2022-02-05T03:15:57.848853Z","shell.execute_reply":"2022-02-05T03:15:58.72083Z"},"trusted":true},"execution_count":null,"outputs":[]}]}