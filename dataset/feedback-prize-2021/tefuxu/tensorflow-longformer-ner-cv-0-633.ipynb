{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 【日本語解説】 TensorFlow LongFormer NER Baseline - CV 0.633!\n\nThis notebook is a Japanese explanation of [TensorFlow LongFormer NER Baseline][3] by CHRIS DEOTTE.\n\nこれは上のノートブックを自習するために作りましたが、参考になる方いたら投票いただけると幸いです。\nコードの主な内容は次の点です。\n\n* LongFormer\n* NERの定式化\n* 1-fold\n\n簡単な変更で、このノートブックを質問と回答の定式化に変換し、さまざまなバックボーンを試すことができます。 さらに、このノートブックは1つ折りです。 90％のデータでトレーニングし、10％のデータで検証します。 このノートブックをKフォールドに変換するか、LBをブーストするために100％のデータでトレーニングすることができます。\n\nTransformerモデルのLongFormerについて、日本語の解説は[ここ][1]が良いと思われます。 Robertaに似ていますが、最大4096トークンの入力を受け入れることができます。 このノートブックでは、1024幅のトークンをTransformerに供給します。 HuggingFaceユーザーのAllenAIは、事前にトレーニングされたウェイトをアップロードしてくれました[ここ][2]。\n\n[1]: https://data-analytics.fun/2020/12/14/understanding-longformer/\n[2]: https://huggingface.co/allenai/longformer-base-4096\n[3]: https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-633","metadata":{}},{"cell_type":"markdown","source":"# 構成説明\nLongFormerは、Hugging Face社が提供しているTransformer系のモデルに特化したDeep Learningのフレームワークから使用します。\nTransformer系のモデルを作成するのに必要なTokenizerやPretrainモデルを、下のようにHugging Face社のHP上に公開されたものから簡単にロードすることが出来ます。\n\nこのノートブックは、新しいモデルをトレーニングすることも、以前にトレーニングしたモデル（以前のノートブックバージョンから作成）をロードすることもできます。 さらに、このノートブックは、新しいNER(Named Entity Recognition; 固有表現抽出)トークンを作成するか、既存のトークン（以前のノートブックバージョンから作成）をロードすることができます。 このノートブックバージョンでは、モデルをロードし、NERトークンをロードします。","metadata":{}},{"cell_type":"code","source":"import os\n# DECLARE HOW MANY GPUS YOU WISH TO USE. \n# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n\n# VERSION FOR SAVING/LOADING MODEL WEIGHTS\n# THIS SHOULD MATCH THE MODEL IN LOAD_MODEL_FROM\nVER=14 \n\n# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\nLOAD_TOKENS_FROM = '../input/tf-longformer-v12'\n\n# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\nLOAD_MODEL_FROM = '../input/tflongformerv14'\n\n# IF FOLLOWING IS NONE, THEN NOTEBOOK \n# USES INTERNET AND DOWNLOADS HUGGINGFACE \n# CONFIG, TOKENIZER, AND MODEL\nDOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n\nif DOWNLOADED_MODEL_PATH is None:\n    DOWNLOADED_MODEL_PATH = 'model'    \nMODEL_NAME = 'allenai/longformer-base-4096'","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:34.698031Z","iopub.execute_input":"2021-12-31T10:24:34.698371Z","iopub.status.idle":"2021-12-31T10:24:34.721735Z","shell.execute_reply.started":"2021-12-31T10:24:34.698285Z","shell.execute_reply":"2021-12-31T10:24:34.721087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# インターネットなしでTensorFlowを送信する方法\nHuggingFace Transformerを使用すると、簡単です。 次の3つ（1）モデルの重み、（2）トークナイザーファイル、（3）構成ファイルをダウンロードし、Kaggleデータセットにアップロードするだけです。 以下に、AllenAIのモデルlongformer-baseのHuggingFaceからファイルを取得する方法のコードを示します。 しかし、これと同じコードで、roberta-baseなどの任意のトランスフォーマーをダウンロードできます。","metadata":{}},{"cell_type":"code","source":"if DOWNLOADED_MODEL_PATH == 'model':\n    os.mkdir('model')\n    \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    tokenizer.save_pretrained('model')\n\n    config = AutoConfig.from_pretrained(MODEL_NAME) \n    config.save_pretrained('model')\n\n    backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n    backbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:34.724727Z","iopub.execute_input":"2021-12-31T10:24:34.72523Z","iopub.status.idle":"2021-12-31T10:24:34.730314Z","shell.execute_reply.started":"2021-12-31T10:24:34.725192Z","shell.execute_reply":"2021-12-31T10:24:34.729596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"上記はファイルを保存します\n* トークン化ファイル-merges.txt、tokenizer_config.json、special_tokens_map.json、tokenizer.json、vocab.json\n* 設定ファイル-config.json\n* モデル重量ファイル-tf_model.h5\n\n次に、[ここ] [1]で行ったように、これらすべてのファイルをKaggleデータセットにアップロードします。 次に、読んでいるノートブックと同じように、それらをノートブックにロードします。 そして、インターネットをオフにすることができます！\n\n[1]: https://www.kaggle.com/cdeotte/tf-longformer-v12","metadata":{}},{"cell_type":"markdown","source":"# ライブラリの読み込み","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *\nprint('TF version',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:34.731826Z","iopub.execute_input":"2021-12-31T10:24:34.732674Z","iopub.status.idle":"2021-12-31T10:24:45.208572Z","shell.execute_reply.started":"2021-12-31T10:24:34.732648Z","shell.execute_reply":"2021-12-31T10:24:45.207748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MULTIPLE GPUS\nif os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n    strategy = tf.distribute.get_strategy()\n    print('single strategy')\nelse:\n    strategy = tf.distribute.MirroredStrategy()\n    print('multiple strategy')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:45.21008Z","iopub.execute_input":"2021-12-31T10:24:45.210322Z","iopub.status.idle":"2021-12-31T10:24:45.226055Z","shell.execute_reply.started":"2021-12-31T10:24:45.210287Z","shell.execute_reply":"2021-12-31T10:24:45.224631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:45.228958Z","iopub.execute_input":"2021-12-31T10:24:45.229257Z","iopub.status.idle":"2021-12-31T10:24:45.235779Z","shell.execute_reply.started":"2021-12-31T10:24:45.229193Z","shell.execute_reply":"2021-12-31T10:24:45.234965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# トレインの読み込み","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\nprint( train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:45.237301Z","iopub.execute_input":"2021-12-31T10:24:45.237681Z","iopub.status.idle":"2021-12-31T10:24:47.059943Z","shell.execute_reply.started":"2021-12-31T10:24:45.237644Z","shell.execute_reply":"2021-12-31T10:24:47.059283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The train labels are:')\ntrain.discourse_type.unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:47.061247Z","iopub.execute_input":"2021-12-31T10:24:47.062024Z","iopub.status.idle":"2021-12-31T10:24:47.083092Z","shell.execute_reply.started":"2021-12-31T10:24:47.061988Z","shell.execute_reply":"2021-12-31T10:24:47.082105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = train.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:47.084418Z","iopub.execute_input":"2021-12-31T10:24:47.084806Z","iopub.status.idle":"2021-12-31T10:24:47.102257Z","shell.execute_reply.started":"2021-12-31T10:24:47.084771Z","shell.execute_reply":"2021-12-31T10:24:47.101361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# トレインをトークン化する\n次のコードは、Kaggleのトレインデータセットを、NERトランスフォーマーのトレーニングに使用できるNERトークン配列に変換します。 どのターゲットがどのクラスに属しているかを明確にしました。 これにより、必要に応じて、このコードを非常に簡単に質問回答の定式化に変換できます。 14個のNER配列を、7つのクラスそれぞれの開始位置と終了位置の14個の配列に変更するだけです。 （1つのテキストに1つのクラスが複数ある場合は、どうすればよいかを創造的に考える必要があります）。","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 1024\n\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\n# HELPER VARIABLES\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:47.103406Z","iopub.execute_input":"2021-12-31T10:24:47.103786Z","iopub.status.idle":"2021-12-31T10:24:47.251873Z","shell.execute_reply.started":"2021-12-31T10:24:47.103751Z","shell.execute_reply":"2021-12-31T10:24:47.25118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WE ASSUME DATAFRAME IS ASCENDING WHICH IT IS\nassert( np.sum(train.groupby('id')['discourse_start'].diff()<=0)==0 )\n\n# FOR LOOP THROUGH EACH TRAIN TEXT\nfor id_num in range(len(IDS)):\n    if LOAD_TOKENS_FROM: break\n    if id_num%100==0: print(id_num,', ',end='')\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = IDS[id_num]\n    name = f'../input/feedback-prize-2021/train/{n}.txt'\n    txt = open(name, 'r').read()\n    train_lens.append( len(txt.split()))\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    train_tokens[id_num,] = tokens['input_ids']\n    train_attention[id_num,] = tokens['attention_mask']\n    \n    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id==n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index>len(offsets)-1:\n            break\n        c = offsets[offset_index][0]\n        d = offsets[offset_index][1]\n        beginning = True\n        while b>c:\n            if (c>=a)&(b>=d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index>len(offsets)-1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:47.254699Z","iopub.execute_input":"2021-12-31T10:24:47.254896Z","iopub.status.idle":"2021-12-31T10:24:49.633875Z","shell.execute_reply.started":"2021-12-31T10:24:47.254871Z","shell.execute_reply":"2021-12-31T10:24:49.633156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    plt.hist(train_lens,bins=100)\n    plt.title('Histogram of Train Word Counts',size=16)\n    plt.xlabel('Train Word Count',size=14)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:49.636973Z","iopub.execute_input":"2021-12-31T10:24:49.637189Z","iopub.status.idle":"2021-12-31T10:24:49.6428Z","shell.execute_reply.started":"2021-12-31T10:24:49.637164Z","shell.execute_reply":"2021-12-31T10:24:49.641985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Dec-2021/lengths4.png)\n\n上記のトレインワードカウントのヒストグラムから、1024のトランスフォーマー幅を使用することは、データの信号の大部分をキャプチャすることで構成されますが、モデルが大きすぎないことがわかります。 （トレイン**トークン**カウントのヒストグラムを分析する方が良いことに注意してくださいが、ここではそれを行いません）。 おそらく、512から1024の間の他の幅も調べることができます。 または、サイズが512以下の幅を使用し、1つのテキストを複数のチャンクに分割するストライドを使用することもできます（重複する可能性があります）。","metadata":{}},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1-np.max(targets,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:49.644256Z","iopub.execute_input":"2021-12-31T10:24:49.644501Z","iopub.status.idle":"2021-12-31T10:24:49.650358Z","shell.execute_reply.started":"2021-12-31T10:24:49.644467Z","shell.execute_reply":"2021-12-31T10:24:49.649669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:49.651586Z","iopub.execute_input":"2021-12-31T10:24:49.652008Z","iopub.status.idle":"2021-12-31T10:24:56.146533Z","shell.execute_reply.started":"2021-12-31T10:24:49.65196Z","shell.execute_reply":"2021-12-31T10:24:56.145724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# モデルの構築\n\nLongFormerバックボーンを使用し、サイズ256の1つの隠れ層とsoftmaxの最後の1つの層を使用して独自のNERヘッドを追加します。 7つのラベルのそれぞれにBクラスとIクラスがあるため、15のクラスを使用します。 また、14のクラスのいずれにも属さないトークン用の追加のクラス（Oクラスと呼ばれる）があります。","metadata":{}},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n    \n    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n    \n    x = backbone(tokens, attention_mask=attention)\n    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4),\n                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:56.149854Z","iopub.execute_input":"2021-12-31T10:24:56.150082Z","iopub.status.idle":"2021-12-31T10:24:56.158205Z","shell.execute_reply.started":"2021-12-31T10:24:56.150035Z","shell.execute_reply":"2021-12-31T10:24:56.157438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:24:56.159819Z","iopub.execute_input":"2021-12-31T10:24:56.160084Z","iopub.status.idle":"2021-12-31T10:25:26.618813Z","shell.execute_reply.started":"2021-12-31T10:24:56.160038Z","shell.execute_reply":"2021-12-31T10:25:26.617084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# モデルのトレーニングまたはロード\n\n上記の変数`LOAD_MODEL_FROM`にパスを指定すると、以前にトレーニングされたモデルがロードされます。 それ以外の場合は、今すぐトレーニングします。\n\nこのノートブックのバージョン1から4にロードされたモデルは、バッチサイズ32の5つのエポックを使用してオフラインでトレーニングされ、最初の4つのエポックで学習率`1e4`、最後のエポックで`1e5`を学習しました。 そのモデルは、4xV100GPUを使用してトレーニングされました。\n\nこのノートブックのバージョン5は、ユーザー@kaggleqrdlがノートブックバージョン20でKaggleノートブックでトレーニングしたモデルをここにロードします。 Qrdlのノートブックに賛成してください:-) Qrdlは実験を行っており、小さなバッチサイズでトレーニングするときに使用できる優れた学習率を見つけました。\n\nKaggleの1xP100GPUでトレーニングする場合、バッチサイズを4に減らす必要があります。また、学習率を`0.25e-4`と`0.25e-5`に減らします。 以下のバッチサイズと学習率を更新して、Kaggleノートブックでトレーニングできるようにしました。 （Kaggleの各トレーニングエポックには1時間8分かかります）。 \n\n[1]: https://www.kaggle.com/kaggleqrdl/v4expmt-tensorflow-longformer-ner-cv-0-634?scriptVersionId=83341823","metadata":{}},{"cell_type":"code","source":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 5\nBATCH_SIZE = 4 \nLRS = [0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5] \ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:25:26.620254Z","iopub.execute_input":"2021-12-31T10:25:26.620491Z","iopub.status.idle":"2021-12-31T10:25:26.625658Z","shell.execute_reply.started":"2021-12-31T10:25:26.620458Z","shell.execute_reply":"2021-12-31T10:25:26.624689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:25:26.627094Z","iopub.execute_input":"2021-12-31T10:25:26.627335Z","iopub.status.idle":"2021-12-31T10:25:26.64219Z","shell.execute_reply.started":"2021-12-31T10:25:26.627303Z","shell.execute_reply":"2021-12-31T10:25:26.641362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD MODEL\nif LOAD_MODEL_FROM:\n    model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n    \n# OR TRAIN MODEL\nelse:\n    model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n          y = targets[train_idx,],\n          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                             targets[valid_idx,]),\n          callbacks = [lr_callback],\n          epochs = EPOCHS,\n          batch_size = BATCH_SIZE,\n          verbose = 2)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-31T10:25:26.6435Z","iopub.execute_input":"2021-12-31T10:25:26.64394Z","iopub.status.idle":"2021-12-31T10:25:33.945428Z","shell.execute_reply.started":"2021-12-31T10:25:26.643903Z","shell.execute_reply":"2021-12-31T10:25:33.9447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# モデルの検証-OOFを推測する\n\n次に、検証テキストの予測を行います。 このモデルは、トークンごとにラベル予測を行います。これを各ラベルの単語インデックスのリストに変換する必要があります。 トークンと単語は同じではないことに注意してください。 1つの単語が複数のトークンに分割される場合があります。 したがって、最初にマップを作成して、トークンインデックスを単語インデックスに変更する必要があります。","metadata":{}},{"cell_type":"code","source":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=2)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:25:33.946854Z","iopub.execute_input":"2021-12-31T10:25:33.947131Z","iopub.status.idle":"2021-12-31T10:29:11.891972Z","shell.execute_reply.started":"2021-12-31T10:25:33.947097Z","shell.execute_reply":"2021-12-31T10:29:11.891221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:11.893177Z","iopub.execute_input":"2021-12-31T10:29:11.8942Z","iopub.status.idle":"2021-12-31T10:29:11.898549Z","shell.execute_reply.started":"2021-12-31T10:29:11.894157Z","shell.execute_reply":"2021-12-31T10:29:11.897843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n    \n        # GET ID\n        if (id_num%100==0)&(verbose): \n            print(id_num,', ',end='')\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i<MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>4:\n                all_predictions.append( (n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:11.899977Z","iopub.execute_input":"2021-12-31T10:29:11.900448Z","iopub.status.idle":"2021-12-31T10:29:11.917463Z","shell.execute_reply.started":"2021-12-31T10:29:11.90041Z","shell.execute_reply":"2021-12-31T10:29:11.916629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\noof.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:11.918822Z","iopub.execute_input":"2021-12-31T10:29:11.919296Z","iopub.status.idle":"2021-12-31T10:29:35.292749Z","shell.execute_reply.started":"2021-12-31T10:29:11.919261Z","shell.execute_reply":"2021-12-31T10:29:35.291944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The following classes are present in oof preds:')\noof['class'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:35.293916Z","iopub.execute_input":"2021-12-31T10:29:35.2942Z","iopub.status.idle":"2021-12-31T10:29:35.30383Z","shell.execute_reply.started":"2021-12-31T10:29:35.294162Z","shell.execute_reply":"2021-12-31T10:29:35.302918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 検証メトリックの計算\n\n次のコードは、RobMullaの優れた[ノートブック][2]からのものです。 LongFormerシングルフォールドモデルはCVスコア0.633を達成しています。\n\n[2]: https://www.kaggle.com/robikscube/student-writing-competition-twitch","metadata":{}},{"cell_type":"code","source":"# CODE FROM : Rob Mulla @robikscube\n# https://www.kaggle.com/robikscube/student-writing-competition-twitch\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:35.305389Z","iopub.execute_input":"2021-12-31T10:29:35.305835Z","iopub.status.idle":"2021-12-31T10:29:35.322372Z","shell.execute_reply.started":"2021-12-31T10:29:35.305798Z","shell.execute_reply":"2021-12-31T10:29:35.321366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALID DATAFRAME\nvalid = train.loc[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:35.32544Z","iopub.execute_input":"2021-12-31T10:29:35.325659Z","iopub.status.idle":"2021-12-31T10:29:35.360685Z","shell.execute_reply.started":"2021-12-31T10:29:35.325635Z","shell.execute_reply":"2021-12-31T10:29:35.359814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:35.362142Z","iopub.execute_input":"2021-12-31T10:29:35.362324Z","iopub.status.idle":"2021-12-31T10:29:37.521775Z","shell.execute_reply.started":"2021-12-31T10:29:35.362302Z","shell.execute_reply":"2021-12-31T10:29:37.521088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# テストデータを推測する\n\n次に、テストデータを推測し、提出物を作成します。 私たちのCVは0.633です、私たちのLBが何であるか見てみましょう。","metadata":{}},{"cell_type":"code","source":"# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:37.524515Z","iopub.execute_input":"2021-12-31T10:29:37.524716Z","iopub.status.idle":"2021-12-31T10:29:37.534668Z","shell.execute_reply.started":"2021-12-31T10:29:37.524691Z","shell.execute_reply":"2021-12-31T10:29:37.533223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:37.53634Z","iopub.execute_input":"2021-12-31T10:29:37.536735Z","iopub.status.idle":"2021-12-31T10:29:37.578075Z","shell.execute_reply.started":"2021-12-31T10:29:37.536697Z","shell.execute_reply":"2021-12-31T10:29:37.577441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attention], \n                  batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:37.579238Z","iopub.execute_input":"2021-12-31T10:29:37.57987Z","iopub.status.idle":"2021-12-31T10:29:38.205016Z","shell.execute_reply.started":"2021-12-31T10:29:37.579831Z","shell.execute_reply":"2021-12-31T10:29:38.20431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission.csvの書き込み","metadata":{}},{"cell_type":"code","source":"# GET TEST PREDICIONS\nsub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:38.207814Z","iopub.execute_input":"2021-12-31T10:29:38.208017Z","iopub.status.idle":"2021-12-31T10:29:38.290355Z","shell.execute_reply.started":"2021-12-31T10:29:38.207991Z","shell.execute_reply":"2021-12-31T10:29:38.289481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WRITE SUBMISSION CSV\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T10:29:38.291757Z","iopub.execute_input":"2021-12-31T10:29:38.292011Z","iopub.status.idle":"2021-12-31T10:29:38.299129Z","shell.execute_reply.started":"2021-12-31T10:29:38.291976Z","shell.execute_reply":"2021-12-31T10:29:38.298359Z"},"trusted":true},"execution_count":null,"outputs":[]}]}