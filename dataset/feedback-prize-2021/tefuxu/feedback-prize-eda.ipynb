{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feedback Prize - Evaluating Student Writing\n\nこのコンペの説明は少し分かりづらいように思えます。\n冬休みに取り組みたい日本人向けに、自習もかねて解説してみました。\n\n参考になった方は、ぜひ投票をお願いします。\n<br><br>\nI referred to the following great notebook.<br>\n<a href=\"https://www.kaggle.com/erikbruin/nlp-on-student-writing-eda\">NLP on Student Writing: EDA</a><br>\n<a href=\"https://www.kaggle.com/odins0n/feedback-prize-eda\">🔥📊 Feedback Prize - EDA 📊🔥</a>","metadata":{"papermill":{"duration":0.031081,"end_time":"2021-12-26T10:22:56.492954","exception":false,"start_time":"2021-12-26T10:22:56.461873","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nfrom matplotlib.ticker import FuncFormatter\nfrom nltk.corpus import stopwords\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport spacy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":10.716447,"end_time":"2021-12-26T10:23:07.241595","exception":false,"start_time":"2021-12-26T10:22:56.525148","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:34:03.006857Z","iopub.execute_input":"2021-12-28T05:34:03.00728Z","iopub.status.idle":"2021-12-28T05:34:03.016739Z","shell.execute_reply.started":"2021-12-28T05:34:03.007232Z","shell.execute_reply":"2021-12-28T05:34:03.01598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain[['discourse_id', 'discourse_start', 'discourse_end']] = train[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n\nsample_submission = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\n\n#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\ntrain_txt = glob('../input/feedback-prize-2021/train/*.txt') \ntest_txt = glob('../input/feedback-prize-2021/test/*.txt')","metadata":{"_kg_hide-input":true,"papermill":{"duration":2.205462,"end_time":"2021-12-26T10:23:09.476222","exception":false,"start_time":"2021-12-26T10:23:07.27076","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:34:03.018303Z","iopub.execute_input":"2021-12-28T05:34:03.018799Z","iopub.status.idle":"2021-12-28T05:34:04.098903Z","shell.execute_reply.started":"2021-12-28T05:34:03.018762Z","shell.execute_reply":"2021-12-28T05:34:04.097913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# コンペの紹介\n\nデータセットには、6年生から12年生の米国の学生が書いた論争のエッセイが含まれています。エッセイは、論争的な執筆で一般的に見られる要素について専門家の評価者によって注釈が付けられました。\n\nこれはコードの競争であり、目に見えないテストセットに対して実行されるコードを提出することに注意してください。見えないテストセットは約1万ドキュメントです。ノートブックをテストするための小さな公開テストサンプルが提供されています。\n\nあなたの仕事は人間の注釈を予測することです。まず、各エッセイを個別の修辞的要素と議論的要素（つまり、談話要素）に分割してから、各要素を次のいずれかに分類する必要があります。\n\n- Lead リード-統計、引用、説明、または読者の注意を引き、論文に向けるその他のデバイスで始まる紹介\n- Position -立場-主な質問に対する意見または結論\n- Claim -主張-立場を支持する主張\n- Counterclaim -反訴-別の主張に反論する、またはその立場に反対の理由を与える主張\n- Rebuttal -反訴-反訴に反論する主張\n- Evidence -証拠-主張、反訴、または反論を裏付けるアイデアまたは例。\n- Concluding Statement -結論ステートメント-クレームを言い換える結論ステートメント\n\nまず、1つのエッセイの全文を見てみましょう。","metadata":{"papermill":{"duration":0.028829,"end_time":"2021-12-26T10:23:09.534197","exception":false,"start_time":"2021-12-26T10:23:09.505368","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!cat ../input/feedback-prize-2021/train/423A1CA112E2.txt","metadata":{"papermill":{"duration":0.810335,"end_time":"2021-12-26T10:23:10.373532","exception":false,"start_time":"2021-12-26T10:23:09.563197","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:34:04.100486Z","iopub.execute_input":"2021-12-28T05:34:04.101274Z","iopub.status.idle":"2021-12-28T05:34:04.882357Z","shell.execute_reply.started":"2021-12-28T05:34:04.101221Z","shell.execute_reply":"2021-12-28T05:34:04.881318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"trainデータは、このエッセイから抽出された次の人間の注釈を提供します。","metadata":{"papermill":{"duration":0.02945,"end_time":"2021-12-26T10:23:10.432908","exception":false,"start_time":"2021-12-26T10:23:10.403458","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train.query('id == \"423A1CA112E2\"')","metadata":{"papermill":{"duration":0.075789,"end_time":"2021-12-26T10:23:10.539579","exception":false,"start_time":"2021-12-26T10:23:10.46379","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:34:04.885337Z","iopub.execute_input":"2021-12-28T05:34:04.885706Z","iopub.status.idle":"2021-12-28T05:34:04.920586Z","shell.execute_reply.started":"2021-12-28T05:34:04.88564Z","shell.execute_reply":"2021-12-28T05:34:04.919942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"トレーニングセットは、.txtファイルのフォルダー内の個々のエッセイと、これらのエッセイの注釈付きバージョンを含む.csvファイルで構成されます。 エッセイの一部には注釈が付けられていないことに注意することが重要です（つまり、上記の分類の1つに当てはまりません）。\n\ntrain.csv-トレーニングセット内のすべてのエッセイの注釈付きバージョンを含む.csvファイル\n- id-エッセイ応答のIDコード\n- discourse_id-談話要素のIDコード\n- discourse_start-エッセイの応答で談話要素が始まる文字の位置\n- discourse_end-談話要素がエッセイ応答で終了する文字位置\n- discourse_text-談話要素のテキスト\n- discourse_type-談話要素の分類\n- discourse_type_num-談話要素の列挙されたクラスラベル\n- predictionstring-予測に必要なトレーニングサンプルの単語インデックス\n\nここでの正解は、談話タイプと予測文字列の組み合わせです。予測文字列はエッセイの単語のインデックスに対応し、この一連の単語の予測される談話タイプは正しいはずです。正しい談話タイプが予測されているが、Ground Truthで指定されているよりも長いまたは短い単語のシーケンスである場合、部分的に一致する可能性があります。\n\nご覧のとおり、エッセイのすべてのテキストが談話の一部であるとは限りません。この場合、タイトルは談話の一部ではありません。","metadata":{"papermill":{"duration":0.029565,"end_time":"2021-12-26T10:23:10.599008","exception":false,"start_time":"2021-12-26T10:23:10.569443","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# discourse_typeごとの長さと頻度および相対位置\n\n談話の長さとクラス（discourse_type）の間に相関関係はありますか？はいあります。証拠は、平均して最長の割引タイプです。発生頻度を見ると、反訴と反論は比較的まれであることがわかります","metadata":{"papermill":{"duration":0.033897,"end_time":"2021-12-26T10:23:12.104716","exception":false,"start_time":"2021-12-26T10:23:12.070819","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#add columns\ntrain[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x: len(x.split()))\ntrain[\"pred_len\"] = train[\"predictionstring\"].apply(lambda x: len(x.split()))\n\n\ncols_to_display = ['discourse_id', 'discourse_text', 'discourse_type','predictionstring', 'discourse_len', 'pred_len']\ntrain[cols_to_display].head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:34:04.921991Z","iopub.execute_input":"2021-12-28T05:34:04.922226Z","iopub.status.idle":"2021-12-28T05:34:05.866859Z","shell.execute_reply.started":"2021-12-28T05:34:04.922197Z","shell.execute_reply":"2021-12-28T05:34:05.865894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(211)\nax1 = train.groupby('discourse_type')['discourse_len'].mean().sort_values().plot(kind=\"barh\")\nax1.set_title(\"Average number of words versus Discourse Type\", fontsize=14, fontweight = 'bold')\nax1.set_xlabel(\"Average number of words\", fontsize = 10)\nax1.set_ylabel(\"\")\n\nax2 = fig.add_subplot(212)\nax2 = train.groupby('discourse_type')['discourse_type'].count().sort_values().plot(kind=\"barh\")\nax2.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\nax2.set_title(\"Frequency of Discourse Type in all essays\", fontsize=14, fontweight = 'bold')\nax2.set_xlabel(\"Frequency\", fontsize = 10)\nax2.set_ylabel(\"\")\n\nplt.tight_layout(pad=2)\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.58351,"end_time":"2021-12-26T10:23:12.722049","exception":false,"start_time":"2021-12-26T10:23:12.138539","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:34:05.868371Z","iopub.execute_input":"2021-12-28T05:34:05.868654Z","iopub.status.idle":"2021-12-28T05:34:06.375689Z","shell.execute_reply.started":"2021-12-28T05:34:05.868625Z","shell.execute_reply":"2021-12-28T05:34:06.375091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"フィールドdiscourse_type_numがあります。 Evidence1、Position1、Claim1はほとんどの場合エッセイに含まれていることがわかります。 ほとんどの学生はまた、少なくとも1つの結論ステートメントを持っていました。 ","metadata":{"papermill":{"duration":0.03504,"end_time":"2021-12-26T10:23:12.791414","exception":false,"start_time":"2021-12-26T10:23:12.756374","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nav_per_essay = train['discourse_type_num'].value_counts(ascending = True).rename_axis('discourse_type_num').reset_index(name='count')\nav_per_essay['perc'] = round((av_per_essay['count'] / train.id.nunique()),3)\nav_per_essay = av_per_essay.set_index('discourse_type_num')\nax = av_per_essay.query('perc > 0.03')['perc'].plot(kind=\"barh\")\nax.set_title(\"discourse_type_num: Percent present in essays\", fontsize=20, fontweight = 'bold')\nax.bar_label(ax.containers[0], label_type=\"edge\")\nax.set_xlabel(\"Percent\")\nax.set_ylabel(\"\")\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.475132,"end_time":"2021-12-26T10:23:13.300595","exception":false,"start_time":"2021-12-26T10:23:12.825463","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:34:06.376628Z","iopub.execute_input":"2021-12-28T05:34:06.379158Z","iopub.status.idle":"2021-12-28T05:34:06.811687Z","shell.execute_reply.started":"2021-12-28T05:34:06.379112Z","shell.execute_reply":"2021-12-28T05:34:06.810747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, I am also interested in the relative positions of discourse types with the essays. Therefore, I am adding this number in the loop below. I think the main takeaway is that the Lead (if it's there!) is almost always the first discourse in an essay.\n\n**More on this in the next version.**","metadata":{"papermill":{"duration":0.036278,"end_time":"2021-12-26T10:23:13.3732","exception":false,"start_time":"2021-12-26T10:23:13.336922","status":"completed"},"tags":[],"_kg_hide-input":true}},{"cell_type":"code","source":"train['discourse_nr'] = 1\ncounter = 1\n\nfor i in tqdm(range(1, len(train))):\n    if train.loc[i, 'id'] == train.loc[i-1, 'id']:\n        counter += 1\n        train.loc[i, 'discourse_nr'] = counter\n    else:\n        counter = 1\n        train.loc[i, 'discourse_nr'] = counter\n        \nav_position = train.groupby('discourse_type')['discourse_nr'].mean().sort_values()\nav_position","metadata":{"papermill":{"duration":95.452778,"end_time":"2021-12-26T10:24:48.862143","exception":false,"start_time":"2021-12-26T10:23:13.409365","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:34:06.812982Z","iopub.execute_input":"2021-12-28T05:34:06.81323Z","iopub.status.idle":"2021-12-28T05:35:43.544981Z","shell.execute_reply.started":"2021-12-28T05:34:06.813203Z","shell.execute_reply":"2021-12-28T05:35:43.544031Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 注釈（discourse_textとして使用されていないテキスト）間のギャップを調査する\n\ntrainの中で最後のdiscourse_endを取るだけでは、最後のテキストが談話として使用されていない可能性があるため、完全に正しいわけではありません。","metadata":{"papermill":{"duration":0.037006,"end_time":"2021-12-26T10:24:48.9363","exception":false,"start_time":"2021-12-26T10:24:48.899294","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# this code chunk is copied from Rob Mulla\nlen_dict = {}\nword_dict = {}\nfor t in tqdm(train_txt):\n    with open(t, \"r\") as txt_file:\n        myid = t.split(\"/\")[-1].replace(\".txt\", \"\")\n        data = txt_file.read()\n        mylen = len(data.strip())\n        myword = len(data.split())\n        len_dict[myid] = mylen\n        word_dict[myid] = myword\ntrain[\"essay_len\"] = train[\"id\"].map(len_dict)\ntrain[\"essay_words\"] = train[\"id\"].map(word_dict)","metadata":{"papermill":{"duration":44.912498,"end_time":"2021-12-26T10:25:33.961847","exception":false,"start_time":"2021-12-26T10:24:49.049349","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:35:43.548411Z","iopub.execute_input":"2021-12-28T05:35:43.549191Z","iopub.status.idle":"2021-12-28T05:35:52.388512Z","shell.execute_reply.started":"2021-12-28T05:35:43.549151Z","shell.execute_reply":"2021-12-28T05:35:52.387762Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initialize column\ntrain['gap_length'] = np.nan\n\n#set the first one\ntrain.loc[0, 'gap_length'] = 7 #discourse start - 1 (previous end is always -1)\n\n#loop over rest\nfor i in tqdm(range(1, len(train))):\n    #gap if difference is not 1 within an essay\n    if ((train.loc[i, \"id\"] == train.loc[i-1, \"id\"])\\\n        and (train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] > 1)):\n        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] - 2\n        #minus 2 as the previous end is always -1 and the previous start always +1\n    #gap if the first discourse of an new essay does not start at 0\n    elif ((train.loc[i, \"id\"] != train.loc[i-1, \"id\"])\\\n        and (train.loc[i, \"discourse_start\"] != 0)):\n        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] -1\n\n\n #is there any text after the last discourse of an essay?\nlast_ones = train.drop_duplicates(subset=\"id\", keep='last')\nlast_ones['gap_end_length'] = np.where((last_ones.discourse_end < last_ones.essay_len),\\\n                                       (last_ones.essay_len - last_ones.discourse_end),\\\n                                       np.nan)\n\ncols_to_merge = ['id', 'discourse_id', 'gap_end_length']\ntrain = train.merge(last_ones[cols_to_merge], on = [\"id\", \"discourse_id\"], how = \"left\")","metadata":{"papermill":{"duration":32.615009,"end_time":"2021-12-26T10:26:06.69026","exception":false,"start_time":"2021-12-26T10:25:34.075251","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:35:52.389584Z","iopub.execute_input":"2021-12-28T05:35:52.390505Z","iopub.status.idle":"2021-12-28T05:36:25.815372Z","shell.execute_reply.started":"2021-12-28T05:35:52.390464Z","shell.execute_reply":"2021-12-28T05:36:25.814495Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display an example\ncols_to_display = ['id', 'discourse_start', 'discourse_end', 'discourse_type', 'essay_len', 'gap_length', 'gap_end_length']\ntrain[cols_to_display].query('id == \"AFEC37C2D43F\"')","metadata":{"papermill":{"duration":0.102123,"end_time":"2021-12-26T10:26:06.830642","exception":false,"start_time":"2021-12-26T10:26:06.728519","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-28T05:36:25.816949Z","iopub.execute_input":"2021-12-28T05:36:25.817213Z","iopub.status.idle":"2021-12-28T05:36:25.871147Z","shell.execute_reply.started":"2021-12-28T05:36:25.817183Z","shell.execute_reply":"2021-12-28T05:36:25.870154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#how many pieces of tekst are not used as discourses?\nprint(f\"Besides the {len(train)} discourse texts, there are {len(train.query('gap_length.notna()', engine='python'))+ len(train.query('gap_end_length.notna()', engine='python'))} pieces of text not classified.\")","metadata":{"papermill":{"duration":0.06138,"end_time":"2021-12-26T10:26:06.930902","exception":false,"start_time":"2021-12-26T10:26:06.869522","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:36:25.872823Z","iopub.execute_input":"2021-12-28T05:36:25.873085Z","iopub.status.idle":"2021-12-28T05:36:25.894654Z","shell.execute_reply.started":"2021-12-28T05:36:25.873053Z","shell.execute_reply":"2021-12-28T05:36:25.893998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"以下に、外れ値を取り除いたすべてのギャップの長さのヒストグラムを示します（すべてのギャップが300文字より長い）。","metadata":{"papermill":{"duration":0.04006,"end_time":"2021-12-26T10:26:07.34292","exception":false,"start_time":"2021-12-26T10:26:07.30286","status":"completed"},"tags":[]}},{"cell_type":"code","source":"all_gaps = (train.gap_length[~train.gap_length.isna()]).append((train.gap_end_length[~train.gap_end_length.isna()]), ignore_index= True)\n#filter outliers\nall_gaps = all_gaps[all_gaps<300]\nfig = plt.figure(figsize=(12,6))\nall_gaps.plot.hist(bins=100)\nplt.title(\"Histogram of gap length (gaps up to 300 characters only)\")\nplt.xticks(rotation=0)\nplt.xlabel(\"Length of gaps in characters\")\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.449101,"end_time":"2021-12-26T10:26:07.831588","exception":false,"start_time":"2021-12-26T10:26:07.382487","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:36:25.895937Z","iopub.execute_input":"2021-12-28T05:36:25.896169Z","iopub.status.idle":"2021-12-28T05:36:26.318778Z","shell.execute_reply.started":"2021-12-28T05:36:25.89614Z","shell.execute_reply":"2021-12-28T05:36:26.317734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# エッセイの分類ごと色塗り\n\nエッセイに含まれる談話を分類ごとに色塗りします。無分類の箇所もあることに注意してください。","metadata":{"papermill":{"duration":0.041144,"end_time":"2021-12-26T10:26:07.91494","exception":false,"start_time":"2021-12-26T10:26:07.873796","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def add_gap_rows(essay):\n    cols_to_keep = ['discourse_start', 'discourse_end', 'discourse_type', 'gap_length', 'gap_end_length']\n    df_essay = train.query('id == @essay')[cols_to_keep].reset_index(drop = True)\n\n    #index new row\n    insert_row = len(df_essay)\n   \n    for i in range(1, len(df_essay)):          \n        if df_essay.loc[i,\"gap_length\"] >0:\n            if i == 0:\n                start = 0 #as there is no i-1 for first row\n                end = df_essay.loc[0, 'discourse_start'] -1\n                disc_type = \"Nothing\"\n                gap_end = np.nan\n                gap = np.nan\n                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n                insert_row += 1\n            else:\n                start = df_essay.loc[i-1, \"discourse_end\"] + 1\n                end = df_essay.loc[i, 'discourse_start'] -1\n                disc_type = \"Nothing\"\n                gap_end = np.nan\n                gap = np.nan\n                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n                insert_row += 1\n\n    df_essay = df_essay.sort_values(by = \"discourse_start\").reset_index(drop=True)\n\n    #add gap at end\n    if df_essay.loc[(len(df_essay)-1),'gap_end_length'] > 0:\n        start = df_essay.loc[(len(df_essay)-1), \"discourse_end\"] + 1\n        end = start + df_essay.loc[(len(df_essay)-1), 'gap_end_length']\n        disc_type = \"Nothing\"\n        gap_end = np.nan\n        gap = np.nan\n        df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n        \n    return(df_essay)","metadata":{"papermill":{"duration":0.05571,"end_time":"2021-12-26T10:26:08.012955","exception":false,"start_time":"2021-12-26T10:26:07.957245","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:36:26.320154Z","iopub.execute_input":"2021-12-28T05:36:26.320386Z","iopub.status.idle":"2021-12-28T05:36:26.33395Z","shell.execute_reply.started":"2021-12-28T05:36:26.320358Z","shell.execute_reply":"2021-12-28T05:36:26.332987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_gap_rows(\"129497C3E0FC\")","metadata":{"papermill":{"duration":0.078104,"end_time":"2021-12-26T10:26:08.132371","exception":false,"start_time":"2021-12-26T10:26:08.054267","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:36:26.335194Z","iopub.execute_input":"2021-12-28T05:36:26.335585Z","iopub.status.idle":"2021-12-28T05:36:26.398509Z","shell.execute_reply.started":"2021-12-28T05:36:26.335547Z","shell.execute_reply":"2021-12-28T05:36:26.397643Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_colored_essay(essay):\n    df_essay = add_gap_rows(essay)\n    #code from https://www.kaggle.com/odins0n/feedback-prize-eda, but adjusted to df_essay\n    essay_file = \"../input/feedback-prize-2021/train/\" + essay + \".txt\"\n\n    ents = []\n    for i, row in df_essay.iterrows():\n        ents.append({\n                        'start': int(row['discourse_start']), \n                         'end': int(row['discourse_end']), \n                         'label': row['discourse_type']\n                    })\n\n    with open(essay_file, 'r') as file: data = file.read()\n\n    doc2 = {\n        \"text\": data,\n        \"ents\": ents,\n    }\n\n    colors = {'Lead': '#EE11D0','Position': '#AB4DE1','Claim': '#1EDE71','Evidence': '#33FAFA','Counterclaim': '#4253C1','Concluding Statement': 'yellow','Rebuttal': 'red'}\n    options = {\"ents\": df_essay.discourse_type.unique().tolist(), \"colors\": colors}\n    spacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);","metadata":{"papermill":{"duration":0.052788,"end_time":"2021-12-26T10:26:08.310673","exception":false,"start_time":"2021-12-26T10:26:08.257885","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:36:26.401731Z","iopub.execute_input":"2021-12-28T05:36:26.402051Z","iopub.status.idle":"2021-12-28T05:36:26.419493Z","shell.execute_reply.started":"2021-12-28T05:36:26.40201Z","shell.execute_reply":"2021-12-28T05:36:26.415947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_colored_essay(\"7330313ED3F0\")\n#print_colored_essay(\"423A1CA112E2\")","metadata":{"papermill":{"duration":0.068037,"end_time":"2021-12-26T10:26:08.420626","exception":false,"start_time":"2021-12-26T10:26:08.352589","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-28T05:36:26.420993Z","iopub.execute_input":"2021-12-28T05:36:26.421327Z","iopub.status.idle":"2021-12-28T05:36:26.481471Z","shell.execute_reply.started":"2021-12-28T05:36:26.421283Z","shell.execute_reply":"2021-12-28T05:36:26.480778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 分類ごとに最もよく使用される単語¶\nここで、各discourse_type（ストップワードを除く）で最もよく使用されている単語を調べたいと思います。 また、各discourse_typeの図のいたるところにある余分な単語をいくつか取り出しました。","metadata":{"papermill":{"duration":0.04331,"end_time":"2021-12-26T10:26:08.506458","exception":false,"start_time":"2021-12-26T10:26:08.463148","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train['discourse_text'] = train['discourse_text'].str.lower()\n\n#get stopwords from nltk library\nstop_english = stopwords.words(\"english\")\nother_words_to_take_out = ['school', 'students', 'people', 'would', 'could', 'many']\nstop_english.extend(other_words_to_take_out)\n\n#put series of Top-10 words in dict for all discourse types\ncounts_dict = {}\nfor dt in train['discourse_type'].unique():\n    df = train.query('discourse_type == @dt')\n    text = df.discourse_text.apply(lambda x: x.split()).tolist()\n    text = [item for elem in text for item in elem]\n    df1 = pd.Series(text).value_counts().to_frame().reset_index()\n    df1.columns = ['Word', 'Frequency']\n    df1 = df1[~df1.Word.isin(stop_english)].head(10)\n    df1 = df1.set_index(\"Word\").sort_values(by = \"Frequency\", ascending = True) #to series\n    counts_dict[dt] = df1\n","metadata":{"papermill":{"duration":4.179047,"end_time":"2021-12-26T10:26:12.728184","exception":false,"start_time":"2021-12-26T10:26:08.549137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:36:26.482742Z","iopub.execute_input":"2021-12-28T05:36:26.483101Z","iopub.status.idle":"2021-12-28T05:36:30.702772Z","shell.execute_reply.started":"2021-12-28T05:36:26.483069Z","shell.execute_reply":"2021-12-28T05:36:30.701972Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 12))\nplt.subplots_adjust(hspace=0.5)\n\nkeys = list(counts_dict.keys())\n\nfor n, key in enumerate(keys):\n    ax = plt.subplot(4, 2, n + 1)\n    ax.set_title(f\"Most used words in {key}\")\n    counts_dict[keys[n]].plot(ax=ax, kind = 'barh')\n    plt.ylabel(\"\")","metadata":{"papermill":{"duration":1.716143,"end_time":"2021-12-26T10:26:14.487465","exception":false,"start_time":"2021-12-26T10:26:12.771322","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-28T05:36:30.703923Z","iopub.execute_input":"2021-12-28T05:36:30.704289Z","iopub.status.idle":"2021-12-28T05:36:32.421883Z","shell.execute_reply.started":"2021-12-28T05:36:30.704259Z","shell.execute_reply":"2021-12-28T05:36:32.421202Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}