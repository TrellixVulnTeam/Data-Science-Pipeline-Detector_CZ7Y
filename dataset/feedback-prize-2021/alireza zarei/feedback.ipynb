{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n*     Dataset Information\n*         Data description\n*         Files\n*     Preliminary Data Exploration\n*         Install and Import Libraries\n*         Load Data\n*         General Dataset Information\n*     Exploratory Data Analysis\n*         Text Length\n*         Word Count\n*         Distribution of top n-grams\n*         Distribution of top n-grams for each discourse type\n*         Text Distribution\n*         Word Clouds\n*         Displaying Labels\n*         NER: Name Entity Recognition\n*         Text Clustering\n*         Word Embeddings Visualization\n\n\n# Data Description\n\n\nThe dataset contains argumentative essays written by U.S students in grades 6-12. The essays were annotated by expert raters for elements commonly found in argumentative writing.\nThe task is to predict the human annotations. You will first need to segment each essay into discrete rhetorical and argumentative elements (i.e., discourse elements) and then classify each element as one of the following: Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the readerâ€™s attention and point toward the thesis\n\n***Position***- an opinion or conclusion on the main question\n\n***Claim*** - a claim that supports the position\n\n***Counterclaim*** - a claim that refutes another claim or gives an opposing reason to the position\n\n***Rebuttal***- a claim that refutes a counterclaim\n\n***Evidence***- ideas or examples that support claims, counterclaims, or rebuttals.\n\n***Concluding Statement***- a concluding statement that restates the claims\n\n\n# Files\n***train.zip*** - folder of individual .txt files, with each file containing the full text of an essay response in the training set\n\n***train.csv*** - file containing the annotated version of all essays in the training set\n\n***test.zip*** - folder of individual .txt files, with each file containing the full text of an essay response in the test set\n\n***sample_submission.csv*** - file in the required format for making predictions - note that if you are\nmaking multiple predictions for a document, submit multiple rows ","metadata":{}},{"cell_type":"markdown","source":"* backbone LongFormer\n* Named Entity Recognition (NER) formulation\n\n\nWith simple changes, we can convert this notebook into Question Answer formulation and we can try different backbones. Furthermore this notebook is one fold. It trains with 90% data and validates on 10% data. We can convert this notebook to K-fold or train with 100% data for boost in LB.\n\nThe transformer model LongFormer is explained here. It is similar to Roberta but can accept inputs as wide as 4096 tokens! In this notebook we feed the transformer with 1024 wide tokens. HuggingFace user AllenAI uploaded pretrained weights for us here","metadata":{}},{"cell_type":"markdown","source":"# Install and Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn import metrics\nfrom tokenizers import *\n\nfrom sklearn.cluster import KMeans, MiniBatchKMeans\n\nimport logging\nfrom optparse import OptionParser\nimport sys\nfrom time import time\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom gensim.models import KeyedVectors\nfrom gensim.scripts.glove2word2vec import glove2word2vec\nfrom sklearn.decomposition import PCA\n\nfrom nltk.stem.snowball import SnowballStemmer\nfrom itertools import cycle\nplt.style.use(\"ggplot\")\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:02:29.595534Z","iopub.execute_input":"2022-02-01T18:02:29.595791Z","iopub.status.idle":"2022-02-01T18:02:30.249046Z","shell.execute_reply.started":"2022-02-01T18:02:29.595764Z","shell.execute_reply":"2022-02-01T18:02:30.248271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading the data","metadata":{}},{"cell_type":"code","source":"VER = 14\nEPOCHS = 6\nN_SPLITS = 5\nMAX_LEN = 1024\nTRAIN_SUBSET = None\nRUN_TRAINING = False\nLRS = [1e-4, 1e-4, 1e-4, 1e-4, 1e-5]\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n\n# VERSION FOR SAVING MODEL WEIGHTS\nVER=12\n\n# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\nLOAD_TOKENS_FROM = '../input/tf-longformer-v12'\n\n# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\nLOAD_MODEL_FROM = '../input/long-v14'\n\n# IF FOLLOWING IS NONE, THEN NOTEBOOK \n# USES INTERNET AND DOWNLOADS HUGGINGFACE \n# CONFIG, TOKENIZER, AND MODEL\nDOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n\nif DOWNLOADED_MODEL_PATH is None:\n    DOWNLOADED_MODEL_PATH = 'model'    \nMODEL_NAME = 'allenai/longformer-base-4096'\n\nif DOWNLOADED_MODEL_PATH == 'model':\n    os.makedirs('model', exist_ok = True)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    tokenizer.save_pretrained('model')\n    config = AutoConfig.from_pretrained(MODEL_NAME)\n    config.save_pretrained('model')\n    backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n    backbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:57:26.120223Z","iopub.execute_input":"2022-02-01T17:57:26.120521Z","iopub.status.idle":"2022-02-01T17:57:26.129318Z","shell.execute_reply.started":"2022-02-01T17:57:26.120488Z","shell.execute_reply":"2022-02-01T17:57:26.128708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #disable all tensorflow logging output\nfrom transformers import *\nprint('TF version',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:57:27.253068Z","iopub.execute_input":"2022-02-01T17:57:27.253635Z","iopub.status.idle":"2022-02-01T17:57:32.485731Z","shell.execute_reply.started":"2022-02-01T17:57:27.253585Z","shell.execute_reply":"2022-02-01T17:57:32.484784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:57:35.799032Z","iopub.execute_input":"2022-02-01T17:57:35.799332Z","iopub.status.idle":"2022-02-01T17:57:35.808974Z","shell.execute_reply.started":"2022-02-01T17:57:35.799301Z","shell.execute_reply":"2022-02-01T17:57:35.808407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\nprint( train.shape )","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:57:51.584171Z","iopub.execute_input":"2022-02-01T17:57:51.58491Z","iopub.status.idle":"2022-02-01T17:57:52.497659Z","shell.execute_reply.started":"2022-02-01T17:57:51.584876Z","shell.execute_reply":"2022-02-01T17:57:52.496331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Dataset Information","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:57:54.161Z","iopub.execute_input":"2022-02-01T17:57:54.161823Z","iopub.status.idle":"2022-02-01T17:57:54.272324Z","shell.execute_reply.started":"2022-02-01T17:57:54.161784Z","shell.execute_reply":"2022-02-01T17:57:54.271501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:58:00.875357Z","iopub.execute_input":"2022-02-01T17:58:00.87591Z","iopub.status.idle":"2022-02-01T17:58:00.892007Z","shell.execute_reply.started":"2022-02-01T17:58:00.875861Z","shell.execute_reply":"2022-02-01T17:58:00.891201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The column descriptions are:\n\n*     **id** - ID code for essay response\n*     **discourse_id** - ID code for discourse element\n*     **discourse_start** - character position where discourse element begins in the essay response\n*     **discourse_end** - character position where discourse element ends in the essay response\n*     **discourse_text** - text of discourse element\n*    **discourse_type**- classification of discourse element\n*     **discourse_type_num**- enumerated class label of discourse element\n*     **predictionstring** - the word indices of the training sample, as required for predictions\n","metadata":{}},{"cell_type":"code","source":"assert( np.sum(train.groupby('id')['discourse_start'].diff()<=0)==0 )","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:08.608956Z","iopub.execute_input":"2022-02-01T17:59:08.609255Z","iopub.status.idle":"2022-02-01T17:59:11.533529Z","shell.execute_reply.started":"2022-02-01T17:59:08.60922Z","shell.execute_reply":"2022-02-01T17:59:11.532604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The train labels are:')\ntrain.discourse_type.unique()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:11.535099Z","iopub.execute_input":"2022-02-01T17:59:11.535345Z","iopub.status.idle":"2022-02-01T17:59:11.553816Z","shell.execute_reply.started":"2022-02-01T17:59:11.535315Z","shell.execute_reply":"2022-02-01T17:59:11.55292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = train.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:11.555032Z","iopub.execute_input":"2022-02-01T17:59:11.555309Z","iopub.status.idle":"2022-02-01T17:59:11.574967Z","shell.execute_reply.started":"2022-02-01T17:59:11.555253Z","shell.execute_reply":"2022-02-01T17:59:11.574255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What Does an essay look like\n\nlets print the first txt file AFEC37C2D43F.txt to see what an essay looks like. It's an essay about asking for advice on a certain topic or subject.\n","metadata":{}},{"cell_type":"code","source":"!cat ../input/feedback-prize-2021/train/AFEC37C2D43F.txt","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:16.319289Z","iopub.execute_input":"2022-02-01T17:59:16.319791Z","iopub.status.idle":"2022-02-01T17:59:17.05722Z","shell.execute_reply.started":"2022-02-01T17:59:16.319741Z","shell.execute_reply":"2022-02-01T17:59:17.056415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets print the same example with the text colored by discourse type.","metadata":{}},{"cell_type":"code","source":"def read_essay(id):\n    with open(f\"../input/feedback-prize-2021/train/{id}.txt\") as f:\n        essay = f.read()\n    return essay\n\n\ndef text_to_color(essay, discourse_type, predictionstring):\n    \"\"\"\n    Takes an entire essay, the discourse type and prediction string.\n    Returns highlighted text for the prediction string\n    \"\"\"\n    discourse_color_map = {\n        \"Lead\": 1,  # 1 red\n        \"Position\": 2,  # 2 green\n        \"Evidence\": 3,  # 3 yellow\n        \"Claim\": 4,  # 4 blue\n        \"Concluding Statement\": 5,  # 5 magenta\n        \"Counterclaim\": 6,  # 6 cyan\n        \"Rebuttal\": 7,  # 7 white\n        \"None\": 9,  # default\n    }\n    hcolor = discourse_color_map[discourse_type]\n    text_index = [int(c) for c in predictionstring.split()]\n    text_subset = \" \".join(np.array(essay.split())[text_index])\n    if discourse_type == \"None\":\n        return f\"\\033[4{hcolor};30m{text_subset}\\033[m\"\n    return f\"\\033[4{hcolor};30m{text_subset}\\033[m\"\n\n\ndef get_non_discourse_df(train, essay, id):\n    all_pred_strings = \" \".join(train.query(\"id == @id\")[\"predictionstring\"].values)\n    all_pred_strings = [int(c) for c in all_pred_strings.split()]\n    # [c for c in all_pred_strings\n\n    non_discourse_df = pd.DataFrame(\n        [c for c in range(len(essay.split())) if c not in all_pred_strings]\n    )\n    non_discourse_df.columns = [\"predictionstring\"]\n    non_discourse_df[\"cluster\"] = (\n        non_discourse_df[\"predictionstring\"].diff().fillna(1) > 1\n    ).cumsum()\n\n    non_discourse_strings = []\n    for i, d in non_discourse_df.groupby(\"cluster\"):\n        pred_string = [str(x) for x in d[\"predictionstring\"].values]\n        non_discourse_strings.append(\" \".join(pred_string))\n    df = pd.DataFrame(non_discourse_strings).rename(columns={0: \"predictionstring\"})\n    df[\"discourse_type\"] = \"None\"\n    return df\n\n\ndef get_colored_essay(train, id):\n    essay = read_essay(id)\n    all_text = \"\"\n    train_subset = train.query(\"id == @id\").copy()\n    df = get_non_discourse_df(train, essay, id)\n    train_subset = pd.concat([train_subset, df])\n    train_subset[\"first_index\"] = (\n        train_subset[\"predictionstring\"].str.split(\" \").str[0].astype(\"int\")\n    )\n    train_subset = train_subset.sort_values(\"first_index\").reset_index(drop=True).copy()\n    for i, d in train_subset.iterrows():\n        colored_text = text_to_color(essay, d.discourse_type, d.predictionstring)\n        all_text += \" \" + colored_text\n    return all_text[1:]\n\n\nall_text = get_colored_essay(train, \"AFEC37C2D43F\")\nprint(all_text)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:22.034623Z","iopub.execute_input":"2022-02-01T17:59:22.034909Z","iopub.status.idle":"2022-02-01T17:59:22.095435Z","shell.execute_reply.started":"2022-02-01T17:59:22.034879Z","shell.execute_reply":"2022-02-01T17:59:22.094614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_f = os.listdir('../input/feedback-prize-2021/train')\n\nfor file in range(len(train_f)):\n    train_f[file] = str('../input/feedback-prize-2021/train') + \"/\" +  str(train_f[file])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:25.9128Z","iopub.execute_input":"2022-02-01T17:59:25.91307Z","iopub.status.idle":"2022-02-01T17:59:26.232963Z","shell.execute_reply.started":"2022-02-01T17:59:25.913042Z","shell.execute_reply":"2022-02-01T17:59:26.232328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying Labels","metadata":{}},{"cell_type":"code","source":"j = 40\nents = []\nfor i, row in train[train['id'] == train_f[j][35:-4]].iterrows():\n    ents.append({\n                    'start': int(row['discourse_start']), \n                     'end': int(row['discourse_end']), \n                     'label': row['discourse_type']\n                })\nwith open(train_f[j], 'r') as file: data = file.read()\n\ndoc2 = {\n    \"text\": data,\n    \"ents\": ents,\n}\ncols = {'Lead': '#dad1f6','Position': '#f9d5de','Claim': '#adcfad','Evidence': '#fbbf9a','Counterclaim': '#bdf2fa','Concluding Statement': '#eea69e','Rebuttal': '#d1f8f4'}\noptions = {\"ents\": train.discourse_type.unique().tolist(), \"colors\": cols}\ndisplacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);","metadata":{"execution":{"iopub.status.busy":"2022-02-01T17:59:28.78902Z","iopub.execute_input":"2022-02-01T17:59:28.789479Z","iopub.status.idle":"2022-02-01T17:59:28.842825Z","shell.execute_reply.started":"2022-02-01T17:59:28.789436Z","shell.execute_reply":"2022-02-01T17:59:28.842016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What Type of Annotations are Most Common","metadata":{}},{"cell_type":"code","source":"ax = (\n    train[\"discourse_type\"]\n    .value_counts(ascending=True)\n    .plot(kind=\"barh\", figsize=(10, 5))\n)\nax.set_title(\"Discourse Label Frequency (in train)\", fontsize=16)\nax.bar_label(ax.containers[0], label_type=\"edge\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:02:41.505478Z","iopub.execute_input":"2022-02-01T18:02:41.506198Z","iopub.status.idle":"2022-02-01T18:02:41.758891Z","shell.execute_reply.started":"2022-02-01T18:02:41.506161Z","shell.execute_reply":"2022-02-01T18:02:41.758039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train['full_text'] = train['discourse_text'].groupby(train['id']).transform(lambda x: ' '.join(x)) # obviously we will have duplicates","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:05:38.325997Z","iopub.execute_input":"2022-02-01T18:05:38.326315Z","iopub.status.idle":"2022-02-01T18:05:40.214804Z","shell.execute_reply.started":"2022-02-01T18:05:38.326283Z","shell.execute_reply":"2022-02-01T18:05:40.213988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's see for example the first essay:**","metadata":{}},{"cell_type":"code","source":"train.full_text.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:05:42.425719Z","iopub.execute_input":"2022-02-01T18:05:42.426011Z","iopub.status.idle":"2022-02-01T18:05:42.431817Z","shell.execute_reply.started":"2022-02-01T18:05:42.425978Z","shell.execute_reply":"2022-02-01T18:05:42.43123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of top n-grams for full-text essays","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(corpus, n=None, remove_stop_words=False, n_words=1): # if n_words=1 -> unigrams, if n_words=2 -> bigrams..\n    if remove_stop_words:\n        vec = CountVectorizer(stop_words = 'english', ngram_range=(n_words, n_words)).fit(corpus)\n    else:\n        vec = CountVectorizer(ngram_range=(n_words, n_words)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:05:52.690522Z","iopub.execute_input":"2022-02-01T18:05:52.691283Z","iopub.status.idle":"2022-02-01T18:05:52.698045Z","shell.execute_reply.started":"2022-02-01T18:05:52.691221Z","shell.execute_reply":"2022-02-01T18:05:52.697409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Unigrams**","metadata":{}},{"cell_type":"code","source":"common_words = get_top_n_words(train['full_text'].drop_duplicates(), 20, remove_stop_words=True, n_words=1)\nfor word, freq in common_words:\n    print(word, freq)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:05:54.446439Z","iopub.execute_input":"2022-02-01T18:05:54.447057Z","iopub.status.idle":"2022-02-01T18:06:05.643317Z","shell.execute_reply.started":"2022-02-01T18:05:54.447025Z","shell.execute_reply":"2022-02-01T18:06:05.642399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bigrams**","metadata":{}},{"cell_type":"code","source":"common_words = get_top_n_words(train['full_text'].drop_duplicates(), 20, remove_stop_words=True, n_words=2)\nfor word, freq in common_words:\n    print(word, freq)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:06:05.645137Z","iopub.execute_input":"2022-02-01T18:06:05.645749Z","iopub.status.idle":"2022-02-01T18:06:26.230677Z","shell.execute_reply.started":"2022-02-01T18:06:05.645685Z","shell.execute_reply":"2022-02-01T18:06:26.229934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Trigrams**","metadata":{}},{"cell_type":"code","source":"common_words = get_top_n_words(train['full_text'].drop_duplicates(), 20, remove_stop_words=True, n_words=3)\nfor word, freq in common_words:\n    print(word, freq)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:06:26.231984Z","iopub.execute_input":"2022-02-01T18:06:26.232217Z","iopub.status.idle":"2022-02-01T18:06:54.708147Z","shell.execute_reply.started":"2022-02-01T18:06:26.23219Z","shell.execute_reply":"2022-02-01T18:06:54.70694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of top n-grams for each discourse type","metadata":{}},{"cell_type":"markdown","source":"**Unigrams**","metadata":{}},{"cell_type":"code","source":"text_Lead = train[train.discourse_type == 'Lead'].discourse_text.values\ntext_Position = train[train.discourse_type == 'Position'].discourse_text.values\ntext_Evidence = train[train.discourse_type == 'Evidence'].discourse_text.values\ntext_Claim = train[train.discourse_type == 'Claim'].discourse_text.values\ntext_Concluding_Statement = train[train.discourse_type == 'Concluding Statement'].discourse_text.values\ntext_Counterclaim = train[train.discourse_type == 'Counterclaim'].discourse_text.values\ntext_Rebuttal = train[train.discourse_type == 'Rebuttal'].discourse_text.values\n\ncommon_words_Lead = get_top_n_words(text_Lead, 20, remove_stop_words=True, n_words=1)\ncommon_words_Position = get_top_n_words(text_Position, 20, remove_stop_words=True, n_words=1)\ncommon_words_Evidence = get_top_n_words(text_Evidence, 20, remove_stop_words=True, n_words=1)\ncommon_words_Claim = get_top_n_words(text_Claim, 20, remove_stop_words=True, n_words=1)\ncommon_words_Concluding_Statement = get_top_n_words(text_Concluding_Statement, 20, remove_stop_words=True, n_words=1)\ncommon_words_Counterclaim = get_top_n_words(text_Counterclaim, 20, remove_stop_words=True, n_words=1)\ncommon_words_Rebuttal = get_top_n_words(text_Rebuttal, 20, remove_stop_words=True, n_words=1)\ndf_tmp_Lead = pd.DataFrame(common_words_Lead, columns = ['text' , 'count'])\ndf_tmp_Position = pd.DataFrame(common_words_Position, columns = ['text' , 'count'])\ndf_tmp_Evidence = pd.DataFrame(common_words_Evidence, columns = ['text' , 'count'])\ndf_tmp_Claim = pd.DataFrame(common_words_Claim, columns = ['text' , 'count'])\ndf_tmp_Concluding_Statement = pd.DataFrame(common_words_Concluding_Statement, columns = ['text' , 'count'])\ndf_tmp_Counterclaim = pd.DataFrame(common_words_Counterclaim, columns = ['text' , 'count'])\ndf_tmp_Rebuttal = pd.DataFrame(common_words_Rebuttal, columns = ['text' , 'count'])\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Lead.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Lead Unigram Distribution')\nax1.set_xlabel(\"Unigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Position.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Position Unigram Distribution')\nax2.set_xlabel(\"Unigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Evidence.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Evidence Unigram Distribution')\nax1.set_xlabel(\"Unigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Claim.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Claim Unigram Distribution')\nax2.set_xlabel(\"Unigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Concluding_Statement.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Concluding Statement Unigram Distribution')\nax1.set_xlabel(\"Unigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Counterclaim.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Counterclaim Unigram Distribution')\nax2.set_xlabel(\"Unigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Rebuttal.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Rebuttal Unigram Distribution')\nax1.set_xlabel(\"Unigrams\")\nax1.set_ylabel(\"Frequency\")\n\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:06:54.713314Z","iopub.execute_input":"2022-02-01T18:06:54.713562Z","iopub.status.idle":"2022-02-01T18:07:09.764176Z","shell.execute_reply.started":"2022-02-01T18:06:54.713522Z","shell.execute_reply":"2022-02-01T18:07:09.763316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bigrams**","metadata":{}},{"cell_type":"code","source":"text_Lead = train[train.discourse_type == 'Lead'].discourse_text.values\ntext_Position = train[train.discourse_type == 'Position'].discourse_text.values\ntext_Evidence = train[train.discourse_type == 'Evidence'].discourse_text.values\ntext_Claim = train[train.discourse_type == 'Claim'].discourse_text.values\ntext_Concluding_Statement = train[train.discourse_type == 'Concluding Statement'].discourse_text.values\ntext_Counterclaim = train[train.discourse_type == 'Counterclaim'].discourse_text.values\ntext_Rebuttal = train[train.discourse_type == 'Rebuttal'].discourse_text.values\n\ncommon_words_Lead = get_top_n_words(text_Lead, 20, remove_stop_words=True, n_words=2)\ncommon_words_Position = get_top_n_words(text_Position, 20, remove_stop_words=True, n_words=2)\ncommon_words_Evidence = get_top_n_words(text_Evidence, 20, remove_stop_words=True, n_words=2)\ncommon_words_Claim = get_top_n_words(text_Claim, 20, remove_stop_words=True, n_words=2)\ncommon_words_Concluding_Statement = get_top_n_words(text_Concluding_Statement, 20, remove_stop_words=True, n_words=2)\ncommon_words_Counterclaim = get_top_n_words(text_Counterclaim, 20, remove_stop_words=True, n_words=2)\ncommon_words_Rebuttal = get_top_n_words(text_Rebuttal, 20, remove_stop_words=True, n_words=2)\ndf_tmp_Lead = pd.DataFrame(common_words_Lead, columns = ['text' , 'count'])\ndf_tmp_Position = pd.DataFrame(common_words_Position, columns = ['text' , 'count'])\ndf_tmp_Evidence = pd.DataFrame(common_words_Evidence, columns = ['text' , 'count'])\ndf_tmp_Claim = pd.DataFrame(common_words_Claim, columns = ['text' , 'count'])\ndf_tmp_Concluding_Statement = pd.DataFrame(common_words_Concluding_Statement, columns = ['text' , 'count'])\ndf_tmp_Counterclaim = pd.DataFrame(common_words_Counterclaim, columns = ['text' , 'count'])\ndf_tmp_Rebuttal = pd.DataFrame(common_words_Rebuttal, columns = ['text' , 'count'])\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Lead.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Lead Bigram Distribution')\nax1.set_xlabel(\"Bigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Position.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Position Bigram Distribution')\nax2.set_xlabel(\"Bigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Evidence.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Evidence Bigram Distribution')\nax1.set_xlabel(\"Bigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Claim.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Claim Bigram Distribution')\nax2.set_xlabel(\"Bigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Concluding_Statement.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Concluding Statement Bigram Distribution')\nax1.set_xlabel(\"Bigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Counterclaim.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Counterclaim Bigram Distribution')\nax2.set_xlabel(\"Bigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Rebuttal.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Rebuttal Bigram Distribution')\nax1.set_xlabel(\"Bigrams\")\nax1.set_ylabel(\"Frequency\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:07:33.593581Z","iopub.execute_input":"2022-02-01T18:07:33.594173Z","iopub.status.idle":"2022-02-01T18:07:58.547659Z","shell.execute_reply.started":"2022-02-01T18:07:33.594136Z","shell.execute_reply":"2022-02-01T18:07:58.54675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Trigrams**","metadata":{}},{"cell_type":"code","source":"text_Lead = train[train.discourse_type == 'Lead'].discourse_text.values\ntext_Position = train[train.discourse_type == 'Position'].discourse_text.values\ntext_Evidence = train[train.discourse_type == 'Evidence'].discourse_text.values\ntext_Claim = train[train.discourse_type == 'Claim'].discourse_text.values\ntext_Concluding_Statement = train[train.discourse_type == 'Concluding Statement'].discourse_text.values\ntext_Counterclaim = train[train.discourse_type == 'Counterclaim'].discourse_text.values\ntext_Rebuttal = train[train.discourse_type == 'Rebuttal'].discourse_text.values\n\ncommon_words_Lead = get_top_n_words(text_Lead, 20, remove_stop_words=True, n_words=3)\ncommon_words_Position = get_top_n_words(text_Position, 20, remove_stop_words=True, n_words=3)\ncommon_words_Evidence = get_top_n_words(text_Evidence, 20, remove_stop_words=True, n_words=3)\ncommon_words_Claim = get_top_n_words(text_Claim, 20, remove_stop_words=True, n_words=3)\ncommon_words_Concluding_Statement = get_top_n_words(text_Concluding_Statement, 20, remove_stop_words=True, n_words=3)\ncommon_words_Counterclaim = get_top_n_words(text_Counterclaim, 20, remove_stop_words=True, n_words=3)\ncommon_words_Rebuttal = get_top_n_words(text_Rebuttal, 20, remove_stop_words=True, n_words=3)\ndf_tmp_Lead = pd.DataFrame(common_words_Lead, columns = ['text' , 'count'])\ndf_tmp_Position = pd.DataFrame(common_words_Position, columns = ['text' , 'count'])\ndf_tmp_Evidence = pd.DataFrame(common_words_Evidence, columns = ['text' , 'count'])\ndf_tmp_Claim = pd.DataFrame(common_words_Claim, columns = ['text' , 'count'])\ndf_tmp_Concluding_Statement = pd.DataFrame(common_words_Concluding_Statement, columns = ['text' , 'count'])\ndf_tmp_Counterclaim = pd.DataFrame(common_words_Counterclaim, columns = ['text' , 'count'])\ndf_tmp_Rebuttal = pd.DataFrame(common_words_Rebuttal, columns = ['text' , 'count'])\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Lead.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Lead Trigram Distribution')\nax1.set_xlabel(\"Trigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Position.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Position Trigram Distribution')\nax2.set_xlabel(\"Trigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Evidence.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Evidence Trigram Distribution')\nax1.set_xlabel(\"Trigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Claim.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Claim Trigram Distribution')\nax2.set_xlabel(\"Trigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Concluding_Statement.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Concluding Statement Trigram Distribution')\nax1.set_xlabel(\"Trigrams\")\nax1.set_ylabel(\"Frequency\")\n\nax2 = fig.add_subplot(122)\nax2 = df_tmp_Counterclaim.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n   kind='bar', color = \"#120f7a\")\nax2.set_title('Counterclaim Trigram Distribution')\nax2.set_xlabel(\"Trigrams\")\nax2.set_ylabel(\"Frequency\")\n\nfig = plt.figure(figsize=(15,6))\n\nax1 = fig.add_subplot(121)\nax1 = df_tmp_Rebuttal.groupby('text').sum()['count'].sort_values(ascending=False).plot(\n    kind='bar', color = \"#120f7a\")\nax1.set_title('Rebuttal Trigram Distribution')\nax1.set_xlabel(\"Trigrams\")\nax1.set_ylabel(\"Frequency\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:07:58.549282Z","iopub.execute_input":"2022-02-01T18:07:58.549495Z","iopub.status.idle":"2022-02-01T18:08:28.359428Z","shell.execute_reply.started":"2022-02-01T18:07:58.54947Z","shell.execute_reply":"2022-02-01T18:08:28.358878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = (\n    train.groupby(\"discourse_type\")[[\"discourse_start\", \"discourse_end\"]]\n    .mean()\n    .sort_values(\"discourse_start\")\n    .plot(\n        kind=\"barh\",\n        figsize=(10, 5),\n    )\n)\nax.set_title(\"Average Discourse Label Start and End\", fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:08:28.36035Z","iopub.execute_input":"2022-02-01T18:08:28.360851Z","iopub.status.idle":"2022-02-01T18:08:28.624945Z","shell.execute_reply.started":"2022-02-01T18:08:28.360821Z","shell.execute_reply":"2022-02-01T18:08:28.624161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wordclouds by Discourse Type","metadata":{}},{"cell_type":"code","source":"plt.style.use('default')\n\nfig, axs = plt.subplots(7, 1, figsize=(20, 25))\n\nplt_idx = 0\n\nfor discourse_type, d in train.groupby(\"discourse_type\"):\n    discourse_text = \" \".join(d[\"discourse_text\"].values.tolist())\n    wordcloud = WordCloud(\n        max_font_size=200,\n        max_words=200,\n        width=1200,\n        height=800,\n        background_color=\"white\",\n    ).generate(discourse_text)\n    axs = axs.flatten()\n    axs[plt_idx].imshow(wordcloud, interpolation=\"bilinear\")\n    axs[plt_idx].set_title(discourse_type, fontsize=18)\n    axs[plt_idx].axis(\"off\")\n    plt_idx += 1\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:08:53.314381Z","iopub.execute_input":"2022-02-01T18:08:53.314655Z","iopub.status.idle":"2022-02-01T18:09:26.47814Z","shell.execute_reply.started":"2022-02-01T18:08:53.314626Z","shell.execute_reply":"2022-02-01T18:09:26.47724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize Train\nThe following code converts train dataset into a NER token array that we can use to train a NER transformer. I have made it very clear which targets belong to which class. This allows us to very easily convert this code to Question Answer formulation if we want. Just change the 14 NER arrays to be 14 arrays of start position and end position for each of the 7 classes. (You will need to think creatively what to do if a single text has multiple of one class).","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 1024\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4, 'Counterclaim':5, 'Rebuttal':6}\n\nfor id_num in range(len(IDS)):\n    if LOAD_TOKENS_FROM: break\n    if id_num % 100 == 0: print(id_num,', ',end='')\n    n = IDS[id_num]\n    name = f'../input/feedback-prize-2021/train/{n}.txt'\n    txt = open(name, 'r').read()\n    train_lens.append( len(txt.split()))\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length', truncation=True, return_offsets_mapping=True)\n    train_tokens[id_num,] = tokens['input_ids']\n    train_attention[id_num,] = tokens['attention_mask']\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id==n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index>len(offsets)-1:\n            break\n        c = offsets[offset_index][0]\n        d = offsets[offset_index][1]\n        beginning = True\n        while b>c:\n            if (c>=a)&(b>=d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index>len(offsets)-1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]\n\nif LOAD_TOKENS_FROM is None:\n    targets = np.zeros((len(IDS), MAX_LEN, 15), dtype = 'int32')\n    for k in range(7):\n        targets[:, :, 2 * k] = targets_b[k]\n        targets[:, :, 2 * k + 1] = targets_i[k]\n    targets[:, :, 14] = 1 - np.max(targets, axis = -1)\nif LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:09:58.243441Z","iopub.execute_input":"2022-02-01T18:09:58.243976Z","iopub.status.idle":"2022-02-01T18:10:05.804701Z","shell.execute_reply.started":"2022-02-01T18:09:58.243944Z","shell.execute_reply":"2022-02-01T18:10:05.802918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    plt.hist(train_lens,bins=100)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:05.805945Z","iopub.execute_input":"2022-02-01T18:10:05.80615Z","iopub.status.idle":"2022-02-01T18:10:05.810916Z","shell.execute_reply.started":"2022-02-01T18:10:05.806124Z","shell.execute_reply":"2022-02-01T18:10:05.810023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the histogram of train token counts above, we see that using a transformer width of 1024 is a good comprise of capturing most of the data's signal but not having too large a model. We could probably explore other widths between 512 and 1024 also. Or we could use widths of size 512 or smaller and use a stride which breaks a single text into multiple chunks (with possible overlap).","metadata":{}},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1-np.max(targets,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:05.812197Z","iopub.execute_input":"2022-02-01T18:10:05.812583Z","iopub.status.idle":"2022-02-01T18:10:05.822425Z","shell.execute_reply.started":"2022-02-01T18:10:05.812538Z","shell.execute_reply":"2022-02-01T18:10:05.821471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:05.823951Z","iopub.execute_input":"2022-02-01T18:10:05.824308Z","iopub.status.idle":"2022-02-01T18:10:06.381939Z","shell.execute_reply.started":"2022-02-01T18:10:05.824201Z","shell.execute_reply":"2022-02-01T18:10:06.381013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model\nWe will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a B class and I class for each of 7 labels. And we have an additional class (called O class) for tokens that do not belong to one of the 14 classes.","metadata":{}},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n    \n    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n    \n    x = backbone(tokens, attention_mask=attention)\n    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4),\n                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:10.145061Z","iopub.execute_input":"2022-02-01T18:10:10.145359Z","iopub.status.idle":"2022-02-01T18:10:10.154771Z","shell.execute_reply.started":"2022-02-01T18:10:10.145325Z","shell.execute_reply":"2022-02-01T18:10:10.153693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:11.924117Z","iopub.execute_input":"2022-02-01T18:10:11.924738Z","iopub.status.idle":"2022-02-01T18:10:11.970918Z","shell.execute_reply.started":"2022-02-01T18:10:11.924691Z","shell.execute_reply":"2022-02-01T18:10:11.970334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"srategy = tf.distribute.MirroredStrategy([\"GPU:0\",\"GPU:1\"])\ndef value_fn(ctx):\n    return tf.consstant(1.)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:15.080144Z","iopub.execute_input":"2022-02-01T18:10:15.080884Z","iopub.status.idle":"2022-02-01T18:10:15.094512Z","shell.execute_reply.started":"2022-02-01T18:10:15.080837Z","shell.execute_reply":"2022-02-01T18:10:15.093778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:10:16.563369Z","iopub.execute_input":"2022-02-01T18:10:16.564113Z","iopub.status.idle":"2022-02-01T18:10:55.500407Z","shell.execute_reply.started":"2022-02-01T18:10:16.564069Z","shell.execute_reply":"2022-02-01T18:10:55.499572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train or Load Model\nIf you provide a path in variable LOAD_MODEL_FROM above, then it will load your previously trained model. Otherwise it will train now.\n\nWe train 5 epochs of batch size 32 using learning rate 1e-4 for the first four and 1e-5 for the last epoch. I trained my model offline.","metadata":{}},{"cell_type":"code","source":"# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(123)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:11:00.994628Z","iopub.execute_input":"2022-02-01T18:11:00.994936Z","iopub.status.idle":"2022-02-01T18:11:01.012093Z","shell.execute_reply.started":"2022-02-01T18:11:00.994904Z","shell.execute_reply":"2022-02-01T18:11:01.010787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 7\nLRS = [1e-4, 1e-4, 1e-4, 1e-5, 1e-5]\ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:11:07.835763Z","iopub.execute_input":"2022-02-01T18:11:07.836026Z","iopub.status.idle":"2022-02-01T18:11:07.843081Z","shell.execute_reply.started":"2022-02-01T18:11:07.835998Z","shell.execute_reply":"2022-02-01T18:11:07.84232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_MODEL_FROM:\n    model.load_weights(f'{LOAD_MODEL_FROM}/long_v14.h5')\n    \n# OR TRAIN MODEL\nelse:\n    model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n          y = targets[train_idx,],\n          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                             targets[valid_idx,]),\n          callbacks = [lr_callback],\n          epochs = EPOCHS,\n          batch_size = 32,\n          verbose = 2)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:11:13.133763Z","iopub.execute_input":"2022-02-01T18:11:13.134033Z","iopub.status.idle":"2022-02-01T18:11:19.429106Z","shell.execute_reply.started":"2022-02-01T18:11:13.134003Z","shell.execute_reply":"2022-02-01T18:11:19.428551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate Model - Infer Out of fold (OOF)\nWe will now make predictions on the validation texts. Our model makes label predictions for each token, we need to convert this into a list of word indices for each label. Note that the tokens and words are not the same. A single word may be broken into multiple tokens. Therefore we need to first create a map to change token indices to word indices.","metadata":{}},{"cell_type":"code","source":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=2)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:12:18.416154Z","iopub.execute_input":"2022-02-01T18:12:18.41659Z","iopub.status.idle":"2022-02-01T19:15:04.972501Z","shell.execute_reply.started":"2022-02-01T18:12:18.416556Z","shell.execute_reply":"2022-02-01T19:15:04.971521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:16:18.058021Z","iopub.execute_input":"2022-02-01T19:16:18.058658Z","iopub.status.idle":"2022-02-01T19:16:18.064034Z","shell.execute_reply.started":"2022-02-01T19:16:18.058617Z","shell.execute_reply":"2022-02-01T19:16:18.063453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n    \n        # GET ID\n        if (id_num%100==0)&(verbose): \n            print(id_num,', ',end='')\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n        txt = open(name, 'r').read()\n        \n        '''txt = txt.replace(' .', '. ')\n        txt = txt.replace(' ,', ', ')'''\n        \n        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue #ignore first blank\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        # KEY:\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i<MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>=4:\n                all_predictions.append( (n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:16:42.158336Z","iopub.execute_input":"2022-02-01T19:16:42.158593Z","iopub.status.idle":"2022-02-01T19:16:42.179543Z","shell.execute_reply.started":"2022-02-01T19:16:42.158566Z","shell.execute_reply":"2022-02-01T19:16:42.178729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\noof.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:16:46.852835Z","iopub.execute_input":"2022-02-01T19:16:46.853117Z","iopub.status.idle":"2022-02-01T19:17:14.390211Z","shell.execute_reply.started":"2022-02-01T19:16:46.853084Z","shell.execute_reply":"2022-02-01T19:17:14.389482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The following classes are present in oof preds:')\noof['class'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:17:34.286962Z","iopub.execute_input":"2022-02-01T19:17:34.287791Z","iopub.status.idle":"2022-02-01T19:17:34.295955Z","shell.execute_reply.started":"2022-02-01T19:17:34.287746Z","shell.execute_reply":"2022-02-01T19:17:34.295111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Validation Metric","metadata":{}},{"cell_type":"code","source":"def calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:17:41.756516Z","iopub.execute_input":"2022-02-01T19:17:41.757212Z","iopub.status.idle":"2022-02-01T19:17:41.775033Z","shell.execute_reply.started":"2022-02-01T19:17:41.757178Z","shell.execute_reply":"2022-02-01T19:17:41.774368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = train.loc[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:17:44.848937Z","iopub.execute_input":"2022-02-01T19:17:44.851337Z","iopub.status.idle":"2022-02-01T19:17:44.936645Z","shell.execute_reply.started":"2022-02-01T19:17:44.851292Z","shell.execute_reply":"2022-02-01T19:17:44.935548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:17:49.315139Z","iopub.execute_input":"2022-02-01T19:17:49.315447Z","iopub.status.idle":"2022-02-01T19:17:51.968087Z","shell.execute_reply.started":"2022-02-01T19:17:49.315412Z","shell.execute_reply":"2022-02-01T19:17:51.967178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:17:56.911713Z","iopub.execute_input":"2022-02-01T19:17:56.91202Z","iopub.status.idle":"2022-02-01T19:17:56.926094Z","shell.execute_reply.started":"2022-02-01T19:17:56.911986Z","shell.execute_reply":"2022-02-01T19:17:56.925329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    \n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:18:03.28597Z","iopub.execute_input":"2022-02-01T19:18:03.286629Z","iopub.status.idle":"2022-02-01T19:18:03.350874Z","shell.execute_reply.started":"2022-02-01T19:18:03.286579Z","shell.execute_reply":"2022-02-01T19:18:03.350166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attention], \n                  batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:18:05.269268Z","iopub.execute_input":"2022-02-01T19:18:05.269745Z","iopub.status.idle":"2022-02-01T19:18:17.236309Z","shell.execute_reply.started":"2022-02-01T19:18:05.269714Z","shell.execute_reply":"2022-02-01T19:18:17.235715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET TEST PREDICIONS\nsub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:18:26.044934Z","iopub.execute_input":"2022-02-01T19:18:26.045363Z","iopub.status.idle":"2022-02-01T19:18:26.147162Z","shell.execute_reply.started":"2022-02-01T19:18:26.04532Z","shell.execute_reply":"2022-02-01T19:18:26.146339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nfor id_num in range(len(TEST_IDS)):\n        \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    \n    txt = txt.replace('?','.')\n    phrases = txt.split('.')[0:-1]\n    \n    phrase_start = [0]\n    for phrase in phrases:\n        phrase_len = len(phrase.split())\n        phrase_start.append(phrase_start[-1]+phrase_len)\n        \n    '''print(phrase_start)\n    print(' '.join(txt.split()[65:84]))'''\n    predstrings = sub.loc[sub.id==TEST_IDS[id_num]]['predictionstring']\n    \n    corr_predstrings=[]\n    for i, predstring in enumerate(predstrings):\n        predstart = int(predstring.split()[0])\n        predend = int(predstring.split()[-1])\n        \n        for j in range(len(phrase_start)-1):\n            if (predstart > phrase_start[j]) & (predstart < phrase_start[j+1]):\n                predstart = phrase_start[j]\n            if (predend > phrase_start[j]) & (predend < phrase_start[j+1]):\n                predend = phrase_start[j+1]\n            \n        predstring = ' '.join([str(val) for val in range(predstart,predend)])\n        corr_predstrings.append(predstring)\n    \n    sub.loc[sub.id==TEST_IDS[id_num], 'predictionstring'] = corr_predstrings\n    \n    \n        \nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:18:37.318046Z","iopub.execute_input":"2022-02-01T19:18:37.318335Z","iopub.status.idle":"2022-02-01T19:18:37.355376Z","shell.execute_reply.started":"2022-02-01T19:18:37.318303Z","shell.execute_reply":"2022-02-01T19:18:37.35454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Submission CSV\n# ","metadata":{}},{"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:18:43.247787Z","iopub.execute_input":"2022-02-01T19:18:43.248032Z","iopub.status.idle":"2022-02-01T19:18:43.25666Z","shell.execute_reply.started":"2022-02-01T19:18:43.248004Z","shell.execute_reply":"2022-02-01T19:18:43.255897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}