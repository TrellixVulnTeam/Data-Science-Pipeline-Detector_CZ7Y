{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T14:26:12.200715Z","iopub.execute_input":"2021-12-22T14:26:12.201049Z","iopub.status.idle":"2021-12-22T14:26:18.221152Z","shell.execute_reply.started":"2021-12-22T14:26:12.200953Z","shell.execute_reply":"2021-12-22T14:26:18.220274Z"},"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Code by MAMMAD ABBASLI    https://www.kaggle.com/mammadabbasli/friends-text-generator","metadata":{}},{"cell_type":"code","source":"import warnings\nimport nltk\nimport spacy\nimport re\nfrom spacy import displacy\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport plotly.express as px\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.models import load_model\nfrom wordcloud import WordCloud\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:26:51.560325Z","iopub.execute_input":"2021-12-22T14:26:51.56127Z","iopub.status.idle":"2021-12-22T14:27:05.134325Z","shell.execute_reply.started":"2021-12-22T14:26:51.561201Z","shell.execute_reply":"2021-12-22T14:27:05.133374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_of_file = '../input/feedback-prize-2021/train/00C819ADE423.txt'\ntext = open(path_of_file, 'r').read()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:29:30.475179Z","iopub.execute_input":"2021-12-22T14:29:30.47574Z","iopub.status.idle":"2021-12-22T14:29:30.483156Z","shell.execute_reply.started":"2021-12-22T14:29:30.475689Z","shell.execute_reply":"2021-12-22T14:29:30.482471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text[:2000]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:29:46.560458Z","iopub.execute_input":"2021-12-22T14:29:46.561144Z","iopub.status.idle":"2021-12-22T14:29:46.566565Z","shell.execute_reply.started":"2021-12-22T14:29:46.561108Z","shell.execute_reply":"2021-12-22T14:29:46.56576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\nstopword = nltk.corpus.stopwords.words('english')\ndef text_cleaning(text):\n    \n    text = re.sub(r'[^\\w\\s]', '',str(text))             #Punctuations\n    text=re.split(\"\\W+\",text)                           #Tokenizing\n    text=[word for word in text if word not in stopword]#Stop words\n    text = ' '.join(text)                              \n    return text\n\n\ndef frequent_of_words(string):\n    \n    clean_string = text_cleaning(string)\n    split_string = pd.DataFrame(clean_string.split(),columns=['Words'])\n    split_string = split_string.value_counts()[:1000].reset_index(drop=False)[:1000]\n    split_string.columns = ['Words','Count']\n    return split_string","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:30:13.552201Z","iopub.execute_input":"2021-12-22T14:30:13.552842Z","iopub.status.idle":"2021-12-22T14:30:14.436729Z","shell.execute_reply.started":"2021-12-22T14:30:13.5528Z","shell.execute_reply":"2021-12-22T14:30:14.435656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequent_words = frequent_of_words(text)\nfrequent_words[:15].style.background_gradient(cmap='summer')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:30:43.622751Z","iopub.execute_input":"2021-12-22T14:30:43.623021Z","iopub.status.idle":"2021-12-22T14:30:43.722503Z","shell.execute_reply.started":"2021-12-22T14:30:43.622994Z","shell.execute_reply":"2021-12-22T14:30:43.721497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.funnel(frequent_words[:15], x='Count', y='Words')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:31:04.156446Z","iopub.execute_input":"2021-12-22T14:31:04.156729Z","iopub.status.idle":"2021-12-22T14:31:05.52211Z","shell.execute_reply.started":"2021-12-22T14:31:04.156699Z","shell.execute_reply":"2021-12-22T14:31:05.521256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_for_cloud = []\nfor i in frequent_words.Words:\n    list_for_cloud.append(str(i))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:31:27.287303Z","iopub.execute_input":"2021-12-22T14:31:27.28768Z","iopub.status.idle":"2021-12-22T14:31:27.294082Z","shell.execute_reply.started":"2021-12-22T14:31:27.287641Z","shell.execute_reply":"2021-12-22T14:31:27.293154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width = 300, height = 300,\n                background_color ='black',\n                colormap='Set3',      \n                stopwords = stopword,\n                min_font_size = 10).generate(' '.join(list_for_cloud))\n  \n# plot the WordCloud image                       \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:34:22.82707Z","iopub.execute_input":"2021-12-22T14:34:22.827793Z","iopub.status.idle":"2021-12-22T14:34:23.320962Z","shell.execute_reply.started":"2021-12-22T14:34:22.827744Z","shell.execute_reply":"2021-12-22T14:34:23.3201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name_list = ['Nasa','Venus','Earth','Solar','Mars','Planets']\nscripts = []\nsplit_string = text.split()\nfor name in name_list:\n    scripts.append((name,split_string.count(name)))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:39:31.391654Z","iopub.execute_input":"2021-12-22T14:39:31.394019Z","iopub.status.idle":"2021-12-22T14:39:31.406145Z","shell.execute_reply.started":"2021-12-22T14:39:31.393899Z","shell.execute_reply":"2021-12-22T14:39:31.405249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#2F86A6','#34BE82','#2FDD92','#F2F013','#F9975D','#F4E185']\nsections = [scripts[0][1],\n            scripts[1][1],\n            scripts[2][1],\n            scripts[3][1],\n           scripts[4][1],\n           scripts[5][1]]\nplt.figure(figsize=(14, 8), dpi=75)\nplt.pie(sections, labels=name_list,colors=colors, \n        wedgeprops=dict( alpha=1),\n        startangle=90,\n        #explode = (0,0,0,0),\n        autopct = '%0.1f%%',\n         textprops={\n                'fontsize': 15, \n                'fontweight': 'normal'}\n            )\n\nplt.axis('equal')\nplt.title('Script Count',fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:40:29.930703Z","iopub.execute_input":"2021-12-22T14:40:29.930994Z","iopub.status.idle":"2021-12-22T14:40:30.13731Z","shell.execute_reply.started":"2021-12-22T14:40:29.930966Z","shell.execute_reply":"2021-12-22T14:40:30.136416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#After here only errors.","metadata":{}},{"cell_type":"code","source":"def target(text):\n    input_txt = text[:-1]\n    target = text[1:]\n    return input_txt, target\n\nvocab = sorted(set(text))\nchar_index = {u:i for i, u in enumerate(vocab)}\nindex_of_charachter = np.array(vocab)\nencoded_text = np.array([char_index[c] for c in text])\nchar_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\nsequence_lenght = 120\n#+1 because of zero indexing\nsequences = char_dataset.batch(sequence_lenght+1, drop_remainder=True)\ndataset = sequences.map(target)\nbatch_size = 128\nbuffer_size = 10000\ndataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:42:20.67056Z","iopub.execute_input":"2021-12-22T14:42:20.671038Z","iopub.status.idle":"2021-12-22T14:42:20.896804Z","shell.execute_reply.started":"2021-12-22T14:42:20.671005Z","shell.execute_reply":"2021-12-22T14:42:20.895781Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Function for Prepare Dataset for RNN Model","metadata":{}},{"cell_type":"code","source":"class PlanetsTextGenerator:\n    '''\n    TextGeneratorModel writed for generate text for Planets.\n    Class Bulit with Tenserflow.\n    This class has multifunction. It can train and save alse test ability.\n    '''\n\n    def loss_func(self,true,pred):\n         return sparse_categorical_crossentropy(true, pred, from_logits=True) \n        \n    def base_model(self,size_of_vocab=94,embedding_dim = 64,neurons = 1026,batch_size = 128):\n      \n        model = Sequential()\n        model.add(Embedding(size_of_vocab, embedding_dim,batch_input_shape=[batch_size, None]))\n        model.add(GRU(neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n        model.add(Dense(size_of_vocab))\n        model.compile(optimizer='adam', loss=self.loss_func) \n      \n        return model\n    \n    def train_model(self,dataset,epoch=2,train_vb_size=94,em_dim = 64,rnn_nrs = 1026,batchs = 128):\n        '''\n        This funtion used for train model with defined params\n\n        '''\n    \n        model = self.base_model(size_of_vocab = train_vb_size,\n                                embedding_dim = em_dim,\n                                neurons = rnn_nrs,\n                                batch_size = batchs)\n        print('\\n    --Model Creat Succesfully--   ')\n        model.fit(dataset,epochs=epoch)\n        model.save('planets.h5') \n        print('\\n    --Model Saved Succesfully--   ')\n        return model\n    \n    def use_trained_model(self,path):\n        '''\n        Function takes only path of trained model and generated sentence afterwords\n\n        '''\n        saved_model = self.base_model(size_of_vocab=94,embedding_dim = 64,neurons = 1026,batch_size=1)\n        saved_model.load_weights(path)\n        saved_model.build(tf.TensorShape([1, None]))\n        print('\\n    --Model ReCreat Succesfully--   ')\n        return saved_model\n    \n    def generate_dialog(self,model, start_sentence,characters=100):\n        '''\n        Purpose of this function is generate senctence\n        model : trained sequential model\n        start_sentence : according to which word will be generate\n        characters : lenght of generated sentence\n        '''\n    \n        num_generate = characters\n        change_char = {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6,'&': 7,\"'\": 8,'(': 9,')': 10, '*': 11,'+': 12,',': 13,'-': 14,'.': 15,'/': 16,'0': 17,'1': 18,'2': 19,'3': 20,'4': 21,'5': 22,'6': 23,'7': 24,\n        '8': 25,'9': 26,':': 27,';': 28,'<': 29,'=': 30,'>': 31,'?': 32,'@': 33,'A': 34,'B': 35,'C': 36,'D': 37,'E': 38,'F': 39,'G': 40,'H': 41,'I': 42,'J': 43,'K': 44,'L': 45,'M': 46,'N': 47,'O': 48,'P': 49,\n        'Q': 50,'R': 51,'S': 52,'T': 53,'U': 54,'V': 55,'W': 56,'X': 57,'Y': 58,'Z': 59,'[': 60,']': 61,'^': 62,'_': 63,'`': 64,'a': 65,'b': 66,'c': 67,'d': 68,'e': 69,'f': 70,'g': 71,'h': 72, 'i': 73,'j': 74,\n        'k': 75,'l': 76,'m': 77,'n': 78,'o': 79,'p': 80,'q': 81,'r': 82,'s': 83,'t': 84,'u': 85,'v': 86,'w': 87,'x': 88,'y': 89,'z': 90,'{': 91,'|': 92, '}': 93}\n        vocab = ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n                 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n                 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}']\n        \n        index_of_charachter = np.array(vocab)\n        # Vecotrizing sentecnce\n        input_sentence = [change_char[chrr] for chrr in start_sentence]\n        input_sentence = tf.expand_dims(input_sentence, 0)\n        generated_txt = []\n        model.reset_states()\n        print('\\n    --Dialog Creating--   ')\n        for i in range(num_generate):\n            \n            predictions = model(input_sentence)\n            predictions = tf.squeeze(predictions, 0)\n            predictions = predictions / 1.0\n            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n            input_sentence = tf.expand_dims([predicted_id], 0)\n            generated_txt.append(index_of_charachter[predicted_id])\n       \n        return (start_sentence + ''.join(generated_txt))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:45:19.762184Z","iopub.execute_input":"2021-12-22T14:45:19.762634Z","iopub.status.idle":"2021-12-22T14:45:19.793908Z","shell.execute_reply.started":"2021-12-22T14:45:19.762587Z","shell.execute_reply":"2021-12-22T14:45:19.793292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = PlanetsTextGenerator()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:46:25.333904Z","iopub.execute_input":"2021-12-22T14:46:25.334234Z","iopub.status.idle":"2021-12-22T14:46:25.339357Z","shell.execute_reply.started":"2021-12-22T14:46:25.334181Z","shell.execute_reply":"2021-12-22T14:46:25.338352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_model = generator.train_model(dataset,epoch=35)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:46:44.314331Z","iopub.execute_input":"2021-12-22T14:46:44.314632Z","iopub.status.idle":"2021-12-22T14:46:44.818082Z","shell.execute_reply.started":"2021-12-22T14:46:44.314603Z","shell.execute_reply":"2021-12-22T14:46:44.816988Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:47:33.646443Z","iopub.execute_input":"2021-12-22T14:47:33.646769Z","iopub.status.idle":"2021-12-22T14:47:33.682136Z","shell.execute_reply.started":"2021-12-22T14:47:33.646729Z","shell.execute_reply":"2021-12-22T14:47:33.681136Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = './planets.h5'\ntest_model = generator.use_trained_model(path)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T14:48:35.618166Z","iopub.execute_input":"2021-12-22T14:48:35.618512Z","iopub.status.idle":"2021-12-22T14:48:36.026129Z","shell.execute_reply.started":"2021-12-22T14:48:35.618464Z","shell.execute_reply":"2021-12-22T14:48:36.024945Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]}]}