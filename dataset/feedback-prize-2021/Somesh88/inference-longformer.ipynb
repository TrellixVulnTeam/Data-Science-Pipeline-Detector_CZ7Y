{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nfrom tqdm import tqdm \nfrom torch.utils.data import Dataset, DataLoader \nfrom torch.optim import Adam\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport os \n\nimport sys \nimport gc ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-15T11:21:53.668794Z","iopub.execute_input":"2022-01-15T11:21:53.669388Z","iopub.status.idle":"2022-01-15T11:21:55.056417Z","shell.execute_reply.started":"2022-01-15T11:21:53.669291Z","shell.execute_reply":"2022-01-15T11:21:55.05559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# from kaggle_datasets import KaggleDatasets\n# GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"allenailongformerbase4096\")","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:21:55.058287Z","iopub.execute_input":"2022-01-15T11:21:55.058535Z","iopub.status.idle":"2022-01-15T11:21:55.063408Z","shell.execute_reply.started":"2022-01-15T11:21:55.058508Z","shell.execute_reply":"2022-01-15T11:21:55.062778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !gsutil ls $GCS_DS_PATH","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:21:55.064489Z","iopub.execute_input":"2022-01-15T11:21:55.065043Z","iopub.status.idle":"2022-01-15T11:21:55.0745Z","shell.execute_reply.started":"2022-01-15T11:21:55.065004Z","shell.execute_reply":"2022-01-15T11:21:55.073517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"done\")","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:21:55.076726Z","iopub.execute_input":"2022-01-15T11:21:55.077255Z","iopub.status.idle":"2022-01-15T11:21:55.084272Z","shell.execute_reply.started":"2022-01-15T11:21:55.077217Z","shell.execute_reply":"2022-01-15T11:21:55.083571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\nIDS = train.id.unique()\nMAX_LEN = 1024\nfrom transformers import LongformerTokenizerFast, LongformerForTokenClassification\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = LongformerTokenizerFast.from_pretrained(\"../input/allenailongformerbase4096/longformer\")\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\n# HELPER VARIABLES\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:21:55.085605Z","iopub.execute_input":"2022-01-15T11:21:55.086122Z","iopub.status.idle":"2022-01-15T11:22:02.343975Z","shell.execute_reply.started":"2022-01-15T11:21:55.086085Z","shell.execute_reply":"2022-01-15T11:22:02.343279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:22:02.345162Z","iopub.execute_input":"2022-01-15T11:22:02.345405Z","iopub.status.idle":"2022-01-15T11:22:02.35845Z","shell.execute_reply.started":"2022-01-15T11:22:02.345374Z","shell.execute_reply":"2022-01-15T11:22:02.357593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:22:02.360823Z","iopub.execute_input":"2022-01-15T11:22:02.361285Z","iopub.status.idle":"2022-01-15T11:22:02.417497Z","shell.execute_reply.started":"2022-01-15T11:22:02.361247Z","shell.execute_reply":"2022-01-15T11:22:02.416763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(torch.nn.Module):\n    def __init__(self,backbone):\n        super(Model, self).__init__()\n        self.backbone = backbone\n        self.linear_1 = torch.nn.Linear(15,128)\n        self.relu = torch.nn.ReLU()\n        self.linear_2 = torch.nn.Linear(128, 15)\n        self.softmax = torch.nn.Softmax()\n    \n    def forward(self, inp, att):\n        outs = backbone(inp,att)\n        outs = self.linear_1(outs.logits)\n        outs = self.relu(outs)\n        outs = self.linear_2(outs)\n        outs = self.softmax(outs)\n        return outs ","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:22:02.419926Z","iopub.execute_input":"2022-01-15T11:22:02.42039Z","iopub.status.idle":"2022-01-15T11:22:02.427298Z","shell.execute_reply.started":"2022-01-15T11:22:02.420352Z","shell.execute_reply":"2022-01-15T11:22:02.426479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LongformerTokenizerFast, LongformerForTokenClassification\n# THE TOKENS AND ATTENTION ARRAYS\nbackbone =LongformerForTokenClassification.from_pretrained('../input/allenailongformerbase4096/longformer',num_labels = 15 )","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:22:02.429274Z","iopub.execute_input":"2022-01-15T11:22:02.429996Z","iopub.status.idle":"2022-01-15T11:22:10.83283Z","shell.execute_reply.started":"2022-01-15T11:22:02.429935Z","shell.execute_reply":"2022-01-15T11:22:10.831988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tokens, test_attention","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:23:25.596903Z","iopub.execute_input":"2022-01-15T11:23:25.597677Z","iopub.status.idle":"2022-01-15T11:23:25.604109Z","shell.execute_reply.started":"2022-01-15T11:23:25.597635Z","shell.execute_reply":"2022-01-15T11:23:25.603117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(backbone = backbone)\nmodel.load_state_dict(torch.load(\"../input/model-weights-longformer-pytorch/model_weights7.pth\"))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:23:25.732438Z","iopub.execute_input":"2022-01-15T11:23:25.732662Z","iopub.status.idle":"2022-01-15T11:23:38.680321Z","shell.execute_reply.started":"2022-01-15T11:23:25.732637Z","shell.execute_reply":"2022-01-15T11:23:38.679441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test_data(torch.utils.data.Dataset):\n    def __init__(self, token, attention):\n        self.token = token \n        self.attention = attention \n#         self.targets = targets \n    def __len__(self):\n        return len(self.token)\n    \n    def __getitem__(self, idx):\n        tok = self.token[idx]\n        att = self.attention[idx]\n#         tt = self.targets[idx]\n#         tt = torch.tensor(tt, dtype = torch.float)\n        tok = torch.tensor(tok)\n        att = torch.tensor(att)\n        return [tok,att]","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:23:38.682Z","iopub.execute_input":"2022-01-15T11:23:38.682449Z","iopub.status.idle":"2022-01-15T11:23:38.689207Z","shell.execute_reply.started":"2022-01-15T11:23:38.682413Z","shell.execute_reply":"2022-01-15T11:23:38.688567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_d = Test_data(token = test_tokens , attention = test_attention)\ntest_f = torch.utils.data.DataLoader(test_d, batch_size = 6, shuffle = False )","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:23:38.690728Z","iopub.execute_input":"2022-01-15T11:23:38.691143Z","iopub.status.idle":"2022-01-15T11:23:38.701673Z","shell.execute_reply.started":"2022-01-15T11:23:38.691107Z","shell.execute_reply":"2022-01-15T11:23:38.700987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_outs = []\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\nfor idx , data in tqdm(enumerate(test_f)):\n    #= lights will guide you HOME and ignite your BONES and I'll try to FIX YOU!! \n    ins = data[0].to(device)\n    att = data[1].to(device)\n    outs = model(inp = ins , att = att)\n    total_outs.append(outs)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:23:38.703643Z","iopub.execute_input":"2022-01-15T11:23:38.703872Z","iopub.status.idle":"2022-01-15T11:23:40.149265Z","shell.execute_reply.started":"2022-01-15T11:23:38.703837Z","shell.execute_reply":"2022-01-15T11:23:40.148554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_outs = total_outs[0].cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T11:23:40.150471Z","iopub.execute_input":"2022-01-15T11:23:40.151196Z","iopub.status.idle":"2022-01-15T11:23:40.155648Z","shell.execute_reply.started":"2022-01-15T11:23:40.151157Z","shell.execute_reply":"2022-01-15T11:23:40.154989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\nfinal_preds = []\nfinal_scores = []\nraw_preds = total_outs.copy()\n\npred_class = np.argmax(raw_preds, axis=2)\npred_scrs = np.max(raw_preds, axis=2)\nfor pred, pred_scr in zip(pred_class, pred_scrs):\n        pred = pred.tolist()\n        pred_scr = pred_scr.tolist()\n        final_preds.append(pred)\n        final_scores.append(pred_scr)\n\n# for j in range(len(test_samples)):\n#     tt = [id_target_map[p] for p in final_preds[j][1:]]\n#     tt_score = final_scores[j][1:]\n#     test_samples[j][\"preds\"] = tt\n#     test_samples[j][\"pred_scores\"] = tt_score\n\nfinal_preds, final_scores\n\ndef _prepare_test_data_helper(tokenizer, ids):\n    test_samples = []\n    for idx in ids:\n        filename = os.path.join(\"../input/feedback-prize-2021/\", \"test\", idx + \".txt\")\n        with open(filename, \"r\") as f:\n            text = f.read()\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=False,\n            return_offsets_mapping=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        offset_mapping = encoded_text[\"offset_mapping\"]\n\n        sample = {\n            \"id\": idx,\n            \"input_ids\": input_ids,\n            \"text\": text,\n            \"offset_mapping\": offset_mapping,\n        }\n\n        test_samples.append(sample)\n    return test_samples\n\n\ndef prepare_test_data(df, tokenizer):\n    test_samples = []\n    ids = df[\"id\"].unique()\n    ids_splits = np.array_split(ids, 4)\n\n    results = [_prepare_test_data_helper(tokenizer, idx) for idx in ids_splits]\n    \n    for result in results:\n        test_samples.extend(result)\n\n    return test_samples\n\ndf = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"sample_submission.csv\"))\ndf_ids = df[\"id\"].unique()\n\ntest_samples = prepare_test_data(df,tokenizer = tokenizer)\n\npd.DataFrame(test_samples)\n\noutput_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}\nfor j in range(len(test_samples)):\n    tt = [ids_to_labels[p] for p in final_preds[j][1:]]\n    tt_score = final_scores[j][1:]\n    test_samples[j][\"preds\"] = tt\n    test_samples[j][\"pred_scores\"] = tt_score\n\npd.DataFrame(test_samples)\n\ndef jn(pst, start, end):\n    return \" \".join([str(x) for x in pst[start:end]])\n\n\ndef link_evidence(oof):\n    thresh = 1\n    idu = oof['id'].unique()\n    idc = idu[1]\n    eoof = oof[oof['class'] == \"Evidence\"]\n    neoof = oof[oof['class'] != \"Evidence\"]\n    for thresh2 in range(26,27, 1):\n        retval = []\n        for idv in idu:\n            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n                   'Counterclaim', 'Rebuttal']:\n                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for i,r in q.iterrows():\n                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n                start = 1\n                end = 1\n                for i in range(2,len(pst)):\n                    cur = pst[i]\n                    end = i\n                    #if pst[start] == 205:\n                    #   print(cur, pst[start], cur - pst[start])\n                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end+1))\n                #print(v)\n                retval.append(v)\n        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n        roof = roof.merge(neoof, how='outer')\n        return roof\n\nproba_thresh = {\n    \"Lead\": 0,\n    \"Position\": 0,\n    \"Evidence\": 0,\n    \"Claim\": 0,\n    \"Concluding Statement\": 0,\n    \"Counterclaim\": 0,\n    \"Rebuttal\": 0,\n}\n\nmin_thresh = {\n    \"Lead\": 9,\n    \"Position\": 5,\n    \"Evidence\": 14,\n    \"Claim\": 3,\n    \"Concluding Statement\": 11,\n    \"Counterclaim\": 6,\n    \"Rebuttal\": 4,\n}\n\nsubmission = []\nfor sample_idx, sample in enumerate(test_samples):\n    preds = sample[\"preds\"]\n    offset_mapping = sample[\"offset_mapping\"]\n    sample_id = sample[\"id\"]\n    sample_text = sample[\"text\"]\n    sample_input_ids = sample[\"input_ids\"]\n    sample_pred_scores = sample[\"pred_scores\"]\n    sample_preds = []\n\n    if len(preds) < len(offset_mapping):\n        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n    \n    idx = 0\n    phrase_preds = []\n    while idx < len(offset_mapping):\n        start, _ = offset_mapping[idx]\n        if preds[idx] != \"O\":\n            label = preds[idx][2:]\n        else:\n            label = \"O\"\n        phrase_scores = []\n        phrase_scores.append(sample_pred_scores[idx])\n        idx += 1\n        while idx < len(offset_mapping):\n            if label == \"O\":\n                matching_label = \"O\"\n            else:\n                matching_label = f\"I-{label}\"\n            if preds[idx] == matching_label:\n                _, end = offset_mapping[idx]\n                phrase_scores.append(sample_pred_scores[idx])\n                idx += 1\n            else:\n                break\n        if \"end\" in locals():\n            phrase = sample_text[start:end]\n            phrase_preds.append((phrase, start, end, label, phrase_scores))\n\n    temp_df = []\n    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n        word_start = len(sample_text[:start].split())\n        word_end = word_start + len(sample_text[start:end].split())\n        word_end = min(word_end, len(sample_text.split()))\n        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n        if label != \"O\":\n            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n                if len(ps.split()) >= min_thresh[label]:\n                    temp_df.append((sample_id, label, ps))\n    \n    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n    submission.append(temp_df)\n\nsubmission\n\nsubmission = pd.concat(submission).reset_index(drop=True)\nsubmission = link_evidence(submission)\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-01-15T09:01:43.460821Z","iopub.execute_input":"2022-01-15T09:01:43.46112Z","iopub.status.idle":"2022-01-15T09:01:43.725582Z","shell.execute_reply.started":"2022-01-15T09:01:43.46108Z","shell.execute_reply":"2022-01-15T09:01:43.724936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}