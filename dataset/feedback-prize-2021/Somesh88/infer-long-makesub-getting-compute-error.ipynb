{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install --upgrade torch\nimport pandas as pd \nimport torch \nimport numpy as np\nimport os \nfrom tqdm import tqdm ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-26T09:47:10.96539Z","iopub.execute_input":"2022-01-26T09:47:10.965755Z","iopub.status.idle":"2022-01-26T09:47:10.970744Z","shell.execute_reply.started":"2022-01-26T09:47:10.965697Z","shell.execute_reply":"2022-01-26T09:47:10.969035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LongformerTokenizerFast\ntokenizer = LongformerTokenizerFast.from_pretrained(\"../input/allenailongformerbase4096/longformer\")\n","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:12.035078Z","iopub.execute_input":"2022-01-26T09:47:12.035343Z","iopub.status.idle":"2022-01-26T09:47:15.655103Z","shell.execute_reply.started":"2022-01-26T09:47:12.035313Z","shell.execute_reply":"2022-01-26T09:47:15.654307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\n\nclass LongformerSingle(nn.Module):\n    def __init__(self, backbone, config):\n        super().__init__()\n        self.config = config\n        self.backbone = backbone\n        self.classifier = nn.Linear(config.hidden_size, 15)\n\n    def forward(self, tokens, attention_mask):\n        transformer_out = self.backbone(\n            tokens, attention_mask=attention_mask)\n        sequence_output = transformer_out.last_hidden_state\n        logits = self.classifier(sequence_output)\n        logits = torch.softmax(logits, dim=-1)\n        return logits\n\n\ndef build_model():\n    config = AutoConfig.from_pretrained(\n        \"../input/allenailongformerbase4096/longformer/config.json\")\n    backbone = AutoModel.from_pretrained(\n        \"../input/allenailongformerbase4096/longformer/pytorch_model.bin\", config=config)\n    return LongformerSingle(backbone=backbone, config=config)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:15.656822Z","iopub.execute_input":"2022-01-26T09:47:15.657122Z","iopub.status.idle":"2022-01-26T09:47:15.675575Z","shell.execute_reply.started":"2022-01-26T09:47:15.657089Z","shell.execute_reply":"2022-01-26T09:47:15.674684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:15.678261Z","iopub.execute_input":"2022-01-26T09:47:15.678567Z","iopub.status.idle":"2022-01-26T09:47:24.100908Z","shell.execute_reply.started":"2022-01-26T09:47:15.678533Z","shell.execute_reply":"2022-01-26T09:47:24.100146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"../input/train-longformer/saved_model4.pth\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:24.103079Z","iopub.execute_input":"2022-01-26T09:47:24.103315Z","iopub.status.idle":"2022-01-26T09:47:35.7716Z","shell.execute_reply.started":"2022-01-26T09:47:24.103282Z","shell.execute_reply":"2022-01-26T09:47:35.770883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:35.773176Z","iopub.execute_input":"2022-01-26T09:47:35.77372Z","iopub.status.idle":"2022-01-26T09:47:35.779605Z","shell.execute_reply.started":"2022-01-26T09:47:35.773661Z","shell.execute_reply":"2022-01-26T09:47:35.778708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting model up for evaluation \nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:35.781274Z","iopub.execute_input":"2022-01-26T09:47:35.781826Z","iopub.status.idle":"2022-01-26T09:47:35.796462Z","shell.execute_reply.started":"2022-01-26T09:47:35.781787Z","shell.execute_reply":"2022-01-26T09:47:35.795703Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}\n# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:35.798077Z","iopub.execute_input":"2022-01-26T09:47:35.798681Z","iopub.status.idle":"2022-01-26T09:47:35.81217Z","shell.execute_reply.started":"2022-01-26T09:47:35.798642Z","shell.execute_reply":"2022-01-26T09:47:35.811222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\nMAX_LEN = 1024\ntest_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\noffset_mapping =[]\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']\n    offset_mapping.append(tokens['offset_mapping'])","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:35.81396Z","iopub.execute_input":"2022-01-26T09:47:35.814257Z","iopub.status.idle":"2022-01-26T09:47:35.869086Z","shell.execute_reply.started":"2022-01-26T09:47:35.814219Z","shell.execute_reply":"2022-01-26T09:47:35.86842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:01:27.102519Z","iopub.execute_input":"2022-01-26T10:01:27.103123Z","iopub.status.idle":"2022-01-26T10:01:27.111932Z","shell.execute_reply.started":"2022-01-26T10:01:27.103084Z","shell.execute_reply":"2022-01-26T10:01:27.111004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    preds = model(torch.tensor(test_tokens), torch.tensor(test_attention,dtype = torch.float16))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:47:35.870727Z","iopub.execute_input":"2022-01-26T09:47:35.870909Z","iopub.status.idle":"2022-01-26T09:48:06.24778Z","shell.execute_reply.started":"2022-01-26T09:47:35.870885Z","shell.execute_reply":"2022-01-26T09:48:06.247029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"test pred shape : \", preds.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:48:06.249842Z","iopub.execute_input":"2022-01-26T09:48:06.250121Z","iopub.status.idle":"2022-01-26T09:48:06.257696Z","shell.execute_reply.started":"2022-01-26T09:48:06.250078Z","shell.execute_reply":"2022-01-26T09:48:06.256955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-26T09:55:25.317528Z","iopub.execute_input":"2022-01-26T09:55:25.317803Z","iopub.status.idle":"2022-01-26T09:55:25.325128Z","shell.execute_reply.started":"2022-01-26T09:55:25.317772Z","shell.execute_reply":"2022-01-26T09:55:25.324247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0: 'Lead', 1: 'Position', 2: 'Evidence', 3: 'Claim', 4: 'Concluding Statement', 5: 'Counterclaim', 6: 'Rebuttal', 7: 'blank'}\n\ndef get_preds(dataset = 'train', verbose = True, text_ids = None, preds = None):\n    all_predictions = []\n    for id_num in range(len(preds)):\n#         print(id_num) # predictions from preds\n        if (id_num % 100 == 0) & (verbose): print(id_num, ', ', end = '') # for monitoring stuff \n        n = text_ids[id_num] # n here we are getting test_id for that num\n#         print(n)\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n#         print(name)\n        txt = open(name, 'r').read() # opening text file \n        tokens = tokenizer.encode_plus(txt, max_length = MAX_LEN, padding = 'max_length', truncation = True, return_offsets_mapping = True)\n        off = tokens['offset_mapping']\n        w = []\n#         print(\"encoding and tokenization done\")\n        \n        blank = True\n        for i in range(len(txt)):\n            if (txt[i] != ' ') & (txt[i] != '\\n') & (blank == True):\n                w.append(i)\n                blank = False\n            elif (txt[i] == ' ') | (txt[i] == '\\n'):\n                blank = True\n        w.append(1e6)\n        word_map = -1 * np.ones(MAX_LEN, dtype = 'int32')\n        w_i = 0\n        for i in range(len(off)):\n#             print(off[i][1],\" is zero? \")\n            if off[i][1] == 0: continue\n            while off[i][0] >= w[w_i + 1]: w_i += 1\n#             if int(w_i)!= 0 : print(w_i, \"there is not an error\")\n            word_map[i] = int(w_i)\n#         print(word_map)\n        pred = preds[id_num,] / 2.0\n        i = 0\n#         print(pred)\n        while i < MAX_LEN:\n            prediction = []\n            start = int(pred[i])\n            if start in [0, 1, 2, 3, 4, 5, 6, 7]:\n#                 print(word_map[i])\n                prediction.append(word_map[i])\n                i += 1\n                if i >= MAX_LEN: break\n                while pred[i] == start + 0.5:\n                    if not word_map[i] in prediction: prediction.append(word_map[i])\n                    i += 1\n                    if i >= MAX_LEN: break\n            else: i += 1\n            prediction = [x for x in prediction if x != -1]\n#             print(prediction) # we are getting prediction as the blank array\n            if len(prediction) > 4: all_predictions.append((n, target_map_rev[int(start)], ' '.join([str(x) for x in prediction])))\n    \n#     print(all_predictions)\n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id', 'class', 'predictionstring']\n    return df\n\n# def calc_overlap(row):\n#     set_pred = set(row.predictionstring_pred.split(' '))\n#     set_gt = set(row.predictionstring_gt.split(' '))\n#     len_gt = len(set_gt)\n#     len_pred = len(set_pred)\n#     inter = len(set_gt.intersection(set_pred))\n#     overlap_1 = inter / len_gt\n#     overlap_2 = inter / len_pred\n#     return [overlap_1, overlap_2]\n\n# def score_feedback_comp(pred_df, gt_df):\n#     gt_df = gt_df[['id', 'discourse_type', 'predictionstring']].reset_index(drop = True).copy()\n#     pred_df = pred_df[['id', 'class', 'predictionstring']].reset_index(drop = True).copy()\n#     pred_df['pred_id'] = pred_df.index\n#     gt_df['gt_id'] = gt_df.index\n#     joined = pred_df.merge(gt_df, left_on = ['id', 'class'], right_on = ['id', 'discourse_type'], how = 'outer', suffixes = ('_pred', '_gt'))\n#     joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n#     joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n#     joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n#     joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n#     joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n#     joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n#     joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n#     tp_pred_ids = joined.query('potential_TP')         .sort_values('max_overlap', ascending=False)         .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n#     fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n#     matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n#     unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n#     TP = len(tp_pred_ids)\n#     FP = len(fp_pred_ids)\n#     FN = len(unmatched_gt_ids)\n#     my_f1_score = TP / (TP + 0.5*(FP+FN))\n#     return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:35:34.884121Z","iopub.execute_input":"2022-01-26T10:35:34.884643Z","iopub.status.idle":"2022-01-26T10:35:34.902868Z","shell.execute_reply.started":"2022-01-26T10:35:34.884602Z","shell.execute_reply":"2022-01-26T10:35:34.90217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.argmax(preds, axis=-1)\nprint('Predicting Test...')\nsub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds)\n\nmap_clip = {'Lead':9, 'Position':5, 'Evidence':14, 'Claim':3, 'Concluding Statement':11, 'Counterclaim':6, 'Rebuttal':4}\ndef threshold(df):\n    df = df.copy()\n    for key, value in map_clip.items():\n    # if df.loc[df['class']==key,'len'] < value \n        index = df.loc[df['class']==key].query(f'len<{value}').index\n        df.drop(index, inplace = True)\n    return df\n\nsub['len'] = sub['predictionstring'].apply(lambda x:len(x.split()))\nsub = threshold(sub)\n\nsub[['id','class','predictionstring']].to_csv('submission.csv', index = False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:35:35.084223Z","iopub.execute_input":"2022-01-26T10:35:35.084784Z","iopub.status.idle":"2022-01-26T10:35:35.269787Z","shell.execute_reply.started":"2022-01-26T10:35:35.08475Z","shell.execute_reply":"2022-01-26T10:35:35.269082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:16:20.229035Z","iopub.execute_input":"2022-01-26T10:16:20.22951Z","iopub.status.idle":"2022-01-26T10:16:20.25396Z","shell.execute_reply.started":"2022-01-26T10:16:20.229461Z","shell.execute_reply":"2022-01-26T10:16:20.253199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:42:28.40303Z","iopub.execute_input":"2022-01-20T11:42:28.403724Z","iopub.status.idle":"2022-01-20T11:42:28.410502Z","shell.execute_reply.started":"2022-01-20T11:42:28.403688Z","shell.execute_reply":"2022-01-20T11:42:28.40969Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_samples = pd.DataFrame()\n# test_samples['id'] = TEST_IDS\n# # test_samples[\"input_ids\"]= test_tokens \n# # test_samples[\"test_attention\"] = test_attention\n# test_samples[\"preds\"] = None \n# test_samples[\"pred_scores\"] = None\n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:50:28.722703Z","iopub.execute_input":"2022-01-20T11:50:28.723041Z","iopub.status.idle":"2022-01-20T11:50:28.735803Z","shell.execute_reply.started":"2022-01-20T11:50:28.723007Z","shell.execute_reply":"2022-01-20T11:50:28.735143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_samples","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:50:47.489544Z","iopub.execute_input":"2022-01-20T11:50:47.490039Z","iopub.status.idle":"2022-01-20T11:50:47.502775Z","shell.execute_reply.started":"2022-01-20T11:50:47.490005Z","shell.execute_reply":"2022-01-20T11:50:47.502137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"final_preds = []\nfinal_scores = []\n\n\npred_class = np.argmax(preds, axis=2)\npred_scrs = np.max(preds.numpy(), axis=2)\nfor pred, pred_scr in zip(pred_class, pred_scrs):\n        pred = pred.tolist()\n        pred_scr = pred_scr.tolist()\n        final_preds.append(pred)\n        final_scores.append(pred_scr)\n\nfor j in range(len(test_samples)):\n    tt = [p for p in final_preds[j][1:]]\n    tt_score = final_scores[j][1:]\n    test_samples[\"preds\"][j] = tt\n    test_samples[\"pred_scores\"][j]= tt_score","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:51:13.821015Z","iopub.execute_input":"2022-01-20T11:51:13.821595Z","iopub.status.idle":"2022-01-20T11:51:13.836219Z","shell.execute_reply.started":"2022-01-20T11:51:13.821556Z","shell.execute_reply":"2022-01-20T11:51:13.835379Z"}}},{"cell_type":"markdown","source":"for i in iterrows(test_samples):","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:53:00.721248Z","iopub.execute_input":"2022-01-20T11:53:00.721792Z","iopub.status.idle":"2022-01-20T11:53:00.741831Z","shell.execute_reply.started":"2022-01-20T11:53:00.721753Z","shell.execute_reply":"2022-01-20T11:53:00.741138Z"}}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:56:11.069339Z","iopub.execute_input":"2022-01-20T11:56:11.07003Z","iopub.status.idle":"2022-01-20T11:56:11.086759Z","shell.execute_reply.started":"2022-01-20T11:56:11.069986Z","shell.execute_reply":"2022-01-20T11:56:11.085936Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-20T12:00:35.626541Z","iopub.execute_input":"2022-01-20T12:00:35.627155Z","iopub.status.idle":"2022-01-20T12:00:35.634418Z","shell.execute_reply.started":"2022-01-20T12:00:35.627117Z","shell.execute_reply":"2022-01-20T12:00:35.633449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def jn(pst, start, end):\n#     return \" \".join([str(x) for x in pst[start:end]])\n\n\n# def link_evidence(oof):\n#     thresh = 1\n#     idu = oof['id'].unique()\n#     idc = idu[1]\n#     eoof = oof[oof['class'] == \"Evidence\"]\n#     neoof = oof[oof['class'] != \"Evidence\"]\n#     for thresh2 in range(26,27, 1):\n#         retval = []\n#         for idv in idu:\n#             for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n#                    'Counterclaim', 'Rebuttal']:\n#                 q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n#                 if len(q) == 0:\n#                     continue\n#                 pst = []\n#                 for i,r in q.iterrows():\n#                     pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n#                 start = 1\n#                 end = 1\n#                 for i in range(2,len(pst)):\n#                     cur = pst[i]\n#                     end = i\n#                     #if pst[start] == 205:\n#                     #   print(cur, pst[start], cur - pst[start])\n#                     if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n#                         retval.append((idv, c, jn(pst, start, end)))\n#                         start = i + 1\n#                 v = (idv, c, jn(pst, start, end+1))\n#                 #print(v)\n#                 retval.append(v)\n#         roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n#         roof = roof.merge(neoof, how='outer')\n#         return roof\n    \n# proba_thresh = {\n#     \"Lead\": 0.7,\n#     \"Position\": 0.55,\n#     \"Evidence\": 0.65,\n#     \"Claim\": 0.55,\n#     \"Concluding Statement\": 0.7,\n#     \"Counterclaim\": 0.5,\n#     \"Rebuttal\": 0.55,\n# }\n\n# min_thresh = {\n#     \"Lead\": 9,\n#     \"Position\": 5,\n#     \"Evidence\": 14,\n#     \"Claim\": 3,\n#     \"Concluding Statement\": 11,\n#     \"Counterclaim\": 6,\n#     \"Rebuttal\": 4,\n# }\n\n# submission = []\n# for sample_idx, sample in enumerate(test_samples):\n#     preds = sample[\"preds\"]\n#     offset_mapping = sample[\"offset_mapping\"]\n#     sample_id = sample[\"id\"]\n#     sample_text = sample[\"text\"]\n#     sample_input_ids = sample[\"input_ids\"]\n#     sample_pred_scores = sample[\"pred_scores\"]\n#     sample_preds = []\n\n#     if len(preds) < len(offset_mapping):\n#         preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n#         sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n    \n#     idx = 0\n#     phrase_preds = []\n#     while idx < len(offset_mapping):\n#         start, _ = offset_mapping[idx]\n#         if preds[idx] != \"O\":\n#             label = preds[idx][2:]\n#         else:\n#             label = \"O\"\n#         phrase_scores = []\n#         phrase_scores.append(sample_pred_scores[idx])\n#         idx += 1\n#         while idx < len(offset_mapping):\n#             if label == \"O\":\n#                 matching_label = \"O\"\n#             else:\n#                 matching_label = f\"I-{label}\"\n#             if preds[idx] == matching_label:\n#                 _, end = offset_mapping[idx]\n#                 phrase_scores.append(sample_pred_scores[idx])\n#                 idx += 1\n#             else:\n#                 break\n#         if \"end\" in locals():\n#             phrase = sample_text[start:end]\n#             phrase_preds.append((phrase, start, end, label, phrase_scores))\n\n#     temp_df = []\n#     for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n#         word_start = len(sample_text[:start].split())\n#         word_end = word_start + len(sample_text[start:end].split())\n#         word_end = min(word_end, len(sample_text.split()))\n#         ps = \" \".join([str(x) for x in range(word_start, word_end)])\n#         if label != \"O\":\n#             if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n#                 if len(ps.split()) >= min_thresh[label]:\n#                     temp_df.append((sample_id, label, ps))\n    \n#     temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n#     submission.append(temp_df)\n\n# submission = pd.concat(submission).reset_index(drop=True)\n# submission = link_evidence(submission)\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:51:17.370621Z","iopub.execute_input":"2022-01-20T11:51:17.371204Z","iopub.status.idle":"2022-01-20T11:51:17.415563Z","shell.execute_reply.started":"2022-01-20T11:51:17.371169Z","shell.execute_reply":"2022-01-20T11:51:17.414337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # GET TEST PREDICIONS\n# sub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\n# sub['len'] = sub['predictionstring'].apply(lambda x:len(x.split()))\n# sub = threshold(sub)\n\n\n# sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T11:34:40.41882Z","iopub.execute_input":"2022-01-20T11:34:40.419267Z","iopub.status.idle":"2022-01-20T11:34:40.962435Z","shell.execute_reply.started":"2022-01-20T11:34:40.41923Z","shell.execute_reply":"2022-01-20T11:34:40.957227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}