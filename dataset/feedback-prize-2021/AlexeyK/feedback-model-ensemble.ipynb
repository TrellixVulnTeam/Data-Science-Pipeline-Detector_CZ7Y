{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\nimport shutil\nfrom pathlib import Path\n\ntransformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n\ninput_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n\nconvert_file = input_dir / \"convert_slow_tokenizer.py\"\nconversion_path = transformers_path/convert_file.name\n\nif conversion_path.exists():\n    conversion_path.unlink()\n\nshutil.copy(convert_file, transformers_path)\ndeberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n\nfor filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n    if str(filename).startswith(\"deberta\"):\n        filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n    else:\n        filepath = deberta_v2_path/filename\n    if filepath.exists():\n        filepath.unlink()\n\n    shutil.copy(input_dir/filename, filepath)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:15.939738Z","iopub.execute_input":"2022-03-15T06:33:15.940069Z","iopub.status.idle":"2022-03-15T06:33:15.99001Z","shell.execute_reply.started":"2022-03-15T06:33:15.939978Z","shell.execute_reply":"2022-03-15T06:33:15.989329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.enable()\n\nimport sys\nsys.path.append(\"../input/tez-lib/\")\n\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport tez\nimport torch\nimport torch.nn as nn\nfrom joblib import Parallel, delayed\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\nfrom transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-15T06:33:15.99288Z","iopub.execute_input":"2022-03-15T06:33:15.993073Z","iopub.status.idle":"2022-03-15T06:33:18.085874Z","shell.execute_reply.started":"2022-03-15T06:33:15.993049Z","shell.execute_reply":"2022-03-15T06:33:18.085153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_models = 5\n\nnum_discourse_marker = 15\n\nclass mod_args:\n    input_path = \"../input/feedback-prize-2021/\"\n    model_def = [\n        \"../input/longformerlarge4096/longformer-large-4096/\",\n        \"../input/funnel-large/\",        \n        \"../input/longformerlarge4096/longformer-large-4096/\",\n        \"../input/deberta-large/\",\n        \"../input/deberta-large/\",\n        \"../input/debertav3large/\",\n        \"../input/debertav3large/\",\n        \"../input/longformerlarge4096/longformer-large-4096/\"\n    ]\n    model_path = [\n        \"../input/tez-fb-large/\",\n        \"../input/funnel2/\",\n        \"../input/fblongformerlarge1536/\",\n        \"../input/deberta-large1-1024/\",\n        \"../input/debertalarge21024/\",\n        \"../input/deberta-v3-large2-1024/\", \n        \"../input/deberta-v3-large1-1024/\",\n        \"../input/lf-large-1024-m15/\"\n    ]\n    folds = [[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [2, 3, 4], [0, 1, 2, 3, 4]]\n    output = \".\"\n    batch_size = [8, 8, 8, 2, 2, 8, 8, 8]\n    max_len = 4096","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.086981Z","iopub.execute_input":"2022-03-15T06:33:18.087231Z","iopub.status.idle":"2022-03-15T06:33:18.096885Z","shell.execute_reply.started":"2022-03-15T06:33:18.087197Z","shell.execute_reply":"2022-03-15T06:33:18.094578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_id_map = {\n    \"B-Lead\": 0,\n    \"I-Lead\": 1,\n    \"B-Position\": 2,\n    \"I-Position\": 3,\n    \"B-Evidence\": 4,\n    \"I-Evidence\": 5,\n    \"B-Claim\": 6,\n    \"I-Claim\": 7,\n    \"B-Concluding Statement\": 8,\n    \"I-Concluding Statement\": 9,\n    \"B-Counterclaim\": 10,\n    \"I-Counterclaim\": 11,\n    \"B-Rebuttal\": 12,\n    \"I-Rebuttal\": 13,\n    \"O\": 14,\n    \"PAD\": -100,\n}\n\nid_target_map = {v: k for k, v in target_id_map.items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.099219Z","iopub.execute_input":"2022-03-15T06:33:18.099814Z","iopub.status.idle":"2022-03-15T06:33:18.106641Z","shell.execute_reply.started":"2022-03-15T06:33:18.099778Z","shell.execute_reply":"2022-03-15T06:33:18.105966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackDataset:\n    def __init__(self, samples, max_len, tokenizer):\n        self.samples = samples\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.length = len(samples)\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        input_ids = self.samples[idx][\"input_ids\"]\n        input_ids = [self.tokenizer.cls_token_id] + input_ids\n\n        if len(input_ids) > self.max_len - 1:\n            input_ids = input_ids[: self.max_len - 1]\n\n        # add end token id to the input_ids\n        input_ids = input_ids + [self.tokenizer.sep_token_id]\n        attention_mask = [1] * len(input_ids)\n\n        return {\n            \"ids\": input_ids,\n            \"mask\": attention_mask,\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.108035Z","iopub.execute_input":"2022-03-15T06:33:18.1087Z","iopub.status.idle":"2022-03-15T06:33:18.116965Z","shell.execute_reply.started":"2022-03-15T06:33:18.108663Z","shell.execute_reply":"2022-03-15T06:33:18.116123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Collate:\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n\n    def __call__(self, batch):\n        output = dict()\n        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n\n        # calculate max token length of this batch\n        batch_max = max([len(ids) for ids in output[\"ids\"]])\n\n        # add padding\n        if self.tokenizer.padding_side == \"right\":\n            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n        else:\n            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n\n        # convert to tensors\n        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.119438Z","iopub.execute_input":"2022-03-15T06:33:18.119692Z","iopub.status.idle":"2022-03-15T06:33:18.130539Z","shell.execute_reply.started":"2022-03-15T06:33:18.119628Z","shell.execute_reply":"2022-03-15T06:33:18.129823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _prepare_test_data_helper(args, tokenizer, ids):\n    test_samples = []\n    for idx in ids:\n        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n        with open(filename, \"r\") as f:\n            text = f.read()\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=False,\n            return_offsets_mapping=True,\n            max_length=args.max_len, # added for BigBert\n            truncation=True, # added for BigBert\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        offset_mapping = encoded_text[\"offset_mapping\"]\n\n        sample = {\n            \"id\": idx,\n            \"input_ids\": input_ids,\n            \"text\": text,\n            \"text_len\": len(text),\n            \"offset_mapping\": offset_mapping,\n        }\n\n        test_samples.append(sample)\n    return test_samples\n\n\ndef prepare_test_data(df, tokenizer, args):\n    test_samples = []\n    ids = df[\"id\"].unique()\n    ids_splits = np.array_split(ids, 4)\n\n    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n        delayed(_prepare_test_data_helper)(args, tokenizer, idx) for idx in ids_splits\n    )\n    for result in results:\n        test_samples.extend(result)\n\n    test_samples.sort(key=lambda d: d[\"text_len\"], reverse=False)\n    return test_samples","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.131857Z","iopub.execute_input":"2022-03-15T06:33:18.132292Z","iopub.status.idle":"2022-03-15T06:33:18.142411Z","shell.execute_reply.started":"2022-03-15T06:33:18.132258Z","shell.execute_reply":"2022-03-15T06:33:18.141647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackModel(tez.Model):\n    def __init__(self, model_name, num_labels):\n        super().__init__()\n        self.model_name = model_name\n        self.num_labels = num_labels\n        config = AutoConfig.from_pretrained(model_name)\n\n        hidden_dropout_prob: float = 0.10\n        layer_norm_eps: float = 1e-7\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        self.transformer = AutoModel.from_config(config)\n        self.output = nn.Linear(config.hidden_size, self.num_labels)\n\n    def forward(self, ids, mask):\n        transformer_out = self.transformer(ids, mask)\n        sequence_output = transformer_out.last_hidden_state\n        logits = self.output(sequence_output)\n        logits = torch.softmax(logits, dim=-1)\n        return logits, 0, {}","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.143736Z","iopub.execute_input":"2022-03-15T06:33:18.14403Z","iopub.status.idle":"2022-03-15T06:33:18.153983Z","shell.execute_reply.started":"2022-03-15T06:33:18.143997Z","shell.execute_reply":"2022-03-15T06:33:18.153252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Heng's ensembling approach\n\ndf = pd.read_csv(os.path.join(mod_args.input_path, \"sample_submission.csv\"))\n\nresult_nn = []\n\nfor i in range(n_models):\n    \n    if mod_args.model_def[i] == \"../input/debertav3large/\":\n        tokenizer = DebertaV2TokenizerFast.from_pretrained(mod_args.model_def[i])\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(mod_args.model_def[i])\n    \n    collate = Collate(tokenizer)\n    test_samples = prepare_test_data(df, tokenizer, mod_args)\n    test_dataset = FeedbackDataset(test_samples, mod_args.max_len, tokenizer)\n\n    model = FeedbackModel(model_name=mod_args.model_def[i], num_labels=len(target_id_map) - 1)\n    \n    n_folds = len(mod_args.folds[i])\n    model_prob = []\n    first_fold = mod_args.folds[i][0]\n    \n    for _fold in mod_args.folds[i]:\n        # print(_fold)\n        model.load(os.path.join(mod_args.model_path[i], f\"model_{_fold}.bin\"), weights_only=True)\n        model.eval()\n\n        preds_iter = model.predict(test_dataset, batch_size=mod_args.batch_size[i], n_jobs=-1, collate_fn=collate,)\n\n        current_idx = 0\n        for preds in preds_iter:\n            preds = preds.astype(np.float16)\n            preds = preds / n_folds\n            \n            if _fold == first_fold:\n                model_prob.append(preds)\n            else:\n                model_prob[current_idx] += preds\n                current_idx += 1\n            \n        torch.cuda.empty_cache()\n        gc.collect()\n            \n    model_prob = [item for sublist in model_prob for item in sublist]\n    for j in range(len(test_samples)):\n        test_samples[j][\"probability\"] = model_prob[j]\n\n    result_nn.append(test_samples)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:33:18.155381Z","iopub.execute_input":"2022-03-15T06:33:18.155625Z","iopub.status.idle":"2022-03-15T06:40:59.622217Z","shell.execute_reply.started":"2022-03-15T06:33:18.155585Z","shell.execute_reply":"2022-03-15T06:40:59.621404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length_threshold = {\n    'Lead'                : 6,\n    'Position'            : 4,\n    'Claim'               : 3,\n    'Counterclaim'        : 7,\n    'Rebuttal'            : 4,\n    'Evidence'            : 14,\n    'Concluding Statement': 7,\n}\nprobability_threshold = {\n    'Lead'                : 0.55,\n    'Position'            : 0.55,\n    'Claim'               : 0.50,\n    'Counterclaim'        : 0.50,\n    'Rebuttal'            : 0.55,\n    'Evidence'            : 0.60,\n    'Concluding Statement': 0.60,\n}\n\n# probability_threshold = {\n#     \"Lead\": 0.687,\n#     \"Position\": 0.537,\n#     \"Evidence\": 0.637,\n#     \"Claim\": 0.537,\n#     \"Concluding Statement\": 0.687,\n#     \"Counterclaim\": 0.537,\n#     \"Rebuttal\": 0.537,\n# }\n\ndef do_threshold(submit_df, use=['length','probability']):\n    df = submit_df.copy()\n    df = df.fillna('')\n    \n    if 'probability' in use:\n        df['s'] = df.score.apply(lambda x: np.mean(eval(x)))\n        for key, value in probability_threshold.items():\n            index = df.loc[df['class'] == key].query('s<%f'%value).index\n            df.drop(index, inplace=True)\n\n    if 'length' in use:\n        df['l'] = df.predictionstring.apply(lambda x: len(x.split()))\n        for key, value in length_threshold.items():\n            index = df.loc[df['class'] == key].query('l<%d'%value).index\n            df.drop(index, inplace=True)\n\n    df = df[['id', 'class', 'predictionstring']]\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:40:59.62512Z","iopub.execute_input":"2022-03-15T06:40:59.625349Z","iopub.status.idle":"2022-03-15T06:40:59.635234Z","shell.execute_reply.started":"2022-03-15T06:40:59.625317Z","shell.execute_reply":"2022-03-15T06:40:59.634525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_to_word(text):\n    word = text.split()\n    word_offset = []\n\n    start = 0\n    for w in word:\n        r = text[start:].find(w)\n\n        if r == -1:\n            raise NotImplementedError\n        else:\n            start = start + r\n            end = start + len(w)\n            word_offset.append((start, end))\n\n        start = end\n\n    return word, word_offset\n\ndef word_probability_to_predict_df(text_to_word_probability, id):\n    len_word = len(text_to_word_probability)\n    word_predict = text_to_word_probability.argmax(-1)\n    word_score   = text_to_word_probability.max(-1)\n    predict_df = []\n\n    t = 0\n    while 1:\n        if word_predict[t] not in [\n            target_id_map['O'],\n            target_id_map['PAD'],\n        ]:\n            start = t\n            b_marker_label = word_predict[t]\n        else:\n            t = t+1\n            if t == len_word-1: break\n            continue\n\n        t = t+1\n        if t== len_word-1: break\n\n        #----\n        if   id_target_map[b_marker_label][0]=='B':\n            i_marker_label = b_marker_label+1\n        elif id_target_map[b_marker_label][0]=='I':\n            i_marker_label = b_marker_label\n        else:\n            raise NotImplementedError\n\n        while 1:\n            if (word_predict[t] != i_marker_label) or (t ==len_word-1):\n                end = t\n                prediction_string = ' '.join([str(i) for i in range(start,end)]) #np.arange(start,end).tolist()\n                discourse_type = id_target_map[b_marker_label][2:]\n                discourse_score = word_score[start:end].tolist()\n                predict_df.append((id, discourse_type, prediction_string, str(discourse_score)))\n                #print(predict_df[-1])\n                break\n            else:\n                t = t+1\n                continue\n        if t== len_word-1: break\n\n    predict_df = pd.DataFrame(predict_df, columns=['id', 'class', 'predictionstring', 'score'])\n    return predict_df","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:40:59.636328Z","iopub.execute_input":"2022-03-15T06:40:59.63749Z","iopub.status.idle":"2022-03-15T06:40:59.651873Z","shell.execute_reply.started":"2022-03-15T06:40:59.637452Z","shell.execute_reply":"2022-03-15T06:40:59.651126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jn(pst, start, end):\n    return \" \".join([str(x) for x in pst[start:end]])\n\n\ndef link_evidence(oof):\n    thresh = 1\n    idu = oof['id'].unique()\n    idc = idu[1]\n    eoof = oof[oof['class'] == \"Evidence\"]\n    neoof = oof[oof['class'] != \"Evidence\"]\n    for thresh2 in range(26, 27, 1):\n        retval = []\n        for idv in idu:\n            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n                   'Counterclaim', 'Rebuttal']:\n                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for i,r in q.iterrows():\n                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n                start = 1\n                end = 1\n                for i in range(2,len(pst)):\n                    cur = pst[i]\n                    end = i\n                    #if pst[start] == 205:\n                    #   print(cur, pst[start], cur - pst[start])\n                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end+1))\n                #print(v)\n                retval.append(v)\n        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n        roof = roof.merge(neoof, how='outer')\n        return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:40:59.65291Z","iopub.execute_input":"2022-03-15T06:40:59.653217Z","iopub.status.idle":"2022-03-15T06:40:59.666337Z","shell.execute_reply.started":"2022-03-15T06:40:59.653182Z","shell.execute_reply":"2022-03-15T06:40:59.66541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_valid = len(result_nn[0])\n\nsubmit_df = []\nfor i in range(num_valid):\n    \n    text_id = result_nn[0][i][\"id\"]\n    text = result_nn[0][i][\"text\"]\n    word, word_offset = text_to_word(text)\n        \n    #--- ensemble\n    token_to_text_probability = np.full((len(text), num_discourse_marker), 0, np.float32)\n    for j in range(n_models):\n        p = result_nn[j][i][\"probability\"][1:]\n\n        for t, (start, end) in enumerate(result_nn[j][i][\"offset_mapping\"]):\n            if t == mod_args.max_len - 1:\n                break\n            token_to_text_probability[start:end] += p[t]\n    token_to_text_probability = token_to_text_probability / n_models\n    #-------------\n    \n    text_to_word_probability = np.full((len(word), num_discourse_marker), 0, np.float32)\n    for t, (start, end) in enumerate(word_offset):\n        text_to_word_probability[t] = token_to_text_probability[start:end].mean(0)\n\n    predict_df = word_probability_to_predict_df(text_to_word_probability, text_id)\n    submit_df.append(predict_df)\n    \n    # if i % 300 == 0: print(i, text_id, len(text), len(word))\n    \n\nsubmit_df = pd.concat(submit_df).reset_index(drop=True)\nsubmit_df = do_threshold(submit_df, use=['length', 'probability'])\n\nsubmit_df = link_evidence(submit_df)\nsubmit_df.to_csv(\"submission.csv\", index=False)\n\nsubmit_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:40:59.66771Z","iopub.execute_input":"2022-03-15T06:40:59.668021Z","iopub.status.idle":"2022-03-15T06:40:59.920592Z","shell.execute_reply.started":"2022-03-15T06:40:59.667986Z","shell.execute_reply":"2022-03-15T06:40:59.919819Z"},"trusted":true},"execution_count":null,"outputs":[]}]}