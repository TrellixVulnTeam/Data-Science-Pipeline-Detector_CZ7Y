{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Bag of Words\nThe objective of this is to create a dataframe containing the Bag of Words for the Data Set \\\nThis file takes a lot of ram to run so that's why I am saving and opening frequently","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nimport nltk","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:28:00.653046Z","iopub.execute_input":"2022-01-17T05:28:00.65369Z","iopub.status.idle":"2022-01-17T05:28:00.657583Z","shell.execute_reply.started":"2022-01-17T05:28:00.653639Z","shell.execute_reply":"2022-01-17T05:28:00.656939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\nfrom os.path import isfile, join\nonlyfiles = [f for f in listdir('../input/feedback-prize-2021/train') if isfile(join('../input/feedback-prize-2021/train', f))]","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:25:16.6567Z","iopub.execute_input":"2022-01-17T05:25:16.657366Z","iopub.status.idle":"2022-01-17T05:25:25.886052Z","shell.execute_reply.started":"2022-01-17T05:25:16.657328Z","shell.execute_reply":"2022-01-17T05:25:25.885398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is just getting all of the text into 1 string. Basically just doing this to get every unique word that has been written in the data set","metadata":{}},{"cell_type":"code","source":"text = \"\"\ncount = 0\nfor i in onlyfiles:\n    count+=1\n    tmp = '../input/feedback-prize-2021/train/' + i\n    data = \"\"\n    with open(tmp, 'r') as file:\n        data = file.read().replace('\\n', ' ')\n    text = text + ' ' + data","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:28:08.933107Z","iopub.execute_input":"2022-01-17T05:28:08.933868Z","iopub.status.idle":"2022-01-17T05:30:39.285486Z","shell.execute_reply.started":"2022-01-17T05:28:08.93383Z","shell.execute_reply":"2022-01-17T05:30:39.284437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk.tokenize import word_tokenize\nimport nltk\nnltk.download('punkt')\ntext = re.sub(r'[^A-Za-z0-9 ]+', '', text.lower()).split(' ')\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:30:39.287148Z","iopub.execute_input":"2022-01-17T05:30:39.287532Z","iopub.status.idle":"2022-01-17T05:30:41.83482Z","shell.execute_reply.started":"2022-01-17T05:30:39.287494Z","shell.execute_reply":"2022-01-17T05:30:41.833957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing words that aren't in the english dictionary & stop words","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('words')\nreal = []\nenglish_vocab = set(w.lower() for w in nltk.corpus.words.words())\nfor i in text:\n    if i in english_vocab and i not in stop_words:\n        real.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:30:41.836339Z","iopub.execute_input":"2022-01-17T05:30:41.836577Z","iopub.status.idle":"2022-01-17T05:30:44.089709Z","shell.execute_reply.started":"2022-01-17T05:30:41.836549Z","shell.execute_reply":"2022-01-17T05:30:44.088707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real = list(set(real))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:30:44.091674Z","iopub.execute_input":"2022-01-17T05:30:44.091926Z","iopub.status.idle":"2022-01-17T05:30:44.274733Z","shell.execute_reply.started":"2022-01-17T05:30:44.091893Z","shell.execute_reply":"2022-01-17T05:30:44.273867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport re\ndf = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")\ntypes = [\"Claim\",\t\"Concluding Statement\",\t\"Counterclaim\",\t\"Evidence\",\t\"Lead\",\t\"Position\",\"Rebuttal\"]\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:30:44.276053Z","iopub.execute_input":"2022-01-17T05:30:44.276327Z","iopub.status.idle":"2022-01-17T05:30:46.429147Z","shell.execute_reply.started":"2022-01-17T05:30:44.276294Z","shell.execute_reply":"2022-01-17T05:30:46.428369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting all of the data for the bag of words dataset","metadata":{}},{"cell_type":"code","source":"vals = []\ntype1 = []\ncount = 0\nfor index, values in df.iterrows():\n    t = []\n    string = re.sub(r'[^A-Za-z0-9 ]+', '', values[\"discourse_text\"].lower())\n    for i in real:\n        if i not in string:\n            t.append(0)\n        else:\n            t.append(string.count(i))\n    vals.append(t)\n    type1.append(values[\"discourse_type\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:30:46.43023Z","iopub.execute_input":"2022-01-17T05:30:46.43045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame.from_records(vals,columns=real)\ndf[\"type1\"] = type1\ndf.to_csv(\"BOW_train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}