{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This baseline is based on the following notebooks \n\nby Sylvain Gugger: https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n\nby DAREK KŁECZEK: https://www.kaggle.com/thedrcat/feedback-prize-huggingface-baseline-training/notebook\n\ni don't use metric for simple, if you want to use metric, you can see the above notebooks.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install --no-index --find-links ../input/python-package-amulil/datasets/datasets datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic utils\nimport gc\nimport psutil\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nfrom collections import defaultdict\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\n# for transformer\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom transformers import DataCollatorForTokenClassification, TrainingArguments, Trainer\nfrom datasets import load_dataset, load_metric, Dataset\nfrom transformers.utils.logging import set_verbosity, WARNING, INFO\n\n# system congi\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper function\ndef dataset_size(dataset):\n    size_gb = dataset.dataset_size / (1024**2)\n    print(f\"Dataset size (cache file) : {size_gb:.2f} MB\")\n    \ndef set_seed(seed=42):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\ndef get_raw_text(ids):\n    with open(f\"../input/feedback-prize-2021/train/{ids}.txt\", 'r') as file: data = file.read()\n    return data\n\ndef get_test_text(ids):\n    with open(f\"../input/feedback-prize-2021/test/{ids}.txt\", 'r') as file: data = file.read()\n    return data\n\ndef tokenize_and_align_labels(examples):\n    o = CONFIG[\"tokenizer\"](examples[\"text\"], truncation=True, max_length=CONFIG[\"max_length\"],\n                            return_offsets_mapping=True)\n    \n    offsets = o['offset_mapping']\n    labels = []\n    for k in range(len(offsets)):\n        label = []\n        for i in o.tokens(k):\n            if i == None:\n                label.append(-100)\n            else:\n                label.append(l2i[\"O\"])\n                \n        for a, b, t in \\\n            zip(examples[\"starts\"][k], examples[\"ends\"][k], examples[\"classlist\"][k]):\n            offset_index = 1\n            c = offsets[k][offset_index][0]\n            d = offsets[k][offset_index][1]\n            beginning = True\n            while b>c:\n                if (c>=a)&(b>=d):\n                    if beginning:\n                        label[offset_index] = l2i[f'B-{t}']  \n                        beginning = False\n                    else:\n                        label[offset_index] = l2i[f'I-{t}']  \n                offset_index += 1\n                if offset_index>len(offsets[k])-1:\n                    break\n                c = offsets[k][offset_index][0]\n                d = offsets[k][offset_index][1]\n        labels.append(label)\n\n    o[\"labels\"] = labels\n        \n    return o\n\ndef tokenize_for_test(examples):\n    o = CONFIG[\"tokenizer\"](examples['text'], truncation=True, return_offsets_mapping=True)\n    return o\n\ndef prepare_loaders(fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_datas = Dataset.from_pandas(df_train)\n    valid_datas = Dataset.from_pandas(df_valid)    \n    \n    tokenized_train_datas = train_datas.map(tokenize_and_align_labels, \n                                                    batched=True,\n                                                    batch_size=5000,\n                                                    remove_columns=train_datas.column_names)\n    \n    tokenized_valid_datas = valid_datas.map(tokenize_and_align_labels, \n                                                    batched=True,\n                                                    batch_size=5000,\n                                                    remove_columns=valid_datas.column_names)\n    \n    \n    return tokenized_train_datas, tokenized_valid_datas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed()\n\ndevices = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ncheckpoint = [\n    \"../input/amulil-huggingface/allenai/longformer-base-4096\",\n    \"../input/amulil-huggingface/google/bigbird-roberta-base\"\n]\n\nCONFIG = {\n    \"debug\": True,\n    \"max_length\":1024,\n    \"seed\": 666,\n    \"batch_size\": 4,\n    \"checkpoint\": checkpoint[0],\n    \"task\": \"ner\",\n    \"n_fold\": 2,\n    \"epochs\": 1\n}\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG[\"checkpoint\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_datas = pd.read_csv('../input/feedback-prize-2021/train.csv')\nclasses = all_datas.discourse_type.unique().tolist()\nif CONFIG[\"debug\"]: all_datas = all_datas.sample(n=10).reset_index(drop=True)\nclasses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = all_datas.groupby('id')['discourse_type'].apply(list).reset_index(name='classlist')\ndf2 = all_datas.groupby('id')['discourse_start'].apply(list).reset_index(name='starts')\ndf3 = all_datas.groupby('id')['discourse_end'].apply(list).reset_index(name='ends')\ndf4 = all_datas.groupby('id')['predictionstring'].apply(list).reset_index(name='predictionstrings')\n\ndf = pd.merge(df1, df2, how='inner', on='id')\ndf = pd.merge(df, df3, how='inner', on='id')\ndf = pd.merge(df, df4, how='inner', on='id')\ndf['text'] = df['id'].apply(get_raw_text)\n\nprint(len(df))\n\nskf = KFold(n_splits=CONFIG[\"n_fold\"], shuffle=True, random_state=42)\n\nfor fold, ( _, val_) in enumerate(skf.split(X=df, y=df.classlist)):\n    df.loc[val_ , \"kfold\"] = int(fold)\n    \ndf[\"kfold\"] = df[\"kfold\"].astype(int)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = defaultdict()\n\ntags[f'O'] = 0\nfor i, c in enumerate(classes):\n    tags[f'B-{c}'] = 2*i + 1\n    tags[f'I-{c}'] = 2*i + 2\n    \nl2i = dict(tags)\n\ni2l = defaultdict()\nfor k, v in l2i.items(): \n    i2l[v] = k\n\ni2l = dict(i2l)\n\nN_LABELS = len(i2l) - 1 # not accounting for -100\nl2i","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(0, CONFIG['n_fold']):\n    print(f\"====== Fold: {fold} ======\")\n    \n    tokenized_train_datas, tokenized_valid_datas = prepare_loaders(fold)\n    data_collator = DataCollatorForTokenClassification(tokenizer=CONFIG['tokenizer'])\n    \n    set_verbosity(WARNING)\n    model = AutoModelForTokenClassification.from_pretrained(\n        CONFIG[\"checkpoint\"],\n        id2label=i2l,\n        label2id=l2i,\n    )\n\n    model_name = CONFIG['checkpoint'].split(\"/\")[-1]\n    task = CONFIG['task']\n    set_verbosity(WARNING)\n    args = TrainingArguments(\n        f\"{model_name}-finetuned-fold{fold}-{task}\",\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=2e-5,\n        num_train_epochs=1,\n        per_device_train_batch_size=CONFIG[\"batch_size\"],\n        per_device_eval_batch_size=CONFIG[\"batch_size\"],\n        weight_decay=0.01,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=tokenized_train_datas,\n        eval_dataset=tokenized_valid_datas,\n        data_collator=data_collator,\n        tokenizer=CONFIG[\"tokenizer\"],\n    )\n    set_verbosity(WARNING)\n    trainer.train()\n    \n    del model, tokenized_train_datas, tokenized_valid_datas, trainer, args\n    _ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}