{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ“– Topic Modeling with LDA\n \n![](https://storage.googleapis.com/kaggle-competitions/kaggle/31779/logos/header.png)\n\n## Simple topic modeling over the [Feedback Prize - Evaluating Student Writing](https://www.kaggle.com/c/feedback-prize-2021) data using `CountVectorizer` and `LDA`.\n\n\nAdapted from scikit's Topic Modeling documentation script: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n\n\nIt mimics [RAPIDS UMAP Tfidf KMeans - Discovers 15 Topics!](https://www.kaggle.com/cdeotte/rapids-umap-tfidf-kmeans-discovers-15-topics) with LDA.","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:30:38.094256Z","iopub.execute_input":"2022-01-29T00:30:38.094573Z","iopub.status.idle":"2022-01-29T00:30:38.109976Z","shell.execute_reply.started":"2022-01-29T00:30:38.094541Z","shell.execute_reply":"2022-01-29T00:30:38.108735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load texts","metadata":{}},{"cell_type":"code","source":"def load_df():\n    # https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n    train_names, train_texts = [], []\n    for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n        train_names.append(f.replace('.txt', ''))\n        train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n    train_text_df = pd.DataFrame({'id': train_names, 'text': train_texts})\n    return train_text_df\n\ndf = load_df()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:30:39.380037Z","iopub.execute_input":"2022-01-29T00:30:39.380472Z","iopub.status.idle":"2022-01-29T00:30:48.686865Z","shell.execute_reply.started":"2022-01-29T00:30:39.380431Z","shell.execute_reply":"2022-01-29T00:30:48.685798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"n_features = 1000\nn_topics = 10\nn_top_words = 20","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:13:52.137401Z","iopub.execute_input":"2022-01-29T00:13:52.138027Z","iopub.status.idle":"2022-01-29T00:13:52.143191Z","shell.execute_reply.started":"2022-01-29T00:13:52.137976Z","shell.execute_reply":"2022-01-29T00:13:52.142445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Count Vectorizer","metadata":{}},{"cell_type":"code","source":"%%time\nvect = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\")\nX = vect.fit_transform(df.text.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:31:40.260538Z","iopub.execute_input":"2022-01-29T00:31:40.26086Z","iopub.status.idle":"2022-01-29T00:31:46.559764Z","shell.execute_reply.started":"2022-01-29T00:31:40.260826Z","shell.execute_reply":"2022-01-29T00:31:46.558752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LDA","metadata":{}},{"cell_type":"code","source":"%%time\nlda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n                                learning_method=\"online\",\n                                learning_offset=50.0,\n                                random_state=42,\n                                n_jobs=-1)\nlabels = lda.fit_transform(X)\nlabels = labels.argmax(-1)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:34:11.506816Z","iopub.execute_input":"2022-01-29T00:34:11.50728Z","iopub.status.idle":"2022-01-29T00:34:51.856697Z","shell.execute_reply.started":"2022-01-29T00:34:11.507229Z","shell.execute_reply":"2022-01-29T00:34:51.85569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot","metadata":{}},{"cell_type":"code","source":"def plot_top_words(model, feature_names, n_top_words, title):\n    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n    axes = axes.flatten()\n    for topic_idx, topic in enumerate(model.components_):\n        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        weights = topic[top_features_ind]\n\n        ax = axes[topic_idx]\n        ax.barh(top_features, weights, height=0.7)\n        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n        ax.invert_yaxis()\n        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n        for i in \"top right left\".split():\n            ax.spines[i].set_visible(False)\n        fig.suptitle(title, fontsize=40)\n\n    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n    plt.show()\n\n\nfeature_names = vect.get_feature_names()\nplot_top_words(lda, feature_names, n_top_words, \"Topics in LDA model\")","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:36:51.241704Z","iopub.execute_input":"2022-01-29T00:36:51.242097Z","iopub.status.idle":"2022-01-29T00:36:53.50492Z","shell.execute_reply.started":"2022-01-29T00:36:51.242048Z","shell.execute_reply":"2022-01-29T00:36:53.503906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Examples","metadata":{}},{"cell_type":"code","source":"df['topic'] = labels\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:37:20.278946Z","iopub.execute_input":"2022-01-29T00:37:20.279605Z","iopub.status.idle":"2022-01-29T00:37:20.291669Z","shell.execute_reply.started":"2022-01-29T00:37:20.279569Z","shell.execute_reply":"2022-01-29T00:37:20.290965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['topic'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:37:27.862281Z","iopub.execute_input":"2022-01-29T00:37:27.862606Z","iopub.status.idle":"2022-01-29T00:37:27.876353Z","shell.execute_reply.started":"2022-01-29T00:37:27.862573Z","shell.execute_reply":"2022-01-29T00:37:27.87511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for topic_idx in range(n_topics):\n    topic = lda.components_[topic_idx]\n    top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n    top_features = [feature_names[i] for i in top_features_ind]\n    samples = df[df['topic'] == topic_idx].sample(5)\n    print(\"=========================================================\")\n    print(f\"TOPIC {topic_idx + 1}\")\n    print(f\"  Top words: {top_features}\")\n    print(\"=========================================================\")\n    for sample_idx, sample in enumerate(samples['text'].tolist(), 1):\n        print(f\"Example {sample_idx}:\")\n        print(sample)\n        print()\n        print('---------------------')\n        print()\n    print()\n    print()\n    print()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-29T00:42:33.946044Z","iopub.execute_input":"2022-01-29T00:42:33.946539Z","iopub.status.idle":"2022-01-29T00:42:34.028097Z","shell.execute_reply.started":"2022-01-29T00:42:33.946491Z","shell.execute_reply":"2022-01-29T00:42:34.026886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}