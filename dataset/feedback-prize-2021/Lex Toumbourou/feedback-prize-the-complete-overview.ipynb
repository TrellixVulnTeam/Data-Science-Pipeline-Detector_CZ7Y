{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Welcome to the [Feedback Prize - Predicting Effective Arguments](https://www.kaggle.com/competitions/feedback-prize-effectiveness) competition by [Georgia State University](https://www.gsu.edu/) on Kaggle.\n\n <img alt=\"An example of inference on an essay\" src=\"https://i.imgur.com/uZIST9f.png\" width=\"750px\"/>\n\nIn this notebook, I give an overview of the competition and explore the dataset before training a baseline model. I also perform additional analysis using the trained model.\n\nThe notebook includes:\n* An example of using pseudo-labels on the larger [2021 Feedback Prize Competition](https://www.kaggle.com/competitions/feedback-prize-2021) dataset.\n* A custom head for the [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) framework.\n* An implementation of [multi-sample dropout](https://arxiv.org/abs/1905.09788).\n\nIf you find this helpful notebook, I would appreciate an upvote! ‚ù§Ô∏è\n\n* For inference on the test set, see [Feedback Prize - DeBERTa-v3 Inference](https://www.kaggle.com/code/lextoumbourou/feedback-prize-deberta-v3-inference).\n* For inference on the 2021 data, see [Feedback Prize - Inference on 2021 Dataset](https://www.kaggle.com/code/lextoumbourou/feedback-prize-inference-on-2021-dataset).","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Changelog\n\n* **2022-06-25**\n\n  Reduce Dropout and validate 2x each epoch. Also some changes for faster training.\n \n* **2022-06-19**\n\n  Include essay text.\n \n* **2022-06-17**\n\n  Pseudo-labels appear to be making results a bit worse. Reducing the number. Soft labels or inference with a more accurate model will likely help here.\n  \n  Also tuned the multi-sample dropout params.\n \n* **2022-06-11**\n\n  Add Mean Pooling taken from [this](https://www.kaggle.com/code/debarshichanda/pytorch-feedback-deberta-v3-baseline) notebook by [@debarshichanda](https://www.kaggle.com/debarshichanda).\n \n* **2022-06-07**\n\n  Clean up.\n\n* **2022-06-05**\n\n  Add topics to improve EDA.\n  \n  Revert label smoothing.\n\n* **2022-06-02**\n\n  Revert to Deberta Base for iteration speed.\n  \n  Add label smoothing.\n  \n  Also, update Model Interpretation.\n \n* **2022-05-31**\n\n  Try Deberta Large.\n \n* **2022-05-29**\n\n  Add 2021 competition data experiment.","metadata":{}},{"cell_type":"markdown","source":"# Competition Overview","metadata":{}},{"cell_type":"markdown","source":"From the [competition description](https://www.kaggle.com/competitions/feedback-prize-effectiveness/overview/description):\n\n*Writing is crucial for success.  In particular, argumentative writing fosters critical thinking and civic engagement skills, and can be strengthened by practice. However, only 13 percent of eighth-grade teachers ask their students to write persuasively each week. Additionally, resource constraints disproportionately impact Black and Hispanic students, so they are more likely to write at the ‚Äúbelow basic‚Äù level as compared to their white peers. An automated feedback tool is one way to make it easier for teachers to grade writing tasks assigned to their students that will also improve their writing skills.*\n\nOur goal in this competition is to classify sections (or \"*elements*\") of student's essays, in 3 categories: `Ineffective` or `Adequate` or `Effective`.\n\nThe essays were written by 6th-12th grade students located in the USA.\n\nThe competition is a Code Competition, which means that you must submit your kernel to get a leaderboard score. The unseen test set contains around 3000 essays.","metadata":{}},{"cell_type":"markdown","source":"# Related Competitions\n\n## Feedback Prize (2021)\n\nThe original [Feedback Prize competition](https://www.kaggle.com/competitions/feedback-prize-2021) finished earlier this year. Though a [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition) competition as opposed to classification, the dataset contains 11,403 additional essays and 70,763 additional essay sections.\n\nI have done some analysis on that dataset [here](https://www.kaggle.com/code/lextoumbourou/feedback-prize-inference-on-2021-dataset).\n\n* [1st solution with code(cv:0.748 lb:0.742)](https://www.kaggle.com/c/feedback-prize-2021/discussion/313177)\n* [2nd Place - Weighted Box Fusion and Post Process](https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313389)\n* [3rd Place Solution w code and notebook](https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313235)\n* [4th place solution - üéñÔ∏è my first gold medal üéñÔ∏è (+source code available!)](https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313330)\n* [5'th place : simultaneous span segmentation and classification + WBF](https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313478)\n* [6th place solution. A YOLO-like text span detector.](https://www.kaggle.com/c/feedback-prize-2021/discussion/313424)\n* [7th place solution](https://www.kaggle.com/competitions/feedback-prize-2021/discussion/315887)\n* [9th solution, deberta is the king, pure ensemble of bert models](https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313201)\n* [10th solution](https://www.kaggle.com/c/feedback-prize-2021/discussion/313718)\n\n## U.S. Patent Phrase to Phrase Matching\n\nhttps://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching\n\nAn NLP competition that finished very recently on June 20.\n\n* [1st place solution](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332243)\n* [2nd Place Solution](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332234)\n* [3rd place solution](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332420)\n* [5th solution: prompt is all you need](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332418)\n* [7th place solution - the power of randomness](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332928)\n* [8th place solution: Predicting Targets at Once Led Us to Gold](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332492)\n* [10th place Solution : Single model public lb 0.8562, private lb 0.8717](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332273)\n* [12th Place Solution](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332567)\n\n## NBME Score Clinical Patients\n\nhttps://www.kaggle.com/competitions/nbme-score-clinical-patient-notes\n\nA recent NLP competition that finished in May 2022.\n\n* [1st solution](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/323095)\n* [#2 solution](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/323085)\n* [3rd Place Solution: Meta Pseudo Labels + Knowledge Distillation](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/322832)\n* [4th place solution: Deberta models & postprocess](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/322799)\n* [5th place solution](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/322875)\n* [6th place solution](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/323237)\n* [7th place solution: Get 0.892 in just 10 minutes](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/322829)\n* [8th place solution](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/322962)\n* [9th Weight search and threshold modification](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/322891)\n\n## Jigsaw Rate Severity of Toxic Comments\n\nhttps://www.kaggle.com/competitions/jigsaw-toxic-severity-rating\n\nAnother recent NLP competition with a similar problem statement that finished in February 2022. \n\n* [1st place solution with code](https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/discussion/306274)\n* [Toxic Solution and Review (2nd Place)](https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/discussion/308938)\n* [4th - This is Great! - Shared Solution](https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/discussion/306084)\n* [5th place solution](https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/discussion/306390)\n* [7th Place Solution](https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/discussion/306366)\n\nSee also: [Every single Jigsaw competition solution write up in history](https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating/discussion/286333)\n\n","metadata":{}},{"cell_type":"markdown","source":"# Competition Metric","metadata":{}},{"cell_type":"markdown","source":"Solutions are evaluated using multi-class log loss (also known as negative log-likelihood).\n\n$$\\text{log loss} = -\\frac{1}{\\color{magenta}{N}} \\sum\\limits_{i=1}^{\\color{magenta}{N}} \\sum\\limits_{j=1}^{\\color{purple}{M}} \\color{olive}{y_{ij}} \\color{orange}{\\log}(\\color{teal}{p_{ij}})$$\n\nWhere:\n* $\\color{magenta}{N}$ = number of rows.\n* $\\color{purple}{M}$ = number of class labels.\n* $\\color{olive}{y_{ij}}$ = 1 if $i$ is in class $j$, else 0.\n* $\\color{orange}{\\log}$ = natural logarithm.\n* $\\color{teal}{p_{ij}}$ is the predicted probability that $i$ belongs to class $j$.\n\n\nYou can think of log loss as the negative log of your prediction for the correct class.\n\nThe negative log has a range where at 0 the function returns ‚àû `‚àílog(0)= ‚àû` and at 1 returns 0 `‚àílog(1) = 0`\n\nThis means confidentally wrong answers are heavily penalised.\n\nHere I plot the range of the `-log(x)` function.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.arange(0.001, 1.0, 0.001)\ny = -np.log(x)\n\nfig,ax = plt.subplots(figsize=(6,4))\nax.plot(x,y)\nplt.ylabel('-log(x)')\nplt.xlabel('x')\nplt.title('Range of negative log-likelihood function')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:17:58.58385Z","iopub.execute_input":"2022-06-25T05:17:58.584163Z","iopub.status.idle":"2022-06-25T05:17:58.77809Z","shell.execute_reply.started":"2022-06-25T05:17:58.584133Z","shell.execute_reply":"2022-06-25T05:17:58.777418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports\n\nOn top of the standard data science libraries: Pandas, Numpy and Matplotlib, I'm importing these additional libraries for training neural networks:\n\n* [HuggingFace Transfomers](https://github.com/huggingface/transformers) library for pre-trained models and training framework.\n* [PyTorch](https://pytorch.org/) for GPU computation.\n* [Weights and Biases](https://wandb.ai) for experiment tracking.","metadata":{}},{"cell_type":"code","source":"import os\n\nrun_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nimport logging\nfrom types import SimpleNamespace\nfrom pathlib import Path\nfrom datetime import datetime\nimport math\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\nfrom transformers import TrainingArguments, Trainer\nfrom tqdm import tqdm\nfrom scipy.special import softmax\nfrom IPython.core.display import display, HTML\n\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset, load_metric\n\nimport wandb\n\n# From this Gist: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\ndef seed_everything(seed: int):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-06-25T05:17:58.779691Z","iopub.execute_input":"2022-06-25T05:17:58.780085Z","iopub.status.idle":"2022-06-25T05:18:01.886302Z","shell.execute_reply.started":"2022-06-25T05:17:58.780048Z","shell.execute_reply":"2022-06-25T05:18:01.885445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data\n\nThe competition data includes a training CSV file which includes metadata for each essay element, and a folder containing the full essay texts.\n\nLet's start by loading these and looking at an example from the train and test set.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/feedback-prize-effectiveness/train.csv')\ntest_df = pd.read_csv('../input/feedback-prize-effectiveness/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:01.888979Z","iopub.execute_input":"2022-06-25T05:18:01.88919Z","iopub.status.idle":"2022-06-25T05:18:02.040207Z","shell.execute_reply.started":"2022-06-25T05:18:01.889164Z","shell.execute_reply":"2022-06-25T05:18:02.039478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:02.042488Z","iopub.execute_input":"2022-06-25T05:18:02.042744Z","iopub.status.idle":"2022-06-25T05:18:02.056656Z","shell.execute_reply.started":"2022-06-25T05:18:02.04271Z","shell.execute_reply":"2022-06-25T05:18:02.055435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:02.058237Z","iopub.execute_input":"2022-06-25T05:18:02.058805Z","iopub.status.idle":"2022-06-25T05:18:02.070083Z","shell.execute_reply.started":"2022-06-25T05:18:02.058768Z","shell.execute_reply":"2022-06-25T05:18:02.068901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_df), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:02.071561Z","iopub.execute_input":"2022-06-25T05:18:02.071819Z","iopub.status.idle":"2022-06-25T05:18:02.077207Z","shell.execute_reply.started":"2022-06-25T05:18:02.071784Z","shell.execute_reply":"2022-06-25T05:18:02.076425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The train set contains **36,756** essay elements.\n\nThe test set CSV only contains **10** elements, as the notebook needs to be submitted to run against the entire test set.","metadata":{}},{"cell_type":"markdown","source":"# Essay Texts","metadata":{}},{"cell_type":"markdown","source":"Let's see the first 200 characters of a few essay examples.","metadata":{}},{"cell_type":"code","source":"essays = train_df.essay_id.unique()\n\ntexts = []\nfor essay_id in essays[:10]:\n    texts.append(open(f'../input/feedback-prize-effectiveness/train/{essay_id}.txt').read())\n\ninner_html = \"\"\nfor text in texts:\n    inner_html += f'<td style=\"vertical-align:top; border-right: 1px solid #7accd8\">{text[:200]}</td>'\ndisplay(HTML(f\"\"\"\n<table style=\"font-family: monospace;\">\n    <tr>\n         {inner_html}\n    </tr>\n</table>\n\"\"\"))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.078829Z","iopub.execute_input":"2022-06-25T05:18:02.079372Z","iopub.status.idle":"2022-06-25T05:18:02.106263Z","shell.execute_reply.started":"2022-06-25T05:18:02.079314Z","shell.execute_reply":"2022-06-25T05:18:02.105338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's count the number of unique essays in the folder.","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\nessay_ids_in_folder = set()\nfor path in Path('../input/feedback-prize-effectiveness/train').iterdir():\n    essay_ids_in_folder.add(path.name[:-4])\nlen(essay_ids_in_folder)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.107698Z","iopub.execute_input":"2022-06-25T05:18:02.107954Z","iopub.status.idle":"2022-06-25T05:18:02.127603Z","shell.execute_reply.started":"2022-06-25T05:18:02.10792Z","shell.execute_reply":"2022-06-25T05:18:02.12684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are **4,191** unique essays. Not a huge dataset at all!","metadata":{}},{"cell_type":"markdown","source":"Compared with number of essays in the CSV?","metadata":{}},{"cell_type":"code","source":"train_df.essay_id.nunique()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.128749Z","iopub.execute_input":"2022-06-25T05:18:02.129054Z","iopub.status.idle":"2022-06-25T05:18:02.139558Z","shell.execute_reply.started":"2022-06-25T05:18:02.129017Z","shell.execute_reply":"2022-06-25T05:18:02.138665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"essay_ids_in_folder - set(train_df.essay_id.unique()), set(train_df.essay_id.unique()) - essay_ids_in_folder","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:02.143333Z","iopub.execute_input":"2022-06-25T05:18:02.143647Z","iopub.status.idle":"2022-06-25T05:18:02.157774Z","shell.execute_reply.started":"2022-06-25T05:18:02.143611Z","shell.execute_reply":"2022-06-25T05:18:02.156996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So every essay in the CSV is represented in the folder. At least for the train set.","metadata":{}},{"cell_type":"markdown","source":"# Topics/Prompts\n\n[@jdoesv](https://www.kaggle.com/jdoesv) put together a really useful [notebook](https://www.kaggle.com/code/jdoesv/topics-identification), which runs [BERTopic](https://maartengr.github.io/BERTopic/index.html) across each of the training examples. This uncovers the essay prompts used for each of the training examples.\n\njdoesv determines that there are [15 essay prompts used in the dataset](https://www.kaggle.com/competitions/feedback-prize-effectiveness/discussion/327514). The topic information is useful for data analysis, and will potentially be useful in the final model, so I'm joining it with the competition dataset.","metadata":{}},{"cell_type":"code","source":"topic_pred_df = pd.read_csv('../input/feedback-topics-identification-with-bertopic/topic_model_feedback.csv')\ntopic_pred_df = topic_pred_df.drop(columns={'prob'})\ntopic_pred_df = topic_pred_df.rename(columns={'id': 'essay_id'})\n\ntopic_meta_df = pd.read_csv('../input/feedback-topics-identification-with-bertopic/topic_model_metadata.csv')\ntopic_meta_df = topic_meta_df.rename(columns={'Topic': 'topic', 'Name': 'topic_name'}).drop(columns=['Count'])\ntopic_meta_df.topic_name = topic_meta_df.topic_name.apply(lambda n: ' '.join(n.split('_')[1:]))\n\ntopic_pred_df = topic_pred_df.merge(topic_meta_df, on='topic', how='left')\n\ntrain_df = train_df.merge(topic_pred_df, on='essay_id', how='left')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.158975Z","iopub.execute_input":"2022-06-25T05:18:02.159284Z","iopub.status.idle":"2022-06-25T05:18:02.203569Z","shell.execute_reply.started":"2022-06-25T05:18:02.159248Z","shell.execute_reply":"2022-06-25T05:18:02.202933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\n \nsns.countplot(y=\"topic_name\", data=train_df, linewidth=1.25, alpha=1, ax=ax, zorder=2, orient='v')\nax.set_title(\"Topic distribution\")\n\nfor tick in ax.get_xticklabels():\n    tick.set_rotation(90)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.204554Z","iopub.execute_input":"2022-06-25T05:18:02.204787Z","iopub.status.idle":"2022-06-25T05:18:02.524831Z","shell.execute_reply.started":"2022-06-25T05:18:02.204755Z","shell.execute_reply":"2022-06-25T05:18:02.524193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, let's take a look at the competition metadata and start speculating on how it could be useful.","metadata":{}},{"cell_type":"markdown","source":"## Discourse Type\n\nEach essay element contains discourse type metadata. There are 7 `discourse_type` values with explainations taken from the [data page](https://www.kaggle.com/competitions/feedback-prize-effectiveness/data).\n\n* `Lead` - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader‚Äôs attention and point toward the thesis\n* `Position` - an opinion or conclusion on the main question\n* `Claim` - a claim that supports the position\n* `Counterclaim` - a claim that refutes another claim or gives an opposing reason to the position\n* `Rebuttal` - a claim that refutes a counterclaim\n* `Evidence` - ideas or examples that support claims, counterclaims, or rebuttals.\n* `Concluding Statement` - a concluding statement that restates the claims.\n\nLet's look at the distribution across the whole dataset.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\nsns.countplot(x=\"discourse_type\", data=train_df, linewidth=1.25, alpha=1, ax=ax, zorder=2)\nax.set_title(\"Discourse type distribution\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.526406Z","iopub.execute_input":"2022-06-25T05:18:02.526862Z","iopub.status.idle":"2022-06-25T05:18:02.747816Z","shell.execute_reply.started":"2022-06-25T05:18:02.526826Z","shell.execute_reply":"2022-06-25T05:18:02.747164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next section, we'll explore the Discourse Effectiveness field. For now, it's sufficient to know there are three possible values: `Adequate`, `Efficient`, and `Ineffective`. Let's see the distribution of Discourse Type across Discourse Effectiveness.","metadata":{}},{"cell_type":"code","source":"labels = ['Adequate', 'Effective', 'Ineffective']","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:02.748841Z","iopub.execute_input":"2022-06-25T05:18:02.749068Z","iopub.status.idle":"2022-06-25T05:18:02.753195Z","shell.execute_reply.started":"2022-06-25T05:18:02.749031Z","shell.execute_reply":"2022-06-25T05:18:02.752375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discourse_types = train_df.discourse_type.unique()\n\nfig, axes = plt.subplots(1, len(discourse_types), sharex='col', sharey='row', figsize=(25, 3))\nfor i, discourse_type in enumerate(discourse_types):\n    ax = axes[i]\n    filtered_df = train_df[train_df.discourse_type == discourse_type]\n    sns.countplot(x=\"discourse_effectiveness\", data=filtered_df, linewidth=1.25, alpha=1, ax=ax, zorder=2, order=labels)\n    ax.set_title(discourse_type)\n    ax.set(xlabel=None, ylabel=None)\n    \nfig.suptitle('Discourse Effectiveness distribution per Discourse Type', y=1.08)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:02.754786Z","iopub.execute_input":"2022-06-25T05:18:02.75518Z","iopub.status.idle":"2022-06-25T05:18:03.381949Z","shell.execute_reply.started":"2022-06-25T05:18:02.755143Z","shell.execute_reply":"2022-06-25T05:18:03.3812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that you have highest probability of having your section marked `Ineffective` within the `Evidence` Discourse Type.\n\nThat makes sense as the degree of Evidence seems more objectively quantifiable.","metadata":{}},{"cell_type":"markdown","source":"## Discourse Effectiveness (label)","metadata":{}},{"cell_type":"markdown","source":"Each essay section is labelled from one of three labels: `Adequate`, `Effective`, and `Ineffective`.","metadata":{}},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:03.384336Z","iopub.execute_input":"2022-06-25T05:18:03.384585Z","iopub.status.idle":"2022-06-25T05:18:03.389775Z","shell.execute_reply.started":"2022-06-25T05:18:03.384559Z","shell.execute_reply":"2022-06-25T05:18:03.388836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's explore the distribution.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\n \nsns.countplot(x=\"discourse_effectiveness\", data=train_df, linewidth=1.25, alpha=1, ax=ax, zorder=2)\nax.set_title(\"Discourse type distribution\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:03.39147Z","iopub.execute_input":"2022-06-25T05:18:03.391772Z","iopub.status.idle":"2022-06-25T05:18:03.599738Z","shell.execute_reply.started":"2022-06-25T05:18:03.391739Z","shell.execute_reply":"2022-06-25T05:18:03.599092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, quite an imbalanced dataset. We may want to use some kind of weighting, or perhaps up or downsampling within the solution.","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\n\ndef show_examples_for_discourse_type(discourse_type, topic):\n    filt = train_df.query(f'discourse_type == \"{discourse_type}\"').query(f'topic == {topic}').sample(frac=1, random_state=420)\n    display(HTML(\n        f\"\"\"\n        <h4><code>{discourse_type}</code> examples</h4>\n        <table>\n            <tr>\n              <th width=33%>Ineffective</th>\n              <th width=33%>Adequate</th>\n              <th width=33%>Effective</th>\n            </tr>\n            <tr>\n              <td>{filt.query(\"discourse_effectiveness == 'Ineffective'\").iloc[0].discourse_text}</td>\n              <td>{filt.query(\"discourse_effectiveness == 'Adequate'\").iloc[0].discourse_text}</td>\n              <td>{filt.query(\"discourse_effectiveness == 'Effective'\").iloc[0].discourse_text}</td>\n            </tr>\n        </table>\n        \"\"\"\n    ))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:03.601052Z","iopub.execute_input":"2022-06-25T05:18:03.601294Z","iopub.status.idle":"2022-06-25T05:18:03.606646Z","shell.execute_reply.started":"2022-06-25T05:18:03.601262Z","shell.execute_reply":"2022-06-25T05:18:03.605921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Examples","metadata":{}},{"cell_type":"markdown","source":"Let's see examples of each for each discourse type from topic: `face mars landform aliens`","metadata":{}},{"cell_type":"code","source":"for dt in discourse_types: show_examples_for_discourse_type(dt, 10)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:03.608048Z","iopub.execute_input":"2022-06-25T05:18:03.608662Z","iopub.status.idle":"2022-06-25T05:18:03.715812Z","shell.execute_reply.started":"2022-06-25T05:18:03.608625Z","shell.execute_reply":"2022-06-25T05:18:03.715169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Count","metadata":{}},{"cell_type":"markdown","source":"Let's look at the word count distribution across the dataset. The token count will inform settings for our model, like max sequence length and the types of model architectures we can use. Only some are suitable for very long sequences.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 5))\ntrain_df['word_count'] = train_df.discourse_text.apply(lambda x: len(x.split()))\nsns.histplot(data=train_df, x=\"word_count\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:03.717102Z","iopub.execute_input":"2022-06-25T05:18:03.71737Z","iopub.status.idle":"2022-06-25T05:18:04.514574Z","shell.execute_reply.started":"2022-06-25T05:18:03.717324Z","shell.execute_reply":"2022-06-25T05:18:04.513879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mean word count is 44.65 words:","metadata":{}},{"cell_type":"code","source":"train_df['word_count'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:04.51605Z","iopub.execute_input":"2022-06-25T05:18:04.516309Z","iopub.status.idle":"2022-06-25T05:18:04.522658Z","shell.execute_reply.started":"2022-06-25T05:18:04.516274Z","shell.execute_reply":"2022-06-25T05:18:04.521772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The max word count is 836.","metadata":{}},{"cell_type":"code","source":"train_df['word_count'].max()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:04.524334Z","iopub.execute_input":"2022-06-25T05:18:04.524673Z","iopub.status.idle":"2022-06-25T05:18:04.534216Z","shell.execute_reply.started":"2022-06-25T05:18:04.524639Z","shell.execute_reply":"2022-06-25T05:18:04.533221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the first 1000 characters:","metadata":{}},{"cell_type":"code","source":"train_df.iloc[train_df['word_count'].idxmax()].discourse_text[:1000]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:04.53586Z","iopub.execute_input":"2022-06-25T05:18:04.536244Z","iopub.status.idle":"2022-06-25T05:18:04.544887Z","shell.execute_reply.started":"2022-06-25T05:18:04.536126Z","shell.execute_reply":"2022-06-25T05:18:04.54411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the word count per Discourse Type","metadata":{}},{"cell_type":"code","source":"discourse_types = train_df.discourse_type.unique()\n\nfig, axes = plt.subplots(1, len(discourse_types), sharex='col', sharey='row', figsize=(25, 5))\nfor i, discourse_type in enumerate(discourse_types):\n    filtered_df = train_df[train_df.discourse_type == discourse_type]\n    sns.histplot(data=filtered_df, x=\"word_count\", ax=axes[i])\n    axes[i].set_title(discourse_type)\n    \nfig.suptitle('Word count distribution per discourse_type', y=1.08)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:18:04.546195Z","iopub.execute_input":"2022-06-25T05:18:04.547097Z","iopub.status.idle":"2022-06-25T05:18:06.676303Z","shell.execute_reply.started":"2022-06-25T05:18:04.54706Z","shell.execute_reply":"2022-06-25T05:18:06.674422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So `Claim` and `Evidence` appear to have the largest word count.","metadata":{}},{"cell_type":"markdown","source":"# 2021 Data","metadata":{}},{"cell_type":"markdown","source":"In [this](https://www.kaggle.com/code/lextoumbourou/feedback-prize-inference-on-2021-dataset) notebook, I made predictions on the full 2021 set from the original Feedback competition.\n\nLet's load them here. I'll exclude any that are in the 2022 subset.","metadata":{}},{"cell_type":"code","source":"train_2021_preds_df = pd.read_csv('../input/feedback-prize-inference-on-2021-dataset/train_2021_preds.csv')\ntrain_2021_preds_df = train_2021_preds_df[train_2021_preds_df.in_2022 == False]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:06.67763Z","iopub.execute_input":"2022-06-25T05:18:06.677963Z","iopub.status.idle":"2022-06-25T05:18:07.410301Z","shell.execute_reply.started":"2022-06-25T05:18:06.677923Z","shell.execute_reply":"2022-06-25T05:18:07.409563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_preds_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.411844Z","iopub.execute_input":"2022-06-25T05:18:07.412088Z","iopub.status.idle":"2022-06-25T05:18:07.428654Z","shell.execute_reply.started":"2022-06-25T05:18:07.412055Z","shell.execute_reply":"2022-06-25T05:18:07.427835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\n \nsns.countplot(x=\"discourse_effectiveness\", data=train_2021_preds_df, linewidth=1.25, alpha=1, ax=ax, zorder=2)\nax.set_title(\"Discourse Effectiveness distribution\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.430308Z","iopub.execute_input":"2022-06-25T05:18:07.430942Z","iopub.status.idle":"2022-06-25T05:18:07.695729Z","shell.execute_reply.started":"2022-06-25T05:18:07.430903Z","shell.execute_reply":"2022-06-25T05:18:07.694884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'm going to get essays that contain the most confident predictions.\n\nThat should maintain the same distribution of discourse types.","metadata":{}},{"cell_type":"code","source":"num_essays = 2","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.703046Z","iopub.execute_input":"2022-06-25T05:18:07.703249Z","iopub.status.idle":"2022-06-25T05:18:07.706686Z","shell.execute_reply.started":"2022-06-25T05:18:07.703224Z","shell.execute_reply":"2022-06-25T05:18:07.70578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_preds_df['label_prob'] = train_2021_preds_df[labels].max(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.708218Z","iopub.execute_input":"2022-06-25T05:18:07.708897Z","iopub.status.idle":"2022-06-25T05:18:07.721844Z","shell.execute_reply.started":"2022-06-25T05:18:07.708848Z","shell.execute_reply":"2022-06-25T05:18:07.720997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_2021_preds_df = train_2021_preds_df.merge(topic_pred_df, on='essay_id', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.723147Z","iopub.execute_input":"2022-06-25T05:18:07.72368Z","iopub.status.idle":"2022-06-25T05:18:07.729433Z","shell.execute_reply.started":"2022-06-25T05:18:07.723635Z","shell.execute_reply":"2022-06-25T05:18:07.7284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confident_essays = train_2021_preds_df[['essay_id', 'label_prob']].groupby('essay_id').mean().sort_values('label_prob', ascending=False)[:num_essays]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.731318Z","iopub.execute_input":"2022-06-25T05:18:07.73161Z","iopub.status.idle":"2022-06-25T05:18:07.772174Z","shell.execute_reply.started":"2022-06-25T05:18:07.731573Z","shell.execute_reply":"2022-06-25T05:18:07.769692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"essay_ids = set(confident_essays.index)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.776427Z","iopub.execute_input":"2022-06-25T05:18:07.778786Z","iopub.status.idle":"2022-06-25T05:18:07.788119Z","shell.execute_reply.started":"2022-06-25T05:18:07.778744Z","shell.execute_reply":"2022-06-25T05:18:07.78668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_filt_df = train_2021_preds_df[train_2021_preds_df.essay_id.isin(essay_ids)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.791631Z","iopub.execute_input":"2022-06-25T05:18:07.792052Z","iopub.status.idle":"2022-06-25T05:18:07.803101Z","shell.execute_reply.started":"2022-06-25T05:18:07.792024Z","shell.execute_reply":"2022-06-25T05:18:07.801973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_filt_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.804704Z","iopub.execute_input":"2022-06-25T05:18:07.80503Z","iopub.status.idle":"2022-06-25T05:18:07.813174Z","shell.execute_reply.started":"2022-06-25T05:18:07.804995Z","shell.execute_reply":"2022-06-25T05:18:07.812405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, let's get to training a model!","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"markdown","source":"I include some additional dropout in the config as the model tends to overfit as well as label smoothing, as it seems to work slightly better in the tests I've performed.","metadata":{}},{"cell_type":"code","source":"config = SimpleNamespace()\n\nconfig.seed = 420\nconfig.model_name = 'microsoft/deberta-v3-base'\nconfig.output_path = Path('./')\nconfig.input_path = Path('../input/feedback-prize-effectiveness')\n\nconfig.n_folds = 4\nconfig.lr = 1e-5\nconfig.weight_decay = 0.01\nconfig.epochs = 4\nconfig.batch_size = 16\nconfig.gradient_accumulation_steps = 1\nconfig.warm_up_ratio = 0.1\nconfig.max_len = 384\nconfig.hidden_dropout_prob = 0.1\nconfig.label_smoothing_factor = 0.\nconfig.eval_per_epoch = 2\n\nlogging.disable(logging.WARNING)\n\nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.814458Z","iopub.execute_input":"2022-06-25T05:18:07.814774Z","iopub.status.idle":"2022-06-25T05:18:07.824734Z","shell.execute_reply.started":"2022-06-25T05:18:07.81474Z","shell.execute_reply":"2022-06-25T05:18:07.824013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WanDB","metadata":{}},{"cell_type":"code","source":"if run_type == 'Interactive':\n    print('Wandb in offline mode.')\n    os.environ['WANDB_MODE'] = 'offline'","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.826109Z","iopub.execute_input":"2022-06-25T05:18:07.827622Z","iopub.status.idle":"2022-06-25T05:18:07.833188Z","shell.execute_reply.started":"2022-06-25T05:18:07.827582Z","shell.execute_reply":"2022-06-25T05:18:07.832422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following lines of code assumes that you have a [User Secret](https://www.kaggle.com/product-feedback/114053) setup called `wandb` with your wandb API key.","metadata":{}},{"cell_type":"code","source":"print('Authenticating with wandb.')\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_creds = user_secrets.get_secret(\"wandb\")\n\n!wandb login {wandb_creds}","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:07.834438Z","iopub.execute_input":"2022-06-25T05:18:07.835306Z","iopub.status.idle":"2022-06-25T05:18:10.145359Z","shell.execute_reply.started":"2022-06-25T05:18:07.835271Z","shell.execute_reply":"2022-06-25T05:18:10.14442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.config = config.__dict__","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:10.147375Z","iopub.execute_input":"2022-06-25T05:18:10.147661Z","iopub.status.idle":"2022-06-25T05:18:10.151933Z","shell.execute_reply.started":"2022-06-25T05:18:10.147623Z","shell.execute_reply":"2022-06-25T05:18:10.151209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(project=\"feedback-prize-effectiveness\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:10.153163Z","iopub.execute_input":"2022-06-25T05:18:10.153657Z","iopub.status.idle":"2022-06-25T05:18:14.8931Z","shell.execute_reply.started":"2022-06-25T05:18:10.153617Z","shell.execute_reply":"2022-06-25T05:18:14.892215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup CV","metadata":{}},{"cell_type":"markdown","source":"Note that I am using `StratifiedKFold` instead of `StratifiedGroupKFold` here, as it performs better on the LB. This comes at the expense of an accurate CV score.","metadata":{}},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:14.894609Z","iopub.execute_input":"2022-06-25T05:18:14.895194Z","iopub.status.idle":"2022-06-25T05:18:14.900956Z","shell.execute_reply.started":"2022-06-25T05:18:14.895152Z","shell.execute_reply":"2022-06-25T05:18:14.900091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['fold'] = -1\nfor fold_num, (train_idxs, test_idxs) in enumerate(cv.split(train_df.index, train_df.discourse_effectiveness, train_df.essay_id)):\n    train_df.loc[test_idxs, ['fold']] = fold_num","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:14.902574Z","iopub.execute_input":"2022-06-25T05:18:14.903Z","iopub.status.idle":"2022-06-25T05:18:14.976714Z","shell.execute_reply.started":"2022-06-25T05:18:14.902964Z","shell.execute_reply":"2022-06-25T05:18:14.976079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:14.978023Z","iopub.execute_input":"2022-06-25T05:18:14.978406Z","iopub.status.idle":"2022-06-25T05:18:15.002605Z","shell.execute_reply.started":"2022-06-25T05:18:14.978355Z","shell.execute_reply":"2022-06-25T05:18:15.001288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(config.output_path / 'train_folds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:15.003934Z","iopub.execute_input":"2022-06-25T05:18:15.004205Z","iopub.status.idle":"2022-06-25T05:18:15.53745Z","shell.execute_reply.started":"2022-06-25T05:18:15.004157Z","shell.execute_reply":"2022-06-25T05:18:15.536621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"config.model_name","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:15.538676Z","iopub.execute_input":"2022-06-25T05:18:15.539291Z","iopub.status.idle":"2022-06-25T05:18:15.546059Z","shell.execute_reply.started":"2022-06-25T05:18:15.539249Z","shell.execute_reply":"2022-06-25T05:18:15.54533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name, use_fast=True)\ntokenizer.model_max_length = config.max_len","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:15.547547Z","iopub.execute_input":"2022-06-25T05:18:15.54798Z","iopub.status.idle":"2022-06-25T05:18:19.404269Z","shell.execute_reply.started":"2022-06-25T05:18:15.547942Z","shell.execute_reply":"2022-06-25T05:18:19.40341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.405797Z","iopub.execute_input":"2022-06-25T05:18:19.406062Z","iopub.status.idle":"2022-06-25T05:18:19.412622Z","shell.execute_reply.started":"2022-06-25T05:18:19.406025Z","shell.execute_reply":"2022-06-25T05:18:19.411947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_essay(essay_fns):\n    essay_cache = {}\n\n    output = []\n    for essay_fn in essay_fns:\n        if essay_fn not in essay_cache:\n            essay_txt = open(essay_fn).read().strip().lower()\n            essay_cache[essay_fn] = essay_txt\n        output.append(essay_cache[essay_fn])\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.414006Z","iopub.execute_input":"2022-06-25T05:18:19.41449Z","iopub.status.idle":"2022-06-25T05:18:19.423422Z","shell.execute_reply.started":"2022-06-25T05:18:19.414452Z","shell.execute_reply":"2022-06-25T05:18:19.422692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The essay string is passed as the `text_pair` argument to the tokenisation function. I got this idea from [this](https://www.kaggle.com/code/abhishek/tez-for-feedback-v2-0) kernel. I can't tell you exactly why it helps to pass as `text_pair` instead of concatenating onto the sequence, but it seems to work a bit.","metadata":{}},{"cell_type":"code","source":"def tokenizer_func(x):\n    return tokenizer(x[\"inputs\"], get_essay(x['essay_fn']), truncation=True, max_len=config.max_len)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.424659Z","iopub.execute_input":"2022-06-25T05:18:19.424934Z","iopub.status.idle":"2022-06-25T05:18:19.432505Z","shell.execute_reply.started":"2022-06-25T05:18:19.424897Z","shell.execute_reply":"2022-06-25T05:18:19.431798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the `discourse_type` will be potentially valuable information, I'll concatenate it to the essay elements.\n\nI'm also concatenating the topic information.\n\nLastly, converting all text to lowercase as it performs better on CV and LB.","metadata":{}},{"cell_type":"code","source":"def add_inputs(df, basepath):\n    df['essay_fn'] = basepath + '/' + df.essay_id + '.txt'\n    df['inputs'] = df.discourse_type.str.lower() + ' ' + tokenizer.sep_token + ' ' + df.topic_name + ' ' + tokenizer.sep_token + ' ' + df.discourse_text.str.lower()\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.433884Z","iopub.execute_input":"2022-06-25T05:18:19.434457Z","iopub.status.idle":"2022-06-25T05:18:19.441904Z","shell.execute_reply.started":"2022-06-25T05:18:19.43442Z","shell.execute_reply":"2022-06-25T05:18:19.441024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = add_inputs(train_df, str(config.input_path / 'train'))\ntrain_2021_filt_df = add_inputs(train_2021_filt_df, '../input/feedback-prize-2021/train')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.444096Z","iopub.execute_input":"2022-06-25T05:18:19.444722Z","iopub.status.idle":"2022-06-25T05:18:19.578979Z","shell.execute_reply.started":"2022-06-25T05:18:19.44462Z","shell.execute_reply":"2022-06-25T05:18:19.578253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"For maximum experimentation flexibility, I've setup a custom head.\n\nI've included an implementation of [Multi-Sample Dropout](https://arxiv.org/abs/1905.09788) as the model is overfitting quite quickly.\n\nWhen using HuggingFace Transformers, the [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) class has a few rules you need to follow when creating custom models:\n\n* your model always return tuples or subclasses of ModelOutput.\n* your model can compute the loss if a labels argument is provided and that loss is returned as the first element of the tuple (if your model returns tuples)\n* your model can accept multiple label arguments (use the label_names in your TrainingArguments to indicate their name to the Trainer) but none of them should be named \"label\".\n\nI've also replaced the `ContextPooler` with a mean pooling layer, as it works better in the tests I've run outside of Kaggle.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom transformers import AutoConfig, AutoModelForSequenceClassification\nfrom transformers.models.deberta_v2.modeling_deberta_v2 import ContextPooler\nfrom transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout\nfrom transformers.modeling_outputs import TokenClassifierOutput\n\ndef get_dropouts(num, start_prob, increment):\n    return [StableDropout(start_prob + (increment * i)) for i in range(num)]  \n\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\nclass CustomModel(nn.Module):\n    def __init__(self, backbone):\n        super(CustomModel, self).__init__()\n        \n        self.model = backbone\n        self.config = self.model.config\n        self.num_labels = self.config.num_labels\n\n        # self.pooler = ContextPooler(self.config)\n        self.pooler = MeanPooling()\n        \n        self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n    \n        self.dropouts = get_dropouts(num=5, start_prob=config.hidden_dropout_prob - 0.02, increment=0.01)\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        inputs_embeds=None,\n        labels=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        return_dict=None\n    ):\n        outputs = self.model.deberta(\n            input_ids,\n            token_type_ids=token_type_ids,\n            attention_mask=attention_mask,\n            position_ids=position_ids,\n            inputs_embeds=inputs_embeds,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n        \n        encoder_layer = outputs[0]\n        pooled_output = self.pooler(encoder_layer, attention_mask)\n                      \n        # Multi-sample dropout.\n        num_dps = float(len(self.dropouts))\n        for ii, drop in enumerate(self.dropouts):\n            if ii == 0:\n                logits = (self.classifier(drop(pooled_output)) / num_dps)\n            else:\n                logits += (self.classifier(drop(pooled_output)) / num_dps)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            logits = logits.view(-1, self.num_labels)\n            loss = loss_fn(logits, labels.view(-1))\n\n        output = (logits,) + outputs[1:]\n\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.58036Z","iopub.execute_input":"2022-06-25T05:18:19.580651Z","iopub.status.idle":"2022-06-25T05:18:19.625259Z","shell.execute_reply.started":"2022-06-25T05:18:19.580613Z","shell.execute_reply":"2022-06-25T05:18:19.62451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_backbone_config():\n    model_config = AutoConfig.from_pretrained(config.model_name, num_labels=3)\n    model_config.hidden_dropout_prob = config.hidden_dropout_prob\n    return model_config","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.62658Z","iopub.execute_input":"2022-06-25T05:18:19.626908Z","iopub.status.idle":"2022-06-25T05:18:19.631641Z","shell.execute_reply.started":"2022-06-25T05:18:19.626866Z","shell.execute_reply":"2022-06-25T05:18:19.630931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model_config = get_backbone_config()\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        config.model_name,\n        config=model_config,\n    )\n    return CustomModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.632717Z","iopub.execute_input":"2022-06-25T05:18:19.633143Z","iopub.status.idle":"2022-06-25T05:18:19.642224Z","shell.execute_reply.started":"2022-06-25T05:18:19.633103Z","shell.execute_reply":"2022-06-25T05:18:19.641405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Need to save this to generate the backbone offline.","metadata":{}},{"cell_type":"code","source":"backbone_config = get_backbone_config()\nbackbone_config.save_pretrained('./backbone_config')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:19.643685Z","iopub.execute_input":"2022-06-25T05:18:19.644211Z","iopub.status.idle":"2022-06-25T05:18:20.102565Z","shell.execute_reply.started":"2022-06-25T05:18:19.644175Z","shell.execute_reply":"2022-06-25T05:18:20.101831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:20.103733Z","iopub.execute_input":"2022-06-25T05:18:20.104394Z","iopub.status.idle":"2022-06-25T05:18:22.910323Z","shell.execute_reply.started":"2022-06-25T05:18:20.104336Z","shell.execute_reply":"2022-06-25T05:18:22.909515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"The loss function Cross-Entropy is identical to the competition metric when running the model output through Softmax.\n\nI'll include accuracy as an additional metric as it tends to be human interpretable.","metadata":{}},{"cell_type":"code","source":"metric = load_metric('accuracy')\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:22.911651Z","iopub.execute_input":"2022-06-25T05:18:22.911909Z","iopub.status.idle":"2022-06-25T05:18:23.690114Z","shell.execute_reply.started":"2022-06-25T05:18:22.911875Z","shell.execute_reply":"2022-06-25T05:18:23.689422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df.sample(n=150)\n# config.epochs = 1","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:23.6913Z","iopub.execute_input":"2022-06-25T05:18:23.691588Z","iopub.status.idle":"2022-06-25T05:18:23.714215Z","shell.execute_reply.started":"2022-06-25T05:18:23.69155Z","shell.execute_reply":"2022-06-25T05:18:23.713559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_fold(fold_num):\n    train_data  = train_df.query(f'fold != {fold_num}').reset_index(drop=True)\n\n    val_data  = train_df.query(f'fold == {fold_num}').reset_index(drop=True)\n    \n    # Add 2021 to train data.\n    train_data = pd.concat([train_data, train_2021_filt_df[['inputs', 'essay_fn', 'discourse_effectiveness']]]).sample(frac=1., random_state=config.seed).reset_index(drop=True)\n    print(f'Train data size: {train_data.shape}')\n\n    train_dataset = Dataset.from_pandas(train_data[['inputs', 'essay_fn', 'discourse_effectiveness']]).rename_column('discourse_effectiveness', 'label').class_encode_column(\"label\")\n    val_dataset = Dataset.from_pandas(val_data[['inputs', 'essay_fn', 'discourse_effectiveness']]).rename_column('discourse_effectiveness', 'label').class_encode_column(\"label\")\n\n    train_tok_dataset = train_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n    val_tok_dataset = val_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='longest')\n\n    num_steps = len(train_data) / config.batch_size / config.gradient_accumulation_steps\n    eval_steps = num_steps // config.eval_per_epoch\n    print(f'Num steps: {num_steps}, eval steps: {eval_steps}')\n\n    args = TrainingArguments(\n        output_dir=config.output_path,\n        learning_rate=config.lr,\n        warmup_ratio=config.warm_up_ratio,\n        lr_scheduler_type='cosine',\n        fp16=True,\n        per_device_train_batch_size=config.batch_size,\n        per_device_eval_batch_size=config.batch_size * 2,\n        num_train_epochs=config.epochs,\n        weight_decay=config.weight_decay,\n        report_to=\"wandb\",\n\n        evaluation_strategy='steps',\n        eval_steps=eval_steps, \n        save_strategy='steps',\n        save_steps=eval_steps,\n        \n        load_best_model_at_end=True,\n        gradient_accumulation_steps=config.gradient_accumulation_steps,\n        label_smoothing_factor=config.label_smoothing_factor,\n        save_total_limit=3  # Prevents running out of disk space.\n    )\n\n    model = get_model()\n\n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=train_tok_dataset,\n        eval_dataset=val_tok_dataset,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    trainer.train()\n    \n    trainer.save_model(config.output_path / f'fold_{fold_num}')\n    \n    outputs = trainer.predict(val_tok_dataset)\n\n    val_data[labels] = softmax(outputs.predictions, axis=1)\n    \n    !rm -rf {config.output_path / 'checkpoint'}*\n    \n    return val_data","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:23.715935Z","iopub.execute_input":"2022-06-25T05:18:23.716406Z","iopub.status.idle":"2022-06-25T05:18:23.744306Z","shell.execute_reply.started":"2022-06-25T05:18:23.716367Z","shell.execute_reply":"2022-06-25T05:18:23.74362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df = pd.DataFrame()\n\nval_data = do_fold(0)\n\nval_preds_df = pd.concat([val_preds_df, val_data])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:23.745705Z","iopub.execute_input":"2022-06-25T05:18:23.746055Z","iopub.status.idle":"2022-06-25T05:18:52.346635Z","shell.execute_reply.started":"2022-06-25T05:18:23.746016Z","shell.execute_reply":"2022-06-25T05:18:52.345498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## All Folds","metadata":{}},{"cell_type":"code","source":"for fold in range(1, config.n_folds):\n    val_data = do_fold(fold)\n    val_preds_df = pd.concat([val_preds_df, val_data])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:18:52.352572Z","iopub.execute_input":"2022-06-25T05:18:52.35522Z","iopub.status.idle":"2022-06-25T05:20:28.543161Z","shell.execute_reply.started":"2022-06-25T05:18:52.355161Z","shell.execute_reply":"2022-06-25T05:20:28.542191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df.drop(columns=['inputs']).to_csv(config.output_path / 'val_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:28.546383Z","iopub.execute_input":"2022-06-25T05:20:28.547011Z","iopub.status.idle":"2022-06-25T05:20:28.562262Z","shell.execute_reply.started":"2022-06-25T05:20:28.546976Z","shell.execute_reply":"2022-06-25T05:20:28.561589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df = pd.read_csv(config.output_path / 'val_preds.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:28.563465Z","iopub.execute_input":"2022-06-25T05:20:28.563814Z","iopub.status.idle":"2022-06-25T05:20:29.930749Z","shell.execute_reply.started":"2022-06-25T05:20:28.563777Z","shell.execute_reply":"2022-06-25T05:20:29.929953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:29.932186Z","iopub.execute_input":"2022-06-25T05:20:29.932464Z","iopub.status.idle":"2022-06-25T05:20:30.792873Z","shell.execute_reply.started":"2022-06-25T05:20:29.932429Z","shell.execute_reply":"2022-06-25T05:20:30.791699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Score","metadata":{}},{"cell_type":"code","source":"cv = log_loss(val_preds_df['discourse_effectiveness'], val_preds_df[labels])\ncv","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:30.794866Z","iopub.execute_input":"2022-06-25T05:20:30.795299Z","iopub.status.idle":"2022-06-25T05:20:30.810211Z","shell.execute_reply.started":"2022-06-25T05:20:30.795254Z","shell.execute_reply":"2022-06-25T05:20:30.809418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.log({\"cv\": cv})","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:30.81148Z","iopub.execute_input":"2022-06-25T05:20:30.811814Z","iopub.status.idle":"2022-06-25T05:20:30.817457Z","shell.execute_reply.started":"2022-06-25T05:20:30.811758Z","shell.execute_reply":"2022-06-25T05:20:30.816678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Interpretation","metadata":{}},{"cell_type":"markdown","source":"I'm going to explore some of the model's predictions. I hope to learn more about the dataset and its limitations by doing this.","metadata":{}},{"cell_type":"markdown","source":"Firstly, I'll add a column to calculate the `-log` error per example.","metadata":{}},{"cell_type":"code","source":"def compute_loss(row):\n    return -math.log(row[row.discourse_effectiveness])\n\nval_preds_df['loss'] = val_preds_df.apply(compute_loss, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:30.81885Z","iopub.execute_input":"2022-06-25T05:20:30.819252Z","iopub.status.idle":"2022-06-25T05:20:30.831706Z","shell.execute_reply.started":"2022-06-25T05:20:30.819197Z","shell.execute_reply":"2022-06-25T05:20:30.831011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And another boolean column to describe where the prediction was correct or not. ","metadata":{}},{"cell_type":"code","source":"val_preds_df['predicted'] = val_preds_df[labels].idxmax(axis=1)\nval_preds_df['is_correct'] = val_preds_df.discourse_effectiveness == val_preds_df.predicted","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:30.832825Z","iopub.execute_input":"2022-06-25T05:20:30.833074Z","iopub.status.idle":"2022-06-25T05:20:30.844134Z","shell.execute_reply.started":"2022-06-25T05:20:30.83304Z","shell.execute_reply":"2022-06-25T05:20:30.843139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Average error per class","metadata":{}},{"cell_type":"code","source":"loss_per_class = val_preds_df[['discourse_effectiveness', 'loss']].groupby('discourse_effectiveness').mean('loss')\nloss_per_class","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:30.845871Z","iopub.execute_input":"2022-06-25T05:20:30.846386Z","iopub.status.idle":"2022-06-25T05:20:30.860116Z","shell.execute_reply.started":"2022-06-25T05:20:30.846329Z","shell.execute_reply":"2022-06-25T05:20:30.859366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot()\n\nsns.barplot(x=loss_per_class.index, y=loss_per_class.loss, ax=ax)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:30.861104Z","iopub.execute_input":"2022-06-25T05:20:30.861296Z","iopub.status.idle":"2022-06-25T05:20:31.054885Z","shell.execute_reply.started":"2022-06-25T05:20:30.861273Z","shell.execute_reply":"2022-06-25T05:20:31.054202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly the ineffective classes are the most difficult to classify.","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix\n\nA confusion matrix is a useful way of viewing which classes the model has the most difficulty with.\n\nA common practice to create a nice looking confusion matrix is to pass a scikit Confusion Matrix into a Seaborn Heatmap.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nlabels = ['Ineffective', 'Adequate', 'Effective']\n\ndef do_conf_matrix(y_true, y_pred, ax, title=None):\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    cm\n\n    sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Blues');\n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels');\n    ax.set_ylabel('True labels'); \n    ax.set_title('Confusion Matrix'); \n\n    ax.xaxis.set_ticklabels(labels)\n    ax.yaxis.set_ticklabels(labels);\n    \n\ny_true = val_preds_df.discourse_effectiveness.values\ny_pred = val_preds_df[labels].idxmax(axis=1).values\nax= plt.subplot()\ndo_conf_matrix(y_true, y_pred, ax=ax)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:31.056307Z","iopub.execute_input":"2022-06-25T05:20:31.056614Z","iopub.status.idle":"2022-06-25T05:20:31.30786Z","shell.execute_reply.started":"2022-06-25T05:20:31.056581Z","shell.execute_reply":"2022-06-25T05:20:31.307193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see again that the model is having a lot of difficulty with `Ineffective` labeled examples.","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix Per Discourse Type","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, len(discourse_types), figsize=(30, 3))\nfor i, discourse_type in enumerate(discourse_types):\n    filtered_df = val_preds_df[val_preds_df.discourse_type == discourse_type]\n    y_true = filtered_df.discourse_effectiveness.values\n    y_pred = filtered_df[labels].idxmax(axis=1).values\n    ax = axes[i]\n    do_conf_matrix(y_true, y_pred, ax=ax)\n    axes[i].set_title(discourse_type)\n    \nfig.suptitle('Confusion matrix per discourse_type', y=1.08)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:31.309069Z","iopub.execute_input":"2022-06-25T05:20:31.309315Z","iopub.status.idle":"2022-06-25T05:20:33.397767Z","shell.execute_reply.started":"2022-06-25T05:20:31.309287Z","shell.execute_reply":"2022-06-25T05:20:33.396922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confident wrong examples\n\nLet's see 5 examples where the model was very confident but wrong.","metadata":{}},{"cell_type":"code","source":"inner_html = \"\"\nfor idx, row in val_preds_df[~val_preds_df.is_correct].sort_values('loss', ascending=True).head(5).iterrows():\n    inner_html += f'''\n    <td width=\"20%\" style=\"vertical-align:top; border-right: 1px solid #7accd8\"><p><b>Actual</b>: {row.discourse_effectiveness} <br><b>Predicted</b>: {row.predicted} ({row[row.predicted]}) <p><i>{row.discourse_text}</p></td>\n    '''\n    \ndisplay(HTML(f\"\"\"\n<table style=\"font-family: monospace;\">\n    <tr>\n         {inner_html}\n    </tr>\n</table>\n\"\"\"))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:33.399372Z","iopub.execute_input":"2022-06-25T05:20:33.399622Z","iopub.status.idle":"2022-06-25T05:20:33.420743Z","shell.execute_reply.started":"2022-06-25T05:20:33.399587Z","shell.execute_reply":"2022-06-25T05:20:33.417773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confident right examples\n\nLet's see 5 examples where the model was very confident and right.","metadata":{}},{"cell_type":"code","source":"inner_html = \"\"\nfor idx, row in val_preds_df[val_preds_df.is_correct].sort_values('loss', ascending=True).head(5).iterrows():\n    inner_html += f'''\n        <td width=\"20%\" style=\"vertical-align:top; border-right: 1px solid #7accd8\"><p><b>Actual</b>: {row.discourse_effectiveness} <br><b>Predicted</b>: {row.predicted} ({row[row.predicted]}) <p><i>{row.discourse_text}</p></td>\n    '''\n    \ndisplay(HTML(f\"\"\"\n<table style=\"font-family: monospace;\">\n    <tr>\n         {inner_html}\n    </tr>\n</table>\n\"\"\"))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:33.422043Z","iopub.execute_input":"2022-06-25T05:20:33.422427Z","iopub.status.idle":"2022-06-25T05:20:33.441599Z","shell.execute_reply.started":"2022-06-25T05:20:33.422387Z","shell.execute_reply":"2022-06-25T05:20:33.440706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Whole Essays","metadata":{}},{"cell_type":"code","source":"def _get_label_color(label):\n    return {\n        'Adequate': '#777',\n        'Ineffective': '#d9534f',\n        'Effective': '#5cb85c'\n    }[label]\n\ndef display_essay(essay_id):\n    table_header = \"\"\"<table style=\"line-height: 25px; border-collapse:collapse;\" width=100%>\n        <tr style=\"font-size: 1.2em; padding-top: 15px; font-family: monospace; background-image: repeating-linear-gradient(white 0px, white 24px, #7accd8 25px);\">\n            <th style=\"padding-bottom: 10px;\" width=\"10%\" align=\"left\">Prediction</th>\n            <th style=\"padding-bottom: 10px;\" width=\"5%\" align=\"left\">Conf</th>\n            <th style=\"padding-bottom: 10px;\"  width=\"75%\" align=\"left\">Text</th>\n            <th style=\"padding-bottom: 10px;\"  width=\"10%\" align=\"left\">Type</th>\n        </tr>\"\"\"\n\n\n    for idx, row in val_preds_df[val_preds_df.essay_id == essay_id].iterrows():\n        table_header += f\"\"\"\n        <tr  style=\"padding: 0px; vertical-align: top; align: left; background-image: repeating-linear-gradient(white 0px, white 24px, #7accd8 25px);\">\n            <td style=\"vertical-align: top; line-height: 25px;\">\n                <div style=\"line-height: 20px; width: 100%;  text-align:center; border-radius: 0.25em; background-color: {_get_label_color(row.predicted)}; color: #fff; font-family: monospace\">{row.predicted}</div>\n                \n            </td>\n            <td style=\"vertical-align: top; align: left; line-height: 25px;\">\n                <span style=\"border-radius: 0.25em; color: #000; font-family: monospace\"> {round(row[row.predicted], 2)}</span>\n            </td>\n            <td style=\"vertical-align: top; align: left; font-family: monospace; line-height: 25px;\">\n                {row.discourse_text}\n            </td>\n            <td style=\"vertical-align: top; align: left; line-height: 25px;\">\n                <span style=\"border-radius: 0.25em; color: #000; font-family: monospace\"><b>{row.discourse_type}</b></span>\n            </td>\n        </tr>\n        \"\"\"\n\n    table_footer = \"\"\"</table>\"\"\"\n    display(HTML(table_header + table_footer))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T05:20:33.442966Z","iopub.execute_input":"2022-06-25T05:20:33.443239Z","iopub.status.idle":"2022-06-25T05:20:33.451244Z","shell.execute_reply.started":"2022-06-25T05:20:33.443202Z","shell.execute_reply":"2022-06-25T05:20:33.450428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"essay1, essay2 = list(val_preds_df[val_preds_df.is_correct].sort_values('loss', ascending=True).essay_id.values[:2])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:33.4529Z","iopub.execute_input":"2022-06-25T05:20:33.453376Z","iopub.status.idle":"2022-06-25T05:20:33.463603Z","shell.execute_reply.started":"2022-06-25T05:20:33.453319Z","shell.execute_reply":"2022-06-25T05:20:33.462758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_essay(essay1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:33.466078Z","iopub.execute_input":"2022-06-25T05:20:33.466328Z","iopub.status.idle":"2022-06-25T05:20:33.476224Z","shell.execute_reply.started":"2022-06-25T05:20:33.466283Z","shell.execute_reply":"2022-06-25T05:20:33.475181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_essay(essay2)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:33.47794Z","iopub.execute_input":"2022-06-25T05:20:33.47891Z","iopub.status.idle":"2022-06-25T05:20:33.487526Z","shell.execute_reply.started":"2022-06-25T05:20:33.478869Z","shell.execute_reply":"2022-06-25T05:20:33.486496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"markdown","source":"For inference results see [Feedback Prize - DeBERTa-v3 Inference](https://www.kaggle.com/code/lextoumbourou/feedback-prize-deberta-v3-inference).\n\nI add the inference code here just for completeness.","metadata":{}},{"cell_type":"code","source":"import sys\nimport glob\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nsys.path.append('../input/feedback-topics-identification-with-bertopic/site-packages')\nfrom bertopic import BERTopic\n\ntopic_model = BERTopic.load(\"../input/feedback-topics-identification-with-bertopic/feedback_2021_topic_model\")\n\nsws = stopwords.words(\"english\") + [\"n't\",  \"'s\", \"'ve\"]\nfls = glob.glob(\"../input/feedback-prize-effectiveness/test/*.txt\")\ndocs = []\nfor fl in tqdm(fls):\n    with open(fl) as f:\n        txt = f.read()\n        word_tokens = word_tokenize(txt)\n        txt = \" \".join([w for w in word_tokens if not w.lower() in sws])\n    docs.append(txt)\n\ntopics, probs = topic_model.transform(docs)\n\npred_topics = pd.DataFrame()\ndids = list(map(lambda fl: fl.split(\"/\")[-1].split(\".\")[0], fls))\npred_topics[\"id\"] = dids\npred_topics[\"topic\"] = topics\npred_topics['prob'] = probs\npred_topics = pred_topics.drop(columns={'prob'})\npred_topics = pred_topics.rename(columns={'id': 'essay_id'})\npred_topics = pred_topics.merge(topic_meta_df, on='topic', how='left')\npred_topics","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:20:33.48929Z","iopub.execute_input":"2022-06-25T05:20:33.490067Z","iopub.status.idle":"2022-06-25T05:21:26.599971Z","shell.execute_reply.started":"2022-06-25T05:20:33.490023Z","shell.execute_reply":"2022-06-25T05:21:26.59921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.merge(pred_topics, on='essay_id', how='left')\ntest_df = add_inputs(test_df, str(config.input_path / 'test'))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:21:26.601265Z","iopub.execute_input":"2022-06-25T05:21:26.601539Z","iopub.status.idle":"2022-06-25T05:21:26.615539Z","shell.execute_reply.started":"2022-06-25T05:21:26.601502Z","shell.execute_reply":"2022-06-25T05:21:26.614721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nall_test_data = np.zeros((config.n_folds, len(test_df), len(labels)))\n\nfor fold_num in range(config.n_folds):\n    print(f'Do fold {fold_num}')\n\n    tokenizer = AutoTokenizer.from_pretrained(f'./fold_{fold_num}')\n    tokenizer.model_max_length = config.max_len\n\n    model = get_model()\n    state_dict = torch.load(f'./fold_{fold_num}/pytorch_model.bin')\n    model.load_state_dict(state_dict)\n    \n    test_dataset = Dataset.from_pandas(test_df[['inputs', 'essay_fn']])\n    test_tok_dataset = test_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n    \n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='longest')\n\n    args = TrainingArguments(\n        output_dir=config.output_path,\n        learning_rate=config.lr,\n        lr_scheduler_type='cosine',\n        fp16=True,\n        evaluation_strategy='epoch',\n        per_device_train_batch_size=config.batch_size,\n        per_device_eval_batch_size=config.batch_size * 2,\n        report_to=\"none\",\n        save_strategy='no'\n    )\n    \n    trainer = Trainer(\n        model,\n        args,\n        tokenizer=tokenizer,\n        data_collator=data_collator\n    )\n    \n    outputs = trainer.predict(test_tok_dataset) \n    softmax_outputs = softmax(outputs.predictions, axis=1)\n    \n    all_test_data[fold_num] = softmax_outputs","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:21:26.618901Z","iopub.execute_input":"2022-06-25T05:21:26.619117Z","iopub.status.idle":"2022-06-25T05:21:58.064491Z","shell.execute_reply.started":"2022-06-25T05:21:26.619091Z","shell.execute_reply":"2022-06-25T05:21:58.063757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"preds = np.mean(all_test_data, axis=0)\noutput_df = pd.concat([test_df[['discourse_id']], pd.DataFrame(preds, columns=labels)], axis=1)\noutput_df.to_csv('submission.csv', index=False)\npd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T05:21:58.065672Z","iopub.execute_input":"2022-06-25T05:21:58.065941Z","iopub.status.idle":"2022-06-25T05:21:58.088967Z","shell.execute_reply.started":"2022-06-25T05:21:58.065904Z","shell.execute_reply":"2022-06-25T05:21:58.088228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}