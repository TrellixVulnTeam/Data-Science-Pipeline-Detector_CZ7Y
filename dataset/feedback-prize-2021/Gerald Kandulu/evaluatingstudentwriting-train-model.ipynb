{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feedback Prize - Evaluating Student Writing\nWriting is a critical skill for success. However, less than a third of high school seniors are proficient writers, according to the National Assessment of Educational Progress. Unfortunately, low-income, Black, and Hispanic students fare even worse, with less than 15 percent demonstrating writing proficiency. One way to help students improve their writing is via automated feedback tools, which evaluate student writing and provide personalized feedback.\nThis notebook identify elements in student writing. More specifically, by using NLP to automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. The essays have the following elements:\n* Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the readerâ€™s attention and point toward the thesis\n* Position - an opinion or conclusion on the main question\n* Claim - a claim that supports the position\n* Counterclaim - a claim that refutes another claim or gives an opposing reason to the position\n* Rebuttal - a claim that refutes a counterclaim\n* Evidence - ideas or examples that support claims, counterclaims, or rebuttals.\n* Concluding Statement - a concluding statement that restates the claims\n\nThe essays were annotated by expert raters for elements commonly found in argumentative writing. The data were provided by Georgia State University and the Learning Agency Lab.\n\nDescription of the data for model training:\n* train.zip - folder of individual .txt files, with each file containing the full text of an essay response in the training set\n* train.csv - a .csv file containing the annotated version of all essays in the training set\n    * id - ID code for essay response\n    * discourse_id - ID code for discourse element\n    * discourse_start - character position where discourse element begins in the essay response\n    * discourse_end - character position where discourse element ends in the essay response\n    * discourse_text - text of discourse element\n    * discourse_type - classification of discourse element\n    * discourse_type_num - enumerated class label of discourse element\n    * predictionstring - the word indices of the training sample, as required for predictions\n* test.zip - folder of individual .txt files, with each file containing the full text of an essay response in the test set\n* sample_submission.csv - file in the required format for making predictions - note that if you are making multiple predictions for a document, submit multiple rows\n","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install umap-learn\n!pip install seqeval\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:09:20.577409Z","iopub.execute_input":"2022-04-21T07:09:20.577818Z","iopub.status.idle":"2022-04-21T07:12:45.546872Z","shell.execute_reply.started":"2022-04-21T07:09:20.577733Z","shell.execute_reply":"2022-04-21T07:12:45.545803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libaries\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nimport math\n\nfrom IPython.display import display\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport spacy\nimport umap\n\nfrom tqdm.auto import tqdm\n\nimport gc\nimport copy\npd.set_option('display.max_columns', None)\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nimport transformers\nfrom transformers import  BertConfig, BertForTokenClassification\nfrom transformers import AutoTokenizer\nfrom torch import cuda\n\n#set random seed\nrandom.seed(9999)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:45.549593Z","iopub.execute_input":"2022-04-21T07:12:45.549942Z","iopub.status.idle":"2022-04-21T07:12:56.061307Z","shell.execute_reply.started":"2022-04-21T07:12:45.549901Z","shell.execute_reply":"2022-04-21T07:12:56.060539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoModel, AutoTokenizer\ntransformers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:56.062934Z","iopub.execute_input":"2022-04-21T07:12:56.063442Z","iopub.status.idle":"2022-04-21T07:12:56.091032Z","shell.execute_reply.started":"2022-04-21T07:12:56.063399Z","shell.execute_reply":"2022-04-21T07:12:56.090339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = '../input/huggingface-bert/bert-base-cased'","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:56.092808Z","iopub.execute_input":"2022-04-21T07:12:56.093305Z","iopub.status.idle":"2022-04-21T07:12:56.098847Z","shell.execute_reply.started":"2022-04-21T07:12:56.093264Z","shell.execute_reply":"2022-04-21T07:12:56.097633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the bert tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\nassert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:56.101915Z","iopub.execute_input":"2022-04-21T07:12:56.105427Z","iopub.status.idle":"2022-04-21T07:12:56.185423Z","shell.execute_reply.started":"2022-04-21T07:12:56.105388Z","shell.execute_reply":"2022-04-21T07:12:56.184413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:56.186764Z","iopub.execute_input":"2022-04-21T07:12:56.187032Z","iopub.status.idle":"2022-04-21T07:12:56.193153Z","shell.execute_reply.started":"2022-04-21T07:12:56.186994Z","shell.execute_reply":"2022-04-21T07:12:56.192391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#config cuda device\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:56.194799Z","iopub.execute_input":"2022-04-21T07:12:56.19544Z","iopub.status.idle":"2022-04-21T07:12:56.201967Z","shell.execute_reply.started":"2022-04-21T07:12:56.195399Z","shell.execute_reply":"2022-04-21T07:12:56.200891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#folder containing essays\ntrain_essays = '/kaggle/input/feedback-prize-2021/train'\ntest_essays = '/kaggle/input/feedback-prize-2021/test'\n\n#read the training data frame\ndf = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\n\nsubmission_df = pd.read_csv('/kaggle/input/feedback-prize-2021/sample_submission.csv')\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:56.203382Z","iopub.execute_input":"2022-04-21T07:12:56.204206Z","iopub.status.idle":"2022-04-21T07:12:57.824998Z","shell.execute_reply.started":"2022-04-21T07:12:56.204159Z","shell.execute_reply":"2022-04-21T07:12:57.824191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert the discourse_start and discourse_end to int \ndf['discourse_start'] = df['discourse_start'].astype('int')\ndf['discourse_end'] = df['discourse_end'].astype('int')\n\n#View first 5 rows of the train df\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:57.82638Z","iopub.execute_input":"2022-04-21T07:12:57.826836Z","iopub.status.idle":"2022-04-21T07:12:57.847253Z","shell.execute_reply.started":"2022-04-21T07:12:57.826791Z","shell.execute_reply":"2022-04-21T07:12:57.846511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of essays in training folder: {len(os.listdir(train_essays))}\")\nprint(f\"Number of essays in test folder: {len(os.listdir(test_essays))}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:57.84839Z","iopub.execute_input":"2022-04-21T07:12:57.850744Z","iopub.status.idle":"2022-04-21T07:12:58.528866Z","shell.execute_reply.started":"2022-04-21T07:12:57.850702Z","shell.execute_reply":"2022-04-21T07:12:58.528008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n\nThe training data frame has **144,293** records while number of essays in the training folder is **15,594**. From this and also observing the first 5 rows of the data frame, it shows that an essay file (represented by id column)can have one or more entries in training data frame. Below code plots histogram for the essays.","metadata":{}},{"cell_type":"code","source":"ax = df['id'].value_counts().hist()\nax.set_ylabel('count')\nax.set_xlabel('# of times essay in dataframe')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:58.531901Z","iopub.execute_input":"2022-04-21T07:12:58.532119Z","iopub.status.idle":"2022-04-21T07:12:58.809409Z","shell.execute_reply.started":"2022-04-21T07:12:58.532092Z","shell.execute_reply":"2022-04-21T07:12:58.808627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above, essays with 4 to 14 instance appear much in the data frame.","metadata":{}},{"cell_type":"code","source":"#code plot distribution of the discourse type\nax = sns.countplot(y='discourse_type', data=df, order = df['discourse_type'].value_counts().index)\nax.set_xlabel(\"Count\")\nax.set_ylabel('')\nax.set_title('Distribution of discourse types')\n\n#list of discourse types\ndiscourse_type_list = df['discourse_type'].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:58.811004Z","iopub.execute_input":"2022-04-21T07:12:58.811299Z","iopub.status.idle":"2022-04-21T07:12:59.163681Z","shell.execute_reply.started":"2022-04-21T07:12:58.811258Z","shell.execute_reply":"2022-04-21T07:12:59.162893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pivot_table to see how many instance each essay are in discourse_type and discourse_type_num \ndf_ = pd.pivot_table(df, index=['discourse_type', 'discourse_type_num'], values=['id'], aggfunc='count')\ndf_ = df_.rename(columns= {'id': 'num_of_essays'})\ndf_.sort_values(['discourse_type', 'num_of_essays'], ascending=[True, False])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:59.164989Z","iopub.execute_input":"2022-04-21T07:12:59.165902Z","iopub.status.idle":"2022-04-21T07:12:59.236509Z","shell.execute_reply.started":"2022-04-21T07:12:59.165855Z","shell.execute_reply":"2022-04-21T07:12:59.235638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above it can be observed that, more essays are have the \"claim\" discourse type and within this group \"claim 1\" has more essays. Next we will explore the distribution of the discourse and compare how it varies by discourse type.","metadata":{}},{"cell_type":"code","source":"df['discourse_len'] = df['discourse_end'] - df['discourse_start'] \nax = df['discourse_end'].hist()\nax.set_xlabel('Length of Discourse')\nax.set_ylabel('count')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:59.240561Z","iopub.execute_input":"2022-04-21T07:12:59.240789Z","iopub.status.idle":"2022-04-21T07:12:59.484299Z","shell.execute_reply.started":"2022-04-21T07:12:59.240762Z","shell.execute_reply":"2022-04-21T07:12:59.483459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pivot_table to see how many instance each essay are in discourse_type and discourse_type_num \ndf_ = pd.pivot_table(df, index=['discourse_type'], values=['discourse_len'], aggfunc=['mean', 'median'])\ndf_.reset_index(inplace=True)\ndf_.columns = [c0 + ('' if c1.strip() == '' else '_') +c1 for c0, c1 in df_.columns]\ndf_.sort_values('mean_discourse_len', ascending=False).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:59.485631Z","iopub.execute_input":"2022-04-21T07:12:59.486279Z","iopub.status.idle":"2022-04-21T07:12:59.543513Z","shell.execute_reply.started":"2022-04-21T07:12:59.486238Z","shell.execute_reply":"2022-04-21T07:12:59.542718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the data it can be observed that the \"claim\" discourse type has the shortest discourse length even though it  has most essays. The longest discourse is in \"Evidence\" discourse type.","metadata":{}},{"cell_type":"markdown","source":"We now visualise 5 random essays from the training set.","metadata":{}},{"cell_type":"code","source":"#labels and colors to visualize the essays\ncolor_map = {\n                'Evidence': '#40E0D0',\n                'Concluding Statement': '#9FE2BF',\n                'Lead': '#6495ED',\n                'Rebuttal': '#CCCCFF',\n                'Counterclaim': '#DFFF00',\n                'Position': '#FFBF00',\n                'Claim': '#FF7F50'        \n             }\n\ndef get_essay_text(id_, folder_=train_essays):\n    \"\"\"\n    params id_ - essay id\n    returns text for this essay id\n    \"\"\"\n    \n    txt = \"\"\n    #read the essay from the text file\n    with open(os.path.join(folder_, id_ + '.txt'), 'r') as file:\n        txt = file.read()\n    return(txt)\n    \ndef visualize_essay(essay_ids_, df_):\n    \"\"\"\n    params essay_ids_ - list of essay id\n    params df_ - data frame containing meta data for the essays\n    \"\"\"\n   \n\n    ents = []\n\n    for id in essay_ids_:\n        for i, row in df_[df_['id']==id].iterrows():\n            ents.append({\n                        'start': row['discourse_start'], \n                         'end': row['discourse_end'],\n                        'label': row['discourse_type']}\n                        )\n\n        \n        doc_ = {\n                'text': get_essay_text(id, train_essays),\n                'ents': ents,\n               }\n        \n        print(f'Essay ID: {id}')\n        print('=========================================================================================')\n        options = {\"ents\": discourse_type_list, \"colors\": color_map}\n        spacy.displacy.render(doc_, style=\"ent\", options=options, manual=True, jupyter=True);\n        print('   ')\n   ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:59.545078Z","iopub.execute_input":"2022-04-21T07:12:59.545356Z","iopub.status.idle":"2022-04-21T07:12:59.555657Z","shell.execute_reply.started":"2022-04-21T07:12:59.545317Z","shell.execute_reply":"2022-04-21T07:12:59.554482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get sample essay ids to preview  \nessay_ids = df.groupby('discourse_type')['id'].sample(n=1, random_state=2).to_list()\n\nvisualize_essay(essay_ids, df)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:59.557246Z","iopub.execute_input":"2022-04-21T07:12:59.55774Z","iopub.status.idle":"2022-04-21T07:12:59.830261Z","shell.execute_reply.started":"2022-04-21T07:12:59.557702Z","shell.execute_reply":"2022-04-21T07:12:59.829507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize embeddings**\n\nThis section visualises the essays embedding by using UMAP.","metadata":{}},{"cell_type":"code","source":"# Load a large model, and disable pipeline unnecessary parts for our task\nnlp = spacy.load('en_core_web_lg', disable=[\"parser\", \"tagger\", \"ner\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:12:59.831829Z","iopub.execute_input":"2022-04-21T07:12:59.832093Z","iopub.status.idle":"2022-04-21T07:13:05.068483Z","shell.execute_reply.started":"2022-04-21T07:12:59.832055Z","shell.execute_reply":"2022-04-21T07:13:05.067635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize embedding of 1000 essays\nessay_ids =  df.groupby('discourse_type')['id'].sample(n=1000, random_state=2).to_list()\n\n\ndf_ =  df[ df['id'].isin(essay_ids)][['id', 'discourse_type']]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:13:05.070016Z","iopub.execute_input":"2022-04-21T07:13:05.070332Z","iopub.status.idle":"2022-04-21T07:13:05.123385Z","shell.execute_reply.started":"2022-04-21T07:13:05.07029Z","shell.execute_reply":"2022-04-21T07:13:05.122551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_['essay'] = df_['id'].apply(get_essay_text)\ndf_.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:13:05.124827Z","iopub.execute_input":"2022-04-21T07:13:05.125432Z","iopub.status.idle":"2022-04-21T07:13:53.484192Z","shell.execute_reply.started":"2022-04-21T07:13:05.125388Z","shell.execute_reply":"2022-04-21T07:13:53.483462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the vector for each essay\nspacy_emb = df_['essay'].apply(lambda x: nlp(x).vector)\nembeddings = np.vstack(spacy_emb)\nembeddings.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:13:53.485343Z","iopub.execute_input":"2022-04-21T07:13:53.486078Z","iopub.status.idle":"2022-04-21T07:49:54.751321Z","shell.execute_reply.started":"2022-04-21T07:13:53.486037Z","shell.execute_reply":"2022-04-21T07:49:54.750491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use UMAP to reduce the dimmensions\nmodel = umap.UMAP()\ndata = model.fit_transform(embeddings)\n\n#convert to DataFrame\ndata_ = pd.DataFrame(data, columns=['Dim_1', 'Dim_2'])\ndata_['label'] = df_['discourse_type'].to_list()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:49:54.75267Z","iopub.execute_input":"2022-04-21T07:49:54.752966Z","iopub.status.idle":"2022-04-21T07:51:36.612302Z","shell.execute_reply.started":"2022-04-21T07:49:54.752927Z","shell.execute_reply":"2022-04-21T07:51:36.611455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 10))\ngroups = data_.groupby('label')\nfor lbl, group in groups:\n    plt.scatter(group['Dim_1'], group['Dim_2'], label=lbl, c=color_map.get(lbl))\n    plt.legend()\nplt.title('Visualization of the Word Embeddings')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:51:36.613743Z","iopub.execute_input":"2022-04-21T07:51:36.614012Z","iopub.status.idle":"2022-04-21T07:51:40.070034Z","shell.execute_reply.started":"2022-04-21T07:51:36.613979Z","shell.execute_reply":"2022-04-21T07:51:40.068413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define hyper-parameters**","metadata":{}},{"cell_type":"code","source":"\nMAX_PASSAGE = 250 #approx half page\nBATCH_SIZE = 32\nNUM_EPOCHS = 15\nLEARNING_RATE = 1e-05\nMAX_GRAD_NORM = 10\nLABEL_ALL_TOKENS = False\nprint(f'Max passage : {MAX_PASSAGE}')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:51:40.07105Z","iopub.execute_input":"2022-04-21T07:51:40.071343Z","iopub.status.idle":"2022-04-21T07:51:40.077862Z","shell.execute_reply.started":"2022-04-21T07:51:40.071299Z","shell.execute_reply":"2022-04-21T07:51:40.077007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prepare Data**\n\nPrepare data for training and validation.","metadata":{}},{"cell_type":"markdown","source":"**Prepare the datasets and dataloaders**","metadata":{}},{"cell_type":"code","source":"B_TAG = 'B-'\nI_TAG = 'I-'\nO_TAG = 'O'\n\n#create list of output labels\noutput_labels  = []\n\noutput_labels.append(O_TAG)\nfor k in color_map.keys():\n    output_labels.append(B_TAG + k)\n    output_labels.append(I_TAG + k)\n\n#2 Dictionaries: one that maps individual tags to indices, and one that maps indices to their individual tags\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}\n\nprint(labels_to_ids)\nprint(ids_to_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:51:40.079308Z","iopub.execute_input":"2022-04-21T07:51:40.080279Z","iopub.status.idle":"2022-04-21T07:51:40.089958Z","shell.execute_reply.started":"2022-04-21T07:51:40.080216Z","shell.execute_reply":"2022-04-21T07:51:40.088817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(df_):\n    \"\"\"\n    creates dataframe with essay and IOB tags\n    \"\"\"\n    data = None\n    prev_id = None\n    len_essay = 0\n\n    for i, row in tqdm(df_.iterrows()):\n        id_ = row['id']\n    \n        #get essay if id_ != prev_id\n        if id_ != prev_id:\n            essay = get_essay_text(id_, train_essays)\n            len_essay = len(essay.strip().split())\n            \n        discourse_ = row['discourse_type']\n        predictionstring_ = row['predictionstring'].split()\n   \n        #initialize the Tag\n        ents_ = [ I_TAG + discourse_]* len(predictionstring_)\n    \n        #add begining tag to \n        ents_[0] = B_TAG + discourse_\n      \n        \n        assert len(ents_) == len(predictionstring_ )   \n    \n        data = pd.concat(\n                        [\n                            data, pd.DataFrame({'id': [id_],\n                                            'essay': [essay],\n                                             'len_essay' : [len_essay],\n                                            'predictionstring0': [','.join(predictionstring_)],\n                                            'ents': [','.join(ents_)],\n                                           })\n                        ]\n                        )\n    \n        prev_id = id_\n    \n    #clean-up theoutput data frame\n    data['discourse_tags'] = data.groupby(['id'])['ents'].transform(lambda x: ','.join(x))\n    data['predictionstring'] = data.groupby(['id'])['predictionstring0'].transform(lambda x: ','.join(x))\n\n    #drop the duplicate rows\n    data = data[['id', 'essay', 'len_essay', 'discourse_tags', 'predictionstring']].drop_duplicates().reset_index(drop=True)\n    \n    #add the O tag\n    labels = []\n    print('adding O tags ........')\n    for i, row in tqdm(data.iterrows()):\n        label = [O_TAG] * int(row['len_essay'])\n    \n        for BI_tag, pos in zip(row['discourse_tags'].split(','), row['predictionstring'].split(',')):\n            label[int(pos)] = BI_tag\n        labels.append(','.join(label))\n    \n    data['labels'] = labels\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:51:40.091613Z","iopub.execute_input":"2022-04-21T07:51:40.092447Z","iopub.status.idle":"2022-04-21T07:51:40.10756Z","shell.execute_reply.started":"2022-04-21T07:51:40.092407Z","shell.execute_reply":"2022-04-21T07:51:40.106763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = prepare_data(df)\n\nprint(f'Essay Length - max: {np.max(data[\"len_essay\"])}, mean: {np.mean(data[\"len_essay\"]):.2f}')\nprint(display(data.head(5)))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:51:40.109216Z","iopub.execute_input":"2022-04-21T07:51:40.109567Z","iopub.status.idle":"2022-04-21T08:06:35.191009Z","shell.execute_reply.started":"2022-04-21T07:51:40.109528Z","shell.execute_reply":"2022-04-21T08:06:35.19013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_list_into_chunks(list_, chunk_len_=250):\n    \"\"\"\n    \"\"\"\n    return [list_[i:i+chunk_len_] for i in range(0, len(list_), chunk_len_)]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:06:35.192567Z","iopub.execute_input":"2022-04-21T08:06:35.19287Z","iopub.status.idle":"2022-04-21T08:06:35.198286Z","shell.execute_reply.started":"2022-04-21T08:06:35.192831Z","shell.execute_reply":"2022-04-21T08:06:35.197501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_essay_into_chucks(df_, max_passage_=250):\n    \"\"\"\"\n    splits the IOB and essay to < 512, so that when tokenized within BERT limit \n    \"\"\"\n    data = None\n    for i, row in tqdm(df_.iterrows()):\n        id_ = row['id']\n        essay_ = row['essay']\n        labels_ = row['labels']\n        \n        essay_ = essay_.strip().split()\n        labels_ = labels_.split(\",\")\n        \n        assert len(labels_) == len(essay_)\n        \n        #split the essay and tags into chunks, so that it less 512 (Max bert )\n        passages = split_list_into_chunks(essay_, max_passage_)\n        sub_labels_ = split_list_into_chunks(labels_, max_passage_)\n        \n        #get passage length\n        passage_len = [len(passage) for passage in passages ]\n        \n        passages = [' '.join(passage) for passage in passages ]\n        sub_labels_ = [','.join(labs_) for labs_ in  sub_labels_]\n        \n        \n        df_ = pd.DataFrame({ 'essay': passages,\n                             'labels': sub_labels_,\n                             \n                          })\n        \n        df_['id'] = id_\n        \n        data = pd.concat([data, df_])\n    \n    \n    #drop the duplicate rows\n    if not data.empty:\n        data = data.drop_duplicates().reset_index(drop=True)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:06:35.19967Z","iopub.execute_input":"2022-04-21T08:06:35.200474Z","iopub.status.idle":"2022-04-21T08:06:35.213205Z","shell.execute_reply.started":"2022-04-21T08:06:35.200431Z","shell.execute_reply":"2022-04-21T08:06:35.212364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_split_df(df, frac=0.2):\n    # get random sample \n    test = df.sample(frac=frac, axis=0, random_state=1999)\n\n    # get everything but the test sample\n    train = df.drop(index=test.index).reset_index(drop=True)\n    test = test.reset_index(drop=True)\n    \n      \n    return train, test","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:06:35.2146Z","iopub.execute_input":"2022-04-21T08:06:35.21496Z","iopub.status.idle":"2022-04-21T08:06:35.223168Z","shell.execute_reply.started":"2022-04-21T08:06:35.214917Z","shell.execute_reply":"2022-04-21T08:06:35.222356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split_df(data[['id', 'essay', 'labels']])\n\nprint(f'Source data shape: {data.shape}, train_df shape: {train_df.shape}, val_df shape: {val_df.shape} ')\n#split the essay in junks\n\ntrain_df = split_essay_into_chucks(train_df, MAX_PASSAGE)\nval_df = split_essay_into_chucks(val_df, MAX_PASSAGE)\n\nprint(f'After splitting in chunks: train_df shape: {train_df.shape}, val_df shape: {val_df.shape} ')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:06:35.224538Z","iopub.execute_input":"2022-04-21T08:06:35.224969Z","iopub.status.idle":"2022-04-21T08:07:09.478987Z","shell.execute_reply.started":"2022-04-21T08:06:35.224927Z","shell.execute_reply":"2022-04-21T08:07:09.478249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_inputs(text_, max_passage_):\n  # add two for the special tokens {start, end [CLS][SEP]\n  input_tokens_ = tokenizer(\n                                  text_, \n                                  is_split_into_words=True,\n                                  padding='max_length', \n                                  truncation=True, \n                                  max_length= max_passage_ + 2\n                                )\n  \n  return input_tokens_","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:09.480493Z","iopub.execute_input":"2022-04-21T08:07:09.480787Z","iopub.status.idle":"2022-04-21T08:07:09.48769Z","shell.execute_reply.started":"2022-04-21T08:07:09.480749Z","shell.execute_reply":"2022-04-21T08:07:09.486932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define dataset\nclass passageDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len  \n    \n  \n    def __getitem__(self, index):\n        # step 1: get the sentence and word labels \n        essay_ = self.data.essay[index].strip().split()\n        discourse_tags_ = self.data.labels[index].split(\",\")\n              \n        #step 2: tokenize the passage \n        input_tokens_ = tokenize_inputs(essay_, self.max_len)\n      \n        #step 3: align tokens to labels\n        previous_word_idx = None\n        label_ids = []\n\n\n        for word_idx_ in input_tokens_.word_ids():\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n\n            if word_idx_ is None:\n                label_ids.append(-100)\n            elif word_idx_ != previous_word_idx:\n                label_ids.append(labels_to_ids[discourse_tags_[word_idx_]])\n                # For the other tokens in a word, we set the label to either the current label or -100, depending on\n                # the label_all_tokens flag.\n            else:\n                #previous word id is same to this one -- word was split by tokenizer\n                label_ids.append(-100) \n\n        \n            previous_word_idx = word_idx_\n        \n        # step 4: turn everything into PyTorch tensors\n        item_ = {key: torch.as_tensor(val) for key, val in input_tokens_.items()}\n\n        #append the labels_ids to dict    \n        item_[\"labels\"] = torch.as_tensor(label_ids)\n\n\n        return item_\n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:09.489027Z","iopub.execute_input":"2022-04-21T08:07:09.4893Z","iopub.status.idle":"2022-04-21T08:07:09.50048Z","shell.execute_reply.started":"2022-04-21T08:07:09.489265Z","shell.execute_reply":"2022-04-21T08:07:09.49963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = passageDataset(train_df, tokenizer, MAX_PASSAGE)\n\ntrain_loader = DataLoader(train_dataset,\n                              batch_size= BATCH_SIZE,\n                              shuffle=True)\n\nval_dataset = passageDataset(val_df, tokenizer, MAX_PASSAGE)\n\nval_loader = DataLoader(val_dataset,\n                        batch_size=BATCH_SIZE,\n                        shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:09.502005Z","iopub.execute_input":"2022-04-21T08:07:09.502483Z","iopub.status.idle":"2022-04-21T08:07:09.512055Z","shell.execute_reply.started":"2022-04-21T08:07:09.502445Z","shell.execute_reply":"2022-04-21T08:07:09.511205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preview 2 essays and their tags\nexamples = iter(train_loader)\nexample_data = examples.next()\n\n\nmax_preview = 1\nSPECIAL_TOK = [-100] #special token used by bert\n\nfor i, tokens, lbls in zip(range(max_preview), example_data['input_ids'], example_data['labels']):\n  \n    print(f'Passage: {tokenizer.decode(tokens)}') \n    print(f'Tokenized Passage: {[tk for tk in tokenizer.convert_ids_to_tokens(tokens)]}')\n    print(f'Passage label_ids : {[lb.item() for lb in lbls]}')\n    print(f'Passage labels : { [ids_to_labels[lb.item()] for lb in lbls if lb.item() not in SPECIAL_TOK ]}')\n    print('------------------------------------------------------------------------------------------------------------------')\n    print(f'Length of: tokens {len(tokens)}, labels with special tokens {len(lbls)}')\n    print('==================================================================================================================') \n  \n    if i > max_preview:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:09.513557Z","iopub.execute_input":"2022-04-21T08:07:09.514082Z","iopub.status.idle":"2022-04-21T08:07:09.657512Z","shell.execute_reply.started":"2022-04-21T08:07:09.514043Z","shell.execute_reply":"2022-04-21T08:07:09.655804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define Model**\n\nBERT will be used to predict each words discourse type.","metadata":{}},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(MODEL_PATH, num_labels=len(labels_to_ids))\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:09.659065Z","iopub.execute_input":"2022-04-21T08:07:09.659328Z","iopub.status.idle":"2022-04-21T08:07:23.291487Z","shell.execute_reply.started":"2022-04-21T08:07:09.659291Z","shell.execute_reply":"2022-04-21T08:07:23.29076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training the model**","metadata":{}},{"cell_type":"code","source":"#Sanity check of model:  initial loss of your model should be close to -ln(1/number of classes)\ninputs = example_data\ninput_ids = inputs[\"input_ids\"][0].unsqueeze(0)\nattention_mask = inputs[\"attention_mask\"][0].unsqueeze(0)\nlabels = inputs[\"labels\"][0].unsqueeze(0)\n\ninput_ids = input_ids.to(device)\nattention_mask = attention_mask.to(device)\nlabels = labels.to(device)\n\nprint(f'input ids shape: {input_ids.shape}, attention mask shape: {attention_mask.shape}, labels shape: {labels.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:23.292694Z","iopub.execute_input":"2022-04-21T08:07:23.292938Z","iopub.status.idle":"2022-04-21T08:07:23.301018Z","shell.execute_reply.started":"2022-04-21T08:07:23.292903Z","shell.execute_reply":"2022-04-21T08:07:23.30027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\ninitial_loss = outputs.loss\nlogits = outputs.logits\nprint(f'Initial loss: {initial_loss:.4f}, logits shape: {logits.shape}, -Log(1/num_output) = {-math.log(1/logits.shape[-1]):.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:23.30248Z","iopub.execute_input":"2022-04-21T08:07:23.302954Z","iopub.status.idle":"2022-04-21T08:07:24.029045Z","shell.execute_reply.started":"2022-04-21T08:07:23.302913Z","shell.execute_reply":"2022-04-21T08:07:24.028256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define optimizer\noptimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:24.030401Z","iopub.execute_input":"2022-04-21T08:07:24.030728Z","iopub.status.idle":"2022-04-21T08:07:24.037224Z","shell.execute_reply.started":"2022-04-21T08:07:24.030696Z","shell.execute_reply":"2022-04-21T08:07:24.036481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the training method to fine tuning the bert model\ndef train_model(model_, epoch_):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    tr_preds, tr_labels = [], []\n    # put model in training mode\n    model_.train()\n    \n    for idx, batch in enumerate(train_loader):\n        \n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        labels = batch['labels'].to(device, dtype = torch.long)\n\n        outputs = model_(input_ids=ids, attention_mask=mask, labels=labels)\n       \n        loss = outputs.loss\n        tr_logits = outputs.logits\n     \n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        \n        if idx % 1000 ==0:\n            loss_step = tr_loss/nb_tr_steps\n            #print(type(ids))\n            print(f\"Training - Epoch: {epoch_} Step: {nb_tr_steps}/{len(train_loader)} Batch #: {idx} loss: {loss_step}\")\n           \n        # compute training accuracy\n        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n        active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        tr_labels.extend(labels)\n        tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")\n    \n    return model_","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:24.03882Z","iopub.execute_input":"2022-04-21T08:07:24.039327Z","iopub.status.idle":"2022-04-21T08:07:24.054775Z","shell.execute_reply.started":"2022-04-21T08:07:24.039287Z","shell.execute_reply":"2022-04-21T08:07:24.053904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_ = model\n\nfor epoch_ in range(NUM_EPOCHS):\n    model_ = train_model(model_, epoch_)\n\n    if epoch_ % 5 == 0:\n        torch.cuda.empty_cache()\n    \nmodel = model_","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:24.060817Z","iopub.execute_input":"2022-04-21T08:07:24.061149Z","iopub.status.idle":"2022-04-21T11:09:58.257355Z","shell.execute_reply.started":"2022-04-21T08:07:24.061111Z","shell.execute_reply":"2022-04-21T11:09:58.256629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluate model**","metadata":{}},{"cell_type":"code","source":"def validate_model(model, val_loader):\n    # put model in evaluation mode\n    model.eval()\n    \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_examples, nb_eval_steps = 0, 0\n    eval_preds, eval_labels = [], []\n    \n    with torch.no_grad():\n        for idx, batch in enumerate(val_loader):\n            \n            ids = batch['input_ids'].to(device, dtype = torch.long)\n            mask = batch['attention_mask'].to(device, dtype = torch.long)\n            labels = batch['labels'].to(device, dtype = torch.long)\n            \n            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n           \n            loss = outputs.loss\n            eval_logits = outputs.logits\n            \n            eval_loss += loss.item()\n\n            nb_eval_steps += 1\n            nb_eval_examples += labels.size(0)\n        \n            if idx % 100==0:\n                loss_step = eval_loss/nb_eval_steps\n                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n              \n            # compute evaluation accuracy\n            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n            \n            # only compute accuracy at active labels\n            active_accuracy = labels.view(-1) != SPECIAL_TOK[0] # shape (batch_size, seq_len)\n        \n            labels = torch.masked_select(flattened_targets, active_accuracy)\n            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n            \n            eval_labels.extend(labels)\n            eval_preds.extend(predictions)\n            \n            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n            eval_accuracy += tmp_eval_accuracy\n\n    labels = [ids_to_labels[id.item()] for id in eval_labels]\n    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n    \n    eval_loss = eval_loss / nb_eval_steps\n    eval_accuracy = eval_accuracy / nb_eval_steps\n    print(f\"Validation Loss: {eval_loss}\")\n    print(f\"Validation Accuracy: {eval_accuracy}\")\n\n    return labels, predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:09:58.25884Z","iopub.execute_input":"2022-04-21T11:09:58.259093Z","iopub.status.idle":"2022-04-21T11:09:58.272608Z","shell.execute_reply.started":"2022-04-21T11:09:58.259058Z","shell.execute_reply":"2022-04-21T11:09:58.271803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels, predictions = validate_model(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:09:58.273856Z","iopub.execute_input":"2022-04-21T11:09:58.274527Z","iopub.status.idle":"2022-04-21T11:11:35.945833Z","shell.execute_reply.started":"2022-04-21T11:09:58.274486Z","shell.execute_reply":"2022-04-21T11:11:35.945048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test model and prepare submission file**","metadata":{}},{"cell_type":"code","source":"def prepare_passage(passage_, max_passage_=MAX_PASSAGE):\n    \"\"\"\n      tokenize essay prepares it for model input\n    \"\"\"\n \n    #step 2: tokenize the passage \n    input_tokens_ = tokenize_inputs(passage_, max_passage_)\n   \n    # step 4: turn everything into PyTorch tensors\n    item_ = {key: torch.as_tensor(val) for key, val in input_tokens_.items()}\n   \n    #add batch dimmension\n    input_ids = item_['input_ids'].unsqueeze(0)\n    att_mask = item_['attention_mask'].unsqueeze(0)\n\n    return input_ids, att_mask ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:40:39.723762Z","iopub.execute_input":"2022-04-21T11:40:39.724612Z","iopub.status.idle":"2022-04-21T11:40:39.731004Z","shell.execute_reply.started":"2022-04-21T11:40:39.724545Z","shell.execute_reply":"2022-04-21T11:40:39.730001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_prediction_word_pos(id_, predicted_labels_):\n    word_pos = []\n    pos = []\n    dis_course = []\n\n    prev_dis = None\n\n    for i, lb in enumerate(predicted_labels_):\n        #\n        if lb != O_TAG:\n            #print(lb)\n            dis_ = lb.split('-')[1]\n        \n            if prev_dis and prev_dis != dis_:\n                #change discourse\n                dis_course.append(prev_dis)\n                word_pos.append(pos)\n                pos = []\n        \n            pos.append(i)  \n            prev_dis = dis_\n\n    if prev_dis: \n        #last discourse\n        dis_course.append(prev_dis)\n        word_pos.append(pos)\n\n    data = None\n\n    for dis, w_pos in zip (dis_course, word_pos):\n        data = pd.concat(\n                    [data, \n                     pd.DataFrame([{'id': id_,\n                                    'class': dis, 'predictionstring': ','.join(str(e) for e in w_pos),\n                                    'discourse_start':w_pos[0], 'discourse_end':w_pos[-1]}])\n                    ])\n    data.reset_index(drop=True, inplace=True)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:41:06.0264Z","iopub.execute_input":"2022-04-21T11:41:06.026669Z","iopub.status.idle":"2022-04-21T11:41:06.036644Z","shell.execute_reply.started":"2022-04-21T11:41:06.026638Z","shell.execute_reply":"2022-04-21T11:41:06.035703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_passage(model_, passage_):\n    \n    input_id, att_mask = prepare_passage(passage_)    \n    \n\n    input_id = input_id.to(device, dtype = torch.long)\n    att_mask = att_mask.to(device, dtype = torch.long)\n\n    model_.eval()           \n    outputs = model_(input_ids=input_id, attention_mask=att_mask)\n\n    logits = outputs.logits\n\n    logits = logits.view(-1) # shape (batch_size * seq_len,)\n\n    logits = logits.view(-1, model_.num_labels) # shape (batch_size * seq_len, num_labels)\n   \n    preds = torch.argmax(logits, axis=1) # shape (batch_size * seq_len,)\n    \n    #mask that ignores all special tokens\n    mask = input_id != SPECIAL_TOK[0]\n    \n    #only select tokens that are NOT special tokens\n    preds = torch.masked_select(preds, mask)\n\n    predictions = [p.item() for p in preds]\n\n    #ignore \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:41:06.038614Z","iopub.execute_input":"2022-04-21T11:41:06.039536Z","iopub.status.idle":"2022-04-21T11:41:06.04811Z","shell.execute_reply.started":"2022-04-21T11:41:06.039495Z","shell.execute_reply":"2022-04-21T11:41:06.047426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_inference(essay_):\n    \n    predictions = []\n    \n    passages = split_list_into_chunks(essay_.strip().split(), MAX_PASSAGE)\n\n\n    for passage_ in passages:\n        preds_ = predict_passage(model_, passage_)\n\n        predictions.extend(preds_)\n    \n    return predictions\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:41:06.05532Z","iopub.execute_input":"2022-04-21T11:41:06.055532Z","iopub.status.idle":"2022-04-21T11:41:06.062452Z","shell.execute_reply.started":"2022-04-21T11:41:06.055507Z","shell.execute_reply":"2022-04-21T11:41:06.061699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = None\n\nfor i, row in submission_df.iterrows():\n    id_ = row['id']\n    essay = get_essay_text(id_, test_essays)\n\n    #make predictions\n    predictions = run_inference(essay) \n\n    preds = [ids_to_labels[id] for id in predictions]\n\n    #put predictions in data frame\n    pds = get_prediction_word_pos(id_, preds)\n\n    df_test = pd.concat([df_test, pds])\n\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:41:06.064063Z","iopub.execute_input":"2022-04-21T11:41:06.064653Z","iopub.status.idle":"2022-04-21T11:41:06.540639Z","shell.execute_reply.started":"2022-04-21T11:41:06.064616Z","shell.execute_reply":"2022-04-21T11:41:06.539888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prepare submission file\ndf_test[['id', 'class', 'predictionstring']].to_csv(os.path.join('submission.csv'), index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:41:18.136197Z","iopub.execute_input":"2022-04-21T11:41:18.136466Z","iopub.status.idle":"2022-04-21T11:41:18.143946Z","shell.execute_reply.started":"2022-04-21T11:41:18.136435Z","shell.execute_reply":"2022-04-21T11:41:18.143031Z"},"trusted":true},"execution_count":null,"outputs":[]}]}