{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Name Entity Recognition with Keras\nIn this notebook, I will build a Name Entity Recognition Model using Keras to evaluate student writing using dataset for Kaggle Competition [Feedback Prize - Evaluating Student Writing](https://www.kaggle.com/c/feedback-prize-2021). In this Project, Modeling part will be very easy, what's challenging is converting this dataset to Name Entity Recognization format that can be handled by Keras Name Entity Recognition Model. I also perform some Exploratory Data Analysis to find insights.\n## Import Packages","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport numpy as np\nimport time\nimport tensorflow as tf\nimport seaborn as sns\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:45:38.148853Z","iopub.execute_input":"2021-12-18T16:45:38.149165Z","iopub.status.idle":"2021-12-18T16:45:43.179071Z","shell.execute_reply.started":"2021-12-18T16:45:38.149076Z","shell.execute_reply":"2021-12-18T16:45:43.178155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Common Parameters","metadata":{}},{"cell_type":"code","source":"vocab_size = 10000 # Vocabulary size\nsequence_length = 1024 # Sequence Length\nbatch_size = 128 # Batch size\nunk_token = \"<unk>\" # Unknownd token\nvectorizer_path = \"vectorizer.json\"\n# Use output dataset for inference\noutput_dataset_path = \"../input/name-entity-recognition-with-keras-output/\"\nmodel_path = \"model.h5\"\nembed_size = 64\nhidden_size = 64\nmodes = [\"training\", \"inference\"] # There is training and inference mode\nmode = modes[1]\nepochs = 10\ndropout = 0.2 # Dropout rate for the Model.","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:03.415Z","iopub.execute_input":"2021-12-18T16:46:03.41526Z","iopub.status.idle":"2021-12-18T16:46:03.420805Z","shell.execute_reply.started":"2021-12-18T16:46:03.415231Z","shell.execute_reply":"2021-12-18T16:46:03.419811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:06.001733Z","iopub.execute_input":"2021-12-18T16:46:06.001993Z","iopub.status.idle":"2021-12-18T16:46:07.72865Z","shell.execute_reply.started":"2021-12-18T16:46:06.001963Z","shell.execute_reply":"2021-12-18T16:46:07.727925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/feedback-prize-2021/sample_submission.csv\")\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:15.529797Z","iopub.execute_input":"2021-12-18T16:46:15.530052Z","iopub.status.idle":"2021-12-18T16:46:15.54971Z","shell.execute_reply.started":"2021-12-18T16:46:15.530022Z","shell.execute_reply":"2021-12-18T16:46:15.549057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA & Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Add File Path to train and submission Files","metadata":{}},{"cell_type":"code","source":"train[\"file_path\"] = train[\"id\"].apply(lambda item: \"../input/feedback-prize-2021/train/\" + item + \".txt\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:18.20948Z","iopub.execute_input":"2021-12-18T16:46:18.209739Z","iopub.status.idle":"2021-12-18T16:46:18.287597Z","shell.execute_reply.started":"2021-12-18T16:46:18.209712Z","shell.execute_reply":"2021-12-18T16:46:18.286848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"file_path\"] = submission[\"id\"].apply(lambda item: \"../input/feedback-prize-2021/test/\" + item + \".txt\")\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:21.344619Z","iopub.execute_input":"2021-12-18T16:46:21.344867Z","iopub.status.idle":"2021-12-18T16:46:21.356783Z","shell.execute_reply.started":"2021-12-18T16:46:21.344839Z","shell.execute_reply":"2021-12-18T16:46:21.355949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Labels","metadata":{}},{"cell_type":"code","source":"train[\"discourse_type\"].value_counts().plot(kind=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:24.027771Z","iopub.execute_input":"2021-12-18T16:46:24.028475Z","iopub.status.idle":"2021-12-18T16:46:24.285443Z","shell.execute_reply.started":"2021-12-18T16:46:24.028432Z","shell.execute_reply":"2021-12-18T16:46:24.284757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discourse_types = np.array([\"<PAD>\", \"<None>\"] + sorted(train[\"discourse_type\"].unique()))\ndiscourse_types_index = dict([(discoure_type, index) for (index, discoure_type) in enumerate(discourse_types)])\ndiscourse_types, discourse_types_index","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:27.080173Z","iopub.execute_input":"2021-12-18T16:46:27.080777Z","iopub.status.idle":"2021-12-18T16:46:27.102239Z","shell.execute_reply.started":"2021-12-18T16:46:27.080734Z","shell.execute_reply":"2021-12-18T16:46:27.101514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of discourse_type_num","metadata":{}},{"cell_type":"code","source":"train[\"discourse_type_num\"].value_counts().plot(kind=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:32.12678Z","iopub.execute_input":"2021-12-18T16:46:32.127022Z","iopub.status.idle":"2021-12-18T16:46:32.716718Z","shell.execute_reply.started":"2021-12-18T16:46:32.126993Z","shell.execute_reply":"2021-12-18T16:46:32.716049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Unique files","metadata":{}},{"cell_type":"code","source":"len(train[\"id\"].unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:35.672248Z","iopub.execute_input":"2021-12-18T16:46:35.672793Z","iopub.status.idle":"2021-12-18T16:46:35.691017Z","shell.execute_reply.started":"2021-12-18T16:46:35.672757Z","shell.execute_reply":"2021-12-18T16:46:35.690105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenization\n\nI am trying to build a Tokenizer to tokenize sentences that extracted from predictionstring and see if it can match with the discourse_text including shifting left and right. A good Tokenizer can match more cases without shifting sentences or just a few shifting, so that it may have a better prediction on test set.","metadata":{}},{"cell_type":"code","source":"def get_range(item):\n    locations = [int(location) for location in item[\"predictionstring\"].split(\" \")]\n    return (locations[0], locations[-1])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:40.18664Z","iopub.execute_input":"2021-12-18T16:46:40.186895Z","iopub.status.idle":"2021-12-18T16:46:40.191131Z","shell.execute_reply.started":"2021-12-18T16:46:40.186868Z","shell.execute_reply":"2021-12-18T16:46:40.190454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"character_counter = defaultdict(int)\ncharacter_counter\nallow_set = set(\"'&%-_/$+ÂÃÅËÓâåóþ@|~¢£¢£\")\ndef tokenize(text):\n    tokens = []\n    chars = []\n    for i in range(len(text)):\n        c = text[i].lower()\n        character_counter[c] += 1\n        is_valid = c.isalnum() or c in allow_set\n        if i >= 1 and i < len(text) - 1:\n            if text[i-1].isdigit() and text[i+1].isdigit():\n                is_valid = True\n            elif text[i-1].isalpha() and text[i+1].isalpha() and c == \".\":\n                is_valid = True\n        if is_valid:\n            chars.append(c)\n        if (not is_valid or i == len(text) - 1) and len(chars) > 0:\n            tokens.append(\"\".join(chars))\n            chars.clear()\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:43.232683Z","iopub.execute_input":"2021-12-18T16:46:43.233549Z","iopub.status.idle":"2021-12-18T16:46:43.242156Z","shell.execute_reply.started":"2021-12-18T16:46:43.233479Z","shell.execute_reply":"2021-12-18T16:46:43.241505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nbegin = time.time()\nlast_id = \"\"\ncontents = []\nwrong_samples = []\ntoken_list = []\nannotation_list = []\nnum_samples = len(train)\nunmaptch_count = 0 # Number of sentences extracted from predictionstring that doesn't discourse_text\nmatch_count = 0 # Number of sentences extracted from predictionstring that matches discourse_text including shifting\ncompletely_match_count = 0 # Number of sentences extracted from predictionstring that matches discourse_text without shifting\nmismatch_count = 0\nfor i in range(len(train)):\n    item = train.iloc[i]\n    identifier = item[\"id\"] \n    discourse_type_id = discourse_types_index[item[\"discourse_type\"]]\n    if identifier != last_id:\n        last_id = identifier\n        with open(item[\"file_path\"]) as f:\n            content = \"\".join(f.readlines())\n            contents.append(content)\n            tokens = tokenize(content)\n            token_list.append(tokens)\n            annotations = [1] * len(tokens)\n            annotation_list.append(annotations)\n    annotation_range = get_range(item)\n    extracted = tokens[annotation_range[0]:annotation_range[1]+1]\n    discourse = tokenize(item[\"discourse_text\"])\n    delta = None\n    num_tokens_to_compare = min(len(discourse), 3)\n    \n    # Compare text extracted from predictionstring with discourse_text, shift discourse_text or right if needed, just compare a few words for performance\n    for j in range(10):\n        if len(extracted) < num_tokens_to_compare or len(discourse) <= j + num_tokens_to_compare:\n            break\n        if extracted[0:num_tokens_to_compare] == discourse[j:num_tokens_to_compare+j]:\n            delta = j\n            break\n    if delta == None:\n        for j in range(10):\n            if len(discourse) < num_tokens_to_compare and len(extracted) <= j + num_tokens_to_compare:\n                break\n            if discourse[0:num_tokens_to_compare] == extracted[j:num_tokens_to_compare+j]:\n                delta = -j\n                break\n    if delta == None:\n        unmaptch_count += 1\n    else:\n        not_match = False\n        for j in range(annotation_range[0] - delta, min(min(annotation_range[1] - delta + 1, len(tokens)), len(discourse) + annotation_range[0] - delta)): \n            if tokens[j] != discourse[j - annotation_range[0] + delta]:\n                mismatch_count += 1\n                not_match = True\n                break\n        if not not_match:\n            for j in range(annotation_range[0] - delta, min(min(annotation_range[1] - delta + 1, len(tokens)), len(discourse) + annotation_range[0] - delta)): \n                annotation_list[-1][j] = discourse_type_id\n            match_count += 1\n        else:\n            unmaptch_count += 1\n        if delta == 0:\n            completely_match_count += 1 \nprint(\"Unmatch count:%d Match Count: %d Completedly Match count: %d\"%(unmaptch_count, match_count, completely_match_count))\nprint(\"Mismatch count:\", mismatch_count)\nprint(token_list[0])\nprint(annotation_list[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:46:50.458991Z","iopub.execute_input":"2021-12-18T16:46:50.459286Z","iopub.status.idle":"2021-12-18T16:49:41.488838Z","shell.execute_reply.started":"2021-12-18T16:46:50.459252Z","shell.execute_reply":"2021-12-18T16:49:41.488093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filter samples without annotations","metadata":{}},{"cell_type":"code","source":"useful_tokens = []\nuseful_annotations = []\nfor i in range(len(annotation_list)):\n    if np.sum(annotation_list[i]) != 0:\n        useful_tokens.append(token_list[i])\n        useful_annotations.append(annotation_list[i])\ntoken_list = useful_tokens\nannotation_list = useful_annotations","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:41.490262Z","iopub.execute_input":"2021-12-18T16:49:41.491017Z","iopub.status.idle":"2021-12-18T16:49:42.86106Z","shell.execute_reply.started":"2021-12-18T16:49:41.490978Z","shell.execute_reply":"2021-12-18T16:49:42.860254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of Word Counts","metadata":{}},{"cell_type":"code","source":"word_counter = defaultdict(int)\nfor tokens in token_list:\n    for token in tokens:\n        word_counter[token] += 1","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:42.863363Z","iopub.execute_input":"2021-12-18T16:49:42.863914Z","iopub.status.idle":"2021-12-18T16:49:45.111342Z","shell.execute_reply.started":"2021-12-18T16:49:42.863876Z","shell.execute_reply":"2021-12-18T16:49:45.110613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count = pd.DataFrame({\"key\": word_counter.keys(), \"count\": word_counter.values()})\n\nsns.barplot(x=\"key\", y=\"count\", data=word_count[:30])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:45.113288Z","iopub.execute_input":"2021-12-18T16:49:45.113576Z","iopub.status.idle":"2021-12-18T16:49:45.159941Z","shell.execute_reply.started":"2021-12-18T16:49:45.113541Z","shell.execute_reply":"2021-12-18T16:49:45.159278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:45.182918Z","iopub.execute_input":"2021-12-18T16:49:45.183232Z","iopub.status.idle":"2021-12-18T16:49:45.199621Z","shell.execute_reply.started":"2021-12-18T16:49:45.183195Z","shell.execute_reply":"2021-12-18T16:49:45.198976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of words","metadata":{}},{"cell_type":"code","source":"len(word_count)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:45.200733Z","iopub.execute_input":"2021-12-18T16:49:45.201125Z","iopub.status.idle":"2021-12-18T16:49:45.206271Z","shell.execute_reply.started":"2021-12-18T16:49:45.201089Z","shell.execute_reply":"2021-12-18T16:49:45.205516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Words appearing only once","metadata":{}},{"cell_type":"code","source":"(word_count[\"count\"] == 1).sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:45.207941Z","iopub.execute_input":"2021-12-18T16:49:45.208491Z","iopub.status.idle":"2021-12-18T16:49:45.215869Z","shell.execute_reply.started":"2021-12-18T16:49:45.208456Z","shell.execute_reply":"2021-12-18T16:49:45.215029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distibution of Character Counts","metadata":{}},{"cell_type":"code","source":"character_count = pd.DataFrame({\"key\": character_counter.keys(), \"count\": character_counter.values()})\ncharacter_count.sort_values(by=\"count\", ascending=False, inplace=True)\ncharacter_count.head(30)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:45.217583Z","iopub.execute_input":"2021-12-18T16:49:45.217997Z","iopub.status.idle":"2021-12-18T16:49:45.231269Z","shell.execute_reply.started":"2021-12-18T16:49:45.21796Z","shell.execute_reply":"2021-12-18T16:49:45.230361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=\"key\", y=\"count\", data=character_count[:30])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:49:45.233606Z","iopub.execute_input":"2021-12-18T16:49:45.233899Z","iopub.status.idle":"2021-12-18T16:49:45.61088Z","shell.execute_reply.started":"2021-12-18T16:49:45.233864Z","shell.execute_reply":"2021-12-18T16:49:45.610172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unique Characters","metadata":{}},{"cell_type":"code","source":"print(list(character_count['key'].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:50:11.761881Z","iopub.execute_input":"2021-12-18T16:50:11.76263Z","iopub.status.idle":"2021-12-18T16:50:11.768191Z","shell.execute_reply.started":"2021-12-18T16:50:11.76258Z","shell.execute_reply":"2021-12-18T16:50:11.76721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ditrubtion of Sentence Length","metadata":{}},{"cell_type":"code","source":"sentence_length = defaultdict(int)\nfor tokens in token_list:\n    length = len(tokens)\n    sentence_length[length] += 1\nsentence_length = pd.DataFrame({\"sentence_length\": sentence_length.keys(), \"count\": sentence_length.values()})\nsentence_length.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:50:20.303199Z","iopub.execute_input":"2021-12-18T16:50:20.303791Z","iopub.status.idle":"2021-12-18T16:50:20.321503Z","shell.execute_reply.started":"2021-12-18T16:50:20.303755Z","shell.execute_reply":"2021-12-18T16:50:20.320555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_length.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:50:23.131945Z","iopub.execute_input":"2021-12-18T16:50:23.132625Z","iopub.status.idle":"2021-12-18T16:50:23.150942Z","shell.execute_reply.started":"2021-12-18T16:50:23.132588Z","shell.execute_reply":"2021-12-18T16:50:23.150122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of sentences that has more than 1000 tokens","metadata":{}},{"cell_type":"code","source":"sentence_length[(sentence_length[\"sentence_length\"] >= 1000)][\"count\"].sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:50:25.80684Z","iopub.execute_input":"2021-12-18T16:50:25.807128Z","iopub.status.idle":"2021-12-18T16:50:25.814704Z","shell.execute_reply.started":"2021-12-18T16:50:25.807097Z","shell.execute_reply":"2021-12-18T16:50:25.813919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Vectorization","metadata":{}},{"cell_type":"code","source":"class Vectorizer:\n    \n    def __init__(self, vocab_size = None, sequence_length = None, unk_token = \"<unk>\"):\n        self.vocab_size = vocab_size\n        self.sequence_length = sequence_length\n        self.unk_token = unk_token\n        \n    def fit_transform(self, sentences):\n        word_counter = dict()\n        for tokens in sentences:\n            for token in tokens: \n                if token in word_counter:\n                    word_counter[token] += 1\n                else:\n                    word_counter[token] = 1\n        word_counter = pd.DataFrame({\"key\": word_counter.keys(), \"count\": word_counter.values()})\n        word_counter.sort_values(by=\"count\", ascending=False, inplace=True)\n        vocab = set(word_counter[\"key\"][0:self.vocab_size-1])\n        word_index = dict()\n        begin_index = 1 \n        word_index[self.unk_token] = begin_index\n        begin_index += 1\n        Xs = []\n        for i in range(len(sentences)):\n            X = []\n            for token in sentences[i]:\n                if token not in word_index and token in vocab:\n                    word_index[token] = begin_index\n                    begin_index += 1\n                if token in word_index:\n                    X.append(word_index[token])\n                else:\n                    X.append(word_index[self.unk_token])\n                if len(X) == self.sequence_length:\n                    break\n            if len(X) < self.sequence_length:\n                X += [0] * (self.sequence_length - len(X))\n            Xs.append(X)\n        self.word_index = word_index\n        self.vocab = vocab\n        return Xs\n    \n    def transform(self, sentences):\n        Xs = []\n        for i in range(len(sentences)):\n            X = []\n            for token in sentences[i]:\n                if token in self.word_index:\n                    X.append(self.word_index[token])\n                else:\n                    X.append(self.word_index[self.unk_token])\n                if len(X) == self.sequence_length:\n                    break\n            if len(X) < self.sequence_length:\n                X += [0] * (self.sequence_length - len(X))\n            Xs.append(X)\n        return Xs\n    \n    def load(self, path):\n        with open(path, 'r') as f:\n            dic = json.load(f)\n            self.vocab_size = dic['vocab_size']\n            self.sequence_length = dic['sequence_length']\n            self.unk_token = dic['unk_token']\n            self.word_index = dic['word_index']\n            \n    def save(self, path):\n        with open(path, 'w') as f:\n            data = json.dumps({\n                \"vocab_size\": self.vocab_size, \n                \"sequence_length\": self.sequence_length, \n                \"unk_token\": self.unk_token,\n                \"word_index\": self.word_index\n            })\n            f.write(data)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:50:27.761716Z","iopub.execute_input":"2021-12-18T16:50:27.762702Z","iopub.status.idle":"2021-12-18T16:50:27.78563Z","shell.execute_reply.started":"2021-12-18T16:50:27.762654Z","shell.execute_reply":"2021-12-18T16:50:27.784719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nvectorizer = Vectorizer(vocab_size = vocab_size, sequence_length = sequence_length, unk_token = unk_token)\nif mode == modes[0]:\n    Xs = vectorizer.fit_transform(token_list)\n    vectorizer.save(vectorizer_path)\n\nelse:\n    vectorizer.load(output_dataset_path + vectorizer_path)\n    Xs = vectorizer.transform(token_list)\nys = []\nannotation_count = [0] * len(discourse_types_index)\nfor annotation in annotation_list:\n    if len(annotation) <= sequence_length:\n        ys.append(annotation + [0] * (sequence_length - len(annotation)))\n    else:\n        ys.append(annotation[0:sequence_length])\n    for item in ys[-1]:\n        annotation_count[item] += 1\nX_train, X_val, y_train, y_val = train_test_split(np.array(Xs), np.array(ys), test_size = 0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:58:17.087544Z","iopub.execute_input":"2021-12-18T16:58:17.087794Z","iopub.status.idle":"2021-12-18T16:58:25.188153Z","shell.execute_reply.started":"2021-12-18T16:58:17.087767Z","shell.execute_reply":"2021-12-18T16:58:25.1874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Disturbution of annotation","metadata":{}},{"cell_type":"code","source":"annotation_count_df = pd.DataFrame({\n    \"key\":discourse_types,\n    \"value\": list(range(len(discourse_types))),\n    \"count\": annotation_count\n})\nplt.figure(figsize=(15, 10))\nsns.barplot(x=\"key\", y=\"count\", data=annotation_count_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:59:39.05193Z","iopub.execute_input":"2021-12-18T16:59:39.052232Z","iopub.status.idle":"2021-12-18T16:59:39.313952Z","shell.execute_reply.started":"2021-12-18T16:59:39.0522Z","shell.execute_reply":"2021-12-18T16:59:39.313262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Tensorflow Dataset","metadata":{}},{"cell_type":"code","source":"def make_dataset(X, y, batch_size, mode=\"train\"):\n    ds = tf.data.Dataset.from_tensor_slices((X, y))\n    if mode == \"train\":\n        ds = ds.shuffle(512)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-18T17:01:07.862028Z","iopub.execute_input":"2021-12-18T17:01:07.862452Z","iopub.status.idle":"2021-12-18T17:01:07.871082Z","shell.execute_reply.started":"2021-12-18T17:01:07.862418Z","shell.execute_reply":"2021-12-18T17:01:07.870202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = make_dataset(X_train, y_train, batch_size)\nval_ds = make_dataset(X_val, y_val, batch_size, mode=\"valid\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T17:01:09.871919Z","iopub.execute_input":"2021-12-18T17:01:09.872175Z","iopub.status.idle":"2021-12-18T17:01:10.085456Z","shell.execute_reply.started":"2021-12-18T17:01:09.872147Z","shell.execute_reply":"2021-12-18T17:01:10.084722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"markdown","source":"### Name Entity Recognition  Model","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.Embedding(vocab_size, embed_size, input_length=sequence_length),\n    keras.layers.SpatialDropout1D(dropout),\n    keras.layers.Bidirectional(keras.layers.LSTM(hidden_size, dropout=dropout, recurrent_dropout=dropout)),\n    keras.layers.RepeatVector(sequence_length),\n    keras.layers.Bidirectional(keras.layers.LSTM(hidden_size, return_sequences=True)),\n    keras.layers.TimeDistributed(keras.layers.Dense(len(discourse_types), activation=\"softmax\"))\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T17:01:27.139384Z","iopub.execute_input":"2021-12-18T17:01:27.140021Z","iopub.status.idle":"2021-12-18T17:01:29.296518Z","shell.execute_reply.started":"2021-12-18T17:01:27.139986Z","shell.execute_reply":"2021-12-18T17:01:29.295799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model, show_shapes=True, show_dtype=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T17:01:35.07535Z","iopub.execute_input":"2021-12-18T17:01:35.075886Z","iopub.status.idle":"2021-12-18T17:01:35.854113Z","shell.execute_reply.started":"2021-12-18T17:01:35.07585Z","shell.execute_reply":"2021-12-18T17:01:35.853207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"if mode == modes[0]:\n    checkpoint = keras.callbacks.ModelCheckpoint(\n        model_path, \n        save_best_only=True,\n        save_weights_only=True\n    )\n    early_stop = keras.callbacks.EarlyStopping(\n        min_delta=1e-4, \n        patience=10\n    )\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n        factor=0.3,\n        patience=2, \n        min_lr=1e-7\n    )\n    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n    callbacks = [early_stop, checkpoint, reduce_lr]\n    optimizer = tf.keras.optimizers.Adam(1e-3)\n    model.compile(loss=loss, optimizer=optimizer)\n    model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)\nelse:\n    model.load_weights(output_dataset_path + model_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T17:06:26.361028Z","iopub.execute_input":"2021-12-18T17:06:26.361326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report\ndef evaluate(model, dataset):\n    all_true_tag_ids, all_predicted_tag_ids = [], []\n    for x, y in dataset:\n        output = model.predict(x)\n        predictions = np.argmax(output, axis=-1)\n        predictions = np.reshape(predictions, [-1])\n\n        true_tag_ids = np.reshape(y, [-1])\n\n        mask = (true_tag_ids > 0) & (predictions > 0)\n        true_tag_ids = true_tag_ids[mask]\n        predicted_tag_ids = predictions[mask]\n\n        all_true_tag_ids.append(true_tag_ids)\n        all_predicted_tag_ids.append(predicted_tag_ids)\n\n    all_true_tag_ids = np.concatenate(all_true_tag_ids)\n    all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n    cls_report = classification_report(all_true_tag_ids, all_predicted_tag_ids)\n    print(cls_report)\n    f1 =  f1_score(all_true_tag_ids, all_predicted_tag_ids, average=\"micro\")\n    print(\"F1 Score:\", f1)\nevaluate(model, val_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"%%time\ncontents = []\ntoken_list = []\nfor i in range(len(submission)):\n    item = submission.iloc[i]\n    identifier = item[\"id\"] \n    with open(item[\"file_path\"]) as f:\n        content = \"\".join(f.readlines())\n        contents.append(content)\n        tokens = tokenize(content)\n        token_list.append(tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = vectorizer.transform(token_list)\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test)).batch(batch_size)\ny_pred = model.predict(test_ds)\ny_pred = np.argmax(y_pred, axis=-1)\nprint(y_pred.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictionstrings = []\nclasses = []\nids = []\nfor i in range(y_pred.shape[0]):\n    identifier = submission.iloc[i][\"id\"]\n    last_prediction = 0\n    indices = []\n    upper_bound = min(y_pred.shape[1], len(token_list[i]))\n    for j in range(upper_bound):\n        if last_prediction != y_pred[i, j]:\n            if len(indices) > 0:\n                ids.append(identifier)\n                predictionstrings.append(\" \".join(indices))\n                classes.append(discourse_types[last_prediction])\n                indices = []\n            last_prediction = y_pred[i, j]\n        if y_pred[i, j] > 1:\n            indices.append(str(j))\n        if j == upper_bound - 1:\n            if len(indices) > 0:\n                ids.append(identifier)\n                predictionstrings.append(\" \".join(indices))\n                classes.append(discourse_types[last_prediction])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame({\"id\": ids, \"class\": classes, \"predictionstring\": predictionstrings})\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}