{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\nwarnings.filterwarnings(\"ignore\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-28T12:38:58.999094Z","iopub.execute_input":"2021-12-28T12:38:58.999721Z","iopub.status.idle":"2021-12-28T12:39:08.5966Z","shell.execute_reply.started":"2021-12-28T12:38:58.999685Z","shell.execute_reply":"2021-12-28T12:39:08.595572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Notebook explaining how to train with minimal code using datasets and Trainer API \n\n* Loads datafrom dataframe to Datasets\n* Uses the BigBird using with 1024 tokens\n* Trainer API with fp16 enabled so as to optimize the training processes.\n* \n\n### Improvements\n* change the hyperparameter-tunning of the Trainer \n* Improving post processing of labels as mentioned here https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615\n\n## Do Upvote if you find it usefull, It keeps me motivated to do more quality work, Thanks!\n\n\n### load data and convert text into dataframe, then convert predictionstring to NER IOB format look at this [notebook](http://https://www.kaggle.com/raghavendrakotala/pre-processed-data-for-ner-modeling) to prepare data ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\n\ntrain_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:39:08.602224Z","iopub.execute_input":"2021-12-28T12:39:08.604413Z","iopub.status.idle":"2021-12-28T12:39:10.501316Z","shell.execute_reply.started":"2021-12-28T12:39:08.604366Z","shell.execute_reply":"2021-12-28T12:39:10.500408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    test_names.append(f.replace('.txt', ''))\n    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n# test_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntest_texts.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:39:10.502832Z","iopub.execute_input":"2021-12-28T12:39:10.503249Z","iopub.status.idle":"2021-12-28T12:39:10.545304Z","shell.execute_reply.started":"2021-12-28T12:39:10.503186Z","shell.execute_reply":"2021-12-28T12:39:10.544327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_names, train_texts = [], []\n# for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))[:100]):\n#     test_names.append(f.replace('.txt', ''))\n#     train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n# train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n# # train_texts['text'] = test_texts['text'].apply(lambda x:x.split())\n# train_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:39:10.547785Z","iopub.execute_input":"2021-12-28T12:39:10.548101Z","iopub.status.idle":"2021-12-28T12:39:10.552973Z","shell.execute_reply.started":"2021-12-28T12:39:10.54806Z","shell.execute_reply":"2021-12-28T12:39:10.551587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_entities = []\n# for i in tqdm(train_text_df.iterrows()):\n#     total = i[1]['text'].split().__len__()\n# #     entities = []\n#     entities = [\"O\" for i in range(total)]\n#     for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n#         discourse = j[1]['discourse_type']\n#         list_ix = j[1]['predictionstring'].split()\n#         for li in list_ix[1:]:\n# #             print(li, entities)\n#             entities[int(li)] = f\"I-{discourse}\"\n#         entities[int(list_ix[0])] = f\"B-{discourse}\"\n#     all_entities.append(entities)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:39:10.55448Z","iopub.execute_input":"2021-12-28T12:39:10.554924Z","iopub.status.idle":"2021-12-28T12:39:10.565182Z","shell.execute_reply.started":"2021-12-28T12:39:10.554876Z","shell.execute_reply":"2021-12-28T12:39:10.564139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df = pd.read_csv(\"/kaggle/input/feedback-prize-ner-tagged-data/feedback_prize_ner_tagged_data.csv\")\ntrain_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:39:10.566578Z","iopub.execute_input":"2021-12-28T12:39:10.567379Z","iopub.status.idle":"2021-12-28T12:39:12.696165Z","shell.execute_reply.started":"2021-12-28T12:39:10.567333Z","shell.execute_reply":"2021-12-28T12:39:12.695172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\ntrain_text_df['entities'] = train_text_df['entities'].apply(lambda x:ast.literal_eval(x))\n\nprint(train_text_df['entities'].values[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:39:12.698097Z","iopub.execute_input":"2021-12-28T12:39:12.698705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df = train_text_df[:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define config and Load model, tokenizer","metadata":{}},{"cell_type":"code","source":"import datasets\nfrom transformers import Trainer, TrainingArguments, DataCollatorWithPadding\nfrom transformers import BigBirdForTokenClassification, BigBirdTokenizerFast\nfrom torch import cuda\nimport torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {'model_name': '/kaggle/input/huggingfacebigbirdrobertabase/',\n         'max_length': 1024,\n         'train_batch_size':4,\n         'valid_batch_size':8,\n         'epochs':5,\n         'learning_rate':5e-05,\n         'max_grad_norm':10,\n          'warmup':0.1,\n          \"grad_acc\":8,\n          \"model_save_path\":\"big-bird\",\n         'device': 'cuda' if cuda.is_available() else 'cpu'}\n\noutput_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df['labels'] = train_text_df['entities'].apply(lambda x: [labels_to_ids[i] for i in x])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BigBirdTokenizerFast.from_pretrained(config['model_name'])\nmodel = BigBirdForTokenClassification.from_pretrained(config['model_name'],\n                                                     num_labels=len(output_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test to make sure is_split_into_words, return_offsets parameters are working properly","metadata":{}},{"cell_type":"code","source":"converted = tokenizer(train_text_df.loc[0].values[1].split(),\n                      is_split_into_words=True, return_offsets_mapping=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:29.470784Z","iopub.execute_input":"2021-12-28T12:34:29.471109Z","iopub.status.idle":"2021-12-28T12:34:29.483982Z","shell.execute_reply.started":"2021-12-28T12:34:29.471066Z","shell.execute_reply":"2021-12-28T12:34:29.482962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ix = 0\nfor i,j in zip(tokenizer.convert_ids_to_tokens(converted['input_ids']), converted['offset_mapping']):\n    print(i, j)\n    ix += 1\n    if ix == 15:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:31.880784Z","iopub.execute_input":"2021-12-28T12:34:31.881986Z","iopub.status.idle":"2021-12-28T12:34:31.895595Z","shell.execute_reply.started":"2021-12-28T12:34:31.881938Z","shell.execute_reply":"2021-12-28T12:34:31.894395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize the data\n\n* Load data into huggingface datasets.\n* Make sure you take care of sub-word tokenizing problem when adding labels to tokenized data.\n* use .map to map tokenizer_data function to data\n* Look at one sample to see whether mapping is done correctly or not\n","metadata":{}},{"cell_type":"code","source":"def tokenizer_data(example):\n    encoding = tokenizer(example['text'].split(),\n                         is_split_into_words=True,\n                         truncation=True,\n                         padding='max_length', \n                         return_offsets_mapping=True,\n                         max_length=config['max_length'])\n    i = 0\n    labels = example['labels']\n    encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n    for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n        if mapping[0] == 0 and mapping[1] != 0:\n            try:\n                encoded_labels[idx] = labels[i]\n            except:\n                pass\n            i += 1\n    item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n    item['labels'] = torch.as_tensor(encoded_labels)\n    return item\n","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:32.575994Z","iopub.execute_input":"2021-12-28T12:34:32.576299Z","iopub.status.idle":"2021-12-28T12:34:32.586083Z","shell.execute_reply.started":"2021-12-28T12:34:32.576241Z","shell.execute_reply":"2021-12-28T12:34:32.585019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.Dataset.from_pandas(train_text_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:32.984595Z","iopub.execute_input":"2021-12-28T12:34:32.98523Z","iopub.status.idle":"2021-12-28T12:34:33.019214Z","shell.execute_reply.started":"2021-12-28T12:34:32.985195Z","shell.execute_reply":"2021-12-28T12:34:33.018132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:33.318988Z","iopub.execute_input":"2021-12-28T12:34:33.320102Z","iopub.status.idle":"2021-12-28T12:34:33.35805Z","shell.execute_reply.started":"2021-12-28T12:34:33.320056Z","shell.execute_reply":"2021-12-28T12:34:33.35717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = dataset['train'][1]\n\n# print(text['text'], text['entities'], text['labels'])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:33.65493Z","iopub.execute_input":"2021-12-28T12:34:33.655179Z","iopub.status.idle":"2021-12-28T12:34:33.660479Z","shell.execute_reply.started":"2021-12-28T12:34:33.655149Z","shell.execute_reply":"2021-12-28T12:34:33.659369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted = tokenizer_data(text)\n\nconverted","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:34.240338Z","iopub.execute_input":"2021-12-28T12:34:34.24093Z","iopub.status.idle":"2021-12-28T12:34:34.272133Z","shell.execute_reply.started":"2021-12-28T12:34:34.240897Z","shell.execute_reply":"2021-12-28T12:34:34.271209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted\n\ni=0\nfor token, label in zip(tokenizer.convert_ids_to_tokens(converted[\"input_ids\"]), \n                        converted[\"labels\"]):\n    print(token, label, converted['offset_mapping'][i])\n    i+=1\n    if i == 15:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:34.597455Z","iopub.execute_input":"2021-12-28T12:34:34.597725Z","iopub.status.idle":"2021-12-28T12:34:34.629599Z","shell.execute_reply.started":"2021-12-28T12:34:34.597696Z","shell.execute_reply":"2021-12-28T12:34:34.628665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(tokenizer_data)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:35.294469Z","iopub.execute_input":"2021-12-28T12:34:35.294886Z","iopub.status.idle":"2021-12-28T12:34:36.281576Z","shell.execute_reply.started":"2021-12-28T12:34:35.294823Z","shell.execute_reply":"2021-12-28T12:34:36.280464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.set_format(type='torch', columns=['input_ids', 'attention_mask',\n                                         'labels'])\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:36.28369Z","iopub.execute_input":"2021-12-28T12:34:36.284091Z","iopub.status.idle":"2021-12-28T12:34:36.292744Z","shell.execute_reply.started":"2021-12-28T12:34:36.284048Z","shell.execute_reply":"2021-12-28T12:34:36.291603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the shape of inputs_ids and attention_mask are same or not","metadata":{}},{"cell_type":"code","source":"for a in dataset['train']:\n    if a['input_ids'].shape[0] != a['attention_mask'].shape[0]:\n        print(a)\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:34:36.615045Z","iopub.execute_input":"2021-12-28T12:34:36.615635Z","iopub.status.idle":"2021-12-28T12:34:36.661236Z","shell.execute_reply.started":"2021-12-28T12:34:36.6156Z","shell.execute_reply":"2021-12-28T12:34:36.660246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define training argument and train the model","metadata":{}},{"cell_type":"code","source":"trainer_args = TrainingArguments('test_trainer',\n                                report_to='none',\n                                 num_train_epochs=config['epochs'],\n                                evaluation_strategy ='epoch',\n                                per_device_train_batch_size=config['train_batch_size'],\n                                per_device_eval_batch_size=config['valid_batch_size'],\n                                fp16=True,\n                                save_strategy = \"epoch\",\n                                 warmup_ratio= config['warmup'],\n                                 gradient_accumulation_steps=config['grad_acc'],\n                                 logging_strategy=\"epoch\",\n                                 save_total_limit=1\n                                )\n\ntrainer = Trainer(model=model,\n                  args=trainer_args, \n                  train_dataset = dataset['train'],\n                  eval_dataset=dataset['test'],\n#                   data_collator = data_collator,\n                  tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:38:15.180988Z","iopub.execute_input":"2021-12-28T12:38:15.181336Z","iopub.status.idle":"2021-12-28T12:38:15.205694Z","shell.execute_reply.started":"2021-12-28T12:38:15.18125Z","shell.execute_reply":"2021-12-28T12:38:15.20471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:38:15.810423Z","iopub.execute_input":"2021-12-28T12:38:15.810741Z","iopub.status.idle":"2021-12-28T12:38:33.204657Z","shell.execute_reply.started":"2021-12-28T12:38:15.810708Z","shell.execute_reply":"2021-12-28T12:38:33.203201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = config['device']","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:37:38.606386Z","iopub.execute_input":"2021-12-28T12:37:38.614052Z","iopub.status.idle":"2021-12-28T12:37:38.62686Z","shell.execute_reply.started":"2021-12-28T12:37:38.613968Z","shell.execute_reply":"2021-12-28T12:37:38.62337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Write inference function, loop through the test_text and dump into submission file","metadata":{}},{"cell_type":"code","source":"trainer.model.eval()\ndef inference(sentence):\n    inputs = tokenizer(sentence.split(),\n                        is_split_into_words=True, \n                        return_offsets_mapping=True, \n                        padding='max_length', \n                        truncation=True, \n                        max_length=4096,\n                        return_tensors=\"pt\")\n\n    # move to gpu\n    ids = inputs[\"input_ids\"].to(device)\n    mask = inputs[\"attention_mask\"].to(device)\n    # forward pass\n    outputs = trainer.model(input_ids=ids, attention_mask=mask, return_dict=False)\n#     print(outputs)\n    logits = outputs[0]\n    \n    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n    print(logits.shape, active_logits.shape, flattened_predictions.shape)\n    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n\n    prediction = []\n    out_str = []\n    off_list = inputs[\"offset_mapping\"].squeeze().tolist()\n    for idx, mapping in enumerate(off_list):\n#         print(mapping, token_pred[1], token_pred[0],\"####\")\n\n#         only predictions on first word pieces are important\n        if mapping[0] == 0 and mapping[1] != 0:\n#             print(mapping, token_pred[1], token_pred[0])\n            prediction.append(wp_preds[idx][1])\n            out_str.append(wp_preds[idx][0])\n        else:\n            if idx == 1:\n                prediction.append(wp_preds[idx][1])\n                out_str.append(wp_preds[idx][0])\n            continue\n    return prediction, out_str","metadata":{"execution":{"iopub.status.busy":"2021-12-26T06:17:12.901933Z","iopub.execute_input":"2021-12-26T06:17:12.902306Z","iopub.status.idle":"2021-12-26T06:17:12.917029Z","shell.execute_reply.started":"2021-12-26T06:17:12.902272Z","shell.execute_reply":"2021-12-26T06:17:12.915827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = []\nimport pdb\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred, _ = inference(test_texts.text.values[i])\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n    preds = []\n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 7:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \n# print(final_preds[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-26T06:17:52.239952Z","iopub.execute_input":"2021-12-26T06:17:52.240255Z","iopub.status.idle":"2021-12-26T06:17:53.128487Z","shell.execute_reply.started":"2021-12-26T06:17:52.240216Z","shell.execute_reply":"2021-12-26T06:17:53.127517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_preds)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T06:17:53.130808Z","iopub.execute_input":"2021-12-26T06:17:53.131448Z","iopub.status.idle":"2021-12-26T06:17:53.138289Z","shell.execute_reply.started":"2021-12-26T06:17:53.131403Z","shell.execute_reply":"2021-12-26T06:17:53.137259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest_df\n\nsub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T06:18:16.83531Z","iopub.execute_input":"2021-12-26T06:18:16.836031Z","iopub.status.idle":"2021-12-26T06:18:16.855083Z","shell.execute_reply.started":"2021-12-26T06:18:16.835992Z","shell.execute_reply":"2021-12-26T06:18:16.854112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T06:18:17.122696Z","iopub.execute_input":"2021-12-26T06:18:17.123278Z","iopub.status.idle":"2021-12-26T06:18:17.131685Z","shell.execute_reply.started":"2021-12-26T06:18:17.123209Z","shell.execute_reply":"2021-12-26T06:18:17.130766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}