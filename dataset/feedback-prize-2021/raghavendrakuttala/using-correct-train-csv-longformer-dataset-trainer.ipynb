{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\nwarnings.filterwarnings(\"ignore\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-30T13:59:19.377503Z","iopub.execute_input":"2021-12-30T13:59:19.378174Z","iopub.status.idle":"2021-12-30T13:59:27.961681Z","shell.execute_reply.started":"2021-12-30T13:59:19.378062Z","shell.execute_reply":"2021-12-30T13:59:27.960628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model trained on corrected train.csv check out https://www.kaggle.com/nbroad/corrected-train-csv-feedback-prize detailed notebook on how to get the file.\n\n* Loads datafrom dataframe to Datasets\n* Uses the Longformer using with 1024 tokens\n* Trainer API with fp16 enabled so as to optimize the training processes.\n \n\n## Do Upvote if you find it usefull, It keeps me motivated to do more quality work, Thanks!\n","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/corrected-train-csv-feedback-prize/corrected_train.csv')\n\ntrain_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:27.963806Z","iopub.execute_input":"2021-12-30T13:59:27.964514Z","iopub.status.idle":"2021-12-30T13:59:32.527054Z","shell.execute_reply.started":"2021-12-30T13:59:27.964441Z","shell.execute_reply":"2021-12-30T13:59:32.526109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    test_names.append(f.replace('.txt', ''))\n    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n# test_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntest_texts.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:32.528814Z","iopub.execute_input":"2021-12-30T13:59:32.529299Z","iopub.status.idle":"2021-12-30T13:59:32.580488Z","shell.execute_reply.started":"2021-12-30T13:59:32.529254Z","shell.execute_reply":"2021-12-30T13:59:32.579624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, train_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))[:]):\n    test_names.append(f.replace('.txt', ''))\n    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\ntrain_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n# train_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntrain_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:32.582665Z","iopub.execute_input":"2021-12-30T13:59:32.583174Z","iopub.status.idle":"2021-12-30T13:59:32.792543Z","shell.execute_reply.started":"2021-12-30T13:59:32.583102Z","shell.execute_reply":"2021-12-30T13:59:32.791611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:38.08246Z","iopub.execute_input":"2021-12-30T13:59:38.083263Z","iopub.status.idle":"2021-12-30T13:59:38.106619Z","shell.execute_reply.started":"2021-12-30T13:59:38.083226Z","shell.execute_reply":"2021-12-30T13:59:38.105587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_entities = []\nfor i in tqdm(train_text_df.iterrows()):\n    total = i[1]['text'].split().__len__()\n#     entities = []\n    entities = [\"O\" for i in range(total)]\n    for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n        discourse = j[1]['discourse_type']\n        list_ix = j[1]['new_predictionstring'].split()\n        for li in list_ix[1:]:\n#             print(li, entities)\n            entities[int(li)] = f\"I-{discourse}\"\n        entities[int(list_ix[0])] = f\"B-{discourse}\"\n    all_entities.append(entities)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:38.628396Z","iopub.execute_input":"2021-12-30T13:59:38.628947Z","iopub.status.idle":"2021-12-30T13:59:39.705Z","shell.execute_reply.started":"2021-12-30T13:59:38.628912Z","shell.execute_reply":"2021-12-30T13:59:39.703985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_text_df = pd.read_csv(\"/kaggle/input/feedback-prize-ner-tagged-data/feedback_prize_ner_tagged_data.csv\")\n# train_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:39.707286Z","iopub.execute_input":"2021-12-30T13:59:39.70783Z","iopub.status.idle":"2021-12-30T13:59:39.712312Z","shell.execute_reply.started":"2021-12-30T13:59:39.70777Z","shell.execute_reply":"2021-12-30T13:59:39.711043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import ast\n# train_text_df['entities'] = train_text_df['entities'].apply(lambda x:ast.literal_eval(x))\n\n# print(train_text_df['entities'].values[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:39.714066Z","iopub.execute_input":"2021-12-30T13:59:39.714698Z","iopub.status.idle":"2021-12-30T13:59:39.72471Z","shell.execute_reply.started":"2021-12-30T13:59:39.714654Z","shell.execute_reply":"2021-12-30T13:59:39.72354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df['entities'] = all_entities\n\ntrain_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:39.727307Z","iopub.execute_input":"2021-12-30T13:59:39.727651Z","iopub.status.idle":"2021-12-30T13:59:39.751365Z","shell.execute_reply.started":"2021-12-30T13:59:39.727608Z","shell.execute_reply":"2021-12-30T13:59:39.750303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_text_df[train_text_df.apply(lambda x: x['text'].split().__len__() == len(x['entities']), axis=1)]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:03:19.592805Z","iopub.execute_input":"2021-12-30T14:03:19.593103Z","iopub.status.idle":"2021-12-30T14:03:19.597998Z","shell.execute_reply.started":"2021-12-30T14:03:19.593072Z","shell.execute_reply":"2021-12-30T14:03:19.596609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df = train_text_df[:]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:40.871125Z","iopub.execute_input":"2021-12-30T13:59:40.871681Z","iopub.status.idle":"2021-12-30T13:59:40.877339Z","shell.execute_reply.started":"2021-12-30T13:59:40.871647Z","shell.execute_reply":"2021-12-30T13:59:40.875268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define config and Load model, tokenizer","metadata":{}},{"cell_type":"code","source":"import datasets\nfrom transformers import Trainer, TrainingArguments, DataCollatorWithPadding\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom torch import cuda\nimport torch","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:41.929749Z","iopub.execute_input":"2021-12-30T13:59:41.930139Z","iopub.status.idle":"2021-12-30T13:59:51.219942Z","shell.execute_reply.started":"2021-12-30T13:59:41.930108Z","shell.execute_reply":"2021-12-30T13:59:51.21887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {'model_name': '/kaggle/input/allenailongformerbase4096/longformer/',\n         'max_length': 1024,\n         'train_batch_size':4,\n         'valid_batch_size':8,\n         'epochs':5,\n         'learning_rate':5e-05,\n         'max_grad_norm':10,\n          'warmup':0.1,\n          \"grad_acc\":8,\n          \"model_save_path\":\"long-former\",\n         'device': 'cuda' if cuda.is_available() else 'cpu'}\n\noutput_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:51.224091Z","iopub.execute_input":"2021-12-30T13:59:51.224372Z","iopub.status.idle":"2021-12-30T13:59:51.281021Z","shell.execute_reply.started":"2021-12-30T13:59:51.224341Z","shell.execute_reply":"2021-12-30T13:59:51.279247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df['labels'] = train_text_df['entities'].apply(lambda x: [labels_to_ids[i] for i in x])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:51.285547Z","iopub.execute_input":"2021-12-30T13:59:51.285957Z","iopub.status.idle":"2021-12-30T13:59:51.309117Z","shell.execute_reply.started":"2021-12-30T13:59:51.285913Z","shell.execute_reply":"2021-12-30T13:59:51.307214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:51.320366Z","iopub.execute_input":"2021-12-30T13:59:51.321206Z","iopub.status.idle":"2021-12-30T13:59:51.353952Z","shell.execute_reply.started":"2021-12-30T13:59:51.321112Z","shell.execute_reply":"2021-12-30T13:59:51.35306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config['model_name'], add_prefix_space=True)\nmodel = AutoModelForTokenClassification.from_pretrained(config['model_name'],\n                                                     num_labels=len(output_labels))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:51.35644Z","iopub.execute_input":"2021-12-30T13:59:51.356926Z","iopub.status.idle":"2021-12-30T13:59:59.425184Z","shell.execute_reply.started":"2021-12-30T13:59:51.356881Z","shell.execute_reply":"2021-12-30T13:59:59.424087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test to make sure is_split_into_words, return_offsets parameters are working properly","metadata":{}},{"cell_type":"code","source":"converted = tokenizer(train_text_df.loc[0].values[1].split(),\n                      is_split_into_words=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.428449Z","iopub.execute_input":"2021-12-30T13:59:59.42879Z","iopub.status.idle":"2021-12-30T13:59:59.441645Z","shell.execute_reply.started":"2021-12-30T13:59:59.428759Z","shell.execute_reply":"2021-12-30T13:59:59.44034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(converted, converted.word_ids())","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.443392Z","iopub.execute_input":"2021-12-30T13:59:59.444043Z","iopub.status.idle":"2021-12-30T13:59:59.451399Z","shell.execute_reply.started":"2021-12-30T13:59:59.443999Z","shell.execute_reply":"2021-12-30T13:59:59.4501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(converted.word_ids()), len(train_text_df.loc[0].values[1].split())","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.453031Z","iopub.execute_input":"2021-12-30T13:59:59.453904Z","iopub.status.idle":"2021-12-30T13:59:59.463335Z","shell.execute_reply.started":"2021-12-30T13:59:59.453859Z","shell.execute_reply":"2021-12-30T13:59:59.462152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenizer.convert_ids_to_tokens(converted['input_ids'][:]), len(tokenizer.convert_ids_to_tokens(converted['input_ids'])))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.464944Z","iopub.execute_input":"2021-12-30T13:59:59.466083Z","iopub.status.idle":"2021-12-30T13:59:59.474768Z","shell.execute_reply.started":"2021-12-30T13:59:59.466035Z","shell.execute_reply":"2021-12-30T13:59:59.473442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize the data\n\n* Load data into huggingface datasets.\n* Make sure you take care of sub-word tokenizing problem when adding labels to tokenized data.\n* use .map to map tokenizer_data function to data\n* Look at one sample to see whether mapping is done correctly or not\n","metadata":{}},{"cell_type":"code","source":"def tokenizer_data(example):\n    encoding = tokenizer(example['text'].split(),\n                         is_split_into_words=True,\n                         truncation=True,\n                         padding='max_length',\n                         max_length=config['max_length'])\n#     i = 0\n    labels = example['labels']\n    encoded_labels = np.ones(len(encoding[\"input_ids\"]), dtype=int) * -100\n    previous_idx = None\n    word_idx = encoding.word_ids()\n    for i,idx in enumerate(word_idx):\n        if idx != previous_idx and idx is not None:\n#             print(idx)\n            encoded_labels[i] = labels[idx]\n#             i += 1\n        previous_idx = idx\n    item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n    item['labels'] = torch.as_tensor(encoded_labels)\n    return item","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.47902Z","iopub.execute_input":"2021-12-30T13:59:59.479722Z","iopub.status.idle":"2021-12-30T13:59:59.488948Z","shell.execute_reply.started":"2021-12-30T13:59:59.479676Z","shell.execute_reply":"2021-12-30T13:59:59.487778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.Dataset.from_pandas(train_text_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.491103Z","iopub.execute_input":"2021-12-30T13:59:59.491448Z","iopub.status.idle":"2021-12-30T13:59:59.543926Z","shell.execute_reply.started":"2021-12-30T13:59:59.491404Z","shell.execute_reply":"2021-12-30T13:59:59.543011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.54564Z","iopub.execute_input":"2021-12-30T13:59:59.546247Z","iopub.status.idle":"2021-12-30T13:59:59.575419Z","shell.execute_reply.started":"2021-12-30T13:59:59.546199Z","shell.execute_reply":"2021-12-30T13:59:59.574343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = dataset['train'][0]\n\n# print(text['text'], text['entities'], text['labels'])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.577141Z","iopub.execute_input":"2021-12-30T13:59:59.577452Z","iopub.status.idle":"2021-12-30T13:59:59.584789Z","shell.execute_reply.started":"2021-12-30T13:59:59.577412Z","shell.execute_reply":"2021-12-30T13:59:59.583609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text['text'].split())","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.587151Z","iopub.execute_input":"2021-12-30T13:59:59.587505Z","iopub.status.idle":"2021-12-30T13:59:59.597396Z","shell.execute_reply.started":"2021-12-30T13:59:59.587461Z","shell.execute_reply":"2021-12-30T13:59:59.596165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted = tokenizer_data(text)\n\nprint(converted)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.599048Z","iopub.execute_input":"2021-12-30T13:59:59.599376Z","iopub.status.idle":"2021-12-30T13:59:59.628195Z","shell.execute_reply.started":"2021-12-30T13:59:59.599346Z","shell.execute_reply":"2021-12-30T13:59:59.627145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converted\n\ni=0\nfor token, label in zip(tokenizer.convert_ids_to_tokens(converted[\"input_ids\"]), \n                        converted[\"labels\"]):\n#     print(token)\n    if label != -100:\n        print(token, '@@',text['text'].split()[i], ids_to_labels[label.item()],'@@', text['entities'][i])\n        i+=1\n    if i == 15:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.678925Z","iopub.execute_input":"2021-12-30T13:59:59.679198Z","iopub.status.idle":"2021-12-30T13:59:59.717428Z","shell.execute_reply.started":"2021-12-30T13:59:59.679171Z","shell.execute_reply":"2021-12-30T13:59:59.716501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(tokenizer_data)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:59:59.719614Z","iopub.execute_input":"2021-12-30T13:59:59.720027Z","iopub.status.idle":"2021-12-30T14:00:00.192817Z","shell.execute_reply.started":"2021-12-30T13:59:59.719984Z","shell.execute_reply":"2021-12-30T14:00:00.191593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.set_format(type='torch', columns=['input_ids', 'attention_mask',\n                                         'labels'])\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:00:00.323441Z","iopub.execute_input":"2021-12-30T14:00:00.323724Z","iopub.status.idle":"2021-12-30T14:00:00.332279Z","shell.execute_reply.started":"2021-12-30T14:00:00.32368Z","shell.execute_reply":"2021-12-30T14:00:00.331236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the shape of inputs_ids and attention_mask are same or not","metadata":{}},{"cell_type":"code","source":"for a in dataset['train']:\n    if a['input_ids'].shape[0] != a['attention_mask'].shape[0]:\n        print(a)\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:00:01.346713Z","iopub.execute_input":"2021-12-30T14:00:01.347022Z","iopub.status.idle":"2021-12-30T14:00:01.376179Z","shell.execute_reply.started":"2021-12-30T14:00:01.34699Z","shell.execute_reply":"2021-12-30T14:00:01.375334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define training argument and train the model","metadata":{}},{"cell_type":"code","source":"trainer_args = TrainingArguments('test_trainer',\n                                report_to='none',\n                                 num_train_epochs=config['epochs'],\n                                evaluation_strategy ='epoch',\n                                per_device_train_batch_size=config['train_batch_size'],\n                                per_device_eval_batch_size=config['valid_batch_size'],\n                                fp16=True,\n                                save_strategy = \"epoch\",\n                                 warmup_ratio= config['warmup'],\n                                 gradient_accumulation_steps=config['grad_acc'],\n                                 logging_strategy=\"epoch\",\n                                 save_total_limit=1\n                                )\n\ntrainer = Trainer(model=model,\n                  args=trainer_args, \n                  train_dataset = dataset['train'],\n                  eval_dataset=dataset['test'],\n#                   data_collator = data_collator,\n                  tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:00:02.131618Z","iopub.execute_input":"2021-12-30T14:00:02.131945Z","iopub.status.idle":"2021-12-30T14:00:07.232342Z","shell.execute_reply.started":"2021-12-30T14:00:02.131915Z","shell.execute_reply":"2021-12-30T14:00:07.231208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:00:07.234343Z","iopub.execute_input":"2021-12-30T14:00:07.234619Z","iopub.status.idle":"2021-12-30T14:01:38.013375Z","shell.execute_reply.started":"2021-12-30T14:00:07.234574Z","shell.execute_reply":"2021-12-30T14:01:38.012219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = config['device']","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:01:38.023006Z","iopub.execute_input":"2021-12-30T14:01:38.02687Z","iopub.status.idle":"2021-12-30T14:01:38.036672Z","shell.execute_reply.started":"2021-12-30T14:01:38.026814Z","shell.execute_reply":"2021-12-30T14:01:38.035627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Write inference function, loop through the test_text and dump into submission file","metadata":{}},{"cell_type":"code","source":"trainer.model.eval()\ndef inference(sentence):\n    inputs = tokenizer(sentence.split(),\n                        is_split_into_words=True,\n                        padding='max_length', \n                        truncation=True, \n                        max_length=4096,\n                        return_tensors=\"pt\")\n\n    # move to gpu\n    ids = inputs[\"input_ids\"].to(device)\n    mask = inputs[\"attention_mask\"].to(device)\n    # forward pass\n    outputs = trainer.model(input_ids=ids, attention_mask=mask, return_dict=False)\n#     print(outputs)\n    logits = outputs[0]\n    \n    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n    print(logits.shape, active_logits.shape, flattened_predictions.shape)\n    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n\n    prediction = []\n    out_str = []\n    previous_idx = None\n    for idx, mapping in enumerate(inputs.word_ids()):\n#         print(mapping, token_pred[1], token_pred[0],\"####\")\n\n#         only predictions on first word pieces are important\n        if mapping is not None and mapping != previous_idx:\n#             print(mapping, token_pred[1], token_pred[0])\n            prediction.append(wp_preds[idx][1])\n            out_str.append(wp_preds[idx][0])\n#         else:\n#             if idx == 1:\n#                 prediction.append(wp_preds[idx][1])\n#                 out_str.append(wp_preds[idx][0])\n#             continue\n        previous_idx = mapping\n    return prediction, out_str","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:01:38.042832Z","iopub.execute_input":"2021-12-30T14:01:38.045662Z","iopub.status.idle":"2021-12-30T14:01:41.351894Z","shell.execute_reply.started":"2021-12-30T14:01:38.045584Z","shell.execute_reply":"2021-12-30T14:01:41.350624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"te = test_texts.iloc[3]['text']","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:02:42.94478Z","iopub.execute_input":"2021-12-30T14:02:42.945131Z","iopub.status.idle":"2021-12-30T14:02:42.950231Z","shell.execute_reply.started":"2021-12-30T14:02:42.945083Z","shell.execute_reply":"2021-12-30T14:02:42.949137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(inference(te)[0]), len(te.split())","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:02:43.479115Z","iopub.execute_input":"2021-12-30T14:02:43.479411Z","iopub.status.idle":"2021-12-30T14:02:43.764159Z","shell.execute_reply.started":"2021-12-30T14:02:43.479378Z","shell.execute_reply":"2021-12-30T14:02:43.763061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = []\nimport pdb\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred, _ = inference(test_texts.text.values[i])\n#     print(idx.split(), pred)\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n    preds = []\n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 7:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \n# print(final_preds[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:02:55.859988Z","iopub.execute_input":"2021-12-30T14:02:55.860284Z","iopub.status.idle":"2021-12-30T14:02:57.154014Z","shell.execute_reply.started":"2021-12-30T14:02:55.860252Z","shell.execute_reply":"2021-12-30T14:02:57.152999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_preds)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:02:57.156073Z","iopub.execute_input":"2021-12-30T14:02:57.15709Z","iopub.status.idle":"2021-12-30T14:02:57.164405Z","shell.execute_reply.started":"2021-12-30T14:02:57.157046Z","shell.execute_reply":"2021-12-30T14:02:57.163392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest_df\n\nsub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:02:59.692194Z","iopub.execute_input":"2021-12-30T14:02:59.693223Z","iopub.status.idle":"2021-12-30T14:02:59.724007Z","shell.execute_reply.started":"2021-12-30T14:02:59.693172Z","shell.execute_reply":"2021-12-30T14:02:59.722978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T14:03:02.690818Z","iopub.execute_input":"2021-12-30T14:03:02.691478Z","iopub.status.idle":"2021-12-30T14:03:02.701752Z","shell.execute_reply.started":"2021-12-30T14:03:02.691442Z","shell.execute_reply":"2021-12-30T14:03:02.700577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}