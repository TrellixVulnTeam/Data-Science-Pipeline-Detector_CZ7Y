{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") is None:\n    ON_KAGGLE = False\nelse:\n    ON_KAGGLE = True\nif not ON_KAGGLE:\n    import shutil\n    from requests import get\n\n    from google.colab import drive, files\n    # mount Google Drive\n    drive.mount(\"/content/drive\")\nelse:\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.idle":"2022-02-20T00:41:51.724261Z","shell.execute_reply.started":"2022-02-20T00:41:45.926638Z","shell.execute_reply":"2022-02-20T00:41:51.723541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overview\nThis notebook is for inferencing. A notebook for training is below.\n\nhttps://www.kaggle.com/ytakayama/train-pytorch-longformer-5fold-forgooglecolab\n\n# How to infer\n- calculate probability for 15 classes by 5 fold model(LongFormer)\n\n15 classes: OUTPUT_LABELS in \"constants\" header which mean 14 combinations of 2 NER tags(B- /I-) and 7 elements + others\n\n- average probability in 5 predictions\n- calculate class of the highest probability \n- postprocess based on probability of predicted class and how long predcited class is continuous\n\n## update historyÂ¶\n- version 4: edit to train other models\n- version 5: use model trained for 2 epochs\n- version 6: use model trained by using multi sample dropout\n- version 7: add softmax as activation function\n- version 8: modify incorrect implementation","metadata":{}},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    name = 'fp_exp3'\n    # choose model \n    #model_savename = 'roberta-base'\n    #model_savename = 'roberta-large'\n    model_savename = 'longformer'\n    if ON_KAGGLE:\n        if model_savename == 'longformer':\n            # longformer-base-4096\n            model_name = '../input/pt-longformer-base' # https://www.kaggle.com/kishalmandal/pt-longformer-base\n        elif model_savename == 'roberta-base':\n            model_name = '../input/roberta-base' #https://www.kaggle.com/abhishek/roberta-base\n        elif model_savename == 'roberta-large':\n            model_name = '../input/robertalarge' # https://www.kaggle.com/marshal02/robertalarge\n        base_dir = '/content/drive/MyDrive/petfinder'\n        data_dir = '../input/feedback-prize-2021/'\n        pre_data_dir = './preprocessed/'\n        model_dir = '../input/train-pytorch-longformer-5fold-forgooglecolab'\n        output_dir = '.'\n    else:\n        # customize for my own Google Colab Environment\n        if model_savename == 'longformer':\n            model_name = 'allenai/longformer-base-4096'\n        elif model_savename == 'roberta-base':\n            model_name = 'roberta-base'\n        elif model_savename == 'roberta-large':\n            model_name = 'roberta-large'\n        base_dir = '/content/drive/MyDrive/feedback_prize'\n        data_dir = os.path.join(base_dir, 'data')\n        pre_data_dir = os.path.join(base_dir, 'data/preprocessed')\n        model_dir = os.path.join(base_dir, f'model/{name}')\n        output_dir = os.path.join(base_dir, f'output/{name}')\n    is_debug = False\n    n_epoch = 1 # not to exceed runtime limit\n    n_fold = 5\n    verbose_steps = 500\n    random_seed = 42\n\n    if model_savename == 'longformer':\n        max_length = 1024\n        inference_max_length = 4096\n        train_batch_size = 4\n        valid_batch_size = 4\n        lr = 4e-5\n    elif model_savename == 'roberta-base':\n        max_length = 512\n        inference_max_length = 512\n        train_batch_size = 8\n        valid_batch_size = 8\n        lr = 8e-5\n    elif model_savename == 'roberta-large':\n        max_length = 512\n        inference_max_length = 512\n        train_batch_size = 4\n        valid_batch_size = 4\n        lr = 4e-5\n    num_labels = 15\n    label_subtokens = True\n    output_hidden_states = True\n    hidden_dropout_prob = 0.1\n    layer_norm_eps = 1e-7\n    add_pooling_layer = False\n    verbose_steps = 500\n    if is_debug:\n        debug_sample = 1000\n        verbose_steps = 16\n        n_epoch = 1\n        n_fold = 2","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:51.726044Z","iopub.execute_input":"2022-02-20T00:41:51.72634Z","iopub.status.idle":"2022-02-20T00:41:51.737551Z","shell.execute_reply.started":"2022-02-20T00:41:51.726302Z","shell.execute_reply":"2022-02-20T00:41:51.736834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## constants","metadata":{}},{"cell_type":"code","source":"IGNORE_INDEX = -100\nNON_LABEL = -1\nOUTPUT_LABELS = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n                 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nLABELS_TO_IDS = {v:k for k,v in enumerate(OUTPUT_LABELS)}\nIDS_TO_LABELS = {k:v for k,v in enumerate(OUTPUT_LABELS)}\n\nMIN_THRESH = {\n    \"I-Lead\": 9,\n    \"I-Position\": 5,\n    \"I-Evidence\": 14,\n    \"I-Claim\": 3,\n    \"I-Concluding Statement\": 11,\n    \"I-Counterclaim\": 6,\n    \"I-Rebuttal\": 4,\n}\n\nPROB_THRESH = {\n    \"I-Lead\": 0.7,\n    \"I-Position\": 0.55,\n    \"I-Evidence\": 0.65,\n    \"I-Claim\": 0.55,\n    \"I-Concluding Statement\": 0.7,\n    \"I-Counterclaim\": 0.5,\n    \"I-Rebuttal\": 0.55,\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:51.738842Z","iopub.execute_input":"2022-02-20T00:41:51.739269Z","iopub.status.idle":"2022-02-20T00:41:51.754494Z","shell.execute_reply.started":"2022-02-20T00:41:51.739233Z","shell.execute_reply":"2022-02-20T00:41:51.753774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## libraries","metadata":{}},{"cell_type":"code","source":"# general\nimport pandas as pd\nimport numpy as np\nimport random\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nimport gc\nfrom collections import defaultdict\n# nlp\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport torch\nimport torch.nn as nn\nfrom transformers import LongformerConfig, LongformerModel, LongformerTokenizerFast, AutoConfig, AutoModel, AutoTokenizer\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:51.75661Z","iopub.execute_input":"2022-02-20T00:41:51.757087Z","iopub.status.idle":"2022-02-20T00:41:58.874587Z","shell.execute_reply.started":"2022-02-20T00:41:51.757052Z","shell.execute_reply":"2022-02-20T00:41:58.873694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:58.875968Z","iopub.execute_input":"2022-02-20T00:41:58.876259Z","iopub.status.idle":"2022-02-20T00:41:58.924754Z","shell.execute_reply.started":"2022-02-20T00:41:58.876214Z","shell.execute_reply":"2022-02-20T00:41:58.920789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocess","metadata":{}},{"cell_type":"code","source":"def agg_essays(train_flg):\n    folder = 'train' if train_flg else 'test'\n    names, texts =[], []\n    for f in tqdm(list(os.listdir(f'{Config.data_dir}/{folder}'))):\n        names.append(f.replace('.txt', ''))\n        texts.append(open(f'{Config.data_dir}/{folder}/' + f, 'r').read())\n        df_texts = pd.DataFrame({'id': names, 'text': texts})\n\n    df_texts['text_split'] = df_texts.text.str.split()\n    print('Completed tokenizing texts.')\n    return df_texts\n\ndef ner(df_texts, df_train):\n    all_entities = []\n    for _,  row in tqdm(df_texts.iterrows(), total=len(df_texts)):\n        total = len(row['text_split'])\n        entities = ['0'] * total\n\n        for _, row2 in df_train[df_train['id'] == row['id']].iterrows():\n            discourse = row2['discourse_type']\n            list_ix = [int(x) for x in row2['predictionstring'].split(' ')]\n            entities[list_ix[0]] = f'B-{discourse}'\n            for k in list_ix[1:]: entities[k] = f'I-{discourse}'\n        all_entities.append(entities)\n\n    df_texts['entities'] = all_entities\n    print('Completed mapping discourse to each token.')\n    return df_texts\n\ndef preprocess(df_train = None):\n    if df_train is None:\n        train_flg = False\n    else:\n        train_flg = True\n    \n    df_texts = agg_essays(train_flg)\n\n    if train_flg:\n        df_texts = ner(df_texts, df_train)\n    return df_texts\n  ","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:58.926177Z","iopub.execute_input":"2022-02-20T00:41:58.926431Z","iopub.status.idle":"2022-02-20T00:41:58.939928Z","shell.execute_reply.started":"2022-02-20T00:41:58.926395Z","shell.execute_reply":"2022-02-20T00:41:58.939222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts = preprocess()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:58.941715Z","iopub.execute_input":"2022-02-20T00:41:58.942058Z","iopub.status.idle":"2022-02-20T00:41:59.01841Z","shell.execute_reply.started":"2022-02-20T00:41:58.942023Z","shell.execute_reply":"2022-02-20T00:41:59.017725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"class FeedbackPrizeDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len, has_labels):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.has_labels = has_labels\n    \n    def __getitem__(self, index):\n        text = self.data.text[index]\n        encoding = self.tokenizer(\n            text.split(),\n            is_split_into_words = True,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_len\n        )\n        word_ids = encoding.word_ids()\n\n        # targets\n        if self.has_labels:\n            word_labels = self.data.entities[index]\n            prev_word_idx = None\n            labels_ids = []\n            for word_idx in word_ids:\n                if word_idx is None:\n                    labels_ids.append(IGNORE_INDEX)\n                elif word_idx != prev_word_idx:\n                    labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n                else:\n                    if Config.label_subtokens:\n                        labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n                    else:\n                        labels_ids.append(IGNORE_INDEX)\n                prev_word_idx = word_idx\n            encoding['labels'] = labels_ids\n        # convert to torch.tensor\n        item = {k: torch.as_tensor(v) for k, v in encoding.items()}\n        word_ids2 = [w if w is not None else NON_LABEL for w in word_ids]\n        item['word_ids'] = torch.as_tensor(word_ids2)\n        return item\n\n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:59.019414Z","iopub.execute_input":"2022-02-20T00:41:59.020153Z","iopub.status.idle":"2022-02-20T00:41:59.032683Z","shell.execute_reply.started":"2022-02-20T00:41:59.020117Z","shell.execute_reply":"2022-02-20T00:41:59.031976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self):\n        super(FeedbackModel, self).__init__()\n        if Config.model_savename == 'longformer':\n            model_config = LongformerConfig.from_pretrained(Config.model_name)\n            self.backbone = LongformerModel.from_pretrained(Config.model_name, config=model_config)\n        else:\n            model_config = AutoConfig.from_pretrained(Config.model_name)\n            self.backbone = AutoModel.from_pretrained(Config.model_name, config=model_config)\n        self.model_config = model_config\n        self.head = nn.Linear(model_config.hidden_size, Config.num_labels)\n    \n    def forward(self, input_ids, mask):\n        x = self.backbone(input_ids, mask)\n        logits = self.head(x[0])\n        return logits\n    \ndef build_model_tokenizer():\n    if Config.model_savename == 'longformer':\n        tokenizer = LongformerTokenizerFast.from_pretrained(Config.model_name, add_prefix_space = True)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(Config.model_name, add_prefix_space = True)\n    model = FeedbackModel()\n    return model, tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:59.034597Z","iopub.execute_input":"2022-02-20T00:41:59.035109Z","iopub.status.idle":"2022-02-20T00:41:59.045604Z","shell.execute_reply.started":"2022-02-20T00:41:59.03507Z","shell.execute_reply":"2022-02-20T00:41:59.044929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## utility function","metadata":{}},{"cell_type":"code","source":"def active_logits(raw_logits, word_ids):\n    word_ids = word_ids.view(-1)\n    active_mask = word_ids.unsqueeze(1).expand(word_ids.shape[0], Config.num_labels)\n    active_mask = active_mask != NON_LABEL\n    active_logits = raw_logits.view(-1, Config.num_labels)\n    active_logits = torch.masked_select(active_logits, active_mask) # return 1dTensor\n    active_logits = active_logits.view(-1, Config.num_labels) \n    return active_logits\n\ndef active_labels(labels):\n    active_mask = labels.view(-1) != IGNORE_INDEX\n    active_labels = torch.masked_select(labels.view(-1), active_mask)\n    return active_labels\n\ndef active_preds_prob(active_logits):\n    active_preds = torch.argmax(active_logits, axis = 1)\n    active_preds_prob, _ = torch.max(active_logits, axis = 1)\n    return active_preds, active_preds_prob","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:59.048487Z","iopub.execute_input":"2022-02-20T00:41:59.0488Z","iopub.status.idle":"2022-02-20T00:41:59.056877Z","shell.execute_reply.started":"2022-02-20T00:41:59.048753Z","shell.execute_reply":"2022-02-20T00:41:59.056138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## inference function","metadata":{}},{"cell_type":"code","source":"def inference(model, dl, criterion, valid_flg):\n    final_predictions = []\n    final_predictions_prob = []\n    stream = tqdm(dl)\n    model.eval()\n    \n    valid_loss = 0\n    valid_accuracy = 0\n    all_logits = None\n    for batch_idx, batch in enumerate(stream, start = 1):\n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        with torch.no_grad():\n            raw_logits = model(input_ids=ids, mask = mask)\n        del ids, mask\n        \n        word_ids = batch['word_ids'].to(device, dtype = torch.long)\n        logits = active_logits(raw_logits, word_ids)\n        sf_logits = torch.softmax(logits, dim= -1)\n        sf_raw_logits = torch.softmax(raw_logits, dim=-1)\n        if valid_flg:    \n            raw_labels = batch['labels'].to(device, dtype = torch.long)\n            labels = active_labels(raw_labels)\n            preds, preds_prob = active_preds_prob(sf_logits)\n            valid_accuracy += accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n            loss = criterion(logits, labels)\n            valid_loss += loss.item()\n        \n        if batch_idx == 1:\n            all_logits = sf_raw_logits.cpu().numpy()\n        else:\n            all_logits = np.append(all_logits, sf_raw_logits.cpu().numpy(), axis=0)\n\n    \n    if valid_flg:        \n        epoch_loss = valid_loss / batch_idx\n        epoch_accuracy = valid_accuracy / batch_idx\n    else:\n        epoch_loss, epoch_accuracy = 0, 0\n    return all_logits, epoch_loss, epoch_accuracy\n\n\ndef preds_class_prob(all_logits, dl):\n    print(\"predict target class and its probabilty\")\n    final_predictions = []\n    final_predictions_score = []\n    stream = tqdm(dl)\n    len_sample = all_logits.shape[0]\n\n    for batch_idx, batch in enumerate(stream, start=0):\n        for minibatch_idx in range(Config.valid_batch_size):\n            sample_idx = int(batch_idx * Config.valid_batch_size + minibatch_idx)\n            if sample_idx > len_sample - 1 : break\n            word_ids = batch['word_ids'][minibatch_idx].numpy()\n            predictions =[]\n            predictions_prob = []\n            pred_class_id = np.argmax(all_logits[sample_idx], axis=1)\n            pred_score = np.max(all_logits[sample_idx], axis=1)\n            pred_class_labels = [IDS_TO_LABELS[i] for i in pred_class_id]\n            prev_word_idx = -1\n            for idx, word_idx in enumerate(word_ids):\n                if word_idx == -1:\n                    pass\n                elif word_idx != prev_word_idx:\n                    predictions.append(pred_class_labels[idx])\n                    predictions_prob.append(pred_score[idx])\n                    prev_word_idx = word_idx\n            final_predictions.append(predictions)\n            final_predictions_score.append(predictions_prob)\n    return final_predictions, final_predictions_score","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:41:59.05803Z","iopub.execute_input":"2022-02-20T00:41:59.058735Z","iopub.status.idle":"2022-02-20T00:41:59.07592Z","shell.execute_reply.started":"2022-02-20T00:41:59.058699Z","shell.execute_reply":"2022-02-20T00:41:59.075179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds_onefold(model, df, dl, criterion, valid_flg):\n    logits, valid_loss, valid_acc = inference(model, dl, criterion, valid_flg)\n    all_preds, all_preds_prob = preds_class_prob(logits, dl)\n    df_pred = post_process_pred(df, all_preds, all_preds_prob)\n    return df_pred, valid_loss, valid_acc\n\ndef get_preds_folds(model, df, dl, criterion, valid_flg=False):\n    for i_fold in range(Config.n_fold):\n        model_filename = os.path.join(Config.model_dir, f\"{Config.model_savename}_{i_fold}.bin\")\n        print(f\"{model_filename} inference\")\n        model = model.to(device)\n        model.load_state_dict(torch.load(model_filename))\n        logits, valid_loss, valid_acc = inference(model, dl, criterion, valid_flg)\n        if i_fold == 0:\n            avg_pred_logits = logits\n        else:\n            avg_pred_logits += logits\n    avg_pred_logits /= Config.n_fold\n    all_preds, all_preds_prob = preds_class_prob(avg_pred_logits, dl)\n    df_pred = post_process_pred(df, all_preds, all_preds_prob)\n    return df_pred\n\ndef post_process_pred(df, all_preds, all_preds_prob):\n    final_preds = []\n    for i in range(len(df)):\n        idx = df.id.values[i]\n        pred = all_preds[i]\n        pred_prob = all_preds_prob[i]\n        j = 0\n        while j < len(pred):\n            cls = pred[j]\n            if cls == 'O': j += 1\n            else: cls = cls.replace('B', 'I')\n            end = j + 1\n            while end < len(pred) and pred[end] == cls:\n                end += 1\n            if cls != 'O' and cls !='':\n                avg_score = np.mean(pred_prob[j:end])\n                if end - j > MIN_THRESH[cls] and avg_score > PROB_THRESH[cls]:\n                    final_preds.append((idx, cls.replace('I-', ''), ' '.join(map(str, list(range(j, end))))))\n            j = end\n    df_pred = pd.DataFrame(final_preds)\n    df_pred.columns = ['id', 'class', 'new_predictionstring']\n    return df_pred","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:45:13.396276Z","iopub.execute_input":"2022-02-20T00:45:13.396543Z","iopub.status.idle":"2022-02-20T00:45:13.411566Z","shell.execute_reply.started":"2022-02-20T00:45:13.396512Z","shell.execute_reply":"2022-02-20T00:45:13.410869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## inference","metadata":{}},{"cell_type":"code","source":"model, tokenizer = build_model_tokenizer()\ncriterion = nn.CrossEntropyLoss()\nds_test = FeedbackPrizeDataset(test_texts, tokenizer, Config.max_length, False)\ndl_test = DataLoader(ds_test, batch_size=Config.train_batch_size, shuffle=False, num_workers=2, pin_memory=True)\nsub = get_preds_folds(model, test_texts, dl_test, criterion)\nsub.columns = ['id', 'class', 'predictionstring']\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:45:13.413007Z","iopub.execute_input":"2022-02-20T00:45:13.413607Z","iopub.status.idle":"2022-02-20T00:45:20.516731Z","shell.execute_reply.started":"2022-02-20T00:45:13.413571Z","shell.execute_reply":"2022-02-20T00:45:20.515883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## submission file","metadata":{}},{"cell_type":"code","source":"sub_filename = 'submission.csv'\nsub.to_csv(sub_filename, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:45:20.518471Z","iopub.execute_input":"2022-02-20T00:45:20.518743Z","iopub.status.idle":"2022-02-20T00:45:20.526736Z","shell.execute_reply.started":"2022-02-20T00:45:20.518709Z","shell.execute_reply":"2022-02-20T00:45:20.526022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(sub_filename).head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T00:45:20.528754Z","iopub.execute_input":"2022-02-20T00:45:20.529013Z","iopub.status.idle":"2022-02-20T00:45:20.542326Z","shell.execute_reply.started":"2022-02-20T00:45:20.52898Z","shell.execute_reply":"2022-02-20T00:45:20.541686Z"},"trusted":true},"execution_count":null,"outputs":[]}]}