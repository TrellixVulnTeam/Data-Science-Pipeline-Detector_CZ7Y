{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Overview\nThis notebook is for training Longformer-base-4096 of 5 folds and calculating cv score after postprocessing predictions by using average probability of predicted classes. \n\nA notebook for inferencing is below.\n\nhttps://www.kaggle.com/ytakayama/inference-pytorch-longformer-5fold\n\n### Reference\nFollowing notebooks are very informative and great. Thanks.\n- https://www.kaggle.com/abhishek/two-longformers-are-better-than-1\n- https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615\n- https://www.kaggle.com/nbroad/corrected-train-csv-feedback-prize\n\n\n### How to infer\n- calculate probability for 15 classes by 5 fold model(LongFormer)\n\n15 classes: OUTPUT_LABELS in \"constants\" header which mean 14 combinations of 2 NER tags(B- /I-) and 7 elements + others\n\n- calculate class of the highest probability \n - inference test data: calculate average probability in 5 predictions\n - validate train data: use probability of each fold\n- postprocess based on probability of predicted class and how long predcited class is continuous\n\n### customize for executing this notebook on Google Colab\n- prepare data: competion data and following data\n\nhttps://www.kaggle.com/nbroad/corrected-train-csv-feedback-prize\n- set variables about directories of Config class (e.g. data_dir)\n\n### update history\n- version 4: correct function to caluculate oof score: I missed f1 of class 'Claim'\n- version 6: edit to train other models\n- version 7: change epoch setting\n- version 8: multi sample dropout\nPaper: https://arxiv.org/abs/1905.09788\n- version 9: add softmax as[](http://) activation function\n- version 10: modify implementation about O tag and inference function","metadata":{"id":"yHHiMfFSkk5Y"}},{"cell_type":"markdown","source":"## setup envirionment","metadata":{}},{"cell_type":"code","source":"import os\n\nif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") is None:\n    ON_KAGGLE = False\nelse:\n    ON_KAGGLE = True\nif not ON_KAGGLE:\n    import shutil\n    from requests import get\n\n    from google.colab import drive, files\n    # mount Google Drive\n    drive.mount(\"/content/drive\")\nelse:\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))","metadata":{"id":"3zuiIZsfklQp","executionInfo":{"status":"ok","timestamp":1643460858524,"user_tz":-540,"elapsed":1965,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"75b66195-51d1-4ea2-b321-8792e36bba08","_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Config\n\nmodel setting\n- prepare dataset\n- set model_savename and model_name you want to train","metadata":{"id":"Ip73rtLOC8tV"}},{"cell_type":"code","source":"class Config:\n    name = 'fp_exp3'\n    # choose model \n    #model_savename = 'roberta-base'\n    #model_savename = 'roberta-large'\n    model_savename = 'longformer'\n    if ON_KAGGLE:\n        if model_savename == 'longformer':\n            # longformer-base-4096\n            model_name = '../input/pt-longformer-base' # https://www.kaggle.com/kishalmandal/pt-longformer-base\n        elif model_savename == 'roberta-base':\n            model_name = '../input/roberta-base' #https://www.kaggle.com/abhishek/roberta-base\n        elif model_savename == 'roberta-large':\n            model_name = '../input/robertalarge' # https://www.kaggle.com/marshal02/robertalarge\n        base_dir = '/content/drive/MyDrive/petfinder'\n        data_dir = '../input/feedback-prize-2021/'\n        pre_data_dir = './preprocessed/'\n        model_dir = '.'\n        output_dir = '.'\n    else:\n        # customize for my own Google Colab Environment\n        if model_savename == 'longformer':\n            model_name = 'allenai/longformer-base-4096'\n        elif model_savename == 'roberta-base':\n            model_name = 'roberta-base'\n        elif model_savename == 'roberta-large':\n            model_name = 'roberta-large'\n        base_dir = '/content/drive/MyDrive/feedback_prize'\n        data_dir = os.path.join(base_dir, 'data')\n        pre_data_dir = os.path.join(base_dir, 'data/preprocessed')\n        model_dir = os.path.join(base_dir, f'model/{name}')\n        output_dir = os.path.join(base_dir, f'output/{name}')\n    is_debug = False\n    n_epoch = 2 # not to exceed runtime limit\n    n_fold = 5\n    verbose_steps = 500\n    random_seed = 42\n\n    if model_savename == 'longformer':\n        max_length = 1024\n        inference_max_length = 4096\n        train_batch_size = 4\n        valid_batch_size = 4\n        lr = 4e-5\n    elif model_savename == 'roberta-base':\n        max_length = 512\n        inference_max_length = 512\n        train_batch_size = 8\n        valid_batch_size = 8\n        lr = 8e-5\n    elif model_savename == 'roberta-large':\n        max_length = 512\n        inference_max_length = 512\n        train_batch_size = 4\n        valid_batch_size = 4\n        lr = 1e-5\n    num_labels = 15\n    label_subtokens = True\n    output_hidden_states = True\n    hidden_dropout_prob = 0.1\n    layer_norm_eps = 1e-7\n    add_pooling_layer = False\n    verbose_steps = 500\n    if is_debug:\n        debug_sample = 1000\n        verbose_steps = 16\n        n_epoch = 1\n        n_fold = 2","metadata":{"id":"KgOMqia7C8Rn","executionInfo":{"status":"ok","timestamp":1643460858524,"user_tz":-540,"elapsed":8,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:23.197286Z","iopub.execute_input":"2022-02-19T13:14:23.19746Z","iopub.status.idle":"2022-02-19T13:14:23.209097Z","shell.execute_reply.started":"2022-02-19T13:14:23.197438Z","shell.execute_reply":"2022-02-19T13:14:23.208426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"constants","metadata":{"id":"iP34ixYneANA"}},{"cell_type":"code","source":"IGNORE_INDEX = -100\nNON_LABEL = -1\nOUTPUT_LABELS = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n                 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nLABELS_TO_IDS = {v:k for k,v in enumerate(OUTPUT_LABELS)}\nIDS_TO_LABELS = {k:v for k,v in enumerate(OUTPUT_LABELS)}\n\nMIN_THRESH = {\n    \"I-Lead\": 9,\n    \"I-Position\": 5,\n    \"I-Evidence\": 14,\n    \"I-Claim\": 3,\n    \"I-Concluding Statement\": 11,\n    \"I-Counterclaim\": 6,\n    \"I-Rebuttal\": 4,\n}\n\nPROB_THRESH = {\n    \"I-Lead\": 0.7,\n    \"I-Position\": 0.55,\n    \"I-Evidence\": 0.65,\n    \"I-Claim\": 0.55,\n    \"I-Concluding Statement\": 0.7,\n    \"I-Counterclaim\": 0.5,\n    \"I-Rebuttal\": 0.55,\n}\n","metadata":{"id":"e0IRAsjceDS2","executionInfo":{"status":"ok","timestamp":1643460858525,"user_tz":-540,"elapsed":8,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:23.210472Z","iopub.execute_input":"2022-02-19T13:14:23.210758Z","iopub.status.idle":"2022-02-19T13:14:23.222597Z","shell.execute_reply.started":"2022-02-19T13:14:23.210721Z","shell.execute_reply":"2022-02-19T13:14:23.221849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ON_KAGGLE:\n    if not os.path.exists(Config.model_dir):\n        !mkdir $Config.model_dir\n    if not os.path.exists(Config.output_dir):\n        !mkdir $Config.output_dir","metadata":{"id":"ah8WKsqGHja0","executionInfo":{"status":"ok","timestamp":1643460858889,"user_tz":-540,"elapsed":372,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"caab8c48-0e5a-4859-8c0a-6f3ae1bd6e04","execution":{"iopub.status.busy":"2022-02-19T13:14:23.226083Z","iopub.execute_input":"2022-02-19T13:14:23.226293Z","iopub.status.idle":"2022-02-19T13:14:23.235892Z","shell.execute_reply.started":"2022-02-19T13:14:23.22627Z","shell.execute_reply":"2022-02-19T13:14:23.23516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"libraries","metadata":{"id":"1MzNuNB1kvb3"}},{"cell_type":"code","source":"if not ON_KAGGLE:\n    !pip install -qq transformers","metadata":{"id":"JnVna5XqnuWN","executionInfo":{"status":"ok","timestamp":1643460863003,"user_tz":-540,"elapsed":4116,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:23.237195Z","iopub.execute_input":"2022-02-19T13:14:23.238091Z","iopub.status.idle":"2022-02-19T13:14:23.243641Z","shell.execute_reply.started":"2022-02-19T13:14:23.238052Z","shell.execute_reply":"2022-02-19T13:14:23.242849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# general\nimport pandas as pd\nimport numpy as np\nimport random\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nimport gc\nfrom collections import defaultdict\n# nlp\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport torch\nimport torch.nn as nn\nfrom transformers import LongformerConfig, LongformerModel, LongformerTokenizerFast, AutoConfig, AutoModel, AutoTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler","metadata":{"id":"DZe70phDk1QF","executionInfo":{"status":"ok","timestamp":1643460864661,"user_tz":-540,"elapsed":1661,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:23.244919Z","iopub.execute_input":"2022-02-19T13:14:23.24554Z","iopub.status.idle":"2022-02-19T13:14:30.612099Z","shell.execute_reply.started":"2022-02-19T13:14:23.245473Z","shell.execute_reply":"2022-02-19T13:14:30.611392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocess\nuse corrected train.csv\n\nhttps://www.kaggle.com/nbroad/corrected-train-csv-feedback-prize/notebook","metadata":{"id":"OzvQtzK4ni9Q"}},{"cell_type":"code","source":"if ON_KAGGLE:\n    df_alltrain = pd.read_csv('../input/corrected-train-csv-feedback-prize/corrected_train.csv')\nelse:\n    df_alltrain = pd.read_csv(f'{Config.data_dir}/corrected_train.csv')","metadata":{"id":"-wS1I6Xsmnla","executionInfo":{"status":"ok","timestamp":1643460866403,"user_tz":-540,"elapsed":1745,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:30.614546Z","iopub.execute_input":"2022-02-19T13:14:30.614808Z","iopub.status.idle":"2022-02-19T13:14:34.046668Z","shell.execute_reply.started":"2022-02-19T13:14:30.614773Z","shell.execute_reply":"2022-02-19T13:14:34.045924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def agg_essays(train_flg):\n    folder = 'train' if train_flg else 'test'\n    names, texts =[], []\n    for f in tqdm(list(os.listdir(f'{Config.data_dir}/{folder}'))):\n        names.append(f.replace('.txt', ''))\n        texts.append(open(f'{Config.data_dir}/{folder}/' + f, 'r').read())\n        df_texts = pd.DataFrame({'id': names, 'text': texts})\n\n    df_texts['text_split'] = df_texts.text.str.split()\n    print('Completed tokenizing texts.')\n    return df_texts","metadata":{"id":"wkADwF11m1nK","executionInfo":{"status":"ok","timestamp":1643460866403,"user_tz":-540,"elapsed":4,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:34.048069Z","iopub.execute_input":"2022-02-19T13:14:34.048304Z","iopub.status.idle":"2022-02-19T13:14:34.054355Z","shell.execute_reply.started":"2022-02-19T13:14:34.048272Z","shell.execute_reply":"2022-02-19T13:14:34.053729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ner(df_texts, df_train):\n    all_entities = []\n    for _,  row in tqdm(df_texts.iterrows(), total=len(df_texts)):\n        total = len(row['text_split'])\n        entities = ['O'] * total\n\n        for _, row2 in df_train[df_train['id'] == row['id']].iterrows():\n            discourse = row2['discourse_type']\n            list_ix = [int(x) for x in row2['predictionstring'].split(' ')]\n            entities[list_ix[0]] = f'B-{discourse}'\n            for k in list_ix[1:]: entities[k] = f'I-{discourse}'\n        all_entities.append(entities)\n\n    df_texts['entities'] = all_entities\n    print('Completed mapping discourse to each token.')\n    return df_texts","metadata":{"id":"5pL88Q7UqItJ","executionInfo":{"status":"ok","timestamp":1643460866404,"user_tz":-540,"elapsed":4,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:14:34.055871Z","iopub.execute_input":"2022-02-19T13:14:34.056535Z","iopub.status.idle":"2022-02-19T13:14:34.064969Z","shell.execute_reply.started":"2022-02-19T13:14:34.056488Z","shell.execute_reply":"2022-02-19T13:14:34.06425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train = None):\n    if df_train is None:\n        train_flg = False\n    else:\n        train_flg = True\n    \n    df_texts = agg_essays(train_flg)\n\n    if train_flg:\n        df_texts = ner(df_texts, df_train)\n    return df_texts\n  \nalltrain_texts = preprocess(df_alltrain)\ntest_texts = preprocess()\n","metadata":{"id":"IZKDoHIhhZiO","executionInfo":{"status":"ok","timestamp":1643461094610,"user_tz":-540,"elapsed":228209,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"6158da45-925f-41ac-d02d-810666ab7e00","execution":{"iopub.status.busy":"2022-02-19T13:14:34.068378Z","iopub.execute_input":"2022-02-19T13:14:34.068595Z","iopub.status.idle":"2022-02-19T13:21:21.144162Z","shell.execute_reply.started":"2022-02-19T13:14:34.068564Z","shell.execute_reply":"2022-02-19T13:21:21.143476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if Config.is_debug:\n    alltrain_texts = alltrain_texts.sample(Config.debug_sample).reset_index(drop=True)\nprint(len(alltrain_texts))","metadata":{"id":"yDSJobRdjdqs","executionInfo":{"status":"ok","timestamp":1643461094611,"user_tz":-540,"elapsed":19,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"94abb031-0d4f-4266-f575-61acf9e40aef","execution":{"iopub.status.busy":"2022-02-19T13:21:21.145296Z","iopub.execute_input":"2022-02-19T13:21:21.145982Z","iopub.status.idle":"2022-02-19T13:21:21.393358Z","shell.execute_reply.started":"2022-02-19T13:21:21.145946Z","shell.execute_reply":"2022-02-19T13:21:21.39266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alltrain_texts.head()","metadata":{"id":"pYO6yvyelTfY","executionInfo":{"status":"ok","timestamp":1643461094611,"user_tz":-540,"elapsed":17,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"4792445f-f420-429b-9739-99966fb5f35a","execution":{"iopub.status.busy":"2022-02-19T13:21:21.394967Z","iopub.execute_input":"2022-02-19T13:21:21.395205Z","iopub.status.idle":"2022-02-19T13:21:21.420022Z","shell.execute_reply.started":"2022-02-19T13:21:21.395173Z","shell.execute_reply":"2022-02-19T13:21:21.419228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts.head()","metadata":{"id":"NpIBOiqqx05a","executionInfo":{"status":"ok","timestamp":1643461094612,"user_tz":-540,"elapsed":11,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"630b30ed-3131-401a-bf6b-b68ef45b395f","execution":{"iopub.status.busy":"2022-02-19T13:21:21.421476Z","iopub.execute_input":"2022-02-19T13:21:21.421749Z","iopub.status.idle":"2022-02-19T13:21:21.441771Z","shell.execute_reply.started":"2022-02-19T13:21:21.421714Z","shell.execute_reply":"2022-02-19T13:21:21.440595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"set seed & split train/test","metadata":{"id":"DKENi2ZOkJv1"}},{"cell_type":"code","source":"def seed_everything(seed=Config.random_seed):\n    #os.environ['PYTHONSEED'] = str(seed)\n    np.random.seed(seed%(2**32-1))\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic =True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()\n# device optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","metadata":{"id":"zrYLMWzfljQ0","executionInfo":{"status":"ok","timestamp":1643461095069,"user_tz":-540,"elapsed":467,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"d3352984-5a7a-4c07-91ae-4ce4f8be5db9","execution":{"iopub.status.busy":"2022-02-19T13:21:21.443828Z","iopub.execute_input":"2022-02-19T13:21:21.444282Z","iopub.status.idle":"2022-02-19T13:21:21.499016Z","shell.execute_reply.started":"2022-02-19T13:21:21.444242Z","shell.execute_reply":"2022-02-19T13:21:21.498208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_fold(df_train):\n    ids = df_train['id'].unique()\n    kf = KFold(n_splits=Config.n_fold, shuffle = True, random_state=Config.random_seed)\n    for i_fold, (_, valid_index) in enumerate(kf.split(ids)):\n        df_train.loc[valid_index,'fold'] = i_fold\n    return df_train\n\nalltrain_texts = split_fold(alltrain_texts)\nalltrain_texts.head()","metadata":{"id":"zsZXHSH-vcGA","executionInfo":{"status":"ok","timestamp":1643461095070,"user_tz":-540,"elapsed":10,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"8e1cd311-e801-42fc-9a13-ab6bdd0e60e3","execution":{"iopub.status.busy":"2022-02-19T13:21:21.500365Z","iopub.execute_input":"2022-02-19T13:21:21.50062Z","iopub.status.idle":"2022-02-19T13:21:21.530772Z","shell.execute_reply.started":"2022-02-19T13:21:21.500585Z","shell.execute_reply":"2022-02-19T13:21:21.530109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{"id":"NjsguQtHonKZ"}},{"cell_type":"code","source":"class FeedbackPrizeDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len, has_labels):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.has_labels = has_labels\n    \n    def __getitem__(self, index):\n        text = self.data.text[index]\n        encoding = self.tokenizer(\n            text.split(),\n            is_split_into_words = True,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_len\n        )\n        word_ids = encoding.word_ids()\n\n        # targets\n        if self.has_labels:\n            word_labels = self.data.entities[index]\n            prev_word_idx = None\n            labels_ids = []\n            for word_idx in word_ids:\n                if word_idx is None:\n                    labels_ids.append(IGNORE_INDEX)\n                elif word_idx != prev_word_idx:\n                    labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n                else:\n                    if Config.label_subtokens:\n                        labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n                    else:\n                        labels_ids.append(IGNORE_INDEX)\n                prev_word_idx = word_idx\n            encoding['labels'] = labels_ids\n        # convert to torch.tensor\n        item = {k: torch.as_tensor(v) for k, v in encoding.items()}\n        word_ids2 = [w if w is not None else NON_LABEL for w in word_ids]\n        item['word_ids'] = torch.as_tensor(word_ids2)\n        return item\n\n    def __len__(self):\n        return self.len","metadata":{"id":"-eRhZHHNprqv","executionInfo":{"status":"ok","timestamp":1643461095071,"user_tz":-540,"elapsed":9,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.531983Z","iopub.execute_input":"2022-02-19T13:21:21.532448Z","iopub.status.idle":"2022-02-19T13:21:21.543813Z","shell.execute_reply.started":"2022-02-19T13:21:21.532412Z","shell.execute_reply":"2022-02-19T13:21:21.543032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{"id":"LoKi2f7lC2UR"}},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self):\n        super(FeedbackModel, self).__init__()\n        if Config.model_savename == 'longformer':\n            model_config = LongformerConfig.from_pretrained(Config.model_name)\n            self.backbone = LongformerModel.from_pretrained(Config.model_name, config=model_config)\n        else:\n            model_config = AutoConfig.from_pretrained(Config.model_name)\n            self.backbone = AutoModel.from_pretrained(Config.model_name, config=model_config)\n        self.model_config = model_config\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.head = nn.Linear(model_config.hidden_size, Config.num_labels)\n    \n    def forward(self, input_ids, mask):\n        x = self.backbone(input_ids, mask)\n        logits1 = self.head(self.dropout1(x[0]))\n        logits2 = self.head(self.dropout2(x[0]))\n        logits3 = self.head(self.dropout3(x[0]))\n        logits4 = self.head(self.dropout4(x[0]))\n        logits5 = self.head(self.dropout5(x[0]))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        return logits","metadata":{"id":"qlfQN-BpC3Et","executionInfo":{"status":"ok","timestamp":1643461095071,"user_tz":-540,"elapsed":9,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.545072Z","iopub.execute_input":"2022-02-19T13:21:21.545581Z","iopub.status.idle":"2022-02-19T13:21:21.557315Z","shell.execute_reply.started":"2022-02-19T13:21:21.545545Z","shell.execute_reply":"2022-02-19T13:21:21.556581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model_tokenizer():\n    if Config.model_savename == 'longformer':\n        tokenizer = LongformerTokenizerFast.from_pretrained(Config.model_name, add_prefix_space = True)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(Config.model_name, add_prefix_space = True)\n    model = FeedbackModel()\n    return model, tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-02-19T13:21:21.558564Z","iopub.execute_input":"2022-02-19T13:21:21.559475Z","iopub.status.idle":"2022-02-19T13:21:21.569169Z","shell.execute_reply.started":"2022-02-19T13:21:21.559438Z","shell.execute_reply":"2022-02-19T13:21:21.568316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## utility function","metadata":{"id":"tIzPUw0n21Cq"}},{"cell_type":"code","source":"def active_logits(raw_logits, word_ids):\n    word_ids = word_ids.view(-1)\n    active_mask = word_ids.unsqueeze(1).expand(word_ids.shape[0], Config.num_labels)\n    active_mask = active_mask != NON_LABEL\n    active_logits = raw_logits.view(-1, Config.num_labels)\n    active_logits = torch.masked_select(active_logits, active_mask) # return 1dTensor\n    active_logits = active_logits.view(-1, Config.num_labels) \n    return active_logits\n\ndef active_labels(labels):\n    active_mask = labels.view(-1) != IGNORE_INDEX\n    active_labels = torch.masked_select(labels.view(-1), active_mask)\n    return active_labels\n\ndef active_preds_prob(active_logits):\n    active_preds = torch.argmax(active_logits, axis = 1)\n    active_preds_prob, _ = torch.max(active_logits, axis = 1)\n    return active_preds, active_preds_prob","metadata":{"id":"CHZI4rsi2yO-","executionInfo":{"status":"ok","timestamp":1643461095072,"user_tz":-540,"elapsed":10,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.57217Z","iopub.execute_input":"2022-02-19T13:21:21.572395Z","iopub.status.idle":"2022-02-19T13:21:21.581244Z","shell.execute_reply.started":"2022-02-19T13:21:21.572361Z","shell.execute_reply":"2022-02-19T13:21:21.580453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## evaluating function","metadata":{"id":"6tJJuIK01jGT"}},{"cell_type":"code","source":"def calc_overlap(row):\n    \"\"\"\n    calculate the overlap between prediction and ground truth\n    \"\"\"\n    set_pred = set(row.new_predictionstring_pred.split(' '))\n    set_gt = set(row.new_predictionstring_gt.split(' '))\n    # length of each end intersection\n    len_pred = len(set_pred)\n    len_gt = len(set_gt)\n    intersection = len(set_gt.intersection(set_pred))\n    overlap_1 = intersection / len_gt\n    overlap_2 = intersection / len_pred\n    return [overlap_1, overlap_2]\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id', 'discourse_type', 'new_predictionstring']].reset_index(drop = True).copy()\n    pred_df = pred_df[['id', 'class', 'new_predictionstring']].reset_index(drop = True).copy()\n    gt_df['gt_id'] = gt_df.index\n    pred_df['pred_id'] = pred_df.index\n    joined = pred_df.merge(\n        gt_df,\n        left_on = ['id', 'class'],\n        right_on = ['id', 'discourse_type'],\n        how = 'outer',\n        suffixes = ['_pred', '_gt']\n    )\n    joined['new_predictionstring_gt'] =  joined['new_predictionstring_gt'].fillna(' ')\n    joined['new_predictionstring_pred'] =  joined['new_predictionstring_pred'].fillna(' ')\n    joined['overlaps'] = joined.apply(calc_overlap, axis = 1)\n    # overlap over 0.5: true positive\n    # If nultiple overlaps exists, the higher is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1', 'overlap2']].max(axis = 1)\n    tp_pred_ids = joined.query('potential_TP').sort_values('max_overlap', ascending = False)\\\n                  .groupby(['id', 'new_predictionstring_gt']).first()['pred_id'].values\n    \n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    macro_f1_score = TP / (TP + 1/2 * (FP + FN))\n    return macro_f1_score\n\ndef oof_score(df_val, oof):\n    f1score = []\n    classes = ['Lead', 'Position','Claim', 'Counterclaim', 'Rebuttal','Evidence','Concluding Statement']\n    for c in classes:\n        pred_df = oof.loc[oof['class'] == c].copy()\n        gt_df = df_val.loc[df_val['discourse_type'] == c].copy()\n        f1 = score_feedback_comp(pred_df, gt_df)\n        print(f'{c:<10}: {f1:4f}')\n        f1score.append(f1)\n    f1avg = np.mean(f1score)\n    return f1avg","metadata":{"id":"NGIRUiBf1rkM","executionInfo":{"status":"ok","timestamp":1643461095072,"user_tz":-540,"elapsed":9,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.58331Z","iopub.execute_input":"2022-02-19T13:21:21.584Z","iopub.status.idle":"2022-02-19T13:21:21.602029Z","shell.execute_reply.started":"2022-02-19T13:21:21.583903Z","shell.execute_reply":"2022-02-19T13:21:21.601265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## inferencing function","metadata":{"id":"a6NYa6Op2Cwu"}},{"cell_type":"code","source":"def inference(model, dl, criterion, valid_flg):\n    final_predictions = []\n    final_predictions_prob = []\n    stream = tqdm(dl)\n    model.eval()\n    \n    valid_loss = 0\n    valid_accuracy = 0\n    all_logits = None\n    for batch_idx, batch in enumerate(stream, start = 1):\n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        with torch.no_grad():\n            raw_logits = model(input_ids=ids, mask = mask)\n        del ids, mask\n        \n        word_ids = batch['word_ids'].to(device, dtype = torch.long)\n        logits = active_logits(raw_logits, word_ids)\n        sf_logits = torch.softmax(logits, dim= -1)\n        sf_raw_logits = torch.softmax(raw_logits, dim=-1)\n        if valid_flg:    \n            raw_labels = batch['labels'].to(device, dtype = torch.long)\n            labels = active_labels(raw_labels)\n            preds, preds_prob = active_preds_prob(sf_logits)\n            valid_accuracy += accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n            loss = criterion(logits, labels)\n            valid_loss += loss.item()\n        \n        if batch_idx == 1:\n            all_logits = sf_raw_logits.cpu().numpy()\n        else:\n            all_logits = np.append(all_logits, sf_raw_logits.cpu().numpy(), axis=0)\n\n    \n    if valid_flg:        \n        epoch_loss = valid_loss / batch_idx\n        epoch_accuracy = valid_accuracy / batch_idx\n    else:\n        epoch_loss, epoch_accuracy = 0, 0\n    return all_logits, epoch_loss, epoch_accuracy\n\n\ndef preds_class_prob(all_logits, dl):\n    print(\"predict target class and its probabilty\")\n    final_predictions = []\n    final_predictions_score = []\n    stream = tqdm(dl)\n    len_sample = all_logits.shape[0]\n\n    for batch_idx, batch in enumerate(stream, start=0):\n        for minibatch_idx in range(Config.valid_batch_size):\n            sample_idx = int(batch_idx * Config.valid_batch_size + minibatch_idx)\n            if sample_idx > len_sample - 1 : break\n            word_ids = batch['word_ids'][minibatch_idx].numpy()\n            predictions =[]\n            predictions_prob = []\n            pred_class_id = np.argmax(all_logits[sample_idx], axis=1)\n            pred_score = np.max(all_logits[sample_idx], axis=1)\n            pred_class_labels = [IDS_TO_LABELS[i] for i in pred_class_id]\n            prev_word_idx = -1\n            for idx, word_idx in enumerate(word_ids):\n                if word_idx == -1:\n                    pass\n                elif word_idx != prev_word_idx:\n                    predictions.append(pred_class_labels[idx])\n                    predictions_prob.append(pred_score[idx])\n                    prev_word_idx = word_idx\n            final_predictions.append(predictions)\n            final_predictions_score.append(predictions_prob)\n    return final_predictions, final_predictions_score","metadata":{"execution":{"iopub.status.busy":"2022-02-19T13:21:21.603319Z","iopub.execute_input":"2022-02-19T13:21:21.603762Z","iopub.status.idle":"2022-02-19T13:21:21.622141Z","shell.execute_reply.started":"2022-02-19T13:21:21.603725Z","shell.execute_reply":"2022-02-19T13:21:21.621427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds_onefold(model, df, dl, criterion, valid_flg):\n    logits, valid_loss, valid_acc = inference(model, dl, criterion, valid_flg)\n    all_preds, all_preds_prob = preds_class_prob(logits, dl)\n    df_pred = post_process_pred(df, all_preds, all_preds_prob)\n    return df_pred, valid_loss, valid_acc\n\ndef get_preds_folds(model, df, dl, criterion, valid_flg=False):\n    for i_fold in range(Config.n_fold):\n        model_filename = os.path.join(Config.model_dir, f\"{Config.model_savename}_{i_fold}.bin\")\n        print(f\"{model_filename} inference\")\n        model = model.to(device)\n        model.load_state_dict(torch.load(model_filename))\n        logits, valid_loss, valid_acc = inference(model, dl, criterion, valid_flg)\n        if i_fold == 0:\n            avg_pred_logits = logits\n        else:\n            avg_pred_logits += logits\n    avg_pred_logits /= Config.n_fold\n    all_preds, all_preds_prob = preds_class_prob(avg_pred_logits, dl)\n    df_pred = post_process_pred(df, all_preds, all_preds_prob)\n    return df_pred\n\ndef post_process_pred(df, all_preds, all_preds_prob):\n    final_preds = []\n    for i in range(len(df)):\n        idx = df.id.values[i]\n        pred = all_preds[i]\n        pred_prob = all_preds_prob[i]\n        j = 0\n        while j < len(pred):\n            cls = pred[j]\n            if cls == 'O': j += 1\n            else: cls = cls.replace('B', 'I')\n            end = j + 1\n            while end < len(pred) and pred[end] == cls:\n                end += 1\n            if cls != 'O' and cls !='':\n                avg_score = np.mean(pred_prob[j:end])\n                if end - j > MIN_THRESH[cls] and avg_score > PROB_THRESH[cls]:\n                    final_preds.append((idx, cls.replace('I-', ''), ' '.join(map(str, list(range(j, end))))))\n            j = end\n    df_pred = pd.DataFrame(final_preds)\n    df_pred.columns = ['id', 'class', 'new_predictionstring']\n    return df_pred","metadata":{"id":"DwjxrC2WZYH8","executionInfo":{"status":"ok","timestamp":1643462075870,"user_tz":-540,"elapsed":3,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.623542Z","iopub.execute_input":"2022-02-19T13:21:21.624239Z","iopub.status.idle":"2022-02-19T13:21:21.639148Z","shell.execute_reply.started":"2022-02-19T13:21:21.624176Z","shell.execute_reply":"2022-02-19T13:21:21.63832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training and validating function","metadata":{"id":"hCw88fKN2bWF"}},{"cell_type":"code","source":"def train_fn(model, dl_train, optimizer, epoch, criterion):\n    model.train()\n    train_loss = 0\n    train_accuracy = 0\n    stream = tqdm(dl_train)\n    scaler = GradScaler()\n\n    for batch_idx, batch in enumerate(stream, start = 1):\n        ids = batch['input_ids'].to(device, dtype = torch.long)\n        mask = batch['attention_mask'].to(device, dtype = torch.long)\n        raw_labels = batch['labels'].to(device, dtype = torch.long)\n        word_ids = batch['word_ids'].to(device, dtype = torch.long)\n        optimizer.zero_grad()\n        with autocast():\n            raw_logits = model(input_ids = ids, mask = mask)\n        \n        logits = active_logits(raw_logits, word_ids)\n        labels = active_labels(raw_labels)\n        sf_logits = torch.softmax(logits, dim=-1)\n        preds, preds_prob = active_preds_prob(sf_logits)\n        train_accuracy += accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n        criterion = nn.CrossEntropyLoss()\n        loss = criterion(logits, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        train_loss += loss.item()\n        \n        if batch_idx % Config.verbose_steps == 0:\n            loss_step = train_loss / batch_idx\n            print(f'Training loss after {batch_idx:04d} training steps: {loss_step}')\n            \n    epoch_loss = train_loss / batch_idx\n    epoch_accuracy = train_accuracy / batch_idx\n    del dl_train, raw_logits, logits, raw_labels, preds, labels\n    torch.cuda.empty_cache()\n    gc.collect()\n    print(f'epoch {epoch} - training loss: {epoch_loss:.4f}')\n    print(f'epoch {epoch} - training accuracy: {epoch_accuracy:.4f}')","metadata":{"id":"EJUnTD0w2aZJ","executionInfo":{"status":"ok","timestamp":1643462076357,"user_tz":-540,"elapsed":489,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.640448Z","iopub.execute_input":"2022-02-19T13:21:21.640842Z","iopub.status.idle":"2022-02-19T13:21:21.65448Z","shell.execute_reply.started":"2022-02-19T13:21:21.640801Z","shell.execute_reply":"2022-02-19T13:21:21.653569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(model, df_val, df_val_eval, dl_val, epoch, criterion):\n    oof, valid_loss, valid_acc  = get_preds_onefold(model, df_val, dl_val, criterion, valid_flg=True)\n    f1score =[]\n    # classes = oof['class'].unique()\n    classes = ['Lead', 'Position', 'Claim','Counterclaim', 'Rebuttal','Evidence','Concluding Statement']\n    print(f\"Validation F1 scores\")\n\n    for c in classes:\n        pred_df = oof.loc[oof['class'] == c].copy()\n        gt_df = df_val_eval.loc[df_val_eval['discourse_type'] == c].copy()\n        f1 = score_feedback_comp(pred_df, gt_df)\n        print(f' * {c:<10}: {f1:4f}')\n        f1score.append(f1)\n    f1avg = np.mean(f1score)\n    print(f'Overall Validation avg F1: {f1avg:.4f} val_loss:{valid_loss:.4f} val_accuracy:{valid_acc:.4f}')\n    return valid_loss, oof","metadata":{"id":"SUNaOnL5a5UM","executionInfo":{"status":"ok","timestamp":1643462076357,"user_tz":-540,"elapsed":3,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.655739Z","iopub.execute_input":"2022-02-19T13:21:21.656468Z","iopub.status.idle":"2022-02-19T13:21:21.665931Z","shell.execute_reply.started":"2022-02-19T13:21:21.656431Z","shell.execute_reply":"2022-02-19T13:21:21.665186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training loop\n\n","metadata":{"id":"83QJcq4h1Wy2"}},{"cell_type":"code","source":"oof = pd.DataFrame()\nfor i_fold in range(Config.n_fold):\n    print(f'=== fold{i_fold} training ===')\n    model, tokenizer = build_model_tokenizer()\n    model = model.to(device)\n    optimizer = torch.optim.Adam(params=model.parameters(), lr=Config.lr)\n    \n    df_train = alltrain_texts[alltrain_texts['fold'] != i_fold].reset_index(drop = True)\n    ds_train = FeedbackPrizeDataset(df_train, tokenizer, Config.max_length, True)\n    df_val = alltrain_texts[alltrain_texts['fold'] == i_fold].reset_index(drop = True)\n    val_idlist = df_val['id'].unique().tolist()\n    df_val_eval = df_alltrain.query('id==@val_idlist').reset_index(drop=True)\n    ds_val = FeedbackPrizeDataset(df_val, tokenizer, Config.max_length, True)\n    dl_train = DataLoader(ds_train, batch_size=Config.train_batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    dl_val = DataLoader(ds_val, batch_size=Config.valid_batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n    best_val_loss = np.inf\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(1, Config.n_epoch + 1):\n        train_fn(model, dl_train, optimizer, epoch, criterion)\n        valid_loss, _oof = valid_fn(model, df_val, df_val_eval, dl_val, epoch, criterion)\n        if valid_loss < best_val_loss:\n            best_val_loss = valid_loss\n            _oof_fold_best = _oof\n            _oof_fold_best['fold'] = i_fold\n            model_filename = f'{Config.model_dir}/{Config.model_savename}_{i_fold}.bin'\n            torch.save(model.state_dict(), model_filename)\n            print(f'{model_filename} saved')\n\n    oof = pd.concat([oof, _oof_fold_best])","metadata":{"id":"Z8VJd-zodQyg","outputId":"564ea0ee-d08c-4a71-bbdd-a88ce2aebd83","executionInfo":{"status":"ok","timestamp":1643462393562,"user_tz":-540,"elapsed":317208,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"execution":{"iopub.status.busy":"2022-02-19T13:21:21.668258Z","iopub.execute_input":"2022-02-19T13:21:21.66898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof.head()","metadata":{"id":"qDt2P8nznAb0","executionInfo":{"status":"ok","timestamp":1643462393562,"user_tz":-540,"elapsed":18,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"f26af2a3-51ee-4668-a21e-3bdbf5a5b6b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof.to_csv(f'{Config.output_dir}/oof_{Config.name}.csv', index=False)","metadata":{"id":"JpRQZ3rCIYTm","executionInfo":{"status":"ok","timestamp":1643462393923,"user_tz":-540,"elapsed":371,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(f'{Config.output_dir}/oof_{Config.name}.csv').head()","metadata":{"id":"VJZUUpbeIlpb","executionInfo":{"status":"ok","timestamp":1643462393924,"user_tz":-540,"elapsed":7,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"85a7837c-28dc-4a87-c7d5-4c7b9fb7fb97","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## cv score","metadata":{}},{"cell_type":"code","source":"if Config.is_debug:\n    idlist = alltrain_texts['id'].unique().tolist()\n    df_train = df_alltrain.query('id==@idlist')\nelse:\n    df_train = df_alltrain.copy()\nprint(f'overall cv score: {oof_score(df_train, oof)}')","metadata":{"id":"qoFvFhk9obhS","executionInfo":{"status":"ok","timestamp":1643462613934,"user_tz":-540,"elapsed":1212,"user":{"displayName":"y t","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRZ6fLkineSxkBHgMnfgIHRSuvYfVHMYPCUZkOvA=s64","userId":"13164130964423266686"}},"outputId":"81f759b4-3517-4d60-9882-779546a1faed","trusted":true},"execution_count":null,"outputs":[]}]}