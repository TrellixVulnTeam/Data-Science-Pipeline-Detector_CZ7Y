{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *\nfrom datasets import get_dataset_config_names, load_dataset\nimport tqdm.notebook as tqdm\n# from torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.153783Z","iopub.execute_input":"2022-03-13T16:32:36.154036Z","iopub.status.idle":"2022-03-13T16:32:36.161724Z","shell.execute_reply.started":"2022-03-13T16:32:36.154007Z","shell.execute_reply":"2022-03-13T16:32:36.161046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Test","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ntest_names, test = [], []\nfor f in list(os.listdir('../input/feedback-prize-2021/test')):\n    test_names.append(f.replace('.txt', ''))\n    test.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\ntest = pd.DataFrame({'id': test_names, 'text': test})\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.163552Z","iopub.execute_input":"2022-03-13T16:32:36.164056Z","iopub.status.idle":"2022-03-13T16:32:36.186601Z","shell.execute_reply.started":"2022-03-13T16:32:36.164015Z","shell.execute_reply":"2022-03-13T16:32:36.185994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns = [\"id\", \"context\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.188019Z","iopub.execute_input":"2022-03-13T16:32:36.188497Z","iopub.status.idle":"2022-03-13T16:32:36.192509Z","shell.execute_reply.started":"2022-03-13T16:32:36.188438Z","shell.execute_reply":"2022-03-13T16:32:36.191511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n             'Counterclaim', 'Rebuttal']","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.195069Z","iopub.execute_input":"2022-03-13T16:32:36.195884Z","iopub.status.idle":"2022-03-13T16:32:36.201932Z","shell.execute_reply.started":"2022-03-13T16:32:36.19582Z","shell.execute_reply":"2022-03-13T16:32:36.201227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['question'] = [labels for row in range(test.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.203144Z","iopub.execute_input":"2022-03-13T16:32:36.203697Z","iopub.status.idle":"2022-03-13T16:32:36.211204Z","shell.execute_reply.started":"2022-03-13T16:32:36.203656Z","shell.execute_reply":"2022-03-13T16:32:36.210551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.explode('question')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.212419Z","iopub.execute_input":"2022-03-13T16:32:36.212903Z","iopub.status.idle":"2022-03-13T16:32:36.222506Z","shell.execute_reply.started":"2022-03-13T16:32:36.212868Z","shell.execute_reply":"2022-03-13T16:32:36.221743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = test.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.223568Z","iopub.execute_input":"2022-03-13T16:32:36.226096Z","iopub.status.idle":"2022-03-13T16:32:36.23335Z","shell.execute_reply.started":"2022-03-13T16:32:36.226067Z","shell.execute_reply":"2022-03-13T16:32:36.2325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_ckpt = \"distilbert-base-cased-distilled-squad\"\nmodel_checkpoint = \"../input/q-a-pytorch/model.h5\"\n# model_checkpoint = \"distilbert-base-cased-distilled-squad\"\nconfig_model = \"../input/q-a-pytorch/model.h5/config.json\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.234747Z","iopub.execute_input":"2022-03-13T16:32:36.235274Z","iopub.status.idle":"2022-03-13T16:32:36.262182Z","shell.execute_reply.started":"2022-03-13T16:32:36.235238Z","shell.execute_reply":"2022-03-13T16:32:36.261492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.mkdir('model')\n\n# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n# tokenizer.save_pretrained('model')\n\n# #     config_model = AutoConfig.from_pretrained(model_checkpoint) \n# #     config_model.num_labels = 15\n# #     config_model.save_pretrained('model')\n\n# backbone = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n# backbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.263664Z","iopub.execute_input":"2022-03-13T16:32:36.264156Z","iopub.status.idle":"2022-03-13T16:32:36.268034Z","shell.execute_reply.started":"2022-03-13T16:32:36.26412Z","shell.execute_reply":"2022-03-13T16:32:36.267387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = tokenizer.model_max_length\nstride = 64","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.270733Z","iopub.execute_input":"2022-03-13T16:32:36.271217Z","iopub.status.idle":"2022-03-13T16:32:36.276124Z","shell.execute_reply.started":"2022-03-13T16:32:36.271181Z","shell.execute_reply":"2022-03-13T16:32:36.275459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_validation_examples(examples):\n    #strip removes leading and trailing whitespaces\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n#         offset = inputs[\"offset_mapping\"][i]\n#         inputs[\"offset_mapping\"][i] = [\n#             o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n#         ]\n\n    inputs[\"example_id\"] = example_ids\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.277099Z","iopub.execute_input":"2022-03-13T16:32:36.277575Z","iopub.status.idle":"2022-03-13T16:32:36.286466Z","shell.execute_reply.started":"2022-03-13T16:32:36.27754Z","shell.execute_reply":"2022-03-13T16:32:36.285732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.287767Z","iopub.execute_input":"2022-03-13T16:32:36.288017Z","iopub.status.idle":"2022-03-13T16:32:36.300399Z","shell.execute_reply.started":"2022-03-13T16:32:36.287982Z","shell.execute_reply":"2022-03-13T16:32:36.299722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.column_names","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.406132Z","iopub.execute_input":"2022-03-13T16:32:36.406363Z","iopub.status.idle":"2022-03-13T16:32:36.411918Z","shell.execute_reply.started":"2022-03-13T16:32:36.406336Z","shell.execute_reply":"2022-03-13T16:32:36.411011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model\nWe will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a `B` class and `I` class for each of 7 labels. And we have an additional class (called `O` class) for tokens that do not belong to one of the 14 classes.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.413929Z","iopub.execute_input":"2022-03-13T16:32:36.414468Z","iopub.status.idle":"2022-03-13T16:32:36.420474Z","shell.execute_reply.started":"2022-03-13T16:32:36.414407Z","shell.execute_reply":"2022-03-13T16:32:36.41968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:36.421819Z","iopub.execute_input":"2022-03-13T16:32:36.422387Z","iopub.status.idle":"2022-03-13T16:32:38.34692Z","shell.execute_reply.started":"2022-03-13T16:32:36.422349Z","shell.execute_reply":"2022-03-13T16:32:38.346185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_set","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.348923Z","iopub.execute_input":"2022-03-13T16:32:38.349217Z","iopub.status.idle":"2022-03-13T16:32:38.353025Z","shell.execute_reply.started":"2022-03-13T16:32:38.349181Z","shell.execute_reply":"2022-03-13T16:32:38.352371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = QuestionAnsweringPipeline(model=model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.354431Z","iopub.execute_input":"2022-03-13T16:32:38.354903Z","iopub.status.idle":"2022-03-13T16:32:38.371319Z","shell.execute_reply.started":"2022-03-13T16:32:38.354853Z","shell.execute_reply":"2022-03-13T16:32:38.370685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(question, context, text_id):\n    inputs = tokenizer(\n        question,\n        context,\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n        return_tensors = 'pt'\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = inputs.pop(\"offset_mapping\")\n#     example_ids = []\n\n#     for i in range(len(inputs[\"input_ids\"])):\n#         sample_idx = sample_map[i]\n#         example_ids.append(text_id)\n#         sequence_ids = inputs.sequence_ids(i)\n\n#     inputs[\"example_id\"] = example_ids\n    \n    return inputs, offset_mapping","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.373805Z","iopub.execute_input":"2022-03-13T16:32:38.375012Z","iopub.status.idle":"2022-03-13T16:32:38.381599Z","shell.execute_reply.started":"2022-03-13T16:32:38.374982Z","shell.execute_reply":"2022-03-13T16:32:38.38091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(outputs, inputs, offsets, context):\n    start_logits = outputs.start_logits\n    end_logits = outputs.end_logits\n    #print(start_logits.shape, end_logits.shape)\n    sequence_ids = inputs.sequence_ids()\n    # Mask everything apart from the tokens of the context\n    mask = [i != 1 for i in sequence_ids]\n    # Unmask the [CLS] token\n    mask[0] = False\n    # Mask all the [PAD] tokens\n    mask = torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] == 0))\n\n    start_logits[mask] = -10000\n    end_logits[mask] = -10000\n    start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n    end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)\n    \n    candidates = []\n    for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n        scores = start_probs[:, None] * end_probs[None, :]\n        idx = torch.triu(scores).argmax().item()\n\n        start_idx = idx // scores.shape[0]\n        end_idx = idx % scores.shape[0]\n        score = scores[start_idx, end_idx].item()\n        candidates.append((start_idx, end_idx, score))\n\n    #print(candidates)\n    results = []\n    for candidate, offset in zip(candidates, offsets):\n        start_token, end_token, score = candidate\n        start_char, _ = offset[start_token]\n        _, end_char = offset[end_token]\n        answer = context[start_char:end_char]\n        result = {\"answer\": answer, \"start\": start_char, \"end\": end_char, \"score\": score}\n        results.append(result)\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.382921Z","iopub.execute_input":"2022-03-13T16:32:38.383388Z","iopub.status.idle":"2022-03-13T16:32:38.394632Z","shell.execute_reply.started":"2022-03-13T16:32:38.383353Z","shell.execute_reply":"2022-03-13T16:32:38.393869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictionstring(result):\n    pred = result['answer']\n    if len(pred) == 0:\n        return \"\"\n    start = result['start']\n    end = result['end']\n    score = result['score']\n    start_index = len(context[:start].split())\n    end_index = start_index + len(pred.split())\n    predictionstring = \"\"\n    for i in range(start_index, end_index):\n        predictionstring += str(i) + \" \"\n    return predictionstring","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.396042Z","iopub.execute_input":"2022-03-13T16:32:38.396624Z","iopub.status.idle":"2022-03-13T16:32:38.404797Z","shell.execute_reply.started":"2022-03-13T16:32:38.396587Z","shell.execute_reply":"2022-03-13T16:32:38.404105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['predictionstring'] = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.407297Z","iopub.execute_input":"2022-03-13T16:32:38.407869Z","iopub.status.idle":"2022-03-13T16:32:38.413659Z","shell.execute_reply.started":"2022-03-13T16:32:38.407832Z","shell.execute_reply":"2022-03-13T16:32:38.412998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_dict = {}\npredictions_dict['id'] = []\npredictions_dict['class'] = []\npredictions_dict['predictionstring'] = []","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:32:38.416138Z","iopub.execute_input":"2022-03-13T16:32:38.417061Z","iopub.status.idle":"2022-03-13T16:32:38.422228Z","shell.execute_reply.started":"2022-03-13T16:32:38.417026Z","shell.execute_reply":"2022-03-13T16:32:38.421595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in dataset:\n    question = item['question']\n    text_id = item['id']\n    context = item['context']\n#     inputs, offset_mapping = preprocess(question, context, text_id)\n#     outputs = model(**inputs)\n#     results_model = get_predictions(outputs, inputs, offset_mapping, context)\n    with torch.no_grad():\n        results = pipe(question = question, context = context, top_k = 2, max_seq_len = max_length, max_answer_len = max_length)\n    for result in results:\n        predictionstring = get_predictionstring(result)\n        if len(predictionstring) == 0:\n            continue\n        predictions_dict['id'].append(text_id)\n        predictions_dict['class'].append(question)\n        predictions_dict['predictionstring'].append(predictionstring)\n#         counter += 1\n#         if counter > 3:\n#             break\n            ","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:33:24.231869Z","iopub.execute_input":"2022-03-13T16:33:24.232122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame.from_dict(predictions_dict)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:33:16.122357Z","iopub.execute_input":"2022-03-13T16:33:16.122683Z","iopub.status.idle":"2022-03-13T16:33:16.127557Z","shell.execute_reply.started":"2022-03-13T16:33:16.122644Z","shell.execute_reply":"2022-03-13T16:33:16.126661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T16:33:16.129175Z","iopub.execute_input":"2022-03-13T16:33:16.129812Z","iopub.status.idle":"2022-03-13T16:33:16.142307Z","shell.execute_reply.started":"2022-03-13T16:33:16.129768Z","shell.execute_reply":"2022-03-13T16:33:16.141581Z"},"trusted":true},"execution_count":null,"outputs":[]}]}