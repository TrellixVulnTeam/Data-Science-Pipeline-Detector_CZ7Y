{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:51.762302Z","iopub.execute_input":"2022-02-26T17:23:51.762644Z","iopub.status.idle":"2022-02-26T17:23:51.792147Z","shell.execute_reply.started":"2022-02-26T17:23:51.762547Z","shell.execute_reply":"2022-02-26T17:23:51.791384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mostly inspired by chris deotte please upvode and check out his notebook: https://www.kaggle.com/code/cdeotte/tensorflow-longformer-ner-cv-0-633","metadata":{}},{"cell_type":"code","source":"from datasets import get_dataset_config_names, load_dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:51.793718Z","iopub.execute_input":"2022-02-26T17:23:51.794634Z","iopub.status.idle":"2022-02-26T17:23:53.817851Z","shell.execute_reply.started":"2022-02-26T17:23:51.794555Z","shell.execute_reply":"2022-02-26T17:23:53.816753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qa_cols = [\"title\", \"question\", \"answers.text\",\n           \"answers.answer_start\", \"context\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:53.81901Z","iopub.execute_input":"2022-02-26T17:23:53.819282Z","iopub.status.idle":"2022-02-26T17:23:53.82472Z","shell.execute_reply.started":"2022-02-26T17:23:53.819253Z","shell.execute_reply":"2022-02-26T17:23:53.822819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How To Submit TensorFlow Without Internet\nMany people ask me, how do I submit TensorFlow models without internet? With HuggingFace Transformer, it's easy. Just download the following 3 things (1) model weights, (2) tokenizer files, (3) config file, and upload them to a Kaggle dataset. Below shows code how to get the files from HuggingFace for AllenAI's model `longformer-base`. But this same code can download any transformer, like for example `roberta-base`.","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:23:53.826153Z","iopub.execute_input":"2022-02-26T17:23:53.826629Z","iopub.status.idle":"2022-02-26T17:24:06.686025Z","shell.execute_reply.started":"2022-02-26T17:23:53.826587Z","shell.execute_reply":"2022-02-26T17:24:06.684785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/qatrain/qatrain_df.csv')\nprint( train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:06.688989Z","iopub.execute_input":"2022-02-26T17:24:06.689272Z","iopub.status.idle":"2022-02-26T17:24:13.764238Z","shell.execute_reply.started":"2022-02-26T17:24:06.689239Z","shell.execute_reply":"2022-02-26T17:24:13.763295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns = [\"id\", \"question\", \"answer\", \"answer_start\", \"answer_end\", \"context\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:13.765755Z","iopub.execute_input":"2022-02-26T17:24:13.766087Z","iopub.status.idle":"2022-02-26T17:24:13.771949Z","shell.execute_reply.started":"2022-02-26T17:24:13.766042Z","shell.execute_reply":"2022-02-26T17:24:13.771033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n             'Counterclaim', 'Rebuttal']","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:13.773468Z","iopub.execute_input":"2022-02-26T17:24:13.773745Z","iopub.status.idle":"2022-02-26T17:24:13.784625Z","shell.execute_reply.started":"2022-02-26T17:24:13.773714Z","shell.execute_reply":"2022-02-26T17:24:13.783697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = train.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:13.786367Z","iopub.execute_input":"2022-02-26T17:24:13.786612Z","iopub.status.idle":"2022-02-26T17:24:13.819439Z","shell.execute_reply.started":"2022-02-26T17:24:13.786584Z","shell.execute_reply":"2022-02-26T17:24:13.818157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_ckpt = \"distilbert-base-cased-distilled-squad\"\nmodel_checkpoint = \"distilbert-base-cased-distilled-squad\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:13.821282Z","iopub.execute_input":"2022-02-26T17:24:13.821701Z","iopub.status.idle":"2022-02-26T17:24:15.585956Z","shell.execute_reply.started":"2022-02-26T17:24:13.821653Z","shell.execute_reply":"2022-02-26T17:24:15.585264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize Train\nThe following code converts Kaggle's train dataset into a NER token array that we can use to train a NER transformer. I have made it very clear which targets belong to which class. This allows us to very easily convert this code to `Question Answer formulation` if we want. Just change the 14 NER arrays to be 14 arrays of `start position` and `end position` for each of the 7 classes. (You will need to think creatively what to do if a single text has multiple of one class).","metadata":{}},{"cell_type":"code","source":"n = IDS[0]\nname = f'../input/feedback-prize-2021/train/{n}.txt'\nname","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.587172Z","iopub.execute_input":"2022-02-26T17:24:15.587614Z","iopub.status.idle":"2022-02-26T17:24:15.592189Z","shell.execute_reply.started":"2022-02-26T17:24:15.587566Z","shell.execute_reply":"2022-02-26T17:24:15.59145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt = open(name, 'r').read()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.593442Z","iopub.execute_input":"2022-02-26T17:24:15.593854Z","iopub.status.idle":"2022-02-26T17:24:15.610938Z","shell.execute_reply.started":"2022-02-26T17:24:15.593767Z","shell.execute_reply":"2022-02-26T17:24:15.609909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt.split()[:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.612149Z","iopub.execute_input":"2022-02-26T17:24:15.612539Z","iopub.status.idle":"2022-02-26T17:24:15.622757Z","shell.execute_reply.started":"2022-02-26T17:24:15.612508Z","shell.execute_reply":"2022-02-26T17:24:15.621908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.question[0:3]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.624155Z","iopub.execute_input":"2022-02-26T17:24:15.624483Z","iopub.status.idle":"2022-02-26T17:24:15.636762Z","shell.execute_reply.started":"2022-02-26T17:24:15.624442Z","shell.execute_reply":"2022-02-26T17:24:15.636046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = train.question[0:3].to_list()\ncontext = train.context[0:3].to_list()\ninputs = tokenizer(\n    question,\n    context,\n    max_length=100,\n    truncation=\"only_second\",\n    stride=50,\n    return_overflowing_tokens=True,\n    return_offsets_mapping = True\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.640239Z","iopub.execute_input":"2022-02-26T17:24:15.640501Z","iopub.status.idle":"2022-02-26T17:24:15.656254Z","shell.execute_reply.started":"2022-02-26T17:24:15.640472Z","shell.execute_reply":"2022-02-26T17:24:15.655411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs.keys()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.657495Z","iopub.execute_input":"2022-02-26T17:24:15.657973Z","iopub.status.idle":"2022-02-26T17:24:15.663352Z","shell.execute_reply.started":"2022-02-26T17:24:15.657939Z","shell.execute_reply":"2022-02-26T17:24:15.662797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The 3 examples gave {len(inputs['input_ids'])} features.\")\nprint(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.66451Z","iopub.execute_input":"2022-02-26T17:24:15.665108Z","iopub.status.idle":"2022-02-26T17:24:15.67605Z","shell.execute_reply.started":"2022-02-26T17:24:15.665064Z","shell.execute_reply":"2022-02-26T17:24:15.675069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answers = train.answer[0:3].to_list()\nstart_positions = []\nend_positions = []\n\nfor i, offset in enumerate(inputs[\"offset_mapping\"]):\n    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n    answer = answers[sample_idx]\n    start_char = train.answer_start[i]\n    end_char = train.answer_end[i]\n    sequence_ids = inputs.sequence_ids(i)\n\n    # Find the start and end of the context\n    idx = 0\n    while sequence_ids[idx] != 1:\n        idx += 1\n    context_start = idx\n    while sequence_ids[idx] == 1:\n        idx += 1\n    context_end = idx - 1\n\n    # If the answer is not fully inside the context, label is (0, 0)\n    if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n        start_positions.append(0)\n        end_positions.append(0)\n    else:\n        # Otherwise it's the start and end token positions\n        idx = context_start\n        while idx <= context_end and offset[idx][0] <= start_char:\n            idx += 1\n        start_positions.append(idx - 1)\n\n        idx = context_end\n        while idx >= context_start and offset[idx][1] >= end_char:\n            idx -= 1\n        end_positions.append(idx + 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.677128Z","iopub.execute_input":"2022-02-26T17:24:15.677592Z","iopub.status.idle":"2022-02-26T17:24:15.693589Z","shell.execute_reply.started":"2022-02-26T17:24:15.677551Z","shell.execute_reply":"2022-02-26T17:24:15.692461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 0\nsample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\nanswer = train.answer[sample_idx]\n\nstart = start_positions[idx]\nend = end_positions[idx]\nlabeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n\nprint(f\"Theoretical answer: \\n{answer} \\nlabels give: \\n{labeled_answer}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.695258Z","iopub.execute_input":"2022-02-26T17:24:15.695783Z","iopub.status.idle":"2022-02-26T17:24:15.712433Z","shell.execute_reply.started":"2022-02-26T17:24:15.695742Z","shell.execute_reply":"2022-02-26T17:24:15.711481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 4\nsample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\nanswer = train.answer[sample_idx]\n\ndecoded_example = tokenizer.decode(inputs[\"input_ids\"][idx])\nprint(f\"Theoretical answer: \\n{answer} \\ndecoded example: \\n{decoded_example}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.715236Z","iopub.execute_input":"2022-02-26T17:24:15.716241Z","iopub.status.idle":"2022-02-26T17:24:15.728339Z","shell.execute_reply.started":"2022-02-26T17:24:15.716174Z","shell.execute_reply":"2022-02-26T17:24:15.727254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.model_max_length","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.729898Z","iopub.execute_input":"2022-02-26T17:24:15.730771Z","iopub.status.idle":"2022-02-26T17:24:15.742542Z","shell.execute_reply.started":"2022-02-26T17:24:15.730725Z","shell.execute_reply":"2022-02-26T17:24:15.74177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = tokenizer.model_max_length\nstride = 128\n\n\ndef preprocess_training_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answer\"]\n    starts = examples[\"answer_start\"]\n    ends = examples[\"answer_end\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = starts[sample_idx]\n        end_char = ends[sample_idx]\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.743667Z","iopub.execute_input":"2022-02-26T17:24:15.744157Z","iopub.status.idle":"2022-02-26T17:24:15.759608Z","shell.execute_reply.started":"2022-02-26T17:24:15.744124Z","shell.execute_reply":"2022-02-26T17:24:15.758615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(train)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:15.761038Z","iopub.execute_input":"2022-02-26T17:24:15.761327Z","iopub.status.idle":"2022-02-26T17:24:16.678802Z","shell.execute_reply.started":"2022-02-26T17:24:15.761296Z","shell.execute_reply":"2022-02-26T17:24:16.677682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:16.680222Z","iopub.execute_input":"2022-02-26T17:24:16.680453Z","iopub.status.idle":"2022-02-26T17:24:16.68608Z","shell.execute_reply.started":"2022-02-26T17:24:16.680426Z","shell.execute_reply":"2022-02-26T17:24:16.685388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset.map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=dataset.column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:24:16.687316Z","iopub.execute_input":"2022-02-26T17:24:16.687583Z","iopub.status.idle":"2022-02-26T17:27:31.346933Z","shell.execute_reply.started":"2022-02-26T17:24:16.687553Z","shell.execute_reply":"2022-02-26T17:27:31.345811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"squad\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:27:31.348495Z","iopub.execute_input":"2022-02-26T17:27:31.348797Z","iopub.status.idle":"2022-02-26T17:27:31.943309Z","shell.execute_reply.started":"2022-02-26T17:27:31.348759Z","shell.execute_reply":"2022-02-26T17:27:31.942609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:27:31.944594Z","iopub.execute_input":"2022-02-26T17:27:31.94518Z","iopub.status.idle":"2022-02-26T17:27:31.950886Z","shell.execute_reply.started":"2022-02-26T17:27:31.945144Z","shell.execute_reply":"2022-02-26T17:27:31.949867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train.loc[train.id == n]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:27:31.952669Z","iopub.execute_input":"2022-02-26T17:27:31.953006Z","iopub.status.idle":"2022-02-26T17:27:31.996436Z","shell.execute_reply.started":"2022-02-26T17:27:31.952964Z","shell.execute_reply":"2022-02-26T17:27:31.99554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:27:31.997565Z","iopub.execute_input":"2022-02-26T17:27:31.99837Z","iopub.status.idle":"2022-02-26T17:27:32.015877Z","shell.execute_reply.started":"2022-02-26T17:27:31.998334Z","shell.execute_reply":"2022-02-26T17:27:32.014767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB\")\n    wandb.login(key=api_key)\n    anonymous = None\nexcept:\n    wandb.login(anonymous='must')\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model\nWe will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a `B` class and `I` class for each of 7 labels. And we have an additional class (called `O` class) for tokens that do not belong to one of the 14 classes.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:27:32.017428Z","iopub.execute_input":"2022-02-26T17:27:32.018435Z","iopub.status.idle":"2022-02-26T17:27:32.028513Z","shell.execute_reply.started":"2022-02-26T17:27:32.018383Z","shell.execute_reply":"2022-02-26T17:27:32.027465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:27:32.030073Z","iopub.execute_input":"2022-02-26T17:27:32.030601Z","iopub.status.idle":"2022-02-26T17:27:41.701481Z","shell.execute_reply.started":"2022-02-26T17:27:32.030549Z","shell.execute_reply":"2022-02-26T17:27:41.70028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"distilbert-base-cased-distilled-squad\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=False,\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:31:43.338062Z","iopub.execute_input":"2022-02-26T17:31:43.338411Z","iopub.status.idle":"2022-02-26T17:31:43.350151Z","shell.execute_reply.started":"2022-02-26T17:31:43.338374Z","shell.execute_reply":"2022-02-26T17:31:43.349304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:31:44.154259Z","iopub.execute_input":"2022-02-26T17:31:44.154846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(\"model.h5\")","metadata":{},"execution_count":null,"outputs":[]}]}