{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *\nfrom datasets import get_dataset_config_names, load_dataset\nimport tqdm.notebook as tqdm","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:36:50.497666Z","iopub.execute_input":"2022-03-14T18:36:50.498258Z","iopub.status.idle":"2022-03-14T18:37:03.138974Z","shell.execute_reply.started":"2022-03-14T18:36:50.498195Z","shell.execute_reply":"2022-03-14T18:37:03.137964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Test","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ntest_names, test = [], []\nfor f in list(os.listdir('../input/feedback-prize-2021/test')):\n    test_names.append(f.replace('.txt', ''))\n    test.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\ntest = pd.DataFrame({'id': test_names, 'text': test})\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.141267Z","iopub.execute_input":"2022-03-14T18:37:03.141511Z","iopub.status.idle":"2022-03-14T18:37:03.19224Z","shell.execute_reply.started":"2022-03-14T18:37:03.141482Z","shell.execute_reply":"2022-03-14T18:37:03.19159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns = [\"id\", \"context\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.193438Z","iopub.execute_input":"2022-03-14T18:37:03.193744Z","iopub.status.idle":"2022-03-14T18:37:03.197668Z","shell.execute_reply.started":"2022-03-14T18:37:03.193719Z","shell.execute_reply":"2022-03-14T18:37:03.196843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n             'Counterclaim', 'Rebuttal']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.198926Z","iopub.execute_input":"2022-03-14T18:37:03.199351Z","iopub.status.idle":"2022-03-14T18:37:03.213063Z","shell.execute_reply.started":"2022-03-14T18:37:03.199313Z","shell.execute_reply":"2022-03-14T18:37:03.211974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['question'] = [labels for row in range(test.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.215598Z","iopub.execute_input":"2022-03-14T18:37:03.216232Z","iopub.status.idle":"2022-03-14T18:37:03.237539Z","shell.execute_reply.started":"2022-03-14T18:37:03.216187Z","shell.execute_reply":"2022-03-14T18:37:03.234564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.explode('question')","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.23984Z","iopub.execute_input":"2022-03-14T18:37:03.240282Z","iopub.status.idle":"2022-03-14T18:37:03.270634Z","shell.execute_reply.started":"2022-03-14T18:37:03.240249Z","shell.execute_reply":"2022-03-14T18:37:03.267088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = test.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.272339Z","iopub.execute_input":"2022-03-14T18:37:03.273368Z","iopub.status.idle":"2022-03-14T18:37:03.280454Z","shell.execute_reply.started":"2022-03-14T18:37:03.27331Z","shell.execute_reply":"2022-03-14T18:37:03.279854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_ckpt = \"distilbert-base-cased-distilled-squad\"\nmodel_checkpoint = \"../input/q-a-pytorch/model.h5\"\n# model_checkpoint = \"distilbert-base-cased-distilled-squad\"\nconfig_model = \"../input/q-a-pytorch/model.h5/config.json\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.281376Z","iopub.execute_input":"2022-03-14T18:37:03.28191Z","iopub.status.idle":"2022-03-14T18:37:03.366635Z","shell.execute_reply.started":"2022-03-14T18:37:03.281877Z","shell.execute_reply":"2022-03-14T18:37:03.36599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.mkdir('model')\n\n# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n# tokenizer.save_pretrained('model')\n\n# #     config_model = AutoConfig.from_pretrained(model_checkpoint) \n# #     config_model.num_labels = 15\n# #     config_model.save_pretrained('model')\n\n# backbone = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n# backbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.367692Z","iopub.execute_input":"2022-03-14T18:37:03.368039Z","iopub.status.idle":"2022-03-14T18:37:03.371214Z","shell.execute_reply.started":"2022-03-14T18:37:03.36801Z","shell.execute_reply":"2022-03-14T18:37:03.370497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = tokenizer.model_max_length\nstride = 64","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.372227Z","iopub.execute_input":"2022-03-14T18:37:03.372533Z","iopub.status.idle":"2022-03-14T18:37:03.383455Z","shell.execute_reply.started":"2022-03-14T18:37:03.372508Z","shell.execute_reply":"2022-03-14T18:37:03.382579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_validation_examples(examples):\n    #strip removes leading and trailing whitespaces\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n#         offset = inputs[\"offset_mapping\"][i]\n#         inputs[\"offset_mapping\"][i] = [\n#             o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n#         ]\n\n    inputs[\"example_id\"] = example_ids\n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.384591Z","iopub.execute_input":"2022-03-14T18:37:03.384809Z","iopub.status.idle":"2022-03-14T18:37:03.396861Z","shell.execute_reply.started":"2022-03-14T18:37:03.384785Z","shell.execute_reply":"2022-03-14T18:37:03.395878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.397855Z","iopub.execute_input":"2022-03-14T18:37:03.398499Z","iopub.status.idle":"2022-03-14T18:37:03.439307Z","shell.execute_reply.started":"2022-03-14T18:37:03.398461Z","shell.execute_reply":"2022-03-14T18:37:03.438659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.column_names","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.440183Z","iopub.execute_input":"2022-03-14T18:37:03.440714Z","iopub.status.idle":"2022-03-14T18:37:03.445437Z","shell.execute_reply.started":"2022-03-14T18:37:03.440678Z","shell.execute_reply":"2022-03-14T18:37:03.444472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset = dataset.map(\n    preprocess_validation_examples,\n    batched=True,\n    remove_columns=dataset.column_names,\n)\nlen(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.449Z","iopub.execute_input":"2022-03-14T18:37:03.449393Z","iopub.status.idle":"2022-03-14T18:37:03.57542Z","shell.execute_reply.started":"2022-03-14T18:37:03.449361Z","shell.execute_reply":"2022-03-14T18:37:03.574789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model\nWe will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a `B` class and `I` class for each of 7 labels. And we have an additional class (called `O` class) for tokens that do not belong to one of the 14 classes.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.576487Z","iopub.execute_input":"2022-03-14T18:37:03.577131Z","iopub.status.idle":"2022-03-14T18:37:03.58118Z","shell.execute_reply.started":"2022-03-14T18:37:03.57709Z","shell.execute_reply":"2022-03-14T18:37:03.5802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:03.582773Z","iopub.execute_input":"2022-03-14T18:37:03.583217Z","iopub.status.idle":"2022-03-14T18:37:08.848042Z","shell.execute_reply.started":"2022-03-14T18:37:03.58308Z","shell.execute_reply":"2022-03-14T18:37:08.847163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = test.question.iloc[0]\ncontext = test.context.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.84908Z","iopub.execute_input":"2022-03-14T18:37:08.849271Z","iopub.status.idle":"2022-03-14T18:37:08.853919Z","shell.execute_reply.started":"2022-03-14T18:37:08.849248Z","shell.execute_reply":"2022-03-14T18:37:08.852877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.85529Z","iopub.execute_input":"2022-03-14T18:37:08.855544Z","iopub.status.idle":"2022-03-14T18:37:08.873907Z","shell.execute_reply.started":"2022-03-14T18:37:08.855505Z","shell.execute_reply":"2022-03-14T18:37:08.872972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom transformers import default_data_collator\ndataloader = DataLoader(validation_dataset, collate_fn = default_data_collator, batch_size = 8)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.875908Z","iopub.execute_input":"2022-03-14T18:37:08.876222Z","iopub.status.idle":"2022-03-14T18:37:08.888Z","shell.execute_reply.started":"2022-03-14T18:37:08.876181Z","shell.execute_reply":"2022-03-14T18:37:08.887071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(question, context, text_id):\n    inputs = tokenizer(\n        question,\n        context,\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n        return_tensors = 'pt'\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = inputs.pop(\"offset_mapping\")\n#     example_ids = []\n\n#     for i in range(len(inputs[\"input_ids\"])):\n#         sample_idx = sample_map[i]\n#         example_ids.append(text_id)\n#         sequence_ids = inputs.sequence_ids(i)\n\n#     inputs[\"example_id\"] = example_ids\n    \n    return inputs, offset_mapping","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.889467Z","iopub.execute_input":"2022-03-14T18:37:08.889788Z","iopub.status.idle":"2022-03-14T18:37:08.901159Z","shell.execute_reply.started":"2022-03-14T18:37:08.88976Z","shell.execute_reply":"2022-03-14T18:37:08.900324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(outputs, inputs, offsets, context):\n    start_logits = outputs.start_logits\n    end_logits = outputs.end_logits\n    #print(start_logits.shape, end_logits.shape)\n    sequence_ids = inputs.sequence_ids()\n    # Mask everything apart from the tokens of the context\n    mask = [i != 1 for i in sequence_ids]\n    # Unmask the [CLS] token\n    mask[0] = False\n    # Mask all the [PAD] tokens\n    mask = torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] == 0))\n\n    start_logits[mask] = -10000\n    end_logits[mask] = -10000\n    start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n    end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)\n    print(f\"start shape {start_probabilities.shape}, end shape {end_probabilities.shape}\")\n    candidates = []\n    for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n        scores = start_probs[:, None] * end_probs[None, :]\n        idx = torch.triu(scores).argmax().item()\n\n        start_idx = idx // scores.shape[0]\n        end_idx = idx % scores.shape[0]\n        score = scores[start_idx, end_idx].item()\n        candidates.append((start_idx, end_idx, score))\n\n    #print(candidates)\n    results = []\n    for candidate, offset in zip(candidates, offsets):\n        start_token, end_token, score = candidate\n        start_char, _ = offset[start_token]\n        _, end_char = offset[end_token]\n        answer = context[start_char:end_char]\n        result = {\"answer\": answer, \"start\": start_char, \"end\": end_char, \"score\": score}\n        results.append(result)\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.902238Z","iopub.execute_input":"2022-03-14T18:37:08.902792Z","iopub.status.idle":"2022-03-14T18:37:08.921497Z","shell.execute_reply.started":"2022-03-14T18:37:08.902761Z","shell.execute_reply":"2022-03-14T18:37:08.92051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictionstring(result):\n    pred = result['answer']\n    if len(pred) == 0:\n        return \"\"\n    start = result['start']\n    end = result['end']\n    score = result['score']\n    start_index = len(context[:start].split())\n    end_index = start_index + len(pred.split())\n    predictionstring = \"\"\n    for i in range(start_index, end_index):\n        predictionstring += str(i) + \" \"\n    return predictionstring","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.922918Z","iopub.execute_input":"2022-03-14T18:37:08.923301Z","iopub.status.idle":"2022-03-14T18:37:08.940355Z","shell.execute_reply.started":"2022-03-14T18:37:08.923257Z","shell.execute_reply":"2022-03-14T18:37:08.939471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['predictionstring'] = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.941608Z","iopub.execute_input":"2022-03-14T18:37:08.942022Z","iopub.status.idle":"2022-03-14T18:37:08.955458Z","shell.execute_reply.started":"2022-03-14T18:37:08.941944Z","shell.execute_reply":"2022-03-14T18:37:08.954221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_dict = {}\npredictions_dict['id'] = []\npredictions_dict['class'] = []\npredictions_dict['predictionstring'] = []","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.956513Z","iopub.execute_input":"2022-03-14T18:37:08.957132Z","iopub.status.idle":"2022-03-14T18:37:08.971602Z","shell.execute_reply.started":"2022-03-14T18:37:08.957097Z","shell.execute_reply":"2022-03-14T18:37:08.970969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n#     counter = 0\n    for index, row in test.iterrows():\n        question = row.question\n        text_id = row.id\n        context = row.context\n        inputs, offset_mapping = preprocess(question, context, text_id)\n        outputs = model(**inputs)\n        results = get_predictions(outputs, inputs, offset_mapping, context)\n        break\n        for result in results:\n            predictionstring = get_predictionstring(result)\n            if len(predictionstring) == 0:\n                continue\n            predictions_dict['id'].append(text_id)\n            predictions_dict['class'].append(question)\n            predictions_dict['predictionstring'].append(predictionstring)\n#         counter += 1\n#         if counter > 3:\n#             break\n            ","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:08.972854Z","iopub.execute_input":"2022-03-14T18:37:08.973313Z","iopub.status.idle":"2022-03-14T18:37:10.163475Z","shell.execute_reply.started":"2022-03-14T18:37:08.973277Z","shell.execute_reply":"2022-03-14T18:37:10.162547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame.from_dict(predictions_dict)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:10.16481Z","iopub.execute_input":"2022-03-14T18:37:10.165097Z","iopub.status.idle":"2022-03-14T18:37:10.169566Z","shell.execute_reply.started":"2022-03-14T18:37:10.165066Z","shell.execute_reply":"2022-03-14T18:37:10.168681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:37:10.170998Z","iopub.execute_input":"2022-03-14T18:37:10.17154Z","iopub.status.idle":"2022-03-14T18:37:10.185882Z","shell.execute_reply.started":"2022-03-14T18:37:10.171498Z","shell.execute_reply":"2022-03-14T18:37:10.184955Z"},"trusted":true},"execution_count":null,"outputs":[]}]}