{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:23.544714Z","iopub.execute_input":"2022-03-15T07:41:23.54547Z","iopub.status.idle":"2022-03-15T07:41:23.578353Z","shell.execute_reply.started":"2022-03-15T07:41:23.545368Z","shell.execute_reply":"2022-03-15T07:41:23.577616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import get_dataset_config_names, load_dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:23.580192Z","iopub.execute_input":"2022-03-15T07:41:23.58061Z","iopub.status.idle":"2022-03-15T07:41:25.429626Z","shell.execute_reply.started":"2022-03-15T07:41:23.580568Z","shell.execute_reply":"2022-03-15T07:41:25.42891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qa_cols = [\"title\", \"question\", \"answers.text\",\n           \"answers.answer_start\", \"context\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:25.431162Z","iopub.execute_input":"2022-03-15T07:41:25.431394Z","iopub.status.idle":"2022-03-15T07:41:25.435781Z","shell.execute_reply.started":"2022-03-15T07:41:25.431362Z","shell.execute_reply":"2022-03-15T07:41:25.434943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:25.436958Z","iopub.execute_input":"2022-03-15T07:41:25.437525Z","iopub.status.idle":"2022-03-15T07:41:34.147089Z","shell.execute_reply.started":"2022-03-15T07:41:25.437475Z","shell.execute_reply":"2022-03-15T07:41:34.145834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Test","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ntest_names, test = [], []\nfor f in list(os.listdir('../input/feedback-prize-2021/test')):\n    test_names.append(f.replace('.txt', ''))\n    test.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\ntest = pd.DataFrame({'id': test_names, 'text': test})","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:34.153611Z","iopub.execute_input":"2022-03-15T07:41:34.154638Z","iopub.status.idle":"2022-03-15T07:41:34.190606Z","shell.execute_reply.started":"2022-03-15T07:41:34.154596Z","shell.execute_reply":"2022-03-15T07:41:34.188659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns = [\"id\", \"context\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:34.192126Z","iopub.execute_input":"2022-03-15T07:41:34.192591Z","iopub.status.idle":"2022-03-15T07:41:34.203442Z","shell.execute_reply.started":"2022-03-15T07:41:34.192544Z","shell.execute_reply":"2022-03-15T07:41:34.202555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n             'Counterclaim', 'Rebuttal']","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:34.207171Z","iopub.execute_input":"2022-03-15T07:41:34.207632Z","iopub.status.idle":"2022-03-15T07:41:34.215358Z","shell.execute_reply.started":"2022-03-15T07:41:34.207592Z","shell.execute_reply":"2022-03-15T07:41:34.214564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['question'] = [labels for row in range(test.shape[0])]\ntest = test.explode('question')\n#model_ckpt = \"distilbert-base-cased-distilled-squad\"\nmodel_checkpoint = \"../input/q-a-pytorch/model.h5\"\n# model_checkpoint = \"distilbert-base-cased-distilled-squad\"\nconfig_model = \"../input/q-a-pytorch/model.h5/config.json\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:34.217768Z","iopub.execute_input":"2022-03-15T07:41:34.218587Z","iopub.status.idle":"2022-03-15T07:41:34.337346Z","shell.execute_reply.started":"2022-03-15T07:41:34.218549Z","shell.execute_reply":"2022-03-15T07:41:34.336437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:41:34.33855Z","iopub.execute_input":"2022-03-15T07:41:34.338924Z","iopub.status.idle":"2022-03-15T07:41:34.34592Z","shell.execute_reply.started":"2022-03-15T07:41:34.338892Z","shell.execute_reply":"2022-03-15T07:41:34.344544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 512\nstride = 128\ndef preprocess_examples(examples):\n    #strip removes leading and trailing whitespaces\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    #offset_mapping = inputs.pop(\"offset_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n#         offset = inputs[\"offset_mapping\"][i]\n#         inputs[\"offset_mapping\"][i] = [\n#             o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n#         ]\n\n    inputs[\"example_id\"] = example_ids\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:50:45.590937Z","iopub.execute_input":"2022-03-15T07:50:45.5912Z","iopub.status.idle":"2022-03-15T07:50:45.600783Z","shell.execute_reply.started":"2022-03-15T07:50:45.59117Z","shell.execute_reply":"2022-03-15T07:50:45.599996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:43:07.404319Z","iopub.execute_input":"2022-03-15T07:43:07.404781Z","iopub.status.idle":"2022-03-15T07:43:07.414135Z","shell.execute_reply.started":"2022-03-15T07:43:07.404743Z","shell.execute_reply":"2022-03-15T07:43:07.413206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:43:07.682087Z","iopub.execute_input":"2022-03-15T07:43:07.682822Z","iopub.status.idle":"2022-03-15T07:43:07.688853Z","shell.execute_reply.started":"2022-03-15T07:43:07.682772Z","shell.execute_reply":"2022-03-15T07:43:07.687792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset.map(\n    preprocess_examples,\n    batched=True,\n    remove_columns=dataset.column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:50:53.763423Z","iopub.execute_input":"2022-03-15T07:50:53.763989Z","iopub.status.idle":"2022-03-15T07:50:54.194921Z","shell.execute_reply.started":"2022-03-15T07:50:53.76395Z","shell.execute_reply":"2022-03-15T07:50:54.194046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nmetric = load_metric(\"squad\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:43:08.761399Z","iopub.execute_input":"2022-03-15T07:43:08.762156Z","iopub.status.idle":"2022-03-15T07:43:09.479152Z","shell.execute_reply.started":"2022-03-15T07:43:08.762113Z","shell.execute_reply":"2022-03-15T07:43:09.478452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:43:09.480591Z","iopub.execute_input":"2022-03-15T07:43:09.480818Z","iopub.status.idle":"2022-03-15T07:43:09.486019Z","shell.execute_reply.started":"2022-03-15T07:43:09.480786Z","shell.execute_reply":"2022-03-15T07:43:09.48535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T08:02:56.720128Z","iopub.execute_input":"2022-03-15T08:02:56.720435Z","iopub.status.idle":"2022-03-15T08:02:58.768276Z","shell.execute_reply.started":"2022-03-15T08:02:56.720404Z","shell.execute_reply":"2022-03-15T08:02:58.767469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"distilbert-base-cased-distilled-squad\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=False,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:43:12.219055Z","iopub.execute_input":"2022-03-15T07:43:12.219296Z","iopub.status.idle":"2022-03-15T07:43:12.232904Z","shell.execute_reply.started":"2022-03-15T07:43:12.219263Z","shell.execute_reply":"2022-03-15T07:43:12.232056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:43:12.235103Z","iopub.execute_input":"2022-03-15T07:43:12.235299Z","iopub.status.idle":"2022-03-15T07:43:16.933421Z","shell.execute_reply.started":"2022-03-15T07:43:12.235275Z","shell.execute_reply":"2022-03-15T07:43:16.932725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(start_logits, end_logits, offsets, context, question):\n\n    start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n    end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)\n    \n    candidates = []\n    scores = start_probabilities * end_probabilities\n    idx = scores.argmax().item()\n\n    start_idx = start_probabilities.argmax().item()\n    end_idx = end_probabilities.argmax().item()\n    score = scores[idx]\n    candidates.append((start_idx, end_idx, score))\n\n    #print(candidates)\n    results = []\n    for candidate, offset in zip(candidates, offsets):\n        start_token, end_token, score = candidate\n        start_char, _ = offset[start_token]\n        _, end_char = offset[end_token]\n        answer = context[start_char:end_char]\n        result = {\"answer\": answer, \"start\": start_char, \"end\": end_char, \"score\": score, \"question\": questions}\n        results.append(result)\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-03-15T08:09:03.577364Z","iopub.execute_input":"2022-03-15T08:09:03.577877Z","iopub.status.idle":"2022-03-15T08:09:03.588238Z","shell.execute_reply.started":"2022-03-15T08:09:03.577834Z","shell.execute_reply":"2022-03-15T08:09:03.587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictionstring(result):\n    pred = result['answer']\n    if len(pred) == 0:\n        return \"\"\n    start = result['start']\n    end = result['end']\n    score = result['score']\n    start_index = len(context[:start].split())\n    end_index = start_index + len(pred.split())\n    predictionstring = \"\"\n    for i in range(start_index, end_index):\n        predictionstring += str(i) + \" \"\n    return predictionstring","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:52:09.036597Z","iopub.execute_input":"2022-03-15T07:52:09.037085Z","iopub.status.idle":"2022-03-15T07:52:09.042858Z","shell.execute_reply.started":"2022-03-15T07:52:09.037049Z","shell.execute_reply":"2022-03-15T07:52:09.042086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = trainer.predict(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T08:03:07.287337Z","iopub.execute_input":"2022-03-15T08:03:07.288184Z","iopub.status.idle":"2022-03-15T08:03:08.097575Z","shell.execute_reply.started":"2022-03-15T08:03:07.288137Z","shell.execute_reply":"2022-03-15T08:03:08.096894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs.predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-15T08:03:13.125432Z","iopub.execute_input":"2022-03-15T08:03:13.126137Z","iopub.status.idle":"2022-03-15T08:03:13.134314Z","shell.execute_reply.started":"2022-03-15T08:03:13.126098Z","shell.execute_reply":"2022-03-15T08:03:13.133637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n# from transformers import default_data_collator\ndataloader = DataLoader(dataset, batch_size = 1)\ntokenized_loader = DataLoader(train_dataset, batch_size = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T07:51:01.697619Z","iopub.execute_input":"2022-03-15T07:51:01.69817Z","iopub.status.idle":"2022-03-15T07:51:01.702719Z","shell.execute_reply.started":"2022-03-15T07:51:01.69813Z","shell.execute_reply":"2022-03-15T07:51:01.702008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# index = 0\n# for batch, t_batch in zip(dataloader, tokenized_loader):\n#     question = batch['question']\n#     context = batch['context']\n#     text_id = batch['id']\n#     inputs, offset_mapping = t_batch[\"input_ids\"], t_batch[\"offset_mapping\"]\n#     start_logits, end_logits = torch.Tensor(outputs.predictions[0][index]), torch.Tensor(outputs.predictions[1][index])\n#     results = get_predictions(start_logits, end_logits, inputs, offset_mapping, context)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T08:09:10.307695Z","iopub.execute_input":"2022-03-15T08:09:10.307955Z","iopub.status.idle":"2022-03-15T08:09:10.407773Z","shell.execute_reply.started":"2022-03-15T08:09:10.307928Z","shell.execute_reply":"2022-03-15T08:09:10.406817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}