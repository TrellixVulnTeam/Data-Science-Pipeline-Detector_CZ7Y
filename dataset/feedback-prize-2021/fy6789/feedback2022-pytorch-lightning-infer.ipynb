{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit to\n-  [CHRIS DEOTTE, PyTorch - BigBird - NER - [CV 0.615]](http://https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615/notebook)\n- [CPMP, Faster Metric Computation](http://https://www.kaggle.com/cpmpml/faster-metric-computation/notebook)\n\n### Training notebook is here:\n[feedback2022_pytorch lightning [Train]](https://www.kaggle.com/fangyu67/feedback2022-pytorch-lightning-train)\n\n### If you feel useful please upvote :)","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport gc\npd.set_option('display.max_columns', None)\ngc.enable()\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n#from torch.utils.data import RandomSampler, SequentialSampler,TensorDataset\nfrom torch.optim.lr_scheduler import OneCycleLR#,CosineAnnealingLR\n#from torch.optim import lr_scheduler\n\nfrom pytorch_lightning import LightningModule, LightningDataModule,Trainer\nfrom pytorch_lightning.callbacks import ModelCheckpoint,LearningRateMonitor\n\n# transformer\nfrom transformers import AutoTokenizer, AutoModel, AdamW,AutoConfig,AutoModelForTokenClassification\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:52.553897Z","iopub.execute_input":"2022-02-18T15:21:52.554887Z","iopub.status.idle":"2022-02-18T15:21:59.839766Z","shell.execute_reply.started":"2022-02-18T15:21:52.554771Z","shell.execute_reply":"2022-02-18T15:21:59.838983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ntext_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    text_names.append(f.replace('.txt', ''))\n    text = open('../input/feedback-prize-2021/test/' + f, 'r').read()\n    text=text.replace(\",\", \", \")\n    test_texts.append(text)\ntest_text_df = pd.DataFrame({'id': text_names, 'text': test_texts})\ntest_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:59.841425Z","iopub.execute_input":"2022-02-18T15:21:59.842319Z","iopub.status.idle":"2022-02-18T15:21:59.911172Z","shell.execute_reply.started":"2022-02-18T15:21:59.84228Z","shell.execute_reply":"2022-02-18T15:21:59.910453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE DICTIONARIES THAT WE CAN USE DURING TRAIN AND INFER\noutput_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}\n\n#{'O': 0,'B-Lead': 1,'I-Lead': 2,'B-Position': 3,'I-Position': 4,'B-Claim': 5,'I-Claim': 6,\n# 'B-Counterclaim': 7,'I-Counterclaim': 8,'B-Rebuttal': 9,'I-Rebuttal': 10,'B-Evidence': 11,\n#'I-Evidence': 12,'B-Concluding Statement': 13,'I-Concluding Statement': 14}","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:59.913565Z","iopub.execute_input":"2022-02-18T15:21:59.913789Z","iopub.status.idle":"2022-02-18T15:21:59.918527Z","shell.execute_reply.started":"2022-02-18T15:21:59.913753Z","shell.execute_reply":"2022-02-18T15:21:59.917762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Class","metadata":{}},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # GET TEXT AND WORD LABELS \n        text = self.data.text[index]\n        #text_id = self.data.id[index]\n\n        # TOKENIZE TEXT (use is_split_into_words)\n        encoding = self.tokenizer(text.split(),\n                             is_split_into_words=True,\n                             #return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        \n        # padding and prefix=None\n        # map token[0,0,0,1,2] to split['a.b','c','d']\n        #word_ids = encoding.word_ids()\n            \n        return {\n            'input_ids': torch.tensor(encoding['input_ids'], dtype=torch.long),\n            'attention_mask': torch.tensor(encoding['attention_mask'], dtype=torch.long),\n            #'word_ids':str(word_ids),\n            #'text_id':text_id\n        }\n\n\nclass DataModule(LightningDataModule):\n    def __init__(self, test_df, tokenizer, cfg=None):\n        super().__init__()\n        self.test_df = test_df\n        self.cfg = cfg\n        self.tokenizer = tokenizer\n\n    \n    def setup(self,stage):\n        if stage == 'fit':\n            pass\n        elif stage=='predict':\n            self.test_ds = Dataset(self.test_df, self.tokenizer, self.cfg.max_length)\n    \n    def predict_dataloader(self):\n        return DataLoader(\n            self.test_ds, batch_size=self.cfg.batch_size, \n            shuffle=False, num_workers=self.cfg.num_workers,\n            pin_memory=True\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:59.920982Z","iopub.execute_input":"2022-02-18T15:21:59.921454Z","iopub.status.idle":"2022-02-18T15:21:59.933658Z","shell.execute_reply.started":"2022-02-18T15:21:59.921418Z","shell.execute_reply":"2022-02-18T15:21:59.93289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class ModelModule(LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg=cfg\n        config = AutoConfig.from_pretrained(self.cfg['modelpath']+'/config.json')\n        self.model = AutoModelForTokenClassification.from_pretrained(self.cfg['modelpath']+'/pytorch_model.bin',config=config)\n        #self.model = AutoModel.from_pretrained(self.hparams.modelpath,config=config)\n\n    def forward(self, input_ids, attention_mask):\n        out = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        return out.logits\n    \n    def predict_step(self, batch, batch_idx):\n        logits = self(batch['input_ids'], batch['attention_mask']) # (N,seq,label)\n        return logits.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:59.934936Z","iopub.execute_input":"2022-02-18T15:21:59.935345Z","iopub.status.idle":"2022-02-18T15:21:59.95004Z","shell.execute_reply.started":"2022-02-18T15:21:59.93531Z","shell.execute_reply":"2022-02-18T15:21:59.949088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"class CFG:\n    def __init__(self):\n        self.n_procs=1\n        self.num_workers=2\n        self.precision = 16\n        self.seed=2022\n        #########################\n        self.modelpath = '../input/py-bigbird-v26'\n        self.ckppath = '../input/feedback2022/BigBird-ep5-len1024.ckpt'\n        self.tokpath = '../input/py-bigbird-v26'\n        self.max_length=1024\n        self.num_labels=15\n        self.batch_size = 4 \n\nCFG1 = CFG()\nseed_everything(CFG1.seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:59.95122Z","iopub.execute_input":"2022-02-18T15:21:59.951511Z","iopub.status.idle":"2022-02-18T15:21:59.966177Z","shell.execute_reply.started":"2022-02-18T15:21:59.951477Z","shell.execute_reply":"2022-02-18T15:21:59.965413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(CFG1.ckppath)\n    \nmodel = ModelModule(CFG1.__dict__)\nmodel.load_state_dict(torch.load(CFG1.ckppath)['state_dict'])\n#model.load_state_dict(torch.load(CFG1.ckppath))\n\ntokenizer = AutoTokenizer.from_pretrained(CFG1.tokpath,add_prefix_space=True)\ntest_loader = DataModule(test_text_df,tokenizer,CFG1)\n\ntrainer = Trainer(gpus=1,precision=CFG1.precision,num_sanity_val_steps=0)\n\npreds = trainer.predict(model, datamodule=test_loader)\npreds = np.concatenate(preds) # (N,seq,label)\n\n\n#torch.cuda.empty_cache()\n#del test_loader,trainer,model   \n#gc.collect()\n#!free -m","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:21:59.968637Z","iopub.execute_input":"2022-02-18T15:21:59.969306Z","iopub.status.idle":"2022-02-18T15:22:26.224298Z","shell.execute_reply.started":"2022-02-18T15:21:59.969267Z","shell.execute_reply":"2022-02-18T15:22:26.223524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_max1 = np.argmax(preds,axis=2) # (N,seq)\ntext_id = test_text_df['id'].values  # (N)\nword_ids = []                        # (N,seq)\nfor text in test_text_df['text']:\n    encoding = tokenizer(\n        text.split(),is_split_into_words=True,#return_offsets_mapping=True, \n        padding='max_length', truncation=True, max_length=CFG1.max_length\n    )\n    word_ids.append(encoding.word_ids())","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:22:26.2259Z","iopub.execute_input":"2022-02-18T15:22:26.226166Z","iopub.status.idle":"2022-02-18T15:22:26.263704Z","shell.execute_reply.started":"2022-02-18T15:22:26.226133Z","shell.execute_reply":"2022-02-18T15:22:26.263086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# get prediction str","metadata":{}},{"cell_type":"code","source":"def get_prediction(preds,word_ids,text_id): \n        \n        sub = pd.DataFrame(columns = ['id','class','predictionstring'])\n        \n        for k in range(len(text_id)):\n            id_ = text_id[k]\n            pred_ = [ids_to_labels[i] for i in preds[k]]\n            word_ids_ = word_ids[k]\n            \n            prediction = [] #word wise\n            previous_word_idx = -1\n            \n            for idx,word_idx in enumerate(word_ids_):                            \n                if word_idx!=None and word_idx != previous_word_idx:\n                    # use only first subword pred  \n                    prediction.append(pred_[idx])\n                    previous_word_idx = word_idx\n            j = 0\n            end = 0\n            while j < len(prediction):\n                if prediction[j]=='O':\n                    j+=1\n                else:\n                    cls = prediction[j].replace('B','I') # Take I and B\n                    end = j + 1\n                    while end < len(prediction) and prediction[end] == cls:\n                        end += 1\n                    if end - j > 5: # 7 to check\n                        sub = sub.append(\n                            pd.Series([id_, cls.replace('I-','') ,' '.join(map(str, list(range(j, end))))], index = sub.columns), \n                            ignore_index=True)\n                    j = end\n            \n        return sub\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:22:26.264945Z","iopub.execute_input":"2022-02-18T15:22:26.265181Z","iopub.status.idle":"2022-02-18T15:22:26.275838Z","shell.execute_reply.started":"2022-02-18T15:22:26.26515Z","shell.execute_reply":"2022-02-18T15:22:26.275058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = get_prediction(preds_max1,word_ids,text_id)\n#sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:22:26.278941Z","iopub.execute_input":"2022-02-18T15:22:26.279232Z","iopub.status.idle":"2022-02-18T15:22:26.36843Z","shell.execute_reply.started":"2022-02-18T15:22:26.279194Z","shell.execute_reply":"2022-02-18T15:22:26.367801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:22:26.370981Z","iopub.execute_input":"2022-02-18T15:22:26.371164Z","iopub.status.idle":"2022-02-18T15:22:26.386135Z","shell.execute_reply.started":"2022-02-18T15:22:26.371139Z","shell.execute_reply":"2022-02-18T15:22:26.385505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}