{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feedback Prize - Yet Another EDA (work in progress)\n\nThis is a EDA for data available by [Feedback Prize](https://www.kaggle.com/c/feedback-prize-2021) competition on Kaggle.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport string\nimport wordcloud\nimport spacy\nimport nltk\nfrom collections import Counter\n\nrandom.seed(42)\nsns.set(rc={'figure.figsize':(12,6)})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-16T17:17:58.435773Z","iopub.execute_input":"2021-12-16T17:17:58.436057Z","iopub.status.idle":"2021-12-16T17:17:58.443041Z","shell.execute_reply.started":"2021-12-16T17:17:58.436025Z","shell.execute_reply":"2021-12-16T17:17:58.442143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load CSV files and list of essays (I'll call a train file as an *essay*)","metadata":{}},{"cell_type":"code","source":"train_dir = \"../input/feedback-prize-2021/train\"\ntest_dir = \"../input/feedback-prize-2021/test\"\ntrain_files = os.listdir(train_dir)\ntest_files = os.listdir(test_dir)\n\nfor file in range(len(train_files)):\n    train_files[file] = str(train_dir) + \"/\" +  str(train_files[file])\nfor file in range(len(test_files)):\n    test_files[file] = str(test_dir) + \"/\" +  str(test_files[file])\n    \ndf_train = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-16T17:18:04.116313Z","iopub.execute_input":"2021-12-16T17:18:04.117193Z","iopub.status.idle":"2021-12-16T17:18:05.166476Z","shell.execute_reply.started":"2021-12-16T17:18:04.117143Z","shell.execute_reply":"2021-12-16T17:18:05.165678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T17:18:05.168247Z","iopub.execute_input":"2021-12-16T17:18:05.168454Z","iopub.status.idle":"2021-12-16T17:18:05.185528Z","shell.execute_reply.started":"2021-12-16T17:18:05.168429Z","shell.execute_reply":"2021-12-16T17:18:05.184597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analyzing label structure for first paragraph in `0000D23A521A` essay: </br></br>\n*Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens.*","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', 200)\ndf_train[df_train['id']=='0000D23A521A'][['discourse_start', 'discourse_end', 'discourse_text', 'predictionstring',  'discourse_type' ]]","metadata":{"execution":{"iopub.status.busy":"2021-12-16T17:23:49.809572Z","iopub.execute_input":"2021-12-16T17:23:49.810486Z","iopub.status.idle":"2021-12-16T17:23:49.835323Z","shell.execute_reply.started":"2021-12-16T17:23:49.810427Z","shell.execute_reply":"2021-12-16T17:23:49.834209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's possible to check that punctuation and apostrophe are included withing the word spam. For instance `mars.` or `NASAS's` counts only one position in `predictionstring`, so the correct text split looks like simple empty space.","metadata":{}},{"cell_type":"markdown","source":"He I convert some datatypes and create some counts","metadata":{}},{"cell_type":"code","source":"df_train['discourse_type'] = df_train['discourse_type'].astype('category')\ndf_train['discourse_type_num'] = df_train['discourse_type_num'].astype('category')\ndf_train['discourse_start'] = df_train['discourse_start'].astype(int)\ndf_train['discourse_end'] = df_train['discourse_end'].astype(int)\ndf_train['discourse_id'] = df_train['discourse_id'].astype('category')\ndf_train['id'] = df_train['id'].astype('category')\ndf_train['discourse_words'] = df_train['discourse_text'].apply(lambda x : len(x.split(' ')))\ndf_train['discourse_len'] = df_train['discourse_end'] - df_train['discourse_start']\ndf_train['discourse_text_lower'] = df_train['discourse_text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:27.543312Z","iopub.execute_input":"2021-12-16T16:57:27.544223Z","iopub.status.idle":"2021-12-16T16:57:28.189622Z","shell.execute_reply.started":"2021-12-16T16:57:27.54418Z","shell.execute_reply":"2021-12-16T16:57:28.18868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Some statistics from data","metadata":{}},{"cell_type":"code","source":"print(\"Total number of train files = \" , len(train_files))\nprint(\"Total number of test files = \" , len(test_files))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:28.190953Z","iopub.execute_input":"2021-12-16T16:57:28.191275Z","iopub.status.idle":"2021-12-16T16:57:28.198576Z","shell.execute_reply.started":"2021-12-16T16:57:28.191234Z","shell.execute_reply":"2021-12-16T16:57:28.197607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check if the number of unique IDs for essays are the same of train files","metadata":{}},{"cell_type":"code","source":"assert len(df_train.id.unique()) == len(train_files)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:28.199735Z","iopub.execute_input":"2021-12-16T16:57:28.199975Z","iopub.status.idle":"2021-12-16T16:57:28.208179Z","shell.execute_reply.started":"2021-12-16T16:57:28.199951Z","shell.execute_reply":"2021-12-16T16:57:28.207489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot `discourse_type` counts","metadata":{}},{"cell_type":"code","source":"ax = sns.histplot(data=df_train, x=\"discourse_type\")\nticks = plt.xticks(rotation=45)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:28.209352Z","iopub.execute_input":"2021-12-16T16:57:28.209995Z","iopub.status.idle":"2021-12-16T16:57:28.563392Z","shell.execute_reply.started":"2021-12-16T16:57:28.209964Z","shell.execute_reply":"2021-12-16T16:57:28.562549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot `discourse_type_num` grouped by `discourse_type`","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:26:24.201033Z","iopub.execute_input":"2021-12-15T15:26:24.20176Z","iopub.status.idle":"2021-12-15T15:26:24.20838Z","shell.execute_reply.started":"2021-12-15T15:26:24.201712Z","shell.execute_reply":"2021-12-15T15:26:24.207068Z"}}},{"cell_type":"code","source":"ax = sns.histplot(data=df_train, x=\"discourse_type_num\", hue='discourse_type')\nticks = plt.xticks(rotation=90)\nax = sns.barplot(\n    data=df_train, \n    x=\"discourse_type_num\", hue='discourse_type', y=np.ones(len(df_train))\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:28.564811Z","iopub.execute_input":"2021-12-16T16:57:28.565107Z","iopub.status.idle":"2021-12-16T16:57:33.956411Z","shell.execute_reply.started":"2021-12-16T16:57:28.565067Z","shell.execute_reply":"2021-12-16T16:57:33.955511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since Claim and Evidence are most frequent types, it's natural them have more items two.\n\nNow let's plot bloxplot of number of discourses by essay","metadata":{}},{"cell_type":"code","source":"df_count = df_train.groupby('id').size().reset_index(name='counts')\nax = sns.boxplot(x=df_count['counts'])\nlabels = ax.set(xlabel='Number of discourses by essay')\nprint(df_count['counts'].describe())","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:33.957616Z","iopub.execute_input":"2021-12-16T16:57:33.95784Z","iopub.status.idle":"2021-12-16T16:57:34.187773Z","shell.execute_reply.started":"2021-12-16T16:57:33.957813Z","shell.execute_reply":"2021-12-16T16:57:34.186845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot the box plot of number of words by `discourse_type`","metadata":{}},{"cell_type":"code","source":"ax = sns.boxplot(data=df_train, y='discourse_words', x='discourse_type', orient='v', showfliers = False)\nlabels = ax.set(xlabel='Number of words by discourse')\nticks = plt.xticks(rotation=45)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:34.189605Z","iopub.execute_input":"2021-12-16T16:57:34.189917Z","iopub.status.idle":"2021-12-16T16:57:34.50075Z","shell.execute_reply.started":"2021-12-16T16:57:34.189883Z","shell.execute_reply":"2021-12-16T16:57:34.499936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Text Analysis","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nstop_words = set(stopwords.words('english'))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T17:00:13.291904Z","iopub.execute_input":"2021-12-16T17:00:13.292787Z","iopub.status.idle":"2021-12-16T17:00:13.297732Z","shell.execute_reply.started":"2021-12-16T17:00:13.292732Z","shell.execute_reply":"2021-12-16T17:00:13.297068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample train essay","metadata":{}},{"cell_type":"code","source":"with open(random.sample(train_files,1)[0], \"r\") as essay:\n    print(essay.read())","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:34.512916Z","iopub.execute_input":"2021-12-16T16:57:34.513182Z","iopub.status.idle":"2021-12-16T16:57:34.524017Z","shell.execute_reply.started":"2021-12-16T16:57:34.513142Z","shell.execute_reply":"2021-12-16T16:57:34.52311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample test essay","metadata":{}},{"cell_type":"code","source":"with open(random.sample(test_files,1)[0], \"r\") as essay:\n    print(essay.read())","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:57:34.525127Z","iopub.execute_input":"2021-12-16T16:57:34.525953Z","iopub.status.idle":"2021-12-16T16:57:34.535153Z","shell.execute_reply.started":"2021-12-16T16:57:34.525909Z","shell.execute_reply":"2021-12-16T16:57:34.534235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Let's visualize discourses type on a sample essay text</b>\n","metadata":{}},{"cell_type":"code","source":"## code from: https://www.kaggle.com/odins0n/feedback-prize-eda\n\nsample_essay = random.sample(train_files,1)[0]\nsample_id = sample_essay.split('/')[-1][:-4]\n                                        \nents = []\nfor i, row in df_train[df_train['id'] == sample_id].iterrows():\n    ents.append({\n                    'start': int(row['discourse_start']), \n                     'end': int(row['discourse_end']), \n                     'label': row['discourse_type']\n                })\n\nwith open(sample_essay, 'r') as file: \n    data = file.read()\n\ndoc2 = {\n    \"text\": data,\n    \"ents\": ents,\n}\n\ncolors = {'Lead': '#EE11D0','Position': '#AB4DE1','Claim': '#1EDE71','Evidence': '#33FAFA',\n          'Counterclaim': '#4253C1','Concluding Statement': 'yellow','Rebuttal': 'red'}\noptions = {\"ents\": df_train['discourse_type'].unique().tolist(), \"colors\": colors}\nspacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);","metadata":{"execution":{"iopub.status.busy":"2021-12-16T17:00:24.719368Z","iopub.execute_input":"2021-12-16T17:00:24.720307Z","iopub.status.idle":"2021-12-16T17:00:24.73687Z","shell.execute_reply.started":"2021-12-16T17:00:24.720264Z","shell.execute_reply":"2021-12-16T17:00:24.736261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Important to notice that several labels consists of multiple sentences and not all text on essay has a label**.","metadata":{}},{"cell_type":"markdown","source":"Word Cloud from train data. I removed stop words, punctuation and converted to lower case","metadata":{}},{"cell_type":"code","source":"all_text = df_train['discourse_text'].str.cat(sep=' ').translate(str.maketrans('', '', string.punctuation))\nimg_wordcloud = wordcloud.WordCloud(stopwords=wordcloud.STOPWORDS, background_color='black').generate(all_text)\nax = plt.imshow(img_wordcloud, interpolation='bilinear')\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:53:45.823855Z","iopub.execute_input":"2021-12-16T11:53:45.824163Z","iopub.status.idle":"2021-12-16T11:54:10.120363Z","shell.execute_reply.started":"2021-12-16T11:53:45.824134Z","shell.execute_reply":"2021-12-16T11:54:10.119656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's vizualize for test data","metadata":{}},{"cell_type":"code","source":"all_test_text = ''\nfor test_file in test_files:\n    with open(test_file) as file:\n        all_test_text += ' ' + file.read().translate(str.maketrans('', '', string.punctuation)).lower()\nimg_wordcloud = wordcloud.WordCloud(stopwords=wordcloud.STOPWORDS, background_color='black').generate(all_test_text)\nax = plt.imshow(img_wordcloud, interpolation='bilinear')\nax = plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:54:10.121389Z","iopub.execute_input":"2021-12-16T11:54:10.121934Z","iopub.status.idle":"2021-12-16T11:54:10.840917Z","shell.execute_reply.started":"2021-12-16T11:54:10.121902Z","shell.execute_reply":"2021-12-16T11:54:10.839792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The images are a little differents, but we can see some words in both clouds.\n\nNow let's count word frequency for each type of discourse","metadata":{}},{"cell_type":"code","source":"df_wordfreq = (df_train.set_index('discourse_type')['discourse_text_lower']\n       .str.split(' ', expand=True)\n       .stack()\n       .rename('discourse_type_lower')\n       .reset_index(name='discourse_word'))\n#df_wordfreq.head()\ndiscourse_text_by_type = {}\nfor discourse_type in df_train['discourse_type'].unique():\n    df_temp = df_wordfreq[df_wordfreq['discourse_type']==discourse_type]\n    discourse_text_by_type[discourse_type] = df_temp['discourse_word'].str.cat(\n        sep=' ').translate(str.maketrans('', '', string.punctuation))   ","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:54:10.842685Z","iopub.execute_input":"2021-12-16T11:54:10.843327Z","iopub.status.idle":"2021-12-16T11:55:04.081239Z","shell.execute_reply.started":"2021-12-16T11:54:10.843281Z","shell.execute_reply":"2021-12-16T11:55:04.080171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for discourse_type, text in discourse_text_by_type.items():\n    text_without_stop = [w for w in word_tokenize(text) if not w in stop_words]\n    cnt = Counter(text_without_stop)\n    print(' --------  Most common words for discourse type ', discourse_type, '---------- \\n')\n    print(cnt.most_common(10), '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:04.082492Z","iopub.execute_input":"2021-12-16T11:55:04.082743Z","iopub.status.idle":"2021-12-16T11:55:46.048647Z","shell.execute_reply.started":"2021-12-16T11:55:04.082695Z","shell.execute_reply":"2021-12-16T11:55:46.047484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Entity recognition using Spacy","metadata":{}},{"cell_type":"code","source":"from pandarallel import pandarallel\npandarallel.initialize()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:46.049929Z","iopub.execute_input":"2021-12-16T11:55:46.050159Z","iopub.status.idle":"2021-12-16T11:55:46.149437Z","shell.execute_reply.started":"2021-12-16T11:55:46.050129Z","shell.execute_reply":"2021-12-16T11:55:46.148641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'lemmatizer', 'textcat'])\n\ndef show_ents(row):\n    ents = []\n    doc = nlp(row)\n    if doc.ents: \n        ents = [ent.text for ent in doc.ents]\n    return ents\n\ndf_train['spacy_entities'] = df_train['discourse_text'].parallel_apply(show_ents)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:46.151053Z","iopub.execute_input":"2021-12-16T11:55:46.15135Z","iopub.status.idle":"2021-12-16T12:04:56.444104Z","shell.execute_reply.started":"2021-12-16T11:55:46.151319Z","shell.execute_reply":"2021-12-16T12:04:56.4431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's print the most commont entities by `discourse_type`","metadata":{}},{"cell_type":"code","source":"df_wordfreq = (df_train.set_index('discourse_type').apply(lambda x: pd.Series(x['spacy_entities']),axis=1).stack()\n       .rename('spacy_entities')\n       .reset_index(name='spacy_entities'))\n\ndiscourse_entities_by_type = {}\nfor discourse_type in df_train['discourse_type'].unique():\n    df_temp = df_wordfreq[df_wordfreq['discourse_type']==discourse_type]\n    discourse_entities_by_type[discourse_type] = df_temp['spacy_entities'].to_list()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T12:04:56.446007Z","iopub.execute_input":"2021-12-16T12:04:56.446366Z","iopub.status.idle":"2021-12-16T12:06:05.969672Z","shell.execute_reply.started":"2021-12-16T12:04:56.44632Z","shell.execute_reply":"2021-12-16T12:06:05.968967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for discourse_type, text in discourse_entities_by_type.items():\n    cnt = Counter(text)\n    print(' --------  Most common Entities for discourse type ', discourse_type, '---------- \\n')\n    print(cnt.most_common(10), '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T12:06:05.970998Z","iopub.execute_input":"2021-12-16T12:06:05.971757Z","iopub.status.idle":"2021-12-16T12:06:06.019578Z","shell.execute_reply.started":"2021-12-16T12:06:05.971712Z","shell.execute_reply":"2021-12-16T12:06:06.018735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}