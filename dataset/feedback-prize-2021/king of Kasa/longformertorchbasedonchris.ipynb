{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm\n","metadata":{"id":"x3z7K19x8xtL","execution":{"iopub.status.busy":"2021-12-24T09:33:58.160073Z","iopub.execute_input":"2021-12-24T09:33:58.160395Z","iopub.status.idle":"2021-12-24T09:34:04.732579Z","shell.execute_reply.started":"2021-12-24T09:33:58.160313Z","shell.execute_reply":"2021-12-24T09:34:04.731587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    model_name = '../input/allenailongformerbase4096'\n    max_length = 1024\n    train_batch_size = 4\n    valid_batch_size = 4\n    epochs = 5\n    learning_rates = [2e-5,2e-5,2e-5,2e-5,2e-6]\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    seed = 318\n    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n    bert_lr = 1e-3","metadata":{"id":"IiOpayAB9uMP","outputId":"53aebc8a-d4ec-4c41-9dd9-faf7b6ae8f64","execution":{"iopub.status.busy":"2021-12-24T09:34:05.916888Z","iopub.execute_input":"2021-12-24T09:34:05.917475Z","iopub.status.idle":"2021-12-24T09:34:05.9978Z","shell.execute_reply.started":"2021-12-24T09:34:05.917436Z","shell.execute_reply":"2021-12-24T09:34:05.997028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain_df","metadata":{"id":"LDyXKVoe9_mm","outputId":"9f168426-9e1d-4efe-b4cf-fbb3c3deb837","execution":{"iopub.status.busy":"2021-12-24T09:34:19.046875Z","iopub.execute_input":"2021-12-24T09:34:19.047131Z","iopub.status.idle":"2021-12-24T09:34:20.832106Z","shell.execute_reply.started":"2021-12-24T09:34:19.047104Z","shell.execute_reply":"2021-12-24T09:34:20.831375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ntest_names, test_texts = [], []\nfor f in list(os.listdir('../input/feedback-prize-2021/test')):\n    test_names.append(f.replace('.txt',''))\n    test_texts.append(open('../input/feedback-prize-2021/test/'+f).read())\ntest_texts = pd.DataFrame({\"id\":test_names,'text':test_texts})\ntest_texts","metadata":{"id":"H3cZ5jJG9_pa","outputId":"c2402e75-2241-40e4-8e49-5f145cfcc48e","execution":{"iopub.status.busy":"2021-12-24T09:35:22.632582Z","iopub.execute_input":"2021-12-24T09:35:22.633286Z","iopub.status.idle":"2021-12-24T09:35:22.659115Z","shell.execute_reply.started":"2021-12-24T09:35:22.633246Z","shell.execute_reply":"2021-12-24T09:35:22.658404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ntrain_names, train_texts = [], []\nfor f in list(os.listdir('../input/feedback-prize-2021/train')):\n    train_names.append(f.replace('.txt',''))\n    train_texts.append(open('../input/feedback-prize-2021/train/'+f).read())\ntrain_texts = pd.DataFrame({\"id\":train_names,'text':train_texts})\ntrain_texts","metadata":{"id":"lHtxeO4T9_sZ","outputId":"68788e26-8cb2-4972-d21a-cfd9809c4a83","execution":{"iopub.status.busy":"2021-12-24T09:35:37.310618Z","iopub.execute_input":"2021-12-24T09:35:37.311194Z","iopub.status.idle":"2021-12-24T09:35:44.235149Z","shell.execute_reply.started":"2021-12-24T09:35:37.311155Z","shell.execute_reply":"2021-12-24T09:35:44.234477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_entities = []\nfor i, item in enumerate(train_texts.iterrows()):\n    if i % 100 == 0: print(i, \", \", end=\"\")\n    total = len(item[1]['text'].split())\n    entities = ['O'] * total\n    for j in train_df[train_df['id']==item[1]['id']].iterrows():\n        discourse = j[1]['discourse_type']\n        list_idx = [int(x) for x in j[1]['predictionstring'].split()]\n        entities[list_idx[0]] = f'B-{discourse}'\n        for k in list_idx[1:]:\n            entities[k] = f'I-{discourse}'\n        \n    all_entities.append(entities)\ntrain_texts['entities'] = all_entities\n    \n","metadata":{"id":"vlG713mG_IyN","outputId":"c2792fc3-0153-49bc-c61f-770b8ddd6be0","execution":{"iopub.status.busy":"2021-12-24T09:35:44.23685Z","iopub.execute_input":"2021-12-24T09:35:44.237097Z","iopub.status.idle":"2021-12-24T09:41:13.026971Z","shell.execute_reply.started":"2021-12-24T09:35:44.237063Z","shell.execute_reply":"2021-12-24T09:41:13.026213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts","metadata":{"id":"GiiUDKPh_I03","outputId":"3abcc46f-6c43-4b46-84bc-9aef5ee0eede","execution":{"iopub.status.busy":"2021-12-24T09:41:13.028397Z","iopub.execute_input":"2021-12-24T09:41:13.028661Z","iopub.status.idle":"2021-12-24T09:41:13.054628Z","shell.execute_reply.started":"2021-12-24T09:41:13.028617Z","shell.execute_reply":"2021-12-24T09:41:13.053991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}","metadata":{"id":"4SdOMDGj_I3P","execution":{"iopub.status.busy":"2021-12-24T09:41:13.056872Z","iopub.execute_input":"2021-12-24T09:41:13.057209Z","iopub.status.idle":"2021-12-24T09:41:13.062126Z","shell.execute_reply.started":"2021-12-24T09:41:13.057172Z","shell.execute_reply":"2021-12-24T09:41:13.061458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABEL_ALL_SUBTOKENS = False\n\nclass MyDataset(Dataset):\n  def __init__(self, dataframe,get_wids):\n        \n        self.data = dataframe\n        self.tokenizer = Config.tokenizer\n        self.max_len = Config.max_length\n        self.get_wids = get_wids # for validation\n\n  def __getitem__(self, index):\n        # GET TEXT AND WORD LABELS \n        text = self.data.text[index]        \n        word_labels = self.data.entities[index] if not self.get_wids else None\n\n        # TOKENIZE TEXT\n        encoding = self.tokenizer(text.split(),\n                             is_split_into_words=True,\n                             #return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        word_ids = encoding.word_ids()  \n        \n        # CREATE TARGETS\n        if not self.get_wids:\n            previous_word_idx = None\n            label_ids = []\n            for word_idx in word_ids:                            \n                if word_idx is None:\n                    label_ids.append(-100)\n                elif word_idx != previous_word_idx:              \n                    # print(word_labels[word_idx])\n                    label_ids.append( labels_to_ids[word_labels[word_idx]] )\n                else:\n                    if LABEL_ALL_SUBTOKENS:\n                        label_ids.append( labels_to_ids[word_labels[word_idx]] )\n                    else:\n                        label_ids.append(-100)\n                previous_word_idx = word_idx\n            encoding['labels'] = label_ids\n\n        # CONVERT TO TORCH TENSORS\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n        if self.get_wids: \n            word_ids2 = [w if w is not None else -1 for w in word_ids]\n            item['wids'] = torch.as_tensor(word_ids2)\n        \n        return item\n\n  def __len__(self):\n        return len(self.data)","metadata":{"id":"jYShr4SK_I5y","execution":{"iopub.status.busy":"2021-12-24T09:41:13.063353Z","iopub.execute_input":"2021-12-24T09:41:13.063761Z","iopub.status.idle":"2021-12-24T09:41:13.080772Z","shell.execute_reply.started":"2021-12-24T09:41:13.063725Z","shell.execute_reply":"2021-12-24T09:41:13.080009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nIDS = train_texts.id.unique()\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nset_seed(Config.seed)","metadata":{"id":"wUjcAuw8_I8K","execution":{"iopub.status.busy":"2021-12-24T09:41:13.082085Z","iopub.execute_input":"2021-12-24T09:41:13.08259Z","iopub.status.idle":"2021-12-24T09:41:13.101415Z","shell.execute_reply.started":"2021-12-24T09:41:13.082552Z","shell.execute_reply":"2021-12-24T09:41:13.100716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)), train_idx)","metadata":{"id":"TInYSXZy_I_n","execution":{"iopub.status.busy":"2021-12-24T09:41:13.103037Z","iopub.execute_input":"2021-12-24T09:41:13.103352Z","iopub.status.idle":"2021-12-24T09:41:13.114374Z","shell.execute_reply.started":"2021-12-24T09:41:13.103315Z","shell.execute_reply":"2021-12-24T09:41:13.113642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train_texts[['id','text','entities']]\ntrain_dataset = data.loc[data['id'].isin(IDS[train_idx]), ['text', 'entities']].reset_index(drop=True)\ntest_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntrain_dataset = MyDataset(train_dataset,False)\ntest_dataset = MyDataset(test_dataset,False)","metadata":{"id":"vreSlHnS_JCI","outputId":"eb780c17-6c6e-42dc-f80e-c0f654baf590","execution":{"iopub.status.busy":"2021-12-24T09:47:16.020446Z","iopub.execute_input":"2021-12-24T09:47:16.021283Z","iopub.status.idle":"2021-12-24T09:47:16.045912Z","shell.execute_reply.started":"2021-12-24T09:47:16.021245Z","shell.execute_reply":"2021-12-24T09:47:16.045196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, \n                              batch_size=Config.train_batch_size,\n                              shuffle=True,\n                              num_workers=2,\n                              pin_memory=True)\ntest_dataloader = DataLoader(test_dataset,\n                             batch_size=Config.valid_batch_size,\n                             shuffle=False,\n                             num_workers=2,\n                             pin_memory=True)","metadata":{"id":"fCTi2C839_yK","execution":{"iopub.status.busy":"2021-12-24T09:47:16.476038Z","iopub.execute_input":"2021-12-24T09:47:16.476369Z","iopub.status.idle":"2021-12-24T09:47:16.484638Z","shell.execute_reply.started":"2021-12-24T09:47:16.476329Z","shell.execute_reply":"2021-12-24T09:47:16.48315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(Config.model_name)\n        self.ffn1 = nn.Linear(768, 15)\n        # self.ffn2 = nn.Linear(128, 15)\n        # self.relu = nn.ReLU()\n        self.softmax = nn.Softmax()\n        self.dropout = nn.Dropout(0.1)\n    def forward(self,input_ids, attention_mask):\n        output = self.bert(input_ids, attention_mask)['last_hidden_state']\n        output = self.dropout(output)\n        output = self.ffn1(output)\n        # output = self.relu(output)\n        # output = self.ffn2(output)\n        output = self.softmax(output)\n        return output","metadata":{"id":"yzxGlAX4Nnf3","execution":{"iopub.status.busy":"2021-12-24T09:41:13.153656Z","iopub.execute_input":"2021-12-24T09:41:13.155657Z","iopub.status.idle":"2021-12-24T09:41:13.161845Z","shell.execute_reply.started":"2021-12-24T09:41:13.155619Z","shell.execute_reply":"2021-12-24T09:41:13.161099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    model.train()\n    running_loss = 0\n    data_size = 0\n    for step, batch in bar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        loss_fn = nn.CrossEntropyLoss()\n\n        batch_size = input_ids.size(0)\n        output = model(input_ids,attention_mask)\n        output = torch.permute(output,(0,2,1))\n        # print(label.shape)\n        # print(output.shape)\n        \n        loss = loss_fn(output, labels)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        scheduler.step()\n\n        running_loss += loss.item() * batch_size\n        data_size += batch_size\n        epoch_loss = running_loss / data_size\n        bar.set_postfix(EPOCH=epoch, TRAINING_LOSS=\"{:.6f}\".format(epoch_loss))\n    return epoch_loss\n\n","metadata":{"id":"ePZM38-aNno2","execution":{"iopub.status.busy":"2021-12-24T09:41:13.16309Z","iopub.execute_input":"2021-12-24T09:41:13.163494Z","iopub.status.idle":"2021-12-24T09:41:13.1755Z","shell.execute_reply.started":"2021-12-24T09:41:13.163456Z","shell.execute_reply":"2021-12-24T09:41:13.174713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_one_epoch(model, data_loader, device, epoch):\n    model.eval()\n    data_size = 0\n    running_loss = 0\n    bar = tqdm(enumerate(data_loader), total=len(data_loader))\n\n    for step, batch in bar:\n        with torch.no_grad():\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            output = model(input_ids, attention_mask)\n            output = torch.permute(output,(0,2,1))\n            batch_size = input_ids.size(0)\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(output, labels)\n\n            running_loss += loss.item() * batch_size\n            data_size += batch_size\n            epoch_loss = running_loss / data_size\n            bar.set_postfix(EPOCH=epoch, VALIDATION_LOSS=\"{:.6f}\".format(epoch_loss))\n    return epoch_loss\n\n\n","metadata":{"id":"HJPLVYSDNnrl","execution":{"iopub.status.busy":"2021-12-24T09:41:13.178475Z","iopub.execute_input":"2021-12-24T09:41:13.178971Z","iopub.status.idle":"2021-12-24T09:41:13.187422Z","shell.execute_reply.started":"2021-12-24T09:41:13.178916Z","shell.execute_reply":"2021-12-24T09:41:13.18659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\nfrom collections import defaultdict\n\n\ndef train(model, num_epochs, training_dataloader, validation_dataloader, device):\n    best_model_weights = copy.deepcopy(model.state_dict())\n    best_epoch_loss = float('inf')\n    history = defaultdict(list)\n    optimizer = AdamW([\n        {'params': model.bert.parameters()},\n        {'params': model.ffn1.parameters()},\n        # {'params': model.ffn2.parameters()}\n    ], lr=Config.bert_lr)\n\n    num_train_steps = len(training_dataloader.dataset) / Config.train_batch_size * Config.epochs\n    num_warm_steps = int(num_train_steps * 0.1)\n\n    scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                num_warmup_steps=num_warm_steps,\n                                                num_training_steps=num_train_steps)\n\n    for epoch in range(1, num_epochs + 1):\n        train_epoch_loss = train_one_epoch(model,\n                                           optimizer,\n                                           scheduler,\n                                           training_dataloader,\n                                           device,\n                                           epoch)\n        valid_epoch_loss = valid_one_epoch(\n                        model,\n                        validation_dataloader,                                                              \n                        device,\n                        epoch)\n#(model, data_loader, device, epoch\n        history['TRAINING_LOSS'].append(train_epoch_loss)\n        history['VALIDATION_LOSS'].append(valid_epoch_loss)\n\n        if valid_epoch_loss < best_epoch_loss:\n            print(\"The best loss was {}, current loss was{}\".format(best_epoch_loss, valid_epoch_loss))\n            best_epoch_loss = valid_epoch_loss\n            best_model_weights = copy.deepcopy(model.state_dict)\n            PATH = f'model.bin'\n            torch.save(model.state_dict, PATH)\n    return model, history\n","metadata":{"id":"XfDVgxTB9_08","execution":{"iopub.status.busy":"2021-12-24T09:41:13.190136Z","iopub.execute_input":"2021-12-24T09:41:13.190607Z","iopub.status.idle":"2021-12-24T09:41:13.20199Z","shell.execute_reply.started":"2021-12-24T09:41:13.190571Z","shell.execute_reply":"2021-12-24T09:41:13.201283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel.to(Config.device)\ntrain(model, Config.epochs, train_dataloader, test_dataloader, Config.device)","metadata":{"id":"eJQ7vb_zU2Ax","outputId":"42b9a798-58b0-4d87-c375-3f8157e73fbd","execution":{"iopub.status.busy":"2021-12-24T09:41:13.204868Z","iopub.execute_input":"2021-12-24T09:41:13.206736Z","iopub.status.idle":"2021-12-24T09:41:25.819845Z","shell.execute_reply.started":"2021-12-24T09:41:13.206694Z","shell.execute_reply":"2021-12-24T09:41:25.81758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"vJfSQJysU2C8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Model()\n# model.to(Config.device)\n","metadata":{"id":"Pk7k-PqMU2FZ","execution":{"iopub.status.busy":"2021-12-24T09:56:48.893451Z","iopub.execute_input":"2021-12-24T09:56:48.893758Z","iopub.status.idle":"2021-12-24T09:56:51.128251Z","shell.execute_reply.started":"2021-12-24T09:56:48.893727Z","shell.execute_reply":"2021-12-24T09:56:51.127562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_names, test_texts = [], []\n# for f in list(os.listdir('../input/feedback-prize-2021/test')):\n#     test_names.append(f.replace('.txt',''))\n#     test_texts.append(open('../input/feedback-prize-2021/test/'+f).read())\n\n# test_texts = pd.DataFrame({'id':test_names, 'text':test_texts})\n# test_dataset = MyDataset(test_texts, True)\n# test_texts_loader = DataLoader(test_dataset, \n#                                batch_size=Config.valid_batch_size,\n#                                shuffle=False,\n#                                num_workers=2,\n#                                pin_memory=True\n#                                )","metadata":{"id":"VSbjcCUBhmM1","execution":{"iopub.status.busy":"2021-12-24T09:56:51.129778Z","iopub.execute_input":"2021-12-24T09:56:51.1301Z","iopub.status.idle":"2021-12-24T09:56:51.14619Z","shell.execute_reply.started":"2021-12-24T09:56:51.130062Z","shell.execute_reply":"2021-12-24T09:56:51.145375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def inference(model, batch):\n#     input_ids = batch['input_ids'].to(Config.device)\n#     attention_mask = batch['attention_mask'].to(Config.device)\n#     outputs = model(input_ids, attention_mask)\n    \n#     all_preds = torch.argmax(outputs, axis=-1).cpu().numpy()\n#     print(all_preds.shape)\n#     predictions = []\n#     for k, text_preds in enumerate(all_preds):\n#         token_preds = [ids_to_labels[i] for i in text_preds]\n\n#         prediction = []\n#         word_ids = batch['wids'][k].numpy()\n#         previous_word_idx = -1\n#         for idx, word_idx in enumerate(word_ids):\n#             if word_idx == -1:\n#                 pass\n            \n#             elif word_idx != previous_word_idx:\n#                 prediction.append(token_preds[idx])\n#                 previous_word_idx = word_idx\n#         predictions.append(prediction)\n#     return predictions\n\n","metadata":{"id":"EsEjnwRkhmPO","execution":{"iopub.status.busy":"2021-12-24T09:57:17.048901Z","iopub.execute_input":"2021-12-24T09:57:17.049271Z","iopub.status.idle":"2021-12-24T09:57:17.05726Z","shell.execute_reply.started":"2021-12-24T09:57:17.04923Z","shell.execute_reply":"2021-12-24T09:57:17.056557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_predictions(model, df, dataloader):\n#     model.eval()\n#     y_pred2 = []\n#     for i, batch in enumerate(dataloader):\n#         labels = inference(model, batch)\n#         y_pred2.extend(labels)\n#     final_preds2 = []\n#     for i in range(len(df)):\n#         idx = df.id.values[i]\n#         pred = y_pred2[i]\n#         preds = []\n#         j = 0\n#         while j < len(pred):\n#             cls = pred[j]\n#             if cls == 'O': j += 1\n#             else: cls = cls.replace(\"B\",\"I\")\n#             end = j + 1\n\n#             while end < len(pred) and pred[end] == cls:\n#                 end += 1\n#             if cls != \"O\" and cls != \"\" and end - j >7:\n#                 final_preds2.append((idx,cls.replace(\"I-\",\"\"),\" \".join(map(str, list(range(j, end))))))\n            \n#             j = end\n        \n#     oof = pd.DataFrame(final_preds2)\n#     oof.columns = ['id','class','predictionstring']\n#     return oof\n    \n","metadata":{"id":"lzP4oCZBhmR1","execution":{"iopub.status.busy":"2021-12-24T09:57:17.736848Z","iopub.execute_input":"2021-12-24T09:57:17.737722Z","iopub.status.idle":"2021-12-24T09:57:17.746596Z","shell.execute_reply.started":"2021-12-24T09:57:17.737673Z","shell.execute_reply":"2021-12-24T09:57:17.745946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = get_predictions(model, test_texts, test_texts_loader)","metadata":{"id":"PN3MKNoqhmUd","execution":{"iopub.status.busy":"2021-12-24T09:57:18.014756Z","iopub.execute_input":"2021-12-24T09:57:18.015491Z","iopub.status.idle":"2021-12-24T09:57:18.59715Z","shell.execute_reply.started":"2021-12-24T09:57:18.015441Z","shell.execute_reply":"2021-12-24T09:57:18.595902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Ki2U2FZHhmXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"cplHgOQThmZ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"0hk6NI45U2K0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-roberta-base\",add_prefix_space=True)\n# model = AutoModel.from_pretrained(Config.model_name)","metadata":{"id":"eZj8e80G9_3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sentences = \"Go Home RIGHT NOW!\"\n# inputs = tokenizer(sentences.split(),\n#                    is_split_into_words=True,\n#                    padding='max_length',\n# #                    max_length=1024)","metadata":{"id":"-eP42C3vGFaj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inputs.word_ids()","metadata":{"id":"ejVsF4_dGav1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output = model(torch.tensor([inputs['input_ids']]),torch.tensor([inputs['attention_mask']]))","metadata":{"id":"AOW5813iGhh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output.keys()","metadata":{"id":"BfzQZV8APei9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1ECW7YcuP0cK"},"execution_count":null,"outputs":[]}]}