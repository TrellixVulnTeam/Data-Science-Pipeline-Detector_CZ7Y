{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\ngc.enable()\n\nimport os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Dense\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import AutoTokenizer, AutoConfig, TFAutoModel\nprint('TF version',tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:18:55.664819Z","iopub.execute_input":"2022-03-10T12:18:55.665193Z","iopub.status.idle":"2022-03-10T12:19:02.384088Z","shell.execute_reply.started":"2022-03-10T12:18:55.665104Z","shell.execute_reply":"2022-03-10T12:19:02.382643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DECLARE HOW MANY GPUS YOU WISH TO USE. \n# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n\n# VERSION FOR SAVING/LOADING MODEL WEIGHTS\nVER=14 \n# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\nLOAD_TOKENS_FROM = '../input/tf-longformer-v12'\n# IF FOLLOWING IS NONE, THEN NOTEBOOK \n# USES INTERNET AND DOWNLOADS HUGGINGFACE \n# CONFIG, TOKENIZER, AND MODEL\nDOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\nLOAD_MODEL_FROM = '../input/tflongformerv14'\n# https://huggingface.co/allenai/longformer-base-4096\nMODEL_NAME = 'allenai/longformer-base-4096'","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:02.385866Z","iopub.execute_input":"2022-03-10T12:19:02.386123Z","iopub.status.idle":"2022-03-10T12:19:02.393467Z","shell.execute_reply.started":"2022-03-10T12:19:02.386088Z","shell.execute_reply":"2022-03-10T12:19:02.391991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    MAX_LEN = 1024\n    # LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\n    EPOCHS = 5\n    BATCH_SIZE = 4 \n    LRS = [0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5] \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:02.394881Z","iopub.execute_input":"2022-03-10T12:19:02.395325Z","iopub.status.idle":"2022-03-10T12:19:02.40475Z","shell.execute_reply.started":"2022-03-10T12:19:02.395277Z","shell.execute_reply":"2022-03-10T12:19:02.403974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MULTIPLE GPUS\nif os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n    strategy = tf.distribute.get_strategy()\n    print('single strategy')\nelse:\n    strategy = tf.distribute.MirroredStrategy()\n    print('multiple strategy')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:02.406951Z","iopub.execute_input":"2022-03-10T12:19:02.407266Z","iopub.status.idle":"2022-03-10T12:19:02.420536Z","shell.execute_reply.started":"2022-03-10T12:19:02.407234Z","shell.execute_reply":"2022-03-10T12:19:02.419861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:02.421589Z","iopub.execute_input":"2022-03-10T12:19:02.423234Z","iopub.status.idle":"2022-03-10T12:19:02.42946Z","shell.execute_reply.started":"2022-03-10T12:19:02.423205Z","shell.execute_reply":"2022-03-10T12:19:02.428713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Dataset\n\n**id** - ID code for essay response\n\n**discourse_id** - ID code for discourse element\n\n**discourse_start** - character position where discourse element begins in the essay response\n\n**discourse_end** - character position where discourse element ends in the essay response\n\n**discourse_text** - text of discourse element\n\n**discourse_type** - classification of discourse element\n\n**discourse_type_num** - enumerated class label of discourse element\n\n**predictionstring** - the word indices of the training sample, as required for predictions","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:02.430466Z","iopub.execute_input":"2022-03-10T12:19:02.430848Z","iopub.status.idle":"2022-03-10T12:19:03.873546Z","shell.execute_reply.started":"2022-03-10T12:19:02.430813Z","shell.execute_reply":"2022-03-10T12:19:03.872732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The train labels are:')\ntrain_df.discourse_type.unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:03.875076Z","iopub.execute_input":"2022-03-10T12:19:03.875365Z","iopub.status.idle":"2022-03-10T12:19:03.895605Z","shell.execute_reply.started":"2022-03-10T12:19:03.875326Z","shell.execute_reply":"2022-03-10T12:19:03.894749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = train_df.id.unique()\nids_len = len(IDS)\nprint(f\"The number of Train Text : {ids_len}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:03.897218Z","iopub.execute_input":"2022-03-10T12:19:03.897511Z","iopub.status.idle":"2022-03-10T12:19:03.915447Z","shell.execute_reply.started":"2022-03-10T12:19:03.897477Z","shell.execute_reply":"2022-03-10T12:19:03.91481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The tokens and attention arrays\ntokenizer = AutoTokenizer.from_pretrained(LOAD_TOKENS_FROM)\ntrain_tokens = np.zeros((ids_len, config.MAX_LEN), dtype='int32')\ntrain_attentions = np.zeros((ids_len, config.MAX_LEN), dtype='int32')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:03.917139Z","iopub.execute_input":"2022-03-10T12:19:03.917603Z","iopub.status.idle":"2022-03-10T12:19:04.063098Z","shell.execute_reply.started":"2022-03-10T12:19:03.917567Z","shell.execute_reply":"2022-03-10T12:19:04.062284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The 14 classes for NER with Begin and Inside Tags\nlead_b = np.zeros((ids_len, config.MAX_LEN))\nlead_i = np.zeros((ids_len, config.MAX_LEN))\n\nposition_b = np.zeros((ids_len, config.MAX_LEN))\nposition_i = np.zeros((ids_len, config.MAX_LEN))\n\nevidence_b = np.zeros((ids_len, config.MAX_LEN))\nevidence_i = np.zeros((ids_len, config.MAX_LEN))\n\nclaim_b = np.zeros((ids_len, config.MAX_LEN))\nclaim_i = np.zeros((ids_len, config.MAX_LEN))\n\nconclusion_b = np.zeros((ids_len, config.MAX_LEN))\nconclusion_i = np.zeros((ids_len, config.MAX_LEN))\n\ncounterclaim_b = np.zeros((ids_len, config.MAX_LEN))\ncounterclaim_i = np.zeros((ids_len, config.MAX_LEN))\n\nrebuttal_b = np.zeros((ids_len, config.MAX_LEN))\nrebuttal_i = np.zeros((ids_len, config.MAX_LEN))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:04.068126Z","iopub.execute_input":"2022-03-10T12:19:04.068388Z","iopub.status.idle":"2022-03-10T12:19:04.079164Z","shell.execute_reply.started":"2022-03-10T12:19:04.068357Z","shell.execute_reply":"2022-03-10T12:19:04.07843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper variables\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}\n\ndel lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b\ndel lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:04.080521Z","iopub.execute_input":"2022-03-10T12:19:04.080813Z","iopub.status.idle":"2022-03-10T12:19:04.088336Z","shell.execute_reply.started":"2022-03-10T12:19:04.080771Z","shell.execute_reply":"2022-03-10T12:19:04.087485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumming all value in discourse_start is ascending\nassert(np.sum(train_df.groupby('id')['discourse_start'].diff()<=0)==0)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:04.089741Z","iopub.execute_input":"2022-03-10T12:19:04.09018Z","iopub.status.idle":"2022-03-10T12:19:06.650919Z","shell.execute_reply.started":"2022-03-10T12:19:04.090141Z","shell.execute_reply":"2022-03-10T12:19:06.650229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def target_arrays(ind, name):  \n    # Find Targets in text and save in Target Arrays\n    offsets = tokens['offset_mapping']\n    offset_index=0\n    df = train_df.loc[train_df.id==name]\n    for index,row in df.iterrows():\n        # Index of Offset need be less than length of offsets \n        if offset_index>=config.MAX_LEN: #MAX_LEN = len(offsets)\n            break\n        a = row.discourse_start\n        b = row.discourse_end\n        c = offsets[offset_index][0] # char_start\n        d = offsets[offset_index][1] # char_end\n\n        beginning=True\n        while b > c:\n            if(c>=a)&(b>=d): # word in offset inside discourse start/end\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][ind][offset_index] = 1\n                    beginning=False\n                else:\n                    targets_i[k][ind][offset_index] = 1\n            offset_index += 1\n            if offset_index>=config.MAX_LEN: # MAX_LEN = len(offsets)\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:06.652079Z","iopub.execute_input":"2022-03-10T12:19:06.652347Z","iopub.status.idle":"2022-03-10T12:19:06.659883Z","shell.execute_reply.started":"2022-03-10T12:19:06.652294Z","shell.execute_reply":"2022-03-10T12:19:06.659264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tokens(data_name, file_name):\n    # Read training text, tokenize and save in token arrays\n    file_path = f\"../input/feedback-prize-2021/{data_name}/{file_name}.txt\"\n    txt = open(file_path,'r').read()\n    # Tokenization\n    tokens = tokenizer.encode_plus(txt, \n                               max_length=config.MAX_LEN, \n                               padding='max_length', \n                               truncation=True, \n                               return_offsets_mapping=True), # Whether or not to return (char_start, char_end) for each token.\n    return tokens[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:06.661164Z","iopub.execute_input":"2022-03-10T12:19:06.661607Z","iopub.status.idle":"2022-03-10T12:19:06.671877Z","shell.execute_reply.started":"2022-03-10T12:19:06.661571Z","shell.execute_reply":"2022-03-10T12:19:06.671194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    # FULL Training text\n    for id_num in range(ids_len):\n        file_name = IDS[id_num]\n        # TOKEN ARRAYS\n        tokens = get_tokens(data_name='train', \n                            file_name=file_name)\n        train_tokens[id_num,] = tokens['input_ids']\n        train_attentions[id_num,] = tokens['attention_mask']\n        # FILLING TARGET ARRAYS\n        target_arrays(id_num, file_name)\n    # FILLING targets    \n    targets = np.zeros((len(IDS),config.MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1-np.max(targets,axis=-1)\n    del targets_b, targets_i","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:06.674051Z","iopub.execute_input":"2022-03-10T12:19:06.675169Z","iopub.status.idle":"2022-03-10T12:19:06.684068Z","shell.execute_reply.started":"2022-03-10T12:19:06.67514Z","shell.execute_reply":"2022-03-10T12:19:06.683414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{config.MAX_LEN}', targets)\n    np.save(f'tokens_{config.MAX_LEN}', train_tokens)\n    np.save(f'attention_{config.MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{config.MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{config.MAX_LEN}.npy')\n    train_attentions = np.load(f'{LOAD_TOKENS_FROM}/attention_{config.MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:06.685867Z","iopub.execute_input":"2022-03-10T12:19:06.68647Z","iopub.status.idle":"2022-03-10T12:19:13.245367Z","shell.execute_reply.started":"2022-03-10T12:19:06.686427Z","shell.execute_reply":"2022-03-10T12:19:13.244593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    tokens = Input(shape=(config.MAX_LEN,), name='Tokens',dtype=tf.int32)\n    attention = Input(shape=(config.MAX_LEN,), name='Attentions', dtype=tf.int32)\n    \n    configModel = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json')\n    transformer = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=configModel)\n    \n    x = transformer(tokens, attention_mask=attention)\n    x = Dense(256, activation='relu')(x[0]) # final hidden activations\n    x = Dense(15, activation='softmax', dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=[tokens, attention], outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                  loss=[tf.keras.losses.CategoricalCrossentropy()],\n                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n    \n    model.summary()\n    \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:13.24675Z","iopub.execute_input":"2022-03-10T12:19:13.247203Z","iopub.status.idle":"2022-03-10T12:19:13.255558Z","shell.execute_reply.started":"2022-03-10T12:19:13.247163Z","shell.execute_reply":"2022-03-10T12:19:13.254825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()\ntf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:13.257229Z","iopub.execute_input":"2022-03-10T12:19:13.257699Z","iopub.status.idle":"2022-03-10T12:19:44.259267Z","shell.execute_reply.started":"2022-03-10T12:19:13.257664Z","shell.execute_reply":"2022-03-10T12:19:44.258493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"# Learning Rate function\ndef lrfn(epoch):\n    return config.LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:44.261172Z","iopub.execute_input":"2022-03-10T12:19:44.261688Z","iopub.status.idle":"2022-03-10T12:19:44.267083Z","shell.execute_reply.started":"2022-03-10T12:19:44.261643Z","shell.execute_reply":"2022-03-10T12:19:44.26634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(319)\ntrain_ids = np.random.choice(np.arange(ids_len), int(0.9*ids_len), replace=False)\nval_ids = np.setdiff1d(np.arange(ids_len), train_ids)\nprint('Train Size:', len(train_ids), ',Valid Size:', len(val_ids))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:44.268317Z","iopub.execute_input":"2022-03-10T12:19:44.268622Z","iopub.status.idle":"2022-03-10T12:19:44.282548Z","shell.execute_reply.started":"2022-03-10T12:19:44.268587Z","shell.execute_reply":"2022-03-10T12:19:44.281417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD MODEL\nif LOAD_MODEL_FROM:\n    model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n    \n# OR TRAIN MODEL\nelse:# Training Model\n    model.fit(x=[train_tokens[train_ids,], train_attentions[train_ids,]],\n              y=targets[train_ids,],\n              validation_data=([train_tokens[val_ids,], train_attentions[val_ids,]],targets[val_ids,]),\n              callbacks=[lr_callback],\n              epochs=config.EPOCHS,\n              batch_size=config.BATCH_SIZE,\n              verbose=2)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:44.284156Z","iopub.execute_input":"2022-03-10T12:19:44.284522Z","iopub.status.idle":"2022-03-10T12:19:50.219098Z","shell.execute_reply.started":"2022-03-10T12:19:44.284488Z","shell.execute_reply":"2022-03-10T12:19:50.218317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# out-of-fold (OOF) predictions","metadata":{}},{"cell_type":"code","source":"p = model.predict([train_tokens[val_ids,], train_attentions[val_ids,]],\n                  batch_size=16,\n                  verbose=2)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:19:50.220577Z","iopub.execute_input":"2022-03-10T12:19:50.220868Z","iopub.status.idle":"2022-03-10T12:23:27.293458Z","shell.execute_reply.started":"2022-03-10T12:19:50.220814Z","shell.execute_reply":"2022-03-10T12:23:27.292644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:27.294889Z","iopub.execute_input":"2022-03-10T12:23:27.295326Z","iopub.status.idle":"2022-03-10T12:23:27.299996Z","shell.execute_reply.started":"2022-03-10T12:23:27.295272Z","shell.execute_reply":"2022-03-10T12:23:27.299344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET ID function\ndef get_id(txt):\n    # TOKENIZATION\n    tokens = tokenizer.encode_plus(txt, \n                                   max_length=config.MAX_LEN, \n                                   padding='max_length',\n                                   truncation=True, \n                                   return_offsets_mapping=True)\n    off = tokens['offset_mapping']\n\n    # GET WORD POSITIONS IN CHARS\n    w = []\n    blank = True\n    for i in range(len(txt)):\n        charac = txt[i]\n        cond1 = (charac!=' ')&(charac!='\\n')&(charac!='\\xa0')&(charac!='\\x85')&(blank==True)\n        cond2 = (charac==' ')|(charac=='\\n')|(charac=='\\xa0')|(charac=='\\x85')\n        if cond1:\n            w.append(i)\n            blank=False\n        elif cond2:\n            blank=True\n    w.append(1e6)\n    return w, off","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:27.301171Z","iopub.execute_input":"2022-03-10T12:23:27.301581Z","iopub.status.idle":"2022-03-10T12:23:27.310992Z","shell.execute_reply.started":"2022-03-10T12:23:27.30154Z","shell.execute_reply":"2022-03-10T12:23:27.310178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(data_name, preds, text_ids):\n    all_predictions = []\n    for ind in range(len(preds)):\n        # GET ID\n        name = text_ids[ind]\n        # GET TOKEN POSITIONS IN CHARS\n        name_path = f'../input/feedback-prize-2021/{data_name}/{name}.txt'\n        text = open(name_path,'r').read()\n        # GET TOKENS POSITIONS IN CHARS\n        ws, offs = get_id(text)\n        # MAPPING FROM TOKENS TO WORDS\n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[ind,]/2.0\n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(config.MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(offs)):\n            if offs[i][1]==0: continue\n            while offs[i][0]>=ws[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        i = 0\n        while i<config.MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=config.MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=config.MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>4:\n                res = (name, target_map_rev[int(start)], ' '.join([str(x) for x in prediction]) )\n                all_predictions.append(res)    \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n                \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:27.312273Z","iopub.execute_input":"2022-03-10T12:23:27.312732Z","iopub.status.idle":"2022-03-10T12:23:27.327023Z","shell.execute_reply.started":"2022-03-10T12:23:27.312696Z","shell.execute_reply":"2022-03-10T12:23:27.326252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MAKE DATAFRAME\noof = get_preds(data_name ='train',\n                preds=oof_preds, \n                text_ids=IDS[val_ids])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:27.328381Z","iopub.execute_input":"2022-03-10T12:23:27.328867Z","iopub.status.idle":"2022-03-10T12:23:48.516178Z","shell.execute_reply.started":"2022-03-10T12:23:27.328831Z","shell.execute_reply":"2022-03-10T12:23:48.51545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:48.517354Z","iopub.execute_input":"2022-03-10T12:23:48.517608Z","iopub.status.idle":"2022-03-10T12:23:48.529384Z","shell.execute_reply.started":"2022-03-10T12:23:48.517574Z","shell.execute_reply":"2022-03-10T12:23:48.528561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Validation Metric","metadata":{}},{"cell_type":"code","source":"# CODE FROM : Rob Mulla @robikscube\n# https://www.kaggle.com/robikscube/student-writing-competition-twitch\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:48.534294Z","iopub.execute_input":"2022-03-10T12:23:48.534624Z","iopub.status.idle":"2022-03-10T12:23:48.550037Z","shell.execute_reply.started":"2022-03-10T12:23:48.534592Z","shell.execute_reply":"2022-03-10T12:23:48.549408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALID DATAFRAME\nvalid = train_df.loc[train_df['id'].isin(IDS[val_ids])]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:48.551237Z","iopub.execute_input":"2022-03-10T12:23:48.551527Z","iopub.status.idle":"2022-03-10T12:23:48.594146Z","shell.execute_reply.started":"2022-03-10T12:23:48.551494Z","shell.execute_reply":"2022-03-10T12:23:48.593539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:48.595316Z","iopub.execute_input":"2022-03-10T12:23:48.595563Z","iopub.status.idle":"2022-03-10T12:23:50.817385Z","shell.execute_reply.started":"2022-03-10T12:23:48.595531Z","shell.execute_reply":"2022-03-10T12:23:50.816489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test Data","metadata":{}},{"cell_type":"code","source":"# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\ntest_len = len(TEST_IDS)\nprint('There are',test_len,'test texts.')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:51.170867Z","iopub.status.idle":"2022-03-10T12:23:51.171493Z","shell.execute_reply.started":"2022-03-10T12:23:51.171222Z","shell.execute_reply":"2022-03-10T12:23:51.17125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((test_len, config.MAX_LEN), dtype='int32')\ntest_attentions = np.zeros((test_len, config.MAX_LEN), dtype='int32')\n\nfor id_num in range(test_len):\n   # READ TRAIN TEXT, TOKENIZE AND SAVE IN TOKEN ARRAYS\n    name = TEST_IDS[id_num]\n    tokens = get_tokens(data_name='test',\n                             file_name=name)\n    test_tokens[id_num,]= tokens['input_ids']\n    test_attentions[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:51.172742Z","iopub.status.idle":"2022-03-10T12:23:51.173357Z","shell.execute_reply.started":"2022-03-10T12:23:51.173088Z","shell.execute_reply":"2022-03-10T12:23:51.173116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attentions], batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:51.174529Z","iopub.status.idle":"2022-03-10T12:23:51.175124Z","shell.execute_reply.started":"2022-03-10T12:23:51.174857Z","shell.execute_reply":"2022-03-10T12:23:51.174884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# THRESHOLD\nTo remove the data which is less than 2% in word length ","metadata":{}},{"cell_type":"code","source":"oof['len'] =oof['predictionstring'].apply(lambda x: len(x.split()))\ntrain_df['len'] = train_df['predictionstring'].apply(lambda x: len(x.split()))\n# Describe in Percentile\ntrain_df.groupby('discourse_type')['len'].describe(percentiles=[0.02])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def threshold_2percent(df):\n    df = oof.copy()\n    # Create a dictionary with threshold less than 2% \n    map_clip = {'Lead':9, 'Position':5, 'Evidence':14, 'Claim':3, 'Concluding Statement':11,\n             'Counterclaim':6, 'Rebuttal':4}\n    for key, value in map_clip.items():\n        index = df.loc[df['class']==key].query(f'len<{value}').index\n        df.drop(index, inplace=True)\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof2 = threshold_2percent(oof)\nf1s = []\nCLASSES = oof2['class'].unique()\nfor c in CLASSES:\n    pred_df = oof2.loc[oof2['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall',np.mean(f1s))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = get_preds(data_name='test', \n                preds=test_preds, \n                text_ids=TEST_IDS)\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:23:51.176429Z","iopub.status.idle":"2022-03-10T12:23:51.177023Z","shell.execute_reply.started":"2022-03-10T12:23:51.17676Z","shell.execute_reply":"2022-03-10T12:23:51.176789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\n\nhttps://www.kaggle.com/phanttan/bert-distilbert-fine-tune\n\nhttps://www.kaggle.com/phanttan/student-writing-competition-twitch-stream\n\nhttps://www.kaggle.com/vuxxxx/tensorflow-longformer-ner-postprocessing","metadata":{}}]}