{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- 1st stage\n    - longformer 2048\n    - roberta 512\n    - bart 512\n    - deberta 1024\n    - funnel 512\n    - distilbart_cnn 512\n    \n\n- Optimization\n    - ensemble weight (model)\n    - label weight (normlization)\n\n\n- 2nd stage\n    - XGB \n    - MLP\n    - LSTM","metadata":{}},{"cell_type":"code","source":"# =================================\n# Library\n# =================================\nimport gc\nimport os\nimport pickle\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\n\nimport xgboost as xgb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport transformers\nfrom transformers import LongformerTokenizer, LongformerModel,AutoTokenizer,RobertaModel,BartModel,DebertaModel,FunnelModel\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') ","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:25.985032Z","iopub.execute_input":"2022-03-08T10:41:25.985712Z","iopub.status.idle":"2022-03-08T10:41:25.992128Z","shell.execute_reply.started":"2022-03-08T10:41:25.985671Z","shell.execute_reply":"2022-03-08T10:41:25.991174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =================================\n# Constant\n# =================================\nSUB_PATH = \"../input/feedback-prize-2021/sample_submission.csv\"\nDATA_PATH = \"../input/feedback-prize-2021/test/\"\n\nXGB_MODEL = \"../input/expv2-en-038-xgb-mlp-lstm-fe-fix/model\"  # /xgb_fold{fold}.pkl\nMLP_MODEL = \"../input/expv2-en-038-xgb-mlp-lstm-fe-fix/model\"  # /mean_std_df.csv, /mlp_{fold}.pth\nLSTM_MODEL = \"../input/expv2-en-038-xgb-mlp-lstm-fe-fix/model\" # lstm_{fold}.pth\n\n# =================================\n# Config\n# =================================\nclass CFG_ex019:\n    max_len = 2048\n    batch_size = 8\n    tokenizer_path = \"../input/longformer-large-4096-tokenizer/longformer-large-4096\"\n    model_path = \"../input/feed-ex019\"\n    model_prefix = \"ex019_\"\n    n_fold = 5\n    \nclass CFG_ex046:\n    max_len = 512\n    batch_size = 16\n    tokenizer_path = \"../input/roberta-large-tokenizer/roberta-large\"\n    model_path = \"../input/feed-ex046\"\n    model_prefix = \"ex046_\"\n    n_fold = 5\n    \nclass CFG_ex048:\n    max_len = 512\n    batch_size = 16\n    tokenizer_path = \"../input/bart-large-tokenizer/bart-large\"\n    model_path = \"../input/feed-ex048\"\n    model_prefix = \"ex048_\"\n    n_fold = 5\n    \nclass CFG_ex067:\n    max_len = 1024\n    batch_size = 8\n    tokenizer_path = \"../input/deberta-large-tokenizer/deberta-large\"\n    model_path = \"../input/feed-ex067\"\n    model_prefix = \"ex067_\"\n    n_fold = 5\n    \nclass CFG_ex051:\n    max_len = 512\n    batch_size = 16\n    tokenizer_path = \"../input/funnel-large-tokenizer/funnel-large\"\n    model_path = \"../input/feed-ex051-model\"\n    model_prefix = \"ex051_\"\n    n_fold = 5\n    \nclass CFG_ex064:\n    max_len = 512\n    batch_size = 16\n    tokenizer_path = \"../input/distilbart-tokenizer/distilbart\"\n    model_path = \"../input/feed-ex064-model\"\n    model_prefix = \"ex064_\"\n    n_fold=5\n\nfeatures = [\n    'class', 'pred_len', 'proba', 'start',\n    \n    'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4',\n    'pred_mean_5', 'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9',\n    'pred_mean_10', 'pred_mean_11', 'pred_mean_12', 'pred_mean_13', 'pred_mean_14',\n    \n    'pred_std_0', 'pred_std_1', 'pred_std_2', 'pred_std_3', 'pred_std_4', \n    'pred_std_5', 'pred_std_6', 'pred_std_7', 'pred_std_8', 'pred_std_9', \n    'pred_std_10', 'pred_std_11', 'pred_std_12', 'pred_std_13', 'pred_std_14',\n    \n    'id_len_mean', 'id_len_mean_diff', 'id_proba_mean', 'id_proba_mean_diff',\n    'id_class_count',\n    'id_class_len_mean', 'id_class_len_mean_diff',\n    'id_class_proba_mean', 'id_class_proba_mean_diff',\n    \n    'pred_max_0', 'pred_max_1', 'pred_max_2', 'pred_max_3', 'pred_max_4',\n    'pred_max_5', 'pred_max_6', 'pred_max_7', 'pred_max_8', 'pred_max_9',\n    'pred_max_10', 'pred_max_11', 'pred_max_12', 'pred_max_13', 'pred_max_14',\n    \n    'pred_min_0', 'pred_min_1', 'pred_min_2', 'pred_min_3', 'pred_min_4', \n    'pred_min_5', 'pred_min_6', 'pred_min_7', 'pred_min_8', 'pred_min_9', \n    'pred_min_10', 'pred_min_11', 'pred_min_12', 'pred_min_13', 'pred_min_14',\n    \n    \"second\"]\n\ncat_cols = [\"class\", \"start\", \"second\"]\n\nnum_cols = [\n    'pred_len', 'proba',\n    'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4',\n    'pred_mean_5', 'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9',\n    'pred_mean_10', 'pred_mean_11', 'pred_mean_12', 'pred_mean_13', 'pred_mean_14', \n    \n    'pred_std_0', 'pred_std_1', 'pred_std_2', 'pred_std_3', 'pred_std_4',\n    'pred_std_5', 'pred_std_6', 'pred_std_7', 'pred_std_8', 'pred_std_9',\n    'pred_std_10', 'pred_std_11', 'pred_std_12', 'pred_std_13', 'pred_std_14',\n    \n    'id_len_mean', 'id_len_mean_diff', 'id_proba_mean', 'id_proba_mean_diff', \n    'id_class_count', 'id_class_len_mean', 'id_class_len_mean_diff', \n    'id_class_proba_mean','id_class_proba_mean_diff']\n\n\npred_dict_first = {'Claim': 0.325,\n 'Concluding Statement': 0.4,\n 'Counterclaim': 0.25,\n 'Evidence': 0.375,\n 'Lead': 0.375,\n 'Position': 0.275,\n 'Rebuttal': 0.225}\n\npred_dict_second = {'Claim': 0.35000000000000003,\n 'Concluding Statement': 0.42500000000000004,\n 'Counterclaim': 0.325,\n 'Evidence': 0.375,\n 'Lead': 0.375,\n 'Position': 0.325,\n 'Rebuttal': 0.225}\n\nclasses = [\n    \"Lead\",\n    \"Claim\",\n    \"Position\",\n    \"Evidence\",\n    \"Counterclaim\",\n    \"Concluding Statement\",\n    \"Rebuttal\"]\n\n\ntarget_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}\n\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n              'Counterclaim':5, 'Rebuttal':6}\n","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:54:58.821023Z","iopub.execute_input":"2022-03-08T10:54:58.82143Z","iopub.status.idle":"2022-03-08T10:54:58.839564Z","shell.execute_reply.started":"2022-03-08T10:54:58.821394Z","shell.execute_reply":"2022-03-08T10:54:58.838736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =================================\n# Function\n# =================================\ndef get_preds_collate(text_ids, preds, preds_len):\n    all_predictions = []\n\n    for id_num in tqdm(range(len(preds))):\n    \n        # GET ID\n        #if (id_num%100==0)&(verbose): \n        #    print(id_num,', ',end='')\n        n = text_ids[id_num]\n        max_len = int(preds_len[id_num])\n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/test/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=max_len, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(max_len,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i<max_len:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=max_len: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=max_len: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>4:\n                all_predictions.append( (n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    return df\n\ndef get_preds_collate_xgboost(text_ids, preds, preds_len, preds_raw_max, preds_raw,th_len,tokenizer):\n    all_predictions = []\n    all_predictions_mean = []\n    all_predictions_std = []\n    all_predictions_max = []\n    all_predictions_min = []\n    for id_num in tqdm(range(len(preds))):\n        k = 0\n        # GET ID\n        #if (id_num%100==0)&(verbose): \n        #    print(id_num,', ',end='')\n        n = text_ids[id_num]\n        max_len = int(preds_len[id_num])\n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/test/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=max_len, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(max_len,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2.0\n        pred_raw_max = preds_raw_max[id_num]\n        pred_raw = preds_raw[id_num]\n        i = 0\n        \n        while i<max_len:\n            prediction = []\n            prediction_max_proba = []\n            prediction_proba = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                prediction_max_proba.append(pred_raw_max[i])\n                prediction_proba.append(pred_raw[i])\n                i += 1\n                if i>=max_len: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    prediction_max_proba.append(pred_raw_max[i])\n                    prediction_proba.append(pred_raw[i])\n                    \n                    i += 1\n                    if i>=max_len: break\n            elif start in [0.5,1.5,2.5,3.5,4.5,5.5,6.5]:\n                prediction.append(word_map[i])\n                prediction_max_proba.append(pred_raw_max[i])\n                prediction_proba.append(pred_raw[i])\n                i += 1\n                if i>=max_len: break\n                while pred[i]==start:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    prediction_max_proba.append(pred_raw_max[i])\n                    prediction_proba.append(pred_raw[i])\n                    i += 1\n                    if i>=max_len: break\n            else:\n                i += 1\n                \n            prediction = [x for x in prediction if x!=-1]\n            if start in [0,1,2,3,4,5,6]:\n                if len(prediction)>th_len:\n                    all_predictions.append( (n, target_map_rev[int(start)], \n                                    ' '.join([str(x) for x in prediction]),len(prediction),np.mean(prediction_max_proba),1))\n                    all_predictions_mean.append(np.mean(prediction_proba,axis=0))\n                    all_predictions_std.append(np.std(prediction_proba,axis=0))\n                    all_predictions_max.append(np.max(prediction_proba,axis=0))\n                    all_predictions_min.append(np.min(prediction_proba,axis=0))\n            elif start in [0.5,1.5,2.5,3.5,4.5,5.5,6.5]:\n                if len(prediction)>th_len:\n                    all_predictions.append( (n, target_map_rev[int(start - 0.5)], \n                                    ' '.join([str(x) for x in prediction]),len(prediction),np.mean(prediction_max_proba),0) )\n                    all_predictions_mean.append(np.mean(prediction_proba,axis=0))\n                    all_predictions_std.append(np.std(prediction_proba,axis=0))\n                    all_predictions_max.append(np.max(prediction_proba,axis=0))\n                    all_predictions_min.append(np.min(prediction_proba,axis=0))\n        k += 1\n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring',\"pred_len\",\"proba\",\"start\"]\n    \n    \n    return df,all_predictions_mean,all_predictions_std,all_predictions_max,all_predictions_min\n\n\ndef get_preds_collate_xgboost_second(text_ids, preds, preds_len, preds_max, preds_raw,preds_second_max,tokenizer):\n    all_predictions = []\n    all_predictions_mean = []\n    all_predictions_std = []\n    all_predictions_max = []\n    all_predictions_min = []\n    for id_num in tqdm(range(len(preds))):\n        k = 0\n        # GET ID\n        #if (id_num%100==0)&(verbose): \n        #    print(id_num,', ',end='')\n        n = text_ids[id_num]\n        max_len = int(preds_len[id_num])\n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/test/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=max_len, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(max_len,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2\n        pred_max = preds_max[id_num]\n        pred_second_max = preds_second_max[id_num,]/2\n        pred_raw = preds_raw[id_num]\n        #fold_ = fold[id_num]\n        i = 0\n        while i<max_len:\n            prediction = []\n            prediction_second = []\n            prediction_max_proba = []\n            prediction_proba = []\n            start = pred[i]\n            start_second = pred_second_max[i]\n            if (start in [7]) & (start_second in [0,1,2,3,4,5,6]):\n                prediction.append(word_map[i])\n                prediction_second.append(word_map[i])\n                prediction_max_proba.append(pred_max[i])\n                prediction_proba.append(pred_raw[i])\n                i += 1\n                if i>=max_len: break\n                while (pred[i]==start) & (pred_second_max[i] == start_second + 0.5):\n                    if not word_map[i] in prediction_second:\n                        prediction_second.append(word_map[i])\n                    prediction_max_proba.append(pred_max[i])\n                    prediction_proba.append(pred_raw[i])\n                    i += 1\n                    if i>=max_len: break\n            elif (start in [7]) &  (start_second in [0.5,1.5,2.5,3.5,4.5,5.5,6.5]):\n                prediction.append(word_map[i])\n                prediction_second.append(word_map[i])\n                prediction_max_proba.append(pred_max[i])\n                prediction_proba.append(pred_raw[i])\n                i += 1\n                if i>=max_len: break\n                while (pred[i]==start) & (pred_second_max[i] == start_second):\n                    if not word_map[i] in prediction_second:\n                        prediction_second.append(word_map[i])\n                    prediction_max_proba.append(pred_max[i])\n                    prediction_proba.append(pred_raw[i])\n                    i += 1\n                    if i>=max_len: break\n            else:\n                i += 1\n                \n            prediction_second = [x for x in prediction_second if x!=-1]\n            if start_second in [0,1,2,3,4,5,6]:\n                if len(prediction_second)>4:\n                    all_predictions.append( (n, target_map_rev[int(start_second)], \n                                        ' '.join([str(x) for x in prediction_second]) ,len(prediction_second), \n                                             np.mean(prediction_max_proba),1))\n                    all_predictions_mean.append(np.mean(prediction_proba,axis=0))\n                    all_predictions_std.append(np.std(prediction_proba,axis=0))\n                    all_predictions_max.append(np.max(prediction_proba,axis=0))\n                    all_predictions_min.append(np.min(prediction_proba,axis=0))\n            elif start_second in [0.5,1.5,2.5,3.5,4.5,5.5,6.5]:\n                if len(prediction_second)>4:\n                        all_predictions.append( (n, target_map_rev[int(start_second - 0.5)], \n                                        ' '.join([str(x) for x in prediction_second]) , len(prediction_second),\n                                        np.mean(prediction_max_proba),0) )\n                        all_predictions_mean.append(np.mean(prediction_proba,axis=0))\n                        all_predictions_std.append(np.std(prediction_proba,axis=0))\n                        all_predictions_max.append(np.max(prediction_proba,axis=0))\n                        all_predictions_min.append(np.min(prediction_proba,axis=0))\n        k += 1\n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring',\"pred_len\",\"proba\",\"start\"]\n    \n    return df,all_predictions_mean,all_predictions_std,all_predictions_max,all_predictions_min","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:26.238633Z","iopub.execute_input":"2022-03-08T10:41:26.23887Z","iopub.status.idle":"2022-03-08T10:41:26.301763Z","shell.execute_reply.started":"2022-03-08T10:41:26.238843Z","shell.execute_reply":"2022-03-08T10:41:26.300938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =================================\n# Dataset & Model\n# =================================\nclass TestDataset(Dataset):\n    def __init__(self, ids, max_len, tokenizer):\n        self.ids = ids\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, index):\n        # GET TEXT AND WORD LABELS \n        name = f'{DATA_PATH}{self.ids[index]}.txt'\n        txt = open(name, 'r').read()\n        tokens = self.tokenizer.encode_plus(txt, max_length=self.max_len, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        return {\n          'token': torch.tensor(tokens['input_ids'], dtype=torch.long),\n          'mask': torch.tensor(tokens['attention_mask'], dtype=torch.long),\n           }\n\n    def __len__(self):\n        return len(self.ids)\n    \n    \ndef collatte(d,train=True):\n    mask_len = int(d[\"mask\"].sum(axis=1).max())\n    if train:\n        return {\"token\" : d['token'][:,:mask_len],\n                 \"mask\" : d['mask'][:,:mask_len],\n                 \"y\" : d['y'][:,:mask_len],\n                  \"max_len\" : mask_len}\n    else:\n        return {\"token\" : d['token'][:,:mask_len],\n                 \"mask\" : d['mask'][:,:mask_len],\n                  \"max_len\" : mask_len}\n\n    \nclass custom_model_ex019(nn.Module):\n    def __init__(self):\n        super(custom_model_ex019, self).__init__()\n        self.backbone = LongformerModel.from_pretrained(\n            CFG_ex019.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        return out\n    \n    \nclass custom_model_ex025(nn.Module):\n    def __init__(self):\n        super(custom_model_ex025, self).__init__()\n        self.backbone = LongformerModel.from_pretrained(\n            CFG_ex025.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n        \n        self.linear2_1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2_8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        \n        output3_1 = self.linear2_1(output_concat)\n        output3_2 = self.linear2_2(output_concat)\n        output3_3 = self.linear2_3(output_concat)\n        output3_4 = self.linear2_4(output_concat)\n        output3_5 = self.linear2_5(output_concat)\n        output3_6 = self.linear2_6(output_concat)\n        output3_7= self.linear2_7(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        out2 = torch.cat(\n            [output3_1,output3_2,output3_3,output3_4,\n             output3_5,output3_6,output3_7], axis=2)\n        return out\n    \n    \nclass custom_model_ex046(nn.Module):\n    def __init__(self):\n        super(custom_model_ex046, self).__init__()\n        self.backbone = RobertaModel.from_pretrained(\n            CFG_ex046.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        return out\n    \nclass custom_model_ex048(nn.Module):\n    def __init__(self):\n        super(custom_model_ex048, self).__init__()\n        self.backbone = BartModel.from_pretrained(\n            CFG_ex048.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        return out\n    \nclass custom_model_ex067(nn.Module):\n    def __init__(self):\n        super(custom_model_ex067, self).__init__()\n        self.backbone = DebertaModel.from_pretrained(\n            CFG_ex067.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        return out\n    \nclass custom_model_ex051(nn.Module):\n    def __init__(self):\n        super(custom_model_ex051, self).__init__()\n        self.backbone = FunnelModel.from_pretrained(\n            CFG_ex051.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        return out\n\n    \nclass custom_model_ex064(nn.Module):\n    def __init__(self):\n        super(custom_model_ex064, self).__init__()\n        self.backbone = BartModel.from_pretrained(\n            CFG_ex064.tokenizer_path, \n        )\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        \n        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n                                            nn.ReLU(),\n                                            nn.Dropout(0.2))\n        \n        self.linear1 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear3 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear4 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear5 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear6 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear7 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,2),\n        )\n        self.linear8 = nn.Sequential(\n            nn.Linear(2048,1024),\n            nn.LayerNorm(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024,1),\n        )\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n        output = self.ln(emb)\n        output = output.permute((0, 2, 1)).contiguous()\n        output1 = self.conv1(output)\n        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n        output2 = self.conv2(output)\n        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n        output3 = self.conv3(output)\n        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n        output4 = self.conv4(output)\n        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n        output2_1 = self.linear1(output_concat)\n        output2_2 = self.linear2(output_concat)\n        output2_3 = self.linear3(output_concat)\n        output2_4 = self.linear4(output_concat)\n        output2_5 = self.linear5(output_concat)\n        output2_6 = self.linear6(output_concat)\n        output2_7= self.linear7(output_concat)\n        output2_8 = self.linear8(output_concat)\n        out = torch.cat(\n            [output2_1,output2_2,output2_3,output2_4,\n             output2_5,output2_6,output2_7,output2_8], axis=2)\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:26.492951Z","iopub.execute_input":"2022-03-08T10:41:26.49356Z","iopub.status.idle":"2022-03-08T10:41:26.648374Z","shell.execute_reply.started":"2022-03-08T10:41:26.493515Z","shell.execute_reply":"2022-03-08T10:41:26.647642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class mlp_Dataset(Dataset):\n    def __init__(self, class_val, start_val, second_val, num_features, shift1class_val, shiftm1class_val, y = None, train=True):\n        self.class_val = class_val\n        self.start_val = start_val\n        self.second_val = second_val\n        self.num_features = num_features\n        self.shift1class_val = shift1class_val\n        self.shiftm1class_val = shiftm1class_val\n        self.y = y\n        self.train = train\n    \n    def __len__(self):\n        return len(self.class_val)\n\n    def __getitem__(self, item):\n        # Return the processed data where the lists are converted to `torch.tensor`s\n        if self.train : \n            return {\n              'input_data_class': torch.tensor(self.class_val[item], dtype=torch.long),\n              'input_data_start': torch.tensor(self.start_val[item], dtype=torch.long),\n              'input_data_second': torch.tensor(self.second_val[item], dtype=torch.long),\n              'input_data_shift1_class': torch.tensor(self.shift1class_val[item], dtype=torch.long),\n              'input_data_shiftm1_class': torch.tensor(self.shiftm1class_val[item], dtype=torch.long),\n              'input_data_num_features': torch.tensor(self.num_features[item], dtype=torch.float32),\n              \"y\":torch.tensor(self.y[item], dtype=torch.float32)\n               }\n        else:\n            return {\n              'input_data_class': torch.tensor(self.class_val[item], dtype=torch.long),\n              'input_data_start': torch.tensor(self.start_val[item], dtype=torch.long),\n              'input_data_second': torch.tensor(self.second_val[item], dtype=torch.long), \n              'input_data_shift1_class': torch.tensor(self.shift1class_val[item], dtype=torch.long),\n              'input_data_shiftm1_class': torch.tensor(self.shiftm1class_val[item], dtype=torch.long),\n              'input_data_num_features': torch.tensor(self.num_features[item], dtype=torch.float32),\n               }\n\nclass mlp_model(nn.Module):\n    def __init__(\n            self, dropout=0.2, class_unique = 7, start_unique=2, second_unique = 2, class_emb = 15, start_emb = 5,\n            num_emb = 107, emb = 2048,\n            shift1_class = 8, shiftm1_class = 8):\n        super(mlp_model, self).__init__()\n        self.embedding_class = nn.Embedding(\n            num_embeddings=class_unique, embedding_dim=class_emb)\n        self.embedding_start = nn.Embedding(\n            num_embeddings=start_unique, embedding_dim=start_emb)\n        self.embedding_second = nn.Embedding(\n            num_embeddings=second_unique, embedding_dim=start_emb)\n        self.embedding_shift1_class = nn.Embedding(\n            num_embeddings=shift1_class, embedding_dim=class_emb)\n        self.embedding_shiftm1_class = nn.Embedding(\n            num_embeddings=shiftm1_class, embedding_dim=class_emb)\n        self.concat_embedding = nn.Sequential(\n            nn.Linear(class_emb*3 + start_emb*2 + num_emb, emb),\n            nn.BatchNorm1d(emb)\n        )\n        \n        self.batch_norm_c1 = nn.BatchNorm1d(256)\n        self.dropout_c1 = nn.Dropout(0.2)\n        self.conv1 = nn.Conv1d(128,256,kernel_size = 5, stride = 1, padding=2)\n        self.relu1 = nn.ReLU()\n        \n        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = 8)\n\n        self.batch_norm_c2 = nn.BatchNorm1d(256)\n        self.dropout_c2 = nn.Dropout(0.2)\n        self.conv2 = nn.Conv1d(256,256,kernel_size = 5, stride = 1, padding=2)\n        self.relu2 = nn.ReLU()\n        self.flt = nn.Flatten()\n        \n        self.linear3 = nn.Linear(2048, 512)\n        self.batch_norm_c3 = nn.BatchNorm1d(512)\n        self.dropout_c3 = nn.Dropout(0.2)\n        self.relu3= nn.ReLU()\n        self.linear4 = nn.Linear(512, 1)\n        \n        \n\n    def forward(self, class_val, start_val, second_val, num_val, \n                shift1class_val, shiftm1class_val):\n        embedding_class = self.embedding_class(class_val)\n        embedding_start = self.embedding_start(start_val)\n        embedding_second = self.embedding_start(second_val)\n        embedding_shift1_class = self.embedding_shift1_class(shift1class_val)\n        embedding_shiftm1_class = self.embedding_shiftm1_class(shiftm1class_val)\n\n        embedding_concat = torch.cat(\n            [embedding_class, embedding_start, embedding_second , num_val,\n             embedding_shift1_class, embedding_shiftm1_class], axis=1)\n        embedding_concat = self.concat_embedding(embedding_concat)\n        embedding_concat = embedding_concat.reshape(-1,128,16)\n        \n        embedding_concat = self.conv1(embedding_concat)\n        embedding_concat = self.batch_norm_c1(embedding_concat)\n        embedding_concat = self.relu1(embedding_concat)\n        embedding_concat = self.dropout_c1(embedding_concat)\n        embedding_concat = self.ave_po_c1(embedding_concat)\n        \n        embedding_concat = self.conv2(embedding_concat)\n        embedding_concat = self.batch_norm_c2(embedding_concat)\n        embedding_concat = self.relu2(embedding_concat)\n        embedding_concat = self.dropout_c2(embedding_concat)\n        embedding_concat = self.flt(embedding_concat)\n        \n        embedding_concat = self.linear3(embedding_concat)\n        embedding_concat = self.batch_norm_c3(embedding_concat)\n        embedding_concat = self.relu3(embedding_concat)\n        embedding_concat = self.dropout_c3(embedding_concat)\n        output = self.linear4(embedding_concat)\n        \n        return output\n    \n    \nclass lstm_Dataset(Dataset):\n    def __init__(self, num_seq, class_seq, start_seq, mask,y = None, train=True):\n        self.num_seq = num_seq\n        self.class_seq = class_seq\n        self.start_seq = start_seq\n        self.mask = mask\n        self.y = y\n        self.train = train\n    \n    def __len__(self):\n        return len(self.num_seq)\n\n    def __getitem__(self, item):\n        # Return the processed data where the lists are converted to `torch.tensor`s\n        if self.train : \n            return {\n              'input_data_num_seq': torch.tensor(self.num_seq[item], dtype=torch.float32),\n              'input_data_class_seq': torch.tensor(self.class_seq[item], dtype=torch.long),\n              'input_data_start_seq': torch.tensor(self.start_seq[item], dtype=torch.long),  \n              'input_data_mask': torch.tensor(self.mask[item], dtype=torch.long), \n              \"y\":torch.tensor(self.y[item], dtype=torch.float32)\n               }\n        else:\n            return {\n              'input_data_num_seq': torch.tensor(self.num_seq[item], dtype=torch.float32),\n              'input_data_class_seq': torch.tensor(self.class_seq[item], dtype=torch.long),\n              'input_data_start_seq': torch.tensor(self.start_seq[item], dtype=torch.long),  \n              'input_data_mask': torch.tensor(self.mask[item], dtype=torch.long), \n               }\n        \n        \nclass lstm_model(nn.Module):\n    def __init__(\n            self, dropout=0.2, class_unique = 7 + 1,start_unique = 2 + 1 ,\n        class_emb = 15,start_emb = 5, d_model= 128,hidden_size1=128,output_dim=1):\n        super(lstm_model, self).__init__()\n        self.embedding_class = nn.Embedding(\n            num_embeddings=class_unique, embedding_dim=class_emb)\n        self.embedding_start = nn.Embedding(\n            num_embeddings=start_unique, embedding_dim=start_emb)\n        \n        self.concat_emb = nn.Sequential(                \n            nn.Linear(class_emb + start_emb + 41, d_model),\n            nn.LayerNorm(d_model),\n        )\n        self.lstm = nn.LSTM(d_model, d_model,bidirectional = True, batch_first=True)\n        # dense\n        self.linear1 = nn.Linear(d_model*2 ,hidden_size1)\n        self.layernorm = nn.LayerNorm(hidden_size1)\n        self.dropout = nn.Dropout(dropout)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(hidden_size1,output_dim)\n        \n\n    def forward(self, num_seq, class_seq, start_seq):\n        embedding_class = self.embedding_class(class_seq)\n        embedding_start = self.embedding_start(start_seq)\n        embedding_concat = torch.cat(\n            [embedding_class, embedding_start,num_seq], axis=-1)\n        embedding_concat = self.concat_emb(embedding_concat)\n        output,_ = self.lstm(embedding_concat)\n        output = self.linear1(output)\n        output = self.layernorm(output)\n        output = self.relu(output)\n        output = self.dropout(output)\n        output = self.linear2(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:26.650171Z","iopub.execute_input":"2022-03-08T10:41:26.650679Z","iopub.status.idle":"2022-03-08T10:41:26.685272Z","shell.execute_reply.started":"2022-03-08T10:41:26.650595Z","shell.execute_reply":"2022-03-08T10:41:26.684606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def char2longformertoken(preds, longformer_tokenizer, tokenizer, pred_id, max_len=2048, token_len=512, dataset=\"test\"):\n    output_preds = np.zeros((len(preds), max_len, 15), dtype=np.float32)\n\n    for id_num in tqdm(range(len(preds))):\n        n = pred_id[id_num]\n        name =  name = f'../input/feedback-prize-2021/test/{n}.txt'\n        txt = open(name, 'r').read()\n            \n        char_pred = np.zeros([len(txt), 15], dtype=np.float32)\n        longformer_tokens = longformer_tokenizer.encode_plus(\n            txt, \n            max_length=max_len, \n            padding='max_length',\n            truncation=True, \n            return_offsets_mapping=True\n        )\n        tokens = tokenizer.encode_plus(\n            txt,\n            max_length=token_len,\n            padding='max_length',\n            truncation=True,\n            return_offsets_mapping=True\n        )\n        for m, o in enumerate(tokens['offset_mapping']):\n            if (o[1] != 0) & (o[0] != o[1]):\n                char_pred[o[0]:o[1]] = preds[id_num, m]\n\n        for m,o in enumerate(longformer_tokens['offset_mapping']):\n            if (o[1] != 0) & (o[0] != o[1]):\n                output_preds[id_num, m, :] = np.mean(char_pred[o[0]:o[1]], axis=0)\n\n    max_index = np.where(output_preds.sum(axis=-1).sum(axis=0) > 0)[0].max() + 1\n    output_preds = output_preds[:, :max_index, :]\n    print('shape:', output_preds.shape)\n    return output_preds\n\n\ndef get_preds(CFG, custom_model):\n    sub_preds0 = np.zeros((len(IDS), CFG.max_len, 15)).astype(np.float32)\n    tokenizer = AutoTokenizer.from_pretrained(CFG.tokenizer_path)\n    \n    test_dataset = TestDataset(IDS, CFG.max_len, tokenizer)\n    test_loader = DataLoader(test_dataset, \n                             batch_size=CFG.batch_size,\n                             shuffle=False, \n                             pin_memory=True, drop_last=False)\n    for fold in tqdm(range(5)):\n        model = custom_model()\n        model.load_state_dict(torch.load(CFG.model_path + f\"/{CFG.model_prefix}{fold}.pth\"))\n        model.to(device)\n        model.eval()\n\n        test_preds_ = np.ndarray((0, CFG.max_len, 15), dtype=np.float32)\n        if fold == 0:\n            test_len = np.ndarray((0))\n        with torch.no_grad():  \n            for d in test_loader:\n                d = collatte(d, train=False)\n                ids = d['token'].to(device)\n                mask = d['mask'].to(device)\n                with autocast():\n                    outputs = model(ids, mask)\n                outputs = np.concatenate([\n                    outputs.sigmoid().detach().cpu().numpy().astype(np.float32),\n                    np.zeros([len(outputs), CFG.max_len - d[\"max_len\"], 15], dtype=np.float32)],\n                    axis=1)\n                test_preds_ = np.concatenate([test_preds_, outputs], axis=0)\n                if fold == 0:\n                    test_len = np.concatenate([test_len, np.array([d[\"max_len\"] for i in range(len(ids))])],axis=0)\n\n        torch.cuda.empty_cache()\n        sub_preds0 += test_preds_ / 5\n        del model, test_preds_ ; gc.collect()\n    print(sub_preds0.shape)\n    del test_dataset,test_loader\n    gc.collect()\n    return sub_preds0, test_len","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:26.686972Z","iopub.execute_input":"2022-03-08T10:41:26.687409Z","iopub.status.idle":"2022-03-08T10:41:26.707831Z","shell.execute_reply.started":"2022-03-08T10:41:26.687374Z","shell.execute_reply":"2022-03-08T10:41:26.707171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# Prepar Dynamic padding\n# ================================================\nfiles = os.listdir(DATA_PATH)\nIDS = np.array([f.replace('.txt','') for f in files if 'txt' in f])\ntxt_len = []\nfor i in files:\n    txt = open(f'{DATA_PATH}{i}', 'r').read()\n    txt_len.append(len(txt))\nIDS = IDS[np.argsort(txt_len)]","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:26.710712Z","iopub.execute_input":"2022-03-08T10:41:26.711066Z","iopub.status.idle":"2022-03-08T10:41:26.723073Z","shell.execute_reply.started":"2022-03-08T10:41:26.711033Z","shell.execute_reply":"2022-03-08T10:41:26.722389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# exp019 longformer large + 1dcnn \n# ================================================\nsub_preds0, test_len = get_preds(CFG=CFG_ex019, custom_model=custom_model_ex019)\n\n# ================================================\n# exp046 roberta-large ex048 bart large\n# ================================================\nsub_preds1, _ = get_preds(CFG=CFG_ex046, custom_model=custom_model_ex046)\nsub_preds2, _ = get_preds(CFG=CFG_ex048, custom_model=custom_model_ex048)\n\n# ================================================\n# exp067 deberta-large\n# ================================================\nsub_preds3, _ = get_preds(CFG=CFG_ex067, custom_model=custom_model_ex067)\n\n# ================================================\n# exp051 funnel-large\n# ================================================\nsub_preds4, _ = get_preds(CFG=CFG_ex051, custom_model=custom_model_ex051)\n\n# ================================================\n# exp064 distilbart\n# ================================================\nsub_preds5, _ = get_preds(CFG=CFG_ex064, custom_model=custom_model_ex064)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:41:26.726283Z","iopub.execute_input":"2022-03-08T10:41:26.72684Z","iopub.status.idle":"2022-03-08T10:53:29.855842Z","shell.execute_reply.started":"2022-03-08T10:41:26.726805Z","shell.execute_reply":"2022-03-08T10:53:29.853493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# Token => Char => Token\n# ================================================\nlongformer_tokenizer = AutoTokenizer.from_pretrained(CFG_ex019.tokenizer_path)\n# deberta large\nsub_preds3 = char2longformertoken(\n    preds=sub_preds3,\n    longformer_tokenizer=longformer_tokenizer,\n    tokenizer=AutoTokenizer.from_pretrained(CFG_ex067.tokenizer_path), \n    pred_id=IDS,\n    max_len=2048, \n    token_len=CFG_ex067.max_len,\n    dataset=\"test\")\n\n# funnel large\nsub_preds4 = char2longformertoken(\n    preds=sub_preds4,\n    longformer_tokenizer=longformer_tokenizer,\n    tokenizer=AutoTokenizer.from_pretrained(CFG_ex051.tokenizer_path), \n    pred_id=IDS,\n    max_len=2048, \n    token_len=CFG_ex051.max_len,\n    dataset=\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:53:29.859873Z","iopub.execute_input":"2022-03-08T10:53:29.860798Z","iopub.status.idle":"2022-03-08T10:53:30.289559Z","shell.execute_reply.started":"2022-03-08T10:53:29.860764Z","shell.execute_reply":"2022-03-08T10:53:30.287271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# Ensemble\n# ================================================\nmodel_names = ['longformer', 'roberta', 'bart', 'deberta', 'funnel', \"distilbart\"]\nbio_names = []\nfor k in list(target_map.keys()):\n    bio_names.append(k + '_B')\n    bio_names.append(k + '_I')\nbio_names.append('O')\n\nvariable_names = []\nfor model in model_names:\n    for bio in bio_names:\n        variable_names.append(model + '_' + bio)\n        \nlongformer_len = sub_preds0.shape[1]\nroberta_len = sub_preds1.shape[1]\nbart_len = sub_preds2.shape[1]\ndeberta_len = sub_preds3.shape[1]\nfuunel_len = sub_preds4.shape[1]\ndistilbart_len = sub_preds5.shape[1]\n\nlen_lst = [longformer_len, roberta_len, bart_len, deberta_len, fuunel_len, distilbart_len]\nlen_unq_lst = np.sort(np.unique(len_lst)).tolist() \nprint(len_unq_lst)\n\ndef get_ensemble_preds(\n    len_unq_lst, \n    w, \n    longformer, \n    roberta, \n    bart, \n    deberta, \n    funnel, \n    distilbart\n    ):\n    \n    oof_pred = np.zeros_like(longformer, dtype=np.float32)\n    # 0 ~ 512\n    oof_pred[:, 0:len_unq_lst[0], :] += (\n        (longformer[:, :len_unq_lst[0], :] * w[0]) +\n        (deberta[:,0:len_unq_lst[0], :] * w[1]) + \n        (funnel[:, 0:len_unq_lst[0], :] * w[2]) + \n        (roberta[:, 0:len_unq_lst[0], :] * w[3]) + \n        (bart[:, 0:len_unq_lst[0], :] * w[4]) + \n        (distilbart[:, 0:len_unq_lst[0], :] * w[5]) \n        )\n    \n    # 0 ~ 724\n    oof_pred[:, len_unq_lst[0]:len_unq_lst[1], :] += (\n        (longformer[:, len_unq_lst[0]:len_unq_lst[1], :] * w[6]) +\n        (deberta[:, len_unq_lst[0]:len_unq_lst[1], :] * w[7]) + \n        (funnel[:, len_unq_lst[0]:len_unq_lst[1], :] * w[8])\n        )\n\n    # 724 ~ 1023\n    oof_pred[:, len_unq_lst[1]:len_unq_lst[2], :] += (\n        (longformer[:, len_unq_lst[1]:len_unq_lst[2], :] * w[9]) +\n        (deberta[:, len_unq_lst[1]:len_unq_lst[2], :] * w[10])\n        )\n    \n    # 1023 ~ \n    oof_pred[:, len_unq_lst[2]:len_unq_lst[3], :] += longformer[:, len_unq_lst[2]:len_unq_lst[3], :] \n    return oof_pred\n\nw = [0.24184607824700105,\n    0.18400482284411232,\n    0.24723517454937421,\n    0.04129454852214315,\n    0.17143565406629763,\n    0.11418372177107165,\n    0.2966133594221963,\n    0.2911699110109591,\n    0.4122167295668446,\n    0.8888865848806372,\n    0.11111341511936275]\n\nsub_preds = get_ensemble_preds(\n    len_unq_lst=len_unq_lst,\n    w=w,\n    longformer=sub_preds0, \n    roberta=sub_preds1, \n    bart=sub_preds2, \n    deberta=sub_preds3, \n    funnel=sub_preds4, \n    distilbart=sub_preds5,\n   )\n\ndel w, sub_preds0, sub_preds1, sub_preds2, sub_preds3, sub_preds4, sub_preds5\ngc.collect()\n\n# normalization [0~1]\nsum_sub_preds = np.repeat(np.expand_dims(sub_preds.sum(axis=-1), axis=2), 15, axis=-1) + 1e-15\nsub_preds = (sub_preds / sum_sub_preds)\nprint(sub_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:53:30.291217Z","iopub.execute_input":"2022-03-08T10:53:30.291496Z","iopub.status.idle":"2022-03-08T10:53:30.546222Z","shell.execute_reply.started":"2022-03-08T10:53:30.291457Z","shell.execute_reply":"2022-03-08T10:53:30.544954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# Weighting\n# ================================================\ndef weight_labels_score(target_map, oof_pred, weights):\n    if type(weights) == dict:\n\n        for key, weight in weights.items():\n            label = key.split('_')[0]\n            if label != \"O\":\n                bio = key.split('_')[1]\n                l_idx = target_map[label] * 2\n                t_idx = 0 if bio == \"B\" else 1\n                idx = l_idx + t_idx\n            else:\n                idx = 14\n            \n            oof_pred[:, :, idx] *= weight\n    \n    else:\n        for i in range(len(weights)):\n            oof_pred[:, :, i] *= weights[i]\n    \n    return oof_pred\n\n\nweights = {\n    'Claim_B': 0.9149562809773297,\n    'Claim_I': 0.8620142880910798,\n    'Concluding Statement_B': 0.984674716755495,\n    'Concluding Statement_I': 1.000519439831772,\n    'Counterclaim_B': 0.9147544869816964,\n    'Counterclaim_I': 1.1494319296540767,\n    'Evidence_B': 1.0867709452911303,\n    'Evidence_I': 1.0216596474248285,\n    'Lead_B': 1.0434384111736767,\n    'Lead_I': 1.0226444903418863,\n    'O': 0.8189547714458012,\n    'Position_B': 1.0658158817759569,\n    'Position_I': 0.875215904989662,\n    'Rebuttal_B': 1.0007876209721709,\n    'Rebuttal_I': 1.1801748766472047}\nsub_preds =  weight_labels_score(target_map, sub_preds, weights)  \nsub_preds[:,1 :-1,:] = sub_preds[:,1:-1,:] * 0.85 + sub_preds[:,0:-2,:] * 0.075 + sub_preds[:,2:,:] * 0.075\nprint(sub_preds.shape)\n\ndel weights\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:53:30.54769Z","iopub.execute_input":"2022-03-08T10:53:30.547937Z","iopub.status.idle":"2022-03-08T10:53:30.726968Z","shell.execute_reply.started":"2022-03-08T10:53:30.547903Z","shell.execute_reply":"2022-03-08T10:53:30.726234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# Prepar for PP\n# ================================================\nsub_preds_max = np.argmax(sub_preds,axis=-1)\nsub_preds_max_proba = np.max(sub_preds,axis=-1)\nsub,sub_mean,sub_std,sub_max,sub_min = get_preds_collate_xgboost(\n    IDS, \n    sub_preds_max,\n    test_len,\n    sub_preds_max_proba,\n    sub_preds, 0, longformer_tokenizer)\ndel sub_preds_max_proba\ngc.collect()\n\nsub_mean_df = pd.DataFrame(sub_mean, columns = [f\"pred_mean_{i}\" for i in range(15)])\nsub_std_df = pd.DataFrame(sub_std, columns = [f\"pred_std_{i}\" for i in range(15)])\nsub_max_df = pd.DataFrame(sub_max, columns = [f\"pred_max_{i}\" for i in range(15)])\nsub_min_df = pd.DataFrame(sub_min, columns = [f\"pred_min_{i}\" for i in range(15)])\ndel sub_mean,sub_std,sub_max,sub_min\ngc.collect()\n\nsub = pd.concat([sub,sub_mean_df,sub_std_df,sub_max_df,sub_min_df], axis=1)\nsub[\"second\"] = 0\ndel sub_mean_df,sub_std_df,sub_max_df,sub_min_df\ngc.collect()\n\nsub_preds_max_second = np.argsort(sub_preds,axis=-1)[:,:,-2]\nsub_preds_max_proba_second = np.zeros([sub_preds_max_second.shape[0], sub_preds_max_second.shape[1]])\nfor i in tqdm(range(len(sub_preds_max_proba_second))):\n    sub_preds_max_proba_second[i,:] = sub_preds[i, np.arange(sub_preds.shape[1]), sub_preds_max_second[i]]\n    \nsub_second,sub_mean_second,sub_std_second,sub_max_second,sub_min_second = get_preds_collate_xgboost(\n    IDS, \n    sub_preds_max_second,\n    test_len,\n    sub_preds_max_proba_second,\n    sub_preds,\n    4,\n    longformer_tokenizer)\ndel sub_preds_max, sub_preds_max_proba_second,sub_preds_max_second,sub_preds\ngc.collect()\n\nsub_mean_second_df = pd.DataFrame(sub_mean_second, columns = [f\"pred_mean_{i}\" for i in range(15)])\nsub_std_second_df = pd.DataFrame(sub_std_second, columns = [f\"pred_std_{i}\" for i in range(15)])\nsub_max_second_df = pd.DataFrame(sub_max_second, columns = [f\"pred_max_{i}\" for i in range(15)])\nsub_min_second_df = pd.DataFrame(sub_min_second, columns = [f\"pred_min_{i}\" for i in range(15)])\ndel sub_mean_second,sub_std_second,sub_max_second,sub_min_second\ngc.collect()\n\nsub_second = pd.concat([\n    sub_second,\n    sub_mean_second_df,\n    sub_std_second_df,\n    sub_max_second_df,\n    sub_min_second_df],axis=1)\nsub_second[\"second\"] = 1\ndel sub_mean_second_df,sub_std_second_df,sub_max_second_df,sub_min_second_df\ngc.collect()\n\nprint(\"sub\",len(sub))\nprint(\"sub_second\",len(sub_second))\n\nsub = pd.concat([sub, sub_second]).reset_index(drop=True)\ndel sub_second\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:53:30.728236Z","iopub.execute_input":"2022-03-08T10:53:30.72866Z","iopub.status.idle":"2022-03-08T10:53:32.097128Z","shell.execute_reply.started":"2022-03-08T10:53:30.728621Z","shell.execute_reply":"2022-03-08T10:53:32.096362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# FE\n# ================================================\nid_len_mean = sub[[\"id\",\"pred_len\"]].groupby(by=\"id\")[\"pred_len\"].mean().to_dict()\nid_proba_mean = sub[[\"id\",\"proba\"]].groupby(by=\"id\")[\"proba\"].mean().to_dict()\nsub[\"id_len_mean\"] = sub[\"id\"].map(id_len_mean)\nsub[\"id_len_mean_diff\"] = sub[\"pred_len\"] - sub[\"id_len_mean\"]\nsub[\"id_proba_mean\"] = sub[\"id\"].map(id_proba_mean)\nsub[\"id_proba_mean_diff\"] = sub[\"proba\"] - sub[\"id_proba_mean\"]\n\nsub[\"id_class\"] = sub[\"id\"].astype(str) + \"-\" + sub[\"class\"].astype(str)\nid_class_count_dict = sub[\"id_class\"].value_counts().to_dict()\nsub[\"id_class_count\"] = sub[\"id_class\"].map(id_class_count_dict)\n\nid_class_len_mean = sub[[\"id_class\",\"pred_len\"]].groupby(by=\"id_class\")[\"pred_len\"].mean().to_dict()\nid_class_proba_mean = sub[[\"id_class\",\"proba\"]].groupby(by=\"id_class\")[\"proba\"].mean().to_dict()\n\nsub[\"id_class_len_mean\"] = sub[\"id_class\"].map(id_class_len_mean)\nsub[\"id_class_len_mean_diff\"] = sub[\"pred_len\"] - sub[\"id_class_len_mean\"]\n\nsub[\"id_class_proba_mean\"] = sub[\"id_class\"].map(id_class_proba_mean)\nsub[\"id_class_proba_mean_diff\"] = sub[\"proba\"] - sub[\"id_class_proba_mean\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:53:32.098532Z","iopub.execute_input":"2022-03-08T10:53:32.099127Z","iopub.status.idle":"2022-03-08T10:53:32.135775Z","shell.execute_reply.started":"2022-03-08T10:53:32.099086Z","shell.execute_reply":"2022-03-08T10:53:32.135135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sort_by_id_second_predstr(oof):\n    oof_ = oof.copy()\n    oof_[\"_1st_pred_str\"] = oof_[\"predictionstring\"].apply(lambda x:int(x.split()[0]))\n    oof_ = oof_.sort_values([\"id\", \"second\", \"_1st_pred_str\"]).reset_index(drop=True)\n    return oof_.drop(\"_1st_pred_str\", axis=1)\n\nsub = sort_by_id_second_predstr(sub)  # sort","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:53:32.136802Z","iopub.execute_input":"2022-03-08T10:53:32.137066Z","iopub.status.idle":"2022-03-08T10:53:32.152115Z","shell.execute_reply.started":"2022-03-08T10:53:32.137028Z","shell.execute_reply":"2022-03-08T10:53:32.151521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost \nsub[\"class\"] = sub[\"class\"].map(target_map)\nxgb_features = features.copy()\n\nfor lag in [-1, 1]:\n    tmp_df = sub.groupby(['id', 'second'])[\n        [\n            'class', 'pred_len', 'proba',  'start',\n            'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4',\n            'pred_mean_5', 'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9',\n            'pred_mean_10', 'pred_mean_11', 'pred_mean_12', 'pred_mean_13', 'pred_mean_14',\n        ]\n    ].shift(lag).add_prefix(f'shift{lag}_')\n    sub = pd.concat([sub, tmp_df], axis=1)\n    xgb_features += list(tmp_df.columns)\n\nfor lag in [-1, 1]:\n    tmp_df = sub.groupby(['id', 'second'])[\n        [\n            'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4',\n            'pred_mean_5', 'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9',\n            'pred_mean_10', 'pred_mean_11', 'pred_mean_12', 'pred_mean_13', 'pred_mean_14',\n        ]\n    ].shift(lag).add_prefix(f'diff{lag}_')\n    tmp_df[tmp_df.columns] = tmp_df.values - sub[[\n        'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4',\n        'pred_mean_5', 'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9',\n        'pred_mean_10', 'pred_mean_11', 'pred_mean_12', 'pred_mean_13', 'pred_mean_14',\n    ]].values\n    sub = pd.concat([sub, tmp_df], axis=1)\n    xgb_features += list(tmp_df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:54:17.794893Z","iopub.execute_input":"2022-03-08T10:54:17.795621Z","iopub.status.idle":"2022-03-08T10:54:17.836054Z","shell.execute_reply.started":"2022-03-08T10:54:17.795583Z","shell.execute_reply":"2022-03-08T10:54:17.835387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# XGB\n# ================================================\ntest_preds_xgb = np.zeros(len(sub))\nfor i in range(5):\n    clf = pickle.load(open(f\"{XGB_MODEL}/xgb_fold{i}.pkl\",\"rb\"))\n    clf.set_param({'predictor': 'gpu_predictor'})\n    test_preds_xgb  += clf.predict(xgb.DMatrix(sub[xgb_features].values), ntree_limit=clf.best_ntree_limit) / 5","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:55:06.235432Z","iopub.execute_input":"2022-03-08T10:55:06.236113Z","iopub.status.idle":"2022-03-08T10:55:18.790815Z","shell.execute_reply.started":"2022-03-08T10:55:06.236074Z","shell.execute_reply":"2022-03-08T10:55:18.789801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# MLP\n# ================================================\n\n# shift_classの欠損値埋め\nsub[['shift1_class', 'shift-1_class']] = sub[['shift1_class', 'shift-1_class']].fillna(7).astype(np.uint8)\n\n# # catとnumにそれぞれ追加\ncat_cols += ['shift1_class', 'shift-1_class']\nnum_cols += sorted(list(set(xgb_features) - set(features) - set(cat_cols)))\nprint(num_cols)\n\nnum_cols = [\n    'pred_len', 'proba', \n    'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4', 'pred_mean_5',\n    'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9', 'pred_mean_10', 'pred_mean_11',\n    'pred_mean_12', 'pred_mean_13', 'pred_mean_14', \n    'pred_std_0', 'pred_std_1', 'pred_std_2', 'pred_std_3', 'pred_std_4', 'pred_std_5',\n    'pred_std_6', 'pred_std_7', 'pred_std_8', 'pred_std_9', 'pred_std_10', 'pred_std_11',\n    'pred_std_12', 'pred_std_13', 'pred_std_14', \n    'id_len_mean', 'id_len_mean_diff', 'id_proba_mean', 'id_proba_mean_diff',\n    'id_class_count', 'id_class_len_mean', 'id_class_len_mean_diff', \n    'id_class_proba_mean', 'id_class_proba_mean_diff', \n    'diff-1_pred_mean_0', 'diff-1_pred_mean_1', 'diff-1_pred_mean_10', 'diff-1_pred_mean_11',\n    'diff-1_pred_mean_12', 'diff-1_pred_mean_13', 'diff-1_pred_mean_14', 'diff-1_pred_mean_2',\n    'diff-1_pred_mean_3', 'diff-1_pred_mean_4', 'diff-1_pred_mean_5', 'diff-1_pred_mean_6', \n    'diff-1_pred_mean_7', 'diff-1_pred_mean_8', 'diff-1_pred_mean_9', 'diff1_pred_mean_0',\n    'diff1_pred_mean_1', 'diff1_pred_mean_10', 'diff1_pred_mean_11', 'diff1_pred_mean_12', \n    'diff1_pred_mean_13', 'diff1_pred_mean_14', 'diff1_pred_mean_2', 'diff1_pred_mean_3', \n    'diff1_pred_mean_4', 'diff1_pred_mean_5', 'diff1_pred_mean_6', 'diff1_pred_mean_7', \n    'diff1_pred_mean_8', 'diff1_pred_mean_9', 'shift-1_pred_len', 'shift-1_pred_mean_0',\n    'shift-1_pred_mean_1', 'shift-1_pred_mean_10', 'shift-1_pred_mean_11', 'shift-1_pred_mean_12',\n    'shift-1_pred_mean_13', 'shift-1_pred_mean_14', 'shift-1_pred_mean_2', 'shift-1_pred_mean_3',\n    'shift-1_pred_mean_4', 'shift-1_pred_mean_5', 'shift-1_pred_mean_6', 'shift-1_pred_mean_7',\n    'shift-1_pred_mean_8', 'shift-1_pred_mean_9', 'shift-1_proba', 'shift-1_start', 'shift1_pred_len',\n    'shift1_pred_mean_0', 'shift1_pred_mean_1', 'shift1_pred_mean_10', 'shift1_pred_mean_11', \n    'shift1_pred_mean_12', 'shift1_pred_mean_13', 'shift1_pred_mean_14', 'shift1_pred_mean_2',\n    'shift1_pred_mean_3', 'shift1_pred_mean_4', 'shift1_pred_mean_5', 'shift1_pred_mean_6',\n    'shift1_pred_mean_7', 'shift1_pred_mean_8', 'shift1_pred_mean_9', 'shift1_proba', 'shift1_start']\n\n\ndf_mean_std = pd.read_csv(f\"{MLP_MODEL}/mean_std_df.csv\")\nfor c in num_cols:\n    mean_v = df_mean_std[df_mean_std.feature == c][\"mean_val\"].values[0]\n    std_v = df_mean_std[df_mean_std.feature == c][\"std_val\"].values[0]\n    sub[c] = (sub[c] - mean_v) / std_v\n    sub[c] = sub[c].fillna(0)\n\ntest_preds_mlp = np.zeros(len(sub))\nfor fold in range(5):\n    print(f\"fold{fold}:start\")\n    test_ = mlp_Dataset(class_val = sub[\"class\"].values,\n                        start_val = sub[\"start\"].values,\n                        second_val = sub[\"second\"].values,\n                        num_features = sub[num_cols].values,\n                        shift1class_val = sub[\"shift1_class\"].values,\n                        shiftm1class_val = sub[\"shift-1_class\"].values,\n                        train = False)\n\n\n    # loader\n    test_loader = DataLoader(dataset=test_, batch_size=64, shuffle = False , pin_memory=True)\n\n    # model\n    model = mlp_model()\n    model.load_state_dict(torch.load(f\"{MLP_MODEL}/seed_0_mlp_{fold}.pth\"))\n    model.to(device)\n    model.eval()\n    test_preds_ = np.ndarray((0,1))\n    model.eval()  # switch model to the evaluation mode\n    with torch.no_grad():  \n        # Predicting on validation set\n\n        for d in tqdm(test_loader,total=len(test_loader)):\n            # =========================\n            # data loader\n            # =========================\n            class_val = d['input_data_class'].to(device)\n            start_val = d['input_data_start'].to(device)\n            second_val = d['input_data_second'].to(device)\n            num_val = d['input_data_num_features'].to(device)\n            shift1class_val = d['input_data_shift1_class'].to(device)\n            shiftm1class_val = d['input_data_shiftm1_class'].to(device)\n            output = model(class_val, start_val, second_val, num_val, shift1class_val, shiftm1class_val)\n            test_preds_ = np.concatenate([test_preds_, output.sigmoid().detach().cpu().numpy()], axis=0)\n            \n    test_preds_mlp += test_preds_.reshape(-1)/5","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:55:46.889911Z","iopub.execute_input":"2022-03-08T10:55:46.890487Z","iopub.status.idle":"2022-03-08T10:55:49.589909Z","shell.execute_reply.started":"2022-03-08T10:55:46.890449Z","shell.execute_reply":"2022-03-08T10:55:49.589195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# LSTM\n# ================================================\n# lstm\nmax_seq_len = 70\n\n# raw num_cols\nnum_cols = [\n    'pred_len', 'proba',\n    'pred_mean_0', 'pred_mean_1', 'pred_mean_2', 'pred_mean_3', 'pred_mean_4', \n    'pred_mean_5', 'pred_mean_6', 'pred_mean_7', 'pred_mean_8', 'pred_mean_9', \n    'pred_mean_10', 'pred_mean_11', 'pred_mean_12', 'pred_mean_13', 'pred_mean_14',\n    \n    'pred_std_0', 'pred_std_1', 'pred_std_2', 'pred_std_3', 'pred_std_4', \n    'pred_std_5', 'pred_std_6', 'pred_std_7', 'pred_std_8', 'pred_std_9',\n    'pred_std_10', 'pred_std_11', 'pred_std_12', 'pred_std_13', 'pred_std_14',\n    'id_len_mean', 'id_len_mean_diff', 'id_proba_mean', 'id_proba_mean_diff', \n    \n    'id_class_count',\n    'id_class_len_mean', 'id_class_len_mean_diff', \n    'id_class_proba_mean', 'id_class_proba_mean_diff']\n\n# keyの作成\nsub[\"id_second\"] = sub[\"id\"].astype(str) + \"-\" +  sub[\"second\"].astype(str)\nle = LabelEncoder()\nsub[\"id_second\"] = le.fit_transform(sub[\"id_second\"])\n\n# paddingを0にする\nsub[\"class_\"] = sub[\"class\"] + 1\nsub[\"start_\"] = sub[\"start\"] + 1\n\n# seqの作成\nnum_seq = np.zeros([sub[\"id_second\"].nunique(),max_seq_len,len(num_cols)])\nclass_seq = np.zeros([sub[\"id_second\"].nunique(),max_seq_len])\nstart_seq = np.zeros([sub[\"id_second\"].nunique(),max_seq_len])\nmask = np.zeros([sub[\"id_second\"].nunique(),max_seq_len])\n\nnum_values = sub[num_cols].values\nclass_ = sub[\"class_\"].values\nstart_ = sub[\"start_\"].values\nid_second_unique = sub[\"id_second\"].unique()\nid_second = sub[\"id_second\"].values\n\nfor n,i in tqdm(enumerate(id_second_unique),total=len(id_second_unique)):\n    seq_len = np.sum(id_second == i)\n    num_seq[n,:seq_len,:] = num_values[id_second == i,:]\n    class_seq[n,:seq_len] = class_[id_second == i]\n    start_seq[n,:seq_len] = start_[id_second == i]\n    mask[n,:seq_len] = 1\n    \ntest_preds_lstm = np.zeros(len(sub))\ntest_preds_lstm_seq = np.zeros_like(mask)\n\nfor fold in range(5):\n    print(f\"fold{fold}:start\")\n    test_ = lstm_Dataset( num_seq = num_seq,\n                          class_seq = class_seq,\n                          start_seq = start_seq,\n                          mask = mask,\n                          train=False)\n\n    # loader\n    test_loader = DataLoader(dataset=test_, batch_size=32, shuffle = False , pin_memory=True)\n\n    # model\n    model = lstm_model()\n    model.load_state_dict(torch.load(f\"{LSTM_MODEL}/seed_0_lstm_{fold}.pth\"))\n    model.to(device)\n    model.eval()\n    test_preds_ = np.ndarray((0,max_seq_len,1))\n    model.eval()  # switch model to the evaluation mode\n    with torch.no_grad():  \n        # Predicting on validation set\n\n        for d in tqdm(test_loader,total=len(test_loader)):\n            # =========================\n            # data loader\n            # =========================\n            input_num = d['input_data_num_seq'].to(device)\n            input_class = d['input_data_class_seq'].to(device)\n            input_start = d['input_data_start_seq'].to(device)\n            output = model(input_num,input_class,input_start)\n            test_preds_ = np.concatenate([test_preds_, output.sigmoid().detach().cpu().numpy()], axis=0)\n    test_preds_lstm_seq += test_preds_.reshape([-1,max_seq_len])/5\n\nfor n,i in tqdm(enumerate(id_second_unique),total=len(id_second_unique)):\n    seq_len = np.sum(id_second == i)\n    test_preds_lstm[id_second == i] = test_preds_lstm_seq[n,:seq_len]","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:56:03.586471Z","iopub.execute_input":"2022-03-08T10:56:03.586868Z","iopub.status.idle":"2022-03-08T10:56:04.009393Z","shell.execute_reply.started":"2022-03-08T10:56:03.586827Z","shell.execute_reply":"2022-03-08T10:56:04.008667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# XGB + MLP + LSTM\n# ================================================\nw = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n\nsub[\"pred\"] = (test_preds_xgb * w[0] + test_preds_mlp * w[1] + test_preds_lstm * w[2])\nsub[\"class\"] = sub[\"class\"].map(target_map_rev)\n\nsub[\"test_preds_xgb\"] = test_preds_xgb\nsub[\"test_preds_mlp\"] = test_preds_mlp\nsub[\"test_preds_lstm\"] = test_preds_lstm\nsub = sort_by_id_second_predstr(sub)\ndisplay(sub[[\"id\", \"predictionstring\", \"test_preds_xgb\", \"test_preds_mlp\", \"test_preds_lstm\", \"pred\"]].head(60))","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:56:58.06382Z","iopub.execute_input":"2022-03-08T10:56:58.064367Z","iopub.status.idle":"2022-03-08T10:56:58.09755Z","shell.execute_reply.started":"2022-03-08T10:56:58.064329Z","shell.execute_reply":"2022-03-08T10:56:58.096824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================================\n# Last PP -> Submission\n# ================================================\nsub_ensemble = pd.DataFrame()\npred_df_first = sub[sub.second == 0].reset_index(drop=True)\npred_df_second = sub[sub.second == 1].reset_index(drop=True)\nfor c in classes:\n    \n    pred_df_first_ = pred_df_first.loc[(pred_df_first['class']==c) & (pred_df_first['pred']>pred_dict_first[c])].reset_index(drop=True)\n    pred_df_second_ = pred_df_second.loc[(pred_df_second['class']==c) & (pred_df_second['pred']>pred_dict_second[c])].reset_index(drop=True)\n\n    pred_df = pd.concat([pred_df_first_,pred_df_second_]).reset_index(drop=True)\n    pred_df = pred_df.sort_values(by=[\"id\",\"pred\"],ascending=False).reset_index(drop=True)\n    if c in [\"Lead\",\"Position\",\"Concluding Statement\"]:\n        pred_df = pred_df.drop_duplicates(subset = \"id\").reset_index(drop=True)\n    sub_ensemble = pd.concat([sub_ensemble,pred_df[['id','class','predictionstring']]],axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T10:57:27.382411Z","iopub.execute_input":"2022-03-08T10:57:27.383176Z","iopub.status.idle":"2022-03-08T10:57:27.470473Z","shell.execute_reply.started":"2022-03-08T10:57:27.38313Z","shell.execute_reply":"2022-03-08T10:57:27.469727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = [\n    \"Lead\",\n    \"Claim\",\n    \"Position\",\n    \"Evidence\",\n    \"Counterclaim\",\n    \"Concluding Statement\",\n    \"Rebuttal\"\n]\n\nweightclass_dict = {\n    'weight_Lead': 0.14570664728598393,\n    'weight_Claim': 0.27054193883215294,\n    'weight_Position': 0.2160497395777658,\n    'weight_Evidence': 0.22809965269846363,\n    'weight_Counterclaim': 0.3465951774864235,\n    'weight_Concluding Statement': 0.28841514563843695,\n    'weight_Rebuttal': 0.28076095423970426,\n    'threshold_Lead': 59,\n    'threshold_Claim': 33,\n    'threshold_Position': 31,\n    'threshold_Evidence': 155,\n    'threshold_Counterclaim': 34,\n    'threshold_Concluding Statement': 174,\n    'threshold_Rebuttal': 40,   \n}\n\n\ndef add_pred(predictstring, weight, threshold):\n    predictstring = predictstring.split()\n    if len(predictstring) > threshold:\n        predictstring = predictstring[:-1*int(len(predictstring)*weight)]\n    return \" \".join(predictstring)\n\nfor c in classes:\n    func = lambda x: add_pred(x, weightclass_dict[f'weight_{c}'], weightclass_dict[f'threshold_{c}'])\n    index = (sub_ensemble['class']==c)\n    sub_ensemble.loc[index, 'predictionstring'] = sub_ensemble.loc[index, 'predictionstring'].apply(func)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_ensemble.to_csv(\"submission.csv\",index=False)\ndisplay(sub_ensemble)","metadata":{},"execution_count":null,"outputs":[]}]}