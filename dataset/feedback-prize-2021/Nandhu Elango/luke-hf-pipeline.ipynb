{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font color='brown' size=4>Objective:</font> \n        \n<p> This notebook approaches this problem using NER but not as tokens classification but using spans to classify entities. Introducing <b>LUKE: Deep Contextualized Entity Representations with\nEntity-aware Self-attention</b> We will formulate the inputs accordingly to feed the data to LUKE model. Lets dig in further</p>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np, os \nimport pandas as pd, gc \nfrom tqdm import tqdm\n\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification,LukeForEntitySpanClassification,RobertaTokenizer,RobertaTokenizerFast,LukeTokenizer,DataCollatorForTokenClassification,TrainingArguments, Trainer, EarlyStoppingCallback\nfrom datasets import Dataset as ds, DatasetDict, load_metric\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom sklearn.metrics import accuracy_score\nfrom torch import cuda\nfrom torch import nn\nimport itertools\n\n!pip install seqeval\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-03T12:45:50.598112Z","iopub.execute_input":"2022-01-03T12:45:50.598485Z","iopub.status.idle":"2022-01-03T12:46:14.201527Z","shell.execute_reply.started":"2022-01-03T12:45:50.598396Z","shell.execute_reply":"2022-01-03T12:46:14.200419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of Contents\n\n- 1. LUKE Demo\n\n- 2. LUKE Overview\n   - 2.1 Summary\n   - 2.2 Architecture\n   - 2.3 Benchmark results\n      \n- 3. LUKE Training\n   - 3.1 Helpers\n   - 3.2 Dataset\n   - 3.3 Engine\n\n- 4. HF trainer\n      \n- 5. Acknowledgements","metadata":{}},{"cell_type":"markdown","source":"# <font color='brown' size=4>1. LUKE Demo</font>","metadata":{}},{"cell_type":"code","source":"config = {'model_name': 'studio-ousia/luke-large-finetuned-conll-2003',   \n         'max_length': 512,\n         'train_batch_size':2,\n         'valid_batch_size':4,\n         'epochs':1,\n         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n         'max_grad_norm':10,\n         'device': 'cuda' if cuda.is_available() else 'cpu'}","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:34:22.151313Z","iopub.execute_input":"2022-01-03T12:34:22.151597Z","iopub.status.idle":"2022-01-03T12:34:22.193247Z","shell.execute_reply.started":"2022-01-03T12:34:22.15156Z","shell.execute_reply":"2022-01-03T12:34:22.192543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spans_tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n\ntokenizer = LukeTokenizer.from_pretrained(config['model_name'])\nmodel = LukeForEntitySpanClassification.from_pretrained(config['model_name'])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:34:22.195018Z","iopub.execute_input":"2022-01-03T12:34:22.195682Z","iopub.status.idle":"2022-01-03T12:35:36.13922Z","shell.execute_reply.started":"2022-01-03T12:34:22.195643Z","shell.execute_reply":"2022-01-03T12:35:36.138519Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **📌 Note**: Here we initialize two tokenizers.\n>1. To create entity spans\n>2. Luke specific tokenizer for the model inference\n\n>LUKE is based on RoBERTa and adds entity embeddings as well as an entity-aware self-attention mechanism, which helps improve performance on various downstream tasks involving reasoning about entities such as named entity recognition, extractive and cloze-style question answering, entity typing, and relation classification.","metadata":{}},{"cell_type":"code","source":"text = \"Beyoncé lives in Los Angeles\"\nout=spans_tokenizer(text,return_offsets_mapping=True, padding='max_length', truncation=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:36.14123Z","iopub.execute_input":"2022-01-03T12:35:36.142636Z","iopub.status.idle":"2022-01-03T12:35:36.154863Z","shell.execute_reply.started":"2022-01-03T12:35:36.142595Z","shell.execute_reply":"2022-01-03T12:35:36.154148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_spans(offset_mapping):\n    spans=[]\n    for ix,offset in enumerate(offset_mapping):\n        \n        if offset==(0,0):\n            continue\n\n        if offset[0]==0 and offset[1]!=0:\n            start=offset[0]\n            end=offset[1]\n\n        elif offset_mapping[ix-1][1]!=offset_mapping[ix][0]:\n            spans.append((start,end))\n            start=offset[0]\n\n        end=offset[1]\n\n    if start!=0 and end!=0:\n        spans.append((start,end))\n        \n    return spans","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:36.156347Z","iopub.execute_input":"2022-01-03T12:35:36.156628Z","iopub.status.idle":"2022-01-03T12:35:38.469739Z","shell.execute_reply.started":"2022-01-03T12:35:36.156593Z","shell.execute_reply":"2022-01-03T12:35:38.468745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p>Get span function gets token level spans from offset mapping </p>","metadata":{}},{"cell_type":"code","source":"spans=get_spans(out['offset_mapping'])\n\n# List all possible entity spans in the text\nword_start_positions = list(list(zip(*spans))[0])  # character-based start positions of word tokens\nword_end_positions = list(list(zip(*spans))[1])  # character-based end positions of word tokens\nentity_spans = []\nfor i, start_pos in enumerate(word_start_positions):\n    for end_pos in word_end_positions[i:]:\n        entity_spans.append((start_pos, end_pos))\n\ninputs = tokenizer(text, entity_spans=entity_spans, return_tensors=\"pt\")\noutputs = model(**inputs)\nlogits = outputs.logits\npredicted_class_indices = logits.argmax(-1).squeeze().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:38.473076Z","iopub.execute_input":"2022-01-03T12:35:38.473976Z","iopub.status.idle":"2022-01-03T12:35:39.148771Z","shell.execute_reply.started":"2022-01-03T12:35:38.473934Z","shell.execute_reply":"2022-01-03T12:35:39.148008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for span, predicted_class_idx in zip(entity_spans, predicted_class_indices):\n    if predicted_class_idx != 0:\n         print(text[span[0]:span[1]], model.config.id2label[predicted_class_idx])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:39.150123Z","iopub.execute_input":"2022-01-03T12:35:39.150379Z","iopub.status.idle":"2022-01-03T12:35:39.158888Z","shell.execute_reply.started":"2022-01-03T12:35:39.150342Z","shell.execute_reply":"2022-01-03T12:35:39.15818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p>Tada. We have our entities from the spans.</p>\n\n> **📌 Note**:We need to pass all combination of token spans during the inference time to get the predictions for each spans. This is highly computational heavy","metadata":{}},{"cell_type":"code","source":"predicted_class_indices","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:39.160145Z","iopub.execute_input":"2022-01-03T12:35:39.160523Z","iopub.status.idle":"2022-01-03T12:35:39.168992Z","shell.execute_reply.started":"2022-01-03T12:35:39.160472Z","shell.execute_reply":"2022-01-03T12:35:39.168314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.id2label","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:39.170368Z","iopub.execute_input":"2022-01-03T12:35:39.170866Z","iopub.status.idle":"2022-01-03T12:35:39.178464Z","shell.execute_reply.started":"2022-01-03T12:35:39.170831Z","shell.execute_reply":"2022-01-03T12:35:39.177755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='brown' size=4>2. LUKE Overview</font>","metadata":{}},{"cell_type":"markdown","source":"<p>LUKE is based\non a transformer trained\nusing a large amount of entity-annotated corpus obtained from Wikipedia. An important difference\nbetween LUKE and existing CWRs(Context Word Representations) is that it treats\nnot only words, but also entities as independent tokens, and computes intermediate and output representations for all tokens using the transformer. Since entities are treated as tokens, LUKE can directly model the relationships between entities</p>","metadata":{}},{"cell_type":"markdown","source":"## <font color='brown' size=4>2.1 Summary</font>","metadata":{}},{"cell_type":"markdown","source":"<p>Author proposes a new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. LUKE model is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. Author also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores.</p> \n\n<p>The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering).</p>","metadata":{}},{"cell_type":"markdown","source":"## <font color='brown' size=4>2.2 Architecture</font>","metadata":{}},{"cell_type":"markdown","source":"<img src='https://d3i71xaburhd42.cloudfront.net/eedf2748a9a1ba2779cde95fd8bad9c2260d5317/2-Figure1-1.png' width=1000>\n<div align=\"center\"><font size=\"3\">Source: Google</font></div>","metadata":{"execution":{"iopub.status.busy":"2022-01-03T11:06:30.609306Z","iopub.execute_input":"2022-01-03T11:06:30.609929Z","iopub.status.idle":"2022-01-03T11:06:30.617135Z","shell.execute_reply.started":"2022-01-03T11:06:30.609886Z","shell.execute_reply":"2022-01-03T11:06:30.615677Z"}}},{"cell_type":"markdown","source":"> **📌 Note**:Architecture of LUKE using the input sentence “Beyonce lives in Los Angeles. ´ ” LUKE outputs contextualized representation for each word and entity in the text. The model is trained to predict randomly masked words\n(e.g., lives and Angeles in the figure) and entities (e.g., Los Angeles in the figure). Downstream tasks are solved\nusing its output representations with linear classifiers.","metadata":{}},{"cell_type":"markdown","source":"- The main contributions of this paper are summarized as follows:\n    - Contextualized representations specifically designed to address entity related tasks. LUKE is trained to predict randomly masked words and entities using a large amount of entity-annotated corpus obtained from Wikipedia.\n    - Entity-aware self-attention\n    mechanism, an effective extension of the original mechanism of transformer. The proposed mechanism considers the type of the tokens (words or entities) when computing attention scores.\n    - LUKE achieves strong empirical performance and obtains state-of-the-art results on five popular datasets: Open Entity, TACRED, CoNLL2003, ReCoRD, and SQuAD 1.1.\n","metadata":{}},{"cell_type":"markdown","source":"## <font color='brown' size=4>2.3 Benchmark results</font>","metadata":{}},{"cell_type":"markdown","source":"![image.png](attachment:ab8279b4-ede5-48f3-a616-97916119880d.png)","metadata":{},"attachments":{"ab8279b4-ede5-48f3-a616-97916119880d.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"# <font color='brown' size=4>3. LUKE Training</font>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain_df['discourse_start']=train_df['discourse_start'].apply(lambda x:int(x))\ntrain_df['discourse_end']=train_df['discourse_end'].apply(lambda x:int(x))\ntrain_df=train_df.groupby('id').agg({'discourse_start':list,'discourse_end':list,'discourse_type':list,'predictionstring':list})\n\ntrain_df['spans']=train_df[['discourse_start','discourse_end']].apply(lambda x: list(zip(x[0],x[1])),axis=1)\ntrain_df['spans']=train_df[['discourse_start','discourse_end']].apply(lambda x: list(zip(x[0],x[1])),axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:39.18183Z","iopub.execute_input":"2022-01-03T12:35:39.183039Z","iopub.status.idle":"2022-01-03T12:35:42.728489Z","shell.execute_reply.started":"2022-01-03T12:35:39.182396Z","shell.execute_reply":"2022-01-03T12:35:42.727568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color='brown' size=4>3.1 Helpers</font>","metadata":{}},{"cell_type":"code","source":"def create_chunks(\n    uniqueid: int = 0,\n    content: str = \"\",\n    tokenizer: RobertaTokenizer = None,\n    max_length: int = 512,\n):\n    \"\"\"\n    Chunk the given text\n\n    :param uniqueid: Unique id for the record\n    :param content: Text to chunk\n    :param tokenizer: Tokenizer from huggingface library\n    :param max_length: Max length the chunked sentence has to be, after tokenizing\n    :return: Returns a list of chunked sentences.\n    \"\"\"\n\n    try:\n        all_chunks = []\n        splits = tokenizer.encode_plus(\n            content,\n            add_special_tokens=False,\n            return_tensors=\"pt\",\n            return_offsets_mapping=True,\n        )\n        offsets = splits[\"offset_mapping\"][0].split(max_length)\n\n        if len(offsets) > 1:\n            for ix, offset in enumerate(offsets):\n\n                if ix == 0:\n                    all_chunks.append(\n                        (uniqueid, 0, content[0 : offset[-1][1]])\n                    )\n                else:\n                    all_chunks.append(\n                        (\n                            uniqueid,\n                            int(offset[0][0]),\n                            content[offset[0][0] : offset[-1][1]],\n                        )\n                    )\n\n        else:\n            all_chunks.append((uniqueid, 0, content[0 : offsets[0][-1][1]]))\n\n        return all_chunks\n\n    except Exception as e:\n        print(f\"Chunking failed : {str(e)}\")\n        print(f\"Chunk text: {content}\")\n        return [(-100, 0, \"\")]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:42.730952Z","iopub.execute_input":"2022-01-03T12:35:42.731584Z","iopub.status.idle":"2022-01-03T12:35:42.748017Z","shell.execute_reply.started":"2022-01-03T12:35:42.731544Z","shell.execute_reply":"2022-01-03T12:35:42.747151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **📌 Note**:The above function can be used to break down the longer text into chunks. It is not used as part of training process. We can use it in inference pipeline","metadata":{}},{"cell_type":"code","source":"def correct_spans(offsets):\n    new_offsets=[]\n    for ix,span in enumerate(offsets):\n        \n        if ix==0:\n            new_offsets.append(span)\n        elif offsets[ix-1][1]==offsets[ix][0]:\n            new_offsets.append((span[0]+1,span[1]))\n        else:\n            new_offsets.append(span)\n            \n    return new_offsets\n\ndef fill_spans(offsets,labels):\n    new_offsets=[]\n    new_labels=[]\n    \n    for ix,span in enumerate(offsets):\n        \n        if ix==0 and span[0]==0:\n            new_offsets.append(span)\n            new_labels.append(labels[ix])\n            \n        elif ix==0 and span[0]!=0:\n            new_offsets.append((0,span[0]-1))\n            new_labels.append('Nil')\n            \n            new_offsets.append(span)\n            new_labels.append(labels[ix])\n            \n        elif offsets[ix][0]-offsets[ix-1][1]>1:\n            new_offsets.append((offsets[ix-1][1]+1,offsets[ix][0]-1))\n            new_offsets.append(span)\n            \n            new_labels.append('Nil')\n            new_labels.append(labels[ix])\n        else:\n            new_offsets.append(span)\n            new_labels.append(labels[ix])\n            \n    return (new_offsets,new_labels)\n\n\ndef fix_chars(text,span):\n    span[-1]=(span[-1][0],len(text.strip()))\n        \n    return span","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:42.749996Z","iopub.execute_input":"2022-01-03T12:35:42.750786Z","iopub.status.idle":"2022-01-03T12:35:42.778931Z","shell.execute_reply.started":"2022-01-03T12:35:42.750745Z","shell.execute_reply":"2022-01-03T12:35:42.777932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **📌 Note**: Brief overview of the above helper functions\n- correct_spans - fixes spans which are continuous \n    - eg: [(3,4),(4,5)] -> [(3,4),(5,6)]\n- fill_spans - fills the inbetween spans and also labels them as nil entity \n    - eg: [(5,8),(11,12)] ['claim','claim'] - > [(0,4),(5,8),(9,10),(11,12)] ['Nil','claim','Nil','claim']","metadata":{}},{"cell_type":"code","source":"train_df['spans']=train_df['spans'].apply(lambda x:correct_spans(x))\ntrain_df[['spans','discourse_type']]=train_df[['spans','discourse_type']].apply(lambda x:fill_spans(x[0],x[1]),axis=1,result_type='expand')\ntrain_df['spans']=train_df['spans'].apply(lambda x:correct_spans(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:42.785854Z","iopub.execute_input":"2022-01-03T12:35:42.786731Z","iopub.status.idle":"2022-01-03T12:35:44.494528Z","shell.execute_reply.started":"2022-01-03T12:35:42.786658Z","shell.execute_reply":"2022-01-03T12:35:44.49371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######### Unit test to make sure the spans are correct\nfor i in range(len(train_df)):\n    assert len(train_df.iloc[i]['spans'])==len(train_df.iloc[i]['discourse_type'])\n    \nfor i in range(len(train_df)):\n\n    spans=train_df.iloc[i]['spans']\n    for ix, span in enumerate(spans):\n        if ix==0:\n            pass\n        else:\n            assert (spans[ix][0]-spans[ix-1][1])==1","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:44.495934Z","iopub.execute_input":"2022-01-03T12:35:44.496166Z","iopub.status.idle":"2022-01-03T12:35:47.104376Z","shell.execute_reply.started":"2022-01-03T12:35:44.496133Z","shell.execute_reply":"2022-01-03T12:35:47.103675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ntest_names, train_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n    test_names.append(f.replace('.txt', ''))\n    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\ntrain_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\ntrain_text_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:35:47.105683Z","iopub.execute_input":"2022-01-03T12:35:47.105934Z","iopub.status.idle":"2022-01-03T12:36:56.66613Z","shell.execute_reply.started":"2022-01-03T12:35:47.105903Z","shell.execute_reply":"2022-01-03T12:36:56.665494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=train_text_df.merge(train_df,on='id')\n\ntrain_df['tok_len']=train_df['text'].apply(lambda x: len(spans_tokenizer.tokenize(x)))\ntrain_df=train_df[train_df['tok_len']<450].head(500)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:36:56.66757Z","iopub.execute_input":"2022-01-03T12:36:56.667814Z","iopub.status.idle":"2022-01-03T12:37:20.168108Z","shell.execute_reply.started":"2022-01-03T12:36:56.66778Z","shell.execute_reply":"2022-01-03T12:37:20.167346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p>We run only on limited set of examples for demo and also on records which are less than 512 token length</p>","metadata":{}},{"cell_type":"code","source":"train_df['spans']=train_df[['text','spans']].apply(lambda x:fix_chars(x[0],x[1]),axis=1)\ntrain_df['text']=train_df['text'].apply(lambda x:x.strip())","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.169313Z","iopub.execute_input":"2022-01-03T12:37:20.169643Z","iopub.status.idle":"2022-01-03T12:37:20.185923Z","shell.execute_reply.started":"2022-01-03T12:37:20.169605Z","shell.execute_reply":"2022-01-03T12:37:20.185275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE DICTIONARIES THAT WE CAN USE DURING TRAIN AND INFER\noutput_labels = ['Nil', 'Lead', 'Position','Claim', 'Counterclaim','Rebuttal', 'Evidence', 'Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.186941Z","iopub.execute_input":"2022-01-03T12:37:20.187327Z","iopub.status.idle":"2022-01-03T12:37:20.20096Z","shell.execute_reply.started":"2022-01-03T12:37:20.187291Z","shell.execute_reply":"2022-01-03T12:37:20.200149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['discourse_type']=train_df['discourse_type'].apply(lambda x: [labels_to_ids[label] for label in x])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.202379Z","iopub.execute_input":"2022-01-03T12:37:20.202663Z","iopub.status.idle":"2022-01-03T12:37:20.211875Z","shell.execute_reply.started":"2022-01-03T12:37:20.202629Z","shell.execute_reply":"2022-01-03T12:37:20.211246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[:2]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.213344Z","iopub.execute_input":"2022-01-03T12:37:20.213688Z","iopub.status.idle":"2022-01-03T12:37:20.238741Z","shell.execute_reply.started":"2022-01-03T12:37:20.213654Z","shell.execute_reply":"2022-01-03T12:37:20.238015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color='brown' size=4>3.2 Dataset</font>","metadata":{}},{"cell_type":"code","source":"class luke_dataset(Dataset):\n  def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n  def __getitem__(self, index):\n    \n        # GET TEXT AND WORD LABELS \n        text = self.data.text[index]  \n        spans = self.data.spans[index]\n        \n        print(\"1111\",spans)\n        # TOKENIZE TEXT\n        inputs = self.tokenizer(text, entity_spans=spans)\n        \n        inputs = {key: torch.as_tensor(val) for key, val in inputs.items()}\n        inputs['labels'] = torch.as_tensor(spans)\n        \n        return inputs\n\n  def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.240389Z","iopub.execute_input":"2022-01-03T12:37:20.240678Z","iopub.status.idle":"2022-01-03T12:37:20.248274Z","shell.execute_reply.started":"2022-01-03T12:37:20.240644Z","shell.execute_reply":"2022-01-03T12:37:20.247454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHOOSE VALIDATION INDEXES (that match my TF notebook)\nIDS = train_df.id.unique()\nprint('There are',len(IDS),'train texts. We will split 90% 10% for validation.')\n\n# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.249677Z","iopub.execute_input":"2022-01-03T12:37:20.250049Z","iopub.status.idle":"2022-01-03T12:37:20.262844Z","shell.execute_reply.started":"2022-01-03T12:37:20.250014Z","shell.execute_reply":"2022-01-03T12:37:20.26155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE TRAIN SUBSET AND VALID SUBSET\ndata = train_df[['id','text', 'spans','discourse_type']]\ntrain_dataset = data.loc[data['id'].isin(IDS[train_idx])].reset_index(drop=True)\ntest_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = luke_dataset(train_dataset, tokenizer, config['max_length'])\ntesting_set = luke_dataset(test_dataset, tokenizer,config['max_length'])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.264183Z","iopub.execute_input":"2022-01-03T12:37:20.264645Z","iopub.status.idle":"2022-01-03T12:37:20.277351Z","shell.execute_reply.started":"2022-01-03T12:37:20.264608Z","shell.execute_reply":"2022-01-03T12:37:20.276517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN DATASET AND VALID DATASET\ntrain_params = {'batch_size': config['train_batch_size'],\n                'shuffle': False,\n                'num_workers': 2,\n                'pin_memory':True\n                }\n\ntest_params = {'batch_size': config['valid_batch_size'],\n                'shuffle': False,\n                'num_workers': 2,\n                'pin_memory':True\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.278689Z","iopub.execute_input":"2022-01-03T12:37:20.278966Z","iopub.status.idle":"2022-01-03T12:37:20.287112Z","shell.execute_reply.started":"2022-01-03T12:37:20.278928Z","shell.execute_reply":"2022-01-03T12:37:20.286361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color='brown' size=4>3.3 Engine</font>","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\ndef train(df,epoch):\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    batch_size=config['train_batch_size']\n    pad_token=-100\n    \n    # put model in training mode\n    model.train()\n    \n    for batch_start_idx in range(0, len(df), batch_size):\n        \n        batch_examples = df.iloc[batch_start_idx:batch_start_idx + batch_size]\n        \n        # GET TEXT AND WORD LABELS \n        text = batch_examples['text'].values.tolist()  \n        spans = batch_examples['spans'].values.tolist() \n\n        labels=batch_examples['discourse_type'].values.tolist() \n        labels = zip(*itertools.zip_longest(*labels, fillvalue=pad_token))\n        \n        # TOKENIZE TEXT\n        inputs = tokenizer(text, entity_spans=spans,padding=True)\n        inputs = {key: torch.as_tensor(val).cuda() for key, val in inputs.items()}\n\n        inputs['labels']=torch.as_tensor(list(labels)).cuda()\n        \n        output=model(**inputs,return_dict=False)\n    \n        loss=output[0]\n        logits=output[1]\n        \n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += inputs['labels'].size(0)\n        \n        if batch_start_idx % 200==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss after {batch_start_idx:4d} training steps: {loss_step}\")\n           \n        # compute training accuracy\n        flattened_targets = inputs['labels'].view(-1) # shape (batch_size * seq_len,)\n        active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n        \n        # only compute accuracy at active labels\n        active_accuracy = inputs['labels'].view(-1) != -100 # shape (batch_size, seq_len)\n        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n        \n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        \n        #tr_labels.extend(labels)\n        #tr_preds.extend(predictions)\n\n        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n        tr_accuracy += tmp_tr_accuracy\n    \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=config['max_grad_norm']\n        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.288534Z","iopub.execute_input":"2022-01-03T12:37:20.289127Z","iopub.status.idle":"2022-01-03T12:37:20.305277Z","shell.execute_reply.started":"2022-01-03T12:37:20.289088Z","shell.execute_reply":"2022-01-03T12:37:20.304328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE MODEL\nmodel = LukeForEntitySpanClassification.from_pretrained(config['model_name'])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:20.307376Z","iopub.execute_input":"2022-01-03T12:37:20.307827Z","iopub.status.idle":"2022-01-03T12:37:27.810219Z","shell.execute_reply.started":"2022-01-03T12:37:20.30779Z","shell.execute_reply":"2022-01-03T12:37:27.809398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.classifier=nn.Linear(3072,len(labels_to_ids))\nmodel.num_labels=len(labels_to_ids)\nmodel.config.id2label=ids_to_labels\nmodel.config.label2id=labels_to_ids","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:27.81153Z","iopub.execute_input":"2022-01-03T12:37:27.811857Z","iopub.status.idle":"2022-01-03T12:37:27.81757Z","shell.execute_reply.started":"2022-01-03T12:37:27.81182Z","shell.execute_reply":"2022-01-03T12:37:27.816568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(config['device'])\noptimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rates'][0])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:27.823091Z","iopub.execute_input":"2022-01-03T12:37:27.823335Z","iopub.status.idle":"2022-01-03T12:37:32.83415Z","shell.execute_reply.started":"2022-01-03T12:37:27.823278Z","shell.execute_reply":"2022-01-03T12:37:32.833409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOOP TO TRAIN MODEL\nfor epoch in range(config['epochs']):\n\n    print(f\"### Training epoch: {epoch + 1}\")\n    for g in optimizer.param_groups: \n        g['lr'] = config['learning_rates'][epoch]\n    lr = optimizer.param_groups[0]['lr']\n    print(f'### LR = {lr}\\n')\n\n    train(train_df,epoch)\n    torch.cuda.empty_cache()\n    gc.collect()\n\ntorch.save(model.state_dict(), 'luke.pt')","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:37:32.835284Z","iopub.execute_input":"2022-01-03T12:37:32.835799Z","iopub.status.idle":"2022-01-03T12:39:35.340694Z","shell.execute_reply.started":"2022-01-03T12:37:32.835754Z","shell.execute_reply":"2022-01-03T12:39:35.339847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='brown' size=4>4. HF trainer for NER</font>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/train-ner/train_NER.csv',nrows=1000)\n\ntrain_df['tokens']=train_df['text'].apply(lambda x: x.split())\ntrain_df['entities']=train_df['entities'].apply(lambda x: eval(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:14.205246Z","iopub.execute_input":"2022-01-03T12:46:14.205817Z","iopub.status.idle":"2022-01-03T12:46:14.95454Z","shell.execute_reply.started":"2022-01-03T12:46:14.205758Z","shell.execute_reply":"2022-01-03T12:46:14.953608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:14.956289Z","iopub.execute_input":"2022-01-03T12:46:14.956656Z","iopub.status.idle":"2022-01-03T12:46:14.983558Z","shell.execute_reply.started":"2022-01-03T12:46:14.956593Z","shell.execute_reply":"2022-01-03T12:46:14.982551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHOOSE VALIDATION INDEXES (that match my TF notebook)\nIDS = train_df.id.unique()\nprint('There are',len(IDS),'train texts. We will split 90% 10% for validation.')\n\n# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:14.986361Z","iopub.execute_input":"2022-01-03T12:46:14.986637Z","iopub.status.idle":"2022-01-03T12:46:15.000839Z","shell.execute_reply.started":"2022-01-03T12:46:14.986589Z","shell.execute_reply":"2022-01-03T12:46:14.999752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE TRAIN SUBSET AND VALID SUBSET\ndata = train_df[['id','tokens', 'entities']]\ntrain_dataset = data.loc[data['id'].isin(IDS[train_idx]),['tokens', 'entities']].reset_index(drop=True)\nval_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(val_dataset.shape))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.002427Z","iopub.execute_input":"2022-01-03T12:46:15.003229Z","iopub.status.idle":"2022-01-03T12:46:15.021749Z","shell.execute_reply.started":"2022-01-03T12:46:15.003183Z","shell.execute_reply":"2022-01-03T12:46:15.020428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_all_tokens=True\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], padding=True, truncation=True, \n                                 is_split_into_words=True, return_offsets_mapping=True)\n\n    labels = []\n    for i, label in enumerate(examples[\"entities\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append(-100)\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # For the other tokens in a word, we set the label to either the current label with I-tag or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                if label_all_tokens:\n                    new_label = id2tag[label[word_idx]].replace('B-', 'I-')\n                    label_ids.append(tag2id[new_label])\n                else:\n                    label_ids.append(-100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.023807Z","iopub.execute_input":"2022-01-03T12:46:15.024315Z","iopub.status.idle":"2022-01-03T12:46:15.034705Z","shell.execute_reply.started":"2022-01-03T12:46:15.024271Z","shell.execute_reply":"2022-01-03T12:46:15.033779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.037628Z","iopub.execute_input":"2022-01-03T12:46:15.038882Z","iopub.status.idle":"2022-01-03T12:46:15.04915Z","shell.execute_reply.started":"2022-01-03T12:46:15.038809Z","shell.execute_reply":"2022-01-03T12:46:15.048218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mappings\nall_tags = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nunique_tags = sorted(set(all_tags))\ntag2id = {tag: id for id, tag in enumerate(unique_tags)}\nid2tag = {id: tag for tag, id in tag2id.items()}","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.051197Z","iopub.execute_input":"2022-01-03T12:46:15.052149Z","iopub.status.idle":"2022-01-03T12:46:15.065088Z","shell.execute_reply.started":"2022-01-03T12:46:15.052104Z","shell.execute_reply":"2022-01-03T12:46:15.063869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode labels\ntrain_dataset['entities'] = train_dataset['entities'].apply(lambda labels: [tag2id[x] for x in labels])\nval_dataset['entities'] = val_dataset['entities'].apply(lambda labels: [tag2id[x] for x in labels])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.067104Z","iopub.execute_input":"2022-01-03T12:46:15.067911Z","iopub.status.idle":"2022-01-03T12:46:15.110699Z","shell.execute_reply.started":"2022-01-03T12:46:15.067869Z","shell.execute_reply":"2022-01-03T12:46:15.109488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ds.from_pandas(train_dataset[['tokens', 'entities']])\nval_dataset = ds.from_pandas(val_dataset[['tokens', 'entities']])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.114637Z","iopub.execute_input":"2022-01-03T12:46:15.114881Z","iopub.status.idle":"2022-01-03T12:46:15.21262Z","shell.execute_reply.started":"2022-01-03T12:46:15.114844Z","shell.execute_reply":"2022-01-03T12:46:15.211677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets = DatasetDict({\n    'train': train_dataset,\n    'val': val_dataset\n})\n\ndatasets","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.213938Z","iopub.execute_input":"2022-01-03T12:46:15.214273Z","iopub.status.idle":"2022-01-03T12:46:15.222199Z","shell.execute_reply.started":"2022-01-03T12:46:15.214217Z","shell.execute_reply":"2022-01-03T12:46:15.221138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_list = list(unique_tags)\nprint(sorted(label_list))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.224241Z","iopub.execute_input":"2022-01-03T12:46:15.224884Z","iopub.status.idle":"2022-01-03T12:46:15.234469Z","shell.execute_reply.started":"2022-01-03T12:46:15.224825Z","shell.execute_reply":"2022-01-03T12:46:15.233234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    batch_size=4\n    model_checkpoint = 'roberta-base'\n    num_classes=len(label_list)\n    label_all_tokens = True\n    lr_rate=3.3374982585607736e-05\n    epochs=5\n    weight_decay=0.013998996632720116\n    device='cuda' if cuda.is_available() else 'cpu'\n    \nconfig=config()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.236453Z","iopub.execute_input":"2022-01-03T12:46:15.237012Z","iopub.status.idle":"2022-01-03T12:46:15.289171Z","shell.execute_reply.started":"2022-01-03T12:46:15.236965Z","shell.execute_reply":"2022-01-03T12:46:15.287952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_checkpoint, add_prefix_space=True, do_lower_case=False)\nmodel = AutoModelForTokenClassification.from_pretrained(config.model_checkpoint, num_labels=len(label_list)).to(config.device)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:15.291926Z","iopub.execute_input":"2022-01-03T12:46:15.29245Z","iopub.status.idle":"2022-01-03T12:46:48.087191Z","shell.execute_reply.started":"2022-01-03T12:46:15.292385Z","shell.execute_reply":"2022-01-03T12:46:48.086055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.num_labels = config.num_classes\nmodel.config.num_labels = config.num_classes\nmodel.config.id2label=id2tag\nmodel.config.label2id=tag2id","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:48.088892Z","iopub.execute_input":"2022-01-03T12:46:48.089262Z","iopub.status.idle":"2022-01-03T12:46:48.094327Z","shell.execute_reply.started":"2022-01-03T12:46:48.089218Z","shell.execute_reply":"2022-01-03T12:46:48.093006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:48.096008Z","iopub.execute_input":"2022-01-03T12:46:48.096554Z","iopub.status.idle":"2022-01-03T12:46:48.108028Z","shell.execute_reply.started":"2022-01-03T12:46:48.096494Z","shell.execute_reply":"2022-01-03T12:46:48.106914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# align labels with subword tokens\ntokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:48.111117Z","iopub.execute_input":"2022-01-03T12:46:48.112232Z","iopub.status.idle":"2022-01-03T12:46:57.952519Z","shell.execute_reply.started":"2022-01-03T12:46:48.112182Z","shell.execute_reply":"2022-01-03T12:46:57.951553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = load_metric(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:57.954217Z","iopub.execute_input":"2022-01-03T12:46:57.954758Z","iopub.status.idle":"2022-01-03T12:46:58.855435Z","shell.execute_reply.started":"2022-01-03T12:46:57.954714Z","shell.execute_reply":"2022-01-03T12:46:58.854426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if '/' in config.model_checkpoint:\n    model_name = config.model_checkpoint.split(\"/\")[-1]\nelse:\n    model_name = config.model_checkpoint\n\nargs = TrainingArguments(\n    output_dir=f\"{model_name}-finetuned-ner\",\n    logging_dir = f\"{model_name}-finetuned-ner/runs\",\n    overwrite_output_dir=True,\n    evaluation_strategy = 'epoch',\n    save_strategy='epoch',\n    logging_strategy='epoch',\n#     save_steps=100,\n#     eval_steps=100,\n#     logging_steps=100,\n    #log_level='info',\n    learning_rate=config.lr_rate,\n    per_device_train_batch_size=config.batch_size,\n    per_device_eval_batch_size=config.batch_size,\n    num_train_epochs=config.epochs,\n    weight_decay=config.weight_decay,\n    push_to_hub=False,\n    load_best_model_at_end=True,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:58.856895Z","iopub.execute_input":"2022-01-03T12:46:58.857378Z","iopub.status.idle":"2022-01-03T12:46:59.682167Z","shell.execute_reply.started":"2022-01-03T12:46:58.857332Z","shell.execute_reply":"2022-01-03T12:46:59.681116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"val\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:46:59.685333Z","iopub.execute_input":"2022-01-03T12:46:59.686396Z","iopub.status.idle":"2022-01-03T12:46:59.699185Z","shell.execute_reply.started":"2022-01-03T12:46:59.686347Z","shell.execute_reply":"2022-01-03T12:46:59.698126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment the above line for training","metadata":{}},{"cell_type":"markdown","source":"# <font color='brown' size=4>5. Acknowledgements</font>","metadata":{}},{"cell_type":"markdown","source":"1. https://arxiv.org/pdf/2010.01057.pdf\n2. https://huggingface.co/docs/transformers/model_doc/luke\n3. https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}