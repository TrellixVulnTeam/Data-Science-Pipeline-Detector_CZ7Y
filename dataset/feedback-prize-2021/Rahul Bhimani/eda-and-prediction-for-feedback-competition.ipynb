{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA:\n\n- EDA stands for Exploratory Data Analysis\n\n- This is a Data Science method in which the data is analysed and sorted for Machine Learning purpose Or Deep Learning purpose.\n\n- Also the featured data can be displayed using different plotting method, which are simple distplot, boxplot, barchart, piechart, etc.\n\n- This sorted data is known as features.\n\n- This can be also known as statistical Analysis, this is due to knowing of the given data, with is better probability using different methods and more.","metadata":{}},{"cell_type":"markdown","source":"# About competition :\n![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.makemyassignments.com%2Fblog%2Fwp-content%2Fuploads%2F2020%2F04%2F1_JrK45nVmcOg2Uvx0nY7gzA.jpeg&f=1&nofb=1)\nIn this competition we are tasked with giving feedback on argumentative essays by US students in class 6 to 12.\n\nIn this specifically our task is to predict the human annotations.\n\n- Segmenting each essay into discrete rhetorical and argumenatative elemenst.\n\n- Classify each elements.","metadata":{}},{"cell_type":"code","source":"# importing all the libraries : \n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pylab as plt  \nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nfrom itertools import cycle\n\nplt.style.use('ggplot')\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-19T09:51:06.372686Z","iopub.execute_input":"2021-12-19T09:51:06.373404Z","iopub.status.idle":"2021-12-19T09:51:07.198812Z","shell.execute_reply.started":"2021-12-19T09:51:06.373311Z","shell.execute_reply":"2021-12-19T09:51:07.198099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading data:\n\nHere our train data or .csv file is readed using pandas. By using read_csv() method .","metadata":{}},{"cell_type":"code","source":"# Reading the data train.csv \ntrain = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:07.202055Z","iopub.execute_input":"2021-12-19T09:51:07.202252Z","iopub.status.idle":"2021-12-19T09:51:08.979146Z","shell.execute_reply.started":"2021-12-19T09:51:07.202229Z","shell.execute_reply":"2021-12-19T09:51:08.978424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()  # Taking use full information from csv file\ntrain.describe() # Taking stastical anaylsis of train file","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:08.980219Z","iopub.execute_input":"2021-12-19T09:51:08.980457Z","iopub.status.idle":"2021-12-19T09:51:09.101664Z","shell.execute_reply.started":"2021-12-19T09:51:08.980424Z","shell.execute_reply":"2021-12-19T09:51:09.100856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading sample submisson file to fill final predication\nsample_submission_file = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\nsample_submission_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.103701Z","iopub.execute_input":"2021-12-19T09:51:09.10395Z","iopub.status.idle":"2021-12-19T09:51:09.123057Z","shell.execute_reply.started":"2021-12-19T09:51:09.103915Z","shell.execute_reply":"2021-12-19T09:51:09.122344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the actual data from different dict.","metadata":{}},{"cell_type":"code","source":"train_text = glob(\"../input/feedback-prize-2021/train/*.txt\")\ntest_text = glob(\"../input/feedback-prize-2021/test/*.txt\")\n\n\n# Remove {'#'} to see the paths of .txt files in two different variables\n#print(train_text)\n#print(test_text)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.124383Z","iopub.execute_input":"2021-12-19T09:51:09.124658Z","iopub.status.idle":"2021-12-19T09:51:09.421574Z","shell.execute_reply.started":"2021-12-19T09:51:09.124626Z","shell.execute_reply":"2021-12-19T09:51:09.420808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading data which is in .txt form (from train dict.)\n\n\n### Defining a function which can read a file in txt from:","metadata":{}},{"cell_type":"code","source":"# Function to read a txt file\n\ndef read_txt(file):\n    with open(f'../input/feedback-prize-2021/train/{file}.txt') as f:\n        a = f.read()\n        \n    return a","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.424662Z","iopub.execute_input":"2021-12-19T09:51:09.424864Z","iopub.status.idle":"2021-12-19T09:51:09.431297Z","shell.execute_reply.started":"2021-12-19T09:51:09.42484Z","shell.execute_reply":"2021-12-19T09:51:09.430514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just putting the id name in it\ntrain_file_txt = read_txt('0000D23A521A') \nprint(train_file_txt)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.433991Z","iopub.execute_input":"2021-12-19T09:51:09.434712Z","iopub.status.idle":"2021-12-19T09:51:09.444889Z","shell.execute_reply.started":"2021-12-19T09:51:09.434674Z","shell.execute_reply":"2021-12-19T09:51:09.444189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking into .csv file to find and look into the raw annotation. **Train essay from above has `Evidence` with 5 , `claim` is 2 and others are 1.**","metadata":{}},{"cell_type":"code","source":"train.query('id == \"423A1CA112E2\"')[\"discourse_type\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.445947Z","iopub.execute_input":"2021-12-19T09:51:09.446192Z","iopub.status.idle":"2021-12-19T09:51:09.467185Z","shell.execute_reply.started":"2021-12-19T09:51:09.446159Z","shell.execute_reply":"2021-12-19T09:51:09.466564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlighting the sentences or words\n\nThe HighLighting of the sentence or words can be easily done by using the data or information which is given in the .csv file, paticular the `discourse`.","metadata":{}},{"cell_type":"code","source":"def text_to_color(essay, discourse_type, predictionstring):\n    \"\"\"\n    Takes an entire essay, the discourse type and prediction string.\n    Returns highlighted text for the prediction string\n    \"\"\"\n    discourse_color_map = {\n        \"Lead\": 1,  # 1 red\n        \"Position\": 2,  # 2 green\n        \"Evidence\": 3,  # 3 yellow\n        \"Claim\": 4,  # 4 blue\n        \"Concluding Statement\": 5,  # 5 magenta\n        \"Counterclaim\": 6,  # 6 cyan\n        \"Rebuttal\": 7,  # 7 white\n        \"None\": 9,  # default\n    }\n    hcolor = discourse_color_map[discourse_type]\n    text_index = [int(c) for c in predictionstring.split()]\n    text_subset = \" \".join(np.array(essay.split())[text_index])\n    if discourse_type == \"None\":\n        return f\"\\033[4{hcolor};30m{text_subset}\\033[m\"\n    return f\"\\033[4{hcolor};30m{text_subset}\\033[m\"\n\n\ndef get_non_discourse_df(train, essay, id):\n    all_pred_strings = \" \".join(train.query(\"id == @id\")[\"predictionstring\"].values)\n    all_pred_strings = [int(c) for c in all_pred_strings.split()]\n    # [c for c in all_pred_strings\n\n    non_discourse_df = pd.DataFrame(\n        [c for c in range(len(essay.split())) if c not in all_pred_strings]\n    )\n    non_discourse_df.columns = [\"predictionstring\"]\n    non_discourse_df[\"cluster\"] = (\n        non_discourse_df[\"predictionstring\"].diff().fillna(1) > 1\n    ).cumsum()\n\n    non_discourse_strings = []\n    for i, d in non_discourse_df.groupby(\"cluster\"):\n        pred_string = [str(x) for x in d[\"predictionstring\"].values]\n        non_discourse_strings.append(\" \".join(pred_string))\n    df = pd.DataFrame(non_discourse_strings).rename(columns={0: \"predictionstring\"})\n    df[\"discourse_type\"] = \"None\"\n    return df\n\n\ndef get_colored_essay(train, id):\n    essay = read_txt(id)\n    all_text = \"\"\n    train_subset = train.query(\"id == @id\").copy()\n    df = get_non_discourse_df(train, essay, id)\n    train_subset = pd.concat([train_subset, df])\n    train_subset[\"first_index\"] = (\n        train_subset[\"predictionstring\"].str.split(\" \").str[0].astype(\"int\")\n    )\n    train_subset = train_subset.sort_values(\"first_index\").reset_index(drop=True).copy()\n    for i, d in train_subset.iterrows():\n        colored_text = text_to_color(essay, d.discourse_type, d.predictionstring)\n        all_text += \" \" + colored_text\n    return all_text[1:]\n\n\nall_text = get_colored_essay(train, \"423A1CA112E2\")\nprint(all_text)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.469809Z","iopub.execute_input":"2021-12-19T09:51:09.470031Z","iopub.status.idle":"2021-12-19T09:51:09.514371Z","shell.execute_reply.started":"2021-12-19T09:51:09.470005Z","shell.execute_reply":"2021-12-19T09:51:09.5135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting the graph","metadata":{}},{"cell_type":"code","source":"# Most annotation used:\n\nax = (\n    train[\"discourse_type\"]\n    .value_counts(ascending=True)\n    .plot(kind=\"barh\", figsize=(15, 5), color=color_pal[5])\n)\nax.set_title(\"Discourse Label Frequency (in train)\", fontsize=16)\nax.bar_label(ax.containers[0], label_type=\"edge\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.517638Z","iopub.execute_input":"2021-12-19T09:51:09.517972Z","iopub.status.idle":"2021-12-19T09:51:09.788038Z","shell.execute_reply.started":"2021-12-19T09:51:09.517934Z","shell.execute_reply":"2021-12-19T09:51:09.787376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = (\n    train.groupby(\"discourse_type\")[[\"discourse_start\", \"discourse_end\"]]\n    .mean()\n    .sort_values(\"discourse_start\")\n    .plot(\n        kind=\"barh\",\n        figsize=(15, 7),\n    )\n)\nax.set_title(\"Average Discourse Label Start and End\", fontsize=24)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:09.789247Z","iopub.execute_input":"2021-12-19T09:51:09.789571Z","iopub.status.idle":"2021-12-19T09:51:10.056445Z","shell.execute_reply.started":"2021-12-19T09:51:09.789534Z","shell.execute_reply":"2021-12-19T09:51:10.055797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The length of each label\ntrain[\"discourse_len\"] = (train[\"discourse_end\"] - train[\"discourse_start\"]).astype(\n    \"int\"\n)\n\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x=\"discourse_type\", y=\"discourse_len\", data=train)\nax.set_title(\"The Average Lenth of each Discourse\")\nax.set_xlabel(\"Discourse Type\")\nax.set_ylabel(\"Average Text Length\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:10.057836Z","iopub.execute_input":"2021-12-19T09:51:10.058081Z","iopub.status.idle":"2021-12-19T09:51:11.31501Z","shell.execute_reply.started":"2021-12-19T09:51:10.058047Z","shell.execute_reply":"2021-12-19T09:51:11.314344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_dict = {}\nword_dict = {}\nfor t in tqdm(train_text):\n    with open(t, \"r\") as txt_file:\n        myid = t.split(\"/\")[-1].replace(\".txt\", \"\")\n        data = txt_file.read()\n        mylen = len(data.strip())\n        myword = len(data.split())\n        len_dict[myid] = mylen\n        word_dict[myid] = myword\ntrain[\"essay_len\"] = train[\"id\"].map(len_dict)\ntrain[\"essay_words\"] = train[\"id\"].map(word_dict)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:11.316322Z","iopub.execute_input":"2021-12-19T09:51:11.31675Z","iopub.status.idle":"2021-12-19T09:51:56.892033Z","shell.execute_reply.started":"2021-12-19T09:51:11.316711Z","shell.execute_reply":"2021-12-19T09:51:56.891228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 10))\ntrain.groupby(\"id\").first().plot(\n    x=\"essay_len\", y=\"essay_words\", kind=\"scatter\", color=color_pal[3], ax=ax\n)\nax.set_title(\"Word vs Character Length per Essay\", fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:56.893471Z","iopub.execute_input":"2021-12-19T09:51:56.893755Z","iopub.status.idle":"2021-12-19T09:51:57.29713Z","shell.execute_reply.started":"2021-12-19T09:51:56.893713Z","shell.execute_reply":"2021-12-19T09:51:57.296454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"discourse_start_pct\"] = train[\"discourse_start\"] / train[\"essay_len\"]\ntrain[\"discourse_end_pct\"] = train[\"discourse_end\"] / train[\"essay_len\"]\n\nax = (\n    train.groupby(\"discourse_type\")[[\"discourse_start_pct\", \"discourse_end_pct\"]]\n    .mean()\n    .sort_values(\"discourse_start_pct\")\n    .plot(\n        kind=\"barh\",\n        figsize=(15, 5),\n    )\n)\nax.set_title(\"Label Start and End as Percentage of Total Essay\", fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:57.298952Z","iopub.execute_input":"2021-12-19T09:51:57.299425Z","iopub.status.idle":"2021-12-19T09:51:57.595654Z","shell.execute_reply.started":"2021-12-19T09:51:57.299386Z","shell.execute_reply":"2021-12-19T09:51:57.593873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# DECLARE HOW MANY GPUS YOU WISH TO USE. \n# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n\n# VERSION FOR SAVING MODEL WEIGHTS\nVER=12\n\n# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\nLOAD_TOKENS_FROM = '../input/tf-longformer-v12'\n\n# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\nLOAD_MODEL_FROM = '../input/tf-longformer-v12'\n\n# IF FOLLOWING IS NONE, THEN NOTEBOOK \n# USES INTERNET AND DOWNLOADS HUGGINGFACE \n# CONFIG, TOKENIZER, AND MODEL\nDOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n\nif DOWNLOADED_MODEL_PATH is None:\n    DOWNLOADED_MODEL_PATH = 'model'    \nMODEL_NAME = 'allenai/longformer-base-4096'","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:57.597206Z","iopub.execute_input":"2021-12-19T09:51:57.597816Z","iopub.status.idle":"2021-12-19T09:51:57.611772Z","shell.execute_reply.started":"2021-12-19T09:51:57.597771Z","shell.execute_reply":"2021-12-19T09:51:57.608727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DOWNLOADED_MODEL_PATH == 'model':\n    os.mkdir('model')\n    \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    tokenizer.save_pretrained('model')\n\n    config = AutoConfig.from_pretrained(MODEL_NAME) \n    config.save_pretrained('model')\n\n    backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n    backbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:57.614319Z","iopub.execute_input":"2021-12-19T09:51:57.616449Z","iopub.status.idle":"2021-12-19T09:51:57.629089Z","shell.execute_reply.started":"2021-12-19T09:51:57.616309Z","shell.execute_reply":"2021-12-19T09:51:57.625687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *\nprint('TF version',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:51:57.63075Z","iopub.execute_input":"2021-12-19T09:51:57.63105Z","iopub.status.idle":"2021-12-19T09:52:07.793105Z","shell.execute_reply.started":"2021-12-19T09:51:57.631011Z","shell.execute_reply":"2021-12-19T09:52:07.792314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MULTIPLE GPUS\nif os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n    strategy = tf.distribute.get_strategy()\n    print('single strategy')\nelse:\n    strategy = tf.distribute.MirroredStrategy()\n    print('multiple strategy')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:07.794883Z","iopub.execute_input":"2021-12-19T09:52:07.795139Z","iopub.status.idle":"2021-12-19T09:52:07.812046Z","shell.execute_reply.started":"2021-12-19T09:52:07.795097Z","shell.execute_reply":"2021-12-19T09:52:07.811232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:07.813219Z","iopub.execute_input":"2021-12-19T09:52:07.813478Z","iopub.status.idle":"2021-12-19T09:52:07.832692Z","shell.execute_reply.started":"2021-12-19T09:52:07.813442Z","shell.execute_reply":"2021-12-19T09:52:07.831734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Labels \nprint('The train labels are:')\ntrain.discourse_type.unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:07.834192Z","iopub.execute_input":"2021-12-19T09:52:07.834645Z","iopub.status.idle":"2021-12-19T09:52:07.857179Z","shell.execute_reply.started":"2021-12-19T09:52:07.834601Z","shell.execute_reply":"2021-12-19T09:52:07.856547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total ids\n\nIDS = train.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:07.858445Z","iopub.execute_input":"2021-12-19T09:52:07.858845Z","iopub.status.idle":"2021-12-19T09:52:07.879989Z","shell.execute_reply.started":"2021-12-19T09:52:07.858808Z","shell.execute_reply":"2021-12-19T09:52:07.879258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize training data","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 1024\n\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\n# HELPER VARIABLES\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:07.881317Z","iopub.execute_input":"2021-12-19T09:52:07.881922Z","iopub.status.idle":"2021-12-19T09:52:08.047785Z","shell.execute_reply.started":"2021-12-19T09:52:07.881881Z","shell.execute_reply":"2021-12-19T09:52:08.046986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WE ASSUME DATAFRAME IS ASCENDING WHICH IT IS\nassert( np.sum(train.groupby('id')['discourse_start'].diff()<=0)==0 )\n\n# FOR LOOP THROUGH EACH TRAIN TEXT\nfor id_num in range(len(IDS)):\n    if LOAD_TOKENS_FROM: break\n    if id_num%100==0: print(id_num,', ',end='')\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = IDS[id_num]\n    name = f'../input/feedback-prize-2021/train/{n}.txt'\n    txt = open(name, 'r').read()\n    train_lens.append( len(txt.split()))\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    train_tokens[id_num,] = tokens['input_ids']\n    train_attention[id_num,] = tokens['attention_mask']\n    \n    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id==n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index>len(offsets)-1:\n            break\n        c = offsets[offset_index][0]\n        d = offsets[offset_index][1]\n        beginning = True\n        while b>c:\n            if (c>=a)&(b>=d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index>len(offsets)-1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:08.049102Z","iopub.execute_input":"2021-12-19T09:52:08.049426Z","iopub.status.idle":"2021-12-19T09:52:10.587691Z","shell.execute_reply.started":"2021-12-19T09:52:08.049388Z","shell.execute_reply":"2021-12-19T09:52:10.586925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1-np.max(targets,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:10.589028Z","iopub.execute_input":"2021-12-19T09:52:10.589432Z","iopub.status.idle":"2021-12-19T09:52:10.598184Z","shell.execute_reply.started":"2021-12-19T09:52:10.589396Z","shell.execute_reply":"2021-12-19T09:52:10.597265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:10.599976Z","iopub.execute_input":"2021-12-19T09:52:10.600537Z","iopub.status.idle":"2021-12-19T09:52:16.844832Z","shell.execute_reply.started":"2021-12-19T09:52:10.600353Z","shell.execute_reply":"2021-12-19T09:52:16.844062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n    \n    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n    \n    x = backbone(tokens, attention_mask=attention)\n    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n    #x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-6),\n                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:16.846095Z","iopub.execute_input":"2021-12-19T09:52:16.846342Z","iopub.status.idle":"2021-12-19T09:52:16.855345Z","shell.execute_reply.started":"2021-12-19T09:52:16.846305Z","shell.execute_reply":"2021-12-19T09:52:16.854533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:16.86073Z","iopub.execute_input":"2021-12-19T09:52:16.860918Z","iopub.status.idle":"2021-12-19T09:52:47.405827Z","shell.execute_reply.started":"2021-12-19T09:52:16.860895Z","shell.execute_reply":"2021-12-19T09:52:47.405044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train or load model","metadata":{}},{"cell_type":"code","source":"# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:47.406968Z","iopub.execute_input":"2021-12-19T09:52:47.408952Z","iopub.status.idle":"2021-12-19T09:52:47.421563Z","shell.execute_reply.started":"2021-12-19T09:52:47.408909Z","shell.execute_reply":"2021-12-19T09:52:47.420737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 5\nLRS = [1e-4, 1e-4, 1e-4, 1e-4, 1e-5]\ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:47.423547Z","iopub.execute_input":"2021-12-19T09:52:47.424021Z","iopub.status.idle":"2021-12-19T09:52:47.431228Z","shell.execute_reply.started":"2021-12-19T09:52:47.423976Z","shell.execute_reply":"2021-12-19T09:52:47.430437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD MODEL\nif LOAD_MODEL_FROM:\n    model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n    \n# OR TRAIN MODEL\nelse:\n    model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n          y = targets[train_idx,],\n          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                             targets[valid_idx,]),\n          callbacks = [lr_callback],\n          epochs = EPOCHS,\n          batch_size = 32,\n          verbose = 2)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:47.432433Z","iopub.execute_input":"2021-12-19T09:52:47.433692Z","iopub.status.idle":"2021-12-19T09:52:53.947511Z","shell.execute_reply.started":"2021-12-19T09:52:47.433624Z","shell.execute_reply":"2021-12-19T09:52:53.946767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions:","metadata":{}},{"cell_type":"code","source":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=2)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:52:53.948921Z","iopub.execute_input":"2021-12-19T09:52:53.949179Z","iopub.status.idle":"2021-12-19T09:56:31.983427Z","shell.execute_reply.started":"2021-12-19T09:52:53.949146Z","shell.execute_reply":"2021-12-19T09:56:31.982676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:31.984685Z","iopub.execute_input":"2021-12-19T09:56:31.985672Z","iopub.status.idle":"2021-12-19T09:56:31.990515Z","shell.execute_reply.started":"2021-12-19T09:56:31.98563Z","shell.execute_reply":"2021-12-19T09:56:31.989357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n    \n        # GET ID\n        if (id_num%100==0)&(verbose): \n            print(id_num,', ',end='')\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        # KEY:\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i<MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>4:\n                all_predictions.append( (n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:31.993433Z","iopub.execute_input":"2021-12-19T09:56:31.993948Z","iopub.status.idle":"2021-12-19T09:56:32.010162Z","shell.execute_reply.started":"2021-12-19T09:56:31.993919Z","shell.execute_reply":"2021-12-19T09:56:32.009365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\noof.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:32.013316Z","iopub.execute_input":"2021-12-19T09:56:32.0155Z","iopub.status.idle":"2021-12-19T09:56:49.50104Z","shell.execute_reply.started":"2021-12-19T09:56:32.015468Z","shell.execute_reply":"2021-12-19T09:56:49.500368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The following classes are present in oof preds:')\noof['class'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:49.502381Z","iopub.execute_input":"2021-12-19T09:56:49.502669Z","iopub.status.idle":"2021-12-19T09:56:49.511234Z","shell.execute_reply.started":"2021-12-19T09:56:49.502633Z","shell.execute_reply":"2021-12-19T09:56:49.510469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:49.512907Z","iopub.execute_input":"2021-12-19T09:56:49.513715Z","iopub.status.idle":"2021-12-19T09:56:49.52951Z","shell.execute_reply.started":"2021-12-19T09:56:49.513675Z","shell.execute_reply":"2021-12-19T09:56:49.528633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALID DATAFRAME\nvalid = train.loc[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:49.532275Z","iopub.execute_input":"2021-12-19T09:56:49.532476Z","iopub.status.idle":"2021-12-19T09:56:49.574514Z","shell.execute_reply.started":"2021-12-19T09:56:49.532445Z","shell.execute_reply":"2021-12-19T09:56:49.573662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:49.575743Z","iopub.execute_input":"2021-12-19T09:56:49.575972Z","iopub.status.idle":"2021-12-19T09:56:51.623505Z","shell.execute_reply.started":"2021-12-19T09:56:49.575939Z","shell.execute_reply":"2021-12-19T09:56:51.622808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:51.624893Z","iopub.execute_input":"2021-12-19T09:56:51.625126Z","iopub.status.idle":"2021-12-19T09:56:51.631656Z","shell.execute_reply.started":"2021-12-19T09:56:51.625094Z","shell.execute_reply":"2021-12-19T09:56:51.63074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:51.633395Z","iopub.execute_input":"2021-12-19T09:56:51.633663Z","iopub.status.idle":"2021-12-19T09:56:51.686263Z","shell.execute_reply.started":"2021-12-19T09:56:51.63363Z","shell.execute_reply":"2021-12-19T09:56:51.685569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attention], \n                  batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:51.687466Z","iopub.execute_input":"2021-12-19T09:56:51.688211Z","iopub.status.idle":"2021-12-19T09:56:52.322201Z","shell.execute_reply.started":"2021-12-19T09:56:51.688172Z","shell.execute_reply":"2021-12-19T09:56:52.321477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = get_preds(dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:56:52.323215Z","iopub.execute_input":"2021-12-19T09:56:52.323479Z","iopub.status.idle":"2021-12-19T09:56:52.407247Z","shell.execute_reply.started":"2021-12-19T09:56:52.323441Z","shell.execute_reply":"2021-12-19T09:56:52.406467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WRITE SUBMISSION CSV\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:03:29.803074Z","iopub.execute_input":"2021-12-19T10:03:29.803366Z","iopub.status.idle":"2021-12-19T10:03:29.813359Z","shell.execute_reply.started":"2021-12-19T10:03:29.803334Z","shell.execute_reply":"2021-12-19T10:03:29.8125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# please upvote","metadata":{}}]}