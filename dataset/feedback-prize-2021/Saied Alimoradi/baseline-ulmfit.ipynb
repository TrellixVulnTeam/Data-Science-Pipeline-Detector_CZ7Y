{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n<!-- ![](https://cdn.dribbble.com/users/2353146/screenshots/9073115/media/eadd1ef050b49fbdf20d42e7c504458d.png)\nImage is made by [Алена Молчанова](https://dribbble.com/shots/9073115-WRITING?utm_source=Clipboard_Shot&utm_campaign=mimipig&utm_content=WRITING&utm_medium=Social_Share&utm_source=Clipboard_Shot&utm_campaign=mimipig&utm_content=WRITING&utm_medium=Social_Share) -->\n\n# Here is a baseline notebook for [Feedback Prize - Evaluating Student Writing](https://www.kaggle.com/c/feedback-prize-2021/)\n\n\n**The notebook outline:** \n1. spacy EDA \n2. Text preprocessing and transforming data to sentences using this great notebook: [📖Feedback- Baseline🤗 Sentence Classifier [0.226]](https://www.kaggle.com/julian3833/feedback-baseline-sentence-classifier-0-226)\n3. Train model with [ULMFIT](https://arxiv.org/pdf/1708.02182v1.pdf) using fastai library for sentence classficiation\n4. Submit\n\n\n","metadata":{}},{"cell_type":"markdown","source":"### First we do necessary imports and load the data","metadata":{}},{"cell_type":"code","source":"from fastai.text import *\nfrom fastai.text.all import *\nimport nltk\nimport spacy\nimport pandas as pd\nimport numpy as np\nimport fastai\nimport torch\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import classification_report\ntqdm.pandas()\nprint(f\"fastai version: {fastai.__version__}\")\nif torch.cuda.is_available():\n    print(f\"GPU which is used : {torch.cuda.get_device_name(0)}\")\n    \n\n## defining directories\nroot = Path().absolute()\ndata_dir = root / \"../input/feedback-prize-2021\"\ntrain_text_dir = data_dir / \"train\"\ntest_text_dir = data_dir / \"test\"\nout = root / \"out\"\nout.mkdir(exist_ok=True)\n# data_dir.ls()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:01.640417Z","iopub.execute_input":"2021-12-27T17:12:01.640752Z","iopub.status.idle":"2021-12-27T17:12:05.94647Z","shell.execute_reply.started":"2021-12-27T17:12:01.640662Z","shell.execute_reply":"2021-12-27T17:12:05.945696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(data_dir / \"train.csv\", dtype={'discourse_id': int, 'discourse_start': int, 'discourse_end': int})\nprint('\\nHere is the data sample : \\n\\n')\ndf.head(2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:05.948022Z","iopub.execute_input":"2021-12-27T17:12:05.948265Z","iopub.status.idle":"2021-12-27T17:12:06.691468Z","shell.execute_reply.started":"2021-12-27T17:12:05.948231Z","shell.execute_reply":"2021-12-27T17:12:06.690693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize classes","metadata":{}},{"cell_type":"code","source":"def visualize_classes(file_name):\n    ents = []\n    for i, row in df[df['id'] == file_name].iterrows():\n        ents.append({\n                        'start': int(row['discourse_start']), \n                         'end': int(row['discourse_end']), \n                         'label': row['discourse_type']\n                    })\n    with open(f'{train_text_dir}/{file_name}.txt', 'r') as file: data = file.read()\n\n    doc2 = {\n        \"text\": data,\n        \"ents\": ents,\n        \"title\": file_name\n    }\n    colors = {'Lead': '#c1dbd5',\n            'Position': '#fcf2b6',\n            'Claim': '#bbceae',\n            'Evidence': '#c8f1bf',\n            'Counterclaim': '#d3b88a',\n            'Concluding Statement': '#ed9a8b',\n            'Rebuttal': '#ef8c9d'}\n\n    options = {\"ents\": df.discourse_type.unique().tolist(), \"colors\": colors}\n    spacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)\n    print('\\n')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:06.692834Z","iopub.execute_input":"2021-12-27T17:12:06.693425Z","iopub.status.idle":"2021-12-27T17:12:06.702342Z","shell.execute_reply.started":"2021-12-27T17:12:06.693386Z","shell.execute_reply":"2021-12-27T17:12:06.701254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize 4 sample of data","metadata":{}},{"cell_type":"code","source":"for i in df['id'].sample(n=4, random_state=2).values.tolist():\n    visualize_classes(i)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:06.704744Z","iopub.execute_input":"2021-12-27T17:12:06.705384Z","iopub.status.idle":"2021-12-27T17:12:06.890549Z","shell.execute_reply.started":"2021-12-27T17:12:06.705353Z","shell.execute_reply":"2021-12-27T17:12:06.888493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### preprocessing","metadata":{}},{"cell_type":"markdown","source":"Convert classes into ints, also we put `No Class` for sentences with no label","metadata":{"id":"FcaDhR1k_JzV"}},{"cell_type":"code","source":"ID2CLASS = dict(enumerate(df['discourse_type'].unique().tolist() + ['No Class']))\nCLASS2ID = {v: k for k, v in ID2CLASS.items()}\n# print(ID2CLASS)\nCLASS2ID","metadata":{"id":"zD5Z06uF-yIE","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:06.891686Z","iopub.execute_input":"2021-12-27T17:12:06.892023Z","iopub.status.idle":"2021-12-27T17:12:06.910739Z","shell.execute_reply.started":"2021-12-27T17:12:06.891986Z","shell.execute_reply":"2021-12-27T17:12:06.90999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here are some helper functions to transform data to sentences\n* fill_gaps(), classifies parts of the texts that has not label as \"No Class\" \n* get_elements(), creates a list of text sections for a each text\n* get_x_samples(), maps each sentences to their labels.","metadata":{}},{"cell_type":"code","source":"def get_text(source_dir,a_id):\n    a_file = f\"{source_dir}/{a_id}.txt\"\n    with open(a_file, \"r\") as fp:\n        txt = fp.read()\n    return txt\n\ndef fill_gaps(elements, text):\n    \"\"\"Add \"No Class\" elements to a list of elements (see get_elements) \"\"\"\n    initial_idx = 0\n    final_idx = len(text)\n\n    # Add element at the beginning if it doesn't in index 0\n    new_elements = []\n    if elements[0][0] != initial_idx:\n        starting_element = (0, elements[0][0]-1, 'No Class')\n        new_elements.append(starting_element)\n\n\n    # Add element at the end if it doesn't in index \"-1\"\n    if elements[-1][1] != final_idx:\n        closing_element = (elements[-1][1]+1, final_idx, 'No Class')\n        new_elements.append(closing_element)\n\n    elements += new_elements\n    elements = sorted(elements, key=lambda x: x[0])\n\n    # Add \"No class\" elements inbetween separated elements \n    new_elements = []\n    for i in range(1, len(elements)-1):\n        if elements[i][0] != elements[i-1][1] + 1 and elements[i][0] != elements[i-1][1]:\n            new_element = (elements[i-1][1] + 1, elements[i][0]-1, 'No Class')\n            new_elements.append(new_element)\n\n    elements += new_elements\n    elements = sorted(elements, key=lambda x: x[0])\n    return elements\n\n\ndef get_elements(df, text_id, do_fill_gaps=True, text=None):\n    \"\"\"Get a list of (start, end, class) elements for a given text_id\"\"\"\n    text = get_text(text_id) if text is None else text\n    df_text = df[df['id'] == text_id]\n    elements = df_text[['discourse_start', 'discourse_end', 'discourse_type']].to_records(index=False).tolist()\n    if do_fill_gaps:\n        elements = fill_gaps(elements, text)\n    return elements\n\ndef get_x_samples(df, text_id, do_fill_gaps=True):\n    \"\"\"Create a dataframe of the sentences of the text_id, with columns text, label \"\"\"\n    text = get_text(train_text_dir,text_id)\n    elements = get_elements(df, text_id, do_fill_gaps, text)\n    sentences = []\n    for start, end, class_ in elements:\n        elem_sentences = nltk.sent_tokenize(text[start:end])\n        sentences += [(sentence, class_) for sentence in elem_sentences]\n    df = pd.DataFrame(sentences, columns=['text', 'label'])\n    df['label'] = df['label'].map(CLASS2ID)\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:06.912266Z","iopub.execute_input":"2021-12-27T17:12:06.912664Z","iopub.status.idle":"2021-12-27T17:12:06.927131Z","shell.execute_reply.started":"2021-12-27T17:12:06.912626Z","shell.execute_reply":"2021-12-27T17:12:06.926294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_ids = df['id'].unique().tolist()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:12:06.928444Z","iopub.execute_input":"2021-12-27T17:12:06.929212Z","iopub.status.idle":"2021-12-27T17:12:06.953515Z","shell.execute_reply.started":"2021-12-27T17:12:06.929174Z","shell.execute_reply":"2021-12-27T17:12:06.952726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here we build our sentence dataframe","metadata":{}},{"cell_type":"code","source":"x = []\nfor text_id in tqdm(text_ids):\n    x.append(get_x_samples(df, text_id))\n\ndf_sentences = pd.concat(x)\ndf_sentences = df_sentences[df_sentences.text.str.split().str.len() >= 3]\ndf_sentences.to_csv(\"df_sentence.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T17:12:06.955064Z","iopub.execute_input":"2021-12-27T17:12:06.955741Z","iopub.status.idle":"2021-12-27T17:18:52.005537Z","shell.execute_reply.started":"2021-12-27T17:12:06.9557Z","shell.execute_reply":"2021-12-27T17:18:52.004614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Slice trainset, in order to train the kernel faster\n\nIt should be removed when training model for submission","metadata":{}},{"cell_type":"code","source":"df_sample = df_sentences.sample(n=3000, random_state=42)\nprint('class distribution in sample set :')\ndf_sample['label'].value_counts()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:18:52.01031Z","iopub.execute_input":"2021-12-27T17:18:52.010638Z","iopub.status.idle":"2021-12-27T17:18:52.032513Z","shell.execute_reply.started":"2021-12-27T17:18:52.010605Z","shell.execute_reply":"2021-12-27T17:18:52.031836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finetune AWD-LSTM on our corpus to train [ULMFIT](https://docs.fast.ai/tutorial.text.html) ","metadata":{"id":"wTJ48LTTElwc"}},{"cell_type":"markdown","source":"Create [TextDataLoaders](https://docs.fast.ai/text.data.html#TextDataLoaders.from_df) from our df_sentences. keep in mind that using `is_lm` to `True` because later on we want to use it for finetuning our language model.","metadata":{"id":"AQvBuRKuDIy_"}},{"cell_type":"code","source":"dls_lm = TextDataLoaders.from_df(df_sample, path=data_dir,is_lm=True)\ndls_lm.show_batch(max_n=3)","metadata":{"executionInfo":{"elapsed":347216,"status":"ok","timestamp":1640091119499,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"IyrbzwnBAMln","outputId":"0a70e85c-f6a1-429b-abcf-d80ab1bd72b7","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:18:52.035565Z","iopub.execute_input":"2021-12-27T17:18:52.035767Z","iopub.status.idle":"2021-12-27T17:19:00.147575Z","shell.execute_reply.started":"2021-12-27T17:18:52.035744Z","shell.execute_reply":"2021-12-27T17:19:00.146789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"and save dataloader for later use","metadata":{"id":"hTQWhNhXGihQ"}},{"cell_type":"code","source":"torch.save(dls_lm, out / 'dls_lm.pkl')\n# dls_lm = torch.load(out / 'dls_lm.pkl')","metadata":{"id":"gIokcqvfgNDw","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T17:19:00.149121Z","iopub.execute_input":"2021-12-27T17:19:00.149427Z","iopub.status.idle":"2021-12-27T17:19:00.244623Z","shell.execute_reply.started":"2021-12-27T17:19:00.149373Z","shell.execute_reply":"2021-12-27T17:19:00.24391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we instantiate our [language_model_learner](https://docs.fast.ai/text.learner.html#language_model_learner) and using [Mixed precision training](https://docs.fast.ai/callback.fp16.html#Learner.to_fp16) by adding `.to_fp16()` at the end of code","metadata":{"id":"arHsbR2y5_Z8"}},{"cell_type":"code","source":"learn = language_model_learner(dls_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], path=data_dir, wd=0.1, model_dir=\"/tmp/model/\").to_fp16()","metadata":{"executionInfo":{"elapsed":11966,"status":"ok","timestamp":1640091143616,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"41DLv4vWC33A","outputId":"d5f33be5-9cd3-413e-ec96-a2d7b2828cd5","execution":{"iopub.status.busy":"2021-12-27T17:19:00.246766Z","iopub.execute_input":"2021-12-27T17:19:00.247212Z","iopub.status.idle":"2021-12-27T17:19:00.738159Z","shell.execute_reply.started":"2021-12-27T17:19:00.247172Z","shell.execute_reply":"2021-12-27T17:19:00.737407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using learning rate finder of fastai. Here we plot the loss versus the learning rates. We're interested in finding a good order of magnitude of the learning rate, so we plot with a log scale. Then, we choose a value that is approximately in the middle of the sharpest downward slope.\n\nFor more information on the finding the good learning rate you can refer to this post: [how do you find a good learning rate](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)","metadata":{"id":"WrD67LfV5u0F"}},{"cell_type":"code","source":"learn.lr_find()","metadata":{"executionInfo":{"elapsed":45671,"status":"ok","timestamp":1640091189253,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"q4VQ0kN2C6DR","outputId":"668c4dba-afa3-4120-c2fb-12f37e9d4de5","execution":{"iopub.status.busy":"2021-12-27T17:19:00.739573Z","iopub.execute_input":"2021-12-27T17:19:00.739826Z","iopub.status.idle":"2021-12-27T17:19:27.166462Z","shell.execute_reply.started":"2021-12-27T17:19:00.739792Z","shell.execute_reply":"2021-12-27T17:19:27.165787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we finetune the model. By default, a pretrained Learner is in a frozen state, meaning that only the head of the model will train while the body stays frozen.","metadata":{"id":"QPebovzF6j5a"}},{"cell_type":"code","source":"learn.fit_one_cycle(1, 1e-3)","metadata":{"executionInfo":{"elapsed":751155,"status":"ok","timestamp":1640091940370,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"47JAW7aNHtdn","outputId":"3f56bccf-e801-4fc0-d472-465e52ff51c5","execution":{"iopub.status.busy":"2021-12-27T17:19:27.1679Z","iopub.execute_input":"2021-12-27T17:19:27.168186Z","iopub.status.idle":"2021-12-27T17:19:31.268615Z","shell.execute_reply.started":"2021-12-27T17:19:27.16815Z","shell.execute_reply":"2021-12-27T17:19:31.267963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can then fine-tune the model after unfreezing","metadata":{"id":"tAwMbvR26mR9"}},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(7, 1e-4)","metadata":{"id":"i5mP4BbcJ3LZ","outputId":"3993a9ca-4ac9-4068-d97f-5e549103036d","execution":{"iopub.status.busy":"2021-12-27T17:19:31.269999Z","iopub.execute_input":"2021-12-27T17:19:31.270254Z","iopub.status.idle":"2021-12-27T17:19:58.252205Z","shell.execute_reply.started":"2021-12-27T17:19:31.270219Z","shell.execute_reply":"2021-12-27T17:19:58.251198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving encoder for later use in text classification\nNOTE THAT\n\n`\nEncoder: The model not including the task-specific final layer(s). It means much the same thing as body when applied to vision CNNs, but tends to be more used for NLP and generative models\n`","metadata":{"id":"SuxNdScTjCJC"}},{"cell_type":"code","source":"learn.save_encoder(out / 'finetuned')","metadata":{"id":"6zTrB_YahkhB","execution":{"iopub.status.busy":"2021-12-27T17:19:58.25397Z","iopub.execute_input":"2021-12-27T17:19:58.254272Z","iopub.status.idle":"2021-12-27T17:19:58.466558Z","shell.execute_reply.started":"2021-12-27T17:19:58.254231Z","shell.execute_reply":"2021-12-27T17:19:58.465751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we gather our data for text classification almost exactly like before.\n\nThe main difference is that we have to use the exact same vocabulary as when we were fine-tuning our language model, or the weights learned won't make any sense. We pass that vocabulary with vocab by adding `text_vocab=dls_lm.vocab`","metadata":{"id":"Usf3Wl0w6t0O"}},{"cell_type":"code","source":"dls_clas = TextDataLoaders.from_df(df_sentences, path=data_dir, text_col='text', label_col='label',text_vocab=dls_lm.vocab)\ndls_clas.show_batch(max_n=3)","metadata":{"id":"6S5I8LmghmYt","outputId":"c9ca6218-5444-414e-d42b-bd32b69d2d50","execution":{"iopub.status.busy":"2021-12-27T17:19:58.46789Z","iopub.execute_input":"2021-12-27T17:19:58.468277Z","iopub.status.idle":"2021-12-27T17:28:47.636619Z","shell.execute_reply.started":"2021-12-27T17:19:58.468245Z","shell.execute_reply":"2021-12-27T17:28:47.635812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(dls_clas, out / 'dls_clas.pkl')\n# dls_clas = torch.load(out / 'dls_clas.pkl')","metadata":{"id":"JpVqkSfjj9xL","execution":{"iopub.status.busy":"2021-12-27T17:28:47.63816Z","iopub.execute_input":"2021-12-27T17:28:47.638415Z","iopub.status.idle":"2021-12-27T17:28:57.960235Z","shell.execute_reply.started":"2021-12-27T17:28:47.638379Z","shell.execute_reply":"2021-12-27T17:28:57.959344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we can define our text classifier like before:\n\nDefing metrics: we use [accuracy](https://docs.fast.ai/metrics.html#accuracy) and [F1Score](https://docs.fast.ai/metrics.html#F1Score)","metadata":{"id":"DoUNI-6u6zps"}},{"cell_type":"code","source":"metrics=[accuracy,F1Score(average='micro')]\nlearn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=metrics, model_dir=\"/tmp/model/\")","metadata":{"id":"ua2CDIxVnN2N","execution":{"iopub.status.busy":"2021-12-27T17:28:57.961586Z","iopub.execute_input":"2021-12-27T17:28:57.961867Z","iopub.status.idle":"2021-12-27T17:28:58.381094Z","shell.execute_reply.started":"2021-12-27T17:28:57.961828Z","shell.execute_reply":"2021-12-27T17:28:58.380348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As said before we load our encoder that we saved so that we use the exact same vocabulary as when we were fine-tuning our language model.","metadata":{"id":"_ELzdB_97zUz"}},{"cell_type":"code","source":"learn = learn.load_encoder(out / 'finetuned')","metadata":{"id":"w1HcuM7CoJUD","execution":{"iopub.status.busy":"2021-12-27T17:28:58.382304Z","iopub.execute_input":"2021-12-27T17:28:58.382847Z","iopub.status.idle":"2021-12-27T17:28:58.445151Z","shell.execute_reply.started":"2021-12-27T17:28:58.382807Z","shell.execute_reply":"2021-12-27T17:28:58.444428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.lr_find()","metadata":{"executionInfo":{"elapsed":21320,"status":"ok","timestamp":1640101863746,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"f31VJCr7oNXJ","outputId":"a7696246-cf7d-4453-de8a-13aba45ae876","execution":{"iopub.status.busy":"2021-12-27T17:28:58.446571Z","iopub.execute_input":"2021-12-27T17:28:58.446829Z","iopub.status.idle":"2021-12-27T17:29:07.265613Z","shell.execute_reply.started":"2021-12-27T17:28:58.446794Z","shell.execute_reply":"2021-12-27T17:29:07.264806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-2\nlearn.fit_one_cycle(1, lr)","metadata":{"executionInfo":{"elapsed":484682,"status":"ok","timestamp":1640106783853,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"P7ilMQw4pwsj","outputId":"e6f0f856-375d-49cf-d5b0-4c7b1bcc2557","execution":{"iopub.status.busy":"2021-12-27T17:29:07.267047Z","iopub.execute_input":"2021-12-27T17:29:07.26771Z","iopub.status.idle":"2021-12-27T17:35:48.616847Z","shell.execute_reply.started":"2021-12-27T17:29:07.267659Z","shell.execute_reply":"2021-12-27T17:35:48.615883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last step is to train with discriminative learning rates and gradual unfreezing. In computer vision, we often unfreeze the model all at once, but for NLP classifiers, we find that unfreezing a few layers at a time makes a real difference.","metadata":{"id":"lcskkI9G9Q1Q"}},{"cell_type":"markdown","source":"Here is abit of information about using `slice` in learning rate","metadata":{"id":"XjZPUY9q_Hn6"}},{"cell_type":"markdown","source":"Applying different lr for different groups is a technique called “discriminative layer training” that is introduced in part 1. This technique is commonly used in both computer vision and natural language processing.\nyou can find some good info by reading this blog post: [The 1cycle policy](https://sgugger.github.io/the-1cycle-policy.html#the-1cycle-policy)","metadata":{"id":"KPGNPJTu_Php"}},{"cell_type":"markdown","source":"slice() can be passed 1 or 2 arguments only. Below is a snippet of experiments for your reference:\n\n```python\nIn [9]: slice(5)\nOut[9]: slice(None, 5, None)\n\nIn [10]: slice(1, 5)\nOut[10]: slice(1, 5, None)\n```","metadata":{"id":"dSgcTvp0AJpG"}},{"cell_type":"markdown","source":"Therefore, in your last line, `slice(5e-3/(2.6**4),5e-3)` is equivalent to `slice(start = 5e-3/(2.6**4), stop = 5e-3, step = None)`","metadata":{"id":"RJTxC6qKAWb0"}},{"cell_type":"code","source":"learn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(lr/(2.6**4),lr))","metadata":{"executionInfo":{"elapsed":481442,"status":"ok","timestamp":1640107265273,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"ClNjjjcF8TAg","outputId":"e328a05d-823b-42a6-fd2b-33940ab7af14","execution":{"iopub.status.busy":"2021-12-27T17:35:48.618552Z","iopub.execute_input":"2021-12-27T17:35:48.620128Z","iopub.status.idle":"2021-12-27T17:42:40.811857Z","shell.execute_reply.started":"2021-12-27T17:35:48.620082Z","shell.execute_reply":"2021-12-27T17:42:40.810837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.freeze_to(-3)\nlearn.fit_one_cycle(1, slice(lr/2/(2.6**4),lr/2))","metadata":{"executionInfo":{"elapsed":493218,"status":"ok","timestamp":1640107758483,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"3kVmuq1C8TEI","outputId":"06e000a5-258f-41cc-e5f3-154c46ebf4e6","execution":{"iopub.status.busy":"2021-12-27T17:42:40.813683Z","iopub.execute_input":"2021-12-27T17:42:40.81398Z","iopub.status.idle":"2021-12-27T17:49:48.091897Z","shell.execute_reply.started":"2021-12-27T17:42:40.813925Z","shell.execute_reply":"2021-12-27T17:49:48.091045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(2, slice(lr/10/(2.6**4),lr/10))","metadata":{"executionInfo":{"elapsed":1010755,"status":"ok","timestamp":1640108769703,"user":{"displayName":"Ali Farid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3Z6YV0-2TkYch5LSCn-o-LLgml064QtEiE1mr=s64","userId":"12633910519416978942"},"user_tz":-210},"id":"jZT31B0F8THs","outputId":"690e8745-c3a0-48ae-b351-981a082fa923","execution":{"iopub.status.busy":"2021-12-27T17:49:48.093732Z","iopub.execute_input":"2021-12-27T17:49:48.094208Z","iopub.status.idle":"2021-12-27T18:04:31.881466Z","shell.execute_reply.started":"2021-12-27T17:49:48.09416Z","shell.execute_reply":"2021-12-27T18:04:31.880635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare test data","metadata":{}},{"cell_type":"code","source":"def create_df_test():\n    test_ids = [f[:-4] for f in os.listdir(test_text_dir)]\n    test_data = []\n    for test_id in test_ids:\n        text = get_text(test_text_dir, test_id)\n        sentences = nltk.sent_tokenize(text)\n        id_sentences = []\n        idx = 0 \n        for sentence in sentences:\n            id_sentence = []\n            words = sentence.split()\n            # I created this heuristic for mapping words in senteces to \"word indexes\"\n            # This is not definitive and might have strong drawbacks and problems\n            for w in words:\n                id_sentence.append(idx)\n                idx+=1\n            id_sentences.append(id_sentence)\n        test_data += list(zip([test_id] * len(sentences), sentences, id_sentences))\n    df_test = pd.DataFrame(test_data, columns=['id', 'text', 'ids'])\n    return df_test","metadata":{"execution":{"iopub.status.busy":"2021-12-27T18:04:31.883274Z","iopub.execute_input":"2021-12-27T18:04:31.883571Z","iopub.status.idle":"2021-12-27T18:04:31.891318Z","shell.execute_reply.started":"2021-12-27T18:04:31.883529Z","shell.execute_reply":"2021-12-27T18:04:31.89034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = create_df_test()\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T18:04:31.892963Z","iopub.execute_input":"2021-12-27T18:04:31.893226Z","iopub.status.idle":"2021-12-27T18:04:31.933204Z","shell.execute_reply.started":"2021-12-27T18:04:31.89319Z","shell.execute_reply":"2021-12-27T18:04:31.932573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make prediction","metadata":{}},{"cell_type":"code","source":"def predict(txt):\n    with learn.no_bar(), learn.no_logging():\n        return int(learn.predict(txt)[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-27T18:04:31.937175Z","iopub.execute_input":"2021-12-27T18:04:31.937367Z","iopub.status.idle":"2021-12-27T18:04:31.941383Z","shell.execute_reply.started":"2021-12-27T18:04:31.937344Z","shell.execute_reply":"2021-12-27T18:04:31.940691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['predictions'] = df_test[\"text\"].progress_apply(lambda x: predict(x))\n\ndf_test['class'] = df_test['predictions'].map(ID2CLASS)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T18:04:31.942744Z","iopub.execute_input":"2021-12-27T18:04:31.94333Z","iopub.status.idle":"2021-12-27T18:04:42.323412Z","shell.execute_reply.started":"2021-12-27T18:04:31.943293Z","shell.execute_reply":"2021-12-27T18:04:42.322722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Turn the word ids into predictionstring ","metadata":{}},{"cell_type":"code","source":"df_test['predictionstring'] = df_test['ids'].apply(lambda x: ' '.join([str(i) for i in x]))\ndf_test.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T18:04:42.324761Z","iopub.execute_input":"2021-12-27T18:04:42.325176Z","iopub.status.idle":"2021-12-27T18:04:42.34203Z","shell.execute_reply.started":"2021-12-27T18:04:42.325136Z","shell.execute_reply":"2021-12-27T18:04:42.341328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drop the sentences with label \"No class\" ","metadata":{}},{"cell_type":"code","source":"df_test = df_test[df_test['class'] != 'No Class']\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T18:04:42.343267Z","iopub.execute_input":"2021-12-27T18:04:42.343656Z","iopub.status.idle":"2021-12-27T18:04:42.363591Z","shell.execute_reply.started":"2021-12-27T18:04:42.343615Z","shell.execute_reply":"2021-12-27T18:04:42.3628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit\ndf_test[['id', 'class', 'predictionstring']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T18:04:42.364922Z","iopub.execute_input":"2021-12-27T18:04:42.365182Z","iopub.status.idle":"2021-12-27T18:04:42.373483Z","shell.execute_reply.started":"2021-12-27T18:04:42.36515Z","shell.execute_reply":"2021-12-27T18:04:42.372716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Refrences:**\n\n- [Transfer learning in text](https://docs.fast.ai/tutorial.text.html)\n- [Efficient multi-lingual language model fine-tuning](https://nlp.fast.ai/)\n- [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146)","metadata":{"id":"e4CyAqvO8Tem"}}]}