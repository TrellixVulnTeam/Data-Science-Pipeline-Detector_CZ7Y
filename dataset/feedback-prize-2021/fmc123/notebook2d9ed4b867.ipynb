{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)、\nfrom tqdm import tqdm#进度条显示\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom transformers import BertTokenizer, BertModel, BertConfig\nimport torch\nimport torch.nn as nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-09T03:17:17.938907Z","iopub.execute_input":"2022-02-09T03:17:17.939732Z","iopub.status.idle":"2022-02-09T03:17:25.288735Z","shell.execute_reply.started":"2022-02-09T03:17:17.939626Z","shell.execute_reply":"2022-02-09T03:17:25.288015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = 'bert-base-uncased'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('device=',device)\ntokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)#do_lower_case=False表示不识别非小写的单词，为True表示大小写的单词都识别\nconfig = BertConfig.from_pretrained(MODEL_NAME)#下载配置参数\nbert_model = BertModel.from_pretrained(MODEL_NAME, config=config)#下载模型参数","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:17:49.021245Z","iopub.execute_input":"2022-02-09T03:17:49.021586Z","iopub.status.idle":"2022-02-09T03:18:13.386542Z","shell.execute_reply.started":"2022-02-09T03:17:49.021555Z","shell.execute_reply":"2022-02-09T03:18:13.38579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('model')\ntokenizer.save_pretrained('model')\nconfig.save_pretrained('model')\nbert_model.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:18:26.237066Z","iopub.execute_input":"2022-02-09T03:18:26.237713Z","iopub.status.idle":"2022-02-09T03:18:26.787288Z","shell.execute_reply.started":"2022-02-09T03:18:26.237675Z","shell.execute_reply":"2022-02-09T03:18:26.786563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#text = \"[CLS] i love you! my dear friends all the time! what's your problem? [SEP]\"\ndf = pd.read_csv('../input/feedback-prize-2021/train.csv')\nsentences = df['discourse_text'].values\nlabels = df['discourse_type'].values\ndigit_dic = {'Concluding Statement': 0, 'Claim': 1, 'Evidence': 2, 'Counterclaim': 3, 'Rebuttal': 4, 'Position': 5, 'Lead': 6}\nlabels = [digit_dic[label] for label in labels]#将标签映射成数字\n#text = tokenizer.tokenize(text)\n#setences[0:5]\nlabels[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:18:30.603121Z","iopub.execute_input":"2022-02-09T03:18:30.603371Z","iopub.status.idle":"2022-02-09T03:18:32.061543Z","shell.execute_reply.started":"2022-02-09T03:18:30.603342Z","shell.execute_reply":"2022-02-09T03:18:32.060793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = ['[CLS] ' + sent + ' [SEP]' for sent in tqdm(sentences)]#一定注意添加CLS和SEP，因为bert识别以CLS为开头，以SEP为句子（文本）的分隔符\nsentences[0:5]#打印前5条数据","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:18:35.450248Z","iopub.execute_input":"2022-02-09T03:18:35.450529Z","iopub.status.idle":"2022-02-09T03:18:35.587926Z","shell.execute_reply.started":"2022-02-09T03:18:35.4505Z","shell.execute_reply":"2022-02-09T03:18:35.587111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_sents = [tokenizer.tokenize(sent) for sent in tqdm(sentences)]#句子分词","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:18:38.988061Z","iopub.execute_input":"2022-02-09T03:18:38.988416Z","iopub.status.idle":"2022-02-09T03:22:05.380084Z","shell.execute_reply.started":"2022-02-09T03:18:38.988379Z","shell.execute_reply":"2022-02-09T03:22:05.379392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aver_sentence_len = 0\nfor sent in tqdm(tokenized_sents):\n    aver_sentence_len += len(sent)\nprint('句子平均长度=',aver_sentence_len/len(tokenized_sents))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:22:35.614177Z","iopub.execute_input":"2022-02-09T03:22:35.614949Z","iopub.status.idle":"2022-02-09T03:22:35.728543Z","shell.execute_reply.started":"2022-02-09T03:22:35.614913Z","shell.execute_reply":"2022-02-09T03:22:35.727748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#将分割后的句子转化成数字  word-->idx\ninput_ids = [tokenizer.convert_tokens_to_ids(sent) for sent in tqdm(tokenized_sents)]\n#input_ids[0]#显示第一条数据","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:22:38.402941Z","iopub.execute_input":"2022-02-09T03:22:38.403703Z","iopub.status.idle":"2022-02-09T03:22:46.03745Z","shell.execute_reply.started":"2022-02-09T03:22:38.403657Z","shell.execute_reply":"2022-02-09T03:22:46.036616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#定义句子最大长度(传统bert最大承受长度为512)\nMAX_LEN=100\ninput_ids = [(sent + [0] * MAX_LEN)[0: MAX_LEN] for sent in tqdm(input_ids)]#进行PADDING\n#print(len(input_ids[0]))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:23:03.678051Z","iopub.execute_input":"2022-02-09T03:23:03.678679Z","iopub.status.idle":"2022-02-09T03:23:04.618351Z","shell.execute_reply.started":"2022-02-09T03:23:03.678641Z","shell.execute_reply":"2022-02-09T03:23:04.617501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#建立mask\nattention_masks = []\nfor seq in tqdm(input_ids):\n    seq_mask = [float(i>0) for i in seq]\n    attention_masks.append(seq_mask)\nprint(\"第一个attention mask:\",attention_masks[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:23:08.966348Z","iopub.execute_input":"2022-02-09T03:23:08.967094Z","iopub.status.idle":"2022-02-09T03:23:11.952576Z","shell.execute_reply.started":"2022-02-09T03:23:08.967057Z","shell.execute_reply":"2022-02-09T03:23:11.951853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#划分训练集、验证集\n#random_state为随机数因子，保证每次随机处理的结果都是一致的\ntrain_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2022, test_size=0.2)\ntrain_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=2022, test_size=0.2)\nprint(\"训练集的一个inputs\",train_inputs[0])\nprint(\"训练集的一个mask\",train_masks[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:23:17.979008Z","iopub.execute_input":"2022-02-09T03:23:17.979272Z","iopub.status.idle":"2022-02-09T03:23:18.137976Z","shell.execute_reply.started":"2022-02-09T03:23:17.979242Z","shell.execute_reply":"2022-02-09T03:23:18.137117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#将训练集、验证集转化成tensor\ntrain_inputs = torch.tensor(train_inputs).to(device)\nvalidation_inputs = torch.tensor(validation_inputs).to(device)\ntrain_labels = torch.tensor(train_labels).to(device)\nvalidation_labels = torch.tensor(validation_labels).to(device)\ntrain_masks = torch.tensor(train_masks).to(device)\nvalidation_masks = torch.tensor(validation_masks).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:23:22.454174Z","iopub.execute_input":"2022-02-09T03:23:22.454918Z","iopub.status.idle":"2022-02-09T03:23:29.854612Z","shell.execute_reply.started":"2022-02-09T03:23:22.454868Z","shell.execute_reply":"2022-02-09T03:23:29.853839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, bert_model, num_label):\n        super().__init__()\n        self.bert_model = bert_model\n        self.line1 = nn.Linear(768, num_label)\n    def forward(self, input_ids, attention_mask):\n        out = self.bert_model(input_ids, attention_mask)\n        out = self.line1(out[1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:23:35.134011Z","iopub.execute_input":"2022-02-09T03:23:35.13427Z","iopub.status.idle":"2022-02-09T03:23:35.139829Z","shell.execute_reply.started":"2022-02-09T03:23:35.13424Z","shell.execute_reply":"2022-02-09T03:23:35.139125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(bert_model, 7)\nmodel.to(device)\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'gamma', 'beta']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.0}\n]\nopt = torch.optim.AdamW(optimizer_grouped_parameters, \n                        lr=2e-5)\n#opt = torch.optim.Adam(model.parameters(), lr=2e-5)\nloss = nn.CrossEntropyLoss()\nbatch_size = 64\nepochs = 5","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:24:00.638935Z","iopub.execute_input":"2022-02-09T03:24:00.639189Z","iopub.status.idle":"2022-02-09T03:24:00.653784Z","shell.execute_reply.started":"2022-02-09T03:24:00.639161Z","shell.execute_reply":"2022-02-09T03:24:00.652975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    for index in range(0, len(train_inputs), batch_size):\n        train_L, train_R = index, index + batch_size\n        logits = model(train_inputs[train_L: train_R], train_masks[train_L: train_R])\n        train_loss = loss(logits, train_labels[train_L: train_R])\n        opt.zero_grad()\n        train_loss.backward()\n        opt.step()\n        #------------------计算acc--------------------------\n        logits = logits.detach().cpu().numpy()#把数据从GPU上取下来，并且从tensor转换成numpy格式\n        train_accuracy = accuracy_score(train_labels[train_L: train_R].detach().cpu().numpy(), np.argmax(logits, 1))\n        print('epoch=',epoch,str(index)+'/'+str(len(train_inputs)),' train_loss=', train_loss.item(),' train_accuracy=',train_accuracy)\n    #------------训练结束一个epoch，看看验证集上的效果---------------\n    val_loss_all = 0\n    val_accuracy_all = 0\n    ans = 0\n    for index in range(0, len(validation_inputs), batch_size):\n        val_L, val_R = index, index + batch_size\n        logits = model(validation_inputs[val_L: val_R], validation_masks[val_L: val_R])\n        val_loss = loss(logits, validation_labels[val_L: val_R])\n        val_loss_all += val_loss.item()\n        #------------------计算acc--------------------------\n        logits = logits.detach().cpu().numpy()\n        val_accuracy = accuracy_score(validation_labels[val_L: val_R].detach().cpu().numpy(), np.argmax(logits, 1))\n        val_accuracy_all += val_accuracy\n        ans += 1\n    print('val_loss_all=',val_loss_all/ans,' val_accuracy_all=',val_accuracy_all/ans)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T03:24:04.046157Z","iopub.execute_input":"2022-02-09T03:24:04.046422Z","iopub.status.idle":"2022-02-09T03:43:37.410668Z","shell.execute_reply.started":"2022-02-09T03:24:04.046392Z","shell.execute_reply":"2022-02-09T03:43:37.408838Z"},"trusted":true},"execution_count":null,"outputs":[]}]}