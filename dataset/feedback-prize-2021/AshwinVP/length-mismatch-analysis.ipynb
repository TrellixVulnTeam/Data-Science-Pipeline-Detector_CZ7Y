{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"As mentioned by @erikbruin in his EDA notebook (https://www.kaggle.com/erikbruin/nlp-on-student-writing-eda), we notice that for some of the records inside the train.csv there is a mismatch in the discousre_text values and the predictionstring values.\n\nBelow are some of the analysis that I did as part of this.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport glob\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-17T04:58:04.333413Z","iopub.execute_input":"2022-01-17T04:58:04.334072Z","iopub.status.idle":"2022-01-17T04:58:04.343962Z","shell.execute_reply.started":"2022-01-17T04:58:04.333963Z","shell.execute_reply":"2022-01-17T04:58:04.343353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/feedback-prize-2021/train.csv')\nprint(f\"Shape of the training dataset: {train_data.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:58:04.346421Z","iopub.execute_input":"2022-01-17T04:58:04.346868Z","iopub.status.idle":"2022-01-17T04:58:05.280722Z","shell.execute_reply.started":"2022-01-17T04:58:04.346818Z","shell.execute_reply":"2022-01-17T04:58:05.279704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_name = train_data.columns\ntrain_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:58:05.283568Z","iopub.execute_input":"2022-01-17T04:58:05.284095Z","iopub.status.idle":"2022-01-17T04:58:05.306471Z","shell.execute_reply.started":"2022-01-17T04:58:05.284058Z","shell.execute_reply":"2022-01-17T04:58:05.305545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['disclosure_text_tokens'] = train_data['discourse_text'].apply(lambda x: len(x.split()))\ntrain_data['predictionstring_tokens'] = train_data['predictionstring'].apply(lambda x: len(x.split()))\ntrain_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:58:05.308019Z","iopub.execute_input":"2022-01-17T04:58:05.308397Z","iopub.status.idle":"2022-01-17T04:58:06.162003Z","shell.execute_reply.started":"2022-01-17T04:58:05.308354Z","shell.execute_reply":"2022-01-17T04:58:06.161196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here creating a separate dataframe for just the length mismatch records","metadata":{}},{"cell_type":"code","source":"sample = train_data[train_data.disclosure_text_tokens != train_data.predictionstring_tokens]\nsample = sample.reset_index(drop=True)\nprint(f\"Shape of the above prepared sample dataset: {sample.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:58:06.163112Z","iopub.execute_input":"2022-01-17T04:58:06.163346Z","iopub.status.idle":"2022-01-17T04:58:06.173395Z","shell.execute_reply.started":"2022-01-17T04:58:06.163318Z","shell.execute_reply":"2022-01-17T04:58:06.172712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here, initially we are extracting the starting and ending positions as mentioned in the predictionstring column.\nThe discourse text start and finish values are then compared to the real document (which is being extracted using the above position values)\nIf the strings do not match, we apply the following set of rules:\n\n1) Check if the discourse_text begins with special characters like [',','.']; if it does, we'll skip that value.\n2) If the beginning string matches but the ending string does not:\n        a) Look to see if it has a special character at the end.\n        b) If any extra characters are selected, they will be removed.\n3) Similar checks are also done if the starting string does not match with the disclose_text\n","metadata":{}},{"cell_type":"code","source":"def string_cleaning(i):\n    print('\\n')\n    print(f'========== {i} ==========')\n    print(f\"------------------- {sample['id'][i]}.txt -------------------- \")\n    file_dir = f\"../input/feedback-prize-2021/train/{sample['id'][i]}.txt\"\n    file = open(file_dir)\n    text_data = file.read()\n    print('-'*50)\n    print(sample['discourse_text'][i])\n    print('-'*50)\n    print(sample['predictionstring'][i])\n    print('-'*50)\n    print(f\"Shape of the discourse text: {sample['disclosure_text_tokens'][i]}\")\n    print('-'*50)\n    print(f\"Shape of the Prediction String: {sample['predictionstring_tokens'][i]}\")\n    print('-'*50)\n    start = sample['predictionstring'][i].split()[0]\n    end = sample['predictionstring'][i].split()[-1]\n    print(f\"Prediction string starting from position: {start}\")\n    print(f\"Prediction string end at postion: {end}\")\n\n    print('-'*50)\n    print(f\"Discourse value: {sample['discourse_text'][i].split()[0]}\")\n    print(f\"Prediction value: {text_data.split()[int(sample['predictionstring'][i].split()[0])]}\")\n    print('-'*50)\n    \n    print('-'*50)\n    print(f\"Discourse value: {sample['discourse_text'][i].split()[-1]}\")\n    print(f\"Prediction value: {text_data.split()[int(sample['predictionstring'][i].split()[-1])]}\")\n    print('-'*50)\n    \n    \n    dict1 = {}\n    for val in sample['predictionstring'][i].split():\n        dict1[val] = text_data.split()[int(val)]\n    display(dict1)\n    \n    dict2 = {}\n    for val in range(len(sample['discourse_text'][i].split())):\n        dict2[str(val)] = sample['discourse_text'][i].split()[val]\n    display(dict2)\n    \n    if sample['discourse_text'][i].split()[0] in [',','.']:\n        print('-'*50)\n        print(\"Starting with a sepecial character\")\n        sample.loc[i,'discourse_text'] = ' '.join(sample.loc[i,'discourse_text'].split()[1:])\n        print(f\"New discourse value length: {len(sample['discourse_text'][i].split())}\")\n        print('-'*50)\n        \n        \n    if sample['discourse_text'][i].split()[0] == text_data.split()[int(sample['predictionstring'][i].split()[0])]:\n        print(\"values are matching\")\n        if sample['discourse_text'][i].split()[-1] == text_data.split()[int(sample['predictionstring'][i].split()[-1])]:\n            print('The ending values are matching')\n        else:\n            print(f\"Final value: {text_data.split()[int(sample['predictionstring'][i].split()[-1])]}\")\n            print('-'*50)\n            dict_values = [v for k,v in dict1.items()]\n            dict_key = [k for k,v in dict1.items()]\n            \n            \n                \n            if text_data.split()[int(sample['predictionstring'][i].split()[-1])] == ',' or text_data.split()[int(sample['predictionstring'][i].split()[-1])] == '.':\n                print('-------- Ending with special character -------------')\n                end = str(int(end)-1)\n                \n            elif sample['discourse_text'][i].split()[-1] in dict_values:\n                end = dict_key[dict_values.index(sample['discourse_text'][i].split()[-1])]\n            else:\n                print(\"ending values doesnt match\")\n                print(f\"Discourse value: {sample['discourse_text'][i].split()[-1]}\")\n                print(f\"Extracted value: {text_data.split()[int(sample['predictionstring'][i].split()[-1])]}\")\n\n                end_bk = end\n                end = [str(j) for j in range(len(text_data.split())) if j>int(start) and text_data.split()[j] == sample['discourse_text'][i].split()[-1]]\n                if len(end) == 1:\n                    end = ''.join(end) \n                elif end:\n                    end = end[0]\n                else:\n                    end = end_bk\n\n\n#                 print(f\"Index value of the last string: {text_data.split().index(sample['discourse_text'][i].split()[-1])}\")\n#                 end = text_data.split().index(sample['discourse_text'][i].split()[-1])\n    else:\n        print('Change the starting position')\n        print(text_data.split()[int(sample['predictionstring'][i].split()[0])-1])\n        print(sample['discourse_text'][i].split()[0])\n        for sign in [',','.','\"']:\n            if text_data.split()[int(sample['predictionstring'][i].split()[0])-1].find(sign) != -1:\n                print('We have special character in the first position!')\n                val = text_data.split()[int(sample['predictionstring'][i].split()[0])-1].split(sign)\n                if val[1] is not None or text_data.split()[int(sample['predictionstring'][i].split()[0])-1].split(',')[1] == sample['discourse_text'][i].split()[0]:\n                    start = int(sample['predictionstring'][i].split()[0])-1\n        \n        if sample['discourse_text'][i].split()[0] == text_data.split()[int(sample['predictionstring'][i].split()[0])-1]:\n            print(\"Now the values are matching as we chnaged the index position\")\n            print(f\"Original Index value: {int(sample['predictionstring'][i].split()[0])}\")\n            print(f\"New index position is : {int(sample['predictionstring'][i].split()[0])-1}\")\n            start = int(sample['predictionstring'][i].split()[0])-1\n        elif text_data.split()[int(sample['predictionstring'][i].split()[0])] == '.':\n            start = int(sample['predictionstring'][i].split()[0])+1\n            \n        print(f\" ----- Length of modified Discourse value: {len(sample['discourse_text'][i].split())} ------- \")\n            \n        if sample['discourse_text'][i].split()[-1] == text_data.split()[int(sample['predictionstring'][i].split()[-1])]:\n            print('The ending values are matching')\n        else:\n            print(f\"Final value: {text_data.split()[int(sample['predictionstring'][i].split()[-1])]}\")\n            dict_values = [v for k,v in dict1.items()]\n            dict_key = [k for k,v in dict1.items()]\n            \n            if sample['discourse_text'][i].split()[-1] in dict_values:\n                end = dict_key[dict_values.index(sample['discourse_text'][i].split()[-1])]\n                \n\n            elif text_data.split()[int(sample['predictionstring'][i].split()[-1])] == ',' or text_data.split()[int(sample['predictionstring'][i].split()[-1])] == '.':\n                print('-------- Ending with special character -------------')\n                end = str(int(end)-1)\n            else:\n                print(\"ending values doesnt match\")\n                print(f\"Discourse value: {sample['discourse_text'][i].split()[-1]}\")\n                print(f\"Extracted value: {text_data.split()[int(sample['predictionstring'][i].split()[-1])]}\")\n                \n                end_bk = end\n                end = [str(j) for j in range(len(text_data.split())) if j>int(start) and text_data.split()[j] == sample['discourse_text'][i].split()[-1]]\n                if len(end) == 1:\n                    end = ''.join(end) \n                elif end:\n                    end = end[0]\n                else:\n                    end = end_bk\n#             print(f\"List of new end values: {new_end}\")\n            \n#             print(f\"Index value of the last string: {text_data.split().index(sample['discourse_text'][i].split()[-1])}\")\n#             end = text_data.split().index(sample['discourse_text'][i].split()[-1])\n\n\n    print('-'*50)\n    print(f\"New start value: {start}\")\n    print('-'*50)\n    print(f\"New ending value: {end}\")\n    print('-'*50)\n    list1 = [str(i) for i in range(int(start), int(end)+1)]\n    print(' '.join(list1))\n    print(len(list1))\n#     final_list.append(list1)\n    \n    print('-'*50)\n    \n    return list1","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-17T04:58:06.247505Z","iopub.execute_input":"2022-01-17T04:58:06.247743Z","iopub.status.idle":"2022-01-17T04:58:06.291249Z","shell.execute_reply.started":"2022-01-17T04:58:06.247715Z","shell.execute_reply":"2022-01-17T04:58:06.290349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_list = [string_cleaning(x) for x in tqdm(sample.index)]","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_list))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:59:08.324169Z","iopub.execute_input":"2022-01-17T04:59:08.324683Z","iopub.status.idle":"2022-01-17T04:59:08.328986Z","shell.execute_reply.started":"2022-01-17T04:59:08.324651Z","shell.execute_reply":"2022-01-17T04:59:08.328219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df_list)):\n    df_list[i] = ' '.join(df_list[i])\n    \nsample['new_predictionstring'] = df_list\nsample['new_disclosure_text_tokens'] = sample['discourse_text'].apply(lambda x: len(x.split()))\nsample['new_predictionstring_tokens'] = sample['new_predictionstring'].apply(lambda x: len(x.split()))\nsample.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:59:08.900833Z","iopub.execute_input":"2022-01-17T04:59:08.901171Z","iopub.status.idle":"2022-01-17T04:59:08.933064Z","shell.execute_reply.started":"2022-01-17T04:59:08.901141Z","shell.execute_reply":"2022-01-17T04:59:08.93242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:59:12.757881Z","iopub.execute_input":"2022-01-17T04:59:12.758601Z","iopub.status.idle":"2022-01-17T04:59:12.764573Z","shell.execute_reply.started":"2022-01-17T04:59:12.758562Z","shell.execute_reply":"2022-01-17T04:59:12.76369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = train_data.merge(sample[['id','discourse_id','discourse_text','new_predictionstring']], on = ['id','discourse_id'], how = 'left')\nprint(f\"Shape of the final prepared dataframe: {df_final.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:59:37.462098Z","iopub.execute_input":"2022-01-17T04:59:37.462613Z","iopub.status.idle":"2022-01-17T04:59:37.608603Z","shell.execute_reply.started":"2022-01-17T04:59:37.462567Z","shell.execute_reply":"2022-01-17T04:59:37.607663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_list = []\nfor x in tqdm(range(len(df_final))):\n    if pd.isnull(df_final.loc[x, 'new_predictionstring']):\n        pass\n    else:\n        index_list.append(x)\n        df_final.loc[x,'discourse_text_x'] = df_final.loc[x,'discourse_text_y']\n        df_final.loc[x,'predictionstring'] = df_final.loc[x,'new_predictionstring']","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:01:05.653708Z","iopub.execute_input":"2022-01-17T05:01:05.654476Z","iopub.status.idle":"2022-01-17T05:01:13.496341Z","shell.execute_reply.started":"2022-01-17T05:01:05.654437Z","shell.execute_reply":"2022-01-17T05:01:13.495543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final['disclosure_text_tokens'] = df_final['discourse_text_x'].apply(lambda x: len(x.split()))\ndf_final['predictionstring_tokens'] = df_final['predictionstring'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:01:15.810266Z","iopub.execute_input":"2022-01-17T05:01:15.811067Z","iopub.status.idle":"2022-01-17T05:01:16.644202Z","shell.execute_reply.started":"2022-01-17T05:01:15.811016Z","shell.execute_reply":"2022-01-17T05:01:16.643395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['discourse_text_y','new_predictionstring'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:58:06.419167Z","iopub.status.idle":"2022-01-17T04:58:06.419486Z","shell.execute_reply.started":"2022-01-17T04:58:06.419316Z","shell.execute_reply":"2022-01-17T04:58:06.419331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total number of mismtach after the above processing: {df_final[df_final['disclosure_text_tokens'] != df_final['predictionstring_tokens']].shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T05:01:21.496897Z","iopub.execute_input":"2022-01-17T05:01:21.497435Z","iopub.status.idle":"2022-01-17T05:01:21.56183Z","shell.execute_reply.started":"2022-01-17T05:01:21.497394Z","shell.execute_reply":"2022-01-17T05:01:21.560998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are still some mismatches, for these records the initial value of the discourse_text are missing some text values due to which, its not getting considered in any of the above rules.\n\nFor example:\n\n1) listening and istening \\\n2) the and he\\\n3) Students and tudents\n\nWhile the position differnce between the text mentioned in the discourse_text and that in the predictionstring are greater than 1.","metadata":{}},{"cell_type":"code","source":"df_final.to_csv('updates_train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T04:58:06.421516Z","iopub.status.idle":"2022-01-17T04:58:06.421803Z","shell.execute_reply.started":"2022-01-17T04:58:06.421649Z","shell.execute_reply":"2022-01-17T04:58:06.421665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}