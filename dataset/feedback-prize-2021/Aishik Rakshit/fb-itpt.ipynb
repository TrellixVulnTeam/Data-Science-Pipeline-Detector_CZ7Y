{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport logging\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer,\\\n                         AdamW, DataCollatorForLanguageModeling,\\\n                         get_scheduler","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:25:48.175144Z","iopub.execute_input":"2022-03-13T23:25:48.17567Z","iopub.status.idle":"2022-03-13T23:25:51.535123Z","shell.execute_reply.started":"2022-03-13T23:25:48.175575Z","shell.execute_reply":"2022-03-13T23:25:51.534146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    model_name = 'allenai/longformer-large-4096'\n    max_length = 512\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    validation_size = 0.05\n    mlm_probability = 0.15\n    \n    train_batch_size = 2\n    eval_batch_size = 2\n    \n    learning_rate = 2.5e-5\n    \n    num_train_epochs = 3\n        \n    lr_scheduler_type = 'constant_with_warmup'\n    num_warmup_steps = 0\n\nargs = Config()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:25:51.543348Z","iopub.execute_input":"2022-03-13T23:25:51.543939Z","iopub.status.idle":"2022-03-13T23:25:51.585549Z","shell.execute_reply.started":"2022-03-13T23:25:51.543879Z","shell.execute_reply":"2022-03-13T23:25:51.584528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mlm_csv():\n    \"\"\" Read all training texts to a csv file with one column 'text' \"\"\"\n    texts = []\n    \n    for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n        with open('../input/feedback-prize-2021/train/' + f, 'r') as fp:\n            texts.append(fp.read())\n    \n    df = pd.DataFrame({'text': texts})\n    \n    display(df.head())\n    df.to_csv(\"mlm_train.csv\", index=False)\n    return df\n\ndf = create_mlm_csv()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:25:51.587088Z","iopub.execute_input":"2022-03-13T23:25:51.58746Z","iopub.status.idle":"2022-03-13T23:26:04.502212Z","shell.execute_reply.started":"2022-03-13T23:25:51.587413Z","shell.execute_reply":"2022-03-13T23:26:04.500875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMaskedLM.from_pretrained(args.model_name)\nmodel.to(args.device)\n\ntokenizer = AutoTokenizer.from_pretrained(args.model_name)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:26:04.508965Z","iopub.execute_input":"2022-03-13T23:26:04.509229Z","iopub.status.idle":"2022-03-13T23:26:19.225132Z","shell.execute_reply.started":"2022-03-13T23:26:04.509201Z","shell.execute_reply":"2022-03-13T23:26:19.224243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples['text'], return_special_tokens_mask=True)\n\ndef group_texts(examples):\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    total_length = (total_length // args.max_length) * args.max_length\n    result = {\n        k: [t[i : i + args.max_length] for i in range(0, total_length, args.max_length)]\n        for k, t in concatenated_examples.items()\n    }\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:26:19.226748Z","iopub.execute_input":"2022-03-13T23:26:19.227044Z","iopub.status.idle":"2022-03-13T23:26:19.235532Z","shell.execute_reply.started":"2022-03-13T23:26:19.227003Z","shell.execute_reply":"2022-03-13T23:26:19.234617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_datasets = load_dataset(\"csv\", data_files={'train': 'mlm_train.csv'})\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True, remove_columns=['text'])\\\n                                 .map(group_texts, batched=True)\n\ntokenized_datasets = tokenized_datasets[\"train\"].train_test_split(test_size=args.validation_size)\ntokenized_datasets['validation'] = tokenized_datasets.pop(\"test\")\n\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=args.mlm_probability)\n\n\ndl_train = DataLoader(tokenized_datasets[\"train\"], \n                      shuffle=True, \n                      collate_fn=data_collator, \n                      batch_size=args.train_batch_size)\n\ndl_val = DataLoader(tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=args.eval_batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:26:19.237603Z","iopub.execute_input":"2022-03-13T23:26:19.238284Z","iopub.status.idle":"2022-03-13T23:27:59.697918Z","shell.execute_reply.started":"2022-03-13T23:26:19.238207Z","shell.execute_reply":"2022-03-13T23:27:59.696914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=args.learning_rate)\n\nnum_training_steps = args.num_train_epochs * len(dl_train)\nlr_scheduler = get_scheduler(\n    name=args.lr_scheduler_type,\n    optimizer=optimizer,\n    num_warmup_steps=args.num_warmup_steps,\n    num_training_steps=num_training_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:27:59.701208Z","iopub.execute_input":"2022-03-13T23:27:59.701974Z","iopub.status.idle":"2022-03-13T23:27:59.716818Z","shell.execute_reply.started":"2022-03-13T23:27:59.70194Z","shell.execute_reply":"2022-03-13T23:27:59.715869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** Running training *****\")\nprint(f\"  Num examples = {len(tokenized_datasets['train'])}\")\nprint(f\"  Num Epochs = {args.num_train_epochs}\")\nprint(f\"  Total training steps = {num_training_steps}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:27:59.718222Z","iopub.execute_input":"2022-03-13T23:27:59.718581Z","iopub.status.idle":"2022-03-13T23:27:59.815702Z","shell.execute_reply.started":"2022-03-13T23:27:59.718533Z","shell.execute_reply":"2022-03-13T23:27:59.813299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar = tqdm(range(num_training_steps))\ncompleted_steps = 0\n\nfor epoch in range(args.num_train_epochs):\n    model.train()\n    cum_loss = 0\n    for batch_idx, batch in enumerate(dl_train, 1):\n        \n        outputs = model(**{k: v.to(args.device) for k, v in batch.items()})\n        loss = outputs.loss\n        cum_loss += loss.item()\n        \n        \n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n        progress_bar.set_postfix({'loss': cum_loss / batch_idx})\n        #if batch_idx > 100:\n        #    break\n\n    model.eval()\n    losses = []\n    for batch_idx, batch in enumerate(dl_val, 1):\n        with torch.no_grad():\n            outputs = model(**{k: v.to(args.device) for k, v in batch.items()})\n\n        loss = outputs.loss\n        losses.append(loss)\n        #if batch_idx > 100:\n        #    break\n\n    losses = torch.tensor(losses)\n    losses = losses[: len(tokenized_datasets['validation'])]\n    perplexity = math.exp(torch.mean(losses))\n\n    print(f\"Epoch {epoch}: perplexity: {perplexity}\")\n    model.save_pretrained(f'longformer_large-itpt-e{epoch}')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T23:27:59.819026Z","iopub.execute_input":"2022-03-13T23:27:59.82061Z"},"trusted":true},"execution_count":null,"outputs":[]}]}