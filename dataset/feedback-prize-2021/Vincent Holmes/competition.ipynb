{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch \nimport transformers\nimport os\nfrom tqdm import tqdm\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-02-15T11:47:18.148828Z","iopub.execute_input":"2022-02-15T11:47:18.14916Z","iopub.status.idle":"2022-02-15T11:47:18.757436Z","shell.execute_reply.started":"2022-02-15T11:47:18.149077Z","shell.execute_reply":"2022-02-15T11:47:18.756689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-15T11:47:18.758934Z","iopub.execute_input":"2022-02-15T11:47:18.759584Z","iopub.status.idle":"2022-02-15T11:47:19.706554Z","shell.execute_reply.started":"2022-02-15T11:47:18.759543Z","shell.execute_reply":"2022-02-15T11:47:19.705779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = \"1223\".replace(\"2\", \",\")\na","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reindex(text:str, idx:str, beginner=0) -> str:\n    \"\"\"\n      Func:\n        to reindex the text from character index to word index\n        \n      Args:\n        idx: a string indicating the indices with space as the seperater\n        \n      Returns:\n        1. the clean text\n        2. the new index\n        3. the next index's beginning index\n    \"\"\"\n    text = cleaner(text)\n    idx = [int(i) for i in idx.split(\" \") if len(i)>0]\n    if 0 in idx:\n        # it's the first pharagraph of an article\n        idx = [str(i) for i in range(count_words(text))]\n    else:\n        idx = [str(i) for i in range(beginner, beginner+count_words(text))]\n    \n    return text, \" \".join(idx), int(idx[-1])+1\n\n\ndef cleaner(text:str):\n    \"\"\"\n      Func:\n        To clean the text\n    \"\"\"\n    notation = \"\"\":!~.,?;'\\t\\n\"\"\"\n    for n in notation:\n        text = text.replace(n, \" \")\n    while \"  \" in text:\n        text = text.replace(\"  \", \" \")\n    \n    return text\n\n\ndef count_words(text):\n    \"\"\"\n      Returns:\n        return the word count\n    \"\"\"\n    l = text.split(\" \")\n    return len(l)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-15T11:48:10.149832Z","iopub.execute_input":"2022-02-15T11:48:10.150126Z","iopub.status.idle":"2022-02-15T11:48:10.160729Z","shell.execute_reply.started":"2022-02-15T11:48:10.150097Z","shell.execute_reply":"2022-02-15T11:48:10.159882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reindex(training.iloc[1, 4], training.iloc[1, 7], 45)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T11:48:13.394298Z","iopub.execute_input":"2022-02-15T11:48:13.394625Z","iopub.status.idle":"2022-02-15T11:48:13.40369Z","shell.execute_reply.started":"2022-02-15T11:48:13.394585Z","shell.execute_reply":"2022-02-15T11:48:13.402992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing test data\ntest_id, test_context = [], []\nfor f in list(os.listdir(\"../input/feedback-prize-2021/test/\")):\n    test_id.append(f.split(\".txt\")[0])\n    with open(\"../input/feedback-prize-2021/test/\"+f) as file:\n        test_context.append(file.read())\ntest = pd.DataFrame({\"id\":test_id,\"text\":test_context})\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocessing traininig dataset\ntrain_id, train_context = [], []\nfor f in tqdm(list(os.listdir(\"../input/feedback-prize-2021/train\"))):\n    train_id.append(f.split(\".txt\")[0])\n    with open(\"../input/feedback-prize-2021/train/\" + f) as file:\n        train_context.append(file.read())\ntrain_context_df = pd.DataFrame({\"id\":train_id,\"text\":train_context})\ntrain_context_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_end = training.groupby(\"id\").apply(lambda x: [[x[\"discourse_start\"].to_list()[i],x[\"discourse_end\"].to_list()[i]]for i in range(len(x[\"discourse_start\"].to_list()))]).reset_index(name = \"start_end\")\nclass_type = training.groupby(\"id\")[\"discourse_type\"].apply(list).reset_index(name = \"class_type\")\npred_string = training.groupby(\"id\")[\"predictionstring\"].apply(list).reset_index(name = \"string\")\ndisc_text = training.groupby(\"id\")[\"discourse_text\"].apply(list).reset_index(name = \"discourse_text\")\ndf = pd.merge(class_type, start_end,how = \"inner\", on=\"id\")\ndf = pd.merge(df,pred_string, how = \"inner\", on = \"id\")\ndf = pd.merge(df,train_context_df, how=\"inner\", on=\"id\")\ndf = pd.merge(df, disc_text, how = \"inner\", on = \"id\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the competition is basically a multiple classification problem, label is the corresponding discourse_type\nlabels = training['discourse_type'].unique().tolist()\n# create dict to map index to corresponding labels\nlabs2idx = {label:ids for ids, label in enumerate(labels)}\nidx2labs = {ids:label for ids, label in enumerate(labels)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Done the preprocessing part, check if the start_end is the same as corresponding given text","metadata":{}},{"cell_type":"code","source":"def get_start_end_text(input_):\n    '''\n    This function is to check whether the start_end string is different from the given discourse_text\n    '''\n    ids = input_[\"id\"]\n    start_end = input_[\"start_end\"]\n    dis_text = input_[\"discourse_text\"]\n    text = input_[\"text\"]\n    labels_texts = []\n    assert len(start_end) == len(dis_text)\n    for start_end, txt in zip(start_end, dis_text):\n        # check it\n        labels_text = text[int(start_end[0]):int(start_end[1])]\n        labels_texts.append(labels_text)\n    return labels_texts\nlabels_text = df.apply(lambda x: get_start_end_text(x),axis=1)\ndf[\"labels_text\"] = labels_text\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### check whether the string is the same","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:31:37.826316Z","iopub.execute_input":"2022-02-15T03:31:37.826668Z","iopub.status.idle":"2022-02-15T03:31:37.870164Z","shell.execute_reply.started":"2022-02-15T03:31:37.826632Z","shell.execute_reply":"2022-02-15T03:31:37.869261Z"}}},{"cell_type":"code","source":"def check_diff(input_):\n    '''\n    This function check whether there the labels text is the same as the given_ground truth text\n    '''\n    dis_text = input_[\"discourse_text\"]\n    labels_text = input_[\"labels_text\"]\n    assert len(dis_text) == len(labels_text)\n    count = 0\n    for i, j in zip(dis_text, labels_text):\n        if i != j:\n            count+=1\n    return count\ndf.apply(lambda x: check_diff(x), axis=1).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now change the class type in the whole set to it's corresponding index","metadata":{}},{"cell_type":"code","source":"df[\"class_ids\"] = df[\"class_type\"].apply(lambda x:[labs2idx[types_] for types_ in x])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check our text length, basically using longformer has max_length = 4096","metadata":{}},{"cell_type":"code","source":"a = df[\"text\"].apply(lambda x: len(re.findall('[a-zA-Z0-9]+',x)))\na_gt = a[a>=4096].index.values\nlen(a_gt),a_gt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use re change the corresponding string and check if the prediction string length is equal to the start-end","metadata":{}},{"cell_type":"code","source":"df[\"text\"] = df[\"text\"].apply(lambda x: (re.findall('[a-zA-Z0-9]+',x)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can see that they are all equal\ncheck_ = df.apply(lambda x: len(x[\"start_end\"]) == len(x[\"string\"]),axis = 1)\ncheck_[check_ == False].sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create torch dataset","metadata":{}},{"cell_type":"markdown","source":"### Using longformer tokenization to tokenize corresponding text into it's own dictionary idxs","metadata":{}},{"cell_type":"code","source":"#some basic parameter\n","metadata":{},"execution_count":null,"outputs":[]}]}