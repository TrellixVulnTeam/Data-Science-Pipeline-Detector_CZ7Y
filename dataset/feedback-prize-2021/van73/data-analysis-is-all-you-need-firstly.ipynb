{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data analysis is all you need firstly!","metadata":{}},{"cell_type":"markdown","source":"## load package","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T06:39:19.282854Z","iopub.execute_input":"2021-12-18T06:39:19.283403Z","iopub.status.idle":"2021-12-18T06:39:19.288384Z","shell.execute_reply.started":"2021-12-18T06:39:19.283369Z","shell.execute_reply":"2021-12-18T06:39:19.287474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport string\nfrom collections import defaultdict\nfrom transformers import AutoTokenizer\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:19.290254Z","iopub.execute_input":"2021-12-18T06:39:19.290515Z","iopub.status.idle":"2021-12-18T06:39:19.300925Z","shell.execute_reply.started":"2021-12-18T06:39:19.290484Z","shell.execute_reply":"2021-12-18T06:39:19.299973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained('../input/bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:19.302532Z","iopub.execute_input":"2021-12-18T06:39:19.30313Z","iopub.status.idle":"2021-12-18T06:39:19.395305Z","shell.execute_reply.started":"2021-12-18T06:39:19.303082Z","shell.execute_reply":"2021-12-18T06:39:19.394434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_text_path ='../input/feedback-prize-2021/train'\ndata_label_path ='../input/feedback-prize-2021/train.csv'","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:19.396571Z","iopub.execute_input":"2021-12-18T06:39:19.396795Z","iopub.status.idle":"2021-12-18T06:39:19.400931Z","shell.execute_reply.started":"2021-12-18T06:39:19.396763Z","shell.execute_reply":"2021-12-18T06:39:19.400023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_label = pd.read_csv('../input/feedback-prize-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:19.403664Z","iopub.execute_input":"2021-12-18T06:39:19.404036Z","iopub.status.idle":"2021-12-18T06:39:20.259126Z","shell.execute_reply.started":"2021-12-18T06:39:19.403968Z","shell.execute_reply":"2021-12-18T06:39:20.25812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_label.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:20.260537Z","iopub.execute_input":"2021-12-18T06:39:20.261306Z","iopub.status.idle":"2021-12-18T06:39:20.277748Z","shell.execute_reply.started":"2021-12-18T06:39:20.261254Z","shell.execute_reply":"2021-12-18T06:39:20.276826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tokenized_len(text):\n    return len(tokenizer.encode(text))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:20.279174Z","iopub.execute_input":"2021-12-18T06:39:20.279487Z","iopub.status.idle":"2021-12-18T06:39:20.288294Z","shell.execute_reply.started":"2021-12-18T06:39:20.279453Z","shell.execute_reply":"2021-12-18T06:39:20.287376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ans type","metadata":{}},{"cell_type":"code","source":"df_train_label['discourse_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:20.289314Z","iopub.execute_input":"2021-12-18T06:39:20.290136Z","iopub.status.idle":"2021-12-18T06:39:20.319898Z","shell.execute_reply.started":"2021-12-18T06:39:20.290098Z","shell.execute_reply":"2021-12-18T06:39:20.319255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_label['discourse_start'].hist(bins=[0,200,500,1000,2000,3000,4000,5000,6000])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:20.321083Z","iopub.execute_input":"2021-12-18T06:39:20.321531Z","iopub.status.idle":"2021-12-18T06:39:20.61143Z","shell.execute_reply.started":"2021-12-18T06:39:20.321495Z","shell.execute_reply":"2021-12-18T06:39:20.610518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_label['discourse_end'].hist(bins=[0,200,500,1000,2000,3000,4000,5000,6000])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:20.612649Z","iopub.execute_input":"2021-12-18T06:39:20.612872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ans char len","metadata":{}},{"cell_type":"code","source":"(df_train_label['discourse_end']-df_train_label['discourse_start']).hist(bins=[0,100,200,500,1000,2000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ans word len","metadata":{}},{"cell_type":"code","source":"def get_split_len(textstr):\n    return len(textstr.strip().split())\n\ndf_train_label['predictionstring'].apply(get_split_len).hist(bins=[0,50,100,150,200,500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## per discoures_text len after tokenized","metadata":{}},{"cell_type":"code","source":"df_train_label['discoures_text_len'] = df_train_label['discourse_text'].apply(get_tokenized_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_label.hist(column=['discoures_text_len'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## processing","metadata":{}},{"cell_type":"code","source":"df_group = df_train_label.groupby('id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f(x):\n    #print(len(x['id']))\n    return pd.Series({    \n                          'discourse_id':x['discourse_id'].values.reshape(-1).tolist(),\n                         'discourse_start':x['discourse_start'].values.reshape(-1).tolist(),\n                         'discourse_end':x['discourse_end'].values.reshape(-1).tolist(),\n                          'discourse_text':x['discourse_text'].values.reshape(-1).tolist(),\n                          'discourse_type':x['discourse_type'].values.reshape(-1).tolist(),\n                         \"predictionstring\":x['predictionstring'].values.reshape(-1).tolist()\n            \n                         }).T\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol = df_group.apply(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_group_recol.index ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol.reset_index(level=0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_group_recol)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_from_afile(text_path):\n    with open(os.path.join(\"../input/feedback-prize-2021/train\",text_path+'.txt'), 'r') as f:\n        return (f.read())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol['text'] = df_group_recol['id'].apply(get_text_from_afile)\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ans char position check","metadata":{"execution":{"iopub.status.busy":"2021-12-18T03:23:02.227909Z","iopub.execute_input":"2021-12-18T03:23:02.228215Z","iopub.status.idle":"2021-12-18T03:23:02.23236Z","shell.execute_reply.started":"2021-12-18T03:23:02.228185Z","shell.execute_reply":"2021-12-18T03:23:02.231376Z"}}},{"cell_type":"code","source":"inequal_count =0 \nfor index, irow in df_group_recol.iterrows():\n    start_list = irow['discourse_start']\n    end_list =irow['discourse_end']\n    discourse_text_list = irow['discourse_text']\n\n    split_text=irow['text'].split()\n\n    for istart, iend,ians in zip(start_list, end_list,discourse_text_list):\n        \n\n        extracted_str = irow['text'][int(istart):int(iend)].strip().strip(string.punctuation)#.strip().strip(string.punctuation).strip()\n        ians_p = ians.strip().strip(string.punctuation)#.strip().strip(string.punctuation).strip()\n        if extracted_str!= ians_p:\n            inequal_count+=1\n            #print('*'*20)\n            #print(irow['text'][int(istart):int(iend)], ians,sep='**')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inequal_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ans predictionstring check","metadata":{}},{"cell_type":"code","source":"inequal_count =0 \nfor index, irow in df_group_recol.iterrows():\n    start_list = irow['discourse_start']\n    end_list =irow['discourse_end']\n    discourse_text_list = irow['discourse_text']\n    predictionstring_list = irow['predictionstring']\n    split_text=irow['text'].split()\n    \n    for ians,predictionstring in zip(discourse_text_list,predictionstring_list):\n        predictionstring_split =predictionstring.strip().split()\n        word_start_index = int(predictionstring_split[0])\n        word_end_idnex = int(predictionstring_split[-1])\n        ans_from_wordidnex = ' '.join(split_text[word_start_index:word_end_idnex+1]).strip().strip(string.punctuation).strip()\n        ians_p = \" \".join(ians.split()).strip().strip(string.punctuation).strip()\n        if ans_from_wordidnex!=ians_p:\n            inequal_count+=1\n            #print('*'*20)\n            #print(ans_from_wordidnex,ians_p,'-pair_end-\\n',sep='*******',)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inequal_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ans split check","metadata":{}},{"cell_type":"code","source":"inequal_count =0\nfor index, irow in df_group_recol.iterrows():\n    start_list = irow['discourse_start']\n    end_list =irow['discourse_end']\n    discourse_text_list = irow['discourse_text']\n    predictionstring_list = irow['predictionstring']\n    \n    split_text=irow['text'].split()\n\n    wordindex2charindex={}\n    ipos=0\n    new_format_text = \"\"\n    for i_index,iword in enumerate(split_text):\n        wordindex2charindex[i_index]=(ipos,ipos+len(iword)-1)\n        # space\n        ipos= ipos+len(iword)+1\n        new_format_text+=(iword+' ')\n    for ians,predictionstring in zip(discourse_text_list,predictionstring_list):\n        predictionstring_split =predictionstring.strip().split()\n        word_start_index = int(predictionstring_split[0])\n        word_end_idnex = int(predictionstring_split[-1])\n        extracted_str=new_format_text[wordindex2charindex[word_start_index][0]:wordindex2charindex[word_end_idnex][1]+1]\n        if extracted_str.strip().strip(string.punctuation)!= \" \".join(ians.split()).strip().strip(string.punctuation):\n                inequal_count+=1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inequal_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## label count per doc","metadata":{}},{"cell_type":"code","source":"df_group_recol.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_group_recol['label_count'] =df_group_recol['discourse_type'].apply(len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol.hist(column=['label_count'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## each label type count per doc","metadata":{}},{"cell_type":"code","source":"label_type = list(df_train_label['discourse_type'].value_counts().keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perlabel_count(label_list):\n    dd_dict = defaultdict(lambda:0)\n    for ilabel in label_list:\n        dd_dict[ilabel]+=1\n    return [ dd_dict[il_type] for il_type in label_type]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol['perlabel_count'] = df_group_recol['discourse_type'].apply(perlabel_count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_multiple_img(df_list, rows, cols,title):\n    '''\n    ref: https://stackoverflow.com/questions/38082602/plotting-multiple-different-plots-in-one-figure-using-seaborn\n    \n    '''\n    figure, all_ax = plt.subplots(nrows=rows,ncols=cols,figsize=(16,3))\n    plt.suptitle(title, fontsize=20)\n    for i in range(rows*cols):\n        df_list[i].hist(ax=all_ax.ravel()[i])\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_count_array=np.array(df_group_recol['perlabel_count'].values.reshape(-1).tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_list = [pd.DataFrame({itype:type_count_array[:,i_index]}) for i_index, itype in enumerate(label_type)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_multiple_img(df_list, 1, 7,label_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## len after tokenied","metadata":{}},{"cell_type":"code","source":"df_group_recol['tokenizer_len'] = df_group_recol['text'].apply(get_tokenized_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_group_recol.hist(column=['tokenizer_len'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## unkown word","metadata":{}},{"cell_type":"code","source":"tokenizer.unk_token_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nunktoken_dict={}\nfor text in tqdm(df_group_recol['text']):\n    tokenized_examples =tokenizer(\n            text,  # QA第一个句子的列表\n            max_length=512,  # 最大长度\n            stride=0,  # 是不同窗口 重叠的长度，不是滑动的长度\n            return_overflowing_tokens=True,  # 返回每个span 样例对应的 question-context的样本序号 如[0,0,0,1,1,1]\n            return_offsets_mapping=True,  # 返回token对应的char的位置\n            padding=\"max_length\",  # 设置padding，“max_length”表示设置为 当前的max_length的值，True表示paddingg到模型的最长长度，False不padding\n        )\n    for index in range(len(tokenized_examples['input_ids'][0])):\n        if tokenized_examples['input_ids'][0][index] ==tokenizer.unk_token_id:\n            #print(tokenized_examples['offset_mapping'][0][index])\n            \n            span  = str(text[tokenized_examples['offset_mapping'][0][index][0]:tokenized_examples['offset_mapping'][0][index][1]])\n            if span not in unktoken_dict:\n                unktoken_dict[span] =0 \n            try:\n                unktoken_dict[span]+=1\n            except:\n                print(span)\n                pass\n        #print(tokenized_examples['input_ids'])\n        #print(tokenized_examples['offset_mapping'])\n        #print(tokenized_examples.sequence_ids(0))\n    \nprint(len((unktoken_dict)))\nprint(unktoken_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}