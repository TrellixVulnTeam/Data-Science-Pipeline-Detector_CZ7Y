{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nAs we all know , this is a hardware heavy competition and training at a higher MAX_LEN and a larger model does the trick , but all those with limited hardware like me have been struggling to do so . DeepSpeed Library allows one to Train Large models with bigger batch sizes on smaller GPUs , This notebook integrates DeepSpeed with HF Trainer and most of it is a replica of the wonderful Baseline prepared by Darek [Here](https://www.kaggle.com/thedrcat/feedback-prize-huggingface-baseline-training) \n\n\n<b>Please Note that in this notebook I show an example to use DeepSpeed and its features to train LongFormer Base with a batch_size of 10 on a 16GB card . We can train even larger batch size or bigger sequences and utilize more juice out of a 16Gb card if we have more CPU memory but since kaggle gives us only 16GB of memory I was only able to demonstrate use of Stage2 ZeRO Optimizer given by DEEPSPEED</b>\n\nI am able to train longformer large on a bs of 6 on a 24GB RTX 6000 card on [Jarvislabs.ai](https://cloud.jarvislabs.ai/) using DeepSpeed and HF Trainer . Here is an [article](https://jarvislabs.ai/blogs/deepspeed) which describes in detail to make full use of DeepSpeed \n\n\nHope you all are able to use your GPU's more efficiently , thanks for reading","metadata":{}},{"cell_type":"code","source":"!conda install -y mpi4py \n!pip -qq install deepspeed","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:33:50.814335Z","iopub.execute_input":"2022-02-02T07:33:50.815207Z","iopub.status.idle":"2022-02-02T07:35:06.514274Z","shell.execute_reply.started":"2022-02-02T07:33:50.815094Z","shell.execute_reply":"2022-02-02T07:35:06.51337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAMPLE = False # set True for debugging","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:06.516569Z","iopub.execute_input":"2022-02-02T07:35:06.516834Z","iopub.status.idle":"2022-02-02T07:35:06.522915Z","shell.execute_reply.started":"2022-02-02T07:35:06.516797Z","shell.execute_reply":"2022-02-02T07:35:06.522007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seqeval -qq # evaluation metrics for training (not the competition metric)\n!pip install --upgrade wandb -qq # experiment tracking","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:06.525721Z","iopub.execute_input":"2022-02-02T07:35:06.526367Z","iopub.status.idle":"2022-02-02T07:35:30.207555Z","shell.execute_reply.started":"2022-02-02T07:35:06.526332Z","shell.execute_reply":"2022-02-02T07:35:30.206545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:30.210222Z","iopub.execute_input":"2022-02-02T07:35:30.210548Z","iopub.status.idle":"2022-02-02T07:35:30.217259Z","shell.execute_reply.started":"2022-02-02T07:35:30.210502Z","shell.execute_reply":"2022-02-02T07:35:30.216273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONFIG\n\nEXP_NUM = 4\ntask = \"ner\"\nmodel_checkpoint = \"allenai/longformer-base-4096\"\nmax_length = 1024\nstride = 128\nmin_tokens = 6\nmodel_path = f'{model_checkpoint.split(\"/\")[-1]}-{EXP_NUM}'\n\n# TRAINING HYPERPARAMS\nBS = 10\nGRAD_ACC = 2\nLR = 5e-5\nWD = 0.01\nWARMUP = 0.1\nN_EPOCHS = 5","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-02-02T07:35:30.219766Z","iopub.execute_input":"2022-02-02T07:35:30.220073Z","iopub.status.idle":"2022-02-02T07:35:30.228853Z","shell.execute_reply.started":"2022-02-02T07:35:30.220041Z","shell.execute_reply":"2022-02-02T07:35:30.228143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# read train data\ntrain = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:30.230022Z","iopub.execute_input":"2022-02-02T07:35:30.230624Z","iopub.status.idle":"2022-02-02T07:35:31.822627Z","shell.execute_reply.started":"2022-02-02T07:35:30.230548Z","shell.execute_reply":"2022-02-02T07:35:31.82197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check unique classes\nclasses = train.discourse_type.unique().tolist()\nclasses","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:31.823841Z","iopub.execute_input":"2022-02-02T07:35:31.824135Z","iopub.status.idle":"2022-02-02T07:35:31.845772Z","shell.execute_reply.started":"2022-02-02T07:35:31.824095Z","shell.execute_reply":"2022-02-02T07:35:31.844556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup label indices\n\nfrom collections import defaultdict\ntags = defaultdict()\n\nfor i, c in enumerate(classes):\n    tags[f'B-{c}'] = i\n    tags[f'I-{c}'] = i + len(classes)\ntags[f'O'] = len(classes) * 2\ntags[f'Special'] = -100\n    \nl2i = dict(tags)\n\ni2l = defaultdict()\nfor k, v in l2i.items(): \n    i2l[v] = k\ni2l[-100] = 'Special'\n\ni2l = dict(i2l)\n\nN_LABELS = len(i2l) - 1 # not accounting for -100","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:31.846951Z","iopub.execute_input":"2022-02-02T07:35:31.847267Z","iopub.status.idle":"2022-02-02T07:35:31.854748Z","shell.execute_reply.started":"2022-02-02T07:35:31.847229Z","shell.execute_reply":"2022-02-02T07:35:31.853897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some helper functions\n\nfrom pathlib import Path\n\npath = Path('../input/feedback-prize-2021/train')\n\ndef get_raw_text(ids):\n    with open(path/f'{ids}.txt', 'r') as file: data = file.read()\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:31.856244Z","iopub.execute_input":"2022-02-02T07:35:31.85657Z","iopub.status.idle":"2022-02-02T07:35:31.862515Z","shell.execute_reply.started":"2022-02-02T07:35:31.856537Z","shell.execute_reply":"2022-02-02T07:35:31.86157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group training labels by text file\n\ndf1 = train.groupby('id')['discourse_type'].apply(list).reset_index(name='classlist')\ndf2 = train.groupby('id')['discourse_start'].apply(list).reset_index(name='starts')\ndf3 = train.groupby('id')['discourse_end'].apply(list).reset_index(name='ends')\ndf4 = train.groupby('id')['predictionstring'].apply(list).reset_index(name='predictionstrings')\n\ndf = pd.merge(df1, df2, how='inner', on='id')\ndf = pd.merge(df, df3, how='inner', on='id')\ndf = pd.merge(df, df4, how='inner', on='id')\ndf['text'] = df['id'].apply(get_raw_text)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:35:31.864092Z","iopub.execute_input":"2022-02-02T07:35:31.864411Z","iopub.status.idle":"2022-02-02T07:36:15.56404Z","shell.execute_reply.started":"2022-02-02T07:35:31.864374Z","shell.execute_reply":"2022-02-02T07:36:15.563358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# debugging\nif SAMPLE: df = df.sample(n=100).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:36:15.565127Z","iopub.execute_input":"2022-02-02T07:36:15.56597Z","iopub.status.idle":"2022-02-02T07:36:15.570551Z","shell.execute_reply.started":"2022-02-02T07:36:15.565915Z","shell.execute_reply":"2022-02-02T07:36:15.569507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will use HuggingFace datasets\nfrom datasets import Dataset, load_metric\n\nds = Dataset.from_pandas(df)\ndatasets = ds.train_test_split(test_size=0.1, shuffle=True, seed=42)\ndatasets","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:36:15.572114Z","iopub.execute_input":"2022-02-02T07:36:15.572468Z","iopub.status.idle":"2022-02-02T07:36:16.668569Z","shell.execute_reply.started":"2022-02-02T07:36:15.572432Z","shell.execute_reply":"2022-02-02T07:36:16.66785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:36:16.670044Z","iopub.execute_input":"2022-02-02T07:36:16.670291Z","iopub.status.idle":"2022-02-02T07:36:27.511475Z","shell.execute_reply.started":"2022-02-02T07:36:16.670256Z","shell.execute_reply":"2022-02-02T07:36:27.510627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Not sure if this is needed, but in case we create a span with certain class without starting token of that class,\n# let's convert the first token to be the starting token.\n\ne = [0,7,7,7,1,1,8,8,8,9,9,9,14,4,4,4]\n\ndef fix_beginnings(labels):\n    for i in range(1,len(labels)):\n        curr_lab = labels[i]\n        prev_lab = labels[i-1]\n        if curr_lab in range(7,14):\n            if prev_lab != curr_lab and prev_lab != curr_lab - 7:\n                labels[i] = curr_lab -7\n    return labels\n\nfix_beginnings(e)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:36:27.516076Z","iopub.execute_input":"2022-02-02T07:36:27.5163Z","iopub.status.idle":"2022-02-02T07:36:27.528738Z","shell.execute_reply.started":"2022-02-02T07:36:27.516265Z","shell.execute_reply":"2022-02-02T07:36:27.527976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenize and add labels\ndef tokenize_and_align_labels(examples):\n\n    o = tokenizer(examples['text'], truncation=True, padding=True, return_offsets_mapping=True, max_length=max_length, stride=stride, return_overflowing_tokens=True)\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = o[\"overflow_to_sample_mapping\"]\n    # The offset mappings will give us a map from token to character position in the original context. This will\n    # help us compute the start_positions and end_positions.\n    offset_mapping = o[\"offset_mapping\"]\n    \n    o[\"labels\"] = []\n\n    for i in range(len(offset_mapping)):\n                   \n        sample_index = sample_mapping[i]\n\n        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n\n        for label_start, label_end, label in \\\n        list(zip(examples['starts'][sample_index], examples['ends'][sample_index], examples['classlist'][sample_index])):\n            for j in range(len(labels)):\n                token_start = offset_mapping[i][j][0]\n                token_end = offset_mapping[i][j][1]\n                if token_start == label_start: \n                    labels[j] = l2i[f'B-{label}']    \n                if token_start > label_start and token_end <= label_end: \n                    labels[j] = l2i[f'I-{label}']\n\n        for k, input_id in enumerate(o['input_ids'][i]):\n            if input_id in [0,1,2]:\n                labels[k] = -100\n\n        labels = fix_beginnings(labels)\n                   \n        o[\"labels\"].append(labels)\n        \n    return o","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:36:27.530211Z","iopub.execute_input":"2022-02-02T07:36:27.530798Z","iopub.status.idle":"2022-02-02T07:36:27.542818Z","shell.execute_reply.started":"2022-02-02T07:36:27.530688Z","shell.execute_reply":"2022-02-02T07:36:27.54205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True,batch_size=20000, remove_columns=datasets[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:36:27.544089Z","iopub.execute_input":"2022-02-02T07:36:27.544536Z","iopub.status.idle":"2022-02-02T07:43:32.527698Z","shell.execute_reply.started":"2022-02-02T07:36:27.544479Z","shell.execute_reply":"2022-02-02T07:43:32.526981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:32.529077Z","iopub.execute_input":"2022-02-02T07:43:32.529477Z","iopub.status.idle":"2022-02-02T07:43:32.536861Z","shell.execute_reply.started":"2022-02-02T07:43:32.529439Z","shell.execute_reply":"2022-02-02T07:43:32.536203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training","metadata":{}},{"cell_type":"code","source":"# we will use auto model for token classification\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=N_LABELS)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:32.538223Z","iopub.execute_input":"2022-02-02T07:43:32.538743Z","iopub.status.idle":"2022-02-02T07:43:48.786077Z","shell.execute_reply.started":"2022-02-02T07:43:32.538685Z","shell.execute_reply":"2022-02-02T07:43:48.785375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###### DECLARING DEEPSPEED CONDFIG ##################\n\nds_config_dict = {\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": \"auto\",\n            \"betas\": \"auto\",\n            \"eps\": \"auto\",\n            \"weight_decay\": \"auto\"\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": \"auto\",\n            \"warmup_max_lr\": \"auto\",\n            \"warmup_num_steps\": \"auto\"\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": True\n        },\n        \"allgather_partitions\": True,\n        \"allgather_bucket_size\": 2e8,\n        \"overlap_comm\": True,\n        \"reduce_scatter\": True,\n        \"reduce_bucket_size\": 5e8,\n        \"contiguous_gradients\": True\n    },\n\n    \"gradient_accumulation_steps\": \"auto\",\n    \"gradient_clipping\": \"auto\",\n    \"steps_per_print\": 2000,\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\",\n    \"wall_clock_breakdown\": False\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:48.787621Z","iopub.execute_input":"2022-02-02T07:43:48.788121Z","iopub.status.idle":"2022-02-02T07:43:48.796569Z","shell.execute_reply.started":"2022-02-02T07:43:48.788081Z","shell.execute_reply":"2022-02-02T07:43:48.7959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = model_checkpoint.split(\"/\")[-1]\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-{task}\",\n    evaluation_strategy = \"epoch\",\n    logging_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=LR,\n    per_device_train_batch_size=BS,\n    per_device_eval_batch_size=BS,\n    num_train_epochs=N_EPOCHS,\n    weight_decay=WD,\n   # report_to='wandb', \n    gradient_accumulation_steps=GRAD_ACC,\n    warmup_ratio=WARMUP,\n    fp16 = True,\n    \n    #### THE ONLY CHANGE YOU NEED TO MAKE TO USE DEEPSPEED ########\n    deepspeed=ds_config_dict\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:48.797659Z","iopub.execute_input":"2022-02-02T07:43:48.800081Z","iopub.status.idle":"2022-02-02T07:43:49.416965Z","shell.execute_reply.started":"2022-02-02T07:43:48.80004Z","shell.execute_reply":"2022-02-02T07:43:49.416173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:49.419326Z","iopub.execute_input":"2022-02-02T07:43:49.419888Z","iopub.status.idle":"2022-02-02T07:43:49.42492Z","shell.execute_reply.started":"2022-02-02T07:43:49.419841Z","shell.execute_reply":"2022-02-02T07:43:49.424092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is not the competition metric, but for now this will be better than nothing...\n\nmetric = load_metric(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:49.428028Z","iopub.execute_input":"2022-02-02T07:43:49.428259Z","iopub.status.idle":"2022-02-02T07:43:50.215891Z","shell.execute_reply.started":"2022-02-02T07:43:49.428228Z","shell.execute_reply":"2022-02-02T07:43:50.215257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [i2l[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [i2l[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:50.217029Z","iopub.execute_input":"2022-02-02T07:43:50.217294Z","iopub.status.idle":"2022-02-02T07:43:50.225257Z","shell.execute_reply.started":"2022-02-02T07:43:50.217256Z","shell.execute_reply":"2022-02-02T07:43:50.224137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics, \n)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:50.226345Z","iopub.execute_input":"2022-02-02T07:43:50.226896Z","iopub.status.idle":"2022-02-02T07:43:50.275068Z","shell.execute_reply.started":"2022-02-02T07:43:50.226859Z","shell.execute_reply":"2022-02-02T07:43:50.274328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T07:43:50.276279Z","iopub.execute_input":"2022-02-02T07:43:50.27653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## End\n\nI'll appreciate every upvote or comment!","metadata":{}}]}