{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import KFold\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, LongformerTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-29T02:14:22.78472Z","iopub.execute_input":"2022-01-29T02:14:22.785272Z","iopub.status.idle":"2022-01-29T02:14:31.303044Z","shell.execute_reply.started":"2022-01-29T02:14:22.785173Z","shell.execute_reply":"2022-01-29T02:14:31.302225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:31.305323Z","iopub.execute_input":"2022-01-29T02:14:31.305677Z","iopub.status.idle":"2022-01-29T02:14:31.311255Z","shell.execute_reply.started":"2022-01-29T02:14:31.305624Z","shell.execute_reply":"2022-01-29T02:14:31.310444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    batch_size = 4\n    acc_steps = 8\n    max_len = 2048\n    lr = 2e-5\n    weight_decay=1e-3","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:31.312605Z","iopub.execute_input":"2022-01-29T02:14:31.316264Z","iopub.status.idle":"2022-01-29T02:14:31.333659Z","shell.execute_reply.started":"2022-01-29T02:14:31.316207Z","shell.execute_reply":"2022-01-29T02:14:31.332814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment2label = {\n    \"B\": 0,\n    \"I\": 1,\n    \"O\": 2\n}\n\nlabel2segment = {\n    0: \"B\",\n    1: \"I\",\n    2: \"O\"\n}\n\ndiscourse2label={\n    'Lead': 0,\n    'Position' : 1,\n    'Evidence' : 2,\n    'Claim' : 3,\n    'Concluding Statement' : 4,\n    'Counterclaim' : 5,\n    'Rebuttal': 6,\n    'O': 7\n}\nlabel2discourse={\n    0: 'Lead',\n    1: 'Position',\n    2: 'Evidence',\n    3: 'Claim',\n    4: 'Concluding Statement',\n    5: 'Counterclaim',\n    6: 'Rebuttal',\n    7: 'O'\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:31.33492Z","iopub.execute_input":"2022-01-29T02:14:31.3352Z","iopub.status.idle":"2022-01-29T02:14:31.345026Z","shell.execute_reply.started":"2022-01-29T02:14:31.335158Z","shell.execute_reply":"2022-01-29T02:14:31.344208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self):\n        super(FeedbackModel, self).__init__()\n        modelconfig = AutoConfig.from_pretrained(config.model_name)\n\n        self.backbone = AutoModel.from_pretrained(config.model_name)\n        self.fc_segment = nn.Linear(modelconfig.hidden_size, 3)\n        self.fc_discourse = nn.Linear(modelconfig.hidden_size, 8)\n    \n    def forward(self, input_ids, attn_mask):\n        attn_outputs = self.backbone(input_ids, attn_mask)\n        ysegment   = self.fc_segment(attn_outputs.last_hidden_state)\n        ydiscourse = self.fc_discourse(attn_outputs.last_hidden_state)\n        return ysegment, ydiscourse","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:31.347131Z","iopub.execute_input":"2022-01-29T02:14:31.347629Z","iopub.status.idle":"2022-01-29T02:14:31.357182Z","shell.execute_reply.started":"2022-01-29T02:14:31.347532Z","shell.execute_reply":"2022-01-29T02:14:31.356334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataset","metadata":{}},{"cell_type":"code","source":"class FeedbackDataset( torch.utils.data.Dataset ):\n    def __init__(self, df, tokenizer):\n        self.tokenizer=tokenizer\n        df=df.copy()\n        self.content = df.content.values\n    \n    def get_tokenized_inputs(self, essay):\n        tokenized_inputs = self.tokenizer(essay, is_split_into_words=True)\n        word_ids = tokenized_inputs.word_ids()\n        return (tokenized_inputs, word_ids)\n    \n    \n    def __getitem__(self, idx):\n        essay  = self.content[idx]\n        (tokenized_inputs, word_ids) = self.get_tokenized_inputs(essay)\n        word_ids[0] = -100\n        word_ids[-1] = -100\n        \n        input_ids = tokenized_inputs['input_ids'][:config.max_len]\n        attn_mask = tokenized_inputs['attention_mask'][:config.max_len]\n        word_ids = word_ids[:config.max_len]\n        seq_len = len(input_ids)\n        \n        if seq_len < config.max_len:\n            len_diff = config.max_len - seq_len\n            attn_mask += [0] * len_diff\n            input_ids += [self.tokenizer.pad_token_id] * len_diff\n            word_ids += [-100] * len_diff\n        \n        rpercentile = ((1 + np.arange(0, config.max_len))/seq_len) - 0.5        \n        input_ids=torch.tensor(input_ids, dtype=torch.long)\n        attn_mask = torch.tensor(attn_mask, dtype=torch.long)\n        seq_len = torch.tensor(seq_len, dtype=torch.long)\n        word_ids= torch.tensor(word_ids, dtype=torch.long)\n        rpercentile = torch.tensor(rpercentile, dtype=torch.float32)\n        \n        return {\n            'input_ids': input_ids,\n            'attn_mask': attn_mask,\n            'word_ids': word_ids,\n            'seq_len': seq_len,\n            'rpercentile': rpercentile\n        }\n    def __len__(self):\n        return len(self.content)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:31.358332Z","iopub.execute_input":"2022-01-29T02:14:31.358976Z","iopub.status.idle":"2022-01-29T02:14:31.372064Z","shell.execute_reply.started":"2022-01-29T02:14:31.358942Z","shell.execute_reply":"2022-01-29T02:14:31.371197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load models","metadata":{}},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(\n    '../input/longformer-base-tokenizer/longformer_base_tokenizer'\n)\nmodels = [\n    #torch.load('../input/longformer-multitask-baselinemodel/model1.pt', map_location = device),\n    #torch.load('../input/longformer-multitask-baselinemodel/model2.pt', map_location = device),\n    torch.load('../input/feedback-longformer-fold0/model.pt', map_location=device),\n    \n    #torch.load('../input/longformer-baseline-multitask2-models/model3.pt', map_location=device),\n    #torch.load('../input/longformer-baseline-multitask2-models/model4.pt', map_location=device)\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:31.373332Z","iopub.execute_input":"2022-01-29T02:14:31.373596Z","iopub.status.idle":"2022-01-29T02:14:39.307537Z","shell.execute_reply.started":"2022-01-29T02:14:31.373545Z","shell.execute_reply":"2022-01-29T02:14:39.306706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_essay(filename):\n    essay_folder='../input/feedback-prize-2021/test'\n    filepath = os.path.join(essay_folder, filename)\n    essay = ''\n    with open(filepath) as file:\n        essay = file.read()\n    essay=essay.split()\n    return essay","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:39.309019Z","iopub.execute_input":"2022-01-29T02:14:39.309426Z","iopub.status.idle":"2022-01-29T02:14:39.31541Z","shell.execute_reply.started":"2022-01-29T02:14:39.309377Z","shell.execute_reply":"2022-01-29T02:14:39.314372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files = os.listdir('../input/feedback-prize-2021/test')\ntest_df = []\nfor filename in test_files:\n    test_df.append({\n        'id': filename.replace(\".txt\", ''),\n        'content': read_essay(filename)\n    })\ntest_df = pd.DataFrame.from_dict(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:39.316452Z","iopub.execute_input":"2022-01-29T02:14:39.316687Z","iopub.status.idle":"2022-01-29T02:14:39.34976Z","shell.execute_reply.started":"2022-01-29T02:14:39.316659Z","shell.execute_reply":"2022-01-29T02:14:39.349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset   = FeedbackDataset(test_df, tokenizer)\nval_dataloader = torch.utils.data.DataLoader(val_dataset,\n                                             batch_size=2,\n                                             shuffle=False,\n                                             drop_last=False\n                                            )","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:39.351139Z","iopub.execute_input":"2022-01-29T02:14:39.351632Z","iopub.status.idle":"2022-01-29T02:14:39.362096Z","shell.execute_reply.started":"2022-01-29T02:14:39.351584Z","shell.execute_reply":"2022-01-29T02:14:39.361322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess( y, word_ids):\n    seq_len = len(y)\n    prv_word_id=None\n    predSegment=[]\n    predTokens=[]\n    \n    preds=[]\n    for i in range(seq_len):\n        word_id = word_ids[i]\n        if  (word_id== -100) or (prv_word_id == word_id):\n            continue\n        prv_word_id = word_id\n        if y[i] not in label2discourse:\n            continue\n        \n        segment = label2discourse[ y[i] ]\n        if segment == 'O':\n            continue\n        predSegment.append(segment)\n        predTokens.append( word_id )\n    \n    if len(predSegment) == 0:\n        return []\n    \n    if len(predSegment) == 1:\n        preds.append({\n            'segment': predSegment[0],\n            'word_ids': [predTokens[0]]\n        })\n        return preds\n    else:\n        num_tokens=len(predTokens)\n        prv_id=0\n        cur_id=0\n        prv_segment=predSegment[0]\n        \n        for i in range(1, num_tokens+1):\n            cur_id=i\n            if (i!=num_tokens) and (predTokens[i] == 1+predTokens[i-1]) and (predSegment[i] == predSegment[i-1]):\n                continue\n            \n            pred_token_list=[]\n            for j in range(prv_id, cur_id):\n                pred_token_list.append(predTokens[j])\n            \n            preds.append({\n                'segment': prv_segment,\n                'word_ids': pred_token_list\n            })\n            if i!=num_tokens:\n                prv_segment = predSegment[i]\n                prv_id=cur_id\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:39.363135Z","iopub.execute_input":"2022-01-29T02:14:39.363905Z","iopub.status.idle":"2022-01-29T02:14:39.378464Z","shell.execute_reply.started":"2022-01-29T02:14:39.363866Z","shell.execute_reply":"2022-01-29T02:14:39.377579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction(val_dataloader):\n    predvalues = []\n    for inputs in val_dataloader:\n        input_ids = inputs['input_ids']\n        attn_mask = inputs['attn_mask']\n        word_ids = inputs['word_ids']\n        seq_len = inputs['seq_len']\n        rpercentile = inputs['rpercentile']\n        batch_max_seqlen = torch.max(seq_len).item()\n        \n        input_ids = input_ids[:, :batch_max_seqlen].to(device)\n        attn_mask = attn_mask[:, :batch_max_seqlen].to(device)\n        rpercentile = rpercentile[:, :batch_max_seqlen].to(device)\n        \n        bsize = attn_mask.shape[0]\n        yhat_discourse = torch.zeros((bsize, batch_max_seqlen, 8))\n        \n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                (_, ycur_discourse)  = model(input_ids, attn_mask)\n                #yhat_segment = yhat_segment.softmax(dim=-1).argmax(dim=-1).cpu()\n                ycur_discourse = ycur_discourse.softmax(dim=-1).cpu()\n                yhat_discourse += ycur_discourse\n        yhat_discourse = yhat_discourse/len(models)\n        yhat_discourse = yhat_discourse.argmax(dim=-1)\n        \n        for i in range(bsize):\n            yhat_discourse_i = yhat_discourse[i].numpy()\n            word_ids_i = word_ids[i].numpy()\n            \n            pred_tokens = postprocess(yhat_discourse_i, word_ids_i)\n            for token in pred_tokens:\n                token['word_ids'] = [str(x) for x in token['word_ids']]\n                token['word_ids'] = ' '.join(token['word_ids'])\n            predvalues.append(pred_tokens)\n    return predvalues","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:39.379863Z","iopub.execute_input":"2022-01-29T02:14:39.380101Z","iopub.status.idle":"2022-01-29T02:14:39.393821Z","shell.execute_reply.started":"2022-01-29T02:14:39.380055Z","shell.execute_reply":"2022-01-29T02:14:39.392983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['predvalues'] = prediction(val_dataloader)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:39.395364Z","iopub.execute_input":"2022-01-29T02:14:39.395751Z","iopub.status.idle":"2022-01-29T02:14:57.124825Z","shell.execute_reply.started":"2022-01-29T02:14:39.395712Z","shell.execute_reply":"2022-01-29T02:14:57.124017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"this threshold is picked from the training data with <1% number of words","metadata":{}},{"cell_type":"code","source":"min_number_threshold={\n    'Lead': 8,\n    'Position': 5,\n    'Evidence': 11,\n    'Claim': 3,\n    'Concluding Statement': 9,\n    'Counterclaim': 5,\n    'Rebuttal': 4\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:57.127699Z","iopub.execute_input":"2022-01-29T02:14:57.12796Z","iopub.status.idle":"2022-01-29T02:14:57.133283Z","shell.execute_reply.started":"2022-01-29T02:14:57.127928Z","shell.execute_reply":"2022-01-29T02:14:57.132213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data=[]\nfor index, row in test_df.iterrows():\n    predvalues = row.predvalues\n    \n    for pred in predvalues:\n        submission_data.append({\n            'id': row.id,\n            'class': pred['segment'],\n            'predictionstring': pred['word_ids']\n        })\nsubmission_df = pd.DataFrame.from_dict(submission_data)\nsubmission_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:57.13463Z","iopub.execute_input":"2022-01-29T02:14:57.134972Z","iopub.status.idle":"2022-01-29T02:14:57.155581Z","shell.execute_reply.started":"2022-01-29T02:14:57.134938Z","shell.execute_reply":"2022-01-29T02:14:57.154437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_submission(row):\n    segment = row['class']\n    threshold = min_number_threshold[segment]\n    num_words = len(row.predictionstring.split())\n    if num_words <= threshold:\n        return False\n    return True","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:57.15828Z","iopub.execute_input":"2022-01-29T02:14:57.158756Z","iopub.status.idle":"2022-01-29T02:14:57.169142Z","shell.execute_reply.started":"2022-01-29T02:14:57.15871Z","shell.execute_reply":"2022-01-29T02:14:57.168331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = submission_df [ submission_df.apply(filter_submission, axis=1) ].copy()\nsubmission_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:57.170754Z","iopub.execute_input":"2022-01-29T02:14:57.171316Z","iopub.status.idle":"2022-01-29T02:14:57.193099Z","shell.execute_reply.started":"2022-01-29T02:14:57.171269Z","shell.execute_reply":"2022-01-29T02:14:57.191436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:14:57.195315Z","iopub.execute_input":"2022-01-29T02:14:57.195662Z","iopub.status.idle":"2022-01-29T02:14:57.206882Z","shell.execute_reply.started":"2022-01-29T02:14:57.195618Z","shell.execute_reply":"2022-01-29T02:14:57.206119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}