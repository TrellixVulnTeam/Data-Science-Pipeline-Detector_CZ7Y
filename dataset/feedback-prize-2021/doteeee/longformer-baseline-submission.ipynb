{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import KFold\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, LongformerTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-19T05:30:35.07145Z","iopub.execute_input":"2022-01-19T05:30:35.071805Z","iopub.status.idle":"2022-01-19T05:30:38.018582Z","shell.execute_reply.started":"2022-01-19T05:30:35.071711Z","shell.execute_reply":"2022-01-19T05:30:38.017434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:38.020624Z","iopub.execute_input":"2022-01-19T05:30:38.020855Z","iopub.status.idle":"2022-01-19T05:30:38.024957Z","shell.execute_reply.started":"2022-01-19T05:30:38.020828Z","shell.execute_reply":"2022-01-19T05:30:38.024118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    batch_size = 4\n    acc_steps = 8\n    max_len = 1024\n    lr = 2e-5\n    weight_decay=1e-3","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:38.026034Z","iopub.execute_input":"2022-01-19T05:30:38.026249Z","iopub.status.idle":"2022-01-19T05:30:38.042523Z","shell.execute_reply.started":"2022-01-19T05:30:38.026223Z","shell.execute_reply":"2022-01-19T05:30:38.041526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label2segment={\n    0: 'Lead',\n    1: 'Lead',\n    \n    2: 'Position',\n    3: 'Position',\n    \n    4: 'Evidence',\n    5: 'Evidence',\n    \n    6: 'Claim',\n    7: 'Claim',\n    \n    8: 'Concluding Statement',\n    9: 'Concluding Statement',\n    \n    10: 'Counterclaim',\n    11: 'Counterclaim',\n    \n    12: 'Rebuttal',\n    13: 'Rebuttal'\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:38.043848Z","iopub.execute_input":"2022-01-19T05:30:38.044454Z","iopub.status.idle":"2022-01-19T05:30:38.056722Z","shell.execute_reply.started":"2022-01-19T05:30:38.044414Z","shell.execute_reply":"2022-01-19T05:30:38.056062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self, num_labels):\n        super(FeedbackModel, self).__init__()\n        modelconfig = AutoConfig.from_pretrained(config.model_name)\n\n        self.backbone = AutoModel.from_pretrained(config.model_name)\n        self.output = nn.Linear(modelconfig.hidden_size, num_labels)\n    \n    def forward(self, input_ids, attn_mask, rpercentile):\n        attn_outputs = self.backbone(input_ids, attn_mask)\n        y=self.output(attn_outputs.last_hidden_state)\n        return y","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:38.058949Z","iopub.execute_input":"2022-01-19T05:30:38.059324Z","iopub.status.idle":"2022-01-19T05:30:38.067853Z","shell.execute_reply.started":"2022-01-19T05:30:38.059282Z","shell.execute_reply":"2022-01-19T05:30:38.067206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataset","metadata":{}},{"cell_type":"code","source":"class FeedbackDataset( torch.utils.data.Dataset ):\n    def __init__(self, df, tokenizer):\n        self.tokenizer=tokenizer\n        df=df.copy()\n        self.content = df.content.values\n    \n    def get_tokenized_inputs(self, essay):\n        tokenized_inputs = self.tokenizer(essay, is_split_into_words=True)\n        word_ids = tokenized_inputs.word_ids()\n        return (tokenized_inputs, word_ids)\n    \n    \n    def __getitem__(self, idx):\n        essay  = self.content[idx]\n        (tokenized_inputs, word_ids) = self.get_tokenized_inputs(essay)\n        word_ids[0] = -100\n        word_ids[-1] = -100\n        \n        input_ids = tokenized_inputs['input_ids'][:config.max_len]\n        attn_mask = tokenized_inputs['attention_mask'][:config.max_len]\n        word_ids = word_ids[:config.max_len]\n        seq_len = len(input_ids)\n        \n        if seq_len < config.max_len:\n            len_diff = config.max_len - seq_len\n            attn_mask += [0] * len_diff\n            input_ids += [self.tokenizer.pad_token_id] * len_diff\n            word_ids += [-100] * len_diff\n        \n        rpercentile = ((1 + np.arange(0, config.max_len))/seq_len) - 0.5        \n        input_ids=torch.tensor(input_ids, dtype=torch.long)\n        attn_mask = torch.tensor(attn_mask, dtype=torch.long)\n        seq_len = torch.tensor(seq_len, dtype=torch.long)\n        word_ids= torch.tensor(word_ids, dtype=torch.long)\n        rpercentile = torch.tensor(rpercentile, dtype=torch.float32)\n        \n        return {\n            'input_ids': input_ids,\n            'attn_mask': attn_mask,\n            'word_ids': word_ids,\n            'seq_len': seq_len,\n            'rpercentile': rpercentile\n        }\n    def __len__(self):\n        return len(self.content)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:38.06929Z","iopub.execute_input":"2022-01-19T05:30:38.069774Z","iopub.status.idle":"2022-01-19T05:30:38.083734Z","shell.execute_reply.started":"2022-01-19T05:30:38.069739Z","shell.execute_reply":"2022-01-19T05:30:38.082682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load models","metadata":{}},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained('../input/longformer-base-tokenizer/longformer_base_tokenizer')\nmodel = torch.load('../input/longformer-baseline-model/model.pt', map_location = device)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:38.085312Z","iopub.execute_input":"2022-01-19T05:30:38.085637Z","iopub.status.idle":"2022-01-19T05:30:44.829695Z","shell.execute_reply.started":"2022-01-19T05:30:38.085595Z","shell.execute_reply":"2022-01-19T05:30:44.82874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_essay(filename):\n    essay_folder='../input/feedback-prize-2021/test'\n    filepath = os.path.join(essay_folder, filename)\n    essay = ''\n    with open(filepath) as file:\n        essay = file.read()\n    essay=essay.split()\n    return essay","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:44.831035Z","iopub.execute_input":"2022-01-19T05:30:44.831249Z","iopub.status.idle":"2022-01-19T05:30:44.837206Z","shell.execute_reply.started":"2022-01-19T05:30:44.831224Z","shell.execute_reply":"2022-01-19T05:30:44.83625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files = os.listdir('../input/feedback-prize-2021/test')\ntest_df = []\nfor filename in test_files:\n    test_df.append({\n        'id': filename.replace(\".txt\", ''),\n        'content': read_essay(filename)\n    })\ntest_df = pd.DataFrame.from_dict(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:44.838525Z","iopub.execute_input":"2022-01-19T05:30:44.838828Z","iopub.status.idle":"2022-01-19T05:30:44.885388Z","shell.execute_reply.started":"2022-01-19T05:30:44.838737Z","shell.execute_reply":"2022-01-19T05:30:44.884693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset   = FeedbackDataset(test_df, tokenizer)\nval_dataloader = torch.utils.data.DataLoader(val_dataset,\n                                             batch_size=2,\n                                             shuffle=False,\n                                             drop_last=False\n                                            )","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:44.886521Z","iopub.execute_input":"2022-01-19T05:30:44.887065Z","iopub.status.idle":"2022-01-19T05:30:44.893517Z","shell.execute_reply.started":"2022-01-19T05:30:44.88703Z","shell.execute_reply":"2022-01-19T05:30:44.892885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess( y, word_ids):\n    seq_len = len(y)\n    prv_word_id=None\n    predSegment=[]\n    predTokens=[]\n    \n    preds=[]\n    for i in range(seq_len):\n        word_id = word_ids[i]\n        if  (word_id== -100) or (prv_word_id == word_id):\n            continue\n        prv_word_id = word_id\n        \n        if y[i] not in label2segment:\n            continue\n        \n        segment = label2segment[ y[i] ]\n        predSegment.append(segment)\n        predTokens.append( word_id )\n    \n    if len(predSegment) == 0:\n        return []\n    \n    if len(predSegment) == 1:\n        preds.append({\n            'segment': predSegment[0],\n            'word_ids': [predTokens[0]]\n        })\n        return preds\n    else:\n        num_tokens=len(predTokens)\n        prv_id=0\n        cur_id=0\n        prv_segment=predSegment[0]\n        \n        for i in range(1, num_tokens+1):\n            cur_id=i\n            if (i!=num_tokens) and \\\n                (predTokens[i] == 1+predTokens[i-1]) and \\\n                (predSegment[i] == predSegment[i-1]):\n                continue\n            \n            pred_token_list=[]\n            for j in range(prv_id, cur_id):\n                pred_token_list.append(predTokens[j])\n            \n            preds.append({\n                'segment': prv_segment,\n                'word_ids': pred_token_list\n            })\n            if i!=num_tokens:\n                prv_segment = predSegment[i]\n                prv_id=cur_id\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:44.894594Z","iopub.execute_input":"2022-01-19T05:30:44.895415Z","iopub.status.idle":"2022-01-19T05:30:44.907275Z","shell.execute_reply.started":"2022-01-19T05:30:44.895382Z","shell.execute_reply":"2022-01-19T05:30:44.906485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction(model, val_dataloader):\n    model.eval()\n    predvalues = []\n    for inputs in val_dataloader:\n        input_ids = inputs['input_ids']\n        attn_mask = inputs['attn_mask']\n        word_ids = inputs['word_ids']\n        seq_len = inputs['seq_len']\n        rpercentile = inputs['rpercentile']\n        batch_max_seqlen = torch.max(seq_len).item()\n        \n        input_ids = input_ids[:, :batch_max_seqlen].to(device)\n        attn_mask = attn_mask[:, :batch_max_seqlen].to(device)\n        rpercentile = rpercentile[:, :batch_max_seqlen].to(device)\n        with torch.no_grad():\n            yhat = model(input_ids, attn_mask, rpercentile).softmax(dim=-1).argmax(dim=-1).cpu()\n        \n        bsize = attn_mask.shape[0]\n        for i in range(bsize):\n            yhati = yhat[i].numpy()\n            word_ids_i = word_ids[i].numpy()\n            \n            pred_tokens = postprocess(yhati, word_ids_i)\n            for token in pred_tokens:\n                token['word_ids'] = [str(x) for x in token['word_ids']]\n                token['word_ids'] = ' '.join(token['word_ids'])\n            predvalues.append(pred_tokens)\n    return predvalues","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:44.908405Z","iopub.execute_input":"2022-01-19T05:30:44.908966Z","iopub.status.idle":"2022-01-19T05:30:44.926374Z","shell.execute_reply.started":"2022-01-19T05:30:44.908922Z","shell.execute_reply":"2022-01-19T05:30:44.925111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['predvalues'] = prediction(model, val_dataloader)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:44.927644Z","iopub.execute_input":"2022-01-19T05:30:44.927863Z","iopub.status.idle":"2022-01-19T05:30:58.107923Z","shell.execute_reply.started":"2022-01-19T05:30:44.927836Z","shell.execute_reply":"2022-01-19T05:30:58.106991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data=[]\nfor index, row in test_df.iterrows():\n    predvalues = row.predvalues\n    \n    for pred in predvalues:\n        if len(pred['word_ids'].split()) == 1:\n            continue\n            \n        submission_data.append({\n            'id': row.id,\n            'class': pred['segment'],\n            'predictionstring': pred['word_ids']\n        })\nsubmission_df = pd.DataFrame.from_dict(submission_data)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:58.110005Z","iopub.execute_input":"2022-01-19T05:30:58.110326Z","iopub.status.idle":"2022-01-19T05:30:58.124889Z","shell.execute_reply.started":"2022-01-19T05:30:58.110291Z","shell.execute_reply":"2022-01-19T05:30:58.123972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T05:30:58.1261Z","iopub.execute_input":"2022-01-19T05:30:58.12634Z","iopub.status.idle":"2022-01-19T05:30:58.141351Z","shell.execute_reply.started":"2022-01-19T05:30:58.126313Z","shell.execute_reply":"2022-01-19T05:30:58.140189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}