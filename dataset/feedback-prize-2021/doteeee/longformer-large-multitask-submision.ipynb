{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import KFold\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, LongformerTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-29T01:52:19.072455Z","iopub.execute_input":"2022-01-29T01:52:19.072973Z","iopub.status.idle":"2022-01-29T01:52:26.990497Z","shell.execute_reply.started":"2022-01-29T01:52:19.072863Z","shell.execute_reply":"2022-01-29T01:52:26.989634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:52:26.992241Z","iopub.execute_input":"2022-01-29T01:52:26.99254Z","iopub.status.idle":"2022-01-29T01:52:26.997373Z","shell.execute_reply.started":"2022-01-29T01:52:26.992496Z","shell.execute_reply":"2022-01-29T01:52:26.996671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    batch_size = 4\n    acc_steps = 8\n    max_len = 2048\n    lr = 2e-5\n    weight_decay=1e-3","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:52:26.998302Z","iopub.execute_input":"2022-01-29T01:52:26.999228Z","iopub.status.idle":"2022-01-29T01:52:27.017459Z","shell.execute_reply.started":"2022-01-29T01:52:26.999142Z","shell.execute_reply":"2022-01-29T01:52:27.016881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment2label = {\n    \"B\": 0,\n    \"I\": 1,\n    \"O\": 2\n}\n\nlabel2segment = {\n    0: \"B\",\n    1: \"I\",\n    2: \"O\"\n}\n\ndiscourse2label={\n    'Lead': 0,\n    'Position' : 1,\n    'Evidence' : 2,\n    'Claim' : 3,\n    'Concluding Statement' : 4,\n    'Counterclaim' : 5,\n    'Rebuttal': 6,\n    'O': 7\n}\nlabel2discourse={\n    0: 'Lead',\n    1: 'Position',\n    2: 'Evidence',\n    3: 'Claim',\n    4: 'Concluding Statement',\n    5: 'Counterclaim',\n    6: 'Rebuttal',\n    7: 'O'\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:52:27.019877Z","iopub.execute_input":"2022-01-29T01:52:27.020386Z","iopub.status.idle":"2022-01-29T01:52:27.028576Z","shell.execute_reply.started":"2022-01-29T01:52:27.020341Z","shell.execute_reply":"2022-01-29T01:52:27.027965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self):\n        super(FeedbackModel, self).__init__()\n        modelconfig = AutoConfig.from_pretrained(config.model_name)\n\n        self.backbone = AutoModel.from_pretrained(config.model_name)\n        self.fc_segment = nn.Linear(modelconfig.hidden_size, 3)\n        self.fc_discourse = nn.Linear(modelconfig.hidden_size, 8)\n    \n    def forward(self, input_ids, attn_mask):\n        attn_outputs = self.backbone(input_ids, attn_mask)\n        ysegment   = self.fc_segment(attn_outputs.last_hidden_state)\n        ydiscourse = self.fc_discourse(attn_outputs.last_hidden_state)\n        return ysegment, ydiscourse","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:52:27.03006Z","iopub.execute_input":"2022-01-29T01:52:27.030628Z","iopub.status.idle":"2022-01-29T01:52:27.040366Z","shell.execute_reply.started":"2022-01-29T01:52:27.030587Z","shell.execute_reply":"2022-01-29T01:52:27.039483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataset","metadata":{}},{"cell_type":"code","source":"class FeedbackDataset( torch.utils.data.Dataset ):\n    def __init__(self, df, tokenizer):\n        self.tokenizer=tokenizer\n        df=df.copy()\n        self.content = df.content.values\n    \n    def get_tokenized_inputs(self, essay):\n        tokenized_inputs = self.tokenizer(essay, is_split_into_words=True)\n        word_ids = tokenized_inputs.word_ids()\n        return (tokenized_inputs, word_ids)\n    \n    \n    def __getitem__(self, idx):\n        essay  = self.content[idx]\n        (tokenized_inputs, word_ids) = self.get_tokenized_inputs(essay)\n        word_ids[0] = -100\n        word_ids[-1] = -100\n        \n        input_ids = tokenized_inputs['input_ids'][:config.max_len]\n        attn_mask = tokenized_inputs['attention_mask'][:config.max_len]\n        word_ids = word_ids[:config.max_len]\n        seq_len = len(input_ids)\n        \n        if seq_len < config.max_len:\n            len_diff = config.max_len - seq_len\n            attn_mask += [0] * len_diff\n            input_ids += [self.tokenizer.pad_token_id] * len_diff\n            word_ids += [-100] * len_diff\n        \n        rpercentile = ((1 + np.arange(0, config.max_len))/seq_len) - 0.5        \n        input_ids=torch.tensor(input_ids, dtype=torch.long)\n        attn_mask = torch.tensor(attn_mask, dtype=torch.long)\n        seq_len = torch.tensor(seq_len, dtype=torch.long)\n        word_ids= torch.tensor(word_ids, dtype=torch.long)\n        rpercentile = torch.tensor(rpercentile, dtype=torch.float32)\n        \n        return {\n            'input_ids': input_ids,\n            'attn_mask': attn_mask,\n            'word_ids': word_ids,\n            'seq_len': seq_len,\n            'rpercentile': rpercentile\n        }\n    def __len__(self):\n        return len(self.content)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:52:27.04175Z","iopub.execute_input":"2022-01-29T01:52:27.042224Z","iopub.status.idle":"2022-01-29T01:52:27.055778Z","shell.execute_reply.started":"2022-01-29T01:52:27.042189Z","shell.execute_reply":"2022-01-29T01:52:27.055017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load models","metadata":{}},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained('../input/longformer-base-tokenizer/longformer_large_tokenizer')\nmodels = [\n    torch.load('../input/longformer-multitask-baselinemodel/model0.pt', map_location = device),\n    torch.load('../input/feedback-large-longformer-model1/model1.pt', map_location = device),\n    torch.load('../input/feedback-large-longformer-model2/model2.pt', map_location = device)\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:52:27.057073Z","iopub.execute_input":"2022-01-29T01:52:27.057814Z","iopub.status.idle":"2022-01-29T01:53:22.841317Z","shell.execute_reply.started":"2022-01-29T01:52:27.057778Z","shell.execute_reply":"2022-01-29T01:53:22.840488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_essay(filename):\n    essay_folder='../input/feedback-prize-2021/test'\n    filepath = os.path.join(essay_folder, filename)\n    essay = ''\n    with open(filepath) as file:\n        essay = file.read()\n    essay=essay.split()\n    return essay","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:53:22.84278Z","iopub.execute_input":"2022-01-29T01:53:22.842994Z","iopub.status.idle":"2022-01-29T01:53:22.848081Z","shell.execute_reply.started":"2022-01-29T01:53:22.842968Z","shell.execute_reply":"2022-01-29T01:53:22.84728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files = os.listdir('../input/feedback-prize-2021/test')\ntest_df = []\nfor filename in test_files:\n    test_df.append({\n        'id': filename.replace(\".txt\", ''),\n        'content': read_essay(filename)\n    })\ntest_df = pd.DataFrame.from_dict(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:53:22.849618Z","iopub.execute_input":"2022-01-29T01:53:22.849938Z","iopub.status.idle":"2022-01-29T01:53:22.890083Z","shell.execute_reply.started":"2022-01-29T01:53:22.849911Z","shell.execute_reply":"2022-01-29T01:53:22.889107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset   = FeedbackDataset(test_df, tokenizer)\nval_dataloader = torch.utils.data.DataLoader(val_dataset,\n                                             batch_size=2,\n                                             shuffle=False,\n                                             drop_last=False\n                                            )","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:53:22.893197Z","iopub.execute_input":"2022-01-29T01:53:22.893552Z","iopub.status.idle":"2022-01-29T01:53:22.905041Z","shell.execute_reply.started":"2022-01-29T01:53:22.893507Z","shell.execute_reply":"2022-01-29T01:53:22.904219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess( y, word_ids):\n    seq_len = len(y)\n    prv_word_id=None\n    predSegment=[]\n    predTokens=[]\n    \n    preds=[]\n    for i in range(seq_len):\n        word_id = word_ids[i]\n        if  (word_id== -100) or (prv_word_id == word_id):\n            continue\n        prv_word_id = word_id\n        if y[i] not in label2discourse:\n            continue\n        \n        segment = label2discourse[ y[i] ]\n        if segment == 'O':\n            continue\n        predSegment.append(segment)\n        predTokens.append( word_id )\n    \n    if len(predSegment) == 0:\n        return []\n    \n    if len(predSegment) == 1:\n        preds.append({\n            'segment': predSegment[0],\n            'word_ids': [predTokens[0]]\n        })\n        return preds\n    else:\n        num_tokens=len(predTokens)\n        prv_id=0\n        cur_id=0\n        prv_segment=predSegment[0]\n        \n        for i in range(1, num_tokens+1):\n            cur_id=i\n            if (i!=num_tokens) and (predTokens[i] == 1+predTokens[i-1]) and (predSegment[i] == predSegment[i-1]):\n                continue\n            \n            pred_token_list=[]\n            for j in range(prv_id, cur_id):\n                pred_token_list.append(predTokens[j])\n            \n            preds.append({\n                'segment': prv_segment,\n                'word_ids': pred_token_list\n            })\n            if i!=num_tokens:\n                prv_segment = predSegment[i]\n                prv_id=cur_id\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:53:22.906221Z","iopub.execute_input":"2022-01-29T01:53:22.907112Z","iopub.status.idle":"2022-01-29T01:53:22.920132Z","shell.execute_reply.started":"2022-01-29T01:53:22.907075Z","shell.execute_reply":"2022-01-29T01:53:22.919361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction(val_dataloader):\n    predvalues = []\n    for inputs in val_dataloader:\n        input_ids = inputs['input_ids']\n        attn_mask = inputs['attn_mask']\n        word_ids = inputs['word_ids']\n        seq_len = inputs['seq_len']\n        rpercentile = inputs['rpercentile']\n        batch_max_seqlen = torch.max(seq_len).item()\n        \n        input_ids = input_ids[:, :batch_max_seqlen].to(device)\n        attn_mask = attn_mask[:, :batch_max_seqlen].to(device)\n        rpercentile = rpercentile[:, :batch_max_seqlen].to(device)\n        \n        bsize = attn_mask.shape[0]\n        yhat_discourse = torch.zeros((bsize, batch_max_seqlen, 8))\n        \n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                (_, ycur_discourse)  = model(input_ids, attn_mask)\n                #yhat_segment = yhat_segment.softmax(dim=-1).argmax(dim=-1).cpu()\n                ycur_discourse = ycur_discourse.softmax(dim=-1).cpu()\n                yhat_discourse += ycur_discourse\n        yhat_discourse = yhat_discourse/len(models)\n        yhat_discourse = yhat_discourse.argmax(dim=-1)\n        \n        for i in range(bsize):\n            yhat_discourse_i = yhat_discourse[i].numpy()\n            word_ids_i = word_ids[i].numpy()\n            \n            pred_tokens = postprocess(yhat_discourse_i, word_ids_i)\n            for token in pred_tokens:\n                token['word_ids'] = [str(x) for x in token['word_ids']]\n                token['word_ids'] = ' '.join(token['word_ids'])\n            predvalues.append(pred_tokens)\n    return predvalues","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:53:22.921194Z","iopub.execute_input":"2022-01-29T01:53:22.922579Z","iopub.status.idle":"2022-01-29T01:53:22.936171Z","shell.execute_reply.started":"2022-01-29T01:53:22.92254Z","shell.execute_reply":"2022-01-29T01:53:22.9356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['predvalues'] = prediction(val_dataloader)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:53:22.937258Z","iopub.execute_input":"2022-01-29T01:53:22.937812Z","iopub.status.idle":"2022-01-29T01:56:02.628371Z","shell.execute_reply.started":"2022-01-29T01:53:22.937775Z","shell.execute_reply":"2022-01-29T01:56:02.626857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"this threshold is picked from the training data with <1% number of words","metadata":{}},{"cell_type":"code","source":"min_number_threshold={\n    'Lead': 8,\n    'Position': 5,\n    'Evidence': 11,\n    'Claim': 3,\n    'Concluding Statement': 9,\n    'Counterclaim': 5,\n    'Rebuttal': 4\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:56:02.629834Z","iopub.execute_input":"2022-01-29T01:56:02.630087Z","iopub.status.idle":"2022-01-29T01:56:02.635491Z","shell.execute_reply.started":"2022-01-29T01:56:02.630055Z","shell.execute_reply":"2022-01-29T01:56:02.634385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data=[]\nfor index, row in test_df.iterrows():\n    predvalues = row.predvalues\n    cur_lst=[]\n    for pred in predvalues:\n        segment = pred['segment']\n        predString = pred['word_ids']\n        \n        if len( predString.split() ) <= min_number_threshold[segment]:\n            continue\n        \n        cur_lst.append({\n            'id': row.id,\n            'class': segment,\n            'predictionstring': predString,\n            'ignore': False\n        })\n    \n    if len(cur_lst) == 1:\n        submission_data+=cur_lst\n    else:\n        for i in range(0, len(cur_lst)-1):\n            cur_segment = cur_lst[i]['class']\n            cur_predstring = cur_lst[i]['predictionstring']\n            \n            next_segment = cur_lst[i+1]['class']\n            next_predstring = cur_lst[i+1]['predictionstring']\n            \n            x1 = int(cur_predstring.split()[-1])\n            x2 = int(next_predstring.split()[0])\n            \n            if (cur_segment == 'Evidence') and (cur_segment == next_segment) and (x2-x1-1) == 1:\n                cur_lst[i+1]['predictionstring'] = (cur_lst[i]['predictionstring'] +' '+str(x1+1)+' '+cur_lst[i+1]['predictionstring'])\n                cur_lst[i]['ignore']=True\n        cur_lst = [ob for ob in cur_lst if ob['ignore']==False]\n        submission_data += cur_lst\n\nsubmission_df = pd.DataFrame.from_dict(submission_data)\nsubmission_df.drop(columns=['ignore'], inplace=True)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:56:02.636935Z","iopub.execute_input":"2022-01-29T01:56:02.637154Z","iopub.status.idle":"2022-01-29T01:56:02.669683Z","shell.execute_reply.started":"2022-01-29T01:56:02.637129Z","shell.execute_reply":"2022-01-29T01:56:02.668674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T01:56:02.671278Z","iopub.execute_input":"2022-01-29T01:56:02.671674Z","iopub.status.idle":"2022-01-29T01:56:02.68084Z","shell.execute_reply.started":"2022-01-29T01:56:02.671633Z","shell.execute_reply":"2022-01-29T01:56:02.680119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}