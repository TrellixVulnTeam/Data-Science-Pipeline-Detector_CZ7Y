{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output \n# when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-06T12:07:11.989378Z","iopub.execute_input":"2021-11-06T12:07:11.989893Z","iopub.status.idle":"2021-11-06T12:07:12.0058Z","shell.execute_reply.started":"2021-11-06T12:07:11.989804Z","shell.execute_reply":"2021-11-06T12:07:12.0048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:07:06.804498Z","iopub.execute_input":"2021-11-06T15:07:06.805195Z","iopub.status.idle":"2021-11-06T15:07:06.814838Z","shell.execute_reply.started":"2021-11-06T15:07:06.80516Z","shell.execute_reply":"2021-11-06T15:07:06.813769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_train = pd.read_csv('/kaggle/input/data-science-london-scikit-learn/train.csv', header=None)\nfull_test = pd.read_csv('/kaggle/input/data-science-london-scikit-learn/test.csv', header=None)\ntrainLabels = pd.read_csv('/kaggle/input/data-science-london-scikit-learn/trainLabels.csv', names=['y'])","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:08:20.268913Z","iopub.execute_input":"2021-11-06T12:08:20.269612Z","iopub.status.idle":"2021-11-06T12:08:20.584424Z","shell.execute_reply.started":"2021-11-06T12:08:20.269578Z","shell.execute_reply":"2021-11-06T12:08:20.583543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. **Some EDA**","metadata":{}},{"cell_type":"code","source":"full_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:40:42.349378Z","iopub.execute_input":"2021-11-06T12:40:42.349774Z","iopub.status.idle":"2021-11-06T12:40:42.377676Z","shell.execute_reply.started":"2021-11-06T12:40:42.349741Z","shell.execute_reply":"2021-11-06T12:40:42.376582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_train.shape,full_test.shape,trainLabels.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:41:14.175111Z","iopub.execute_input":"2021-11-06T12:41:14.175456Z","iopub.status.idle":"2021-11-06T12:41:14.18213Z","shell.execute_reply.started":"2021-11-06T12:41:14.175426Z","shell.execute_reply":"2021-11-06T12:41:14.181123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check out missing values\nfull_train.info()\nprint('-'*50)\nfull_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:47:03.236355Z","iopub.execute_input":"2021-11-06T12:47:03.236775Z","iopub.status.idle":"2021-11-06T12:47:03.276074Z","shell.execute_reply.started":"2021-11-06T12:47:03.236741Z","shell.execute_reply":"2021-11-06T12:47:03.275012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check whether exist the unbalanced-problems\ntrainLabels.apply(pd.value_counts)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:55:30.220459Z","iopub.execute_input":"2021-11-06T12:55:30.220866Z","iopub.status.idle":"2021-11-06T12:55:30.233591Z","shell.execute_reply.started":"2021-11-06T12:55:30.220834Z","shell.execute_reply":"2021-11-06T12:55:30.232636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. **Explore baseline models**","metadata":{}},{"cell_type":"code","source":"models = {}\nmodels['LR'] = LogisticRegression()\nmodels['LDA'] = LinearDiscriminantAnalysis()\nmodels['KNN'] = KNeighborsClassifier()\nmodels['DT'] = DecisionTreeClassifier()\nmodels['RF'] = RandomForestClassifier()\nmodels['NB'] = GaussianNB()\nmodels['SVM'] = SVC()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T13:23:24.319415Z","iopub.execute_input":"2021-11-06T13:23:24.319793Z","iopub.status.idle":"2021-11-06T13:23:24.325509Z","shell.execute_reply.started":"2021-11-06T13:23:24.319762Z","shell.execute_reply":"2021-11-06T13:23:24.324677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_mean_acc = {}\nresults = []\nfor model in models:\n    kfold = KFold(n_splits=5)\n    cv_results = cross_val_score(models[model],full_train, np.ravel(trainLabels),cv=kfold,scoring='accuracy')\n    results.append(cv_results)\n    baseline_mean_acc[model] = round(cv_results.mean(), 3)\n\nbaseline_mean_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:22:35.733322Z","iopub.execute_input":"2021-11-06T14:22:35.733695Z","iopub.status.idle":"2021-11-06T14:22:38.768514Z","shell.execute_reply.started":"2021-11-06T14:22:35.733661Z","shell.execute_reply":"2021-11-06T14:22:38.76738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Feature Engineering**","metadata":{}},{"cell_type":"markdown","source":"# Feature Scaling\n\nTwo approaches are shown below:\n\n- The StandardScaler assumes your data is normally distributed within each ***feature*** and will scale them such that the distribution is now centred around 0, with a standard deviation of 1.\n\n- The normalizer scales each ***value*** by dividing each value by its magnitude in n-dimensional space for n number of features.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, Normalizer\n\nstd = StandardScaler()\nstd_train_data = std.fit_transform(full_train)\n\nnorm = Normalizer()\nnorm_train_data = norm.fit_transform(full_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T13:40:28.215458Z","iopub.execute_input":"2021-11-06T13:40:28.21603Z","iopub.status.idle":"2021-11-06T13:40:28.231671Z","shell.execute_reply.started":"2021-11-06T13:40:28.215951Z","shell.execute_reply":"2021-11-06T13:40:28.230533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std_mean_acc = {}\nresults_std = []\nfor model in models:\n    kfold = KFold(n_splits=5)\n    cv_results_std = cross_val_score(models[model],std_train_data, np.ravel(trainLabels),cv=kfold,scoring='accuracy')\n    results_std.append(cv_results_std)\n    std_mean_acc[model] = round(cv_results_std.mean(), 3)\n    \nstd_mean_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:25:13.817497Z","iopub.execute_input":"2021-11-06T14:25:13.817875Z","iopub.status.idle":"2021-11-06T14:25:16.667753Z","shell.execute_reply.started":"2021-11-06T14:25:13.817844Z","shell.execute_reply":"2021-11-06T14:25:16.666745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm_mean_acc = {}\nresults_norm = []\nfor model in models:\n    kfold = KFold(n_splits=5)\n    cv_results_norm = cross_val_score(models[model], norm_train_data, np.ravel(trainLabels),cv=kfold,scoring='accuracy')\n    results_norm.append(cv_results_norm)\n    norm_mean_acc[model] = round(cv_results_norm.mean(), 3)\n    \nnorm_mean_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:26:06.5151Z","iopub.execute_input":"2021-11-06T14:26:06.515492Z","iopub.status.idle":"2021-11-06T14:26:09.435663Z","shell.execute_reply.started":"2021-11-06T14:26:06.515458Z","shell.execute_reply":"2021-11-06T14:26:09.434569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Principal Component Analysis (PCA)**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(0.85, whiten=True)\npca_train_data = pca.fit_transform(full_train)\nprint(pca_train_data.shape,'\\n')\n\nexplained_variance = pca.explained_variance_ratio_ \nprint(explained_variance)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:02:11.740696Z","iopub.execute_input":"2021-11-06T14:02:11.741195Z","iopub.status.idle":"2021-11-06T14:02:11.753482Z","shell.execute_reply.started":"2021-11-06T14:02:11.741164Z","shell.execute_reply":"2021-11-06T14:02:11.752268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_mean_acc = {}\nresults_pca = []\nfor model in models:\n    kfold = KFold(n_splits=5)\n    cv_results_pca = cross_val_score(models[model], pca_train_data, np.ravel(trainLabels),cv=kfold,scoring='accuracy')\n    results_pca.append(cv_results_pca)\n    pca_mean_acc[model] = round(cv_results_pca.mean(), 3)\n    \npca_mean_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:26:46.666437Z","iopub.execute_input":"2021-11-06T14:26:46.666824Z","iopub.status.idle":"2021-11-06T14:26:48.701435Z","shell.execute_reply.started":"2021-11-06T14:26:46.666791Z","shell.execute_reply":"2021-11-06T14:26:48.700665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualisation**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=[12,7])\n\n\nplt.plot(range(len(baseline_mean_acc)), list(baseline_mean_acc.values()), label='Baseline')\nplt.plot(range(len(std_mean_acc)), list(std_mean_acc.values()), label='Std_scale')\nplt.plot(range(len(norm_mean_acc)), list(norm_mean_acc.values()), label='Norm_scale')\nplt.plot(range(len(pca_mean_acc)), list(pca_mean_acc.values()), label='PCA')\n\n\nplt.legend(loc='lower right')\nplt.title('Approach comparison')\nplt.xlabel('Models')\nplt.ylabel('Accuracy')\nplt.xticks(range(len(baseline_mean_acc)), list(baseline_mean_acc.keys()))\nplt.yticks(np.arange(0.75, 0.93, 0.005))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:41:07.886669Z","iopub.execute_input":"2021-11-06T14:41:07.887037Z","iopub.status.idle":"2021-11-06T14:41:08.275701Z","shell.execute_reply.started":"2021-11-06T14:41:07.887008Z","shell.execute_reply":"2021-11-06T14:41:08.274683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gaussian Mixture and Grid Search\n\nLets take the above 2 algorithms (**KNN and SVM**) which gave maximum accuracy for the further analysis","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.mixture import GaussianMixture","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:07:38.369877Z","iopub.execute_input":"2021-11-06T15:07:38.370231Z","iopub.status.idle":"2021-11-06T15:07:38.467907Z","shell.execute_reply.started":"2021-11-06T15:07:38.370202Z","shell.execute_reply":"2021-11-06T15:07:38.466822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.r_[full_train,full_test]\nprint('X shape :',X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:08:12.550862Z","iopub.execute_input":"2021-11-06T15:08:12.551224Z","iopub.status.idle":"2021-11-06T15:08:12.574295Z","shell.execute_reply.started":"2021-11-06T15:08:12.551195Z","shell.execute_reply":"2021-11-06T15:08:12.573205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USING THE GAUSSIAN MIXTURE MODEL \n# The Bayesian information criterion (BIC) can be used to select the number of components \n# in a Gaussian Mixture in an efficient way. As the AIC does.\n\nlowest_bic = np.infty\nbic = []\nn_components_range = range(1, 10)\n\n# The GaussianMixture comes with different options to constrain the covariance of the difference classes estimated: \n# spherical, diagonal, tied or full covariance.\n\ncv_types = ['spherical', 'tied', 'diag', 'full']\nfor cv_type in cv_types:\n    for n_components in n_components_range:\n        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n        gmm.fit(X)\n        bic.append(gmm.bic(X))\n        if bic[-1] < lowest_bic:\n            lowest_bic = bic[-1]\n            best_gmm = gmm\n            \nbest_gmm.fit(X)\ngmm_train = best_gmm.predict_proba(full_train)\ngmm_test = best_gmm.predict_proba(full_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:22:48.479086Z","iopub.execute_input":"2021-11-06T15:22:48.479442Z","iopub.status.idle":"2021-11-06T15:23:36.618991Z","shell.execute_reply.started":"2021-11-06T15:22:48.479415Z","shell.execute_reply":"2021-11-06T15:23:36.617436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The predict_proba method take in new data points and predict the probability that this data point came from each Gaussian distribution.","metadata":{}},{"cell_type":"code","source":"#KNN \nknn = KNeighborsClassifier()\n\n#USING GRID SEARCH\nparam_grid_knn = {\"n_neighbors\": range(1, 11, 2), \n              \"weights\": ['uniform', 'distance']}\n\ngrid_search_knn = GridSearchCV(estimator=knn, \n                               param_grid=param_grid_knn, \n                               cv = 5, n_jobs=-1,\n                               scoring='accuracy').fit(gmm_train, trainLabels.values.ravel())\n\nknn_best = grid_search_knn.best_estimator_\n\nprint('KNN Best Score', grid_search_knn.best_score_)\nprint('KNN Best Params',grid_search_knn.best_params_)\nprint('KNN Accuracy',cross_val_score(knn_best, gmm_train, trainLabels.values.ravel(), cv=5).mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:41:26.446452Z","iopub.execute_input":"2021-11-06T15:41:26.446855Z","iopub.status.idle":"2021-11-06T15:41:26.686847Z","shell.execute_reply.started":"2021-11-06T15:41:26.446822Z","shell.execute_reply":"2021-11-06T15:41:26.685006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SVM\nsvc = SVC()\n\n#USING GRID SEARCH\nparam_grid_svm = {'C':[1,10,100,1000],\n              'gamma':[1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel':['linear','rbf']}\n\ngrid_search_svm = GridSearchCV(estimator=svc, \n                               param_grid=param_grid_svm, \n                               cv = 5, n_jobs=-1,\n                               scoring='accuracy').fit(gmm_train, trainLabels.values.ravel())\n\nsvm_best = grid_search_svm.best_estimator_\n\nprint('SVM Best Score',grid_search_svm.best_score_)\nprint('SVM Best Params',grid_search_svm.best_params_)\nprint('SVM Accuracy',cross_val_score(svm_best,gmm_train, trainLabels.values.ravel(), cv=5).mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:44:59.498277Z","iopub.execute_input":"2021-11-06T15:44:59.498774Z","iopub.status.idle":"2021-11-06T15:45:00.084434Z","shell.execute_reply.started":"2021-11-06T15:44:59.498744Z","shell.execute_reply":"2021-11-06T15:45:00.083361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4. Submission**","metadata":{}},{"cell_type":"code","source":"# Fitting our model\nsvm_best.fit(gmm_train,trainLabels.values.ravel())\npred  = svm_best.predict(gmm_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T15:52:49.734859Z","iopub.execute_input":"2021-11-06T15:52:49.735252Z","iopub.status.idle":"2021-11-06T15:52:49.746478Z","shell.execute_reply.started":"2021-11-06T15:52:49.735223Z","shell.execute_reply":"2021-11-06T15:52:49.745195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(pred)\nsubmission.columns = ['Solution']\nsubmission['Id'] = np.arange(1,submission.shape[0]+1)\nsubmission = submission[['Id', 'Solution']]\nsubmission.to_csv('submission_with_GMM.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T18:01:34.62678Z","iopub.execute_input":"2021-08-13T18:01:34.627163Z","iopub.status.idle":"2021-08-13T18:01:34.91903Z","shell.execute_reply.started":"2021-08-13T18:01:34.627133Z","shell.execute_reply":"2021-08-13T18:01:34.917935Z"},"trusted":true},"execution_count":null,"outputs":[]}]}