{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nseed = 42\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/data-science-london-scikit-learn/train.csv', header=None)\ntrain_labels = pd.read_csv('../input/data-science-london-scikit-learn/trainLabels.csv', header=None, names = ['Label'])\ntest_data = pd.read_csv('../input/data-science-london-scikit-learn/test.csv', header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape, train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting Training data into train and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train_data, np.ravel(train_labels)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(model):\n    \n    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n    print('Cross validation score - ', scores.mean()*100)\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n\n    accuracy = accuracy_score(y_valid, y_pred) \n    print('Validation accuracy - ',accuracy*100)\n    \n    #Return trained model\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\n\nprint('\\nKNN Classifier ')\nknn = evaluate_model(knn)\n\ndtc = DecisionTreeClassifier(random_state=seed)\nprint('\\nDecision Tree Classifier')\ndtc = evaluate_model(dtc)\n\nrfc = RandomForestClassifier(n_estimators=10, random_state=seed)\nprint('\\nRandom Forest Classifier')\nrfc = evaluate_model(rfc)\n\nsvc = SVC(gamma='auto', random_state=seed)\nprint('\\nSVM Classifier')\nsvc = evaluate_model(svc)\n\n\ngbc = GradientBoostingClassifier(n_estimators=20, random_state=seed)\nprint('\\nGradient Boosting Classifier')\ngbc = evaluate_model(gbc)\n\nadc = AdaBoostClassifier(base_estimator=rfc, n_estimators=30, random_state=seed)\nprint('\\nAdaBoost classifier with Random Forest Classifier')\nadc = evaluate_model(adc)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNN and SVM** classifiers have the highes accuracy**"},{"metadata":{},"cell_type":"markdown","source":"Dimensionality reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(random_state=seed)\n\npca.fit(X)\n\nfeatures = range(pca.n_components_)\nplt.figure(figsize=(13,6))\nplt.bar(features, pca.explained_variance_)\nplt.xlabel('PCA feature')\nplt.ylabel('variance')\nplt.xticks(features)\nplt.title('PCA Explained Variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selecting features with high explained variance and transforming the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=13)\n\nX_reduced = pca.fit_transform(X)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_reduced, y, test_size=0.3, random_state = seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making predictions with transformed data "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\n\nprint('\\nKNN Classifier ')\nknn = evaluate_model(knn)\n\ndtc = DecisionTreeClassifier(random_state=seed)\nprint('\\nDecision Tree Classifier')\ndtc = evaluate_model(dtc)\n\nrfc = RandomForestClassifier(n_estimators=10, random_state=seed)\nprint('\\nRandom Forest Classifier')\nrfc = evaluate_model(rfc)\n\nsvc = SVC(gamma='auto', random_state=seed)\nprint('\\nSVM Classifier')\nsvc = evaluate_model(svc)\n\n\ngbc = GradientBoostingClassifier(n_estimators=20, random_state=seed)\nprint('\\nGradient Boosting Classifier')\ngbc = evaluate_model(gbc)\n\nadc = AdaBoostClassifier(base_estimator=rfc, n_estimators=30, random_state=seed)\nprint('\\nAdaBoost classifier with Random Forest Classifier')\nadc = evaluate_model(adc)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNN, SVC and AdaBoost(with RFC)** gave the best accuracy after dimensionality reduction using PCA."},{"metadata":{},"cell_type":"markdown","source":"Using grid search to further improve model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"def perform_grid_search(model, param_grid, cv = 10, scoring='accuracy'):\n    \n    grid_search_model = GridSearchCV(estimator=model, param_grid=param_grid, cv = cv,scoring=scoring,n_jobs=-1, iid=False)\n    grid_search_model.fit(X_train, y_train)\n\n\n    best_model = grid_search_model.best_estimator_\n    print('Best Accuracy :',grid_search_model.best_score_ * 100)\n    print('Best Parmas',grid_search_model.best_params_)\n    \n    y_pred = best_model.predict(X_valid)\n    print('Validation Accuracy',accuracy_score(y_valid, y_pred)*100)\n    \n    return best_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\n\nn_neighbors = [3,4,5,6,7,8,9,10]\nparam_grid_knn = dict(n_neighbors=n_neighbors)\n\nprint('\\nKNN Classifier')\nknn_best = perform_grid_search(knn, param_grid_knn)\n\nrfc = RandomForestClassifier(random_state=seed)\n\nn_estimators = [10, 50, 100, 200]\nmax_depth = [3, 10, 15, 30]\nparam_grid_rfc = dict(n_estimators=n_estimators,max_depth=max_depth)\n\nprint('\\nRandom Forest Classifier')\nrfc_best = perform_grid_search(rfc, param_grid_rfc)\n\n\nsvc = SVC(random_state=seed)\n\nparam_grid_svc = [{'kernel':['linear'],'C':[1,10, 50,100]},\n              {'kernel':['rbf'],'C':[1,10, 50,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n\nprint('\\nSVM Classifier')\nsvc_best = perform_grid_search(svc, param_grid_svc)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Gaussian Mixture to furthur improve the performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\nX = np.r_[train_data,test_data]\n\nlowest_bic = np.infty\nbic = []\nn_components_range = range(1, 12)\n\ncv_types = ['spherical', 'tied', 'diag', 'full']\nfor cv_type in cv_types:\n    for n_components in n_components_range:\n        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n        gmm.fit(X)\n        bic.append(gmm.aic(X))\n        if bic[-1] < lowest_bic:\n            lowest_bic = bic[-1]\n            best_gmm = gmm\n            \nbest_gmm.fit(X)\ngmm_train = best_gmm.predict_proba(train_data)\ngmm_test = best_gmm.predict_proba(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the transformed data into training and validation sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(gmm_train, y, test_size=0.3, random_state = seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using grid search again to get the best model."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\n\nn_neighbors = [3,4,5,6,7,8,9,10]\nparam_grid_knn = dict(n_neighbors=n_neighbors)\n\nprint('\\nKNN Classifier')\nknn_best = perform_grid_search(knn, param_grid_knn)\n\nrfc_best = RandomForestClassifier(random_state=seed)\n\nn_estimators = [10, 50, 100, 200]\nmax_depth =  [3, 10, 15, 30]\nparam_grid_rfc = dict(n_estimators=n_estimators,max_depth=max_depth)\n\nprint('\\nRandom Forest Classifier')\nrfc = perform_grid_search(rfc, param_grid_rfc)\n\n\nsvc = SVC(random_state=seed)\n\nparam_grid_svc = [{'kernel':['linear'],'C':[1,10, 50,100]},\n              {'kernel':['rbf'],'C':[1,10, 50,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n\nprint('\\nSVM Classifier')\nsvc_best = perform_grid_search(svc, param_grid_svc)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making predictions with the best model"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred  = svc_best.predict(gmm_test)\nbest_pred = pd.DataFrame(pred)\n\nbest_pred.index += 1\n\nbest_pred.columns = ['Solution']\nbest_pred['Id'] = np.arange(1, best_pred.shape[0]+1)\nbest_pred = best_pred[['Id', 'Solution']]\n\nbest_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_pred.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}