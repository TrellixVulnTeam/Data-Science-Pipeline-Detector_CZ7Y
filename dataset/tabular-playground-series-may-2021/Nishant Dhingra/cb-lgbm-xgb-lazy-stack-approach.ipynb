{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nimport optuna\nfrom sklearn.metrics import log_loss\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nsns.set(color_codes=True)\npal = sns.color_palette(\"viridis\", 10)\nsns.set_palette(pal)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:33.806565Z","iopub.execute_input":"2021-06-01T10:56:33.807203Z","iopub.status.idle":"2021-06-01T10:56:35.431161Z","shell.execute_reply.started":"2021-06-01T10:56:33.807095Z","shell.execute_reply":"2021-06-01T10:56:35.430376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:35.432894Z","iopub.execute_input":"2021-06-01T10:56:35.433192Z","iopub.status.idle":"2021-06-01T10:56:36.012752Z","shell.execute_reply.started":"2021-06-01T10:56:35.433167Z","shell.execute_reply":"2021-06-01T10:56:36.011919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:36.015121Z","iopub.execute_input":"2021-06-01T10:56:36.015376Z","iopub.status.idle":"2021-06-01T10:56:36.054444Z","shell.execute_reply.started":"2021-06-01T10:56:36.015352Z","shell.execute_reply":"2021-06-01T10:56:36.053504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:36.055803Z","iopub.execute_input":"2021-06-01T10:56:36.056145Z","iopub.status.idle":"2021-06-01T10:56:36.093729Z","shell.execute_reply.started":"2021-06-01T10:56:36.056109Z","shell.execute_reply":"2021-06-01T10:56:36.093019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:36.094856Z","iopub.execute_input":"2021-06-01T10:56:36.095207Z","iopub.status.idle":"2021-06-01T10:56:36.116244Z","shell.execute_reply.started":"2021-06-01T10:56:36.095171Z","shell.execute_reply":"2021-06-01T10:56:36.115328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting + Report with Dataprep","metadata":{}},{"cell_type":"code","source":"!pip install dataprep","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-01T10:56:36.117447Z","iopub.execute_input":"2021-06-01T10:56:36.117799Z","iopub.status.idle":"2021-06-01T10:57:13.908824Z","shell.execute_reply.started":"2021-06-01T10:56:36.117766Z","shell.execute_reply":"2021-06-01T10:57:13.907813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataprep.eda import plot, plot_correlation, create_report, plot_missing","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:13.910487Z","iopub.execute_input":"2021-06-01T10:57:13.910866Z","iopub.status.idle":"2021-06-01T10:57:15.944539Z","shell.execute_reply.started":"2021-06-01T10:57:13.91082Z","shell.execute_reply":"2021-06-01T10:57:15.943577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(train.drop(['id','target'],axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:15.94771Z","iopub.execute_input":"2021-06-01T10:57:15.948073Z","iopub.status.idle":"2021-06-01T10:57:29.48227Z","shell.execute_reply.started":"2021-06-01T10:57:15.948033Z","shell.execute_reply":"2021-06-01T10:57:29.481457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_report(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:29.484094Z","iopub.execute_input":"2021-06-01T10:57:29.484562Z","iopub.status.idle":"2021-06-01T10:57:29.488021Z","shell.execute_reply.started":"2021-06-01T10:57:29.484504Z","shell.execute_reply":"2021-06-01T10:57:29.487289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights from EDA\n> #### 1. There is no corelation between the features even with the target variable.\n> #### 2. Most of the features are skewed with 0 values even >90%, that means feature selection will be necessary.\n> #### 3. Baseline model can overfit because of skewness in data.\n> #### 4. Outlier Detection and removal will also be handy to improve score.\n> #### 5. No corelation means that there are some unnecessary features.\n> #### 6. Also we can gain some info by feature engineering by trying feature interaction or ratio and increase corelation.","metadata":{}},{"cell_type":"code","source":"X = train.drop(['id','target'],axis=1)\ny = train['target']","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:29.489072Z","iopub.execute_input":"2021-06-01T10:57:29.489487Z","iopub.status.idle":"2021-06-01T10:57:29.514884Z","shell.execute_reply.started":"2021-06-01T10:57:29.489454Z","shell.execute_reply":"2021-06-01T10:57:29.514061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test  = train_test_split(X,y,train_size=0.8,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:29.516034Z","iopub.execute_input":"2021-06-01T10:57:29.516493Z","iopub.status.idle":"2021-06-01T10:57:29.592008Z","shell.execute_reply.started":"2021-06-01T10:57:29.516455Z","shell.execute_reply":"2021-06-01T10:57:29.59104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline CATBoost Classifier","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool\ntrain_pool = Pool(data=X_train, label=y_train)\ntest_pool = Pool(data=X_test, label=y_test.values) ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:29.593303Z","iopub.execute_input":"2021-06-01T10:57:29.593686Z","iopub.status.idle":"2021-06-01T10:57:29.727241Z","shell.execute_reply.started":"2021-06-01T10:57:29.593648Z","shell.execute_reply":"2021-06-01T10:57:29.726468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='MultiClass',\n    verbose=False\n)\nmodel.fit(train_pool,plot=True,eval_set=test_pool)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:29.728375Z","iopub.execute_input":"2021-06-01T10:57:29.728724Z","iopub.status.idle":"2021-06-01T10:58:43.744738Z","shell.execute_reply.started":"2021-06-01T10:57:29.728688Z","shell.execute_reply":"2021-06-01T10:58:43.743922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict_proba(X_test)\nlog_loss(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:58:43.746064Z","iopub.execute_input":"2021-06-01T10:58:43.746618Z","iopub.status.idle":"2021-06-01T10:58:43.810809Z","shell.execute_reply.started":"2021-06-01T10:58:43.746577Z","shell.execute_reply":"2021-06-01T10:58:43.810066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection with Permutation Importance","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nperm = PermutationImportance(model, random_state=13, scoring = 'neg_log_loss')\nperm.fit(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:58:43.811975Z","iopub.execute_input":"2021-06-01T10:58:43.812301Z","iopub.status.idle":"2021-06-01T10:59:03.744306Z","shell.execute_reply.started":"2021-06-01T10:58:43.812268Z","shell.execute_reply":"2021-06-01T10:59:03.743441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_importance = pd.DataFrame({'Feature':X_train.columns, 'Importance':perm.feature_importances_}).sort_values(by='Importance',ascending=False)\nplt.figure(figsize= (8,15))\nsns.barplot(data = feat_importance, y = 'Feature', x= 'Importance',orient='h')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-01T10:59:03.745668Z","iopub.execute_input":"2021-06-01T10:59:03.745995Z","iopub.status.idle":"2021-06-01T10:59:04.423034Z","shell.execute_reply.started":"2021-06-01T10:59:03.745959Z","shell.execute_reply":"2021-06-01T10:59:04.422057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = perm.feature_importances_\nl = []\nfor i in range(50):\n    if a[i]<0:\n        l.append('feature_'+str(i))\n        \nprint('Dropped Features')\nprint(l)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:59:04.424464Z","iopub.execute_input":"2021-06-01T10:59:04.424834Z","iopub.status.idle":"2021-06-01T10:59:04.431118Z","shell.execute_reply.started":"2021-06-01T10:59:04.424797Z","shell.execute_reply":"2021-06-01T10:59:04.430113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_new = train.drop(l,axis=1)\ntest_new =test.drop(l,axis=1)\nX_new = train_new.drop(['id','target'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:59:04.43246Z","iopub.execute_input":"2021-06-01T10:59:04.432878Z","iopub.status.idle":"2021-06-01T10:59:04.480146Z","shell.execute_reply.started":"2021-06-01T10:59:04.43284Z","shell.execute_reply":"2021-06-01T10:59:04.479074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizing Catboost Classifier with OPTUNA","metadata":{}},{"cell_type":"code","source":"def fun(trial,data=X_new,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param = {\n        'loss_function': 'MultiClass',\n        'eval_metric': 'MultiClass',\n        'learning_rate' : trial.suggest_uniform('learning_rate',1e-3,0.1),\n        \n        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,30),\n        'subsample': trial.suggest_uniform('subsample',0,1),\n        'random_strength': trial.suggest_uniform('random_strength',0,1),\n        'depth': trial.suggest_int('depth',5,12),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,100),\n        'num_leaves' : trial.suggest_int('num_leaves',16,64),\n        'leaf_estimation_method' : 'Newton',\n        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,10),\n        'verbose':False,\n        'bootstrap_type': 'Bernoulli',\n        'random_state' : trial.suggest_categorical('random_state',[13]),\n        'task_type' : 'GPU',\n        'grow_policy' : 'Lossguide'\n        \n    }\n    model = CatBoostClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=200,verbose=False)\n    \n    preds = model.predict_proba(test_x)\n    \n    ll = log_loss(test_y, preds)\n    \n    return ll","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:59:04.481508Z","iopub.execute_input":"2021-06-01T10:59:04.481877Z","iopub.status.idle":"2021-06-01T10:59:04.492948Z","shell.execute_reply.started":"2021-06-01T10:59:04.48184Z","shell.execute_reply":"2021-06-01T10:59:04.491743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(fun, n_trials=100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-01T10:59:04.494287Z","iopub.execute_input":"2021-06-01T10:59:04.494891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Predictions with tuned Model","metadata":{}},{"cell_type":"code","source":"best_params_cb = study.best_params\nbest_params_cb['loss_function'] = 'MultiClass'\nbest_params_cb['eval_metric'] = 'MultiClass'\nbest_params_cb['verbose'] = False\nbest_params_cb['n_estimators'] = 10000\nbest_params_cb['bootstrap_type']= 'Bernoulli'\nbest_params_cb['leaf_estimation_method'] = 'Newton'\nbest_params_cb['task_type'] = 'GPU'\nbest_params_cb['grow_policy'] = 'Lossguide'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions on Kfold","metadata":{}},{"cell_type":"code","source":"stacked_df = pd.DataFrame(columns = ['Class1m1', 'Class2m1','Class3m1','Class4m1','Class1m2', 'Class2m2','Class3m2','Class4m2','Class1m3', 'Class2m3','Class3m3','Class4m3','target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = train_new.drop(['id','target'],axis=1).columns\ncb_df = pd.DataFrame(columns = ['Class1m1', 'Class2m1','Class3m1','Class4m1','target'])\npreds = np.zeros((test.shape[0],4))\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train_new[columns], train_new['target']):\n    \n    X_tr, X_val = train_new[columns].iloc[tr_idx], train_new[columns].iloc[test_idx]\n    y_tr, y_val = train_new['target'].iloc[tr_idx], train_new['target'].iloc[test_idx]\n    \n    model = CatBoostClassifier(**best_params_cb)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=500,verbose=False)\n    y_pred  = model.predict_proba(X_val)\n    df = pd.DataFrame(y_pred,columns=['Class1m1', 'Class2m1','Class3m1','Class4m1'])\n    df['target'] = list(y_val)\n    \n    cb_df = pd.concat([cb_df,df])\n    preds+=model.predict_proba(test_new.drop(['id'],axis=1))/kf.n_splits\n    ll.append(log_loss(y_val, y_pred))\n    print(n+1,ll[n])\n    n+=1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(ll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold = pd.DataFrame(preds,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold['id']  = test['id']\ndf_kfold = df_kfold[['id','Class_1','Class_2','Class_3','Class_4']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_3 = df_kfold.to_csv('submit_3.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LGBMClassifier(random_state= 13, objective= 'multiclass', metric = 'multi_logloss').fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perm = PermutationImportance(model, random_state=13, scoring = 'neg_log_loss')\nperm.fit(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_importance = pd.DataFrame({'Feature':X_train.columns, 'Importance':perm.feature_importances_}).sort_values(by='Importance',ascending=False)\nplt.figure(figsize= (8,15))\nsns.barplot(data = feat_importance, y = 'Feature', x= 'Importance',orient='h')\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = perm.feature_importances_\nl = []\nfor i in range(50):\n    if a[i]<0:\n        l.append('feature_'+str(i))\n        \nprint('Dropped Features')\nprint(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_new = train.drop(l,axis=1)\ntest_new =test.drop(l,axis=1)\nX_new = train_new.drop(['id','target'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuning with OPTUNA","metadata":{}},{"cell_type":"code","source":"def fun2(trial, data = X_new, target=y):\n    train_x, test_x, train_y, test_y = train_test_split(data,target,train_size=0.8,random_state=42)\n    param = {\n         'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 30.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 30.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n\n        'subsample': trial.suggest_uniform('subsample', 0,1),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0, 0.1 ),\n        'max_depth': trial.suggest_int('max_depth', 1,100),\n        'num_leaves' : trial.suggest_int('num_leaves', 2, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100),\n        'cat_l2': trial.suggest_int('cat_l2',1,20),\n        'metric': 'multi_logloss', \n        'random_state' : trial.suggest_categorical('random_state',[13]),\n        'n_estimators': 10000,\n        'objective': 'multiclass',\n        'device_type':'gpu'\n        \n    }\n    model = LGBMClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=200,verbose=False)\n    \n    pred = model.predict_proba(test_x)\n    \n    ll = log_loss(test_y, pred)\n    \n    return ll","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_2 = optuna.create_study(direction='minimize')\nstudy_2.optimize(fun2, n_trials=100)\nprint('Number of finished trials:', len(study_2.trials))\nprint('Best trial:', study_2.best_trial.params)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params_lgbm = study_2.best_params\nbest_params_lgbm['objective'] = 'multiclass'\nbest_params_lgbm['metric'] = 'multi_logloss'\nbest_params_lgbm['n_estimators'] = 10000\nbest_params_lgbm['device_type'] : 'gpu'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM Kfold Predictions","metadata":{}},{"cell_type":"code","source":"columns = train_new.drop(['id','target'],axis=1).columns\npreds_2 = np.zeros((test.shape[0],4))\nlgbm_df = pd.DataFrame(columns = ['Class1m2', 'Class2m2','Class3m2','Class4m2','target'])\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train_new[columns], train_new['target']):\n    \n    X_tr, X_val = train_new[columns].iloc[tr_idx], train_new[columns].iloc[test_idx]\n    y_tr, y_val = train_new['target'].iloc[tr_idx], train_new['target'].iloc[test_idx]\n    \n    model = LGBMClassifier(**best_params_lgbm)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=500,verbose=False)\n    y_pred  = model.predict_proba(X_val)\n    df = pd.DataFrame(y_pred,columns=['Class1m2', 'Class2m2','Class3m2','Class4m2'])\n    df['target'] = list(y_val)\n    \n    lgbm_df = pd.concat([lgbm_df,df])\n    preds_2+=model.predict_proba(test_new.drop(['id'],axis=1))/kf.n_splits\n    ll.append(log_loss(y_val, y_pred))\n    print(n+1,ll[n])\n    n+=1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(ll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold_lgbm = pd.DataFrame(preds_2,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold_lgbm['id']  = test['id']\ndf_kfold_lgbm = df_kfold_lgbm[['id','Class_1','Class_2','Class_3','Class_4']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold_lgbm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_5 = df_kfold_lgbm.to_csv('submit_5.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection with Permutation Importance","metadata":{}},{"cell_type":"code","source":"model = XGBClassifier(random_State=13).fit(X_train, y_train)\nperm = PermutationImportance(model, random_state=13, scoring = 'neg_log_loss')\nperm.fit(X_test,y_test)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_importance = pd.DataFrame({'Feature':X_train.columns, 'Importance':perm.feature_importances_}).sort_values(by='Importance',ascending=False)\nplt.figure(figsize= (8,15))\nsns.barplot(data = feat_importance, y = 'Feature', x= 'Importance',orient='h')\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = perm.feature_importances_\nl = []\nfor i in range(50):\n    if a[i]<0:\n        l.append('feature_'+str(i))\n        \nprint('Dropped Features')\nprint(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_new = train.drop(l,axis=1)\ntest_new =test.drop(l,axis=1)\nX_new = train_new.drop(['id','target'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuning with OPTUNA","metadata":{}},{"cell_type":"code","source":"def fun3(trial, data = X_new, target = y):\n    train_x, test_x, train_y, test_y = train_test_split(data,target,train_size=0.8,random_state=42)\n\n    param = {\n       'learning_rate' : trial.suggest_uniform('learning_rate',0,1),\n        'gamma' : trial.suggest_uniform('gamma',0,100),\n        'max_depth': trial.suggest_int('max_depth', 1,100),\n        'min_child_weight' : trial.suggest_uniform('min_child_weight', 0,100),\n        'max_delta_step' : trial.suggest_uniform('max_delta_step',1,10),\n        'subsample' : trial.suggest_uniform('subsample',0,1),\n        'colsample_bytree' : trial.suggest_uniform('colsample_bytree',0,1),\n        'lambda' : trial.suggest_uniform('lambda',1e-5,30),\n        'alpha' : trial.suggest_uniform('alpha',1e-5,30),\n        'tree_method' :'gpu_hist',\n        'grow_policy':'lossguide',\n        'max_leaves': trial.suggest_int('max_leaves',16,64),\n        'random_state' : trial.suggest_categorical('random_state',[13]),\n        'objective':'multi:softprob',\n        'eval_metric':'mlogloss',\n        'predictor':'gpu_predictor'\n\n        \n    }\n    model = XGBClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=200,verbose=False)\n    pred_y = model.predict_proba(test_x)\n    \n    ll = log_loss(test_y, pred_y)\n    \n    return ll\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_3 = optuna.create_study(direction='minimize')\nstudy_3.optimize(fun3, n_trials=100)\nprint('Number of finished trials:', len(study_3.trials))\nprint('Best trial:', study_3.best_trial.params)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params_xgb = study_3.best_params\nbest_params_xgb['objective'] = 'multi:softprob'\nbest_params_xgb['eval_metric'] = 'mlogloss'\nbest_params_xgb['grow_policy'] = 'lossguide'\nbest_params_xgb['n_estimators'] = 10000\nbest_params_xgb['tree_method'] ='gpu_hist'\nbest_params_xgb['predictor'] ='gpu_predictor'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost KFOLD Predictions ","metadata":{}},{"cell_type":"code","source":"columns = train_new.drop(['id','target'],axis=1).columns\npreds_3 = np.zeros((test.shape[0],4))\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nxgb_df = pd.DataFrame(columns = ['Class1m3', 'Class2m3','Class3m3','Class4m3','target'])\nll =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train_new[columns], train_new['target']):\n    \n    X_tr, X_val = train_new[columns].iloc[tr_idx], train_new[columns].iloc[test_idx]\n    y_tr, y_val = train_new['target'].iloc[tr_idx], train_new['target'].iloc[test_idx]\n    \n    model = XGBClassifier(**best_params_xgb)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=500,verbose = False)\n    y_pred  = model.predict_proba(X_val)\n    df = pd.DataFrame(y_pred,columns=['Class1m3', 'Class2m3','Class3m3','Class4m3'])\n    df['target'] = list(y_val)\n    xgb_df = pd.concat([xgb_df,df])\n    \n    preds_3+=model.predict_proba(test_new.drop(['id'],axis=1))/kf.n_splits\n    ll.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,ll[n])\n    n+=1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(ll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold_xgb = pd.DataFrame(preds_3,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold_xgb['id']  = test['id']\ndf_kfold_xgb = df_kfold_xgb[['id','Class_1','Class_2','Class_3','Class_4']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold_xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_6 = df_kfold_xgb.to_csv('submit_6.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting Classifier (Catboost+LGBM+XGBoost)","metadata":{}},{"cell_type":"code","source":"preds_combined = (preds+preds_2+preds_3)/3\npreds_combined = np.clip(preds_combined,0.05, 0.95)\ndf_combined = pd.DataFrame(preds_combined,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_combined['id'] = test['id']\ndf_combined = df_combined[['id','Class_1','Class_2','Class_3','Class_4']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_output = df_combined.to_csv('final_submit.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacked Model","metadata":{}},{"cell_type":"code","source":"stacked_df['Class1m1'] = cb_df['Class1m1']\nstacked_df['Class2m1'] = cb_df['Class2m1']\nstacked_df['Class3m1'] = cb_df['Class3m1']\nstacked_df['Class4m1'] = cb_df['Class4m1']\n\nstacked_df['Class1m2'] = lgbm_df['Class1m2']\nstacked_df['Class2m2'] = lgbm_df['Class2m2']\nstacked_df['Class3m2'] = lgbm_df['Class3m2']\nstacked_df['Class4m2'] = lgbm_df['Class4m2']\n\nstacked_df['Class1m3'] = xgb_df['Class1m3']\nstacked_df['Class2m3'] = xgb_df['Class2m3']\nstacked_df['Class3m3'] = xgb_df['Class3m3']\nstacked_df['Class4m3'] = xgb_df['Class4m3']\n\nstacked_df['target'] = cb_df['target']\n\n\ntest_stacked_df = pd.DataFrame(columns = ['Class1m1', 'Class2m1','Class3m1','Class4m1','Class1m2', 'Class2m2','Class3m2','Class4m2','Class1m3', 'Class2m3','Class3m3','Class4m3'])\ntest_stacked_df['Class1m1'] = df_kfold['Class_1']\ntest_stacked_df['Class2m1'] = df_kfold['Class_2']\ntest_stacked_df['Class3m1'] = df_kfold['Class_3']\ntest_stacked_df['Class4m1'] = df_kfold['Class_4']\n\ntest_stacked_df['Class1m2'] = df_kfold_lgbm['Class_1']\ntest_stacked_df['Class2m2'] = df_kfold_lgbm['Class_2']\ntest_stacked_df['Class3m2'] = df_kfold_lgbm['Class_3']\ntest_stacked_df['Class4m2'] = df_kfold_lgbm['Class_4']\n\ntest_stacked_df['Class1m3'] = df_kfold_xgb['Class_1']\ntest_stacked_df['Class2m3'] = df_kfold_xgb['Class_2']\ntest_stacked_df['Class3m3'] = df_kfold_xgb['Class_3']\ntest_stacked_df['Class4m3'] = df_kfold_xgb['Class_4']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[]\nfor i in stacked_df['target']:\n    l.append(int(i))\n    \nstacked_df['target'] = l","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_stacked = np.zeros((test.shape[0],4))\ncolumns = ['Class1m1', 'Class2m1','Class3m1','Class4m1','Class1m2', 'Class2m2','Class3m2','Class4m2','Class1m3', 'Class2m3','Class3m3','Class4m3']\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(stacked_df[columns], stacked_df['target']):\n    \n    X_tr, X_val = stacked_df[columns].iloc[tr_idx], stacked_df[columns].iloc[test_idx]\n    y_tr, y_val = stacked_df['target'].iloc[tr_idx], stacked_df['target'].iloc[test_idx]\n    \n    model = LGBMClassifier(random_state= 13, objective= 'multiclass', metric = 'multi_logloss')\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=500,verbose=False)\n    y_pred  = model.predict_proba(X_val)\n    \n    preds_stacked+=model.predict_proba(test_stacked_df)/kf.n_splits\n    ll.append(log_loss(y_val, y_pred))\n    print(n+1,ll[n])\n    n+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(ll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold_st = pd.DataFrame(preds_stacked,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold_st['id']  = test['id']\ndf_kfold_st = df_kfold_st[['id','Class_1','Class_2','Class_3','Class_4']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_kfold_st","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_submit = df_kfold_st.to_csv('stacked_submit.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thanks, and don't forget to upvote, I'm a beginner it will motivate me!!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}