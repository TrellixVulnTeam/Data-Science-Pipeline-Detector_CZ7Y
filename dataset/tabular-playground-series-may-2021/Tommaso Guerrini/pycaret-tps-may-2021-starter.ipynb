{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Tabular Playground Series May 2021\n\n<img src=\"https://i.imgur.com/uHVJtv0.png\">\n<br>\n<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/4SxnawE.png\" align=\"center\"></p>\n\n<br><br>\n\n### Notebook Contents:\n\nHaving participated to some of the latest TPS challenges I noticed how more and more people have been using some autoMl library, not just to achieve great performances, but also to have a good starting point from where one can go on with the analysis. \n\nIn the [April TPS challenge](https://www.kaggle.com/c/tabular-playground-series-apr-2021/overview) alone some great notebook used AutoML:\n\n<ul>\n    <li><a href=https://www.kaggle.com/alexryzhkov/n3-tps-april-21-lightautoml-starter> LightAutoML </a></li>\n    <li><a href=https://www.kaggle.com/sureshmecad/tps-apr21-h2oautoml> H2OAutoML </a></li>\n    <li><a href=https://www.kaggle.com/mt77pp/mljar-automl-tps-apr-21> MLJAR </a></li>\n    <li><a href=https://www.kaggle.com/subinium/how-to-use-pycaret-with-feature-engineering> PYCARET </a></li>\n</ul>\n\nThere was also [this](https://www.kaggle.com/andreshg/tps-apr-automl-libraries-comparison) awesome notebook comparing all of them. Please upvote them if you find them useful, definitely a lot to learn (at least for me) from all of those people. \n\nHaving used PyCaret in some projects of mine I've decided to give it a try here, trying to keep things as simple and lean as possible.\n\nIn short: ***PyCaret*** *is a machine learning library which basically handles anything from data preprocessing to model search to hyperparameter optimization. You basically don't need anything other than the input data*. \n\n<div id=\"toc_container\" style=\"background: #f9f9f9; border: 1px solid #aaa; display: table; font-size: 95%;\n                               margin-bottom: 1em; padding: 20px; width: auto;\">\n<p class=\"toc_title\" style=\"font-weight: 700; text-align: center\">Notebook Contents</p>\n<ul class=\"toc_list\">\n  <li><a href=\"#loading\">0. Imports, Data Loading and Preprocessing</a>\n  <li><a href=\"#pycaret\">1. PyCaret </a>\n      <br>\n      <ul>\n    <li><a href=\"#setup\">1.0 Setup</a></li>\n    <li><a href=\"#model_search\">1.1 Model Search</a></li>\n    <li><a href=\"#tuning\">1.2 Model Tuning</a></li>\n  </ul>\n</li>\n<li><a href=\"#submission\">2. Submission</a></li>\n</ul>\n</div>","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.017004,"end_time":"2021-04-07T05:45:35.393896","exception":false,"start_time":"2021-04-07T05:45:35.376892","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"loading\"></a>\n\n##### 0. Imports, Data Loading and Preprocessing","metadata":{"papermill":{"duration":0.01564,"end_time":"2021-04-07T05:45:35.42565","exception":false,"start_time":"2021-04-07T05:45:35.41001","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install pycaret\n!pip install ngboost","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pycaret\nimport numpy as np\nimport pandas as pd\npd.options.display.max_columns = 100\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import QuantileTransformer, StandardScaler, PolynomialFeatures, LabelEncoder\nfrom sklearn.tree import DecisionTreeRegressor\ndtr_friedman_3 = DecisionTreeRegressor(criterion='friedman_mse', max_depth=3)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tqdm\nimport gc\nimport os\nroot_path = '/kaggle/input/tabular-playground-series-may-2021'","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":3.444298,"end_time":"2021-04-07T05:45:38.885901","exception":false,"start_time":"2021-04-07T05:45:35.441603","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data loading\ntrain = pd.read_csv(os.path.join(root_path, 'train.csv'))\ntest = pd.read_csv(os.path.join(root_path, 'test.csv'))\nsample_submission = pd.read_csv(os.path.join(root_path, 'sample_submission.csv'))","metadata":{"papermill":{"duration":0.688407,"end_time":"2021-04-07T05:45:39.591549","exception":false,"start_time":"2021-04-07T05:45:38.903142","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<a id=\"pycaret\"></a>\n\n### PyCaret\n\n<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/4SxnawE.png\" width=\"50%\"></p>\n\n_PyCaret is an open-source, low-code machine learning library in Python that aims to reduce the cycle time from hypothesis to insights. It is well suited for seasoned data scientists who want to increase the productivity of their ML experiments by using PyCaret in their workflows or for citizen data scientists and those new to data science with little or no background in coding. PyCaret allows you to go from preparing your data to deploying your model within seconds using your choice of notebook environment._\n\nLook [here](https://pycaret.org/guide/) to start with PyCaret.\n\n[Here](https://pycaret.readthedocs.io/en/latest/modules.html) you can find tutorial Notebooks for different tasks including Classification, Regression or Anomaly Detecetion. \n\nFurthermore I would take a look also at [this](https://www.learndatasci.com/tutorials/introduction-pycaret-machine-learning/) notebook and especially [this](https://www.kdnuggets.com/2020/11/5-things-doing-wrong-pycaret.html).","metadata":{"papermill":{"duration":0.016277,"end_time":"2021-04-07T05:45:41.841674","exception":false,"start_time":"2021-04-07T05:45:41.825397","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from pycaret.classification import setup, compare_models, predict_model\nfrom pycaret.classification import create_model, tune_model, plot_model, pull, models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'setup'></a>\n*Before doing anything we must call the [**setup**](https://pycaret.org/classification/) function*:\n\n_This function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must called before executing any other function in pycaret. It takes two mandatory parameters: dataframe {array-like, sparse matrix} and name of the target column. All other parameters are optional._\n\nIt has tons of parameters...","metadata":{}},{"cell_type":"code","source":"#expand to see all parameters\n?setup","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can specify how to handle categorical, ordinal, numeric, high cardinality features, how to deal with missing values, how to deal with collinearity, whether to use polynomial features, how to perform crossvalidation, whether to handle outliers or unbalanced data.  \n\nBut if you don't want to think about anything of that and just let PyCaret handle all the business **you will need just 2 parameters**: \n\n`data`: your Pandas Dataframe input data, where the preprocessing will be done and models will be trained and evaluated;\n\n`target`: the target column, the one which will be predicted","metadata":{}},{"cell_type":"code","source":"NFOLDS = 5\n#SAMPLE_SIZE = 10000\n#Just for demonstration purposes I will use these parameters, change them accordingly","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing = setup(data = train, ignore_features= ['id'],\n                      fold=NFOLDS, target = 'target', silent = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"model_search\"></a>\n\n---\n\n<h5> Model search </h5>\n\nOnce the preprocessing is done through the `setup` function, we can compare the models, using `compare_models`. \n\nWe just need to pick a metric to rank the models.\n\nTo see a list of available models you just need to call the `models` function:","metadata":{}},{"cell_type":"code","source":"models()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can also include custom models, for instance `ngboost`:","metadata":{}},{"cell_type":"code","source":"from ngboost import NGBClassifier\nfrom ngboost.distns import k_categorical\n\n#ngb parameters from here: https://www.kaggle.com/tomwarrens/ngboost-probabilistic-predictions-tps-may-21?scriptVersionId=61814577\nngb_model = NGBClassifier(**{\"random_state\": 42, \"Dist\": k_categorical(4), \n                           \"verbose\": True, \"verbose_eval\": 100, \"n_estimators\": 500,\n                           \"Base\": dtr_friedman_3, \"natural_gradient\": False,\n                           \"col_sample\": 0.8756820351378953, \"minibatch_frac\": 0.3791506299009752,\n                           \"learning_rate\": 0.1})\n\nngb_model = create_model(ngb_model, cross_validation=True, fold=NFOLDS)\n\nmodel_comparison = compare_models(include = ['lr', 'catboost', 'lightgbm', 'ada', 'ridge', 'gbc', ngb_model], \n                                  n_select = 2,\n                                  sort='Accuracy', fold = NFOLDS, verbose = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"if you don't want to see all the printing out just set `verbose=False` and use the `pull` method:","metadata":{}},{"cell_type":"code","source":"pull()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`compare_model` returns a list of the top `n_select` models, already trained. That allows you to already predict your test data labels throught the `predict_model` function:","metadata":{}},{"cell_type":"code","source":"print(model_comparison[0])\npredict_model(model_comparison[0], test.sample(100), raw_score = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<a id = \"tuning\"></a>\n\nWe can also directly create a model using the `create_model` function.","metadata":{}},{"cell_type":"code","source":"model = create_model('catboost', cross_validation=True, fold=NFOLDS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, 'error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, plot='feature')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n<a id = \"tuning\"></a>\n\n<h5> Model Tuning </h5>\n\nPyCaret allows also to tune a model, using a GridSearchCV, after having trained it once (as we did using the `create_model` function or the `compare_model` one). \n\nYou can either provide your own parameters in `custom_grid` or let it handle it by itself. ","metadata":{}},{"cell_type":"code","source":"params = {'n_estimators' : [10, 30], 'max_depth': [5, 6, 7, 8]}\n\ntuned_model = tune_model(model_comparison[0], optimize='Accuracy', fold=NFOLDS, custom_grid=params, n_iter=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(tuned_model, 'error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(tuned_model, plot='feature')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"submission\"></a>\n\n### Submission","metadata":{"papermill":{"duration":0.246567,"end_time":"2021-04-07T06:09:41.036187","exception":false,"start_time":"2021-04-07T06:09:40.78962","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Predictions are made using the `predict_model` function: once again it is very simple, we just need to provide a trained model and the test data.","metadata":{}},{"cell_type":"code","source":"test_predictions = (predict_model(model_comparison[0], data = test, raw_score = True)\n                    [['id', 'Score_Class_1', 'Score_Class_2', 'Score_Class_3', 'Score_Class_4']]\n                    .rename(columns = {'Score_Class_1': 'Class_1', \n                                       'Score_Class_2': 'Class_2',\n                                       'Score_Class_3': 'Class_3',\n                                       'Score_Class_4': 'Class_4'}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(test_predictions) == len(test)\ntest_predictions.to_csv('submission.csv', index = False)","metadata":{"papermill":{"duration":0.263548,"end_time":"2021-04-07T06:09:51.91388","exception":false,"start_time":"2021-04-07T06:09:51.650332","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}