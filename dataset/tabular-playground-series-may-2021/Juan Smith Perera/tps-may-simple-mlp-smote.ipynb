{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Simple Keras Pipeline\n\n- EDA : https://www.kaggle.com/subinium/tps-may-categorical-eda","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\nfrom sklearn.utils import class_weight\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n#!pip install imbalanced-learn\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\n\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)\n\n# counts each type of Class\nsorted(train['target'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalization","metadata":{}},{"cell_type":"code","source":"for i in range(50):\n        #mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n        #train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n        max = train[f'feature_{i}'].max()\n        train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : x/max)\n        \ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform target column into four columns, one for each class\n\nlabel_dict = {val:idx for idx, val in enumerate(sorted(train['target'].unique()))}\ntrain['target'] = train['target'].map(label_dict)\n\ntarget = train['target']\ntrain.drop(['target'], inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.values\ntarget = target.values\ntarget = to_categorical(target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split Data","metadata":{}},{"cell_type":"code","source":"oversample = SMOTE()\ntrainS, targetS = oversample.fit_resample(train, target)\nnp.sum(targetS, axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(trainS, targetS, test_size = 0.20, \n                                                  random_state = 2021, stratify = targetS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model (Keras)","metadata":{}},{"cell_type":"code","source":"num_features = 50\nnum_classes = 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The structure of the model can be changed freely, and the model is an MLP model using only Dense, Batchnormalization, Dropout.","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n        Dense(528, input_dim = num_features, kernel_initializer='normal', activation='relu'),\n        Dropout(0.3),\n        BatchNormalization(),\n        Dense(256, activation='relu'),\n        Dropout(0.3),\n        BatchNormalization(),\n        Dense(128, activation='relu'),\n        Dropout(0.2),\n        BatchNormalization(),\n        Dense(num_classes, activation = 'softmax')\n    ])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile","metadata":{}},{"cell_type":"code","source":"model.compile(loss = CategoricalCrossentropy(label_smoothing = 0.001),\n              optimizer = keras.optimizers.Adam(), \n              metrics = 'categorical_accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train,\n            batch_size = 512, epochs = 60, verbose = 2,\n            validation_data = (X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate","metadata":{}},{"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose = 0)\nscore = model.evaluate(train, target, verbose = 0)\nprint('Val loss: {}%'.format(score[0]))\nprint('Val score: {}%'.format(score[1] * 100))\nprint(\"MLP Error: %.2f%%\" % (100*(1 - score[1])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result visualization","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['loss'])\nsns.lineplot(x = history.epoch, y = history.history['val_loss'])\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc='best')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Method 2\npred = model.predict(train).argmax(axis=1)\nfig, ax = plt.subplots(figsize=(9, 9))\nsns.heatmap(confusion_matrix(target.argmax(axis=1), pred), cmap ='Blues', \n            annot = True, cbar = False, fmt ='d', square = True, linewidth = 0.4, ax = ax)\n\nax.set_xlabel('Pred', fontweight='bold')\nax.set_ylabel('True', fontweight='bold')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Output","metadata":{}},{"cell_type":"code","source":"for i in range(50):\n        #mean, std = test[f'feature_{i}'].mean(), test[f'feature_{i}'].std()\n        #test[f'feature_{i}'] = test[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n        max = test[f'feature_{i}'].max()\n        test[f'feature_{i}'] = test[f'feature_{i}'].apply(lambda x : x/max)\n        \ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = model.predict(test)\n\nsample_submission.to_csv('my_submission.csv',index = False)\nsample_submission.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}