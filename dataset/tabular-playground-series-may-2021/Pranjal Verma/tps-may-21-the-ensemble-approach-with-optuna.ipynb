{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n<h1 style = \"font-size:40px; font-family:cursive ; font-weight : normal; color : #7100B4; text-align: center; border-radius: 100px 100px;\">‚ö°Catboost+XGBoost+Lightgbm+DNN with OPTUNA‚ö°</h1>\n<br>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">‚úÖImporting Required Libraries: </h1>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\nfrom catboost import CatBoostClassifier\nfrom sklearn.feature_selection import chi2, f_classif, f_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import model_selection\nimport lightgbm as lgbm\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier, VotingClassifier\nimport optuna\nimport tqdm\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">üîçBasic Data Exploration: </h1>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.nunique()[1:].plot.barh(figsize=(8,12))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 6))\nsns.countplot(x='target', data=train)\nax.set_title('Target Distribution')\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns=['id']).describe().T.style.bar(subset=['mean'], color='#606ff2')\\\n                            .background_gradient(subset=['std'], cmap='magma_r')\\\n                            .background_gradient(subset=['50%'], cmap='summer')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(columns=['id']).describe().T.style.bar(subset=['mean'], color='#606ff2')\\\n                            .background_gradient(subset=['std'], cmap='magma_r')\\\n                            .background_gradient(subset=['50%'], cmap='summer')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">‚öí Data Transformation </h1>","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])\ntrain.columns\ncols = list(train.columns)\ncols.remove(\"target\")\ncols.remove(\"id\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_features = ['id', 'target']\nfeatures = []\nfor feat in train.columns:\n    if feat not in not_features:\n        features.append(feat)\nprint(features)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\ntrain[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train.drop(['target','id'],axis=1)\nX\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y=train['target']\nY","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">üéØCatBoost with OPTUNA </h1>","metadata":{}},{"cell_type":"code","source":"def objective(trial,data=X,target=Y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3,random_state=42)\n    params = {'iterations':trial.suggest_int(\"iterations\", 4000, 15000),\n              'od_wait':trial.suggest_int('od_wait', 500, 2300),\n             'loss_function':'MultiClass',\n              'task_type':\"GPU\",\n              'eval_metric':'MultiClass',\n              'leaf_estimation_method':'Newton',\n              'bootstrap_type': 'Bernoulli',\n              'learning_rate' : trial.suggest_uniform('learning_rate',0.02,0.3),\n              'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n              'subsample': trial.suggest_uniform('subsample',0,1),\n              'random_strength': trial.suggest_uniform('random_strength',10,30),\n              'depth': trial.suggest_int('depth',1,6),\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,6),\n               }\n    model = CatBoostClassifier(**params)  \n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n        \n    y_preds = model.predict_proba(X_test)\n\n\n    log_loss_multi = log_loss(y_test, y_preds)\n    \n    return log_loss_multi","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=25)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    #display(optuna.visualization.plot_intermediate_values(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_params = study.best_trial.params\ncat_params['loss_function'] = 'MultiClass'\ncat_params['eval_metric'] = 'MultiClass'\ncat_params['bootstrap_type']= 'Bernoulli'\ncat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = 42\ncat_params['task_type']='GPU'\ntest_preds=None\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(X.values , Y.values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = X.values[tr_index] , X.values[val_index]\n    y_train,y_val = Y.values[tr_index] , Y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =CatBoostClassifier(**cat_params)\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = False)\n    \n    train_preds = model.predict(x_train)    \n    val_preds = model.predict_proba(x_val)\n    \n    print(log_loss(y_val, val_preds))\n    \n    if test_preds is None:\n        test_preds = model.predict_proba(test[cols].values)\n    else:\n        test_preds += model.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\ntest_preds /= 10","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")\nsubmission1['Class_1']=test_preds[:,0]\nsubmission1['Class_2']=test_preds[:,1]\nsubmission1['Class_3']=test_preds[:,2]\nsubmission1['Class_4']=test_preds[:,3]\nsubmission1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">üéØXGBoost with OPTUNA </h1>","metadata":{}},{"cell_type":"code","source":"def objective(trial,data=X,target=Y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3,random_state=42)\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\",200,2000,100),\n        \"subsample\": trial.suggest_discrete_uniform(\"subsample\",0.6,1,0.1),\n        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\",0.6,1,0.1),\n        \"eta\": trial.suggest_loguniform(\"eta\",1e-3,0.1),\n        \"reg_alpha\": trial.suggest_int(\"reg_alpha\",1,50),\n        \"reg_lambda\": trial.suggest_int(\"reg_lambda\",5,100),\n        \"max_depth\": trial.suggest_int(\"max_depth\",5,20),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\",5,20),\n    }\n    model = xgb.XGBClassifier(**params, tree_method='gpu_hist', random_state=42)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose = False,eval_metric='mlogloss')\n        \n    y_preds = model.predict_proba(X_test)\n\n\n    log_loss_multi = log_loss(y_test, y_preds)\n    \n    return log_loss_multi","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=25)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    #display(optuna.visualization.plot_intermediate_values(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = study.best_trial.params\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['random_state'] = 42\ntest_preds1=None\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(X.values , Y.values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = X.values[tr_index] , X.values[val_index]\n    y_train,y_val = Y.values[tr_index] , Y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model1 = xgb.XGBClassifier(**xgb_params)\n    model1.fit(x_train, y_train, eval_set = eval_set, eval_metric='mlogloss',verbose=False)\n    \n    train_preds = model1.predict(x_train)    \n    val_preds = model1.predict_proba(x_val)\n    \n    print(log_loss(y_val, val_preds))\n    \n    if test_preds1 is None:\n        test_preds1 = model1.predict_proba(test[cols].values)\n    else:\n        test_preds1 += model1.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\ntest_preds1 /= 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")\nsubmission2['Class_1']=test_preds1[:,0]\nsubmission2['Class_2']=test_preds1[:,1]\nsubmission2['Class_3']=test_preds1[:,2]\nsubmission2['Class_4']=test_preds1[:,3]\nsubmission2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">üéØLightGBM with OPTUNA</h1>","metadata":{}},{"cell_type":"code","source":"def objective(trial,data=X,target=Y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3,random_state=42)\n    params = {\n        \"objective\": \"multiclass\",\n        \"num_class\":4,\n        \"metric\": \"multi_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    model = lgbm.LGBMClassifier(**params,random_state=42)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose = False)\n        \n    y_preds = model.predict_proba(X_test)\n\n\n    log_loss_multi = log_loss(y_test, y_preds)\n    \n    return log_loss_multi","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=25)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    #display(optuna.visualization.plot_intermediate_values(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_params = study.best_trial.params\nlgbm_params['objective'] = 'multiclass'\nlgbm_params['random_state'] = 42\nlgbm_params['metric'] = 'multi_logloss'\ntest_preds2=None\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(X.values , Y.values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = X.values[tr_index] , X.values[val_index]\n    y_train,y_val = Y.values[tr_index] , Y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model2 = lgbm.LGBMClassifier(**lgbm_params)\n    model2.fit(x_train, y_train, eval_set = eval_set,verbose=False)\n    \n    train_preds = model2.predict(x_train)    \n    val_preds = model2.predict_proba(x_val)\n    \n    print(log_loss(y_val, val_preds))\n    \n    if test_preds2 is None:\n        test_preds2 = model2.predict_proba(test[cols].values)\n    else:\n        test_preds2 += model2.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\ntest_preds2 /= 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission3 = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")\nsubmission3['Class_1']=test_preds2[:,0]\nsubmission3['Class_2']=test_preds2[:,1]\nsubmission3['Class_3']=test_preds2[:,2]\nsubmission3['Class_4']=test_preds2[:,3]\nsubmission3.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers, models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">üéØDNN </h1>","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(16, input_shape=X.shape,input_dim=50,activation='relu', name=\"Hidden-1\"))\nlayers.BatchNormalization()\nmodel.add(layers.Dropout(0.2))\n\n# model.add(layers.Dense(256, activation='relu'))\n# layers.BatchNormalization()\n# model.add(layers.Dropout(0.25))\n\n# model.add(layers.Dense(128, activation='relu'))\n# layers.BatchNormalization()\n# model.add(layers.Dropout(0.25))\n\n# model.add(layers.Dense(64, activation='relu'))\n# layers.BatchNormalization()\n# model.add(layers.Dropout(0.25))\n\n# model.add(layers.Dense(32, activation='relu'))\n# layers.BatchNormalization()\n# model.add(layers.Dropout(0.25))\n\n# model.add(layers.Dense(16, activation='relu'))\n# layers.BatchNormalization()\n# model.add(layers.Dropout(0.25))\n\nmodel.add(layers.Dense(8, activation='relu'))\nlayers.BatchNormalization()\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Dense(4, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y1 = pd.get_dummies(Y)\nY1","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X, Y1, epochs=50,validation_split=0.3)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.plot(history.history['loss'],lw=4)\nplt.plot(history.history['val_loss'],lw=4)\nplt.title('Model Loss',fontsize=20)\nplt.ylabel('Loss',fontsize=15)\nplt.xlabel('Epoch',fontsize=15)\nplt.legend(['Train','Test'])\nplt.show()","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds3=model.predict_proba(test[cols].values)\nsubmission4 = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")\nsubmission4['Class_1']=test_preds3[:,0]\nsubmission4['Class_2']=test_preds3[:,1]\nsubmission4['Class_3']=test_preds3[:,2]\nsubmission4['Class_4']=test_preds3[:,3]\nsubmission4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1.to_csv('sub1.csv',index=False)\nsubmission2.to_csv('sub2.csv',index=False)\nsubmission3.to_csv('sub3.csv',index=False)\nsubmission4.to_csv('sub4.csv',index=False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: cursive;display:fill; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #5CFBFA; color :#000000; border-radius: 150px 150px;\">üåÄEnsemble time </h1>","metadata":{}},{"cell_type":"markdown","source":"Playing with weights","metadata":{}},{"cell_type":"code","source":"res1 = (2*submission1 + submission2 + submission3 + 2*submission4)/6\nres1.to_csv(\"res1.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res2 = (submission1 + 2*submission2 + 2*submission3 + submission4)/6\nres2.to_csv(\"res2.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res3 = (2*submission1 + 2*submission2 + submission3 + submission4)/6\nres3.to_csv(\"res3.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res4 = (4*submission1 + 3*submission2 + 2*submission3 + submission4)/10\nres4.to_csv(\"res4.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}