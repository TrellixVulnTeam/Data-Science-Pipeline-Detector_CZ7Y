{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0 = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv')\ndf1 = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0.target = df0.target.map({val:i for i, val in enumerate(sorted(df0.target.unique()),1)})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0.target[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manifold Learning / Dimension Reduction","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, SpectralEmbedding, MDS\nfrom sklearn.model_selection import train_test_split, StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_train = df0.iloc[:, 1:].sample(10000, random_state = 1)\nsub_target = sub_train.target\nsub_train_only = sub_train.iloc[:,:-1]\nsub_train_only.shape, sub_target.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from umap import UMAP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\numap = UMAP(random_state=1)\ndr = umap.fit_transform(sub_train_only, sub_target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fig, ax = plt.subplots(figsize = (10,10))\n#sns.scatterplot(dr[:,0], dr[:,1], hue = sub_target , palette = sns.color_palette()[:4] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(x=dr[:,0], y=dr[:,1], color = sub_target  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"umap0 = UMAP(random_state=1)\ndr0 = umap0.fit_transform(df0.iloc[:,1:-1], df0.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(x=dr0[:,0], y=dr0[:,1], color = df0.target  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UMAP data clustering as additional feature\n\nExperiment it as addtional features or just using that clustering as feature for classificaiton. \nExperiment UMAP with different number of dimension output . \n\nShould try KNN classification with clustering results as input. ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = df0.iloc[:, 1:-1], df0.iloc[:, -1]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1, stratify = y)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc = GradientBoostingClassifier(n_estimators = 300 , verbose = 1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_gbc = gbc.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc.score(x_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_gbc, labels = gbc.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = gbc.classes_)\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_gbc, labels = gbc.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"umap2 = UMAP(random_state=1)\nx_train_umap_2 = umap2.fit_transform(x_train, y_train)\nx_test_umap_2 = umap2.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_umap_2 = GradientBoostingClassifier(n_estimators = 300 , verbose = 1)\ngbc_umap_2.fit(x_train_umap_2, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_gbc_umap2 = gbc_umap_2.predict(x_test_umap_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_umap_2.score(x_test_umap_2, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_gbc_umap2 )\ndisp = ConfusionMatrixDisplay(cm, display_labels = gbc_umap_2.classes_)\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_gbc_umap2, labels = gbc_umap_2.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_umap_2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_x_train_umap_2 = pd.DataFrame(x_train_umap_2, columns = ['umap2_1','umap2_2'])\n#df_x_train_umap_2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x_train = x_train.iloc[:,:-2]\nx_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x_train_add_umap2 = pd.concat([x_train, df_x_train_umap_2 ], axis=1 ,ignore_index= True) #strange, extra rows???\n#x_train_add_umap2 = pd.concat([x_train, df_x_train_umap_2 ], axis=1 ,ignore_index=False) #strange, extra rows???\n#x_train_add_umap2 = x_train.join(df_x_train_umap_2) #strange result in NAN\nx_train_add_umap2 = x_train.copy()          \nx_train_add_umap2['umap2_1'] = x_train_umap_2[:,0]\nx_train_add_umap2['umap2_2'] = x_train_umap_2[:,1]                           \n                           \n                           ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_add_umap2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_add_umap_2 = GradientBoostingClassifier(n_estimators = 300 , verbose = 1)\ngbc_add_umap_2.fit(x_train_add_umap2, y_train)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_add_umap2 = x_test.copy()       \nx_test_add_umap2['umap2_1'] = x_test_umap_2[:,0] \nx_test_add_umap2['umap2_2'] = x_test_umap_2[:,1]    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_gbc_add_umap2 = gbc_add_umap_2.predict(x_test_add_umap2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_add_umap_2.score(x_test_add_umap2, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_gbc_add_umap2 )\ndisp = ConfusionMatrixDisplay(cm, display_labels = gbc_add_umap_2.classes_)\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Note\n\nIt seems due to class imbalance, GBC always predict class_2 which gives overall good result. GBC on UMAP 2 dimension alone, shows underfit. GBC with raw data + UMAP 2 as extra feature does not give good result. Considering UMAP for reduced dimension of 6 instead of 2. ","metadata":{}},{"cell_type":"code","source":"x_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"umap6 = UMAP(n_components = 6, random_state = 1)\nx_train_umap6 = umap6.fit_transform(x_train, y_train)\nx_test_umap6 = umap6.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_umap6_only = GradientBoostingClassifier(n_estimators = 300,  verbose = 1)\ngbc_umap6_only.fit(x_train_umap6, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_gbc_umap6_only = gbc_umap6_only.predict(x_test_umap6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_test, y_pred_gbc_umap6_only), display_labels = gbc_umap6_only.classes_)\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Umap6 alone is rubbish. Try add this to raw data and see. ","metadata":{}},{"cell_type":"code","source":"#x_train_add_umap6 = pd.concat([x_train, pd.DataFrame(x_train_umap6, columns=['umap6_'+str(i) for i in range(1,7)])], axis = 1 , ignore_index = True)\n#x_train_add_umap6.head()\nx_train_add_umap6 = x_train.copy()\nx_test_add_umap6 = x_test.copy()       \nfor i in range(6):\n    yvar = 'umap6_'+str(i+1)\n    x_train_add_umap6[yvar] = x_train_umap6[:,i]\n    x_test_add_umap6[yvar] = x_test_umap6[:,i]\nx_train_add_umap6.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_add_umap6.shape, x_test_add_umap6.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_add_umap_6 = GradientBoostingClassifier(n_estimators = 300 , verbose = 1)\ngbc_add_umap_6.fit(x_train_add_umap6, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_gbc_umap6 = gbc_add_umap_6.predict(x_test_add_umap6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_test, y_pred_gbc_umap6), display_labels = gbc_add_umap_6.classes_)\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## test component of 3 and 4","metadata":{}},{"cell_type":"code","source":"umap_only = {}\nraw_add_umap = {}\nfor n_components in range(3,5):\n    print('%'*30)\n    print(f'Umap n_components = {n_components}')\n    print(f'Only {n_components} Umap components as feature for classification')\n    umap_only[n_components] = UMAP(n_components = n_components, random_state = 1)\n    umap_only['x_train_'+str(n_components)] = umap_only[n_components].fit_transform(x_train, y_train)\n    umap_only['x_test_'+str(n_components)] = umap_only[n_components].transform(x_test)\n    umap_only['gbc_umap'+str(n_components)] = GradientBoostingClassifier(n_estimators = 300, verbose = 1)\n    umap_only['gbc_umap'+str(n_components)].fit(umap_only['x_train_'+str(n_components)], y_train)\n    umap_only['y_pred_gbc_umap'+str(n_components)] = umap_only['gbc_umap'+str(n_components)].predict(umap_only['x_test_'+str(n_components)])\n    #print(umap_only['y_pred_gbc_umap'+str(n_components)].shape, y_test.shape)\n    print(umap_only['gbc_umap'+str(n_components)].score( umap_only['x_test_'+str(n_components)] , y_test))\n    disp = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_test, umap_only['y_pred_gbc_umap'+str(n_components)]), display_labels = umap_only['gbc_umap'+str(n_components)].classes_)\n    disp.plot()\n    print(classification_report(y_test, umap_only['y_pred_gbc_umap'+str(n_components)], labels = umap_only['gbc_umap'+str(n_components)].classes_))\n    \n    print('='*20)\n    print(f'Original Feature +  {n_components} Umap components as feature for classification')\n    raw_add_umap['x_train_umap'+str(n_components)] = x_train.copy()\n    raw_add_umap['x_test_umap'+str(n_components)]  = x_test.copy()       \n    for i in range(n_components):\n        yvar = 'umap'+str(n_components)+'_'+str(i+1)\n        raw_add_umap['x_train_umap'+str(n_components)][yvar] = umap_only['x_train_'+str(n_components)][:,i]\n        raw_add_umap['x_test_umap'+str(n_components)][yvar] = umap_only['x_test_'+str(n_components)][:,i]\n    raw_add_umap['gbc_umap'+str(n_components)] = GradientBoostingClassifier(n_estimators = 300, verbose = 1)\n    raw_add_umap['gbc_umap'+str(n_components)].fit(raw_add_umap['x_train_umap'+str(n_components)], y_train)\n    raw_add_umap['y_pred_gbc_umap'+str(n_components)] = raw_add_umap['gbc_umap'+str(n_components)].predict(raw_add_umap['x_test_umap'+str(n_components)])\n    print(raw_add_umap['gbc_umap'+str(n_components)].score( raw_add_umap['x_test_umap'+str(n_components)] , y_test))\n    disp = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_test, raw_add_umap['y_pred_gbc_umap'+str(n_components)]), display_labels = raw_add_umap['gbc_umap'+str(n_components)].classes_)\n    disp.plot()\n    \n    print(classification_report(y_test, raw_add_umap['y_pred_gbc_umap'+str(n_components)], labels = raw_add_umap['gbc_umap'+str(n_components)].classes_))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}