{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MLJAR AutoML \n\nMLJAR is an Automated Machine Learning framework. It is available as Python package with code at GitHub: https://github.com/mljar/mljar-supervised\n\nThe MLJAR AutoML can work in several modes:\n- Explain - ideal for initial data exploration\n- Perform - perfect for production-level ML systems\n- Compete - mode for ML competitions under restricted time budget. By the default, it performs advanced feature engineering like golden features search, kmeans features, feature selection. It does model stacking.\n- Optuna - uses Optuna to highly tune algorithms: Random Forest, Extra Trees, Xgboost, LightGBM, CatBoost, Neural Network. Each algorithm is tuned with `Optuna` hperparameters framework with selected time budget (controlled with `optuna_time_budget`). By the default feature engineering is not enabled (you need to manually swtich it on, in AutoML() parameter).\n\n\n## Explain\n\nThe example useage of `Explain` with `MLJAR`:\n\n```python\n\nautoml = AutoML(mode=\"Explain\")\nautoml.fit(X, y)\n```\n\nThe best choice to get initial information about your data. This mode will produce a lot of explanations for your data. All details can be viewed in the Notebook by calling the `automl.report()` method.\n\n\n## Compete\n\nThe example useage of `Compete` with `MLJAR`:\n\n```python\n\nautoml = AutoML(mode=\"Compete\",\n                total_time_limit=8*3600)\nautoml.fit(X, y)\n```\n\nThat's it. It will train: Random Forest, Extra Trees, Xgboost, LightGBM, CatBoost, Neural Network, Ensemble, and stack all the models. Feature engineering will be applied (if enough training time). \n\n\n## Optuna\n\nThe example useage of `Optuna` with `MLJAR`:\n\n```python\n\nautoml = AutoML(mode=\"Optuna\", \n                optuna_time_budget=1800, \n                optuna_init_params={}, \n                algorithms=[\"LightGBM\", \"Xgboost\", \"Extra Trees\"], \n                total_time_limit=24*3600)\nautoml.fit(X, y)\n```\n\nDescription of parameters:\n- `optuna_time_budget` - time budget for `Optuna` to tune each algorithm,\n- `optuna_init_params` - if you have precomputed parameters for `Optuna` they can be passed here, then for already optimized models `Optuna` will not be used.\n- `algorithms` - the algorithms that we will check,\n- `total_time_limit` - the total time limit for AutoML training.\n\n(In the `Optuna` mode, only first fold is used for model tuning.)\n\n---\n\nMLJAR GitHub: https://github.com/mljar/mljar-supervised\n\n<img src=\"https://raw.githubusercontent.com/mljar/visual-identity/main/media/kaggle_banner_white.png\" style=\"width: 70%;\"/>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -q -U git+https://github.com/mljar/mljar-supervised.git@dev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom supervised.automl import AutoML # mljar-supervised","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_cols = train.columns[1:-1].tolist()\ny_col = train.columns[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"automl = AutoML(\n    mode=\"Optuna\",\n    optuna_time_budget=600,\n    total_time_limit=6*3600,\n    golden_features=True,\n    boost_on_errors=True,\n    optuna_verbose=False\n)\nautoml.fit(train[x_cols], train[y_col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = automl.predict_proba(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")\nsub[sub.columns[1:]] = preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"1_submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"automl.report()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}