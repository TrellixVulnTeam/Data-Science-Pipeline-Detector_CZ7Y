{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tqdm.notebook as tqdm\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/train.csv\").drop(columns='id')\ndf_test = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/test.csv\").drop(columns='id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are duplicated within the train data\nprint(df_train.drop(columns='target').duplicated(keep=False).sum())\nprint(df_test.duplicated(keep=False).sum())\n\n# We just drop these since they all have different classes\nprint(df_train.duplicated(keep=False).sum())  # Not dropping tatget gives 0\ndf_train = df_train[~df_train.drop(columns='target').duplicated(keep=False)]\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_df_train = df_train.copy()\n_df_test = df_test.copy()\n_df_test['split'] = 'test'\n_df_train['split'] = 'train'\n_df = pd.concat([_df_train, _df_test])\n_df[_df.drop(columns=['split', 'target']).duplicated(keep=False)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## Train vs Test distributions","metadata":{}},{"cell_type":"code","source":"df_train.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import anderson_ksamp, ks_2samp\n\nfor col in df_test.columns:\n    s = ks_2samp(df_train[col], df_test[col])\n    # s = anderson_ksamp([df_train[col], df_test[col]])\n    print(f'{col}: {s}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"KS test implies that train and test distibutions are pretty similar.","metadata":{}},{"cell_type":"markdown","source":"## Target counts","metadata":{}},{"cell_type":"code","source":"df_train.target.value_counts().plot(kind='bar')\n# df_test.target.value_counts().plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"df_train.boxplot(figsize=(20, 10), rot=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Variation of features split by target\n\nKeep in mind class imbalance","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(17, 3, figsize=(18, 54))\n\ncnts = df_train.drop(columns='target').value_counts().sort_index()\ntarget_order = sorted(df_train.target.unique())\n\nfor col, ax in tqdm.tqdm(zip(df_train.drop(columns='target'), axes.flatten()), total=50):\n    cnt = df_train[col].value_counts().sort_index()\n    sns.kdeplot(x=col, hue='target', hue_order=target_order, data=df_train, fill=True, legend=True, ax=ax,)\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.set_title(f'{col}, Unique Values: {len(cnt)}', loc='right', fontsize=12)\n    ax.axis('off')\n    \naxes.flatten()[-1].axis('off')\naxes.flatten()[-2].axis('off')\n\nfig.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlations","metadata":{}},{"cell_type":"code","source":"_ = plt.figure(figsize=(10, 10))\ncorr = df_train.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nvt = VarianceThreshold(threshold=0.1).fit(df_train.drop(columns='target'))\nvt.get_support()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier, plot_importance\nfrom sklearn.metrics import classification_report as cr, confusion_matrix as cm\nfrom sklearn.metrics import log_loss\nfrom sklearn.utils import compute_sample_weight\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df_train.drop(columns='target')\nle = preprocessing.LabelEncoder().fit(df_train.target)\ny = le.transform(df_train.target)\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, stratify=y, shuffle=True, random_state=0)\n\n# sample_weight = compute_sample_weight('balanced', y_train)\nmodel = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=0).fit(x_train, y_train) #, sample_weight=sample_weight)\n\nprint(\"Train:\")\ny_pred = model.predict_proba(x_train)\nprint(cm(y_true=y_train, y_pred=y_pred.argmax(axis=1)))\nprint(cr(y_true=y_train, y_pred=y_pred.argmax(axis=1)))\nprint(log_loss(y_pred=y_pred, y_true=y_train, labels=np.unique(y_train)))\n\nprint(\"Val:\")\ny_pred = model.predict_proba(x_val)\nprint(cm(y_true=y_val, y_pred=y_pred.argmax(axis=1)))\nprint(cr(y_true=y_val, y_pred=y_pred.argmax(axis=1)))\nprint(log_loss(y_pred=y_pred, y_true=y_val, labels=np.unique(y_val)))\n\n_, ax = plt.subplots(1, 1, figsize=(18, 18))\nplot_importance(model, ax=ax)\nplt.title('Feature Importance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nthresholds = np.sort(model.feature_importances_)\nfor thresh in tqdm.tqdm(thresholds[[5, 10, 15, 20, 25, 30, 35, 40, 49]):\n    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n    sel_x_train = selection.transform(x_train)\n    xgb = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=0).fit(sel_x_train, y_train)\n    xgb.fit(sel_x_train, y_train)\n    \n    sel_x_val = selection.transform(x_val)\n    y_pred = xgb.predict_proba(sel_x_val)\n    ll = log_loss(y_pred=y_pred, y_true=y_val, labels=np.unique(y_val))\n    print(f\"Thresh={thresh}, n={sel_x_train.shape}, Log-Loss: {ll}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 100\na_min = np.linspace(0.0, 0.5, num=N)\na_max = np.linspace(0.5, 1.0, num=N)\n\nz = np.array([[log_loss(y_pred=np.clip(y_pred, a_min=i, a_max=j), y_true=y_val, labels=np.unique(y_val)) for i in a_min] for j in a_max])\n\nprint(z.min())\ni, j = np.unravel_index(z.argmin(), z.shape)\na_min, a_max = a_min[i], a_max[j]\nprint(a_min, a_max)\n\n# The a_max cutoff is pretty low here.\na_max = 0.9","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train on all the data\nmodel = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=0).fit(x, y) #, sample_weight=sample_weight)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/test.csv\")\ny_pred = model.predict_proba(df_test.drop(columns='id'))\n# y_pred = np.clip(y_pred, a_min, a_max)\n\nsubmission = pd.DataFrame(y_pred, columns=le.classes_)\nsubmission = submission[['Class_1','Class_2','Class_3','Class_4']]\n\n\nsubmission['id'] = df_test['id']\nsubmission.to_csv('./submission.csv', index=False)\nassert len(submission) == 50000","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}