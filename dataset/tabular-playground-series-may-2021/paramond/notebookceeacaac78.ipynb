{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Voting + Stacking ensemble","metadata":{}},{"cell_type":"markdown","source":"## 1. read datasets.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport tensorflow as tf\nimport random\nimport os\n\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nSEED=42\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n    \ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:04.455678Z","iopub.execute_input":"2021-05-26T04:11:04.45616Z","iopub.status.idle":"2021-05-26T04:11:04.903131Z","shell.execute_reply.started":"2021-05-26T04:11:04.456122Z","shell.execute_reply":"2021-05-26T04:11:04.902042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. preprocessing datasets.","metadata":{}},{"cell_type":"markdown","source":"### 2.1. convert 'target' value to 0,1,2,3. ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nlabel_map = {\n    'Class_1' : 0,\n    'Class_2' : 1,\n    'Class_3' : 2,\n    'Class_4' : 3,\n}\ntrain['target'] = train['target'].map(label_map)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:04.905198Z","iopub.execute_input":"2021-05-26T04:11:04.905539Z","iopub.status.idle":"2021-05-26T04:11:04.923738Z","shell.execute_reply.started":"2021-05-26T04:11:04.90551Z","shell.execute_reply":"2021-05-26T04:11:04.922796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2. clip datasets.","metadata":{}},{"cell_type":"code","source":"features = ['feature_{}'.format(x) for x in range(50)]\nqt = train[features].quantile(np.arange(0,1,0.002))\n\ndef clip(df):\n    df = df.copy()\n    for feature in features:\n        df[feature] = df[feature].clip(lower=0, upper=qt.loc[0.998][feature])\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:04.925203Z","iopub.execute_input":"2021-05-26T04:11:04.925512Z","iopub.status.idle":"2021-05-26T04:11:05.141965Z","shell.execute_reply.started":"2021-05-26T04:11:04.925485Z","shell.execute_reply":"2021-05-26T04:11:05.141041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3. prepare feature's value based on the probability of target's rate. ","metadata":{}},{"cell_type":"code","source":"values=[]\nlabels=[0,1,2,3,]\nfor feature in features:\n    grouped = clip(train).groupby(feature)\n    for value, group in grouped:\n        value=[feature, value]\n        for label in labels:\n            p =  (group['target'] == label).mean()\n            p = np.clip(p, 1e-06, 1 - 1e-06)\n            value.append(np.log(p+0.5))\n            value.append(np.log(p/(1-p)))\n        values.append(value)\ndf_proba = pd.DataFrame(values,\n                        columns=['feature', 'value',\n                                 'Class_1_proba1',\n                                 'Class_1_proba2',\n                                 'Class_2_proba1',\n                                 'Class_2_proba2',\n                                 'Class_3_proba1',\n                                 'Class_3_proba2',\n                                 'Class_4_proba1',\n                                 'Class_4_proba2',\n                                ])\nproba_dict_1={}\nproba_dict_2={}\n\nfor i in range(len(df_proba)):\n    feature = df_proba.iloc[i]['feature']\n    value = df_proba.iloc[i]['value']\n    proba_dict_1[feature, value] = df_proba.iloc[i][['Class_1_proba1','Class_2_proba1','Class_3_proba1','Class_4_proba1',]].values.astype(float)\n    proba_dict_2[feature, value] = df_proba.iloc[i][['Class_1_proba2','Class_2_proba2','Class_3_proba2','Class_4_proba2',]].values.astype(float)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:05.143125Z","iopub.execute_input":"2021-05-26T04:11:05.143404Z","iopub.status.idle":"2021-05-26T04:11:37.702026Z","shell.execute_reply.started":"2021-05-26T04:11:05.143378Z","shell.execute_reply":"2021-05-26T04:11:37.700901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. define my transformer","metadata":{}},{"cell_type":"code","source":"from sklearn.base import TransformerMixin\n\ndef reshape(df):\n    values=[]\n    for value in df.values:\n        values.append([_ for _ in value])\n    return np.array(values)\n\nclass MyTransformer1(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=qt.loc[0.002][feature], upper=qt.loc[0.998][feature])\n            newX[feature] = 1 / (newX[feature] - newX[feature].min() + 1)\n        return newX\n\nclass MyTransformer2(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        X = clip(X)\n        for feature in features:\n            newX[feature] = X[feature].apply(lambda x:proba_dict_1[feature, x])\n        return reshape(newX).reshape((-1,200))\n\nclass MyTransformer3(MyTransformer2):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        X = clip(X)\n        for feature in features:\n            newX[feature] = X[feature].apply(lambda x:proba_dict_1[feature, x])\n        return reshape(newX)\n\ndef normalize(df, columns):\n    \"\"\"\n    sklearn.preprocessing.MinMaxScaler\n    \"\"\"\n\n    for column in columns:\n        min_val, max_val = df[column].agg([min,max])\n        df[column] = (df[column] - min_val) / (max_val - min_val)\n    return df\n\nclass MyTransformer4(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=0).apply(lambda x:1/(x+1))\n        return normalize(newX, features)\n\nclass MyTransformer5(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=qt.loc[0.002][feature], upper=qt.loc[0.998][feature])\n        return newX\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:37.704058Z","iopub.execute_input":"2021-05-26T04:11:37.70437Z","iopub.status.idle":"2021-05-26T04:11:37.722576Z","shell.execute_reply.started":"2021-05-26T04:11:37.704339Z","shell.execute_reply":"2021-05-26T04:11:37.721813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. define my classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.base import ClassifierMixin\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\nmy_model1 = CatBoostClassifier(\n    iterations=887,\n    min_child_samples=200,\n    random_state=SEED,\n    max_depth=6,\n    verbose=0)\n\nmy_model2 = CatBoostClassifier(\n    iterations=160,\n    min_child_samples=200,\n    max_depth=2,\n    eval_metric='MultiClass',\n    random_state=SEED,\n    verbose=0)\n\ninitial_learning_rate = 0.001\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.96,\n    staircase=True)\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=lr_schedule, \n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name='Adam'\n)\nclass TensorflowClassifier(ClassifierMixin):\n    def __init__(self):\n        self.histories=[]\n        self.classes_ = [0,1,2,3]\n        self.model = tf.keras.Sequential([\n            tf.keras.layers.Flatten(input_shape=(50,4)),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(4, activation='softmax')\n        ])\n        self.model.compile(\n            optimizer=optimizer, \n            loss='sparse_categorical_crossentropy',\n            metrics=['sparse_categorical_crossentropy',])\n    def get_params(self,deep):\n        return {}\n    def fit(self, X, y):\n        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n        history = self.model.fit(X, y, epochs=300, batch_size = 200, validation_split=0.1, callbacks=[callback],verbose=0)\n        self.histories.append(history)\n        return self\n    def predict_proba(self, X):\n        return self.model.predict(X).reshape((-1, 4))\n\nmy_model3 = TensorflowClassifier()\n\nmy_model4 = LGBMClassifier(\n    random_state=SEED,\n    min_child_samples=150,\n    n_estimators=74,\n)\n\nmy_model5 = RandomForestClassifier(\n    random_state=SEED,\n    min_samples_leaf=200,\n    n_estimators=200,\n)\n\npipeline1 = make_pipeline(MyTransformer1(),my_model1)\npipeline2 = make_pipeline(MyTransformer2(),my_model2)\npipeline3 = make_pipeline(MyTransformer3(),my_model3)\npipeline4 = make_pipeline(MyTransformer4(),my_model4)\npipeline5 = make_pipeline(MyTransformer5(),my_model5)\n\nmy_final_estimator = LogisticRegression(\n    random_state=SEED,\n    max_iter=2000,\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:37.723717Z","iopub.execute_input":"2021-05-26T04:11:37.724123Z","iopub.status.idle":"2021-05-26T04:11:37.787429Z","shell.execute_reply.started":"2021-05-26T04:11:37.724094Z","shell.execute_reply":"2021-05-26T04:11:37.786497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. train VotingClassifier, StackingClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier,StackingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss,accuracy_score\n\nvoting_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n]\nstacking_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n    ('mod5', pipeline5),\n]\n\nX = train[features]\ny = train['target']\n\nmod_vot = VotingClassifier(\n    estimators=voting_estimators,\n    voting = 'soft',\n).fit(X, y)\n\nmod_stk = StackingClassifier(\n    estimators=stacking_estimators,\n    final_estimator=my_final_estimator,\n    stack_method='predict_proba',\n    cv=4,\n).fit(X, y)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:11:37.78855Z","iopub.execute_input":"2021-05-26T04:11:37.788998Z","iopub.status.idle":"2021-05-26T04:29:15.369601Z","shell.execute_reply.started":"2021-05-26T04:11:37.788958Z","shell.execute_reply":"2021-05-26T04:29:15.368234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. create my submission file","metadata":{}},{"cell_type":"code","source":"y_pred_vot  = mod_vot.predict_proba(test[features])\ny_pred_stk  = mod_stk.predict_proba(test[features])\n\ny_pred_test = (y_pred_vot + y_pred_stk) / 2\n\nsubmission = test[['id']].copy()\nsubmission['Class_1'] = y_pred_test[:,0]\nsubmission['Class_2'] = y_pred_test[:,1]\nsubmission['Class_3'] = y_pred_test[:,2]\nsubmission['Class_4'] = y_pred_test[:,3]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:29:15.371433Z","iopub.execute_input":"2021-05-26T04:29:15.372239Z","iopub.status.idle":"2021-05-26T04:29:49.288798Z","shell.execute_reply.started":"2021-05-26T04:29:15.372187Z","shell.execute_reply":"2021-05-26T04:29:49.287997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}