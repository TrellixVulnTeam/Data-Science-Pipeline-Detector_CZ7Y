{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# StackingClassifier,VotingClassifier ensemble example","metadata":{"papermill":{"duration":0.021139,"end_time":"2021-05-26T22:40:45.709813","exception":false,"start_time":"2021-05-26T22:40:45.688674","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1. read datasets.","metadata":{"papermill":{"duration":0.02134,"end_time":"2021-05-26T22:40:45.749961","exception":false,"start_time":"2021-05-26T22:40:45.728621","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport tensorflow as tf\nimport random\nimport os\n\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nSEED=42\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv')\n","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:40:45.787955Z","iopub.status.busy":"2021-05-26T22:40:45.78659Z","iopub.status.idle":"2021-05-26T22:40:53.518664Z","shell.execute_reply":"2021-05-26T22:40:53.517719Z","shell.execute_reply.started":"2021-05-26T16:19:41.697555Z"},"papermill":{"duration":7.751808,"end_time":"2021-05-26T22:40:53.518836","exception":false,"start_time":"2021-05-26T22:40:45.767028","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. preprocessing datasets.","metadata":{"papermill":{"duration":0.014929,"end_time":"2021-05-26T22:40:53.549159","exception":false,"start_time":"2021-05-26T22:40:53.53423","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 2.1. convert 'target' value to 0,1,2,3. ","metadata":{"papermill":{"duration":0.014966,"end_time":"2021-05-26T22:40:53.579309","exception":false,"start_time":"2021-05-26T22:40:53.564343","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nlabel_map = {\n    'Class_1' : 0,\n    'Class_2' : 1,\n    'Class_3' : 2,\n    'Class_4' : 3,\n}\ntrain['target'] = train['target'].map(label_map)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:40:53.615734Z","iopub.status.busy":"2021-05-26T22:40:53.614944Z","iopub.status.idle":"2021-05-26T22:40:53.78302Z","shell.execute_reply":"2021-05-26T22:40:53.782453Z","shell.execute_reply.started":"2021-05-26T16:19:42.102072Z"},"papermill":{"duration":0.18874,"end_time":"2021-05-26T22:40:53.783184","exception":false,"start_time":"2021-05-26T22:40:53.594444","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2. clip datasets.","metadata":{"papermill":{"duration":0.015086,"end_time":"2021-05-26T22:40:53.814537","exception":false,"start_time":"2021-05-26T22:40:53.799451","status":"completed"},"tags":[]}},{"cell_type":"code","source":"features = ['feature_{}'.format(x) for x in range(50)]\nqt = train[features].quantile(np.arange(0,1,0.002))\n\ndef clip(df):\n    df = df.copy()\n    for feature in features:\n        df[feature] = df[feature].clip(lower=0, upper=qt.loc[0.998][feature])\n    return df\n","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:40:53.852974Z","iopub.status.busy":"2021-05-26T22:40:53.852294Z","iopub.status.idle":"2021-05-26T22:40:54.064335Z","shell.execute_reply":"2021-05-26T22:40:54.063666Z","shell.execute_reply.started":"2021-05-26T16:19:42.119676Z"},"papermill":{"duration":0.234255,"end_time":"2021-05-26T22:40:54.064505","exception":false,"start_time":"2021-05-26T22:40:53.83025","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3. prepare feature's value based on probability of target's rate. ","metadata":{"papermill":{"duration":0.014888,"end_time":"2021-05-26T22:40:54.095397","exception":false,"start_time":"2021-05-26T22:40:54.080509","status":"completed"},"tags":[]}},{"cell_type":"code","source":"values=[]\nlabels=[0,1,2,3,]\nfor feature in features:\n    grouped = clip(train).groupby(feature)\n    for value, group in grouped:\n        value=[feature, value]\n        for label in labels:\n            p =  (group['target'] == label).mean()\n            p = np.clip(p, 1e-06, 1 - 1e-06)\n            value.append(np.log(p+0.5))\n            value.append(np.log(p/(1-p)))\n        values.append(value)\ndf_proba = pd.DataFrame(values,\n                        columns=['feature', 'value',\n                                 'Class_1_proba1',\n                                 'Class_1_proba2',\n                                 'Class_2_proba1',\n                                 'Class_2_proba2',\n                                 'Class_3_proba1',\n                                 'Class_3_proba2',\n                                 'Class_4_proba1',\n                                 'Class_4_proba2',\n                                ])\nproba_dict_1={}\nproba_dict_2={}\n\nfor i in range(len(df_proba)):\n    feature = df_proba.iloc[i]['feature']\n    value = df_proba.iloc[i]['value']\n    proba_dict_1[feature, value] = df_proba.iloc[i][['Class_1_proba1','Class_2_proba1','Class_3_proba1','Class_4_proba1',]].values.astype(float)\n    proba_dict_2[feature, value] = df_proba.iloc[i][['Class_1_proba2','Class_2_proba2','Class_3_proba2','Class_4_proba2',]].values.astype(float)\n    ","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:40:54.139829Z","iopub.status.busy":"2021-05-26T22:40:54.138285Z","iopub.status.idle":"2021-05-26T22:41:28.182228Z","shell.execute_reply":"2021-05-26T22:41:28.182763Z","shell.execute_reply.started":"2021-05-26T16:19:42.323534Z"},"papermill":{"duration":34.071273,"end_time":"2021-05-26T22:41:28.182991","exception":false,"start_time":"2021-05-26T22:40:54.111718","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. define my transformer","metadata":{"papermill":{"duration":0.014822,"end_time":"2021-05-26T22:41:28.213433","exception":false,"start_time":"2021-05-26T22:41:28.198611","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.base import TransformerMixin\n\ndef reshape(df):\n    values=[]\n    for value in df.values:\n        values.append([_ for _ in value])\n    return np.array(values)\n\nclass MyTransformer1(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=qt.loc[0.002][feature], upper=qt.loc[0.998][feature])\n            newX[feature] = 1 / (newX[feature] - newX[feature].min() + 1)\n        return newX\n\nclass MyTransformer2(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        X = clip(X)\n        for feature in features:\n            newX[feature] = X[feature].apply(lambda x:proba_dict_1[feature, x])\n        return reshape(newX).reshape((-1,200))\n\nclass MyTransformer3(MyTransformer2):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        X = clip(X)\n        for feature in features:\n            newX[feature] = X[feature].apply(lambda x:proba_dict_1[feature, x])\n        return reshape(newX)\n\ndef normalize(df, columns):\n    \"\"\"\n    sklearn.preprocessing.MinMaxScaler\n    \"\"\"\n    for column in columns:\n        min_val, max_val = df[column].agg([min,max])\n        df[column] = (df[column] - min_val) / (max_val - min_val)\n    return df\n\nclass MyTransformer4(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=0).apply(lambda x:1/(x+1))\n        return normalize(newX, features)\n\nclass MyTransformer5(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for feature in features:\n            newX[feature] = X[feature].clip(lower=qt.loc[0.002][feature], upper=qt.loc[0.998][feature])\n        return newX\n","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:41:28.264134Z","iopub.status.busy":"2021-05-26T22:41:28.263369Z","iopub.status.idle":"2021-05-26T22:41:28.266723Z","shell.execute_reply":"2021-05-26T22:41:28.266161Z","shell.execute_reply.started":"2021-05-26T16:20:04.245099Z"},"papermill":{"duration":0.038201,"end_time":"2021-05-26T22:41:28.266896","exception":false,"start_time":"2021-05-26T22:41:28.228695","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. define my classifier","metadata":{"papermill":{"duration":0.014707,"end_time":"2021-05-26T22:41:28.29684","exception":false,"start_time":"2021-05-26T22:41:28.282133","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.base import ClassifierMixin\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n!pip install --upgrade lightautoml\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\n\nfrom sklearn.pipeline import make_pipeline\nmy_model1 = CatBoostClassifier(\n    iterations=887,\n    min_child_samples=200,\n    random_state=SEED,\n    max_depth=6,\n    verbose=0)\n\nmy_model2 = CatBoostClassifier(\n    iterations=160,\n    min_child_samples=200,\n    max_depth=2,\n    eval_metric='MultiClass',\n    random_state=SEED,\n    verbose=0)\n\ninitial_learning_rate = 0.001\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.96,\n    staircase=True)\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=lr_schedule, \n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name='Adam'\n)\nclass TensorflowClassifier(ClassifierMixin):\n    def __init__(self):\n        self.histories=[]\n        self.classes_ = [0,1,2,3]\n        self.model = tf.keras.Sequential([\n            tf.keras.layers.Flatten(input_shape=(50,4)),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(4, activation='softmax')\n        ])\n        self.model.compile(\n            optimizer=optimizer, \n            loss='sparse_categorical_crossentropy',\n            metrics=['sparse_categorical_crossentropy',])\n    def get_params(self,deep):\n        return {}\n    def fit(self, X, y):\n        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n        history = self.model.fit(X, y, epochs=300, batch_size = 200, validation_split=0.1, callbacks=[callback],verbose=0)\n        self.histories.append(history)\n        return self\n    def predict_proba(self, X):\n        return self.model.predict(X).reshape((-1, 4))\n\nmy_model3 = TensorflowClassifier()\n\nmy_model4 = LGBMClassifier(\n    random_state=SEED,\n    min_child_samples=150,\n    n_estimators=74,\n)\n\nmy_model5 = GradientBoostingClassifier(\n    random_state=SEED,\n    min_samples_leaf=200,\n    n_estimators=200,\n)\n\nclass AutoMLClassifier(ClassifierMixin):\n    def __init__(self):\n        task = Task('multiclass', metric = 'crossentropy', )\n        self.model  = TabularAutoML(\n            task = task,\n            timeout = 300,\n            general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n            reader_params = {'cv': 5, 'random_state': SEED},\n            tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n            lgb_params = {'default_params': {'num_threads': 8}}, verbose=0)\n        self.classes_ = [0,1,2,3]\n        self.train_prediction = None\n    def get_params(self,deep):\n        return {}\n    def dataframe(self, X):\n        if not isinstance(X, type(pd.DataFrame())):\n            X = pd.DataFrame(X, columns=['column_{}'.format(x) for x in range(X.shape[1])])\n        return X\n    def fit(self, X, y):\n        df = self.dataframe(X.copy())\n        df['target'] = y\n        self.train_prediction = self.model.fit_predict(df, roles = {'target':'target'}).data\n        return self\n    def predict_proba(self, X):\n        X = self.dataframe(X)\n        return self.model.predict(X).data\n\npipeline1 = make_pipeline(MyTransformer1(),my_model1)\npipeline2 = make_pipeline(MyTransformer2(),my_model2)\npipeline3 = make_pipeline(MyTransformer3(),my_model3)\npipeline4 = make_pipeline(MyTransformer4(),my_model4)\npipeline5 = make_pipeline(MyTransformer5(),my_model5)\n","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:41:28.364832Z","iopub.status.busy":"2021-05-26T22:41:28.33576Z","iopub.status.idle":"2021-05-26T22:41:54.310369Z","shell.execute_reply":"2021-05-26T22:41:54.310891Z","shell.execute_reply.started":"2021-05-26T16:20:04.262467Z"},"papermill":{"duration":25.999153,"end_time":"2021-05-26T22:41:54.31109","exception":false,"start_time":"2021-05-26T22:41:28.311937","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1 define my final estimator for StackingClassifier","metadata":{"papermill":{"duration":0.039277,"end_time":"2021-05-26T22:41:54.39082","exception":false,"start_time":"2021-05-26T22:41:54.351543","status":"completed"},"tags":[]}},{"cell_type":"code","source":"my_final_estimator = AutoMLClassifier()\n","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:41:54.493097Z","iopub.status.busy":"2021-05-26T22:41:54.487797Z","iopub.status.idle":"2021-05-26T22:41:54.507205Z","shell.execute_reply":"2021-05-26T22:41:54.506511Z","shell.execute_reply.started":"2021-05-26T16:20:10.47457Z"},"papermill":{"duration":0.07716,"end_time":"2021-05-26T22:41:54.507351","exception":false,"start_time":"2021-05-26T22:41:54.430191","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. train StackingClassifier, VotingClassifier","metadata":{"papermill":{"duration":0.038921,"end_time":"2021-05-26T22:41:54.585811","exception":false,"start_time":"2021-05-26T22:41:54.54689","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier,StackingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss,accuracy_score\n\nvoting_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n]\nstacking_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n    ('mod5', pipeline5),\n]\n\nX = train[features]\ny = train['target']\n\nmod_vot = VotingClassifier(\n    estimators=voting_estimators,\n    voting = 'soft',\n).fit(X, y)\n\nmod_stk = StackingClassifier(\n    estimators=stacking_estimators,\n    final_estimator=my_final_estimator,\n    stack_method='predict_proba',\n    cv=4,\n).fit(X, y)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T22:41:54.690169Z","iopub.status.busy":"2021-05-26T22:41:54.689067Z","iopub.status.idle":"2021-05-27T00:59:24.178644Z","shell.execute_reply":"2021-05-27T00:59:24.179754Z","shell.execute_reply.started":"2021-05-26T16:20:10.504225Z"},"papermill":{"duration":8249.555339,"end_time":"2021-05-27T00:59:24.180472","exception":false,"start_time":"2021-05-26T22:41:54.625133","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. create my submission file","metadata":{"papermill":{"duration":0.041352,"end_time":"2021-05-27T00:59:24.264311","exception":false,"start_time":"2021-05-27T00:59:24.222959","status":"completed"},"tags":[]}},{"cell_type":"code","source":"y_pred_test  = (mod_vot.predict_proba(test[features]) + mod_stk.predict_proba(test[features])) / 2\nsubmission = test[['id']].copy()\nsubmission['Class_1'] = y_pred_test[:,0]\nsubmission['Class_2'] = y_pred_test[:,1]\nsubmission['Class_3'] = y_pred_test[:,2]\nsubmission['Class_4'] = y_pred_test[:,3]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2021-05-27T00:59:24.355525Z","iopub.status.busy":"2021-05-27T00:59:24.354757Z","iopub.status.idle":"2021-05-27T01:45:53.278391Z","shell.execute_reply":"2021-05-27T01:45:53.277451Z","shell.execute_reply.started":"2021-05-26T18:13:48.529766Z"},"papermill":{"duration":2788.973509,"end_time":"2021-05-27T01:45:53.278773","exception":false,"start_time":"2021-05-27T00:59:24.305264","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.04103,"end_time":"2021-05-27T01:47:36.458936","exception":false,"start_time":"2021-05-27T01:47:36.417906","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}