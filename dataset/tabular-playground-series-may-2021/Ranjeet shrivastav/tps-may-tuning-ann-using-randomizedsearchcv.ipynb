{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(r'../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv(r'../input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Drop **id** feature from both **train** & **test** datasets","metadata":{}},{"cell_type":"code","source":"train.drop('id',axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* reference :[https://www.kaggle.com/subinium/tps-may-categorical-eda](https://www.kaggle.com/subinium/tps-may-categorical-eda)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.countplot(x='target', data=train, order=sorted(train['target'].unique()))\nplt.ylim(0, 63000)\nplt.title('Target Distribution', weight='bold')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,7))\n\n# x = [f'feature_{i}' for i in range(50)]\ny = sorted([len(train[f'feature_{i}'].unique()) for i in range(50)])\n\nplt.bar(range(50), y, zorder=10)\nplt.xticks([])\nplt.yticks(range(0, 80, 5))\nplt.margins(0.02)\n\nplt.title('# of Features Unique Values', loc='left', fontweight='bold')\nplt.grid(axis='y', linestyle='--', zorder=5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(13, 4, figsize=(20, 30))\n\ntarget_order = sorted(train['target'].unique())\nfor idx, ax in zip(range(50), axes.flatten()):\n    cnt = train[f'feature_{idx}'].value_counts().sort_index()\n    sns.kdeplot(x=f'feature_{idx}', \n                hue='target', hue_order=target_order,\n                data=train,\n                alpha=0.3, \n                linewidth=0.6, fill=True,\n                legend=False,\n                ax=ax)\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    cnt = len(train[f'feature_{idx}'].unique())\n    ax.set_title(f'Feature_{idx}({cnt})', loc='right', weight='bold')\n\naxes.flatten()[-1].axis('off')    \naxes.flatten()[-2].axis('off')\n\nfig.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model building","metadata":{}},{"cell_type":"code","source":"X = train.drop('target',axis=1)\ny = train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\nencoded_Y = encoder.transform(y)\n# convert integers to dummy variables (i.e. one hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, dummy_y, stratify=dummy_y,test_size=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\ntest = sc.fit_transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I define a function build_classifier to use the wrappers KerasClassifier. build_classifier creates and returns the Keras sequential model.\nI am passing three arguments to the function:\n* optimizer is the optimization technique we want to use for our neural network\n* Kernel which is to set the kernel_initializer\n* units is the no. of hidden nodes in the hidden layer","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_classifier(optimizer,kernel, units):\n    classifier = Sequential()\n    #First Hidden Layer\n    classifier.add(Dense(units=units, activation='relu', kernel_initializer=kernel, input_dim=X_train.shape[1]))\n    classifier.add(Dropout(rate=0.3))\n    #Second  Hidden Layer\n    classifier.add(Dense(units=units, activation='relu', kernel_initializer=kernel))\n    classifier.add(Dropout(0.2))\n    # Adding the third hidden layer\n    classifier.add(Dense(units = units, kernel_initializer=kernel,activation='relu'))\n    classifier.add(Dropout(0.2))\n    #Output Layer\n    classifier.add(Dense(4, activation='softmax', kernel_initializer=kernel))\n    #Compiling the neural network\n    classifier.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics =['accuracy'])\n    return classifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"passing build_classifier function to the build_fn argument when constructing the **KerasClassifier** class.","metadata":{}},{"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nclassifier = KerasClassifier(build_fn=build_classifier)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am tuning the neural network using the **RandomizedSearchCV**. The hyperparameters we want to tune are:\n* batch_size\n* epochs\n* optimizer — this will pass an argument while building the neural network to function build_classifier\n* kernel_initializer — this will pass an argument while building the neural network to function build_classifier\n* units — this will pass as an argument while building the neural network to function build_classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nparameters ={'batch_size':(32,64,128),\n            'epochs':(10,20,25),\n            'optimizer':('adam','SGD'),\n            'kernel':('he_uniform','glorot_uniform'),\n            'units':[(20), (40, 20), (45, 30, 15)]}\nrandom_search= RandomizedSearchCV(estimator=classifier, param_distributions=parameters,cv=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_result = random_search.fit(X_train, y_train)","metadata":{"scrolled":true,"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Random Best score',random_result.best_score_)\nprint('Random Best params',random_result.best_params_)\nprint('Random execution time',random_result.refit_time_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = random_search.predict_proba(test)\nsample_submission.to_csv(f'submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"model = Sequential()\n# Adding the input layer and the first hidden layer\nmodel.add(Dense(units = 20, kernel_initializer='he_uniform', activation='relu', input_dim=X_train.shape[1]))\n#model.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n# Adding the second hidden layer\nmodel.add(Dense(units = 20, kernel_initializer='he_uniform',activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n# Adding the third hidden layer\nmodel.add(Dense(units = 20, kernel_initializer='he_uniform',activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n# Adding the output layer\nmodel.add(Dense(units=4,activation='softmax'))\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20,batch_size=128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# plot the loss\nplt.plot(model_history.history['loss'], label='train loss')\nplt.plot(model_history.history['val_loss'], label='val loss')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend()\nplt.show()\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# plot the accuracy\nplt.plot(model_history.history['accuracy'], label='train acc')\nplt.plot(model_history.history['val_accuracy'], label='val acc')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend()\nplt.show()\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}