{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import GridSearchCV\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport json\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_path =\"/kaggle/input/tabular-playground-series-may-2021/\"\ntrain = pd.read_csv(os.path.join(root_path, 'train.csv'))\ntest = pd.read_csv(os.path.join(root_path, 'test.csv'))\nsample_submission = pd.read_csv(os.path.join(root_path, 'sample_submission.csv'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.head()\nunique_targets = train['target'].unique().tolist()\nlabel_mapping = dict(zip(unique_targets, [int(i[-1]) - 1 for i in unique_targets]))\n# label_mapping\ntrain['target'] = train['target'].map(label_mapping)\n# train.head(5).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train['target'][:95000]\nx_train = train.drop(['id', 'target'], axis=1)[:95000]\nx_val = x_train[-5000:]\ny_val = y_train[-5000:]\ntest = test.drop(['id'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)\nprint(test.shape)\nprint(np.unique(y_train))\nprint(sample_submission.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=2)),\n                     ('lr_classifier',LogisticRegression(random_state=0))])\npipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n                     ('pca3',PCA(n_components=2)),\n                     ('rf_classifier',RandomForestClassifier())])\npipeline_lightgbm  = Pipeline([('scalar3',StandardScaler()),\n                              ('lgbm_classifier',LGBMClassifier(n_jobs=-1))])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipelines = [pipeline_lr,  pipeline_randomforest,pipeline_lightgbm]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for pipe in pipelines:\n    pipe.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_dict = {0: 'Logistic Regression', 1: 'RandomForest',2:'lightGBM'}\n\nfor  i,model in enumerate(pipelines):\n    print(pipe_dict[i],model.score(x_val,y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_output = pipelines[0].predict_proba(test)\nx_train_new = pd.concat([x_train,x_val],axis=0,ignore_index= True)\ny_train_new = pd.concat([y_train,y_val],axis=0,ignore_index= True)\n#([train, test], axis = 0, ignore_index = True\nprint(x_train_new.shape,y_train_new.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train on all data\n# final_model  = pipelines[2].fit(x_train_new,y_train_new)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Running Gridsearch on the chosen model**","metadata":{}},{"cell_type":"code","source":"# grid-search params on final_model\nparams = {'boosting_type': 'gbdt',\n          'max_depth' : -1,\n          'objective': 'binary',\n          'device_type':'cuda',\n          'nthread': 3, # Updated from nthread\n          'num_leaves': 64,\n          'learning_rate': 0.05,\n          'max_bin': 512,\n          'subsample_for_bin': 200,\n          'subsample': 1,\n          'subsample_freq': 1,\n          'colsample_bytree': 0.8,\n          'reg_alpha': 5,\n          'reg_lambda': 10,\n          'min_split_gain': 0.5,\n          'min_child_weight': 1,\n          'min_child_samples': 5,\n          'scale_pos_weight': 1,\n          'num_class' : 1,\n          'metric' : 'binary_error',\n         }\n\n# Create parameters to search\ngridParams = {\n    'learning_rate': [0.005],\n    'n_estimators': [40],\n    'num_leaves': [6,8,12,16],\n    'boosting_type' : ['gbdt'],\n    'objective' : ['binary'],\n    'random_state' : [501], # Updated from 'seed'\n    'colsample_bytree' : [0.65, 0.66],\n    'subsample' : [0.7,0.75],\n    'reg_alpha' : [1,1.2],\n    'reg_lambda' : [1,1.2,1.4],\n    }\n# gridParams = {\n#     'n_estimators': [40],\n#     'boosting_type' : ['gbdt'],\n#     'objective' : ['binary'],\n#     'random_state' : [501], # Updated from 'seed'\n\n#     }\n\nmdl = LGBMClassifier(boosting_type= 'gbdt',\n          objective = 'binary',\n          n_jobs = 3, # Updated from 'nthread'\n          silent = True,\n                     device_type='cuda',\n          max_depth = params['max_depth'],\n          max_bin = params['max_bin'],\n          subsample_for_bin = params['subsample_for_bin'],\n          subsample = params['subsample'],\n          subsample_freq = params['subsample_freq'],\n          min_split_gain = params['min_split_gain'],\n          min_child_weight = params['min_child_weight'],\n          min_child_samples = params['min_child_samples'],\n          scale_pos_weight = params['scale_pos_weight'])\n\n# create a gridsearch of the pipeline, the fit the best model\ngridsearch = GridSearchCV(mdl, gridParams, cv=5, verbose=0,n_jobs=-1) # Fit grid search","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gridsearch.fit(x_train_new, y_train_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_output = gridsearch.best_estimator_.predict_proba(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_output = final_model.predict_proba(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df = pd.DataFrame(test_output, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])\npredictions_df['id'] = sample_submission['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.to_csv(\"submission3.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install kaggle\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"api_token= {\"username\":\"lol\",\"key\":\"lol\"}\nwith open('/root/.kaggle/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! kaggle competitions submit -c tabular-playground-series-may-2021 -f submission3.csv -m \"Gridsearch new\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}