{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv')\nsample_sub = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring a bit of a new thing : \n\n### Coloring a dataframe based on Frequencies","metadata":{}},{"cell_type":"code","source":"train.head().style.background_gradient(cmap = \"Blues\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head().style.background_gradient(cmap = \"Spectral\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoding the 'target' column","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing \n\nle = preprocessing.LabelEncoder()\n\ntrain['target'] = le.fit_transform(train['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model-based and Sequential Feature Selection","metadata":{}},{"cell_type":"markdown","source":"# Importance of Features","metadata":{}},{"cell_type":"markdown","source":"### Selecting features based on Feature Importance from Co-efficients\n\n### LASSOCV","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LassoCV\n\nX = train.drop(['target', 'id'], axis = 1)\ny = train['target']\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 12))\n\nlasso = LassoCV().fit(X, y)\nimportance = np.abs(lasso.coef_)\nfeature_names = np.array(X.columns)\nplt.barh(feature_names, importance)\nplt.title(\"Feature Importances via Coefficients [ Lasso CV ]\")\nplt.figure(figsize=(12, 22))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting Features based on Importance","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nfrom time import time\n\nthreshold = np.sort(importance)[-3]\n\ntic = time()\nsfm = SelectFromModel(lasso, threshold = threshold).fit(X, y)\ntoc = time()\nprint(\"Features Selcted by SelectFromModel : \"f\"{feature_names[sfm.get_support()]}\")\nprint(f\"Done in {toc - tic : .3f}s\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names_lassocv = feature_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OBSERVATION : \n\n**'feature_13' 'feature_29' 'feature_36' are useful features as per LassoCV** ","metadata":{}},{"cell_type":"markdown","source":"# Selecting Features with Sequential Feature Selection\n\nGreedy procedure where , at each iteration, we choose the best new feature to add to our selected features based a Cross-Validation Score. \nThe procedure is repeated until we reachthe desired number of selected Features. \n\nWe can also go back in reverse direction **(backward SFS)** i.e. start with all features and greedily chose features to remove one by one. ","metadata":{}},{"cell_type":"markdown","source":"**BTW this has been running Endlessly. \nNot a good option !**","metadata":{}},{"cell_type":"code","source":"# from sklearn.feature_selection import SequentialFeatureSelector\n\n# tic_fwd = time()\n# sfs_forward = SequentialFeatureSelector(lasso, n_features_to_select = 4, direction = 'forward').fit(X, y)\n# toc_fwd = time()\n\n# tic_bwd = time()\n# sfs_backward = SequentialFeatureSelector(lasso, n_features_to_select = 4, direction = 'backward').fit(X, y)\n# toc_bwd = time()\n\n# print(\"Features Selected by Forward Sequential Selection : \"f\"{feature_names[sfs_forward.get_support()]}\")\n# print(f\"Done in {toc_fwd - tic_fwd:.3f}s\")\n\n# print(\"Features Selected by Backward Sequential Selection: \"f\"{feature_names[sfs_backward.get_support()]}\")\n# print(f\"Done in {toc_bwd - tic_bwd: .3f}s\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tree Based Feature Selection\n\nUsed to compute **Impurity-Based Feature Importances** , which in turn can be used to discard irrelevant features","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\nclf = ExtraTreesClassifier(n_estimators = 50)\nclf = clf.fit(X, y)\n\nmodel = SelectFromModel(clf, prefit = True)\nfeature_names_extratreesclf = feature_names[model.get_support()]\n\nprint(\"Features Selcted by Extra Tree Classifier and SelectFromModel : \"f\"{feature_names[model.get_support()]}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names_extratreesclf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Looks like there has been a reduction. 49 features -> 23 features","metadata":{}},{"cell_type":"markdown","source":"### Feature Importance based on Mean Decrease in Impurity and Feature Permutation","metadata":{}},{"cell_type":"markdown","source":"## Feature Selection with respect to the Mean Decrease in Impurity","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)\n\nfeature_names = np.array(X.columns)\n\nforest = RandomForestClassifier(random_state = 0)\nforest.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nstart_time = time.time()\nimportances = forest.feature_importances_\nstd = np.std([\n    tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n\nelapsed_time = time.time() - start_time\n\nprint(f\"Elapsed time to compute the importances:\" f\"{elapsed_time:.3f} seconds\" )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\nforest_importances = pd.Series(importances, index = feature_names)\n\nfig, ax = plt.subplots(figsize = (10, 12))\nforest_importances.plot.barh(std, ax)\nax.set_title(\"Feature importances using MDI (Mean Decrease in Impurity)\")\nax.set_ylabel(\" Mean Decrease in Impurity\")\nfig.tight_layout()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OBSERVATION : Feature Importance is different from what we found with LassoCV**","metadata":{}},{"cell_type":"code","source":"feature_importance_mdi = forest_importances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(feature_importance_mdi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_importances.loc[forest_importances > np.mean(forest_importances)].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Permutation \n\nPermutation Feature importance overcomes limitations of impurity-based-feature importance: they do not have bias toward high-cardinality features can be computed on a left-out test set","metadata":{}},{"cell_type":"markdown","source":"An Interesting Package that I came across. \n**sklearn.inspection is a base version of ExplainableAI concepts**","metadata":{}},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\nstart_time = time.time()\nresult = permutation_importance(\n                               forest, X_test, y_test, n_repeats = 10, random_state = 42)\nelapsed_time = time.time() - start_time\n\nprint(f\"Elapsed time to compute the importances :\" f\"{elapsed_time:.3f} seconds\")\n\nforest_importances = pd.Series(result.importances_mean, index = feature_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10, 12))\nforest_importances.plot.barh(result.importances_std, ax)\nax.set_title(\"Feature Importances using permutation on Full Model\")\nax.set_xlabel(\"Mean Accuracy decrease\")\nfig.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recursive Feature Elimination","metadata":{}},{"cell_type":"markdown","source":"**This also seems to run for quite a lot of time. Not a good option**","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# from sklearn.svm import SVC\n# from sklearn.model_selection import StratifiedKFold\n# from sklearn.feature_selection import RFECV\n\n# svc = SVC(kernel = \"linear\")\n\n# min_features_to_select = 4 # Min number of features to consider\n# rfecv = RFECV(estimator = svc, step = 1, cv = StratifiedKFold(2), scoring = 'accuracy',\n#              min_features_to_select = min_features_to_select)\n\n# rfecv.fit(X_train, y_train)\n\n# print(\"Optimal Number of Features : %d\" % rfecv.n_features_)\n\n# plt.figure()\n# plt.xlabel(\"Number of features selected\")\n# plt.ylabel(\"Cross Validation Score (nb of Correct Classifications)\")\n# plt.plot(range(min_features_to_select, \n#               len(rfecv.grid_scores_) + min_features_to_select),\n#         rfecv.grid_scores_)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Chi Square Test","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import chi2\n\nX1 = X.abs()\nchi_scores = chi2(X1, y)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chi_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**here first array represents chi square values and second array represnts p-values**","metadata":{}},{"cell_type":"code","source":"p_values = pd.Series(chi_scores[1], index = X.columns)\np_values.sort_values(ascending = False, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_values.plot.bar(figsize = (10, 12))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OBSERVATION : \n\n**Feature 6 has the highest p-value, hence it is Independent of the values in the 'target' column.\nIt cannot be considered for Model Training**","metadata":{}},{"cell_type":"markdown","source":"* 'feature_13' 'feature_29' 'feature_36' are useful as per LassoCV\n* Below features are selected by ExtraTreeClassifier : \n\n'feature_3' 'feature_7' 'feature_8' 'feature_9' 'feature_14' 'feature_15'\n 'feature_17' 'feature_18' 'feature_19' 'feature_21' 'feature_23'\n 'feature_24' 'feature_28' 'feature_31' 'feature_34' 'feature_35'\n 'feature_38' 'feature_40' 'feature_41' 'feature_48' 'feature_49' \n \n* Mean Decrease in Impurity : \n\n'feature_3', 'feature_7', 'feature_8', 'feature_9', 'feature_12',\n'feature_14', 'feature_15', 'feature_17', 'feature_18', 'feature_19',\n'feature_21', 'feature_24', 'feature_28', 'feature_31', 'feature_34',\n'feature_35', 'feature_38', 'feature_40', 'feature_41', 'feature_48',\n'feature_49'","metadata":{}},{"cell_type":"markdown","source":"# PIPELINES","metadata":{}},{"cell_type":"code","source":"from functools import wraps\nimport datetime as dt\n\ndef log_step(func):\n    \n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        \n        tic = dt.datetime.now()\n        result = func(*args, **kwargs)\n        time_taken = str(dt.datetime.now() - tic)\n        print(f\"just ran step {func.__name__} shape = {result.shape} took {time_taken}s\")\n        return result\n    return wrapper","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@log_step\ndef start_pipeline(dataf):\n    return dataf.copy() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LABEL ENCODING","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\n@log_step\ndef label_encode(data):\n    le = preprocessing.LabelEncoder()\n\n    for c in data.columns:\n\n        if (data[c].dtype == 'object'):\n            data[c] = le.fit_transform(data[c])\n\n    return data\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATIONS of different features with the \"target\" column in Descending Order","metadata":{}},{"cell_type":"code","source":"@log_step\ndef corelation_target(data, target):\n    \n    \"\"\"\n    Find Co-relation of different features with the \"Target\" column in Descending Order\n    \"\"\"\n    plt.figure(figsize = (8, 12))\n\n    heatmap = sns.heatmap(data.corr()[[target]].drop(index = target, axis = 0).sort_values(by = target, ascending = False),\n                         vmin = -1,\n                         vmax = 1, \n                         annot = True, \n                         cmap = 'BrBG')\n\n    heatmap.set_title(f\"Features Correlating with {target} column\", \n                      fontdict = {'fontsize':18}, pad = 16)\n    \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This information sometimes gets lost in the Heatmap","metadata":{}},{"cell_type":"code","source":"@log_step\ndef corelation_horizontal_target(data, target):\n    \n    \"\"\"\n    Horizontal Bar Plot of the Co-relation of individual features with the Target Column \n    \"\"\"\n    plt.figure(figsize=(10, 12))\n\n    corr = data.corr()[[target]].drop(index = target, axis = 0) # Removes the 1st row i.e. Corelation of target with itself\n    plt.barh(corr.index, corr.reset_index(drop = True).to_numpy().ravel())\n    plt.title(\"Corelation with target\")\n    plt.figure(figsize=(12, 22))\n    plt.show()\n    \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@log_step\ndef zero_percent(data):\n    \n    \"\"\"\n    Horizontal Bar Plot of Percentage of Data containing '0' in each feature\n    \"\"\"\n    \n    raw_light_palette = [\n        (0, 122, 255), # Blue\n        (255, 149, 0), # Orange\n        (52, 199, 89), # Green\n        (255, 59, 48), # Red\n        (175, 82, 222),# Purple\n        (255, 45, 85), # Pink\n        (88, 86, 214), # Indigo\n        (90, 200, 250),# Teal\n        (255, 204, 0)  # Yellow\n    ]\n\n    light_palette = np.array(raw_light_palette) / 255\n\n    zero_data = ((data.iloc[:, :50] == 0 ).sum() / len(data) * 100)[::-1]\n    fig, ax = plt.subplots(1, 1, figsize = (10, 19))\n\n    ax.barh(zero_data.index, 100, color = '#dadada', height = 0.6)\n    barh = ax.barh(zero_data.index, zero_data, color = light_palette[1], height = 0.6)\n    ax.bar_label(barh, fmt = '%.01f %%', color = 'black')\n\n    # Line noting the data area boundaries\n    ax.spines[['left', 'bottom']].set_visible(False)\n\n    # xticks : Set the current label of x-axis\n    ax.set_xticks([])\n\n    ax.set_title('# of Zeros (by feature)', loc = 'center', fontweight = 'bold', fontsize = 15)\n    plt.show()\n    \n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@log_step\ndef bargraph_average_by_class_by_feature(data, target):\n    \n    \"\"\"\n    Bar Graph Plot of Mean of Each value (Class) in a Feature \n    \"\"\"\n    \n    raw_dark_palette = [\n    (10, 132, 255), # Blue\n    (255, 159, 10), # Orange\n    (48, 209, 88),  # Green\n    (255, 69, 58),  # Red\n    (191, 90, 242), # Purple\n    (94, 92, 230),  # Indigo\n    (255, 55, 95),  # Pink\n    (100, 210, 255),# Teal\n    (255, 214, 10)  # Yellow\n    ]\n\n    dark_palette = np.array(raw_dark_palette)/255\n\n    fig, axes = plt.subplots(13, 4, figsize = (10, 16))\n\n    target_order = sorted(data[target].unique())\n    mean = data.groupby(target).mean().sort_index()\n    std = data.groupby(target).std().sort_index()\n\n    for idx, ax in zip(range(50), axes.flatten()):\n        #main code\n        ax.bar(mean[f'feature_{idx}'].index, mean[f'feature_{idx}'],\n              color = dark_palette[:4], width = 0.6)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_xlabel('')\n        ax.set_ylabel('')\n        ax.margins(0.1)\n        ax.spines['left'].set_visible(False)\n        ax.set_title(f'Feature_{idx}', loc = 'right', weight = 'bold', fontsize = 11)\n\n    axes.flatten()[-1].axis('off')\n    axes.flatten()[-2].axis('off')\n\n    fig.supxlabel('AVERAGE by class (by feature)', ha = 'center', fontweight = 'bold')\n\n    fig.tight_layout()\n    plt.show()\n\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = (train\n           .pipe(start_pipeline)\n           .pipe(label_encode)\n           .pipe(corelation_target, target = 'target')\n           .pipe(corelation_horizontal_target, target = 'target')\n           .pipe(zero_percent)\n           .pipe(bargraph_average_by_class_by_feature, target = 'target'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We cannot validate with the test dataset, as there is no 'target' column . \n\nHave to split the train dataset.\n","metadata":{}},{"cell_type":"code","source":"     \n\nfrom cycler import cycler\n\n\nraw_light_palette = [\n    (0, 122, 255), # Blue\n    (255, 149, 0), # Orange\n    (52, 199, 89), # Green\n    (255, 59, 48), # Red\n    (175, 82, 222),# Purple\n    (255, 45, 85), # Pink\n    (88, 86, 214), # Indigo\n    (90, 200, 250),# Teal\n    (255, 204, 0)  # Yellow\n]\n\nraw_dark_palette = [\n    (10, 132, 255), # Blue\n    (255, 159, 10), # Orange\n    (48, 209, 88),  # Green\n    (255, 69, 58),  # Red\n    (191, 90, 242), # Purple\n    (94, 92, 230),  # Indigo\n    (255, 55, 95),  # Pink\n    (100, 210, 255),# Teal\n    (255, 214, 10)  # Yellow\n]\n\nraw_gray_light_palette = [\n    (142, 142, 147),# Gray\n    (174, 174, 178),# Gray (2)\n    (199, 199, 204),# Gray (3)\n    (209, 209, 214),# Gray (4)\n    (229, 229, 234),# Gray (5)\n    (242, 242, 247),# Gray (6)\n]\n\nraw_gray_dark_palette = [\n    (142, 142, 147),# Gray\n    (99, 99, 102),  # Gray (2)\n    (72, 72, 74),   # Gray (3)\n    (58, 58, 60),   # Gray (4)\n    (44, 44, 46),   # Gray (5)\n    (28, 28, 39),   # Gray (6)\n]\n\n\nlight_palette = np.array(raw_light_palette)/255\ndark_palette = np.array(raw_dark_palette)/255\ngray_light_palette = np.array(raw_gray_light_palette)/255\ngray_dark_palette = np.array(raw_gray_dark_palette)/255\n\nmpl.rcParams['axes.prop_cycle'] = cycler('color',dark_palette)\nmpl.rcParams['figure.facecolor']  = gray_dark_palette[-2]\nmpl.rcParams['figure.edgecolor']  = gray_dark_palette[-2]\nmpl.rcParams['axes.facecolor'] =  gray_dark_palette[-2]\n\nwhite_color = gray_light_palette[-2]\nmpl.rcParams['text.color'] = white_color\nmpl.rcParams['axes.labelcolor'] = white_color\nmpl.rcParams['axes.edgecolor'] = white_color\nmpl.rcParams['xtick.color'] = white_color\nmpl.rcParams['ytick.color'] = white_color\n\nmpl.rcParams['figure.dpi'] = 200\n\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Soft Voting Ensemble Starter :** https://www.kaggle.com/manabendrarout/soft-voting-ensemble-starter-tps-may21","metadata":{}},{"cell_type":"code","source":"import warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category = FutureWarning)\nwarnings.filterwarnings('ignore', category = RuntimeWarning)\nwarnings.filterwarnings('ignore', category = UserWarning)\nwarnings.filterwarnings('ignore', category = sklearn.exceptions.UndefinedMetricWarning)\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport os\n#fmin : Minimize function using simplex downhill algorithm\nfrom scipy.optimize import fmin as scip_fmin\n\n# visualization \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style = \"whitegrid\")\n\n# Machine Learning\n\n# Utils\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_validate\nfrom sklearn.model_selection import cross_val_score, train_test_split, KFold\nfrom sklearn import preprocessing\nimport category_encoders as ce\n\n# Feature Selection\nfrom sklearn.feature_selection import chi2, f_classif, f_regression\nfrom sklearn.feature_selection import mutual_info_classif, mutual_info_regression\nfrom sklearn.feature_selection import SelectKBest, SelectPercentile, VarianceThreshold\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier, VotingClassifier\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = RANDOM_SEED):\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Scaling\n\nTo bring all features into a similar scale let's use simple scaler to scale all the features","metadata":{}},{"cell_type":"code","source":"not)features = ['id', 'target']\nfeatures = []\n\nfor feat in train_df.columns:\n    \n    if feat not in not_features:\n        features.append(feat)\n        \nprint(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nscaler.fit(train_df[features])\ntrain_df[features] = scaler.transform(train_df[features])\ntest_df[features] = scaler.transform(test_df[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KFOLD SPLITS\n\nBefore moving to feature engineering, it's better to perform cross validation splits. \n\nIn that way, we will not risk any data leakage and would be more certain of the validation set being aptly representative of the real world unknown data. ","metadata":{}},{"cell_type":"code","source":"NUM_SPLITS = 5\n\ntrain_df[\"kfold\"] = -1\ntrain_df = train_df.sample(frac = 1).reset_index(drop = True)\ny = train_df.target.values\nkf = StratifiedKFold(n_splits = NUM_SPLITS)\n\nfor f, (t_, v_) in enumerate(kf.split(X = train_df, y = y)):\n    train_df.loc[v_, 'kfold'] = f\n    \ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FEATURE SELECTION\n\nWe need to select only the important features for better performance of the model. \nAn unnecessary in best case scenario will not add to any productive calculation of the algorithm or in worst case scenario 'confuse' the model. `\n\nTo DO THE SAME LET'S CREATE A WRAPPER CLASS THAT HAS ALL BUILD IN STATISTICAL TESTS REQUIRED TO PERFORM FEATURE SELECTION AND TAKE SOME BASIC INPUTS FROM USER and spits out the required features \n","metadata":{}},{"cell_type":"code","source":"# FROM abhishek thakur's book \n\nclass UnivariateFeatureSelection:\n    \n    def __init__(self, n_features, problem_type, scoring, return_cols = True):\n        \n        \"\"\"\n        Custom Univariate Feature Selction wrapper on different Univariate Feature selection \n        models from Scikit-Learn. \n        : param n_features: SelectPercentile if Float else SelectKBest\n        : param problem_type : classification or regression\n        : param scoring : scoring function, string\n        \"\"\"\n        \n        self.n_features = n_features\n        \n        if problem_type = \"classification\":\n            \n            valid_scoring = {\n                \"f_classif\": f_classif, \n                \"chi2\" : chi2,\n                \"mutual_info_classif\": mutual_info_classif\n            }\n            \n        else : \n            valid_scoring = {\n                \"f_regression\" : f_regression,\n                \"mutual_info_regression\" : mutual_info_regression\n            }\n            \n        if scoring not in valid_scoring:\n            raise Exception(\"Invalid scoring function\")\n            \n        if isinstance(n_features, int):\n            \n            self.selection = SelectKBest(\n                                            valid_scoring[scoring])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}