{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Experiment  \ni tried to do undersampling.  \nhyper parameters were tuned by optuna for undersampled data.  \n  \npublic score: 1.36304  \n  \npredicted probabilities for each class are almost the same (about 0.25) <- df_sub  \ni suspect that it is difficult to predict class.","metadata":{}},{"cell_type":"markdown","source":"【実験】  \nアンダーサンプリングしたデータで学習・予測してみた。  \nハイパーパラメータはoptunaでチューニングした。  \n  \npublic score: 1.3604  \n  \n予測された確率はどのクラスもほぼ同じ（だいたい0.25付近）<- df_sub参照  \nクラスを予測するのは難しいのではないかと思う。  \n<- Xからyを予測するとして、yの予測にXが全然寄与してない。Xを使っても全然予測できない。予測できていない。","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nSEED = 1380","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\")\n\ndata1 = df_train[df_train[\"target\"] == \"Class_1\"]\ndata2 = df_train[df_train[\"target\"] == \"Class_2\"]\ndata3 = df_train[df_train[\"target\"] == \"Class_3\"]\ndata4 = df_train[df_train[\"target\"] == \"Class_4\"]\n\nprint(\"Class_1:\", len(data1))\nprint(\"Class_2:\", len(data2))\nprint(\"Class_3:\", len(data3))\nprint(\"Class_4:\", len(data4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = data1\ndata2 = data2.sample(n=len(data1), axis=0, random_state=SEED)\ndata3 = data3.sample(n=len(data1), axis=0, random_state=SEED)\ndata4 = data4.sample(n=len(data1), axis=0, random_state=SEED)\n\nprint(\"Class_1:\", len(data1))\nprint(\"Class_2:\", len(data2))\nprint(\"Class_3:\", len(data3))\nprint(\"Class_4:\", len(data4))\n\ndataset1 = pd.concat([data1, data2, data3, data4], axis=0).reset_index(drop=True)\nprint(\"dataset1 shape:\", dataset1.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dataset1.drop([\"id\", \"target\"], axis=1)\ny = dataset1.target\n\nctoi = {\"Class_1\": 0, \"Class_2\": 1, \"Class_3\": 2, \"Class_4\": 3}\ny.replace(ctoi, inplace=True)\n\nX = np.array(X)\ny = np.array(y)\n\nprint(X.shape, y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\")\nX_test = df_test.drop([\"id\"], axis=1)\nX_test = np.array(X_test)\n\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nimport xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"tree_method\": \"gpu_hist\",\n    \"objective\": \"multi:softprob\",  # predict probability / 確率を出力\n    \"num_class\": 4,\n    \"eval_metric\": \"mlogloss\",\n    \"eta\": 0.006,\n    \"max_depth\": 4,\n    \"gamma\": 0.8481259071157187,\n    \"min_child_weight\": 0.5702096116340974,\n    \"colsample_bytree\": 0.2235888371622891,\n    \"subsample\": 0.6269307669980926,\n    \"lambda\": 0.05686076044791255,\n    \"alpha\": 9.971025438987308,\n    \"max_bin\": 900,\n    \"seed\": SEED\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.zeros((50000, 4))\nd_test = xgb.DMatrix(X_test)\n\nfor tr_id, vl_id in kf.split(X, y):\n    print(\"#\"*70)\n    \n    X_train, X_valid = X[tr_id, :], X[vl_id, :]\n    y_train, y_valid = y[tr_id], y[vl_id]\n\n    d_train = xgb.DMatrix(X_train, y_train)\n    d_valid = xgb.DMatrix(X_valid, y_valid)\n\n    model = xgb.train(params=params,\n                      dtrain=d_train,\n                      num_boost_round=100000,\n                      early_stopping_rounds=300,\n                      evals=[(d_train, \"train\"), (d_valid, \"valid\")],\n                      verbose_eval=1000)\n    pred = model.predict(d_test, ntree_limit=model.best_ntree_limit)\n    preds += pred\n    \npreds = preds / 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")\ndf_sub[[\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"]] = preds\n\ndf_sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.to_csv(\"XGBoost_undersampling.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}