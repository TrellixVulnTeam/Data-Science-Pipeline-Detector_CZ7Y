{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Scoreboard\n\n- normalized (model_1): loss: 1.1068 - accuracy: 0.5749 - score: 2.89593","metadata":{}},{"cell_type":"code","source":"## Imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Constants\ndir = '../input/tabular-playground-series-may-2021/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Util functions\ndef plot_history(history):\n    pd.DataFrame(history.history).plot(title='Loss/accuracy vs epochs')\n    plt.ylabel('loss / accuracy')\n    plt.xlabel('epoch');\n    \ndef plot_lr(history):\n    lrs = history.history['lr']\n    plt.semilogx(lrs, history.history['loss'])\n    plt.xlabel('lr')\n    plt.ylabel('loss')\n    plt.title('Lr vs loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Read Data\ntrain = pd.read_csv(dir + 'train.csv')\ntest = pd.read_csv(dir + 'test.csv')\nsample_submission = pd.read_csv(dir + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train: \", train.shape)\nprint(\"Test: \", test.shape)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Preprocessing\nX = train.drop(['id', 'target'], axis=1)\ny = train.target\n\n## Remove duplicate rows in training data\nduplicated_rows = train[train.drop(['id','target'], axis=1).duplicated()]\ny = y.drop(duplicated_rows.index.tolist()).values\nX = X.drop_duplicates(keep='first').values\n\nle = preprocessing.LabelEncoder()\ny = le.fit_transform(y)\n\n# Noramlize data\n# scaler = preprocessing.MinMaxScaler()\n# X_norm = scaler.fit_transform(X)\n# test_norm = scaler.transform(test.drop('id', axis=1))\n\nprint(X.shape, y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y)\nprint(X_train.shape, y_train.shape, X_test.shape, y_train.shape)\n\n## Split the normalized data\n# X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, shuffle=True, stratify=y)\n# print(X_train.shape, y_train.shape, X_test.shape, y_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set seed\ntf.random.set_seed(42)\n\n# model\nmodel_1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n])\n\n# compile\nmodel_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n             optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n             metrics=[\"accuracy\"])\n\n# fit model\nhistory_1 = model_1.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets find the optimal LR","metadata":{}},{"cell_type":"code","source":"# set seed\ntf.random.set_seed(42)\n\n# model\nmodel_2 = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n])\n\n# lr scheduler\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))\n\n# compile\nmodel_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n             optimizer=\"Adam\",\n             metrics=[\"accuracy\"])\n\n# fit the model\nhistory_2 = model_2.fit(X_train, y_train, epochs=100, callbacks=[lr_scheduler], verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_lr(history_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set seed\ntf.random.set_seed(42)\n\n# model\nmodel_3 = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n])\n\n# compile\nmodel_3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n             optimizer=\"sgd\",\n             metrics=[\"accuracy\"])\n\n# fit model\nhistory_3 = model_3.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history_3)\nmodel_3.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set seed\ntf.random.set_seed(42)\n\n# model\nmodel_4 = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n])\n\n# compile\nmodel_4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n             optimizer=\"sgd\",\n             metrics=[\"accuracy\"])\n\n# fit model\nhistory_4 = model_4.fit(X_train, y_train, epochs=100, verbose=0, validation_data=(X_test, y_test))\n\nplot_history(history_4)\nmodel_4.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets make predictions","metadata":{}},{"cell_type":"code","source":"preds = model_1.predict(test.drop('id', axis=1))\npreds = pd.DataFrame(preds, columns=['Class_1', 'Class_2', 'Class_3', 'Class_4'])\npreds.insert(loc=0, column='id', value=test.id)\npreds.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}