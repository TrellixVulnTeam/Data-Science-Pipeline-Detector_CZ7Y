{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Scoreboard:\n\n- **LR**: 1.10161 (366)\n- **RF**: 1.12760\n- **RF**(optimized): 1.10230\n- **LR**(optimized): 1.10184\n- **LightGBM**(optimized): 1.08949","metadata":{}},{"cell_type":"code","source":"## Installs\n!pip install optuna -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Imports\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom skopt import gp_minimize\nfrom skopt import space\nfrom skopt.plots import plot_convergence\nimport xgboost as xgb\nimport optuna\nfrom lightgbm import LGBMClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Constants\ndir = '../input/tabular-playground-series-may-2021/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Read data\ntrain = pd.read_csv(dir + 'train.csv', index_col='id')\ntest = pd.read_csv(dir + 'test.csv', index_col='id')\nsample_submission = pd.read_csv(dir + 'sample_submission.csv')\n\nX_train = train.drop('target', axis=1)\ny_train = train.target\nprint(f\"Train {train.shape}\")\nprint(f\"Test {test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Remove duplicate rows in training data\nduplicated_rows = train[train.drop('target', axis=1).duplicated()]\ny_train = y_train.drop(duplicated_rows.index.tolist())\nX_train = X_train.drop_duplicates(keep='first')\nX_train.shape, y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Label encode target column\nle = preprocessing.LabelEncoder()\ny_train = le.fit_transform(y_train)\ny_train = pd.DataFrame(y_train, columns=['target'])\ny_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Scale the features\nmin_max_scaler = preprocessing.MinMaxScaler()\ntransformed_X_train = min_max_scaler.fit_transform(X_train)\ntransformed_test = min_max_scaler.transform(test)\nX_train = pd.DataFrame(transformed_X_train, columns=X_train.columns)\ntest = pd.DataFrame(transformed_test, columns=test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([X_train, y_train], axis=1)\nprint(train.shape)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.shape)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Create folds\ntrain['kfold'] = -1\n\n# randomize the rows\ntrain = train.sample(frac=1).reset_index(drop=True)\n\n# fetch targets\ny = train.target.values\n\n# initiate kfold\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X=train, y=y)):\n    train.loc[v_, 'kfold'] = f\n    \n## save to csv\ntrain.to_csv('train_folds.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv('test_processed.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    'LR': LogisticRegression(max_iter=200, penalty='l2', C=10),\n    'RF': RandomForestClassifier(n_jobs=-1, max_depth=12,n_estimators=118,criterion='gini',max_features=0.7859074745773753),\n    'decision_tree_gini': tree.DecisionTreeClassifier(criterion='gini'),\n    'decision_tree_entropy': tree.DecisionTreeClassifier(criterion='entropy'),\n    'xgb': xgb.XGBClassifier(),\n    'lgbm': LGBMClassifier(num_leaves=109,learning_rate=0.2,max_depth=3,min_child_samples=89)\n}\n\nparam_grid_models = {\n    'RF': {\n        'n_estimators': [100, 200, 300, 400],\n        \"max_depth\": [1, 3, 5, 7],\n        \"criterion\": ['gini', 'entroyp']\n    },\n    'LR': {\n        'max_iter': [100, 200, 300, 500, 800, 1000],\n        'C': [0.001, 0.01, 0.1, 1, 10, 100]\n    }\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold, model):\n    df_train = train[train.kfold != fold].reset_index(drop=True)\n    df_valid = train[train.kfold == fold].reset_index(drop=True)\n    \n    xtrain = df_train.drop(['target','kfold'], axis=1).values\n    ytrain = df_train.target.values\n    \n    xvalid = df_valid.drop(['target', 'kfold'], axis=1).values\n    yvalid = df_valid.target.values\n    \n    clf = models[model]\n    \n    clf.fit(xtrain, ytrain)\n    \n    preds = clf.predict_proba(xvalid)\n    \n    loss = metrics.log_loss(yvalid, preds)\n    \n    score = clf.score(xvalid, yvalid)\n    \n    print(f\"model {model}: Fold {fold} accuracy {score} loss {loss}\")\n    \n    joblib.dump(clf, f\"{model}_{fold}.bin\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = 'lgbm'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    run(i, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(5):\n#     run(i, 'decision_tree_gini')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(5):\n#     run(i, 'xgb')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(5):\n#     run(i, 'RF')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(5):\n#     run(i, 'lgbm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 4\nmodel = joblib.load(f\"{model}_{fold}.bin\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_proba(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.DataFrame(preds, columns=['Class_1','Class_2','Class_3','Class_4'])\npredictions = pd.concat([sample_submission.id, predictions], axis=1)\npredictions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Hyperparameter optimization (ref: https://www.youtube.com/watch?v=5nYqK-HaoKY)\n\n## Grid Search\ndef run_search(model):\n    xtrain = train.drop(['target','kfold'], axis=1).values\n    ytrain = train.target.values\n    \n    clf = models[model]\n    \n    param_grid = param_grid_models[model]\n    \n    model = model_selection.GridSearchCV(\n        estimator=clf,\n        param_grid=param_grid,\n        scoring=\"accuracy\",\n        verbose=42,\n        n_jobs=-1,\n        cv=5\n    )\n    \n    model.fit(xtrain, ytrain)\n    print(model.best_score_)\n    print(model.best_estimator_.get_params())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = 'LR'\nrun_search(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = 'RF'\nrun_search(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## skopt\nfrom functools import partial\n\ndef optimize(params, param_names, model, X, y):\n    model = models[model]\n    params = dict(zip(param_names, params))\n    model.set_params(**params)\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X, y):\n        train_idx, test_idx = idx[0], idx[1]\n        xtrain = X[train_idx]\n        ytrain = y[train_idx]\n        \n        xtest = X[test_idx]\n        ytest = y[test_idx]\n        \n        model.fit(xtrain, ytrain)\n        score = model.score(xtest, ytest)\n        accuracies.append(score)\n    return -1 * np.mean(accuracies)    \n\nmodel = 'RF'\nparam_space = [\n    space.Integer(3, 15, name=\"max_depth\"),\n    space.Integer(100, 600, name=\"n_estimators\"),\n    space.Categorical([\"gini\", \"entropy\"], name='criterion'),\n    space.Real(0.01, 1, name=\"max_features\", prior=\"uniform\")\n]\nparam_names = [\n    \"max_depth\",\n    \"n_estimators\",\n    \"criterion\",\n    \"max_features\"\n]\ntrain = pd.read_csv(dir + 'train.csv', index_col='id')\ntest = pd.read_csv(dir + 'test.csv', index_col='id')\nX = train.drop('target', axis=1).values\ny = train.target.values\noptimize_func = partial(\n    optimize,\n    param_names=param_names,\n    model=model,\n    X=X,\n    y=y\n)\nresult = gp_minimize(optimize_func, dimensions=param_space, n_calls=15,verbose=42)\nprint(dict(zip(param_names, result.x)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot the convergence\nplot_convergence(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Optuna\ntrain = pd.read_csv(dir + 'train.csv', index_col='id')\ntest = pd.read_csv(dir + 'test.csv', index_col='id')\nX = train.drop('target', axis=1).values\ny = train.target.values\nmodel='lgbm'\n\ndef objective(trial, data=X, target=y, model=model):\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(data, target, test_size=0.2, random_state=42, shuffle=True)\n    params = {\n        'num_leaves' : trial.suggest_int('num_leaves' , 109 , 109),\n        'learning_rate' : trial.suggest_float('learning_rate' , 0.2 , 0.2),\n        'max_depth' : trial.suggest_int('max_depth' , 3 , 3),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 100)\n    }\n#     model = models[model]\n    model = LGBMClassifier(**params) \n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_test, y_test)],\n        eval_metric='multi_logloss',\n        early_stopping_rounds=100,\n        verbose=42\n    )\n    preds = model.predict_proba(X_test)\n    return metrics.log_loss(y_test, preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=35)\nprint(f\"trails finished {len(study.trials)}\")\nprint(f\"Best trail: {study.best_trial.params}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}