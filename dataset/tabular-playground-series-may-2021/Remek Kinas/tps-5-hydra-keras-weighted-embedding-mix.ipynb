{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is story about Hydra ... HydraNet for ... TPS-05\n\n### Each hydra has many heads. So let's teach each one to look through a world of different data. For this purpose, we will build a neural network consisting of heads  and the heart of Hydra will be another neural network. So we are really building a solution that implements the Stacked Ensemble.\n\n- 11.05.2021 - first release (one head type, kfold trining)\n- 12.05.2021 - multi-head architecture (I decided to remove kfold training - one method of training is enough to understand way of creating Keras Ensemble Stacking, second reason - to speed up learning proces - I do not see any big differences on score)\n- 12.05.2021 - **WEIGHTED TRAINING (!) - custom weighted crossentropy loss function implemented**\n- 26.05.2021 - probabilities blending\n\nInteresting in my TPS-05 notebooks?\n- [Pytorch NN for tabular - step by step](https://www.kaggle.com/remekkinas/tps-5-pytorch-nn-for-tabular-step-by-step)\n- [CNN (2D Convolution) for solving TPS-05](https://www.kaggle.com/remekkinas/cnn-2d-convolution-for-solving-tps-05)\n- [SHAP + LGBM - looking for best features](https://www.kaggle.com/remekkinas/shap-lgbm-looking-for-best-features)\n- [Weighted training - XGB, RF, LR, ... SMOTE](https://www.kaggle.com/remekkinas/tps-5-weighted-training-xgb-rf-lr-smote)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"![](https://vignette3.wikia.nocookie.net/dragon/images/7/78/Image.jpg/revision/latest?cb=20130506000229)","metadata":{}},{"cell_type":"markdown","source":"IMPORT MODULES","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report \nfrom sklearn.utils import class_weight\n\nimport tensorflow as tf\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization,  Flatten, Embedding, MaxPooling1D, Conv1D\nfrom keras.layers.merge import concatenate\nfrom keras.utils import plot_model\nfrom tensorflow.keras import activations,callbacks\nfrom keras import backend as K\n\n\nfrom tqdm.notebook import tqdm\nfrom IPython.display import Image , display\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-25T12:58:18.54664Z","iopub.execute_input":"2021-05-25T12:58:18.547105Z","iopub.status.idle":"2021-05-25T12:58:26.184675Z","shell.execute_reply.started":"2021-05-25T12:58:18.547005Z","shell.execute_reply":"2021-05-25T12:58:26.183186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SET NOTEBOOK PARAMS","metadata":{}},{"cell_type":"code","source":"RANDOM_STATE = 2021\n\nNUM_HEADS = 2 # Let's create Hydra with 4 heads \n\nHEAD_EPOCHS = 50\nHYDRA_EPOCHS = 30\n\nTRAIN_VERBOSE = 2\n\nNUM_CLASS = 4","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:26.186836Z","iopub.execute_input":"2021-05-25T12:58:26.187311Z","iopub.status.idle":"2021-05-25T12:58:26.192815Z","shell.execute_reply.started":"2021-05-25T12:58:26.187264Z","shell.execute_reply":"2021-05-25T12:58:26.192005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LOAD AND PREPROCESS DATA","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\", index_col = 'id')\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\", index_col = 'id')\n\nX = train.drop('target', axis = 1)\n\nlencoder = LabelEncoder()\ny = pd.DataFrame(lencoder.fit_transform(train['target']), columns=['target'])\n\ndf_all = pd.concat([X, test], axis = 0)\n\ndf_all = df_all.apply(lencoder.fit_transform)\n\nX, test = df_all[:len(train)], df_all[len(train):]\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state= RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:26.194416Z","iopub.execute_input":"2021-05-25T12:58:26.194836Z","iopub.status.idle":"2021-05-25T12:58:27.945153Z","shell.execute_reply.started":"2021-05-25T12:58:26.194802Z","shell.execute_reply":"2021-05-25T12:58:27.944244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_FEATURES = len(X_train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:27.947092Z","iopub.execute_input":"2021-05-25T12:58:27.947487Z","iopub.status.idle":"2021-05-25T12:58:27.952019Z","shell.execute_reply.started":"2021-05-25T12:58:27.947445Z","shell.execute_reply":"2021-05-25T12:58:27.950967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. CREATE HYDRA HEADS","metadata":{}},{"cell_type":"code","source":"# inspired from mhttps://www.kaggle.com/pourchot/lb-1-0896-keras-nn-with-20-folds\n\nes = callbacks.EarlyStopping(monitor = 'val_loss', \n                             min_delta = 0.0000001, \n                             patience = 2,\n                             mode = 'min',\n                             baseline = None, \n                             restore_best_weights = True,\n                             verbose = 1)\n\nplateau  = callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n                                       factor = 0.5, \n                                       patience = 2, \n                                       mode = 'min', \n                                       min_delt = 0.0000001,\n                                       cooldown = 0, \n                                       min_lr = 1e-8,\n                                       verbose = 1) ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:27.953352Z","iopub.execute_input":"2021-05-25T12:58:27.953645Z","iopub.status.idle":"2021-05-25T12:58:27.970693Z","shell.execute_reply.started":"2021-05-25T12:58:27.953608Z","shell.execute_reply":"2021-05-25T12:58:27.969854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1B. HEAD NN ARCHITECTURE","metadata":{}},{"cell_type":"code","source":"# Lets define different architecture (brains) for each head :) \n# Let each hydra think differently.\n\n# You can play with configurations - i just randomly created 4 nn architectures\n\nh_model_1 = [\n        Dense(64, input_dim = NUM_FEATURES, activation='relu', kernel_initializer='he_uniform'),\n        Dropout(0.3),\n        Dense(32, activation='relu', kernel_initializer='he_uniform'),\n        Dropout(0.2),\n        Dense(128, activation='softmax', kernel_initializer='he_uniform'),\n        Dropout(0.2),\n        Dense(NUM_CLASS, activation='softmax', kernel_initializer='he_uniform')\n    ]\n\nh_model_2 = [\n        Dense(150, input_dim = NUM_FEATURES, activation='relu', kernel_initializer='he_uniform'),\n        Dropout(0.3),\n        Dense(150, activation='relu', kernel_initializer='he_uniform'),\n        Dropout(0.2),\n        Dense(150, activation='softmax', kernel_initializer='he_uniform'),\n        Dropout(0.2),\n        Dense(NUM_CLASS, activation='softmax', kernel_initializer='he_uniform')\n    ]\n\n\nh_model_3 = [\n        Dense(50, input_dim = NUM_FEATURES, activation='relu', kernel_initializer='he_uniform'),\n        Dropout(0.25),\n        Dense(25, activation='relu', kernel_initializer='he_uniform'),\n        Dropout(0.25),\n        Dense(10, activation='softmax', kernel_initializer='he_uniform'),\n        Dropout(0.2),\n        Dense(NUM_CLASS, activation='softmax', kernel_initializer='he_uniform')\n    ]\n\nh_model_4 = [\n        Dense(512, input_dim = NUM_FEATURES, activation='relu', kernel_initializer='he_uniform'),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(256, activation='relu', kernel_initializer='he_uniform'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(128, activation='relu', kernel_initializer='he_uniform'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(NUM_CLASS, activation='softmax', kernel_initializer='he_uniform')\n    ]\n\n\nh_model_5 = [\n    Embedding(100, 4, input_length = NUM_FEATURES),\n    Flatten(),\n    Dense(64, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(NUM_CLASS, activation='softmax')\n]\n\nh_model_6 = [\n    Embedding(100, 16, input_length = NUM_FEATURES),\n    Flatten(),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(40, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.25),\n    Dense(NUM_CLASS, activation='softmax')\n]\n\nhead_nn_models = [h_model_1, h_model_6]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:27.972028Z","iopub.execute_input":"2021-05-25T12:58:27.97255Z","iopub.status.idle":"2021-05-25T12:58:28.040591Z","shell.execute_reply.started":"2021-05-25T12:58:27.972504Z","shell.execute_reply":"2021-05-25T12:58:28.039442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HYDRA TRAINING (+ WEIGHTED)","metadata":{}},{"cell_type":"markdown","source":"### CREATE CUSTOM WEIGHTED CROSSENTROPY LOSS","metadata":{}},{"cell_type":"code","source":"# custom  weighted categorical crossentropy for Keras\n\ndef weight_categorical_crossentropy(weights):\n    \n    weights = K.variable(weights)\n\n    def loss(y_true, y_pred):\n        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n        loss = y_true * K.log(y_pred) * weights\n        loss = -K.sum(loss, -1)\n        return loss\n\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.041931Z","iopub.execute_input":"2021-05-25T12:58:28.042237Z","iopub.status.idle":"2021-05-25T12:58:28.048101Z","shell.execute_reply.started":"2021-05-25T12:58:28.042205Z","shell.execute_reply":"2021-05-25T12:58:28.047141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CALCULATE CLASS WEIGHTS","metadata":{}},{"cell_type":"code","source":"class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.target), y_train.target)\nprint(class_weights)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.05092Z","iopub.execute_input":"2021-05-25T12:58:28.051537Z","iopub.status.idle":"2021-05-25T12:58:28.083043Z","shell.execute_reply.started":"2021-05-25T12:58:28.051501Z","shell.execute_reply":"2021-05-25T12:58:28.082044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here is our playground for testing with weights\n\nclass_weights = [1.5, 0.5, 1, 1]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.085408Z","iopub.execute_input":"2021-05-25T12:58:28.085929Z","iopub.status.idle":"2021-05-25T12:58:28.090389Z","shell.execute_reply.started":"2021-05-25T12:58:28.085878Z","shell.execute_reply":"2021-05-25T12:58:28.089313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DEFINE WEIGHTED TRAINIG LOOP ","metadata":{}},{"cell_type":"code","source":"def fit_hydra_head_model(fX_train, fy_train, fX_valid, fy_valid, n_model):\n    oy_train = to_categorical(fy_train)\n    oy_valid = to_categorical(fy_valid)\n    \n    model = Sequential(head_nn_models[n_model])\n    \n    if WEIGHTED_TRAINING:\n        model.compile(loss = weight_categorical_crossentropy(class_weights), optimizer = tf.keras.optimizers.Adam(), metrics=['accuracy'])\n    else:\n        model.compile(loss = \"categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(), metrics=['accuracy'])\n        \n    history = model.fit(fX_train, oy_train, epochs = HEAD_EPOCHS, \n                        verbose = TRAIN_VERBOSE, \n                        validation_data=(fX_valid, oy_valid), \n                        callbacks = [es, plateau], \n                        batch_size = 128)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.091935Z","iopub.execute_input":"2021-05-25T12:58:28.092268Z","iopub.status.idle":"2021-05-25T12:58:28.107613Z","shell.execute_reply.started":"2021-05-25T12:58:28.092228Z","shell.execute_reply":"2021-05-25T12:58:28.105644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. TRAIN HYDRA HEADS","metadata":{}},{"cell_type":"code","source":"def plot_model_learning(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.109653Z","iopub.execute_input":"2021-05-25T12:58:28.110415Z","iopub.status.idle":"2021-05-25T12:58:28.13068Z","shell.execute_reply.started":"2021-05-25T12:58:28.110348Z","shell.execute_reply":"2021-05-25T12:58:28.12947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_hydra_df():\n    if NUM_HEADS <= len(head_nn_models):     \n        for i in tqdm(range(NUM_HEADS)):\n            print(f'\\n>>>>>>>>>>> Training head {i+1} ... <<<<<<<<<<<')\n            model, history = fit_hydra_head_model(X_train, y_train, X_valid, y_valid, i)\n            hydra_heads_models_df.append(model)\n            print(\"\\n\")\n            plot_model_learning(history)\n    else:\n        print(\"ERROR: param NUM_HEADS > list of defined model heads [head_nn_models].\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.132335Z","iopub.execute_input":"2021-05-25T12:58:28.132823Z","iopub.status.idle":"2021-05-25T12:58:28.143779Z","shell.execute_reply.started":"2021-05-25T12:58:28.132777Z","shell.execute_reply":"2021-05-25T12:58:28.142651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you want to turn on weighted training with custom weighted entropy loss change to True\n\nWEIGHTED_TRAINING = False","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:58:28.145482Z","iopub.execute_input":"2021-05-25T12:58:28.146082Z","iopub.status.idle":"2021-05-25T12:58:28.156183Z","shell.execute_reply.started":"2021-05-25T12:58:28.146037Z","shell.execute_reply":"2021-05-25T12:58:28.155119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hydra_heads_models_df = []\ntrain_hydra_df()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-05-25T12:58:28.157578Z","iopub.execute_input":"2021-05-25T12:58:28.157893Z","iopub.status.idle":"2021-05-25T12:59:23.211098Z","shell.execute_reply.started":"2021-05-25T12:58:28.157846Z","shell.execute_reply":"2021-05-25T12:59:23.209971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. DEFINE HYDRA HEART","metadata":{}},{"cell_type":"code","source":"from keras import regularizers\n\ndef define_hydra_model(heads):\n    for i in range(len(heads)):\n        model = heads[i]\n        \n        # Lets freeze all head layers \n        for layer in model.layers:\n            layer.trainable = False\n            layer._name = 'hydra_head' + str(i+1) + '_' + layer.name\n\n    \n    hydra_visible = [model.input for model in heads]\n    hydra_outputs = [model.output for model in heads]\n    merge = concatenate(hydra_outputs)\n    \n    # Create Hydra heart layers and train them \n    \n    hidden = Dense(NUM_HEADS * NUM_CLASS, activation='relu')(merge)\n    #x = Dense(10, activation='softmax', kernel_initializer='he_uniform')(hidden)\n    output = Dense(4, activation='softmax')(hidden)\n    \n    # Architecture will be examined later ... below you can find my experiment\n    #x = BatchNormalization()(hidden)\n    #x = Dropout(0.3)(x)\n    #x = Dense(32, activation='relu')(x)\n    #x = BatchNormalization()(x)\n    #x = Dropout(0.2)(x)\n    # output = Dense(4, activation='softmax')(x)\n    \n    model = Model(inputs = hydra_visible, outputs = output)\n    \n    if WEIGHTED_TRAINING:\n        model.compile(loss = weight_categorical_crossentropy(class_weights), optimizer='adam',  metrics=['accuracy'])\n    else:\n        model.compile(loss = \"categorical_crossentropy\", optimizer='adam',  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:23.212745Z","iopub.execute_input":"2021-05-25T12:59:23.213183Z","iopub.status.idle":"2021-05-25T12:59:23.225014Z","shell.execute_reply.started":"2021-05-25T12:59:23.213137Z","shell.execute_reply":"2021-05-25T12:59:23.223679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Hydra model\nhydra_model_df = define_hydra_model(hydra_heads_models_df)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:23.226683Z","iopub.execute_input":"2021-05-25T12:59:23.227117Z","iopub.status.idle":"2021-05-25T12:59:23.271487Z","shell.execute_reply.started":"2021-05-25T12:59:23.227074Z","shell.execute_reply":"2021-05-25T12:59:23.270577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. PLOT HYDRA MODEL","metadata":{}},{"cell_type":"code","source":"# Since models are the same (could be different :)) lets plot one of them \n\nplot_model(hydra_model_df, show_shapes=True, show_layer_names=True, to_file='model.png')\ndisplay(Image('model.png'))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:23.273079Z","iopub.execute_input":"2021-05-25T12:59:23.273483Z","iopub.status.idle":"2021-05-25T12:59:23.823375Z","shell.execute_reply.started":"2021-05-25T12:59:23.273439Z","shell.execute_reply":"2021-05-25T12:59:23.821983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hydra_model_df.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:23.825278Z","iopub.execute_input":"2021-05-25T12:59:23.825731Z","iopub.status.idle":"2021-05-25T12:59:23.844553Z","shell.execute_reply.started":"2021-05-25T12:59:23.825681Z","shell.execute_reply":"2021-05-25T12:59:23.842599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. LET'S LEARN THE HYDRA TO SEE THE WHOLE WORLD","metadata":{}},{"cell_type":"code","source":"def prepare_input_data(model, X_in):\n    X = [X_in for _ in range(len(model.input))]\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:23.846079Z","iopub.execute_input":"2021-05-25T12:59:23.846382Z","iopub.status.idle":"2021-05-25T12:59:23.853415Z","shell.execute_reply.started":"2021-05-25T12:59:23.846352Z","shell.execute_reply":"2021-05-25T12:59:23.852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train)\ny_valid = to_categorical(y_valid)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:23.855133Z","iopub.execute_input":"2021-05-25T12:59:23.855585Z","iopub.status.idle":"2021-05-25T12:59:23.87132Z","shell.execute_reply.started":"2021-05-25T12:59:23.855536Z","shell.execute_reply":"2021-05-25T12:59:23.870382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now it is time to fit Hydras heart .... to see the world througt emotion :)  \nprint(\"\\n\\n>>>>>>>>>>  Fit  HydraNet <<<<<<<<<<<<\")\nhistory = hydra_model_df.fit(prepare_input_data(hydra_model_df, X_train), \n                             y_train, \n                             epochs = HYDRA_EPOCHS, \n                             verbose = TRAIN_VERBOSE, \n                             validation_data=(prepare_input_data(hydra_model_df, X_valid), y_valid),\n                             callbacks = [es, plateau], \n                             batch_size = 128)\nplot_model_learning(history)","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-05-25T12:59:23.872888Z","iopub.execute_input":"2021-05-25T12:59:23.87336Z","iopub.status.idle":"2021-05-25T12:59:49.61465Z","shell.execute_reply.started":"2021-05-25T12:59:23.873311Z","shell.execute_reply":"2021-05-25T12:59:49.613822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. LET'S LOOK HOW HYDRA SEES","metadata":{}},{"cell_type":"code","source":"# Lets look what Hydra sees\ny_valud_preds_df = hydra_model_df.predict(prepare_input_data(hydra_model_df, X_valid), verbose=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:49.615848Z","iopub.execute_input":"2021-05-25T12:59:49.616146Z","iopub.status.idle":"2021-05-25T12:59:50.426803Z","shell.execute_reply.started":"2021-05-25T12:59:49.616118Z","shell.execute_reply":"2021-05-25T12:59:50.426064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_class = np.argmax(y_valid, axis = 1)\npreds = np.argmax(y_valud_preds_df, axis = 1)\n\nsns.heatmap(pd.DataFrame(confusion_matrix(base_class, preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:59:50.430953Z","iopub.execute_input":"2021-05-25T12:59:50.431551Z","iopub.status.idle":"2021-05-25T12:59:50.760668Z","shell.execute_reply.started":"2021-05-25T12:59:50.431504Z","shell.execute_reply":"2021-05-25T12:59:50.75971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. LET'S PREDICT AND SUBMIT TO TPS-05","metadata":{}},{"cell_type":"code","source":"sub_preds_df = hydra_model_df.predict(prepare_input_data(hydra_model_df, test), verbose=0)\npredictions_df = pd.DataFrame(sub_preds_df, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:13:15.146486Z","iopub.execute_input":"2021-05-25T13:13:15.146938Z","iopub.status.idle":"2021-05-25T13:13:17.486022Z","shell.execute_reply.started":"2021-05-25T13:13:15.146899Z","shell.execute_reply":"2021-05-25T13:13:17.485001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blend_l1 = pd.read_csv(\"../input/tps05blender-v2/tps05-remek-blender_v2.csv\")\n\n\noutput = predictions_df.copy()\noutput[\"Class_1\"] = (predictions_df.Class_1 * 0.3 + blend_l1.Class_1 * 0.7)\noutput[\"Class_2\"] = (predictions_df.Class_2 * 0.3 + blend_l1.Class_2 * 0.7)\noutput[\"Class_3\"] = (predictions_df.Class_3 * 0.3 + blend_l1.Class_3 * 0.7) \noutput[\"Class_4\"] = (predictions_df.Class_4 * 0.3 + blend_l1.Class_4 * 0.7) ","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:56:44.900192Z","iopub.execute_input":"2021-05-26T04:56:44.90219Z","iopub.status.idle":"2021-05-26T04:56:44.977366Z","shell.execute_reply.started":"2021-05-26T04:56:44.902109Z","shell.execute_reply":"2021-05-26T04:56:44.976144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv\")\n\npredictions_df = pd.DataFrame(output, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])\npredictions_df['id'] = sub['id']\npredictions_df.to_csv(\"TPS-05-hydra_df_blended_submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:13:21.426968Z","iopub.execute_input":"2021-05-25T13:13:21.427481Z","iopub.status.idle":"2021-05-25T13:13:21.935244Z","shell.execute_reply.started":"2021-05-25T13:13:21.427448Z","shell.execute_reply":"2021-05-25T13:13:21.934242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.drop(\"id\", axis=1).describe().T.style.bar(subset=['mean'], color='#205ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:13:24.250656Z","iopub.execute_input":"2021-05-25T13:13:24.251032Z","iopub.status.idle":"2021-05-25T13:13:24.295233Z","shell.execute_reply.started":"2021-05-25T13:13:24.251001Z","shell.execute_reply":"2021-05-25T13:13:24.294097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TO DO\n- [x] NN head architecture improvements\n- [x] NN heart architecure improvements\n- [X] Better imput data preparation\n- [X] Hyperparameter tuning (mainly LR)\n- [X] Learning callbacks \n- [X] Training metrics plots","metadata":{}},{"cell_type":"markdown","source":"If you like it I appreciate any feedback and further development. \n\n## Next solution is coming ....... stay tuned :)  ","metadata":{}}]}