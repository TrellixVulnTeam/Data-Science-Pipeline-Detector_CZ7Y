{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [TPS-05] What if we assume that data are images ... Can we use convolution for this challange?","metadata":{}},{"cell_type":"markdown","source":"I love making AI fun. This is for fun ... or just this is not fun and you can find something cool with this experiment. I appreciate comments, feedback or any improvements for this notebook.","metadata":{}},{"cell_type":"markdown","source":"# 0. PREPARE","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport umap\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras import backend as K\nfrom keras.utils.vis_utils import plot_model\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 2021\nimg_rows, img_cols = 5, 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. LOAD DATA AND TRANSFORM FOR NN","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\", index_col = 'id')\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\", index_col = 'id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Duplicates in dataset? This is noise ... kill them ....\n# I find it thanks @omarvivas: https://www.kaggle.com/c/tabular-playground-series-may-2021/discussion/236561\n\ntrain = train[~train.drop('target', axis = 1).duplicated()]\ntrain.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.DataFrame(train.drop(\"target\", axis = 1))\nlencoder = LabelEncoder()\ny = pd.DataFrame(lencoder.fit_transform(train['target']), columns=['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state= RANDOM_STATE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train, dtype= np.float32) \nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\ny_train = np.array(y_train)\n\nX_test = np.array(X_test, dtype= np.float32) \nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\ny_test = np.array(y_test)\n\ntest = np.array(test, dtype= np.float32)\ntest = test.reshape(test.shape[0], img_rows, img_cols, 1)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'X_test shape: {y_train.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'X_test shape: {y_test.shape}')\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\ntest = test.astype('float32')\n\nX_train /= 255\nX_test /= 255\ntest /= 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. VISUALIZE DATA (IMAGES)","metadata":{}},{"cell_type":"markdown","source":"## 2A. Show images","metadata":{}},{"cell_type":"code","source":"num = 25\nimages = X_train[:num]\nlabels = y_train[:num]\n\nnum_row = 5\nnum_col = 5\n\n\nfig, axes = plt.subplots(num_row, num_col, figsize=(3*num_col,4*num_row))\nfor i in range(num):\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(images[i], cmap='gray')\n    ax.set_title('Label: {}'.format(labels[i]))\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2B. TSNE","metadata":{}},{"cell_type":"code","source":"# Lets look on TSNE  \ntrain_sub = train.sample(10000, random_state= RANDOM_STATE)\nmodel = TSNE(n_components=2, random_state=0, perplexity= 50, n_iter=3000)\ntsne_data = model.fit_transform(StandardScaler().fit_transform(train_sub.drop('target', axis = 1).astype(float)))\ntsne_data = np.vstack((tsne_data.T, train_sub.target)).T\n\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"D1\", \"D2\", \"target\"))\n\nsns.FacetGrid(tsne_df, hue=\"target\", height=6).map(plt.scatter, 'D1', 'D2').add_legend()\nplt.title('Perplexity= 50, n_iter=3000')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2C. LDA","metadata":{}},{"cell_type":"code","source":"train_sub = train.sample(10000, random_state= RANDOM_STATE)\nlda_data = LDA(n_components=3).fit_transform(train_sub.drop(columns='target'),train_sub.target)\nplt.figure(figsize=(10,10))\nsns.scatterplot(x = lda_data[:, 0], y = lda_data[:, 1], hue = 'target', data=train_sub)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2D. UMAP","metadata":{}},{"cell_type":"code","source":"train_sub = train.sample(10000, random_state= RANDOM_STATE)\nembedding = umap.UMAP(random_state = RANDOM_STATE ,n_components=3).fit_transform(train_sub.drop(columns='target').to_numpy())\nplt.figure(figsize=(10,10))\nsns.scatterplot(x = embedding[:, 0], y = embedding[:, 1], hue='target', data=train_sub)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Neural Network (Keras 2DConv)\nI take just simple NN architecture from cool MNIST dataset. You can just train this network as you can. ** Just play and have fun !!!","metadata":{}},{"cell_type":"code","source":"batch_size = 128\nnum_classes = 4\nepochs = 50\n\ninput_shape = (img_rows, img_cols, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2A. CONVERT TO CATEGORICAL","metadata":{}},{"cell_type":"code","source":"y_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2B. DEFINE MODEL ARCHITECTURE","metadata":{}},{"cell_type":"code","source":"# standard model ... nothing special ... \n\nmodel = Sequential()\nx = Conv2D(256, kernel_size=(2, 2), padding='same', activation='relu', input_shape=input_shape)\nmodel.add(x)\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (2, 2), padding='same', activation = 'relu'))\nmodel.add(Conv2D(32, (2, 2), padding='same', activation = 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(63, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2C. TRAIN ","metadata":{}},{"cell_type":"code","source":" earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n\nhistory = model.fit(X_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(X_test, y_test),\n                    callbacks = earlystop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2D. VISUALIZE TRAINING LOSS","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2E. MODEL EVALUATE","metadata":{}},{"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy on test set: \",score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2F. HACK THE MODEL","metadata":{}},{"cell_type":"markdown","source":"### A. FILTERS - first conv layer ","metadata":{}},{"cell_type":"code","source":"filters, biases = x.get_weights()\nconv_weight = filters[:,:,0,:]\n\n# Check the shape of first Conv2D layer\nprint(f'First conv2D shape: {filters.shape}')\nprint(f'First conv2D output size: {x.output.shape} \\n')\n\nplt.figure(figsize = (20,10))\nprint(\"First 16 filters of conv2D layer\")\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    plt.imshow(conv_weight[:,:,i], interpolation='nearest', cmap='gray', aspect='auto')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### B. OUTPUTS\nHow input looks like after filter application  ... ","metadata":{}},{"cell_type":"code","source":"from numpy import expand_dims\nfrom keras.models import Model\n\n# I take one example from test dataset\nimg = expand_dims(X_test[0], axis=0)\n\n# Then hijacked output from first layer\nmodel_first2D = Model(inputs=model.inputs, outputs=x.output)\n\n# Made prediction of first sample\nfeature_maps = model_first2D.predict(img)\n\n# Plot all (32) images from our conv2D layer \nplt.figure(figsize = (40,20))\nsquare = 8\nix = 1\nfor _ in range(4):\n    for _ in range(square):\n        ax = plt.subplot(square, square, ix)\n        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray', interpolation='nearest')\n        ix += 1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2F. PREDICT","metadata":{}},{"cell_type":"code","source":"preds = model.predict_proba(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. SUBMIT","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv\")\n\npredictions_df = pd.DataFrame(preds, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])\npredictions_df['id'] = sub['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.to_csv(\"conv_net_submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}