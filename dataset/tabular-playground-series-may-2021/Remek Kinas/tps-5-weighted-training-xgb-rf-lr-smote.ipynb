{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Weighted training - XGBoost, RandomForest etc ....\nSince we have imbalanced dataset I am looking for way to build model using weighted training. I decided to build a notebook in which I compare different models using regular and weighted training.\n\n\n**This notebook is \"in progress\" but I encourage you to follow the progress of the work.** \n\n<div class=\"alert alert-block alert-success\">\n<b>Notebook scope:</b>\n    <ul>\n        <li>Curret top LB submission analysis.</li>\n        <li>XGBoost - baseline & weighted training comparition - I checked there is no difference between CatBoost and LightBoost (slight differences). You can find my notebok - Keras weighted training section below.</li>\n        <li>LightGBM - out of the box + weighted training + probability callibration.</li>\n        <li>RandomForest - out of the box & weighted.</li>\n        <li>Logistic Regression - out of the box & weighted.</li>\n        <li>Sampling Techniques - Under Sampling.</li>\n        <li>Sampling Techniques - Over Sampling - Synthetic Minority Oversampling Technique(SMOTE).</li>\n        <li>Result comparition and conlusion.</li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"You can find the rest of my notebooks with TPS-05 here:\n\n- [Pytorch NN for tabular - step by step](https://www.kaggle.com/remekkinas/tps-5-pytorch-nn-for-tabular-step-by-step)\n- [CNN (2D Convolution) for solving TPS-05](https://www.kaggle.com/remekkinas/cnn-2d-convolution-for-solving-tps-05)\n- [SHAP + LGBM - looking for best features](https://www.kaggle.com/remekkinas/shap-lgbm-looking-for-best-features/)\n- [HydraNet!! ... Keras Stacked Ensemble ..](https://www.kaggle.com/remekkinas/tps-5-hydranet-keras-stacked-ensemble)","metadata":{}},{"cell_type":"markdown","source":"### My personal opinion (summary and conclusions):\n- in this competition the main challange is dealing with data sparsity (not class imbalance) - creating new features, dimention reduction etc.\n- I tried many ways to deal with imbalance - weighted training / cost sensitive training (out of the box, custom weights), uder and over sampling, probability calibration. All methods did not  improve results (still looking for solution or your feedback - it is chance that I am wrong).\n- out of the box algorithms predicts class_2 and class_3 but do not predict correctly class_1 and class_4 (probably due to data sparsity)","metadata":{}},{"cell_type":"markdown","source":"# Why this is important?\n\n## **If you look at the world through pink glasses all the colors seem to be pink ...**\n\n# Hypothesis\n* Models on public leaderbord currently look thorough pink glasses","metadata":{}},{"cell_type":"code","source":"from numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve, classification_report\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport xgboost as xgb \nfrom lightgbm import LGBMClassifier\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nRANDOM_STATE = 2021","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\", index_col = 'id')\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\", index_col = 'id')\n#train = train[~train.drop('target', axis = 1).duplicated()]\n\nX = pd.DataFrame(train.drop(\"target\", axis = 1))\n\nlencoder = LabelEncoder()\ny = pd.DataFrame(lencoder.fit_transform(train['target']), columns=['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPERIMENT #1\n# Lets look on class distribution in TPS-05 TRAINING dataset","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'target', data= y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets look on class distribution on TOP leaderboard submission \nI am not specifically mentioning which results. I took the first ones that are on the TOP list.","metadata":{}},{"cell_type":"code","source":"top_submission = pd.read_csv(\"../input/tps05-sample-top-submission/tps-05-sample-submission-001.csv\", index_col = 'id')\n\ntop_submission.describe().T.style.bar(subset=['mean'], color='#205ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we can see in TOP Leaderboard submission there is no Class_1 .... almost no Class_4 .... It could be potential problem but we have to examine it more in next sections.\n- Distribution is almost the same comparing with training dataset.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion - distribution is ..... similar (\"pink color\" biased)???? Looks good on public leaderboard ... but what if class distribution in remaining 50% of test dataset )private leaderboard) is different? Still we should see pink color?","metadata":{}},{"cell_type":"markdown","source":"# EXPERIMENT #2\n# Lets make a prediction using XGBoost model and test them on train dataset\n# SCORE ON PUBLIC LEADERBOARD -> 1.08684 (without optimization)\n","metadata":{}},{"cell_type":"markdown","source":"We will use subset (20%) of training data to see accuracy of model. We want to see how model trains on dataset and then compare results with validation dataset distribution. ","metadata":{}},{"cell_type":"code","source":"# We define X_test for results comparision \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state= RANDOM_STATE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, X_train_oof, y_train_oof, weighted = False, b_type = True, ):\n    test_preds = None\n    test_oof_preds = None\n    train_rmse = 0\n    val_rmse = 0\n    n_splits = 10\n    \n    skf = StratifiedKFold(n_splits = n_splits, shuffle = True,  random_state = 0)\n    for fold, (tr_index , val_index) in enumerate(skf.split(X_train_oof.values , y_train_oof.values)):\n\n        print(f\"\\nFold {fold + 1}\")\n\n        x_train_o, x_val_o = X_train_oof.iloc[tr_index] , X_train_oof.iloc[val_index]\n        y_train_o, y_val_o = y_train_oof.iloc[tr_index] , y_train_oof.iloc[val_index]\n        \n        if weighted:\n            weights_y = weights_df.iloc[tr_index]\n\n        eval_set = [(x_val_o, y_val_o)]\n        \n        if b_type:\n            if weighted:\n                model.fit(x_train_o, y_train_o, eval_set = eval_set, verbose = 500, sample_weight = weights_y)\n            else:\n                model.fit(x_train_o, y_train_o, eval_set = eval_set, verbose = 500)\n        \n        else:\n            model.fit(x_train_o, y_train_o)\n\n        train_preds = model.predict(x_train_o)\n        train_rmse += mean_squared_error(y_train_o ,train_preds , squared = False)\n        print(\"\\n- Training RMSE : \" , mean_squared_error(y_train_o ,train_preds , squared = False))\n\n        val_preds = model.predict(x_val_o)\n        val_rmse += mean_squared_error(y_val_o , val_preds , squared = False)\n        print(\"- Validation RMSE : \" , mean_squared_error(y_val_o , val_preds , squared = False))\n        print('---------------')\n\n        if test_preds is None:\n            test_preds = model.predict_proba(test.values)\n            test_oof_preds = model.predict_proba(X_test.values)\n        else:\n            test_preds += model.predict_proba(test.values)\n            test_oof_preds += model.predict_proba(X_test.values)\n\n    print(\"\\nAverage Training RMSE : \" , train_rmse / n_splits)\n    print(\"Average Validation RMSE : \" , val_rmse / n_splits)\n\n    test_preds /= n_splits\n    test_oof_preds /= n_splits\n    \n    return test_preds, test_oof_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(tree_method='gpu_hist',  eval_metric='mlogloss')\nxgb_preds_weighted, y_pred = training(xgb_model, X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nsorted_idx = xgb_model.feature_importances_.argsort()\nplt.barh(X_train.columns[sorted_idx], xgb_model.feature_importances_[sorted_idx])\nplt.xlabel(\"Xgboost Feature Importance\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In test dataset (dataset separated from training dataset) we have .... ","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'target', data= y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## But our model see .... through pink glasses ...","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'target', data= pd.DataFrame(y_preds, columns=['target']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upppssss - distribution is ..... pink color - class_2 biased ... Is it not? Am I making a mistake?\n\n","metadata":{}},{"cell_type":"markdown","source":"# We can check this using LGBM as well","metadata":{}},{"cell_type":"code","source":"params = { \n        'objective': 'multiclass', \n        'num_class' : 4, \n        'metric': 'multi_logloss' \n    } ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_model =  LGBMClassifier(**params)\nlgbm_preds_weighted, y_pred = training(lgbm_model, X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conclutions:\n- The same here - we have problem with prediction - model can not predict class_1 and class_3 well\n- There is no bigger difference between XGBoost and Light Boost - when optimized (on oryginal dataset) it could improve better results but ... this is in my opiniion marginal gain (model does not see classes correctly) ","metadata":{}},{"cell_type":"markdown","source":"# EXPERIMENT 3 - WEIGHTED TRAININGS\n\n# Explore class weight","metadata":{}},{"cell_type":"code","source":"# I do not use this one - this is only for testing\n\nlargest_class_weight_coef = max(y_train.target.value_counts().values)/y_train.shape[0]\nprint(largest_class_weight_coef)\n\ndef BalancedSampleWeights(y_train, class_weight_coef):\n    classes = np.unique(y_train, axis = 0)\n    classes.sort()\n    class_samples = np.bincount(y_train)\n    total_samples = class_samples.sum()\n    n_classes = len(class_samples)\n    weights = total_samples / (n_classes * class_samples * 1.0)\n    class_weight_dict = {key : value for (key, value) in zip(classes, weights)}\n    class_weight_dict[classes[1]] = class_weight_dict[classes[1]] * class_weight_coef\n    sample_weights = [class_weight_dict[i] for i in y_train]\n    return sample_weights\n\nweight = BalancedSampleWeights(y_train.target, largest_class_weight_coef)\nprint(len(weight))\nweights_df= pd.DataFrame(weight, columns=['weight'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I use only this one ...\n\nfrom sklearn.utils.class_weight import compute_sample_weight\nweights_df= pd.DataFrame(compute_sample_weight(\"balanced\", y_train.target), columns=['weight'])\n\n# Some models eg. RF, LR require weights as dictionary\ndict_weight = dict(enumerate(class_weight.compute_class_weight('balanced', np.unique(y_train.target), y_train.target).flatten(), 0))\nprint(dict_weight)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. XGBoost training weighted training ","metadata":{}},{"cell_type":"markdown","source":"* I do not use any hyperparameter optimization - it will be done as a last step (after all methods development)\n* The weighted training for XGBoost seems to be not working. I am looking for a way to solve the problem.","metadata":{}},{"cell_type":"markdown","source":"### 1A. XGBoost - COST SENSITIVE LEARNING\n\n","metadata":{}},{"cell_type":"code","source":"xgb_model_weighted = xgb.XGBClassifier(tree_method='gpu_hist',  eval_metric='mlogloss')\nxgb_preds_weighted, y_pred = training(xgb_model_weighted, X_train, y_train, weighted = True)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nsorted_idx = xgb_model_weighted.feature_importances_.argsort()\nplt.barh(X_train.columns[sorted_idx], xgb_model_weighted.feature_importances_[sorted_idx])\nplt.xlabel(\"Xgboost Feature Importance\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = 'target', data= pd.DataFrame(y_preds, columns=['target']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upppssss - something streange has happened ... distribution is ..... not biased but way from source ... Is it not? Am I making a mistake?","metadata":{}},{"cell_type":"markdown","source":"### 1B. LightGBM - COST SENSITIVE LEARNING","metadata":{}},{"cell_type":"markdown","source":"LightGBM provides two ways - class_weight = 'balanced' || class_weight = custom_weights","metadata":{}},{"cell_type":"code","source":"params_weighted = { \n        'objective': 'multiclass', \n        'num_class' : 4, \n        'metric': 'multi_logloss',\n        'class_weight': dict_weight  # or 'balanced'\n    } ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_model_weighted =  LGBMClassifier(**params_weighted)\nlgbm_preds_weighted, y_pred = training(lgbm_model_weighted, X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see .... still model does not performing well .... we can use probability calibration with isotonic regression or logistic regression.","metadata":{}},{"cell_type":"code","source":"from sklearn.calibration import CalibratedClassifierCV\n\ncalibrated_clf = CalibratedClassifierCV(base_estimator = lgbm_model_weighted, cv=3, ensemble = False)\ncalibrated_clf.fit(X_train, y_train)\n\ny_pred = calibrated_clf.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uppppssss ..... we are in starting point  ...... Not good ....","metadata":{}},{"cell_type":"markdown","source":"# 2. Sampling Techniques - Under Sampling","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nundersample = RandomUnderSampler(random_state=0)\n\nX_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\nsns.countplot(x = 'target', data= y_train_under)\n\n# Other methods\n# - The Condensed Nearest Neighbor Rule — CondensedNearestNeighbour\n# - Two modifications of CNN — TomekLinks\n# - One-Sided Selection — OneSidedSelection\n# - Edited Nearest Neighbors — EditedNearestNeighbors\n# - Neighborhood Cleaning Rule — NeighborhoodCleaningRule","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(tree_method='gpu_hist',  eval_metric='mlogloss')\nxgb_preds_weighted, y_pred = training(xgb_model, X_train_under, y_train_under)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = 'target', data= pd.DataFrame(y_preds, columns=['target']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Sampling Techniques - Over Sampling ","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nX_train_over, y_train_over = SMOTE().fit_resample(X_train, y_train)\nsns.countplot(x = 'target', data= y_train_over)\n\n# Other methods\n# - Borderline-SMOTE\n# - Borderline-SMOTE SVM\n# - Adaptive Synthetic Sampling (ADASYN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(tree_method='gpu_hist',  eval_metric='mlogloss')\nxgb_preds_weighted, y_pred = training(xgb_model, X_train_over, y_train_over)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = 'target', data= pd.DataFrame(y_preds, columns=['target']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = 'target', data= y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SMOTE looks good (class distribution) but .... metrics are .... not good :) !!!","metadata":{}},{"cell_type":"markdown","source":"# 4. BONUS","metadata":{}},{"cell_type":"markdown","source":"## 4A. RandomForest","metadata":{}},{"cell_type":"markdown","source":"### A. DecisionTreeClassifier baseline","metadata":{}},{"cell_type":"code","source":"rf_model = DecisionTreeClassifier()\nrf_preds_weighted, y_pred = training(rf_model, X_train, y_train, False, False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### B. DecisionTreeClassifier weighted training (use \"balanced\" param) ","metadata":{}},{"cell_type":"code","source":"rf_model_weighted_balanced = DecisionTreeClassifier(class_weight = 'balanced') # you can use class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\nrf_preds_weighted, y_pred = training(rf_model_weighted_balanced, X_train, y_train, False, False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### C. DecisionTreeClassifier weighted training (use custom weight params) ","metadata":{}},{"cell_type":"code","source":"rf_model_weighted = DecisionTreeClassifier(class_weight = dict_weight)\nrf_preds_weighted, y_pred = training(rf_model_weighted, X_train, y_train, False, False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4B. LogisticRegression","metadata":{}},{"cell_type":"markdown","source":"### A. LogisticRegression baseline","metadata":{}},{"cell_type":"code","source":"lr_model = LogisticRegression()\nlr_preds_weighted, y_pred = training(lr_model, X_train, y_train, False, False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### B. LogisticRegression weighted training (use \"balanced\" param)","metadata":{}},{"cell_type":"code","source":"lr_model_weighted = LogisticRegression(class_weight = \"balanced\")\nlr_preds_weighted, y_pred = training(lr_model_weighted, X_train, y_train, False, False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = np.argmax(y_pred, axis=1)\nprint(f'MSE Score: {mean_squared_error(y_test,y_preds)}\\n')\nprint(classification_report(y_test, y_preds))\n\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_preds)), annot=True, linewidths=.5, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv\")\n\n#predictions_df = pd.DataFrame(test_preds, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])\n#predictions_df['id'] = sub['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions_df.to_csv(\"xgboost_weighted_submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}