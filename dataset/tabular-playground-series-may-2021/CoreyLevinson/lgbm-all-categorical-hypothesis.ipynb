{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, gc\nfrom tqdm import tqdm\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nimport shap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"figure.figsize\"] = [10, 7] # Make plots bigger\n\n# Pandas show more columns\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Following https://www.kaggle.com/returnofsputnik/may-tabular-coreys-eda I hypothesize that every feature is actually a category, not a numeric feature. If that's the case, we have to take a few steps.\n 1. Check if there are any categories in the test that are not in the train\n 2. Run LightGBM, tune the categorical hyperparameters (e.g. cat_l2)\n 3. Run SHAP, see which features are most important, may be helpful for feature engineering inspiration\n 3. Feature engineer and re-run, does it have any impact?\n 4. Run SHAP, see if anything else interesting comes out\n 5. Rerun blindly on full set with same hyperparameters\n 6. Potentially pseudolabel and rerun","metadata":{}},{"cell_type":"code","source":"tr = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv')\nte = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Before we begin, for my sanity, let's just convert the target column into integers. \nRight now it's \"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\" so the column is an object. Let's convert this to a numeric columns.","metadata":{}},{"cell_type":"code","source":"target_map = {'Class_1':0, 'Class_2':1, 'Class_3':2, 'Class_4':3}\nreverse_target_map = {0:'Class_1', 1:'Class_2', 2:'Class_3', 3:'Class_4'}\n\ntr['target'] = pd.to_numeric(tr['target'].map(target_map))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = [c for c in tr.columns if 'feature_' in c]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the test to train\nte['target'] = -1\n\ntr_te = pd.concat([tr, te],axis=0,sort=True).reset_index(drop=True)\ntr_te['is_train'] = tr_te['target'] != -1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Any categories in test that are not in train? Any categories in train that are not in test?","metadata":{}},{"cell_type":"code","source":"for col in feature_cols:\n    test_vals_not_in_train = set(te[col]) - set(tr[col])\n    train_vals_not_in_test = set(tr[col]) - set(te[col])\n    print(col, 'Test\\Train:', test_vals_not_in_train, 'Train\\Test:', train_vals_not_in_test)\n    if len(test_vals_not_in_train) > 0:\n        for val in test_vals_not_in_train:\n            print(val, 'Value has number of rows:', tr_te.loc[tr_te[col]==val].shape[0])\n            \n    if len(train_vals_not_in_test) > 0:\n        for val in train_vals_not_in_test:\n            print(val, 'Value has number of rows:', tr_te.loc[tr_te[col]==val].shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So we see that the maximum number of rows for a missing value is 11. In order to increase regularization and robustness, let's overwrite any values that have fewer than 20 samples with -99, just to represent the idea of \"rare value\".","metadata":{}},{"cell_type":"code","source":"for col in tqdm(feature_cols):\n    tr_te[col+'_modified'] = tr_te[col].copy()\n    for val in tr_te[col].unique():\n        val_mask = tr_te[col] == val\n        if tr_te.loc[val_mask].shape[0] < 20: # If fewer than 20 rows\n            tr_te.loc[val_mask, col+'_modified'] = -99 # Overwrite with -99 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additionally, because I believe these to all be categories, let's Label Encode them.","metadata":{}},{"cell_type":"code","source":"for col in tqdm(feature_cols):\n    col = col + '_modified'\n    tr_te[col] = tr_te[col].astype('category').cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Okay, now let's perform LightGBM.","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits = 5, shuffle = True,  random_state = 2021)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr = tr_te.loc[tr_te['target']!=-1].copy()\nte = tr_te.loc[tr_te['target']==-1].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_use = [f'feature_{x}_modified' for x in range(50)]\ntarget_col = 'target'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label the fold numbers in the train set\ntr['fold_number'] = -1 # Initialize fold number\nfor fold_number, (train_index, valid_index) in enumerate(skf.split(tr[cols_to_use], tr[target_col])):\n    tr.loc[valid_index, 'fold_number'] = fold_number","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Double check the folds are distributed evenly\ntr['fold_number'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr.groupby('fold_number')['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loop through all 5 folds","metadata":{}},{"cell_type":"code","source":"tr['oof_predictions_class0'] = 0\ntr['oof_predictions_class1'] = 0\ntr['oof_predictions_class2'] = 0\ntr['oof_predictions_class3'] = 0\n\nte['predictions_class0'] = 0\nte['predictions_class1'] = 0\nte['predictions_class2'] = 0\nte['predictions_class3'] = 0\n\ngain_imps = {}\nfor col in cols_to_use:\n    gain_imps[col] = 0 # Initialize to 0\n\nfor fold_number in [0,1,2,3,4]:\n    train_mask = tr['fold_number'] != fold_number\n    valid_mask = tr['fold_number'] == fold_number\n    \n    # Create the LightGBM Datasets\n    dtrain = lgb.Dataset(data = tr.loc[train_mask, cols_to_use], \n                         label = tr.loc[train_mask, target_col],\n                         categorical_feature = list(range(50))) # Pass the indices of the categorical features\n\n    dvalid = lgb.Dataset(data = tr.loc[valid_mask, cols_to_use], \n                         label = tr.loc[valid_mask, target_col],\n                         categorical_feature = list(range(50))) # Pass the indices of the categorical features\n\n    np.random.seed(fold_number)\n    # Define parameters\n    # Note a different seed for each fold so the models can be different \n    # (Model Diversity = more robust predictions)\n    params = {\n        'objective': 'multiclass',\n        'num_class': 4, # Only used in multiclass\n        'metric': ['multi_logloss','multi_error'], \n        'boosting_type': 'gbdt',\n        'num_leaves': 31, \n        'max_depth': 11, \n        'learning_rate': 0.05, \n        'feature_fraction': 0.5, \n        'seed': 2021 + fold_number,\n        'cat_l2': 10,\n        'cat_smooth': 10,\n        'verbose':-1\n    }\n    \n    print(f'=========== Fold {fold_number} ===========')\n    # Train the model\n    model = lgb.train(\n        params=params,\n        train_set = dtrain,\n        num_boost_round=1000,\n        valid_sets=[dtrain, dvalid],\n        verbose_eval = 50,\n        early_stopping_rounds=100,\n        categorical_feature=list(range(50))\n    )\n    \n    \n    # Make your predictions\n    oof_preds = model.predict(tr.loc[valid_mask, cols_to_use])\n    test_preds = model.predict(te[cols_to_use])\n    for class_num in range(4):\n        tr.loc[valid_mask, f'oof_predictions_class{class_num}'] = oof_preds[:,class_num]\n        te[f'predictions_class{class_num}'] += test_preds[:,class_num]\n        \n    \n    # If it's the first fold, make SHAP predictions so we can explain model\n    if fold_number == 0:\n        print(f'=========== Performing SHAP Explainer ===========')\n        # Commented this out because it takes too long...\n        # Maybe SHAP is slow with categorical values?\n        # shap_values = shap.Explainer(model).shap_values(tr[cols_to_use])\n        \n    # Save out the gain importances instead\n    for col, imp in zip(cols_to_use, model.feature_importance(importance_type='gain')):\n        gain_imps[col] += imp\n    \nfor class_num in range(4):\n    te[f'predictions_class{class_num}'] /= 5\n    \nfor col in cols_to_use:\n    gain_imps[col] /= 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html\ngain_imps_df = pd.DataFrame.from_dict(gain_imps, orient='index').reset_index(drop=False)\ngain_imps_df.columns = ['feat','imp']\ngain_imps_df = gain_imps_df.sort_values('imp',ascending=False)\n\n# Also attach the nunique for each\ngain_imps_df['nunique'] = gain_imps_df['feat'].apply(lambda x: tr_te[x].nunique())\ngain_imps_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's look at the log loss?","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import log_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_loss(y_true = tr['target'], \n         y_pred=tr[[f'oof_predictions_class{class_num}' for class_num in range(4)]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Can we improve this at all?\nI remember in one competition that taking the counts of each feature ended up improving the cross-validation. Maybe we can do a similar thing?","metadata":{}},{"cell_type":"code","source":"for col_num in tqdm(range(50)):\n    col = f'feature_{col_num}'\n    normalized_frequency = tr_te[col].value_counts(normalize=True).to_dict()\n    tr_te[col+'_count'] = tr_te[col].map(normalized_frequency)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_cols = [f'feature_{col_num}_count' for col_num in range(50)]\ntr_te['avg_count'] = tr_te[count_cols].mean(axis=1)\ntr_te['min_count'] = tr_te[count_cols].min(axis=1)\ntr_te['max_count'] = tr_te[count_cols].max(axis=1)\ntr_te['std_count'] = tr_te[count_cols].std(axis=1)\ntr_te['max_minus_min_count'] = tr_te['max_count'] - tr_te['min_count']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col_num in tqdm(range(50)):\n    col = f'feature_{col_num}'\n    print(col, tr_te[col].value_counts().index[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col_num in tqdm(range(50)):\n    col = f'feature_{col_num}'\n    tr_te[col+'_uncommon'] = pd.to_numeric(tr_te[col]!=0) # Since 0 is the most common class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uncommon_cols = [f'feature_{col_num}_uncommon' for col_num in range(50)]\ntr_te['avg_uncommonness'] = tr_te[uncommon_cols].mean(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aight, let's split back out and retry","metadata":{}},{"cell_type":"code","source":"tr = tr_te.loc[tr_te['target']!=-1].copy()\nte = tr_te.loc[tr_te['target']==-1].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_te","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_use = [f'feature_{x}_modified' for x in range(50)]+count_cols+['avg_count','min_count','max_count','std_count','max_minus_min_count']+uncommon_cols+['avg_uncommonness']\ntarget_col = 'target'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label the fold numbers in the train set\ntr['fold_number'] = -1 # Initialize fold number\nfor fold_number, (train_index, valid_index) in enumerate(skf.split(tr[cols_to_use], tr[target_col])):\n    tr.loc[valid_index, 'fold_number'] = fold_number","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr.groupby('fold_number')['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr['oof_predictions_class0'] = 0\ntr['oof_predictions_class1'] = 0\ntr['oof_predictions_class2'] = 0\ntr['oof_predictions_class3'] = 0\n\nte['predictions_class0'] = 0\nte['predictions_class1'] = 0\nte['predictions_class2'] = 0\nte['predictions_class3'] = 0\n\ngain_imps = {}\nfor col in cols_to_use:\n    gain_imps[col] = 0 # Initialize to 0\n\nfor fold_number in [0,1,2,3,4]:\n    train_mask = tr['fold_number'] != fold_number\n    valid_mask = tr['fold_number'] == fold_number\n    \n    # Create the LightGBM Datasets\n    dtrain = lgb.Dataset(data = tr.loc[train_mask, cols_to_use], \n                         label = tr.loc[train_mask, target_col],\n                         categorical_feature = list(range(50))) # Pass the indices of the categorical features\n\n    dvalid = lgb.Dataset(data = tr.loc[valid_mask, cols_to_use], \n                         label = tr.loc[valid_mask, target_col],\n                         categorical_feature = list(range(50))) # Pass the indices of the categorical features\n\n    np.random.seed(fold_number)\n    # Define parameters\n    # Note a different seed for each fold so the models can be different \n    # (Model Diversity = more robust predictions)\n    params = {\n        'objective': 'multiclass',\n        'num_class': 4, # Only used in multiclass\n        'metric': ['multi_logloss','multi_error'], \n        'boosting_type': 'gbdt',\n        'num_leaves': 31, \n        'max_depth': 11, \n        'learning_rate': 0.05, \n        'feature_fraction': 0.5, \n        'seed': 2021 + fold_number,\n        'cat_l2': 10,\n        'cat_smooth': 10,\n        'verbose':-1\n    }\n    \n    print(f'=========== Fold {fold_number} ===========')\n    # Train the model\n    model = lgb.train(\n        params=params,\n        train_set = dtrain,\n        num_boost_round=1000,\n        valid_sets=[dtrain, dvalid],\n        verbose_eval = 50,\n        early_stopping_rounds=100,\n        categorical_feature=list(range(50))\n    )\n    \n    \n    # Make your predictions\n    oof_preds = model.predict(tr.loc[valid_mask, cols_to_use])\n    test_preds = model.predict(te[cols_to_use])\n    for class_num in range(4):\n        tr.loc[valid_mask, f'oof_predictions_class{class_num}'] = oof_preds[:,class_num]\n        te[f'predictions_class{class_num}'] += test_preds[:,class_num]\n        \n    \n    # If it's the first fold, make SHAP predictions so we can explain model\n    if fold_number == 0:\n        print(f'=========== Performing SHAP Explainer ===========')\n        # Commented this out because it takes too long...\n        # Maybe SHAP is slow with categorical values?\n        # shap_values = shap.Explainer(model).shap_values(tr[cols_to_use])\n        \n    # Save out the gain importances instead\n    for col, imp in zip(cols_to_use, model.feature_importance(importance_type='gain')):\n        gain_imps[col] += imp\n    \nfor class_num in range(4):\n    te[f'predictions_class{class_num}'] /= 5\n    \nfor col in cols_to_use:\n    gain_imps[col] /= 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# And study the gain importances:","metadata":{}},{"cell_type":"code","source":"# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html\ngain_imps_df = pd.DataFrame.from_dict(gain_imps, orient='index').reset_index(drop=False)\ngain_imps_df.columns = ['feat','imp']\ngain_imps_df = gain_imps_df.sort_values('imp',ascending=False)\n\n# Also attach the nunique for each\ngain_imps_df['nunique'] = gain_imps_df['feat'].apply(lambda x: tr_te[x].nunique())\ngain_imps_df.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Least important:\ngain_imps_df.tail(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get our new log loss:","metadata":{}},{"cell_type":"code","source":"log_loss(y_true = tr['target'], \n         y_pred=tr[[f'oof_predictions_class{class_num}' for class_num in range(4)]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save out predictions","metadata":{}},{"cell_type":"code","source":"saveout = te[['id','predictions_class0','predictions_class1','predictions_class2','predictions_class3']]\nsaveout.columns = ['id','Class_1','Class_2','Class_3','Class_4']\nsaveout.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View predictions\nsaveout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}