{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://github.com/SauravMaheshkar/Tabular-Playground-Series-May-2021/blob/main/assets/Banner.png?raw=true)","metadata":{}},{"cell_type":"markdown","source":"# Table of Content\n\n1. [Packages üì¶ and Basic Setup](#basic)\n2. [Pre-Processing üëéüèª -> üëç](#pre)\n3. [The Model üë∑‚Äç‚ôÄÔ∏è](#model)\n4. [Training üí™üèª](#train)","metadata":{}},{"cell_type":"markdown","source":"<a id = 'basic'></a>\n<h1 style=\"background-color:black;color:white;padding:10px; height: 50px;\"> <center>Packages üì¶ and Basic Setup</center> </h1>\n\nInitiially introduced in the paper titled [**\"TabNet: Attentive Interpretable Tabular Learning\"**](https://arxiv.org/pdf/1908.07442.pdf), TabNet is a novel high-performance and interpretable canonical deep tabular data learning architecture. It uses sequential attention to choose which features to reason\nfrom at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features.\n\n![](https://github.com/SauravMaheshkar/Tabular-Playground-Series-May-2021/blob/main/assets/tabnet.png?raw=true)\n\nA Pytorch Implementation of Tabnet has been made available by the team at [dreamquark-ai](https://github.com/dreamquark-ai/tabnet). We can simply install the package using `pip`.\n\n```\npip install pytorch-tabnet\n```\n\nThis kernel aims to be a starter notebook for you to add your own pre-processing / parameters.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pytorch-tabnet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\n\ntrain = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'pre'></a>\n<h1 style=\"background-color:black;color:white;padding:10px; height: 50px;\"> <center>Pre-Processing üëéüèª -> üëç</center> </h1>","metadata":{}},{"cell_type":"markdown","source":"Upon a closer look, we realize that most features are left skewed in this dataset. Thus, Normalization seems ideal.\n\n<center><img src=\"https://github.com/SauravMaheshkar/Tabular-Playground-Series-May-2021/blob/main/assets/feature_distribution.png?raw=true\"></center>\n\n> Image taken from [TPS-May: Categorical EDA](https://www.kaggle.com/subinium/tps-may-categorical-eda)","metadata":{}},{"cell_type":"code","source":"# Normalization\nfor i in range(50):\n    mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n    train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)/std)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll split the dataset into a **80-10-10** split for training, validation and test respectively.","metadata":{}},{"cell_type":"code","source":"# Train, Test, Validation Split\ntarget = 'target'\nif \"Set\" not in train.columns:\n    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n\ntrain_indices = train[train.Set==\"train\"].index\nvalid_indices = train[train.Set==\"valid\"].index\ntest_indices = train[train.Set==\"test\"].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Fill NaN values + optional script for `object` columns.","metadata":{}},{"cell_type":"code","source":"nunique = train.nunique()\ntypes = train.dtypes\n\ncategorical_columns = []\ncategorical_dims =  {}\nfor col in train.columns:\n    if types[col] == 'object':\n        print(col, train[col].nunique())\n        l_enc = LabelEncoder()\n        train[col] = l_enc.fit_transform(train[col].values)\n        categorical_columns.append(col)\n        categorical_dims[col] = len(l_enc.classes_)\n    else:\n        train.fillna(train.loc[train_indices, col].mean(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='model'></a>\n<h1 style=\"background-color:black;color:white;padding:10px; height: 50px;\"> <center>The Model üë∑‚Äç‚ôÄÔ∏è</center> </h1>","metadata":{}},{"cell_type":"code","source":"# Columns not to use\nunused_feat = ['Set']\n\n# Features to Use\nfeatures = [ col for col in train.columns if col not in unused_feat+[target]] \n\nX_train = train[features].values[train_indices]\ny_train = train[target].values[train_indices]\n\nX_valid = train[features].values[valid_indices]\ny_valid = train[target].values[valid_indices]\n\nX_test = train[features].values[test_indices]\ny_test = train[target].values[test_indices]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic model parameters\nmax_epochs = 30\nbatch_size = 1024\nopt = torch.optim.Adam # Optimizer\nopt_params = dict(lr=1e-3)\nsch = torch.optim.lr_scheduler.StepLR # LR Scheduler\nsch_params = {\"step_size\":10, \"gamma\":0.9}\nmask = 'entmax'\nworkers = 2 # For torch DataLoader\nsample_type = 1 # For automated sampling with inverse class occurrences \nvirtual_batch = 128 # Size of the mini batches used for \"Ghost Batch Normalization\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The paper highlights a semi-supervised pre-training method which is available via the `TabNetPretrainer` class. We'll use this pretrain this model and use it to boost the tabnet model performance as a unsupervised prior.","metadata":{}},{"cell_type":"code","source":"unsupervised_model = TabNetPretrainer(\n    optimizer_fn = opt,\n    optimizer_params = opt_params,\n    mask_type = mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = TabNetClassifier(gamma = 1.5,\n                       lambda_sparse = 1e-4,\n                       optimizer_fn = opt,\n                       optimizer_params = opt_params,\n                       scheduler_fn = sch,\n                       scheduler_params = sch_params,\n                       mask_type = mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'train'></a>\n<h1 style=\"background-color:black;color:white;padding:10px; height: 50px;\"> <center>Training üí™üèª</center> </h1>","metadata":{}},{"cell_type":"code","source":"unsupervised_model.fit(\n    X_train=X_train,\n    eval_set=[X_valid],\n    pretraining_ratio=0.8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train=X_train, \n    y_train=y_train,\n    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n    eval_name=['train', 'val'],\n    eval_metric=[\"logloss\", 'balanced_accuracy'],\n    max_epochs=max_epochs , patience=15,\n    batch_size=batch_size,\n    virtual_batch_size=virtual_batch,\n    num_workers=workers,\n    weights=sample_type,\n    drop_last=False,\n    from_unsupervised=unsupervised_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot losses\nplt.plot(clf.history['loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot auc\nplt.plot(clf.history['train_logloss'])\nplt.plot(clf.history['val_logloss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:black;color:white;padding:10px; height: 50px;\"> <center>Submission</center> </h1>","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\ntest_indices = test.index\ntest_ds = test[features].values[test_indices]\n\nsample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')\nsample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = clf.predict_proba(test_ds)\nsample_submission.to_csv('tabnet_submission.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}