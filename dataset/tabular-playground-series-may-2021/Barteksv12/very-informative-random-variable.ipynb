{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"It is quite popular to add random feature to data and observe which features have greater feature importance and which have smaller. But the results in this competition are quite interesting","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SPLITS = 5\n\ndef seed(seed=42):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv').drop(['id'], axis=1)\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv').drop(['id'], axis=1)\nsample_sub = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(['target'], axis = 1)\ny = train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\ntrain = train.assign(target = le.fit_transform(train.target))\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_eval_lgb(model_fn):\n    oof = np.zeros((len(train), 4))\n    test_preds = np.zeros((len(test), 4))\n    feature_importace = pd.DataFrame()\n\n    \n    cv = StratifiedKFold(N_SPLITS, shuffle=True, random_state = 42)\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n        model = model_fn()\n        model = model.fit(\n            X.iloc[train_idx],\n            y.iloc[train_idx],\n            eval_set=[(X.iloc[val_idx], y.iloc[val_idx])],\n            eval_metric='multi_logloss',\n            early_stopping_rounds = 100,verbose=250)\n        \n        tmp_oof = model.predict_proba(X.iloc[val_idx].values)\n        oof[val_idx] += tmp_oof\n        test_preds += model.predict_proba(test.values) / N_SPLITS\n        \n        fe = pd.DataFrame()\n        fe['feature'] = model.feature_name_\n        fe['importance'] = model.feature_importances_\n        feature_importace = feature_importace.append(fe)\n        print(f'fold {fold + 1} logloss = {log_loss(y.iloc[val_idx], tmp_oof)}')\n    \n    print(f'oof logloss = {log_loss(y.values, oof)}')\n    return test_preds, feature_importace","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Original features","metadata":{}},{"cell_type":"code","source":"params = {\n    'num_iterations': 20_000,\n    'learning_rate': 0.05,\n    'max_depth': 10,\n    'num_leaves' : 63,\n    'objective': 'multiclass',\n    'metric': 'multi_logloss',\n    'bagging_seed': 42,\n    'boosting_type': 'gbdt',\n    'is_unbalance': True\n}\n\nmodel_fn  = lambda : LGBMClassifier(**params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds, feature_importace = train_and_eval_lgb(model_fn)\norder = list(feature_importace.groupby('feature').agg('mean').sort_values('importance', ascending=False).index)\n\nplt.figure(figsize=(16,8))\np = sns.barplot(x='feature', y='importance', data = feature_importace, order = order)\nplt.title(\"LGM Classifier importance\")\nplt.tight_layout()\n_ = p.set_xticklabels(p.get_xticklabels(), rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add random feature","metadata":{}},{"cell_type":"code","source":"X['random'] = np.random.random((len(X)))\ntest['random'] = np.random.random((len(test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds, feature_importace = train_and_eval_lgb(model_fn)\norder = list(feature_importace.groupby('feature').agg('mean').sort_values('importance', ascending=False).index)\n\nplt.figure(figsize=(16,8))\np = sns.barplot(x='feature', y='importance', data = feature_importace, order = order)\nplt.title(\"LGM Classifier importance\")\nplt.tight_layout()\n_ = p.set_xticklabels(p.get_xticklabels(), rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}