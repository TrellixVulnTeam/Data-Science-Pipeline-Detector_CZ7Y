{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport lightgbm as lgb\nimport shap\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpful function ","metadata":{}},{"cell_type":"code","source":"def create_missing_table(input_dataframe: pd.DataFrame):\n    total = len(input_dataframe)\n    naCount = input_dataframe.isnull().sum()\n    zeroCount = len(input_dataframe) - input_dataframe.fillna(1).astype(bool).sum()\n    zeroPercent = (zeroCount/len(input_dataframe)*100).round().map(lambda n: '{0:.1f} %'.format(n))\n    naPercent = (input_dataframe.isnull().sum()/len(input_dataframe)*100).round().map(lambda n: '{0:.1f} %'.format(n))\n    uniqCount = input_dataframe.nunique()\n    hitRate = (input_dataframe.notnull().sum()/len(input_dataframe)*100).round().map(lambda n: '{0:.1f} %'.format(n))\n    return pd.DataFrame({'count_total': total, 'count_unique': uniqCount, 'count_zero':zeroCount,'percentile_zero':zeroPercent, 'count_missing': naCount,'percentile_missing':naPercent, 'hit_rate':hitRate})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def describe_category(dataframe, column_name, ignore_zero=False, figsize=(11,7)):\n    \"\"\"\n    plot describe category with percentage\n    \"\"\"\n    if ignore_zero:\n        dataframe = dataframe[dataframe[column_name] != 0]\n    value_count = dataframe[column_name].value_counts().sort_index()\n    df_value_count = pd.DataFrame({column_name: value_count.index, \"count\": value_count.values})\n    sum_class = df_value_count[\"count\"].sum()\n    df_value_count[\"percentage\"] = df_value_count[\"count\"]/sum_class*100\n    display(df_value_count)\n    \n    fig, ax = plt.subplots(figsize = figsize)\n    ax = sns.barplot(data=df_value_count, x=column_name, y=\"count\")\n    ax.set_ylim(0, df_value_count[\"count\"].max()*1.2)\n    for p, percentage in zip(ax.patches, list(df_value_count[\"percentage\"])):\n        ax.annotate(\"%.2f\" % percentage +\" %\", (p.get_x() + p.get_width() / 2., p.get_height()),\n             ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')  #vertical bars\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/tabular-playground-series-may-2021/train.csv\"\ntest_path = \"/kaggle/input/tabular-playground-series-may-2021/test.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training data","metadata":{}},{"cell_type":"markdown","source":"## 1D eda","metadata":{}},{"cell_type":"code","source":"train_df[\"target\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is multi-classification problem.<br>\nEach data point have 1 class only. <br>\nClass are not balance.<br>","metadata":{}},{"cell_type":"markdown","source":"## Check zeros and missing","metadata":{}},{"cell_type":"code","source":"create_missing_table(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A lot of zero. Most feature have > 80% zero.\n","metadata":{}},{"cell_type":"markdown","source":"Let see value of some feature","metadata":{}},{"cell_type":"code","source":"train_df[\"feature_1\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"feature_10\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"They have very small number of unique value. Seem like all category","metadata":{}},{"cell_type":"code","source":"# describe_category(train_df, \"feature_10\", ignore_zero=True, figsize=(20,7))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Draw distribution of feature","metadata":{}},{"cell_type":"code","source":"feature_list = list(train_df.columns)\nfeature_list.remove(\"id\")\nfeature_list.remove(\"target\")\nfeature_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature_name in feature_list:\n    print(\"=============  \" + feature_name + \"  ===================\")\n    describe_category(train_df, feature_name, ignore_zero=True, figsize=(20,7))\n    print(\"=========================================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Negative value\n\nFeature 42, 39, 38, 35, 31, 30, 19","metadata":{}},{"cell_type":"markdown","source":"# 2D ","metadata":{}},{"cell_type":"markdown","source":"## Correlation","metadata":{}},{"cell_type":"code","source":"train_corr = train_df.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(train_corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(25, 20))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(train_corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We do not see strong correlation between feature.","metadata":{}},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"markdown","source":"Let use LightGBM because it train fast and decent performance. ","metadata":{}},{"cell_type":"code","source":"lgbm_params = {\n    'boosting': 'gbdt',\n    'learning_rate': 0.01, \n    'num_leaves': 300, \n    'objective': 'multiclass',\n    'num_class':4,\n    'metric': 'multi_logloss',\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"def convert_text_to_class(str_class):\n    if str_class == \"Class_1\":\n        return 0\n    elif str_class == \"Class_2\":\n        return 1\n    elif str_class == \"Class_3\":\n        return 2\n    elif str_class == \"Class_4\":\n        return 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df[feature_list]\ny = train_df[\"target\"].apply(convert_text_to_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for feature_name in feature_list:\n#     X[feature_name] = X[feature_name].astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = lgb.Dataset(X, label=y, free_raw_data=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5 Fold cross validation ","metadata":{}},{"cell_type":"code","source":"boost_round = 200\ncv_result = lgb.cv(lgbm_params, data, num_boost_round=boost_round, early_stopping_rounds=20, nfold=5, verbose_eval=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"CV 5 Fold result\")\nprint(\"multi_logloss-mean :\" ,cv_result[\"multi_logloss-mean\"][-1])\nprint(\"multi_logloss-stdv :\" ,cv_result[\"multi_logloss-stdv\"][-1])\nprint(cv_result.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Shape value ","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=3041975)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\nval_data = lgb.Dataset(X_val, label=y_val, reference=train_data ,free_raw_data=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nboost_round = 500\nmodel = lgb.train(lgbm_params, train_data, valid_sets=[val_data], num_boost_round = boost_round, verbose_eval=100, early_stopping_rounds=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nexplainer = shap.TreeExplainer(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_very_small = X.sample(500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nshap_values = explainer.shap_values(X_very_small)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], X_very_small, plot_type='dot', max_display=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_df[feature_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = pd.DataFrame(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = y_test.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"id\"] = test_df[\"id\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.columns = [\"id\", \"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = submission[[\"id\", \"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}