{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nimport lightgbm as lgb\nimport plotly.express as px\n!pip install bhtsne\nfrom bhtsne import tsne\n!pip install umap-learn\nimport umap\nimport scipy.sparse\nfrom lightgbm import plot_importance","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/tabular-playground-series-may-2021/'\nsample = pd.read_csv(DATA_PATH + 'sample_submission.csv')\ntrain = pd.read_csv(DATA_PATH + 'train.csv')\n\n# Drop \"id\" as well since lightgbm used it as the most important feature\n# https://www.kaggle.com/mstkmyhr/2021-05-15-tps-baseline-submission-by-lightgbm/edit/run/62983993\ntrain_x = train.drop(['id', 'target'], axis=1)\ntrain_y = train['target']\n# Convert target values to integer (e.g. Convert \"Class_1\" into 0)\ntrain_y = train_y.map(lambda x: int(x.split('_')[1]) - 1)\n\ntest_x = pd.read_csv(DATA_PATH + 'test.csv')\ntest_x = test_x.drop(['id'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['id'], axis=1).describe().T\\\n        .style.bar(subset=['mean'], color=px.colors.qualitative.G10[0])\\\n        .background_gradient(subset=['std'], cmap='Greens')\\\n        .background_gradient(subset=['50%'], cmap='BuGn')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying t-SNE takes forever...\n# Y = tsne(train_x.astype(np.float64))\n# plt.scatter(Y[:, 0], Y[:, 1], c=train_y)\n# plt.show()\n\n# Instead, use UMAP\nreducer = umap.UMAP(\n    n_components=2,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nembedding = reducer.fit_transform(train_x)\nembedding.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(\n    embedding[:, 0],\n    embedding[:, 1],\n    c=train_y,\n    s=.5)\nplt.gca().set_aspect('equal', 'datalim')\nplt.colorbar(boundaries=np.arange(5)-0.5).set_ticks(np.arange(4))\nplt.title('UMAP projection of the dataset', fontsize=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- あまり良い特徴量が得られたような気はしないが、特徴量に追加してみる。","metadata":{}},{"cell_type":"code","source":"reducer = umap.UMAP(\n    n_components=2\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nembedding_test = reducer.fit_transform(test_x)\nembedding_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x['umap_x'] = embedding[:, 0]\ntrain_x['umap_y'] = embedding[:, 1]\ntest_x['umap_x'] = embedding_test[:, 0]\ntest_x['umap_y'] = embedding_test[:, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'objective': 'multiclassova',\n    'verbose': -1,\n    'seed': 71,\n    'metrics': 'multi_logloss',\n    'num_class': 4\n}\nnum_round = 100\n\nscores = []\nkf = KFold(n_splits=4, shuffle=True, random_state=71)\nfor tr_idx, va_idx in kf.split(train_x):\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    \n    lgb_train = lgb.Dataset(tr_x, tr_y)\n    lgb_eval = lgb.Dataset(va_x, va_y)\n    model = lgb.train(params, lgb_train, num_boost_round=num_round, valid_sets=[lgb_train, lgb_eval])\n    va_pred = model.predict(va_x)\n    score = log_loss(va_y, va_pred)\n    scores.append(score)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'logloss: {np.mean(scores):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_train = lgb.Dataset(train_x, train_y)\nmodel = lgb.train(params, lgb_train, num_boost_round=num_round)\npred = model.predict(test_x)\n\ndf_pred = pd.DataFrame(pred, columns=['Class_1', 'Class_2', 'Class_3', 'Class_4'])\ndf_pred['id'] = pd.read_csv(DATA_PATH + 'test.csv').iloc[:, 0]\nsubmission = df_pred[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4']]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(model, figsize=(8,16), importance_type='split')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(model, figsize=(8,16), importance_type='gain')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}