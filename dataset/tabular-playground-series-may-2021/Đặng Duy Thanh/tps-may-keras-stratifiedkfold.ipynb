{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Simple Keras Pipeline\n\n- EDA : https://www.kaggle.com/subinium/tps-may-categorical-eda","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras as keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, learning_curve, cross_val_score\nfrom sklearn.metrics import confusion_matrix, log_loss, make_scorer, accuracy_score\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')\n\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalization\n\nThe data needs to be normalized to fit into the DNN.","metadata":{}},{"cell_type":"code","source":"# # for i in range(50):\n# #     mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n# #     train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n# #     test[f'feature_{i}'] = test[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n\nfeatures = [col for col in test.columns if col != \"id\" and col != \"target\"]\n\n# from sklearn.preprocessing import StandardScaler\n# scaler = StandardScaler().fit(train[features])\n# train[features] = scaler.transform(train[features])\n# test[features] = scaler.transform(test[features])\n\n# # from sklearn import preprocessing\n# # min_max_scaler = preprocessing.MinMaxScaler()\n# # train[features] = min_max_scaler.fit_transform(train[features])\n# # test[features] = min_max_scaler.fit_transform(test[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_dict = {val:idx for idx, val in enumerate(sorted(train['target'].unique()))}\ntrain['target'] = train['target'].map(label_dict)\n\ntarget = train['target']\ntrain.drop(['target'], inplace=True, axis=1)\n\n# train = train.values\n# target = target.values\n# target =  to_categorical(target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/nishantdhingra/cb-lgbm-xgb-feature-importance-and-interactions","metadata":{}},{"cell_type":"code","source":"drop_features = ['feature_3']\ntrain_new = train.drop(drop_features,axis=1)\ntest_new =test.drop(drop_features,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_features(df, features):\n    for i in range (len(features)):\n        for j in range(i+1, len(features)):\n            df[str(features[i])+'+'+str(features[j])] = df[str(features[i])]+df[str(features[j])]\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['feature_2','feature_13']\ntrain_new = gen_features(train_new, features)\ntest_new = gen_features(test_new, features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_features = train_new.columns\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(train_new[new_features])\ntrain_new[new_features] = scaler.transform(train_new[new_features])\ntest_new[new_features] = scaler.transform(test_new[new_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model (Keras)","metadata":{}},{"cell_type":"markdown","source":"### Initialization","metadata":{}},{"cell_type":"code","source":"num_features = len(new_features)\nnum_classes = 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The structure of the model can be changed freely, and the model is an MLP model using only Dense, Batchnormalization, Dropout.","metadata":{}},{"cell_type":"code","source":"def CreateModel():\n    hidden_units = [150, 150, 150]\n    dropout_rates = [0.2, 0.2, 0.2, 0.2]\n    \n    inp = tf.keras.layers.Input(shape=(num_features,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(\"relu\")(x)\n#         x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n\n    x = tf.keras.layers.Dense(num_classes)(x)\n    out = tf.keras.layers.Activation(\"softmax\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    \n#     model = Sequential([\n#         Dense(512, input_dim=num_features, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.3),\n#         Dense(256, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.2),\n#         Dense(128, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.2),\n#         Dense(num_classes, activation='softmax')\n#     ])\n    model.compile(loss='mean_squared_logarithmic_error', optimizer=\"adam\", metrics='accuracy')\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit\n\nI didn't do a lot of Epochs for fast execution, and the batch size and epoch can be adjusted.\n\nWith the GPU, you can run the model much faster.","metadata":{}},{"cell_type":"code","source":"N_FOLDS = 5\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = np.zeros((train_new.shape[0],4))\npred = np.zeros((test_new.shape[0],4))\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train_new, target)):\n    print(f\"===== FOLD {fold} =====\")       \n    X_train = train_new.iloc[tr_idx] # X_train\n    y_train = target.iloc[tr_idx] # y_train\n    X_val = train_new.iloc[ts_idx] # X_valid \n    y_val = target.iloc[ts_idx] # y_valid\n    \n    X_train = X_train.values\n    X_val = X_val.values\n    y_train = y_train.values\n    y_val = y_val.values\n    y_train =  to_categorical(y_train)\n    y_val =  to_categorical(y_val)\n\n    model = CreateModel()\n    model.fit(X_train, y_train,\n          batch_size = 100, epochs = 20, verbose = 2,\n          validation_data=(X_val, y_val));\n    \n    oof[ts_idx] = model.predict(X_val)\n    pred += model.predict(test) / N_FOLDS\n    \n    score = log_loss(y_val, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n\nscore = log_loss(target, oof)\nprint(f\"Score total {score}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Output","metadata":{}},{"cell_type":"code","source":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(f'submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}