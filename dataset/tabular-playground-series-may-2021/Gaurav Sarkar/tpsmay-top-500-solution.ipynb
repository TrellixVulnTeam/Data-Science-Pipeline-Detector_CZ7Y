{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data= pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape[0])\nprint(data.shape[1])\n\nprint(data.columns)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport time\nimport warnings\nimport numpy as np\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import normalize\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics._classification import accuracy_score, log_loss\nfrom sklearn.linear_model import SGDClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom scipy.sparse import hstack\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import StratifiedKFold \nfrom collections import Counter, defaultdict\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport math\nfrom sklearn.metrics import normalized_mutual_info_score\nfrom sklearn.ensemble import RandomForestClassifier\nwarnings.filterwarnings(\"ignore\")\n\nfrom mlxtend.classifier import StackingClassifier\n\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.DataFrame(data.drop(\"target\", axis = 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X[['feature_38','feature_14','feature_31','feature_15','feature_34','feature_28','feature_9','feature_19','feature_24','feature_48','feature_7','feature_35','feature_17','feature_6','feature_43','feature_40','feature_12','feature_42','feature_3','feature_18','feature_37','feature_41','feature_49','feature_33']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X['sum_feature'] = X['feature_39'] + X['feature_23']+X['feature_25']+X['feature_46']+X['feature_16']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data['Employed'] = data['Employed'].replace('Fulltime',1).replace('Parttime',0)\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data['Employed'] = data['Employed'].replace('Fulltime',1).replace('Parttime',0)\n\nlencoder = LabelEncoder()\ny = pd.DataFrame(lencoder.fit_transform(data['target']), columns=['target'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2)\n\nx_train, x_cv, y_train, y_cv = train_test_split(X_train, Y_train, stratify=Y_train, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape[0],x_cv.shape[0],X_test.shape[0])\nx_train.head()\ny_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\ntrain_class_distribution = pd.DataFrame(y_train).value_counts()\ntest_class_distribution = pd.DataFrame(Y_test).value_counts()\ncv_class_distribution = pd.DataFrame(y_cv).value_counts()\nmy_colors = 'rgbkymc'\ntrain_class_distribution.plot(kind='bar')\nplt.xlabel('Class')\nplt.ylabel('Data points per Class')\nplt.title('Distribution of yi in train data')\nplt.grid()\nplt.show()\n\nmy_colors = 'rgbkymc'\ntest_class_distribution.plot(kind='bar')\nplt.xlabel('Class')\nplt.ylabel('Data points per Class')\nplt.title('Distribution of yi in train data')\nplt.grid()\nplt.show()\n\nmy_colors = 'rgbkymc'\ncv_class_distribution.plot(kind='bar')\nplt.xlabel('Class')\nplt.ylabel('Data points per Class')\nplt.title('Distribution of yi in train data')\nplt.grid()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom matplotlib import pyplot\n\npyplot.figure(figsize=(50,30))\nmodel = XGBClassifier()\nmodel.fit(x_train, y_train)\nplot_importance(model, max_num_features=25)\n\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = [10 ** x for x in range(-5, 1)] # hyperparam for SGD classifier.\n\n\n\ncv_log_error_array=[]\nfor i in alpha:\n    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42, class_weight='balanced')\n    clf.fit(x_train, y_train)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(x_train, y_train)\n    predict_y = sig_clf.predict_proba(x_cv)\n    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n\nfig, ax = plt.subplots()\nax.plot(alpha, cv_log_error_array,c='g')\nfor i, txt in enumerate(np.round(cv_log_error_array,3)):\n    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\nplt.grid()\nplt.title(\"Cross Validation Error for each alpha\")\nplt.xlabel(\"Alpha i's\")\nplt.ylabel(\"Error measure\")\nplt.show()\n\n\nbest_alpha = np.argmin(cv_log_error_array)\nclf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42, class_weight=\"balanced\")\nclf.fit(x_train, y_train)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(x_train, y_train)\n\npredict_y = sig_clf.predict_proba(x_train)\nprint('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\npredict_y = sig_clf.predict_proba(x_cv)\nprint('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\npredict_y = sig_clf.predict_proba(X_test)\nprint('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(Y_test, predict_y, labels=clf.classes_, eps=1e-15))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SGDClassifier(alpha=0.1, penalty='l2', loss='log', random_state=42, )\nclf.fit(x_train, y_train)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(x_train, y_train)\n#predict_y = sig_clf.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = sig_clf.predict(test)\noutputArray = []\nid = 100000\nfor i in range(len(result)):\n    predict = result[i]\n    innerArray = [id, predict[0], predict[1], predict[2], predict[3]]\n    outputArray.append(innerArray)\n    id += 1\ndf = pd.DataFrame(outputArray, columns=['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4'])\ndf.to_csv(path_or_buf='submission.csv', index=False)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsub = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv\", index_col=\"id\")\nsub[[\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\"]] = sig_clf.predict_proba(test)\nsub.to_csv(\"lr_onehot.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nalpha = [10,50,100,200,500,1000]\nmax_depth = [2,3,5,10]\ncv_log_error_array = []\nfor i in alpha:\n    for j in max_depth:\n        print(\"for n_estimators =\", i,\"and max depth = \", j)\n        clf = LGBMClassifier(n_estimators=i, criterion='gini', max_depth=j, random_state=42, n_jobs=-1)\n        clf.fit(x_train, y_train)\n        sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n        sig_clf.fit(x_train, y_train)\n        sig_clf_probs = sig_clf.predict_proba(x_cv)\n        cv_log_error_array.append(log_loss(y_cv, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n        print(\"Log Loss :\",log_loss(y_cv, sig_clf_probs)) \n\nbest_alpha = np.argmin(cv_log_error_array)\nclf = LGBMClassifier(n_estimators=alpha[int(best_alpha/4)], , max_depth=max_depth[int(best_alpha%4)], random_state=42, n_jobs=-1)\nclf.fit(x_train, y_train)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(x_train, y_train)\n\npredict_y = sig_clf.predict_proba(x_train)\nprint('For values of best alpha = ', alpha[int(best_alpha/4)], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\npredict_y = sig_clf.predict_proba(x_cv)\nprint('For values of best alpha = ', alpha[int(best_alpha/4)], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\npredict_y = sig_clf.predict_proba(X_test)\nprint('For values of best alpha = ', alpha[int(best_alpha/4)], \"The test log loss is:\",log_loss(Y_test, predict_y, labels=clf.classes_, eps=1e-15))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclf = LGBMClassifier(n_estimators=alpha[int(best_alpha/4)], max_depth=max_depth[int(best_alpha%4)], random_state=42, n_jobs=-1)\nclf.fit(x_train, y_train)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsub = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv\", index_col=\"id\")\nsub[[\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\"]] = sig_clf.predict_proba(test)\nsub.to_csv(\"light1234.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['feature_38','feature_14','feature_31','feature_15','feature_34','feature_28','feature_9','feature_19','feature_24','feature_48','feature_7','feature_35','feature_17','feature_6','feature_43','feature_40','feature_12','feature_42','feature_3','feature_18','feature_37','feature_41','feature_49','feature_33']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test['sum_feature'] = test['feature_39'] + test['feature_23']+test['feature_25']+test['feature_46']+test['feature_16']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install lightgbm\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}