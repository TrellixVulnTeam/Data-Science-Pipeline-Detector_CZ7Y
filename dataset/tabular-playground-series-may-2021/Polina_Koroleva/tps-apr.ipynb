{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.041687,"end_time":"2021-05-08T13:07:37.140825","exception":false,"start_time":"2021-05-08T13:07:37.099138","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import SGDClassifier as SGD\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.semi_supervised import SelfTrainingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import log_loss, f1_score","metadata":{"papermill":{"duration":1.123556,"end_time":"2021-05-08T13:07:38.287734","exception":false,"start_time":"2021-05-08T13:07:37.164178","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для работы с [нейронной сетью](https://www.tensorflow.org/) сделаем соответствующие импорты","metadata":{"papermill":{"duration":0.022666,"end_time":"2021-05-08T13:07:38.333645","exception":false,"start_time":"2021-05-08T13:07:38.310979","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import metrics","metadata":{"papermill":{"duration":5.408484,"end_time":"2021-05-08T13:07:43.764991","exception":false,"start_time":"2021-05-08T13:07:38.356507","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предобработка данных","metadata":{"papermill":{"duration":0.02285,"end_time":"2021-05-08T13:07:43.810807","exception":false,"start_time":"2021-05-08T13:07:43.787957","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Посмотрим на входные данные, при необходимости предобработаем их","metadata":{"papermill":{"duration":0.022632,"end_time":"2021-05-08T13:07:43.856723","exception":false,"start_time":"2021-05-08T13:07:43.834091","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv')\ndf_train.head()","metadata":{"papermill":{"duration":1.045828,"end_time":"2021-05-08T13:07:44.925587","exception":false,"start_time":"2021-05-08T13:07:43.879759","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"papermill":{"duration":0.069101,"end_time":"2021-05-08T13:07:45.018672","exception":false,"start_time":"2021-05-08T13:07:44.949571","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как мы видим, отсутствуют пустые значения. Посмотрим на сами значения","metadata":{"papermill":{"duration":0.024283,"end_time":"2021-05-08T13:07:45.067872","exception":false,"start_time":"2021-05-08T13:07:45.043589","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"Y unique: {}\".format(np.unique(df_train['target'])))\nfor i in range(50):\n    print(\"feature_{} unique: {}\".format(i, np.unique(df_train['feature_{}'.format(i)])))","metadata":{"papermill":{"duration":0.294053,"end_time":"2021-05-08T13:07:45.386523","exception":false,"start_time":"2021-05-08T13:07:45.09247","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как мы видим, предобработки требуют только метки классов. Предположим, что значения признаков $feature_k, k \\in [0, 49]$ отсортированы по возрастанию значимости, то есть если $feature_k[i] > feature_k[j]$, то $i$-ый объект более значим по признаку $k$, чем $j$-ый объект.","metadata":{"papermill":{"duration":0.030449,"end_time":"2021-05-08T13:07:45.443005","exception":false,"start_time":"2021-05-08T13:07:45.412556","status":"completed"},"tags":[]}},{"cell_type":"code","source":"mapping = {\n    'Class_1': 0,\n    'Class_2': 1,\n    'Class_3': 2,\n    'Class_4': 3,\n}\ndf_train['target'] = df_train['target'].map(mapping)\ndf_train['target']","metadata":{"papermill":{"duration":0.04939,"end_time":"2021-05-08T13:07:45.517599","exception":false,"start_time":"2021-05-08T13:07:45.468209","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = df_train['target']\nX_train = df_train.drop(['target', 'id'], axis=1)\nX_test = df_test.drop('id', axis=1)\ny_sparse_train = np.zeros(4 * y_train.shape[0]).reshape((-1, 4))\nfor y in y_train:\n    y_sparse_train[y] = 1.0","metadata":{"papermill":{"duration":0.19355,"end_time":"2021-05-08T13:07:45.737299","exception":false,"start_time":"2021-05-08T13:07:45.543749","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Создание моделей","metadata":{"papermill":{"duration":0.025317,"end_time":"2021-05-08T13:07:45.78856","exception":false,"start_time":"2021-05-08T13:07:45.763243","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Для подбора метрик будем использовать [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n\nscoring = 'neg_log_loss' аналогично [log_loss](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). По условию задачи оценивается Log loss метрика, поэтому ориентироваться будем именно на нее.\n\nТак как данных достаточно много, будем делать число фолдов, равным 10.","metadata":{"papermill":{"duration":0.026041,"end_time":"2021-05-08T13:07:45.840593","exception":false,"start_time":"2021-05-08T13:07:45.814552","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)","metadata":{"papermill":{"duration":0.025553,"end_time":"2021-05-08T13:07:45.892865","exception":false,"start_time":"2021-05-08T13:07:45.867312","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\nparams = {\n    'alpha': [0.00001, 0.0001, 0.01, 0.1],\n    'early_stopping': [False, True]\n}\n\nsgd_model = SGD(loss='log', shuffle=False)\nclf_SGD = GridSearchCV(sgd_model, params, scoring = 'neg_log_loss', cv=10)\nclf_SGD.fit(X_train, y_train)\nclf_SGD.best_params_","metadata":{"papermill":{"duration":308.120564,"end_time":"2021-05-08T13:12:54.039419","exception":false,"start_time":"2021-05-08T13:07:45.918855","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_SGD = clf_SGD.predict_proba(X_test)\ny_pred_SGD","metadata":{"papermill":{"duration":0.073653,"end_time":"2021-05-08T13:12:54.139593","exception":false,"start_time":"2021-05-08T13:12:54.06594","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [SelfTrainingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.SelfTrainingClassifier.html)","metadata":{"papermill":{"duration":0.048564,"end_time":"2021-05-08T13:12:54.236576","exception":false,"start_time":"2021-05-08T13:12:54.188012","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Классификатор основывается на удалении некоторых меток классов и последующем восстановлении их.\n\nДля того чтобы натренировать алгоритм, добавить неизвестные метки классов, как тестовый набор.","metadata":{"papermill":{"duration":0.026958,"end_time":"2021-05-08T13:12:54.292464","exception":false,"start_time":"2021-05-08T13:12:54.265506","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[Статья](https://towardsdatascience.com/a-gentle-introduction-to-self-training-and-semi-supervised-learning-ceee73178b38)","metadata":{"papermill":{"duration":0.026676,"end_time":"2021-05-08T13:12:54.346422","exception":false,"start_time":"2021-05-08T13:12:54.319746","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_unlabeled = X_test\nX_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_train, y_train, test_size=0.90, stratify=y_train)\ny_train_c","metadata":{"papermill":{"duration":0.149479,"end_time":"2021-05-08T13:12:54.522954","exception":false,"start_time":"2021-05-08T13:12:54.373475","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iterations = 0\ntrain_f1s = []\ntest_f1s = []\npseudo_labels = []\nhigh_prob = [1]\n\nwhile len(high_prob) > 0 and X_unlabeled.shape[0] > 0:\n    print(\"Итерация {}\".format(iterations))\n    # Обучаем классификатор и делаем предсказания\n    clf = DecisionTreeClassifier()\n    clf.fit(X_train_c, y_train_c)\n    y_hat_train = clf.predict(X_train_c)\n    y_hat_test = clf.predict(X_test_c)\n    \n    # Вычисляем f1_score\n    f1s_train = f1_score(y_train_c, y_hat_train, average=None)\n    f1s_test = f1_score(y_test_c, y_hat_test, average=None)\n    train_f1s.append(f1s_train)\n    test_f1s.append(f1s_test)\n    print('Train f1: {}'.format(f1s_train))\n    print('Test f1: {}'.format(f1s_test))\n    print(np.unique(y_hat_train))\n    print(np.unique(y_hat_test))\n    \n    # генерирование вероятностей\n    pred_probs = clf.predict_proba(X_unlabeled)\n    preds = clf.predict(X_unlabeled)\n    prob_0 = pred_probs[:, 0]\n    prob_1 = pred_probs[:, 1]\n    prob_2 = pred_probs[:, 2]\n    prob_3 = pred_probs[:, 3]\n    \n    # Хранение вероятностей и предсказываний в датафрейме\n    df_pred_prob = pd.DataFrame([])\n    df_pred_prob['preds'] = preds\n    df_pred_prob['prob_0'] = prob_0\n    df_pred_prob['prob_1'] = prob_1\n    df_pred_prob['prob_2'] = prob_2\n    df_pred_prob['prob_3'] = prob_3\n    df_pred_prob.index = X_unlabeled.index\n    \n    # Разделяем предсказания с более чем 99,5% вероятностью\n    high_prob = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > 0.999],\n                           df_pred_prob.loc[df_pred_prob['prob_1'] > 0.999],\n                          df_pred_prob.loc[df_pred_prob['prob_2'] > 0.999],\n                          df_pred_prob.loc[df_pred_prob['prob_3'] > 0.999]],\n                          axis=0)\n    print(\"{} предсказаний с высокой вероятностью\".format(len(high_prob)))\n    pseudo_labels.append(len(high_prob))\n    \n    # Добавляем псевдо-метки к данным в тренировке\n    X_train_c = pd.concat([X_train_c, X_unlabeled.loc[high_prob.index]], axis=0)\n    y_train_c = pd.concat([y_train_c, high_prob.preds])\n    \n    # Убираем псевдо-метки из неизвестных данных\n    X_unlabeled = X_unlabeled.drop(index=high_prob.index)\n    print(\"Осталось {} данных без меток\".format(len(X_unlabeled)))\n    \n    # Увеличиваем счетчик итераций\n    iterations += 1\n    print()","metadata":{"papermill":{"duration":0.422794,"end_time":"2021-05-08T13:12:54.973846","exception":false,"start_time":"2021-05-08T13:12:54.551052","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получаем, что дерево решений не колеблется в определении меток классов - легче использовать его.\n\nЗаметим, что точность предсказаний достаточно высока","metadata":{"papermill":{"duration":0.028288,"end_time":"2021-05-08T13:12:55.030833","exception":false,"start_time":"2021-05-08T13:12:55.002545","status":"completed"},"tags":[]}},{"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\ny_pred_STC = clf.predict_proba(X_test)\ny_pred_STC","metadata":{"papermill":{"duration":2.288105,"end_time":"2021-05-08T13:12:57.347519","exception":false,"start_time":"2021-05-08T13:12:55.059414","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Keras](https://keras.io/api/)","metadata":{"papermill":{"duration":0.029584,"end_time":"2021-05-08T13:12:57.407532","exception":false,"start_time":"2021-05-08T13:12:57.377948","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\nmodel = Sequential()\nmodel.add(Dense(2, input_dim=X_train.shape[1], activation='softsign'))\nmodel.add(Dense(5, activation='softsign'))\nmodel.add(Dense(4, activation='softmax'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\nmodel.fit(X_train, y_sparse_train)\n\nbest_last_error = np.inf\nbest_n_neurons = 1\nh_best = []\n\nfor i in range(1, 25, 3):\n    model = Sequential()\n    model.add(Dense(20, input_dim=X_train.shape[1], activation='softsign'))\n    model.add(Dense(i, activation='softsign'))\n    model.add(Dense(4, activation='softmax'))\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n    print('Num neurons: {}'.format(i))\n    %time history = model.fit(X_train, y_sparse_train, epochs=50, verbose=0).history['loss']\n    print(history)\n    last_error = history[-1]\n    if best_last_error > last_error:\n        best_last_error = last_error\n        best_n_neurons = i","metadata":{"papermill":{"duration":993.728827,"end_time":"2021-05-08T13:29:31.166213","exception":false,"start_time":"2021-05-08T13:12:57.437386","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как мы видим, модель обучилась достаточно хорошо - возможно, даже переобучилась","metadata":{"papermill":{"duration":0.049932,"end_time":"2021-05-08T13:29:31.265562","exception":false,"start_time":"2021-05-08T13:29:31.21563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(20, input_dim=X_train.shape[1], activation='softsign'))\nmodel.add(Dense(best_n_neurons, activation='softsign'))\nmodel.add(Dense(4, activation='softmax'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\nprint('Num neurons: {}'.format(best_n_neurons))\n%time history = model.fit(X_train, y_sparse_train, epochs=200, verbose=0).history['loss']\ny_pred_keras = model.predict(X_test)\ny_pred_keras","metadata":{"papermill":{"duration":512.893345,"end_time":"2021-05-08T13:38:04.208652","exception":false,"start_time":"2021-05-08T13:29:31.315307","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Запись данных в файл","metadata":{"papermill":{"duration":0.05063,"end_time":"2021-05-08T13:38:04.310281","exception":false,"start_time":"2021-05-08T13:38:04.259651","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_test.info()","metadata":{"papermill":{"duration":0.074133,"end_time":"2021-05-08T13:38:04.435334","exception":false,"start_time":"2021-05-08T13:38:04.361201","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_SGD = pd.DataFrame({'id': df_test.id, 'Class_1': y_pred_SGD[:, 0],'Class_2': y_pred_SGD[:, 1], 'Class_3': y_pred_SGD[:, 2], 'Class_4': y_pred_SGD[:, 3]})\noutput_SGD.to_csv('SGDClassifier.csv', index=False)\noutput_SGD.info()","metadata":{"papermill":{"duration":0.560593,"end_time":"2021-05-08T13:38:05.047845","exception":false,"start_time":"2021-05-08T13:38:04.487252","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_SGD.head()","metadata":{"papermill":{"duration":0.069896,"end_time":"2021-05-08T13:38:05.170702","exception":false,"start_time":"2021-05-08T13:38:05.100806","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_STC = pd.DataFrame({'id': df_test.id, 'Class_1': y_pred_STC[:, 0],'Class_2': y_pred_STC[:, 1], 'Class_3': y_pred_STC[:, 2], 'Class_4': y_pred_STC[:, 3]})\noutput_STC.to_csv('SelfTrainingClassifier.csv', index=False)\noutput_STC.info()","metadata":{"papermill":{"duration":0.304986,"end_time":"2021-05-08T13:38:05.529514","exception":false,"start_time":"2021-05-08T13:38:05.224528","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_STC.head()","metadata":{"papermill":{"duration":0.06942,"end_time":"2021-05-08T13:38:05.653759","exception":false,"start_time":"2021-05-08T13:38:05.584339","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_nn = pd.DataFrame({'id': df_test.id, 'Class_1': y_pred_keras[:, 0],'Class_2': y_pred_keras[:, 1], 'Class_3': y_pred_keras[:, 2], 'Class_4': y_pred_keras[:, 3]})\noutput_nn.to_csv('keras.csv', index=False)\noutput_nn.info()","metadata":{"papermill":{"duration":0.41613,"end_time":"2021-05-08T13:38:06.123665","exception":false,"start_time":"2021-05-08T13:38:05.707535","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_nn.head()","metadata":{"papermill":{"duration":0.06822,"end_time":"2021-05-08T13:38:06.246232","exception":false,"start_time":"2021-05-08T13:38:06.178012","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Вывод\n\nЛучше всех отработал линейный SGD классификатор. Дерево явно переобучилось, а нейронная сеть отработала немного хуже","metadata":{"papermill":{"duration":0.054446,"end_time":"2021-05-08T13:38:06.354869","exception":false,"start_time":"2021-05-08T13:38:06.300423","status":"completed"},"tags":[]}}]}