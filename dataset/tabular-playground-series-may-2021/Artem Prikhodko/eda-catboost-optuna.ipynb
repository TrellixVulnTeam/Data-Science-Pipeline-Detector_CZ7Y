{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nGreetings!ðŸ‘‹\n\nIn this kernel you will find my data science approach to \"Tabular Playground Series - May 2021\" competition using CatBoost and Optuna.\n\nAs always, any feedback Is very much appreciated! :)","metadata":{}},{"cell_type":"markdown","source":"# Table of contents:\n\n1. Meeting our data\n\n2. Creating visualizations\n\n3. Doing a bit of preprocessing\n\n4. Creating and evaluating models\n\n5. Parameter tuning with Optuna\n\n6. Creating a final model and submitting results","metadata":{}},{"cell_type":"markdown","source":"# 1. Meeting our data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv', index_col = 'id')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv', index_col = 'id')\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train.target.copy()\ntarget","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('target', axis = 1, inplace = True)\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train.columns).equals(test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T.style.bar(subset = ['mean'], color = 'royalblue').background_gradient(subset = ['std'], cmap = 'Blues_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Creating visualizations","metadata":{}},{"cell_type":"code","source":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nsns.set_style('whitegrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16, 6))\ntarget_order = sorted(target.unique())\nsns.barplot(x = target.value_counts().index, y = target.value_counts(), order = target_order, palette = 'Blues_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grid(data, fig_size, grid_size, plot_type, target = ''):\n    \"\"\"\n    Custom function for plotting grid of plots.\n    It takes: DataFrame of data, size of a grid, type of plots, string name of target variable;\n    And it outputs: grid of plots.\n    \"\"\"\n    fig = plt.figure(figsize = fig_size)\n    if plot_type == 'histplot':\n        for i, column_name in enumerate(data.select_dtypes(exclude = 'object').columns):\n            fig.add_subplot(grid_size[0], grid_size[1], i + 1)\n            plot = sns.histplot(data[column_name], kde = True, color = 'royalblue', stat = 'count')\n    if plot_type == 'boxplot':\n        for i, column_name in enumerate(data.select_dtypes(exclude = 'object').columns):\n            fig.add_subplot(grid_size[0], grid_size[1], i + 1)\n            plot = sns.boxplot(x = data[column_name], color = 'royalblue')\n    if plot_type == 'barplot':\n        target = data[target]\n        target_order = sorted(target.unique())\n        for i, column_name in enumerate(data.drop(target.name, axis = 1).columns):\n            fig.add_subplot(grid_size[0], grid_size[1], i + 1)\n            new_data = data[[column_name, target.name]].groupby(target.name).mean()\n            plot = sns.barplot(x = new_data.index, y = new_data[column_name], palette = 'Blues_r', order = target_order)\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train, (16, 36), (17, 3), 'histplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train, fig_size = (16, 36), grid_size = (17, 3), plot_type = 'boxplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(pd.concat([train, target], axis = 1), (16, 36), (17, 3), 'barplot', 'target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16, 16))\nsns.heatmap(train.corr(),\n#             annot = True,\n#             fmt = '.2f',\n            square = True,\n            cmap = 'Blues_r',\n            cbar = False,\n            mask = np.triu(train.corr()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that there are a few features that consist almost entirely out of zeroes. Let's look into that.","metadata":{}},{"cell_type":"code","source":"zeroes = pd.DataFrame()\nfor i, column in enumerate(train.columns):\n    zeroes.loc[i, 'ColumnName'] = column\n    zeroes.loc[i, 'PercentOfZeroes'] = train.loc[train[column] == 0, column].count() / train.shape[0]\n#     print(f'{column} = {train.loc[train[column] == 0, column].count() / train.shape[0]}')\nzeroes.sort_values(by = 'PercentOfZeroes', ascending = False).style.background_gradient('Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Doing a bit of preprocessing","metadata":{}},{"cell_type":"code","source":"train_test = pd.concat([train, test], keys = ['train', 'test'], axis = 0)\ntrain_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test = (train_test - train_test.mean()) / train_test.std()\ntrain = train_test.xs('train').copy()\ntest = train_test.xs('test').copy()\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map = {\n    'Class_1': 0,\n    'Class_2': 1,\n    'Class_3': 2,\n    'Class_4': 3,\n}\n\ntarget = target.map(class_map).astype('int')\n\ntarget","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Creating and evaluating models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_validate, train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_estimators(X, y, estimators, labels, cv):\n    ''' \n    A function for testing multiple estimators.\n    It takes: full train data and target, list of estimators, \n              list of labels or names of estimators,\n              cross validation splitting strategy;\n    And it returns: a DataFrame of table with results of tests\n    '''\n    result_table = pd.DataFrame()\n\n    row_index = 0\n    for est, label in zip(estimators, labels):\n\n        est_name = label\n        result_table.loc[row_index, 'Model Name'] = est_name\n        \n        cv_results = cross_validate(est,\n                                    X,\n                                    y,\n                                    cv = cv,\n                                    scoring = 'neg_log_loss',\n                                    n_jobs = -1)\n\n        result_table.loc[row_index, 'Test log loss'] = -cv_results['test_score'].mean()\n        result_table.loc[row_index, 'Test Std'] = cv_results['test_score'].std()\n        result_table.loc[row_index, 'Fit Time'] = cv_results['fit_time'].mean()\n\n        row_index += 1\n\n    result_table.sort_values(by = ['Test log loss'], ascending = True, inplace = True)\n\n    return result_table","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a sample to save some time.","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train, \n                                                      target, \n                                                      stratify = target,\n                                                      train_size = 0.1,\n                                                      random_state = 1)\ny_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg = LogisticRegression()\ndt = DecisionTreeClassifier(random_state = 1)\nrf = RandomForestClassifier()\nxgb = XGBClassifier()\nlgbm = LGBMClassifier()\ncb = CatBoostClassifier(allow_writing_files = False, logging_level = 'Silent')\nsvc = SVC(probability = True)\ngnb = GaussianNB()\n\nestimators = [logreg,\n              dt,\n              rf,\n              lgbm, \n              cb,\n              svc,\n              gnb,]\n#               xgb]\n\nlabels = ['LogRegression',\n          'DecisionTree',\n          'RandomForest',\n          'LGBM',\n          'CatBoost',\n          'SVC',\n          'GNB',]\n#           'XGB']\n\nresults = test_estimators(X_train, y_train, estimators, labels, cv = StratifiedKFold(n_splits = 5))\nresults.style.background_gradient(cmap = 'Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Parameter tuning with Optuna","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom optuna.trial import TrialState\n\nfrom catboost import Pool, cv\n\ndef objective(trial, model, X_train_full, y_train_full):\n    if (model == 'cb'):\n        train_set = Pool(X_train_full, label = y_train_full)\n        \n        params = {\n            \"objective\": 'MultiClass',\n            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n            \"depth\": trial.suggest_int(\"depth\", 1, 12),\n            \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n            \"bootstrap_type\": trial.suggest_categorical(\n                \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n            ),\n\n            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1, log = True),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-5, 1e-1, log = True),\n            'min_child_samples': trial.suggest_int('min_child_samples', 2, 20),\n            'random_strength': trial.suggest_float('random_strength', 0.05, 1, log = True)\n        }\n\n        if params[\"bootstrap_type\"] == \"Bayesian\":\n            params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n        elif params[\"bootstrap_type\"] == \"Bernoulli\":\n            params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n\n        \n        k = 5\n        cb_cv_results = cv(\n            params = params,\n            pool = train_set,\n            num_boost_round = 4000,\n            nfold = k,\n            stratified = True,\n            early_stopping_rounds = 100,\n            verbose_eval = False,\n        )\n        # Set n_estimators as a trial attribute; Accessible via study.trials_dataframe().\n        trial.set_user_attr(\"n_estimators\", len(cb_cv_results['test-MultiClass-mean']))\n        # Extract the best score.\n        best_score = cb_cv_results['test-MultiClass-mean'].iloc[-1]\n        return best_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_cb = optuna.create_study(direction = 'minimize')\nstudy_cb.optimize(lambda trial: objective(trial, 'cb', train, target), n_trials = 100, timeout = 3600 * 7)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of finished trials: \", len(study_cb.trials))\nprint(\"Best trial:\")\ntrial = study_cb.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n\nprint(\"  Number of estimators: {}\".format(trial.user_attrs[\"n_estimators\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Creating a final model and submitting results","metadata":{}},{"cell_type":"code","source":"cb = CatBoostClassifier(allow_writing_files = False, \n                        logging_level = 'Silent', \n                        n_estimators = trial.user_attrs[\"n_estimators\"], \n                        **study_cb.best_params)\ncb.fit(train, target)\npredictions = cb.predict_proba(test)\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test.index,\n                           'Class_1': predictions[:, 0],\n                           'Class_2': predictions[:, 1],\n                           'Class_3': predictions[:, 2],\n                           'Class_4': predictions[:, 3],})\n\nsubmission.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}