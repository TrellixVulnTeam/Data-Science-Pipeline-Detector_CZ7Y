{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# My Approach to Tabular May 2021 Competition\n\nHi, in this notebook I have performed extensive EDA and used SHAP to find the most impactul and useless features in this data to help us in making better predictions.\n\nPlease upvote if you like it!","metadata":{"papermill":{"duration":0.069766,"end_time":"2022-05-01T15:54:14.047268","exception":false,"start_time":"2022-05-01T15:54:13.977502","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Table of Contents\n* [Importing Libraries](#section-one)\n* [Reading the data files](#section-two)\n* [Overview](#section-three)\n* [Exploratory Data Analysis (EDA)](#section-four)\n    - [Scaling](#subsection-fourone)\n    - [Correlation Check](#subsection-fourtwo)\n    - [Outlier Treatment](#subsection-fourthree)\n* [Modeling](#section-six)\n* [Model Explainability using SHAP](#section-seven)","metadata":{"papermill":{"duration":0.064064,"end_time":"2022-05-01T15:54:14.175071","exception":false,"start_time":"2022-05-01T15:54:14.111007","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# Importing Libraries","metadata":{"id":"89b66afd","papermill":{"duration":0.064563,"end_time":"2022-05-01T15:54:14.304029","exception":false,"start_time":"2022-05-01T15:54:14.239466","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Importing Required Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport shap\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.metrics import log_loss\nfrom statistics import mean\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', 100)\nsns.set_palette(\"coolwarm_r\", 4)","metadata":{"id":"c46da43f","papermill":{"duration":2.726071,"end_time":"2022-05-01T15:54:17.093808","exception":false,"start_time":"2022-05-01T15:54:14.367737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:19.519354Z","iopub.execute_input":"2022-05-08T16:40:19.519969Z","iopub.status.idle":"2022-05-08T16:40:24.067278Z","shell.execute_reply.started":"2022-05-08T16:40:19.51987Z","shell.execute_reply":"2022-05-08T16:40:24.066554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# Reading the data files","metadata":{"id":"f2794938","papermill":{"duration":0.064876,"end_time":"2022-05-01T15:54:17.224267","exception":false,"start_time":"2022-05-01T15:54:17.159391","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Reading the data files\n\ntrain = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\nsample = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')","metadata":{"id":"5bb17080","papermill":{"duration":4.338324,"end_time":"2022-05-01T15:54:21.630296","exception":false,"start_time":"2022-05-01T15:54:17.291972","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.068857Z","iopub.execute_input":"2022-05-08T16:40:24.069123Z","iopub.status.idle":"2022-05-08T16:40:24.633584Z","shell.execute_reply.started":"2022-05-08T16:40:24.069089Z","shell.execute_reply":"2022-05-08T16:40:24.632856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# Overview","metadata":{"id":"b1a8d321","papermill":{"duration":0.063685,"end_time":"2022-05-01T15:54:21.760589","exception":false,"start_time":"2022-05-01T15:54:21.696904","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f'Shape of train data: {train.shape}')\nprint(f'Missing values count: {train.isna().sum().sum()}')\n\ntrain.head()","metadata":{"id":"9f8c046c","outputId":"cef4631f-5e97-4faf-e9e7-007a27d3ebbe","papermill":{"duration":0.851923,"end_time":"2022-05-01T15:54:22.676738","exception":false,"start_time":"2022-05-01T15:54:21.824815","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.634794Z","iopub.execute_input":"2022-05-08T16:40:24.635045Z","iopub.status.idle":"2022-05-08T16:40:24.681324Z","shell.execute_reply.started":"2022-05-08T16:40:24.635013Z","shell.execute_reply":"2022-05-08T16:40:24.68067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()\nprint (\"*\"*40)\ntrain.nunique()","metadata":{"id":"11b559c8","outputId":"d21b6f67-93a5-40ee-b337-1565d78b2f4c","papermill":{"duration":1.312701,"end_time":"2022-05-01T15:54:24.060089","exception":false,"start_time":"2022-05-01T15:54:22.747388","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.683342Z","iopub.execute_input":"2022-05-08T16:40:24.683822Z","iopub.status.idle":"2022-05-08T16:40:24.763954Z","shell.execute_reply.started":"2022-05-08T16:40:24.683753Z","shell.execute_reply":"2022-05-08T16:40:24.763279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Training data has 100000 records and 50 features. \n* Column 'id' is the primary key.\n* It's a multiclass classification problem and 'target' is our target variable.\n* All the features are numerical in this data.\n* There is no missing value in the data.\n* The numerical features are discrete in nature since the cardinality is not very high.","metadata":{"id":"afb42866","papermill":{"duration":0.066638,"end_time":"2022-05-01T15:54:24.194717","exception":false,"start_time":"2022-05-01T15:54:24.128079","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f'Shape of test data: {test.shape}')\nprint(f'Missing values count: {test.isna().sum().sum()}')\n\ntest.head()","metadata":{"id":"639a0d86","outputId":"ccb6d939-bb0f-45ef-ad26-1cfca7570fbf","papermill":{"duration":0.521057,"end_time":"2022-05-01T15:54:24.803308","exception":false,"start_time":"2022-05-01T15:54:24.282251","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.765168Z","iopub.execute_input":"2022-05-08T16:40:24.766645Z","iopub.status.idle":"2022-05-08T16:40:24.795445Z","shell.execute_reply.started":"2022-05-08T16:40:24.766606Z","shell.execute_reply":"2022-05-08T16:40:24.794682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()\nprint (\"*\"*40)\ntest.nunique()","metadata":{"id":"2fb87a8c","outputId":"28cb92c3-7bfe-4332-9480-80045f3557a3","papermill":{"duration":0.882585,"end_time":"2022-05-01T15:54:25.762182","exception":false,"start_time":"2022-05-01T15:54:24.879597","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.796794Z","iopub.execute_input":"2022-05-08T16:40:24.797044Z","iopub.status.idle":"2022-05-08T16:40:24.835165Z","shell.execute_reply.started":"2022-05-08T16:40:24.797012Z","shell.execute_reply":"2022-05-08T16:40:24.834489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Test data has 50000 records and 50 features. \n* Column 'id' is the primary key.\n* All the features are numerical in this data.\n* There is no missing value in the data.\n* The numerical features are discrete in nature since the cardinality is not very high.","metadata":{"id":"9a8f9c8b","papermill":{"duration":0.070457,"end_time":"2022-05-01T15:54:25.902116","exception":false,"start_time":"2022-05-01T15:54:25.831659","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sample.head()","metadata":{"id":"414cb99c","outputId":"66de483c-3146-4e00-fccd-b768a2494dac","papermill":{"duration":0.084474,"end_time":"2022-05-01T15:54:26.057097","exception":false,"start_time":"2022-05-01T15:54:25.972623","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.836525Z","iopub.execute_input":"2022-05-08T16:40:24.836995Z","iopub.status.idle":"2022-05-08T16:40:24.851276Z","shell.execute_reply.started":"2022-05-08T16:40:24.83696Z","shell.execute_reply":"2022-05-08T16:40:24.850554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We need to submit the predicted probability values for each id in the test data.","metadata":{"id":"c7ec61b6","papermill":{"duration":0.069729,"end_time":"2022-05-01T15:54:26.197559","exception":false,"start_time":"2022-05-01T15:54:26.12783","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# Exploratory Data Analysis (EDA)","metadata":{"id":"9213e938","papermill":{"duration":0.069131,"end_time":"2022-05-01T15:54:26.336818","exception":false,"start_time":"2022-05-01T15:54:26.267687","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Setting index as 'id'\ntrain = train.set_index('id')\ntest = test.set_index('id')","metadata":{"papermill":{"duration":0.226164,"end_time":"2022-05-01T15:54:26.632457","exception":false,"start_time":"2022-05-01T15:54:26.406293","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.852417Z","iopub.execute_input":"2022-05-08T16:40:24.852798Z","iopub.status.idle":"2022-05-08T16:40:24.883771Z","shell.execute_reply.started":"2022-05-08T16:40:24.852757Z","shell.execute_reply":"2022-05-08T16:40:24.882978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if there is any difference between the behaviour of train and test data\ntrain.describe() - test.describe()","metadata":{"id":"f080201a","papermill":{"duration":0.436471,"end_time":"2022-05-01T15:54:27.140378","exception":false,"start_time":"2022-05-01T15:54:26.703907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:24.884994Z","iopub.execute_input":"2022-05-08T16:40:24.885827Z","iopub.status.idle":"2022-05-08T16:40:25.258244Z","shell.execute_reply.started":"2022-05-08T16:40:24.885785Z","shell.execute_reply":"2022-05-08T16:40:25.257565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is not a major difference in the values of all features of test and train data. This is a good sign and will help us in correct validation.","metadata":{"id":"60fcbd21","papermill":{"duration":0.069351,"end_time":"2022-05-01T15:54:27.282263","exception":false,"start_time":"2022-05-01T15:54:27.212912","status":"completed"},"tags":[]}},{"cell_type":"code","source":"num_columns = train.select_dtypes(exclude=['object']).columns\nnum_columns = [i for i in num_columns if i != 'target']\n\ncat_columns = train.select_dtypes(include=['object']).columns","metadata":{"papermill":{"duration":0.15614,"end_time":"2022-05-01T15:54:28.356937","exception":false,"start_time":"2022-05-01T15:54:28.200797","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:25.260819Z","iopub.execute_input":"2022-05-08T16:40:25.261229Z","iopub.status.idle":"2022-05-08T16:40:25.283011Z","shell.execute_reply.started":"2022-05-08T16:40:25.261183Z","shell.execute_reply":"2022-05-08T16:40:25.282199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T.style.bar(subset=['mean'], color='royalblue')\\\n                            .background_gradient(subset=['std'], cmap='coolwarm_r')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm_r')\\\n                            .background_gradient(subset=['min'], cmap='coolwarm_r')\\\n                            .background_gradient(subset=['max'], cmap='coolwarm_r')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:40:25.284544Z","iopub.execute_input":"2022-05-08T16:40:25.284845Z","iopub.status.idle":"2022-05-08T16:40:25.551119Z","shell.execute_reply.started":"2022-05-08T16:40:25.284808Z","shell.execute_reply":"2022-05-08T16:40:25.550331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Most of the features have 0 value in more than 50 percentiles.\n* Only feature14 and feature38 have values other than 0 in more than 50 percentile records.\n* Only handful of features have negative values. It will be interesting to see their importance in prediction.","metadata":{}},{"cell_type":"markdown","source":"#### Target Feature","metadata":{"papermill":{"duration":0.08747,"end_time":"2022-05-01T15:54:28.527135","exception":false,"start_time":"2022-05-01T15:54:28.439665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sorted(train['target'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:40:25.552653Z","iopub.execute_input":"2022-05-08T16:40:25.552903Z","iopub.status.idle":"2022-05-08T16:40:25.568576Z","shell.execute_reply.started":"2022-05-08T16:40:25.552869Z","shell.execute_reply":"2022-05-08T16:40:25.567559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the distribution of target variable\n\ntarget3 = train['target'].value_counts()['Class_4']\ntarget2 = train['target'].value_counts()['Class_3']\ntarget1 = train['target'].value_counts()['Class_2']\ntarget0 = train['target'].value_counts()['Class_1']\ntarget3per = target3 / train.shape[0] * 100\ntarget2per = target2 / train.shape[0] * 100\ntarget1per = target1 / train.shape[0] * 100\ntarget0per = target0 / train.shape[0] * 100\n\nprint('{} of {} records have target 1 it is the {:.2f}% of the training set.'.format(target0, train.shape[0], target0per))\nprint('{} of {} records have target 2 and it is the {:.2f}% of the training set.'.format(target1, train.shape[0], target1per))\nprint('{} of {} records have target 3 and it is the {:.2f}% of the training set.'.format(target2, train.shape[0], target2per))\nprint('{} of {} records have target 4 and it is the {:.2f}% of the training set.\\n'.format(target3, train.shape[0], target3per))\n\nplt.figure(figsize=(8,6))\nsns.countplot(train['target'], palette = 'coolwarm_r', order = sorted(train['target'].unique()))\n\nplt.xlabel('Target', size=12, labelpad=15)\nplt.ylabel('Count', size=12, labelpad=15)\nplt.xticks((0, 1, 2, 3), ['1 ({0:.2f}%)'.format(target0per), '2 ({0:.2f}%)'.format(target1per), '3 ({0:.2f}%)'.format(target2per), '4 ({0:.2f}%)'.format(target3per)])\nplt.tick_params(axis='x', labelsize=12)\nplt.tick_params(axis='y', labelsize=12)\n\nplt.title('Training Set Target Distribution', size=15, y=1.05)\n\nplt.show()","metadata":{"id":"9fa4a0a9","papermill":{"duration":0.302862,"end_time":"2022-05-01T15:54:28.917881","exception":false,"start_time":"2022-05-01T15:54:28.615019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:25.570251Z","iopub.execute_input":"2022-05-08T16:40:25.570536Z","iopub.status.idle":"2022-05-08T16:40:25.900423Z","shell.execute_reply.started":"2022-05-08T16:40:25.57049Z","shell.execute_reply":"2022-05-08T16:40:25.899749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Distribution of the classes are imbalanced.\n* More than 50% of the records belong to class2.\n* Smallest class is class1 having only 8.5% records.","metadata":{"id":"9af07b37","papermill":{"duration":0.072269,"end_time":"2022-05-01T15:54:29.062685","exception":false,"start_time":"2022-05-01T15:54:28.990416","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Label Encoding the classes\n\ntrain.loc[train['target'] == 'Class_1', 'target'] = '1'\ntrain.loc[train['target'] == 'Class_2', 'target'] = '2'\ntrain.loc[train['target'] == 'Class_3', 'target'] = '3'\ntrain.loc[train['target'] == 'Class_4', 'target'] = '4'\n\ntrain['target'] = train['target'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:40:25.901835Z","iopub.execute_input":"2022-05-08T16:40:25.902077Z","iopub.status.idle":"2022-05-08T16:40:25.985547Z","shell.execute_reply.started":"2022-05-08T16:40:25.902041Z","shell.execute_reply":"2022-05-08T16:40:25.984835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Continuous Features","metadata":{"id":"kJB9Y9LgHCLX","papermill":{"duration":0.071486,"end_time":"2022-05-01T15:54:29.205944","exception":false,"start_time":"2022-05-01T15:54:29.134458","status":"completed"},"tags":[]}},{"cell_type":"code","source":"len(num_columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:40:25.986634Z","iopub.execute_input":"2022-05-08T16:40:25.986869Z","iopub.status.idle":"2022-05-08T16:40:25.995852Z","shell.execute_reply.started":"2022-05-08T16:40:25.986839Z","shell.execute_reply":"2022-05-08T16:40:25.995149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All of the 50 features are numerical in this data.","metadata":{}},{"cell_type":"code","source":"# Checking the distribution of continuous features\nfrom tqdm import tqdm\n\ni = 1\nfig, ax = plt.subplots(10,5, figsize=(40,30))\n\nfor feature in tqdm(num_columns):\n    plt.subplot(10,5, i)\n    sns.kdeplot(data = train, y = feature, vertical=True, palette = 'coolwarm_r')\n    plt.xlabel(f'{feature}- Skew: {round(train[feature].skew(), 2)}', size=20)\n    i += 1\n\nfig.tight_layout()\nplt.show()","metadata":{"id":"d6608bba","papermill":{"duration":14.675635,"end_time":"2022-05-01T15:54:43.95323","exception":false,"start_time":"2022-05-01T15:54:29.277595","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:40:25.99726Z","iopub.execute_input":"2022-05-08T16:40:25.998016Z","iopub.status.idle":"2022-05-08T16:40:51.458865Z","shell.execute_reply.started":"2022-05-08T16:40:25.997979Z","shell.execute_reply":"2022-05-08T16:40:51.458208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* We can see a big peak in all the features at 0 value.\n* The features are sparse just like one hot encoding.\n* There is skewness present in all the features but let's not treat it since the values are discrete and not continuous in this data.","metadata":{"id":"2a5f8e49","papermill":{"duration":0.079005,"end_time":"2022-05-01T15:54:44.111189","exception":false,"start_time":"2022-05-01T15:54:44.032184","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Checking the distribution of continuous features\nfrom tqdm import tqdm\n\ni = 1\nfig, ax = plt.subplots(10,5, figsize=(50,30))\n\nfor feature in tqdm(num_columns):\n    plt.subplot(10,5, i)\n    sns.countplot(data = train, x = feature, order = train[feature].value_counts()[:4].index, hue = 'target', palette = 'coolwarm_r')\n    plt.xlabel(feature, size=25)\n    plt.legend(loc='upper right', prop={'size': 15})\n    i += 1\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:40:51.461569Z","iopub.execute_input":"2022-05-08T16:40:51.462077Z","iopub.status.idle":"2022-05-08T16:40:59.213009Z","shell.execute_reply.started":"2022-05-08T16:40:51.462037Z","shell.execute_reply":"2022-05-08T16:40:59.212331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* We cannot get any good insight here. Since the values are distributed in almost same proportion as the target variable.\n* Clearly 0 alone won't help the model in classification.\n* It will be interesting to see if the model is able to pick any other value apart from 0 which can help in classification.","metadata":{}},{"cell_type":"markdown","source":"### Analyzing Zeros","metadata":{}},{"cell_type":"markdown","source":"Since 0 covers most of the cell values in this data, let's check if there is any interesting pattern with zeros in this data.","metadata":{}},{"cell_type":"code","source":"zero_data = ((train.drop('target', axis = 1)==0).sum() / len(train) * 100)[::-1]\nfig, ax = plt.subplots(1,1,figsize=(10, 19))\n\nax.barh(zero_data.index, 100, color='lightgrey', height=0.6)\nbarh = ax.barh(zero_data.index, zero_data, height=0.6, color='royalblue')\nax.bar_label(barh, fmt='%.01f %%')\nax.spines[['left', 'bottom', 'right']].set_visible(False)\n\nax.set_xticks([])\n\nax.set_title('# of Zeros (by feature)', loc='center', fontweight='bold', fontsize=15)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:50:27.81936Z","iopub.execute_input":"2022-05-08T16:50:27.819768Z","iopub.status.idle":"2022-05-08T16:50:28.804458Z","shell.execute_reply.started":"2022-05-08T16:50:27.819731Z","shell.execute_reply":"2022-05-08T16:50:28.803349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Some features have more than 90% zero values, these features are very sparse and won't help the model much.\n* features 15, 15, 27, 38 looks most promising since they have variety of negative, positive and zero values.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-fourtwo\"></a>\n### Correlation Check","metadata":{"id":"3165e02e","papermill":{"duration":0.096803,"end_time":"2022-05-01T15:55:55.894367","exception":false,"start_time":"2022-05-01T15:55:55.797564","status":"completed"},"tags":[]}},{"cell_type":"code","source":"num_columns = train.select_dtypes(exclude=['object']).columns\nnum_columns = [i for i in num_columns if i != 'target']\n\ncat_columns = train.select_dtypes(include=['object']).columns","metadata":{"papermill":{"duration":0.176169,"end_time":"2022-05-01T15:55:56.160907","exception":false,"start_time":"2022-05-01T15:55:55.984738","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:00.16439Z","iopub.execute_input":"2022-05-08T16:41:00.164855Z","iopub.status.idle":"2022-05-08T16:41:00.185742Z","shell.execute_reply.started":"2022-05-08T16:41:00.164817Z","shell.execute_reply":"2022-05-08T16:41:00.184932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check how the features are inter-related to each other and with target variable\nf, ax = plt.subplots(nrows=1, ncols=1, figsize=(60,60))\nax.set_title(\"Correlation Matrix\", fontsize=30)\n\ncorr = train[num_columns + ['target']].corr().abs()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\nsns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='coolwarm_r',\n            cbar_kws={\"shrink\": .8}, vmin=0, vmax=1)\n\nfor tick in ax.xaxis.get_major_ticks():\n    tick.label.set_fontsize(20) \n    tick.label.set_rotation(90) \nfor tick in ax.yaxis.get_major_ticks():\n    tick.label.set_fontsize(20)\n    tick.label.set_rotation(0)\n    \nplt.show()","metadata":{"id":"d120f6cb","papermill":{"duration":0.772268,"end_time":"2022-05-01T15:55:57.025361","exception":false,"start_time":"2022-05-01T15:55:56.253093","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:00.187404Z","iopub.execute_input":"2022-05-08T16:41:00.187791Z","iopub.status.idle":"2022-05-08T16:41:07.292414Z","shell.execute_reply.started":"2022-05-08T16:41:00.187752Z","shell.execute_reply":"2022-05-08T16:41:07.291402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* None of the features show any linear correlation among themselves and with the target variable.","metadata":{"id":"fcfba295","papermill":{"duration":0.093768,"end_time":"2022-05-01T15:55:57.211164","exception":false,"start_time":"2022-05-01T15:55:57.117396","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"subsection-fourone\"></a>\n### Scaling","metadata":{"id":"ebc1232e","papermill":{"duration":0.090076,"end_time":"2022-05-01T15:55:55.133476","exception":false,"start_time":"2022-05-01T15:55:55.0434","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train.describe()","metadata":{"papermill":{"duration":0.301256,"end_time":"2022-05-01T15:55:55.524543","exception":false,"start_time":"2022-05-01T15:55:55.223287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:07.29417Z","iopub.execute_input":"2022-05-08T16:41:07.294539Z","iopub.status.idle":"2022-05-08T16:41:07.539046Z","shell.execute_reply.started":"2022-05-08T16:41:07.294474Z","shell.execute_reply":"2022-05-08T16:41:07.538169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* There are some high max values in this data. Let's get them to a standard scale.","metadata":{}},{"cell_type":"code","source":"#Scaling the data using standard scaler\n\ntrain[num_columns] = StandardScaler().fit_transform(train[num_columns])\ntest[num_columns] = StandardScaler().fit_transform(test[num_columns])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:41:07.540625Z","iopub.execute_input":"2022-05-08T16:41:07.541125Z","iopub.status.idle":"2022-05-08T16:41:07.933314Z","shell.execute_reply.started":"2022-05-08T16:41:07.541086Z","shell.execute_reply":"2022-05-08T16:41:07.93247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-fourthree\"></a>\n### Outlier Treatment","metadata":{"id":"237257cd","papermill":{"duration":0.093292,"end_time":"2022-05-01T15:55:57.962448","exception":false,"start_time":"2022-05-01T15:55:57.869156","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# OUTLIERS\n\niqr_factor = [3]\nlist1, list2 = [], []\n\nfor factor in iqr_factor:\n    count = 0\n    print(f'Outliers for {factor} IQR :')\n    print('-------------------------------------')\n    for col in num_columns:\n    \n        IQR = train[col].quantile(0.75) - train[col].quantile(0.25)\n        lower_lim = train[col].quantile(0.25) - factor*IQR\n        upper_lim = train[col].quantile(0.75) + factor*IQR\n    \n        cond = train[(train[col] < lower_lim) | (train[col] > upper_lim)].shape[0]\n        \n        if cond > 0 and factor == 1.5:\n            list1.append(train[(train[col] < lower_lim) | (train[col] > upper_lim)].index.tolist())\n        elif cond > 0 and factor == 3:\n            list2.append(train[(train[col] < lower_lim) | (train[col] > upper_lim)].index.tolist())\n        \n        if cond > 0: print(f'{col:<30} : ', cond); count += cond\n    print(f'\\nTOTAL OUTLIERS FOR {factor} IQR : {count}')\n    print('')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:41:07.93486Z","iopub.execute_input":"2022-05-08T16:41:07.935114Z","iopub.status.idle":"2022-05-08T16:41:08.74371Z","shell.execute_reply.started":"2022-05-08T16:41:07.935078Z","shell.execute_reply":"2022-05-08T16:41:08.742806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* The above table shows the number of outliers in each feature. \n* But these are not the actual outliers since the data is very sparse, most of the values other than 0 are being detected as outlier here.\n* Let's keep these outliers as they are since these are the ones which will halp the model in classification.","metadata":{"id":"9236f2af","papermill":{"duration":0.095384,"end_time":"2022-05-01T15:56:03.869194","exception":false,"start_time":"2022-05-01T15:56:03.77381","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n# Modeling","metadata":{"id":"c15bfcf0","papermill":{"duration":0.096787,"end_time":"2022-05-01T15:56:29.721716","exception":false,"start_time":"2022-05-01T15:56:29.624929","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Let's try different ML models and see which performs best.","metadata":{"id":"3c446af2","papermill":{"duration":0.095279,"end_time":"2022-05-01T15:56:29.912295","exception":false,"start_time":"2022-05-01T15:56:29.817016","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = train.reset_index(drop = True)","metadata":{"id":"0fe168b5","papermill":{"duration":0.150363,"end_time":"2022-05-01T15:56:30.15882","exception":false,"start_time":"2022-05-01T15:56:30.008457","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:08.745115Z","iopub.execute_input":"2022-05-08T16:41:08.747013Z","iopub.status.idle":"2022-05-08T16:41:08.759908Z","shell.execute_reply.started":"2022-05-08T16:41:08.746973Z","shell.execute_reply":"2022-05-08T16:41:08.758859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Storing the target variable separately\n\nX_train = train.drop('target', axis = 1)\nX_test = test\ny_train = train['target']\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))","metadata":{"papermill":{"duration":0.198856,"end_time":"2022-05-01T15:56:30.453936","exception":false,"start_time":"2022-05-01T15:56:30.25508","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:08.761124Z","iopub.execute_input":"2022-05-08T16:41:08.761835Z","iopub.status.idle":"2022-05-08T16:41:08.783424Z","shell.execute_reply.started":"2022-05-08T16:41:08.761796Z","shell.execute_reply":"2022-05-08T16:41:08.782276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Stratified K fold Cross Validation\n\ndef train_and_validate(model, N):\n    \n    scores = []\n    regex = '^[^\\(]+'\n    match = re.findall(regex, str(model))\n    print(f'Running {N} Fold CV with {match[0]} Model.')\n    \n    preds = np.zeros((test.shape[0],4))\n\n    importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=train.drop('target', axis = 1).columns)\n\n    skf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\n\n    for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n        print('Fold {}\\n'.format(fold))\n        \n        # Fitting the model\n        model.fit(X_train.iloc[trn_idx], y_train[trn_idx])\n\n        # Computing Train logloss score\n        trn_logloss_score = log_loss(y_train[trn_idx], model.predict_proba(X_train.iloc[trn_idx]))\n        # Computing Validation logloss score\n        val_logloss_score = log_loss(y_train[val_idx], model.predict_proba(X_train.iloc[val_idx]))\n\n        scores.append((trn_logloss_score, val_logloss_score))\n\n        preds += model.predict_proba(X_test)/skf.n_splits\n        importances.iloc[:, fold - 1] = model.feature_importances_\n        \n        print(scores[-1])\n    \n    trlogloss = mean([i[0] for i in scores])\n    cvlogloss = mean([i[1] for i in scores])\n    \n    print(f'Average Training logloss: {trlogloss}, Average CV logloss: {cvlogloss}')\n    print (\"*\"*40)\n    print (\"\\n\")\n    \n    return trlogloss, cvlogloss, importances, preds, model","metadata":{"papermill":{"duration":0.1159,"end_time":"2022-05-01T15:56:30.666889","exception":false,"start_time":"2022-05-01T15:56:30.550989","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:08.785254Z","iopub.execute_input":"2022-05-08T16:41:08.785772Z","iopub.status.idle":"2022-05-08T16:41:08.801103Z","shell.execute_reply.started":"2022-05-08T16:41:08.78573Z","shell.execute_reply":"2022-05-08T16:41:08.800351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing multiple ML models using stratified K fold CV\n\ndf_row = []\nN = 3\n\nfor i in [DecisionTreeClassifier(),\n    LGBMClassifier(),\n    RandomForestClassifier(n_estimators = 10, max_depth = 10)]:\n    \n    trlogloss, cvlogloss, importances, preds, model = train_and_validate(i, N)\n    \n    regex = '^[^\\(]+'\n    match = re.findall(regex, str(i))\n    \n    df_row.append([match[0], trlogloss, cvlogloss])\n\ndf = pd.DataFrame(df_row, columns = ['Model', f'{N} Fold Training logloss', f'{N} Fold CV logloss'])\ndf","metadata":{"papermill":{"duration":259.970283,"end_time":"2022-05-01T16:00:50.733319","exception":false,"start_time":"2022-05-01T15:56:30.763036","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:08.802618Z","iopub.execute_input":"2022-05-08T16:41:08.803061Z","iopub.status.idle":"2022-05-08T16:41:28.748468Z","shell.execute_reply.started":"2022-05-08T16:41:08.803024Z","shell.execute_reply":"2022-05-08T16:41:28.747796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* LGBM Model has scored the least Logloss. \n* But the best performing model here is RandomForest because the difference between training logloss and CV logloss is least in this model. \n* Random Forest is generalizing the data very well here and is not overfitting much.","metadata":{"papermill":{"duration":0.101075,"end_time":"2022-05-01T16:00:50.934566","exception":false,"start_time":"2022-05-01T16:00:50.833491","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Plotting the RandomForest importances\n\nimportances['Mean_Importance'] = importances.mean(axis=1)\nimportances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\n\nplt.figure(figsize=(8,8))\nsns.barplot(x='Mean_Importance', y=importances.head(15).index, data=importances.head(15), palette = 'coolwarm_r')\n\nplt.xlabel('')\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=10)\nplt.title('Top 15 features', size=10)\n\nplt.show()","metadata":{"papermill":{"duration":0.342719,"end_time":"2022-05-01T16:00:51.3798","exception":false,"start_time":"2022-05-01T16:00:51.037081","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-08T16:41:28.749922Z","iopub.execute_input":"2022-05-08T16:41:28.750391Z","iopub.status.idle":"2022-05-08T16:41:29.168165Z","shell.execute_reply.started":"2022-05-08T16:41:28.750354Z","shell.execute_reply":"2022-05-08T16:41:29.167513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* As expected from EDA, features 38 and 14 are coming among the most important feature since they had a different behaviour than all other features in our data.\n* It's interesting to see feature 2, 15, 6 appearing at the top of importance list. Let's explore more about these features using SHAP.\n\nLet's try making a submission with RandomForest model and see the performance on leaderboard.","metadata":{}},{"cell_type":"code","source":"#Creating the submission with Random Forest Model\n\nmodel = RandomForestClassifier(n_estimators = 10, max_depth = 10)\ntrlogloss, cvlogloss, importances, preds, _ = train_and_validate(model, 5)\n\nsample.iloc[:, 1:] = preds\nsample.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:41:29.169239Z","iopub.execute_input":"2022-05-08T16:41:29.170658Z","iopub.status.idle":"2022-05-08T16:41:33.262681Z","shell.execute_reply.started":"2022-05-08T16:41:29.170615Z","shell.execute_reply":"2022-05-08T16:41:33.26178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We got a logloss of 1.104 on leaderboard on submitting the above csv. Let's check if LGBM model gets a better score.","metadata":{}},{"cell_type":"code","source":"#Creating the submission with LGBM Model\n\nmodel = LGBMClassifier()\ntrlogloss, cvlogloss, importances, preds, _ = train_and_validate(model, 5)\n\nsample.iloc[:, 1:] = preds\nsample.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:41:33.263858Z","iopub.execute_input":"2022-05-08T16:41:33.264467Z","iopub.status.idle":"2022-05-08T16:42:01.437842Z","shell.execute_reply.started":"2022-05-08T16:41:33.264423Z","shell.execute_reply":"2022-05-08T16:42:01.437001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! LGBM scored a logloss of 1.088 which is an improvement over the Random Forest Model.\n\nLet's try to understand more about the features behaviour using SHAP.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-seven\"></a>\n# Model Explainability using SHAP","metadata":{}},{"cell_type":"code","source":"#Fitting the SHAP on our model and training data\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:42:01.43973Z","iopub.execute_input":"2022-05-08T16:42:01.439982Z","iopub.status.idle":"2022-05-08T16:48:51.289416Z","shell.execute_reply.started":"2022-05-08T16:42:01.439947Z","shell.execute_reply":"2022-05-08T16:48:51.288819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the SHAP summary. (Note: Class 0 in the analysis below correspond to class 1 in the data and so on.)\n\nshap.summary_plot(shap_values, X_train, color=plt.get_cmap(\"tab20c\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:48:51.29073Z","iopub.execute_input":"2022-05-08T16:48:51.291229Z","iopub.status.idle":"2022-05-08T16:48:51.991357Z","shell.execute_reply.started":"2022-05-08T16:48:51.291191Z","shell.execute_reply":"2022-05-08T16:48:51.990692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* feature 31, 24, 16 have a major impact in predicting class 3.\n* feature 15, 11, 2, 1, 33 helps most in detecting class 2.\n* feature 37, 25, 28 have greatest impact in deciding class 0.\n* feature 6, 37, 28, 34 have a major impact in predicting class 1.","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[0], X_train, show = False, cmap = 'coolwarm_r')\nplt.gcf().axes[-1].set_aspect(100)\nplt.gcf().axes[-1].set_box_aspect(100)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:48:51.992672Z","iopub.execute_input":"2022-05-08T16:48:51.993078Z","iopub.status.idle":"2022-05-08T16:49:15.464992Z","shell.execute_reply.started":"2022-05-08T16:48:51.993039Z","shell.execute_reply":"2022-05-08T16:49:15.464356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Red bulbs in the center are indicating that 0 values are no having any impact in predicting class 1.\n* feature 6, 15, 41 are positively correlated with class 1.\n* feature 25, 19 show slight negative correlation with class 1.\n* feature 17, 1 have least impact on class 1.","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], X_train, show = False, cmap = 'coolwarm_r')\nplt.gcf().axes[-1].set_aspect(100)\nplt.gcf().axes[-1].set_box_aspect(100)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:49:15.46635Z","iopub.execute_input":"2022-05-08T16:49:15.466822Z","iopub.status.idle":"2022-05-08T16:49:39.387811Z","shell.execute_reply.started":"2022-05-08T16:49:15.466782Z","shell.execute_reply":"2022-05-08T16:49:39.387115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Red bulbs in the center are indicating that 0 values are no having any impact in predicting class 2.\n* feature 19, 35, 29, 14, 28 show positive correlation with class 2.\n* feature 15, 6, 10, 42, 30 show negative correlation with class 2.\n* feature 2 have least impact on class 2.","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[2], X_train, show = False, cmap = 'coolwarm_r')\nplt.gcf().axes[-1].set_aspect(100)\nplt.gcf().axes[-1].set_box_aspect(100)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:49:39.391616Z","iopub.execute_input":"2022-05-08T16:49:39.392049Z","iopub.status.idle":"2022-05-08T16:50:03.72799Z","shell.execute_reply.started":"2022-05-08T16:49:39.392009Z","shell.execute_reply":"2022-05-08T16:50:03.727338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Red bulbs are not completely in center, indicates that zeros have a bit of impact on class 3.\n* feature 43, 14, 42 show positive correlation with class 3.\n* feature 15, 38, 11, 0 show negative correlation with class 3.\n* feature 32 have least impact on class 3.","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[3], X_train, show = False, cmap = 'coolwarm_r')\nplt.gcf().axes[-1].set_aspect(100)\nplt.gcf().axes[-1].set_box_aspect(100)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T16:50:03.729356Z","iopub.execute_input":"2022-05-08T16:50:03.729839Z","iopub.status.idle":"2022-05-08T16:50:27.817983Z","shell.execute_reply.started":"2022-05-08T16:50:03.7298Z","shell.execute_reply":"2022-05-08T16:50:27.817312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* Zero values in feature 31, 14, 24 have a bit of impact on class 4.\n* No feature show strong positive correlation with class 4.\n* feature 31, 14, 24, 16, 23, 7 show negative correlation with class 4.\n* feature 22, 17, 32, 9 have least impact on class 4.","metadata":{}},{"cell_type":"markdown","source":"##  Most useless features in this data\n\nAs per the above analysis, we can safely conclude that feature_32, feature_17, feature_1 are the most indecisive features to predict any class in this data.","metadata":{}},{"cell_type":"markdown","source":"# The End!\n\nThank you for reading this notebook. I have learnt alot from this exercise, hope you have learnt something too.\nPlease share feedback if you find any flaws or have a better approach.\n\nPlease upvote the notebook if you liked! \n\nThank you!","metadata":{"id":"43864aef","papermill":{"duration":0.10848,"end_time":"2022-05-01T16:18:55.212398","exception":false,"start_time":"2022-05-01T16:18:55.103918","status":"completed"},"tags":[]}}]}