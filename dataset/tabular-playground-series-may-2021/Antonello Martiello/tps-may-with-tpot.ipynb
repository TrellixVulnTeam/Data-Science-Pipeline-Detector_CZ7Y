{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Utils\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom catboost import CatBoostClassifier\nimport seaborn as sns\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\nfrom sklearn.manifold import TSNE\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport category_encoders as ce\nfrom tpot import TPOTClassifier\nimport timeit\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom tpot.builtins import ZeroCount\nfrom sklearn.preprocessing import RobustScaler","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv', sep=',')\ntest= pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv', sep=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.set_index('id')\ntest = test.set_index('id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv', sep=',')\nsub_sample = sub_sample.set_index('id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(train, x=\"target\",\n                   width=600, \n                   height=400,\n                   histnorm='percent',\n                   template=\"simple_white\"\n                   )\nfig.update_layout(title=\"Target Description\", \n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  showlegend=True,\n                  legend=dict(\n                      orientation=\"v\", \n                      y=1, \n                      yanchor=\"top\", \n                      x=1.0, \n                      xanchor=\"right\"\n                  )                \n                 ).update_xaxes(categoryorder='total descending')#\nfig.update_traces( \n                  marker_line_width=1.5, opacity=0.99)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Estimation model Log-loss vs Random Guessing","metadata":{}},{"cell_type":"code","source":"def calc_loss(class_perc, num):\n    \n    lst=[]\n    \n    for i,z in enumerate(class_perc):\n        lst = lst+[i for x in range(int(z*(num+1)))]\n        \n    preds=[]\n    \n    for i in range(num):\n        preds+=[class_perc]\n    \n    return (log_loss(lst,preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example of how could be the distribution in classes according to the LB\ncalc_loss([0.60, 0.20, 0.10, 0.10], 200000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target Map\ndict1 = dict(zip(list(train.target.unique()),range(4)))\ndict1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target']= train['target'].replace(dict1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = train.columns[:-1]\ntarget = train['target']\ntrain = train[cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train<0]=0\ntest[test<0]=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create train and test sets\nX_train, X_val, y_train, y_val = train_test_split(train, target, train_size=0.75, test_size=0.25, stratify=target, random_state=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TPOT Classifier","metadata":{}},{"cell_type":"code","source":"tpot = TPOTClassifier(verbosity=3, \n                      scoring='neg_log_loss', \n                      random_state=2, \n                      periodic_checkpoint_folder='tpot_tpsmay.txt', \n                      n_jobs=-1,\n                      cv=5,\n                      generations=5, \n                      population_size=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = timeit.default_timer()\ntpot.fit(X_train, y_train)\nwinning = tpot.fitted_pipeline_\nscore = (tpot.score(X_val, y_val))\ntpot.export('tps_may_pipeline.py')  \nprint('Winning pipeline :', winning, 'Score:', score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Winning pipeline :', winning, 'Score:', score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the Model","metadata":{}},{"cell_type":"code","source":"preds = np.zeros((len(test), 4))\noof_preds = pd.DataFrame(index=train.index)\nk=10\nkf = StratifiedKFold(n_splits = k, random_state = 22 , shuffle = True)\nroc = []\n\nn = 0\nfor trn_idx , val_idx in kf.split(train , target):\n    train_x = train.iloc[trn_idx]\n    train_y = target.iloc[trn_idx]\n    val_x = train.iloc[val_idx]\n    val_y = target.iloc[val_idx]\n    \n    \n   \n    \n    \n    model = Pipeline(steps=[('zerocount', ZeroCount()), ('robustscaler', RobustScaler()),\n                ('mlpclassifier',\n                 MLPClassifier(alpha=0.1, learning_rate_init=0.01,\n                               random_state=2))])\n    \n    \n    if n!=0:\n        model.fit(train_x , train_y)\n        preds += model.predict_proba(test)\n        preds0 = preds/(k)\n        roc.append(log_loss(val_y ,model.predict_proba(val_x)))\n        print(n+1 , roc[n])\n\n    if n==0:\n        roc.append(0)\n        print(n+1 , roc[n])\n        \n    \n    n+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = pd.DataFrame(preds0, index=test.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample['Class_1']=p[1]\nsub_sample['Class_2']=p[0]\nsub_sample['Class_3']=p[3]\nsub_sample['Class_4']=p[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample = sub_sample.reset_index()\nsub_sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}