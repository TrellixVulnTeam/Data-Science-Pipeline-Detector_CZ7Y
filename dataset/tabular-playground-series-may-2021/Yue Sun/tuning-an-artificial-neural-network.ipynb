{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#This librarys is to work with matrices\nimport pandas as pd \n# This librarys is to work with vectors\nimport numpy as np\n# This library is to create some graphics algorithmn\nimport seaborn as sns\n# to render the graphs\nimport matplotlib.pyplot as plt\n#This library use for building ANN model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nimport keras\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Input\n#This library use for data preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n# This function makes the plot directly on browser\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuning packages","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nimport kerastuner as kt\nfrom sklearn.metrics import log_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"reference: https://www.kaggle.com/harunshimanto/tps-2021-eda-build-an-artificial-neural-network by Harun-Ur-Rashid","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(50):\n    mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n    train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)/std)\n    test[f'feature_{i}'] = test[f'feature_{i}'].apply(lambda x : (x-mean)/std)\nlabel = {var:index for index, var in enumerate(sorted(train['target'].unique()))}\ntrain['target'] = train['target'].map(label)\n\ntarget = train['target']\ntrain.drop(['target'], inplace=True, axis=1)\ntrain = train.values\ntarget = target.values\ntarget =  to_categorical(target)\nX_train, X_val, y_train, y_val = train_test_split(train, target, test_size = 0.1, random_state = 2, stratify=target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"optimizers list\noptimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']","metadata":{}},{"cell_type":"markdown","source":"# Bayesian Optimization","metadata":{}},{"cell_type":"code","source":"def create_model1(hp, num_columns, num_labels):\n    model = Sequential()\n    model.add(Dense(hp.Int('hidden_units_1', 9, 99, 3), activation='relu',input_dim = num_columns,kernel_initializer='uniform'))\n    model.add(Dropout(hp.Float(\"dropout_rate_1\", 0.01, 0.5)))\n    model.add(Dense(hp.Int('hidden_units_2', 9, 99, 3), kernel_initializer = 'uniform',activation ='relu'))\n    model.add(Dropout(hp.Float(\"dropout_rate_2\", 0.01, 0.5)))\n    model.add(Dense(hp.Int('hidden_units_3', 9, 150, 3), kernel_initializer = 'uniform',activation ='relu'))\n    model.add(Dropout(hp.Float(\"dropout_rate_3\", 0.01, 0.5)))\n    model.add(Dense(num_labels, kernel_initializer='uniform', \n                    activation = hp.Choice('out_activation',['softmax','sigmoid'])))\n    model.compile(optimizer = 'sgd', \n                       loss = 'categorical_crossentropy', \n                       metrics = ['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'num_columns': 50, 'num_labels': 4}\nEPOCHS = 3\nMAX_TRIAL = 100\nmodel_fn = lambda hp: create_model1(hp, **params)\ntuner = kt.tuners.BayesianOptimization(model_fn, kt.Objective('accuracy', direction='max'), MAX_TRIAL, seed = 2020)\ntuner.search(X_train, y_train, epochs=EPOCHS, validation_data = (X_val, y_val))\ntuner.results_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = tuner.get_best_models()[0]\nmodel1.fit(X_train, y_train, epochs = 30, verbose = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluating the model**","metadata":{}},{"cell_type":"code","source":"scores = model1.evaluate(X_train, y_train, batch_size=30)\nprint(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = model1.predict(test)\nsample_submission.to_csv('BO.csv',index=False)\nsample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna","metadata":{}},{"cell_type":"code","source":"def create_model2(num_columns, num_labels, hidden_units_1, hidden_units_2, hidden_units_3,\n                dropout_rate_1, dropout_rate_2, dropout_rate_3, out_activation):\n    hidden_units = [hidden_units_1, hidden_units_2, hidden_units_3]\n    dropout_rates = [dropout_rate_1, dropout_rate_2, dropout_rate_3]\n    model = Sequential()\n    model.add(Dense(hidden_units[0], activation='relu',input_dim = num_columns, kernel_initializer='uniform'))\n    model.add(Dropout(dropout_rates[0]))\n    model.add(Dense(hidden_units[1], kernel_initializer = 'uniform',activation ='relu'))\n    model.add(Dropout(dropout_rates[1]))\n    model.add(Dense(hidden_units[2], kernel_initializer = 'uniform',activation ='relu'))\n    model.add(Dropout(dropout_rates[2]))\n    model.add(Dense(num_labels, kernel_initializer='uniform', \n                    activation = out_activation))\n    model.compile(optimizer = 'sgd', \n                       loss = 'categorical_crossentropy', \n                       metrics = ['accuracy'])\n    return model\ndef objective(trial , X = X_train , y = y_train):   \n    params = {'num_columns': 50, \n              'num_labels': 4, \n          'hidden_units_1': trial.suggest_int('hidden_units_1' ,9 , 99), \n          'hidden_units_2': trial.suggest_int('hidden_units_2' ,9 , 99), \n          'hidden_units_3': trial.suggest_int('hidden_units_3' ,9 , 150),\n          'dropout_rate_1': trial.suggest_uniform('dropout_rate_1' ,0.01 , 0.5), \n          'dropout_rate_2': trial.suggest_uniform('dropout_rate_2' ,0.01 , 0.5), \n          'dropout_rate_3': trial.suggest_uniform('dropout_rate_3' ,0.01 , 0.5),        \n          'out_activation': trial.suggest_categorical('out_activation' , ['softmax','sigmoid'])}\n    # pruning_callback = optuna.integration.KerasPruningCallback(trial, monitor = 'accuracy')\n    model2 = create_model2(**params)\n    model2.fit(X_train, y_train, epochs = 3, verbose = 0\n               #, callbacks = [pruning_callback]\n              )\n    y_pred = model2.predict(X_val)\n    ll = log_loss(y_val, y_pred)\n    return ll\n              \nstudy = optuna.create_study(direction = 'minimize' , study_name = 'Optuna NN'\n                        #    , pruner = optuna.pruners.HyperbandPruner()\n                           )\nstudy.optimize(objective, n_trials = 100)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = create_model2(**study.best_trial.params, num_columns = 50, num_labels = 4)\nmodel2.fit(X_train, y_train, epochs = 30, verbose = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model2.evaluate(X_train, y_train, batch_size=30)\nprint(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = model2.predict(test)\nsample_submission.to_csv('Optuna.csv',index=False)\nsample_submission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = (model1.predict(test) + model2.predict(test)) / 2\nsample_submission.to_csv('avg.csv',index=False)\nsample_submission","metadata":{},"execution_count":null,"outputs":[]}]}