{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport gc\n\nfrom colorama import Fore, Back, Style\n\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nrs_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/train.csv', index_col=None)\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/test.csv', index_col=None)\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2021/sample_submission.csv', index_col=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cols = list(train.columns[1:-1])\ntarget_count = train.groupby('target')['id'].count().reset_index()\n#target_count\ncolors = {'Class_1' : '#0722ab',\n'Class_2' : '#fdb913',\n'Class_3' : '#3d2256',\n'Class_4' : '#ef4022'}\ntarget_count.rename(columns={'id':'count'}, inplace=True)\ntarget_count['pct'] = (target_count['count'] / target_count['count'].sum())*100\n#target_count\ndef autopct_format(values):\n    def my_format(pct):\n        total = sum(values)\n        val = int(round(pct*total/100.0))\n        return '{v:d}%'.format(v=val)\n    return my_format\n\nexplode = (0.05,0.05,0.05,0.05)\nfig1, ax1 = plt.subplots(1,1, figsize=(6, 6), facecolor='w', edgecolor='b')\nsizes = target_count['pct']\nlabels = target_count['target']\npatches, texts, autotexts = ax1.pie(sizes, \n          colors = [colors[key] for key in labels], \n          labels=labels, \n          autopct=autopct_format(sizes), \n          startangle=90, \n          pctdistance=0.85, \n          explode = explode,\n         textprops={'fontsize': 14,\n                   'fontfamily':'Computer Modern'\n                   })\n[text.set_color('#4a4b52') for text in texts]\n[autotext.set_color('white') for autotext in autotexts]\n[autotext.set_weight('bold') for autotext in autotexts]\n#draw circle\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nart = ax1.add_artist(centre_circle)\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1 = ax1.axis('equal')  \nplt.tight_layout(pad=3.0)\nplt.subplots_adjust(top=0.91)\nplt.suptitle('Target class distribution',fontsize = 20)\nplt.show()\nall_cols = train.columns[1:-1]\ntrain[all_cols].describe().T.style.background_gradient(subset=['mean'], cmap='viridis_r')\\\n        .background_gradient(subset=['std'], cmap='viridis_r')\\\n        .background_gradient(subset=['min'], cmap='nipy_spectral')\\\n        .background_gradient(subset=['max'], cmap='binary')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[all_cols].describe().T.style.background_gradient(subset=['mean'], cmap='viridis_r')\\\n        .background_gradient(subset=['std'], cmap='viridis_r')\\\n        .background_gradient(subset=['min'], cmap='nipy_spectral')\\\n        .background_gradient(subset=['max'], cmap='binary')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nenc = le.fit_transform(train.target)\ntrain = train.assign(target=enc)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[all_cols]\ny = train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Means and SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import KMeansSMOTE\nfrom sklearn.cluster import MiniBatchKMeans\nfor label, count in zip(*np.unique(train['target'], return_counts=True)):\n    print('Class {} has {} samples'.format(label, count))\n\nkmeans_smote = KMeansSMOTE(\n    sampling_strategy = 'not majority',\n    random_state = 42,\n    k_neighbors = 10,\n    cluster_balance_threshold = 0.1,\n    kmeans_estimator = MiniBatchKMeans(n_clusters=100, random_state=42)\n    #kmeans_estimator = 100\n)\nX_resampled, y_resampled = kmeans_smote.fit_resample(train[all_cols], train['target'])\n\nfor label, count in zip(*np.unique(y_resampled, return_counts=True)):\n    print('Class {} has {} samples after oversampling'.format(label, count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_new = pd.DataFrame(X_resampled, columns=all_cols, index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna + XGBoost ","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom functools import partial\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom tqdm import tqdm\n\ndef callback(study, trial):\n    if study.best_trial.number == trial.number:\n        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])\n\ndef optimize(trial, X, y, n_splits):\n \n    n_estimators = trial.suggest_int(\"n_estimators\",500,2500)\n    max_depth = trial.suggest_int(\"max_depth\",10,25)\n    learning_rate = trial.suggest_uniform(\"learning_rate\", 0.01, 0.5)\n    gamma = trial.suggest_uniform(\"gamma\", 0.05, 0.8)\n    subsample = trial.suggest_uniform(\"subsample\", 0.5, 0.8)\n    min_child_weight = trial.suggest_uniform(\"min_child_weight\", 0.5, 3)\n    reg_lambda = trial.suggest_uniform(\"reg_lambda\", 1.3, 2.3)\n    reg_alpha = trial.suggest_uniform(\"reg_alpha\", 1.5, 2.2)\n    colsample_bytree = trial.suggest_uniform(\"colsample_bytree\", 0.25, 0.8)\n\n    params = dict(use_label_encoder=False,\n                  eval_metric='logloss',\n                  objective='multi:softmax',\n                  n_estimators = n_estimators,\n                  max_depth = max_depth,\n                  learning_rate = learning_rate,\n                  gamma = gamma,\n                  subsample = subsample,\n                  min_child_weight = min_child_weight,\n                  reg_lambda = reg_lambda,\n                  reg_alpha = reg_alpha,                  \n                  colsample_bytree = colsample_bytree,\n                  random_state=42)\n\n    gpu_params = dict(tree_method='gpu_hist',gpu_id=0)\n    params.update(gpu_params)\n\n    model = XGBClassifier(**params)\n    \n    strat_split = StratifiedShuffleSplit(n_splits=n_splits, \n                                         test_size = 0.2, \n                                         random_state=42)\n    lg_loss = []\n    for fold, (train_idx, test_idx) in tqdm(enumerate(strat_split.split(X=X, y=y))):\n        X_train = X.loc[train_idx]\n        y_train = y.loc[train_idx]      \n        X_val = X.loc[test_idx]\n        y_val = y.loc[test_idx]\n\n        #model.fit(X_train, y_train,eval_set=[(X_val,y_val)], early_stopping_rounds=100)\n        model.fit(X_train, y_train)\n        preds = model.predict_proba(X_val)\n        fold_lgloss = log_loss(y_val,preds)\n        lg_loss.append(fold_lgloss)\n\n    print(f\"{y_}Mean log_logss : {np.mean(lg_loss)}{rs_}\")\n    trial.set_user_attr(key=\"best_model\", value=model)\n    return np.mean(lg_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_trails = 25\nstudy = optuna.create_study(direction='minimize', study_name='tps-may2021-xgboost-optuna')\noptimization_function = partial(optimize, X=X_new, y=y_resampled, n_splits=5)\nstudy.optimize(optimization_function,n_trials=num_trails, callbacks=[callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_trial.params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train XGBoost with best parameters","metadata":{}},{"cell_type":"code","source":"params = dict(use_label_encoder=False,\n                  eval_metric='logloss',\n                  objective='multi:softmax',\n              verbosity=1,\n              random_state=42)\nparams.update(study.best_trial.params)\ngpu_params = dict(tree_method='gpu_hist',gpu_id=0)\nparams.update(gpu_params)\nparams","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best_model=study.user_attrs[\"best_model\"]\nbest_model = XGBClassifier(**params)\nbest_model.fit(X_new,y_resampled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"predictions = best_model.predict_proba(test[all_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.DataFrame(predictions, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"])\nsubmit['id'] = submission['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv(\"xgboost_baseline.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}