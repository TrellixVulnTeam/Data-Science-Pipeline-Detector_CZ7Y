{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The first step in kaggle is to get better results in an easy way.\n\nKaggleの第一歩は楽は方法でより良い結果をえることが重要です。\n\nLightGBM+ optuna　is a very good tool for first trail.Then acheived SCORE 1.08633!!!\n\nLightGBM+ optuna は初めの手にはとても良いツールで、SCORE 1.08633でした。\nhttps://www.kaggle.com/hayahiko/tps-may-easy-way-lgbm-optuna-step-by-step\n    \nThis nootbook is second step exsample.\n\nこの方法ノートブックはふたつめの事例です。\n\nDon't forget to vote !!","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading files from directory\nimport os\nimport pickle\n \n# Data manipulation & analysis\nimport pandas as pd\npd.set_option('display.max_columns',100)\npd.set_option('display.max_rows', 500)\nimport datetime as dt\n \nimport numpy as np\nimport scipy\n\n# Visualisation\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n \n # 実行に関係ない警告を無視\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm\nimport gc\nimport json\nimport math\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import accuracy_score,roc_auc_score,log_loss\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\n\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\n\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2021/test.csv\")\nsubmission = pd.read_csv(\"../input/tabular-playground-series-may-2021/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head())\ndisplay(train.describe())\ndisplay(train.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(test.head())\ndisplay(test.describe())\ndisplay(test.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------------------\n#数値の特徴量　※上級者は、特徴量のリストを作成している。\n#------------------------------\nfeatures_num = ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n       'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n       'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n       'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', ]\nfeatures_cat = ['target'] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical features distribution \n\n# Params\nn_col = 1\nn_row = round(len(features_num) )\nsize = (n_col * 10, n_row * 4.5)\n\n#Create figure\nplt.subplots(n_row,n_col,figsize=size)\n\n# enumerate関数　for - loop コードの代用 \nfor  i ,feature  in enumerate(features_num , 1):\n    plt.subplot(n_row, n_col , i)\n    sns.countplot(x = feature, hue = 'target', data = train)\n    plt.xlabel(feature, fontsize=9); plt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##--------------------------------------------\n#カテゴリfeature  　ラベルエンコーダー\n#---------------------------------------------\nfor feature in features_cat :\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習データを特徴量と目的変数に分ける  正解ラべルを記入\ntrain_x = train.drop(['target'], axis=1)\ntrain_y = train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 変数Idを除外する\ntrain_x = train_x.drop(['id'], axis=1)\ntest_x = test.drop(['id'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Trial 関数で最適化を探索\n##計算量を減らすために、Hold-out法で2:8に分割\n##パラメータ探索は重要パラメータをsuggest_int(整数で全部探索) , その他をsuggest_categorical（リスト内を選択）\n\ndef objective(trial,data=train_x,target=train_y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=71)\n    params = {#'iterations':trial.suggest_int(\"iterations\", 4000, 10000),\n             'iterations':trial.suggest_int(\"iterations\", 17000, 17000),\n             'od_type':'Iter',\n              'od_wait':trial.suggest_int('od_wait', 1000, 1000),\n              #'od_wait':trial.suggest_int('od_wait', 500, 2300),\n             'loss_function':'MultiClass',\n              'eval_metric':'MultiClass',\n              #'leaf_estimation_method':'Newton',\n              #'bootstrap_type': 'Bernoulli',\n              #'learning_rate' : trial.suggest_uniform('learning_rate',0.02,0.3),\n              'learning_rate' : trial.suggest_uniform('learning_rate',0.01,0.01),\n              #'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n              #'subsample': trial.suggest_uniform('subsample',0,1),\n              #'random_strength': trial.suggest_uniform('random_strength',10,30),\n              #'depth': trial.suggest_int('depth',1,6),\n              'depth': trial.suggest_int('depth',4,4), #FIX\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,3),\n              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,3),\n              'max_ctr_complexity': trial.suggest_int('max_ctr_complexity',15,15),\n               }\n    model = CatBoostClassifier(**params)  \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n        \n    preds_opt = model.predict_proba(test_x)\n\n\n    log_loss_multi = log_loss(test_y, preds_opt)\n    \n    return log_loss_multi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import train_test_split\n\nfrom catboost import CatBoostClassifier\nOPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')  #'maximize''minimize\nstudy.optimize(objective, n_trials=35)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################\n#######   Catboost \n################################\n\ntrain_oof_cat_0 = np.zeros((len(train_x), 4))\ntemp_test = np.zeros((len(test_x), 4))\n\ncat_params = study.best_trial.params\ncat_params['loss_function'] = 'MultiClass'\n#cat_params['eval_metric'] = 'MultiClass'\n#cat_params['bootstrap_type']= 'Bernoulli'\n#cat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = 42\n\n\nNUM_FOLDS = 5\nkf =  StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train_x, train_y))):\n        print(f'Fold {f+1}')\n        train_df = train_x.iloc[train_ind].reset_index(drop=True)\n        val_df = train_x.iloc[val_ind].reset_index(drop=True)\n        train_target = train_y.iloc[train_ind].reset_index(drop=True)\n        val_target = train_y.iloc[val_ind].reset_index(drop=True)\n\n        model =CatBoostClassifier(**cat_params)\n        \n        model =  model.fit(train_df, train_target,eval_set=[(val_df,val_target)],\n                           early_stopping_rounds=30,verbose=False)\n        \n        temp_oof = model.predict_proba(val_df)\n        print(log_loss(val_target, temp_oof))\n        train_oof_cat_0[val_ind] = temp_oof\n\n        temp_test += model.predict_proba(test_x)\n        test_preds_cat_0 = temp_test/NUM_FOLDS\n        test_preds_cat_0 = np.clip(test_preds_cat_0, 0.08, 0.95)\n        \nprint('All_logloss',log_loss(train_y, train_oof_cat_0))\nnp.save('train_oof_cat_0', train_oof_cat_0 ) #for validation\nnp.save('test_preds_cat_0',test_preds_cat_0 ) #for submission","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### 提出用ファイルの作成 ヘッダー無設の設定\nsubmission = pd.DataFrame( test_preds_cat_0)\nsubmission.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\nsubmission['id'] = test['id']\nsubmission = submission[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4']]\n\nsubmission.to_csv(\"submission_cat.csv\", index=False)\ndisplay(submission.head(), submission.tail())","metadata":{},"execution_count":null,"outputs":[]}]}