{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Masked LSTM to predict rainfall"},{"metadata":{"_uuid":"ac30d9d29d899f7442202921c93890144091da36"},"cell_type":"markdown","source":"Forked from https://www.kaggle.com/andkul/deep-lstm-to-predict-rainfall with some changes to the model, in particular I added the masking of paddded time steps and BatchNormalization between each layer (except the first).\nThe optimizer here is [Nadam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam) (Adam + Nesterov momentum) rather than Adam."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nN_FEATURES = 22\n# taken from http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\nTHRESHOLD = 73 ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d56776a079d32c8c8072fed68e810ddbef4a2e31"},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"_uuid":"1cb186ee685e813e8b25ff4ece970c6c8b991896"},"cell_type":"markdown","source":"## Training set"},{"metadata":{"trusted":true,"_uuid":"0128381de6a5c3121da3e438131ba3097eff9399"},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/train.zip\")\n# to reduce memory consumption\ntrain_df[train_df.columns[1:]] = train_df[train_df.columns[1:]].astype(np.float32)\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cec887040a3d4eefab0ffa09714e40163f6b3124"},"cell_type":"markdown","source":"Remove ids with NaNs in `Ref` column for each observation (obeservations, where we have no data from radar)"},{"metadata":{"trusted":true,"_uuid":"3442cf49481dba451b8d484bf3240a226bbf4aa2"},"cell_type":"code","source":"good_ids = set(train_df.loc[train_df['Ref'].notna(), 'Id'])\ntrain_df = train_df[train_df['Id'].isin(good_ids)]\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af1557101c6ac14b071d17a1290463a77a8ea01d"},"cell_type":"markdown","source":"Replace NaN values with zeros"},{"metadata":{"trusted":true,"_uuid":"52d81776a64916c4736c7264c1867cf78e040bc9"},"cell_type":"code","source":"train_df.reset_index(drop=True, inplace=True)\ntrain_df.fillna(0.0, inplace=True)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb2e9ee31f0d00e3196d525501a318419b87cd1e"},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f8df8cdcd6aea2a2ac312f06b1b2025ae2edcbf"},"cell_type":"markdown","source":"Define and exclude outliers from training set"},{"metadata":{"trusted":true,"_uuid":"db2c9d78a7947516ed683b7a84c6fc72dcb5588a"},"cell_type":"code","source":"train_df = train_df[train_df['Expected'] < THRESHOLD]\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92507551963e045d71f284dc39f46ecc5e3850ea"},"cell_type":"markdown","source":"### Grouping and padding into sequences"},{"metadata":{"trusted":true,"_uuid":"087fda9fa805367bd410865ef660ac4804833e24"},"cell_type":"code","source":"train_groups = train_df.groupby(\"Id\")\ntrain_size = len(train_groups)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75c1507c5fc63e0e7b4f5bfc6693a5ec0833b870"},"cell_type":"code","source":"MAX_SEQ_LEN = train_groups.size().max()\nMAX_SEQ_LEN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"087fda9fa805367bd410865ef660ac4804833e24"},"cell_type":"code","source":"X_train = np.zeros((train_size, MAX_SEQ_LEN, N_FEATURES), dtype=np.float32)\ny_train = np.zeros(train_size, dtype=np.float32)\n\ni = 0\nfor _, group in train_groups:\n    X = group.values\n    seq_len = X.shape[0]\n    X_train[i,:seq_len,:] = X[:,1:23]\n    y_train[i] = X[0,23]\n    i += 1\n    del X\n    \ndel train_groups\nX_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b452d668a2fcdd122733513c3c5789cec1c1747"},"cell_type":"markdown","source":"## Test set"},{"metadata":{"trusted":true,"_uuid":"19d69e1b54bbcbbee5f34956191815372815af44"},"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/test.zip\")\ntest_df[test_df.columns[1:]] = test_df[test_df.columns[1:]].astype(np.float32)\ntest_ids = test_df['Id'].unique()\n\n# Convert all NaNs to zero\ntest_df = test_df.reset_index(drop=True)\ntest_df = test_df.fillna(0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3291ce0840993195bf9f0af65f93a9a4257b1a90"},"cell_type":"code","source":"test_groups = test_df.groupby(\"Id\")\ntest_size = len(test_groups)\n\nX_test = np.zeros((test_size, MAX_SEQ_LEN, N_FEATURES), dtype=np.float32)\n\ni = 0\nfor _, group in test_groups:\n    X = group.values\n    seq_len = X.shape[0]\n    X_test[i,:seq_len,:] = X[:,1:23]\n    i += 1\n    del X\n    \ndel test_groups\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c31acdddb00a957700f0810c1f511ad7fda3b86"},"cell_type":"markdown","source":"# Models"},{"metadata":{"trusted":true,"_uuid":"c4e0bcb62f536c8ae9809a706b19b0a37082e790"},"cell_type":"code","source":"from keras.layers import (\n    Input,\n    Dense,\n    LSTM,\n    GlobalAveragePooling1D,\n    AveragePooling1D,\n    TimeDistributed,\n    Flatten,\n    Bidirectional,\n    Dropout,\n    Masking,\n    Layer,\n    BatchNormalization\n)\nfrom keras.models import Model\nfrom keras.optimizers import Adam,Nadam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09716c1155a4c2bf8d2491a2aa6f8e49979a9545"},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_delta=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d21af54467e2f5a5cd4311adf994a3d909b22009"},"cell_type":"code","source":"BATCH_SIZE = 1024\nN_EPOCHS = 30","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7229a9d177f0e809b54f39845d892b06e604c34"},"cell_type":"markdown","source":"## Architecture of the model"},{"metadata":{},"cell_type":"markdown","source":"Before creating the model we define a subclass of the class Layer provided by Keras. This because all layers in or model support [Masking](https://www.tensorflow.org/guide/keras/masking_and_padding) except Flatten. Thus before the Flatten layer we need to remove the mask."},{"metadata":{"trusted":true},"cell_type":"code","source":"class NonMasking(Layer):   \n    def __init__(self, **kwargs):   \n        self.supports_masking = True  \n        super(NonMasking, self).__init__(**kwargs)   \n    def build(self, input_shape):   \n        input_shape = input_shape   \n    def compute_mask(self, input, input_mask=None):   \n        # do not pass the mask to the next layers   \n        return None   \n    def call(self, x, mask=None):   \n        return x   \n    def get_output_shape_for(self, input_shape):   \n        return input_shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b2b157e77a47fed40ac72e0d8940f3a330eb08f"},"cell_type":"code","source":"def get_model_deep(shape=(MAX_SEQ_LEN, N_FEATURES)):\n    inp = Input(shape)\n    x = Dense(16)(inp)\n    x = BatchNormalization()(x)\n    x = Masking(mask_value=0.)(x)\n    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n    x = BatchNormalization()(x)\n    x = TimeDistributed(Dense(64))(x)\n    x = BatchNormalization()(x)\n    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n    x = BatchNormalization()(x)\n    x = TimeDistributed(Dense(1))(x)\n    x = BatchNormalization()(x)\n    x = NonMasking()(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1)(x)\n\n    model = Model(inp, x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f3513444098821f1262b14570995f2cac764e3a"},"cell_type":"code","source":"model = get_model_deep()\nmodel.compile(optimizer=Nadam(lr=0.001), loss='mae')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0ce8aa384b020014c6e954db9c34a3c98cc9997"},"cell_type":"code","source":"history = model.fit(X_train, y_train, \n            batch_size=BATCH_SIZE, epochs=N_EPOCHS, \n            validation_split=0.2, callbacks=[early_stopping, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\ndel history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c0c77a514d93ccb0eb4eda8e7ed483a9cd3c0ff"},"cell_type":"code","source":"y_pred = model.predict(X_test, batch_size=BATCH_SIZE)\nsubmission = pd.DataFrame({'Id': test_ids, 'Expected': y_pred.reshape(-1)})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}