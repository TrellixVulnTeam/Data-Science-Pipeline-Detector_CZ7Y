{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  <div id=\"MONK\">  ** [MONK](https://github.com/Tessellate-Imaging/monk_v1)** </div>"},{"metadata":{},"cell_type":"markdown","source":"*Monk is a low code Deep Learning tool and a unified wrapper for Computer Vision.*"},{"metadata":{},"cell_type":"markdown","source":"**Monk Features**"},{"metadata":{},"cell_type":"markdown","source":"* low-code\n* unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n* syntax invariant wrapper\n"},{"metadata":{},"cell_type":"markdown","source":"**Monk Enables**"},{"metadata":{},"cell_type":"markdown","source":"1. To create, manage and version control deep learning experiments.\n2. To compare experiments across training metrics.\n3. To quickly find best hyper-parameters.\n"},{"metadata":{},"cell_type":"markdown","source":"Goals"},{"metadata":{},"cell_type":"markdown","source":"- To experiment with Models\n- Understand how easy is it to use Monk"},{"metadata":{},"cell_type":"markdown","source":"# **Table of Contents**"},{"metadata":{},"cell_type":"markdown","source":"* [MONK](#MONK)\n* [Exploratory Data Analysis/ Data Visualization](#dv)\n* [Installing Monk](#installingmonk)\n* [Importing Pytorch Backend](#pyb)\n* [Creating and Managing experiments](#cme)\n* [Quick Mode Training - Load the data and the model](#train)\n* [EDA Using Monk](#edaM)\n* [See what other models Monk's backend supports](#mod)\n* [Train the classifier](#tc)\n* [Running inference on test images](#inf)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"dv\"> ** Exploratory Data Analysis ** </div>"},{"metadata":{},"cell_type":"markdown","source":"Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viewing 4 images in train folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axarr = plt.subplots(2,2)\nimg1 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/train/96b00332-21bc-11ea-a13a-137349068a90.jpg')\nimg2 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/train/879d74d8-21bc-11ea-a13a-137349068a90.jpg')\nimg3 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/train/9017f7aa-21bc-11ea-a13a-137349068a90.jpg')\nimg4 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/train/90d93c58-21bc-11ea-a13a-137349068a90.jpg')\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viewing 4 images in test folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axarr = plt.subplots(2,2)\nimg1 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/test/86761d58-21bc-11ea-a13a-137349068a90.jpg')\nimg2 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/test/86767820-21bc-11ea-a13a-137349068a90.jpg')\nimg3 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/test/86763c0c-21bc-11ea-a13a-137349068a90.jpg')\nimg4 = cv2.imread('/kaggle/input/iwildcam-2020-fgvc7/test/867665c4-21bc-11ea-a13a-137349068a90.jpg')\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Converting Json to required CSV format*"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_train_annotations.json') as json_file:\n    train_annotations_json = json.load(json_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_annotations_json.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_annotations = pd.DataFrame(train_annotations_json[\"annotations\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_annotations.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = df_annotations[[\"image_id\",\"category_id\"]].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Adding extension .jpg to image_id*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for index,row in data_train.iterrows():\n    #print(row)\n    #print(index)\n    pathname = str(row['image_id'])+'.jpg'\n    data_train.loc[index,'image_id']=pathname","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of images excluding the corrupted ones\nlen(data_train.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data_train.image_id.astype('str')\n#data_train.category_id.astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.to_csv(\"train.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(r'/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_test_information.json') as json_file:\n    test_information_json = json.load(json_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_information_json.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_information_images = pd.DataFrame(test_information_json[\"images\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_information_images.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = test_information_images[[\"file_name\",\"id\"]].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.rename(columns={'id':'Id'},inplace=True)\n# Adding a new column\ndata_test['Category'] = 0 # 0 is the default value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"installingmonk\"> **[Installing Monk](https://github.com/Tessellate-Imaging/monk_v1/tree/master/installation)** </div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/Tessellate-Imaging/monk_v1.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Imports*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Monk\nimport os\nimport sys\nsys.path.append(\"monk_v1/monk/\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"pyb\"> *Using Pytorch backend* </div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using pytorch backend \nfrom pytorch_prototype import prototype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* To use mxnet backend\n\nfrom gluon_prototype import prototype\n\n* To use keras backend\n\nfrom keras_prototype import prototype"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"cme\"> Creating and managing experiments </div>\n- Provide project name\n- Provide experiment name\n- For a specific data create a single project\n- Inside each project multiple experiments can be created\n- Every experiment can be have diferent hyper-parameters attached to it"},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = prototype(verbose=1);\ngtf.Prototype(\"iWildCam2020\", \"Using_Pytorch_Backend\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This creates files and directories as per the following structure\nworkspace\n\n\n    |\n    |--------iWildCam2020 (Project name can be different)\n                    |\n                    |\n                    |-----Using_Pytorch_Backend (Experiment name can be different)\n                                |\n                                |-----experiment-state.json\n                                |\n                                |-----output\n                                        |\n                                        |------logs (All training logs and graphs saved here)\n                                        |\n                                        |------models (all trained models saved here)"},{"metadata":{},"cell_type":"markdown","source":"# Load the data and the model"},{"metadata":{},"cell_type":"markdown","source":"Docs on  quick mode loading of data and model: https://github.com/Tessellate-Imaging/monk_v1#4\n\nTutorials on Monk: https://github.com/Tessellate-Imaging/monk_v1/tree/master/study_roadmaps/1_getting_started_roadmap"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"train\"> Quick mode training </div>\n- Using Default Function\n    - dataset_path\n    - model_name\n    - num_epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Default(dataset_path=\"/kaggle/input/iwildcam-2020-fgvc7/train/\",\n            path_to_csv=\"train.csv\", # updated csv file \n            model_name=\"resnet18\", \n            freeze_base_network=False,\n            num_epochs=10); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Dataset_Percent(20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Default(dataset_path=\"/kaggle/input/iwildcam-2020-fgvc7/train/\",\n            path_to_csv=\"/kaggle/working/sampled_dataset_train.csv\", # updated csv file \n            model_name=\"resnet18\", \n            freeze_base_network=False,\n            num_epochs=1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"edaM\"> EDA in MONK </div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.EDA(check_corrupt=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"mod\"> See what other models Monk's backend supports </div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.List_Models();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"tc\"> Train the classifier </div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pillow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nprint('PIL',PIL.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Start Training\ngtf.Train();\n#Read the training summary generated once you run the cell and training is completed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div id=\"inf\"> **Running inference on test images** </div>"},{"metadata":{},"cell_type":"markdown","source":"Load the experiment in inference mode\n- Set flag eval_infer as True"},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = prototype(verbose=1);\ngtf.Prototype(\"iWildCam2020\", \"Using_Pytorch_Backend\", eval_infer=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select image and Run inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = \"/kaggle/input/iwildcam-2020-fgvc7/test/867611a0-21bc-11ea-a13a-137349068a90.jpg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = \"/kaggle/input/iwildcam-2020-fgvc7/test/8676382e-21bc-11ea-a13a-137349068a90.jpg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Running Inference on all test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook as tqdm\nfrom scipy.special import softmax\n\nfor i in tqdm(range(len(data_test))):\n    #img_name = \"/kaggle/input/iwildcam-2020-fgvc7/test/\" + data_test[\"Id\"][i] + \".jpg\";\n    img_name = \"/kaggle/input/iwildcam-2020-fgvc7/test/\" + data_test[\"file_name\"][i];\n    #Invoking Monk's nferencing engine inside a loop\n    prediction = gtf.Infer(img_name=img_name, return_raw=True);\n    data_test.loc[i,\"Category\"] = prediction;\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test_new = data_test[[\"Id\",\"Category\"]].copy() # as per the format given ,the csv file must contain Id and Category\ndata_test_new.to_csv(\"submission.csv\", index=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! rm -r monk_v1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! rm -r workspace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! rm pylg.log train.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **To contribute to Monk AI or Pytorch RoadMap repository raise an issue in the git-repo or DM us on linkedin** "},{"metadata":{},"cell_type":"markdown","source":"* https://www.tessellateimaging.com/\n* Abhishek - https://www.linkedin.com/in/abhishek-kumar-annamraju/\n* Akash - https://www.linkedin.com/in/akashdeepsingh01/"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}