{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os as os\nimport json as json\nimport pandas as pd\nimport matplotlib.image as mpimg\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_train_annotations.json') as json_data:\n    train_annotations = json.load(json_data)\n    print(\"Train annotations: \", train_annotations.keys())\n\nwith open('/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_megadetector_results.json') as json_data:\n    megadetector_results = json.load(json_data)\n    print(\"Megadetector results: \", megadetector_results.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_images = pd.DataFrame(train_annotations[\"images\"])\ndisplay(df_train_images.sample(5))\n\ndf_train_annotations = pd.DataFrame(train_annotations[\"annotations\"])\ndisplay(df_train_annotations.sample(5))\n\ndf_detections = pd.DataFrame(megadetector_results[\"images\"])\ndisplay(df_detections.sample(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate ids randomly from df_train_images\n# Obtain detections of those ids from the df_detections dataframe\n# Draw them and display \n\nsample_ids = set()\n\nfor i in range(50):\n    chosen = False\n    while not chosen:\n        potential = df_train_images.id.sample(1).values[0]\n        detections = df_detections[df_detections[\"id\"] == potential][\"detections\"].values[0]\n        confs = [detection[\"conf\"] for detection in detections if detection[\"conf\"] > 0.9]\n        if len(confs) == 0 and potential not in sample_ids:\n            continue\n        chosen = True\n        sample_ids.add(potential)\n    \n\nfor sample_id in sample_ids:\n    detections = df_detections[df_detections[\"id\"] == sample_id][\"detections\"].values[0]\n    \n    img = mpimg.imread(\"/kaggle/input/iwildcam-2020-fgvc7/train/\" + sample_id + \".jpg\")\n    \n    _ = plt.figure(figsize = (15,20))\n    _ = plt.axis('off')\n    ax = plt.gca()\n    # ax.text(10,100, f'{cat} {count}', fontsize=20, color='fuchsia')\n\n    for detection in detections:\n        # ref - https://github.com/microsoft/CameraTraps/blob/e530afd2e139580b096b5d63f0d7ab9c91cbc7a4/visualization/visualization_utils.py#L392\n        if detection[\"conf\"] < 0.9:\n            continue\n        x_rel, y_rel, w_rel, h_rel = detection['bbox']    \n        img_height, img_width, _ = img.shape\n        x = x_rel * img_width\n        y = y_rel * img_height\n        w = w_rel * img_width\n        h = h_rel * img_height\n        \n        cat = 'animal' if detection['category'] == \"1\" else 'human'\n        bbox = patches.FancyBboxPatch((x,y), w, h, alpha=0.8, linewidth=6, capstyle='projecting', edgecolor='fuchsia', facecolor=\"none\")\n        \n        ax.text(x+1.5, y-8, f'{cat} {detection[\"conf\"]}', fontsize=10, bbox=dict(facecolor='fuchsia', alpha=0.8, edgecolor=\"none\"))\n        ax.add_patch(bbox)\n\n    _ = plt.imshow(img)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}