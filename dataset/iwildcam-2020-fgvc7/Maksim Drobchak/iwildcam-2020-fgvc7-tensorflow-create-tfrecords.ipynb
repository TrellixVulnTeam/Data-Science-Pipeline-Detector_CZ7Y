{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Part â„–1 create tfrecords"},{"metadata":{},"cell_type":"markdown","source":"### Simple example how you can to start with Tensorflow for all type accelerators (TPU, GPU, CPU)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os, sys, math, json\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nif 'google.colab' in sys.modules:\n    %tensorflow_version 2.x\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/iwildcam-2020-fgvc7/iwildcam2020_megadetector_results.json', encoding='utf-8') as json_file:\n    megadetector_results =json.load(json_file)\ndetect_df     = pd.DataFrame(megadetector_results[\"images\"])\n# detect_df     = detect_df.loc[detect_df.max_detection_conf > 0.6].reset_index(drop=True)\n# ids           = detect_df['id'].map(lambda x: '/kaggle/input/iwildcam-2020-fgvc7/train/' + x + '.jpg')\n# TRAIN_PATTERN = ids.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_train_annotations.json') as json_file:\n    train_annotations_json = json.load(json_file)\ndf_anot= pd.DataFrame(train_annotations_json[\"annotations\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_PATTERN = '/kaggle/input/iwildcam-2020-fgvc7/train/*.jpg'\nTARGET_SIZE = [1980,1080]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cord(detect_list):\n    h = TARGET_SIZE[1]\n    w = TARGET_SIZE[0]\n    batch_detections = []\n    for detect in detect_list:\n        x1, y1,w_box, h_box = detect[\"bbox\"]\n        ymin,xmin,ymax,xmax = y1, x1, y1 + h_box, x1 + w_box\n        (yminn, xminn, ymaxx, xmaxx) = (ymin * h, xmin * w, (ymax * h) - (ymin * h), (xmax*w) - (xmin*w))\n        batch_detections += [[yminn, xminn, ymaxx, xmaxx]]\n    return batch_detections","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recompress_image(image):\n    image = tf.cast(image, tf.uint8)\n    image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n    return image\n    \ndef decode_jpeg_and_label(filename):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits)\n    label = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='/')\n    label = label.values[-1]\n    return image, label\n\ndef resize_and_crop_image(image, label):\n    w = tf.shape(image)[0]\n    h = tf.shape(image)[1]\n    tw = TARGET_SIZE[1]\n    th = TARGET_SIZE[0]\n    resize_crit = (w * th) / (h * tw)\n    image = tf.cond(resize_crit < 1,\n                    lambda: tf.image.resize(image, [w*tw/w, h*tw/w]), # if true\n                    lambda: tf.image.resize(image, [w*th/h, h*th/h])  # if false\n                   )\n    nw = tf.shape(image)[0]\n    nh = tf.shape(image)[1]\n    image = tf.image.crop_to_bounding_box(image, (nw - tw) // 2, (nh - th) // 2, tw, th)\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = tf.data.Dataset.list_files(TRAIN_PATTERN) # This\ndataset = filenames.map(decode_jpeg_and_label, num_parallel_calls=AUTO)\ndataset = dataset.map(resize_and_crop_image, num_parallel_calls=AUTO) \n# dataset = dataset.repeat()\ndataset = dataset.prefetch(AUTO)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_draw_boxes(img, lbl):\n    images_batch = []\n    im_id = lbl.numpy().decode(\"utf-8\").split('.')[0].split('/')[-1]\n    boxxs = get_cord(detect_df.loc[detect_df.id == im_id]['detections'].values[0])\n    category_id = df_anot.loc[df_anot.image_id == im_id]['category_id'].values[0]\n    w = tf.shape(img)[0]\n    h = tf.shape(img)[1]\n    for boxx in boxxs:\n        yminn, xminn, ymaxx, xmaxx = boxx\n        image = tf.image.crop_to_bounding_box(img, int(yminn), int(xminn), int(ymaxx), int(xmaxx))\n        nw = tf.shape(image)[0]\n        nh = tf.shape(image)[1]\n        if nw < nh*2 and nh < nw*2:\n            image = recompress_image(image)\n            images_batch.append({\"image\": image.numpy(), \"label\": category_id, \"im_id\": str.encode(im_id), \"width\": nw, \"height\": nh })\n    return images_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir tfrecords","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For example set ```if tfrecord_counter > 1: break``` you need delete this string<br />\n```tfrecord_size``` set more pictures in one record"},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASSES = [i for i in range(572)]\n\ndef _bytestring_feature(list_of_bytestrings):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n\ndef _int_feature(list_of_ints): # int64\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n\ndef _float_feature(list_of_floats): # float32\n    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n  \n\ndef to_tfrecord(tfrec_filewriter, img_bytes, label, iage_id, width, height):\n    one_hot_class = np.eye(len(CLASSES))[label]\n\n    feature = {\n      \"image\": _bytestring_feature([img_bytes]),\n      \"class\": _int_feature([label]),\n      \"iage_id\":  _bytestring_feature([iage_id]),\n      \"label\": _float_feature(one_hot_class.tolist()),\n      \"size\":  _int_feature([width, height])\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\nprint(\"Writing TFRecords\")\ntfrecord_size = 50 #  you can to set more size\ntfrecord_counter = 0\nbatch_counter = 0\nbatch = []\nbalance = []\n\nfor counter, (image, label) in enumerate(dataset):\n    pack = get_draw_boxes(image, label)\n    batch_counter += len(pack)\n\n    if len(balance) > 0:\n        batch_counter += len(balance)\n        for item in balance:\n            batch += [item]\n        balance = []\n\n    if len(pack) > 0:\n        for item in pack:\n            batch += [item]\n    if tfrecord_counter > 1: # you need to delete this string\n        break\n    if batch_counter >= tfrecord_size:\n        filename = './tfrecords/' + \"{:02d}-{}.tfrec\".format(tfrecord_counter, tfrecord_size)\n        tfrecord_counter+=1\n        with tf.io.TFRecordWriter(filename) as out_file:\n            balance = batch[tfrecord_size:]\n            batch = batch[:tfrecord_size]\n            for record_item in batch:\n                example = to_tfrecord(out_file,\n                                      record_item[\"image\"],\n                                      record_item[\"label\"],\n                                      record_item[\"im_id\"],\n                                      record_item[\"width\"],\n                                      record_item[\"height\"])\n                out_file.write(example.SerializeToString())\n            batch_counter = 0\n            batch = []\n            print(\"Wrote file {} containing {} records\".format(filename, tfrecord_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecord(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"class\": tf.io.FixedLenFeature([], tf.int64), \n        \"iage_id\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.VarLenFeature(tf.float32) ,\n        \"size\": tf.io.FixedLenFeature([2], tf.int64) \n    }\n    example = tf.io.parse_single_example(example, features)\n    width = example['size'][0]\n    height  = example['size'][1]\n    image = tf.image.decode_jpeg(example['image'], channels=3)\n    image = tf.reshape(image, [width,height, 3])\n    iage_id = example['iage_id']\n    class_num = example['class']\n    label = tf.sparse.to_dense(example['label'])\n\n    return image, class_num, label, iage_id\n\noption_no_order = tf.data.Options()\noption_no_order.experimental_deterministic = False\n\nfilenames = tf.io.gfile.glob('/kaggle/working/tfrecords/' + \"*.tfrec\")\ndataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\ndataset = dataset.with_options(option_no_order)\ndataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\ndataset = dataset.shuffle(300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_9_images_from_dataset(dataset):\n    plt.figure(figsize=(13,13))\n    subplot=331\n    for i, (image, label) in enumerate(dataset):\n        plt.subplot(subplot)\n        plt.axis('off')\n        plt.imshow(image.numpy().astype(np.uint8))\n        plt.title(label.numpy().decode(\"utf-8\"), fontsize=16)\n        subplot += 1\n        if i==8:\n            break\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_dataset = dataset.map(lambda image, class_num, label, iage_id: (image, iage_id))\ndisplay_9_images_from_dataset(display_dataset)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}