{"cells":[{"metadata":{},"cell_type":"markdown","source":"The code/model is based on [this kernel](https://www.kaggle.com/tanlikesmath/fastai-starter-iwildcam-2019) and uses a pretrained DenseNet121, along with Mixup as implemented by the fastai library.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport PIL.Image, PIL.ImageFile\n\nPIL.ImageFile.LOAD_TRUNCATED_IMAGES = True\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.utils.mem import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Load"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input/iwildcam-2020-fgvc7')\n\ndebug =1\nif debug:\n    train_pct=0.04\nelse:\n    train_pct=0.5\nbs=32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/iwildcam-2020-fgvc7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(path/'iwildcam2020_train_annotations.json') as f:\n    train_data = json.load(f)\n    \nwith open(path/'iwildcam2020_test_information.json') as f:\n    test_data = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( '#train_data')\nprint()\nfor key in train_data.keys():\n    print( 'length of', key, ':', len(train_data[key]) )\n    if key != 'info':\n        print( 'example:', train_data[key][0])\n    else:\n        print(train_data[key])\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( '#test_data')\nprint()\nfor key in test_data.keys():\n    print( 'length of', key, ':', len(test_data[key]) )\n    if key != 'info':\n        print( 'example:', test_data[key][0])\n    else:\n        print(test_data[key])\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no annotations in test_data as we expect"},{"metadata":{},"cell_type":"markdown","source":"# Data Parsing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame.from_records(train_data['annotations'])\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame.from_records(train_data['annotations'])\ndf_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop the row which has the loading problem with PIL\n\nerror occured with '896c1198-21bc-11ea-a13a-137349068a90', '8792549a-21bc-11ea-a13a-137349068a90', and so on"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_image[df_image['id'] == '896c1198-21bc-11ea-a13a-137349068a90']\n#df_image[df_image['id'] == '8792549a-21bc-11ea-a13a-137349068a90']\n#df_image[df_image['id'] == '87022118-21bc-11ea-a13a-137349068a90']\n\n#df_image[df_image['seq_id'] == '98a295ba-21bc-11ea-a13a-137349068a90']\n#df_image[df_image['location'] == 537]['id'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These images match with same seq_id, '98a295ba-21bc-11ea-a13a-137349068a90', '99136c90-21bc-11ea-a13a-137349068a90'\n\nand location 537\n\nI dropped images from 537 location"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_image = pd.DataFrame.from_records(train_data['images'])\n\nindices = []\n#indices.append( df_train[ df_train['image_id'] == '896c1198-21bc-11ea-a13a-137349068a90' ].index )\n#indices.append( df_train[ df_train['image_id'] == '8792549a-21bc-11ea-a13a-137349068a90' ].index )\nfor _id in df_image[df_image['location'] == 537]['id'].values:\n    indices.append( df_train[ df_train['image_id'] == _id ].index )\n\nfor the_index in indices:\n    df_train = df_train.drop(df_train.index[the_index])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some images have more than 1 count"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['count']>1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.DataFrame.from_records(test_data['images'])\ndf_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['frame_num'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_test.rename(columns={\"id\": \"image_id\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = [ImageList.from_df(df, path=path, cols='image_id', folder=folder, suffix='.jpg') \n               for df, folder in zip([df_train, df_test], ['train', 'test'])]\ndata = (train.split_by_rand_pct(0.2, seed=2020)\n        .label_from_df(cols='category_id')\n        .add_test(test)\n        .transform(get_transforms(), size=32)\n        .databunch(path=Path('.'), bs=bs).normalize())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if debug:\n    src= train.split_subsets(train_size=train_pct, valid_size= train_pct*2)\n#     test=test[:1000]\nelse:\n    src= train.split_subsets(train_size=train_pct, valid_size=0.2, seed=2)\n#     src= train.split_by_rand_pct(0.2, seed=2)\n\nprint(src)\n    \ndef get_data(size, bs, padding_mode='reflection'):\n    return (src.label_from_df(cols='category_id')\n           .add_test(test)\n           .transform(tfms, size=size, padding_mode=padding_mode)\n           .databunch(bs=bs).normalize(imagenet_stats))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(max_rotate=20, max_zoom=1.3, max_lighting=0.4, max_warp=0.4,\n                      p_affine=1., p_lighting=1.)\n\ndata = get_data(224, bs, 'zeros')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _plot(i,j,ax):\n    x,y = data.train_ds[3]\n    x.show(ax, y=y)\n\nplot_multi(_plot, 3, 3, figsize=(12,12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\nwd=1e-2\n#learn = cnn_learner(data, models.densenet121, metrics=error_rate, bn_final=True, wd=wd )\nlearn = cnn_learner(data, models.resnet34, metrics=error_rate, bn_final=True, wd=wd )\nlearn.model_dir= '/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_data(352,bs)\nlearn.data = data\nlearn.fit_one_cycle(6, max_lr=slice(1e-6,1e-4))\nlearn.save('352')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-3\nlearn.fit_one_cycle(4, slice(lr/100, lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# interpretation"},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = learn.get_preds(DatasetType.Test)\ndf_test['Category'] = test_preds[0].argmax(dim=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_test.rename(columns={\"image_id\": \"Id\"})\ndf_test = df_test.drop(['seq_num_frames', 'location', 'datetime', 'frame_num', 'seq_id', 'width', 'height', 'file_name'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/iwildcam-2020-fgvc7/sample_submission.csv')\nsubmission = submission.drop(['Category'], axis=1)\nsubmission = submission.merge(df_test, on='Id')\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}