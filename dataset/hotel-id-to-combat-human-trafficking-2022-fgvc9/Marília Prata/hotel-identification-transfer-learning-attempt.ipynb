{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-18T21:25:47.225204Z","iopub.execute_input":"2022-03-18T21:25:47.225908Z","iopub.status.idle":"2022-03-18T21:26:21.620139Z","shell.execute_reply.started":"2022-03-18T21:25:47.225797Z","shell.execute_reply":"2022-03-18T21:26:21.61899Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras import Model, layers\nfrom keras.callbacks import *\nfrom keras.models import load_model, model_from_json","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:26:52.837996Z","iopub.execute_input":"2022-03-18T21:26:52.838364Z","iopub.status.idle":"2022-03-18T21:26:59.896641Z","shell.execute_reply.started":"2022-03-18T21:26:52.838308Z","shell.execute_reply":"2022-03-18T21:26:59.895512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random images of Hotels\",\"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/102219/**\") ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:32:47.069752Z","iopub.execute_input":"2022-03-18T21:32:47.070084Z","iopub.status.idle":"2022-03-18T21:32:49.705592Z","shell.execute_reply.started":"2022-03-18T21:32:47.070051Z","shell.execute_reply":"2022-03-18T21:32:49.704573Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random images of Hotels\",\"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/10290/**\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:35:46.033566Z","iopub.execute_input":"2022-03-18T21:35:46.034225Z","iopub.status.idle":"2022-03-18T21:35:49.367698Z","shell.execute_reply.started":"2022-03-18T21:35:46.034172Z","shell.execute_reply":"2022-03-18T21:35:49.366541Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# re-size all the images to this\ntrain_input_shape = (224, 224, 3)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:36:39.134607Z","iopub.execute_input":"2022-03-18T21:36:39.135795Z","iopub.status.idle":"2022-03-18T21:36:39.142444Z","shell.execute_reply.started":"2022-03-18T21:36:39.135733Z","shell.execute_reply":"2022-03-18T21:36:39.141159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/'\nvalid_path = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_masks/'","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:08:29.957685Z","iopub.execute_input":"2022-03-18T22:08:29.958039Z","iopub.status.idle":"2022-03-18T22:08:29.963399Z","shell.execute_reply.started":"2022-03-18T22:08:29.958Z","shell.execute_reply":"2022-03-18T22:08:29.962418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load pre-trained VGG16 model\nvgg = VGG16(weights='imagenet', include_top=False, input_shape=train_input_shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:08:36.650127Z","iopub.execute_input":"2022-03-18T22:08:36.65043Z","iopub.status.idle":"2022-03-18T22:08:37.1475Z","shell.execute_reply.started":"2022-03-18T22:08:36.650393Z","shell.execute_reply":"2022-03-18T22:08:37.146189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:08:44.612951Z","iopub.execute_input":"2022-03-18T22:08:44.613224Z","iopub.status.idle":"2022-03-18T22:08:44.618977Z","shell.execute_reply.started":"2022-03-18T22:08:44.613196Z","shell.execute_reply":"2022-03-18T22:08:44.618278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create a CNN network","metadata":{}},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = vgg.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x) \npredictions = layers.Dense(2, activation='softmax')(x) # 2 since we have only 2 categories","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:08:50.56937Z","iopub.execute_input":"2022-03-18T22:08:50.569816Z","iopub.status.idle":"2022-03-18T22:08:50.596386Z","shell.execute_reply.started":"2022-03-18T22:08:50.569773Z","shell.execute_reply":"2022-03-18T22:08:50.595635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(vgg.input, predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:08:55.762824Z","iopub.execute_input":"2022-03-18T22:08:55.763437Z","iopub.status.idle":"2022-03-18T22:08:55.774988Z","shell.execute_reply.started":"2022-03-18T22:08:55.76337Z","shell.execute_reply":"2022-03-18T22:08:55.774197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=predictions)\n\n# view the structure of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:09:00.647211Z","iopub.execute_input":"2022-03-18T22:09:00.648427Z","iopub.status.idle":"2022-03-18T22:09:00.670933Z","shell.execute_reply.started":"2022-03-18T22:09:00.648381Z","shell.execute_reply":"2022-03-18T22:09:00.669773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#What cost and optimization method to use","metadata":{}},{"cell_type":"code","source":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='sparse_categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:09:07.863723Z","iopub.execute_input":"2022-03-18T22:09:07.864104Z","iopub.status.idle":"2022-03-18T22:09:07.874132Z","shell.execute_reply.started":"2022-03-18T22:09:07.864057Z","shell.execute_reply":"2022-03-18T22:09:07.873473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   preprocessing_function=preprocess_input)\n\ntraining_generator = train_datagen.flow_from_directory(train_path,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntest_generator = test_datagen.flow_from_directory(valid_path,\n                                            target_size = (224, 224),\n                                            shuffle=False,\n                                            batch_size = 32,\n                                            class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:09:16.322042Z","iopub.execute_input":"2022-03-18T22:09:16.322297Z","iopub.status.idle":"2022-03-18T22:09:31.335972Z","shell.execute_reply.started":"2022-03-18T22:09:16.32227Z","shell.execute_reply":"2022-03-18T22:09:31.334822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Found 0 images belonging to 0 classes.\n\nThat's the point I should have stopped.","metadata":{}},{"cell_type":"markdown","source":"#Early stopping criteria","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:44:54.72163Z","iopub.execute_input":"2022-03-18T22:44:54.722053Z","iopub.status.idle":"2022-03-18T22:44:54.739702Z","shell.execute_reply.started":"2022-03-18T22:44:54.721999Z","shell.execute_reply":"2022-03-18T22:44:54.738251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 224\nBATCH = 32\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:48:36.767401Z","iopub.execute_input":"2022-03-18T22:48:36.767721Z","iopub.status.idle":"2022-03-18T22:48:36.773407Z","shell.execute_reply.started":"2022-03-18T22:48:36.76769Z","shell.execute_reply":"2022-03-18T22:48:36.772423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting callbakcs\n\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    min_delta=1e-7,\n    restore_best_weights=True,\n)\n\nplateau = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor = 0.2,                                     \n    patience = 2,                                   \n    min_delt = 1e-7,                                \n    cooldown = 0,                               \n    verbose = 1\n) ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:44:59.855054Z","iopub.execute_input":"2022-03-18T22:44:59.855625Z","iopub.status.idle":"2022-03-18T22:44:59.865854Z","shell.execute_reply.started":"2022-03-18T22:44:59.855586Z","shell.execute_reply":"2022-03-18T22:44:59.864462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \n    #Input shape = [width, height, color channels]\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    # Block One\n    x = layers.Conv2D(filters=16, kernel_size=3, padding='valid')(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.2)(x)\n\n    # Block Two\n    x = layers.Conv2D(filters=32, kernel_size=3, padding='valid')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.2)(x)\n    \n    # Block Three\n    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid')(x)\n    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.4)(x)\n\n    # Head\n    #x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    \n    #Final Layer (Output)\n    output = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:48:42.234498Z","iopub.execute_input":"2022-03-18T22:48:42.235662Z","iopub.status.idle":"2022-03-18T22:48:42.254919Z","shell.execute_reply.started":"2022-03-18T22:48:42.235573Z","shell.execute_reply":"2022-03-18T22:48:42.25305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\n\nmodel = get_model()\nmodel.compile(loss='binary_crossentropy'\n              , optimizer = keras.optimizers.Adam(learning_rate=3e-5), metrics='binary_accuracy')\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:49:18.396149Z","iopub.execute_input":"2022-03-18T22:49:18.396521Z","iopub.status.idle":"2022-03-18T22:49:18.614813Z","shell.execute_reply.started":"2022-03-18T22:49:18.396482Z","shell.execute_reply":"2022-03-18T22:49:18.613704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Transfer learning","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.ResNet152V2(\n    weights='imagenet',\n    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    include_top=False)\n\nbase_model.trainable = False\n\ndef get_pretrained():\n    \n    #Input shape = [width, height, color channels]\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    x = base_model(inputs)\n\n    # Head\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.1)(x)\n    \n    #Final Layer (Output)\n    output = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:58:25.991924Z","iopub.execute_input":"2022-03-18T22:58:25.992227Z","iopub.status.idle":"2022-03-18T22:58:37.966905Z","shell.execute_reply.started":"2022-03-18T22:58:25.992196Z","shell.execute_reply":"2022-03-18T22:58:37.96566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\n\nmodel_pretrained = get_pretrained()\nmodel_pretrained.compile(loss='binary_crossentropy'\n              , optimizer = keras.optimizers.Adam(learning_rate=5e-5), metrics='binary_accuracy')\n\nmodel_pretrained.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:58:58.224582Z","iopub.execute_input":"2022-03-18T22:58:58.225019Z","iopub.status.idle":"2022-03-18T22:59:42.180984Z","shell.execute_reply.started":"2022-03-18T22:58:58.22497Z","shell.execute_reply":"2022-03-18T22:59:42.179627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since I don't have csv files, I couldn't make the epochs training, the history, the learning curves.","metadata":{}},{"cell_type":"markdown","source":"#Acknowledgements:\n\nJonas Palucci  https://www.kaggle.com/code/jonaspalucibarbosa/chest-x-ray-pneumonia-cnn-transfer-learning\n\nNagesh Singh Chauhan  https://www.kaggle.com/code/nageshsingh/alienvspredator-transfer-learning","metadata":{}}]}