{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-25T21:39:58.817495Z","iopub.execute_input":"2022-03-25T21:39:58.818547Z","iopub.status.idle":"2022-03-25T21:40:31.658572Z","shell.execute_reply.started":"2022-03-25T21:39:58.818419Z","shell.execute_reply":"2022-03-25T21:40:31.657475Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #6495ED;\"><b style=\"color:#0000FF;\">U-Net Architecture (It's U!)</b></h1></center>\n\nU-Net: Convolutional Networks for Biomedical Image Segmentation\n\nAuthors: Olaf Ronneberger, Philipp Fischer, and Thomas Brox\n\nhttps://arxiv.org/pdf/1505.04597.pdf - Submitted on 18 May 2015\n\n![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)lmb.informatik..uni-freiburg.de","metadata":{}},{"cell_type":"markdown","source":"<h1><span class=\"label label-default\" style=\"background-color:#6495ED;border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:#0000FF; padding:10px\">Network Architecture</span></h1><br>\n\n\"The network architecture is illustrated above. It consists of a contracting path (left side) and an expansive path (right side). The contracting path follows the typical architecture of a convolutional network.\"\n\n\"It consists of the repeated application of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2\nfor downsampling. At each downsampling step the authors doubled the number of feature channels.\"\n\n\"Every step in the expansive path consists of an upsampling of the feature map followed by a 2x2 convolution (“up-convolution”) that halves the number of feature channels, a concatenation with the correspondingly cropped feature map from the contracting path, and two 3x3 convolutions, each followed by a ReLU.\"\n\n\"The cropping is necessary due to the loss of border pixels in every convolution. At the final layer a 1x1 convolution is used to map each 64- component feature vector to the desired number of classes.\"\n\n\"In total the network has 23 convolutional layers. To allow a seamless tiling of the output segmentation map, it is important to select the input tile size such that all 2x2 max-pooling operations are applied to a layer with an even x- and y-size.\"\n\nhttps://arxiv.org/pdf/1505.04597.pdf","metadata":{}},{"cell_type":"code","source":"#Code by Peter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification\n\nfrom random import randint\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.transform import resize\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n\nfrom tqdm import tqdm_notebook","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:05:07.333069Z","iopub.execute_input":"2022-03-25T22:05:07.333525Z","iopub.status.idle":"2022-03-25T22:05:07.342803Z","shell.execute_reply.started":"2022-03-25T22:05:07.333479Z","shell.execute_reply":"2022-03-25T22:05:07.341701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Params and helpers","metadata":{}},{"cell_type":"code","source":"#Code by Peter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification\n\nimg_size_ori = 101\nimg_size_target = 128\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n    #res[:img_size_ori, :img_size_ori] = img\n    #return res\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n    #return img[:img_size_ori, :img_size_ori]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:05:44.597898Z","iopub.execute_input":"2022-03-25T22:05:44.598668Z","iopub.status.idle":"2022-03-25T22:05:44.606054Z","shell.execute_reply.started":"2022-03-25T22:05:44.598612Z","shell.execute_reply":"2022-03-25T22:05:44.605148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_dir = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images'\ntesting_dir = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images'\nvalidation_dir = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_masks'","metadata":{"execution":{"iopub.status.busy":"2022-03-25T21:56:24.026492Z","iopub.execute_input":"2022-03-25T21:56:24.026969Z","iopub.status.idle":"2022-03-25T21:56:24.032568Z","shell.execute_reply.started":"2022-03-25T21:56:24.026918Z","shell.execute_reply":"2022-03-25T21:56:24.031319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1><span class=\"label label-default\" style=\"background-color:#6495ED;border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:#0000FF; padding:10px\">Rectified Linear Unit (ReLU)</span></h1><br>\n\nReLU as Neural Networks Activation Function\n\nBy Serengil - August 21, 2017 \n\nRectifier linear unit or its more widely known name as ReLU becomes popular for the past several years since its performance and speed. In contrast to other common activation functions, ReLU is a linear function. In other words, its derivative is either 0 or 1. However, you might remember that derivative of activation functions are included in backpropagation. \n\nhttps://serengil.wordpress.com/2017/08/21/relu-as-neural-networks-activation-function/\n\n![](https://serengil.files.wordpress.com/2017/08/relu.png)https://serengil.wordpress.com/category/math/","metadata":{}},{"cell_type":"markdown","source":"#What are the chances that I could build that Model below? Not even in my dreams!","metadata":{}},{"cell_type":"code","source":"#Code by Peter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification\n\n#Build model\ndef build_model(input_layer, start_neurons):\n    # 128 -> 64\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    # 64 -> 32\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    # 32 -> 16\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    # 16 -> 8\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n    # 8 -> 16\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n\n    # 16 -> 32\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n\n    # 32 -> 64\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n    # 64 -> 128\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n\n    #uconv1 = Dropout(0.5)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer\n\ninput_layer = Input((img_size_target, img_size_target, 1))\noutput_layer = build_model(input_layer, 16)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:11:36.498775Z","iopub.execute_input":"2022-03-25T22:11:36.499148Z","iopub.status.idle":"2022-03-25T22:11:36.841134Z","shell.execute_reply.started":"2022-03-25T22:11:36.499109Z","shell.execute_reply":"2022-03-25T22:11:36.84038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Peter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification\n\nmodel = Model(input_layer, output_layer)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:13:27.378441Z","iopub.execute_input":"2022-03-25T22:13:27.37933Z","iopub.status.idle":"2022-03-25T22:13:27.391339Z","shell.execute_reply.started":"2022-03-25T22:13:27.379267Z","shell.execute_reply":"2022-03-25T22:13:27.390616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Peter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:13:32.633845Z","iopub.execute_input":"2022-03-25T22:13:32.634427Z","iopub.status.idle":"2022-03-25T22:13:32.648674Z","shell.execute_reply.started":"2022-03-25T22:13:32.634387Z","shell.execute_reply":"2022-03-25T22:13:32.647772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Peter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:13:50.616449Z","iopub.execute_input":"2022-03-25T22:13:50.616794Z","iopub.status.idle":"2022-03-25T22:13:50.641795Z","shell.execute_reply.started":"2022-03-25T22:13:50.616759Z","shell.execute_reply":"2022-03-25T22:13:50.639859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I simply can't go forward because we don't have csv files to proceed with the training/stratification/augmentation that Peter performed in such a brilliant way.","metadata":{}},{"cell_type":"markdown","source":"#Acknwledgement:\n\nPeter Hönigschmid https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification","metadata":{"execution":{"iopub.status.busy":"2022-03-25T22:14:35.678134Z","iopub.execute_input":"2022-03-25T22:14:35.678543Z","iopub.status.idle":"2022-03-25T22:14:35.70873Z","shell.execute_reply.started":"2022-03-25T22:14:35.678502Z","shell.execute_reply":"2022-03-25T22:14:35.707815Z"}}}]}