{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-18T19:00:07.224188Z","iopub.execute_input":"2022-03-18T19:00:07.224513Z","iopub.status.idle":"2022-03-18T19:00:44.174797Z","shell.execute_reply.started":"2022-03-18T19:00:07.22448Z","shell.execute_reply":"2022-03-18T19:00:44.173852Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:white;\">Generative Adversarial Network(GAN)</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"Hotel-ID to Combat Human Trafficking Competition Dataset\n\nAuthors: Rashmi Kamath, Gregory Rolwes, Samuel Black, Abby Stylianou\n\narXiv:2106.05746 cs.CV - https://doi.org/10.48550/arXiv.2106.05746\n\n\n\"Hotel recognition is an important task for human trafficking investigations since victims are often photographed in hotel rooms. Identifying these hotels is vital to trafficking investigations since they can help track down current and future victims who might be taken to the same places.\"\n\n\"Hotel recognition is a challenging fine grained visual classification task as there can be little similarity between different rooms within the same hotel, and high similarity between rooms from different hotels (especially if they are from the same chain).\"\n\n\"Hotel recognition to combat human trafficking poses additional challenges as investigative images are often low quality, contain uncommon camera angles and are highly occluded. Here, we present the 2021 Hotel-ID dataset to help raise awareness for this problem and generate novel approaches.\"\n\n\"The dataset consists of hotel room images that have been crowd-sourced and uploaded through the TraffickCam mobile application. The quality of these images is similar to investigative images and hence models trained on these images have good chances of accurately narrowing down on the correct hotel.\"\n\nhttps://arxiv.org/abs/2106.05746","metadata":{}},{"cell_type":"code","source":"import fnmatch\nimport random as rn\nfrom sklearn.preprocessing import LabelEncoder\n#from keras.utils import to_categorical\nfrom tensorflow.keras.utils import to_categorical\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport random\nimport glob\nimport cv2\nimport sys\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import ImageOps\n\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:59:23.365462Z","iopub.execute_input":"2022-03-18T18:59:23.365851Z","iopub.status.idle":"2022-03-18T18:59:32.205363Z","shell.execute_reply.started":"2022-03-18T18:59:23.36573Z","shell.execute_reply":"2022-03-18T18:59:32.204017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:00:46.355512Z","iopub.execute_input":"2022-03-18T19:00:46.355799Z","iopub.status.idle":"2022-03-18T19:00:46.425905Z","shell.execute_reply.started":"2022-03-18T19:00:46.355768Z","shell.execute_reply":"2022-03-18T19:00:46.424915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dl libraraies\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n\n# specifically for cnn\nfrom keras.layers import Dropout, Flatten,Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:00:52.810059Z","iopub.execute_input":"2022-03-18T19:00:52.810382Z","iopub.status.idle":"2022-03-18T19:00:52.817248Z","shell.execute_reply.started":"2022-03-18T19:00:52.81035Z","shell.execute_reply":"2022-03-18T19:00:52.816321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import notebook \nfrom tqdm.notebook import tqdm as tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nsns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:01:00.681578Z","iopub.execute_input":"2022-03-18T19:01:00.681938Z","iopub.status.idle":"2022-03-18T19:01:02.205879Z","shell.execute_reply.started":"2022-03-18T19:01:00.681905Z","shell.execute_reply":"2022-03-18T19:01:02.204836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.metrics import Recall,AUC\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:01:07.926662Z","iopub.execute_input":"2022-03-18T19:01:07.926992Z","iopub.status.idle":"2022-03-18T19:01:07.933684Z","shell.execute_reply.started":"2022-03-18T19:01:07.926959Z","shell.execute_reply":"2022-03-18T19:01:07.932695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = glob.glob(\"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/*/*\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:20:35.373319Z","iopub.execute_input":"2022-03-18T18:20:35.373567Z","iopub.status.idle":"2022-03-18T18:20:37.710356Z","shell.execute_reply.started":"2022-03-18T18:20:35.373543Z","shell.execute_reply":"2022-03-18T18:20:37.709873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Zaber Ibn Addul Hakim https://www.kaggle.com/zaber666/human-trafficking-basic-eda-data-analysis\n\nfigure, axes = plt.subplots(nrows=5, ncols=3, figsize=(20,15))\nfor i in range(15):\n    path = np.random.choice(files)\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    axes[i//3, i%3].imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:20:41.618972Z","iopub.execute_input":"2022-03-18T18:20:41.619346Z","iopub.status.idle":"2022-03-18T18:20:51.979303Z","shell.execute_reply.started":"2022-03-18T18:20:41.619322Z","shell.execute_reply":"2022-03-18T18:20:51.976416Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras import Model, layers\nfrom keras.callbacks import *\nfrom keras.models import load_model, model_from_json","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:01:38.07264Z","iopub.execute_input":"2022-03-18T19:01:38.073336Z","iopub.status.idle":"2022-03-18T19:01:38.084191Z","shell.execute_reply.started":"2022-03-18T19:01:38.073282Z","shell.execute_reply":"2022-03-18T19:01:38.082933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random Hotels images in Gray Scale\",\"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/100055/**\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:05:23.991644Z","iopub.execute_input":"2022-03-18T19:05:23.991932Z","iopub.status.idle":"2022-03-18T19:05:25.545383Z","shell.execute_reply.started":"2022-03-18T19:05:23.991902Z","shell.execute_reply":"2022-03-18T19:05:25.5419Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom PIL import Image as Img\nfrom keras import Input\nfrom keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\nfrom keras.models import Model\nfrom tensorflow.keras.optimizers import RMSprop","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:06:29.776864Z","iopub.execute_input":"2022-03-18T19:06:29.777165Z","iopub.status.idle":"2022-03-18T19:06:29.782785Z","shell.execute_reply.started":"2022-03-18T19:06:29.77713Z","shell.execute_reply":"2022-03-18T19:06:29.781904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PIC_DIR = f'../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/100297/'\n\n#I changed to 100297 since it has 19 images (100055 has only 5 images)\n\nIMAGES_COUNT = 1125\n\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) // 2\n\nWIDTH = 128\nHEIGHT = 128\n\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n    images.append(np.uint8(pic))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:12:24.043992Z","iopub.execute_input":"2022-03-18T19:12:24.044304Z","iopub.status.idle":"2022-03-18T19:12:25.738703Z","shell.execute_reply.started":"2022-03-18T19:12:24.044269Z","shell.execute_reply":"2022-03-18T19:12:25.737945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If I have an issue with the snippet below in https://www.kaggle.com/mpwolke/weather-gan check input 6","metadata":{}},{"cell_type":"code","source":"#Image shape\nimages = np.array(images) / 255\nprint(images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:13:52.093507Z","iopub.execute_input":"2022-03-18T19:13:52.093791Z","iopub.status.idle":"2022-03-18T19:13:52.101338Z","shell.execute_reply.started":"2022-03-18T19:13:52.09376Z","shell.execute_reply":"2022-03-18T19:13:52.100349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Display the 1st (15) images","metadata":{}},{"cell_type":"code","source":"#Display first 15 images. 100297 has 19 images. Original code was 25\nplt.figure(1, figsize=(10, 10))\nfor i in range(15):\n    plt.subplot(3, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:14:43.790702Z","iopub.execute_input":"2022-03-18T19:14:43.791036Z","iopub.status.idle":"2022-03-18T19:14:45.143371Z","shell.execute_reply.started":"2022-03-18T19:14:43.791001Z","shell.execute_reply":"2022-03-18T19:14:45.14246Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create a Generator","metadata":{}},{"cell_type":"code","source":"LATENT_DIM = 32\nCHANNELS = 3\n\ndef create_generator():\n    gen_input = Input(shape=(LATENT_DIM, ))\n\n    x = Dense(128 * 16 * 16)(gen_input)\n    x = LeakyReLU()(x)\n    x = Reshape((16, 16, 128))(x)\n\n    x = Conv2D(256, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n\n    generator = Model(gen_input, x)\n    return generator","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:17:37.811963Z","iopub.execute_input":"2022-03-18T19:17:37.812293Z","iopub.status.idle":"2022-03-18T19:17:37.823835Z","shell.execute_reply.started":"2022-03-18T19:17:37.812257Z","shell.execute_reply":"2022-03-18T19:17:37.822859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create a Discriminator","metadata":{}},{"cell_type":"code","source":"def create_discriminator():\n    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n\n    x = Conv2D(256, 3)(disc_input)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n\n    x = Dense(1, activation='sigmoid')(x)\n    discriminator = Model(disc_input, x)\n\n    optimizer = RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\n\n    discriminator.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy'\n    )\n\n    return discriminator","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:18:47.126678Z","iopub.execute_input":"2022-03-18T19:18:47.127169Z","iopub.status.idle":"2022-03-18T19:18:47.136992Z","shell.execute_reply.started":"2022-03-18T19:18:47.12713Z","shell.execute_reply":"2022-03-18T19:18:47.136216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Define a Gan Model","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nfrom keras.utils.vis_utils import model_to_dot","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:19:11.168682Z","iopub.execute_input":"2022-03-18T19:19:11.169544Z","iopub.status.idle":"2022-03-18T19:19:11.173406Z","shell.execute_reply.started":"2022-03-18T19:19:11.169508Z","shell.execute_reply":"2022-03-18T19:19:11.172547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = create_generator()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:19:28.16473Z","iopub.execute_input":"2022-03-18T19:19:28.165229Z","iopub.status.idle":"2022-03-18T19:19:28.492171Z","shell.execute_reply.started":"2022-03-18T19:19:28.165195Z","shell.execute_reply":"2022-03-18T19:19:28.491459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(model_to_dot(generator, show_shapes=True).create_png())","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:20:05.625647Z","iopub.execute_input":"2022-03-18T19:20:05.625962Z","iopub.status.idle":"2022-03-18T19:20:06.638491Z","shell.execute_reply.started":"2022-03-18T19:20:05.625927Z","shell.execute_reply":"2022-03-18T19:20:06.637831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = create_discriminator()\ndiscriminator.trainable = False\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:20:36.363225Z","iopub.execute_input":"2022-03-18T19:20:36.364088Z","iopub.status.idle":"2022-03-18T19:20:36.483428Z","shell.execute_reply.started":"2022-03-18T19:20:36.364041Z","shell.execute_reply":"2022-03-18T19:20:36.482043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(model_to_dot(discriminator, show_shapes=True).create_png())","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:21:18.811333Z","iopub.execute_input":"2022-03-18T19:21:18.811622Z","iopub.status.idle":"2022-03-18T19:21:18.96275Z","shell.execute_reply.started":"2022-03-18T19:21:18.811583Z","shell.execute_reply":"2022-03-18T19:21:18.961833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan_input = Input(shape=(LATENT_DIM, ))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:21:44.976125Z","iopub.execute_input":"2022-03-18T19:21:44.976416Z","iopub.status.idle":"2022-03-18T19:21:45.068159Z","shell.execute_reply.started":"2022-03-18T19:21:44.976384Z","shell.execute_reply":"2022-03-18T19:21:45.067342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = RMSprop(learning_rate=.0001, clipvalue=1.0, decay=1e-8)#The `lr` argument is deprecated, use `learning_rate` instead\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:22:56.175241Z","iopub.execute_input":"2022-03-18T19:22:56.175533Z","iopub.status.idle":"2022-03-18T19:22:56.187287Z","shell.execute_reply.started":"2022-03-18T19:22:56.175504Z","shell.execute_reply":"2022-03-18T19:22:56.186407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:23:13.635542Z","iopub.execute_input":"2022-03-18T19:23:13.635805Z","iopub.status.idle":"2022-03-18T19:23:13.645408Z","shell.execute_reply.started":"2022-03-18T19:23:13.635777Z","shell.execute_reply":"2022-03-18T19:23:13.64455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Training the GAN model","metadata":{}},{"cell_type":"markdown","source":"The snippet below take a long time. I should Know when I read: Import Time= GPU!\n\n50 plus 50 till 15000. Let's do something else.","metadata":{}},{"cell_type":"code","source":"import time\niters = 15000\nbatch_size = 16\n\nRES_DIR = 'res2'\nFILE_PATH = '%s/generated_%d.png'\nif not os.path.isdir(RES_DIR):\n    os.mkdir(RES_DIR)\n\nCONTROL_SIZE_SQRT = 6\ncontrol_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) / 2\n\nstart = 0\nd_losses = []\na_losses = []\nimages_saved = 0\nfor step in range(iters):\n    start_time = time.time()\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    generated = generator.predict(latent_vectors)\n\n    real = images[start:start + batch_size]\n    combined_images = np.concatenate([generated, real])\n\n    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n    labels += .05 * np.random.random(labels.shape)\n\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n    d_losses.append(d_loss)\n\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    misleading_targets = np.zeros((batch_size, 1))\n\n    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n    a_losses.append(a_loss)\n\n    start += batch_size\n    if start > images.shape[0] - batch_size:\n        start = 0\n\n    if step % 50 == 49:\n        gan.save_weights('/gan.h5')\n\n        print('%d/%d: d_loss: %.4f,  a_loss: %.4f.  (%.1f sec)' % (step + 1, iters, d_loss, a_loss, time.time() - start_time))\n\n        control_image = np.zeros((WIDTH * CONTROL_SIZE_SQRT, HEIGHT * CONTROL_SIZE_SQRT, CHANNELS))\n        control_generated = generator.predict(control_vectors)\n        \n        for i in range(CONTROL_SIZE_SQRT ** 2):\n            x_off = i % CONTROL_SIZE_SQRT\n            y_off = i // CONTROL_SIZE_SQRT\n            control_image[x_off * WIDTH:(x_off + 1) * WIDTH, y_off * HEIGHT:(y_off + 1) * HEIGHT, :] = control_generated[i, :, :, :]\n        im = Img.fromarray(np.uint8(control_image * 255))#.save(StringIO(), 'jpeg')\n        im.save(FILE_PATH % (RES_DIR, images_saved))\n        images_saved += 1","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(1, figsize=(12, 8))\nplt.subplot(121)\nplt.plot(d_losses, color='red')\nplt.xlabel('epochs')\nplt.ylabel('discriminant losses')\nplt.subplot(122)\nplt.plot(a_losses)\nplt.xlabel('epochs')\nplt.ylabel('adversary losses')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio\n#import shutilimages_to_gif = [] #invalid syntax\n#for filename in os.listdir(RES_DIR):\n    #images_to_gif.append(imageio.imread(RES_DIR + '/' + filename))\n#imageio.mimsave('trainnig_visual.gif', images_to_gif)\n#shutil.rmtree(RES_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T19:38:52.870799Z","iopub.execute_input":"2022-03-18T19:38:52.871751Z","iopub.status.idle":"2022-03-18T19:38:52.876207Z","shell.execute_reply.started":"2022-03-18T19:38:52.871708Z","shell.execute_reply":"2022-03-18T19:38:52.875619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Acknowledgement:\n\nhttps://www.codercto.com/a/103639.html\n\nNagesh Singh Chauhan https://www.kaggle.com/nageshsingh/alienvspredator-transfer-learning\n\nZaber Ibn Addul Hakim https://www.kaggle.com/zaber666/human-trafficking-basic-eda-data-analysis","metadata":{}}]}