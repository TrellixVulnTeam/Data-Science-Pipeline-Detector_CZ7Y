{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T14:16:31.371248Z","iopub.execute_input":"2022-05-19T14:16:31.371595Z","iopub.status.idle":"2022-05-19T14:16:31.400714Z","shell.execute_reply.started":"2022-05-19T14:16:31.371519Z","shell.execute_reply":"2022-05-19T14:16:31.400117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from PIL import Image, ImageOps\nimport os\nimport pickle\nfrom sklearn.model_selection import train_test_split\nnclasses = -1\ntrain = []\ntrain_labels = []\nclass_names = {}\nfor dirname, _, filenames in os.walk('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images'):\n    nclasses += 1\n    class_names[nclasses] = dirname.split(\"/\")[-1]\n    for filename in filenames:\n        train.append(np.asarray(ImageOps.Image.open(os.path.join(dirname, filename)).resize((224,224))))\n        train_labels.append(nclasses)\ndataset = tf.data.Dataset.from_tensor_slices(train)\n\nx_train, x_val, y_train, y_val = train_test_split(train, train_labels, test_size=0.05)\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n# Shuffle and slice the dataset.\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n\n# Now we get a test dataset.\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\nval_dataset = test_dataset.batch(64)\n\n\nwith open('x_train.pkl', 'wb') as f:\n    pickle.dump(x_train, f)\nwith open('x_val.pkl', 'wb') as f:\n    pickle.dump(x_val, f)\nwith open('y_train.pkl', 'wb') as f:\n    pickle.dump(y_train, f)\nwith open('y_val.pkl', 'wb') as f:\n    pickle.dump(y_val, f)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-05-19T14:16:31.402216Z","iopub.execute_input":"2022-05-19T14:16:31.402518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nwith open('../input/70x70hotel/x_train (1).pkl', 'rb') as f:\n    x_train = pickle.load(f)\nwith open('../input/70x70hotel/x_val (1).pkl', 'rb') as f:\n    x_val = pickle.load(f)\nwith open('../input/70x70hotel/y_train (1).pkl', 'rb') as f:\n    y_train = pickle.load(f)\nwith open('../input/70x70hotel/y_val (1).pkl', 'rb') as f:\n    y_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:28:52.001858Z","iopub.execute_input":"2022-06-01T12:28:52.002597Z","iopub.status.idle":"2022-06-01T12:28:52.742825Z","shell.execute_reply.started":"2022-06-01T12:28:52.00255Z","shell.execute_reply":"2022-06-01T12:28:52.741943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nnp.array(x_train).shape\nnclasses = 3316","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:28:52.744778Z","iopub.execute_input":"2022-06-01T12:28:52.745067Z","iopub.status.idle":"2022-06-01T12:28:52.957091Z","shell.execute_reply.started":"2022-06-01T12:28:52.745031Z","shell.execute_reply":"2022-06-01T12:28:52.956255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:28:52.959711Z","iopub.execute_input":"2022-06-01T12:28:52.960328Z","iopub.status.idle":"2022-06-01T12:28:52.96534Z","shell.execute_reply.started":"2022-06-01T12:28:52.960284Z","shell.execute_reply":"2022-06-01T12:28:52.964597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndef vgg_block(num_convs, num_channels):\n    blk = tf.keras.models.Sequential()\n    for _ in range(num_convs):\n        blk.add(tf.keras.layers.Conv2D(num_channels,kernel_size=3,\n                                    padding='same',activation='relu'))\n    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n    return blk","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:28:52.967413Z","iopub.execute_input":"2022-06-01T12:28:52.967704Z","iopub.status.idle":"2022-06-01T12:28:52.97566Z","shell.execute_reply.started":"2022-06-01T12:28:52.967667Z","shell.execute_reply":"2022-06-01T12:28:52.974839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg(conv_arch):\n    net = tf.keras.models.Sequential()\n    # The convulational part\n    for (num_convs, num_channels) in conv_arch:\n        net.add(vgg_block(num_convs, num_channels))\n    # The fully-connected part\n    net.add(tf.keras.models.Sequential([\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(4096, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(4096, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(nclasses+1)]))\n    return net\n\nnet = vgg(conv_arch)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:28:52.977944Z","iopub.execute_input":"2022-06-01T12:28:52.97816Z","iopub.status.idle":"2022-06-01T12:28:53.019442Z","shell.execute_reply.started":"2022-06-01T12:28:52.978109Z","shell.execute_reply":"2022-06-01T12:28:53.018775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nLOSS = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nOPTIMIZER = tf.keras.optimizers.Adam(\n    learning_rate=0.0001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name='Adam')\nEPOCHS = 50","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:28:53.02082Z","iopub.execute_input":"2022-06-01T12:28:53.021287Z","iopub.status.idle":"2022-06-01T12:28:53.027171Z","shell.execute_reply.started":"2022-06-01T12:28:53.02125Z","shell.execute_reply":"2022-06-01T12:28:53.026251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageOps\nimport os\nimport pickle\nfrom sklearn.model_selection import train_test_split\nmodel = vgg(conv_arch)\nmodel.compile(optimizer=OPTIMIZER,\n              loss= LOSS,\n              metrics=[tf.keras.metrics.Precision()])\nhistory = model.fit(train_dataset, epochs=EPOCHS, batch_size=BATCH_SIZE,\n                    validation_data=val_dataset)\n\ntest = []\nimages = []\nfor dirname, _, filenames in os.walk('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images'):\n    for filename in filenames:\n        images.append(filename)\n        test.append(np.asarray(ImageOps.Image.open(os.path.join(dirname, filename)).resize((70,70))))\ntest = np.array(test, dtype=np.float32)\nprint(test.shape)\ny_pred = model.predict(test)\ny_pred = list(map(np.argmax, y_pred))\nd = {'image_id': images, 'hotel_id': list(map(class_names.get, y_pred))}\ndf = pd.DataFrame(data=d)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:29:12.92668Z","iopub.execute_input":"2022-06-01T12:29:12.927073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from sklearn.neighbors import KNeighborsClassifier\nimport os\nfrom PIL import Image, ImageOps\nk = 5\nknc = KNeighborsClassifier(n_neighbors = k)\nknc.fit(train, train_labels)\ntest = []\nimages = []\nfor dirname, _, filenames in os.walk('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images'):\n    for filename in filenames:\n        images.append(filename)\n        test.append(np.asarray(ImageOps.grayscale(Image.open(os.path.join(dirname, filename)).resize((40,40)))).flatten())\n        \ny_pred = knc.predict(test)\nd = {'image_id': images, 'hotel_id': list(map(class_names.get, y_pred))}\ndf = pd.DataFrame(data=d)\ndf.to_csv(\"submission.csv\", index=False)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:23:57.765593Z","iopub.status.idle":"2022-06-01T12:23:57.766511Z","shell.execute_reply.started":"2022-06-01T12:23:57.766224Z","shell.execute_reply":"2022-06-01T12:23:57.766259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import tensorflow_datasets\nds_train, ds_test = tensorflow_datasets.load('cifar100', split=['train', 'test'], shuffle_files=True, as_supervised=True)\nassert isinstance(ds_train, tf.data.Dataset)\nassert isinstance(ds_test, tf.data.Dataset)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:23:57.767861Z","iopub.status.idle":"2022-06-01T12:23:57.768298Z","shell.execute_reply.started":"2022-06-01T12:23:57.768065Z","shell.execute_reply":"2022-06-01T12:23:57.768089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}