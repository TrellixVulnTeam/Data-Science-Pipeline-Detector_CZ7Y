{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"id":"DAY5rHgTm7e8"}},{"cell_type":"code","source":"%env DEEPFILL=jiahuiyu-deepfill-offline\n!cp -r ../input/$DEEPFILL/generative_inpainting_v2 generative_inpainting","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:00:14.621432Z","iopub.execute_input":"2022-06-05T15:00:14.622291Z","iopub.status.idle":"2022-06-05T15:00:16.07532Z","shell.execute_reply.started":"2022-06-05T15:00:14.622151Z","shell.execute_reply":"2022-06-05T15:00:16.074258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/$DEEPFILL/*.whl # neuralgym converted with tf_upgrade_v2","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:00:16.080638Z","iopub.execute_input":"2022-06-05T15:00:16.081035Z","iopub.status.idle":"2022-06-05T15:00:45.013602Z","shell.execute_reply.started":"2022-06-05T15:00:16.080997Z","shell.execute_reply":"2022-06-05T15:00:45.01261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/tf-slim110/*.whl # used for arg_scope in deepfill lib","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:00:45.016034Z","iopub.execute_input":"2022-06-05T15:00:45.016427Z","iopub.status.idle":"2022-06-05T15:01:12.546393Z","shell.execute_reply.started":"2022-06-05T15:00:45.016389Z","shell.execute_reply":"2022-06-05T15:01:12.545086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir checkpoints\n!cp -rf /kaggle/input/deepfill-v2-pretrained/places2_256_deepfill_v2 checkpoints","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:01:12.549151Z","iopub.execute_input":"2022-06-05T15:01:12.549683Z","iopub.status.idle":"2022-06-05T15:01:16.010151Z","shell.execute_reply.started":"2022-06-05T15:01:12.54963Z","shell.execute_reply":"2022-06-05T15:01:16.008559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"cZoSOL9Qm-Yr"}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom PIL import Image as pil_image\nimport tensorflow as tf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.030593,"end_time":"2021-04-17T11:04:51.983376","exception":false,"start_time":"2021-04-17T11:04:51.952783","status":"completed"},"tags":[],"id":"expired-matter","executionInfo":{"status":"ok","timestamp":1619310548121,"user_tz":-120,"elapsed":14459,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"}},"execution":{"iopub.status.busy":"2022-06-05T15:04:55.716727Z","iopub.execute_input":"2022-06-05T15:04:55.71723Z","iopub.status.idle":"2022-06-05T15:04:55.723711Z","shell.execute_reply.started":"2022-06-05T15:04:55.71719Z","shell.execute_reply":"2022-06-05T15:04:55.72196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Global","metadata":{"id":"0B00pe7mnBTj"}},{"cell_type":"code","source":"IMG_SIZE = 512\nPROJECT_FOLDER = \"../input/hotelid-2022-train-images-512x512/\"\nTEST_DATA_FOLDER = \"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/\"","metadata":{"papermill":{"duration":0.030445,"end_time":"2021-04-17T11:04:58.130825","exception":false,"start_time":"2021-04-17T11:04:58.10038","status":"completed"},"tags":[],"id":"contained-brief","executionInfo":{"status":"ok","timestamp":1619310979015,"user_tz":-120,"elapsed":589,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"}},"execution":{"iopub.status.busy":"2022-06-05T15:02:23.054703Z","iopub.execute_input":"2022-06-05T15:02:23.055398Z","iopub.status.idle":"2022-06-05T15:02:23.06073Z","shell.execute_reply.started":"2022-06-05T15:02:23.055348Z","shell.execute_reply":"2022-06-05T15:02:23.059867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inpanting","metadata":{}},{"cell_type":"code","source":"%cd generative_inpainting\nfrom inpaint_model import InpaintCAModel\nimport neuralgym as ng\n\ndef load_inpaint_model(): # Based on batch_test.py\n    FLAGS = ng.Config('inpaint.yml')\n    #ng.get_gpus(1)\n\n    sess_config = tf.compat.v1.ConfigProto()\n    sess_config.gpu_options.allow_growth = True\n    sess = tf.compat.v1.Session(config=sess_config)\n\n    model = InpaintCAModel()\n    tf.compat.v1.disable_eager_execution()\n    input_image_ph = tf.compat.v1.placeholder(\n        tf.float32, shape=(1, IMG_SIZE, IMG_SIZE*2, 3))\n    output = model.build_server_graph(FLAGS, input_image_ph)\n    output = (output + 1.) * 127.5\n    output = tf.reverse(output, [-1])\n    output = tf.saturate_cast(output, tf.uint8)\n    vars_list = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES)\n    assign_ops = []\n    for var in vars_list:\n        vname = var.name\n        from_name = vname\n        var_value = tf.train.load_variable(\"../checkpoints/places2_256_deepfill_v2\", from_name)\n        assign_ops.append(tf.compat.v1.assign(var, var_value))\n    sess.run(assign_ops)\n    print('Model loaded.')\n    return sess, output, input_image_ph\n\ninpaint_model_sess, inpaint_model_output, inpaint_model_ph = load_inpaint_model()\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:02:24.39585Z","iopub.execute_input":"2022-06-05T15:02:24.396353Z","iopub.status.idle":"2022-06-05T15:02:35.228341Z","shell.execute_reply.started":"2022-06-05T15:02:24.396308Z","shell.execute_reply":"2022-06-05T15:02:35.227279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lower_red = np.array([0,0,200])\nupper_red = np.array([55,55,255])\nmask_kernel = np.ones((4,4), np.uint8)\n\ndef get_mask(img):\n    mask = cv2.inRange(img, lower_red, upper_red)\n    mask = cv2.dilate(mask, mask_kernel, iterations=1)\n    return cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n\ndef inpaint_image(image, mask):\n    h, w, _ = image.shape\n    grid = 4\n    image = image[:h//grid*grid, :w//grid*grid, :]\n    mask = mask[:h//grid*grid, :w//grid*grid, :]\n    #print('Shape of image: {}'.format(image.shape))\n\n    image = np.expand_dims(image, 0)\n    mask = np.expand_dims(mask, 0)\n    input_image = np.concatenate([image, mask], axis=2)\n\n    # load pretrained model\n    result = inpaint_model_sess.run(inpaint_model_output, feed_dict={inpaint_model_ph: input_image})\n    return result[0][:, :, ::-1]","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:03:06.849797Z","iopub.execute_input":"2022-06-05T15:03:06.850312Z","iopub.status.idle":"2022-06-05T15:03:06.862488Z","shell.execute_reply.started":"2022-06-05T15:03:06.850271Z","shell.execute_reply":"2022-06-05T15:03:06.861365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pad_image(img):\n    w, h, c = np.shape(img)\n    if w > h:\n        pad = int((w - h) / 2)\n        img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=0)\n    else:\n        pad = int((h - w) / 2)\n        img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=0)\n        \n    return img\n\ndef open_and_preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img = pad_image(img)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    mask = get_mask(img)\n    img = inpaint_image(img, mask)\n    \n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:03:09.816407Z","iopub.execute_input":"2022-06-05T15:03:09.817507Z","iopub.status.idle":"2022-06-05T15:03:09.830842Z","shell.execute_reply.started":"2022-06-05T15:03:09.817416Z","shell.execute_reply":"2022-06-05T15:03:09.829758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test code\nfrom IPython.display import Image\nimg = open_and_preprocess_image(TEST_DATA_FOLDER+'abc.jpg')\ncv2.imwrite(\"test.png\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\nImage(\"test.png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:04:06.726397Z","iopub.execute_input":"2022-06-05T15:04:06.727353Z","iopub.status.idle":"2022-06-05T15:04:12.564436Z","shell.execute_reply.started":"2022-06-05T15:04:06.727281Z","shell.execute_reply":"2022-06-05T15:04:12.563479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# More test code\n# Add new mask and test again\nimg = pil_image.open('test.png')\nmask = pil_image.open('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_masks/00095.png')\nmask = mask.resize((IMG_SIZE, IMG_SIZE))\nimg.paste(mask, (0,0), mask)\nimg.save('test_mask.png')\nImage(\"test_mask.png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:04:58.987007Z","iopub.execute_input":"2022-06-05T15:04:58.987897Z","iopub.status.idle":"2022-06-05T15:04:59.154661Z","shell.execute_reply.started":"2022-06-05T15:04:58.987835Z","shell.execute_reply":"2022-06-05T15:04:59.15304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = open_and_preprocess_image('test_mask.png')\ncv2.imwrite(\"test2.png\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\nImage(\"test2.png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:05:02.189691Z","iopub.execute_input":"2022-06-05T15:05:02.190167Z","iopub.status.idle":"2022-06-05T15:05:07.285548Z","shell.execute_reply.started":"2022-06-05T15:05:02.190124Z","shell.execute_reply":"2022-06-05T15:05:07.282137Z"},"trusted":true},"execution_count":null,"outputs":[]}]}