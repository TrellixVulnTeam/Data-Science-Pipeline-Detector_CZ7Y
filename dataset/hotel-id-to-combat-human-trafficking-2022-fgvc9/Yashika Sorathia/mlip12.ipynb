{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" # This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/'):\n    for filename in filenames:\n        print(\"filename: \", filename)\n#         print(\"middle::\", _)\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T08:15:22.90588Z","iopub.execute_input":"2022-04-26T08:15:22.906348Z","iopub.status.idle":"2022-04-26T08:15:22.943784Z","shell.execute_reply.started":"2022-04-26T08:15:22.906198Z","shell.execute_reply":"2022-04-26T08:15:22.943073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:16:49.54243Z","iopub.execute_input":"2022-05-03T09:16:49.542869Z","iopub.status.idle":"2022-05-03T09:16:49.549118Z","shell.execute_reply.started":"2022-05-03T09:16:49.542833Z","shell.execute_reply":"2022-05-03T09:16:49.548206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.mkdir('../output/kaggle/working/checkpoint/')\n# ! mkdir checkpoint\n!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 224\nBATCH_SIZE = 32\nTRAIN_DS_PATH = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/'\nSEED = 52\nSPLIT = 0.2 \nCHECKPOINT_FNAME = 'ckpt_effNet.h5'","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:16:52.385997Z","iopub.execute_input":"2022-05-03T09:16:52.386333Z","iopub.status.idle":"2022-05-03T09:16:52.390868Z","shell.execute_reply.started":"2022-05-03T09:16:52.3863Z","shell.execute_reply":"2022-05-03T09:16:52.390143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(validation_split=SPLIT, \n                           shear_range=0.2,\n                           zoom_range=0.2,\n                           horizontal_flip=True,\n                           rotation_range=0.1,)\nval_datagen = ImageDataGenerator(validation_split=SPLIT, \n                           shear_range=0.2,\n                           zoom_range=0.2,\n                           horizontal_flip=True,\n                           rotation_range=0.1,)\n\ntrain_ds = train_datagen.flow_from_directory(\n    TRAIN_DS_PATH, \n    subset='training', \n    seed=SEED,\n    target_size=(IMG_SIZE, IMG_SIZE), \n    batch_size=BATCH_SIZE,\n#     classes=['100055', '100143', '100206', '1007', '10191']\n)\nval_ds = val_datagen.flow_from_directory(\n    TRAIN_DS_PATH, \n    subset='validation', \n    seed=SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n#     classes=['100055', '100143', '100206', '1007', '10191']\n)\n# test_ds = tfds.folder_dataset.ImageFolder('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/')\n# train_mask =  tf.keras.utils.image_dataset_from_directory('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_masks/')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:16:54.899326Z","iopub.execute_input":"2022-05-03T09:16:54.899783Z","iopub.status.idle":"2022-05-03T09:17:00.058128Z","shell.execute_reply.started":"2022-05-03T09:16:54.89974Z","shell.execute_reply":"2022-05-03T09:17:00.057233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnum_classes = train_ds.num_classes\ntrain_ds.labels\nprint(num_classes) ","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:17:00.059709Z","iopub.execute_input":"2022-05-03T09:17:00.059995Z","iopub.status.idle":"2022-05-03T09:17:00.065304Z","shell.execute_reply.started":"2022-05-03T09:17:00.059956Z","shell.execute_reply":"2022-05-03T09:17:00.0645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AlexNet\n# model = keras.models.Sequential([\n#     layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n#     keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu'),\n#     keras.layers.BatchNormalization(),\n#     keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n#     keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n#     keras.layers.BatchNormalization(),\n#     keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n#     keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n#     keras.layers.BatchNormalization(),\n#     keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n#     keras.layers.BatchNormalization(),\n#     keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n#     keras.layers.BatchNormalization(),\n#     keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n#     keras.layers.Flatten(),\n#     keras.layers.Dense(4096, activation='relu'),\n#     keras.layers.Dropout(0.5),\n#     keras.layers.Dense(4096, activation='relu'),\n#     keras.layers.Dropout(0.5),\n#     keras.layers.Dense(num_classes, activation='softmax')\n# ])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:58:57.084434Z","iopub.execute_input":"2022-05-02T09:58:57.084962Z","iopub.status.idle":"2022-05-02T09:58:57.091532Z","shell.execute_reply.started":"2022-05-02T09:58:57.084901Z","shell.execute_reply":"2022-05-02T09:58:57.090565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Transfer learning\n# base_model = tf.keras.applications.InceptionResNetV2(\n#                      include_top=False,\n#                      weights='imagenet',\n#                      input_shape=(IMG_SIZE,IMG_SIZE,3)\n#                      )\n  \n# base_model.trainable=False\n\n# model = tf.keras.Sequential([ \n#         base_model,   \n#         tf.keras.layers.BatchNormalization(renorm=True),\n#         tf.keras.layers.GlobalAveragePooling2D(),\n#         tf.keras.layers.Dense(512, activation='relu'),\n#         tf.keras.layers.Dense(256, activation='relu'),\n#         tf.keras.layers.Dropout(0.5),\n#         tf.keras.layers.Dense(128, activation='relu'),\n#         tf.keras.layers.Dense(num_classes, activation='softmax')\n#     ])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:30:25.016839Z","iopub.execute_input":"2022-05-02T11:30:25.017146Z","iopub.status.idle":"2022-05-02T11:30:35.142392Z","shell.execute_reply.started":"2022-05-02T11:30:25.017061Z","shell.execute_reply":"2022-05-02T11:30:35.141365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New Model\nfrom tensorflow.keras.applications import EfficientNetB0\n\nEffNet = EfficientNetB0(include_top=False,\n                             weights='imagenet',\n                             input_tensor=None,\n                             input_shape=([IMG_SIZE, IMG_SIZE, 3]),\n                             pooling='avg'\n                       )\n\nmodel = tf.keras.Sequential()\nmodel.add(EffNet)\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(num_classes, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:17:06.341363Z","iopub.execute_input":"2022-05-03T09:17:06.341787Z","iopub.status.idle":"2022-05-03T09:17:10.136419Z","shell.execute_reply.started":"2022-05-03T09:17:06.341757Z","shell.execute_reply":"2022-05-03T09:17:10.135584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = keras.optimizers.ADAM(learning_rate=0.001)\ncheckpoints = keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_FNAME, verbose=1, save_best_only=False, save_freq=50,save_weights_only=True)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\nmodel.compile(optimizer='Adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:17:17.057325Z","iopub.execute_input":"2022-05-03T09:17:17.057614Z","iopub.status.idle":"2022-05-03T09:17:17.077596Z","shell.execute_reply.started":"2022-05-03T09:17:17.05758Z","shell.execute_reply":"2022-05-03T09:17:17.076994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:17:21.047539Z","iopub.execute_input":"2022-05-03T09:17:21.048276Z","iopub.status.idle":"2022-05-03T09:17:21.069581Z","shell.execute_reply.started":"2022-05-03T09:17:21.048236Z","shell.execute_reply":"2022-05-03T09:17:21.068743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=5\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs, \n  steps_per_epoch = len(train_ds.labels)/BATCH_SIZE,\n  validation_steps = len(val_ds.labels)/BATCH_SIZE,\n  callbacks = [checkpoints,early_stop]\n#   verbose = 2,\n#   batch_size = batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:17:28.931102Z","iopub.execute_input":"2022-05-03T09:17:28.931384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:26:50.753627Z","iopub.execute_input":"2022-05-01T17:26:50.754357Z","iopub.status.idle":"2022-05-01T17:26:51.101469Z","shell.execute_reply.started":"2022-05-01T17:26:50.754299Z","shell.execute_reply":"2022-05-01T17:26:51.100083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code_test=model.predict(test_ds)\n# test_ds.class_indices\n# train_ds.classes\n\nclass_indices = {k: v for v, k in enumerate(train_ds.classes)}\n# class_indices","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:26:58.547828Z","iopub.execute_input":"2022-05-01T17:26:58.54853Z","iopub.status.idle":"2022-05-01T17:26:58.552825Z","shell.execute_reply.started":"2022-05-01T17:26:58.548492Z","shell.execute_reply":"2022-05-01T17:26:58.552028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create test ds\nimport os\ntest_ds_path = []\nfor dirname, _, filenames in os.walk('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/'):\n    path_dict = {}\n    for filename in filenames:\n        \n#         print(os.path.join(dirname, filename))\n        path_dict[filename] = os.path.join(dirname, filename)\n    test_ds_path.append(path_dict)\n# print(\"test_ds_path::\", test_ds_path)\n# os.system(\"cp ../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/abc.jpg ../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/\")","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:26:59.025211Z","iopub.execute_input":"2022-05-01T17:26:59.025494Z","iopub.status.idle":"2022-05-01T17:26:59.035826Z","shell.execute_reply.started":"2022-05-01T17:26:59.025462Z","shell.execute_reply":"2022-05-01T17:26:59.035255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"test_ds_path","metadata":{}},{"cell_type":"code","source":"def get_top5(oneD_list):\n    return np.argpartition(oneD_list,-5)[-5:]\n\ndef listOfTop5(twoD_list):\n    return [get_top5(row) for row in twoD_list]\n\nkey_list = list(class_indices.keys())\nval_list = list(class_indices.values())\n\ndef replaceWithHotelID(oneRow):\n    return [key_list[i] for i in oneRow]\n\ndef replace2DwthHotelID(twoDArray):\n#     print('twoDArray::', twoDArray)\n    return [replaceWithHotelID(row) for row in twoDArray]\n\n#Single Image Prediction Code\ndef single_image_prediction(submission_filepath):\n    \n        submission = tf.keras.preprocessing.image.load_img(\n            submission_filepath, \n            grayscale=False, \n            color_mode=\"rgb\", \n            target_size=(IMG_SIZE, IMG_SIZE), \n            interpolation=\"nearest\"\n        )\n#         print(\"submission::\", submission)\n\n        submission_arr = tf.keras.preprocessing.image.img_to_array(submission)\n#         print(\"submission_arr::\", submission_arr)\n        submission_arr = np.array([submission_arr])  # Convert single image to a batch.\n        predictions = model.predict(submission_arr)\n#         print('predictions::', predictions)\n        return replace2DwthHotelID(listOfTop5(predictions))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:29:40.007963Z","iopub.execute_input":"2022-05-01T17:29:40.008399Z","iopub.status.idle":"2022-05-01T17:29:40.017469Z","shell.execute_reply.started":"2022-05-01T17:29:40.00837Z","shell.execute_reply":"2022-05-01T17:29:40.016509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# single_image_prediction('../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/abc.jpg')\n\nprediction_list = []\n\nfor path_dict in test_ds_path:\n    prediction_dict = {}\n    for image, path in path_dict.items():\n        prediction_dict[\"image_id\"] = image\n#         print([int(id) for id in single_image_prediction(path)[0]])\n#         print(\"single_image_prediction(path)::\",single_image_prediction(path))\n        single_image_prediction(path)[0] = [int(id) for id in single_image_prediction(path)[0]]\n#         single_image_prediction(path)[0] = single_image_prediction(path)[0].reverse()\n        pred_list = single_image_prediction(path)[0].copy()\n        pred_list.reverse()\n        \n#         print(\"pred_list(path)[0]:::\", pred_list)\n#         hotel_ids = ' '.join(single_image_prediction(path)[0])\n#         prediction_dict[\"hotel_id\"] = [int(id) for id in single_image_prediction(path)[0]]\n#         prediction_dict[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\",\"\") for l in [int(id) for id in single_image_prediction(path)[0]]]\n#         prediction_dict[\"hotel_id\"] = ' '.join( prediction_dict[\"hotel_id\"])\n#         print(\"prediction_list::\",  *prediction_dict[\"hotel_id\"])\n        prediction_dict[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\").replace(\"'\", \"\") for l in [pred_list]]\n        prediction_list.append(prediction_dict.copy())\n\n\nprediction_df = pd.DataFrame(prediction_list)\n\n# print(\"prediction_list::\",  prediction_list)\nprediction_df[\"hotel_id\"] = prediction_df[\"hotel_id\"].apply(lambda m: str(m).strip(\"[]\").replace(\"'\", \"\"))\nprediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:29:41.348474Z","iopub.execute_input":"2022-05-01T17:29:41.348784Z","iopub.status.idle":"2022-05-01T17:29:41.926412Z","shell.execute_reply.started":"2022-05-01T17:29:41.348751Z","shell.execute_reply":"2022-05-01T17:29:41.925492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df.to_csv('submission.csv', index=False)\n# prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:43:58.02558Z","iopub.execute_input":"2022-04-26T08:43:58.026507Z","iopub.status.idle":"2022-04-26T08:43:58.037725Z","shell.execute_reply.started":"2022-04-26T08:43:58.026466Z","shell.execute_reply":"2022-04-26T08:43:58.036834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_df = pd.read_csv('/kaggle/input/hotel-id-to-combat-human-trafficking-2022-fgvc9/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:43:58.039309Z","iopub.execute_input":"2022-04-26T08:43:58.040166Z","iopub.status.idle":"2022-04-26T08:43:58.044163Z","shell.execute_reply.started":"2022-04-26T08:43:58.040126Z","shell.execute_reply":"2022-04-26T08:43:58.043566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:43:58.045493Z","iopub.execute_input":"2022-04-26T08:43:58.045861Z","iopub.status.idle":"2022-04-26T08:43:58.05794Z","shell.execute_reply.started":"2022-04-26T08:43:58.045825Z","shell.execute_reply":"2022-04-26T08:43:58.056882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:43:58.059797Z","iopub.execute_input":"2022-04-26T08:43:58.060172Z","iopub.status.idle":"2022-04-26T08:43:58.071754Z","shell.execute_reply.started":"2022-04-26T08:43:58.060141Z","shell.execute_reply":"2022-04-26T08:43:58.070598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.partition([3, 4, 1, 2,6,8,0], 5)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:43:58.073238Z","iopub.execute_input":"2022-04-26T08:43:58.073573Z","iopub.status.idle":"2022-04-26T08:43:58.086584Z","shell.execute_reply.started":"2022-04-26T08:43:58.073529Z","shell.execute_reply":"2022-04-26T08:43:58.085843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}