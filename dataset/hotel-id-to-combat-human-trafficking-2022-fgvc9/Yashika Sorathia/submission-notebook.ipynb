{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom keras.models import load_model\nimport pandas as pd\nimport numpy as np\nimport os\nfrom keras.preprocessing import image\n\n# import pickle\n# import joblib","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:33:50.010953Z","iopub.execute_input":"2022-05-05T07:33:50.011672Z","iopub.status.idle":"2022-05-05T07:33:56.60816Z","shell.execute_reply.started":"2022-05-05T07:33:50.011559Z","shell.execute_reply":"2022-05-05T07:33:56.60719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 224\nBATCH_SIZE = 32\nTRAIN_DS_PATH = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/'\nSEED = 52\nSPLIT = 0.2 \nCHECKPOINT_FNAME = 'ckpt_effNet.h5'\nLOAD_WEIGHTS = '../input/mlip-ckpt/ckpt_effNet_v3.h5'\nTEST_PATH = '../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images/'\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:01.91133Z","iopub.execute_input":"2022-05-05T07:35:01.911658Z","iopub.status.idle":"2022-05-05T07:35:01.917949Z","shell.execute_reply.started":"2022-05-05T07:35:01.911624Z","shell.execute_reply":"2022-05-05T07:35:01.916899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(validation_split=SPLIT, \n                           shear_range=0.2,\n                           zoom_range=0.2,\n                           horizontal_flip=True,\n                           rotation_range=0.1,)\nval_datagen = ImageDataGenerator(validation_split=SPLIT,)\n\ntrain_ds = train_datagen.flow_from_directory(\n    TRAIN_DS_PATH, \n    subset='training', \n    seed=SEED,\n    target_size=(IMG_SIZE, IMG_SIZE), \n    batch_size=BATCH_SIZE,\n)\nval_ds = val_datagen.flow_from_directory(\n    TRAIN_DS_PATH, \n    subset='validation', \n    seed=SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:05.114591Z","iopub.execute_input":"2022-05-05T07:35:05.115567Z","iopub.status.idle":"2022-05-05T07:35:11.003257Z","shell.execute_reply.started":"2022-05-05T07:35:05.115504Z","shell.execute_reply":"2022-05-05T07:35:11.002262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds_path = []\nfor dirname, _, filenames in os.walk(TEST_PATH):\n    path_dict = {}\n    for filename in filenames:\n        \n        path_dict[filename] = os.path.join(dirname, filename)\n    test_ds_path.append(path_dict)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:11.005375Z","iopub.execute_input":"2022-05-05T07:35:11.006303Z","iopub.status.idle":"2022-05-05T07:35:11.014183Z","shell.execute_reply.started":"2022-05-05T07:35:11.006253Z","shell.execute_reply":"2022-05-05T07:35:11.01305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = load_model(LOAD_WEIGHTS)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:11.015507Z","iopub.execute_input":"2022-05-05T07:35:11.016465Z","iopub.status.idle":"2022-05-05T07:35:15.279831Z","shell.execute_reply.started":"2022-05-05T07:35:11.01642Z","shell.execute_reply":"2022-05-05T07:35:15.278872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load pre trained model\n# with open(LOAD_MODEL, 'rb') as file:  \n#     Pickled_LR_Model = pickle.load(file)\n\n# Pickled_LR_Model","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:38:55.177893Z","iopub.execute_input":"2022-05-04T14:38:55.178974Z","iopub.status.idle":"2022-05-04T14:38:55.270889Z","shell.execute_reply.started":"2022-05-04T14:38:55.178913Z","shell.execute_reply":"2022-05-04T14:38:55.269574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_indices = {k: v for v, k in enumerate(train_ds.classes)}","metadata":{"execution":{"iopub.status.busy":"2022-05-04T08:51:32.218126Z","iopub.execute_input":"2022-05-04T08:51:32.218611Z","iopub.status.idle":"2022-05-04T08:51:32.233668Z","shell.execute_reply.started":"2022-05-04T08:51:32.218559Z","shell.execute_reply":"2022-05-04T08:51:32.232618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_top5(oneD_list):\n#     return np.argpartition(oneD_list,-5)[-5:]\n\n# def listOfTop5(twoD_list):\n#     return [get_top5(row) for row in twoD_list]\n\n# key_list = list(class_indices.keys())\n# val_list = list(class_indices.values())\n\n# def replaceWithHotelID(oneRow):\n#     return [key_list[i] for i in oneRow]\n\n# def replace2DwthHotelID(twoDArray):\n#     return [replaceWithHotelID(row) for row in twoDArray]\n\n# #Single Image Prediction Code\n# def single_image_prediction(submission_filepath):\n    \n#         submission = tf.keras.preprocessing.image.load_img(\n#             submission_filepath, \n#             grayscale=False, \n#             color_mode=\"rgb\", \n#             target_size=(IMG_SIZE, IMG_SIZE), \n#             interpolation=\"nearest\"\n#         )\n\n#         submission_arr = tf.keras.preprocessing.image.img_to_array(submission)\n#         submission_arr = np.array([submission_arr])  # Convert single image to a batch.\n#         predictions = model.predict(submission_arr)\n#         return replace2DwthHotelID(listOfTop5(predictions))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T08:52:49.948285Z","iopub.execute_input":"2022-05-04T08:52:49.949454Z","iopub.status.idle":"2022-05-04T08:52:49.95925Z","shell.execute_reply.started":"2022-05-04T08:52:49.949393Z","shell.execute_reply":"2022-05-04T08:52:49.958224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction_list = []\n\n# for path_dict in test_ds_path:\n#     prediction_dict = {}\n#     for image, path in path_dict.items():\n#         prediction_dict[\"image_id\"] = image\n# #         print([int(id) for id in single_image_prediction(path)[0]])\n# #         print(\"single_image_prediction(path)::\",single_image_prediction(path))\n#         single_image_prediction(path)[0] = [int(id) for id in single_image_prediction(path)[0]]\n# #         single_image_prediction(path)[0] = single_image_prediction(path)[0].reverse()\n#         pred_list = single_image_prediction(path)[0].copy()\n# #         pred_list.reverse()\n        \n# #         print(\"pred_list(path)[0]:::\", pred_list)\n# #         hotel_ids = ' '.join(single_image_prediction(path)[0])\n# #         prediction_dict[\"hotel_id\"] = [int(id) for id in single_image_prediction(path)[0]]\n# #         prediction_dict[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\",\"\") for l in [int(id) for id in single_image_prediction(path)[0]]]\n# #         prediction_dict[\"hotel_id\"] = ' '.join( prediction_dict[\"hotel_id\"])\n# #         print(\"prediction_list::\",  *prediction_dict[\"hotel_id\"])\n#         prediction_dict[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\").replace(\"'\", \"\") for l in [pred_list]]\n#         prediction_list.append(prediction_dict.copy())\n\n\n# prediction_df = pd.DataFrame(prediction_list)\n\n# # print(\"prediction_list::\",  prediction_list)\n# prediction_df[\"hotel_id\"] = prediction_df[\"hotel_id\"].apply(lambda m: str(m).strip(\"[]\").replace(\"'\", \"\"))\n# prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-04T08:52:54.002342Z","iopub.execute_input":"2022-05-04T08:52:54.00297Z","iopub.status.idle":"2022-05-04T08:52:56.463429Z","shell.execute_reply.started":"2022-05-04T08:52:54.002916Z","shell.execute_reply":"2022-05-04T08:52:56.462534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:26:22.443582Z","iopub.execute_input":"2022-05-03T07:26:22.443922Z","iopub.status.idle":"2022-05-03T07:26:22.453006Z","shell.execute_reply.started":"2022-05-03T07:26:22.443891Z","shell.execute_reply":"2022-05-03T07:26:22.452331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_json = []\nimages = []\nimage_id = []\nfor img in os.listdir(TEST_PATH):\n    image_id.append(img)\n    img = os.path.join(TEST_PATH, img)\n    img = image.load_img(img, target_size=(IMG_SIZE, IMG_SIZE))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    images.append(img)\nimages = np.vstack(images)\nclasses = model.predict(images,)\nfor i, pred in enumerate(classes):\n    final_pred = []\n    for p in np.argsort(pred)[::-1][:5]:\n#         print(p)\n        final_pred.append(list(train_ds.class_indices.items())[p][0])\n    submission_json.append({'image_id': image_id[i], 'hotel_id': ' '.join(str(e) for e in final_pred)})\n\nsubmission_json","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:19.036405Z","iopub.execute_input":"2022-05-05T07:35:19.036733Z","iopub.status.idle":"2022-05-05T07:35:21.338188Z","shell.execute_reply.started":"2022-05-05T07:35:19.036693Z","shell.execute_reply":"2022-05-05T07:35:21.337125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df = pd.DataFrame(submission_json)\nprediction_df[\"hotel_id\"] = prediction_df[\"hotel_id\"].apply(lambda m: str(m).strip(\"[]\").replace(\"'\", \"\"))\nprediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:21.394671Z","iopub.execute_input":"2022-05-05T07:35:21.394968Z","iopub.status.idle":"2022-05-05T07:35:21.41829Z","shell.execute_reply.started":"2022-05-05T07:35:21.394937Z","shell.execute_reply":"2022-05-05T07:35:21.417441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:40:11.373854Z","iopub.execute_input":"2022-05-04T15:40:11.374266Z","iopub.status.idle":"2022-05-04T15:40:11.381562Z","shell.execute_reply.started":"2022-05-04T15:40:11.374224Z","shell.execute_reply":"2022-05-04T15:40:11.380579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}