{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Source'] = 'train'\ntest_df['Source'] = 'test'\n\ndataframe = train_df.append([test_df])\ndataframe.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nAdd patient level Baseline information, only the information that the test dataset will also have\n1. Number of visits\n2. Visit Number (0,1,2,3,4)\n4. Variation in Percent\n5. Change in smoking status\n6. Range of Percent\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, shuffle=True, batch_size=32):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop('target')\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def own_ZScaler(df, columns):\n    for col in columns:\n        new_col_name = col + 'Z'\n        col_min = df[col].min()\n        col_max = df[col].max()        \n        df[new_col_name] = (df[col] - col_min) / (col_max - col_min)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_columns = ['FVC', 'Weeks', 'Age', \"Percent\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"own_ZScaler(dataframe, numeric_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe['target'] = dataframe['FVCZ']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Put All the Features Together\nfeature_columns = []\n\n# numeric cols\nfor header in ['WeeksZ', 'AgeZ', \"PercentZ\"]:\n  feature_columns.append(feature_column.numeric_column(header))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indicator_columns\n\nindicator_column_names = ['Sex','SmokingStatus']\nfor col_name in indicator_column_names:\n  categorical_column = feature_column.categorical_column_with_vocabulary_list(\n      col_name, dataframe[col_name].unique())\n  indicator_column = feature_column.indicator_column(categorical_column)\n  feature_columns.append(indicator_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''## Try instead embedding columns\n# embedding columns\nembedded_column_names = ['Sex','SmokingStatus']\nfor col_name in embedded_column_names:\n  m = len(dataframe[col_name].unique())\n  categorical_column = feature_column.categorical_column_with_vocabulary_list(\n      col_name, dataframe[col_name].unique())\n  embedded_column = feature_column.embedding_column(categorical_column, dimension = min(50,m//2))\n  feature_columns.append(embedded_column)'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try crossed columns\n# crossed columns\n# need to create one hot encoded variables first\n'''sex_smoker_feature = feature_column.crossed_column(['Sex', 'SmokingStatus'], hash_bucket_size=100)\nfeature_columns.append(feature_column.indicator_column(sex_smoker_feature))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_layer = tf.keras.layers.DenseFeatures(feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get back original data split\ntrain_df = dataframe.loc[dataframe.Source == 'train']\ntest_df = dataframe.loc[dataframe.Source == 'test']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_test_split(train_df, test_size=0.2)\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### config file\nif len(test_df) < 10:\n    EPOCHS = 200\nelse:\n    EPOCHS = 1000\nbatch_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = df_to_dataset(train, batch_size=batch_size)\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  feature_layer,\n  layers.Dense(64, activation='relu'),\n  layers.Dropout(.2),\n  layers.Dense(64, activation='relu'),\n  layers.Dropout(.2),\n  layers.Dense(1, activation='linear')\n])\n\nADAM = tf.keras.optimizers.Adam(lr = 0.001)\n\noptimizer = ADAM\n\nmodel.compile(optimizer= optimizer,\n              loss='mae',\n              metrics=['mae'])\n\nmodel.fit(train_ds,\n          validation_data=val_ds,\n          epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = [\"Patient\", \"Weeks\", 'PercentZ' , 'AgeZ', 'Sex', 'SmokingStatus']\ndf = pd.DataFrame(columns = column_names)\n\nfor i in range(len(test_df)):\n    Patient  = test_df.iloc[i]['Patient']\n    PercentZ  = test_df.iloc[i]['PercentZ']\n    AgeZ  = test_df.iloc[i]['AgeZ']\n    Sex  = test_df.iloc[i]['Sex']\n    SmokingStatus  = test_df.iloc[i]['SmokingStatus']\n    for week in np.arange(-12,134):\n        df = df.append({'Patient': Patient, \n                        \"Weeks\": week, \n                        'PercentZ' : PercentZ, \n                        'AgeZ': AgeZ, \n                        'Sex': Sex,\n                        'SmokingStatus': SmokingStatus \n                         }, ignore_index=True)\ndf['target'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"own_ZScaler(df, ['Weeks'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Weeks'] = df['Weeks'].astype(int)\ndf['WeeksZ'] = df['WeeksZ'].astype(float)\ndf['AgeZ'] = df['AgeZ'].astype(float)\ndf['PercentZ'] = df['PercentZ'].astype(float)\ndf['Patient'] = df['Patient'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = df_to_dataset(df, shuffle=False, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(test_ds, batch_size = 100, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['FVCZ'] = preds\ndf['Weeks'] = df['Weeks'].astype(str)\ndf['Confidence'] = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['FVC'] =  (df['FVCZ']*(dataframe['FVC'].max() - dataframe['FVC'].min())) + dataframe['FVC'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Patient'] = df['Patient'].str.cat(df['Weeks'],sep=\"_\")\ndf.rename(columns={\"Patient\": \"Patient_Week\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['Patient_Week','FVC', 'Confidence']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}