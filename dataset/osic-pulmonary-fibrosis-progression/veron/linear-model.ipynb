{"cells":[{"metadata":{},"cell_type":"markdown","source":"reference: https://www.kaggle.com/mattbast/feature-engineering-with-a-linear-model"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn import linear_model, ensemble\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport tensorflow as tf\n\nfrom tqdm.notebook import tqdm\n\nimport os\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_path = '/kaggle/input/osic-pulmonary-fibrosis-progression/'\ndf = pd.read_csv(base_path + 'train.csv')\n# df.sample(5,  random_state=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create additional features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weeks_passed(df):\n    min_week_dict = df.groupby('Patient').min('Weeks')['Weeks'].to_dict()\n    df['MinWeek'] =  df['Patient'].map(min_week_dict)\n    df['WeeksPassed'] = df['Weeks'] - df['MinWeek']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_baseline_FVC(df):\n    _df = (\n        df\n        .loc[df.Weeks == df.MinWeek][['Patient','FVC']]\n        .rename({'FVC': 'FirstFVC'}, axis=1)\n        .groupby('Patient')\n        .first()\n#         .reset_index()\n    )\n    \n    first_FVC_dict = _df.to_dict()['FirstFVC']\n    df['FirstFVC'] =  df['Patient'].map(first_FVC_dict)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef calculate_height(row):\n    if row['Sex'] == 'Male':\n        return row['FirstFVC'] / (27.63 - 0.112 * row['Age'])\n    else:\n        return row['FirstFVC'] / (21.78 - 0.101 * row['Age'])\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = get_weeks_passed(df)\ndf = get_baseline_FVC(df)\ndf['Height'] = df.apply(calculate_height, axis=1)\ndf['FullFVC'] = df['FVC']/df['Percent']*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transform data for model ingestion"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the necessary Encoders & Transformers\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.compose import ColumnTransformer\n\n# define which attributes shall not be transformed, are numeric or categorical\nno_transform_attribs = ['Patient','FVC']\nnum_attribs = ['Percent', 'Age', 'WeeksPassed', 'FirstFVC','Height', 'Weeks', 'MinWeek', 'FullFVC']\ncat_attribs = ['Sex', 'SmokingStatus']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass NoTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Passes through data without any change and is compatible with ColumnTransformer class\"\"\"\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        assert isinstance(X, pd.DataFrame)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## transform features into series\n\n# create an instance of the ColumnTransformer\ndatawrangler = ColumnTransformer(([\n     # the No-Transformer does not change the data and is applied to all no_transform_attribs \n     ('original', NoTransformer(), no_transform_attribs),\n     # Apply StdScaler to the numerical attributes, here you can change to e.g. MinMaxScaler()   \n     ('MinMax', MinMaxScaler(), num_attribs),\n     # OneHotEncoder all categorical attributes.   \n     ('cat_encoder', OneHotEncoder(), cat_attribs),\n    ]))\n\ntransformed_data_series = []\ntransformed_data_series = datawrangler.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## put transformed series into dataframe\n\n# get column names for non-categorical data\nnew_col_names = no_transform_attribs + num_attribs\n\n# extract possible values from the fitted transformer\ncategorical_values = [s for s in datawrangler.named_transformers_[\"cat_encoder\"].get_feature_names()]\nnew_col_names += categorical_values\n\n# create Dataframe based on the extracted Column-Names\ntrain_sklearn_df = pd.DataFrame(transformed_data_series, columns=new_col_names)\ntrain_sklearn_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ncsv_features_list = ['FullFVC','Age','Weeks','MinWeek','WeeksPassed','FirstFVC','Height','x0_Female','x1_Currently smokes','x1_Ex-smoker']\n\nX = train_sklearn_df[csv_features_list].astype(float)\n\ny = train_sklearn_df[['FVC']].astype(float)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train a Linear Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import HuberRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # huber = HuberRegressor(max_iter=200)\n# huber = GradientBoostingRegressor(random_state=0, loss='huber')\n# huber.fit(X_train, y_train)\n# preds = huber.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict confidence # https://towardsdatascience.com/how-to-generate-prediction-intervals-with-scikit-learn-and-python-ab3899f992ed\n\n# Set lower and upper quantile\nLOWER_ALPHA = 0.25\nUPPER_ALPHA = 0.75\n# Each model has to be separate\nlower_huber = GradientBoostingRegressor(loss=\"quantile\",                   \n                                        alpha=LOWER_ALPHA)\nupper_huber = GradientBoostingRegressor(loss=\"quantile\",\n                                        alpha=UPPER_ALPHA)\n\n# The mid model will use the default loss\nmid_huber = GradientBoostingRegressor(loss=\"huber\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit models\nlower_huber.fit(X_train, y_train)\nmid_huber.fit(X_train, y_train)\nupper_huber.fit(X_train, y_train)\n\n# Record actual values on test set\n# preds = y_test\n\n\n# Predict\npreds_lower = lower_huber.predict(X_test)\npreds_mid = mid_huber.predict(X_test)\npreds_upper = upper_huber.predict(X_test)\n\npreds = pd.DataFrame({'lower':preds_lower, 'mid':preds_mid, 'upper':preds_upper})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(\n    y_test,\n    preds['mid'],\n    squared=False\n)\n\nmae = mean_absolute_error(\n    y_test,\n    preds['mid']\n)\n\nprint('MSE Loss: {0:.2f}'.format(mse))\nprint('MAE Loss: {0:.2f}'.format(mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def competition_metric(trueFVC, predFVC, predSTD):\n    clipSTD = np.clip(predSTD, 70 , 9e9)  \n    deltaFVC = np.clip(np.abs(trueFVC - predFVC), 0 , 1000)  \n    return np.mean(-1 * (np.sqrt(2) * deltaFVC / clipSTD) - np.log(np.sqrt(2) * clipSTD))\n    \n\nprint(\n    'Competition metric with variable confidence: ', \n    competition_metric(np.ravel(y_test.values), preds['mid'], preds['upper']-preds['lower']) \n)\n\nprint(\n    'Competition metric with static confidence: ', \n    competition_metric(np.ravel(y_test.values), preds['mid'], 285) \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save model weights\n\nimport _pickle as cPickle\n\nwith open('/kaggle/working/lower_huber.pkl', 'wb') as f:\n    cPickle.dump(lower_huber, f)\n\nwith open('/kaggle/working/mid_huber.pkl', 'wb') as f:\n    cPickle.dump(mid_huber, f)\n    \nwith open('/kaggle/working/upper_huber.pkl', 'wb') as f:\n    cPickle.dump(upper_huber, f)\n\n\nwith open('/kaggle/working/datawrangler.pkl', 'wb') as f:\n    cPickle.dump(datawrangler, f)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass NoTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Passes through data without any change and is compatible with ColumnTransformer class\"\"\"\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        assert isinstance(X, pd.DataFrame)\n        return X\n        \n\ndef load_huber_models(lower_huber_path, mid_huber_path, upper_huber_path, datawrangler_path):\n    \n    '''\n    function to load saved huber modles and saved datawrangler\n    \n    Param\n    -----\n    lower_huber_path: string\n    mid_huber_path: string\n    upper_huber_path: string\n    datawrangler_path: string\n    \n    Return\n    ------\n    lower_huber: saved GradientBoostRegressor from sklearn, with loss = 'quantile', alpha = 0.1\n    mid_huber: saved GradientBoostRegressor from sklearn, with loss = 'huber'\n    upper_huber: saved GradientBoostRegressor from sklearn, with loss = 'quantile', alpha = 0.9\n    datawrangler: saved columntransformer from sklearn\n    \n    '''\n    \n    with open(lower_huber_path, 'rb') as f:\n        lower_huber = cPickle.load(f)\n\n    with open(mid_huber_path, 'rb') as f:\n        mid_huber = cPickle.load(f)\n\n    with open(upper_huber_path, 'rb') as f:\n        upper_huber = cPickle.load(f)\n\n    with open(datawrangler_path, 'rb') as f:\n        datawrangler = cPickle.load(f)\n\n    return lower_huber, mid_huber, upper_huber, datawrangler\n    \n\ndef huber_predict(lower_huber, mid_huber, upper_huber, datawrangler, Patient, Week, FVC, Percent, Age, Sex, SmokingStatus, week_start=-12, week_end=134):\n\n    '''\n    function to predict FVC value and confidence\n    \n    Param\n    -----\n    lower_huber: saved GradientBoostRegressor from sklearn, with loss = 'quantile', alpha = 0.1\n    mid_huber: saved GradientBoostRegressor from sklearn, with loss = 'huber'\n    upper_huber: saved GradientBoostRegressor from sklearn, with loss = 'quantile', alpha = 0.9\n    datawrangler: saved columntransformer from sklearn\n    \n    Week: integer \n        Number of weeks after CT Scan, can be negative\n    FVC: integer\n        Initial FVC measurement at above `week`\n    Percent: integer\n        Initial percentage measurement at above `week`\n    Age: integer\n        Age at above `week`\n    Sex: string\n        'Male' or 'Female'\n    SmokingStatus: string\n        'Currently smokes', 'Ex-smoker', or 'Never smoked'\n    week_start: integer\n        start week to predict\n    week_end: interger\n        end week to predict\n    \n    Return\n    ------\n    df: DataFrame\n        DataFrame with user inputs, engineered features, and predictions in running weeks\n    \n    '''\n    \n    \n    MinWeek, FirstFVC, FullFVC, Height = _engineer_feature(Week, FVC, Percent, Age, Sex)\n\n    df = _create_df_with_running_weeks(Patient,\n                                        Week,\n                                        FVC,\n                                        Percent,\n                                        Age,\n                                        Sex,\n                                        SmokingStatus,\n                                        MinWeek,\n                                        FirstFVC,\n                                        FullFVC,\n                                        Height,\n                                        week_start,\n                                        week_end)\n\n    df, df_transformed = _wrangle_data(df, datawrangler)\n    \n    df = _get_predictions(df, df_transformed, lower_huber, mid_huber, upper_huber)\n    \n    return df\n        \ndef _engineer_feature(Week, FVC, Percent, Age, Sex):\n    '''\n    function to calculate MinWeek, FullFVC, and Height from patient details\n    \n    '''\n\n    MinWeek = min(Week, 0)\n    FirstFVC = FVC\n    FullFVC = (FVC/Percent)*100\n\n    if Sex == 'Male':\n        Height = FirstFVC / (27.63 - 0.112 * Age)\n    else:\n        Height = FirstFVC / (21.78 - 0.101 * Age)\n\n    return MinWeek, FirstFVC, FullFVC, Height\n    \ndef _create_df_with_running_weeks(Patient, Weeks, FVC, Percent, Age, Sex, SmokingStatus, MinWeek, FirstFVC, FullFVC, Height, week_start, week_end):\n\n    '''\n    function to put patient details, engineered features, and running list of weeks into DataFrame\n    \n    '''\n\n    Weeks = list(range(week_start, week_end))\n    df = pd.DataFrame({'Weeks':Weeks})\n    df['Patient'] = Patient\n    df['Sex'] = Sex\n    df['Age'] = Age\n    df['SmokingStatus'] = SmokingStatus\n    df['MinWeek'] = MinWeek\n    df['FirstFVC'] = FVC\n    df['FullFVC'] = FullFVC\n    df['Height'] = Height\n    df['Percent'] = Percent\n    df['WeeksPassed'] = df['Weeks'] - df['MinWeek']\n    df['FVC'] = 0 # dummy FVC, to be predicted\n\n    return df\n\ndef _wrangle_data(df, datawrangler):\n    '''\n    function to transform patient details into suitable format for models' ingestion\n    \n    '''\n\n    transformed_data_series = datawrangler.transform(df)\n\n    ## put transformed series into dataframe\n\n    # define which attributes shall not be transformed, are numeric or categorical\n    no_transform_attribs = ['Patient','FVC']\n    num_attribs = ['Percent', 'Age', 'WeeksPassed', 'FirstFVC','Height', 'Weeks', 'MinWeek', 'FullFVC']\n    cat_attribs = ['Sex', 'SmokingStatus']\n\n    # get column names for non-categorical data\n    new_col_names = no_transform_attribs + num_attribs\n\n    # extract possible values from the fitted transformer\n    categorical_values = [s for s in datawrangler.named_transformers_[\"cat_encoder\"].get_feature_names()]\n    new_col_names += categorical_values\n\n    # create Dataframe based on the extracted Column-Names\n    df_transformed = pd.DataFrame(transformed_data_series, columns=new_col_names)\n\n    return df, df_transformed\n\n\ndef _get_predictions(df, df_transformed, lower_huber, mid_huber, upper_huber):\n    \n    '''\n    function to predict lower, upper and mid FVC and confidence interval for patients\n    \n    '''\n    csv_features_list = ['FullFVC','Age','Weeks','MinWeek','WeeksPassed','FirstFVC','Height','x0_Female','x1_Currently smokes','x1_Ex-smoker']\n    df_transformed = df_transformed[csv_features_list]\n\n    preds_lower = lower_huber.predict(df_transformed)\n    preds_mid = mid_huber.predict(df_transformed)\n    preds_upper = upper_huber.predict(df_transformed)\n    \n    df['Lower'] = preds_lower\n    df['Upper'] = preds_upper\n    df['FVC'] = preds_mid\n    df['Confidence'] = abs(preds_upper - preds_lower)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Model inputs\nPatient = 'Albert'\nAge = 69\nSex = 'Female'\nWeek = -4 # Number of weeks after CT Scan, can be negative\nFVC = 3000\nPercent = 78\nSmokingStatus = 'Never smoked'\nimage_folder = 'path/to/folder/containing/dcm/images'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load saved models\nlower_huber, mid_huber, upper_huber, datawrangler = load_huber_models('/kaggle/working/lower_huber.pkl',\n                                                                    '/kaggle/working/mid_huber.pkl',\n                                                                    '/kaggle/working/upper_huber.pkl',\n                                                                    '/kaggle/working/datawrangler.pkl')\n\n# generate prediction\ndf = huber_predict(lower_huber, mid_huber, upper_huber, datawrangler, Patient, Week, FVC, Percent, Age, Sex, SmokingStatus)\ndf = df[['Patient','Weeks','FVC','Lower','Upper']]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submission csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = '/kaggle/input/osic-pulmonary-fibrosis-progression/'\ndf = pd.read_csv(base_path + 'test.csv')\ndf.tail(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lower_huber, mid_huber, upper_huber, datawrangler = load_huber_models('/kaggle/working/lower_huber.pkl',\n#                                                                     '/kaggle/working/mid_huber.pkl',\n#                                                                     '/kaggle/working/upper_huber.pkl',\n#                                                                     '/kaggle/working/datawrangler.pkl')\n\n\n\nfor i, row in df.iterrows():\n    if i == 0:\n        df_predict = huber_predict(lower_huber,\n                            mid_huber,\n                            upper_huber,\n                            datawrangler,\n                            row['Patient'],\n                            row['Weeks'],\n                            row['FVC'],\n                            row['Percent'],\n                            row['Age'],\n                            row['Sex'],\n                            row['SmokingStatus']\n                           )\n    else:\n        df_interim = huber_predict(lower_huber,\n                    mid_huber,\n                    upper_huber,\n                    datawrangler,\n                    row['Patient'],\n                    row['Weeks'],\n                    row['FVC'],\n                    row['Percent'],\n                    row['Age'],\n                    row['Sex'],\n                    row['SmokingStatus']\n                   )\n    \n\n        df_predict = df_predict.append(df_interim)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_predict['Patient_Week'] = df_predict['Patient'] + '_' + df_predict['Weeks'].astype(str)\ndf_predict = df_predict.sort_values('Patient').sort_values('Weeks', ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = df_predict[['Patient_Week', 'FVC']] #, 'Confidence'\ndf_submission['Confidence'] = 285\ndf_submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_predict[['Patient','FVC','Lower','Upper']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# base_path = '/kaggle/input/osic-pulmonary-fibrosis-progression/'\n# df_sub = pd.read_csv(base_path + 'sample_submission.csv')\n# # df_submission[['Patient','Weeks']] = df_submission['Patient_Week'].str.split(\"_\",expand=True,)\n# # df = df.drop(['Weeks', 'FVC','Confidence'],axis=1)\n\n# df_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Draft"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# load saved models\n\nclass LinearModel():\n    \n    def __init__(self):                                                                                                                                                                                                         \n\n        with open('/kaggle/working/lower_huber.pkl', 'rb') as f:\n            self.lower_huber = cPickle.load(f)\n            \n        with open('/kaggle/working/mid_huber.pkl', 'rb') as f:\n            self.mid_huber = cPickle.load(f)\n            \n        with open('/kaggle/working/upper_huber.pkl', 'rb') as f:\n            self.upper_huber = cPickle.load(f)\n            \n        with open('/kaggle/working/datawrangler.pkl', 'rb') as f:\n            self.datawrangler = cPickle.load(f)\n\n    def predict(self, Patient, Weeks, FVC, Percent, Age, Sex, SmokingStatus, week_range):\n        \n        MinWeek, FirstFVC, Height = self._engineer_feature(Weeks, FVC, Percent, Age, Sex)\n        \n        df_inference = self._create_df_with_running_weeks(Patient,\n                                                          Weeks,\n                                                          FVC,\n                                                          Percent,\n                                                          Age,\n                                                          Sex,\n                                                          SmokingStatus,\n                                                          MinWeek,\n                                                          FirstFVC,\n                                                          Height,\n                                                          week_range)\n        \n        df_inference = self._wrangle_data()\n        \n        preds_lower = lower_huber.predict(X_test)\n        preds_mid = mid_huber.predict(X_test)\n        preds_upper = upper_huber.predict(X_test)\n        \n        \n    def _engineer_feature(self, Week, FVC, Percent, Age, Sex):\n        \n        MinWeek = min(Week, 0)\n        FirstFVC = FVC\n        FullFVC = (FVC/Percent)*100\n\n        if Sex == 'Male':\n            Height = FirstFVC / (27.63 - 0.112 * Age)\n        else:\n            Height = FirstFVC / (21.78 - 0.101 * Age)\n        \n        return MinWeek, FirstFVC, Height\n    \n    def _create_df_with_running_weeks(self,Patient, Weeks, FVC, Percent, Age, Sex, SmokingStatus, MinWeek, FirstFVC, Height, week_range)\n    \n        # Put Patient details, and create a running list of weeks into DataFrame\n        Weeks = list(range(week_range))\n        df_inference = pd.DataFrame({'Weeks':Weeks})\n        df_inference['Patient'] = Patient\n        df_inference['Sex'] = Sex\n        df_inference['Age'] = Age\n        df_inference['SmokingStatus'] = SmokingStatus\n        df_inference['MinWeek'] = MinWeek\n        df_inference['FirstFVC'] = FVC\n        df_inference['FullFVC'] = FullFVC\n        df_inference['Height'] = Height\n        df_inference['Percent'] = Percent\n        df_inference['WeeksPassed'] = df_inference['Weeks'] - df_inference['MinWeek']\n        df_inference['FVC'] = 0 # dummy FVC, to be predicted\n        \n        return df_inference\n\n    def _wrangle_data(self, df_inference):\n        \n        transformed_data_series = datawrangler.transform(df_inference)\n        \n        ## put transformed series into dataframe\n        \n        # get column names for non-categorical data\n        new_col_names = no_transform_attribs + num_attribs\n\n        # extract possible values from the fitted transformer\n        categorical_values = [s for s in self.datawrangler.named_transformers_[\"cat_encoder\"].get_feature_names()]\n        new_col_names += categorical_values\n\n        # create Dataframe based on the extracted Column-Names\n        df_inference = pd.DataFrame(transformed_data_series, columns=new_col_names)\n\n        return df_inference\n    \n        \n    def evaluate():\n        \n        \n    def get_default_params():"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# User input these features in application\nPatient = 'Albert'\nWeek = -4 # Number of weeks after CT Scan, can be negative\nFVC = 3000\nPercent = 78\nAge = 69\nSex = 'Female'\nSmokingStatus = 'Never smoked'\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Imputed features\nMinWeek = min(Week, 0)\nFirstFVC = FVC\n\n# Feature Engineering\nFullFVC = (FVC/Percent)*100\n\nif Sex == 'Male':\n    Height = FirstFVC / (27.63 - 0.112 * Age)\nelse:\n    Height = FirstFVC / (21.78 - 0.101 * Age)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Put Patient details, and create a running list of weeks into DataFrame\nWeeks = list(range(101))\ndf_inference = pd.DataFrame({'Weeks':Weeks})\ndf_inference['Patient'] = Patient\ndf_inference['Sex'] = Sex\ndf_inference['Age'] = Age\ndf_inference['SmokingStatus'] = SmokingStatus\ndf_inference['MinWeek'] = MinWeek\ndf_inference['FirstFVC'] = FVC\ndf_inference['FullFVC'] = FullFVC\ndf_inference['Height'] = Height\ndf_inference['Percent'] = Percent\ndf_inference['WeeksPassed'] = df_inference['Weeks'] - df_inference['MinWeek']\ndf_inference['FVC'] = 0 # dummy FVC, to be predicted\n\ntransformed_data_series = datawrangler.transform(df_inference)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## put transformed series into dataframe\n\n# get column names for non-categorical data\nnew_col_names = no_transform_attribs + num_attribs\n\n# extract possible values from the fitted transformer\ncategorical_values = [s for s in datawrangler.named_transformers_[\"cat_encoder\"].get_feature_names()]\nnew_col_names += categorical_values\n\n# create Dataframe based on the extracted Column-Names\ndf_inference = pd.DataFrame(transformed_data_series, columns=new_col_names)\ndf_inference.head()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"csv_features_list = ['FullFVC','Age','Weeks','MinWeek','WeeksPassed','FirstFVC','Height','x0_Female','x1_Currently smokes','x1_Ex-smoker']\ndf_inference = df_inference[csv_features_list]\npreds = huber.predict(df_inference)\ndf_inference['preds'] = preds\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import seaborn as sns\nsns.lineplot(range(101), preds)\nplt.ylim(0, 4000)"},{"metadata":{"trusted":true},"cell_type":"code","source":"## for single prediction\n# df = huber_predict(lower_huber, mid_huber, upper_huber, Patient, Week, FVC, Percent, Age, Sex, SmokingStatus, week_range=101)\n\n# df_submission = df.apply(lambda x: huber_predict(lower_huber,\n#                                             mid_huber,\n#                                             upper_huber,\n#                                             x['Patient'],\n#                                             x['Weeks'],\n#                                             x['FVC'],\n#                                             x['Percent'],\n#                                             x['Age'],\n#                                             x['Sex'],\n#                                             x['SmokingStatus'],\n#                                             week_range = 133\n#                                            ), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}