{"cells":[{"metadata":{},"cell_type":"markdown","source":"# To create tif/jpeg image\n\n* It is to find what is the ways to have jpeg images\n* There are many EDA notebook , here I try to summarize on conversion after reading a 2 very good notebooks","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import cv2 as cv2\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reference:\n* https://www.kaggle.com/nxrprime/fibrosis-eda-fast-ai/notebook#Fast.ai!-(yay-:3)\n* https://www.kaggle.com/jhoward/cleaning-the-data-for-rapid-prototyping-fastai","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Install FAST AI lib\n!pip install fastai2 -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install opencv-contrib-python","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai2.basics           import *\nfrom fastai2.medical.imaging  import *\nimport matplotlib.pyplot as plt\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is just to try some code to check \n# if fast ai is fast enough\nfn = Path('../input/osic-pulmonary-fibrosis-progression/train/ID00026637202179561894768')\nfname = Path('../input/osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/13.dcm')\ndcom = fname.dcmread()\ndcom.show(scale=dicom_windows.lungs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = dcom.mask_from_blur(dicom_windows.lungs)\nwind = dcom.windowed(*dicom_windows.lungs)\n\n_,ax = subplots(1,1)\nshow_image(wind, ax=ax[0])\nshow_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[0]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbs = mask2bbox(mask)\nlo,hi = bbs\nshow_image(wind[lo[0]:hi[0],lo[1]:hi[1]]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fixing DCM images\n* https://www.kaggle.com/jhoward/cleaning-the-data-for-rapid-prototyping-fastai\n\nOn fixing some dcm images , more details on above notebook","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/')\ndef fix_pxrepr(dcm):\n    if dcm.PixelRepresentation != 0 or dcm.RescaleIntercept<-100: return\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"def dcm_tfm(fn): \n    fn = (path/fn).with_suffix('.dcm')\n    \n    try:\n        x = fn.dcmread()\n        fix_pxrepr(x)\n    except Exception as e:\n        pass\n    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n    px = x.scaled_px\n    \n    #img_tensor = TensorImage(px.to_3chan(dicom_windows.lungs,dicom_windows.subdural, bins=None))\n    \n    px.save_jpg('test.jpg',[dicom_windows.lungs,dicom_windows.subdural], bins=None)\n    \n    return 1\n    #return \n    #return TensorImage(px.to_3chan(dicom_windows.lungs, bins=None))","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#dcm_tfm('4')\n#show_images(dcm_tfm('3'))","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#\n# Here to read iamges one by one \n# Modify it to call in loop for all directories and images in it\n# I have put only to call with one directory\n\ndef dcm_img(fn): \n    #fn = (path/fn).with_suffix('.dcm')\n    fn = Path('../input/osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/'+fn+'.dcm')\n    try:\n        x = fn.dcmread()\n        fix_pxrepr(x)\n    except Exception as e:\n        pass\n    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n    \n    \n    return x\n    #return \n    #return TensorImage(px.to_3chan(dicom_windows.lungs, bins=None))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* DCM image to take Lungs window only to center it and then gaussina blur\n* Gaussian blur could be good hyperparameter\n\n* https://www.kaggle.com/nxrprime/fibrosis-eda-fast-ai/notebook#Fast.ai!-(yay-:3)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Example","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gauusing blur\ndcom_img = dcm_img(str(1))\ngdcm = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 80) # using the brain for visualization purposes\n\n_,ax = subplots(1,2)\nshow_image(gdcm,ax[0]);\nshow_image(dcom_img.windowed(*dicom_windows.lungs),ax[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### dcom_img.pixel_array, dcom_img.pixel_array.shape\ntype(gdcm)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Pixel Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"px = dcom_img.pixels.flatten()\nplt.hist(px, bins=50, color='c');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert a DICOM image into tensors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# get image pixels directly from dcm image\ntensor_dicom = dcom_img.hist_scaled()\ntensor_dicom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#_,ax = subplots(1,2)\nplt.imshow(tensor_dicom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save as JPG","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gdcm.save_jpg(path='test1.jpg' , wins=[dicom_windows.lungs,dicom_windows.lungs])\ndcom_img.save_jpg(path='test2.jpg' , wins=[dicom_windows.lungs,dicom_windows.lungs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load TIF image\nfrom PIL import Image \nimg1 = Image.open('test1.jpg')\nimg2 = Image.open('test2.jpg')\n\n#img3 = cv2.addWeighted ( img1,4, img2 ,-4 ,128)\n#plt.imshow(img3,cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save as TIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(gdcm.dtype)\nTensor.save_tif16(gdcm,'test.tif')\n#print(gdcm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load TIF image\nfrom PIL import Image \ntf_file = Image.open('test.tif')\nprint(tf_file.shape)\nplt.imshow(tf_file,cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Same image without Gaussian blur\n# As it is very visible that there is lot of extra\n# information which may not be good\n\ndcom_img1 = dcm_img(str(5))\n#gdcm = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 75) # using the brain for visualization purposes\nshow_image(dcom_img1.windowed(*dicom_windows.lungs));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Another example","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dcom_img = dcm_img(str(13))\ngdcm = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 75) # using the brain for visualization purposes\n\n\n_,ax = subplots(1,2)\nshow_image(gdcm,ax[0]);\nshow_image(dcom_img.windowed(*dicom_windows.lungs),ax[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Masking\n\nAnother way is to crop part that is needed to measure.\nThat is onlt lungs capacity part","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read new image\ndcom_img = dcm_img(str(9))\n\nmask = dcom_img.mask_from_blur(dicom_windows.lungs, sigma=0.1, thresh=0.75, remove_max=False)\n#wind = dcom_img.windowed(*dicom_windows.lungs)\nwind = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 25)\n\n_,ax = subplots(1,2)\nshow_image(wind, ax=ax[0])\nshow_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[1]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbs = mask2bbox(mask)\nlo,hi = bbs\nshow_image(wind[lo[0]:hi[0],lo[1]:hi[1]]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Crop image using mask\nmask_img =  wind[lo[0]:hi[0],lo[1]:hi[1]]\n\n# convert into numpy if to use in TensorFlow\nmask_img_array = mask_img.numpy()\n#mask_img_array.shape\n\n# lets see\nplt.imshow(mask_img_array,cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Visialize image from a patient","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\n\npatient_dir = '../input/osic-pulmonary-fibrosis-progression/train/ID00032637202181710233084'\n#patient_dir = '../input/osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430'\ndatasets = []\n\n# First Order the files in the dataset\nfiles = []\nfor dcm in list(os.listdir(patient_dir)):\n    files.append(dcm) \nfiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n\n# Read in the Dataset\nfor dcm in files:\n    path = patient_dir + \"/\" + dcm\n    datasets.append(pydicom.dcmread(path))\n\n# Plot the images\nfig=plt.figure(figsize=(16, 6))\ncolumns = 10\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = datasets[i-1].pixel_array\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img, cmap=\"plasma\")\n    plt.title(i, fontsize = 9)\n    plt.axis('off');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding similarity in images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# image_path should have dir and image id\n# e.g. - ID00007637202177411956430/1\n\ndef dcm_img_dir(image_path): \n\n    #fn = Path('../input/osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/'+fn+'.dcm')\n    fn = Path('../input/osic-pulmonary-fibrosis-progression/train/'+image_path+'.dcm')\n    try:\n        x = fn.dcmread()\n        fix_pxrepr(x)\n    except Exception as e:\n        pass\n    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n    \n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_img_array(dcom_img):\n         \n    mask = dcom_img.mask_from_blur(dicom_windows.lungs, sigma=0.1, thresh=0.75, remove_max=False)\n    #wind = dcom_img.windowed(*dicom_windows.lungs)\n    wind = gauss_blur2d(dcom_img.windowed(*dicom_windows.lungs), 25)\n\n    bbs = mask2bbox(mask)\n    lo,hi = bbs\n\n    # Crop image using mask\n    mask_img =  wind[lo[0]:hi[0],lo[1]:hi[1]]\n\n    # convert into numpy if to use in TensorFlow\n    mask_img_array = mask_img.numpy()\n    \n    return mask_img_array\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir = 'ID00007637202177411956430/'\nimg_path = img_dir + '1'\n\ndcom_img = dcm_img_dir(img_path)\nimg_array_1 = get_img_array(dcom_img)\nimg_array_1 = cv2.resize(img_array_1, (208, 511))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.transform import rescale, resize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir = 'ID00007637202177411956430/'\nimg_path = img_dir + '13'\n\ndcom_img = dcm_img_dir(img_path)\nimg_array_13 = get_img_array(dcom_img)\nimg_array_13_resize = resize(img_array_13, (208, 511))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img_array_13,cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img_array_13_resize,cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(img_array_1.shape)\nprint(img_array_13.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see\n#plt.imshow(img_array,cmap=plt.cm.bone)\nimport cv2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sift = cv2.xfeatures2d.SIFT_create()\n\nkp_1, desc_1 = sift.detectAndCompute(img_array_1, None)\n\nkp_2, desc_2 = sift.detectAndCompute(img_array_13, None)\n\nindex_params = dict(algorithm=0, trees=5) \nsearch_params = dict() \nflann = cv2.FlannBasedMatcher(index_params, search_params)\n\nmatches = flann.knnMatch(desc_1, desc_2, k=2)\n\ngood_points = [] \nratio = 0.3 \n\nfor m, n in matches: \n    if m.distance < ratio*n.distance: \n        good_points.append(m) \n\nprint(len(good_points))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}