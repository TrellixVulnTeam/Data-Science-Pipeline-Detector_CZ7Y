{"cells":[{"metadata":{},"cell_type":"markdown","source":"## OSIC Pulmonary fibrosis Progression.‚öïÔ∏è\n\nPlumonary fibrosis is a lung disease which occurs due to damage in tissue<br/>\nand damage causes tissue to thicken and patient becomes short of breath.\n\nThe problem with plumonary fibrosis it can be caused by various number of<br/>\nfactors and it is difficult for doctors to find out what is causing the problem<br/>\nand condition in which doctors can not find out the cause is called **idiopathic plumonary fibrosis.**\n\n\n\n![image](https://www.mayoclinic.org/-/media/kcms/gbs/patient-consumer/images/2016/08/10/14/57/mcdc7_pulmonaryfibrosis-8col.jpg)\n\n### Symptoms\n* Shortness of breath\n* A dry cough\n* Fatigue\n* Unexplained Weight Loss\n* Aching muscles and joints\n* Widning and Rounding of tips of the fingers or toes.\n\nTo read more about plumonary fibrosis click [here](https://www.mayoclinic.org/diseases-conditions/pulmonary-fibrosis/symptoms-causes/syc-20353690)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. What is the competion about ?üí°\n\n* So task here is simply to determine how much will patient's current<br/>\nlung health will decline using images from CT(computerised tomography)<br/>\nmetadata and current health of lungs. The health or current state of lungs<br/>\ncan be deterimined using spirometer which is an instrument which measures how <br/>\nmuch and how rapid a person breath. Spirometer gives a value called FVC which <br/>\nstands for **Forces vital Capacity**.\n\n* ### 1.1 what we need to predict ?\nWe will predict a decline in the lung function of patient in <br/> final three FVC measures and their confidence.\nactually we need to make prediction for all the weeks given in the test set but only final three would be considered for evaluation.\nHere you will find negative weeks in the dataset and explanation is a patient took a CT scan at week zero but he/she might have took<br/>\ntest for FVC before or after CT scan so week 0 is baseline but sometimes patient do not get FVC score on the same day as CT scan so there<br/>\nmight be no FVC score for week=0.\n\n**Note: Let me know if any information is wrong**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.Metrics: Laplace Log Likelihood üìè\n\n![image](https://i.imgur.com/tEIZvli.png)\n\n* ### what is Laplace Log Likelihood ?\n\nHere œÉclipped is the confidence score of the and it is clipped<br/> so value is less than or equal to 70.\n\nand delta is abs difference in FVC precited and true which is also clipped with max value of 1000.\n\n![image](data:image/png;base64,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)\n\nActully I know what laplace distribution is and what log likelihood is but I did't find any article on laplace loglikelihood.<br/>\nso please let me know If you find any good article on it.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries üìò","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\nimport sys\nimport glob\nfrom os import listdir\nimport glob\nimport tqdm\nfrom typing import Dict\nimport cv2\nimport pydicom as dicom\n\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n#plotly\n# !pip install chart_studio\nimport plotly.express as px\n# import chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nimport plotly.figure_factory as ff\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True,theme='pearl')\n\n#pydicom\nimport pydicom\n\n#supress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# from bokeh.layouts import row, column\n# from bokeh.models import ColumnDataSource, CustomJS, Label,Range1d,Slider,Span\n# from bokeh.plotting import figure, output_notebook, show\n\n#used for changing color of text in print statement\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nsr_ = Style.RESET_ALL\n\n# output_notebook()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting dataüíΩ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/osic-pulmonary-fibrosis-progression'\ntrain_csv = folder_path + '/train.csv'\ntest_csv = folder_path+ '/test.csv'\nsample_csv = folder_path + '/sample_submission.csv'\n\ntrain_data = pd.read_csv(train_csv)\ntest_data = pd.read_csv(test_csv)\nsample = pd.read_csv(sample_csv)\n\nprint(f\"{y_}Number of rows in train data: {r_}{train_data.shape[0]}\\n{y_}Number of columns in train data: {r_}{train_data.shape[1]}\")\nprint(f\"{g_}Number of rows in test data: {r_}{test_data.shape[0]}\\n{g_}Number of columns in test data: {r_}{test_data.shape[1]}\")\nprint(f\"{b_}Number of rows in submission data: {r_}{sample.shape[0]}\\n{b_}Number of columns in submission data:{r_}{sample.shape[1]}\")\n\ntrain_data.head().style.applymap(lambda x: 'background-color:lightgreen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. EDA\n\n### 3.1 FVC Distributionüìà\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def distribution(feature, color):\n    plt.figure(dpi=100)\n    sns.distplot(train_data[feature],color=color)\n    print(\"{}Max value of {} is: {} {:.2f} \\n{}Min value of {} is: {} {:.2f}\\n{}Mean of {} is: {}{:.2f}\\n{}Standard Deviation of {} is:{}{:.2f}\"\\\n      .format(y_,feature,r_,train_data[feature].max(),g_,feature,r_,train_data[feature].min(),b_,feature,r_,train_data[feature].mean(),m_,feature,r_,train_data[feature].std()))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"distribution(\"FVC\",\"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Distribution of Age üë∂üßíüßëüßì","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"distribution(\"Age\",\"brown\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Distribution of Percentüìà","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"distribution(\"Percent\",\"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 Distribution of weeksüìÖ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution(\"Weeks\",\"yellow\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### 3.5 Number of smokers  sex üö¨","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(dpi=100)\nsns.countplot(data=train_data,x='SmokingStatus',hue='Sex');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6 Distribution of FVC based on smoking status  and Sex","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def distribution2(feature):\n    plt.figure(figsize=(15,7))\n    plt.subplot(121)\n    for i in train_data.Sex.unique():\n        sns.distplot(train_data[train_data['Sex']==i][feature],label=i)\n    plt.title(f\"Distribution of {feature} based on Sex\")\n    plt.legend()\n\n    plt.subplot(122)\n    for i in train_data.SmokingStatus.unique():\n        sns.distplot(train_data[train_data['SmokingStatus']==i][feature],label=i)\n    plt.title(f\"Distribution of {feature}  based on Smoking Status\")\n    plt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution2(\"FVC\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.7 Distribution of Percent based on Sex and SmokingStatus","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"distribution2(\"Percent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### 3.8 Distribution of Age based on SmokingStatus and Sex","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"distribution2(\"Age\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.9 Distribution of Weeks based on SmokingStatus and Sex","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution2(\"Weeks\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.10 FVC vs Percent \n**Note:now will make graphs in plotly just for change**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def vs(feature1,feature2,color=None):\n    fig = px.scatter(train_data,x=feature1,y=feature2,color=color)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vs(\"FVC\",\"Percent\",'SmokingStatus')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.11 FVC vs Age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vs(\"FVC\",\"Age\",'SmokingStatus')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.12 FVC vs Weeks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vs(\"FVC\",\"Weeks\",\"SmokingStatus\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 3.13 FVC vs weeks of 20 random patient üé≤","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"rn = np.random.randint(0,train_data.Patient.nunique()-20,1)[0]\npatients_ids = train_data.Patient.unique()[rn:rn+20]\nfig =go.Figure()\n\nfor patient in patients_ids:\n    df = train_data[train_data[\"Patient\"] == patient]\n    fig.add_trace(go.Scatter(x=df.Weeks,y=df.FVC,\n                            mode='lines',\n                            name=str(patient)))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.14 count of weeks of each patient ‚åõ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f\"{y_}Number of unique patient is {r_}{train_data.Patient.nunique()}\")\n\ndf = train_data.Patient.value_counts()\nfig = px.bar(x=[f\"Patient {i}\" for i in range(len(df.index))],y=df.values)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.15 Box plot of FVC bases on sex and smokingstatus üëÄ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def box(feature1,feature2,color=None):\n    fig = px.box(train_data,x=feature2,y=feature1,color=color)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"box(\"FVC\",\"Sex\",\"SmokingStatus\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.16 Box plot of Percent based on sex and smoking status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"box(\"Percent\",\"Sex\",\"SmokingStatus\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.16 Box plot of Age based on sex and smoking status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"box(\"Age\",\"Sex\",\"SmokingStatus\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.17 Correlation matrix of train data ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(dpi=100)\nsns.heatmap(train_data.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Visulizing Images üñºÔ∏è\n\n* What is DICOM image ?\n**DICOM(Digital Image and Communication in Medecine)** is a standard developed and maintained by  **National Electrical Manufacturers Association (NEMA)** for storing and transfering the medical images like CT(computerised Tomography), Magnetic resonanse image(MRI) and other types of medical images.\n\nDICOM is very good protocol and intresting to read further click [here](https://en.wikipedia.org/wiki/DICOM)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Single Image","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_image_path = folder_path + '/train/'\ntest_image_path = folder_path + '/test/'\n\ntrain_images = os.listdir(train_image_path)\ntest_images = os.listdir(test_image_path)\n\nimage = train_image_path+train_images[0]+\"/1.dcm\"\n\ndef show_image(image):\n    print(f\"{y_} Image {r_}{image}\")\n    image = dicom.dcmread(image)\n    image = image.pixel_array    \n    plt.figure(figsize=(7,7))\n    plt.imshow(image,cmap='gray')\n    plt.axis('off')\n    plt.show()\n\nshow_image(image)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Grid of sorted images of some random patient","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def show_grid(cmap='gray'):\n    rn = np.random.randint(0,len(train_images),1)[0]\n    path= train_image_path+train_images[rn]\n    images = [dicom.read_file(path+\"/\"+img) for img in os.listdir(path)]\n    images.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n    plt.figure(figsize=(10,10))\n    for i,image in enumerate(images[:100]):\n        plt.subplot(10,10,i+1)\n        plt.imshow(image.pixel_array,cmap=cmap)\n        plt.axis('off')\n    plt.show()\n\nshow_grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_grid(cmap='jet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_grid(cmap='RdYlBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Animation","execution_count":null},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.animation as animation\nfrom IPython.display import HTML\n\ndef show_animation():\n    rn = np.random.randint(0,len(train_images),1)[0]\n    fig = plt.figure()\n    path= train_image_path+train_images[0]\n    images = [dicom.read_file(path+\"/\"+img) for img in os.listdir(path)]\n    images.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n    ims = list()\n    for image in images:\n        image = plt.imshow(image.pixel_array,cmap='gray',animated=True)\n        plt.axis('off')\n        ims.append([image])\n    ani = animation.ArtistAnimation(fig,ims,interval=100,blit=False,repeat_delay=1000)\n    return ani\n\nani = show_animation()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HTML(ani.to_jshtml())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4 3-D reconstruction.\n\nThis code for converting 2-D slices to a 3-D image is written by [mrbean-bremen](https://github.com/mrbean-bremen).\n**Orignal Code** [here](https://github.com/pydicom/pydicom/blob/master/examples/image_processing/reslice.py).","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# load the DICOM files\ndef reconstruct():\n    files = []\n    path= train_image_path+train_images[0]\n\n    for fname in os.listdir(path):\n    #     print(\"loading: {}\".format(fname))\n        files.append(pydicom.dcmread(path+\"/\"+fname))\n\n    print(\"file count: {}\".format(len(files)))\n\n    # skip files with no SliceLocation (eg scout views)\n    slices = []\n    skipcount = 0\n    for f in files:\n        if hasattr(f, 'SliceLocation'):\n            slices.append(f)\n        else:\n            skipcount = skipcount + 1\n\n    print(\"skipped, no SliceLocation: {}\".format(skipcount))\n\n    # ensure they are in the correct order\n    slices = sorted(slices, key=lambda s: s.SliceLocation)\n\n    # pixel aspects, assuming all slices are the same\n    ps = slices[0].PixelSpacing\n    ss = slices[0].SliceThickness\n    ax_aspect = ps[1]/ps[0]\n    sag_aspect = ps[1]/ss\n    cor_aspect = ss/ps[0]\n\n    # create 3D array\n    img_shape = list(slices[0].pixel_array.shape)\n    img_shape.append(len(slices))\n    img3d = np.zeros(img_shape)\n\n    # fill 3D array with the images from the files\n    for i, s in enumerate(slices):\n        img2d = s.pixel_array\n        img3d[:, :, i] = img2d\n\n    # plot 3 orthogonal slices\n    plt.figure(figsize=(15,7))\n    a1 = plt.subplot(1,3,1)\n    plt.imshow(img3d[:, :, img_shape[2]//2])\n    a1.set_aspect(ax_aspect)\n    plt.axis('off')\n\n\n    a2 = plt.subplot(1, 3, 2)\n    plt.imshow(img3d[:, img_shape[1]//2, :])\n    a2.set_aspect(sag_aspect)\n    plt.axis('off')\n\n\n    a3 = plt.subplot(1, 3, 3)\n    plt.imshow(img3d[img_shape[0]//2, :, :].T)\n    a3.set_aspect(cor_aspect)\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reconstruct()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Preprocessing Data\n\nLet us create a baseline pytorch model.\n\n### 5.1 Importing some more libraries üìò","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder,PowerTransformer\nfrom sklearn.model_selection import train_test_split, cross_val_score,cross_validate, KFold,GroupKFold\nfrom sklearn.metrics import make_scorer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting base week for patient\ndef get_baseline_week(data):\n    df = data.copy()\n    df['Weeks'] = df['Weeks'].astype(int)\n    df['min_week'] = df.groupby('Patient')['Weeks'].transform('min')\n    df['baseline_week'] = df['Weeks'] - df['min_week']\n    return df\n\n#getting FVC for base week and setting it as base_FVC of patient\ndef get_base_FVC(data):\n    df = data.copy()\n    base = df.loc[df.Weeks == df.min_week][['Patient','FVC']].copy()\n    base.columns = ['Patient','base_FVC']\n    \n    base['nb']=1\n    base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n    \n    base = base[base.nb==1]\n    base.drop('nb',axis =1,inplace=True)\n    df = df.merge(base,on=\"Patient\",how='left')\n    df.drop(['min_week'], axis = 1)\n    return df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop_duplicates(keep=False,inplace=True,subset=['Patient','Weeks'])\ntrain_data = get_baseline_week(train_data)\ntrain_data = get_base_FVC(train_data)\n\nsample = pd.read_csv(sample_csv)\nsample.drop(\"FVC\",axis=1,inplace=True)\nsample[[\"Patient\",\"Weeks\"]] = sample[\"Patient_Week\"].str.split(\"_\",expand=True) \nsample = sample.merge(test_data.drop(\"Weeks\",axis=1),on=\"Patient\",how=\"left\")\n\n#we have to predict for all weeks \nsample[\"min_Weeks\"] = np.nan\nsample = get_baseline_week(sample)\nsample = get_base_FVC(sample)\n\ntrain_columns = ['baseline_week','base_FVC','Percent','Age','Sex','SmokingStatus']\ntrain_label = ['FVC']\nsub_columns = ['Patient_Week','FVC','Confidence']\n\ntrain = train_data[train_columns]\ntest = sample[train_columns]\n#Preprocessing\ntransformer = ColumnTransformer([('s',StandardScaler(),[0,1,2,3]),('o',OneHotEncoder(),[4,5])])\ntarget = train_data[train_label].values\ntrain = transformer.fit_transform(train)\ntest = transformer.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution(\"baseline_week\",'green');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 6 Simple Pytorch Model\n\n### 6.1 importing pytorch libraries üìò","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,n):\n        super(Model,self).__init__()\n        self.layer1 = nn.Linear(n,200)\n        self.layer2 = nn.Linear(200,100)\n        \n        self.out1 = nn.Linear(100,3)\n        self.relu3 = nn.ReLU()\n        self.out2 = nn.Linear(100,3)\n            \n    def forward(self,xb):\n        x1 =  F.leaky_relu(self.layer1(xb))\n        x1 =  F.leaky_relu(self.layer2(x1))\n        \n        o1 = self.out1(x1)\n        o2 = F.relu(self.out2(x1))\n        return o1 + torch.cumsum(o2,dim=1)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.2 Training Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run():\n    \n    def score(outputs,target):\n        confidence = outputs[:,2] - outputs[:,0]\n        clip = torch.clamp(confidence,min=70)\n        target=torch.reshape(target,outputs[:,1].shape)\n        delta = torch.abs(outputs[:,1] - target)\n        delta = torch.clamp(delta,max=1000)\n        sqrt_2 = torch.sqrt(torch.tensor([2.])).to(device)\n        metrics = (delta*sqrt_2/clip) + torch.log(clip*sqrt_2)\n        return torch.mean(metrics)\n    \n    def qloss(outputs,target):\n        qs = [0.25,0.5,0.75]\n        qs = torch.tensor(qs,dtype=torch.float).to(device)\n        e =  target - outputs\n        e.to(device)\n        v = torch.max(qs*e,(qs-1)*e)\n        v = torch.sum(v,dim=1)\n        return torch.mean(v)\n    \n    def loss_fn(outputs,target,l):\n        return l * qloss(outputs,target) + (1- l) * score(outputs,target)\n        \n    def train_loop(train_loader,model,loss_fn,device,optimizer,lr_scheduler=None):\n        model.train()\n        losses = list()\n        metrics = list()\n        for i, (inputs, labels) in enumerate(train_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            with torch.set_grad_enabled(True):           \n                outputs = model(inputs)                 \n                metric = score(outputs,labels)\n\n                loss = loss_fn(outputs,labels,0.8)\n                metrics.append(metric.cpu().detach().numpy())\n                losses.append(loss.cpu().detach().numpy())\n\n                loss.backward()\n\n                optimizer.step()\n                if lr_scheduler != None:\n                    lr_scheduler.step()\n            \n        return losses,metrics\n    \n    def valid_loop(valid_loader,model,loss_fn,device):\n        model.eval()\n        losses = list()\n        metrics = list()\n        for i, (inputs, labels) in enumerate(valid_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)                 \n            metric = score(outputs,labels)\n            \n            loss = loss_fn(outputs,labels,0.8)\n            metrics.append(metric.cpu().detach().numpy())\n            losses.append(loss.cpu().detach().numpy())\n            \n        return losses,metrics    \n\n    NFOLDS =5\n    kfold = KFold(NFOLDS,shuffle=True,random_state=42)\n    \n    #kfold\n    for k , (train_idx,valid_idx) in enumerate(kfold.split(train)):\n        batch_size = 64\n        epochs = 50\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"{device} is used\")\n        x_train,x_valid,y_train,y_valid = train[train_idx,:],train[valid_idx,:],target[train_idx],target[valid_idx]\n        n = x_train.shape[1]\n        model = Model(n)\n        model.to(device)\n        lr = 0.1\n        optimizer = optim.Adam(model.parameters(),lr=lr)\n        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n\n        train_tensor = torch.tensor(x_train,dtype=torch.float)\n        y_train_tensor = torch.tensor(y_train,dtype=torch.float)\n\n        train_ds = TensorDataset(train_tensor,y_train_tensor)\n        train_dl = DataLoader(train_ds,\n                             batch_size = batch_size,\n                             num_workers=4,\n                             shuffle=True\n                             )\n\n        valid_tensor = torch.tensor(x_valid,dtype=torch.float)\n        y_valid_tensor = torch.tensor(y_valid,dtype=torch.float)\n\n        valid_ds = TensorDataset(valid_tensor,y_valid_tensor)\n        valid_dl = DataLoader(valid_ds,\n                             batch_size = batch_size,\n                             num_workers=4,\n                             shuffle=False\n                             )\n        \n        print(f\"Fold {k}\")\n        for i in range(epochs):\n            losses,metrics = train_loop(train_dl,model,loss_fn,device,optimizer,lr_scheduler)\n            valid_losses,valid_metrics = valid_loop(valid_dl,model,loss_fn,device)\n            if (i+1)%5==0:\n                print(f\"epoch:{i} Training | loss:{np.mean(losses)} score: {np.mean(metrics)}| \\n Validation | loss:{np.mean(valid_losses)} score:{np.mean(valid_metrics)}|\")\n        torch.save(model.state_dict(),f'model{k}.bin')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.3 Inference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference():\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    nfold = 5\n    all_prediction = np.zeros((test.shape[0],3))\n    \n    for i in range(nfold):\n        n = train.shape[1]\n        \n        model = Model(n)\n        model.load_state_dict(torch.load(f\"model{i}.bin\"))\n        predictions = list()\n        model.to(device)\n        test_tensor = torch.tensor(test,dtype=torch.float)\n        test_dl = DataLoader(test_tensor,\n                        batch_size=64,\n                        num_workers=2,\n                        shuffle=False)\n    \n        with torch.no_grad():\n            for i, inputs in enumerate(test_dl):\n                inputs = inputs.to(device, dtype=torch.float)\n                outputs= model(inputs) \n                predictions.extend(outputs.cpu().detach().numpy())\n\n        all_prediction += np.array(predictions)/nfold\n        \n    return all_prediction  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.4 submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = inference()\nsample[\"Confidence\"] = np.abs(prediction[:,2] - prediction[:,0])\nsample[\"FVC\"] = prediction[:,1]\nsub = sample[sub_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(121)\nsns.distplot(sub.Confidence)\nplt.subplot(122)\nsns.distplot(sub.FVC);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sub.shape)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Please tell me in the comments if anything is wrong or if you did not understand something.ü§ó<br/>\n Please upvote if you found it useful.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Todo \n\n* How to use image to make prediction.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}