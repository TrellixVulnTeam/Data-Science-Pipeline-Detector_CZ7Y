{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.0.13.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.6/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.6\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport cudf \nimport cupy as cp\nfrom cuml.neighbors import KNeighborsRegressor\nfrom cuml import SVR\nfrom cuml.linear_model import Ridge, Lasso\nfrom cuml.metrics import mean_absolute_error, mean_squared_error\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport pydicom\nimport os\nimport numpy as np\n#from matplotlib import cm\nfrom matplotlib import pyplot as plt\nimport cv2\n#import seaborn as sns\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess Data: \n\nBefore we work with cudf dataframes, we will process and curate the data through panadas with a similar taken from Ulrich GOUE. Here is a helpful notebook on preparing the tabular data and using keras NNets for regression: [Osic-Multiple-Quantile-Regression-Start](https://www.kaggle.com/ulrich07/osic-multiple-quantile-regression-starter). However, I will show a fast method to using support vector regressor with RAPIDS.AI (~2 mins. for notebook submission). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/osic-pulmonary-fibrosis-progression/train.csv\")\ntrain_df.drop_duplicates(keep = False, inplace = True, subset = ['Patient', 'Weeks'])\ntest_df = pd.read_csv(\"../input/osic-pulmonary-fibrosis-progression/test.csv\")\n\n\nsub_df = pd.read_csv(\"../input/osic-pulmonary-fibrosis-progression/sample_submission.csv\")\nsub_df['Patient'] = sub_df['Patient_Week'].apply(lambda x:x.split('_')[0])\nsub_df['Weeks'] = sub_df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\nsub_df =  sub_df[['Patient','Weeks','Confidence','Patient_Week']]\nsub_df = sub_df.merge(test_df.drop('Weeks', axis=1), on=\"Patient\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['WHERE'] = 'train'\ntest_df['WHERE'] = 'val'\nsub_df['WHERE'] = 'test'\n\ndf = train_df.append([test_df, sub_df])\ndf['min_week'] = df['Weeks']\ndf.loc[df.WHERE=='test','min_week'] = np.nan\ndf['min_week'] = df.groupby('Patient')['min_week'].transform('min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline_df = df.loc[df.Weeks == df.min_week]\nbaseline_df = baseline_df[['Patient', 'FVC']].copy()\nbaseline_df.columns = ['Patient', 'min_FVC']\nbaseline_df['nb'] = 1\nbaseline_df['nb'] = baseline_df.groupby('Patient')['nb'].transform('cumsum')\nbaseline_df = baseline_df[baseline_df.nb==1]\nbaseline_df.drop('nb', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(baseline_df, on='Patient', how='left')\ndf['base_week'] = df['Weeks'] - df['min_week']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert string labels to numeric labels\ncolumns = ['Sex', 'SmokingStatus']\nfeatures = []\nfor feat in columns: \n    for mode in df[feat].unique():\n        features.append(mode)\n        df[mode]  = (df[feat] == mode).astype(int)\n    \nfeatures += ['Age', 'Percent', 'min_FVC', 'base_week']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Zero-center normalization \n\nfor feat in features:\n    df[feat] = (df[feat] - np.mean(df[feat]))/np.std(df[feat])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert Pandas to Cudf dataframes \n\nThis transformation will then allow us to run SVM, random forests, and other machine learning models with GPU, using the RAPIDS.AI library.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cudf = cudf.from_pandas(df)\ntr_cudf = cudf.loc[cudf.WHERE=='train']\nval_cudf = cudf.loc[cudf.WHERE=='val']\ntest_cudf = cudf.loc[cudf.WHERE=='test']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation metric for the comp\ndef score(y_true, y_pred):\n    C1, C2 = cp.asarray(70.0), cp.asarray(70.0)\n    sigma = y_pred[:, 2] - y_pred[:, 0]\n    fvc_pred = y_pred[:, 1]\n    \n    #sigma_clip = sigma + C1\n    sigma_clip = cp.maximum(sigma, C1)\n    delta = cp.absolute(y_true - fvc_pred)\n    delta = cp.minimum(delta, C2)\n    sq2 = cp.sqrt( 2.0)\n    metric = (delta / sigma_clip)*sq2 + cp.log(sigma_clip* sq2)\n    return cp.mean(metric)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the machine learning model with RAPIDS:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import KFold\n\nKfold = 5\nkf = KFold(n_splits=Kfold)\n\nX, y, X_test = tr_cudf[features].values, tr_cudf['FVC'].values, test_cudf[features].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\nmodel_score, model_zoo, y_preds_scores = [], [], []\nfor c1, c2, c3 in [(1, 50, 500)]:\n    \n    y_preds = cp.zeros((X.shape[0], 3))\n    y_test_preds = cp.zeros((X_test.shape[0], 3))\n    \n    model_container = []\n    SVR_kfold_ensemble,Ridge_kfold_ensemble = [], [] \n    for train_ind, val_ind in kf.split(X):\n        X_train, X_val = X[train_ind,:], X[val_ind,:]\n        y_train, y_val = y[train_ind], y[val_ind]\n        \n        model_1 = SVR(C=c1, cache_size=3000.0)\n        model_1.fit(X_train, y_train)\n        \n        model_2 = SVR(C=c2, cache_size=3000.0)\n        model_2.fit(X_train, y_train)\n        \n        model_3 = SVR(C=c3, cache_size=3000.0)\n        model_3.fit(X_train, y_train)\n        \n        \n        \n        y_preds[val_ind,0] = model_1.predict(X_val)\n        y_preds[val_ind,1] = model_2.predict(X_val)\n        y_preds[val_ind,2] = model_3.predict(X_val)\n        \n        y_test_preds[:,0] += model_1.predict(X_test) \n        y_test_preds[:,1] += model_2.predict(X_test) \n        y_test_preds[:,2] += model_3.predict(X_test) \n        \n    y_test_preds *= 1/cp.asarray(Kfold)\n    y_preds_scores.append(y_test_preds)\n    model_score.append(score(y,y_preds))\n    model_zoo.append([model_1, model_2, model_3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_score, y_preds_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observing the prediction:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_np = cp.asnumpy(y)\ny_preds_np = cp.asnumpy(y_preds)\nidxs = np.random.randint(0, y_np.shape[0], 100)\nplt.plot(y_np[idxs], label=\"ground truth\")\nplt.plot(y_preds_np[idxs, 0], alpha = 0.5, label=\"c=1\")\nplt.plot(y_preds_np[idxs, 1],  alpha = 0.5, label=\"c=5\")\nplt.plot(y_preds_np[idxs, 2],  alpha = 0.5, label=\"c=500\")\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setting up the submission file: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cudf['FVC1'] = 1.0*y_test_preds[:,1]\ntest_cudf['Confidence1'] = y_test_preds[:,2] - y_test_preds[:,0]\ntest_cudf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_cudf = test_cudf[['Patient_Week','FVC','Confidence','FVC1','Confidence1']].copy()\nsubmission_cudf.loc[~submission_cudf.FVC1.isnull()].head(10)\nsubmission_cudf[\"FVC\"] = submission_cudf[\"FVC1\"]\nsubmission_cudf[\"Confidence\"] = submission_cudf[\"Confidence1\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_cudf.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_cudf[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}