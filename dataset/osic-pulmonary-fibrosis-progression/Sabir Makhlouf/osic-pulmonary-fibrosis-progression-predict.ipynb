{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pydicom\nimport os\nimport seaborn as sns\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder,normalize\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport category_encoders as ce\nfrom keras.optimizers import Adam\n\nimport cv2\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.style.use('seaborn-darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n# GPU device Check.\ndevice_name = tf.test.gpu_device_name()\nif device_name == '/device:GPU:0':\n    print('Found GPU at: {}'.format(device_name))\nelse:\n    raise SystemError('GPU device not found')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # PyTorch use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\ntest = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/osic-pulmonary-fibrosis-progression/sample_submission.csv\")\nsub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\nsub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\nsub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\nsub = sub.merge(test.drop('Weeks', axis=1), on=\"Patient\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FVC : forced vital capacity, i.e. the volume of air exhaled","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum(),'\\n')\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(train['Sex'].value_counts().index, train['Sex'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(train['SmokingStatus'].value_counts().index, train['SmokingStatus'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sa = pd.crosstab(train['SmokingStatus'],train['Sex'])\nsa.plot(kind=\"bar\",title='No of passengers survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = 10,5\nax = train['Age'].hist(bins = 15,alpha = 0.9, color = 'green')\nax.set(xlabel = 'Age',ylabel = 'Count',title = 'Visualization of Ages')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = 10,5\nax = train['Weeks'].hist(bins = 15,alpha = 0.9, color = 'green')\nax.set(xlabel = 'Weeks',ylabel = 'Count',title = 'Visualization of Ages')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(train['Weeks'],train['FVC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(train['Age'],train['FVC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = 10,10\nsb.heatmap(train.corr(),annot = True,square = True,linewidths = 2,linecolor = 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['FVC'] == train['FVC'].max()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['FVC'] == train['FVC'].min()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The patient of Max FVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imdir_max = \"/kaggle/input/osic-pulmonary-fibrosis-progression/train/ID00219637202258203123958\"\nimdir_min = \"/kaggle/input/osic-pulmonary-fibrosis-progression/train/ID00225637202259339837603\"\n\nfig=plt.figure(figsize=(12, 12))\n\ncolumns = 4\nrows = 5\n\nimglist = os.listdir(imdir_max)\n\n\nfor i in range(1, columns*rows +1):\n    filename = imdir_max + \"/\" + str(i) + \".dcm\"\n    ds = pydicom.dcmread(filename)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(ds.pixel_array, cmap='jet')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The patient of Min FVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(12, 12))\n\ncolumns = 4\nrows = 5\n\nimglist = os.listdir(imdir_min)\n\n\nfor i in range(1, columns*rows +1):\n    filename = imdir_min + \"/\" + str(i) + \".dcm\"\n    ds = pydicom.dcmread(filename)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(ds.pixel_array, cmap='jet')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission File:\n*     Patient_Week,FVC,Confidence\n*     ID00002637202176704235138_1,2000,100\n*     ID00002637202176704235138_2,2000,100\n*     ID00002637202176704235138_3,2000,100\n\nconfidence = standard deviation Ïƒ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Patient_Week'] = train['Patient'].astype(str) + '_' + train['Weeks'].astype(str)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Patient_Week'] = test['Patient'].astype(str) + '_' + test['Weeks'].astype(str)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct train input\n\noutput = pd.DataFrame()\ngb = train.groupby('Patient')\ntk0 = tqdm(gb, total=len(gb))\nfor _, usr_df in tk0:\n    usr_output = pd.DataFrame()\n    for week, tmp in usr_df.groupby('Weeks'):\n        rename_cols = {'Weeks': 'base_Week', 'FVC': 'base_FVC', 'Percent': 'base_Percent', 'Age': 'base_Age'}\n        tmp = tmp.drop(columns='Patient_Week').rename(columns=rename_cols)\n        drop_cols = ['Age', 'Sex', 'SmokingStatus', 'Percent']\n        _usr_output = usr_df.drop(columns=drop_cols).rename(columns={'Weeks': 'predict_Week'}).merge(tmp, on='Patient')\n        _usr_output['Week_passed'] = _usr_output['predict_Week'] - _usr_output['base_Week']\n        usr_output = pd.concat([usr_output, _usr_output])\n    output = pd.concat([output, usr_output])\n\ntrain = output[output['Week_passed']!=0].reset_index(drop=True)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct test input\n\ntest = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')\\\n        .rename(columns={'Weeks': 'base_Week', 'FVC': 'base_FVC', 'Percent': 'base_Percent', 'Age': 'base_Age'})\nsubmission = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv')\nsubmission['Patient'] = submission['Patient_Week'].apply(lambda x: x.split('_')[0])\nsubmission['predict_Week'] = submission['Patient_Week'].apply(lambda x: x.split('_')[1]).astype(int)\ntest = submission.drop(columns=['FVC', 'Confidence']).merge(test, on='Patient')\ntest['Week_passed'] = test['predict_Week'] - test['base_Week']\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission.shape)\nprint(test.shape)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum(),'\\n')\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index(['Patient_Week'],inplace = True)\n\ntest.set_index(['Patient_Week'],inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['FVC']\nX = train.drop(['FVC'], axis=1)\nX = X.drop(['Patient'], axis=1)\n\n#y_test = test['FVC']\ntest_X = test.drop(['Patient'], axis=1)\n#test_X = test.drop(['FVC'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting dummy variables column\n\nenc = LabelEncoder()\n\nX['Sex'] = enc.fit_transform(X['Sex'])\n\nX['SmokingStatus'] = enc.fit_transform(X['SmokingStatus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X['Sex'] = enc.fit_transform(test_X['Sex'])\ntest_X['SmokingStatus'] = enc.fit_transform(test_X['SmokingStatus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizing\n\nfrom sklearn.preprocessing import normalize\n\nX = normalize(X)\ntest_X = normalize(test_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1-DNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = test_X \npe = np.zeros((test_X.shape[0], 3)) #for predict test\n# pred = np.zeros((X.shape[0], 3)) #for predict val\nze = normalize(sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\n\n# C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n# #=============================#\n# def score(y_true, y_pred):\n#     tf.dtypes.cast(y_true, tf.float32)\n#     tf.dtypes.cast(y_pred, tf.float32)\n#     sigma = y_pred[:, 2] - y_pred[:, 0]\n#     fvc_pred = y_pred[:, 1]\n    \n#     #sigma_clip = sigma + C1\n#     sigma_clip = tf.maximum(sigma, C1)\n#     delta = tf.abs(y_true[:, 0] - fvc_pred)\n#     delta = tf.minimum(delta, C2)\n#     sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n#     metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n#     return K.mean(metric)\n# #============================#\n# def qloss(y_true, y_pred):\n#     # Pinball loss for multiple quantiles\n#     qs = [0.2, 0.50, 0.8]\n#     q = tf.constant(np.array([qs]), dtype=tf.float32)\n#     e = y_true - y_pred\n#     v = tf.maximum(q*e, (q-1)*e)\n#     return K.mean(v)\n# #=============================#\n# def mloss(_lambda):\n#     def loss(y_true, y_pred):\n#         return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n#     return loss\n# #=================\ndef make_model():\n    z = L.Input((8,), name=\"Patient\")\n    x = L.Dense(1000, activation=\"relu\", name=\"d1\")(z)\n    x = L.Dense(1000, activation=\"relu\", name=\"d2\")(x)\n    x = L.Dense(500, activation=\"relu\", name=\"d3\")(x)\n    x = L.Dense(500, activation=\"relu\", name=\"d4\")(x)\n    p1 = L.Dense(3, activation=\"relu\", name=\"p1\")(x)\n    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n                     name=\"preds\")([p1, p2])\n    \n    model = M.Model(z, preds, name=\"CNN\")\n    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n    opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01, amsgrad=False)\n    model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model \n\n \nnet = make_model()\nnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.model_selection import KFold\n\nscores = []\n\nNFOLD = 5\nkf = KFold(n_splits=NFOLD)\nBATCH_SIZE = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncnt = 0\nfor tr_idx, val_idx in kf.split(X):  \n    cnt += 1\n    print(f\"FOLD {cnt}\")\n    net = make_model()  \n    net.fit(X[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=400, \n            validation_data=(X[val_idx], y[val_idx]), verbose=0) #\n#     print(\"train\", net.evaluate(X[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n#     print(\"val\", net.evaluate(X[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n#     print(\"predict val...\")\n#     pred[val_idx] = net.predict(X[val_idx], batch_size=BATCH_SIZE, verbose=0)    \n    print(\"predict test...\")   \n    pe += net.predict(ze, batch_size=BATCH_SIZE, verbose=0) / NFOLD ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2-xgboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# #K Fold Cross Validation\n  \n# from sklearn.model_selection import KFold \n# import xgboost as xgb\n\n\n# kf = KFold(n_splits=20, random_state=42, shuffle=True)\n\n# for train_index, val_index in kf.split(X):\n#     print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n#     X_train, X_val = X[train_index], X[val_index]\n#     y_train, y_val = y[train_index], y[val_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dtrain = xgb.DMatrix(X_train, label=y_train)\n# dvalid = xgb.DMatrix(X_val, label=y_val)\n# watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# xgb_pars = {'min_child_weight': 10, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 15,\n#             'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n#             'eval_metric': 'rmse', 'objective': 'reg:linear'}    \n\n# model = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=250,\n#                   maximize=False, verbose_eval=15) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ze = normalize(test_X)\n# ze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dtest = xgb.DMatrix(ze)\n\n# pred = model.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3-RNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# #K Fold Cross Validation\n\n# from sklearn.model_selection import KFold\n\n\n# kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n\n# for train_index, val_index in kf.split(X):\n#     print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n#     X_train, X_val = X[train_index], X[val_index]\n#     y_train, y_val = y[train_index], y[val_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(X_train.shape)\n# print(y_train.shape)\n# print(X_val.shape)\n# print(y_val.shape)\n\n# #reshape for rnn\n\n# X_train = X_train.reshape(-1, 1, 8)\n# X_val  = X_val.reshape(-1, 1, 8)\n# y_train = y_train.values #convert pd to array\n# y_train = y_train.reshape(-1, 1,)\n# y_val = y_val.values #convert pd to array\n# y_val = y_val.reshape(-1, 1,)\n\n# print(X_train.shape)\n# print(y_train.shape)\n# print(X_val.shape)\n# print(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.layers import Conv2D,LSTM,LeakyReLU, MaxPooling2D,Concatenate,Input, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\n# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n# from tensorflow.keras.models import Model\n\n\n#   # create model\n    \n\n# #input \n# input_layer = Input(shape=(1,8))\n# main_rnn_layer = LSTM(64, return_sequences=True, recurrent_dropout=0.2)(input_layer)\n\n    \n# #output\n# rnn = LSTM(32)(main_rnn_layer)\n# dense = Dense(128)(rnn)\n# dropout_c = Dropout(0.3)(dense)\n# dense = Dense(64)(dropout_c)\n# dropout_c = Dropout(0.3)(dense)\n# dense = Dense(32)(dropout_c)\n# dropout_c = Dropout(0.3)(dense)\n\n# classes = Dense(1, activation= LeakyReLU(alpha=0.1),name=\"class\")(dropout_c)\n\n# model = Model(input_layer, classes)\n\n# # Compile model\n# callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n#              EarlyStopping(monitor='val_loss', patience=20),\n#              ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n# model.compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")\n\n\n# model.summary()\n# # Fit the model\n# history = model.fit(X_train, y_train, \n#           epochs = 250, \n#           batch_size = 8, \n#           validation_data=(X_val,  y_val), \n#           callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('Loss over epochs')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Validation'], loc='best')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.load_weights(\"best_model.h5\")\n\n# test_X = test_X.reshape(-1, 1,8)\n\n\n# predictions = model.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pe.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" pe[:,0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://i.imgur.com/EV7xPrl.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submis = test.copy() #for Patient_Week\nsubmis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\n#calcule Confidence\n \nsubmis['FVC_pred'] = pe[:,0]\n\n# baseline score\nsubmis['Confidence'] = 100\nsubmis['sigma_clipped'] = submis['Confidence'].apply(lambda x: max(x, 70))\nsubmis['diff'] = abs(submis['base_FVC'] - submis['FVC_pred'])\nsubmis['delta'] = submis['diff'].apply(lambda x: min(x, 1000))\nsubmis['score'] = -math.sqrt(2)*submis['delta']/submis['sigma_clipped'] - np.log(math.sqrt(2)*submis['sigma_clipped'])\nscore = submis['score'].mean()\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy as sp\nfrom functools import partial\n\ndef loss_func(weight, row):\n    confidence = weight\n    sigma_clipped = max(confidence, 70)\n    diff = abs(row['base_FVC'] - row['FVC_pred'])\n    delta = min(diff, 1000)\n    score = -math.sqrt(2)*delta/sigma_clipped - np.log(math.sqrt(2)*sigma_clipped)\n    return -score\n\nresults = []\ntk0 = tqdm(submis.iterrows(), total=len(submis))\nfor _, row in tk0:\n    loss_partial = partial(loss_func, row=row)\n    weight = [100]\n    #bounds = [(70, 100)]\n    #result = sp.optimize.minimize(loss_partial, weight, method='SLSQP', bounds=bounds)\n    result = sp.optimize.minimize(loss_partial, weight, method='SLSQP')\n    x = result['x']\n    results.append(x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimized score\nsubmis['Confidence'] = results\nsubmis['sigma_clipped'] = submis['Confidence'].apply(lambda x: max(x, 70))\nsubmis['diff'] = abs(submis['base_FVC'] - submis['FVC_pred'])\nsubmis['delta'] = submis['diff'].apply(lambda x: min(x, 1000))\nsubmis['score'] = -math.sqrt(2)*submis['delta']/submis['sigma_clipped'] - np.log(math.sqrt(2)*submis['sigma_clipped'])\nscore = submis['score'].mean()\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submis=submis.reset_index()\nsubmis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submis_final =  submis[['Patient_Week', 'FVC_pred', 'Confidence']].copy()\nsubmis_final = submis_final.rename(columns={\"FVC_pred\": \"FVC\"})\nsubmis_final['FVC'] = submis_final['FVC']\nsubmis_final.to_csv('submission.csv', index=False)\nsubmis_final","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}