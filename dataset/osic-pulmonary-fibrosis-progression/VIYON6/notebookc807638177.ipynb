{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\n\n\n\nimport seaborn as sns\nimport cv2\nfrom skimage import io\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nimport tensorflow.keras.backend as K\n\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose, concatenate, Input, Dropout\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import (Dense, Dropout, Activation, Flatten, Input, Add,\n                                    BatchNormalization, LeakyReLU, Concatenate, GlobalAveragePooling2D,Conv2D, AveragePooling2D)\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport random\n\nimport glob\nfrom IPython.display import display\n\nfrom pathlib import Path\n\n# Set Color Palettes for the notebook\ncustom_colors = ['#74a09e','#86c1b2','#98e2c6','#f3c969','#f2a553', '#d96548', '#c14953']\nsns.palplot(sns.color_palette(custom_colors))\n\n# Set Style\nsns.set_style(\"whitegrid\")\nsns.despine(left=True, bottom=True)\n\nfrom scipy.stats import pearsonr\nimport pydicom\nimport re\nfrom sklearn.cluster import KMeans\nfrom skimage import morphology\nfrom skimage import measure\nfrom skimage.transform import resize\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:37:48.641767Z","iopub.execute_input":"2022-06-28T11:37:48.642112Z","iopub.status.idle":"2022-06-28T11:38:01.001313Z","shell.execute_reply.started":"2022-06-28T11:37:48.642085Z","shell.execute_reply":"2022-06-28T11:38:01.000194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = Path('../input/osic-pulmonary-fibrosis-progression/')\n\ntrain = pd.read_csv(ROOT / 'train.csv')\ntest = pd.read_csv(ROOT / 'test.csv')\nsub = pd.read_csv(ROOT / 'sample_submission.csv')\n\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.003318Z","iopub.execute_input":"2022-06-28T11:38:01.004548Z","iopub.status.idle":"2022-06-28T11:38:01.109686Z","shell.execute_reply.started":"2022-06-28T11:38:01.004502Z","shell.execute_reply":"2022-06-28T11:38:01.109032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"def get_tab(df):\n    ''' \n    This function gives an array wrt each patient containing\n    feature like age, gender and smoking status\n    '''\n    vector = [(df.Age.values[0]-30)/30]\n    \n    if df.Sex.values[0].lower() == 'male':\n        vector.append(0)\n    else:\n        vector.append(1)\n        \n    if df.SmokingStatus.values[0] == 'Never smoked':\n        vector.extend([0,0])\n    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n        vector.extend([1,1])\n    elif df.SmokingStatus.values[0] == 'Currently smokes':\n        vector.extend([0,1])\n    else:\n        vector.extend([1,0])\n        \n    return np.array(vector)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.112182Z","iopub.execute_input":"2022-06-28T11:38:01.112452Z","iopub.status.idle":"2022-06-28T11:38:01.120986Z","shell.execute_reply.started":"2022-06-28T11:38:01.112426Z","shell.execute_reply":"2022-06-28T11:38:01.120332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"A = {} #Stores slope value for each of the patient\nTAB = {} #Stores training data wrt each patient\nP = [] #Stores all unique patient id's\n\nfor i,p in enumerate(train.Patient.unique()):\n    sub = train.loc[train.Patient == p, :]\n    fvc = sub.FVC.values\n    week = sub.Weeks.values\n    #print(week)\n    c = np.vstack([week, np.ones(len(week))]).T\n    a, b = np.linalg.lstsq(c,fvc)[0]\n    #print(b)\n    \n    A[p] = a # Contains slope\n    TAB[p] = get_tab(sub) #Contains gender and smoking feature\n    P.append(p) #contains unique id\n   # print(TAB)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.123176Z","iopub.execute_input":"2022-06-28T11:38:01.123677Z","iopub.status.idle":"2022-06-28T11:38:01.327535Z","shell.execute_reply.started":"2022-06-28T11:38:01.123648Z","shell.execute_reply":"2022-06-28T11:38:01.326654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img(path):\n    d = pydicom.dcmread(path)\n    return cv2.resize(d.pixel_array/2**11 ,(512,512))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.328689Z","iopub.execute_input":"2022-06-28T11:38:01.328959Z","iopub.status.idle":"2022-06-28T11:38:01.334044Z","shell.execute_reply.started":"2022-06-28T11:38:01.328934Z","shell.execute_reply":"2022-06-28T11:38:01.33287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IGenerator(Sequence):\n    \n    ''' \n    This is the generator class, which generates an input of batch size 32\n    i.e 32 patient's 2 dicom image, and features from tabular data is generated. As output \n    from his generator x and y contains pixel_data of a dicom image, tab conatins patient's meta\n    information, and 'a' is the coeffiecient wrt each patient. \n    '''\n    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n    def __init__(self, keys, a, tab, batch_size=32):\n        self.keys = [k for k in keys if k not in self.BAD_ID]\n        self.a = a\n        self.tab = tab\n        self.batch_size = batch_size\n        \n        self.train_data = {}\n        for p in train.Patient.values:\n            self.train_data[p] = os.listdir(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/')\n            #print(p)\n    def __len__(self):\n        return 1000\n    \n    def __getitem__(self, idx):\n        x = []\n        a, tab = [], [] \n        keys = np.random.choice(self.keys, size = self.batch_size)\n        \n        for k in keys:\n            try:\n                i = np.random.choice(self.train_data[k], size=1)[0]\n                img1 = get_img(f'../input/osic-pulmonary-fibrosis-progression/train/{k}/{i}')\n                x.append(img1)\n                a.append(self.a[k])\n                tab.append(self.tab[k])\n            except:\n                print(k, i)     \n        \n        x,a,tab = np.array(x), np.array(a), np.array(tab)\n        x = np.expand_dims(x, axis=-1)\n        \n        return [x,tab] , a","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.335147Z","iopub.execute_input":"2022-06-28T11:38:01.335405Z","iopub.status.idle":"2022-06-28T11:38:01.348391Z","shell.execute_reply.started":"2022-06-28T11:38:01.335378Z","shell.execute_reply":"2022-06-28T11:38:01.347699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # first layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # second layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x\n  \ndef get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n    # Contracting Path\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    \n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    #c10=GlobalAveragePooling2D()(c9)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n#     input3 = Input(shape=(4,))\n#     model = Model([input_img,input3], outputs=[outputs])\n#     return model\n    x_and_y = GlobalAveragePooling2D()(outputs)\n#Patient tabular data input\n    input3 = Input(shape=(4,))\n    z = tf.keras.layers.GaussianNoise(0.2)(input3)\n    xyz = Concatenate()([x_and_y, z])\n    xyz = Dropout(0.6)(xyz) \n    xyz = Dense(1)(xyz)\n    return Model([input_img, input3] , xyz)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.349496Z","iopub.execute_input":"2022-06-28T11:38:01.349917Z","iopub.status.idle":"2022-06-28T11:38:01.37401Z","shell.execute_reply.started":"2022-06-28T11:38:01.34989Z","shell.execute_reply":"2022-06-28T11:38:01.373034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_height=512\nim_width=512","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.375375Z","iopub.execute_input":"2022-06-28T11:38:01.375959Z","iopub.status.idle":"2022-06-28T11:38:01.3892Z","shell.execute_reply.started":"2022-06-28T11:38:01.37593Z","shell.execute_reply":"2022-06-28T11:38:01.388424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_img = Input((im_height, im_width, 1), name='img')\nmodel = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\nmodel.compile(optimizer=Adam(), loss=\"mae\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.390269Z","iopub.execute_input":"2022-06-28T11:38:01.391106Z","iopub.status.idle":"2022-06-28T11:38:01.917765Z","shell.execute_reply.started":"2022-06-28T11:38:01.391078Z","shell.execute_reply":"2022-06-28T11:38:01.916628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nkeras.utils.plot_model(model,'img.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:01.921222Z","iopub.execute_input":"2022-06-28T11:38:01.921513Z","iopub.status.idle":"2022-06-28T11:38:03.746771Z","shell.execute_reply.started":"2022-06-28T11:38:01.921481Z","shell.execute_reply":"2022-06-28T11:38:03.74561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_p, vl_p = train_test_split(P, shuffle=True, train_size= 0.8)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:03.748921Z","iopub.execute_input":"2022-06-28T11:38:03.749496Z","iopub.status.idle":"2022-06-28T11:38:03.754489Z","shell.execute_reply.started":"2022-06-28T11:38:03.749445Z","shell.execute_reply":"2022-06-28T11:38:03.753702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"er = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=1e-3,\n    patience=5,\n    verbose=1,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True,\n)\n\nmodel.fit_generator(IGenerator(keys=tr_p, \n                               a = A, \n                               tab = TAB), \n                    steps_per_epoch = 20,\n                    validation_data=IGenerator(keys=vl_p, \n                               a = A, \n                               tab = TAB),\n                    validation_steps = 20, \n                    callbacks = [er], \n                    epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:38:03.755682Z","iopub.execute_input":"2022-06-28T11:38:03.756551Z","iopub.status.idle":"2022-06-28T13:09:44.87608Z","shell.execute_reply.started":"2022-06-28T11:38:03.756521Z","shell.execute_reply":"2022-06-28T13:09:44.873803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:09:44.87762Z","iopub.execute_input":"2022-06-28T13:09:44.87877Z","iopub.status.idle":"2022-06-28T13:10:05.28695Z","shell.execute_reply.started":"2022-06-28T13:09:44.878741Z","shell.execute_reply":"2022-06-28T13:10:05.286038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(fvc_true, fvc_pred, sigma):\n    sigma_clip = np.maximum(sigma,70)\n    delta = np.abs(fvc_true - fvc_pred)\n    delta = np.minimum(delta,1000)\n    sqrt = np.sqrt(2)\n    metric = (delta/sigma_clip)*sqrt + np.log(sigma_clip*sqrt)\n    return np.mean(metric)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:10:05.288134Z","iopub.execute_input":"2022-06-28T13:10:05.288394Z","iopub.status.idle":"2022-06-28T13:10:05.295068Z","shell.execute_reply.started":"2022-06-28T13:10:05.288368Z","shell.execute_reply":"2022-06-28T13:10:05.294022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\nmetric = []\nfor q in tqdm(range(1, 10)):\n    m = []\n    for p in vl_p:\n        x, y = [], []\n        tab = [] \n        \n        if p in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n            continue\n            \n        img_set = os.listdir(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/')\n        img_set = np.random.choice(img_set, size=20)\n        for i in img_set:\n            x.append(get_img(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/{i}')) \n            y.append(get_img(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/{i}'))\n            tab.append(get_tab(train.loc[train.Patient == p, :])) \n        tab = np.array(tab) \n    \n        x = np.expand_dims(x, axis=-1)\n        y = np.expand_dims(y, axis=-1)\n        _a = model.predict([x, tab]) \n        a = np.quantile(_a, q / 10)\n        \n        percent_true = train.Percent.values[train.Patient == p]\n        fvc_true = train.FVC.values[train.Patient == p]\n        weeks_true = train.Weeks.values[train.Patient == p]\n        \n        fvc = a * (weeks_true - weeks_true[0]) + fvc_true[0]\n        percent = percent_true[0] - a * abs(weeks_true - weeks_true[0])\n        m.append(score(fvc_true, fvc, percent))\n    print(np.mean(m))\n    metric.append(np.mean(m))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:10:05.296403Z","iopub.execute_input":"2022-06-28T13:10:05.296692Z","iopub.status.idle":"2022-06-28T13:26:28.883521Z","shell.execute_reply.started":"2022-06-28T13:10:05.296667Z","shell.execute_reply":"2022-06-28T13:26:28.882407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q = (np.argmin(metric) + 1)/ 10\nq","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:26:28.8853Z","iopub.execute_input":"2022-06-28T13:26:28.885669Z","iopub.status.idle":"2022-06-28T13:26:28.893428Z","shell.execute_reply.started":"2022-06-28T13:26:28.885633Z","shell.execute_reply":"2022-06-28T13:26:28.892444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv') \nsub.head() ","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:26:28.895209Z","iopub.execute_input":"2022-06-28T13:26:28.8959Z","iopub.status.idle":"2022-06-28T13:26:28.934872Z","shell.execute_reply.started":"2022-06-28T13:26:28.895863Z","shell.execute_reply":"2022-06-28T13:26:28.934026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv') \ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:26:28.938073Z","iopub.execute_input":"2022-06-28T13:26:28.938841Z","iopub.status.idle":"2022-06-28T13:26:28.960433Z","shell.execute_reply.started":"2022-06-28T13:26:28.938811Z","shell.execute_reply":"2022-06-28T13:26:28.959505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"A_test, B_test, P_test,W, FVC= {}, {}, {},{},{} \nSTD, WEEK = {}, {} \nfor p in test.Patient.unique():\n    x,y = [],[]\n    tab = [] \n    img_set = os.listdir(f'../input/osic-pulmonary-fibrosis-progression/test/{p}/')\n    img_set = np.random.choice(img_set, size=20)\n    for i in img_set:\n        x.append(get_img(f'../input/osic-pulmonary-fibrosis-progression/test/{p}/{i}')) \n        tab.append(get_tab(test.loc[test.Patient == p, :])) \n    tab = np.array(tab) \n            \n    x = np.expand_dims(x, axis=-1) \n#     y = np.expand_dims(y, axis=-1) \n    _a = model.predict([x, tab]) \n    a = np.quantile(_a, q)\n    A_test[p] = a\n    B_test[p] = test.FVC.values[test.Patient == p] - a*test.Weeks.values[test.Patient == p]\n    P_test[p] = test.Percent.values[test.Patient == p] \n    WEEK[p] = test.Weeks.values[test.Patient == p]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:26:28.961903Z","iopub.execute_input":"2022-06-28T13:26:28.962434Z","iopub.status.idle":"2022-06-28T13:26:44.995402Z","shell.execute_reply.started":"2022-06-28T13:26:28.962397Z","shell.execute_reply":"2022-06-28T13:26:44.994647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in sub.Patient_Week.values:\n    p, w = k.split('_')\n    w = int(w) \n    \n    fvc = A_test[p] * w + B_test[p]\n    sub.loc[sub.Patient_Week == k, 'FVC'] = fvc\n    sub.loc[sub.Patient_Week == k, 'Confidence'] = (\n        P_test[p] - A_test[p] * abs(WEEK[p] - w) \n) \nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:26:44.996435Z","iopub.execute_input":"2022-06-28T13:26:44.996666Z","iopub.status.idle":"2022-06-28T13:26:45.621574Z","shell.execute_reply.started":"2022-06-28T13:26:44.996645Z","shell.execute_reply":"2022-06-28T13:26:45.620496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}