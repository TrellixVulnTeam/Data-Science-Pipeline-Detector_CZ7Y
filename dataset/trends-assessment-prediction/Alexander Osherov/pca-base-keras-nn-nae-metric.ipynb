{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport scipy.io\nimport h5py\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.express as px\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv3D, Dense, Dropout, Flatten, BatchNormalization, PReLU\nimport tensorflow.keras.backend as K\nfrom xgboost import XGBRegressor\nfrom sklearn.impute import KNNImputer\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport gc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/train_scores.csv\")\nreveal_ID_site2 = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/reveal_ID_site2.csv\")\nfnc = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/fnc.csv\")\nloading = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/loading.csv\")\nICN_numbers = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/ICN_numbers.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([loading, fnc.drop(['Id'], axis=1)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.DataFrame(train_scores.Id).merge(data, on='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id=[]\nfor i in range(0,len(sample_submission.Id),5):\n    test_id.append(float(sample_submission.Id[i].split(\"_\")[0]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame(test_id, columns=[\"Id\"]).merge(data, on='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1, X_pretest1, y_train1, y_pretest1 = train_test_split(train.drop(['Id'], axis=1), pd.DataFrame(train_scores).drop('Id', axis=1), test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute = KNNImputer(n_neighbors=20)\ny_train2 = impute.fit_transform(y_train1)\ny_pretest2 = impute.transform(y_pretest1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ntrain2 = scaler.fit_transform(X_train1)\npretest2 = scaler.transform(X_pretest1)\ntest2 = scaler.transform( test.drop(['Id'], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=445)# more than 0.95\ntrain3 = pca.fit_transform(train2)\npretest3 = pca.transform(pretest2)\ntest3 = pca.transform(test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weighted_NAE(yTrue,yPred):\n    weights = K.constant([.3, .175, .175, .175, .175], dtype=tf.float32)\n    \n\n    return K.sum(weights*K.sum(K.abs(yTrue-yPred))/K.sum(yPred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model = Sequential()\nModel.add(Dense(100, input_shape = (445,), activation ='elu'))\nModel.add(Dropout(0.2))\n\nModel.add(Dense(300, activation='elu'))\nModel.add(Dropout(0.4))\nModel.add(Dense(300, activation='elu'))\nModel.add(Dropout(0.4))\n\nModel.add(Dense(5, activation = 'elu'))\n\nModel.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=[ weighted_NAE])\nModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"filepath = \"best.hdf5\"\n\ncheckpoint = ModelCheckpoint(filepath,\n                            monitor='val_weighted_NAE',\n                            verbose=1,\n                            save_best_only=True, \n                            mode='min')\nModel.fit(train3, y_train2, validation_data=(pretest3, y_pretest2), epochs=15, callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model.load_weights(filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=pd.DataFrame()\npred[\"Id\"]=sample_submission.Id\npred[\"Predicted\"]=Model.predict(test3).flatten()\npred.to_csv('out2.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}