{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import h5py\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv3D, Dense, Dropout, Flatten, BatchNormalization, PReLU, Reshape , MaxPooling3D,MaxPool3D\nimport tensorflow.keras.backend as K\nfrom sklearn.impute import KNNImputer\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport gc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom itertools import combinations, product\nimport random\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/train_scores.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed = 42\n\nids=np.array(train.Id)\nX_train_id, X_pretest_id, Y_train, Y_pretest = train_test_split(ids, train.drop([\"Id\"], axis=1), test_size=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute = KNNImputer(n_neighbors=40)\nY_train_knn = impute.fit_transform(Y_train)\nY_pretest_knn = impute.transform(Y_pretest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weighted_NAE(yTrue,yPred):\n    weights = K.constant([.3, .175, .175, .175, .175], dtype=tf.float32)\n    return K.sum(weights*K.sum(K.abs(yTrue-yPred))/K.sum(yPred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=0.001\nactiv='relu'\n\nstrategy = tf.distribute.MirroredStrategy()\nwith strategy.scope():\n    Model = Sequential()\n    Model.add(Conv3D(100, (3,3,3), input_shape = (53, 52, 63, 53), activation =activ))\n    Model.add(Conv3D(100, (3,3,3), activation =activ))\n    Model.add(MaxPool3D((2,2,2)))\n\n    \n    Model.add(Conv3D(200, (3,3,3), activation =activ))\n    Model.add(Conv3D(200, (3,3,3), activation =activ))\n    Model.add(MaxPool3D((2,2,2)))\n\n    \n    Model.add(Conv3D(500, (2,2,2), activation =activ))\n    Model.add(MaxPool3D((2,2,2)))\n    Model.add(BatchNormalization())    \n    \n    Model.add(Flatten())\n    Model.add(Dense(5000, activation=activ))\n    Model.add(Dropout(0.1))\n\n    Model.add(Dense(2000, activation=activ))\n    Model.add(Dropout(0.1))\n\n    Model.add(Dense(500, activation=activ))\n    Model.add(Dropout(0.1))\n\n    Model.add(Dense(5, activation = activ))\n\n    Model.compile(loss='mse' , optimizer=tf.keras.optimizers.Adam(lr=lr), metrics=[weighted_NAE])\n    print(Model.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with h5py.File('foo3.hdf5','w') as myfile:\n    for i ,name in enumerate(X_train_id):\n        file=str(name) + \".mat\"\n        link = \"/kaggle/input/trends-assessment-prediction/fMRI_train/\" \n\n        myfile[str(i)] = h5py.ExternalLink(link+file, '/SM_feature')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss =[]\nloss=[]\nNAE=[]\nval_NAE=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=10\nepochs=10\n\n\nbatch = np.zeros((batch_size,53, 52, 63, 53))\nfor e in range(epochs):\n    with h5py.File('foo3.hdf5','r') as myfile:        \n\n        batch_n = random.sample(list(np.arange(len(X_train_id))), batch_size)\n\n        for c, i  in enumerate(batch_n):\n            batch[c] = myfile[str(i)]\n\n        hist = Model.fit(batch, Y_train_knn[batch_n], validation_split=0.1)\n        loss+=hist.history[\"loss\"]\n        val_loss+=hist.history[\"val_loss\"]\n        NAE+=hist.history[\"weighted_NAE\"]\n        val_NAE+=hist.history[\"val_weighted_NAE\"]\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.ylim(0,10)\nplt.plot(np.arange(len(val_NAE)),val_NAE, c='r')\nplt.plot(np.arange(len(NAE)),NAE, c='b')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}