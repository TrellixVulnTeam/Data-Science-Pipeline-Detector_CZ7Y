{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd # package for high-performance, easy-to-use data structures and data analysis\nimport numpy as np # fundamental package for scientific computing with Python\nimport matplotlib\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()\n#import cufflinks and offline mode\nimport cufflinks as cf\ncf.go_offline()\n\n# Venn diagram\nfrom matplotlib_venn import venn2\nimport re\nimport nltk\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\neng_stopwords = stopwords.words('english')\nimport gc\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nbp = '/kaggle/input/trends-assessment-prediction'\nprint(os.listdir(bp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Reading data...')\nloading_data = pd.read_csv(bp+'/loading.csv')\ntrain_data = pd.read_csv(bp+'/train_scores.csv')\nsample_submission = pd.read_csv(bp+'/sample_submission.csv')\nprint('Reading data completed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of loading_data', loading_data.shape)\nprint('Size of train_data', train_data.shape)\nprint('Size of sample_submission', sample_submission.shape)\nprint('test size:', len(sample_submission)/5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(loading_data.head())\ndisplay(loading_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_data.head())\ndisplay(train_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = list(train_data.columns)\ntargets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking missing data\ntotal = train_data.isnull().sum().sort_values(ascending = False)\npercent = (train_data.isnull().sum()/train_data.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = loading_data.isnull().sum().sort_values(ascending = False)\npercent = (loading_data.isnull().sum()/loading_data.isnull().count()*100).sort_values(ascending = False)\nmissing_test_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of input variables in loading_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets= sorted(loading_data.columns[1:])\nprint(targets)\n\nfig, axes = plt.subplots(6, 5, figsize=(18, 15))\naxes = axes.ravel()\nbins = np.linspace(-0.05, 0.05, 20)\n\nfor i, col in enumerate(targets):\n    ax = axes[i]\n    sns.distplot(loading_data[col], label=col, kde=False, bins=bins, ax=ax)\n\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of target variables in train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets= train_data.columns[1:]\nfig, axes = plt.subplots(1, 5, figsize=(18, 4))\naxes = axes.ravel()\nbins = np.linspace(0, 100, 20)\n\nfor i, col in enumerate(targets):\n    ax = axes[i]\n    sns.distplot(train_data[col], label=col, kde=False, bins=bins, ax=ax)\n\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation between input variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 6))\ncols = loading_data.columns[1:]\nsns.heatmap(loading_data[cols].corr(), ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 6))\ncols = train_data.columns[1:]\nsns.heatmap(train_data[cols].corr(), ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation between input and target variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = train_data.merge(loading_data)\nmerged.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import cdist\n\ndef calc_corr(df, x_cols, y_cols):\n    arr1 = df[x_cols].T.values\n    arr2 = df[y_cols].T.values\n    corr_df = pd.DataFrame(1 - cdist(arr2, arr1, metric='correlation'), index=y_cols, columns=x_cols)\n    return corr_df\n\ninput_cols = merged.columns[6:]\noutput_cols = merged.columns[1:6]\n\ncorr_df = calc_corr(merged, input_cols, output_cols)\nfig, ax = plt.subplots(figsize=(10, 2))\nsns.heatmap(corr_df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}