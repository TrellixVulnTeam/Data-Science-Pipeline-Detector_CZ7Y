{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if not filename.endswith('.mat'):\n            print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from IPython.display import display, HTML\ntrain_df = pd.read_csv('/kaggle/input/trends-assessment-prediction/train_scores.csv')\nlabels = train_df.columns.to_list()[1:]\nLoading = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/loading.csv\")\nprimary_features = Loading.columns.to_list()[1:]\nFNC= pd.read_csv(\"/kaggle/input/trends-assessment-prediction/fnc.csv\")\nsecondary_features = FNC.columns.to_list()[1:]\nraw_features = primary_features + secondary_features\ntrain_df = pd.merge(train_df,Loading,on='Id')\ntrain_df = pd.merge(train_df,FNC,on='Id')\nsubmission_df = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/sample_submission.csv\")\ntest_df = pd.DataFrame(submission_df.Id.apply(lambda x:int(x[:5]))).drop_duplicates(subset='Id').reset_index().drop('index',axis=1)\ntest_df = pd.merge(test_df,Loading,on='Id')\ntest_df = pd.merge(test_df,FNC,on='Id')\nsite2 = pd.read_csv('/kaggle/input/trends-assessment-prediction/reveal_ID_site2.csv').values[:,0]\nprint(\"Train:\",train_df.shape)\ndisplay(train_df.iloc[[1,-1]])\nprint(\"Test:\",test_df.shape)\ndisplay(test_df.iloc[[1,-1]])\nprint(\"labels:\",labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsite2 = pd.read_csv('/kaggle/input/trends-assessment-prediction/reveal_ID_site2.csv').values[:,0]\nMean1 = train_df.mean()\nMean2 = test_df.loc[test_df.Id.isin(site2)].mean()\nmean_shift = Mean1-Mean2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['site'] = 0\ntrain_df['site'] = 1\ntest_df.loc[test_df.Id.isin(site2),'site'] = 2\ntest0 = test_df[test_df.site==0]\ntest2 = test_df[test_df.site==2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\n\ndef Generate_Site2_samples(df):\n    new_df = copy.deepcopy(df)\n    for feature in raw_features:\n        new_df[feature] = df[feature] - mean_shift.loc[feature]\n    new_df['site'] = 2\n    return new_df\n\ndef Generate_Site1_samples(df):\n    new_df = copy.deepcopy(df)\n    for feature in raw_features:\n        new_df[feature] = df[feature] + mean_shift.loc[feature]\n    new_df['site'] = 1\n    return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\n\ntrain_generated = Generate_Site2_samples(train_df)\ntest_generated = Generate_Site1_samples(test2)\n\ndf = pd.concat([train_df,test2,train_generated,test_generated])\ndf = df.sample(df.shape[0]).reset_index()\ndf.site.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score,roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GroupKFold\ndef lgb_f1_score(y_hat, data):\n    y_true = data.get_label()\n    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n    return 'f1', f1_score(y_true, y_hat,average='macro'), True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gkf = GroupKFold(n_splits=5)\ntarget = (df.site==1).astype(int)\npred = np.zeros(df.shape[0])\nprob = np.zeros(df.shape[0])\n\ntest_probabilities = np.zeros(test_df.shape[0])\ntest_predictions = np.zeros(test_df.shape[0])\nX_test = test_df[raw_features]\n\nn_fold = 0\nfor train_index, val_index in gkf.split(df, df.site,df.index):\n    X_train, X_val = df.loc[train_index,raw_features], df.loc[val_index,raw_features]\n    y_train, y_val = target.loc[train_index], target.loc[val_index]\n#     break\n    X_train = lgb.Dataset(X_train, label=y_train)\n    X_val = lgb.Dataset(X_val, label=y_val)\n    print('training for fold',n_fold)\n    param = {'num_leaves': 50,\n             'min_data_in_leaf': 30, \n             'objective':'binary',\n             'max_depth': 5,\n             'learning_rate': 0.05,\n             \"min_child_samples\": 20,\n             \"boosting\": \"gbdt\",\n             \"feature_fraction\": 0.9,\n             \"bagging_freq\": 1,\n             \"bagging_fraction\": 0.9 ,\n             \"bagging_seed\": 56,\n             \"metric\": 'auc',\n             \"verbosity\": -1}\n    num_round = 2000\n    clf = lgb.train(param, X_train, num_round, valid_sets = [X_train, X_val], verbose_eval=50, feval=lgb_f1_score, early_stopping_rounds = 50)\n\n#     clf = SVC(decision_function_shape='ovo', class_weight=\"balanced\",probability=True)\n#     clf.fit(X_train, y_train )\n    \n    test_prob = clf.predict(test_df[raw_features])\n    test_pred = (test_prob>0.5).astype(int)\n    test_probabilities += test_prob/5\n    \n    print('fold distribution:',np.unique(test_pred,return_counts=True))\n    \n    prob[val_index] = clf.predict(df.loc[val_index,raw_features])\n    pred[val_index] = (prob[val_index]>0.5).astype(int)\n    \n    print('Partial f1: ',metrics.f1_score(y_val, pred[val_index],average='macro'))\n    #print('auc',metrics.roc_auc_score(y_val, pred[val_index]))\n    n_fold += 1\n    print()\ntest_predictions = (test_probabilities>0.5).astype(int)\nprint('net distribution',np.unique(test_predictions,return_counts=True))\nmetrics.f1_score(target, pred,average='macro') #,metrics.roc_auc_score(target, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(target,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importance(),raw_features)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 20))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).head(100))\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.f1_score(target[df.Id.isin(test2.Id)], pred[df.Id.isin(test2.Id)],average='macro') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.f1_score(target[~df.Id.isin(test2.Id)], pred[~df.Id.isin(test2.Id)],average='macro') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(target[df.Id.isin(test2.Id)], pred[df.Id.isin(test2.Id)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(target[~df.Id.isin(test2.Id)], pred[~df.Id.isin(test2.Id)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(target,pred,digits=5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['site_prob'] = test_probabilities\ntest_df[['Id','site_prob']].to_csv('test_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = ((test_df.site_prob//0.1)*0.1+0.05).value_counts().reset_index()\ndist.sort_values(by='index')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(((prob[df.Id.isin(test2.Id) & (df.site==2)]//0.1)*0.1+0.05),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['oof_pred'] = pred\ndf.groupby('Id').oof_pred.agg('mean').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_means = df.groupby('Id').oof_pred.agg('mean')\nids1 = id_means[id_means==0.5].index\nmetrics.f1_score(target[df.Id.isin(ids1)], pred[df.Id.isin(ids1)],average='macro') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(((prob[df.Id.isin(ids1) & (df.site==2)]//0.1)*0.1+0.05),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(((prob[df.Id.isin(ids1) & (df.site==1)]//0.1)*0.1+0.05),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_means = df.groupby('Id').oof_pred.agg('mean')\nids1 = id_means[id_means!=0.5].index\nmetrics.f1_score(target[df.Id.isin(ids1)], pred[df.Id.isin(ids1)],average='macro') \nmetrics.f1_score(target[df.Id.isin(ids1)], pred[df.Id.isin(ids1)],average='macro') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(((prob[df.Id.isin(ids1) & (df.site==2)]//0.1)*0.1+0.05),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(((prob[df.Id.isin(ids1) & (df.site==1)]//0.1)*0.1+0.05),return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}