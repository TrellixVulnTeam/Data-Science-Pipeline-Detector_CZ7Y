{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.0.13.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.6/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.6\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport cudf\nimport cupy as cp\nfrom cuml.neighbors import KNeighborsRegressor\nfrom cuml import SVR\nfrom cuml.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom cuml.metrics import mean_absolute_error, mean_squared_error\nfrom cuml.linear_model import MBSGDRegressor as cumlMBSGDRegressor\nfrom sklearn.linear_model import LinearRegression,LassoLarsCV,ElasticNetCV\nfrom cuml.solvers import SGD as cumlSGD\nfrom cuml.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nimport warnings\n\nimport xgboost as xgb\n#import lightgbm as lgb\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc_df = cudf.read_csv(\"../input/trends-assessment-prediction/fnc.csv\")\nloading_df = cudf.read_csv(\"../input/trends-assessment-prediction/loading.csv\")\nlabels_df = cudf.read_csv(\"../input/trends-assessment-prediction/train_scores.csv\")\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n\ntest_df_load_region=test_df.copy() \ndf_train=df.copy()\ndf_scaled=df.copy()\ntest_df_scaled=test_df.copy()\ntest_df_load_fnc_loadfnc_region=test_df.copy()\ntest_df_load_fnc_loadfnc=test_df.copy()\n\n\ntest_df_scaled_rf=test_df.copy()\ntest_df_load_fnc_loadfnc_region_rf=test_df.copy()\ntest_df_load_fnc_loadfnc_rf=test_df.copy()\n\ntest_df_ensemble=test_df.copy()\n\n# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\nFNC_SCALE = 1/500\n\ndf_scaled[fnc_features] *= FNC_SCALE\ntest_df_scaled[fnc_features] *= FNC_SCALE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sm_data=cudf.read_csv('../input/trends-region400-pca100/train_region_pca100.csv')\ntest_sm_data=cudf.read_csv('../input/trends-region400-pca100/test_region_pca100.csv',names=train_sm_data.columns,header=0)\nregion_df = train_sm_data.merge(labels_df, on=\"Id\", how=\"left\")\nregion_test_df=test_sm_data.copy()\nregion_features=list(region_test_df.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blend_weights = {\"age\":          [0.65, 0.35],\n                 \"domain1_var1\": [0.55, 0.45],\n                 \"domain1_var2\": [0.5,  0.5],\n                 \"domain2_var1\": [0.45, 0.55],\n                 \"domain2_var2\": [0.4,  0.6]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nwarnings.filterwarnings(\"ignore\", message=\"Expected column\")\n\ntargets=['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']\n\nNUM_FOLDS =7\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=10)\n\nfeatures = loading_features + fnc_features\n\n\n#rf\noveral_score_rf_region = 0\noveral_score_rf_fnc = 0\noveral_score_rf_load= 0\noveral_score_rf_load_fnc =0\noveral_score_rf_load_region =0\noveral_score_rf_load_fnc_region= 0\n\noveral_score_rf_loadfnc= 0\noveral_score_rf_load_fnc_loadfnc =0\noveral_score_rf_loadfnc_region=0\noveral_score_rf_load_fnc_loadfnc_region =0\n#svr\noveral_score_svr_region = 0\noveral_score_svr_fnc = 0\noveral_score_svr_load= 0\noveral_score_svr_load_fnc =0\noveral_score_svr_load_region =0\noveral_score_svr_load_fnc_region= 0\n\noveral_score_svr_loadfnc= 0\noveral_score_svr_load_fnc_loadfnc =0\noveral_score_svr_loadfnc_region=0\noveral_score_svr_load_fnc_loadfnc_region =0\n\n\n\noveral_score_ensemble=0\n\nfor target, c,b,w,a,r in [(\"age\", 64,20, 0.3,0.00005,0.5), (\"domain1_var1\",12,10, 0.175,0.00001,0.2), (\"domain1_var2\",16, 10, 0.175,0.15,0.5), (\"domain2_var1\",18,10, 0.175,0.0001,0.9), (\"domain2_var2\",10,10,0.175,0.0001,0.1)]:     \n    \n    \n    #rf\n    y_val_rf_region = np.zeros(region_df.shape[0])\n    y_val_rf_load = np.zeros(df.shape[0])\n    y_val_rf_fnc = np.zeros(df.shape[0])\n    y_val_rf_load_fnc= np.zeros(df.shape[0])\n    y_val_rf_load_region= np.zeros(df.shape[0])\n    y_val_rf_load_fnc_region= np.zeros(df.shape[0])\n     \n    y_val_rf_loadfnc = np.zeros(df.shape[0])\n    y_val_rf_load_fnc_loadfnc= np.zeros(df.shape[0])\n    y_val_rf_loadfnc_region= np.zeros(df.shape[0])\n    y_val_rf_load_fnc_loadfnc_region= np.zeros(df.shape[0])\n\n\n    y_test_rf_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_rf_load_fnc = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_rf_load_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_rf_load_fnc_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    \n    y_test_rf_region_loadfnc = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_rf_load_fnc_loadfnc = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_rf_load_fnc_loadfnc_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    #svr\n    y_val_svr_region = np.zeros(region_df.shape[0])\n    y_val_svr_load = np.zeros(df.shape[0])\n    y_val_svr_fnc = np.zeros(df.shape[0])\n    y_val_svr_load_fnc= np.zeros(df.shape[0])\n    y_val_svr_load_region= np.zeros(df.shape[0])\n    y_val_svr_load_fnc_region= np.zeros(df.shape[0])\n     \n    y_val_svr_loadfnc = np.zeros(df.shape[0])\n    y_val_svr_load_fnc_loadfnc= np.zeros(df.shape[0])\n    y_val_svr_loadfnc_region= np.zeros(df.shape[0])\n    y_val_svr_load_fnc_loadfnc_region= np.zeros(df.shape[0])\n\n\n    y_test_svr_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_svr_load_fnc = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_svr_load_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_svr_load_fnc_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    \n    y_test_svr_region_loadfnc = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_svr_load_fnc_loadfnc = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    y_test_svr_load_fnc_loadfnc_region = np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    \n   \n   \n    #ensemble\n    y_val_ensemble=np.zeros(df.shape[0])\n    y_test_ensemble= np.zeros((region_test_df.shape[0], NUM_FOLDS))\n    \n    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n        region_train_df, region_val_df = region_df.iloc[train_ind], region_df.iloc[val_ind]\n        region_train_df = region_train_df[region_train_df[target].notnull()]\n        \n        train_df, val_df =df.iloc[train_ind],df.iloc[val_ind]\n        train_df =train_df[train_df[target].notnull()]\n        \n        train_df_scaled, val_df_scaled = df_scaled.iloc[train_ind], df_scaled.iloc[val_ind]\n        train_df_scaled = train_df_scaled[train_df_scaled[target].notnull()]\n        \n        #rf \n        #--------------------------------------------------------------------------------------\n        rf_1 =  BaggingRegressor(Ridge(alpha = 0.0001), n_estimators=100, random_state=42, max_samples=0.3, max_features=0.3)\n        rf_1.fit(train_df.to_pandas()[fnc_features].values, train_df.to_pandas()[target].values)\n        rf_2 = BaggingRegressor(Ridge(alpha = 0.0001), n_estimators=100, random_state=2, max_samples=0.3, max_features=0.6)\n        rf_2.fit(train_df.to_pandas()[loading_features].values, train_df.to_pandas()[target].values)\n        rf_3= BaggingRegressor(Ridge(alpha = 0.0001), n_estimators=100, random_state=4, max_samples=0.3, max_features=0.3)\n        rf_3.fit(region_train_df.to_pandas()[region_features].values, region_train_df.to_pandas()[target].values)\n        rf_4= BaggingRegressor(Ridge(alpha = 0.0001),n_estimators=100, random_state=52, max_samples=0.3, max_features=0.3)\n        rf_4.fit(train_df_scaled.to_pandas()[features].values, train_df_scaled.to_pandas()[target].values)\n        \n               \n        n=val_ind\n        y_val_rf_fnc[n]= cudf.from_pandas(pd.Series(rf_1.predict(val_df.to_pandas()[fnc_features])))\n        y_val_rf_load[n]= cudf.from_pandas(pd.Series(rf_2.predict(val_df.to_pandas()[loading_features])))\n        y_val_rf_region[n]= cudf.from_pandas(pd.Series(rf_3.predict(region_val_df.to_pandas()[region_features])))\n        y_val_rf_load_fnc[n]= (y_val_rf_load[n]+y_val_rf_fnc[n])/2\n        y_val_rf_load_region[n]= (y_val_rf_load[n]+y_val_rf_region[n])/2\n        y_val_rf_load_fnc_region[n]=(y_val_rf_load[n]+y_val_rf_fnc[n]+y_val_rf_region[n])/3\n        \n        \n        \n        y_val_rf_loadfnc[n] =  cudf.from_pandas(pd.Series(rf_4.predict(val_df_scaled.to_pandas()[features])))\n        y_val_rf_load_fnc_loadfnc[n]= (y_val_rf_fnc[n]+y_val_rf_load[n]+y_val_rf_loadfnc[n])/3\n        y_val_rf_loadfnc_region[n]=  y_val_rf_loadfnc[n]*0.7+y_val_rf_region[n]*0.3\n        y_val_rf_load_fnc_loadfnc_region[n]= (y_val_rf_load[n]+y_val_rf_fnc[n]+y_val_rf_region[n]+y_val_rf_loadfnc[n])/4\n        \n        \n        test_pred_1 =  cudf.from_pandas(pd.Series(rf_1.predict(test_df.to_pandas()[fnc_features])))\n        test_pred_2 =  cudf.from_pandas(pd.Series(rf_2.predict(test_df.to_pandas()[loading_features])))\n        test_pred_3 =  cudf.from_pandas(pd.Series(rf_3.predict(region_test_df.to_pandas()[region_features])))\n        test_pred_4 =  cudf.from_pandas(pd.Series(rf_4.predict(test_df_scaled.to_pandas()[features])))\n        \n        test_pred_rf_load_fnc = (test_pred_1+test_pred_2)/2\n        test_pred_rf_load_fnc = cp.asnumpy(test_pred_rf_load_fnc.values.flatten())\n        test_pred_rf_load_region = (test_pred_1+test_pred_3)/2\n        test_pred_rf_load_region = cp.asnumpy(test_pred_rf_load_region.values.flatten())\n        test_pred_rf_load_fnc_region = (test_pred_1+test_pred_2+test_pred_3)/3\n        test_pred_rf_load_fnc_region = cp.asnumpy(test_pred_rf_load_fnc_region.values.flatten()) \n        test_pred_rf_region = cp.asnumpy(test_pred_3.values.flatten())\n        \n        test_pred_rf_region_loadfnc=test_pred_3*0.3+test_pred_4*0.7\n        test_pred_rf_region_loadfnc=cp.asnumpy(test_pred_rf_region_loadfnc.values.flatten())\n        test_pred_rf_load_fnc_loadfnc=(test_pred_1+test_pred_2+test_pred_4)/3\n        test_pred_rf_load_fnc_loadfnc=cp.asnumpy(test_pred_rf_load_fnc_loadfnc.values.flatten())\n        test_pred_rf_load_fnc_loadfnc_region=(test_pred_1+test_pred_2+test_pred_3+test_pred_4)/4\n        test_pred_rf_load_fnc_loadfnc_region=cp.asnumpy(test_pred_rf_load_fnc_loadfnc_region.values.flatten())\n\n        y_test_rf_load_fnc[:, f] = test_pred_rf_load_fnc\n        y_test_rf_load_region[:, f] = test_pred_rf_load_region\n        y_test_rf_load_fnc_region[:, f] = test_pred_rf_load_fnc_region\n        y_test_rf_region[:, f] = test_pred_rf_region\n        \n        y_test_rf_region_loadfnc[:, f]  =test_pred_rf_region_loadfnc\n        y_test_rf_load_fnc_loadfnc[:, f]  = test_pred_rf_load_fnc_loadfnc\n        y_test_rf_load_fnc_loadfnc_region[:, f] =test_pred_rf_load_fnc_loadfnc_region\n        \n\n        #svr \n        #--------------------------------------------------------------------------------------\n        svr_1 = SVR(C=c, cache_size=3000.0)\n        svr_1.fit(train_df[fnc_features], train_df[target])\n        svr_2 =SVR(C=c, cache_size=1000.0)\n        svr_2.fit(train_df[loading_features], train_df[target])\n        svr_3= SVR(C=b, cache_size=5000.0)\n        svr_3.fit(region_train_df[region_features], region_train_df[target])\n        svr_4= SVR(C=c, cache_size=4000.0)\n        svr_4.fit(train_df_scaled[features], train_df_scaled[target])\n        \n        \n        \n        n=val_ind\n        y_val_svr_fnc[n]=svr_1.predict(val_df[fnc_features])\n        y_val_svr_load[n]=svr_2.predict(val_df[loading_features])\n        y_val_svr_region[n]=svr_3.predict(region_val_df[region_features])\n        y_val_svr_load_fnc[n]= (y_val_svr_load[n]+y_val_svr_fnc[n])/2\n        y_val_svr_load_region[n]= (y_val_svr_load[n]+y_val_svr_region[n])/2\n        y_val_svr_load_fnc_region[n]=(y_val_svr_load[n]+y_val_svr_fnc[n]+y_val_svr_region[n])/3\n        \n        y_val_svr_loadfnc[n] = svr_4.predict(val_df_scaled[features])\n        y_val_svr_load_fnc_loadfnc[n]= (y_val_svr_fnc[n]+y_val_svr_load[n]+y_val_svr_loadfnc[n])/3\n        y_val_svr_loadfnc_region[n]=  y_val_svr_loadfnc[n]*0.7+y_val_svr_region[n]*0.3\n        y_val_svr_load_fnc_loadfnc_region[n]= (y_val_svr_load[n]+y_val_svr_fnc[n]+y_val_svr_region[n]+y_val_svr_loadfnc[n])/4\n\n        \n        test_pred_1 = svr_1.predict(test_df[fnc_features])\n        test_pred_2 = svr_2.predict(test_df[loading_features])\n        test_pred_3 = svr_3.predict(region_test_df[region_features])\n        test_pred_4 = svr_4.predict(test_df_scaled[features])\n        \n        test_pred_svr_load_fnc = (test_pred_1+test_pred_2)/2\n        test_pred_svr_load_fnc = cp.asnumpy(test_pred_svr_load_fnc.values.flatten())\n        test_pred_svr_load_region = (test_pred_1+test_pred_3)/2\n        test_pred_svr_load_region = cp.asnumpy(test_pred_svr_load_region.values.flatten())\n        test_pred_svr_load_fnc_region = (test_pred_1+test_pred_2+test_pred_3)/3\n        test_pred_svr_load_fnc_region = cp.asnumpy(test_pred_svr_load_fnc_region.values.flatten()) \n        test_pred_svr_region = cp.asnumpy(test_pred_3.values.flatten())\n        \n        test_pred_svr_region_loadfnc=test_pred_3*0.3+test_pred_4*0.7\n        test_pred_svr_region_loadfnc=cp.asnumpy(test_pred_svr_region_loadfnc.values.flatten())\n        test_pred_svr_load_fnc_loadfnc=(test_pred_1+test_pred_2+test_pred_4)/3\n        test_pred_svr_load_fnc_loadfnc=cp.asnumpy(test_pred_svr_load_fnc_loadfnc.values.flatten())\n        test_pred_svr_load_fnc_loadfnc_region=(test_pred_1+test_pred_2+test_pred_3+test_pred_4)/4\n        test_pred_svr_load_fnc_loadfnc_region=cp.asnumpy(test_pred_svr_load_fnc_loadfnc_region.values.flatten())\n\n        y_test_svr_load_fnc[:, f] = test_pred_svr_load_fnc\n        y_test_svr_load_region[:, f] = test_pred_svr_load_region\n        y_test_svr_load_fnc_region[:, f] = test_pred_svr_load_fnc_region\n        y_test_svr_region[:, f] = test_pred_svr_region\n        \n        y_test_svr_region_loadfnc[:, f]  =test_pred_svr_region_loadfnc\n        y_test_svr_load_fnc_loadfnc[:, f]  = test_pred_svr_load_fnc_loadfnc\n        y_test_svr_load_fnc_loadfnc_region[:, f] =test_pred_svr_load_fnc_loadfnc_region\n               \n\n        #ensemble\n        #------------------------------------------------\n        if target is \"age\":\n            y_val_ensemble[n] = blend_weights[target][0]*y_val_svr_loadfnc[n] \\\n                              + blend_weights[target][1]*y_val_rf_loadfnc[n]\n            y_test_ensemble[:,f]= blend_weights[target][0]*cp.asnumpy(svr_4.predict(test_df_scaled[features]).values.flatten()) \\\n                                + blend_weights[target][1]*cp.asnumpy(cudf.from_pandas(pd.Series(rf_4.predict(test_df_scaled.to_pandas()[features]))))\n            print('ensemble_test')\n        elif target is \"domain1_var1\":\n            y_val_ensemble[n] = blend_weights[target][0]*y_val_svr_load_fnc[n] \\\n                              + blend_weights[target][1]*y_val_rf_loadfnc[n]\n            y_test_ensemble[:,f]= blend_weights[target][0]*test_pred_svr_load_fnc \\\n                                + blend_weights[target][1]*cp.asnumpy(cudf.from_pandas(pd.Series(rf_4.predict(test_df_scaled.to_pandas()[features]))))\n        elif target is 'domain1_var2':\n            y_val_ensemble[n] = blend_weights[target][0]*y_val_svr_load_fnc[n] \\\n                              + blend_weights[target][1]*y_val_rf_loadfnc[n]\n            y_test_ensemble[:,f]= blend_weights[target][0]*test_pred_svr_load_fnc \\\n                                + blend_weights[target][1]*cp.asnumpy(cudf.from_pandas(pd.Series(rf_4.predict(test_df_scaled.to_pandas()[features]))))\n        elif target is 'domain2_var1':\n            y_val_ensemble[n] = blend_weights[target][0]*y_val_svr_load_fnc[n] \\\n                              + blend_weights[target][1]*y_val_rf_loadfnc[n]\n            y_test_ensemble[:,f]= blend_weights[target][0]*test_pred_svr_load_fnc \\\n                                + blend_weights[target][1]*cp.asnumpy(cudf.from_pandas(pd.Series(rf_4.predict(test_df_scaled.to_pandas()[features]))))\n        elif target is 'domain2_var2':\n            y_val_ensemble[n] = blend_weights[target][0]*y_val_svr_load_fnc[n] \\\n                              + blend_weights[target][1]*y_val_rf_loadfnc[n]\n            y_test_ensemble[:,f]= blend_weights[target][0]*test_pred_svr_load_fnc \\\n                                + blend_weights[target][1]*cp.asnumpy(cudf.from_pandas(pd.Series(rf_4.predict(test_df_scaled.to_pandas()[features]))))\n    #rf\n    df[\"pred_rf_load_{}\".format(target)] = y_val_rf_load\n    df[\"pred_rf_fnc_{}\".format(target)] = y_val_rf_fnc\n    region_df[\"pred_rf_region_{}\".format(target)] = y_val_rf_region  \n    df[\"pred_rf_load_fnc_{}\".format(target)] = y_val_rf_load_fnc\n    df[\"pred_rf_load_region_{}\".format(target)] = y_val_rf_load_region\n    df[\"pred_rf_load_fnc_region_{}\".format(target)] = y_val_rf_load_fnc_region\n        \n    df[\"pred_rf_loadfnc_{}\".format(target)] = y_val_rf_loadfnc\n    df[\"pred_rf_loadfnc_region_{}\".format(target)] = y_val_rf_loadfnc_region\n    df[\"pred_rf_load_fnc_loadfnc_{}\".format(target)] = y_val_rf_load_fnc_loadfnc\n    df[\"pred_rf_load_fnc_loadfnc_region_{}\".format(target)] = y_val_rf_load_fnc_loadfnc_region\n        \n    region_test_df[target] = y_test_rf_region.mean(axis=1)\n    test_df_load_region[target]=y_test_rf_load_region.mean(axis=1)\n    test_df[target] = y_test_rf_load_fnc_region.mean(axis=1)\n    test_df_scaled[target]=y_test_rf_region_loadfnc.mean(axis=1)\n    test_df_load_fnc_loadfnc[target]=y_test_rf_load_fnc_loadfnc.mean(axis=1)\n    test_df_load_fnc_loadfnc_region[target]=y_test_rf_load_fnc_loadfnc_region.mean(axis=1)\n    \n    \n    score_rf_load= metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_load_{}\".format(target)].values)\n    score_rf_fnc= metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_fnc_{}\".format(target)].values)\n    score_rf_region = metric(region_df[region_df[target].notnull()][target].values, region_df[region_df[target].notnull()][\"pred_rf_region_{}\".format(target)].values)\n    score_rf_load_fnc = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_load_fnc_{}\".format(target)].values)      \n    score_rf_load_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_load_region_{}\".format(target)].values)   \n    score_rf_load_fnc_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_load_fnc_region_{}\".format(target)].values)   \n    \n    score_rf_loadfnc = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_loadfnc_{}\".format(target)].values)      \n    score_rf_loadfnc_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_loadfnc_region_{}\".format(target)].values)   \n    score_rf_load_fnc_loadfnc = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_load_fnc_loadfnc_{}\".format(target)].values)   \n    score_rf_load_fnc_loadfnc_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_rf_load_fnc_loadfnc_region_{}\".format(target)].values)   \n\n   \n    overal_score_rf_load += w*score_rf_load\n    overal_score_rf_fnc += w*score_rf_fnc\n    overal_score_rf_region += w*score_rf_region\n    overal_score_rf_load_fnc += w*score_rf_load_fnc\n    overal_score_rf_load_region += w*score_rf_load_region\n    overal_score_rf_load_fnc_region += w*score_rf_load_fnc_region\n    \n    overal_score_rf_loadfnc += w*score_rf_loadfnc\n    overal_score_rf_load_fnc_loadfnc += w*score_rf_load_fnc_loadfnc\n    overal_score_rf_loadfnc_region += w*score_rf_loadfnc_region\n    overal_score_rf_load_fnc_loadfnc_region  += w*score_rf_load_fnc_loadfnc_region\n\n\n    print(target)\n    print(\"--\"*20)\n    print('rf: Load                   |',target, np.round(score_rf_load, 8))\n    print('rf: FNC                    |',target, np.round(score_rf_fnc, 8))\n    print('rf: Region                 |',target, np.round(score_rf_region, 8))\n    print('rf: Loadfnc                |',target, np.round(score_rf_loadfnc, 8))\n    print('rf: Load+FNC               |',target, np.round(score_rf_load_fnc, 8))\n    print('rf: Load+Region            |',target, np.round(score_rf_load_region, 8))\n    print('rf: Load+FNC+Region        |',target, np.round(score_rf_load_fnc_region, 8))\n    print('rf: Load+FNC+Loadfnc       |',target, np.round(score_rf_load_fnc_loadfnc, 8))\n    print('rf: Loadfnc+Region         |',target, np.round(score_rf_loadfnc_region, 8))\n    print('rf: Load+FNC+Loadfnc+Region|',target, np.round(score_rf_load_fnc_loadfnc_region, 8))\n    print(\"--\"*30)\n \n    #svr\n    df[\"pred_svr_load_{}\".format(target)] = y_val_svr_load\n    df[\"pred_svr_fnc_{}\".format(target)] = y_val_svr_fnc\n    region_df[\"pred_svr_region_{}\".format(target)] = y_val_svr_region  \n    df[\"pred_svr_load_fnc_{}\".format(target)] = y_val_svr_load_fnc\n    df[\"pred_svr_load_region_{}\".format(target)] = y_val_svr_load_region\n    df[\"pred_svr_load_fnc_region_{}\".format(target)] = y_val_svr_load_fnc_region\n        \n    df[\"pred_svr_loadfnc_{}\".format(target)] = y_val_svr_loadfnc\n    df[\"pred_svr_loadfnc_region_{}\".format(target)] = y_val_svr_loadfnc_region\n    df[\"pred_svr_load_fnc_loadfnc_{}\".format(target)] = y_val_svr_load_fnc_loadfnc\n    df[\"pred_svr_load_fnc_loadfnc_region_{}\".format(target)] = y_val_svr_load_fnc_loadfnc_region\n    \n    \n    region_test_df[target] = y_test_svr_region.mean(axis=1)\n    test_df_load_region[target]=y_test_svr_load_region.mean(axis=1)\n    test_df[target] = y_test_svr_load_fnc_region.mean(axis=1)\n    test_df_scaled[target]=y_test_svr_region_loadfnc.mean(axis=1)\n    test_df_load_fnc_loadfnc[target]=y_test_svr_load_fnc_loadfnc.mean(axis=1)\n    test_df_load_fnc_loadfnc_region[target]=y_test_svr_load_fnc_loadfnc_region.mean(axis=1)\n    \n    \n    \n    score_svr_load= metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_load_{}\".format(target)].values)\n    score_svr_fnc= metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_fnc_{}\".format(target)].values)\n    score_svr_region = metric(region_df[region_df[target].notnull()][target].values, region_df[region_df[target].notnull()][\"pred_svr_region_{}\".format(target)].values)\n    score_svr_load_fnc = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_load_fnc_{}\".format(target)].values)      \n    score_svr_load_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_load_region_{}\".format(target)].values)   \n    score_svr_load_fnc_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_load_fnc_region_{}\".format(target)].values)   \n    \n    score_svr_loadfnc = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_loadfnc_{}\".format(target)].values)      \n    score_svr_loadfnc_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_loadfnc_region_{}\".format(target)].values)   \n    score_svr_load_fnc_loadfnc = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_load_fnc_loadfnc_{}\".format(target)].values)   \n    score_svr_load_fnc_loadfnc_region = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_svr_load_fnc_loadfnc_region_{}\".format(target)].values)   \n\n      \n    overal_score_svr_load += w*score_svr_load\n    overal_score_svr_fnc += w*score_svr_fnc\n    overal_score_svr_region += w*score_svr_region\n    overal_score_svr_load_fnc += w*score_svr_load_fnc\n    overal_score_svr_load_region += w*score_svr_load_region\n    overal_score_svr_load_fnc_region += w*score_svr_load_fnc_region\n    \n    overal_score_svr_loadfnc += w*score_svr_loadfnc\n    overal_score_svr_load_fnc_loadfnc += w*score_svr_load_fnc_loadfnc\n    overal_score_svr_loadfnc_region += w*score_svr_loadfnc_region\n    overal_score_svr_load_fnc_loadfnc_region  += w*score_svr_load_fnc_loadfnc_region\n\n    print(target)\n    print(\"--\"*20)\n    print('SVR: Load                   |',target, np.round(score_svr_load, 8))\n    print('SVR: FNC                    |',target, np.round(score_svr_fnc, 8))\n    print('SVR: Region                 |',target, np.round(score_svr_region, 8))\n    print('SVR: Loadfnc                |',target, np.round(score_svr_loadfnc, 8))\n    print('SVR: Load+FNC               |',target, np.round(score_svr_load_fnc, 8))\n    print('SVR: Load+Region            |',target, np.round(score_svr_load_region, 8))\n    print('SVR: Load+FNC+Region        |',target, np.round(score_svr_load_fnc_region, 8))\n    print('SVR: Load+FNC+Loadfnc       |',target, np.round(score_svr_load_fnc_loadfnc, 8))\n    print('SVR: Loadfnc+Region         |',target, np.round(score_svr_loadfnc_region, 8))\n    print('SVR: Load+FNC+Loadfnc+Region|',target, np.round(score_svr_load_fnc_loadfnc_region, 8))\n    print(\"--\"*30)\n  \n    print(\"--\"*30)\n    \n    df[\"pred_ensemble_{}\".format(target)] = y_val_ensemble\n    test_df_ensemble[target]=y_test_ensemble.mean(axis=1)\n    score_ensemble= metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_ensemble_{}\".format(target)].values)\n    overal_score_ensemble += w*score_ensemble\n    print('Ensemble                    |',target, np.round(score_ensemble, 8))\n    \nprint(\"Overal score of rf: Load                    |\", np.round(overal_score_rf_load, 4))\nprint(\"Overal score of rf: FNC                     |\", np.round(overal_score_rf_fnc, 4))\nprint(\"Overal score of rf: Region                  |\", np.round(overal_score_rf_region, 4))\nprint(\"Overal score of rf: Loadfnc                 |\", np.round(overal_score_rf_loadfnc, 4))\nprint(\"Overal score of rf: Load+FNC                |\", np.round(overal_score_rf_load_fnc, 4))\nprint(\"Overal score of rf: Load+Region             |\", np.round(overal_score_rf_load_region, 4))\nprint(\"Overal score of rf: Load+FNC+Region         |\", np.round(overal_score_rf_load_fnc_region, 4))\nprint(\"Overal score of rf: Load+FNC+Loadfnc        |\", np.round(overal_score_rf_load_fnc_loadfnc, 4))\nprint(\"Overal score of rf: Loadfnc+Region          |\", np.round(overal_score_rf_loadfnc_region, 4))\nprint(\"Overal score of rf: Load+FNC+Loadfnc+Region |\", np.round(overal_score_rf_load_fnc_loadfnc_region, 4))\nprint(\"Overal score of SVR: Load                   |\", np.round(overal_score_svr_load, 4))\nprint(\"Overal score of SVR: FNC                    |\", np.round(overal_score_svr_fnc, 4))\nprint(\"Overal score of SVR: Region                 |\", np.round(overal_score_svr_region, 4))\nprint(\"Overal score of SVR: Loadfnc                |\", np.round(overal_score_svr_loadfnc, 4))\nprint(\"Overal score of SVR: Load+FNC               |\", np.round(overal_score_svr_load_fnc, 4))\nprint(\"Overal score of SVR: Load+Region            |\", np.round(overal_score_svr_load_region, 4))\nprint(\"Overal score of SVR: Load+FNC+Region        |\", np.round(overal_score_svr_load_fnc_region, 4))\nprint(\"Overal score of SVR: Load+FNC+Loadfnc       |\", np.round(overal_score_svr_load_fnc_loadfnc, 4))\nprint(\"Overal score of SVR: Loadfnc+Region         |\", np.round(overal_score_svr_loadfnc_region, 4))\nprint(\"Overal score of SVR: Load+FNC+Loadfnc+Region|\", np.round(overal_score_svr_load_fnc_loadfnc_region, 4))\nprint(\"--\"*30)\nprint(\"--\"*30)\nprint(\"Overal score of Ensemble                    |\", np.round(overal_score_ensemble, 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = cudf.melt(test_df_ensemble[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.to_csv(\"submission_rapids_ensemble_rf_svr.csv\", index=False)\nsub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = cudf.melt(region_test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.to_csv(\"submission_rapids_region400_svr.csv\", index=False)\nsub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = cudf.melt(test_df_load_region[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.to_csv(\"submission_rapids_load_region400_svr.csv\", index=False)\nsub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = cudf.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.to_csv(\"submission_rapids_load_fnc_region400_svr.csv\", index=False)\nsub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = cudf.melt(test_df_load_fnc_loadfnc_region_rf[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.to_csv(\"submission_rapids_region400_baggingela.csv\", index=False)\nsub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Log\nV11.SVR+KNN+Elasticnet: 0.1599","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_region1= pd.read_csv(\"../input/region-submission/submission_rapids_region400_knn_elasticnet_svr.csv\")\ndf_region2= pd.read_csv(\"../input/region-submission/submission_rapids_region400_knn_elasticnet_svr (1).csv\")\ndf_region3= pd.read_csv(\"../input/region-submission/submission_rapids_load_fnc_region400_knn_svr.csv\")\ndf_region4= pd.read_csv(\"../input/nnnnnn/submission_rapids_load_fnc_region400_svr.csv\")\ndf_region1['Predicted']=(df_region1['Predicted']*0.5+df_region2['Predicted']*0.5)*0.6+df_region3['Predicted']*0.2+df_region4['Predicted']*0.2\ndf_region1.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ela1 = pd.read_csv('../input/elasticnetcv2-submission/400region_load_FNC_ElasticNetCV.csv')\ndf_ela2 = pd.read_csv(\"../input/bayesoptela1/bayes_opt_loadfnc_skfold10_pure_elasticnetcv.csv\")\ndf_ela3 = pd.read_csv(\"../input/full-skf10-elasticnet-0158/loadfnc_full_skfold10_elasticnetcv.csv\")\ndf_ela4 = pd.read_csv(\"../input/full-skf10-elasticnet-0158/loadfnc_skfold20_pure_elasticnetcv_py_val0.1582.csv\")\ndf_ela5 = pd.read_csv(\"../input/full-skf10-elasticnet-0158/Nodropoutliers_loadfnc_skfold20(Noshuffle)_pure_elasticnetcv_fncscale.csv\")\ndf_ela6 = pd.read_csv(\"../input/dsdwe3/loadfnc_skfold15_elasticnetcv_val0.1579.csv\")\ndf_ela1['Predicted']=(df_ela1['Predicted']*1+df_ela2['Predicted']+df_ela3['Predicted']+df_ela4['Predicted']+df_ela5['Predicted']+df_ela6['Predicted'])/6\ndf_ela1.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_svr1=pd.read_csv(\"../input/dsdwe3/submission_rapids_ensemble.csv\")\ndf_svr2=pd.read_csv(\"../input/rapid-svr/submission_rapids_ensemble_SVR_val0.1581.csv\")\ndf_svr3=pd.read_csv(\"../input/rapid-svr/submission_rapids_ensemble_SVR_KNN.csv\")\ndf_svr4=pd.read_csv(\"../input/elasticnet1/submission_rapids_ensemble_6SVR_4KNN.csv\")\n#df_svr5=pd.read_csv(\"../input/elasticnet1/submission_svr2_ela4_ensemble (1).csv\")\ndf_svr6=pd.read_csv('../input/elasticnetcv2-submission/400region_load_FNC_SVR.csv')\ndf_svr1['Predicted']=df_svr1['Predicted']*0.4+df_svr2['Predicted']*0.1+df_svr3['Predicted']*0.3+df_svr4['Predicted']*0.15+df_svr6['Predicted']*0.05\ndf_svr1.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ela_svr1=pd.read_csv('../input/elasticnetcv2-submission/400region_fold5_ElasticnetCV_SVR.csv')\ndf_ela_svr2=pd.read_csv('../input/elasticnetcv2-submission/400region_load_FNC_ElasticNetCV_SVR.csv')\ndf_ela_svr1['Predicted']=df_ela_svr1['Predicted']*0.5+df_ela_svr2['Predicted']*0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_svr1['Predicted']=df_ela1['Predicted']*0.3+df_svr1['Predicted']*0.4+df_region1['Predicted']*0.25+df_ela_svr1['Predicted']*0.05\ndf_mm=pd.read_csv(\"../input/elasticnet1/submission_svr2_ela4_ensemble (1).csv\")\ndf_svr1['Predicted']=df_svr1['Predicted']*0.8+df_mm['Predicted']*0.2\ndf_svr1.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_svr1.to_csv(\"submission_ramdom_v12.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Log\n> * V6: KNN+SVR+elasticnet \n> * V8: KNN+SVR submission_random_v8.csv LB 0.1601 \n> * V9: SVR (load+fnc+region(full features))\n> * V10: SVR (load+fnc+loadfnc+region(full features))","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_ela1.to_csv(\"submission_svr_elasticnetcv2_load_fnc_region.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}