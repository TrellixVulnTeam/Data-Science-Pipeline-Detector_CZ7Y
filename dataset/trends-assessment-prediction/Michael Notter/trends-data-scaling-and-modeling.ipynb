{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Scaling and Modeling\n\nAfter taking a closer look at the targets (see my [first notebook](https://www.kaggle.com/miykael/trends-exploration-of-the-targets)) and performing feature exploration and engineering (see my [second notebook](https://www.kaggle.com/miykael/trends-feature-exploration-engineering)), we are ready to train some models and perform some predictions.\n\nWith this notebook I want to show how I went from an average performing model to one in the top 25th, just by **(1)** using adapted targets, **(2)** use engineered features from the MRI maps and **(3)** fine tune the scaling of the different datasets. Especially the last point is something that went against my initial intuition.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom os.path import join as opj\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nsns.set_context('notebook')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Load targets and features\n\nFirst things first, let's load the adapted targets and prepared feature datasets from my [second notebook](https://www.kaggle.com/miykael/trends-feature-exploration-engineering).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/trends-feature-exploration-engineering/datasets'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load target values and corresponding scaler\nimport joblib\nscaler_targets = joblib.load(opj(path, 'targets_scaler.pkl'))\n\ntargets = pd.read_hdf(opj(path, 'targets.h5'))\ntargets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To load the feature matrix, let's write a function that performs the following steps:\n\n1. Load the train and test set.\n2. Select the target feature from the 5 (resp. 7) targets.\n3. Centralize the corr_coef features to the median, which is about 0.689\n4. Scale the four feature datasets (IC, FNC, intra and inter correlations) according to a scaler called `scale_values`. Before this scaler is applied, all feature within a dataset are scaled to the 90% value (i.e. top 10%). No centralization was applied.\n5. Missing values are dropped.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset_and_scale(target, dataset_id='merge', scale_values=[1, 1, 1, 1]):\n\n    # Load dataset\n    X_tr = pd.read_hdf(opj(path, '%s_train.h5' % dataset_id))\n    X_te = pd.read_hdf(opj(path, '%s_test.h5' % dataset_id))\n\n    # Specify target\n    y = pd.read_hdf(opj(path, 'targets.h5'))\n    y_tr = y.loc[X_tr.index, target]\n\n    # Remove missing values\n    missval = y_tr.isnull().values\n    idx = ~missval\n    X_tr = X_tr[idx]\n    X_te = X_te\n    y_tr = y_tr[idx]\n    print('Removing %s missing values from target dataset.' % missval.sum())\n    \n    # Centralize corr_coef features\n    median_offset = X_tr.iloc[:, X_tr.columns.str.contains('corr_coef')].median().mean()\n    X_tr.iloc[:, X_tr.columns.str.contains('corr_coef')] -= median_offset\n    X_te.iloc[:, X_te.columns.str.contains('corr_coef')] -= median_offset\n\n    # Establish masks for different kinds of data\n    mask_ids = []\n    for m in ['IC_', '_vs_', 'corr_coef', '^c[0-9]+_c[0-9]+']:\n        mask_ids.append(X_tr.columns.str.contains(m))\n    mask_ids = np.array(mask_ids)\n\n    # Data scaling\n    for i, m in enumerate(mask_ids):\n\n        if m.sum()==0:\n            continue\n        \n        # Apply Scale\n        scale_value = scale_values[i]\n        unify_mask_scale = np.percentile(X_tr.iloc[:, m].abs(), 90)\n\n        X_te.iloc[:, m] /= unify_mask_scale\n        X_tr.iloc[:, m] /= unify_mask_scale\n    \n        X_te.iloc[:, m] *= scale_value\n        X_tr.iloc[:, m] *= scale_value\n\n    # Drop irrelevant measurements\n    X_tr.dropna(axis=1, inplace=True)\n    X_te.dropna(axis=1, inplace=True)\n    \n    # Drop duplicate rows\n    X_tr = X_tr.T.drop_duplicates().T\n    X_te = X_te.T.drop_duplicates().T\n    \n    print('Size of dataset (train/test): ', X_tr.shape, X_te.shape)\n    \n    X_tr = X_tr.values\n    X_te = X_te.values\n    y_tr = y_tr.values\n    \n    return X_tr, X_te, y_tr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Define scoring function and model parameters\n\nNow that the data is ready, let's write a scoring function which **(1)** reverts the target adaptations (scaling and power transformation) and **(2)** makes sure that the predicted values are within the scope of the target values. The actual scoring function is the mean absolute error, as defined by the competition.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create scorer function\nfrom sklearn.metrics import make_scorer\ndef model_metric(y_true, y_pred, scaler=None, tidx=0):\n    \n    # List of power transformations\n    pow_age = 1.0\n    pow_d1v1 = 1.5\n    pow_d1v2 = 1.5\n    pow_d2v1 = 1.5\n    pow_d2v2 = 1.5\n    pow_d21 = 1.5\n    pow_d22 = 1.0\n\n    powers = [pow_age, pow_d1v1, pow_d1v2, pow_d2v1, pow_d2v2, pow_d21, pow_d22]\n    \n    # Invert scaler\n    t_true = scaler.inverse_transform(np.transpose([y_true] * 7))[:, tidx]\n    t_pred = scaler.inverse_transform(np.transpose([y_pred] * 7))[:, tidx]\n    \n    # Assign closest value from training set\n    unique_values = np.unique(t_true)\n    for i, a in enumerate(t_pred):\n        t_pred[i] = unique_values[np.argmin(np.abs(a-unique_values))]\n\n    # Invert power transformation\n    t_true = np.power(t_true, 1./powers[tidx])\n    t_pred = np.power(t_pred, 1./powers[tidx])\n    \n    # Compute the score\n    score = np.mean(np.sum(np.abs(t_true - t_pred), axis=0) / np.sum(t_true, axis=0))\n    return score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also write a function that generates the modeling pipeline, parameter grid and runs the `GridSearchCV` object.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_grid(model_metric, alphas=[0.1, 1, 10], estimator=None,\n                cv=5, scaler_targets=None, tidx=0):\n\n    # Create Pipeline\n    pipeline = Pipeline([\n        ('scaler', None),\n        ('estimator', estimator),\n    ])\n\n    # Define parameter grid\n    param_grid = [{'scaler': [None, RobustScaler()],\n                   'estimator__alpha': alphas,\n                  }]\n\n    # Create grid search object\n    f_scorer = make_scorer(model_metric, greater_is_better=False,\n                           scaler=scaler_targets, tidx=tidx)\n    grid = GridSearchCV(pipeline,\n                        cv=cv,\n                        param_grid=param_grid,\n                        scoring=f_scorer,\n                        return_train_score=True,\n                        verbose=5,\n                        n_jobs=-1)\n\n    return grid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Initial data modeling approach (standard)\n\nMy first data modeling approach was rather standard. Take the data, apply a scaler, run a Ridge regression. So let's try this out, first only on the IC and FNC features and than once also with the feature engineered features.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Data modeling with 2 feature sets and RobustScaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'age'\ntidx = 0\n\n# Let's select which features to use and how to scale them\nscale_values = [1,        # IC features\n                1,        # FNC features\n                np.nan,   # intra features\n                np.nan]   # inter features\n\nX_tr, X_te, y_tr =  load_dataset_and_scale(target, scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define estimator\nestimator = Ridge(tol=1e-3)\n\n# Create grid search object\nalphas = np.logspace(0, 4, 21)\ngrid = create_grid(model_metric, alphas=alphas, estimator=estimator,\n                   cv=5, scaler_targets=scaler_targets, tidx=tidx)\n\n# Run grid search\n_ = grid.fit(X_tr, y_tr)\n\n# Provide some insights into the models top performance\nprint('Dataset scales used: ', scale_values)\nprint(\"Best score at: %f using %s\" % (grid.best_score_, grid.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now to better understand what exactly happend, lets write some helper functions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Extract predictions and plot them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_predictions(X_tr, X_te, grid, y_tr):\n\n    # Store predictions in dictionary\n    res = {}\n    res['tr'] = grid.predict(X_tr)\n    res['te'] = grid.predict(X_te)\n    \n    # Assign closest value from training set \n    unique_values = np.unique(y_tr)\n    for t in ['tr', 'te']:\n        for i, a in enumerate(res[t]):\n            res[t][i] = unique_values[np.argmin(np.abs(a-unique_values))]\n\n    return res['tr'], res['te']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the predictions for the training and the test set\npred_tr, pred_te = extract_predictions(X_tr, X_te, grid, y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_predictions(pred_tr, pred_te, y_tr):\n\n    # Plot prediction descrepancy on training and test set\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n\n    ax[0].set_title('Prediction X_te: %s' % target)\n    ax[0].plot(pred_te, '.', alpha=0.5, markersize=5)\n    ax[0].plot(pred_tr, '.', alpha=0.3, markersize=5)\n    ax[0].legend(['Train', 'Test'])\n    ax[0].set_ylabel('target value')\n    ax[0].set_xlabel('Sample')\n\n    ax[1].set_title('Prediction X_tr: %s' % target)\n    sns.regplot(x=pred_tr, y=y_tr, marker='.', ax=ax[1], scatter_kws={'s':10})\n    ax[1].set_xlim([-3.5, 3.5])\n    ax[1].set_ylim([-3.5, 3.5])\n    ax[1].set_ylabel('True value')\n    ax[1].set_xlabel('Predicted value')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the predictions with respect to each other and to the target\nplot_predictions(pred_tr, pred_te, y_tr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **left** figure shows the individual prediction values (in y direction) in a sequential fashion next to each other (i.e. feature 0 to 5835 = `X_tr.shape[1]`). In blue are the values from the training set, in orange the one from the test set.\n\nIn the **right** figure, we can see the relationship between the predicted and the true target values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Collect information about grid point performance and plot them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_df_pred(grid):\n\n    # Store grid search parameters and outcomes in dataframe\n    df_pred = pd.DataFrame(grid.cv_results_)\n    columns = [c for c in df_pred.columns if 'time' not in c\n               and 'split' not in c\n               and 'rank' not in c\n               and c!='params']\n    df_pred = df_pred[columns].sort_values('mean_test_score', ascending=False)\n    df_pred['param_estimator__alpha'] = df_pred['param_estimator__alpha'].astype('float')\n    df_pred['param_scaler'] = df_pred['param_scaler'].astype('str')\n    \n    return df_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creates dataframe about grid point's performance\ndf_pred = create_df_pred(grid).sort_values('mean_test_score')\ndf_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hyperparam_fitting(df_pred):\n\n    # Plot the model fit information\n    for s in df_pred['param_scaler'].unique():\n\n        df_plot = df_pred[np.prod([df_pred['param_scaler']==s],\n                                  axis=0).astype('bool')]\n\n        df_plot = df_plot.sort_values('param_estimator__alpha')\n\n        # Extract relevant modelling metrics\n        train_scores = df_plot['mean_train_score']\n        valid_scores = df_plot['mean_test_score']\n        std_tr = df_plot['std_train_score']\n        std_va = df_plot['std_test_score']\n\n        plt.figure(figsize=(12, 4))\n        alphas = df_plot['param_estimator__alpha']\n        plt.semilogx(alphas, train_scores, label='Training Set')\n        plt.semilogx(alphas, valid_scores, label='Validation Set')\n\n        # Add marker and text for best score\n        max_id = np.argmax(valid_scores)\n        x_pos = alphas.iloc[max_id]\n        y_pos = valid_scores.iloc[max_id]\n        txt = '{:0.4f}'.format(y_pos)\n        plt.scatter(x_pos, y_pos, marker='x', c='red', zorder=10)\n        plt.text(x_pos, y_pos, txt, fontdict={'size': 18})\n\n        # Quantify variance with ±std curves\n        plt.fill_between(alphas, train_scores-std_tr, train_scores+std_tr, alpha=0.3)\n        plt.fill_between(alphas, valid_scores-std_va, valid_scores+std_va, alpha=0.3)\n        plt.ylabel('Performance metric')\n        plt.xlabel('Model parameter')\n\n        # Adjust x-lim, y-lim, add legend and adjust layout\n        plt.legend()\n        plt.title('Scaler: %s' % s)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot prediction behaviour\nplot_hyperparam_fitting(df_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 1\n\nAs we can see, the unviersally scaled (i.e. using `RobustScaler()`) data leads to better predictions. Let's see what happens if we include all 4 feature sets.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Data modeling with 4 feature sets and RobustScaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'age'\ntidx = 0\n\n# Let's select which features to use and how to scale them\nscale_values = [1,        # IC features\n                1,        # FNC features\n                1,        # intra features\n                1]        # inter features\n\nX_tr, X_te, y_tr =  load_dataset_and_scale(target, scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define estimator\nestimator = Ridge(tol=1e-3)\n\n# Create grid search object\nalphas = np.logspace(1, 5, 21)\ngrid = create_grid(model_metric, alphas=alphas, estimator=estimator,\n                   cv=5, scaler_targets=scaler_targets, tidx=tidx)\n\n# Run grid search\n_ = grid.fit(X_tr, y_tr)\n\n# Provide some insights into the models top performance\nprint('Dataset scales used: ', scale_values)\nprint(\"Best score at: %f using %s\" % (grid.best_score_, grid.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the predictions for the training and the test set\npred_tr, pred_te = extract_predictions(X_tr, X_te, grid, y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the predictions with respect to each other and to the target\nplot_predictions(pred_tr, pred_te, y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creates dataframe about grid point's performance\ndf_pred = create_df_pred(grid).sort_values('mean_test_score', ascending=False)\ndf_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot prediction behaviour\nplot_hyperparam_fitting(df_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 2\n\nHmm... things seem to have gotten worse. It's at that time that I've explored multiple other models. SVR (linear/rbf), lasso, elastinet, SGD, KNN, RandomForests, Neural networks, etc. Nothing seems to have help.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. Manual data scaling\n\nGoing against my initial intuition, I've tried the scaling of the FNC features. I was curious why some people scaled with a factor of 500, others with 400, 600 or 300. My solution to this conundrum was, let's triangulate the optimal scaling.\n\nThe task was straight forward and very iterative. Let's try different values within the variable...\n\n```python\nscale_values = [1,        # IC features\n                1,        # FNC features\n                1,        # intra features\n                1]        # inter features\n\n```\n\nand see if this improves the modeling. As much as I can observe, using different scales means also moving the optimal \"alpha peak\" around. It's kind of like a summazion of different waves where you try to stack the peaks. Changing the scales, changes the peaks location (not necessarily the hight) on the x axis. Problem here is clearly, everytime you add another feature set, the regularization term might shift heavily.\n\nNonetheless, this path proved to be fruitful. So let's see the effect. Again, finding the right values, was a triangulation/iterative approach.\n\nBut before we start, let's package this all into a function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_prediction(model_metric, estimator=None, alphas=[0.1, 1, 10], cv=5,\n                   scaler_targets=None, target='age', tidx=0, scale_values=None):\n    \n    # Extract dataset\n    X_tr, X_te, y_tr = load_dataset_and_scale(target, scale_values=scale_values)\n    \n    # Create grid search object\n    grid = create_grid(model_metric, alphas=alphas, estimator=estimator,\n                       cv=cv, scaler_targets=scaler_targets, tidx=tidx)\n    \n    # Run grid search\n    _ = grid.fit(X_tr, y_tr)\n    \n    # Provide some insights into the models top performance\n    print('Dataset scales used: ', scale_values)\n    print(\"Best score at: %f using %s\" % (grid.best_score_, grid.best_params_))\n\n    # Extract the predictions for the training and the test set\n    pred_tr, pred_te = extract_predictions(X_tr, X_te, grid, y_tr)\n\n    # Plot the predictions with respect to each other and to the target\n    plot_predictions(pred_tr, pred_te, y_tr)\n\n    # Creates dataframe about grid point's performance\n    df_pred = create_df_pred(grid)\n    display(df_pred.sort_values('mean_test_score', ascending=False).head())\n\n    # Plot prediction behaviour\n    plot_hyperparam_fitting(df_pred)\n    \n    return df_pred, pred_tr, pred_te, grid, y_tr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Data modeling with 2 manually scaled feature sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'age'\ntidx = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,     # Feature: IC\n                0.04,     # Feature: FNC\n                np.nan,   # Feature: Intra Corr\n                np.nan,   # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-2, 4, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 3\n\nAs we saw in other scaling approaches (e.g. scaling with a factor of 500), we can see that the results improved and are now better than ones with the `RobustScaler()`. Let's see what the other two feature sets bring to the table.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.2. Data modeling with 3 manually scaled feature sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'age'\ntidx = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,     # Feature: IC\n                0.04,     # Feature: FNC\n                0.087,    # Feature: Intra Corr\n                np.nan,   # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-2, 4, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3. Data modeling with 4 manually scaled feature sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'age'\ntidx = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,     # Feature: IC\n                0.04,     # Feature: FNC\n                0.087,    # Feature: Intra Corr\n                0.025,    # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-2, 4, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observartion 4\n\nAs we can see, using these 4 feature datasets with manually scaled properties, we can reduce the mean absolute error for age quiet a bit. However, using a standard `RobustScaler` approach, this advantage gets lost and we are worse off than before.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5. Compute predictions for all 5 targets using Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect test predictions\npredictions_ridge = {}\n\n# Save predictions for age in output variable\npredictions_ridge[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.1. Predicting `domain1_var1` using Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain1_var1'\ntidx = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,    # Feature: IC\n                0.01,    # Feature: FNC\n                0.032,   # Feature: Intra Corr\n                0.019,   # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-1, 5, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for domain1_var1 in output variable\npredictions_ridge[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2. Predicting `domain1_var2` using Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain1_var2'\ntidx = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.121,   # Feature: IC\n                0.019,   # Feature: FNC\n                0.032,   # Feature: Intra Corr\n                0.025,   # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-1, 5, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for domain1_var2 in output variable\npredictions_ridge[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.3. Predicting `domain2_var1` using Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain2_var1'\ntidx = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,    # Feature: IC\n                0.008,   # Feature: FNC\n                0.012,   # Feature: Intra Corr\n                0.012,   # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-1, 5, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for domain2_var1 in output variable\npredictions_ridge[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.4. Predicting `domain2_var2` using Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain2_var2'\ntidx = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.261,   # Feature: IC\n                0.025,   # Feature: FNC\n                0.052,   # Feature: Intra Corr\n                0.022,   # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = Ridge(tol=1e-3)\nalphas = np.logspace(-1, 5, 31)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=alphas, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for domain2_var2 in output variable\npredictions_ridge[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion 1\n\nUsing the manual scaling approach, together with the four feature datastes is very powerful, but mostly only helps with the prediction of `age`.\n\nIt is possible to increase the scores slightly, by focusing in on the grid space and optimize the alpha value (as well as the manual scaling factor) more precisely, but the risk is clearly also there for overfitting.\n\nIncreasing the number of folds (i.e. `cv`) helps with some targets and worsens other. But the generalization probably improves nonetheless.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 6. Compute prediction for all 5 targets using SVR (rbf)\n\nAs other's have mentioned in the discussions, Ridge and SVR seem to be very suited to predict the target values. For this reason, let's do the same thing as we did above, but this time with an SVR estimator, using an rbf kernel.\n\nThe only thing we need to adapt to make this work is the following three functions.\n\n**Note**: To reduce computation time, we will remove the `RobustScaler` from the grid search.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_grid(model_metric, alphas=[0.1, 1, 10], estimator=None,\n                cv=5, scaler_targets=None, tidx=0):\n\n    # Create Pipeline\n    pipeline = Pipeline([\n        ('estimator', estimator),\n    ])\n\n    # Define parameter grid\n    param_grid = [{'estimator__C': alphas}]\n\n    # Create grid search object\n    f_scorer = make_scorer(model_metric, greater_is_better=False,\n                           scaler=scaler_targets, tidx=tidx)\n    grid = GridSearchCV(pipeline,\n                        cv=cv,\n                        param_grid=param_grid,\n                        scoring=f_scorer,\n                        return_train_score=True,\n                        verbose=5,\n                        n_jobs=-1)\n\n    return grid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_df_pred(grid):\n\n    # Store grid search parameters and outcomes in dataframe\n    df_pred = pd.DataFrame(grid.cv_results_)\n    columns = [c for c in df_pred.columns if 'time' not in c\n               and 'split' not in c\n               and 'rank' not in c\n               and c!='params']\n    df_pred = df_pred[columns].sort_values('mean_test_score', ascending=False)\n    df_pred['param_estimator__C'] = df_pred['param_estimator__C'].astype('float')\n\n    return df_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hyperparam_fitting(df_pred):\n\n    # Plot the model fit information\n    df_plot = df_pred.copy()\n\n    df_plot = df_plot.sort_values('param_estimator__C')\n\n    # Extract relevant modelling metrics\n    train_scores = df_plot['mean_train_score']\n    valid_scores = df_plot['mean_test_score']\n    std_tr = df_plot['std_train_score']\n    std_va = df_plot['std_test_score']\n\n    plt.figure(figsize=(12, 4))\n    Cs = df_plot['param_estimator__C']\n    plt.semilogx(Cs, train_scores, label='Training Set')\n    plt.semilogx(Cs, valid_scores, label='Validation Set')\n\n    # Add marker and text for best score\n    max_id = np.argmax(valid_scores)\n    x_pos = Cs.iloc[max_id]\n    y_pos = valid_scores.iloc[max_id]\n    txt = '{:0.4f}'.format(y_pos)\n    plt.scatter(x_pos, y_pos, marker='x', c='red', zorder=10)\n    plt.text(x_pos, y_pos, txt, fontdict={'size': 18})\n\n    # Quantify variance with ±std curves\n    plt.fill_between(Cs, train_scores-std_tr, train_scores+std_tr, alpha=0.3)\n    plt.fill_between(Cs, valid_scores-std_va, valid_scores+std_va, alpha=0.3)\n    plt.ylabel('Performance metric')\n    plt.xlabel('Model parameter')\n\n    # Adjust x-lim, y-lim, add legend and adjust layout\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.1. Predicting `age` using SVR(rbf)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'age'\ntidx = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,      # Feature: IC\n                0.015,     # Feature: FNC\n                0.042,     # Feature: Intra Corr\n                0.014,     # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = SVR(gamma='scale', epsilon=0.2, tol=1e-3, max_iter=5000)\nCs = np.logspace(-1, 1, 11)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=Cs, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect test predictions\npredictions_svr = {}\n\n# Save predictions for age in output variable\npredictions_svr[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.2. Predicting `domain1_var1` using SVR(rbf)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain1_var1'\ntidx = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,      # Feature: IC\n                0.012,     # Feature: FNC\n                0.032,     # Feature: Intra Corr\n                0.018,     # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = SVR(gamma='scale', epsilon=0.2, tol=1e-3, max_iter=5000)\nCs = np.logspace(-1, 1, 11)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=Cs, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for age in output variable\npredictions_svr[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.3. Predicting `domain1_var2` using SVR(rbf)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain1_var2'\ntidx = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.18,      # Feature: IC\n                0.01,      # Feature: FNC\n                np.nan,    # Feature: Intra Corr (no improvement)\n                0.025,     # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = SVR(gamma='scale', epsilon=0.2, tol=1e-3, max_iter=5000)\nCs = np.logspace(-1.5, 0.5, 11)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=Cs, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for age in output variable\npredictions_svr[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.4. Predicting `domain2_var1` using SVR(rbf)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain2_var1'\ntidx = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.25,      # Feature: IC\n                0.025,     # Feature: FNC\n                0.036,     # Feature: Intra Corr (no improvement)\n                0.023,     # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = SVR(gamma='scale', epsilon=0.2, tol=1e-3, max_iter=5000)\nCs = np.logspace(-1, 1, 11)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=Cs, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for age in output variable\npredictions_svr[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.5. Predicting `domain2_var2` using SVR(rbf)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the target (name and index)\ntarget = 'domain2_var2'\ntidx = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's select which features to use and how to scale them\nscale_values = [0.189,      # Feature: IC\n                0.025,      # Feature: FNC\n                0.050,    # Feature: Intra Corr (no improvement)\n                0.022,     # Feature: Inter Corr\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model parameters\nestimator = SVR(gamma='scale', epsilon=0.2, tol=1e-3, max_iter=5000)\nCs = np.logspace(-1, 1, 11)\ncv = 5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_pred, pred_tr, pred_te, grid, y_tr = run_prediction(\n    model_metric, estimator=estimator, alphas=Cs, cv=cv,\n    scaler_targets=scaler_targets, target=target, tidx=tidx,\n    scale_values=scale_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions for age in output variable\npredictions_svr[target] = pred_te","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Saving predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load sample submission file\nsubmission = pd.read_csv(opj('/kaggle', 'input', 'trends-assessment-prediction', 'sample_submission.csv')).set_index('Id')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's write a function that inverts the initial target feature adapataions (i.e. scaling and power transformation).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def back_transform(y_test, unique_values, scaler=None, tidx=0):\n    \n    # List of power transformations\n    pow_age = 1.0\n    pow_d1v1 = 1.5\n    pow_d1v2 = 1.5\n    pow_d2v1 = 1.5\n    pow_d2v2 = 1.5\n    pow_d21 = 1.5\n    pow_d22 = 1.0\n\n    powers = [pow_age, pow_d1v1, pow_d1v2, pow_d2v1, pow_d2v2, pow_d21, pow_d22]\n    \n    # Assign closest value from training set\n    for i, a in enumerate(y_test):\n        y_test[i] = unique_values[np.argmin(np.abs(a-unique_values))]\n    \n    # Invert scaler\n    y_test = scaler.inverse_transform(np.transpose([y_test] * 7))[:, tidx]\n    \n    # Invert power transformation\n    y_test = np.power(y_test, 1./powers[tidx])\n\n    return y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill up the submission file with the ridge predictions\nprediction_dict = predictions_ridge\nfor i, t in enumerate(['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']):\n    unique_values = sorted(targets[t].dropna().unique())\n    pred_values = back_transform(prediction_dict[t], unique_values, scaler=scaler_targets, tidx=i)\n    submission.iloc[submission.index.str.contains(t), 0] = pred_values\n\n# Let's visualize a few points from the submission file\ndisplay(submission.head(10))\n\n# Store predictions in CSF file\nsubmission.to_csv('submission_ridge.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score for pure Ridge model\n\nOnly using the predictions from the Ridge model, we would have reached a score of 0.15808, which in the final rating would have lead to the 24th place in the public leaderboard.\n\n**Note**: Out of interest, I also ran the predcition with the \"feature offset correction\" described by the 1st place team (see [here](https://www.kaggle.com/c/trends-assessment-prediction/discussion/163017), which moved the score of the Ridge model to 0.15787, corresponding to the 21st position on the public leaderboard.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Fill up the submission file with the ridge predictions\nprediction_dict = predictions_svr\nfor i, t in enumerate(['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']):\n    unique_values = sorted(targets[t].dropna().unique())\n    pred_values = back_transform(prediction_dict[t], unique_values, scaler=scaler_targets, tidx=i)\n    submission.iloc[submission.index.str.contains(t), 0] = pred_values\n\n# Let's visualize a few points from the submission file\ndisplay(submission.head(10))\n\n# Store predictions in CSF file\nsubmission.to_csv('submission_svr.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Score for pure SVR model\n\nOnly using the predictions from the SVR model, we would have reached a score of 0.15769, which in the final rating would have lead to the 19th place in the public leaderboard.\n\n\n**Note**: Out of interest, I also ran the predcition with the \"feature offset correction\" described by the 1st place team (see [here](https://www.kaggle.com/c/trends-assessment-prediction/discussion/163017), which moved the score of the SVR model to 0.15738, corresponding to the 13th position on the public leaderboard.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 8. Visualize differences in prediction\n\nAs a final last step, let's also look at the prediction differences between the two models.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"for c in predictions_ridge.keys():\n    plt.figure(figsize=(6, 6))\n    plt.scatter(predictions_ridge[c], predictions_svr[c], s=2, alpha=0.5)\n    plt.title(c)\n    plt.xlabel('Ridge Prediction')\n    plt.ylabel('SVR Prediction')\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}