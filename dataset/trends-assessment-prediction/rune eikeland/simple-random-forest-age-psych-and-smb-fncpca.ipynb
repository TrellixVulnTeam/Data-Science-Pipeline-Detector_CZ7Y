{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestRegressor # A random forest regressor\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html    \n\nfrom sklearn.decomposition import PCA # For Principal Component Analysis\nimport matplotlib.pyplot as plt # For creating visualizations\n\n\n# Not using now: \n# from sklearn.svm import SVR # Epsilon-Support Vector Regression\n# from sklearn.svm import LinearSVR # Linear Support Vector Regression\n# from sklearn.preprocessing import StandardScaler # Standardize features by removing the mean and scaling to unit variance \n# from umap import UMAP # UMAP is a general purpose manifold learning and dimension reduction algorithm\n# from sklearn.manifold import TSNE # t-SNE is a tool to visualize high-dimensional data\n# from sklearn.pipeline import make_pipeline \n# from sklearn.model_selection import KFold # Provides train/test indices to split data in train/test sets\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n\n# Small program for moving columns: movecol\n# From: https://towardsdatascience.com/reordering-pandas-dataframe-columns-thumbs-down-on-standard-solutions\ndef movecol(df, cols_to_move=[], ref_col='', place='After'):\n    \n    cols = df.columns.tolist()\n    if place == 'After':\n        seg1 = cols[:list(cols).index(ref_col) + 1]\n        seg2 = cols_to_move\n    if place == 'Before':\n        seg1 = cols[:list(cols).index(ref_col)]\n        seg2 = cols_to_move + [ref_col]\n    \n    seg1 = [i for i in seg1 if i not in seg2]\n    seg3 = [i for i in cols if i not in seg1 + seg2]\n    \n    return(df[seg1 + seg2 + seg3])\n\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# https://medium.com/datadriveninvestor/random-forest-regression-9871bc9a25eb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Load data\n\n# Load brain functional connectivity (fnc) and source-baed morphometry (smb) (loading_df) data  \nfnc_df = pd.read_csv(\"../input/trends-assessment-prediction/fnc.csv\") # Load functional connectivity (FNC) data into panda dataframe\nloading_df = pd.read_csv(\"../input/trends-assessment-prediction/loading.csv\") # Load source-based morphometry (SMB) data into panda dataframe\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:]) # Save header information in seperate lists\ndf = fnc_df.merge(loading_df, on=\"Id\") # Merge fnc_df and loading_df while matching data on Id variable\n \n\n# Flag what is training and test data in df    \nlabels_df = pd.read_csv(\"../input/trends-assessment-prediction/train_scores.csv\") # Load dataset containing trainingscores into panda dataframe\nlabels_df[\"is_train\"] = True # Add column indicating it is training data for both training and test data\ndf = df.merge(labels_df, on=\"Id\", how=\"left\") # Merge with df containing both training and test data to indicate which ID is part of training or test dataset\n\ntest_df = df[df[\"is_train\"] != True].copy() # Make df with age, cognitive measures, FCN and SMB data for all test subjects (age and cognitive data blanck for test data while FCN and SMB data is given)\ntrain_df = df[df[\"is_train\"] == True].copy()  # Make df with age, cognitive measures, FCN and SMB data for all train subjects\n\ntrain_df.shape, test_df.shape # check shape of training and test data, as both training and test datasets have equal instances df and test_df should have similar shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reduce FCN to 26 PCA components so that FCN and SBM have same weighting in further analysis\npca = PCA(n_components=26) # set PCA to compute 26 components (SBM has 26 components)\n\nX_fnc = df[fnc_features].values # X_fnc = all functional connectivity measures (both train and test)\n\nX_fnc = pca.fit_transform(X_fnc) # do PCA on X_fnc (both test and train set data) fit data into 26 components\npca_fnc_features = ['pca' + str(number) for number in range(X_fnc.shape[1])] # make header information pca + number for each column of X_fnc\ndf_pca_fnc_features = pd.DataFrame(X_fnc, columns=pca_fnc_features) # make a dataframe wiht the 26 PCA components from X_fnc and colimn names from pca_fnc_features\n\ndf = df.join(df_pca_fnc_features) # join the 26 PCA compoent dataframe to df cointaining all the information (both train and test)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Make training- and test dataset\ntest_df = df[df[\"is_train\"] != True].copy() # Make df with age, cognitive measures, FCN and SMB data for all test subjects (age and cognitive data blanck for test data while FCN and SMB data is given)\ntrain_df = df[df[\"is_train\"] == True].copy()  # Make df with age, cognitive measures, FCN and SMB data for all train subjects\n\ntest_df = test_df.drop(fnc_features, axis=1) # Remove th FNC measures and just keep the fca 26 PCA components\ntrain_df = train_df.drop(fnc_features, axis=1)\n\ntrain_df.shape, test_df.shape # check shape of training and test data, as both training and test datasets have equal instances df and test_df should have similar shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reoder columns to make dataframe information more accessible\n\ntest_df = movecol(test_df, \n             cols_to_move=['age','is_train','domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2'], \n             ref_col='Id',\n             place='After')\n\ntrain_df = movecol(train_df, \n             cols_to_move=['age','is_train','domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2'], \n             ref_col='Id',\n             place='After')\n\ndel test_df['is_train']\ndel train_df['is_train']\n\n\ntest_df.shape, train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove NaN from train data\n# train_df = train_df.dropna() # Drop the rows where at least one element is missing.\n\n# Replace NaN with column mean in train_df\ntrain_df[['domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']] = train_df[['domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].fillna(train_df[['domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].mean())\n\n# Check for NaN in training data\ntrain_df.isnull().values.any(), train_df.shape, test_df.shape\n\n# Missing values can be replaced by the mean, the median or the most frequent value using the basic sklearn.impute.SimpleImputer\n# https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-pyFeature Scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Feature Scaling  \n## p.72 in Hands On Machine Learning\n\n# One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales.\n# Note that scaling the target values is generally not required.\n# There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.\n# Scikit-Learn provides a transformer called StandardScaler for standardization. first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance.     \n# Min-max scaling (many people call this normalization) is quite simple: values are shifted and rescaled so that they end up ranging from 0 to 1. Scikit-Learn provides a transformer called MinMaxScaler for this.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## TEMPORARY FOR INSPECTING THAT THE FOR-LOOP WORKS AS PLANNED\n# train_df['domain2_var1'] = train_df['domain2_var1']*100\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## BEGYNNE MED Å LAGE NY WORKBOOK MED EGNE GENERERTE DATA\n## LÆRE Å BRUKE SPLIT/TEST FØR K-FOLDS\n## FØLGE OPPSKRIFTEN I LÆREBOKEN KAP2\n\n\n# Fitting Random Forest Regression to the dataset \nfrom sklearn.metrics import mean_squared_error\n\n\n# Create regressor object and numpy matrix to store result (xmap)\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 42, oob_score=True)  \n\nx = train_df.iloc[:,6:58].values # Features are 26 SMB ICs and 26 FNC PCA components in the training data\ny = train_df.iloc[:,1].values # Target (i) is in order: \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"\nregressor.fit(x, y)  # Fit (scikit-learn’s name for training) the model using the Features (fixed, x(6:57) and Target (looping, y(i))\n\nage_predictions = regressor.predict(x) # using the model and storing results for testing the models ability to predict training data\n\nregressor_score  = regressor.score(x,y) # getting the score of the regression\n\noob_scores = regressor.oob_score_ # Store models Out-Of-Bag score. # oob_score p197 Hands on Machine Learning. Gives likelihood of accuracy on the test set in percent. i.e score of 0.91 = 91% chance that model will give correct score.\noob_predictions = regressor.oob_prediction_ # Store models Out-Of-Bag score. # oob_score p197 Hands on Machine Learning. Gives likelihood of accuracy on the test set in percent. i.e score of 0.91 = 91% chance that model will give correct score.\n\nage_predictions_mse = mean_squared_error(y ,age_predictions)\nage_predictions_rmse = np.sqrt(age_predictions_mse)\n\n# Evaluation of Model Using Cross-Validation p.76 Hands On Machine Learning\n    #Let’s measure this regression model’s RMSE on the whole training\n    #set using Scikit-Learn’s mean_squared_error function:\n\n# from sklearn.metrics import mean_squared_error\n\n\n# Display model accuracy scores\nprint()\nprint(\"regressor_score: \" + str(regressor_score)) # Regressor score. The best possible score is 1.0 and it can be negative\nprint(\"forest_mse: \" + str(age_predictions_mse)) # Mean square error (14.5 år i skrivende stund) \nprint(\"forest_rmse: \" + str(age_predictions_rmse)) # Lower = Better. Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.\nprint(\"Oob scores: \" + str(oob_scores))\nprint(\"Oob predictions: \" + str(oob_predictions))\n#Based on a rule of thumb, it can be said that RMSE values between 0.2 and 0.5 shows that the model can relatively predict the data accurately. In addition, Adjusted R-squared more than 0.75 is a very good value for showing the accuracy. In some cases, Adjusted R-squared of 0.4 or more is acceptable as well.\n\n\n\n\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_val_predict\npredictions = cross_val_predict(regressor, x, y, cv=10)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(regressor, x, y, cv=10)\nage_predictions_CV_rmse_scores = np.sqrt(scores)\n\ndef display_scores(scores):\n    print(\"Scores:\", scores) # Array of scores of the estimator for each run of the cross validation.\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndisplay_scores(age_predictions_CV_rmse_scores)\n\n# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import cross_val_score\n# scores = cross_val_score(regressor, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n# age_predictions_rmse_scores = np.sqrt(-scores)\n# def display_scores(scores):\n#    print(\"Scores:\", scores)\n#    print(\"Mean:\", scores.mean())\n#    print(\"Standard deviation:\", scores.std())\n\n# display_scores(age_predictions_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# and let’s separate the predictors and the labels since we don’t necessarily want to apply\n# the same transformations to the predictors and the target values (note that drop()\n# creates a copy of the data and does not affect strat_train_set):\n# housing = strat_train_set.drop(\"median_house_value\", axis=1)\n# housing_labels = strat_train_set[\"median_house_value\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Regression to the dataset \n\n# Create regressor object and numpy matrix to store result (xmap)\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 42, oob_score=True)  \ntargets = 3\nxmap = np.zeros(shape=(len(test_df),targets))\nxmap_train = np.zeros(shape=(len(train_df),targets))\nfeature_importance = np.zeros(shape=(52,62))\nmetrics = [0] * targets \noob_scores = [0] * targets \nregressor_score = [0] * targets \ni = 0 # initialize counter \n\n# fit the regressor with x and y data (Training the model)\nfor i in range(1,3):\n    x = train_df.iloc[:,6:58].values # Features are 26 SMB ICs and 26 FNC PCA components in the training data\n    y = train_df.iloc[:,i].values # Target (i) is in order: \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"\n    regressor.fit(x, y)  # Fit (scikit-learn’s name for training) the model using the Features (fixed, x(6:57) and Target (looping, y(i))\n    oob_scores[i] = regressor.oob_score_ # Store models Out-Of-Bag score. # oob_score p197 Hands on Machine Learning. Gives likelihood of accuracy on the test set in percent. i.e score of 0.91 = 91% chance that model will give correct score.\n    oob_predictions[i] = regressor.oob_prediction_ # Store predictions made by Out-Of-Bag process\n    \n# Evaluate Model based on Training data. Compare given (known) training scores to predicted scores from training data using function metric defined at top of script.\n    xmap_train[:,i] = regressor.predict(train_df.iloc[:, 6:58].values) # using the model and storing results for testing the models ability to predict training data\n    xmap_train[:,0] = train_df.iloc[:, 0].values # Add subj ID to xmap first (0) column\n    \n    #Evaluate model using Metrics as defined at start of code\n    regressor_score[i] = regressor.score(x, y)\n    \n    y_true = train_df.iloc[:,i] # target values from tranining set\n    y_pred = xmap_train[:,i] # predicted values from the model for targets based on the training dataset\n    metrics[i]= metric(y_true, y_pred) # Storing information on the comparison between given (known) training scores to predicted scores from training data using function metric defined at top of script (lower score is better)\n\n    feature_importance[:,i] = regressor.feature_importances_[:] # Storing information about which feature is important for making the predictions\n    list(train_df.columns)\n    \n    # Display model accuracy scores\n    print(i)\n    print(\"For Target: \" + str(train_df.columns[i]))\n    print(\"Regressor score: \" + str(regressor_score[i]))\n    print(\"Metrics: \" + str(metrics[i]))\n    print(\"Oob scores: \" + str(oob_scores[i]))\n    print(\" \")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fine-Tune Your Model p.79 Hands On Machine Learning\n# Let’s assume that you now have a shortlist of promising models. You now need to fine-tune them. Let’s look at a few ways you can do that.\n# Grid Search\n# One way to do that would be to fiddle with the hyperparameters manually, until you\n# find a great combination of hyperparameter values. This would be very tedious work,\n# and you may not have time to explore many combinations.\n# Instead you should get Scikit-Learn’s GridSearchCV to search for you. All you need to\n# do is tell it which hyperparameters you want it to experiment with, and what values to\n# try out, and it will evaluate all the possible combinations of hyperparameter values,\n# using cross-validation. For example, the following code searches for the best combination\n# of hyperparameter values for the RandomForestRegressor:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" list(train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.score(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Improving Model\n\nfrom sklearn.feature_selection import VarianceThreshold\n# https://scikit-learn.org/stable/modules/feature_selection.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k, (train, test) in enumerate(k_fold.split(X, y)):\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Regression to the dataset \n\n# Create regressor object and numpy matrix to store result (xmap)\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 42) \nxmap = np.zeros(shape=(len(test_df),6))\nfeature_importance = np.zeros(shape=(52,6))\ni = 0 # initialize counter \n\n\n# fit the regressor with x and y data (Training the model)\nfor i in range(1,6):\n    x =train_df.iloc[:,6:58].values # Features are 26 SMB ICs and 26 FNC PCA components in the training data\n    y = train_df.iloc[:,i].values # Target (i) is in order: \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"\n    regressor.fit(x, y)  # Fit (scikit-learn’s name for training) the model using the Features (fixed, x(6:57) and Target (looping, y(i))\n    xmap[:,i] = regressor.predict(test_df.iloc[:, 6:58].values) # Make the model predict \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\" from the test data 26 SMB ICs and 26 FNC PCA components and store results in xmap\n    xmap[:,0] = test_df.iloc[:, 0].values # Add subj ID to xmap first column\n    feature_importance[:,i] = regressor.feature_importances_[:]\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make dataframe with results \nestimations_df = pd.DataFrame(xmap, columns = [\"Id\",\"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"])\nestimations_df['Id'] = estimations_df['Id'].astype(str)\nestimations_df['Id'] = estimations_df['Id'].str[:5] # remove \".0\" from subject ID\nestimations_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform dataframe to competition format and save as csv file\ndf_out = estimations_df.melt(id_vars='Id',value_name='Predicted')\ndf_out = df_out.sort_values(by=['Id','variable'])\ndf_out[\"Id\"] = df_out[\"Id\"].astype(str) + '_' + df_out[\"variable\"].astype(str)\ndf_out = df_out.drop(['variable'], axis=1)\n\ndf_out.to_csv('df_out.csv', index=False) # Print csv file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show df_out \nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n    print(df_out)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dataframe with feature importance\nfeature_importance_df = pd.DataFrame(importance, columns = [\"Feature\",\"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"])\nfeature_importance_df[\"Feature\"] = train_df.columns[6:58]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance_df.sort_values([\"domain2_var2\"], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## TESTING K-FOLDS\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note:\n# It is always suggested that the value of k should be 10 as the lower value \n# of k is takes towards validation and higher value of k leads to LOOCV method.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nX = train_df.iloc[:,6:58].values\ny = train_df.iloc[:,1].values\nkf = KFold(n_splits=5)\nkf.get_n_splits(X)\n\nprint(kf)\n\nfor train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # Fitting Random Forest Regression to the dataset \ncv_regressor = RandomForestRegressor(n_estimators = 100, random_state = 42) \n\ncv_regressor.fit(X_train, y_train) \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = y\nmetric(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}