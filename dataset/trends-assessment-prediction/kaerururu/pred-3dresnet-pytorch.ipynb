{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport collections\nimport cv2\nimport datetime\nimport gc\nimport glob\nimport h5py\nimport logging\nimport math\nimport operator\nimport os \nimport pickle\nimport random\nimport re\nimport sklearn\nimport scipy.signal\nimport scipy.stats as stats\nimport seaborn as sns\nimport string\nimport sys\nimport time\nimport torch\ntorch.backends.cudnn.benchmark = True\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom contextlib import contextmanager\nfrom collections import Counter, defaultdict, OrderedDict\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import mean_squared_log_error, roc_auc_score, average_precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom skimage import measure\nfrom torch.nn import CrossEntropyLoss, MSELoss\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, MultiStepLR, ExponentialLR\nfrom torch.utils import model_zoo\nfrom torch.utils.data import (Dataset,DataLoader, RandomSampler, SequentialSampler,\n                              TensorDataset)\nimport tensorflow as tf\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/trends-assessment-prediction/'\nTEST_MAP_PATH = DATA_PATH + 'fMRI_test/'\nTRAIN_MAP_PATH = DATA_PATH + 'fMRI_train/'\nEXP_ID = 'exp1'\ndevice = 'cuda'\nEPOCHS = 3\nfold_id = 0\nSEED = 718\nnum_folds = 5\n\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 16\n\n\nfnc_df = pd.read_csv(f\"{DATA_PATH}/fnc.csv\")\nloading_df = pd.read_csv(f\"{DATA_PATH}/loading.csv\")\nlabels_df = pd.read_csv(f\"{DATA_PATH}/train_scores.csv\")\n\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntrain_ids = list(df[df[\"is_train\"] == True].index)\ntest_ids = list(df[df[\"is_train\"] != True]['Id'].index)\n\n\ndf['bin_age'] = pd.cut(df['age'], [i for i in range(0, 100, 10)], labels=False)\n\ndf_train = df.iloc[train_ids].reset_index(drop=True)\ndf_test = df.iloc[test_ids].reset_index(drop=True)\n\n\ntrain_idx = list(df_train.index) # [:500]\ntarget_cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\n# df_test = df_test.head(100)\n\nprint(df_test.shape)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom functools import partial\n\n__all__ = [\n    'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n    'resnet152', 'resnet200'\n]\n\ndef conv3x3x3(in_planes, out_planes, stride=1, dilation=1):\n    # 3x3x3 convolution with padding\n    return nn.Conv3d(\n        in_planes,\n        out_planes,\n        kernel_size=3,\n        dilation=dilation,\n        stride=stride,\n        padding=dilation,\n        bias=False)\n\ndef downsample_basic_block(x, planes, stride, no_cuda=False):\n    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n    zero_pads = torch.Tensor(out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4)).zero_()\n    if not no_cuda:\n        if isinstance(out.data, torch.cuda.FloatTensor):\n            zero_pads = zero_pads.cuda()\n\n    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n    return out\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        self.dilation = dilation\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.conv2 = nn.Conv3d(\n            planes, planes, kernel_size=3, stride=stride, dilation=dilation, padding=dilation, bias=False)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm3d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n        self.dilation = dilation\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\nclass ResNet3D(nn.Module):\n\n    def __init__(self,\n                 block,\n                 layers,\n                 shortcut_type='B',\n                 num_class = 5,\n                 no_cuda=False):\n\n        self.inplanes = 64\n        self.no_cuda = no_cuda\n        super(ResNet3D, self).__init__()\n\n        # 3D conv net\n        self.conv1 = nn.Conv3d(53, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n        # self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n        self.bn1 = nn.BatchNorm3d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n        self.layer2 = self._make_layer(\n            block, 64*2, layers[1], shortcut_type, stride=2)\n        self.layer3 = self._make_layer(\n            block, 128*2, layers[2], shortcut_type, stride=1, dilation=2)\n        self.layer4 = self._make_layer(\n            block, 256*2, layers[3], shortcut_type, stride=1, dilation=4)\n\n        self.fea_dim = 256*2 * block.expansion\n        self.fc = nn.Sequential(nn.Linear(self.fea_dim, num_class, bias=True))\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n            elif isinstance(m, nn.BatchNorm3d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1, dilation=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n\n            if shortcut_type == 'A':\n                downsample = partial(\n                    downsample_basic_block,\n                    planes=planes * block.expansion,\n                    stride=stride,\n                    no_cuda=self.no_cuda)\n            else:\n                downsample = nn.Sequential(\n                    nn.Conv3d(\n                        self.inplanes,\n                        planes * block.expansion,\n                        kernel_size=1,\n                        stride=stride,\n                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1( x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = F.adaptive_avg_pool3d(x, (1, 1, 1))\n        emb_3d = x.view((-1, self.fea_dim))\n        out = self.fc(emb_3d)\n        return out\n\n\ndef resnet10(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet3D(BasicBlock, [1, 1, 1, 1],**kwargs)\n    return model\n\n\ndef resnet34(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = ResNet3D(BasicBlock, [3, 4, 6, 3], **kwargs)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TReNDSDatasetTest:\n    def __init__(self, df, target_cols, map_path):\n        self.df = df\n        self.map_path = map_path\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, item):\n\n        IDX = self.df.iloc[item].Id        \n        path = self.map_path + str(IDX)\n        \n        all_maps = h5py.File(path + '.mat', 'r')['SM_feature'][()]\n\n        return {\n            'features': torch.tensor(all_maps, dtype=torch.float32),\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = TReNDSDatasetTest(df=df_test, target_cols=target_cols, map_path=TEST_MAP_PATH)\ntest_loader = torch.utils.data.DataLoader(\n                test_dataset, shuffle=False, \n                batch_size=TRAIN_BATCH_SIZE,\n                num_workers=0, pin_memory=True)\n\ndel test_dataset\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_fn(data_loader, model, device):\n    model.eval()\n    \n    preds = []\n    with torch.no_grad():\n        tk0 = tqdm(data_loader, total=len(data_loader))\n        for bi, d in enumerate(tk0):\n            features = d[\"features\"].to(device, dtype=torch.float32)\n\n            outputs = model(features)\n            outputs = outputs.cpu().detach().numpy()\n            preds.append(outputs)\n    \n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls ../input/trends-exp1/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nexp1\n\nage metric: 0.17694576\ndomain1_var1 metric: 0.1504816\ndomain1_var2 metric: 0.14616399\ndomain2_var1 metric: 0.17815593\ndomain2_var2 metric: 0.18233863\nall_metric: 0.16808325201272964\nsave model at score=0.16808325201272964 on epoch=12\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EXP_ID = 'exp1'\n\nmodel = resnet10()\nmodel.load_state_dict(torch.load(f'../input/trends-{EXP_ID}/{EXP_ID}_fold0.pth'))\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = test_fn(test_loader, model, 'cuda')\ntest_preds = np.concatenate(test_preds, 0)\nprint(test_preds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.loc[:, target_cols] = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.melt(df_test[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == df_test.shape[0]*5\n\nsub_df.to_csv(\"submission_3dconv.csv\", index=False)\nprint(sub_df.shape)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}