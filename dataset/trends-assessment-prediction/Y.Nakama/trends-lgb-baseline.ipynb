{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#===========================================================\n# Library\n#===========================================================\nimport os\nimport gc\nfrom logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\nfrom contextlib import contextmanager\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom functools import partial\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn import preprocessing\nimport category_encoders as ce\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.listdir('../input/trends-assessment-prediction/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"#===========================================================\n# Utils\n#===========================================================\ndef get_logger(filename='log'):\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nlogger = get_logger()\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\n\ndef seed_everything(seed=777):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n    \ndef load_df(path, df_name, debug=False):\n    if path.split('.')[-1]=='csv':\n        df = pd.read_csv(path)\n        if debug:\n            df = pd.read_csv(path, nrows=1000)\n    elif path.split('.')[-1]=='pkl':\n        df = pd.read_pickle(path)\n    if logger==None:\n        print(f\"{df_name} shape / {df.shape} \")\n    else:\n        logger.info(f\"{df_name} shape / {df.shape} \")\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"#===========================================================\n# Config\n#===========================================================\nOUTPUT_DICT = ''\n\nID = 'Id'\nTARGET_COLS = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\nSEED = 42\nseed_everything(seed=SEED)\n\nN_FOLD = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/trends-assessment-prediction/train_scores.csv', dtype={'Id':str})\\\n            .dropna().reset_index(drop=True) # to make things easy\nreveal_ID = pd.read_csv('../input/trends-assessment-prediction/reveal_ID_site2.csv', dtype={'Id':str})\nICN_numbers = pd.read_csv('../input/trends-assessment-prediction/ICN_numbers.csv')\nloading = pd.read_csv('../input/trends-assessment-prediction/loading.csv', dtype={'Id':str})\nfnc = pd.read_csv('../input/trends-assessment-prediction/fnc.csv', dtype={'Id':str})\nsample_submission = pd.read_csv('../input/trends-assessment-prediction/sample_submission.csv', dtype={'Id':str})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reveal_ID.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ICN_numbers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loading.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['ID_num'] = sample_submission[ID].apply(lambda x: int(x.split('_')[0]))\ntest = pd.DataFrame({ID: sample_submission['ID_num'].unique().astype(str)})\ndel sample_submission['ID_num']; gc.collect()\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge\ntrain = train.merge(loading, on=ID, how='left')\ntrain = train.merge(fnc, on=ID, how='left')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge\ntest = test.merge(loading, on=ID, how='left')\ntest = test.merge(fnc, on=ID, how='left')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = train[[ID]+TARGET_COLS].copy()\nFold = KFold(n_splits=N_FOLD, shuffle=True, random_state=SEED)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[TARGET_COLS])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nfolds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"#===========================================================\n# model\n#===========================================================\ndef run_single_lightgbm(param, train_df, test_df, folds, features, target, fold_num=0, categorical=[]):\n    \n    trn_idx = folds[folds.fold != fold_num].index\n    val_idx = folds[folds.fold == fold_num].index\n    logger.info(f'len(trn_idx) : {len(trn_idx)}')\n    logger.info(f'len(val_idx) : {len(val_idx)}')\n    \n    if categorical == []:\n        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features],\n                               label=target.iloc[trn_idx])\n        val_data = lgb.Dataset(train_df.iloc[val_idx][features],\n                               label=target.iloc[val_idx])\n    else:\n        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features],\n                               label=target.iloc[trn_idx],\n                               categorical_feature=categorical)\n        val_data = lgb.Dataset(train_df.iloc[val_idx][features],\n                               label=target.iloc[val_idx],\n                               categorical_feature=categorical)\n\n    oof = np.zeros(len(train_df))\n    predictions = np.zeros(len(test_df))\n\n    num_round = 10000\n\n    clf = lgb.train(param,\n                    trn_data,\n                    num_round,\n                    valid_sets=[trn_data, val_data],\n                    verbose_eval=100,\n                    early_stopping_rounds=100)\n\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_num\n\n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration)\n    \n    # RMSE\n    logger.info(\"fold{} RMSE score: {:<8.5f}\".format(fold_num, np.sqrt(mean_squared_error(target[val_idx], oof[val_idx]))))\n    \n    return oof, predictions, fold_importance_df\n\n\ndef run_kfold_lightgbm(param, train, test, folds, features, target, n_fold=5, categorical=[]):\n    \n    logger.info(f\"================================= {n_fold}fold lightgbm =================================\")\n    \n    oof = np.zeros(len(train))\n    predictions = np.zeros(len(test))\n    feature_importance_df = pd.DataFrame()\n\n    for fold_ in range(n_fold):\n        print(\"Fold {}\".format(fold_))\n        _oof, _predictions, fold_importance_df = run_single_lightgbm(param,\n                                                                     train,\n                                                                     test,\n                                                                     folds,\n                                                                     features,\n                                                                     target,\n                                                                     fold_num=fold_,\n                                                                     categorical=categorical)\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        oof += _oof\n        predictions += _predictions / n_fold\n\n    # RMSE\n    logger.info(\"CV RMSE score: {:<8.5f}\".format(np.sqrt(mean_squared_error(target, oof))))\n\n    logger.info(f\"=========================================================================================\")\n    \n    return feature_importance_df, predictions, oof\n\n    \ndef show_feature_importance(feature_importance_df, name):\n    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n            .groupby(\"Feature\")\n            .mean()\n            .sort_values(by=\"importance\", ascending=False)[:50].index)\n    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\n    plt.figure(figsize=(8, 16))\n    sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('Features importance (averaged/folds)')\n    plt.tight_layout()\n    plt.savefig(OUTPUT_DICT+f'feature_importance_{name}.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_dict = {}\noof_dict = {}\n\nfor TARGET in TARGET_COLS:\n    \n    logger.info(f'### LGB for {TARGET} ###')\n\n    target = train[TARGET]\n    test[TARGET] = np.nan\n\n    # features\n    cat_features = []\n    num_features = [c for c in test.columns if (test.dtypes[c] != 'object') & (c not in cat_features)]\n    features = num_features + cat_features\n    drop_features = [ID] + TARGET_COLS\n    features = [c for c in features if c not in drop_features]\n\n    if cat_features:\n        ce_oe = ce.OrdinalEncoder(cols=cat_features, handle_unknown='impute')\n        ce_oe.fit(train)\n        train = ce_oe.transform(train)\n        test = ce_oe.transform(test)\n        \n    lgb_param = {'objective': 'regression',\n             'metric': 'rmse',\n             'boosting_type': 'gbdt',\n             'learning_rate': 0.03,\n             'seed': SEED,\n             'max_depth': -1,\n             'verbosity': -1,\n            }\n\n    feature_importance_df, predictions, oof = run_kfold_lightgbm(lgb_param, train, test, folds, features, target, \n                                                                 n_fold=N_FOLD, categorical=cat_features)\n    \n    prediction_dict[TARGET] = predictions\n    oof_dict[TARGET] = oof\n    \n    show_feature_importance(feature_importance_df, TARGET)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_df = pd.DataFrame()\n\nfor TARGET in TARGET_COLS:\n    oof_df[TARGET] = oof_dict[TARGET]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/akurmukov/trends-starter-rf-0-168-lb-metric\n\ndef lb_metric(y_true, y_pred):\n    '''Computes lb metric, both y_true and y_pred should be DataFrames of shape n x 5'''\n    y_true = y_true[['age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2']]\n    y_pred = y_pred[['age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2']]\n    weights = np.array([.3, .175, .175, .175, .175])\n    return np.sum(weights * np.abs(y_pred.values - y_true.values).sum(axis=0) / y_true.values.sum(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = lb_metric(train, oof_df)\nlogger.info(f'Local Score: {score}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame()\n\nfor TARGET in TARGET_COLS:\n    tmp = pd.DataFrame()\n    tmp[ID] = [f'{c}_{TARGET}' for c in test[ID].values]\n    tmp['Predicted'] = prediction_dict[TARGET]\n    pred_df = pd.concat([pred_df, tmp])\n\nprint(pred_df.shape)\nprint(sample_submission.shape)\n\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_submission.drop(columns='Predicted').merge(pred_df, on=ID, how='left')\nprint(submission.shape)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}