{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor as RFR\nfrom sklearn.externals import joblib\nfrom time import time\nimport pickle\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc_df = pd.read_csv(\"../input/trends-assessment-prediction/fnc.csv\")\nloading_df = pd.read_csv(\"../input/trends-assessment-prediction/loading.csv\")\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\n\n\nlabels_df = pd.read_csv(\"../input/trends-assessment-prediction/train_scores.csv\")\nlabels_df['is_train'] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n\ndf.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [500]:\n    # Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\n    tic = time()\n    FNC_SCALE = 1/i\n\n    df[fnc_features] *= FNC_SCALE\n    test_df[fnc_features] *= FNC_SCALE\n\n    NUM_FOLDS = 3\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\n\n    features = loading_features + fnc_features\n\n    overal_score = 0\n    for target, c, w in [(\"age\", 100, 0.3), (\"domain1_var1\", 10, 0.175), (\"domain1_var2\", 10, 0.175), (\"domain2_var1\", 10, 0.175), (\"domain2_var2\", 10, 0.175)]:    \n        y_oof = np.zeros(df.shape[0])\n        y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n\n        for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n            train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n            train_df = train_df[train_df[target].notnull()]\n\n            # model = SVR(C=c, cache_size=3000.0)\n            model = RFR(n_estimators=100)\n            model.fit(train_df[features], train_df[target])\n            \n            s = pickle.dumps(model)\n            joblib.dump(model, 'model'+str(i)+'.pkl')\n\n            y_oof[val_ind] = model.predict(val_df[features])\n            y_test[:, f] = model.predict(test_df[features])\n\n        df[\"pred_{}\".format(target)] = y_oof\n        test_df[target] = y_test.mean(axis=1)\n\n        score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n        overal_score += w*score\n        print(target, np.round(score, 4))\n        print()\n\n    print(\"Overall score:\", np.round(overal_score, 4))\n    \n    sub_df = pd.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\n    sub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\n    sub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\n    assert sub_df.shape[0] == test_df.shape[0]*5\n    sub_df.head(10)\n    \n    sub_df.to_csv(\"submission\"+str(i)+\".csv\", index=False)\n    \n    toc = time()\n    print(\"Time taken for \"+str(i)+\" \"+str(toc-tic))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}