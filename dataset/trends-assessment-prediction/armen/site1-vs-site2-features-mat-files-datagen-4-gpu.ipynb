{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n!pip install -q nilearn\n!pip install -q dltk\n!pip install -q pycaret\n#!pip install -q tensorflow-io\n#import tensorflow_io as tfio\nfrom pycaret.regression import *\nimport nilearn\nfrom nilearn import plotting, masking, input_data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport scipy as sp\nimport scipy.stats\nimport pickle\nimport numpy.ma as ma\nfrom tensorflow.python.keras import backend as K\nimport copy\nfrom scipy.stats import ttest_ind\nfrom scipy.stats import mannwhitneyu\nimport seaborn as sns\nimport dltk\nimport SimpleITK as sitk\nfrom dltk.io.preprocessing import *\nimport random\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndirname = \"/kaggle/input/trends-assessment-prediction\"\nread_test_data = False\nread_train_data = False\ndownload_train_data = True\ndownload_test_data = False\nselect_column_pval_threshold = 0.1 #-1\nplot = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = nilearn.image.load_img(dirname + \"/fMRI_mask.nii\")\nmask.shape\nnilearn.plotting.plot_img(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = h5py.File(dirname + \"/fMRI_train/10001.mat\")['SM_feature'][()]\nprint(\"hdf5 mat shape:\", m.shape)\nm = np.swapaxes(m, 1, 3)\nm = np.moveaxis(m, 0, 3)\nprint(\"after axis moves:\", m.shape)\nim_4d = nilearn.image.new_img_like(mask, m)\nim_first = nilearn.image.new_img_like(mask, m[:,:,:,0])\nplotting.plot_img(im_first)\nim_filtered = nilearn.masking.apply_mask(im_4d, mask)\nprint(\"after apply_mask:\", type(im_filtered), im_filtered.shape)\nim_mean = nilearn.image.mean_img(im_4d)\nplotting.plot_img(im_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"after apply_mask\", im_filtered.shape)\nplt.plot(im_filtered[:53, :2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc = pd.read_csv(dirname + \"/fnc.csv\")\nicn = pd.read_csv(dirname + \"/ICN_numbers.csv\")\nloading = pd.read_csv(dirname + \"/loading.csv\")\ntscores = pd.read_csv(dirname + \"/train_scores.csv\")\ndata = fnc.merge(loading, on = \"Id\")\ndata_columns = list(data.columns)\ndata_columns.remove('Id')\noutput_columns = list(tscores.columns)\noutput_columns.remove('Id')\ndata = data.merge(tscores, on = \"Id\", how = \"outer\")\ndel fnc, icn, tscores\n#data['filename'] = np.where(data['age'].isnull(), dirname + '/fMRI_test/', dirname + '/fMRI_train/')\n#data['filename'] = data['filename'] + data['Id'].astype(str) + \".mat\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = pd.read_csv(dirname + \"/reveal_ID_site2.csv\")\nr2['site'] = \"site2\"\na = data.merge(r2, on = \"Id\", how = \"outer\")\na['site'] = a['site'].fillna(\"site1\")\na.head(15)\ns1 = a[a['site'] == \"site1\"]\ns2 = a[a['site'] == \"site2\"]\nprint(\"site1:\",s1.shape, \"site2:\", s2.shape)\nall_col_types = set([a[i].dtype for i in data_columns])\nprint(\"feature column types:\", all_col_types)\nnumeric_cols = [i for i in data_columns if a[i].dtype == 'int64' or a[i].dtype == 'float64']\nprint(\"number of numeric feature cols:\", len(numeric_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_site1_v_site2(s1, s2, numeric_cols, start_index = 0, end_index = None):\n    end_index = len(numeric_cols) if end_index is None else min(end_index, len(numeric_cols))\n    ncol = 4.0\n    rows = np.ceil(len(numeric_cols[start_index:end_index]) / ncol) \n    f, axes = plt.subplots(int(rows), int(ncol), figsize = (ncol * 5, rows * 5))\n    data = pd.concat([s1, s2], axis = 0)\n    for count, col in enumerate(numeric_cols[start_index:end_index]):\n        i = count // int(ncol)\n        j = count % int(ncol)\n        if rows > 1:\n            sns.boxplot(data = data, x = 'site', y = col, ax = axes[i][j])\n        else:\n            sns.boxplot(data = data, x = 'site', y = col, ax = axes[j])\nif plot:\n    plot_site1_v_site2(s1, s2, numeric_cols, start_index = 2, end_index= 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_test_stats(s1, s2, numeric_cols):\n    test_results = []\n    for col in numeric_cols:\n        t = ttest_ind(s1[col], s2[col], equal_var = False)\n        mw = mannwhitneyu(s1[col], s2[col], alternative = 'two-sided')\n        test_results.append([col, t[1], mw[1]])\n    test_results = pd.DataFrame(test_results, columns = ['name', 'ttest_pval', 'mannwhitney_pval'])\n    return test_results\ntest_results = compute_test_stats(s1, s2, numeric_cols)\nfig, axes = plt.subplots(1, 2)\n_ = axes[0].hist(test_results['ttest_pval'])\n_ = axes[1].hist(test_results['mannwhitney_pval'])\n_ = axes[0].set_title(\"t-test Pvalue distribution\")\n_ = axes[1].set_title(\"Mann-Whitney Pvalue distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of data colums before filtering:\", len(data_columns))\nif select_column_pval_threshold > 0:\n    if read_train_data or download_train_data:\n        select_columns = list(test_results[test_results['ttest_pval'] > select_column_pval_threshold]['name'])\n    else:\n        print(\"using pre-selected columns\")\n    data_columns = list(set(data_columns).intersection(select_columns))\nprint(\"number of data colums after applying\", select_column_pval_threshold, \"threshold on t-test pvalue:\", len(data_columns))\nremoved_columns = test_results[test_results['ttest_pval'] <= select_column_pval_threshold].sort_values('ttest_pval', ascending = True)['name']\nplot_site1_v_site2(s1, s2, removed_columns, start_index = 2, end_index= 6)\ndel a, s1, s2, all_col_types, numeric_cols, removed_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['Id'] + data_columns + output_columns]\ntrain_data = data[~data['age'].isnull()]\ntest_data = data[data['age'].isnull()]\ntest_data.drop(output_columns, axis = 1, inplace = True)\nprint(\"columns with missing values and their counts:\")\ncolumns_w_nan = list(train_data.columns[np.where(train_data.isnull().sum()>0)[0]])\nprint(train_data[columns_w_nan].isnull().sum())\ntrain_data.dropna(axis = 0, inplace = True)\n#train_data = train_data.fillna(train_data.median())\n#print(\"NAs filled with median\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.reset_index(drop = True, inplace = True)\ntrainx = train_data[data_columns]\ntrainy = train_data[output_columns]\ntest_data.reset_index(drop = True, inplace = True)\ntest_ids = test_data['Id']\ntestx = test_data[data_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_order = [1,2,0,4,3]\nfor i in output_order:\n    outname = output_columns[i]\n    d = setup(data = pd.concat([trainx, trainy[outname]], axis = 1), target = outname, silent = True)\n    br = tune_model('br', optimize = 'mse')\n    br = finalize_model(br)\n    out_train = predict_model(br, data = trainx).rename({'Label': outname}, axis = 1)\n    out_test = predict_model(br, data = testx).rename({'Label': outname}, axis = 1)\n    trainx = pd.concat([trainx, out_train[outname]], axis = 1)\n    testx = pd.concat([testx, out_test[outname]], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.concat([testx, test_ids], axis = 1)\noutput = output[['Id'] + output_columns]\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.melt(output, id_vars = \"Id\", value_vars = output_columns, var_name = \"target\", value_name = \"Predicted\")\noutput['Id'] = output['Id'].astype(str) + \"_\" + output['target']\noutput.drop('target', axis = 1, inplace = True)\noutput.to_csv(\"submission.csv\", index = False)\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, valid_data = train_test_split(train_data, test_size = 0.075, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape, valid_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.to_numpy()\nvalid_data = valid_data.to_numpy()\ntest_data = test_data.to_numpy()\ntrain_data[:,0] = train_data[:, 0].astype(int)\nvalid_data[:,0] = valid_data[:, 0].astype(int)\ntest_data[:,0] = test_data[:, 0].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape, valid_data.shape, test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_fnc_loading = False\nuse_mri_images = True\n\nNORMALIZE_SM = True\nTRANSFORM = True\nMASK_IMG = nilearn.image.load_img(dirname + \"/fMRI_mask.nii\")\nAVERAGE_SPACE = True\nAVERAGE_ON = 8\nAPPLY_MASK = False\nBATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\n\nclass hdf5_reader:\n    def read_hdf5(self, number, set_type):\n        #print(str(number))\n        if set_type == b\"test\":\n            m = h5py.File(dirname + \"/fMRI_test/\" + str(number) + \".mat\", 'r')['SM_feature'][()]    \n        else:\n            m = h5py.File(dirname + \"/fMRI_train/\" + str(number) + \".mat\", 'r')['SM_feature'][()]\n        m = np.swapaxes(m, 1, 3)\n        m = np.moveaxis(m, 0, 3)\n        return m #.reshape(-1)\n    \n    def collect_non_sm_features(self, number, set_type):\n        if set_type == b\"test\":\n            df = test_data[np.where(test_data[:,0] == number),1:]\n        elif set_type == b\"train\":\n            df = train_data[np.where(train_data[:,0] == number),1:]\n        if set_type == b\"valid\":\n            df = valid_data[np.where(valid_data[:,0] == number),1:]\n        return df.reshape(-1)\n    \n    def transform_sm_map(self, m):\n        m = nilearn.image.new_img_like(MASK_IMG, m)\n        if AVERAGE_SPACE:\n            if AVERAGE_ON > 0:\n                imgs = [nilearn.image.index_img(m, range(i,min(i+AVERAGE_ON, m.shape[-1]))) for i in range(0, m.shape[-1], AVERAGE_ON)]\n                #for i in imgs:\n                #    print(i.shape)\n                #imgs = [nilearn.image.new_img_like(MASK_IMG, m[:,:,:,i:min(i+AVERAGE_ON, m.shape[-1])]) for i in range(0, m.shape[-1], AVERAGE_ON)]\n                temp = [nilearn.image.mean_img(i) for i in imgs]\n                m = nilearn.image.concat_imgs(temp)\n            else:\n                m = nilearn.image.mean_img(m)\n        if APPLY_MASK:\n            m = nilearn.masking.apply_mask(m, MASK_IMG)\n        else:\n            m = nilearn.image.get_data(m)\n        if NORMALIZE_SM:\n            m = dltk.io.preprocessing.normalise_one_one(m)\n        #print(m.shape)\n        #print(m[:3,:3])\n        m = np.expand_dims(m, -1)\n        #print(m.shape)\n        return m.reshape(-1)\n        \n    def __call__(self, id_num, set_type):\n        id_num = int(id_num)\n        non_sm_features = self.collect_non_sm_features(id_num, set_type)\n        if use_mri_images:\n            sm_map = self.read_hdf5(id_num, set_type)\n            if TRANSFORM:\n                sm_map = self.transform_sm_map(sm_map)\n            else:\n                sm_map = sm_map.reshape(-1)\n        if use_mri_images and use_fnc_loading:\n            m = np.concatenate([sm_map, non_sm_features])\n        elif use_mri_images:\n            if set_type != b\"test\":\n                m = np.concatenate([sm_map, non_sm_features[-5:]])\n            else:\n                m = sm_map\n        elif use_fnc_loading:\n            m = non_sm_features\n        #print(non_sm_features.shape)\n        #print(sm_map.shape)\n        #print(m.shape)\n        m = m.reshape((1,-1))\n        return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nnum_avgs = (53 // AVERAGE_ON) + 1 if AVERAGE_ON > 0 else 53\nif TRANSFORM:\n    if APPLY_MASK and AVERAGE_SPACE:\n        sm_output_size = 58869\n        sms_shape, non_sm_len = ((58869,), len(data_columns))\n    elif APPLY_MASK:\n        sm_output_size = 3120057\n        sms_shape, non_sm_len = ((53, 58869), len(data_columns)) #time is the first dimension\n    elif AVERAGE_SPACE:\n        sm_output_size = 173628 * num_avgs\n        sms_shape, non_sm_len = ((53, 63, 52, num_avgs), len(data_columns)) #there is no time; averaged over time\n    else:\n        sm_output_size = 9202284\n        sms_shape, non_sm_len = ((53, 63, 52, 53), len(data_columns)) #time is the last dimension\nelse:\n    sm_output_size = 9202284\n    sms_shape, non_sm_len = ((53, 63, 52, 53), len(data_columns)) #time is the last dimension\n\nif use_mri_images and use_fnc_loading:\n    ds_output_size = sm_output_size + len(data_columns)\nelif use_mri_images:\n    ds_output_size = sm_output_size\nelif use_fnc_loading:\n    ds_output_size = len(data_columns)\nelse:\n    raise Exception(\"At least one of 'use_mri_images' or 'use_fnc_loading' should be True.\")\n    \ntrain_ds = tf.data.Dataset.from_tensor_slices(train_data[:,0]).shuffle(1024)\ntrain_ds = train_ds.interleave(lambda filename: tf.data.Dataset.from_generator(\n    hdf5_reader(), tf.float32, tf.TensorShape((ds_output_size + 5,)), args=(filename, \"train\")), cycle_length = AUTOTUNE)\ntrain_ds = (train_ds.map(lambda x: (x[:-5], x[-5:]))\n.cache()\n.repeat()\n.batch(BATCH_SIZE)\n)\n\n\nvalid_ds = tf.data.Dataset.from_tensor_slices(valid_data[:,0])#.shuffle(1024)\nvalid_ds = valid_ds.interleave(lambda filename: tf.data.Dataset.from_generator(\n    hdf5_reader(), tf.float32, tf.TensorShape((ds_output_size + 5,)), args=(filename, \"valid\")), cycle_length = AUTOTUNE)\nvalid_ds = (valid_ds.map(lambda x: (x[:-5], x[-5:]))\n.cache()\n.repeat()\n.batch(VALID_BATCH_SIZE)\n)\n\n\ntest_ds = tf.data.Dataset.from_tensor_slices(test_data[:,0])\ntest_ds = (test_ds.interleave(lambda filename: tf.data.Dataset.from_generator(\n    hdf5_reader(), tf.float32, tf.TensorShape((ds_output_size,)), args=(filename, \"test\")), cycle_length = AUTOTUNE)\n.cache()\n.repeat()\n.batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = list(train_ds.take(1).as_numpy_iterator())\nh2 = list(valid_ds.take(1).as_numpy_iterator())\nh3 = list(test_ds.take(1).as_numpy_iterator())\nprint(h[0][0].shape, h[0][1].shape, sms_shape)\nprint(h3[0].shape)\ndel h, h2, h3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LRSelector(tf.keras.callbacks.Callback):\n    def __init__(self, min_lr, max_lr, factor = 2, varname = \"lr\", method = None):\n        self.history = {}\n        self.iteration = 0\n        self.minlr = min_lr\n        self.maxlr = max_lr\n        self.factor = factor\n        self.currentlr = self.minlr\n        self.varname = varname\n        self.method = method\n        #self.num_iterations = math.log(self.maxlr / self.minlr, self.factor)\n        #print(self.num_iterations)\n        \n    def on_train_begin(self, logs):\n        if self.varname == \"lr\":\n            K.set_value(self.model.optimizer.lr, self.minlr)\n        elif self.varname == \"momentum\":\n            K.set_value(self.model.optimizer.momentum, self.minlr)\n        #self.num_iterations = math.log(self.maxlr / self.minlr, self.factor)\n        \n    def compute_lr(self):\n        if self.method == \"sum\":\n            lr = self.minlr + self.iteration * self.factor\n        else:\n            lr = self.minlr * np.power(self.factor, self.iteration)\n        return lr\n        \n    def on_batch_end(self, batch, logs = {}):\n        self.iteration += 1\n        self.history.setdefault('loss', []).append(logs['loss'])\n        self.history.setdefault('lr', []).append(self.currentlr)\n        self.currentlr = self.compute_lr()\n        if self.varname == \"lr\":\n            K.set_value(self.model.optimizer.lr, self.currentlr)\n        elif self.varname == \"momentum\":\n            K.set_value(self.model.optimizer.momentum, self.currentlr)\n        #print(\"in cycler\")\n        #print(logs.keys())\n        #print(logs['loss'])\n        #print(batch)\n        \nclass LRScheduler2(tf.keras.callbacks.Callback):\n    def __init__(self, start_lr, max_lr, epochs, min_lr = 1e-3, stable_percent = 0.2, stable_factor = 0.2, constant = 0):\n        self.stable_steps_start = epochs - np.ceil(epochs * stable_percent)\n        self.constant_start = self.stable_steps_start - constant\n        self.mid_step = self.constant_start\n        self.slope = (max_lr - start_lr) / self.mid_step\n        self.startlr = start_lr\n        self.maxlr = max_lr\n        self.stable_factor = stable_factor\n        self.minlr = min_lr\n    \n    def on_train_begin(self, logs):\n        if hasattr(self, \"model\"):\n            K.set_value(self.model.optimizer.lr, self.startlr)\n    \n    def on_epoch_end(self, epoch, logs = {}):\n        if epoch <= self.mid_step:\n            lr = self.startlr + (epoch * self.slope)\n        elif epoch < self.stable_steps_start:\n            lr = self.maxlr\n        else:\n            lr = min((self.maxlr - self.minlr) * self.stable_factor**(epoch - self.stable_steps_start) + self.minlr, self.maxlr)\n        logs.setdefault('lr', []).append(lr)\n        #return(lr)\n        if hasattr(self, \"model\"):\n            K.set_value(self.model.optimizer.lr, lr)\n            print(self.model.optimizer.lr.numpy())\n        else:\n            return lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(model_name, use_fnc_loading, use_mri_images):\n    if model_name == \"1d_model\":\n        model = build_1d_model(use_fnc_loading, use_mri_images)\n    elif model_name == \"lstm_on_masked\":\n        model = build_lstm_on_masked_seq(use_fnc_loading, use_mri_images)\n    elif model_name == \"3d_on_avg_space\":\n        #model = build_3d_mode(sms_shape, non_sm_feature_count)\n        model = build_3d_model_avg_space(use_fnc_loading, use_mri_images)\n    elif model_name == \"3d_on_mri_sequences\":\n        model = build_3d_model_mri_seq(use_fnc_loading, use_mri_images)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_non_sm_structure(non_sm_features_layer):\n    x = tf.keras.layers.Dense(1024)(non_sm_features_layer)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = tf.keras.layers.Dense(768)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = tf.keras.layers.Dense(64)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = tf.keras.layers.Dense(768)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = tf.keras.layers.Dense(1024)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_1d_model(use_fnc_loading, use_mri_images):\n    features = ds_output_size\n    sms_feature_len = np.prod(sms_shape)\n    print(features)\n    \n    input_layer = tf.keras.layers.Input(shape=(features,))\n    \n    '''\n    if(use_fnc_loading and use_mri_images):\n        input_layer2 = input_layer\n    elif use_fnc_loading:\n        #input_layer = tf.keras.layers.Lambda(lambda x: x[:,-non_sm_len:])(input_layer)\n        input_layer2 = input_layer\n    elif use_mri_images:\n        #input_layer = tf.keras.layers.Lambda(lambda x: x[:,:-non_sm_len])(input_layer)\n        input_layer2 = input_layer\n    else:\n        raise Exception(\"At least one of use_fnc_loading or use_mri_images should be True\")\n    '''\n    x = get_non_sm_structure(input_layer)\n    x = tf.keras.layers.Dense(5)(x)\n    output_layer = tf.keras.layers.Activation('relu')(x)\n\n    model = tf.keras.Model(input_layer, output_layer)\n    \n    optimizer = tf.optimizers.Adam()\n    \n    model.compile(optimizer, loss='mse', metrics=['mae', 'mape'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_lstm_on_masked_seq(use_fnc_loading, use_mri_images):\n    number_of_series = 53\n    series_len = sms_shape[1]\n    \n    features = ds_output_size\n    sms_feature_len = np.prod(sms_shape)\n    \n    input_layer = tf.keras.layers.Input(shape=(features,))\n    \n    if use_fnc_loading and use_mri_images:\n        sm_features_layer = tf.keras.layers.Lambda(lambda x: x[:,:-non_sm_len])(input_layer)\n        non_sm_features_layer = tf.keras.layers.Lambda(lambda x: x[:,-non_sm_len:])(input_layer)\n    else:\n        sm_features_layer = input_layer\n        non_sm_features_layer = input_layer\n    \n    sm_features_layer = tf.keras.layers.Reshape(sms_shape)(sm_features_layer)\n    sm_features_layer = tf.keras.layers.GRU(16, activation = \"tanh\", return_sequences=True)(sm_features_layer)\n    sm_features_layer = tf.keras.layers.GRU(32, activation = \"tanh\", return_sequences=True)(sm_features_layer)\n    sm_features_layer = tf.keras.layers.GRU(32, activation = \"tanh\", return_sequences=False)(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Dense(512, activation = \"relu\")(sm_features_layer)\n    print(\"sm_layer created\")\n    \n    if use_fnc_loading:\n        non_sm_features_layer = get_non_sm_structure(non_sm_features_layer)\n    print(\"non_sm created\")\n    \n    if use_fnc_loading and use_mri_images:\n        print(\"concating both\")\n        squeeze_layer = tf.keras.layers.concatenate([sm_features_layer, non_sm_features_layer])\n    elif use_fnc_loading:\n        print(\"onluy fnc loading\")\n        squeeze_layer = non_sm_features_layer\n    elif use_mri_images:\n        print(\"only images\")\n        squeeze_layer = sm_features_layer\n    else:\n        raise Exception(\"At least one of use_fnc_loading or use_mri_images should be True\")\n    \n    x = tf.keras.layers.Dense(1024, activation = \"relu\")(squeeze_layer)\n    x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n    output_layer = tf.keras.layers.Dense(5, activation = \"relu\")(x)\n    \n    model = tf.keras.Model(input_layer, output_layer)\n    \n    optimizer = tf.optimizers.Adam()\n    \n    model.compile(optimizer, loss='mse', metrics=['mae', 'mape'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_3d_model_avg_space(use_fnc_loading, use_mri_images):\n    features = ds_output_size\n    sms_feature_len = np.prod(sms_shape)\n    \n    input_layer = tf.keras.layers.Input(shape=(features,))\n    if use_fnc_loading and use_mri_images:\n        sm_features_layer = tf.keras.layers.Lambda(lambda x: x[:,:-non_sm_len])(input_layer)\n        non_sm_features_layer = tf.keras.layers.Lambda(lambda x: x[:,-non_sm_len:])(input_layer)\n    else:\n        sm_features_layer = input_layer\n        non_sm_features_layer = input_layer\n    \n\n    sm_features_layer = tf.keras.layers.Reshape(sms_shape)(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, -1))(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Conv3D(32, (3,3,3), activation = \"relu\")(sm_features_layer)\n    sm_features_layer = tf.keras.layers.AveragePooling3D((2,2,2))(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Conv3D(32, (3,3,3), activation = \"relu\")(sm_features_layer)\n    sm_features_layer = tf.keras.layers.AveragePooling3D((2,2,2))(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Conv3D(16, (3,3,3), activation = \"relu\")(sm_features_layer)\n    #sm_features_layer = tf.keras.layers.AveragePooling3D((2,2,2))(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Flatten()(sm_features_layer)\n    sm_features_layer = tf.keras.layers.Dense(1024, activation = \"relu\")(sm_features_layer)\n    #sm_features_layer = tf.keras.layers.Dense(128, activation = \"relu\")(sm_features_layer)  \n    \n    if use_fnc_loading:\n        non_sm_features_layer = get_non_sm_structure(non_sm_features_layer)\n    \n    if use_fnc_loading and use_mri_images:\n        squeeze_layer = tf.keras.layers.concatenate([sm_features_layer, non_sm_features_layer])\n    elif use_fnc_loading:\n        squeeze_layer = non_sm_features_layer\n    elif use_mri_images:\n        squeeze_layer = sm_features_layer\n    else:\n        raise Exception(\"At least one of use_fnc_loading or use_mri_images should be True\")\n        \n    x = tf.keras.layers.Dense(512, activation = \"relu\")(squeeze_layer)\n    x = tf.keras.layers.Dense(256, activation = \"relu\")(x)\n    output_layer = tf.keras.layers.Dense(5, activation = 'linear')(x)\n    model = tf.keras.Model(input_layer, output_layer)\n    \n    optimizer = tf.optimizers.Adam()\n    \n    model.compile(optimizer, loss='mse', metrics=['mae', 'mape'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_3d_model_mri_seq(use_fnc_loading, use_mri_images):\n    number_of_pictures = sms_shape[-1]\n    single_pic_shape = sms_shape[:-1]\n    single_pic_features = np.prod(single_pic_shape)\n    print(single_pic_shape)\n    features = ds_output_size\n    sms_feature_len = np.prod(sms_shape)\n    \n    input_layer = tf.keras.layers.Input(shape=(features,))\n    if use_fnc_loading and use_mri_images:\n        sm_features_layer = tf.keras.layers.Lambda(lambda x: x[:,:-non_sm_len])(input_layer)\n        non_sm_features_layer = tf.keras.layers.Lambda(lambda x: x[:,-non_sm_len:])(input_layer)\n    else:\n        sm_features_layer = input_layer\n        non_sm_features_layer = input_layer\n    \n    sm_outputs = []\n    for i in range(number_of_pictures):\n        single_image_layer = tf.keras.layers.Lambda(lambda x: x[:,(i*single_pic_features):((i+1)*single_pic_features)])(sm_features_layer)\n        single_image_layer = tf.keras.layers.Reshape(single_pic_shape)(single_image_layer)\n        single_image_layer = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, -1))(single_image_layer)\n        single_image_layer = tf.keras.layers.Conv3D(4, (7,7,7), activation = \"relu\", data_format=\"channels_last\")(single_image_layer)\n        single_image_layer = tf.keras.layers.AveragePooling3D((3,3,3))(single_image_layer)\n        single_image_layer = tf.keras.layers.Conv3D(4, (3,3,3), activation = \"relu\", data_format=\"channels_last\")(single_image_layer)\n        single_image_layer = tf.keras.layers.Flatten()(single_image_layer)\n        single_image_layer = tf.keras.layers.Dense(5, activation = \"relu\")(single_image_layer)\n        sm_outputs.append(single_image_layer)\n    tf.print(len(sm_outputs))\n    sm_features_layer = tf.keras.layers.concatenate(sm_outputs)\n    \n    if use_fnc_loading:\n        non_sm_features_layer = get_non_sm_structure(non_sm_features_layer)\n    \n    if use_fnc_loading and use_mri_images:\n        squeeze_layer = tf.keras.layers.concatenate([sm_features_layer, non_sm_features_layer])\n    elif use_fnc_loading:\n        squeeze_layer = non_sm_features_layer\n    elif use_mri_images:\n        squeeze_layer = sm_features_layer\n    else:\n        raise Exception(\"At least one of use_fnc_loading or use_mri_images should be True\")\n    \n    x = tf.keras.layers.Dense(32, activation = \"relu\")(squeeze_layer)\n    x = tf.keras.layers.Dense(32, activation = \"relu\")(x)\n    x = tf.keras.layers.Dense(16, activation = \"relu\")(x)\n    output_layer = tf.keras.layers.Dense(5, activation = \"relu\")(x)\n    \n    model = tf.keras.Model(input_layer, output_layer)\n    \n    optimizer = tf.optimizers.Adam()\n    \n    model.compile(optimizer, loss='mse', metrics=['mae', 'mape'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_name = \"3d_on_avg_space\"\nmodel_name = \"3d_on_mri_sequences\"\n#model_name = \"lstm_on_masked\"\n#model_name = \"1d_model\"\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n\n    # instantiate a distribution strategy\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    with tpu_strategy.scope():\n        model = build_model(model_name, use_fnc_loading, use_mri_images)\n    print(\"TPU successfully set up!\")\nexcept:\n    print(\"running without TPU\")\n    model = build_model(model_name, use_fnc_loading, use_mri_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.summary()\ntf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nSTEP_SIZE_TRAIN = len(train_data[0]) // BATCH_SIZE\nSTEP_SIZE_VALID = len(valid_data[0]) // VALID_BATCH_SIZE\nlr_selector = LRSelector(min_lr = 1e-3, max_lr = 10, factor = 1.05)\na = LRScheduler2(start_lr = 0.003, max_lr = 0.003, epochs = epochs, min_lr = 0.003, constant = 2, stable_percent = 0.5, stable_factor = 0.8)\n\n\nls = [a.on_epoch_end(i) for i in range(epochs)]\n#plt.plot(ls)\n#plt.show()\nscheduler = copy.copy(a)\n\n'''\nmodel.fit(train_ds, \n            #class_weight = (0.3, 0.175, 0.175, 0.175, 175), \n            steps_per_epoch = STEP_SIZE_TRAIN,\n            #callbacks = [lr_selector],\n            callbacks = [scheduler],\n            epochs = epochs,\n            validation_data = valid_ds,\n            validation_steps = STEP_SIZE_VALID\n            )\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#limit = 100\n#print(len(lr_selector.history['lr']))\n#plt.plot(lr_selector.history['lr'][:limit], (lr_selector.history['loss'][:limit]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}