{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\n\nimport numpy as np\nimport pandas as pd\n\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore all csv","metadata":{}},{"cell_type":"code","source":"# Age and 4 anonymized targets, 443 partially missed observations\ntrain_scores = pd.read_csv('/kaggle/input/trends-assessment-prediction/train_scores.csv').sort_values(by='Id')\n\n# Somehow preprocessed morphometry (after group ICA), simplest feature set\nloadings = pd.read_csv('/kaggle/input/trends-assessment-prediction/loading.csv')\n\n# resting-state fMRI Functional Network Connectivity matrices. \n# In simple setting, these are cross-correlations (in this case something more sophisticated) between\n# every pair of brain regions presented in train/test *.mat\nfnc = pd.read_csv('/kaggle/input/trends-assessment-prediction/fnc.csv')\n\n# Submit Age and 4 scores for test ids\nsample = pd.read_csv('/kaggle/input/trends-assessment-prediction/sample_submission.csv')\n\n# List of some of subjects from test set whose data were collected from different scanner\nreveal = pd.read_csv('/kaggle/input/trends-assessment-prediction/reveal_ID_site2.csv')\n\n# 53 unique numbers between 2 and 99 (somehow related to brain regions? regions keys?)\nicn_nums = pd.read_csv('/kaggle/input/trends-assessment-prediction/ICN_numbers.csv')\n\n# Brain template\n# /kaggle/input/trends-assessment-prediction/fMRI_mask.nii \n\n# train/test fMRI spatial maps\n# *.mat","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loadings.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 53 * 52 / 2 = 1378 + Id column\nfnc.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring fnc","metadata":{}},{"cell_type":"code","source":"import re\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = re.compile('\\d+')\ncol_dict = {}\nfor col in fnc.columns:\n    ind = r.findall(col)\n    if ind:\n        col_dict[col] = [int(i) for i in ind]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_matrix(df_row, return_idx=False):\n    matrix = np.zeros((100, 100))\n    for col in df_row.index[1:]:\n        i, j = col_dict[col]\n        matrix[i, j] = df_row[col]\n    matrix += matrix.T\n    \n    idx = np.array([ 2,  3,  4,  5,  7,  8,  9, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23,\n                     27, 32, 33, 37, 38, 40, 43, 45, 48, 51, 53, 54, 55, 56, 61, 62, 63,\n                     66, 67, 68, 69, 70, 71, 72, 77, 79, 80, 81, 83, 84, 88, 93, 94, 96,\n                     98, 99])\n    if return_idx:\n        return matrix[:, idx][idx, :], idx \n    return matrix[:, idx][idx, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"degrees = []\nfor row in tqdm(fnc.iterrows()):\n    mat = get_matrix(row[1])\n    degrees.append(mat.sum(axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, idx = get_matrix(fnc.iloc[0], return_idx=True)\ndegrees = pd.DataFrame(degrees, columns=idx)\ndegrees['Id'] = fnc['Id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(glob('/kaggle/input/trends-assessment-prediction/fMRI_train/*.mat')), len(glob('/kaggle/input/trends-assessment-prediction/fMRI_test/*.mat'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sbj = glob('/kaggle/input/trends-assessment-prediction/fMRI_train/*.mat')[10]\n\nwith h5py.File(sbj, 'r') as f:\n    mat = f['SM_feature'][()]\n    mat = np.moveaxis(mat, [0,1,2,3], [3,2,1,0])\n    \nprint(mat.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build a model\n\nupd1. add mape_scorer\n\nupd2. add fnc to features\n\nupd3. add degrees features\n\nupd4. add fcn/500 from https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging , switch to Ridge regression\n\ntodo: fit on all available targets (currently observation is dropped if any target is missing)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train/test Ids\ntrain_ids = sorted(loadings[loadings['Id'].isin(train_scores.Id)]['Id'].values)\ntest_ids = sorted(loadings[~loadings['Id'].isin(train_scores.Id)]['Id'].values)\n\n# generate test DataFrame\ntest_prediction = pd.DataFrame(test_ids, columns=['Id'], dtype=str)\n\ntarget_columns = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\nfnc_columns = fnc.columns[1:]\ndegrees_columns = degrees.columns[:-1]\n\n# generate X, targets\ndata = pd.merge(loadings, train_scores, on='Id')#.dropna()\ndata = pd.merge(data, fnc, on='Id')\ndata = pd.merge(data, degrees, on='Id')\n\n# X_train = data.drop(list(target_columns), axis=1).drop('Id', axis=1)\n# y_train = data[list(target_columns)]\n\nX_test = pd.merge(loadings[loadings.Id.isin(test_ids)], fnc, on='Id')\nX_test = pd.merge(X_test, degrees, on='Id').drop('Id', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Implement mape scorer\n\nSince lb uses weighted mape (all targets are > 0), we will implement mape scorer to pass into GridSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\ndef MAPE(y_true, y_pred, **kwargs):\n    '''Returns MAPE between y_true and y_pred'''\n    return np.sum(np.abs(y_true - y_pred)) / y_true.sum()\n\nmape_scorer = make_scorer(MAPE, greater_is_better=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up the model\n# model = RandomForestRegressor(\n#     max_depth=5,\n#     min_samples_split=10,\n#     min_samples_leaf=5\n# )\n\n# model = Lasso()\nmodel = Ridge()\n# model = SVR()\n\n\ncv = KFold(n_splits = 5, shuffle=True, random_state=29)\n\n# grid = {\n#     'max_depth':[2, 5, 10],\n#     'n_estimators':[20, 30],\n#     'max_features':[0.1, 0.2, 0.3, 0.5]\n# }\n\ngrid = {\n    'alpha': [0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.5, 1, 5, 10, 15, 20, 30, 50, 75, 100]\n}\n# grid = {\n#     'C': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.5, 0.85, 1, 3, 5, 10]\n# }\n\n# grid = {\n#     'alpha': np.linspace(0.0001, 0.001, 20)\n# }\ngs = GridSearchCV(model, grid, n_jobs=-1, cv=cv, verbose=0, scoring=mape_scorer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# age 0.1446\n\n# domain1_var1 0.1512\n\n# domain1_var2 0.1513\n\n# domain2_var1 0.1819\n\n# domain2_var2 0.1763","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\nbest_models = {}\ntotal_score = []\n\nfor col in target_columns:\n    \n    X_train = data.dropna(subset=[col], axis=0).drop(list(target_columns), axis=1).drop('Id', axis=1)\n    X_train[fnc_columns] /= 600\n    y_train = data.dropna(subset=[col], axis=0)[col]\n    \n    gs.fit(X_train, y_train)\n    best_models[col] = gs.best_estimator_\n    \n    # Train performance\n    y_pred = cross_val_predict(gs.best_estimator_, X_train, y_train, cv=cv, n_jobs=-1)\n    total_score.append(MAPE(y_train, y_pred))\n    print(col, MAPE(y_train, y_pred))\n\ntotal_score = np.array(total_score)\nprint(f'Total score: {np.sum(total_score*[.3, .175, .175, .175, .175])}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pred(col, model):\n    X_train = data.dropna(subset=[col], axis=0).drop(list(target_columns), axis=1).drop('Id', axis=1)\n    X_train[fnc_columns] /= 600\n    y_train = data.dropna(subset=[col], axis=0)[col]\n    \n    # Train performance\n    y_pred = cross_val_predict(model, X_train, y_train, cv=cv, n_jobs=-1)\n    return y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting test\nX_test[fnc_columns] /= 600\n\nfor col in target_columns:\n    test_prediction[col] = best_models[col].predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the lb metric on local cv\n\n# def lb_metric(y_true, y_pred):\n#     '''Computes lb metric, both y_true and y_pred should be DataFrames of shape n x 5'''\n#     y_true = y_true[['age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2']]\n#     y_pred = y_pred[['age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2']]\n    \n#     weights = np.array([.3, .175, .175, .175, .175])\n#     return np.sum(weights * np.abs(y_pred.values - y_true.values).sum(axis=0) / y_train.values.sum(axis=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_prediction_cv = {}\n# for col in target_columns:\n#     train_prediction_cv[col] = cross_val_predict(best_models[col], X_train, y_train[col], cv = cv, n_jobs=-1)\n# train_prediction_cv = pd.DataFrame(train_prediction_cv)\n\n# lb_metric(y_train, train_prediction_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making a submission","metadata":{}},{"cell_type":"code","source":"def make_sub(test_prediction):\n    '''Converts 5877 x 6 DataFrame of predictions into 29385 x 2 DataFrame with valid Id'''\n    target_columns = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\n    _columns = (0,1,2,3,4)\n    tst = test_prediction.rename(columns=dict(zip(target_columns, _columns)))\n    tst = tst.melt(id_vars='Id',\n           value_vars=_columns,\n           value_name='Predicted')\n\n    tst['target_type'] = tst.variable.map(dict(zip(_columns, target_columns)))\n    tst['Id_'] = tst[['Id', 'target_type']].apply(lambda x: '_'.join((str(x[0]), str(x[1]))), axis=1)\n\n    return tst.sort_values(by=['Id', 'variable'])\\\n              .drop(['Id', 'variable', 'target_type'],axis=1)\\\n              .rename(columns={'Id_':'Id'})\\\n              .reset_index(drop=True)\\\n              [['Id', 'Predicted']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = make_sub(test_prediction)\n\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('ridge_mape_500.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}