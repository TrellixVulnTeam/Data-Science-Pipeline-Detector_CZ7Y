{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport os\nimport math\nimport h5py\nimport random\nimport nilearn as nl\nfrom nilearn import image, datasets, plotting\nfrom nilearn.image import get_data\nfrom random import randint\nfrom tqdm.notebook import tqdm\nfrom sklearn.impute import KNNImputer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"source = \"../input/trends-assessment-prediction\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_train = []\nfor name in os.listdir(source+'/fMRI_train'):\n    img_train.append(int(name[:5]))\nimg_train.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = h5py.File(source+'/fMRI_train/10001.mat', 'r')['SM_feature'][()]\nfor i in range(53):\n    print(i)\n    x_axis = t[:,:,i].transpose(1,2,0)\n    plt.imshow(x_axis[:, :,28], cmap=plt.cm.Set1)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I think the 17th picture is the most representative. But you can try another one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Let's create a dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_x = np.array([])\nfor id_img in tqdm(img_train):\n    t = h5py.File(source+f'/fMRI_train/{id_img}.mat', 'r')['SM_feature'][()]\n    x_axis = t[:,:,17].transpose(1,2,0)\n    \n    if len(X_train_x) == 0:\n        X_train_x = x_axis[:, :,28]\n    elif X_train_x.shape[1] == 53:\n        X_train_x = np.append([X_train_x], [x_axis[:, :,28]], axis=0)\n    else:\n        X_train_x = np.append(X_train_x, [x_axis[:, :,28]], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_test = []\nfor name in os.listdir(source+'/fMRI_test'):\n    img_test.append(int(name[:5]))\nimg_test.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_x = np.array([])\nfor id_img in tqdm(img_test):\n\n    t = h5py.File(source+f'/fMRI_test/{id_img}.mat', 'r')['SM_feature'][()]\n    x_axis = t[:,:,17].transpose(1,2,0)\n    \n    if len(X_test_x) == 0:\n        X_test_x = x_axis[:, :,28]\n    elif X_test_x.shape[1] == 53:\n        X_test_x = np.append([X_test_x], [x_axis[:, :,28]], axis=0)\n    else:\n        X_test_x = np.append(X_test_x, [x_axis[:, :,28]], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_x = X_train_x.reshape(X_train_x.shape[0], 1, 52, 53)\nX_test_x = X_test_x.reshape(X_test_x.shape[0], 1, 52, 53)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/train_scores.csv\")\nfnc = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/fnc.csv\")\nloading = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/loading.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/trends-assessment-prediction/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = train_scores.drop(['Id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute = KNNImputer(n_neighbors=20)\ny_train = impute.fit_transform(train_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's create CNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Convolution2D, MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weighted_NAE(yTrue,yPred):\n    weights = K.constant([.3, .175, .175, .175, .175], dtype='float32')\n    \n    return K.sum(weights*K.sum(K.abs(yTrue-yPred))/K.sum(yPred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(BatchNormalization()) \nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,52,53), data_format='channels_first'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization()) \nmodel.add(Dropout(0.4))\nmodel.add(Convolution2D(32, (3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4)) \nmodel.add(Flatten())\nmodel.add(BatchNormalization()) \nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(5, activation='relu'))\n\nmodel.compile(loss='mse',\n              optimizer='adam',\n              metrics=[weighted_NAE])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, mode='min',\n                              patience=3, min_lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train_x, y_train, epochs=20, batch_size=1024, validation_split=0.1, shuffle=True, callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, 21)\nplt.plot(epochs, loss_values, 'b', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.figure(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=pd.DataFrame()\npred[\"Id\"]=sample_submission.Id\npred[\"Predicted\"]=model.predict(X_test_x).flatten()\npred.to_csv('out.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# You can also improve the model or use other axes when cutting pictures. Good luck!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}