{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip freeze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install chainer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install joypy --progress-bar off","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install cupy --no-cache-dir -vvvv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.0.13.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.6/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.6\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cudf\nimport cupy as cp\nfrom cuml.neighbors import KNeighborsRegressor\nfrom cuml import SVR\nfrom cuml.linear_model import Ridge, Lasso\nfrom sklearn.model_selection import KFold\nfrom cuml.metrics import mean_absolute_error, mean_squared_error\n\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc_df = cudf.read_csv(\"../input/trends-assessment-prediction/fnc.csv\")\nloading_df = cudf.read_csv(\"../input/trends-assessment-prediction/loading.csv\")\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\n\n\nlabels_df = cudf.read_csv(\"../input/trends-assessment-prediction/train_scores.csv\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n\ndf.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\nFNC_SCALE = 1/500\n\ndf[fnc_features] *= FNC_SCALE\ntest_df[fnc_features] *= FNC_SCALE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nNUM_FOLDS = 7\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\n\nfeatures = loading_features + fnc_features\n\noveral_score = 0\nfor target, c, w, ff in [(\"age\", 60, 0.3, 0.55), (\"domain1_var1\", 12, 0.175, 0.2), (\"domain1_var2\", 8, 0.175, 0.2), (\"domain2_var1\", 9, 0.175, 0.22), (\"domain2_var2\", 12, 0.175, 0.22)]:    \n    y_oof = np.zeros(df.shape[0])\n    y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n    \n    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n        train_df = train_df[train_df[target].notnull()]\n\n        model_1 = SVR(C=c, cache_size=3000.0)\n        model_1.fit(train_df[features].values, train_df[target].values)\n        model_2 = Ridge(alpha = 0.0001)\n        model_2.fit(train_df[features].values, train_df[target].values)\n        val_pred_1 = model_1.predict(val_df[features])\n        val_pred_2 = model_2.predict(val_df[features])\n        \n        test_pred_1 = model_1.predict(test_df[features])\n        test_pred_2 = model_2.predict(test_df[features])\n        \n        val_pred = (1-ff)*val_pred_1+ff*val_pred_2\n        val_pred = cp.asnumpy(val_pred.values.flatten())\n        test_pred = (1-ff)*test_pred_1+ff*test_pred_2\n        test_pred = cp.asnumpy(test_pred.values.flatten())\n\n        y_oof[val_ind] = val_pred\n        y_test[:, f] = test_pred\n        \n    df[\"pred_{}\".format(target)] = y_oof\n    test_df[target] = y_test.mean(axis=1)\n    \n    score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n    mae = mean_absolute_error(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n    rmse = np.sqrt(mean_squared_error(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values))\n    overal_score += w*score\n    print(target, np.round(score, 8))\n    print(target, np.round(score, 4))\n    print(target, 'mean absolute error:', np.round(mae, 8))\n    print(target, ' root mean square error:', np.round(rmse, 8))\n    print()\n    \nprint(\"Overal score:\", np.round(overal_score, 8))\nprint(\"Overal score:\", np.round(overal_score, 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = cudf.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission_rapids_ensemble.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}