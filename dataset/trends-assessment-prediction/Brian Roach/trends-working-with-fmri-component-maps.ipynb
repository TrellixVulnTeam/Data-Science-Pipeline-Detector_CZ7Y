{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Making use of the fMRI images in .mat files\n\nMost of the notebooks and discussion posted on this comp focuses on the table data.  The fMRI maps provided are the spatial weights for each individual subject for the spatially constrained group ICA derived independent components.  The associated time series for each component is what gets correlated with the time series of other components to generate the fnc data table.  So, it might be of interest to use these maps or attempt to derive variables from them.  This notebook provides an example of how one could do this.\n\nMost of the first few blocks of code are lifted from:\nhttps://www.kaggle.com/bbradt/loading-and-exploring-spatial-maps\n\nThanks to [@bbradt](https://www.kaggle.com/bbradt) for showing how to load and transform mats to nifti images.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"\nFrom: https://www.kaggle.com/bbradt/loading-and-exploring-spatial-maps\n\"\"\"\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy import stats\nfrom scipy.ndimage.morphology import generate_binary_structure\nfrom scipy.ndimage.measurements import label\nimport numpy as np # linear algebra\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport nibabel as nib\nimport h5py\nimport matplotlib.pyplot as plt\nfrom nilearn.masking import apply_mask\nfrom nilearn.masking import unmask\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nmask_filename = '../input/trends-assessment-prediction/fMRI_mask.nii'\n#subject_filename = '../input/trends-assessment-prediction/fMRI_train/10004.mat'\nsubject_filename = '../input/trends-assessment-prediction/fMRI_test/10030.mat'\n# smri_filename = 'ch2better.nii'\nmask_niimg = nl.image.load_img(mask_filename)\n\ndef load_subject(filename, mask_niimg):\n    \"\"\"\n    Load a subject saved in .mat format with\n        the version 7.3 flag. Return the subject\n        niimg, using a mask niimg as a template\n        for nifti headers.\n        \n    Args:\n        filename    <str>            the .mat filename for the subject data\n        mask_niimg  niimg object     the mask niimg object used for nifti headers\n    \"\"\"\n    subject_data = None\n    with h5py.File(subject_filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n    return subject_niimg","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#example...\n\nsubject_niimg = load_subject(subject_filename, mask_niimg)\nprint(\"Image shape is %s\" % (str(subject_niimg.shape)))\nnum_components = subject_niimg.shape[-1]\nprint(\"Detected {num_components} spatial maps\".format(num_components=num_components))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(subject_niimg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now we have one subject's image as a Nifti1Image, which allows us to use other functions from nilearn and nibabel libraries designed to work with this image file type.  Note that the image is X, Y, Z, N where N is the number of fMRI independent components.  Since the group ICA was spatially constrained the idea is that component #1 for each subject matches the same template.  Based on the component numbers (in the label file) there were probably about 100 ICs generated.  Some of these were probably movement-related or noise components, discarded prior to generating the fnc table data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"maskData = apply_mask(subject_niimg, mask_niimg)\ntype(maskData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This call to apply_mask turns the 4D image into a 2D numpy array!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of voxels:' + str(53*63*52))\nprint('Number of voxels in standardized brain mask:' + str(maskData.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_scores = pd.read_csv('../input/trends-assessment-prediction/train_scores.csv')\ndf_train_scores['age_bins'] = pd.cut(x=df_train_scores['age'], bins=[10, 20, 30, 40, 50, 60, 70, 80, 90], \n                                     labels=['teens','twenties','thirties','forties','fifties','sixties','seventies','eighties'])\nskf = StratifiedKFold(n_splits=25, shuffle=True, random_state=5272020)\nfor train_index, test_index in skf.split(df_train_scores, df_train_scores['age_bins']):\n     print(\"TRAIN length:\", len(train_index), \"TEST length:\", len(test_index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can't load all the images in a notebook, but you can get a sense of the average effect with a few hundred subjects.  Let's look at component #5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#this is just a test, so let's try component 5 (ADN) for fun:\nmyComp = 5\n#initialize np array for the test subjects:\nsMat = np.zeros(shape=(len(test_index), maskData.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor id in test_index:\n    subject_filename = '../input/trends-assessment-prediction/fMRI_train/' + str(df_train_scores['Id'].iloc[id]) + '.mat'\n    subject_niimg = load_subject(subject_filename, mask_niimg)\n    maskData = apply_mask(subject_niimg, mask_niimg)\n    sMat[i,]= maskData[myComp,]\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By applying the mask, we get data for each subject for this component into a 2D array, and now we can run a one-sample t-test to find the voxels in the maps that are different from 0.  We can then use unmask to go back to 3D space and use nilearn functions to plot the test statistics on a brain image underlay.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t = stats.ttest_1samp(sMat, 0, axis=0)\ntmap = unmask(t.statistic, mask_niimg).get_fdata()\n\nt_img = nib.Nifti1Image(tmap, header=mask_niimg.header, affine=mask_niimg.affine)\nnlplt.plot_stat_map(t_img, title=\"IC %d\" % myComp, threshold=20.2, colorbar=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So what can you do with this?  Well, there are clearly two regions that define this network.  We can define these as two, distinct regions of interest (ROIs) and calculate summary statistics that could serve as additional features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#generate the binary structure:\nstruct = generate_binary_structure(3,3)\nlabeled_array, num_features = label(tmap>20, struct)\n    \n#label the clusters\nL_img = nib.Nifti1Image(labeled_array, header=mask_niimg.header, affine=mask_niimg.affine)\n\nnlplt.plot_roi(L_img, colorbar=True, cmap='Paired')\n\nnum_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"affine = mask_niimg.affine\nlabel_img = nib.Nifti1Image(labeled_array, affine)\nclustMask = apply_mask(label_img, mask_niimg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustMask.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RightHemMean = np.mean(sMat[:,clustMask==1], axis=1)\nLeftHemMean = np.mean(sMat[:,clustMask==2], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = stats.linregress(RightHemMean, LeftHemMean)\n\nprint(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(RightHemMean, LeftHemMean, 'o', label='original data')\nplt.plot(RightHemMean, r.intercept + r.slope*RightHemMean, 'r', label='fitted line')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, left and right hemisphere ROI means are correlated, which makes some sense given they are part of the same IC, but what about our targets?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X =  np.zeros(shape=len(test_index))\ni = 0\nfor id in test_index:\n    X[i]= df_train_scores['age'].iloc[id]\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = stats.linregress(RightHemMean, X)\n\nprint(r)\nplt.plot(RightHemMean, X, 'o', label='original data')\nplt.plot(RightHemMean, r.intercept + r.slope*RightHemMean, 'r', label='fitted line')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, that's not going to get you a gold, but I thought it was worth sharing a few steps to get into the .mat files, which are either underutilized or the secret weapon in this comp.  Happy to receive feedback about issues with my code and fix problems!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}