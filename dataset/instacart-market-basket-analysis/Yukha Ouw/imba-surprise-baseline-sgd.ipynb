{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":false},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom surprise import Reader, Dataset\nfrom zipfile import ZipFile\nfrom surprise import BaselineOnly\nfrom multiprocessing import Pool\nfrom tqdm import tqdm, tqdm_pandas\ntqdm_pandas(tqdm())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"#zip dir\nds_dir = '../input/instacart-market-basket-analysis'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#unzip dataset\nwith ZipFile(os.path.join(ds_dir,\"aisles.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"departments.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"order_products__prior.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"order_products__train.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"orders.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"products.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"sample_submission.csv.zip\"), 'r') as zipObj:\n   zipObj.extractall()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#load data\nprior = pd.read_csv('order_products__prior.csv')\ntrain = pd.read_csv('order_products__train.csv')\norders = pd.read_csv('orders.csv')\nproducts = pd.read_csv('products.csv')\n\n#fillna\nprior.fillna(0,inplace=True)\ntrain.fillna(0,inplace=True)\norders.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#ignore prior and train, merge them all\ndata = pd.concat([train,prior])\nou = orders[['order_id','user_id']]\n\ndata = pd.merge(data,ou,on='order_id').drop('order_id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#convert reordered to rating/score\nreordered = data.groupby(['user_id','product_id']).reordered.sum()\ndata = pd.merge(data,reordered, on=['user_id','product_id'], how='left')\ndata = data[data.reordered_y>0]\ndata['target'] = np.log(data['reordered_y']+1)\ndata.drop(['reordered_x','reordered_y','add_to_cart_order'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#set test dataset\ntest = orders[orders.eval_set=='test']\ntest = test[['user_id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"watchedList = data.groupby('user_id')['product_id'].apply(list)\nitemIDs = data.product_id.unique()\nuserIDs = data.user_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#backup to trace nan data\nsub = orders[orders.eval_set == 'test']\nsub = sub[['order_id','user_id']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert to surprise dataframe"},{"metadata":{"trusted":false},"cell_type":"code","source":"#convert to surprise df\nreader = Reader(rating_scale=(data.target.min(),data.target.max()))\ndatatrain = Dataset.load_from_df(data, reader)\ntrainset = datatrain.build_full_trainset()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":false},"cell_type":"code","source":"def predict(user):\n    pred = []\n    for x in itemIDs:\n        try:\n            if x in watchedList.loc[user.user_id]:\n                pred.append((x,model.predict(user.user_id,x).est))\n        except KeyError:\n            continue\n    pred = sorted(pred, key = lambda x: x[1], reverse=True)\n    if not pred:\n        return (np.nan, np.nan)\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nmodel = BaselineOnly(bsl_options={'method':'sgd'},verbose=1).fit(trainset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_cores = 4\nnum_partitions = num_cores\ndef parallelize_dataframe(df, func):\n    df_split = np.array_split(df, num_partitions)\n    pool = Pool(num_cores)\n    df = pd.concat(pool.map(func, df_split))\n    pool.close()\n    pool.join()\n    return df\n\ndef coba_mp_apply(data):\n    data['predictions'] = data.progress_apply(predict, axis=1).values\n    return data.explode('predictions')\n    \nrresults = parallelize_dataframe(test, coba_mp_apply)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rresults[['product_id', 'target']] = pd.DataFrame(rresults['predictions'].apply(pd.Series), index=rresults.index)  \nrresults.drop('predictions',inplace=True,axis=1)\nrresults.dropna(inplace=True)\nrresults.product_id = rresults.product_id.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"thresholds = {\n    'mean': rresults.target.mean(),\n    'std' : rresults.target.std(),\n    'zero' : 0,\n    'q05' : rresults.target.quantile(q=0.05),\n    'q10' : rresults.target.quantile(q=0.1)\n    }\n\nresults = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_prediction(row):\n    data = row.products\n    data = str(\"\".join(str(data))[1:-1].replace(',',' '))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for key,item in thresholds.items():\n    results[key] = rresults[rresults['target'] > item]\n    results[key] = results[key].groupby('user_id')['product_id'].apply(list).reset_index(name='products')\n    results[key]['products'] = results[key].apply(clean_prediction, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fill nan with None"},{"metadata":{"trusted":false},"cell_type":"code","source":"for key,item in thresholds.items():\n    results[key] = pd.merge(sub, results[key],how='outer',on='user_id').sort_values('user_id')\n    results[key].fillna('None', inplace=True)\n    results[key].drop('user_id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for key,item in thresholds.items():\n    results[key].to_csv('submission_surprise_Baseline_SGD_'+str(key)+'.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}