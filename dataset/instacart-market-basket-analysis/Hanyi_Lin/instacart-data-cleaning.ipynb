{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"markdown","source":"#reading data\norders=pd.read_csv(\"../input/orders.csv\")\ndepartments=pd.read_csv(\"../input/departments.csv\")\nproducts=pd.read_csv(\"../input/products.csv\")\nsample=pd.read_csv(\"../input/sample_submission.csv\")\nordertrain=pd.read_csv(\"../input/order_products__train.csv\")\norderprior=pd.read_csv(\"../input/order_products__prior.csv\")\naisles=pd.read_csv(\"../input/aisles.csv\")\n\n#cleaning data\n#there is no NAN value in any table except the column orders['days_since_prior_order']\n#and the NAN value in orders['days_since_prior_order'] means the order is the first order for that user so it doesn't have prior order\n#so there is no need for us to remove any row with NAN value\n\n#products['product_name'],aisles['aisle'],departments['department'] has string data\n#incase there are any mis-spellings, I lowercase all the strings and remove the space at the end of the string\nproducts['product_name']=products['product_name'].str.lower().str.strip()\naisles['aisle']=aisles['aisle'].str.lower().str.strip()\ndepartments['department']=departments['department'].str.lower().str.strip()\n"},{"metadata":{"trusted":true,"_uuid":"0a081297bdea495c4ff2a2bc4247034df221aa88"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nIDIR = '../input/'\n\n\nprint('loading prior')\npriors = pd.read_csv(IDIR + 'order_products__prior.csv', dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\n\nprint('loading train')\ntrain = pd.read_csv(IDIR + 'order_products__train.csv', dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\n\nprint('loading orders')\norders = pd.read_csv(IDIR + 'orders.csv', dtype={\n        'order_id': np.int32,\n        'user_id': np.int32,\n        'eval_set': 'category',\n        'order_number': np.int16,\n        'order_dow': np.int8,\n        'order_hour_of_day': np.int8,\n        'days_since_prior_order': np.float32})\n\nprint('loading products')\nproducts = pd.read_csv(IDIR + 'products.csv', dtype={\n        'product_id': np.uint16,\n        'order_id': np.int32,\n        'aisle_id': np.uint8,\n        'department_id': np.uint8},\n        usecols=['product_id', 'aisle_id', 'department_id'])\n\nprint('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\nprint('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\nprint('train {}: {}'.format(train.shape, ', '.join(train.columns)))\n\n###\n\nprint('computing product f')\nprods = pd.DataFrame()\nprods['orders'] = priors.groupby(priors.product_id).size().astype(np.int32)\nprods['reorders'] = priors['reordered'].groupby(priors.product_id).sum().astype(np.float32)\nprods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\nproducts = products.join(prods, on='product_id')\nproducts.set_index('product_id', drop=False, inplace=True)\ndel prods\n\n\nprint('add order info to priors')\norders.set_index('order_id', inplace=True, drop=False)\npriors = priors.join(orders, on='order_id', rsuffix='_')\npriors.drop('order_id_', inplace=True, axis=1)\n\n### user features\n\n\nprint('computing user f')\nusr = pd.DataFrame()\nusr['average_days_between_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\nusr['nb_orders'] = orders.groupby('user_id').size().astype(np.int16)\n\nusers = pd.DataFrame()\nusers['total_items'] = priors.groupby('user_id').size().astype(np.int16)\nusers['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\nusers['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n\nusers = users.join(usr)\ndel usr\nusers['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\nprint('user f', users.shape)\n\n### userXproduct features\n\nprint('compute userXproduct f - this is long...')\npriors['user_product'] = priors.product_id + priors.user_id * 100000\n\n# This was to slow !!\n#def last_order(order_group):\n#    ix = order_group.order_number.idxmax\n#    return order_group.shape[0], order_group.order_id[ix],  order_group.add_to_cart_order.mean()\n#userXproduct = pd.DataFrame()\n#userXproduct['tmp'] = df.groupby('user_product').apply(last_order)\n\nd= dict()\nfor row in priors.itertuples():\n    z = row.user_product\n    if z not in d:\n        d[z] = (1,\n                (row.order_number, row.order_id),\n                row.add_to_cart_order)\n    else:\n        d[z] = (d[z][0] + 1,\n                max(d[z][1], (row.order_number, row.order_id)),\n                d[z][2] + row.add_to_cart_order)\n\nprint('to dataframe (less memory)')\nuserXproduct = pd.DataFrame.from_dict(d, orient='index')\ndel d\nuserXproduct.columns = ['nb_orders', 'last_order_id', 'sum_pos_in_cart']\nuserXproduct.nb_orders = userXproduct.nb_orders.astype(np.int16)\nuserXproduct.last_order_id = userXproduct.last_order_id.map(lambda x: x[1]).astype(np.int32)\nuserXproduct.sum_pos_in_cart = userXproduct.sum_pos_in_cart.astype(np.int16)\nprint('user X product f', len(userXproduct))\n\ndel priors\n\n### train / test orders ###\nprint('split orders : train, test')\ntest_orders = orders[orders.eval_set == 'test']\ntrain_orders = orders[orders.eval_set == 'train']\n\ntrain.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n\n### build list of candidate products to reorder, with features ###\n\ndef features(selected_orders, labels_given=False):\n    print('build candidate list')\n    order_list = []\n    product_list = []\n    labels = []\n    i=0\n    for row in selected_orders.itertuples():\n        i+=1\n        if i%10000 == 0: print('order row',i)\n        order_id = row.order_id\n        user_id = row.user_id\n        user_products = users.all_products[user_id]\n        product_list += user_products\n        order_list += [order_id] * len(user_products)\n        if labels_given:\n            labels += [(order_id, product) in train.index for product in user_products]\n        \n    df = pd.DataFrame({'order_id':order_list, 'product_id':product_list}, dtype=np.int32)\n    labels = np.array(labels, dtype=np.int8)\n    del order_list\n    del product_list\n    \n    print('user related features')\n    df['user_id'] = df.order_id.map(orders.user_id)\n    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n    df['user_total_items'] = df.user_id.map(users.total_items)\n    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n    \n    print('order related features')\n    # df['dow'] = df.order_id.map(orders.order_dow)\n    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n    \n    print('product related features')\n    df['aisle_id'] = df.product_id.map(products.aisle_id)\n    df['department_id'] = df.product_id.map(products.department_id)\n    df['product_orders'] = df.product_id.map(products.orders).astype(np.int32)\n    df['product_reorders'] = df.product_id.map(products.reorders)\n    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n\n    print('user_X_product related features')\n    df['z'] = df.user_id * 100000 + df.product_id\n    df.drop(['user_id'], axis=1, inplace=True)\n    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n    df['UP_reorder_rate'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n    #df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n    #                                              df.order_id.map(orders.order_dow)\n\n    df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n    print(df.dtypes)\n    print(df.memory_usage())\n    return (df, labels)\n    \n\ndf_train, labels = features(train_orders, labels_given=True)\n\nf_to_use = ['user_t otal_orders', 'user_total_items', 'total_distinct_items',\n       'user_average_days_between_orders', 'user_average_basket',\n       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n       'UP_delta_hour_vs_last'] # 'dow', 'UP_same_dow_as_last_order'\n\n\nprint('formating for lgb')\nd_train = lgb.Dataset(df_train[f_to_use],\n                      label=labels,\n                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n#del df_train\n\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': {'binary_logloss'},\n    'num_leaves': 96,\n    'max_depth': 10,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.95,\n    'bagging_freq': 5\n}\nROUNDS = 100\n\nprint('light GBM train :-)')\nbst = lgb.train(params, d_train, ROUNDS)\n# lgb.plot_importance(bst, figsize=(9,20))\ndel d_train\n\n### build candidates list for test ###\n\ndf_test, _ = features(test_orders)\n\nprint('light GBM predict')\npreds = bst.predict(df_test[f_to_use])\n\ndf_test['pred'] = preds\n\nTRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n\nd = dict()\nfor row in df_test.itertuples():\n    if row.pred > TRESHOLD:\n        try:\n            d[row.order_id] += ' ' + str(row.product_id)\n        except:\n            d[row.order_id] = str(row.product_id)\n\nfor order in test_orders.order_id:\n    if order not in d:\n        d[order] = 'None'\n\nsub = pd.DataFrame.from_dict(d, orient='index')\n\nsub.reset_index(inplace=True)\nsub.columns = ['order_id', 'products']\nsub.to_csv('sub.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"652ddd6b1af8807f7cfb72a9f6ff72fd304e6b49"},"cell_type":"markdown","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nIDIR = '../input/'\n\n\nprint('loading prior')\npriors = pd.read_csv(IDIR + 'order_products__prior.csv', dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\n\nprint('loading train')\ntrain = pd.read_csv(IDIR + 'order_products__train.csv', dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\n\nprint('loading orders')\norders = pd.read_csv(IDIR + 'orders.csv', dtype={\n        'order_id': np.int32,\n        'user_id': np.int32,\n        'eval_set': 'category',\n        'order_number': np.int16,\n        'order_dow': np.int8,\n        'order_hour_of_day': np.int8,\n        'days_since_prior_order': np.float32})\n\nprint('loading products')\nproducts = pd.read_csv(IDIR + 'products.csv', dtype={\n        'product_id': np.uint16,\n        'order_id': np.int32,\n        'aisle_id': np.uint8,\n        'department_id': np.uint8},\n        usecols=['product_id', 'aisle_id', 'department_id'])\n\nprint('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\nprint('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\nprint('train {}: {}'.format(train.shape, ', '.join(train.columns)))"},{"metadata":{"trusted":true,"_uuid":"c065eb40f6e5d4cee674609c019b297fde2cd32e"},"cell_type":"markdown","source":"products"},{"metadata":{"trusted":true,"_uuid":"144fa1721b109d2f7e0f2a7d7aa5a5d66d29707a"},"cell_type":"markdown","source":"print('computing product f')\nprods = pd.DataFrame()\nprods['orders'] = priors.groupby(priors.product_id).size().astype(np.int32)\nprods['reorders'] = priors['reordered'].groupby(priors.product_id).sum().astype(np.float32)\nprods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\nproducts = products.join(prods, on='product_id')\nproducts.set_index('product_id', drop=False, inplace=True)\ndel prods\nproducts"},{"metadata":{"trusted":true,"_uuid":"e0e2a093ac7968786556ee295716d4f39a7d86e7"},"cell_type":"markdown","source":"print('add order info to priors')\norders.set_index('order_id', inplace=True, drop=False)\npriors = priors.join(orders, on='order_id', rsuffix='_')\npriors.drop('order_id_', inplace=True, axis=1)\npriors"},{"metadata":{"trusted":true,"_uuid":"1200c81183ec3e12e957ccbf34d423cba6a3d870"},"cell_type":"markdown","source":"print('computing user f')\nusr = pd.DataFrame()\nusr['average_days_between_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\nusr['nb_orders'] = orders.groupby('user_id').size().astype(np.int16)\n\nusers = pd.DataFrame()\nusers['total_items'] = priors.groupby('user_id').size().astype(np.int16)\nusers['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\nusers['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n\nusers = users.join(usr)\ndel usr\nusers['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\nprint('user f', users.shape)\n"},{"metadata":{"trusted":true,"_uuid":"ac1aee6b0388515f592439ac5ff6a9059e91997a"},"cell_type":"markdown","source":"users"},{"metadata":{"trusted":true,"_uuid":"bc4505ea6ca42bf8f4fbad6750b71a0b23d9feef"},"cell_type":"markdown","source":"print('compute userXproduct f - this is long...')\npriors['user_product'] = priors.product_id + priors.user_id * 100000"},{"metadata":{"trusted":true,"_uuid":"2c9039bb9e7afbceb96840a1f9de388537bffef2"},"cell_type":"markdown","source":"priors"},{"metadata":{"trusted":true,"_uuid":"14690a39a6438f805934dbfc83d089811f164aa7"},"cell_type":"markdown","source":"d= dict()\nfor row in priors.itertuples():\n    z = row.user_product\n    if z not in d:\n        d[z] = (1,\n                (row.order_number, row.order_id),\n                row.add_to_cart_order)\n    else:\n        d[z] = (d[z][0] + 1,\n                max(d[z][1], (row.order_number, row.order_id)),\n                d[z][2] + row.add_to_cart_order)\n\nprint('to dataframe (less memory)')\nuserXproduct = pd.DataFrame.from_dict(d, orient='index')\ndel d\nuserXproduct.columns = ['nb_orders', 'last_order_id', 'sum_pos_in_cart']\nuserXproduct.nb_orders = userXproduct.nb_orders.astype(np.int16)\nuserXproduct.last_order_id = userXproduct.last_order_id.map(lambda x: x[1]).astype(np.int32)\nuserXproduct.sum_pos_in_cart = userXproduct.sum_pos_in_cart.astype(np.int16)\nprint('user X product f', len(userXproduct))\n\ndel priors\n"},{"metadata":{"trusted":true,"_uuid":"6e7d4ee7a818f958c53ae0199f4ee7dceea738e6"},"cell_type":"markdown","source":"userXproduct"},{"metadata":{"trusted":true,"_uuid":"a21f81f43f3a806934969e1a08c7c95cfd095a7a"},"cell_type":"markdown","source":"print('split orders : train, test')\ntest_orders = orders[orders.eval_set == 'test']\ntrain_orders = orders[orders.eval_set == 'train']\n\ntrain.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n"},{"metadata":{"trusted":true,"_uuid":"f1ec46c6aafeb727f0df922b049b986010bf68e0"},"cell_type":"markdown","source":"train_orders"},{"metadata":{"trusted":true,"_uuid":"34a0e1bdce14a0f77f3bd08b88a3902dcb9e27a6"},"cell_type":"markdown","source":"test_orders"},{"metadata":{"trusted":true,"_uuid":"481103a0bbe9e0c8134f8f5d7178f93ec82861ea"},"cell_type":"markdown","source":"def features(selected_orders, labels_given=False):\n    print('build candidate list')\n    order_list = []\n    product_list = []\n    labels = []\n    i=0\n    for row in selected_orders.itertuples():\n        i+=1\n        if i%10000 == 0: print('order row',i)\n        order_id = row.order_id\n        user_id = row.user_id\n        user_products = users.all_products[user_id]\n        product_list += user_products\n        order_list += [order_id] * len(user_products)\n        if labels_given:\n            labels += [(order_id, product) in train.index for product in user_products]\n        \n    df = pd.DataFrame({'order_id':order_list, 'product_id':product_list}, dtype=np.int32)\n    labels = np.array(labels, dtype=np.int8)\n    del order_list\n    del product_list\n    \n    print('user related features')\n    df['user_id'] = df.order_id.map(orders.user_id)\n    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n    df['user_total_items'] = df.user_id.map(users.total_items)\n    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n    \n    print('order related features')\n    # df['dow'] = df.order_id.map(orders.order_dow)\n    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n    \n    print('product related features')\n    df['aisle_id'] = df.product_id.map(products.aisle_id)\n    df['department_id'] = df.product_id.map(products.department_id)\n    df['product_orders'] = df.product_id.map(products.orders).astype(np.int32)\n    df['product_reorders'] = df.product_id.map(products.reorders)\n    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n\n    print('user_X_product related features')\n    df['z'] = df.user_id * 100000 + df.product_id\n    df.drop(['user_id'], axis=1, inplace=True)\n    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n    df['UP_reorder_rate'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n    #df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n    #                                              df.order_id.map(orders.order_dow)\n\n    df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n    print(df.dtypes)\n    print(df.memory_usage())\n    return (df, labels)"},{"metadata":{"trusted":true,"_uuid":"68e6de2bb1c7b9eb1bae0fc4c07cac4f0c93ed0b"},"cell_type":"markdown","source":"df_train, labels = features(train_orders, labels_given=True)\n\nf_to_use = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n       'user_average_days_between_orders', 'user_average_basket',\n       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n       'UP_delta_hour_vs_last'] # 'dow', 'UP_same_dow_as_last_order'\n\n\nprint('formating for lgb')\nd_train = lgb.Dataset(df_train[f_to_use],\n                      label=labels,\n                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\ndel df_train\n\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': {'binary_logloss'},\n    'num_leaves': 96,\n    'max_depth': 10,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.95,\n    'bagging_freq': 5\n}\nROUNDS = 100\n\nprint('light GBM train :-)')\nbst = lgb.train(params, d_train, ROUNDS)\n# lgb.plot_importance(bst, figsize=(9,20))\n#del d_train"},{"metadata":{"trusted":true,"_uuid":"463df2d9bda21e8bdc93b841fb3e2f0ff67f6473"},"cell_type":"markdown","source":"d_train"},{"metadata":{"trusted":true,"_uuid":"cc554e7e602cf8f40438f2daa5ac9470459a1717"},"cell_type":"markdown","source":"df_test, _ = features(test_orders)\n\nprint('light GBM predict')\npreds = bst.predict(df_test[f_to_use])\n\ndf_test['pred'] = preds\n\nTRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n\nd = dict()\nfor row in df_test.itertuples():\n    if row.pred > TRESHOLD:\n        try:\n            d[row.order_id] += ' ' + str(row.product_id)\n        except:\n            d[row.order_id] = str(row.product_id)\n\nfor order in test_orders.order_id:\n    if order not in d:\n        d[order] = 'None'\n\nsub = pd.DataFrame.from_dict(d, orient='index')\n\nsub.reset_index(inplace=True)\nsub.columns = ['order_id', 'products']\nsub.to_csv('sub.csv', index=False)"},{"metadata":{"trusted":true,"_uuid":"6063e42bd09a8d562947e5a17126c993d221dee6"},"cell_type":"code","source":"df_train\ndf_train.to_csv('df_train.csv',index=False)\ndf_test\ndf_test.to_csv('df_train.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4530968d52f135a8d93cadd006f9284383c71051"},"cell_type":"markdown","source":"df_test"},{"metadata":{"trusted":true,"_uuid":"0178e9e02c26f18204c8dc69dcf115dbd6447d45"},"cell_type":"markdown","source":"print(os.listdir(\"../input\"))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}