{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T12:59:31.56581Z","iopub.execute_input":"2021-06-28T12:59:31.566255Z","iopub.status.idle":"2021-06-28T12:59:31.586083Z","shell.execute_reply.started":"2021-06-28T12:59:31.56615Z","shell.execute_reply":"2021-06-28T12:59:31.585043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\nfrom scipy import stats\nfrom scipy.stats import skew, norm, probplot, boxcox\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:59:34.168919Z","iopub.execute_input":"2021-06-28T12:59:34.169317Z","iopub.status.idle":"2021-06-28T12:59:35.573236Z","shell.execute_reply.started":"2021-06-28T12:59:34.16928Z","shell.execute_reply":"2021-06-28T12:59:35.572185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Read and Understand Data","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/instacart-market-basket-analysis/'):\n    for filename in filenames:        \n        archive = ZipFile(os.path.join(dirname, filename), mode='r')\n        archive.extractall(path=\"/kaggle/working\")\n        archive.close()\n\nprint(check_output([\"ls\", \"../working\"]).decode(\"utf8\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:59:38.722019Z","iopub.execute_input":"2021-06-28T12:59:38.72239Z","iopub.status.idle":"2021-06-28T12:59:49.736954Z","shell.execute_reply.started":"2021-06-28T12:59:38.72236Z","shell.execute_reply":"2021-06-28T12:59:49.735761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 Order Data","metadata":{}},{"cell_type":"code","source":"order = pd.read_csv('./orders.csv')\norder_products_prior = pd.read_csv('./order_products__prior.csv')\norder_products_train = pd.read_csv('./order_products__train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:00:08.458162Z","iopub.execute_input":"2021-06-28T13:00:08.458591Z","iopub.status.idle":"2021-06-28T13:00:21.773179Z","shell.execute_reply.started":"2021-06-28T13:00:08.458552Z","shell.execute_reply":"2021-06-28T13:00:21.772248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Related Data","metadata":{}},{"cell_type":"code","source":"deparment = pd.read_csv('./departments.csv')\nproduct = pd.read_csv('./products.csv')\naisle = pd.read_csv('./aisles.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:00:31.440968Z","iopub.execute_input":"2021-06-28T13:00:31.441342Z","iopub.status.idle":"2021-06-28T13:00:31.506116Z","shell.execute_reply.started":"2021-06-28T13:00:31.441308Z","shell.execute_reply":"2021-06-28T13:00:31.505162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Overview về dataset:\n\n1.Dataset order chứa thông tin về đơn hàng như: \n\n     - order_id: ID của đơn hàng.\n     - user_id: ID của khách hàng.\n     - eval_set: kiểu dataset của dòng dữ liệu. Ở đây có thể là: train, prior, test.\n     - order_number: số thức tự đơn hàng của khách hàng.\n     - order_dow: ngày đặt hàng trong tuần.\n     - order_hour_of_day: thời gian giờ đặt hàng trong ngày.\n     - day_since_prior_order: khoảng cách thời gian so với lần đặt hàng trước.\n\n2. Dataset order_products_prior và order_products_train: sẽ cùng một kiểu thông tin chỉ khác là dành cho tập data train hay prior:\n\n    - order_id: ID của đơn hàng.\n    - product_id: ID của sản phẩm.\n    - add_to_cart_order: thứ tự thêm vào giỏ hàng của đơn hàng.\n    - reordered: sản phẩm trong đơn hàng được đặt lại.","metadata":{}},{"cell_type":"markdown","source":"## 1.3 Reduce datasize","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        col_type2 = df[col].dtype.name\n        \n        if ((col_type != object) and (col_type2 != 'category')):\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-27T01:43:45.684299Z","iopub.execute_input":"2021-06-27T01:43:45.685002Z","iopub.status.idle":"2021-06-27T01:43:45.695987Z","shell.execute_reply.started":"2021-06-27T01:43:45.684955Z","shell.execute_reply":"2021-06-27T01:43:45.695055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# order = reduce_mem_usage(order)\n# order_products_prior = reduce_mem_usage(order_products_prior)\n# order_products_train = reduce_mem_usage(order_products_train)\n# deparment = reduce_mem_usage(deparment)\n# product = reduce_mem_usage(product)\n# aisle = reduce_mem_usage(aisle)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T13:24:28.888605Z","iopub.execute_input":"2021-06-26T13:24:28.889009Z","iopub.status.idle":"2021-06-26T13:24:31.120765Z","shell.execute_reply.started":"2021-06-26T13:24:28.888974Z","shell.execute_reply":"2021-06-26T13:24:31.119535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-06-28T04:35:29.116497Z","iopub.execute_input":"2021-06-28T04:35:29.116954Z","iopub.status.idle":"2021-06-28T04:35:30.019221Z","shell.execute_reply.started":"2021-06-28T04:35:29.116922Z","shell.execute_reply":"2021-06-28T04:35:30.018227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Data size of the order Dataset is {}'.format(order.shape))\nprint('Data size of the order_products_prior Dataset is {}'.format(order_products_prior.shape))\nprint('Data size of the order_products_train Dataset is {}'.format(order_products_train.shape))\nprint('Data size of the products Dataset is {}'.format(product.shape))\nprint('Data size of the departments Dataset is {}'.format(deparment.shape))\nprint('Data size of the aisles Dataset is {}'.format(aisle.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T04:35:32.430842Z","iopub.execute_input":"2021-06-28T04:35:32.431203Z","iopub.status.idle":"2021-06-28T04:35:32.438875Z","shell.execute_reply.started":"2021-06-28T04:35:32.431169Z","shell.execute_reply":"2021-06-28T04:35:32.437803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order[order.order_id == 2539329]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T01:39:11.897979Z","iopub.execute_input":"2021-06-28T01:39:11.898291Z","iopub.status.idle":"2021-06-28T01:39:11.938746Z","shell.execute_reply.started":"2021-06-28T01:39:11.898262Z","shell.execute_reply":"2021-06-28T01:39:11.937959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_products_prior[(order_products_prior.order_id == 3343014)]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T01:55:00.945809Z","iopub.execute_input":"2021-06-28T01:55:00.946152Z","iopub.status.idle":"2021-06-28T01:55:00.993547Z","shell.execute_reply.started":"2021-06-28T01:55:00.946122Z","shell.execute_reply":"2021-06-28T01:55:00.992783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order[order.order_id == 1187899]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T01:39:17.561855Z","iopub.execute_input":"2021-06-28T01:39:17.562195Z","iopub.status.idle":"2021-06-28T01:39:17.579065Z","shell.execute_reply.started":"2021-06-28T01:39:17.562163Z","shell.execute_reply":"2021-06-28T01:39:17.578098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_products_train[(order_products_train.order_id == 1187899)]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T01:39:19.868844Z","iopub.execute_input":"2021-06-28T01:39:19.869178Z","iopub.status.idle":"2021-06-28T01:39:19.8864Z","shell.execute_reply.started":"2021-06-28T01:39:19.869148Z","shell.execute_reply":"2021-06-28T01:39:19.885583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# deal with missing value of the column day_since_prior_order\norder.days_since_prior_order = order.days_since_prior_order.fillna(0)\n\n## get information about the number line, number line by reordered of each order on eval_set = train\ntrain_0 = order_products_train[order_products_train.reordered == 0].groupby(['order_id','reordered'])['product_id'].count().reset_index()\ntrain_1 = order_products_train[(order_products_train.reordered == 1)].groupby(['order_id','reordered'])['product_id'].count().reset_index()\ntrain_0.rename(columns={'product_id':'reordered_0'}, inplace=True)\ntrain_0 = train_0.drop('reordered', axis = 1)\ntrain_1.rename(columns={'product_id':'reordered_1'}, inplace=True)\ntrain_1 = train_1.drop('reordered', axis = 1)\ntrain_reordered = pd.merge(train_1, train_0, how = 'outer', on = 'order_id')\ntrain_reordered.fillna({'reordered_1':0, 'reordered_0':0}, inplace=True)\ndel train_0\ndel train_1\n\n\n## get information about the number line, number line by reordered of each order on eval_set = prior\nprior_0 = order_products_prior[order_products_prior.reordered == 0].groupby(['order_id','reordered'])['product_id'].count().reset_index()\nprior_1 = order_products_prior[(order_products_prior.reordered == 1)].groupby(['order_id','reordered'])['product_id'].count().reset_index()\nprior_0.rename(columns={'product_id':'reordered_0'}, inplace=True)\nprior_0 = prior_0.drop('reordered', axis = 1)\nprior_1.rename(columns={'product_id':'reordered_1'}, inplace=True)\nprior_1 = prior_1.drop('reordered', axis = 1)\nprior_reordered = pd.merge(prior_1, prior_0, how = 'outer', on = 'order_id')\nprior_reordered.fillna({'reordered_1':0, 'reordered_0':0}, inplace=True)\ndel prior_0\ndel prior_1\n\n## concat two datafarm: train and prior\n\ndf_reordered = pd.concat([prior_reordered,train_reordered])\ndf_reordered = df_reordered.sort_values(by = 'order_id', ascending= True).reset_index()\ndf_reordered = df_reordered.drop('index', axis = 1)\n\n## deal with missing value of the column reordered_0\ndf_reordered.fillna({'reordered_1':0, 'reordered_0':0}, inplace=True)\n\n## get information user_id from the Order Dataset\n\ndf_reordered = df_reordered.merge(order[['user_id','order_id','order_number','days_since_prior_order']], how = 'left', on = 'order_id')\n\ndf_reordered['total_line'] = df_reordered.reordered_0 + df_reordered.reordered_1\n\n\n## create a datafarm about order detail\n\ncus_orderdetail_df = df_reordered.groupby(['user_id']).agg({\n    'reordered_0': 'sum',\n    'reordered_1': 'sum',\n    'total_line' :'sum',\n    'order_number': 'count',\n    'days_since_prior_order': 'mean'\n}).reset_index()\n\ncus_orderdetail_df.rename(columns={'days_since_prior_order':'recency','order_number': 'fequency'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:00:40.949066Z","iopub.execute_input":"2021-06-28T13:00:40.949546Z","iopub.status.idle":"2021-06-28T13:00:50.430251Z","shell.execute_reply.started":"2021-06-28T13:00:40.94951Z","shell.execute_reply":"2021-06-28T13:00:50.429354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cus_orderdetail_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:01:07.473322Z","iopub.execute_input":"2021-06-28T13:01:07.473944Z","iopub.status.idle":"2021-06-28T13:01:07.582875Z","shell.execute_reply.started":"2021-06-28T13:01:07.473891Z","shell.execute_reply":"2021-06-28T13:01:07.581766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def QQ_plot(data, measure):\n    fig = plt.figure(figsize=(20,7))\n\n    #Get the fitted parameters used by the function\n    (mu, sigma) = norm.fit(data[measure])\n    \n    sns.set(style='darkgrid', font_scale=1.0)\n\n    #Kernel Density plot\n    fig1 = fig.add_subplot(121)\n    sns.distplot(data[measure], fit=norm)\n    fig1.set_title(measure + ' Distribution ( mu = {:.2f} and sigma = {:.2f} )'.format(mu, sigma), loc='center')\n    fig1.set_xlabel(measure)\n    fig1.set_ylabel('Frequency')\n\n    #QQ plot\n    fig2 = fig.add_subplot(122)\n    res = probplot(data[measure], plot=fig2)\n    fig2.set_title(measure + ' Probability Plot (skewness: {:.6f} and kurtosis: {:.6f} )'.format(data[measure].skew(), data[measure].kurt()), loc='center')\n\n    plt.tight_layout()\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in cus_orderdetail_df.iloc[1,1:].index:\n    QQ_plot(cus_orderdetail_df, i)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:01:18.484018Z","iopub.execute_input":"2021-06-28T13:01:18.484382Z","iopub.status.idle":"2021-06-28T13:01:29.484366Z","shell.execute_reply.started":"2021-06-28T13:01:18.484345Z","shell.execute_reply":"2021-06-28T13:01:29.48334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cus_order_df = order.groupby(['user_id']).agg({\n#     'order_number': 'count',\n#     'days_since_prior_order': ['min','mean','median', 'max']\n# })\n\n# cus_order_df.columns = [ ' '.join(str(i) for i in col) for col in cus_order_df.columns]\n# cus_order_df = cus_order_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T01:51:49.097972Z","iopub.execute_input":"2021-06-28T01:51:49.098281Z","iopub.status.idle":"2021-06-28T01:51:49.324125Z","shell.execute_reply.started":"2021-06-28T01:51:49.098251Z","shell.execute_reply":"2021-06-28T01:51:49.323287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Processing","metadata":{}},{"cell_type":"code","source":"error = 0.0001\ncus_orderdetail_df['fequency_log'] = np.log(cus_orderdetail_df['fequency'])\ncus_orderdetail_df['reordered_0_log'] = np.log(cus_orderdetail_df['reordered_0'])\ncus_orderdetail_df['total_line_log'] = np.log(cus_orderdetail_df['total_line'])\ncus_orderdetail_df['recency_log'] = np.log(cus_orderdetail_df['recency']+ error)\ncus_orderdetail_df['reordered_1_log'] = np.log(cus_orderdetail_df['reordered_1']+ error)\nfeature_vector = ['fequency_log','recency_log','reordered_0_log','reordered_1_log','total_line_log']\nX_subset = cus_orderdetail_df[feature_vector]\nscaler = StandardScaler()\nX_subset[feature_vector] = scaler.fit_transform(X_subset[feature_vector])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:04:17.943638Z","iopub.execute_input":"2021-06-28T13:04:17.944029Z","iopub.status.idle":"2021-06-28T13:04:18.023075Z","shell.execute_reply.started":"2021-06-28T13:04:17.943997Z","shell.execute_reply":"2021-06-28T13:04:18.022083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl = 10\ncorte = 0.1\n\nanterior = 100000000000000\ncost = [] \nK_best = cl\n\nfor k in range (1, cl+1):\n    # Create a kmeans model on our data, using k clusters.  random_state helps ensure that the algorithm returns the same results each time.\n    model = KMeans(\n        n_clusters=k, \n        init='k-means++', #'random',\n        n_init=10,\n        max_iter=300,\n        tol=1e-04,\n        random_state=101)\n\n    model = model.fit(X_subset)\n\n    # These are our fitted labels for clusters -- the first cluster has label 0, and the second has label 1.\n    labels = model.labels_\n \n    # Sum of distances of samples to their closest cluster center\n    interia = model.inertia_\n    if (K_best == cl) and (((anterior - interia)/anterior) < corte): K_best = k - 1\n    cost.append(interia)\n    anterior = interia\n\nplt.figure(figsize=(8, 6))\nplt.scatter(range (1, cl+1), cost, c='red')\nplt.show()\n\n# Create a kmeans model with the best K.\nprint('The best K sugesst: ',K_best)\nmodel = KMeans(n_clusters=K_best, init='k-means++', n_init=10,max_iter=300, tol=1e-04, random_state=101)\n\n# Note I'm scaling the data to normalize it! Important for good results.\nmodel = model.fit(X_subset)\n\n# These are our fitted labels for clusters -- the first cluster has label 0, and the second has label 1.\nlabels = model.labels_\n\n# And we'll visualize it:\nfig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(121)\nplt.scatter(x = X_subset.iloc[:,1], y = X_subset.iloc[:,0], c=model.labels_.astype(float))\nax.set_xlabel(feature_vector[1])\nax.set_ylabel(feature_vector[0])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T04:38:35.362537Z","iopub.execute_input":"2021-06-28T04:38:35.363063Z","iopub.status.idle":"2021-06-28T04:39:46.377286Z","shell.execute_reply.started":"2021-06-28T04:38:35.36303Z","shell.execute_reply":"2021-06-28T04:39:46.376174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import silhouette_samples, silhouette_score\n\n# A list holds the silhouette coefficients for each k\nsilhouette_coefficients = []\n\n# Notice you start at 2 clusters for silhouette coefficient\nfor k in range(2, 11):\n    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10,max_iter=300, tol=1e-04, random_state=101)\n    kmeans.fit(X_subset)\n    score = silhouette_score(X_subset, kmeans.labels_)\n    silhouette_coefficients.append(score)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T04:45:00.280228Z","iopub.execute_input":"2021-06-28T04:45:00.280681Z","iopub.status.idle":"2021-06-28T06:26:49.550201Z","shell.execute_reply.started":"2021-06-28T04:45:00.280648Z","shell.execute_reply":"2021-06-28T06:26:49.549096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,6))\nplt.plot(range(2, 11), silhouette_coefficients)\nplt.xticks(range(2, 11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T06:27:14.88215Z","iopub.execute_input":"2021-06-28T06:27:14.882532Z","iopub.status.idle":"2021-06-28T06:27:15.113324Z","shell.execute_reply.started":"2021-06-28T06:27:14.8825Z","shell.execute_reply":"2021-06-28T06:27:15.112434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_centers = dict()\n\ncluster_num = [2, 5, 8]\nfor n_clusters in cluster_num:\n\n    clusterer = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10,max_iter=300, tol=1e-04, random_state=101)\n    cluster_labels = clusterer.fit_predict(X_subset)\n    silhouette_avg = silhouette_score(X = X_subset, labels = cluster_labels)\n    cluster_centers.update({n_clusters :{'cluster_center':clusterer.cluster_centers_,\n                                         'silhouette_score':silhouette_avg,\n                                         'labels':cluster_labels}\n                           })\n\n    sample_silhouette_values = silhouette_samples(X = X_subset, labels = cluster_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:04:37.989632Z","iopub.execute_input":"2021-06-28T13:04:37.990023Z","iopub.status.idle":"2021-06-28T14:14:29.56005Z","shell.execute_reply.started":"2021-06-28T13:04:37.989988Z","shell.execute_reply":"2021-06-28T14:14:29.559065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## get the data of cluster center\ncent_transformed = scaler.inverse_transform(cluster_centers[2]['cluster_center'])\ncluster_2 = pd.DataFrame(np.exp(cent_transformed),columns=features)\ncent_transformed = scaler.inverse_transform(cluster_centers[5]['cluster_center'])\ncluster_5 = pd.DataFrame(np.exp(cent_transformed),columns=features)\ncent_transformed = scaler.inverse_transform(cluster_centers[8]['cluster_center'])\ncluster_8 = pd.DataFrame(np.exp(cent_transformed),columns=features)\n\n## add the column Number Cluster\n\ncluster_2['Number_Cluster'] = 'Cluster_2'\ncluster_5['Number_Cluster'] = 'Cluster_5'\ncluster_8['Number_Cluster'] = 'Cluster_8'\n\n## reset index\ncluster_2 = cluster_2.reset_index()\ncluster_5 = cluster_5.reset_index()\ncluster_8 = cluster_8.reset_index()\n\n## concat the datafarms\n\ncluster_center = pd.concat([cluster_2, cluster_5, cluster_8])\ncluster_center.rename(columns={'index':'Cluster'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:17:40.006951Z","iopub.execute_input":"2021-06-28T15:17:40.007482Z","iopub.status.idle":"2021-06-28T15:17:40.024118Z","shell.execute_reply.started":"2021-06-28T15:17:40.007449Z","shell.execute_reply":"2021-06-28T15:17:40.023162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_center.to_csv(\"cluster_center.csv\", index = False, header = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:20:26.458598Z","iopub.execute_input":"2021-06-28T15:20:26.459096Z","iopub.status.idle":"2021-06-28T15:20:26.46722Z","shell.execute_reply.started":"2021-06-28T15:20:26.459054Z","shell.execute_reply":"2021-06-28T15:20:26.466049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['fequency','recency','reordered_0','reordered_1','total_line']\nfor i in cluster_num:\n    print(\"for {} clusters the silhouette score is {:1.2f}\".format(i, cluster_centers[i]['silhouette_score']))\n    print(\"Centers of each cluster:\")\n    cent_transformed = scaler.inverse_transform(cluster_centers[i]['cluster_center'])\n    print(pd.DataFrame(np.exp(cent_transformed),columns=features))\n    print('-'*50)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:13:00.403911Z","iopub.execute_input":"2021-06-28T15:13:00.404358Z","iopub.status.idle":"2021-06-28T15:13:00.427659Z","shell.execute_reply.started":"2021-06-28T15:13:00.404321Z","shell.execute_reply":"2021-06-28T15:13:00.42603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cus_orderdetail_df['clusters_2'] = cluster_centers[2]['labels'] \ncus_orderdetail_df['clusters_5'] = cluster_centers[5]['labels']\ncus_orderdetail_df['clusters_8'] = cluster_centers[8]['labels']\ndisplay(cus_orderdetail_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:18:22.791096Z","iopub.execute_input":"2021-06-28T14:18:22.791483Z","iopub.status.idle":"2021-06-28T14:18:22.818657Z","shell.execute_reply.started":"2021-06-28T14:18:22.791452Z","shell.execute_reply":"2021-06-28T14:18:22.817491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cus_orderdetail_df","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:49:13.738313Z","iopub.execute_input":"2021-06-28T15:49:13.738653Z","iopub.status.idle":"2021-06-28T15:49:13.769484Z","shell.execute_reply.started":"2021-06-28T15:49:13.738624Z","shell.execute_reply":"2021-06-28T15:49:13.768698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThe list style using for matplotlib pyplot\n\n['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', \n'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n\n\n\n\"\"\"\n\nplt.style.use(['fivethirtyeight', 'bmh'])\nfig = plt.figure(figsize=(20,7))\nf1 = fig.add_subplot(131)\nmarket = cus_orderdetail_df.clusters_2.value_counts()\ng = plt.pie(market, labels=market.index, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title('2 Clusters')\nf1 = fig.add_subplot(132)\nmarket = cus_orderdetail_df.clusters_5.value_counts()\ng = plt.pie(market, labels=market.index, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title('5 Clusters')\nf1 = fig.add_subplot(133)\nmarket = cus_orderdetail_df.clusters_8.value_counts()\ng = plt.pie(market, labels=market.index, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title('8 Clusters')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:30:22.896732Z","iopub.execute_input":"2021-06-28T14:30:22.897295Z","iopub.status.idle":"2021-06-28T14:30:23.359533Z","shell.execute_reply.started":"2021-06-28T14:30:22.897244Z","shell.execute_reply":"2021-06-28T14:30:23.358569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly as py\nimport plotly.graph_objs as go\npy.offline.init_notebook_mode()\nimport matplotlib.mlab as mlab\nimport matplotlib.cm as cm","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:26:57.788998Z","iopub.execute_input":"2021-06-28T15:26:57.789392Z","iopub.status.idle":"2021-06-28T15:26:57.928232Z","shell.execute_reply.started":"2021-06-28T15:26:57.789361Z","shell.execute_reply":"2021-06-28T15:26:57.926686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = ['Cluster 0', 'Cluster 1','Cluster 2','Cluster 3','Cluster 4', 'Cluster 5', 'Cluster 6','Cluster 7']\ncolors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', \n          'rgba(22, 80, 57, 0.5)', 'rgba(127, 65, 14, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n\nfeatures = ['fequency','recency','reordered_0','reordered_1','total_line']\ncutoff_quantile = 95\n\n\ndef box_visual(n_clusters):\n    cl = 'clusters_' + str(n_clusters)\n    for fild in range(0, len(features)):\n        field_to_plot = features[fild]        \n        y_data = list()\n        ymax = 0\n        for i in np.arange(0,n_clusters):\n            y0 = cus_orderdetail_df[cus_orderdetail_df[cl]==i][field_to_plot].values\n            y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n            if ymax < max(y0): ymax = max(y0)\n            y_data.insert(i, y0)\n\n        traces = []\n\n        for xd, yd, cls in zip(x_data[:n_clusters], y_data, colors[:n_clusters]):\n                traces.append(go.Box(y=yd, name=xd, boxpoints=False, jitter=0.5, whiskerwidth=0.2, fillcolor=cls,\n                    marker=dict( size=1, ),\n                    line=dict(width=1),\n                ))\n\n        layout = go.Layout(\n            title='Difference in {} with {} Clusters and {:1.2f} Score'.\\\n            format(field_to_plot, n_clusters, cluster_centers[n_clusters]['silhouette_score']),\n            yaxis=dict( autorange=True, showgrid=True, zeroline=True,\n                dtick = int(ymax/10),\n                gridcolor='black', gridwidth=0.1, zerolinecolor='rgb(255, 255, 255)', zerolinewidth=2, ),\n            margin=dict(l=40, r=30, b=50, t=50, ),\n            paper_bgcolor='white',\n            plot_bgcolor='white',\n            showlegend=False\n        )\n\n        fig = go.Figure(data=traces, layout=layout)\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:51:35.934041Z","iopub.execute_input":"2021-06-28T15:51:35.934424Z","iopub.status.idle":"2021-06-28T15:51:35.947661Z","shell.execute_reply.started":"2021-06-28T15:51:35.934386Z","shell.execute_reply":"2021-06-28T15:51:35.946622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"box_visual(2)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:51:45.970416Z","iopub.execute_input":"2021-06-28T15:51:45.970769Z","iopub.status.idle":"2021-06-28T15:51:50.854959Z","shell.execute_reply.started":"2021-06-28T15:51:45.970722Z","shell.execute_reply":"2021-06-28T15:51:50.854132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}