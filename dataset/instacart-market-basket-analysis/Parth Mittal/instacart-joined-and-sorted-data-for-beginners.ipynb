{"cells":[{"metadata":{"_uuid":"82feec1eea1cfaf9e340534356236bc41a224718"},"cell_type":"markdown","source":"## For beginners, having trouble with huge amount of data files and just want to get the joined data, I have created this kernel to ease your pain.\n\n**You can directly download the 'hdf' file  from the OUTPUT TAB  OR include it in your kernel and read it using**  `df=pd.read_hdf('final.hdf', key='final_df', mode='r')` "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Making one DataFrame of all the date.\n### Let's have a look at the different files we have in our data and their respective columns.\n\n**1. aisles.csv**:\nShape: 134x2\n* `aisle_id`: aisle identifier\n* `aisle`: the name of the aisle\n\n**2. department.csv**:\nShape: 21x2\n* `department_id`: department identifier\n* `department`: the name of the department\n\n**(3,4). order_products__SET.csv**:\n* `order_id`: foreign key\n* `product_id`: foreign key\n* `add_to_cart_order`: order in which each product was added to cart\n* `reordered`: 1 if this product has been ordered by this user in the past, 0 otherwise\n\nwhere `SET` is one of the four following evaluation sets (`eval_set` in `orders`):\n* `\"prior\"`: orders prior to that users most recent order (~32.4mx4 )\n* `\"train\"`: training data supplied to participants (1.38mx4)\n\n**5. orders.csv**:\n* `order_id`: order identifier\n* `user_id`: customer identifier\n* `eval_set`: which evaluation set this order belongs in (see `SET` described below)\n* `order_number`: the order sequence number for this user (1 = first, n = nth)\n* `order_dow`: the day of the week the order was placed on\n* `order_hour_of_day`: the hour of the day the order was placed on\n* `days_since_prior`: days since the last order, capped at 30 (with NAs for `order_number` = 1)\n\n(source:https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b/data_description.mds)"},{"metadata":{"trusted":true,"_uuid":"50a53372cca5cdd077b2db655dba6fcff728563f"},"cell_type":"code","source":"# importing 'orders.csv' and sorting it by 'user_id' and 'order_number'\norders=pd.read_csv('../input/orders.csv')\norders=orders[['user_id','order_number', 'order_id', 'eval_set', 'order_dow',\n       'order_hour_of_day', 'days_since_prior_order']].sort_values(['user_id','order_number'])\n#first order of user_id==1 can be seen as below:\nprint(orders.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c8c3e60d208c7025c40d1b7fb6fe96afa1ca0d9"},"cell_type":"code","source":"#Examining the different SETs in the data.\nprint(orders['eval_set'].unique())\n#We can drop the 'test' SET\norders.drop(orders[orders['eval_set']=='test'].index,inplace=True)\nprint(orders['eval_set'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45e93c69adc2f88307f6080ba32f5088369432d7","scrolled":true},"cell_type":"code","source":"#We need to map all the orders based on 'order_id' and 'eval_set'. But before we need to import both SETs of 'order_products_*.csv'\norder_prior=pd.read_csv('../input/order_products__prior.csv')\nprint(order_prior.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bdad9959bfeeacf7b1eb772591378238045fbfb2"},"cell_type":"code","source":"order_train=pd.read_csv('../input/order_products__train.csv')\nprint(order_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c292e83d4fc2826947d1fb23b464dd46a656701a"},"cell_type":"code","source":"p_orders=orders[orders['eval_set']=='prior'].drop('eval_set',axis=1)\ndf_prior=pd.merge(p_orders,order_prior,left_on='order_id',right_on='order_id')\ndf_prior['eval_set']='prior'\ndf_prior.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc428f2e197c76c7980b2f424df7902da7f71825"},"cell_type":"code","source":"t_orders=orders[orders['eval_set']=='train'].drop('eval_set',axis=1)\ndf_train=pd.merge(t_orders,order_train,left_on='order_id',right_on='order_id')\ndf_train['eval_set']='test'\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5350940b811c2f41781bb0f1146b2c39585aeab7"},"cell_type":"code","source":"df=pd.concat([df_prior,df_train],ignore_index=True)\ndf=df.sort_values(['user_id','order_number','add_to_cart_order'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"4e710dff38b3877f06618d874da5d95f8622d130","_kg_hide-input":false},"cell_type":"code","source":"#deleting the dataframes that arent needed\ndel orders\ndel order_prior\ndel order_train\ndel p_orders\ndel t_orders\ndel df_prior\ndel df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccc8d9ff255a7906e5da88699963ee3dd01371f3"},"cell_type":"code","source":"#importing 'products.csv', 'aisles.csv' and 'department.csv'\nproducts=pd.read_csv('../input/products.csv')\naisles=pd.read_csv('../input/aisles.csv')\ndepartments=pd.read_csv('../input/departments.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07ac09eed3836cf08ad8df35e4069265d67bcbe1"},"cell_type":"code","source":"#Merging products and aisles\nproducts_aisles_df= pd.merge(products,aisles,left_on='aisle_id',right_on='aisle_id').sort_values('product_id')\nprint(products_aisles_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62827685dc0a82ddec50172abf7247cc0908a1da"},"cell_type":"code","source":"#Merging products_aisles_df with departments to get 'products_df'\nproducts_df=pd.merge(products_aisles_df,departments,left_on='department_id',right_on='department_id')\nprint(products_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0fb2089c92133be58e8f8b7b046abcede5b16ef"},"cell_type":"code","source":"#deleting the dataframes not needed\ndel products\ndel aisles\ndel departments\ndel products_aisles_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a909b83d5de6769def3fc2fa7a8ecf5c4a37da"},"cell_type":"code","source":"final_df=pd.merge(df,products_df,left_on='product_id',right_on='product_id')\nfinal_df=final_df.sort_values(['user_id','order_number','add_to_cart_order'])\nfinal_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ea1a9a5eb0f079b5052db8205c7188fa74c756d"},"cell_type":"code","source":"final_df.to_hdf('final.hdf','final_df',mode='w',Table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39eab19e677edb375e32e720d4dc2b01a9002c1d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"883df56375427a95a3124b74fef28a1864213e8e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}