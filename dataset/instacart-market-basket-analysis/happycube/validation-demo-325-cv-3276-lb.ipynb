{"nbformat_minor":2,"cells":[{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"b515f10501eaa05446871059da8fd12ed1093a83"},"source":"# CV demonstration notebook\n(based on Fred Navruzov's \"Dumb-and-the-Dumber-Baselines (PLB=0.3276826)\" - https://www.kaggle.com/frednavruzov/dumb-and-the-dumber-baselines-plb-0-3276826.  Some of the code is refactored for less memory use, but the results are unchanged.)"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"deba9d4dcd5a1cf050a69324df9c5119bfaa9aca"},"source":"import pandas as pd # dataframes\nimport numpy as np # algebra & calculus\nimport nltk # text preprocessing & manipulation\n# from textblob import TextBlob\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # plotting\n\nfrom functools import partial # to reduce df memory consumption by applying to_numeric\n\ncolor = sns.color_palette() # adjusting plotting style\nimport warnings\nwarnings.filterwarnings('ignore') # silence annoying warnings"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"ece4a149a1d8c344b5f78b38f3b51792c5138b82"},"source":"# aisles\naisles = pd.read_csv('../input/aisles.csv', engine='c')\nprint('Total aisles: {}'.format(aisles.shape[0]))\n\n# departments\ndepartments = pd.read_csv('../input/departments.csv', engine='c')\nprint('Total departments: {}'.format(departments.shape[0]))\n\n# products\nproducts = pd.read_csv('../input/products.csv', engine='c')\nprint('Total products: {}'.format(products.shape[0]))"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"c179d8c214afd02025b092bc95cc9dc9cb0ce1b3"},"source":"# combine aisles, departments and products (left joined to products)\ngoods = pd.merge(left=pd.merge(left=products, right=departments, how='left'), right=aisles, how='left')\n# to retain '-' and make product names more \"standard\"\ngoods.product_name = goods.product_name.str.replace(' ', '_').str.lower() \n\n# retype goods to reduce memory usage\ngoods.product_id = goods.product_id.astype(np.int32)\ngoods.aisle_id = goods.aisle_id.astype(np.int16)\ngoods.department_id = goods.department_id.astype(np.int8)"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"50e71dbf9d42b6f1c49ef221831e95f79d969e93"},"source":"# load datasets\n\n# train dataset\nop_train = pd.read_csv('../input/order_products__train.csv', engine='c', \n                       dtype={'order_id': np.int32, 'product_id': np.int32, \n                              'add_to_cart_order': np.int16, 'reordered': np.int8})\nprint('Total ordered products(train): {}'.format(op_train.shape[0]))"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"9a8ea4c04ab05f633f39b42ba8a50084df4b08ad"},"source":"# test dataset (submission)\ntest = pd.read_csv('../input/sample_submission.csv', engine='c')\nprint('Total orders(test): {}'.format(test.shape[0]))"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"8ba462f1e6c08312763b7fdcadaac8596b0eb261"},"source":"#prior dataset\nop_prior = pd.read_csv('../input/order_products__prior.csv', engine='c', \n                       dtype={'order_id': np.int32, \n                              'product_id': np.int32, \n                              'add_to_cart_order': np.int16, \n                              'reordered': np.int8})\n\nprint('Total ordered products(prior): {}'.format(op_prior.shape[0]))"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"4a20b4ac57eee0f2fca5160c7e0bc4b454aff0bf"},"source":"# orders\norders = pd.read_csv('../input/orders.csv', engine='c', dtype={'order_id': np.int32, \n                                                           'user_id': np.int32, \n                                                           'order_number': np.int16,  # max 100, could use int8\n                                                           'order_dow': np.int8, \n                                                           'order_hour_of_day': np.int8, \n                                                           'days_since_prior_order': np.float16})\nprint('Total orders: {}'.format(orders.shape[0]))\n\norders.eval_set = orders.eval_set.replace({'prior': 0, 'train': 1, 'test':2}).astype(np.int8)\norders.days_since_prior_order = orders.days_since_prior_order.fillna(-1).astype(np.int8)"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"3140a93626ba4a54555984b25d9ec82fcc381bd5"},"source":"from functools import partial\n\n# merge train and prior together iteratively, to fit into 8GB kernel RAM\n# split df indexes into parts\nindexes = np.linspace(0, len(op_prior), num=10, dtype=np.int32)\n\n# initialize it with train dataset\ntrain_details = pd.merge(\n                left=op_train,\n                 right=orders, \n                 how='left', \n                 on='order_id'\n        ).apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n\n# add order hierarchy\ntrain_details = pd.merge(\n                left=train_details,\n                right=goods[['product_id', \n                             'aisle_id', \n                             'department_id']].apply(partial(pd.to_numeric, \n                                                             errors='ignore', \n                                                             downcast='integer')),\n                how='left',\n                on='product_id'\n)\n\nprint(train_details.shape, op_train.shape)\n\n# delete (redundant now) dataframes\n#del op_train\n\n#order_details.head()"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"busy","_uuid":"372ba739ab2fe18a85b2518b523483053941dfe7"},"source":"%%time\n# update by small portions\norder_details = pd.merge(left=pd.merge(\n                                left=op_prior,\n                                right=goods[['product_id', \n                                             'aisle_id', \n                                             'department_id' ]],\n                                how='left',\n                                on='product_id'\n                                ),\n                         right=orders, \n                         how='left', \n                         on='order_id')\n        \nprint('Datafame length: {}'.format(order_details.shape[0]))\nprint('Memory consumption: {:.2f} Mb'.format(sum(order_details.memory_usage(index=True, \n                                                                         deep=True) / 2**20)))\n# check dtypes to see if we use memory effectively\n#print(order_details.dtypes)\n\n# make sure we didn't forget to retain test dataset :D\n#test_orders = orders[orders.eval_set == 2]\n"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"445f748837b9852bd2c223ec52f2332fb4112c7b"},"source":"train_orders = orders[orders.eval_set == 1]"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"ea3a5b22dcd8e005f2020d335a767c65bdbbf8e5"},"source":"# switch to integer train indexes so .loc == .iloc\ntrain_orders.index.name = 'raw_order'\ntrain_orders.reset_index(inplace=True)"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"5861857ac883ea2a8fa88db83b00fa55727d2d65"},"source":"def get_last_orders_reordered(test_orders):\n    test_history = order_details[(order_details.user_id.isin(test_orders.user_id))]\n    last_orders = test_history.groupby('user_id')['order_number'].max()\n    \n    t = pd.merge(\n        left=pd.merge(\n                left=last_orders.reset_index(),\n                right=test_history[test_history.reordered == 1],\n                how='left',\n                on=['user_id', 'order_number']\n            )[['user_id', 'product_id']],\n        right=test_orders[['user_id', 'order_id']],\n        how='left',\n        on='user_id'\n    ).fillna(-1).groupby('order_id')['product_id'].apply(lambda x: ' '.join([str(int(e)) for e in set(x)]) \n                                              ).reset_index().replace(to_replace='-1', value='None')\n    t.columns = ['order_id', 'products']\n    \n    # occasionally there is a bug where a line with order_id == -1 makes it through. doesn't *seem* to effect things\n    return t[t.order_id > 0].set_index('order_id')\n"},{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"2f487e23e95edfc75c178449316eb2e14df09e6d"},"source":"### Run the above function for 4 folds...\n\nStrictly speaking, this model does not have any interdependance on the train set, but to provide a complete demonstration KFold is used anyway."},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"a0ebaead341baf7831fd65168a9a1aaa21707b11"},"source":"import sklearn.model_selection\n\ncvpreds = []\n\nkf = sklearn.model_selection.KFold(4, shuffle=True, random_state=0)\nfor train_index, test_index in kf.split(train_orders.index):\n    cvpreds.append(get_last_orders_reordered(train_orders.iloc[test_index]))\n\ndf_cvpreds = pd.concat(cvpreds).sort_index()\ndf_cvpreds.head()"},{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"2d62ffa03dfaeeb22fd55a6f16c617caa644cde6"},"source":"#### Now to produce output (indentical to original notebook, so submission is not necessary!)"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"5e32d8328c61b35613ab2e2d8e429bc9144ee66b"},"source":"test_preds = get_last_orders_reordered(orders[orders.eval_set == 2])\ntest_preds.to_csv('cvtest-output.csv', encoding='utf-8')"},{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"6e64095337d0388a22d7479d06afacdf9888810a"},"source":"# CV F1 validation code begins here"},{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"b2393930597f7d4b9065f0a96f5b04ff1634f836"},"source":"### Produce an equivalent .csv + DataFrame to output with the train ground truth data"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"e35bb5ed7067c29b450c8603581b211bd542cd5c"},"source":"try:\n    df_train_gt = pd.read_csv('train.csv', index_col='order_id')\nexcept:\n    train_gtl = []\n\n    for uid, subset in train_details.groupby('user_id'):\n        subset1 = subset[subset.reordered == 1]\n        oid = subset.order_id.values[0]\n\n        if len(subset1) == 0:\n            train_gtl.append((oid, 'None'))\n            continue\n\n        ostr = ' '.join([str(int(e)) for e in subset1.product_id.values])\n        # .strip is needed because join can have a padding space at the end\n        train_gtl.append((oid, ostr.strip()))\n\n    df_train_gt = pd.DataFrame(train_gtl)\n\n    df_train_gt.columns = ['order_id', 'products']\n    df_train_gt.set_index('order_id', inplace=True)\n    df_train_gt.sort_index(inplace=True)\n    \n    df_train_gt.to_csv('train.csv')"},{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"fc68b474d4d5571c92496268a25bec5b875d2961"},"source":"### Now compare the ground truth and CV DataFrames"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"3db6df57c236ed70aa50e0fe2bd93d110086f75d"},"source":"f1 = []\nfor gt, pred in zip(df_train_gt.sort_index().products, df_cvpreds.sort_index().products):\n    lgt = gt.replace(\"None\", \"-1\").split(' ')\n    lpred = pred.replace(\"None\", \"-1\").split(' ')\n    \n    rr = (np.intersect1d(lgt, lpred))\n    precision = np.float(len(rr)) / len(lpred)\n    recall = np.float(len(rr)) / len(lgt)\n\n    denom = precision + recall\n    f1.append(((2 * precision * recall) / denom) if denom > 0 else 0)\n\nprint(np.mean(f1))"},{"cell_type":"markdown","outputs":[],"execution_count":null,"metadata":{"_uuid":"ea36db58dfdd3dff89a416ab7aed82cbfe8d335c"},"source":"#### The original is .327, so we've got a good validation!"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","name":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.1","mimetype":"text/x-python"}},"nbformat":4}