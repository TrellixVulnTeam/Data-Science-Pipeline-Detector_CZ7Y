{"cells":[{"metadata":{"_cell_guid":"762c42a8-fa75-d6dc-815d-f70729f8f898","_uuid":"046c5c4436f3db7da7f9b52228e3c1bd09e14b6c","trusted":true},"cell_type":"code","source":"### Importar librerias necesarias\nimport numpy as np\nimport pandas as pd\n \nimport xgboost as xgb\nfrom sklearn import metrics, model_selection","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5a6d3cfc-1bb8-aba1-43cf-404a0365fcac","_uuid":"7ffc51ca088fc8db29bc8a54e77291d67c8c5988"},"cell_type":"markdown","source":"* Para predecir qué productos comprados anteriormente estarán en el próximo pedido de un usuario\n\nComenzaremos con la lectura del archivo de pedidos."},{"metadata":{"_cell_guid":"0bd76b15-214b-5edb-3a82-468cdbb9126b","_uuid":"2a4e3d4a35246d6dd2738175f598fea0b70c69fd","trusted":true},"cell_type":"code","source":"data_path = \"../input/\"\norders_df = pd.read_csv(data_path + \"orders.csv\", usecols=[\"order_id\",\"user_id\",\"order_number\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32b9322e6fed9b0faf5af359daac50d2de068351"},"cell_type":"code","source":"aisles=pd.read_csv('../input/aisles.csv')\ndepartments=pd.read_csv('../input/departments.csv')\norders=pd.read_csv('../input/orders.csv')\norderp=pd.read_csv('../input/order_products__prior.csv')\nordert=pd.read_csv('../input/order_products__train.csv')\nproducts=pd.read_csv('../input/products.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5efc9f1ee37f870cc8f62e72e1d3c077df6ef9c0"},"cell_type":"code","source":"aisles.head()\nprint('Total pasillos: {}'.format(aisles.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b361f0a70f845f02d965d1824035ab980e2dd6f5"},"cell_type":"code","source":"departments.head()\nprint('Total departamentos: {}'.format(departments.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"158f0fbef00c9342b1868af2a47bae45674be62b"},"cell_type":"code","source":"orders.head()\nprint('Total pedidos: {}'.format(orders.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b2bd1ac894309c0d996a5175e200a9d1fccdbb5"},"cell_type":"code","source":"orderp.head()\nprint('Total pedidosP: {}'.format(orderp.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c4dd2ab742e3d5c3c51c6ff139b5a7dcf48e1cf"},"cell_type":"code","source":"ordert.head()\nprint('Total pedidosT: {}'.format(ordert.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bbf5822f29e4e4f89d2c6d6756d49b19bc154e3"},"cell_type":"code","source":"products.head()\nprint('Total productos: {}'.format(products.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc122d6f72f14e6f2b180bdb6c484d4b17e21f19"},"cell_type":"code","source":"# Combinanación pasillos, departamentos y productos (left joined to products)\ngoods = pd.merge(left=pd.merge(left=products, right=departments, how='left'), right=aisles, how='left')\n# para conservar '-' y hacer que los nombres de los productos sean más \"estándar\"\ngoods.product_name = goods.product_name.str.replace(' ', '_').str.lower() \n\ngoods.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b12b37e63f51d681864d0b03c084805c1a15a74"},"cell_type":"code","source":"import matplotlib.pyplot as plt # plotting\n\n\n# información básica del grupo (departamentos)\nplt.figure(figsize=(12, 5))\ngoods.groupby(['department']).count()['product_id'].copy()\\\n.sort_values(ascending=False).plot(kind='bar', \n                                   #figsize=(12, 5), \n                                   title='Departments: Product #')\n\n\n# información básica del grupo (top-x aisles)\ntop_aisles_cnt = 15\nplt.figure(figsize=(12, 5))\ngoods.groupby(['aisle']).count()['product_id']\\\n.sort_values(ascending=False)[:top_aisles_cnt].plot(kind='bar', \n                                   #figsize=(12, 5), \n                                   title='Aisles: Product #')\n\n# Volumen de departamentos de parcelas, dividido por pasillos.\nf, axarr = plt.subplots(6, 4, figsize=(12, 30))\nfor i,e in enumerate(departments.department.sort_values(ascending=True)):\n    axarr[i//4, i%4].set_title('Dep: {}'.format(e))\n    goods[goods.department==e].groupby(['aisle']).count()['product_id']\\\n    .sort_values(ascending=False).plot(kind='bar', ax=axarr[i//4, i%4])\nf.subplots_adjust(hspace=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"877bceaf-985d-49bc-6d3b-5c6ad7828a41","_uuid":"ef997bc6d80d94641ded5b12ef967865488d6493"},"cell_type":"markdown","source":"Dado que el objetivo es predecir qué productos comprados anteriormente estarán en el próximo pedido, primero obtengamos la lista de todos los productos comprados por el cliente."},{"metadata":{"_cell_guid":"1f5a2d50-e0d7-2c52-b26c-b147a62a770f","_uuid":"73ec6580b92bddd14fc098d698dc4ce7ae09258b","trusted":true},"cell_type":"code","source":"# leer el archivo de pedido anterior #\nprior_df = pd.read_csv(data_path + \"order_products__prior.csv\")\n\n# fusionarse con el archivo de pedidos para obtener el user_id #\nprior_df = pd.merge(prior_df, orders_df, how=\"inner\", on=\"order_id\")\n\n# Obtenga los productos y reordene el estado de la última compra de cada usuario.#\nprior_grouped_df = prior_df.groupby(\"user_id\")[\"order_number\"].aggregate(\"max\").reset_index()\nprior_df_latest = pd.merge(prior_df, prior_grouped_df, how=\"inner\", on=[\"user_id\", \"order_number\"])\nprior_df_latest = prior_df_latest[[\"user_id\", \"product_id\", \"reordered\"]]\nprior_df_latest.columns = [\"user_id\", \"product_id\", \"reordered_latest\"]\n\n# Obtenga el recuento de cada producto y el número de pedidos por parte del cliente #\nprior_df = prior_df.groupby([\"user_id\",\"product_id\"])[\"reordered\"].aggregate([\"count\", \"sum\"]).reset_index()\nprior_df.columns = [\"user_id\", \"product_id\", \"reordered_count\", \"reordered_sum\"]\n\n# fusionar el df anterior con el último df#\nprior_df = pd.merge(prior_df, prior_df_latest, how=\"left\", on=[\"user_id\",\"product_id\"])\nprior_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"41084b81-6fc7-9bab-0aa4-38525d37398a","_uuid":"0985553e9183429196c76faddb62cdd00bf906d2"},"cell_type":"markdown","source":"Lea el entrenamiento y el conjunto de datos de prueba y luego fusionar con los datos de los pedidos para obtener el user_id para el order_id correspondiente."},{"metadata":{"_cell_guid":"8d590c6a-a573-fe56-7ba1-c233deb76555","_uuid":"24e91a224c513ca3478b689e4eba23764bfbbbb1","trusted":true},"cell_type":"code","source":"orders_df.drop([\"order_number\"],axis=1,inplace=True)\n\ntrain_df = pd.read_csv(data_path + \"order_products__train.csv\", usecols=[\"order_id\"])\ntrain_df = train_df.groupby(\"order_id\").aggregate(\"count\").reset_index()\ntest_df = pd.read_csv(data_path + \"sample_submission.csv\", usecols=[\"order_id\"])\ntrain_df = pd.merge(train_df, orders_df, how=\"inner\", on=\"order_id\")\ntest_df = pd.merge(test_df, orders_df, how=\"inner\", on=\"order_id\")\nprint(train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"572a6142-f36a-e368-e12e-6097de1f6e3c","_uuid":"0d4401a54b9c8b4973e5c3d6644f83b0fcd255ca"},"cell_type":"markdown","source":"Combinar el entrenamiento y los datos de prueba con prior_df para obtener los productos comprados previamente por el cliente."},{"metadata":{"_cell_guid":"793028e8-90a5-a7f2-427d-046db698f838","_uuid":"907d93db1c533a953b80fba7a418fcea4ae961bb","trusted":true},"cell_type":"code","source":"train_df = pd.merge(train_df, prior_df, how=\"inner\", on=\"user_id\")\ntest_df = pd.merge(test_df, prior_df, how=\"inner\", on=\"user_id\")\ndel prior_df, prior_grouped_df, prior_df_latest\nprint(train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6660abab-cd0e-6f65-a67c-118800b023e2","_uuid":"c5bd4b6e61e332ae1d874ef54332d16a228d28c5"},"cell_type":"markdown","source":"El archivo products.csv contiene información sobre los productos, como a qué departamento y pasillo pertenece el producto en cuestión. Así que fusionear el entrenamiento y los datos de prueba con la información del producto."},{"metadata":{"_cell_guid":"071ee61e-bd2d-fa6c-bb8e-3e1a4ecaeb78","_uuid":"cf2873e0810d519c922f9f3e897c08cab9fed4fc","trusted":true},"cell_type":"code","source":"products_df = pd.read_csv(data_path + \"products.csv\", usecols=[\"product_id\", \"aisle_id\", \"department_id\"])\ntrain_df = pd.merge(train_df, products_df, how=\"inner\", on=\"product_id\")\ntest_df = pd.merge(test_df, products_df, how=\"inner\", on=\"product_id\")\ndel products_df\nprint(train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5f10ba77-207b-d334-b48a-6b9c52962371","_uuid":"da4b1fae81d56047d387a49881b54742ffde0a14"},"cell_type":"markdown","source":"Ahora tenemos todos los productos que el cliente ha comprado anteriormente, junto con algunas características. Por lo tanto, podemos usar el conjunto de datos del entrenamiento para rellenar la variable objetivo, es decir, el producto se ha reordenado en el siguiente orden."},{"metadata":{"_cell_guid":"45a63103-28bc-7e06-af7e-07773084c37e","_uuid":"1c03505d1131f817d08a7fde80b4041d6facdc6f","trusted":true},"cell_type":"code","source":"train_y_df = pd.read_csv(data_path + \"order_products__train.csv\", usecols=[\"order_id\", \"product_id\", \"reordered\"])\ntrain_y_df = pd.merge(train_y_df, orders_df, how=\"inner\", on=\"order_id\")\ntrain_y_df = train_y_df[[\"user_id\", \"product_id\", \"reordered\"]]\n#print(train_y_df.reordered.sum())\ntrain_df = pd.merge(train_df, train_y_df, how=\"left\", on=[\"user_id\", \"product_id\"])\ntrain_df[\"reordered\"].fillna(0, inplace=True)\nprint(train_df.shape)\n#print(train_df.reordered.sum())\ndel train_y_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"02b5535e-2f86-32d2-7b71-3d1f91154aee","_uuid":"16988dd8a7c811f03779446436391a85b2b53421","trusted":true},"cell_type":"code","source":"# target variable for train set #\ntrain_y = train_df.reordered.values\n\n# marco de datos para las predicciones del conjunto de pruebas #\nout_df = test_df[[\"order_id\", \"product_id\"]]\n\n# soltar las columnas innecesarias #\ntrain_df = np.array(train_df.drop([\"order_id\", \"user_id\", \"reordered\"], axis=1))\ntest_df = np.array(test_df.drop([\"order_id\", \"user_id\"], axis=1))\nprint(train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"82d3fef4-ba00-5b91-4a91-5bfc446210cc","_uuid":"ca8ab909c5434754b05f921c59c521375a9fcac3","trusted":true},"cell_type":"code","source":"# función para ejecutar el modelo xgboost #\ndef runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0):\n        params = {}\n        params[\"objective\"] = \"binary:logistic\"\n        params['eval_metric'] = 'logloss'\n        params[\"eta\"] = 0.05\n        params[\"subsample\"] = 0.7\n        params[\"min_child_weight\"] = 10\n        params[\"colsample_bytree\"] = 0.7\n        params[\"max_depth\"] = 8\n        params[\"silent\"] = 1\n        params[\"seed\"] = seed_val\n        num_rounds = 100\n        plst = list(params.items())\n        xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n        if test_y is not None:\n                xgtest = xgb.DMatrix(test_X, label=test_y)\n                watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n                model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n        else:\n                xgtest = xgb.DMatrix(test_X)\n                model = xgb.train(plst, xgtrain, num_rounds)\n\n        pred_test_y = model.predict(xgtest)\n        return pred_test_y","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29cb3185-abd7-4f43-37d2-d58f1ce20639","_uuid":"219ca53c8bb791c89a1540d8a55d89a1a0f25bd7","trusted":true},"cell_type":"code","source":"# ejecuta el modelo xgboost #\npred = runXGB(train_df, train_y, test_df)\ndel train_df, test_df\n\n# Usa valor cut-off para obtener las predicciones #\ncutoff = 0.2\npred[pred>=cutoff] = 1\npred[pred<cutoff] = 0\nout_df[\"Pred\"] = pred\nout_df = out_df.ix[out_df[\"Pred\"].astype('int')==1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"64a8484b-6df0-9ead-0616-2016cffca6c4","_uuid":"f273eeca4d152f01ca65c7a325c06fbf07146e40","trusted":true},"cell_type":"code","source":"# cuando hay más de 1 producto, fusionarlos en una sola cadena #\ndef merge_products(x):\n    return \" \".join(list(x.astype('str')))\nout_df = out_df.groupby(\"order_id\")[\"product_id\"].aggregate(merge_products).reset_index()\nout_df.columns = [\"order_id\", \"products\"]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"257f81f7-060b-4fd2-9baa-8df2a89b08ce","_uuid":"c51b37d11e1682ceb0f6bc38c2bfbbbb8084914e","trusted":true},"cell_type":"code","source":"# lea el archivo csv de muestra y rellene los productos de las predicciones #\nsub_df = pd.read_csv(data_path + \"sample_submission.csv\", usecols=[\"order_id\"])\nsub_df = pd.merge(sub_df, out_df, how=\"left\", on=\"order_id\")\n\n# cuando no hay predicciones usa \"ninguna\" #\nsub_df[\"products\"].fillna(\"None\", inplace=True)\nsub_df.to_csv(\"xgb_starter_3450.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}