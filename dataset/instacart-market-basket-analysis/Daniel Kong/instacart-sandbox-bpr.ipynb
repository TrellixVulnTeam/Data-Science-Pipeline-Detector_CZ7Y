{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Instacart Recommender with `implicit`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\ndef list_all_files_in(dirpath):\n    for dirname, _, filenames in os.walk(dirpath):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\nlist_all_files_in('../input')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport implicit # implicit feedback recommendation library\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # wrapper to plt for ease of use\nimport time # timing\nimport scipy.sparse as sparse # sparse matrix support\nimport pickle # Python object serialization\n\nfrom zipfile import ZipFile # ZIP file I/O\nfrom IPython.display import display # dataframe rendering, etc.\nfrom pathlib import Path\n\ncolor = sns.color_palette()\nsns.set_style('white')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load from ZIP files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_dir = '../input/instacart-market-basket-analysis'\n\nwith ZipFile(os.path.join(ds_dir,\"aisles.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"departments.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"order_products__prior.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"order_products__train.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"orders.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"products.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()\nwith ZipFile(os.path.join(ds_dir,\"sample_submission.csv.zip\"), 'r') as zipObj:\n    zipObj.extractall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_prior_df = pd.read_csv('order_products__prior.csv')\norder_products_train_df = pd.read_csv('order_products__train.csv')\norders_df               = pd.read_csv('orders.csv')\nproducts_df             = pd.read_csv('products.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge orders and products\norder_products_full_df = pd.concat([order_products_prior_df, order_products_train_df])\nmerged_order_products_df = pd.merge(order_products_full_df, products_df, on='product_id', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_user_products_df(path, orders_df, order_products_df):\n    '''\n    Generates a dataframe of users and their product purchases, and writes it to disk at the given path\n    '''\n    start = time.time()\n    print('Creating user-product dataframe... ', end='')\n    \n    # Consider any \"prior\" orders and remove all columns except `user_id` from `df_orders`\n    order_user_df = orders_df[['order_id', 'user_id']]\n    \n    # Remove all columns except order_id and user_id from orders_df and merge the above on `order_id` and remove `order_id`\n    merged_df = pd.merge(order_products_df, order_user_df, on='order_id').drop('order_id',axis=1)\n    reordered_user_products_df = merged_df.groupby(['user_id', 'product_id']).reordered.sum()\n    user_products_df = pd.merge(merged_df, reordered_user_products_df, how='left', on=['user_id', 'product_id']).drop(['reordered_x', 'add_to_cart_order'], axis=1)\n    \n    # Write to disk\n    user_products_df.to_csv(path, index_label=False)\n    \n    print(f'Completed in {round(time.time() - start, 2)}s')\n\n# Build dataframe of users and their product purchases (Needed for building the utility matrix)\nREBUILD_MATRIX_DF_FULL = False\nmatrix_df_full_path = 'user_products_full.csv'\nif REBUILD_MATRIX_DF_FULL or not Path(matrix_df_full_path).is_file():\n    get_user_products_df(matrix_df_full_path, orders_df, order_products_full_df)\n\nuser_products_df = pd.read_csv(matrix_df_full_path)\nuser_products_df['user_id'] = user_products_df['user_id'].astype('category')\nuser_products_df['product_id'] = user_products_df['product_id'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_product_user_matrix_full(path, user_products_df):\n    '''\n    Generates a utility matrix representing purchase history of users, and writes it to disk.\n    Rows and columns represent products and users respectively.\n    '''\n    start = time.time()\n    print('Creating product-user matrix... ', end='')\n    \n    product_user_matrix = sparse.coo_matrix((user_products_df['reordered_y'],\n                                            (user_products_df['product_id'].cat.codes.copy(),\n                                             user_products_df['user_id'].cat.codes.copy())))\n    sparse.save_npz(path, product_user_matrix)\n    \n    print(f'Completed in {round(time.time() - start, 2)}s')\n\nREBUILD_MATRIX_FULL = False\nmatrix_full_path = 'product_user_matrix.npz'\nif REBUILD_MATRIX_FULL or not Path(matrix_full_path).is_file():\n    build_product_user_matrix_full(matrix_full_path, user_products_df)\n\nproduct_user_matrix_full = sparse.load_npz(matrix_full_path).tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How sparse is the utility matrix?\ndef sparsity(matrix):\n    '''\n    Given a matrix, returns its sparsity\n    '''\n    total_size = matrix.shape[0] * matrix.shape[1]\n    actual_size = matrix.size\n    sparsity = (1 - (actual_size / total_size)) * 100\n    return sparsity\n\nsparsity(product_user_matrix_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def confidence_matrix(product_user_matrix, alpha):\n    '''\n    Given a utility matrix, returns the given matrix converted to a confidence matrix\n    (refer to http://yifanhu.net/PUB/cf.pdf for more details)\n    '''\n    return (product_user_matrix * alpha).astype('double')\n\ndef build_bpr(product_user_matrix, **kwargs):\n    '''\n    Given the utility matrix and model parameters,\n    builds models and writes it to disk at a given path\n    '''\n    start = time.time()\n    \n    # Build model\n    print(f'Building BPR model... ', end='')\n    model = implicit.bpr.BayesianPersonalizedRanking()\n    model.approximate_similar_items = False\n    \n    model.fit(product_user_matrix)\n    \n    # Save model to disk\n    with open(kwargs['path'], 'wb+') as f:\n        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)\n    \n    print(f'Completed in {round(time.time() - start, 2)}s')\n\n# Specify model params and build it\nbpr_params = {'random_state': 0}\nbpr_params['path'] = 'imf_benchmark_bpr.pkl'\n\nREBUILD_MODEL = True\nif REBUILD_MODEL or not Path(bpr_params['path']).exists():\n    build_bpr(product_user_matrix_full, **bpr_params)\nwith open(bpr_params['path'], 'rb') as f:\n    bpr_model = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the utility matrix is 0-indexed, the below dict is required to convert between `ids` and `indices`.\n# For example, `product_id` 1 in the dataset is represented by the `0`th row of the utility matrix.\n\n# Maps user_id: user index\nu_dict = {uid : i for i, uid in enumerate(user_products_df['user_id'].cat.categories)}\n\n# Maps product_index: product id\np_dict = dict(enumerate(user_products_df['product_id'].cat.categories))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_test_df = orders_df[orders_df.eval_set == 'test'][['user_id']]\nrelation_df = user_products_df[['user_id', 'product_id']]\nrelation_df.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sparse_user_product_matrix = product_user_matrix_full.T.tocsr()\nN_REC = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def assign_recommendations(row):\n    # print(f'Progress: {round((row.name + 1) * 100 / end, 2)}%...', end='\\r', flush=True)\n    return [(pid, score, rank) for rank, (pid, score) in enumerate(bpr_model.recommend(u_dict[row.user_id], sparse_user_product_matrix, N=N_REC), start=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = orders_test_df.reset_index(drop='index')\nprint('Recommending items... ', end='')\nstart = time.time()\nresults_df['products'] = results_df.apply(assign_recommendations, axis=1)\nprint(f'Completed in {round(time.time() - start, 2)}s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df_new = results_df.explode('products').reset_index(drop='index').rename(columns={'products': 'product_id'})\nresults_df_new[['product_id', 'score', 'rank']] = pd.DataFrame(results_df_new['product_id'].tolist(), index=results_df_new.index)\nresults_df_new['product_id'] = results_df_new['product_id'].map(p_dict)\nhasil = pd.merge(results_df_new, relation_df, how='inner', left_on=['user_id','product_id'], right_on=['user_id','product_id'])\nhasil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_prediction(row):\n    data = row.products\n    data = str(\"\".join(str(data))[1:-1].replace(',',' '))\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r_hasil = hasil.groupby('user_id')['product_id'].apply(list).reset_index(name='products')\nr_hasil['products'] = r_hasil.apply(clean_prediction, axis=1)\nr_hasil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = orders_df[orders_df.eval_set == 'test']\nsubmission_df = submission_df[['order_id','user_id']]\n\nsub_hasil = pd.merge(submission_df, r_hasil, how='outer', on='user_id').sort_values('user_id')\nsub_hasil.fillna('None', inplace=True)\nsub_hasil.drop('user_id', axis=1, inplace=True)\nsub_hasil.to_csv('submission.csv', index=False)\nsub_hasil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_hasil[sub_hasil['products'] != 'None']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}