{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"_is_fork":false,"language_info":{"pygments_lexer":"ipython3","name":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","nbconvert_exporter":"python","mimetype":"text/x-python"},"_change_revision":0},"cells":[{"metadata":{"_uuid":"ffd578ed880603d5d6aeba1acb7c2b1ee5db20fc","_cell_guid":"4b563cd2-1a7b-ab65-4096-7087a046ed50"},"cell_type":"markdown","source":"Work in progress:\n<br>-- add bf0 to data for all products NOT reordered to all orders after first ordered\n<br>--  add the exponential time weighting - for model memory loss\n<br>--  add new factors to model\n<br>--  try flat Prior where p(reorder) is same for all products\n\nThis file uses p(reordered|product_id) derived from order_products__prior data as a **Prior**. This is to be used in Bayesian Updating of our Prior: our_products_prior['prob_reordered']. Can also use a flat Prior.\n\nThe notion is that after calculating Bayes Factors for each test product purchase the final probability that a product will be reordered is the **Posterior** probability.  Beginning when a product is first purchased (say order k of n total orders) then the **Posterior = BFn x BFn-1 x ... x BFk x Prior**.\n\nMany others here have noticed the correlation between reordered and add_to_cart_order and aisle. I have added an engineered factor I call reorder_count (or count of reordered items in a cart). Using these three variables, I have derived a simple Augmented Naive Bayesian Network as a model to calculate the Bayes Factors for updating.\n\n![Bayesian Network model of reordered][1]\n\nThanks to Kareem Eissa, Nick Sarris and Paul Nguyen for code and inspiration. Thank you smalllebowski and Sagar M for your corrections! You are very generous.\n\n\n\n  [1]: http://elmtreegarden.com/wp-content/uploads/2017/07/Augmented-Naive-Bayesian-Network.png"},{"metadata":{"_execution_state":"idle","_uuid":"0bea51e9703c895a1192a078d749e6b4c828bfe2","_cell_guid":"927116ef-f2f7-7c39-61cb-738950a5cd31"},"execution_count":null,"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport operator\n\n# special thanks to Nick Sarris who has written a similar notebook\n# reading data\n#mdf = 'c:/Users/John/Documents/Research/entropy/python/InstaCart/data/'\nmdf = '../input/'\nprint('loading prior orders')\nprior_orders = pd.read_csv(mdf + 'order_products__prior.csv', dtype={\n        'order_id': np.int32,\n        'product_id': np.int32,\n        'add_to_cart_order': np.int16,\n        'reordered': np.int8})\nprint('loading orders')\norders = pd.read_csv(mdf + 'orders.csv', dtype={\n        'order_id': np.int32,\n        'user_id': np.int32,\n        'eval_set': 'category',\n        'order_number': np.int16,\n        'order_dow': np.int8,\n        'order_hour_of_day': np.int8,\n        'days_since_prior_order': np.float32})\nprint('loading aisles info')\naisles = pd.read_csv(mdf + 'products.csv', engine='c',\n                           usecols = ['product_id','aisle_id'],\n                       dtype={'product_id': np.int32, 'aisle_id': np.int32})\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\nprior_orders.shape\norders.shape","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"812eda8704d6d53ae49d3619b90ed8333c56098b","_cell_guid":"807b5b6e-480a-47c5-bd95-ecd4b8006e8b"},"execution_count":null,"cell_type":"code","source":"# removing all user_ids not in the test set from both files to save memory\n# the test users present ample data to make models. (and saves space)\ntest  = orders[orders['eval_set'] == 'test' ]\nuser_ids = test['user_id'].values\norder_ids = test['order_id'].values\norders = orders[orders['user_id'].isin(user_ids)]\n\n#del test\ntest.shape","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"f5946442035a0c68a9164d376cb84ae42d5910fc","_cell_guid":"1f3b3415-a367-4df7-84df-4e1e1e30bb8a"},"execution_count":null,"cell_type":"code","source":"\n# Calculate the Prior : p(reordered|product_id)\nprior = pd.DataFrame(prior_orders.groupby('product_id')['reordered']\\\n                     .agg([('number_of_orders',len),('sum_of_reorders','sum')]))\n#prior['prior_p'] = (prior['sum_of_reorders']+1)/(prior['number_of_orders']+2) # Informed Prior\nprior['prior_p'] = 1/2  # Flat Prior\nprior.drop(['number_of_orders','sum_of_reorders'], axis=1, inplace=True)\nprint('Here is The Prior: our first guess of how probable it is that a product be reordered once it has been ordered.')\n\nprior.head(3)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"d68a0fda41a737eeb5e32a9490feb485bade050b","_cell_guid":"e47e54fb-0c07-4335-b815-a39c5d5ca842"},"execution_count":null,"cell_type":"code","source":"# merge everything into one dataframe and save any memory space\n\ncomb = pd.DataFrame()\ncomb = pd.merge(prior_orders, orders, on='order_id', how='right')\n# slim down comb - \ncomb.drop(['eval_set','order_dow','order_hour_of_day'], axis=1, inplace=True)\ndel prior_orders\ndel orders\ncomb = pd.merge(comb, aisles, on ='product_id', how = 'left')\ndel aisles\nprior.reset_index(inplace = True)\ncomb = pd.merge(comb, prior, on ='product_id', how = 'left')\ndel prior\nprint('combined data in DataFrame comb')\ncomb.head(3)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"40c4bba5ec2869cd23dda1915da9a6b6f3bddbe0","_cell_guid":"d22f54fe-8571-4b5b-ae17-375f30bd7ec9"},"execution_count":null,"cell_type":"code","source":"\n# Build the factors needed for a model of probability of reordered. This model forms our\n# hypothesis H and allows the calculation of each Bayes Factor: BF = p(e|H)/(1-p(e|H))\n# where e is the test user product buying history. See DAG of model above.\n# discretize reorder count into categories, 9 buckets, being sure to include 0 as bucket\n# These bins maximize mutual information with ['reordered']. Done outside python\nrecount = pd.DataFrame()\nrecount['reorder_c'] = comb.groupby(comb.order_id)['reordered'].sum().fillna(0)\nbins = [-0.1, 0, 2,4,6,8,11,14,19,71]\ncat =  ['None','<=2','<=4','<=6','<=8','<=11','<=14','<=19','>19']\nrecount['reorder_b'] = pd.cut(recount['reorder_c'], bins, labels = cat)\nrecount.reset_index(inplace = True)\ncomb = pd.merge(comb, recount, how = 'left', on = 'order_id')\ndel recount\n\n# discretize 'add_to_cart_order' (atco) into categories, 8 buckets\n# These bins maximize mutual information with ['recount']. Done outside python\nbins = [0,2,3,5,7,9,12,17,80]\ncat = ['<=2','<=3','<=5','<=7','<=9','<=12','<=17','>17']\ncomb['atco1'] = pd.cut(comb['add_to_cart_order'], bins, labels = cat)\ndel comb['add_to_cart_order']\nprint('comb ')\ncomb.head(2)\n","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"232ae69ebb731fe5b0eb7f873b352803d51cc7d2","_cell_guid":"cf937d1f-b100-4832-bc84-5f06d6a4d973"},"execution_count":null,"cell_type":"code","source":"# these are the children Nodes of reordered:atco, aisle, recount. Build occurrence tables\n# first, then calculate probabilities. Then merge to add atco into comb.\n# \natco_fac = pd.DataFrame()\natco_fac = comb.groupby(['reordered', 'atco1'])['atco1'].agg(np.count_nonzero).unstack('atco1')\ntot = pd.DataFrame()\ntot = np.sum(atco_fac,axis=1)\natco_fac = atco_fac.iloc[:,:].div(tot, axis=0)\natco_fac = atco_fac.stack('atco1')\natco_fac = pd.DataFrame(atco_fac)\natco_fac.reset_index(inplace = True)\natco_fac.rename(columns = {0:'atco_fac_p'}, inplace = True)\ncomb = pd.merge(comb, atco_fac, how='left', on=('reordered', 'atco1'))\n\n# calculate other two factors' probability tables, then probability\n# and merge into comb\n\naisle_fac = pd.DataFrame()\naisle_fac = comb.groupby(['reordered', 'atco1', 'aisle_id'])['aisle_id']\\\n                .agg(np.count_nonzero).unstack('aisle_id')\ntot = np.sum(aisle_fac,axis=1)\naisle_fac = aisle_fac.iloc[:,:].div(tot, axis=0)\naisle_fac = aisle_fac.stack('aisle_id')\naisle_fac = pd.DataFrame(aisle_fac)\naisle_fac.reset_index(inplace = True)\naisle_fac.rename(columns = {0:'aisle_fac_p'}, inplace = True)\ncomb = pd.merge(comb, aisle_fac, how = 'left', on = ('aisle_id','reordered','atco1'))\n# last factor is reorder_count_factor   \n    \nrecount_fac = pd.DataFrame()\nrecount_fac = comb.groupby(['reordered', 'atco1', 'reorder_b'])['reorder_b']\\\n                    .agg(np.count_nonzero).unstack('reorder_b')\ntot = pd.DataFrame()\ntot = np.sum(recount_fac,axis=1)\nrecount_fac = recount_fac.iloc[:,:].div(tot, axis=0)\nrecount_fac.stack('reorder_b')\nrecount_fac = pd.DataFrame(recount_fac.unstack('reordered').unstack('atco1')).reset_index()\nrecount_fac.rename(columns = {0:'recount_fac_p'}, inplace = True)\ncomb = pd.merge(comb, recount_fac, how = 'left', on = ('reorder_b', 'reordered', 'atco1'))\n\nrecount_fac.head(3)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"c030dd3195a0820a61149a7c609d91e1c70a63e2","_cell_guid":"97dd8e8c-70fe-471e-b4ef-5b2cfec83226"},"execution_count":null,"cell_type":"code","source":"\n# Use the factors in comb + the prior_p to update a posterior for each product purchased.\np = pd.DataFrame()\np = (comb.loc[:,'atco_fac_p'] * comb.loc[:,'aisle_fac_p'] * comb.loc[:,'recount_fac_p'])\np.reset_index()\ncomb['p'] = p\n\ncomb.head(3)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"95583cca40bfbfce8b238affdef44b8b3c074c5d","_cell_guid":"5cf13cc8-8613-48b8-98f7-d0df41e1a57c"},"execution_count":null,"cell_type":"code","source":" \n# work in progress on beta\n# Use a test beta = 95% per month for memory retention function of users. Akin to Recency.\n\n\n#split into three dataframes. Two are reordered == 1 and == 0\n# add third group when order_number > first_order & reordered <> 1\n# the trird group is when ordered=0 but we don't have data for order=0,\n# so we make it.It must be appended to comb_last\n\n# Calculate bf0 for products when first purchased aka reordered=0\ncomb0 = pd.DataFrame()\ncomb0 = comb[comb['reordered']==0]\ncomb0.loc[:,'first_order'] = comb0['order_number']\n# now every product that was ordered has a posterior in usr.\ncomb0.loc[:,'beta'] = 1\ncomb0.loc[:,'bf'] = (comb0.loc[:,'prior_p'] * comb0.loc[:,'p']/(1 - comb0.loc[:,'p'])) # bf1\n# Small 'slight of hand' here. comb0.bf is really the first posterior and second prior.\n\n# Calculate beta and BF1 for the reordered products\ncomb1 = pd.DataFrame()\ncomb1 = comb[comb['reordered']==1]\n\ncomb1.loc[:,'beta'] = (1 - .05*comb1.loc[:,'days_since_prior_order']/30)\ncomb1.loc[:,'bf'] = (1 - comb1.loc[:,'p'])/comb1.loc[:,'p'] # bf0\n\n\ncomb_last = pd.DataFrame()\ncomb_last = pd.concat([comb0, comb1], axis=0).reset_index(drop=True)\ncomb_last = comb_last[['reordered','user_id','product_id','reorder_c','order_number',\n                       'bf','beta','atco_fac_p', 'aisle_fac_p', 'recount_fac_p']]\ncomb_last = comb_last.sort_values((['user_id', 'order_number', 'bf']))\n\npd.set_option('display.float_format', lambda x: '%.6f' % x)\ncomb_last.head(3)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"e901e67ad4ed2a74b91a59679475f9ad8a52e19e","_cell_guid":"fca6455e-07ef-4b06-97d4-9a63e6af972b"},"execution_count":null,"cell_type":"code","source":"first_order = pd.DataFrame()\nfirst_order = comb_last[comb_last.reordered == 0]\nfirst_order.rename(columns = {'order_number':'first_o'}, inplace = True)\nfirst_order.loc[:,'last_o'] = comb_last.groupby(['user_id'])['order_number'].transform(max)\nfirst_order = first_order[['user_id','product_id','first_o','last_o']]\ncomb_last = pd.merge(comb_last, first_order, on = ('user_id', 'product_id'), how = 'left')\n\n#com = pd.DataFrame()\n#com = comb_last[(comb_last.user_id == 3) & (comb_last.first_o < comb_last.order_number)]\n#com.groupby([('order_id', 'product_id', 'order_number')])['bf'].agg(np.sum).head(50)\n","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"0bbb9d7f6fdae1b0fcfdb1d4a38cd118a17a1200","_cell_guid":"76824c7c-e801-4c49-be25-798ab9cb5cb8"},"execution_count":null,"cell_type":"code","source":"# Calculate beta and bf0 for products not reordered after first order for all orders.\n# must not occur until reordered==0 (aka: when first ordered)\n# they do not exist in the data. there is no record of NOT Ordered.\n# we must produce these records and calculate p, bf0 & beta for each\ncom = pd.DataFrame\n\n# replace nan with bf0 if first_o < order_number (after product is first ordered)\ncom = pd.pivot_table(comb_last[(comb_last.user_id == 3) & \\\n                               (comb_last.first_o < comb_last.order_number)],\n                     values = 'bf', index = ['user_id', 'product_id'],\n                     columns = 'order_number', dropna=False)\ntemp = pd.DataFrame()\ntemp = com[(com.bf == 'nan')]\np = pd.DataFrame()\np.loc[:,'p'] = (temp.loc[:,'atco_fac_p'] * temp.loc[:,'aisle_fac_p'] * temp.loc[:,'recount_fac_p'])\np.reset_index()\ntemp.loc[:,'bf'] = (1 - temp.loc[:,p])/temp.loc[:,p]\ncomb_last = pd.merge(comb_last, temp, on =[('order_id', 'product_id',\n                                            'order_number')]).reset_index()\ntemp = comb_last[comb_last.beta == 'nan']\ntemp.loc[:,'beta'] = (1 - .05*comb1.loc[:,'days_since_prior_order']/30)\ncomb_last = pd.merge(comb_last, temp, on = [('order_id', 'product_id',\n                                             'order_number')]).reset_index()\n\n# replace nan with 1 if first_o > order number (before product has been ordered)\ncom = pd.pivot_table(comb_last[(comb_last.user_id ==3) & (com.first_o < com.order_number)],\n                     values = 'beta', index = ['user_id', 'product_id'], \n                     columns = 'order_number', dropna=False)\n# \ntemp = com[com.bf == 'nan']\ntemp.loc[:,'bf'] = 1\ncomb_last = pd.merge(comb_last, temp, on =[('order_id', 'product_id',\n                                            'order_number')]).reset_index()\ntemp = comb_last[comb_last.beta == 'nan']\ntemp.loc[:,'beta'] = 1\ncomb_last = pd.merge(comb_last, temp, on = [('order_id', 'product_id',\n                                             'order_number')]).reset_index()\n\n\npd.pivot_table(comb_last[comb_last.user_id ==3], values = 'bf',\n               index = ['user_id', 'product_id'], columns = 'order_number', dropna=False).head(15)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"7f763d66c95af14dbda83a19882812de7672498b","collapsed":true,"_cell_guid":"f4a5593d-e095-4db3-ba74-e8827f07dd50"},"execution_count":null,"cell_type":"code","source":"# Find way to introduce beta to the update. ????\n##  update = lambda bf(n) ,bf(n-1), beta(n): bf(n) * bf(n-1)**beta(n);\n\n# finally, perform update of every product\n# Calculate the posterior for every product a user has purchased\nusr = pd.DataFrame()\nusr = comb_last[comb_last.order_number >= comb_last.first_o].groupby(['user_id',\n                                                                      'product_id'])['bf',\n                                                                                     'beta']\\\n    .agg({['bf', 'beta']: lambda x,y: x**y}).reset_index() \n\n# Calculate the average number of reordered products per cart for each user\ntemp = pd.DataFrame()\ntemp = comb_last[comb_last.order_number > 1].groupby(['user_id'])['reorder_c']\\\n    .agg(np.mean).reset_index()\nuser = pd.merge(usr, temp, on = 'user_id', how = 'left')\n\nuser.head(5)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"e55f50762819120a35462b12fd72b0a859ad9e59","_cell_guid":"7a2f7244-94af-4f80-be89-dcc3975deeb5"},"execution_count":null,"cell_type":"code","source":"def f1(x):\n    return ' '.join([str(int(a)) for a in x])\ndef f2(x):\n    return 'None'\n\nu = user.reset_index().sort_values(((['user_id','bf'])), ascending=False)\nu['cumulative'] = u.groupby('user_id').cumcount()\nuu = u[(round(u.reorder_c) > u.cumulative)].groupby('user_id').agg({'product_id': f1})\nuu.reset_index(inplace=True)\nuuu = u[round(u.reorder_c) == 0].groupby('user_id').agg({'product_id': f2})\nuuu.reset_index(inplace=True)\n\nuuuu = pd.concat([uu, uuu], axis=0).reset_index()\nsub = pd.merge(uuuu, test, on='user_id', how ='left').sort_values('order_id')\n\nsub.sort_values('order_id')\nsub[['order_id', 'product_id']].to_csv('bayesian.csv', index=False)\nsub[['order_id', 'product_id']].head(10)","outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"d76982e5ba2e66f0061fa7ef7c2df870cac9f596","collapsed":true,"_cell_guid":"af215e15-0acf-4319-813c-001a64467665"},"execution_count":null,"cell_type":"code","source":"","outputs":[]}],"nbformat_minor":1,"nbformat":4}