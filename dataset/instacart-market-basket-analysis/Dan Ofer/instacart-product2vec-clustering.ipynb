{"cells":[{"metadata":{"_uuid":"96e49ca0c917f66ba01bed84d8db77e423c4fbe3"},"cell_type":"markdown","source":"## Instacart dataset exploratory\n* Forked from : https://www.kaggle.com/goodvc/instacart-product2vec-clustering-using-word2vec \n     * Fixed paths + minor changes\n* Instacart kaggle : https://www.kaggle.com/c/instacart-market-basket-analysis#prizes\n* blog post : https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2\n* data dictionary : https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b\n* dataset file list \n\n\n"},{"metadata":{"trusted":true,"_uuid":"5d56631caad399c33f9720131f027c969b756e22"},"cell_type":"code","source":"! pip install gensim","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cefee9f5460c22d9161dbfea021560709b49b09f","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport gensim\nfrom gensim.models import Word2Vec\n\nimport os\nprint(os.listdir(\"../input\"))\n\npd.options.display.max_rows = 15\n%matplotlib inline\nsns.set(style=\"whitegrid\", palette=\"colorblind\", font_scale=1, rc={'font.family':'NanumGothic'} )\n\ndef toReadable(v):\n    value = round(v,2) if isinstance(v, float) else v\n\n    if value < 1000:\n        return str(value)\n    elif value<1000000:\n        return str(round(value/1000,1))+'K'\n    elif value>=1000000:\n        return str(round(value/1000000,1))+'M'\n    return value","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9916d99872360e6c1bdb62063455b4634c73a443"},"cell_type":"markdown","source":"---\n## Load Dataset"},{"metadata":{"trusted":true,"_uuid":"0b935c2d53bc01541c0a7d2bf224d44739d5c897"},"cell_type":"code","source":"IDIR = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bba550e227922b0b020618cb101a4d5ffd888be","trusted":true},"cell_type":"code","source":"raw_order_ds = pd.read_csv(IDIR + 'orders.csv', dtype={\n        'order_id': np.int32,\n        'user_id': np.int32,\n        'eval_set': 'category',\n        'order_number': np.int16,\n        'order_dow': np.int8,\n        'order_hour_of_day': np.int8,\n        'days_since_prior_order': np.float32})\nprint(\"raw_order_ds shape\",raw_order_ds.shape)\n\norder_product_ds = priors = pd.read_csv(IDIR + 'order_products__prior.csv', dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\nprint(\"order_product_ds shape\",order_product_ds.shape)\n\nproduct_ds = pd.read_csv(IDIR + 'products.csv')\nprint(\"orders shape\",product_ds.shape)\n\norder_product_cnt_ds = order_product_ds.groupby('order_id').count()[['product_id']]\norder_product_cnt_ds.columns = ['product_cnt']\n\n## join product count \norder_ds = raw_order_ds.merge(order_product_cnt_ds, left_on='order_id', right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87cc87c3c2d4ec05ca248786fb9265de1b47f7f2"},"cell_type":"markdown","source":"### Dataset Summery\nLet's look at the simple stats of a dataset"},{"metadata":{"_uuid":"9480cd5c4fa6896a1ca5a0354a62825182aed566","trusted":true},"cell_type":"code","source":"total_user = len(order_ds.user_id.unique())\ntotal_order = len(order_ds)\ntotal_ordered_product = len(order_product_ds)\nunique_products = len(order_product_ds.product_id.unique())\n\nprint(\"total user = {}\".format(toReadable(total_user)))\nprint(\"total order = {} ({} orders per a user )\".format(toReadable(total_order), toReadable(total_order/total_user) ))\nprint(\"total product = \", toReadable(unique_products))\nprint(\"total ordered product  = {} ({} orders per a product )\".format(\n    toReadable(total_ordered_product), toReadable(total_ordered_product/unique_products) ))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67bd39a7a90848d6b2090ddd7722e9e1761bcf11"},"cell_type":"markdown","source":"---\n## Clustering similar product by user's order informaiton\n* Traing product2vec using word2vec \n * word = product_id\n * scentence = user's order = [product_id1, product_id2, ... ]\n* clustering by trained product vector\n* Use only products ordered more than 100 times\n\n* Do not Filter out orders with only 1 item in then in this case ? "},{"metadata":{"_uuid":"9eb108f0987bb42997b35603bfbeabb1b9a9db87","trusted":true},"cell_type":"code","source":"merge_order_product_ds = order_product_ds.merge(order_ds, on='order_id' )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98dd7e88c8bef2cf4e8e7d014d7b7a4ec8d8101a","trusted":true},"cell_type":"code","source":"order_product_list = merge_order_product_ds\\\n    .sort_values(['user_id','order_id','add_to_cart_order'])[['order_id','product_id']]\\\n    .values.tolist()\n\nproduct_corpus = []\nsentence = []\nnew_order_id = order_product_list[0][0]\nfor (order_id, product_id) in order_product_list:\n    if new_order_id != order_id:\n        product_corpus.append(sentence)\n        sentence = []\n        new_order_id = order_id\n    sentence.append(str(product_id))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb98b4f48e72ecbeb8ad2e57ee00cdfcbe161a71","trusted":true},"cell_type":"code","source":"model = Word2Vec(product_corpus, window=9, size=100, workers=4, min_count=50)\n# model.save('./resource/prod2vec.100d.model')\n# model = Word2Vec.load('./resource/prod2vec.100d.model')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a80edf1212baa8b9471bff6c3fca9d69391965d9","trusted":true},"cell_type":"code","source":"def toProductName(id):\n    return product_ds[product_ds.product_id==id]['product_name'].values.tolist()[0]\ntoProductName(24852)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f7c26efb1d30c937927bcfe38e1d30bbc631b3d","trusted":true},"cell_type":"code","source":"def most_similar_readable(model, product_id):\n    similar_list = [(product_id,1.0)]+model.wv.most_similar(str(product_id))\n    \n    return [( toProductName(int(id)), similarity ) for (id,similarity) in similar_list]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"709653282ad07e272acf0dfb77f525f68ae41e17"},"cell_type":"markdown","source":"### What is the most similar?\n* most similar to banana(24852) is .."},{"metadata":{"_uuid":"0dcbf0cd7cd994f0f134ae80710731bd74f0b49c","trusted":false},"cell_type":"code","source":"pd.DataFrame(most_similar_readable(model, 24852), columns=['product','similarity'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ba65a692b31a99136dc2263f991d3581dc75f81"},"cell_type":"markdown","source":"* most similar to Drinking Water(27845) is .."},{"metadata":{"_uuid":"51565ce4f70bcec5cd9e1bec1ec2fd6c8f139287","trusted":false},"cell_type":"code","source":"pd.DataFrame(most_similar_readable(model, 27845), columns=['product','similarity'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a31f6d9ee8bb5a663487f216603b24f64cc2e87"},"cell_type":"markdown","source":"* most similar to Organic Whole Milk(40939) is .. "},{"metadata":{"_uuid":"02ac6ac69a43e9f135b2a0933dda76a2ecbd5d03","trusted":false},"cell_type":"code","source":"pd.DataFrame(most_similar_readable(model, 40939), columns=['product','similarity'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd4a5fa45b2334456fd931e7b678ebe241d54064","trusted":false},"cell_type":"code","source":"pd.DataFrame(most_similar_readable(model, 48697), columns=['product','similarity'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d51ff51e54e347192814ed41b2e8cf6c08ed60a7"},"cell_type":"markdown","source":"### Product2Vec works well !!! "},{"metadata":{"_uuid":"7b6edd39505bf21257883b2f3ea8b7f4923d63bb"},"cell_type":"markdown","source":"* Create 500 clusters as similar products\n* using kmeans ( k=500 )"},{"metadata":{"collapsed":true,"_uuid":"2010738426f97c5690a2dc84f56df8e1c13ab9ee","trusted":false},"cell_type":"code","source":"from __future__ import division\nimport random\nimport numpy as np\nfrom scipy.spatial.distance import cdist  # $scipy/spatial/distance.py\n    # http://docs.scipy.org/doc/scipy/reference/spatial.html\nfrom scipy.sparse import issparse  # $scipy/sparse/csr.py\n\n__date__ = \"2018-09-01\"\n    # X sparse, any cdist metric: real app ?\n    # centres get dense rapidly, metrics in high dim hit distance whiteout\n    # vs unsupervised / semi-supervised svm\n#...............................................................................\ndef kmeans( X, centres, delta=.001, maxiter=10, metric=\"euclidean\", p=2, verbose=1 ):\n    \"\"\" centres, Xtocentre, distances = kmeans( X, initial centres ... )\n    in:\n        X N x dim  may be sparse\n        centres k x dim: initial centres, e.g. random.sample( X, k )\n        delta: relative error, iterate until the average distance to centres\n            is within delta of the previous average distance\n        maxiter\n        metric: any of the 20-odd in scipy.spatial.distance\n            \"chebyshev\" = max, \"cityblock\" = L1, \"minkowski\" with p=\n            or a function( Xvec, centrevec ), e.g. Lqmetric below\n        p: for minkowski metric -- local mod cdist for 0 < p < 1 too\n        verbose: 0 silent, 2 prints running distances\n    out:\n        centres, k x dim\n        Xtocentre: each X -> its nearest centre, ints N -> k\n        distances, N\n    see also: kmeanssample below, class Kmeans below.\n    \"\"\"\n    if not issparse(X):\n        X = np.asanyarray(X)  # ?\n    centres = centres.todense() if issparse(centres) \\\n        else centres.copy()\n    N, dim = X.shape\n    k, cdim = centres.shape\n    if dim != cdim:\n        raise ValueError( \"kmeans: X %s and centres %s must have the same number of columns\" % (\n            X.shape, centres.shape ))\n    if verbose:\n        print (\"kmeans: X %s  centres %s  delta=%.2g  maxiter=%d  metric=%s\" % (\n            X.shape, centres.shape, delta, maxiter, metric) )\n    allx = np.arange(N)\n    prevdist = 0\n    for jiter in range( 1, maxiter+1 ):\n        D = cdist_sparse( X, centres, metric=metric, p=p )  # |X| x |centres|\n        xtoc = D.argmin(axis=1)  # X -> nearest centre\n        distances = D[allx,xtoc]\n        avdist = distances.mean()  # median ?\n        if verbose >= 2:\n            print(\"kmeans: av |X - nearest centre| = %.4g\" % avdist)\n        if (1 - delta) * prevdist <= avdist <= prevdist \\\n        or jiter == maxiter:\n            break\n        prevdist = avdist\n        for jc in range(k):  # (1 pass in C)\n            c = np.where( xtoc == jc )[0]\n            if len(c) > 0:\n                centres[jc] = X[c].mean( axis=0 )\n    if verbose:\n        print (\"kmeans: %d iterations  cluster sizes:\" % jiter, np.bincount(xtoc))\n    if verbose >= 2:\n        r50 = np.zeros(k)\n        r90 = np.zeros(k)\n        for j in range(k):\n            dist = distances[ xtoc == j ]\n            if len(dist) > 0:\n                r50[j], r90[j] = np.percentile( dist, (50, 90) )\n        print (\"kmeans: cluster 50 % radius\", r50.astype(int))\n        print (\"kmeans: cluster 90 % radius\", r90.astype(int))\n            # scale L1 / dim, L2 / sqrt(dim) ?\n    return centres, xtoc, distances\n#...............................................................................\ndef kmeanssample( X, k, nsample=0, **kwargs ):\n    \"\"\" 2-pass kmeans, fast for large N:\n        1) kmeans a random sample of nsample ~ sqrt(N) from X\n        2) full kmeans, starting from those centres\n    \"\"\"\n        # merge w kmeans ? mttiw\n        # v large N: sample N^1/2, N^1/2 of that\n        # seed like sklearn ?\n    N, dim = X.shape\n    if nsample == 0:\n        nsample = max( 2*np.sqrt(N), 10*k )\n    Xsample = randomsample( X, int(nsample) )\n    pass1centres = randomsample( X, int(k) )\n    samplecentres = kmeans( Xsample, pass1centres, **kwargs )[0]\n    return kmeans( X, samplecentres, **kwargs )\n\ndef cdist_sparse( X, Y, **kwargs ):\n    \"\"\" -> |X| x |Y| cdist array, any cdist metric\n        X or Y may be sparse -- best csr\n    \"\"\"\n        # todense row at a time, v slow if both v sparse\n    sxy = 2*issparse(X) + issparse(Y)\n    if sxy == 0:\n        return cdist( X, Y, **kwargs )\n    d = np.empty( (X.shape[0], Y.shape[0]), np.float64 )\n    if sxy == 2:\n        for j, x in enumerate(X):\n            d[j] = cdist( x.todense(), Y, **kwargs ) [0]\n    elif sxy == 1:\n        for k, y in enumerate(Y):\n            d[:,k] = cdist( X, y.todense(), **kwargs ) [0]\n    else:\n        for j, x in enumerate(X):\n            for k, y in enumerate(Y):\n                d[j,k] = cdist( x.todense(), y.todense(), **kwargs ) [0]\n    return d\n\ndef randomsample( X, n ):\n    \"\"\" random.sample of the rows of X\n        X may be sparse -- best csr\n    \"\"\"\n    random.seed(100)    \n    sampleix = random.sample( range( X.shape[0] ), int(n) )\n    return X[sampleix]\n\ndef nearestcentres( X, centres, metric=\"euclidean\", p=2 ):\n    \"\"\" each X -> nearest centre, any metric\n            euclidean2 (~ withinss) is more sensitive to outliers,\n            cityblock (manhattan, L1) less sensitive\n    \"\"\"\n    D = cdist( X, centres, metric=metric, p=p )  # |X| x |centres|\n    return D.argmin(axis=1)\n\ndef Lqmetric( x, y=None, q=.5 ):\n    # yes a metric, may increase weight of near matches; see ...\n    return (np.abs(x - y) ** q) .mean() if y is not None \\\n        else (np.abs(x) ** q) .mean()\n\n#...............................................................................\nclass Kmeans:\n    \"\"\" km = Kmeans( X, k= or centres=, ... )\n        in: either initial centres= for kmeans\n            or k= [nsample=] for kmeanssample\n        out: km.centres, km.Xtocentre, km.distances\n        iterator:\n            for jcentre, J in km:\n                clustercentre = centres[jcentre]\n                J indexes e.g. X[J], classes[J]\n    \"\"\"\n    def __init__( self, X, k=0, centres=None, nsample=0, **kwargs ):\n        self.X = X\n        if centres is None:\n            self.centres, self.Xtocentre, self.distances = kmeanssample(\n                X, k=k, nsample=nsample, **kwargs )\n        else:\n            self.centres, self.Xtocentre, self.distances = kmeans(\n                X, centres, **kwargs )\n\n    def __iter__(self):\n        for jc in range(len(self.centres)):\n            yield jc, (self.Xtocentre == jc)\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5122be40a077f75606ac4a2e9dfa11c9b0d67932","trusted":false},"cell_type":"code","source":"def clustering(model, k=500, delta=0.00000001, maxiter=200):\n    movie_vec = model.wv.syn0\n    centres, index2cid, dist = kmeanssample(movie_vec, k, \n                                                   metric = 'cosine', \n                                                   delta = delta, \n                                                   nsample = 0, maxiter = maxiter,)\n    clustered_ds = pd.DataFrame( [ (a, b, c) for a, b, c in zip(model.wv.index2word, index2cid, dist )],\n                 columns=['product_id', 'cid', 'dist'] ).sort_values(['cid','dist'], ascending=True)\n\n    prod2cid = { product_id:cid for product_id,cid in zip(model.wv.index2word, index2cid) }\n\n    return (centres, index2cid, dist, clustered_ds, prod2cid)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"56d2d3c0b92bf804eae78fcb0734966d23f57407","trusted":false},"cell_type":"code","source":"(centres, index2cid, dist, clustered_ds, prod2cid) = clustering(model)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"03aa7920a3b1f58be3158cead3e9ca3fc8e90316","trusted":false},"cell_type":"code","source":"clustered_ds.product_id = clustered_ds.product_id.apply(pd.to_numeric)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3729f1e69ca09434c2d025ef6cba4e7946b7ea44","trusted":false},"cell_type":"code","source":"def idToProductDesc(id):\n    return product_ds[product_ds.product_id==id][['product_name','aisle_id']].values.tolist()[0]\n    \ndef getProductNames(product_id_list):\n    return [ idToProductDesc(int(product_id)) for  product_id in product_id_list ]\n\nimport urllib\ndef printClusterMembers(cluster_id, topn=10):\n    members = getProductNames(clustered_ds[clustered_ds.cid==cluster_id].product_id[:topn].tolist())\n    for member in members:\n        print(\"{aisle} / {name} \".format( \n            aisle=member[1], name=member[0], q=urllib.parse.quote_plus(member[0]) ) \n        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a635f3dffddd88e72bc4b6fcb0776502604b4013"},"cell_type":"markdown","source":"### Clustered Result\n### Let's look at clustered product "},{"metadata":{"_uuid":"38aefc934ecee1e581c845dec443bc25bca8588b"},"cell_type":"markdown","source":"* Cluster ID = 0 th"},{"metadata":{"_uuid":"38d4e7d5f46ffcf35c0dcc4f678fa00af9b49b4d","trusted":false},"cell_type":"code","source":"printClusterMembers(1, topn=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3978b9c26ffaf51e1a3c33d969a32378ff19831f"},"cell_type":"markdown","source":"* Cluster ID = 100 th"},{"metadata":{"_uuid":"611730aaf349f8af358be45d345603ada5d543d5","trusted":false},"cell_type":"code","source":"printClusterMembers(100, topn=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"596b5e7ed0419be6cf82c94a42740203c925d9ce"},"cell_type":"markdown","source":"* Cluster ID = 200 th"},{"metadata":{"_uuid":"088686c5e8e35ec06f2d5901afb3906585b263cf","trusted":false},"cell_type":"code","source":"printClusterMembers(200, topn=10)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"cc0ed16270f7b5c86715bc211aa35068cc8b5736"},"cell_type":"markdown","source":"* Cluster ID = 300 th"},{"metadata":{"_uuid":"154d3ee15500922c68c4396a906ac1d6dbad47ed","trusted":false},"cell_type":"code","source":"printClusterMembers(300, topn=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e9c9f908dbe8024b7e0330bf8611950871cc1ec"},"cell_type":"markdown","source":"* Cluster ID = 400 th"},{"metadata":{"_uuid":"8c642f4e6c38c1ffa63e36674682cccae7f10504","trusted":false},"cell_type":"code","source":"printClusterMembers(400, topn=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29687f8479b606f675a349884686061c749775f8"},"cell_type":"markdown","source":"* Cluster ID = 499 th"},{"metadata":{"_uuid":"2baa16d616353c6326fbfe979f0de6b6a7329c3b","trusted":false},"cell_type":"code","source":"printClusterMembers(499, topn=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0e37c9e760905b711cd0017d384a99770ad0c7a"},"cell_type":"markdown","source":"### It looks goooood!! "},{"metadata":{"_uuid":"8fdaf0fffbab3785b41230ae45751d514b99fc07"},"cell_type":"markdown","source":"----\n### Order time trend of clustered product."},{"metadata":{"_uuid":"02a38b7b6709d834ce660b61c20012ba95c3ff81"},"cell_type":"markdown","source":"* Extract representative keywords from each cluster.\n* Reprosentative keywords : 3 words and max 15 latters\n* Sort by popular order hour "},{"metadata":{"collapsed":true,"_uuid":"f9adaf1e32766ae6624fe58be2e34c7aea763a31","trusted":false},"cell_type":"code","source":"# product_reorder_ds.groupby('aisle_id').agg({'product_name':                                           lambda x: })\nfrom collections import defaultdict\nimport operator\n\ndef popularWords(names, topn=2):\n    wordFrequency = defaultdict(int)\n    def updateWords(words):\n        for word in words :\n            if len(word)>1:\n                wordFrequency[word] += 1\n    names.apply(lambda x: updateWords(x.split()))\n    tops = sorted(wordFrequency.items(), key=operator.itemgetter(1),reverse=True)[:topn]\n    return \" \".join([n[0] for n in tops])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee2148f19593db6285fee8d1a67d87a341a79d39","trusted":false},"cell_type":"code","source":"clusterIdToKeywords = { cid: popularWords(sub_ds.product_name,3) for cid, sub_ds in clustered_ds.merge(product_ds, on='product_id').groupby('cid')}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ee7fbfa37749c083ce2f2cd761db9831a05b510"},"cell_type":"markdown","source":"#### Hour of Day Trend Per cluster "},{"metadata":{"collapsed":true,"_uuid":"87927bd91f3188b7fcdf3264d7cf3b9add69c098","trusted":false},"cell_type":"code","source":"product_hod_ds = merge_order_product_ds.pivot_table(index='product_id', columns='order_hour_of_day', values='order_id', aggfunc=len, fill_value=0)\n\norderByHotHour = clustered_ds.merge(product_hod_ds, left_on='product_id', right_index=True)\\\n    .groupby('cid').sum()[np.arange(0,24)].idxmax(axis=1).sort_values().index","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"scrolled":false,"_uuid":"4d914d21d148f0dbd286b6f48dab55c6321516bc","trusted":false},"cell_type":"code","source":"sns.set(style=\"whitegrid\", palette=\"colorblind\", font_scale=1, rc={'font.family':'NanumGothic'} )\n\ndef drawHODCluster(ncols, nrows, startClusterNumber, step):\n    fig, axes = plt.subplots(ncols=ncols, nrows = nrows, figsize=(ncols*2.5,nrows*2), sharex=True, sharey=True)\n\n    for cid, ax  in enumerate(axes.flatten()):\n        cid = startClusterNumber + (cid*step)\n        if cid>=500:\n            break\n        cid = orderByHotHour[cid]\n\n        product_id_list = clustered_ds[clustered_ds.cid==cid].product_id.values\n        tmp_ds = product_hod_ds.loc[product_id_list].T\n        hot_hour = tmp_ds.sum(axis=1).argmax()\n        normalized_ds =(tmp_ds/tmp_ds.max())\n        title = \"{cid}th {n} products \\n({keyword})\".format(cid=cid, n=normalized_ds.shape[1],  keyword=clusterIdToKeywords[cid][:23])\n        normalized_ds.plot(linewidth=.3, legend=False, alpha=.4, ax=ax, title=title, color='r' if hot_hour<13 else 'k')\n        ax.plot((hot_hour,hot_hour),(1,0), '-.', linewidth=1, color='b')\n        ax.text(hot_hour,0,\"{h}h(hot)\".format(h=hot_hour),color='b')\n\n    fig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"9465d7fe222f146957ede6459d1581e1e5abbffa","trusted":false},"cell_type":"code","source":"ncols, nrows=(6,4)\nstep = 3\nfor n in np.arange(0,500,ncols*nrows*step):\n    drawHODCluster(ncols, nrows, n, step)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dbcbf2d6ff12483c74742578a9d4035109bb51a"},"cell_type":"markdown","source":"#### Hour of Day Trend Per cluster "},{"metadata":{"collapsed":true,"_uuid":"98a2b4587fcf7f0c05a081e1cfb7f01eb2feaa97","trusted":false},"cell_type":"code","source":"product_dow_ds = merge_order_product_ds.pivot_table(index='product_id', columns='order_dow', values='order_id', aggfunc=len, fill_value=0)\n\norderByHotDay = clustered_ds.merge(product_dow_ds, left_on='product_id', right_index=True)\\\n    .groupby('cid').sum()[np.arange(0,6)].idxmax(axis=1).sort_values().index","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"scrolled":false,"_uuid":"2bc5611f7b3847e7881f31d36ad9f47ab2b4a797","trusted":false},"cell_type":"code","source":"def drawDOWCluster(ncols, nrows, startClusterNumber, step):\n    sns.set(style=\"whitegrid\", palette=\"colorblind\", font_scale=1, rc={'font.family':'NanumGothic'} )\n    week_day = \"Sun Mon Tue Wed Thu Fri Sat\".split()\n    fig, axes = plt.subplots(ncols=ncols, nrows = nrows, figsize=(ncols*2.5,nrows*2), sharex=True, sharey=True)\n\n    for cid, ax  in enumerate(axes.flatten()):\n        cid = startClusterNumber + (cid*step)\n        if cid>=500:\n            break\n        cid = orderByHotDay[cid]    \n        product_id_list = clustered_ds[clustered_ds.cid==cid].product_id.values\n        tmp_ds = product_dow_ds.loc[product_id_list].T\n        hot_day = tmp_ds.sum(axis=1).argmax()\n        normalized_ds =(tmp_ds/tmp_ds.max())\n        normalized_ds.index = week_day\n        title = \"{cid}th \\n({keyword})\".format(cid=cid, h=hot_day,  keyword=clusterIdToKeywords[cid][:23])\n        normalized_ds.plot(kind='bar', linewidth=.1, legend=False, alpha=.4, ax=ax, title=title, color='r' if hot_day in(0,6) else 'k')\n        ax.plot((hot_day,hot_day),(1,0), '-.', linewidth=2, color='b')\n        # ax.text(hot_day+.3,-.5,\"{h}\".format(h=week_day[hot_day]),color='b')\n    \n    fig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"43fde82493fd64e2d477092e8c88442d3d4c8032","trusted":false},"cell_type":"code","source":"ncols, nrows=(6,4)\nstep = 3\nfor n in np.arange(0,500,ncols*nrows*step):\n    drawDOWCluster(ncols, nrows, n, step)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3a70ec48c1719f7fce73acfd1b6ffbed5b0f60b9","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"48ff9431256ea713bccc0cbfcd6ed3cd5d0a1b47","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}