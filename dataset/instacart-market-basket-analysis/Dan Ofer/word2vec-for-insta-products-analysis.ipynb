{"cells":[{"metadata":{"_uuid":"e65822600fc99d2f42bd8ab3cba045e664ce5e85","_cell_guid":"95ad3815-ad15-1b9e-c5ed-2205ea9b54e3"},"cell_type":"markdown","source":"# Word2Vec on Instacart products\n### The goal of this kernel is to try a Word2Vec model on the data of product orders\n### The orders can act as sentences and product ids can act as words, in this kernel we will see if the model will learn any useful information about the products from the order history of all users, maybe in the future this can be used as input to a classifier that recommends products.\n\n* Original author's kernel's blog post: http://omarito.me/word2vec-product-recommendations/"},{"metadata":{"_uuid":"4e9d916d8f28faadba8eaa79902c87b265de6fd0","_cell_guid":"03ecf8ae-159e-7431-b7f5-02daf1088b5a"},"cell_type":"markdown","source":"### Load the needed libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install umap-learn\n## requires internet connection\n\n## UMAP is typically faster and can be better than PCA or even tsne for dim reduciton ;  https://umap-learn.readthedocs.io/en/latest/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a09f1e18d3090755cfa49561d797063d0b419cdb","_cell_guid":"a76aaef1-be2a-bd72-0929-1047da62e163"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gensim\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"838ace0f4b91158e60891b177d46519deff6d344","_cell_guid":"2b8256c2-d87e-1aa2-0321-12520c11691c"},"cell_type":"markdown","source":"### Load the Data"},{"metadata":{"trusted":true,"_uuid":"ed09f158d784c35358898505f06e986bf90823c8","_cell_guid":"1aa25d77-9705-aea4-f702-39465732e6e0"},"cell_type":"code","source":"orders = pd.concat([pd.read_csv(\"../input/order_products__train.csv\"),pd.read_csv(\"../input/order_products__prior.csv\")])\nprint(\"orders\",orders.shape)\nproducts = pd.read_csv(\"../input/products.csv\").set_index('product_id')\nprint(\"products\",products.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f71367766847b3455e4df3442639957e12255b70","_cell_guid":"ba83c492-a018-aa2e-e9a1-e1a5cfbb4926"},"cell_type":"markdown","source":"### Turn the product ID to a string\n#### This is necessary because Gensim's Word2Vec expects sentences, so we have to resort to this dirty workaround"},{"metadata":{"trusted":true,"_uuid":"48245f664e931d3a52c0a560a8db4f83c0a8fe9f","_cell_guid":"f4991a97-8c21-5ac2-8cc1-97161c2244f7"},"cell_type":"code","source":"orders[\"product_id\"] = orders[\"product_id\"].astype(str)\norders.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8665fbc6694ddff1d54d7b8e619779ab759313c0","_cell_guid":"92937791-23b3-70d5-fa8c-6f012f35326c"},"cell_type":"markdown","source":"### Extract the ordered products in each order"},{"metadata":{"trusted":true,"_uuid":"e375e8d4f9e553cd63e48550d1a90547a2e01773","_cell_guid":"98c1d70f-df71-2216-ac72-8dcb8947cb0a"},"cell_type":"code","source":"# train_products = train_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n# prior_products = prior_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n\n# new \nsentences = orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n# print(sentences.shape)\n# sentences.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48144848b51e8f737e8da21c24c4d1f3df80c663","_cell_guid":"2a515ef5-2317-4642-79ae-7621b8012b70"},"cell_type":"markdown","source":"### Create the final sentences"},{"metadata":{"trusted":true,"_uuid":"f90e439f6b038810b1c018ea5f31d8f9faf37654","_cell_guid":"75f59b73-c8ef-3696-9e71-2f7891538a6e"},"cell_type":"code","source":"# sentences = prior_products.append(train_products)\nlongest = np.max(sentences.apply(len))\nprint(\"longest len\",longest)\nprint(\"mean length\",np.mean(sentences.apply(len)))\nsentences = sentences.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06be8e98d9b2e5c20fd2ac4787aed3872d6ee415","_cell_guid":"c8f3ce28-7e7f-c15f-ef64-712d69b820a2"},"cell_type":"markdown","source":"### Train Word2Vec model\n#### I have modified the window size to be equal to the longest order in our dataset. I've explained why in a blog post that is further explaining this kernel in details\nhttp://omarito.me/word2vec-product-recommendations/\n\n* We could/should also consider setting sentenes not just aacording to ORDERS (i.e baskets), but also by USERS"},{"metadata":{"trusted":true,"_uuid":"495e70dd8c4c68fcf9b1b5526f33970a83233705","_cell_guid":"54935e0b-b61d-eaa5-92a7-651a678d935d"},"cell_type":"code","source":"model = gensim.models.Word2Vec(sentences, size=60, window=longest, min_count=4, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa35a21b39199d7172c78b26fabac43ec6bbc5e3","_cell_guid":"634fb194-b042-a662-538f-dcc24d3dfc17"},"cell_type":"markdown","source":"### Organize data for visualization"},{"metadata":{"trusted":true,"_uuid":"6567eaea1bdd1b44e872600a98eff6350ca8a657","_cell_guid":"6001de86-5a3f-7fe5-1f74-3e31d3e2af14"},"cell_type":"code","source":"vocab = list(model.wv.vocab.keys())","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"3305b5634d6de53f757de5842d768eec66e708f4","_cell_guid":"1a0ed0bb-1635-44fc-b711-64945c388e05"},"cell_type":"markdown","source":"### PCA/lower dimensional embed transform the vectors into 2d\n\n* Could use with multiple steps, e.g. pca and tsne (however, this is wasteful since tsne will refit anyway). \n* Could try (also) with umap. \n* another clustering pipeline example https://gist.github.com/stes/92db6023aa3dab5d13e49ece198102c7\n\n* https://github.com/lmcinnes/umap"},{"metadata":{"trusted":true,"_execution_state":"idle","_uuid":"e83037ec88bced44ed8ae380192422d81d510099","_cell_guid":"8f3ef2fe-2901-47bc-8bff-dd82ef2ccf22"},"cell_type":"code","source":"pca = PCA(n_components=2) # ORIG\n# pca = PCA(n_components=50)\n\n# pca = TSNE(n_components=2)\npca.fit(model.wv.syn0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f495992519eb033a10670ea79aad2ee6bc83632","_cell_guid":"ae7d0731-3cbd-64fe-dabe-b9b7832cf6f1"},"cell_type":"markdown","source":"### Some helpers for visualization"},{"metadata":{"trusted":true,"_uuid":"79c5cb4919ca379de2e3d37d66ff03363259eb7e","_cell_guid":"210b9d90-c397-335e-2517-8e251ed0c5e3"},"cell_type":"code","source":"def get_batch(vocab, model, n_batches=4):\n    output = list()\n    for i in range(0, n_batches):\n        rand_int = np.random.randint(len(vocab), size=1)[0]\n        suggestions = model.most_similar(positive=[vocab[rand_int]], topn=5)\n        suggest = list()\n        for i in suggestions:\n            suggest.append(i[0])\n        output += suggest\n        output.append(vocab[rand_int])\n    return output\n\ndef plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n    \"\"\"From Tensorflow's tutorial.\"\"\"\n    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n    plt.figure(figsize=(18, 18))  #in inches\n    for i, label in enumerate(labels):\n        x, y = low_dim_embs[i,:]\n        plt.scatter(x, y)\n        plt.annotate(label,\n                     xy=(x, y),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n#     plt.savefig(filename)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"253dfb655f4b3172040404e76560a83654f68b27","_cell_guid":"6982b03c-a96f-1055-2116-2a76affe9c90"},"cell_type":"markdown","source":"### Visualize a random sample"},{"metadata":{"trusted":true,"_uuid":"f3422a10542a0512b0da020a0ad51b7f7885299d","_cell_guid":"9b15cdd9-274f-f0b0-6156-29476e60939e"},"cell_type":"code","source":"embeds = []\nlabels = []\nfor item in get_batch(vocab, model, n_batches=4):\n    embeds.append(model[item])\n    labels.append(products.loc[int(item)]['product_name'])\nembeds = np.array(embeds)\nembeds = pca.fit_transform(embeds)\nplot_with_labels(embeds, labels)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56a9fdf3b1256d7e040be7c7df01ac4cd7bc3e79","_cell_guid":"056bdf57-901a-eee4-4d8f-cfb78a82901d"},"cell_type":"markdown","source":"### Save the model"},{"metadata":{"trusted":true,"_uuid":"6b21170f84ace799abe940f658d87ef42beaf04c","_cell_guid":"5e3c7611-1e76-64ff-bd5a-d85ed7b14fbb"},"cell_type":"code","source":"model.save(\"product2vec.model\")","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"_is_fork":false,"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","name":"python"}},"nbformat":4,"nbformat_minor":1}