{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Task. Customer Segmentation\n\n- 데이터를 정제해서, 고객별로 재정렬이 필요합니다. (aggregation)\n\n\n- row가 고객별 데이터로 묶이고 난 다음, 고객들을 유형별로 나눠봅니다.\n\n\n- 여러 가지 클러스터링 알고리즘을 사용하여, 결과를 테스트해봅니다.\n\n\n- 클러스터링을 위한 전처리부터, 평가까지 모든 항목을 하나하나 살펴보면서 데이터를 뜯어봅니다.","metadata":{}},{"cell_type":"markdown","source":"### Data Description\n\nSource : https://www.kaggle.com/c/instacart-market-basket-analysis","metadata":{}},{"cell_type":"markdown","source":"### 1. 데이터 불러오기 ","metadata":{}},{"cell_type":"code","source":"data_path = \"../input/instacart-market-basket-analysis/\"","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:20:48.233798Z","iopub.execute_input":"2021-09-07T15:20:48.234457Z","iopub.status.idle":"2021-09-07T15:20:48.24509Z","shell.execute_reply.started":"2021-09-07T15:20:48.234365Z","shell.execute_reply":"2021-09-07T15:20:48.244159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start, end = [int(x) for x in input(\"돌려보고 싶은 클러스터 개수의 시작과 끝 범위를 입력해주세요 : \").split(\",\")]\ncluster_model = input(\"사용할 클러스터링 모델을 입력하세요(kmeans/hac/dbscan/spectral) : \")\ncolumn_level = input(\"user matrix에 사용할 column을 입력하세요(department/aisle/product_name) : \")\nPCA_mode = True\nif PCA_mode:\n    n_components = int(input(\"PCA에 사용할 n_components 개수를 입력하세요 : \"))\n    \nquick_test = False\nK = list(range(start, end+1))","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:20:48.246563Z","iopub.execute_input":"2021-09-07T15:20:48.246853Z","iopub.status.idle":"2021-09-07T15:21:16.968695Z","shell.execute_reply.started":"2021-09-07T15:20:48.246813Z","shell.execute_reply":"2021-09-07T15:21:16.967785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data Preparation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\norders = pd.read_csv(data_path + \"orders.csv\")\nif quick_test: prior = pd.read_csv(data_path + \"order_products__prior.csv\")[:10000]\nelse : prior = pd.read_csv(data_path + \"order_products__prior.csv\")\ntrain = pd.read_csv(data_path + \"order_products__train.csv\")\nproducts = pd.read_csv(data_path + \"products.csv\")\naisle = pd.read_csv(data_path + \"aisles.csv\")\ndepartment = pd.read_csv(data_path + \"departments.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:21:16.970537Z","iopub.execute_input":"2021-09-07T15:21:16.970851Z","iopub.status.idle":"2021-09-07T15:21:38.811647Z","shell.execute_reply.started":"2021-09-07T15:21:16.97081Z","shell.execute_reply":"2021-09-07T15:21:38.810666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 불러온 모든 테이블을 합칩니다.\ntemp = pd.merge(prior, products, on=[\"product_id\"])\ntemp = pd.merge(temp, orders, on=[\"order_id\"])\ntemp = pd.merge(temp, aisle, on=[\"aisle_id\"])\ndata = pd.merge(temp, department, on=[\"department_id\"])\ndel temp\ndata","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:21:38.813205Z","iopub.execute_input":"2021-09-07T15:21:38.813524Z","iopub.status.idle":"2021-09-07T15:22:32.230418Z","shell.execute_reply.started":"2021-09-07T15:21:38.813496Z","shell.execute_reply":"2021-09-07T15:22:32.228937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 거래내역에 대해서 각 물품을 얼마나 샀을까?\nif quick_test:\n    display(data.product_name.value_counts()[:10]) # top10","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:22:32.233138Z","iopub.execute_input":"2021-09-07T15:22:32.2337Z","iopub.status.idle":"2021-09-07T15:22:32.240459Z","shell.execute_reply.started":"2021-09-07T15:22:32.233628Z","shell.execute_reply":"2021-09-07T15:22:32.239122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 고객의 산 물건의 수\nif quick_test:\n    display(data.user_id.value_counts()[:10])","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:22:32.242022Z","iopub.execute_input":"2021-09-07T15:22:32.242503Z","iopub.status.idle":"2021-09-07T15:22:32.257539Z","shell.execute_reply.started":"2021-09-07T15:22:32.242439Z","shell.execute_reply":"2021-09-07T15:22:32.256189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 거래내역에 포함된 소분류별 개수\nif quick_test:\n    display(data.aisle.value_counts()[:10])","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:22:32.259054Z","iopub.execute_input":"2021-09-07T15:22:32.259481Z","iopub.status.idle":"2021-09-07T15:22:32.272507Z","shell.execute_reply.started":"2021-09-07T15:22:32.259449Z","shell.execute_reply":"2021-09-07T15:22:32.271292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 거래내역에 포함된 대분류별 개수\nif quick_test:\n    display(data.department.value_counts()[:10])","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:22:32.276268Z","iopub.execute_input":"2021-09-07T15:22:32.276662Z","iopub.status.idle":"2021-09-07T15:22:32.28373Z","shell.execute_reply.started":"2021-09-07T15:22:32.27663Z","shell.execute_reply":"2021-09-07T15:22:32.282633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. 데이터 전처리\n\n- 데이터를 transaction 단위로 변경합니다.\n\n- 각자의 방법대로 데이터의 단위를 정해봅시다.\n\n- 결측치를 처리하고, 정규화도 진행해봅니다.\n\n- 필요하면 PCA나 SVD를 사용해도 상관없습니다.\n\n\n> User 단위로 어떤 물품을 구매했는지의 정보만 가지는 feature vector로 변환한다. e.g. pd.crosstab, CountVectorizer","metadata":{}},{"cell_type":"code","source":"columns = [\"product_name\", \"user_id\", \"aisle\", \"department\"] #data.columns\ncolumns = np.array(columns)\ncolumns = np.setdiff1d(data.columns, columns) # 차집합 구하는 함수.\ndata.drop(columns=columns, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:22:32.286171Z","iopub.execute_input":"2021-09-07T15:22:32.286603Z","iopub.status.idle":"2021-09-07T15:22:39.693416Z","shell.execute_reply.started":"2021-09-07T15:22:32.28657Z","shell.execute_reply":"2021-09-07T15:22:39.692245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if column_level == \"department\": user_matrix = pd.crosstab(data.user_id, data.department) # 21d\nelif column_level == \"aisle\" :  user_matrix = pd.crosstab(data.user_id, data.aisle) # 134d\nelse: user_matrix = pd.crosstab(data.user_id, data.product_name) #csr_matrix ## sparse matrix\nuser_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:22:39.694786Z","iopub.execute_input":"2021-09-07T15:22:39.695083Z","iopub.status.idle":"2021-09-07T15:23:21.763587Z","shell.execute_reply.started":"2021-09-07T15:22:39.695056Z","shell.execute_reply":"2021-09-07T15:23:21.762404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. 클러스터링 모델 적용하기\n\n- 사용하는 클러스터링 모델은 KMeans와 AgglomerativeClustering으로 합니다.\n\n(원하시면 DBSCAN이나 SpectralClustering을 사용해보셔도 됩니다. 단, 시간이 매우매우 오래 걸릴수 있으니 주의하세요..)\n\n**[K-Means]**\n\n- Elbow method를 이용하여 최적의 K값을 찾아보세요.\n\n\n- sparse한 특징을 가지는 데이터를 클러스터링 하기 위해서는 어떤 기법을 사용해야 할까요?\n\n\n- 클러스터링 결과를 시각화해보고, 실루엣 지수도 계산해봅시다.\n\n\n\n**[Hierarchical Clustering]**\n\n- 클러스터 개수를 4로 지정하고, linkage와 affinity를 바꿔가면서 실험해보세요.\n\n\n- 어떤 linkage와 affinity를 쓸지 고민하려면, 어떤 방법을 사용해보면 좋을까요?\n\n\n- 클러스터링 결과를 시각화해보고, 실루엣 지수도 계산해봅시다.","metadata":{}},{"cell_type":"code","source":"X = user_matrix.values\nprint(X.shape)\n\nif quick_test:\n    from sklearn.manifold import TSNE\n\n    # tSNE : 시각화용도의 차원감소 기법. (2차원으로 변환해주는 기법)\n    tsne = TSNE(n_components=2)\n    #tsne.fit()\n    #tsne.transform()\n    reduced_data = tsne.fit_transform(X)\n    reduced_data","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:23:21.765269Z","iopub.execute_input":"2021-09-07T15:23:21.765623Z","iopub.status.idle":"2021-09-07T15:23:21.773905Z","shell.execute_reply.started":"2021-09-07T15:23:21.76559Z","shell.execute_reply":"2021-09-07T15:23:21.772431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if quick_test:\n    # 206209 x 2\n    plt.figure(figsize=(12, 12))\n    #sns.scatterplot(data=reduced_data)\n    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=5, alpha=0.3)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T15:23:21.775823Z","iopub.execute_input":"2021-09-07T15:23:21.776386Z","iopub.status.idle":"2021-09-07T15:23:21.789883Z","shell.execute_reply.started":"2021-09-07T15:23:21.776333Z","shell.execute_reply":"2021-09-07T15:23:21.788497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import silhouette_score\n#from sklearn.cluster import KMeans\nfrom sklearn.cluster import MiniBatchKMeans\nfrom tqdm import tqdm_notebook\n\ndef find_optimal_clusters(data, K):\n\n\n    scores = [] # initialization\n\n    for n_cluster in tqdm_notebook(K):\n        #model = KMeans(n_clusters=n_cluster) # 2~10\n        model = MiniBatchKMeans(n_clusters=n_cluster, batch_size=1024)\n        pred = model.fit_predict(data)\n\n        score = silhouette_score(data, pred)\n        scores.append(score)\n        \n    optimal_K = np.array(scores).argmax() + K[0] # K\n    best_pred = KMeans(n_clusters=optimal_K).fit_predict(data)\n    if quick_test:\n        return best_pred, scores\n    else:\n        return best_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-07T16:56:06.01827Z","iopub.execute_input":"2021-09-07T16:56:06.01872Z","iopub.status.idle":"2021-09-07T16:56:06.029591Z","shell.execute_reply.started":"2021-09-07T16:56:06.018668Z","shell.execute_reply":"2021-09-07T16:56:06.028068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find optimal K\n# 1) elbow method  -> yellowbrick    # 설치 이슈.\n# from yellowbrick.cluster import elbow\n\n#     elbow()\n\n# 2) Silhouette score   # sklearn\nif quick_test:\n    best_pred, scores = find_optimal_clusters(X, K)\nelse:\n    best_pred = find_optimal_clusters(X, K)\nprint(\"Find optimal K.\")","metadata":{"execution":{"iopub.status.busy":"2021-09-07T16:56:06.032307Z","iopub.execute_input":"2021-09-07T16:56:06.033081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 클러스터 개수별 실루엣 지수를 그려주는 그래프.\nif quick_test:\n    plt.figure(figsize=(8, 4))\n    plt.title(\"Silhouette Score in range %d-%d\" % (K[0], K[-1]), fontsize=14)\n    plt.xlabel(\"Number of Clusters\")\n    plt.ylabel(\"Silhouette Score\")\n    plt.plot(K, scores)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T23:51:37.430934Z","iopub.execute_input":"2021-09-07T23:51:37.431416Z","iopub.status.idle":"2021-09-07T23:51:37.512335Z","shell.execute_reply.started":"2021-09-07T23:51:37.431321Z","shell.execute_reply":"2021-09-07T23:51:37.510721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if quick_test:\n    # 클러스터별 색칠 공부\n    plt.figure(figsize=(8, 8))\n    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=10, alpha=0.3, c=best_pred)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if quick_test:\n    # 실루엣 계산\n    print(\"Silhouette score : %.4f\" % silhouette_score(X, best_pred)) # [-1, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 차원이 큰 경우엔?\n# 차원의 저주 문제를 해결하기 위해서 차원 감소 기법인 PCA를 적용해봅니다.\nif PCA_mode:\n    from sklearn.decomposition import PCA\n\n    # tsne와 같습니다.\n    # 1) n_components가 int면, 해당 차원으로 감소. # 2) n_components가 float면 해당 비율만큼 보존하는 차원으로 감소.\n    pca = PCA(n_components=n_components)\n    reduced_pca = pca.fit_transform(X)\n    print(reduced_pca.shape)\n    \n    pca_columns = [f\"PC_{n}\" for n in range(1, n_components+1)]\n\n    pca_df = pd.DataFrame(data=reduced_pca, columns=pca_columns)\n    display(pca_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pca된 데이터로 optimal_K를 찾아보세요.\n\nif PCA_mode:\n    # Find optimal K\n    best_pred_pca, scores_pca = find_optimal_clusters(reduced_pca, K)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if quick_test:\n# 클러스터 개수별 실루엣 지수를 그려주는 그래프.\n\n    plt.figure(figsize=(8, 4))\n    plt.title(\"Silhouette Score in range %d-%d\" % (K[0], K[-1]), fontsize=14)\n    plt.xlabel(\"Number of Clusters\")\n    plt.ylabel(\"Silhouette Score\")\n    plt.plot(K, scores_pca)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PCA_mode:\n    # PCA를 적용한 모델에 실루엣 계산\n    print(\"Silhouette score : %.4f\" % silhouette_score(reduced_pca, best_pred_pca)) # [-1, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cluster_model == \"hac\":\n    from sklearn.cluster import AgglomerativeClustering\n\n    model = AgglomerativeClustering(n_clusters=4, affinity=\"euclidean\", linkage=\"average\")\n    if PCA_mode:\n        pred_hac = model.fit_predict(reduced_pca)\n        print(\"Silhouette score : %.4f\" % silhouette_score(reduced_pca, pred_hac)) # [-1, 1]\n    else:\n        pred_hac = model.fit_predict(X)\n        print(\"Silhouette score : %.4f\" % silhouette_score(X, pred_hac)) # [-1, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open(f\"result_{model}_{optimal_K}_{custom_no}.txt\", \"w\") as f:\n#     f.write(str(score))\n#     f.write(~~)\n#     ..\n#     ....","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}