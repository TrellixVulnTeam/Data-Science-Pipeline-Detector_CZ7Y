{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"This course extends Intermediate Python for Data Science to provide a stronger foundation in data visualization in Python. The course provides a broader coverage of the Matplotlib library and an overview of Seaborn (a package for statistical graphics). Topics covered include customizing graphics, plotting two-dimensional arrays (e.g., pseudocolor plots, contour plots, images, etc.), statistical graphics (e.g., visualizing distributions & regressions), and working with time series and image data.\n\nInstacart competition's data is used.\n\n**Objective of this competition:**\n\nIn this competition, Instacart is challenging the Kaggle community to use this anonymized data on customer orders over time to predict which previously purchased products will be in a user’s next order. They’re not only looking for the best model, Instacart’s also looking for machine learning engineers to grow their team.\n\nThe dataset is anonymized and contains a sample of over 3 million grocery orders from more than 200,000 Instacart users.\n\nFor each user, 4 and 100 of their orders are given, with the sequence of products purchased in each order"},{"metadata":{"_cell_guid":"fbbba5f1-d7e6-4c8e-bfd5-ca2b72a082ae","_uuid":"3c3e30ecec2255ec0fbaae7a8a862cfc4787e29e"},"cell_type":"markdown","source":"**Import libraries**"},{"metadata":{"_cell_guid":"e51a75c2-a6a7-47a8-82d6-f490af3ad552","collapsed":true,"_uuid":"c61f8103a6aa0a6534d611b96d2b70fab08ac33d","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline","execution_count":65,"outputs":[]},{"metadata":{"_cell_guid":"31352728-ec8c-4de4-995b-00d3d259811e","collapsed":true,"_uuid":"b796cc2474f9b38fad238b7de1ded091a7e597cb"},"cell_type":"markdown","source":"Data loading:"},{"metadata":{"_cell_guid":"14fd1f8e-0fdf-4666-a801-64b0ee7fa536","_uuid":"afea12bc11c03474f79bca137f689099e4b6a22d","trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output(['ls','../input']).decode('utf8'))\n#print(check_output)","execution_count":66,"outputs":[]},{"metadata":{"_cell_guid":"3ee459fd-4a5f-4467-84d7-13bc8a62f7ba","_uuid":"b5bbc723427ffa1434f505b1803340eaa7d2d580"},"cell_type":"markdown","source":"Read data from the above list of csv files to a dataframe:"},{"metadata":{"_cell_guid":"57b6ea50-26d7-4fc2-9fe8-e56e1e533000","_uuid":"56570a803b38b8978d29bedae206c2235cdfe362","collapsed":true,"trusted":true},"cell_type":"code","source":"df_aisles = pd.read_csv('../input/aisles.csv',low_memory=False)\ndf_departments = pd.read_csv('../input/departments.csv', low_memory=False)\ndf_order_product_prior = pd.read_csv('../input/order_products__prior.csv',low_memory=False)\ndf_order_product_train = pd.read_csv('../input/order_products__train.csv',low_memory=False)\ndf_orders = pd.read_csv('../input/orders.csv',low_memory=False)\ndf_products = pd.read_csv('../input/products.csv',low_memory=False)\n","execution_count":67,"outputs":[]},{"metadata":{"_cell_guid":"dd462c86-2dde-4fc1-9ae1-3d24f9304efe","_uuid":"7b3fe645412f8361ad877eda8806cb06d479a6e6"},"cell_type":"markdown","source":"Always remember to tabular data in tabular form to get ab insight of the data\n\nLets check the orders."},{"metadata":{"_cell_guid":"140f7984-1aa5-4afe-96b0-09f74505921f","_uuid":"a477b2027ea762d8d1ddf089b85b1daf37b572e2","trusted":true},"cell_type":"code","source":"df_orders.head()","execution_count":68,"outputs":[]},{"metadata":{"_uuid":"eaf18d76ac0dc271308331c92bf9600fb6b88db9"},"cell_type":"markdown","source":"The .agg() method can be used with a tuple or list of aggregations as input. When applying multiple aggregations on multiple columns, the aggregated DataFrame has a multi-level column index.\n"},{"metadata":{"trusted":true,"_uuid":"bcdb8375c122ba31b051ad4b980b2af6e23ef079"},"cell_type":"code","source":"crs = df_orders.groupby('user_id')[['order_number','order_dow']].agg({'order_number':'max','order_dow':'sum'})\ncrs.head()","execution_count":69,"outputs":[]},{"metadata":{"_cell_guid":"114e5797-7c63-4a17-b771-7f155f12de20","_uuid":"29adb91cd406c05ac1351fe56030a5712346193b","trusted":true},"cell_type":"code","source":"df_order_product_prior.head()","execution_count":70,"outputs":[]},{"metadata":{"_cell_guid":"581a66a5-c3ad-4dca-b706-826495ce7ab7","_uuid":"0e77b7240af55ac135d7f44a8b28b545d8d73057","trusted":true},"cell_type":"code","source":"df_order_product_train.head()","execution_count":71,"outputs":[]},{"metadata":{"_cell_guid":"293924b4-47c2-48d7-bf0c-0cc3d8bb1449","_uuid":"54e5a8c3bda82dbdbb8f14caeecddea084d5046e"},"cell_type":"markdown","source":"Inference: \n\nThe order table has all the list of orders with details such as - 'order_hour_of_day' - on which hour of the day the order was made,  'days_since_prior_order' - days since the previous order, 'order_id' - order ID and so on...\n\ndf_order_product_prior (vs) df_order_product_train dataset :\n\nBoth the datset has same columns. \n\nThe order table has a columns \"eval_set\" which tells us as to which of the three datasets (prior, train or test) the given row goes to. \n\nThe below EDA will give you a clear understanding of how the order_prior, order_train, order_test is distributed. "},{"metadata":{"_cell_guid":"d8ec8e7b-ccd4-4a12-b269-fc91859bedfe","scrolled":true,"_uuid":"440e45aad0e5b614d23e56120b1585fbf7894804","trusted":true},"cell_type":"code","source":"order_src = df_orders['eval_set'].value_counts()\norder_src","execution_count":72,"outputs":[]},{"metadata":{"_cell_guid":"df201924-a1b4-41f1-a616-9197bffa5e92","_uuid":"419dfc02734f726ed2b377a0a55c7eadc94393b8"},"cell_type":"markdown","source":"Equivalent"},{"metadata":{"_cell_guid":"5efa38fe-08d5-49f9-b6d9-d0fd17bd9732","_uuid":"c2c48259401f3bcfd8c5e3baccf76978ee0f956e","trusted":true},"cell_type":"code","source":"order_src = df_orders['eval_set'].value_counts()\n#order_src.head()\nsns.barplot(order_src.index,order_src.values)\nplt.title('EDA on order dataset to count rows in each orders dataset',fontsize=14)\nplt.xlabel('eval set',fontsize=12)\nplt.ylabel('Number of Occurrences',fontsize=12)\nplt.show()","execution_count":73,"outputs":[]},{"metadata":{"_cell_guid":"59c50a40-0218-4b96-a1ed-0d371d68085d","_uuid":"baf7a444a591f32e445ca6cbd53e9f2fb9c4d396"},"cell_type":"markdown","source":"Lets try to find the patter of orders made:\n\n1. Find on which day of the week the order surges and vice versa by plotting a graph using sns.countplot -  'order_dow' is the day of week.\n2. Similary, Let find on what time of the day the order surges or goes down. This is also quite predicatble based on the region . Eg : People are more likely to shop in the morning than in the midnight,  right from buying milk to sugar (Indian buying pattern) - order_hour_of_day"},{"metadata":{"_cell_guid":"0ac19958-34d8-4eeb-8969-c7bf1d9c7c4c","_uuid":"29d24386304cf93a46d493891a1a2e595bd63242","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='order_dow',data=df_orders)\nplt.title('1. Order by week day',fontsize=14)\nplt.xlabel('week day',fontsize=12)\nplt.ylabel('Count',fontsize=12)\nplt.show()","execution_count":74,"outputs":[]},{"metadata":{"_cell_guid":"19f119ed-cf68-4a04-987b-d0c6faca5e10","_uuid":"5955dd30a3d38f3732859e6d29abea122ae64b3a"},"cell_type":"markdown","source":"0 and 1 could be the weekends, The spike in count suggests that it could be sat and sun respectively, yes ! people shop more on weekends. "},{"metadata":{"_cell_guid":"f5513960-6929-4f6b-9df3-25e936e22501","_uuid":"ccd9ff3f8ce5803aeed15379186d54f631d6eb95","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='order_hour_of_day',data=df_orders)\nplt.title('2. Order by time of the day',fontsize=14)\nplt.xlabel('Time of the day',fontsize=12)\nplt.ylabel('Count',fontsize=12)\nplt.show()","execution_count":75,"outputs":[]},{"metadata":{"_cell_guid":"3462a58f-2548-4918-a831-b16e0f8469c9","_uuid":"9904c3361492b8abc1928c8e8cbb7b4da64d5921"},"cell_type":"markdown","source":"So, the above graph implies the buying pattern , it is quite visible that the orders are majorly made during the day between 9 AM to 5 PM. (9 - 17)\n\nNo it sort of makes sense, that the orders surge in the day time and on saturdays and sunday. But lets see the distribution of the both in one graph using a heatmap. "},{"metadata":{"_uuid":"5b62eeb92032c9a0289de7c52003da928cb0dbe1"},"cell_type":"markdown","source":"groupby: with titanic dataset , for those who have not done the titanic competition, you may be less familiar with the columns names\n\n//Group titanic by 'pclass'\nby_class = titanic.groupby('pclass')\n\n//Aggregate 'survived' column of by_class by count\ncount_by_class = by_class['survived'].count()\n\n//Print count_by_class\nprint(count_by_class)\n\n//Group titanic by 'embarked' and 'pclass'\nby_mult = titanic.groupby(['embarked','pclass'])\n\n// Aggregate 'survived' column of by_mult by count\ncount_mult = by_mult['survived'].count()\n\n// Print count_mult\nprint(count_mult)"},{"metadata":{"_uuid":"4330a2d9208eafebb4687b80200ba38439b9e47e"},"cell_type":"markdown","source":"**PIVOT**  example:  Please fork the notebook to view the dataframe and sample code in a readable way. \n\n**users DataFrame: before pivoting **\n\nweekday    city  visitors  signups\n0     Sun  Austin       139        7\n1     Sun  Dallas       237       12\n2     Mon  Austin       326        3\n3     Mon  Dallas       456        5\n\nprint(users)\n//Pivot the users DataFrame: visitors_pivot\nvisitors_pivot = users.pivot(index='weekday',columns='city',values='visitors')\n\n//Print the pivoted DataFrame\nprint(visitors_pivot)\n\n**users DataFrame after pivoting**\n\ncity     Austin  Dallas\nweekday                \nMon         326     456\nSun         139     237\n\n"},{"metadata":{"_cell_guid":"de315efa-8d14-4c2e-93a4-8eea697f1609","_uuid":"7cbb93e4a1db7f121277a718a3fa14d1b6235c25","trusted":true},"cell_type":"code","source":"grouped_df_groupby = df_orders.groupby([\"order_dow\", \"order_hour_of_day\"])\ngrouped_df = grouped_df_groupby[\"order_number\"].aggregate(\"count\").reset_index()\nprint(grouped_df)\nprint('-----------------------------AFTER PIVOT-------------------------------------')\ngrouped_df = grouped_df.pivot('order_dow', 'order_hour_of_day', 'order_number')\nprint(grouped_df)\nplt.figure(figsize=(10,5))\nsns.heatmap(grouped_df)\nplt.title(\"Frequency of Day of week Vs Hour of day\")\nplt.show()","execution_count":76,"outputs":[]},{"metadata":{"_cell_guid":"76e7a95b-a3bd-4633-a72b-91ba2bc73b05","_uuid":"76a6a3c448309518d61b76532dc83af4fb215cc4"},"cell_type":"markdown","source":"So, the orders have surged on saturday between 12:30 to 16 and sunday between 8 to 11:30 "},{"metadata":{"_cell_guid":"ff982808-95ff-4afe-96c9-b6fdd1698303","_uuid":"55d353fffbcd9792f120a55de460c5851d4a5fbb","collapsed":true,"trusted":false},"cell_type":"markdown","source":"Now, lets explore the '**days_since_prior_order** column.....\n\nI would like to know the time interval between the order since the prior order (confusing isn't !). So, I have this habit of not stocking enough milk for the week as its a pershiable good, so i always go the near by supermarket to buy milk like every single morning, so the interval between my day 1 purchase at the shop and the day 2 puchase at the shop is what we are trying to explore.\n\nThe idea is to explore every single column!!"},{"metadata":{"trusted":true,"_uuid":"0589dde7f95159ce3694c5404890f5ea2e821b5d"},"cell_type":"code","source":"plt.figure(figsize=(17,5))\nsns.countplot(x='days_since_prior_order',data=df_orders)\nplt.title('DAY SINCE THE PRIOR ORDER',fontsize=14)\nplt.xlabel('No of days since the prior order',fontsize=12)\nplt.ylabel('Count',fontsize=12)\nplt.show()","execution_count":77,"outputs":[]},{"metadata":{"_uuid":"071289e20bf3b176da4a88549d3b3a180ab7f3a7"},"cell_type":"markdown","source":"Observation:  7 , 30, 8 , 9, 14, 21, 28 --- observable patterns lah\n\n*  Once in 7 days -- may be toilet rolls\n*  Once in 30 days -- solvents, detergents may be condoms, who knows....\n*  Once in 14 days -- ??? i am leaving it to your choice \n"},{"metadata":{"_uuid":"11be454ce7f9153396aaf1c8fd822288fd8bc6ca"},"cell_type":"markdown","source":"Olrite lads,,, we have this column reorder in our prior and train dataset...\n\nwhat can we do abou it ?? Lets have a look !"},{"metadata":{"trusted":true,"_uuid":"c1527a5bfd1a0ad8d7f5adc4682254d801cb8fc5"},"cell_type":"code","source":"df_order_product_prior.head()","execution_count":78,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0357c4310678e6801ee8c032e8b6624a95ac65bc"},"cell_type":"code","source":"df_order_product_train.head()","execution_count":79,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ad48c00302deb4d773f0ad4b238e1d034e4c078"},"cell_type":"code","source":"df_order_product_prior['reordered'].sum()","execution_count":80,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c70ab53838e42245d4b93881b4b46dc74c46eb6b"},"cell_type":"code","source":" df_order_product_prior.shape","execution_count":81,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58f90377b6c6ffc2155bcdb9dfcc6fa1ab9ed346"},"cell_type":"code","source":"df_order_product_prior['reordered'].sum() /df_order_product_prior.shape[0] * 100","execution_count":82,"outputs":[]},{"metadata":{"_uuid":"5d43c47baeb836a0347a25fc8536326c3e4897fb"},"cell_type":"markdown","source":"Implies, the reorder percentage in prior dataset is 59%"},{"metadata":{"trusted":true,"_uuid":"a223e98bcfc745cc6a9ffd8a4f8dc9f35bdf7605"},"cell_type":"code","source":"df_order_product_train['reordered'].sum()/df_order_product_train.shape[0] * 100","execution_count":83,"outputs":[]},{"metadata":{"_uuid":"03839395f10bdb056876f2ccf15a4d84f0cf307d"},"cell_type":"markdown","source":"Prior dataset and train datset has 59 % of reorders in an order."},{"metadata":{"trusted":true,"_uuid":"0038fcebb1d6fadcb932f1977293668d7039535c"},"cell_type":"code","source":"df_order_product_prior.head()","execution_count":84,"outputs":[]},{"metadata":{"_uuid":"393f4e8a94f67bd7059894bfab7ccaed415219a4"},"cell_type":"markdown","source":"lets see the number of products bought in each order.\n\nadd_to_cart_order - Product added to cart \n\norder id - ID of each order"},{"metadata":{"trusted":true,"_uuid":"87580b6b67bf40fd6c694b4d8a65a594eeb2fb9c"},"cell_type":"code","source":"grouped_df = df_order_product_train.groupby('order_id')['add_to_cart_order'].aggregate('max').reset_index()\ncnt_srs = grouped_df.add_to_cart_order.value_counts()\n\nplt.figure(figsize=(20,8))\nsns.barplot(cnt_srs.index,cnt_srs.values,alpha=0.5)\nplt.title('Number of products bought in each order',fontsize=14)\nplt.xlabel('No of products',fontsize=12)\nplt.ylabel('No of occurance',fontsize=12)\nplt.show()","execution_count":91,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"247432754bb15b19de1c2f8b8954dd24eae11186"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5f9ba7fcfc5f396f5f935b657350b8a1fcc6b826"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"049e76b858b63b4165cd3221f94868b59eb2d55d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}