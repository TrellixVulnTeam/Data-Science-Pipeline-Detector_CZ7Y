{"cells":[{"metadata":{"_uuid":"f19e41a817c6ac8bffc4e44309b757a719925c7a"},"cell_type":"markdown","source":"# Merging DataFrames"},{"metadata":{"_uuid":"2a85d9ae4c781f2882a01e4fa17d45a5a95263fd"},"cell_type":"markdown","source":"# Table of Contents\n\n1.  [Overview](# 1. Overview)\n2.  [products, aisles, departments .csv files](# 2. Products, Aisles, departments csv files)\n3.  [Create a final_products dataframe](# 3. Create a final_products dataframe)\n4.  [orders, order_products_prior, order_products_train .csv files](# 4. orders, order_products_prior, order_products_train .csv files)\n5.  [Create a final_orders dataframe](# 5. Create a final_products dataframe)\n6.  [Merge final_orders with final_products dataframe](# 6. Merge final_orders with final_products dataframe)\n\n"},{"metadata":{"_uuid":"53e83d4c5af64e8bda7274d0cc8706d11208f97d"},"cell_type":"markdown","source":"# 1. Overview\nAt this notebook we will have a deeper look into all available datasets that Instacart provides.<br/>\nLater, we will show how we can combine (merge) all of them into a single DataFrame.<br/>\nBelow you will find a summary of all available .csv files and the main attributes that they hold."},{"metadata":{"_uuid":"93472cbc687ece52a93a986134121daeb39a1245"},"cell_type":"markdown","source":"![CSV_NAMES](https://kaggle2.blob.core.windows.net/forum-message-attachments/183176/6539/instacartFiles.png)"},{"metadata":{"_uuid":"dbda068c30ad47d4062846f81cf70d67e9947496"},"cell_type":"markdown","source":"## 1.1 Import Packages\nAs always, we will first import the pandas package but also a new package called \"gc\" [Garbage Collector].\n"},{"metadata":{"trusted":true,"_uuid":"7ee0e575a6cfff865b76d5d1c39b0a767e754087"},"cell_type":"code","source":"import pandas as pd\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b93c30d3e48f817b6ae1379fc72381d5c5443b88"},"cell_type":"markdown","source":"The gc can be proved really helpful for handling big DataFrames; as every DataFrame manipulation reserves a great amount of memory in our resources (e.g. the RAM memory), gc aims to clean unneeded reserved memory.<br/>\nIn practice, it does not change anything in our computations, but it helps our machine (local or cloud) to better handle next requests."},{"metadata":{"_uuid":"2af755d97da84398f12f77ec7ae4b53af2308bf8"},"cell_type":"markdown","source":"# 2. products, aisles, departments csv files\n## 2.1 Load data from the CSV files\n\nAt this stage we will import our three of our .csv files."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"products = pd.read_csv('../input/products.csv')\naisles = pd.read_csv('../input/aisles.csv')\ndepartments = pd.read_csv('../input/departments.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53b691f765a7dc075bab17f99918674736441f72"},"cell_type":"markdown","source":"## 2.2 View and Understand data\n\nAnd we use the <b>head()</b> function in order to get the first 5 rows of the three first dataframes."},{"metadata":{"trusted":true,"_uuid":"1ff62be60d1770c763ed9a5b7420f3e4b0d87b59","_kg_hide-output":false,"scrolled":true},"cell_type":"code","source":"products.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b547395d266e321f47e2ee6a1bb923b2efd9a4c9"},"cell_type":"markdown","source":"Products table describe the 49688 available products of Instacart with:\n1. product_id as the index (unique value) for each product.\n2. product_name to store the name of the product.\n3. aisle_id to indicate the index of the category that the product belongs.\n4. department_id to indicate the index of which department it belongs.\n\nBelow aisles DF returns the names of the different product categories that Instacart has."},{"metadata":{"trusted":true,"_uuid":"072591c86b63d6b62ca2d402a0d655fc8e616481","_kg_hide-output":false},"cell_type":"code","source":"aisles.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8a3afce7dee1ab2bae506eaf2792601e55ad6db"},"cell_type":"markdown","source":"And departments DF, the names of the different departments of products that Instacart has."},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"08fb1dce92c04d1aedfc8f7d7c1f71fe28b9590f"},"cell_type":"code","source":"departments.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eda0b065a61f39b4dbc70c95565d429338f7b0f4"},"cell_type":"markdown","source":"What we can notice by looking at the dataframes of products, aisles and departments?\n\nAnswer: The dataframe of products includes some columns that we can also see in the dataframes of aisles and departments. <br/>\nThe \"aisle_id\" which can be found on aisles DF & the \"department_id\" which can be found on departments DF.<br/>\nIn reality, these columns on products DF indicate an index that match a record in the DFs aisle & departments\n\nSo for example, if we have a look in first product (product_id = 1) we see that: <br/>\n\"Chocolate Sandwich Cookies\" belong to category with aisle_id = 61 <br/>\nBe checking at the aisles DF the aisle_id=61:"},{"metadata":{"trusted":true,"_uuid":"e8c338542001faa65d8fc72fe1fd2bf9a8235922","scrolled":true},"cell_type":"code","source":"aisles[aisles.aisle_id == 61]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"088f80b01ad82f7d2fca091e40c071a60f7e686e"},"cell_type":"markdown","source":"We see that \"Chocolate Sandwich Cookies\" belong to the product category \"cookies cakes\" <br/>\nIn the same fashion, \"Chocolate Sandwich Cookies\"  have as department_id=19. <br/>\nBy checking on departments DF:"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1c2a5b30a5c1069f47b34dead22f4afe876dc473"},"cell_type":"code","source":"departments[departments.department_id == 19]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1327c7b406956c0121c068ce95d88a77dddee960"},"cell_type":"markdown","source":"We see that \"Chocolate Sandwich Cookies\" also belong to the department \"snacks\" <br/>\nSo, the information regarding the category and department **for each** product, can be found on the aisle & departments DFs. <br/>\nThis means that we can <b>merge</b> these dataframes into a new one. \n\n"},{"metadata":{"_uuid":"ec565c0576b798918a7bd2d74c0f3e13f898ac4f"},"cell_type":"markdown","source":"# 3. Create a final_products dataframe\n\nIn order to create a merged dataframe, we need to join the dataframes we have. We create a new dataframe final_products which contains the dataframes products, aisles and departments. We can see that product dataframe includes the columns \"aisle_id\" and \"department_id\" which are common columns at aisles and departments dataframes too.  Towards this end, we use the merge() function, which performs a join operation by columns or indexes.\n\nFirst of all we have to choose the right type of join in order to create a dataframe with the data we want. There are four types of join:\n1. (INNER) JOIN: Returns records(rows) that have matching values in both dataframes.\n2. LEFT (OUTER) JOIN: Return all records from the leftdataframes, and the matched records from the right dataframes.\n3. RIGHT (OUTER) JOIN: Return all records from the right dataframes, and the matched records from the left dataframes.\n4. FULL (OUTER) JOIN: Return all records when there is a match in either left or right dataframes.\n<img src=\"https://imgur.com/yLDkld9.png\" width=\"400\">"},{"metadata":{"_uuid":"8050c774519daac5d78d8a64e52f4fbce3b81006"},"cell_type":"markdown","source":"## 3.1 Merge of products and aisles dataframes\n\nThe new_products (the merged) dataframe should have only the data we want. We need all rows and columns from this dataframe, and the column <b>\"aisle\"</b> from aisles dataframe. According to the shape above, we understand that we need to use the left join.  \n"},{"metadata":{"trusted":true,"_uuid":"a8404cf0908f9974d48a41657813bf65bea7d20b"},"cell_type":"code","source":"new_products = pd.merge(products,aisles,on=\"aisle_id\", how=\"left\")\nnew_products.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bb7e487c1820feda0e245f99e968faa2643709b"},"cell_type":"markdown","source":"The function we used is the: <b><i>pd.merge(products,aisles)</i></b> Let's explain what happened above:\n* The function by default (without any expressions inside it) makes an <b>inner join</b> between the two dataframes. That's why we used the expression <b>how=\"left\"</b>. Using the expression \"how\" we can use the four types of joins that exist.\n* The function by default uses the common column in order to make the join we asked for. In our example we use the expression <b>on=\"aisle_id\"</b> so we can emphasize at the common column of our dataframes. If you try to run the code without this expression you will see that we will get the same result. Can you imagine in which case, this expression is useful for us?\n\nAnswer:\nIf we want to merge two dataframes which have more than one common columns, we should use the expression \"on\" to indicate the column or the columns that the function will use. E.x:\n\n<i>merge( x, y, on=\"key\")</i>    \n<i>merge( x, y, on=[\"first_key\",\"second_key\"])</i>"},{"metadata":{"_uuid":"7b506f2be2915f99333620c13ccb1784765be1a9"},"cell_type":"markdown","source":"## 3.2 Merge of new_products and departments dataframes\n\nIn this section, we would like to merge the \"new_products\" that we created before with the departments dataframe. In order to study a more complicated case of the function \"merge()\", we will make a small change at the column names of the departments dataframe. We set new labels at columns' names. So let's take it as the default situation and see how we can handle it. "},{"metadata":{"trusted":true,"_uuid":"5ebeb301c8d0bd93669aa0fe40ac9f5cf2b89b7e"},"cell_type":"code","source":" new_products.columns = ['product_id','product_name', \"aisle_id\", \"departments_id\",\"aisle\"]\n new_products.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cba94444a21985c38f87f041ca27ed8f33a8f0f"},"cell_type":"markdown","source":"Looking the \"head()\" function above we can observe that the name of the column <b>\"department_id\"</b> is now <b>\"departments_id\"</b>. As we said previously we would like to merge the dataframe \"new_products\" with the \"departments\". Looking more carefully we will see that the common column is the department_id but its name is different between the two dataframes. How will we handle it?"},{"metadata":{"trusted":true,"_uuid":"0d0a0b2771e3ce9707a68f37e6ee21617c64bbc1"},"cell_type":"code","source":"final_products = pd.merge(new_products,departments,left_on=\"departments_id\",right_on=\"department_id\",how=\"left\")\nfinal_products.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea0774dc8d6c7370469927f4ab54081b89703ce7"},"cell_type":"markdown","source":"The function we used is the: <b><i>pd.merge(new_products,departments,left_on=\"departments_id\",right_on=\"department_id\",how=\"left\")</i></b> Let's explain what happened above:\n* We used the expression <b>how=\"left\"</b> as it happened before.\n* We used the expressions <b>left_on</b> and <b>right_on</b> in order to specify which columns should be used for the merging."},{"metadata":{"_uuid":"42b0e563914b84e77735a439a5ef0d9e37eac3f8"},"cell_type":"markdown","source":"## 3.3 Make a uniform format for string columns\nAt the final_products DF, the columns which contain strings are the product_name , aisle & department. In the following lines, we show how to convert all strings to a single word (convert spaces to underscores and turn all letters to lower)"},{"metadata":{"trusted":true,"_uuid":"7f8e045934378d008ca3c3c04a36c202a9e8a3e9"},"cell_type":"code","source":"final_products.product_name = final_products.product_name.str.replace(' ', '_').str.lower()\nfinal_products.department = final_products.department.str.replace(' ', '_').str.lower()\nfinal_products.aisle= final_products.aisle.str.replace(' ', '_').str.lower()\nfinal_products.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8765e78c49a90dc71f6f02000cc863c0e9b27594"},"cell_type":"markdown","source":"## 3.3 Delete unnecessary columns\n\nFinally, in this section we will delete some columns which are not useful for our new dataframe. This columns are the \"aisles_id\", \"departments_id\", \"department_id\". "},{"metadata":{"trusted":true,"_uuid":"adad9c28257668754b03e1a569ec96bf218f4ade"},"cell_type":"code","source":"del final_products[\"aisle_id\"]\ndel final_products[\"departments_id\"]\ndel final_products[\"department_id\"]\nfinal_products.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"938b73d68bf64922cde0815d4ffb8901bd45de10"},"cell_type":"markdown","source":"# 4. orders, order_products_prior, order_products_train .csv files\n## 4.1 Load data from the CSV files\n\n\nNow let's have look again in the overview of our available .csv files <br/>\n![CSV_NAMES](https://kaggle2.blob.core.windows.net/forum-message-attachments/183176/6539/instacartFiles.png)\n\n\nAt this stage we will work with the rest .csv files, except sample_submission.csv file as it is mainly used for the competition hosted on kaggle.\nFirst we import the csv files:"},{"metadata":{"trusted":true,"_uuid":"ee580d157ff02b31498352336d33bd467f19b14e"},"cell_type":"code","source":"orders = pd.read_csv('../input/orders.csv' )\nop_prior = pd.read_csv('../input/order_products__prior.csv')\nop_train = pd.read_csv('../input/order_products__train.csv' )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"446eb58e4b2bf291433dc4fa298a5a7fe94ccc10"},"cell_type":"markdown","source":"## 4.2 View and Understand data\n\nNow we will explore each DF:"},{"metadata":{"trusted":true,"_uuid":"98d49c18df8b6e9182408f15eba8d23403c9b05e"},"cell_type":"code","source":"orders.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a1040151b7bc7477271f35e1c08b911cef5cc81"},"cell_type":"markdown","source":"The orders DF keeps track of the basic information for each order.\n1. order_id is the unique index key for each order.\n2. user_id is a unique index key for each customer.\n3. eval_set has three distinct values [prior, train, test] ; for the being we will not worry about this attribute.\n4. order_number indicates the rank of a given order of a specific user [in the orders.head( ) we see the first five orders of the user_id=1].\n5. order_dow indicates a day of the week [values 0,1,...6].\n6. order_hour_of_day indicates an hour of the day that an order has been placed.\n7. days_since_prior_order indicates how many days have passed since the previous order [that's why the first order has Not A Number (NaN) value].\n"},{"metadata":{"_uuid":"35b25870caceff58988332842e4e97a568ac17b4","trusted":true},"cell_type":"code","source":"op_prior.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d24e9d05d034f6a4bb11fb602d671332ffb51d38"},"cell_type":"markdown","source":"The op_prior DF keeps track the products purchased on each order\n1. order_id indicates the equivalent key of orders DF.\n2. product_id indicates the unique id of a product purchased in this particular order.\n3. add_to_cart_order indicates the rank of the product added on a specific order.\n4. reordered shows if this product has been reordered from the previous order or not [1: reorder / 0: not reordered].\n\nSo if we would like to see which products does the first order from orders DF include we would have to check all rows that have orded_id=2539329 on op_prior:\n\n\n"},{"metadata":{"trusted":true,"_uuid":"bf7b29344604ad188db1af1a042403b5608d18f0"},"cell_type":"code","source":"op_prior[op_prior.order_id == 2539329]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ceb43d0c03b02a65bec34119dcbe9f33fa51854a"},"cell_type":"markdown","source":"Now op_train DF holds the same info but for these orders labeled as train in the orders DF:\n\n"},{"metadata":{"trusted":true,"_uuid":"83fdb9dcfbc0974f0b226423774c3c3e0df34b47"},"cell_type":"code","source":"op_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9048e5201c7076296ff55fe0c4ce535d098f278"},"cell_type":"markdown","source":"For the scopes of this notebook, we will not examine why there are two DFs which hold the products of each order."},{"metadata":{"_uuid":"aa93dd87c828c8e57c28f0f34a28585890082306"},"cell_type":"markdown","source":"# 5. Create a final_orders dataframe\n## 5.1 Merge  op_prior & op_train with orders\n\nFrom the above example we understand that both op_prior & op_train contain more information of the orders found on orders DF. This information includes the products purchased on a particular order as well as other info. <br/>\n\nAs these two DFs are identical and have the same columns we will merge them one down other.\nWe will take the rows of op_train and we will stick them below the rows of op_prior.<br/>\nDo this we will use the pd.concat( ) function, where we will enter as argument the two DFs in a list"},{"metadata":{"trusted":true,"_uuid":"37e590e27c1e34d102f2ddc7107058e30a272479"},"cell_type":"code","source":"final_orders = pd.concat([op_prior, op_train])\nfinal_orders.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a09d79b11bde1d28473886ded1001ae76f7971dc"},"cell_type":"markdown","source":"Which returns a DF with both op_prior & op_train. <br/>\nNow on DF we will include all the relevant info for each order, from the DF \"orders\" <br/>\nWe will use a left join to DF log, as we want to keep all the products purchased on each order, and we will merge it with \"orders\" DF to fetch all relevant info."},{"metadata":{"trusted":true,"_uuid":"49a92401bdff9c16659bede26367f9fb862ca718"},"cell_type":"code","source":"#execution time 20s\nfinal_orders = pd.merge(final_orders , orders,how='left')\nfinal_orders.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"871e756d12ae0fb4ba07f62108dd1497ada6c5bd"},"cell_type":"markdown","source":"The final DF includes all the orders, as well as the products purchased on each order and other metrics.\nHowever, we see that the first order is that with order_id==2 which means that our rows are not sorted properly. <br/>\nTo perform a sorting in the rows of our DF, we will use the .sort_values( ) method. <br/>\nThe sort_values( ) method requires as an argument a list with the column names to base its sorting. <br/>\nIn our case, we would like to order the DF by the 'order_id' and as a second criterion (when there are repetitive rows with the same value) the 'add_to_cart_order':\n"},{"metadata":{"trusted":true,"_uuid":"72a305d9e7f3818ad6ed433fceeca3fc72a9b3fb"},"cell_type":"code","source":"final_orders.sort_values(['order_id', 'add_to_cart_order'])\nfinal_orders.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9b6ec1fc744876c758d6d3891f28b8417d45413"},"cell_type":"markdown","source":"# 6. Merge final_orders with final_products dataframe"},{"metadata":{"_uuid":"e3450a9383dd260e8230b1cfe0a32f51ae260a36"},"cell_type":"markdown","source":"In the last stage of this notebook, we will merge the final_orders DF with the final_products DF. This will lead to a DF that contains all the available information provided from Instacart."},{"metadata":{"trusted":true,"_uuid":"1f050eba0dc4be5eec630d0f4e1bb4f6eba9eb4c"},"cell_type":"code","source":"final = pd.merge(final_orders, final_products, how='left')\nfinal.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb4d7a55054887c68e184237e926186a63d6dd79"},"cell_type":"markdown","source":"The final DF contains all the orders, all the products placed in each order, as well as all available information regarding each product"},{"metadata":{"_uuid":"d45f2dbe9a320d506aa2043259ea7cb3af8750c3"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"c578034ba2c6ddf3dd8f9ca3821028b1a5fd3037"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}