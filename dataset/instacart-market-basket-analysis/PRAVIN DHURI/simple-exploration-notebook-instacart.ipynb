{"metadata":{"language_info":{"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","name":"python","version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1,"cells":[{"metadata":{},"source":" # Instacart Market Basket Analysis","cell_type":"markdown"},{"metadata":{},"source":"Let's Start with Importing the Modules ","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\ncolor = sns.color_palette()\n\n%matplotlib inline","cell_type":"code","outputs":[]},{"metadata":{},"source":"List out the files and their size that are present in directory ","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"INPUT_FOLDER='/Users/pd186040/Documents/Kaggle/Instacart/'\nprint ('File Sizes:')\nfor f in os.listdir(INPUT_FOLDER):\n    if 'zip' not in f:\n       print (f.ljust(30) + str(round(os.path.getsize(INPUT_FOLDER +  f) / 1000, 2)) + ' KB')","cell_type":"code","outputs":[]},{"metadata":{},"source":"Let us first read all the files as dataframe objects and then look at the top few rows.","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"order_products_train_df = pd.read_csv(\"/Users/pd186040/Documents/Kaggle/Instacart/order_products__train.csv\")\norder_products_prior_df = pd.read_csv(\"/Users/pd186040/Documents/Kaggle/Instacart/order_products__prior.csv\")\norders_df = pd.read_csv(\"/Users/pd186040/Documents/Kaggle/Instacart/orders.csv\")\nproducts_df = pd.read_csv(\"/Users/pd186040/Documents/Kaggle/Instacart/products.csv\")\naisles_df = pd.read_csv(\"/Users/pd186040/Documents/Kaggle/Instacart/aisles.csv\")\ndepartments_df = pd.read_csv(\"/Users/pd186040/Documents/Kaggle/Instacart/departments.csv\")","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"print(\"The orders_df size is :\", orders_df.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"orders_df.head(20)","cell_type":"code","outputs":[]},{"metadata":{},"source":"As we could see, orders.csv has all the information about the given order id like the user who has purchased the order, when was it purchased, days since prior order and so on.","cell_type":"markdown"},{"metadata":{},"source":"We can also note that there is a column in orders.csv file called eval_set which tells us as to which of the three datasets (prior, train or test) the given row goes to.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"print(\"The order_products_prior_df size is : \", order_products_prior_df.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"scrolled":true},"source":"order_products_prior_df.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"print(\"The order_products_train_df size is : \", order_products_train_df.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"order_products_train_df.head()","cell_type":"code","outputs":[]},{"metadata":{},"source":"The columns present in order_products_train and order_products_prior are same. Then what is the difference between these files.?","cell_type":"markdown"},{"metadata":{},"source":"As mentioned earlier, in this dataset, 4 to 100 orders of a customer are given (we will look at this later) and we need to predict the products that will be re-ordered. So the last order of the user has been taken out and divided into train and test sets. All the prior order informations of the customer are present in order_products_prior file. ","cell_type":"markdown"},{"execution_count":null,"metadata":{"scrolled":true},"source":"print(\"The products_df size is :\", products_df.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"scrolled":true},"source":"products_df.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"print(\"The aisles_df size is :\", aisles_df.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"aisles_df.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"print(\"The departments_df size is :\", departments_df.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"scrolled":false},"source":"departments_df.head()","cell_type":"code","outputs":[]},{"metadata":{},"source":"# Data Cleaning","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"#checking for missing values\ntotal=orders_df.isnull().sum()\ntotal","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#checking for the percentage\npercentage=total/orders_df.isnull().count()\npercentage","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"missing_value_table_orders = pd.concat([total,percentage],keys=['Total','Percentage'],axis=1)\nmissing_value_table_orders","cell_type":"code","outputs":[]},{"metadata":{},"source":"We can see that only 6% of days_since_prior_order column is null. So we can exclude them and use the data.","cell_type":"markdown"},{"execution_count":null,"metadata":{"scrolled":false},"source":"orders_df_new=orders_df[orders_df['days_since_prior_order'].notnull()]\norders_df_new.head()","cell_type":"code","outputs":[]},{"metadata":{},"source":"Similarly, we check for missing values for all the other 5 data sets to clean the data.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"#aisles\ntotal_a=aisles_df.isnull().count()\ntotal_a","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"percentage_a=total_a/aisles_df.isnull().count()\npercentage_a","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"missing_value_table_aisles = pd.concat([total_a, percentage_a],keys=['Total','Percentage'],axis=1)\nmissing_value_table_aisles","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#departments\ntotal_d=departments_df.isnull().count()\ntotal_d","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"percentage_d=total_d/departments_df.isnull().count()\npercentage_d","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"missing_value_table_departments = pd.concat([total_d,percentage_d],keys=['Total','Percentage'],axis=1)\nmissing_value_table_departments","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#orders_prior\ntotal_order_p_p=order_products_prior_df.isnull().sum()\ntotal_order_p_p","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"percentage_order_p_p=total_order_p_p/order_products_prior_df.isnull().count()\npercentage_order_p_p","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"missing_value_table_order_p_p = pd.concat([total_order_p_p,percentage_order_p_p],keys=['Total','Percentage'],axis=1)\nmissing_value_table_order_p_p","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#order_train\ntotal_order_train=order_products_train_df.isnull().sum()\ntotal_order_train","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"percentage_order_train=total_order_train/order_products_train_df.isnull().count()\npercentage_order_train","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"missing_value_table_order_train = pd.concat([total_order_train,percentage_order_train],keys=['Total','Percentage'],axis=1)\nmissing_value_table_order_train","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#products\ntotal_products=products_df.isnull().sum()\ntotal_products","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"percentage_products=total_products/products_df.isnull().count()\npercentage_products","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"missing_value_table_products = pd.concat([total_products,percentage_products],keys=['Total','Percentage'],axis=1)\nmissing_value_table_products","cell_type":"code","outputs":[]},{"metadata":{},"source":"\nLooking at the other 5 data sets we see that there are no missing values and hence conclude the data cleaning process","cell_type":"markdown"},{"metadata":{},"source":"# Exploratory Data Analysis & Data Visualization","cell_type":"markdown"},{"metadata":{},"source":"\n\nLet us first get the count of rows in each of the three sets.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"def get_unique_count(x):\n    return len(np.unique(x))\n\n\ncnt_eval = orders_df.groupby(\"eval_set\")[\"user_id\"].aggregate(get_unique_count)\ncnt_eval","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.barplot(cnt_eval.index, cnt_eval.values, alpha=0.8, color=color[1])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Eval set type', fontsize=12)\nplt.title('Count of rows in each dataset', fontsize=15)\nplt.xticks(rotation='vertical')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"So there are 206,209 customers in total. Out of which, the last purchase of 131,209 customers are given as train set and we need to predict for the rest 75,000 customers.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"count=orders_df['eval_set'].value_counts()\ncount","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.barplot(count.index, count.values)\nplt.ylabel('Number of Occurrences in the dataset', fontsize=14)\nplt.xlabel('Evaluation set type', fontsize=14)\nplt.title('Eval_set breakdown in orders dataset', fontsize=16)","cell_type":"code","outputs":[]},{"metadata":{},"source":"Now let us validate the claim that 4 to 100 orders of a customer are given.","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"cnt_orders = orders_df.groupby(\"user_id\")[\"order_number\"].aggregate(np.max).reset_index()\ncnt_orders = cnt_orders.order_number.value_counts()\n","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.barplot(cnt_orders.index, cnt_orders.values, color=color[4])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Maximum order number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"So there are no orders less than 4 and is max at 100 as given in the data page","cell_type":"markdown"},{"metadata":{},"source":"# Time of Order","cell_type":"markdown"},{"metadata":{},"source":"Time at which people usually order products.","cell_type":"markdown"},{"metadata":{},"source":"# Days of Orders in a week:","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"order_dow\", data=orders_df, color=color[3])\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Day of week', fontsize=12)\nplt.title(\"Frequency of order by week day\", fontsize=15)\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"Seems like 0 and 1 is Saturday and Sunday when the orders are high","cell_type":"markdown"},{"metadata":{},"source":"# Hour of Order in a Day:","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"order_hour_of_day\", data=orders_df, color=color[5])\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Hour of day', fontsize=12)\nplt.title(\"Frequency of order by hour of day\", fontsize=15)\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"People mostly order between 8 and 19 (probably between 8 a.m and 7 p.m.)","cell_type":"markdown"},{"metadata":{},"source":" Now let us combine the day of week and hour of day to see the distribution.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"grouped_df = orders_df.groupby([\"order_dow\", \"order_hour_of_day\"])[\"order_number\"].aggregate(\"count\").reset_index()\ngrouped_df.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"grouped_df = grouped_df.pivot('order_dow', 'order_hour_of_day', 'order_number')\ngrouped_df","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.heatmap(grouped_df)\nplt.title(\"Frequency of Day of week Vs Hour of day\")\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"Seems Satuday evenings and Sunday mornings are the prime time for orders.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"days_since_prior_order\", data=orders_df, color=color[2])\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Days since prior order', fontsize=12)\nplt.title(\"Frequency distribution by days since prior order\", fontsize=15)\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"From this plot we can see that 7th day is where we have a spike, and then a relative small peak at days 14,21 and 28 which indicates that every 7 days or weekly is the order frequency. And then again there's a huge peak at the end of the month indicating that there's a monthly peak","cell_type":"markdown"},{"metadata":{},"source":"Since our objective is to figure out the re-orders, let us check out the re-order percentage in prior set and train set.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"# percentage of re-orders in orders_products_prior\nprint(\"Percent of reorders in prior set:\") \nprint(order_products_prior_df.reordered.sum() / len(order_products_prior_df))","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"# percentage of re-orders in orders_products_train\nprint(\"Percent of reorders in train set:\") \nprint(order_products_train_df.reordered.sum() / len(order_products_train_df))","cell_type":"code","outputs":[]},{"metadata":{},"source":"On an average, about 59% of the products in an order are re-ordered products","cell_type":"markdown"},{"metadata":{},"source":"Now let us merge these product details with the order_prior details.","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"#merging order_products_prior and products\norder_products_prior_df_merged = pd.merge(order_products_prior_df, products_df, on='product_id', how='left')\n\n#merging op_merged with aisles\norder_products_prior_df_merged = pd.merge(order_products_prior_df_merged, aisles_df, on='aisle_id', how='left')\n\n#merging the new op_prior_merged with departments\norder_products_prior_df_merged = pd.merge(order_products_prior_df_merged, departments_df, on='department_id', how='left')","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"order_products_prior_df_merged.head()","cell_type":"code","outputs":[]},{"metadata":{},"source":"# Most ordered Products\nNow let's identify which products are ordered the most.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"cnt_srs = order_products_prior_df_merged['product_name'].value_counts().reset_index().head(10)\ncnt_srs.columns = ['product_name', 'frequency_count']\ncnt_srs","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"cnt_srs = cnt_srs.groupby(['product_name']).sum()['frequency_count'].sort_values(ascending=False)\nsns.set_style('darkgrid')\nf, ax = plt.subplots(figsize=(12, 10))\nsns.barplot(cnt_srs.index, cnt_srs.values)\nplt.xticks(rotation='vertical')\nplt.ylabel('Number of Reorders', fontsize=13)\nplt.xlabel('Most ordered Products', fontsize=13)\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"# Aisles:\n\nNow let us look at the important aisles.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"cnt_aisle = order_products_prior_df_merged['aisle'].value_counts().head(20)\ncnt_aisle","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.barplot(cnt_aisle.index, cnt_aisle.values, alpha=0.8, color=color[5])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Aisle', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"From this graph we can see that the fresh food and fresh vegetables aisles are the most frequently visited. We can do the same analysis for department","cell_type":"markdown"},{"metadata":{},"source":"# Department Distribution:\n\nLet us now check the department wise distribution.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"cnt_aisle = order_products_prior_df_merged['department'].value_counts().head(20)\ncnt_aisle","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,8))\nsns.barplot(cnt_aisle.index, cnt_aisle.values, alpha=0.8, color=color[2])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Departments', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"From the graph we can see that the department wise frequency is more for produce which aligns with the aisles frequency and then for dairy eggs.","cell_type":"markdown"},{"metadata":{},"source":"# Most important Aisles in each Department","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"grouped =order_products_prior_df_merged.groupby([\"department\", \"aisle\"])[\"product_id\"].aggregate({'Total_products': 'count'}).reset_index()\ngrouped.sort_values(by='Total_products', ascending=False, inplace=True)\ngrouped.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"scrolled":false},"source":"fig, axes = plt.subplots(7,3, figsize=(20,45), gridspec_kw =  dict(hspace=1.4))\nfor (aisle, group), ax in zip(grouped.groupby([\"department\"]), axes.flatten()):\n    g = sns.barplot(group.aisle, group.Total_products , ax=ax)\n    ax.set(xlabel = \"Aisles\", ylabel=\" Number of products\")\n    g.set_xticklabels(labels = group.aisle,rotation=90, fontsize=12)\n    ax.set_title(aisle, fontsize=15)","cell_type":"code","outputs":[]},{"metadata":{},"source":"# Reorders:","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"#merge order_product_prior with orders \nmerged_reorders = pd.merge(order_products_prior_df, orders_df, on='order_id', how='left')\nmerged_reorders.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"count_reordered = merged_reorders['reordered'].value_counts()\ncount_reordered","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(6,12))\nsns.barplot(count_reordered.index, count_reordered.values)\nplt.ylabel('Frequencies', fontsize=14)\nplt.xlabel('Reordered', fontsize=4)\nplt.show()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#finding reorders against day of the week\ngrouped_reorders_dow = merged_reorders.groupby([\"order_dow\"])[\"reordered\"].aggregate(\"count\").reset_index()\ngrouped_reorders_dow","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(6,12))\nsns.barplot(grouped_reorders_dow.order_dow, grouped_reorders_dow.reordered)\nplt.ylabel('Total number of reordered products', fontsize=14)\nplt.xlabel('order_day_of_week', fontsize=14)\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"From this graph, we can see that most products are reordered on Saturday followed by Sunday and Friday. Which follows the same trend as orders placed over the week.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"#finding reorders against hour of the day\ngrouped_reorders = merged_reorders.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"count\").reset_index()\ngrouped_reorders","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"plt.figure(figsize=(12,12))\nsns.barplot(grouped_reorders.order_hour_of_day, grouped_reorders.reordered)\nplt.ylabel('Total number of reordered products', fontsize=14)\nplt.xlabel('order_hour_of_day', fontsize=14)\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{},"source":"This graph shows that most products are reordered from 9am-5pm. This aligns with the number of products ordered during the week and the weekends.","cell_type":"markdown"},{"execution_count":null,"metadata":{},"source":"merged1 = pd.merge(order_products_train_df, orders_df, on='order_id', how='left')\nmerged1.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"df_merged1 = pd.merge(merged1, products_df, on='product_id', how='left')\ndf_merged1.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#merging all the datasets to get a final train dataset\ndf = pd.merge(df_merged1, departments_df, on='department_id', how='left')\ndf.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"df_new = df.copy()\ndf_new.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"del df['eval_set']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"del df['add_to_cart_order']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"scrolled":true},"source":"df.head()","cell_type":"code","outputs":[]},{"metadata":{},"source":"# Algo","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"\n#Variable to be predicted\ny=df['reordered']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"del df['reordered']\ndel df['product_name']\ndel df['department']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"df.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"\nfrom sklearn.model_selection import train_test_split","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"Xtr, Xtest, ytr, ytest = train_test_split(df, y, test_size=0.30, random_state=5)\n","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"Xtr.shape\n","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"from sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"\n#Logistic Regression model\nclf=(LogisticRegression(C=0.02))","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#fitting the model\nclf.fit(Xtr, ytr)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"#predictions\npred=clf.predict(Xtest)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"pred","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"#accuracy score of Logistic Regression Model\nprint(accuracy_score(clf.predict(Xtest), ytest))","cell_type":"code","outputs":[]}],"nbformat":4}