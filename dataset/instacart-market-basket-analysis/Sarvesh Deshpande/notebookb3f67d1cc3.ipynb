{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-22T14:25:45.938821Z","iopub.execute_input":"2022-03-22T14:25:45.93909Z","iopub.status.idle":"2022-03-22T14:25:45.9497Z","shell.execute_reply.started":"2022-03-22T14:25:45.939062Z","shell.execute_reply":"2022-03-22T14:25:45.948557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Jovian commit essentials\n# import jovian\n# jovian.set_project('course-project-machine-learning-local')\n\n# Data analysis \nimport pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\n\n# ML models\nimport xgboost as xgb\nfrom xgboost import plot_tree\nfrom xgboost import plot_importance\nimport lightgbm as lgb\n\n# Models performance evaluation\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n# File saving\nimport joblib\n\n# Plotting\nimport matplotlib.pyplot as plt\nfrom matplotlib.pylab import rcParams\n%matplotlib inline\nimport seaborn as sns\ncolor = sns.color_palette()\n\n# Miscellaneous\nimport warnings\nfrom tabulate import tabulate\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:25:51.65388Z","iopub.execute_input":"2022-03-22T14:25:51.654821Z","iopub.status.idle":"2022-03-22T14:25:54.156721Z","shell.execute_reply.started":"2022-03-22T14:25:51.654777Z","shell.execute_reply":"2022-03-22T14:25:54.155708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# import opendatasets as od\npd.set_option('display.max_columns', 120)\npd.set_option('display.max_rows', 120)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:25:56.527205Z","iopub.execute_input":"2022-03-22T14:25:56.527578Z","iopub.status.idle":"2022-03-22T14:25:56.533568Z","shell.execute_reply.started":"2022-03-22T14:25:56.52755Z","shell.execute_reply":"2022-03-22T14:25:56.532308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since the zip archives have multiple files, we need to unzip them first, then use de read_csv for each file, while converting numerical columns to each dtype:\nfrom zipfile import ZipFile\n\npath_dataset = '/kaggle/input/instacart-market-basket-analysis'\nzip_file = ZipFile(path_dataset+'/orders.csv.zip')\norders_df = pd.read_csv(zip_file.open('orders.csv'), dtype={\n        'order_id': np.int32,\n        'user_id': np.int32,\n        'eval_set': 'category',\n        'order_number': np.int16,\n        'order_dow': np.int8,\n        'order_hour_of_day': np.int8,\n        'days_since_prior_order': np.float32})\n\nzip_file = ZipFile(path_dataset+'/products.csv.zip')\nproducts_df = pd.read_csv(zip_file.open('products.csv'), dtype={\n        'product_id': np.uint16,\n        'order_id': np.int32,\n        'aisle_id': np.uint8,\n        'department_id': np.uint8})\n\nzip_file = ZipFile(path_dataset+'/order_products__train.csv.zip')\norder_products__train_df = pd.read_csv(zip_file.open('order_products__train.csv'), dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\n\nzip_file = ZipFile(path_dataset+'/order_products__prior.csv.zip')\norder_products__prior_df = pd.read_csv(zip_file.open('order_products__prior.csv'), dtype={\n            'order_id': np.int32,\n            'product_id': np.uint16,\n            'add_to_cart_order': np.int16,\n            'reordered': np.int8})\n\nzip_file = ZipFile(path_dataset+'/aisles.csv.zip')\naisles_df = pd.read_csv(zip_file.open('aisles.csv'))\n\nzip_file = ZipFile(path_dataset+'/departments.csv.zip')\ndepartments_df = pd.read_csv(zip_file.open('departments.csv'))\n\nzip_file = ZipFile(path_dataset+'/sample_submission.csv.zip')\nsample_submission = pd.read_csv(zip_file.open('sample_submission.csv'))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:25:58.416011Z","iopub.execute_input":"2022-03-22T14:25:58.416251Z","iopub.status.idle":"2022-03-22T14:26:20.007676Z","shell.execute_reply.started":"2022-03-22T14:25:58.416229Z","shell.execute_reply":"2022-03-22T14:26:20.006608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking all the created dataframes\norders_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:22.144225Z","iopub.execute_input":"2022-03-22T14:26:22.144487Z","iopub.status.idle":"2022-03-22T14:26:22.161591Z","shell.execute_reply.started":"2022-03-22T14:26:22.14446Z","shell.execute_reply":"2022-03-22T14:26:22.160925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"products_df.head()\naisles_df.head()\ndepartments_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:23.321065Z","iopub.execute_input":"2022-03-22T14:26:23.321822Z","iopub.status.idle":"2022-03-22T14:26:23.333855Z","shell.execute_reply.started":"2022-03-22T14:26:23.321781Z","shell.execute_reply":"2022-03-22T14:26:23.332723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging product related dfs as a single products_df\nproducts_df = products_df.merge(aisles_df).merge(departments_df)\nproducts_df.drop(['aisle_id', 'department_id'], axis=1, inplace=True)\nproducts_df","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:24.401878Z","iopub.execute_input":"2022-03-22T14:26:24.402168Z","iopub.status.idle":"2022-03-22T14:26:24.456136Z","shell.execute_reply.started":"2022-03-22T14:26:24.402137Z","shell.execute_reply":"2022-03-22T14:26:24.454993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_products__train_df\norder_products__prior_df\norders_df['eval_set'].unique()\n# Checking the sample submission file\nsample_submission","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:25.517929Z","iopub.execute_input":"2022-03-22T14:26:25.51821Z","iopub.status.idle":"2022-03-22T14:26:25.548074Z","shell.execute_reply.started":"2022-03-22T14:26:25.518182Z","shell.execute_reply":"2022-03-22T14:26:25.547118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the total amount of individual costumers present in the orders_df.\ndef get_unique_counts(x):\n    return len(np.unique(x))\n\nprint(orders_df.groupby('eval_set')['user_id'].aggregate(get_unique_counts))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:26.468574Z","iopub.execute_input":"2022-03-22T14:26:26.469393Z","iopub.status.idle":"2022-03-22T14:26:26.742429Z","shell.execute_reply.started":"2022-03-22T14:26:26.469349Z","shell.execute_reply":"2022-03-22T14:26:26.741722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the occurrences of the maximum order numbers\norder_num = orders_df.groupby('user_id')['order_number'].aggregate(np.max).reset_index()\norder_num = order_num['order_number'].value_counts()\n\nplt.figure(figsize=(18,10))\nsns.barplot(x=order_num.index, y=order_num.values, alpha=0.8, color='green')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Maximum order number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:27.715225Z","iopub.execute_input":"2022-03-22T14:26:27.715676Z","iopub.status.idle":"2022-03-22T14:26:29.171314Z","shell.execute_reply.started":"2022-03-22T14:26:27.715621Z","shell.execute_reply":"2022-03-22T14:26:29.170649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the orders by day of the week\norders_dow = orders_df['order_dow']\n\nplt.figure(figsize=(12,10))\nsns.countplot(x=orders_dow, data=orders_df, alpha=0.8, color='red')\nplt.ylabel('Number of orders', fontsize=12)\nplt.xlabel('Day of the week', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:30.588221Z","iopub.execute_input":"2022-03-22T14:26:30.588737Z","iopub.status.idle":"2022-03-22T14:26:33.041222Z","shell.execute_reply.started":"2022-03-22T14:26:30.588691Z","shell.execute_reply":"2022-03-22T14:26:33.040727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the orders by hour of the day\norders_hotd = orders_df['order_hour_of_day']\n\nplt.figure(figsize=(18,10))\nsns.countplot(x=orders_hotd, data=orders_df, alpha=0.9, color='purple')\nplt.ylabel('Number of orders', fontsize=12)\nplt.xlabel('Hour of the day', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:34.458283Z","iopub.execute_input":"2022-03-22T14:26:34.458982Z","iopub.status.idle":"2022-03-22T14:26:37.37837Z","shell.execute_reply.started":"2022-03-22T14:26:34.458942Z","shell.execute_reply":"2022-03-22T14:26:37.377523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the amount of days since last order\norders_dspo = orders_df['days_since_prior_order']\n\nplt.figure(figsize=(18,10))\nsns.countplot(x=orders_dspo, data=orders_df, alpha=0.9, color='orange')\nplt.ylabel('Number of orders', fontsize=12)\nplt.xlabel('Days since prior order', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:38.846764Z","iopub.execute_input":"2022-03-22T14:26:38.847355Z","iopub.status.idle":"2022-03-22T14:26:43.270323Z","shell.execute_reply.started":"2022-03-22T14:26:38.847311Z","shell.execute_reply":"2022-03-22T14:26:43.269562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product_amount = order_products__train_df.groupby('order_id')['add_to_cart_order'].aggregate(np.max).reset_index()\nproduct_count = product_amount.add_to_cart_order.value_counts()\n\nfig, ax = plt.subplots(figsize=(18,10))\n\nax.bar(x=product_count.index, height=product_count.values, alpha=0.9, color = 'red')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of Items', fontsize=12)\nplt.xticks(rotation='vertical')\nax.annotate('Most common amount of items per order: {:.0f}'.format(product_count.idxmax()), xy=(6, 8900), xytext=(11, 8300), fontsize=12, arrowprops=dict(facecolor='black', shrink=0.05))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:44.592973Z","iopub.execute_input":"2022-03-22T14:26:44.593245Z","iopub.status.idle":"2022-03-22T14:26:44.972241Z","shell.execute_reply.started":"2022-03-22T14:26:44.593219Z","shell.execute_reply":"2022-03-22T14:26:44.971047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestsellers = order_products__prior_df.groupby('product_id')['add_to_cart_order'].count().sort_values(ascending=False).reset_index()\n# Merging dfs to get the product names for the best sellers\nbestsellers = bestsellers.merge(products_df[['product_id','product_name']])\n# Checking top 10\nbestsellers.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:46.338303Z","iopub.execute_input":"2022-03-22T14:26:46.338755Z","iopub.status.idle":"2022-03-22T14:26:47.109837Z","shell.execute_reply.started":"2022-03-22T14:26:46.338715Z","shell.execute_reply":"2022-03-22T14:26:47.109082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestsellers_train = order_products__train_df.groupby('product_id')['add_to_cart_order'].count().sort_values(ascending=False).reset_index()\n# Merging dfs to get the product names for the best sellers\nbestsellers_train = bestsellers_train.merge(products_df[['product_id','product_name']], on='product_id')\n# Checking top 10\nbestsellers_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:48.302261Z","iopub.execute_input":"2022-03-22T14:26:48.302553Z","iopub.status.idle":"2022-03-22T14:26:48.375263Z","shell.execute_reply.started":"2022-03-22T14:26:48.302516Z","shell.execute_reply":"2022-03-22T14:26:48.374478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"products_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:49.386186Z","iopub.execute_input":"2022-03-22T14:26:49.386448Z","iopub.status.idle":"2022-03-22T14:26:49.398239Z","shell.execute_reply.started":"2022-03-22T14:26:49.38642Z","shell.execute_reply":"2022-03-22T14:26:49.397227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merging products related dataframes with orders\nproducts = products_df.merge(aisles_df).merge(departments_df)\nproducts.drop([\"aisle_id\", \"department_id\"], axis=1, inplace=True)\nordert = order_products__train_df.merge(orders_df[[\"order_id\",\"user_id\"]])\norders_products = order_products__prior_df.merge(orders_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:50.343796Z","iopub.execute_input":"2022-03-22T14:26:50.344053Z","iopub.status.idle":"2022-03-22T14:26:58.523892Z","shell.execute_reply.started":"2022-03-22T14:26:50.344026Z","shell.execute_reply":"2022-03-22T14:26:58.522982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting products ordered first and second times to calculate probability\nprd2 = orders_products.sort_values(['user_id', 'order_number', 'product_id'], ascending=True)\nprd2['product_time'] = orders_products.groupby(['user_id', 'product_id']).cumcount()+1\nsub1 = prd2[prd2['product_time'] == 1].groupby('product_id').size().to_frame('prod_first_orders')\nsub2 = prd2[prd2['product_time'] == 2].groupby('product_id').size().to_frame('prod_second_orders')\nsub1['prod_orders'] = prd2.groupby('product_id')['product_id'].size()\nsub1['prod_reorders'] = prd2.groupby('product_id')['reordered'].sum()\nsub2 = sub2.reset_index().merge(sub1.reset_index())\n# calculating probability and ratio\nsub2['prod_reorder_probability'] = sub2['prod_second_orders']/sub2['prod_first_orders']\nsub2['prod_reorder_ratio'] = sub2['prod_reorders']/sub2['prod_orders']\n\nprd = sub2[['product_id', 'prod_orders','prod_reorder_probability', 'prod_reorder_ratio']]\n\n#release memory\ndel sub1, sub2, prd2\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:26:59.935802Z","iopub.execute_input":"2022-03-22T14:26:59.936067Z","iopub.status.idle":"2022-03-22T14:27:51.267608Z","shell.execute_reply.started":"2022-03-22T14:26:59.936039Z","shell.execute_reply":"2022-03-22T14:27:51.26672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merging users related dataframes with orders\norders_df[\"user_mean_days_since_prior\"] = orders_df.days_since_prior_order\nusers = orders_df[orders_df.eval_set == \"prior\"].groupby(\"user_id\").agg({ \"order_number\" : \"max\", \"days_since_prior_order\" : \"sum\", \"user_mean_days_since_prior\" : \"mean\" }).rename(columns = { \"order_number\" : \"user_orders\", \"days_since_prior_order\" : \"user_period\" })\nusers.reset_index(inplace=True)\n# calculating reordered amount, amount of orders, and number of distinct products \nus = orders_products.groupby(\"user_id\").agg({ \"order_id\" : \"count\", \"reordered\" : \"sum\", \"order_number\" : lambda rows: rows[rows > 1].shape[0], \"product_id\" : \"nunique\" }).rename(columns = { \"order_id\" : \"user_total_products\", \"product_id\" : \"user_distinct_products\"})\n# calculating the user reorder ratio\nus[\"user_reorder_ratio\"] = us.reordered / us.order_number\nus.drop([\"reordered\", \"order_number\"], axis=1, inplace=True)\nus.reset_index(inplace=True)\n# merging data\nusers = users.merge(us)\nusers[\"user_average_basket\"] = users.user_total_products / users.user_orders\nus = orders_df[orders_df.eval_set != \"prior\"][[\"user_id\", \"order_id\", \"eval_set\", \"days_since_prior_order\"]].rename(columns = { \"days_since_prior_order\" : \"time_since_last_order\" })\nusers = users.merge(us)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:28:15.2388Z","iopub.execute_input":"2022-03-22T14:28:15.239079Z","iopub.status.idle":"2022-03-22T14:29:18.067905Z","shell.execute_reply.started":"2022-03-22T14:28:15.239048Z","shell.execute_reply":"2022-03-22T14:29:18.066776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data final preparation for modelling\norders_products[\"up_orders\"] = orders_products[\"up_first_order\"] = orders_products[\"up_last_order\"] = orders_products.order_number\ndata = orders_products.groupby([\"user_id\", \"product_id\"]).agg({ \"up_orders\" : \"count\", \"up_first_order\" : \"min\", \"up_last_order\" : \"max\", \"add_to_cart_order\" : \"mean\" }).rename(columns={ \"add_to_cart_order\" : \"up_average_cart_position\" })\ndata.reset_index(inplace=True)\n# merging products and users information\ndata = data.merge(prd).merge(users)\n# calculating the user + product order rate, orders since last order and order rate since last order\ndata[\"up_order_rate\"] = data.up_orders / data.user_orders\ndata[\"up_orders_since_last_order\"] = data.user_orders - data.up_last_order\ndata[\"up_order_rate_since_first_order\"] = data.up_orders / (data.user_orders - data.up_first_order + 1)\n# merging train info to the data\ndata = data.merge(ordert[[\"user_id\", \"product_id\", \"reordered\"]], how=\"left\", on=[\"user_id\", \"product_id\"])\n# filling null values with the reordered = 0\ndata.loc[pd.isnull(data.reordered), \"reordered\"] = 0\ndata","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:31:04.96191Z","iopub.execute_input":"2022-03-22T14:31:04.962188Z","iopub.status.idle":"2022-03-22T14:31:49.439573Z","shell.execute_reply.started":"2022-03-22T14:31:04.962159Z","shell.execute_reply":"2022-03-22T14:31:49.438701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBoost**","metadata":{}},{"cell_type":"code","source":"# split test and train data and features to be discarded \ntrain = data[data.eval_set == \"train\"]\ntest = data[data.eval_set == \"test\"]\nsubtrain = train.sample(frac=1.0)\ndiscard_fields = [\"eval_set\", \"user_id\", \"product_id\", \"order_id\", \"reordered\"]\nX = xgb.DMatrix(subtrain.drop(discard_fields, axis=1), label=subtrain.reordered)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:59:16.359558Z","iopub.execute_input":"2022-03-22T10:59:16.359863Z","iopub.status.idle":"2022-03-22T10:59:26.25233Z","shell.execute_reply.started":"2022-03-22T10:59:16.359827Z","shell.execute_reply":"2022-03-22T10:59:26.25163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set model parameters and train\nparams = {'max_depth':10, \n         'eta':0.02,\n         'colsample_bytree':0.4,\n         'subsample':0.75,\n         'silent':1,\n         'nthread':27,\n         'eval_metric':'logloss',\n         'binary':'logistic',\n         'tree_method':'hist'}\n\n#nrounds = 1000 / early_stopping_rounds=40\n#lowered to 10 for project evaluation\nnrounds = 10\n\nxgb_model = xgb.train(params, X, nrounds, verbose_eval=5)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:49:13.849323Z","iopub.execute_input":"2022-03-22T10:49:13.849614Z","iopub.status.idle":"2022-03-22T10:49:33.216443Z","shell.execute_reply.started":"2022-03-22T10:49:13.849581Z","shell.execute_reply":"2022-03-22T10:49:33.215644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting feature importance\nplt.rcParams[\"figure.figsize\"] = (14, 7)\nxgb.plot_importance(xgb_model)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:50:24.017974Z","iopub.execute_input":"2022-03-22T10:50:24.018308Z","iopub.status.idle":"2022-03-22T10:50:24.338681Z","shell.execute_reply.started":"2022-03-22T10:50:24.018278Z","shell.execute_reply":"2022-03-22T10:50:24.337654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying model with a 0.21 probability threshold\nprobability_threshold = 0.21\nX = xgb.DMatrix(test.drop(discard_fields, axis=1))\n# predict reordered products\ntest[\"reordered\"] = xgb_model.predict(X)\ntest[\"reordered\"] = np.where(test.reordered > probability_threshold, 1, 0)\ntest.loc[:, 'product_id'] = test.product_id.astype(str)\n# join reordered products for submission\nsubmission = test[test.reordered == 1].groupby(\"order_id\").agg({ \"product_id\" : lambda x: ' '.join(x) })\nsubmission.rename(columns = {\"product_id\" : \"products\"}, inplace=True)\nsubmission.reset_index(inplace=True)\n# get only the results for the test set\ntest_set = orders_df[orders_df.eval_set == \"test\"][[\"order_id\"]]\ntest_set = test_set.merge(submission, how=\"outer\")\ntest_set.sort_values(\"order_id\", inplace=True)\n# save file for submission\ntest_set.to_csv((\"sample_021_xgb2.csv\"), columns=[\"order_id\", \"products\"], index=False, na_rep=\"None\")\ntest_set.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:50:25.782192Z","iopub.execute_input":"2022-03-22T10:50:25.782862Z","iopub.status.idle":"2022-03-22T10:50:38.236831Z","shell.execute_reply.started":"2022-03-22T10:50:25.782819Z","shell.execute_reply":"2022-03-22T10:50:38.235946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_2 = pd.get_dummies(data=data, drop_first=True)\ndata_2.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:31:53.070912Z","iopub.execute_input":"2022-03-22T14:31:53.072199Z","iopub.status.idle":"2022-03-22T14:31:57.841052Z","shell.execute_reply.started":"2022-03-22T14:31:53.07216Z","shell.execute_reply":"2022-03-22T14:31:57.839923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        col_type2 = df[col].dtype.name\n        \n        if ((col_type != object) and (col_type2 != 'category')):\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:32:14.343934Z","iopub.execute_input":"2022-03-22T14:32:14.344202Z","iopub.status.idle":"2022-03-22T14:32:14.35977Z","shell.execute_reply.started":"2022-03-22T14:32:14.344179Z","shell.execute_reply":"2022-03-22T14:32:14.35899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = reduce_mem_usage(data_2)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:32:29.279112Z","iopub.execute_input":"2022-03-22T14:32:29.279617Z","iopub.status.idle":"2022-03-22T14:32:32.687166Z","shell.execute_reply.started":"2022-03-22T14:32:29.279586Z","shell.execute_reply":"2022-03-22T14:32:32.686047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data, test_size=0.3, random_state=100)\nprint(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:32:34.765753Z","iopub.execute_input":"2022-03-22T14:32:34.765968Z","iopub.status.idle":"2022-03-22T14:33:01.503903Z","shell.execute_reply.started":"2022-03-22T14:32:34.765948Z","shell.execute_reply":"2022-03-22T14:33:01.502619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in data_2.columns:\n    print(type(data_2[col][0]))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:01:55.960704Z","iopub.execute_input":"2022-03-22T14:01:55.960941Z","iopub.status.idle":"2022-03-22T14:01:55.988058Z","shell.execute_reply.started":"2022-03-22T14:01:55.960917Z","shell.execute_reply":"2022-03-22T14:01:55.987307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import NearestNeighbors\n\nmodel_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\nmodel_knn.fit(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:33:12.9989Z","iopub.execute_input":"2022-03-22T14:33:12.999278Z","iopub.status.idle":"2022-03-22T14:33:14.644157Z","shell.execute_reply.started":"2022-03-22T14:33:12.99925Z","shell.execute_reply":"2022-03-22T14:33:14.643216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_index = np.random.choice(train.shape[0])\n# distances, indices = model_knn.kneighbors(train.iloc[query_index, :].values.reshape((1, -1)), n_neighbors = 6)\n\nn_neighbors = 6\nfor i in range(train.shape[0]):\n    distances, indices = model_knn.kneighbors(train.iloc[i, :].values.reshape((1, -1)), n_neighbors = n_neighbors)\n    \n    print(len(distances))\n    print('Recommendations for {0}:\\n'.format(i, train.index[indices.flatten()[i]]))\n    for j in range(0, n_neighbors):\n#         if i == j:\n#         print('Recommendations for {0}:\\n'.format(j, train.index[indices.flatten()[j]]))\n#         else:\n        print('{0}: {1}'.format(j, train.index[indices.flatten()[j]]))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:37:41.298429Z","iopub.execute_input":"2022-03-22T14:37:41.299426Z","iopub.status.idle":"2022-03-22T14:37:49.283303Z","shell.execute_reply.started":"2022-03-22T14:37:41.299394Z","shell.execute_reply":"2022-03-22T14:37:49.281793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}