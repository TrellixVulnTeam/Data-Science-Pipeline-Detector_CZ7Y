{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# パッケージ読み込み","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nfrom tqdm.notebook import tqdm\n\n# 機械学習\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nimport lightgbm as lgb\n\n\n# 可視化\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:45:13.994032Z","iopub.execute_input":"2021-08-14T10:45:13.994544Z","iopub.status.idle":"2021-08-14T10:45:14.00052Z","shell.execute_reply.started":"2021-08-14T10:45:13.994505Z","shell.execute_reply":"2021-08-14T10:45:13.999654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orders = pd.read_csv(\"/kaggle/input/instadataset/orders.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/instadataset/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:45:14.002378Z","iopub.execute_input":"2021-08-14T10:45:14.0027Z","iopub.status.idle":"2021-08-14T10:45:17.240791Z","shell.execute_reply.started":"2021-08-14T10:45:14.002671Z","shell.execute_reply":"2021-08-14T10:45:17.239541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orders_product_prior = pd.read_csv(\"/kaggle/input/instadataset/order_products__prior.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:45:17.242654Z","iopub.execute_input":"2021-08-14T10:45:17.243016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/instadataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/instadataset/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴生成","metadata":{}},{"cell_type":"code","source":"def add_features(df, orders_df, orders_product_prior_df):\n    \n    # 集約特徴を作るためのテーブル\n    order_mereged_df = pd.merge(orders_df, orders_product_prior_df, on='order_id', how='inner')\n    \n    # ユーザ×商品の列\n    order_mereged_df['user-product'] = order_mereged_df['user_id'].astype(str) + \\\n                                        \"-\" + \\\n                                        order_mereged_df['product_id'].astype(str) \n    \n    # 特徴を追加した内容を保存するdf\n    feature_df = df.copy()\n    \n    # ユーザ×商品の列\n    feature_df['user-product'] = feature_df['user_id'].astype(str) + \\\n                                    \"-\" + \\\n                                    feature_df['product_id'].astype(str) \n    \n    ######################### 商品別の特徴 ###############################\n    # 1-1.商品別の出現回数\n    print(\"making product_count features\")\n    product_count_df = order_mereged_df.groupby(\"product_id\").count()[['order_id']].reset_index().rename(\n        columns={'order_id':'product_count'})\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, product_count_df, on='product_id', how='left')\n    \n    # 中間生成したdfを削除しメモリ解放\n    del product_count_df\n    gc.collect() \n    \n    \n    # 1-2. 商品別のreorder率\n    print(\"making product_reordered_rate features\")\n    product_reordered_df = order_mereged_df.groupby(\"product_id\").mean()[['reordered']].reset_index().rename(\n        columns={'reordered':'product_reordered_rate'})\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, product_reordered_df, on='product_id', how='left')\n    \n    # 中間生成したdfを削除しメモリ解放\n    del product_reordered_df\n    gc.collect() \n    \n    \n    ######################### ユーザごとの特徴 ###############################\n    # 2-1.ユーザの再購入率\n    print(\"making user_reorder_rate features\")\n    user_reorder_rate_df = order_mereged_df.groupby(\"user_id\").mean()[[\"reordered\"]].reset_index().rename(\n        columns={'reordered':'user_reorder_rate'})\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, user_reorder_rate_df, on='user_id', how='left')\n    \n    # 中間生成したdfを削除しメモリ解放\n    del user_reorder_rate_df\n    gc.collect()\n    \n    # 2-2. ユーザの過去の購買行動\n    print(\"making user_action_mean features\")\n    action_list = [\"order_number\", \"order_dow\", \"order_hour_of_day\", \"days_since_prior_order\"]\n    user_past_action_df = orders_df.groupby(\"user_id\").mean()[action_list].reset_index().rename(\n        columns={'order_number':'order_number_mean',\n                 'order_dow':'order_dow_mean',\n                 'order_hour_of_day':'order_hour_of_day_mean',\n                 'days_since_prior_order':'days_since_prior_order_mean'})\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, user_past_action_df, on='user_id', how='left')\n    \n    # 中間生成したdfを削除しメモリ解放\n    del user_past_action_df\n    gc.collect()\n    \n    # 2-3. ユーザの過去のorder回数\n    print(\"making user_action_count features\")\n    user_past_action_df = orders_df.groupby(\"user_id\").count()['order_id'].reset_index().rename(\n        columns={'order_id':'order_count'})\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, user_past_action_df, on='user_id', how='left')\n    \n    # 中間生成したdfを削除しメモリ解放\n    del user_past_action_df\n    gc.collect()\n    \n    ######################### ユーザ・商品ごとの特徴 ###############################\n    # 3-1.すでにそのユーザが商品を再注文した経験があるかどうか\n    print(\"making reordered features\")\n    reorder_product = order_mereged_df.query(\"reordered == 1\")[['user_id', 'product_id']].drop_duplicates()\n    reorder_product['reordered'] = 1\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, reorder_product, on=['user_id', 'product_id'], how='left')\n    \n    # 再注文したことがない商品は欠損扱いになるので0で補完\n    feature_df['reordered'].fillna(0, inplace=True)\n    \n    # 中間生成したdfを削除しメモリ解放\n    del reorder_product\n    gc.collect()\n    \n    # 3-2. そのユーザのその商品の注文回数\n    print(\"making user-product-count features\")\n    user_product_count_df = order_mereged_df.groupby(\"user-product\").count()[[\"order_id\"]].reset_index().rename(\n        columns={'order_id':'user-product_count'})\n    \n    # 作成した特徴を追加\n    feature_df = pd.merge(feature_df, user_product_count_df, on=['user-product'], how='left')\n    \n    # 中間生成したdfを削除しメモリ解放\n    del user_product_count_df\n    gc.collect()\n    \n    # 3-3. そのユーザが過去の注文の中で対象商品を注文した割合\n    feature_df['user_product_order_rate'] = feature_df['user-product_count'] / feature_df['order_count']\n    \n    ######################### 作成したdfを返す ###############################\n    \n    return feature_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orders_prior = orders.query(\"eval_set == 'prior'\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainに特徴量追加","metadata":{}},{"cell_type":"code","source":"train_feature_df = add_features(train_df, orders_prior, orders_product_prior)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testに特徴量追加","metadata":{}},{"cell_type":"code","source":"test_feature_df = add_features(test_df, orders_prior, orders_product_prior)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学習前のデータを書き出し","metadata":{}},{"cell_type":"code","source":"train_feature_df.to_csv(\"train_feature.csv\", header=True, index=False)\ntest_feature_df.to_csv(\"test_feature.csv\", header=True, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feature_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学習","metadata":{}},{"cell_type":"code","source":"# 学習用のConfigファイル\nCFG = {\n    # 乱数シード\n    \"seed\":0,\n    \"fold_num\":5,\n    \n    # LGBMパラメータ\n    \"num_leaves\":255, # 葉の数\n    \"max_depth\":-1, # 最大の深さ\n    \"learning_rate\":0.03, # 学習率\n    \"n_estimators\":6000, # 木を作る数\n    \"subsample\":0.6, # 学習に用いるデータの割合\n    \"subsample_freq\":1, # サンプリングを行う頻度\n    \"colsample_bytree\":0.8, # 学習に用いる列の割合\n    \"objective\":'binary',\n    \"eval_metric\": 'logloss',\n    \"early_stopping_rounds\":50, # 指定回数以上validの値が更新しない場合は学習を止める\n    \"verbose\":100, # 途中経過表示頻度\n    \"step\":20, # 閾値の探索幅\n    \n    \"debug\":False # 表示するときはtrue\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.973188Z","iopub.status.idle":"2021-08-14T10:44:59.973615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測結果を管理する配列\nanswer = np.array([])\nanswer_train = np.array([])\nAUC_list = []\n\n# 学習用のデータを説明変数と目的変数に分割\nif CFG['debug']:\n    full_data_x = train_feature_df.drop([\"order_id\", \"eval_set\", \"product_id\", \"target\" , \"user-product\"],axis=1).iloc[:100000]\n    full_data_y = train_feature_df[[\"target\"]].iloc[:100000]\nelse:\n    full_data_x = train_feature_df.drop([\"order_id\", \"eval_set\", \"product_id\", \"target\", \"user-product\"],axis=1)\n    full_data_y = train_feature_df[[\"target\"]]\n\n# test用のデータ\ntest_x = test_feature_df.drop([\"order_id\", \"eval_set\", \"product_id\", \"user_id\", \"user-product\"],axis=1)\n\n# GroupKFoldの分割\ngroups = full_data_x['user_id'].values\ngroup_kfold = GroupKFold(n_splits=CFG['fold_num'])\n\nfor i, (train_index, valid_index) in enumerate(group_kfold.split(full_data_x, full_data_y, groups)):\n    \n    # デバッグモードの場合は1foldだけ実行して終了\n    if CFG['debug'] and i == 1:\n        break\n    \n    print(\"TRAIN:\", train_index, \"VALID:\", valid_index)  \n        \n    # 学習と検証用にデータ分割\n    train_x = full_data_x.iloc[train_index].drop([\"user_id\"],axis=1)\n    valid_x = full_data_x.iloc[valid_index].drop([\"user_id\"],axis=1)\n    \n    train_y = full_data_y.iloc[train_index]\n    valid_y = full_data_y.iloc[valid_index]\n    \n    # 回帰予測用のlightgbmモデルを設定\n    gbm_model = lgb.LGBMClassifier(\n        boosting_type='gbdt', # 木を作るときのルール\n        num_leaves=CFG['num_leaves'], # 葉の数\n        max_depth=CFG['max_depth'], # 最大の深さ\n        learning_rate=CFG['learning_rate'], # 学習率\n        n_estimators=CFG['n_estimators'], # 木を作る数\n        subsample=CFG['subsample'], # 学習に用いるデータの割合\n        subsample_freq=CFG['subsample_freq'], # サンプリングを行う頻度\n        colsample_bytree=CFG['colsample_bytree'], # 学習に用いる列の割合\n        objective=CFG['objective'], # 対象とするのは回帰問題\n        random_state=CFG['seed'], # 乱数シード\n        silent=False, # 学習内容の表示\n        importance_type='gain' # 変数の重要度の計算方法\n    )\n    \n    # モデルの学習\n    gbm_model.fit(train_x, \n                  train_y,\n                  eval_set=[(valid_x, valid_y)],\n                  eval_metric=CFG[\"eval_metric\"],\n                  early_stopping_rounds=CFG['early_stopping_rounds'],\n                  verbose=CFG['verbose'])\n    \n    # 予測\n    gbm_pred = gbm_model.predict_proba(valid_x)\n    \n    # スコアの計算\n    AUC = roc_auc_score(valid_y[['target']], gbm_pred[:,1])\n    print(\"AUC : \", AUC)\n    AUC_list += [AUC]\n    \n    # 予測\n    temp_pred = gbm_model.predict_proba(test_x)\n    \n    # 答えの結果を記録\n    if i == 0:\n        answer = temp_pred[:, 1]\n        answer_train = gbm_pred[:, 1]\n    else:\n        answer += temp_pred[:, 1]\n    \n    # デバッグモードの場合は１ループ目のみ色々可視化\n    if CFG['debug'] and i == 0:\n\n        # 説明変数の重要度を格納するためのデータフレームを作成\n        feature_importances = pd.DataFrame()\n        feature_importances['feature'] = train_x.columns\n        feature_importances['importance'] = gbm_model.feature_importances_\n\n        # 重要度が大きい順に可視化\n        plt.figure(figsize=(16, 16))\n        sns.barplot(data=feature_importances.sort_values('importance', ascending=False).head(50),\n                    x='importance',\n                    y='feature');\n        plt.title('50 TOP feature importance')\n        plt.show()\n        \n    # F1スコア\n    best_F1 = 0\n    best_thresfold = 0\n    \n    valid = pd.concat([full_data_x.iloc[valid_index], full_data_y.iloc[valid_index]], axis=1)\n    \n    for thresfold in range(0, CFG['step'], 1):\n        if thresfold == 0:\n            continue\n        if thresfold > 6:\n            break\n\n        F1_sum = 0\n        F1_num = valid['user_id'].nunique() # ユーザ数\n        \n        # その閾値での予測値\n        valid['pred'] = np.where(gbm_pred < thresfold/CFG['step'], 0.0, 1.0)[:,1]\n        \n        # ユーザごとのF1スコアを計算し加算\n        for data in tqdm(valid.groupby('user_id')):\n            F1_sum += f1_score(data[1][['target']].values, data[1][['pred']].values) \n        \n        # F1スコアの平均を算出\n        F1 = F1_sum / F1_num \n        \n        print(\"thresfold:\", thresfold, \" F1:\", F1)\n        \n        if F1 > best_F1:\n            best_F1 = F1\n            best_thresfold = thresfold/CFG['step']\n\n    print(\"bestF1\", best_F1)\n    print(\"best_thresfold\", best_thresfold)\n    # 使ったDFの削除\n    del train_x, valid_x, train_y, valid_y, temp_pred, valid\n    gc.collect()\n\n# 提出用のファイルの作成\nsubmission = test_feature_df.copy()\npred_test = answer / CFG['fold_num']\n\n# 提出用ファイルの作成\nsubmission['target'] = pred_test","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.974699Z","iopub.status.idle":"2021-08-14T10:44:59.975141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans = pd.DataFrame()\nfor count, data in enumerate(tqdm(submission.groupby('order_id'))):\n    \n    order_dic = {}\n    order_dic['order_id'] = str(int(data[1].iloc[0]['order_id']))\n  \n    first_flg = True\n    t_str = \"\"\n    for i in data[1].iterrows():\n#         print(i[1]['target'])\n        \n        if i[1]['target'] > best_thresfold:\n            if first_flg == True:\n                t_str += str(i[1]['product_id'])\n                first_flg = False\n            else:\n                t_str += \" \"\n                t_str += str(i[1]['product_id'])\n    \n    if first_flg == True:\n        order_dic['products'] = \"None\"\n    else:\n        order_dic['products'] = t_str\n#     print(order_dic)\n    ans = ans.append(order_dic, ignore_index=True)\n    \n#     if count > 10:\n#         break","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.975974Z","iopub.status.idle":"2021-08-14T10:44:59.976393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target.min()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.977629Z","iopub.status.idle":"2021-08-14T10:44:59.978073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_thresfold","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.979073Z","iopub.status.idle":"2021-08-14T10:44:59.979492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.980469Z","iopub.status.idle":"2021-08-14T10:44:59.980943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans.to_csv(\"submission.csv\", header=True, index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T10:44:59.981858Z","iopub.status.idle":"2021-08-14T10:44:59.982527Z"},"trusted":true},"execution_count":null,"outputs":[]}]}