{"cells":[{"metadata":{"_uuid":"1d7e2e9175fbd8fba6732a6d654205ce1e088011"},"cell_type":"markdown","source":"# Introduction\n\nThis Kernel refers to Instacart competition, using customer orders over time to predict which previously purchased products will be in a user’s next order. Specifically, in this kernel is described in detail the feature engineering part, implementing basic data science methodologies on Python. "},{"metadata":{"_uuid":"57bfb997ef343e5e69e0ae049b4dad4aaae812c3"},"cell_type":"markdown","source":"# Business Insights\n* Day-time\n    * Delta-hour: difference between the exact hour of the day that a specific order occurred and the hour that the previous ones from this order occurred\n* Orders\n    * How many users bought a specific product for first time\n    * How many orders each user has made\n* Re-orders\n    * In how many consecutive orders a product has been bought\n    * How many orders have been made by a user who has bought a product at least one time\n    * Probability that a product will be repurchased consecutive times\n    * Probability that a product will be repurchased within \"N\" orders\n* High-frequency products\n    * Whether or not users have bought high-frequency products"},{"metadata":{"_uuid":"077c174c3fd487d809c86a44064b95864dd859ba"},"cell_type":"markdown","source":"# Python Skills\n* Merge two data frames with inner, left, right join\n* Use Lists\n* Use Dictionaries\n* Perform a .groupby( ) on data of a data frame that meet a condition\n* Create a new column to an already existing data frame\n* Divide columns element-wise of a data frame\n* Check for NaN (Not a Number) values and modify them\n* Set manually an index for a data frame\n* Filter data frames based on a condition\n* Select rows of a data frame, based on a condition\n* Create a new data frame, with column(s) of a existing data frame\n* Compute numerical data ranks along axis / Compute cumulative sum over an axis\n* Create ratios through supportive variables\n* Perform a loop\n* Drop duplicate values"},{"metadata":{"_uuid":"18123a4ec74886d2a5a20d31629dbcbf052f023c"},"cell_type":"markdown","source":"# 1. Variable: Delta Time\nOur purpose is to find the delta hours between the last order’s hour of the day and the hour of the day of the previous ones. In other words, we want to calculate the difference between the exact hour of the day that a specific order occurred and the hour that the previous ones from this order occurred. This will be calculated for the last 3 orders. "},{"metadata":{"_uuid":"f1783d722953ef56e99364d484dd926a301e990f"},"cell_type":"markdown","source":"## 1.1 Loading CSV files\nFirst of all, we load all the CSV files that we are going to use."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\norders = pd.read_csv('../input/orders.csv' )\nproducts = pd.read_csv('../input/products.csv')\norder_products = pd.read_csv('../input/order_products__train.csv' )\norder_products_prior = pd.read_csv('../input/order_products__prior.csv')\naisles = pd.read_csv('../input/aisles.csv')\ndepartments = pd.read_csv('../input/departments.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd159482f4e11c3d2270aeadcca4857fa960797b"},"cell_type":"markdown","source":"## 1.2 Modifications\nAlso, it could be useful to make some modifications in the table \"orders\". These changes will help us in the next steps of our methodology.\n\nSo, initially, we assign the data of the table \"orders\" to a new data frame called as \"order_tbl\" and then, we sort the elements of \"order_tbl\" by the user id and order number."},{"metadata":{"trusted":true,"_uuid":"92d205245e44f59354c979c61e9f16318cb29733","scrolled":true},"cell_type":"code","source":"order_tbl = orders\norder_tbl.sort_values(['user_id', 'order_number'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e7e48ee5d8b04cef79ed63e146dc2999c156563"},"cell_type":"markdown","source":"## 1.3 Importing the three previous orders as columns\nOur next step is to adjust the data frame \"order_tbl\" in a such way as to help us create the new variable that we want. This will be achieved by adding some columns.\n\nFirstly, we add three columns. These columns refer to the last three orders that occurred before each order, using the order id. Specifically, symbolizing with the parameter \"t\" each order/row of \"order_tbl\", we add to each row the order id of \"t-1\",\"t-2\", and \"t-3\" orders. \n\nFor example, if we look at the 4th order of the first user, we will also see the order id of the 3rd, 2nd, and 1st order.\n\nIn the code, we use shift(i) with i=1,2,3 in order to set the first i rows of the three new columns with null values."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"order_tbl['t-1_order_id'] = order_tbl.groupby('user_id')['order_id'].shift(1)\norder_tbl['t-2_order_id'] = order_tbl.groupby('user_id')['order_id'].shift(2)\norder_tbl['t-3_order_id'] = order_tbl.groupby('user_id')['order_id'].shift(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"140c4a631a11831fa2cff137781059bc8ac49d03"},"cell_type":"markdown","source":"We use the function .head() in order to view the first five rows of the data frame."},{"metadata":{"trusted":true,"_uuid":"e725f499cb6bcd4f504717b492105998a8b98dad"},"cell_type":"code","source":"order_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"961d43527ec4c48fbad84c296db94e7ac0778e9a"},"cell_type":"markdown","source":"## 1.4 Importing more information for the previous orders\nApart from these three columns, we need two more columns for each previous order. The information that will be provided is the day of the week and the hour of that day the previous orders occurred.\n\nTo achieve this, we firstly create a list \"col\" which contains the variables the are going to be used. Then, at the name of the column, we add the necessary prefix \"t-i\" with i=1,2,3 and we merge the list with the \"order_tbl\" using left join. "},{"metadata":{"trusted":true,"_uuid":"267a0622b512d91fda95171ecf0e3eb8e2da7eae"},"cell_type":"code","source":"col = ['order_id', 'order_dow', 'order_hour_of_day']\norder_tbl = pd.merge(order_tbl, order_tbl[col].add_prefix('t-1_'), on='t-1_order_id', how='left')\norder_tbl = pd.merge(order_tbl, order_tbl[col].add_prefix('t-2_'), on='t-2_order_id', how='left')\norder_tbl = pd.merge(order_tbl, order_tbl[col].add_prefix('t-3_'), on='t-3_order_id', how='left')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55ab593eb0e84eeddb3047e636c75b0a5e41dcaf"},"cell_type":"markdown","source":"We can see the modified table using the function .head() as previously."},{"metadata":{"trusted":true,"_uuid":"db0462dca7e63a733d232ae23710407fc056bd1a"},"cell_type":"code","source":"order_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ae16ccb03e2f652f6d0bbd6882dd3b6a7222e86"},"cell_type":"markdown","source":"## 1.5 Calculating the new variables\nWe are ready now to create the variables that we want. For each order we calculate the difference between the hour of the order occurred and the hour of the order of the previous ones. \n\nObviously, we put the new information into three new columns calles as \"delt_hour_t-i\" with i=1,2,3."},{"metadata":{"trusted":true,"_uuid":"079736f9a2931f19207a1d4f25d14ad4e82a7870","scrolled":true},"cell_type":"code","source":"order_tbl['delta_hour_t-1'] = order_tbl['order_hour_of_day'] - order_tbl['t-1_order_hour_of_day']\norder_tbl['delta_hour_t-2'] = order_tbl['order_hour_of_day'] - order_tbl['t-2_order_hour_of_day']\norder_tbl['delta_hour_t-3'] = order_tbl['order_hour_of_day'] - order_tbl['t-3_order_hour_of_day']\norder_tbl.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e10d80f734647a6f14e45ee44766d155b805748"},"cell_type":"markdown","source":"## 1.6 Important notice\nThe usefulness of this variable may be seemed if we want to combine it with other pieces of information provided from the csv files or with other variables.\n\nFor instance, we may want to combine the difference in the hours of the orders with the common products included in these orders. That is to say, we can conclude that if there is not a big difference between the hours, it is highly likely the next order which will happen in these time limits will contain a great ratio of repurchased items. "},{"metadata":{"_uuid":"0de343b4fa39e2b14ae38f89367c7ac180bf6082"},"cell_type":"markdown","source":"# 2. Variable: Probability that a product will be repurchased consecutive times\nThe second variable we are going to create will be the fraction of two other variables. \n\nThe first of these variables refers to how many consecutive orders a product has been bought. The second variable refers to how many orders have been made by a user who has bought this product at least one time. So, it computes how many times a user had the chance to buy this item either he did it or not.\n\nIn order to make it more understandable, we give an example: \n\nIf a user bought an item at least one time, the second variable will store the total number of orders that he or she has made. So, if the user has made 10 orders in which there is at least one time this item, the second variable is the number 10.\n\nFor the first variable there are many cases that should be examined.\n* If a user bought it exactly one time, the first variable would be the number 0.\n* If a user bought it more times, it depends on how many of them were consecutive. For instance, if there was this pattern:\n\n**1st Order**: Bought\n**2nd Order**: Not Bought\n**3rd, 4th, 5th Order**: Bought\n**6th Order**: Not Bought \n**7th, 8th Order**: Bought\n**9th Order**: Not Bought\n**10th Order**: Bought\n\n, the first variable would be the number 5.\n\nSo, the final variable would be the ratio 5/10 = 0.5. But this calculation will refer to each product and will contain all the patterns such as the above made by all users.\n\nTo make this happen we are going to use elements of Python such as:\n* Joins\n* Dictionaries\n* Loops"},{"metadata":{"_uuid":"225dcb6ecbde387eb719188c8f24acbd64b0ce7e"},"cell_type":"markdown","source":"## 2.1 Creating a data frame that contains data from multiple sources\nThe first step is to set up the data frame we are going to use.\n\nWe create a data frame that contains the orders made from the customers and the products purchased in each order. \nActually we use the data frames:\n\norders (all the orders made from all customers) ..."},{"metadata":{"trusted":true,"_uuid":"d14dda90d9e8531f821dcccb40cc609f4f6d1f76"},"cell_type":"code","source":"orders.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30b5d2df64622be6e869710844a72e4fb5ce6e3b"},"cell_type":"markdown","source":"... and the order_products_prior (the products purchased in each order)."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7c0f59a2b4bfb1e145229ba900341e52af939ff0"},"cell_type":"code","source":"order_products_prior.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bf6fdea9e628692ece6633d0e9092bd47e73f3e"},"cell_type":"markdown","source":"We merge these two data frames by their matching column, order_id. The method of merge, how='inner' keeps only these rows where each order_id can be found on both dataframes."},{"metadata":{"_uuid":"314a9a10d38a46acba2e28a5ff1c3e057f58ec58"},"cell_type":"markdown","source":"![](https://www.w3schools.com/Sql/img_innerjoin.gif)"},{"metadata":{"_uuid":"280de11586d92541d0a152bffed48121514021dc","trusted":true},"cell_type":"code","source":"prd = pd.merge(orders, order_products_prior, on='order_id', how='inner')\nprd.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60ae144376ecce550cea345011c16807c029cbcf"},"cell_type":"markdown","source":"Now that we have a data frame that combines both the orders and the products purchased on each order, we will get insights for each product."},{"metadata":{"_uuid":"49499a378d9c650ca4bb6c6e0104e5d791a9ab44"},"cell_type":"markdown","source":"## 2.2 Finding how many orders have been made by each user\nWe want to add a column that will demonstrate the maximum number of orders that have been made by each user.\n\nTo do this, we firstly import the package \"numpy\" which we will need in order to find the maximum number of the column \"order_number\" for each user id. \n\nThen, we \"group_by\" the user id and the product id."},{"metadata":{"trusted":true,"_uuid":"35f379a24e261f35622b5bc763afbb3006e17dcb"},"cell_type":"code","source":"import numpy as np\nprd['user_max_onb'] = prd.groupby('user_id').order_number.transform(np.max)\nprd = prd.groupby(['user_id', 'product_id']).head(2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e762d0b89a5ff8eae7044a45afd9dc6c6ea9931"},"cell_type":"markdown","source":"In the picture below, we can see the new column that we create."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"23b5d22f525e9fd2d27ed52ce3ad8165a930381e"},"cell_type":"code","source":"prd.head(30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e4280bc0fd5cd48a9421ff5ed56ea7b1f477ac7"},"cell_type":"markdown","source":"## 2.3 Creating variables which are used for the new data frame\nIn this section, we want to create all the variables that we are going to use in order to end up in the final data frame. The first thing that we should do is to import the package \"defaultdict\". \n\nAfter that, we create two dictionaries: item_cnt (item count) and item_chance. \n\nAt this point, we have to describe what is exactly a dictionary in Python. A dictionary is a collection which is unordered, changeable and indexed. In Python dictionaries are written with curly brackets, and they have keys and values. \n\nThe most important thing that attracts us to use dictionaries rather than lists is the fact that in dictionaries there are indexes; in lists there aren't. Hence, in our case, the keys will be the product id's and the values will be the values of our variables. In this way, we can easily turn the dictionaries into data frames in which the rows will be the keys, the columns will be the variables and the field will be the values of dictionaries. \n\nBack to our code, the reason we use the defaultdict(int) is to prevent from the KeyError, which is appeared when there are not keys in the dictionary. With this function, we fill the dictionary with the integer 0 as key wherever there is no key.\n\nFinally, we assign the value \"None\" in our three new variables: pid_bk (product id), uid_bk (user id), and onb_bk (order number). These variables are going to help us in our loop."},{"metadata":{"trusted":true,"_uuid":"dfae71afae151fb144bde06e87aad3e68964d80a"},"cell_type":"code","source":"from collections import defaultdict\nitem_cnt    = defaultdict(int)\nitem_chance = defaultdict(int)\npid_bk = uid_bk = onb_bk = None","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cb4b806972f30cc1237a844c514d78e7996b796"},"cell_type":"markdown","source":"## 2.4 Using a loop for the calculation of the main indexes\nNow, we are ready to move on the most important part of the code. \n\nWhat we do here is to create a loop which calculates two important variables: item_cnt and item_chance. Specifically:\n* item_cnt : this variable counts how many consecutive orders contained a specific product for all users\n* item_chance : it counts how many orders have been made by all users and contained this specific product at least one time.\n\nThis variables have already been described in previous chapters.\n\nHow does this loop work?\n\nThe first row of the code declares that the code inside the loop runs for every row of the table \"prd\". \n\nThe variables we previously gave the value \"None\" (pid_bk, uid_bk, onb_bk) change their value in every loop. They receive the information of the previous order and they are used in two conditions \"if\". \n\nThe first condition checks if a user bought a product for consecutive time. Specifically, if the user_id and the product_id are the same as those of the previous order, which is checked with the condition current order number minus previous order number equals with one, then count plus 1 in the dictionary item_cnt to the respective index which is the product id in our case. \n\nThe second condition checks if the current order number equals the total orders of the user. If this is true, then it adds one as previously but this time in dictionary item_chance.\n\nThis operation is occurred for every row of the table \"prd\"."},{"metadata":{"trusted":true,"_uuid":"d6b4145302d23f448ee41fca419cfe9ba146c861"},"cell_type":"code","source":"for uid, pid, onb, max_onb in prd[['user_id', 'product_id', 'order_number', 'user_max_onb']].values:\n        \n    if uid==uid_bk and pid==pid_bk and (onb-onb_bk==1):\n        item_cnt[pid] +=1\n    if onb!=max_onb:\n        item_chance[pid] +=1\n    \n    pid_bk = pid\n    uid_bk = uid\n    onb_bk = onb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb2d988d8ae173de50c62d5e99e15ab5a0c02036"},"cell_type":"markdown","source":"## 2.5 Organizing our findings in data frames\nSince we found the variables that we want, we will organize them in data frames.\n\nAs far as the item_cnt is concerned, we organize its numbers in a table with 2 columns, \"product_id\" and \"item_first_cnt\". We do the same for the item_chance as well, but the second column is called \"item_first_chance\". \n\nAfter that, we merge the two data frames in one called df, using as a key the \"product_id\" and applying left join.\n\nFinally, we create another column which calculates the ratio of item_first_cnt to item_first_chance."},{"metadata":{"trusted":true,"_uuid":"17a794bef3b86a6d7452364d37ca86a226fef511"},"cell_type":"code","source":"item_cnt = pd.DataFrame.from_dict(item_cnt, orient='index').reset_index()\nitem_cnt.columns = ['product_id', 'item_first_cnt']\nitem_chance = pd.DataFrame.from_dict(item_chance, orient='index').reset_index()\nitem_chance.columns = ['product_id', 'item_first_chance']\ndf = pd.merge(item_cnt, item_chance, on='product_id', how='outer').fillna(0)\ndf['item_first_ratio'] = df.item_first_cnt/df.item_first_chance","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cceb0afd3c2974faa239cffa5674da5dfde4426d"},"cell_type":"markdown","source":"We use the function below in order to see our final data frame."},{"metadata":{"trusted":true,"_uuid":"f3a7e57845db033b65808d1cea1f779662e60100"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"261f87a3548e12844ede490bb130ad97e3fc89e3"},"cell_type":"markdown","source":"# 3. Variable: Whether or not users have bought high-frequency products\nAfter an exploration in the tables, we chose five high-frequency products: Banana, BoO-Banana, Organic Strawberry, Organic Baby Spinach, and Organic Hass Avocado.\n\nThis variable will provide us information about whether a user have bought one of these items or not. This information may help us to understand better a user's behaviour and draw useful conclusion about the likelihood of purchase for items with similar characteristics etc."},{"metadata":{"_uuid":"47ecd890ca3866c16679a7da9fe88c2258b46076"},"cell_type":"markdown","source":"## 3.1 Deduplicate a data frame\nInitially, we remove the duplicate values of user_id from the data frame \"prd\" and we assign the deduplicated column \"user_id\" to the new \"user\" data frame."},{"metadata":{"trusted":true,"_uuid":"11874fa3ba3173df120fd818cc8a03c5f1f2bfb5"},"cell_type":"code","source":"user = prd.drop_duplicates('user_id')[['user_id']].reset_index(drop=True)\nuser.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47949c33bb4d1a3fab7ee1fb828b094eec84c66b"},"cell_type":"markdown","source":"## 3.2 Creating and interpeting the new table\nThe methodology that will be applied is the following:\n\n* Find the id of the high-frequency product that you are looking for.\n* Create data frame and add to this a column with the name of the item and put \"0\" in each row. \n* If there is a match in product and user id, we put the value \"1\" in the field of the new table which is defined by the product as a column and the user id as a row. \n\nHere, we use five blocks for each of the five frequent products: Banana, BoO-Banana, Organic Strawberry, Organic Baby Spinach, and Organic Hass Avocado. These 5 items will be the columns of our new data frame along with the user_id. \n\nIn general, we fill the table with zeros and if the user have bought one of this product, the value is substituted by 1. So, if a user bought banana, the field defined by the column \"hyb_Banana\" and his user_id contain the number 1.\n\nTo sum up, the answers to the question \"have you ever bought (hyb)...?\" are 1 for \"yes\" and 0 for \"no\"."},{"metadata":{"trusted":true,"_uuid":"5c7c0b3cf3c0d963d58f2ffce8982134f61d7beb"},"cell_type":"code","source":"tag_user = prd[prd.product_id==24852].user_id\nuser['hyb_Banana'] = 0\nuser.loc[user.user_id.isin(tag_user), 'hyb_Banana'] = 1\n    \ntag_user = prd[prd.product_id==13176].user_id\nuser['hyb_BoO-Bananas'] = 0\nuser.loc[user.user_id.isin(tag_user), 'hyb_BoO-Bananas'] = 1\n    \ntag_user = prd[prd.product_id==21137].user_id\nuser['hyb_Organic-Strawberries'] = 0\nuser.loc[user.user_id.isin(tag_user), 'hyb_Organic-Strawberries'] = 1\n    \ntag_user = prd[prd.product_id==21903].user_id\nuser['hyb_Organic-Baby-Spinach'] = 0\nuser.loc[user.user_id.isin(tag_user), 'hyb_Organic-Baby-Spinach'] = 1\n\ntag_user = prd[prd.product_id==47209].user_id\nuser['hyb_Organic-Hass-Avocado'] = 0\nuser.loc[user.user_id.isin(tag_user), 'hyb_Organic-Hass-Avocado'] = 1\nuser.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27d6cfe5db0ac4b8e459d0d3aec2198477898871"},"cell_type":"markdown","source":"# 4. Variable: Probability that a product will be repurchased within \"N\" orders\nThe procedure of the creation of these variables is almost the same as the procedure we implemented in the second chapter, but it is a bit more extended, complicated and the results provide us more information. The steps we are going to follow are the same though.\n\nPreviously, we calculated for each product the ratio of how many consecutive times a user bought it to the total number of orders the user made. Now, we are going to calculate 4 ratios that look like this one. The general ratio is how many times a product has been purchased within ''N'' orders to the total number of orders occurred by each user and it is at least ''N''. This is going to be calculated for N=2,3,4,5.\n\nThe big difference here is that we don't care about the consecutive times that an item is included in the user's order but we care about the range between the order that the item was purchased and the order that the item was repurchased after. This range is symbolized by \"N\".\n\nWe are not going to be so extensive since the procedure looks like the previous one we examined in depth."},{"metadata":{"_uuid":"33c1f61a07ffef98ba62b87d8a3203416371396d"},"cell_type":"markdown","source":"## 4.1 Creating variables which are used for the new data frame\nAs we previously did, we are going to create dictionaries. We create 8 dictionaries and 3 variables with the value \"None\" which are gonna be used in our conditions."},{"metadata":{"trusted":true,"_uuid":"af9abaa93349123a84f31fa2bd6a6760353ecab3"},"cell_type":"code","source":"prd['user_max_onb'] = prd.groupby('user_id').order_number.transform(np.max)   \nitem_N2_cnt    = defaultdict(int)\nitem_N2_chance = defaultdict(int)\nitem_N3_cnt    = defaultdict(int)\nitem_N3_chance = defaultdict(int)\nitem_N4_cnt    = defaultdict(int)\nitem_N4_chance = defaultdict(int)\nitem_N5_cnt    = defaultdict(int)\nitem_N5_chance = defaultdict(int)\npid_bk = uid_bk = onb_bk = None","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fab98122245a1ba6899ab4b23c21682ac04f05f4"},"cell_type":"markdown","source":"## 4.2 Using a loop for the calculation of the main indexes\nAfter that, we create the loop. The only differences are on the conditions. Specifically, if the user and product id are the same as in the previous <= N orders and the user has made at least N orders, the variable item_N_cnt is increased by 1 at the value of the respective index/product_id. \n\nThe second condition is true and does the same for the dictionary item_N_chance when just an item has already been purchased once and the orders are at least N."},{"metadata":{"trusted":true,"_uuid":"7261c5bd526a7d4cab8a80d562a24b8af9bedafb"},"cell_type":"code","source":"for pid, uid, onb, max_onb in prd[['product_id', 'user_id', 'order_number','user_max_onb']].values:\n        \n    if pid==pid_bk and uid==uid_bk and (onb-onb_bk)<=2 and (max_onb-onb) >=2:\n        item_N2_cnt[pid] +=1\n    if pid==pid_bk and uid==uid_bk and (max_onb-onb) >=2:\n        item_N2_chance[pid] +=1\n\n    if pid==pid_bk and uid==uid_bk and (onb-onb_bk)<=3 and (max_onb-onb) >=3:\n        item_N3_cnt[pid] +=1\n    if pid==pid_bk and uid==uid_bk and (max_onb-onb) >=3:\n        item_N3_chance[pid] +=1\n\n    if pid==pid_bk and uid==uid_bk and (onb-onb_bk)<=4 and (max_onb-onb) >=4:\n        item_N4_cnt[pid] +=1\n    if pid==pid_bk and uid==uid_bk and (max_onb-onb) >=4:\n        item_N4_chance[pid] +=1\n\n    if pid==pid_bk and uid==uid_bk and (onb-onb_bk)<=5 and (max_onb-onb) >=5:\n        item_N5_cnt[pid] +=1\n    if pid==pid_bk and uid==uid_bk and (max_onb-onb) >=5:\n        item_N5_chance[pid] +=1\n\n    pid_bk = pid\n    uid_bk = uid\n    onb_bk = onb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73596ae260b7e8f6ca0cbc12580ed267251543d0"},"cell_type":"markdown","source":"## 4.3 Organizing our findings in data frames\nThen, we turn each dictionary into data frame which contains 2 columns: product id and the variable we have already calculated."},{"metadata":{"trusted":true,"_uuid":"21ddb922cc93c1343b0eb6f490cb4aebb1ab8d1f"},"cell_type":"code","source":"item_N2_cnt = pd.DataFrame.from_dict(item_N2_cnt, orient='index').reset_index()\nitem_N2_cnt.columns = ['product_id', 'item_N2_cnt']\nitem_N2_chance = pd.DataFrame.from_dict(item_N2_chance, orient='index').reset_index()\nitem_N2_chance.columns = ['product_id', 'item_N2_chance']\n\nitem_N3_cnt = pd.DataFrame.from_dict(item_N3_cnt, orient='index').reset_index()\nitem_N3_cnt.columns = ['product_id', 'item_N3_cnt']\nitem_N3_chance = pd.DataFrame.from_dict(item_N3_chance, orient='index').reset_index()\nitem_N3_chance.columns = ['product_id', 'item_N3_chance']\n\nitem_N4_cnt = pd.DataFrame.from_dict(item_N4_cnt, orient='index').reset_index()\nitem_N4_cnt.columns = ['product_id', 'item_N4_cnt']\nitem_N4_chance = pd.DataFrame.from_dict(item_N4_chance, orient='index').reset_index()\nitem_N4_chance.columns = ['product_id', 'item_N4_chance']\n\nitem_N5_cnt = pd.DataFrame.from_dict(item_N5_cnt, orient='index').reset_index()\nitem_N5_cnt.columns = ['product_id', 'item_N5_cnt']\nitem_N5_chance = pd.DataFrame.from_dict(item_N5_chance, orient='index').reset_index()\nitem_N5_chance.columns = ['product_id', 'item_N5_chance']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79c59249cdd2b9ada21ab2ab2191651e462c08ce"},"cell_type":"markdown","source":"The next step is to merge each pair of data frame. We use the outer join in order to group the dictionaries by the N number. Hence, we create 4 new data frames with 2 columns: item_N_cnt and item_N_chance."},{"metadata":{"trusted":true,"_uuid":"296a4c369f8e7343086f34c419f0976da0f6004e"},"cell_type":"code","source":"df2 = pd.merge(item_N2_cnt, item_N2_chance, on='product_id', how='outer')\ndf3 = pd.merge(item_N3_cnt, item_N3_chance, on='product_id', how='outer')\ndf4 = pd.merge(item_N4_cnt, item_N4_chance, on='product_id', how='outer')\ndf5 = pd.merge(item_N5_cnt, item_N5_chance, on='product_id', how='outer')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"413d08e4ee5c020b65cfc770a9f6d17073bf67da"},"cell_type":"markdown","source":"We continue the grouping of the data frames until we reach to the final data frame. Now, with the same use of join, we merge the last 4 data frame into one and we fill any null value with 0."},{"metadata":{"trusted":true,"_uuid":"10b979ee07eb310a756a834b6e866c539ab30d7f"},"cell_type":"code","source":"df = pd.merge(pd.merge(df2, df3, on='product_id', how='outer'),\n              pd.merge(df4, df5, on='product_id', how='outer'), \n              on='product_id', how='outer').fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bd3b07ed754d400dab9bd28d6c08c5c3317678d"},"cell_type":"markdown","source":"Finally, in our final data frame we create four new columns which are the ratios of item_N_cnt to item_N_chance for every value of N."},{"metadata":{"trusted":true,"_uuid":"a8da94196e22eb527f7fe0aced5ef4b53c960b32"},"cell_type":"code","source":"df['item_N2_ratio'] = df['item_N2_cnt']/df['item_N2_chance']\ndf['item_N3_ratio'] = df['item_N3_cnt']/df['item_N3_chance']\ndf['item_N4_ratio'] = df['item_N4_cnt']/df['item_N4_chance']\ndf['item_N5_ratio'] = df['item_N5_cnt']/df['item_N5_chance']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3110ab259e27e68a45f91b8c9f49e3770c0e000"},"cell_type":"markdown","source":"At this point, we fill any null values with zero and we are ready to see the table."},{"metadata":{"trusted":true,"_uuid":"6a52c65fa079012abdc25e178bae7e7944e24040"},"cell_type":"code","source":"df.fillna(0, inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8469f025b3c3b90bfe2176d0ca423c82ba54163b"},"cell_type":"markdown","source":"## Important Notice\nAt this point, we should underline the business meaning of these ratios. Actually, they are probabilities which show the possibility that the user will purchase the product on the next order he will make on the basis of the pattern of his purchases."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}