{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Tabular Playground Series - Jan 2022: A simple average model\nIn the [Tabular Playground Series - Jan 2022](https://www.kaggle.com/c/tabular-playground-series-jan-2022) competition we are tasked with predicting the sales of three different products (the `Kaggle Mug`, the `Kaggle Hat` and the `Kaggle Sticker`, all highly sought-after products) in two different stores (`KaggleMart` and `KaggleRama`) in three different countries (`Finland`, `Sweden` and `Norway`) for the year 2019. We are provided with training data for the years 2015 to 2018.","metadata":{}},{"cell_type":"code","source":"import numpy  as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nplt.rcParams.update({'font.size': 16})\nfrom datetime import datetime\nfrom datetime import timedelta","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:27.766842Z","iopub.execute_input":"2022-02-05T06:27:27.767518Z","iopub.status.idle":"2022-02-05T06:27:27.773508Z","shell.execute_reply.started":"2022-02-05T06:27:27.767471Z","shell.execute_reply":"2022-02-05T06:27:27.772834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SMAPE metric\nThis competition is evaluated using the [symmetric mean absolute percentage error (SMAPE)](https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error). Such an evaluation metric was used in the kaggle [Web Traffic Time Series Forecasting competition](https://www.kaggle.com/c/web-traffic-time-series-forecasting/), and [CPMP](https://www.kaggle.com/cpmpml) kindly provided us with the python code to evaluate this metric in the topic [\"SMAPE_Python\"](https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414):","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.round(np.mean(diff),5)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:27.774917Z","iopub.execute_input":"2022-02-05T06:27:27.775861Z","iopub.status.idle":"2022-02-05T06:27:27.788121Z","shell.execute_reply.started":"2022-02-05T06:27:27.775808Z","shell.execute_reply":"2022-02-05T06:27:27.787527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the excellent notebook [\"SMAPE Weirdness\"](https://www.kaggle.com/cpmpml/smape-weirdness), again by CPMP, we see that in a similar fashion to the better known root mean squared logarithmic error (RMSLE) metric the SMAPE is asymmetric; penalizing much more the underestimated predictions than the overestimated predictions (figure adapted from the aforementioned notebook, using 3 as the ground truth value):","metadata":{}},{"cell_type":"code","source":"# true value\ny_true = np.array(3)\n# predictions\ny_pred = np.ones(1)\nx = np.linspace(0,10,100)\nresult = [SMAPE(y_true, i * y_pred) for i in x]\n# plot\nplt.rcParams[\"figure.figsize\"] = (5, 3)\nplt.plot(x, result)\nplt.xlabel('prediction')\nplt.ylabel('SMAPE')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:27.789522Z","iopub.execute_input":"2022-02-05T06:27:27.789712Z","iopub.status.idle":"2022-02-05T06:27:27.921539Z","shell.execute_reply.started":"2022-02-05T06:27:27.789688Z","shell.execute_reply":"2022-02-05T06:27:27.921003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test split and feature engineering\nWe shall read in the training data, and create a new training dataset out of the year 2017 (*i.e.* use a 'look-back' window of 1 year), and a test dataset out of the 2018 data","metadata":{}},{"cell_type":"code","source":"train_all_years = pd.read_csv(\"../input/tabular-playground-series-jan-2022/train.csv\",parse_dates=['date'],index_col=[\"row_id\"])\n\ntrain = train_all_years[train_all_years.date.between('2017-01-01', '2017-12-31')].copy()\ntest  = train_all_years[train_all_years.date.between('2018-01-01', '2018-12-31')].copy()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:27.922423Z","iopub.execute_input":"2022-02-05T06:27:27.922879Z","iopub.status.idle":"2022-02-05T06:27:27.959861Z","shell.execute_reply.started":"2022-02-05T06:27:27.922852Z","shell.execute_reply":"2022-02-05T06:27:27.959413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we shall now create some new features, namely the day of the week and the month","metadata":{}},{"cell_type":"code","source":"train['day_of_the_week'] = train['date'].dt.day_name()\ntest['day_of_the_week']  = test['date'].dt.day_name()\n\ntrain['month'] = train['date'].dt.month_name()\ntest['month']  = test['date'].dt.month_name()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:27.961134Z","iopub.execute_input":"2022-02-05T06:27:27.961391Z","iopub.status.idle":"2022-02-05T06:27:27.972575Z","shell.execute_reply.started":"2022-02-05T06:27:27.961369Z","shell.execute_reply":"2022-02-05T06:27:27.971814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 1: Simple mean\nThis is a simple model, averaging over the `country`, `store` and `product`","metadata":{}},{"cell_type":"code","source":"# calculate the mean values\ntrain_means        = train.groupby(['country','store','product'])['num_sold'].mean().to_dict()\ntest[\"prediction\"] = test.set_index(['country','store','product']).index.map(train_means.get)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:27.97355Z","iopub.execute_input":"2022-02-05T06:27:27.973835Z","iopub.status.idle":"2022-02-05T06:27:27.99429Z","shell.execute_reply.started":"2022-02-05T06:27:27.973814Z","shell.execute_reply":"2022-02-05T06:27:27.993648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now calculate the SMAPE score for this model","metadata":{}},{"cell_type":"code","source":"SMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:27.995047Z","iopub.execute_input":"2022-02-05T06:27:27.995901Z","iopub.status.idle":"2022-02-05T06:27:28.002169Z","shell.execute_reply.started":"2022-02-05T06:27:27.995878Z","shell.execute_reply":"2022-02-05T06:27:28.001758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2: Day of the week model","metadata":{}},{"cell_type":"code","source":"train_means        = train.groupby(['country','store','product','day_of_the_week'])['num_sold'].mean().to_dict()\ntest[\"prediction\"] = test.set_index(['country','store','product','day_of_the_week']).index.map(train_means.get)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:28.002829Z","iopub.execute_input":"2022-02-05T06:27:28.003602Z","iopub.status.idle":"2022-02-05T06:27:28.02199Z","shell.execute_reply.started":"2022-02-05T06:27:28.003574Z","shell.execute_reply":"2022-02-05T06:27:28.021388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:28.022841Z","iopub.execute_input":"2022-02-05T06:27:28.02301Z","iopub.status.idle":"2022-02-05T06:27:28.030849Z","shell.execute_reply.started":"2022-02-05T06:27:28.022985Z","shell.execute_reply":"2022-02-05T06:27:28.030063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us take a look at our predictions for `KaggleMart` stores in `Norway`, our predictions are the thick solid lines, and the test data are the thinner dashed lines","metadata":{}},{"cell_type":"code","source":"country = \"Norway\"\nstore   = \"KaggleMart\"\none_country_and_store = test.query(\"country == @country & store == @store\").copy()\n\nfig, ax = plt.subplots(figsize=(20, 7))\nsns.lineplot(data=one_country_and_store, x=\"date\", y=\"num_sold\", hue=\"product\", linewidth = 2, linestyle='--')\nsns.lineplot(data=one_country_and_store,  x=\"date\", y=\"prediction\", hue=\"product\", linewidth = 3.5)\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:28.031669Z","iopub.execute_input":"2022-02-05T06:27:28.031834Z","iopub.status.idle":"2022-02-05T06:27:28.424797Z","shell.execute_reply.started":"2022-02-05T06:27:28.031812Z","shell.execute_reply":"2022-02-05T06:27:28.42411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 3: Month and day of the week model","metadata":{}},{"cell_type":"code","source":"train_means  = train.groupby(['country','store','product','day_of_the_week','month'])['num_sold'].mean().to_dict()\ntest[\"prediction\"] = test.set_index(['country','store','product','day_of_the_week','month']).index.map(train_means.get)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:28.427213Z","iopub.execute_input":"2022-02-05T06:27:28.427426Z","iopub.status.idle":"2022-02-05T06:27:28.580216Z","shell.execute_reply.started":"2022-02-05T06:27:28.427401Z","shell.execute_reply":"2022-02-05T06:27:28.579703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:28.581125Z","iopub.execute_input":"2022-02-05T06:27:28.581399Z","iopub.status.idle":"2022-02-05T06:27:28.589221Z","shell.execute_reply.started":"2022-02-05T06:27:28.581368Z","shell.execute_reply":"2022-02-05T06:27:28.588396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have an even better score. Let us take a look","metadata":{}},{"cell_type":"code","source":"one_country_and_store = test.query(\"country == @country & store == @store\").copy()\n\nfig, ax = plt.subplots(figsize=(20, 7))\nsns.lineplot(data=one_country_and_store, x=\"date\", y=\"num_sold\", hue=\"product\", linewidth = 2, linestyle='--')\nsns.lineplot(data=one_country_and_store,  x=\"date\", y=\"prediction\", hue=\"product\", linewidth = 3.5)\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:28.590168Z","iopub.execute_input":"2022-02-05T06:27:28.590396Z","iopub.status.idle":"2022-02-05T06:27:29.110748Z","shell.execute_reply.started":"2022-02-05T06:27:28.590364Z","shell.execute_reply":"2022-02-05T06:27:29.110081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that on the whole things are better, but there is plenty of room for improvement, in particular for December, but also around [Easter time](https://en.wikipedia.org/wiki/Easter#Date). Here is a plot of the difference between our predictions and the actual values","metadata":{}},{"cell_type":"code","source":"one_country_and_store[\"residual\"] =  one_country_and_store[\"num_sold\"] - one_country_and_store[\"prediction\"] \nfig, ax = plt.subplots(figsize=(20, 7))\nsns.lineplot(data=one_country_and_store, x=\"date\", y=\"residual\", hue=\"product\", linewidth = 1.5)\nplt.ylim(-200,1000)\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:29.111623Z","iopub.execute_input":"2022-02-05T06:27:29.111788Z","iopub.status.idle":"2022-02-05T06:27:29.426979Z","shell.execute_reply.started":"2022-02-05T06:27:29.111765Z","shell.execute_reply":"2022-02-05T06:27:29.425861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 4: Daily model of Christmas\nLet us focus only on the month of December. Visual inspection indicates that the month of December behaves as most other months up until the week of Christmas (25th-31st). In view of this we shall treat December as two different parts; a day-of-the-week model up to, and including, December 24, and the we shall look at each day individually for the last week.","metadata":{}},{"cell_type":"code","source":"# make a new 'day' feature\ntrain['day'] = train['date'].dt.day\ntest['day']  = test['date'].dt.day","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:29.428217Z","iopub.execute_input":"2022-02-05T06:27:29.428518Z","iopub.status.idle":"2022-02-05T06:27:29.436628Z","shell.execute_reply.started":"2022-02-05T06:27:29.428485Z","shell.execute_reply":"2022-02-05T06:27:29.435798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# December model part 1: day_of_the_week model for pre-Christmas\ntrain_December = train.query(\"month == 'December' & day < 25\").copy()\ntest_December  = test.query(\"month == 'December'& day < 25\").copy()\ntrain_means        = train_December.groupby(['country','store','product','day_of_the_week'])['num_sold'].mean().to_dict()\ntest_December[\"prediction\"]=test_December.set_index(['country','store','product','day_of_the_week']).index.map(train_means.get)\ntest.update(test_December)\n\n# December model part 2: a daily model for the last week\ntrain_December = train.query(\"month == 'December' & day >= 25\").copy()\ntest_December  = test.query(\"month == 'December'& day >= 25\").copy()\ntrain_means                 = train_December.groupby(['country','store','product','day'])['num_sold'].mean().to_dict()\ntest_December[\"prediction\"] = test_December.set_index(['country','store','product','day']).index.map(train_means.get)\ntest.update(test_December)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:29.438081Z","iopub.execute_input":"2022-02-05T06:27:29.438821Z","iopub.status.idle":"2022-02-05T06:27:29.488156Z","shell.execute_reply.started":"2022-02-05T06:27:29.438761Z","shell.execute_reply":"2022-02-05T06:27:29.487091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let us take a look","metadata":{}},{"cell_type":"code","source":"test_December  = test.query(\"month == 'December'\").copy()\none_country_and_store = test_December.query(\"country == @country & store == @store\").copy()\n\nfig, ax = plt.subplots(figsize=(20, 7))\nsns.lineplot(data=one_country_and_store, x=\"date\", y=\"num_sold\", hue=\"product\", linewidth = 2, linestyle='--')\nsns.lineplot(data=one_country_and_store,  x=\"date\", y=\"prediction\", hue=\"product\", linewidth = 3.5)\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:29.489398Z","iopub.execute_input":"2022-02-05T06:27:29.489607Z","iopub.status.idle":"2022-02-05T06:27:29.817311Z","shell.execute_reply.started":"2022-02-05T06:27:29.48958Z","shell.execute_reply":"2022-02-05T06:27:29.81647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us update the **Month and day of the week model** with the **Daily model of December** and calculate the new score","metadata":{}},{"cell_type":"code","source":"SMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:29.818173Z","iopub.execute_input":"2022-02-05T06:27:29.818337Z","iopub.status.idle":"2022-02-05T06:27:29.828494Z","shell.execute_reply.started":"2022-02-05T06:27:29.818315Z","shell.execute_reply":"2022-02-05T06:27:29.827267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now take a look at the combined model","metadata":{}},{"cell_type":"code","source":"one_country_and_store = test.query(\"country == @country & store == @store\").copy()\n\nfig, ax = plt.subplots(figsize=(20, 7))\nsns.lineplot(data=one_country_and_store, x=\"date\", y=\"num_sold\", hue=\"product\", linewidth = 2, linestyle='--')\nsns.lineplot(data=one_country_and_store,  x=\"date\", y=\"prediction\", hue=\"product\", linewidth = 3.5)\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:29.829762Z","iopub.execute_input":"2022-02-05T06:27:29.830325Z","iopub.status.idle":"2022-02-05T06:27:30.32318Z","shell.execute_reply.started":"2022-02-05T06:27:29.830269Z","shell.execute_reply":"2022-02-05T06:27:30.322338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Specific day model: The 1st of January\nIn the above plot we can see that we even may wish to focus on a specific day, for example on the 1st of January we can see a peak where people who have been saving up all year to buy their kaggle merchandise make the most of the January sales:","metadata":{}},{"cell_type":"code","source":"train_1_January = train.query(\"month == 'January' & day == 1\").copy()\ntest_1_January  = test.query(\"month == 'January' & day == 1\").copy()\ntrain_means     = train_1_January.groupby(['country','store','product'])['num_sold'].mean().to_dict()\ntest_1_January[\"prediction\"] = test_1_January.set_index(['country','store','product']).index.map(train_means.get)\ntest.update(test_1_January)\n# calculate the score\nSMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.32434Z","iopub.execute_input":"2022-02-05T06:27:30.324559Z","iopub.status.idle":"2022-02-05T06:27:30.351852Z","shell.execute_reply.started":"2022-02-05T06:27:30.32453Z","shell.execute_reply":"2022-02-05T06:27:30.351137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"...and for those who were way too hungover to make it to their local Kaggle stores on New Year's Day, we shall also look at the sales on the 2nd of January too:","metadata":{}},{"cell_type":"code","source":"train_2_January = train.query(\"month == 'January' & day == 2\").copy()\ntest_2_January  = test.query(\"month == 'January' & day == 2\").copy()\ntrain_means     = train_2_January.groupby(['country','store','product'])['num_sold'].mean().to_dict()\ntest_2_January[\"prediction\"] = test_2_January.set_index(['country','store','product']).index.map(train_means.get)\ntest.update(test_2_January)\n# calculate the score\nSMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.352806Z","iopub.execute_input":"2022-02-05T06:27:30.353515Z","iopub.status.idle":"2022-02-05T06:27:30.387236Z","shell.execute_reply.started":"2022-02-05T06:27:30.353465Z","shell.execute_reply":"2022-02-05T06:27:30.386571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Moveable holidays: Easter\nA visual inspection of the training data indicates that there are substantially more sales during Easter Sunday all the way up to Første pinsedag 🇳🇴, Helluntaipäivä 🇫🇮, and Pingstdagen 🇸🇪, the first Saturday after Pentecost (Whit Sunday), [especially in Norway](https://www.lifeinnorway.net/pinse-holiday/). We shall make use of [`dateutil.easter`](https://dateutil.readthedocs.io/en/stable/easter.html) to provide the date of Easter Sunday onwards for each year of interest:","metadata":{}},{"cell_type":"code","source":"from dateutil.easter import easter\n\ndef get_Easter_dates(years):\n    Easter_dates = []\n    Easter_index = []\n    Easter_date_index = []\n    for year in years:\n        Easter_dates.append(easter(year))\n        Easter_index.append(0)\n        Easter_date_index.append([easter(year),0])\n        # also calculate the dates of the days following Easter\n        for day in range(1, 56):\n            Easter_dates.append(easter(year)+timedelta(days=day))       \n            Easter_index.append(day)\n            Easter_date_index.append([easter(year)+timedelta(days=day),day])  \n    return Easter_dates,Easter_index,Easter_date_index\n\nyears = [2015,2016,2017,2018,2019]\nEaster_dates,Easter_index,Easter_date_index = get_Easter_dates(years)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.38841Z","iopub.execute_input":"2022-02-05T06:27:30.389408Z","iopub.status.idle":"2022-02-05T06:27:30.398771Z","shell.execute_reply.started":"2022-02-05T06:27:30.389373Z","shell.execute_reply":"2022-02-05T06:27:30.397946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now calculate the averages for these dates w.r.t. Easter Sunday, insert them into our model, and see our new score","metadata":{}},{"cell_type":"code","source":"train_Easter = train.query(\"date == @Easter_dates\").copy()\ntest_Easter  = test.query(\"date == @Easter_dates\").copy()\n\n# create the \"day_of_Easter\" feature\nmapping = dict(Easter_date_index)\ntrain_Easter[\"day_of_Easter\"] = train_Easter[\"date\"].map(mapping)\ntest_Easter[\"day_of_Easter\"]  = test_Easter[\"date\"].map(mapping)\n\ntrain_means   = train_Easter.groupby(['country','store','product','day_of_Easter'])['num_sold'].mean().to_dict()\ntest_Easter[\"prediction\"] = test_Easter.set_index(['country','store','product','day_of_Easter']).index.map(train_means.get)\n\ntest.update(test_Easter)\nSMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.401119Z","iopub.execute_input":"2022-02-05T06:27:30.401453Z","iopub.status.idle":"2022-02-05T06:27:30.440589Z","shell.execute_reply.started":"2022-02-05T06:27:30.401418Z","shell.execute_reply":"2022-02-05T06:27:30.440175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling by year-over-year growth\nSo far we have assumed that overall the 2018 test data will behave just as the 2017 training data. However, that may not be the case. For example, here is a table and plot of the total number of units sold annually for the whole training set provided:","metadata":{}},{"cell_type":"code","source":"train_all_years['year'] = train_all_years['date'].dt.year\npivot_table = pd.pivot_table(train_all_years, index=['year'], values=['num_sold'], aggfunc=sum)\npivot_table","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.441361Z","iopub.execute_input":"2022-02-05T06:27:30.441858Z","iopub.status.idle":"2022-02-05T06:27:30.454615Z","shell.execute_reply.started":"2022-02-05T06:27:30.44183Z","shell.execute_reply":"2022-02-05T06:27:30.454067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (5, 2)\npivot_table.plot(kind='bar').legend(loc='center left',bbox_to_anchor=(1.0, 0.5));","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:30.455424Z","iopub.execute_input":"2022-02-05T06:27:30.455816Z","iopub.status.idle":"2022-02-05T06:27:30.579472Z","shell.execute_reply.started":"2022-02-05T06:27:30.455794Z","shell.execute_reply":"2022-02-05T06:27:30.57896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see that the overall number of units sold in 2018 was substantially greater than those sold in 2017. Let us look at the effect on our score of scaling by this growth. Note that this is a form of [data leakage](https://en.wikipedia.org/wiki/Leakage_%28machine_learning%29) as we are now using information from the test set (*i.e.* information from the future is being leaked back into our training data) in our model. If one actually wished to make use of such a scaling one should first construct a model of the yearly growth *only* from the training data.","metadata":{}},{"cell_type":"code","source":"units_sold_2017 = train['num_sold'].sum()\nunits_sold_2018 = test['num_sold'].sum()\nyearly_growth   = units_sold_2018 / units_sold_2017\n# scale our predictions\ntest[\"prediction\"] = test[\"prediction\"] * yearly_growth\nSMAPE(test[\"num_sold\"], test[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.580506Z","iopub.execute_input":"2022-02-05T06:27:30.580777Z","iopub.status.idle":"2022-02-05T06:27:30.590237Z","shell.execute_reply.started":"2022-02-05T06:27:30.580752Z","shell.execute_reply":"2022-02-05T06:27:30.589796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that a good model of the year-over-year growth does indeed have the potential to significantly improve our score. When making such a model of the yearly growth one could make use of additional economic data, for example the [gross domestic product for each of the countries Finland, Norway, and Sweden](https://www.kaggle.com/carlmcbrideellis/gdp-of-finland-norway-and-sweden-2015-2019).\n\nFinally let us now look again at the difference between our predictions and the actual values, on the same scale as the plot above:","metadata":{}},{"cell_type":"code","source":"one_country_and_store = test.query(\"country == @country & store == @store\").copy()\none_country_and_store[\"residual\"] =  one_country_and_store[\"num_sold\"] - one_country_and_store[\"prediction\"] \n\nfig, ax = plt.subplots(figsize=(20, 7))\nsns.lineplot(data=one_country_and_store, x=\"date\", y=\"residual\", hue=\"product\", linewidth = 1.5)\nplt.ylim(-200,1000)\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:30.591119Z","iopub.execute_input":"2022-02-05T06:27:30.591407Z","iopub.status.idle":"2022-02-05T06:27:30.907665Z","shell.execute_reply.started":"2022-02-05T06:27:30.591381Z","shell.execute_reply":"2022-02-05T06:27:30.907223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we shall predict the 2019 data\nLet us now make a prediction, using the combined **(Month-Day of the Week)+(December)+(Moveable holidays)+(Specific Day)** model. If we use all of the training data that we have available (4 years) we obtain a Public Leaderboard score of 7.16. Here, in a rather *ad hoc* fashion, we shall use a look-back window of the last three years:","metadata":{}},{"cell_type":"code","source":"# select the last three years of training data\ntrain = train_all_years.query(\"date >= '2016-01-01' \").copy()\ntest  = pd.read_csv(\"../input/tabular-playground-series-jan-2022/test.csv\",parse_dates=['date'])\n\n# create the new features\ntrain['day_of_the_week'] = train['date'].dt.day_name()\ntest['day_of_the_week']  = test['date'].dt.day_name()\n\ntrain['month'] = train['date'].dt.month_name()\ntest['month']  = test['date'].dt.month_name()\n\ntrain['day'] = train['date'].dt.day\ntest['day']  = test['date'].dt.day\n\n# Overall model\ntrain_means      = train.groupby(['country','store','product','day_of_the_week','month'])['num_sold'].mean().to_dict()\ntest[\"num_sold\"] = test.set_index(['country','store','product','day_of_the_week','month']).index.map(train_means.get)\n\n# December model part 1: day_of_the_week model for pre-Christmas\ntrain_December = train.query(\"month == 'December' & day < 25\").copy()\ntest_December  = test.query(\"month == 'December'  & day < 25\").copy()\ntrain_means    = train_December.groupby(['country','store','product','day_of_the_week'])['num_sold'].mean().to_dict()\ntest_December[\"num_sold\"] = test_December.set_index(['country','store','product','day_of_the_week']).index.map(train_means.get)\ntest.update(test_December)\n\n# December model part 2: a daily model for the last week\ntrain_December = train.query(\"month == 'December' & day >= 25\").copy()\ntest_December  = test.query(\"month == 'December'  & day >= 25\").copy()\ntrain_means                 = train_December.groupby(['country','store','product','day'])['num_sold'].mean().to_dict()\ntest_December[\"num_sold\"] = test_December.set_index(['country','store','product','day']).index.map(train_means.get)\ntest.update(test_December)\n\n# Easter Sunday and the following days up to the saturday after Whit Sunday\ntrain_Easter = train.query(\"date == @Easter_dates\").copy()\ntest_Easter  = test.query(\"date == @Easter_dates\").copy()\ntrain_Easter[\"day_of_Easter\"] = train_Easter[\"date\"].map(mapping)\ntest_Easter[\"day_of_Easter\"]  = test_Easter[\"date\"].map(mapping)\ntrain_means             = train_Easter.groupby(['country','store','product','day_of_Easter'])['num_sold'].mean().to_dict()\ntest_Easter[\"num_sold\"] = test_Easter.set_index(['country','store','product','day_of_Easter']).index.map(train_means.get)\ntest.update(test_Easter)\n\n# Specific day model: January the 1st\ntrain_1_January = train.query(\"month == 'January' & day == 1\").copy()\ntest_1_January  = test.query(\"month == 'January' & day == 1\").copy()\ntrain_means                = train_1_January.groupby(['country','store','product'])['num_sold'].mean().to_dict()\ntest_1_January[\"num_sold\"] = test_1_January.set_index(['country','store','product']).index.map(train_means.get)\ntest.update(test_1_January)\n\n# Specific day model: January the 2nd\ntrain_2_January = train.query(\"month == 'January' & day == 2\").copy()\ntest_2_January  = test.query(\"month == 'January' & day == 2\").copy()\ntrain_means                = train_2_January.groupby(['country','store','product'])['num_sold'].mean().to_dict()\ntest_2_January[\"num_sold\"] = test_2_January.set_index(['country','store','product']).index.map(train_means.get)\ntest.update(test_2_January)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:30.908578Z","iopub.execute_input":"2022-02-05T06:27:30.908819Z","iopub.status.idle":"2022-02-05T06:27:31.098097Z","shell.execute_reply.started":"2022-02-05T06:27:30.908797Z","shell.execute_reply":"2022-02-05T06:27:31.097334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us take a look at our prediction for 2019","metadata":{}},{"cell_type":"code","source":"one_country_and_store_train = train.query(\"country == @country & store == @store\")\none_country_and_store_test  = test.query(\"country == @country & store == @store\")\n\nfig, ax = plt.subplots(figsize=(20, 5))\nsns.lineplot(data=one_country_and_store_train, x=\"date\", y=\"num_sold\", hue=\"product\", linewidth = 1.5)\nsns.lineplot(data=one_country_and_store_test,  x=\"date\", y=\"num_sold\", hue=\"product\", linewidth = 1.5)\nplt.text(datetime.strptime(\"2017-03-01\", '%Y-%m-%d'), 1300, \"training data\")\nplt.text(datetime.strptime(\"2019-04-01\", '%Y-%m-%d'), 1300, \"2019 predictions\")\nplt.legend([],[], frameon=False);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:31.102238Z","iopub.execute_input":"2022-02-05T06:27:31.102474Z","iopub.status.idle":"2022-02-05T06:27:31.690321Z","shell.execute_reply.started":"2022-02-05T06:27:31.102445Z","shell.execute_reply":"2022-02-05T06:27:31.689432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2019 GDP Scaling\nIf we were situated on the 31st of December 2018, and we were asked to predict the `num_sold` for the year 2019 then the following operation **would not be possible**, indeed this would be a prime example of [look-ahead bias](https://www.investopedia.com/terms/l/lookaheadbias.asp). However, as this is a kaggle competition situated in 2022 we shall proceed. We have seen above that scaling by year-over-year growth can significantly improve our score. We obviously do not know the sales data for 2019, however we could use the 2019 GDP data *per capita* as an ersatz indicator. First we shall load in the data from the dataset [GDP per capita: Finland, Norway, Sweden (2015-19)](https://www.kaggle.com/samuelcortinhas/gdp-per-capita-finland-norway-sweden-201519) created by [Samuel Cortinhas](https://www.kaggle.com/samuelcortinhas):","metadata":{}},{"cell_type":"code","source":"GDP_data = pd.read_csv(\"../input/gdp-per-capita-finland-norway-sweden-201519/GDP_per_capita_2015_to_2019_Finland_Norway_Sweden.csv\",index_col=\"year\")\nGDP_data.style.bar(subset=['Finland','Norway','Sweden'], align='left', vmin=0,  color='#A0D6F0')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-05T06:27:31.691433Z","iopub.execute_input":"2022-02-05T06:27:31.69163Z","iopub.status.idle":"2022-02-05T06:27:31.77243Z","shell.execute_reply.started":"2022-02-05T06:27:31.691605Z","shell.execute_reply":"2022-02-05T06:27:31.771572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now for each country we shall calculate a scaling factor for 2019 with respect to the mean GDP of the years 2016, 2017, and 2018, then apply that scaling factor to our predictions for 2019, for each of the countries:","metadata":{}},{"cell_type":"code","source":"scale_Finland = GDP_data.iloc[4,0] / GDP_data.iloc[1:4,0].mean()\nscale_Norway  = GDP_data.iloc[4,1] / GDP_data.iloc[1:4,1].mean()\nscale_Sweden  = GDP_data.iloc[4,2] / GDP_data.iloc[1:4,2].mean()\n\nmask    = (test['country']=='Finland')\nFinland = test[mask]\ntest.loc[mask,'num_sold'] = Finland[\"num_sold\"] * scale_Finland\n\nmask    = (test['country']=='Norway')\nNorway  = test[mask]\ntest.loc[mask,'num_sold'] = Norway[\"num_sold\"] * scale_Norway\n\nmask    = (test['country']=='Sweden')\nSweden  = test[mask]\ntest.loc[mask,'num_sold'] = Sweden[\"num_sold\"] * scale_Sweden","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:31.773547Z","iopub.execute_input":"2022-02-05T06:27:31.77374Z","iopub.status.idle":"2022-02-05T06:27:31.789342Z","shell.execute_reply.started":"2022-02-05T06:27:31.773716Z","shell.execute_reply":"2022-02-05T06:27:31.788493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now create a `submission.csv` file","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'row_id': test.row_id, 'num_sold': test.num_sold})\nsubmission['row_id'] = submission['row_id'].astype('int32')\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T06:27:31.791063Z","iopub.execute_input":"2022-02-05T06:27:31.791242Z","iopub.status.idle":"2022-02-05T06:27:31.815371Z","shell.execute_reply.started":"2022-02-05T06:27:31.79122Z","shell.execute_reply":"2022-02-05T06:27:31.814526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <center style=\"background-color:Gainsboro; width:60%;\">Interesting reading</center>\n* [Rob J. Hyndman and George Athanasopoulos \"*Forecasting: Principles and Practice*\", (3rd Edition)](https://otexts.com/fpp3/)\n* [Fotios Petropoulos, *et al. \"Forecasting: Theory and Practice*\", arXiv:2012.03854 (2020)](https://arxiv.org/pdf/2012.03854.pdf)","metadata":{}}]}