{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Summary\n\n\n#### About the dataset\n\nData found in this dataset was collected from the [Climate Data Online (CDO)](https://www.ncdc.noaa.gov/cdo-web/) of the National Centers For Environmental Information (NCEI). It contains daily country average precipitation and air temperature data (in metric units). The original dataset collected from the CDO's site consisted of around 4.9 million individual observations from 1306 distinct weather stations throughout the three countries. Missing data points were imputed with the daily mean and averaged across all weather stations within the country.\n\nThe dataset can be accessed [here](https://www.kaggle.com/adamwurdits/finland-norway-and-sweden-weather-data-20152019) along with some more information. For updates, suggestions and general discussion, please visit [this](https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/301486) thread.\n\n### Findings\n\nNeither the base features nor any feature engineering seems to improve our predictions.\n* The use of some features improves cross-validation SMAPE slightly, but makes the public score worse\n* Correlations in weather and traing data coincide with the effects of seasonality","metadata":{}},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom catboost import CatBoostRegressor\nimport shap","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:51:47.241662Z","iopub.execute_input":"2022-01-31T20:51:47.242374Z","iopub.status.idle":"2022-01-31T20:51:47.248881Z","shell.execute_reply.started":"2022-01-31T20:51:47.242321Z","shell.execute_reply":"2022-01-31T20:51:47.248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv', parse_dates=['date'])\ndf_test = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv', parse_dates=['date'])\nsample_submission = pd.read_csv('../input/tabular-playground-series-jan-2022/sample_submission.csv')\ndf_weather = pd.read_csv('../input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv', parse_dates=['date'])","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-01-31T20:51:47.250788Z","iopub.execute_input":"2022-01-31T20:51:47.251211Z","iopub.status.idle":"2022-01-31T20:51:47.641454Z","shell.execute_reply.started":"2022-01-31T20:51:47.251168Z","shell.execute_reply":"2022-01-31T20:51:47.640856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Let's merge the weather dataset with our training and test sets and do some basic datetime feature engineering. The latter will make parts of the EDA easier.","metadata":{}},{"cell_type":"code","source":"# Adding weather data to our dataframes.\n\ndf_train = df_train.merge(df_weather, on=['date', 'country'], how='left')\ndf_test = df_test.merge(df_weather, on=['date', 'country'], how='left')\n\nweather_features = ['precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin']\n\n# Creating new features from the 'date' column.\ndf_train['year'] = df_train['date'].dt.year\ndf_train['quarter'] = df_train['date'].dt.quarter\ndf_train['month'] = df_train['date'].dt.month\ndf_train['week'] = df_train['date'].dt.isocalendar().week.astype(int)\ndf_train['day'] = df_train['date'].dt.day\ndf_train['dayofyear'] = df_train['date'].dt.dayofyear\ndf_train['daysinmonth'] = df_train['date'].dt.days_in_month\ndf_train['dayofweek'] = df_train['date'].dt.dayofweek\ndf_train['weekend'] = ((df_train['date'].dt.dayofweek) // 5 == 1).astype(int)\n\ndf_test['year'] = df_test['date'].dt.year\ndf_test['quarter'] = df_test['date'].dt.quarter\ndf_test['month'] = df_test['date'].dt.month\ndf_test['week'] = df_test['date'].dt.isocalendar().week.astype(int)\ndf_test['day'] = df_test['date'].dt.day\ndf_test['dayofyear'] = df_test['date'].dt.dayofyear\ndf_test['daysinmonth'] = df_test['date'].dt.days_in_month\ndf_test['dayofweek'] = df_test['date'].dt.dayofweek\ndf_test['weekend'] = ((df_test['date'].dt.dayofweek) // 5 == 1).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:51:47.642838Z","iopub.execute_input":"2022-01-31T20:51:47.643268Z","iopub.status.idle":"2022-01-31T20:51:47.724495Z","shell.execute_reply.started":"2022-01-31T20:51:47.643228Z","shell.execute_reply":"2022-01-31T20:51:47.723892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary statistics and trends\n\nWe will take a quick look at the data and create a few plots - just enough to get a feel for the data.","metadata":{}},{"cell_type":"code","source":"df_weather.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:51:47.726508Z","iopub.execute_input":"2022-01-31T20:51:47.726945Z","iopub.status.idle":"2022-01-31T20:51:47.743015Z","shell.execute_reply.started":"2022-01-31T20:51:47.726906Z","shell.execute_reply":"2022-01-31T20:51:47.742232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our dataframe contains 7 columns of which 5 are weather features. These are:\n\n- Precipitation - How much rain, snow, hail, etc has fallen. Measured in centimeters (cm).\n- Snow depth - How much snow has collected on the ground. Measured in millimeters (mm).\n- Temperature average - Country average of daily mean temperatures. Measured in degrees Celsius (°C).\n- Temperature maximum - Country average of daily maximum temperatures. Measured in degrees Celsius (°C).\n- Temperature minimum - Country average of daily minimum temperatures. Measured in degrees Celsius (°C).","metadata":{}},{"cell_type":"code","source":"df_train.groupby(['country', 'month'])[weather_features].mean().style.set_caption('Daily averages by month')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:51:47.744388Z","iopub.execute_input":"2022-01-31T20:51:47.744875Z","iopub.status.idle":"2022-01-31T20:51:47.818819Z","shell.execute_reply.started":"2022-01-31T20:51:47.744835Z","shell.execute_reply":"2022-01-31T20:51:47.818019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How to read this table? Taking the very first row as an example, we learn that the daily average precipiation in Finland in January is 1.4 centimeters. This means we can expect 1.4 centimeters of rain, snow or other precipitation every day of the month. Average snow depth is 327 millimeters, which means snow accumulates this high on the ground. Average temperature is self-explanatory, and the last two features show the averages of all the minimum and maximum weather station measurements.\n\nLet's create a few plots next to identify trends in the data.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 10))\n\nfig.add_subplot(211)\nplt.title('Daily mean precipitation')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'], x='month', y='precipitation', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'], x='month', y='precipitation', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'], x='month', y='precipitation', label='Sweden')\nsns.lineplot(data=df_train, x='month', y='precipitation', label='Average', color='grey')\n\nfig.add_subplot(212)\nplt.title('Daily mean snow depth')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'], x='month', y='snow_depth', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'], x='month', y='snow_depth', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'], x='month', y='snow_depth', label='Sweden')\nsns.lineplot(data=df_train, x='month', y='snow_depth', label='Average', color='grey')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:51:47.819967Z","iopub.execute_input":"2022-01-31T20:51:47.820199Z","iopub.status.idle":"2022-01-31T20:51:51.457992Z","shell.execute_reply.started":"2022-01-31T20:51:47.82017Z","shell.execute_reply":"2022-01-31T20:51:51.457388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that countries receive more precipitation in the second half of the year and Norway receives about as much as the other two countries. Snow starts to accumulate in October, starts melting in middle of spring and melts completely by the end on May. On first look, this may seem late. Let's take a look at the temperatures as a sanity check.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 6))\n\nfig.add_subplot(131)\nplt.title('Mean temperature')\nplt.xlabel('Months')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'], x='month', y='tavg', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'], x='month', y='tavg', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'], x='month', y='tavg', label='Sweden')\n\nfig.add_subplot(132)\nplt.title('Maximum temperature')\nplt.xlabel('Months')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'], x='month', y='tmax', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'], x='month', y='tmax', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'], x='month', y='tmax', label='Sweden')\n\nfig.add_subplot(133)\nplt.title('Minimum temperature')\nplt.xlabel('Months')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'], x='month', y='tmin', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'], x='month', y='tmin', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'], x='month', y='tmin', label='Sweden')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:51:51.459108Z","iopub.execute_input":"2022-01-31T20:51:51.459405Z","iopub.status.idle":"2022-01-31T20:51:55.41018Z","shell.execute_reply.started":"2022-01-31T20:51:51.459377Z","shell.execute_reply":"2022-01-31T20:51:55.409272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mean temperatures creep above freezing point in April and are still in the single digits in May, so it makes sense that we still see some snow.\n\nNow let's examine our sales by country and product and see if we identify similar trends.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 6))\n\nfig.add_subplot(131)\nplt.title('Kaggle Hat sales')\nplt.xlabel('Months')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat'], x='month', y='num_sold', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat'], x='month', y='num_sold', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat'], x='month', y='num_sold', label='Sweden')\n\nfig.add_subplot(132)\nplt.title('Kaggle Mug sales')\nplt.xlabel('Months')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug'], x='month', y='num_sold', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug'], x='month', y='num_sold', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug'], x='month', y='num_sold', label='Sweden')\n\nfig.add_subplot(133)\nplt.title('Kaggle Sticker sales')\nplt.xlabel('Months')\nsns.lineplot(data=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker'], x='month', y='num_sold', label='Finland')\nsns.lineplot(data=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker'], x='month', y='num_sold', label='Norway')\nsns.lineplot(data=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker'], x='month', y='num_sold', label='Sweden')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:51:55.411439Z","iopub.execute_input":"2022-01-31T20:51:55.411735Z","iopub.status.idle":"2022-01-31T20:51:59.252351Z","shell.execute_reply.started":"2022-01-31T20:51:55.4117Z","shell.execute_reply":"2022-01-31T20:51:59.251433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have seen so far that:\n\n1. Hat sales start increasing in October and start decreasing after the peak in April. We saw the same trend with snow depth.\n2. Mug sales start increasing in July as temperatures drop and start decreasing after the peak in December. We saw the same trend with precipitation.\n3. Sticker sales peak in December and April but are otherwise even throughout the year.\n\nThe first two points require more investigation.","metadata":{}},{"cell_type":"markdown","source":"# Identifying relationships\n\nIn this section, we will look at relationships of two variables - number of products sold and one of our weather features. Regression plots work well for this purpose. They are just like scatter plots in that they show the relationship between two variables, but also fit a regression line on the points. This shows the strength and nature of the relationship. Let's do for precipitation, snow depth and temperatures combined and we will summarize our findings in the end.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 16))\n\nfig.add_subplot(331)\nplt.title('Kaggle Hat sales in Finland')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['precipitation'])\n\nfig.add_subplot(332)\nplt.title('Kaggle Mug sales in Finland')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['precipitation'])\n\nfig.add_subplot(333)\nplt.title('Kaggle Sticker sales in Finland')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['precipitation'])\n\nfig.add_subplot(334)\nplt.title('Kaggle Hat sales in Norway')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['precipitation'])\n\nfig.add_subplot(335)\nplt.title('Kaggle Mug sales in Norway')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['precipitation'])\n\nfig.add_subplot(336)\nplt.title('Kaggle Sticker sales in Norway')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['precipitation'])\n\nfig.add_subplot(337)\nplt.title('Kaggle Hat sales in Sweden')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['precipitation'])\n\nfig.add_subplot(338)\nplt.title('Kaggle Mug sales in Sweden')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['precipitation'])\n\nfig.add_subplot(339)\nplt.title('Kaggle Sticker sales in Sweden')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['precipitation'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:51:59.253616Z","iopub.execute_input":"2022-01-31T20:51:59.253817Z","iopub.status.idle":"2022-01-31T20:52:02.872847Z","shell.execute_reply.started":"2022-01-31T20:51:59.253791Z","shell.execute_reply":"2022-01-31T20:52:02.871396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 16))\n\nfig.add_subplot(331)\nplt.title('Kaggle Hat sales in Finland')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['snow_depth'])\n\nfig.add_subplot(332)\nplt.title('Kaggle Mug sales in Finland')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['snow_depth'])\n\nfig.add_subplot(333)\nplt.title('Kaggle Sticker sales in Finland')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['snow_depth'])\n\nfig.add_subplot(334)\nplt.title('Kaggle Hat sales in Norway')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['snow_depth'])\n\nfig.add_subplot(335)\nplt.title('Kaggle Mug sales in Norway')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['snow_depth'])\n\nfig.add_subplot(336)\nplt.title('Kaggle Sticker sales in Norway')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['snow_depth'])\n\nfig.add_subplot(337)\nplt.title('Kaggle Hat sales in Sweden')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['snow_depth'])\n\nfig.add_subplot(338)\nplt.title('Kaggle Mug sales in Sweden')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['snow_depth'])\n\nfig.add_subplot(339)\nplt.title('Kaggle Sticker sales in Sweden')\nplt.xlabel('Months')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['snow_depth'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:52:02.876884Z","iopub.execute_input":"2022-01-31T20:52:02.877373Z","iopub.status.idle":"2022-01-31T20:52:06.441347Z","shell.execute_reply.started":"2022-01-31T20:52:02.877326Z","shell.execute_reply":"2022-01-31T20:52:06.44075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 16))\n\nfig.add_subplot(331)\nplt.title('Kaggle Hat sales in Finland')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat']['tmin'])\n\nfig.add_subplot(332)\nplt.title('Kaggle Mug sales in Finland')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug']['tmin'])\n\nfig.add_subplot(333)\nplt.title('Kaggle Sticker sales in Finland')\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker']['tmin'])\n\nfig.add_subplot(334)\nplt.title('Kaggle Hat sales in Norway')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat']['tmin'])\n\nfig.add_subplot(335)\nplt.title('Kaggle Mug sales in Norway')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug']['tmin'])\n\nfig.add_subplot(336)\nplt.title('Kaggle Sticker sales in Norway')\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker']['tmin'])\n\nfig.add_subplot(337)\nplt.title('Kaggle Hat sales in Sweden')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat']['tmin'])\n\nfig.add_subplot(338)\nplt.title('Kaggle Mug sales in Sweden')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug']['tmin'])\n\nfig.add_subplot(339)\nplt.title('Kaggle Sticker sales in Sweden')\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['tavg'])\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['tmax'])\nsns.regplot(x=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['num_sold'], y=df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker']['tmin'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:52:06.442784Z","iopub.execute_input":"2022-01-31T20:52:06.443006Z","iopub.status.idle":"2022-01-31T20:52:15.033094Z","shell.execute_reply.started":"2022-01-31T20:52:06.442978Z","shell.execute_reply":"2022-01-31T20:52:15.032364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last few plots are a bit too busy, but the regression lines make interpreting them easier.\n\n* Precipitation does not seem to have a meaningful effect on product sales in any of the countries.\n* All product sales increase with the accumulation of snow depth, though Stickers less so.\n* All product sales decrease with the increase of temperature.\n\nNext, let's look at the correlation matrices by country and product.","metadata":{}},{"cell_type":"code","source":"weather_features += ['num_sold']\ndf_train[weather_features].corr()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:52:15.034445Z","iopub.execute_input":"2022-01-31T20:52:15.035077Z","iopub.status.idle":"2022-01-31T20:52:15.055043Z","shell.execute_reply.started":"2022-01-31T20:52:15.03504Z","shell.execute_reply":"2022-01-31T20:52:15.054474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the last column, we can see that product sales are positively correlated with precipitation and snow depth, and inversely correlated with temperatures. Both correlations are weak. Let's plot these relationships on heatmaps.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 18))\n\nfig.add_subplot(331)\nplt.title('Finland - Kaggle Hat')\nsns.heatmap(df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Hat'][weather_features].corr())\n\nfig.add_subplot(332)\nplt.title('Finland - Kaggle Mug')\nsns.heatmap(df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Mug'][weather_features].corr())\n\nfig.add_subplot(333)\nplt.title('Finland - Kaggle Sticker')\nsns.heatmap(df_train[df_train['country'] == 'Finland'][df_train['product'] == 'Kaggle Sticker'][weather_features].corr())\n\nfig.add_subplot(334)\nplt.title('Norway - Kaggle Hat')\nsns.heatmap(df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Hat'][weather_features].corr())\n\nfig.add_subplot(335)\nplt.title('Norway - Kaggle Mug')\nsns.heatmap(df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Mug'][weather_features].corr())\n\nfig.add_subplot(336)\nplt.title('Norway - Kaggle Sticker')\nsns.heatmap(df_train[df_train['country'] == 'Norway'][df_train['product'] == 'Kaggle Sticker'][weather_features].corr())\n\nfig.add_subplot(337)\nplt.title('Sweden - Kaggle Hat')\nsns.heatmap(df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Hat'][weather_features].corr())\n\nfig.add_subplot(338)\nplt.title('Sweden - Kaggle Mug')\nsns.heatmap(df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Mug'][weather_features].corr())\n\nfig.add_subplot(339)\nplt.title('Sweden - Kaggle Sticker')\nsns.heatmap(df_train[df_train['country'] == 'Sweden'][df_train['product'] == 'Kaggle Sticker'][weather_features].corr())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:52:15.056001Z","iopub.execute_input":"2022-01-31T20:52:15.056638Z","iopub.status.idle":"2022-01-31T20:52:18.065891Z","shell.execute_reply.started":"2022-01-31T20:52:15.056603Z","shell.execute_reply":"2022-01-31T20:52:18.065123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The weak relationship (coral) between snow depth and sales is interesting, but could be just seasonality/coincidence.\nWe're indifferent to the strong relationship (navy) between snow depth and temperatures of course.","metadata":{}},{"cell_type":"markdown","source":"# Model comparisons\n\nArguably the ultimate test for the usefulness of features is seeing how a model performs with and without them. In this section, we will do a simple comparison training a model by itself and then with the weather features added. We will average our model predictions over 5 seeds to get more consistent results. We can standardize our weather features and encode our categoricals at this point. ","metadata":{}},{"cell_type":"code","source":"weather_features = ['precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin']\n\nscaler = StandardScaler()\ndf_train[weather_features] = scaler.fit_transform(df_train[weather_features])\ndf_test[weather_features] = scaler.transform(df_test[weather_features])\n\ncat_features = ['country', 'store', 'product']\n\nordinal_encoder = OrdinalEncoder()\ndf_train[cat_features] = ordinal_encoder.fit_transform(df_train[cat_features])\ndf_test[cat_features] = ordinal_encoder.fit_transform(df_test[cat_features])\n\ntss = TimeSeriesSplit(n_splits=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:52:18.06726Z","iopub.execute_input":"2022-01-31T20:52:18.067696Z","iopub.status.idle":"2022-01-31T20:52:18.13467Z","shell.execute_reply.started":"2022-01-31T20:52:18.067648Z","shell.execute_reply":"2022-01-31T20:52:18.133904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 1 - No weather features","metadata":{}},{"cell_type":"code","source":"# Excluding all weather features\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin')]\nseeds = 5 # set the number of seeds you want to average\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_baseline.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:52:18.136316Z","iopub.execute_input":"2022-01-31T20:52:18.136731Z","iopub.status.idle":"2022-01-31T20:53:05.876928Z","shell.execute_reply.started":"2022-01-31T20:52:18.136687Z","shell.execute_reply":"2022-01-31T20:53:05.875854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2 - Precipitation","metadata":{}},{"cell_type":"code","source":"# Excluding all weather features but precipitation\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'snow_depth', 'tavg', 'tmax', 'tmin')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_precipitation.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:53:05.878738Z","iopub.execute_input":"2022-01-31T20:53:05.879248Z","iopub.status.idle":"2022-01-31T20:53:55.210066Z","shell.execute_reply.started":"2022-01-31T20:53:05.879203Z","shell.execute_reply":"2022-01-31T20:53:55.208551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 3 - Snow depth","metadata":{}},{"cell_type":"code","source":"# Excluding all weather features but snow_depth\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'precipitation', 'tavg', 'tmax', 'tmin')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_snow.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:53:55.211417Z","iopub.execute_input":"2022-01-31T20:53:55.211681Z","iopub.status.idle":"2022-01-31T20:54:44.459354Z","shell.execute_reply.started":"2022-01-31T20:53:55.211648Z","shell.execute_reply":"2022-01-31T20:54:44.45858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 4 - Temperature average","metadata":{}},{"cell_type":"code","source":"# Excluding all weather features but tavg\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'precipitation', 'snow_depth', 'tmax', 'tmin')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_tavg.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:54:44.46143Z","iopub.execute_input":"2022-01-31T20:54:44.461699Z","iopub.status.idle":"2022-01-31T20:55:32.813217Z","shell.execute_reply.started":"2022-01-31T20:54:44.461671Z","shell.execute_reply":"2022-01-31T20:55:32.812624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 5 - Temperature maximum","metadata":{}},{"cell_type":"code","source":"# Excluding all weather features but tmax\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'precipitation', 'snow_depth', 'tavg', 'tmin')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_tmax.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:55:32.814396Z","iopub.execute_input":"2022-01-31T20:55:32.815089Z","iopub.status.idle":"2022-01-31T20:56:20.550843Z","shell.execute_reply.started":"2022-01-31T20:55:32.815057Z","shell.execute_reply":"2022-01-31T20:56:20.549288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 6 - Temperature minimum","metadata":{}},{"cell_type":"code","source":"# Excluding all weather features but tmin\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'precipitation', 'snow_depth', 'tavg', 'tmax')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_tmin.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:56:20.552594Z","iopub.execute_input":"2022-01-31T20:56:20.552854Z","iopub.status.idle":"2022-01-31T20:57:08.94841Z","shell.execute_reply.started":"2022-01-31T20:56:20.552827Z","shell.execute_reply":"2022-01-31T20:57:08.947676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 7 - All weather features","metadata":{}},{"cell_type":"code","source":"# Including all weather features\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_all_weather.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:57:08.949597Z","iopub.execute_input":"2022-01-31T20:57:08.949788Z","iopub.status.idle":"2022-01-31T20:58:06.255197Z","shell.execute_reply.started":"2022-01-31T20:57:08.949766Z","shell.execute_reply":"2022-01-31T20:58:06.254435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 8 - All but tmin","metadata":{}},{"cell_type":"code","source":"# Including all weather features but tmin\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date', 'tmin')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_select_weather.csv', index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-31T20:58:06.256438Z","iopub.execute_input":"2022-01-31T20:58:06.256714Z","iopub.status.idle":"2022-01-31T20:58:57.779626Z","shell.execute_reply.started":"2022-01-31T20:58:06.256667Z","shell.execute_reply":"2022-01-31T20:58:57.779031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering\n\nWe are going to create a few new features from what we have in the hopes of a score improvement. These are:\n* Diurnal air temperature variation - this is the difference of the maximum and minimum daily temperatures\n* Lag and forecast features of our 5 weather features - these are backward and forward looking features\n* Moving averages\n* Daily differences from the moving averages\n\nI want to thank @khbreslauer and @cv13j0 for their feature engineering ideas.","metadata":{}},{"cell_type":"code","source":"# Adding diurnal air temperature variation.\ndf_train['temp_var'] = df_train['tmax'] - df_train['tmin']\ndf_test['temp_var'] = df_test['tmax'] - df_test['tmin']\n\n# Adding lag and forecast features.\nfor day in range(1, 4):\n    for feature in weather_features:\n        df_train[f'{feature}_{day}_day_lag'] = df_train.groupby(['country', 'store', 'product'])[feature].shift(day)\n        df_test[f'{feature}_{day}_day_lag'] = df_test.groupby(['country', 'store', 'product'])[feature].shift(day)\n        df_train[f'{feature}_{day}_day_forecast'] = df_train.groupby(['country', 'store', 'product'])[feature].shift(-day)\n        df_test[f'{feature}_{day}_day_forecast'] = df_test.groupby(['country', 'store', 'product'])[feature].shift(-day)\n\n# Adding moving averages. This doesn't make much sense when doing for snow_depth, but let's see.\n\ndays = [3, 7, 15, 30]\nfor day in days:\n    for feature in weather_features:\n        df_train[f'{feature}_{day}_day_mov_avg'] = df_train.groupby([\n            'country',\n            'store',\n            'product'])[feature].transform(lambda x: x.shift(1).rolling(\n            window=day,\n            min_periods=0,\n            center=False,\n        ).mean())\n        df_test[f'{feature}_{day}_day_mov_avg'] = df_test.groupby([\n            'country',\n            'store',\n            'product'])[feature].transform(lambda x: x.shift(1).rolling(\n            window=day,\n            min_periods=0,\n            center=False,\n        ).mean())\n        \n# Adding differences from the moving averages to identify sudden dips and hikes.\ndf_train['precipitation_diff_3'] = df_train['precipitation'] - df_train['precipitation_3_day_mov_avg']\ndf_train['precipitation_diff_7'] = df_train['precipitation'] - df_train['precipitation_7_day_mov_avg']\ndf_train['snow_depth_diff_3'] = df_train['snow_depth'] - df_train['snow_depth_3_day_mov_avg']\ndf_train['snow_depth_diff_7'] = df_train['snow_depth'] - df_train['snow_depth_3_day_mov_avg']\ndf_train['tavg_diff_3'] = df_train['tavg'] - df_train['tavg_3_day_mov_avg']\ndf_train['tavg_diff_7'] = df_train['tavg'] - df_train['tavg_7_day_mov_avg']\ndf_train['tmax_diff_3'] = df_train['tmax'] - df_train['tmax_3_day_mov_avg']\ndf_train['tmax_diff_7'] = df_train['tmax'] - df_train['tmax_7_day_mov_avg']\ndf_train['tmin_diff_3'] = df_train['tmin'] - df_train['tmin_3_day_mov_avg']\ndf_train['tmin_diff_7'] = df_train['tmin'] - df_train['tmin_7_day_mov_avg']\n\ndf_test['precipitation_diff_3'] = df_test['precipitation'] - df_test['precipitation_3_day_mov_avg']\ndf_test['precipitation_diff_7'] = df_test['precipitation'] - df_test['precipitation_7_day_mov_avg']\ndf_test['snow_depth_diff_3'] = df_test['snow_depth'] - df_test['snow_depth_3_day_mov_avg']\ndf_test['snow_depth_diff_7'] = df_test['snow_depth'] - df_test['snow_depth_3_day_mov_avg']\ndf_test['tavg_diff_3'] = df_test['tavg'] - df_test['tavg_3_day_mov_avg']\ndf_test['tavg_diff_7'] = df_test['tavg'] - df_test['tavg_7_day_mov_avg']\ndf_test['tmax_diff_3'] = df_test['tmax'] - df_test['tmax_3_day_mov_avg']\ndf_test['tmax_diff_7'] = df_test['tmax'] - df_test['tmax_7_day_mov_avg']\ndf_test['tmin_diff_3'] = df_test['tmin'] - df_test['tmin_3_day_mov_avg']\ndf_test['tmin_diff_7'] = df_test['tmin'] - df_test['tmin_7_day_mov_avg']\n\n# Filling missing values is not important with Catboost. If you're using a different model, you may need to.\n\n# country_features = [c for c in df_test.columns if 'Finland' in c or 'Norway' in c or 'Sweden' in c]\n# df_test[country_features].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:58:57.780929Z","iopub.execute_input":"2022-01-31T20:58:57.781175Z","iopub.status.idle":"2022-01-31T20:58:58.397915Z","shell.execute_reply.started":"2022-01-31T20:58:57.781131Z","shell.execute_reply":"2022-01-31T20:58:58.397284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for feature in features:\n#     fig = plt.figure(figsize=(4, 3))\n#     sns.regplot(x=df_train['num_sold'], y=df_train[feature])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:58:58.398847Z","iopub.execute_input":"2022-01-31T20:58:58.39903Z","iopub.status.idle":"2022-01-31T20:58:58.402719Z","shell.execute_reply.started":"2022-01-31T20:58:58.399008Z","shell.execute_reply":"2022-01-31T20:58:58.402071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All our engineered features are as weakly correlated with the target as the base weather features. These deteriorate both our CV and LB scores significantly and are not worth keeping.","metadata":{}},{"cell_type":"markdown","source":"# Feature importances","metadata":{}},{"cell_type":"markdown","source":"### Model 9 - All weather features including engineered features","metadata":{}},{"cell_type":"code","source":"# Including all weather features\nfeatures = [c for c in df_test.columns if c not in ('row_id', 'date')]\nseeds = 5\n\nseed_valid_preds = []\nseed_scores = []\nseed_test_preds = []\n\nfor s in range(seeds):\n    seed_valid_ids = []\n    fold_valid_preds = {}\n    fold_scores = []\n    fold_test_preds = []\n\n    for fold, (i_train, i_test) in enumerate(tss.split(df_train)):\n        X_train = df_train.iloc[i_train]\n        y_train = df_train['num_sold'].iloc[i_train]\n\n        X_test = df_test.copy()\n\n        X_valid = df_train.iloc[i_test]\n        y_valid = df_train['num_sold'].iloc[i_test]\n\n        fold_valid_ids = X_valid.row_id.values.tolist()\n        seed_valid_ids += fold_valid_ids\n\n        X_train = X_train[features]\n        X_valid = X_valid[features]\n\n        model = CatBoostRegressor(iterations=5000,\n                                  loss_function='MAE',\n                                  eval_metric='SMAPE',\n                                  random_seed=s)\n        model.fit(X_train,\n                  y_train,\n                  early_stopping_rounds=200,\n                  eval_set=[(X_valid, y_valid)],\n                  verbose=0)\n\n        fold_valid_pred = model.predict(X_valid)\n        fold_valid_preds.update(dict(zip(fold_valid_ids, fold_valid_pred)))\n\n        fold_test_pred = model.predict(X_test)\n        fold_test_preds.append(fold_test_pred)\n\n        fold_score = np.mean(np.abs(fold_valid_pred - y_valid) / ((np.abs(y_valid) + np.abs(fold_valid_pred)) / 2)) * 100\n        fold_scores.append(fold_score)\n        print(f'Seed {s} fold {fold} SMAPE: {fold_score}')\n\n    print(f'Seed {s} SMAPE {np.mean(fold_scores)}, std {np.std(fold_scores)}')\n    \n    seed_valid_pred = np.array(list(fold_valid_preds.values()))\n    seed_valid_preds.append(seed_valid_pred)\n        \n    seed_score = np.mean(fold_scores)\n    seed_scores.append(seed_score)\n\n    seed_test_pred = np.mean(np.column_stack(fold_test_preds), axis=1)\n    seed_test_preds.append(seed_test_pred)\n    \nprint(f'SMAPE of {s+1} seeds: {np.mean(seed_scores)}, std {np.std(seed_scores)}')\n\n# Submission\nsample_submission.columns = ['row_id', 'num_sold']\nsample_submission.num_sold = np.round(np.mean(np.column_stack(seed_test_preds), axis=1))\nsample_submission.to_csv('submission_all_weather_fe.csv', index=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-01-31T20:58:58.403573Z","iopub.execute_input":"2022-01-31T20:58:58.403741Z","iopub.status.idle":"2022-01-31T21:03:18.174824Z","shell.execute_reply.started":"2022-01-31T20:58:58.40372Z","shell.execute_reply":"2022-01-31T21:03:18.174075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances = model.get_feature_importance(prettified=True)\nfeature_importances.head(50)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T21:03:18.176703Z","iopub.execute_input":"2022-01-31T21:03:18.177004Z","iopub.status.idle":"2022-01-31T21:03:18.198188Z","shell.execute_reply.started":"2022-01-31T21:03:18.176962Z","shell.execute_reply":"2022-01-31T21:03:18.197532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(df_train)\nshap.summary_plot(shap_values, df_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T21:03:18.199062Z","iopub.execute_input":"2022-01-31T21:03:18.199227Z","iopub.status.idle":"2022-01-31T21:03:29.188163Z","shell.execute_reply.started":"2022-01-31T21:03:18.199205Z","shell.execute_reply":"2022-01-31T21:03:29.187246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our weather features are not deemed important by either method and are scored consistently low by Shap.","metadata":{}},{"cell_type":"markdown","source":"# Final results\n\n","metadata":{}},{"cell_type":"markdown","source":"| Features | SMAPE | Public LB |\n| --- | --- | --- |\n| No weather features | 7.4664912617172380 | 6.00421 |\n| precipitation | 7.5020382959417430 | n/a |\n| snow_depth | 7.4622390996710210 | 6.11984 |\n| tavg | 7.5011167684512190 | n/a |\n| tmax | 7.4754759828989590 | 6.11840 |\n| tmin | 7.5467655794719875 | n/a |\n| All weather features | 7.4596059127535440 | 6.25309 |\n| All but tmin (best) | 7.4480535771435420 | 6.21853 |\n\nUnfortunately, the features just make our predictions worse.\n\nThank you for reading this notebook. Please share with me if you find a use for this dataset!","metadata":{}}]}