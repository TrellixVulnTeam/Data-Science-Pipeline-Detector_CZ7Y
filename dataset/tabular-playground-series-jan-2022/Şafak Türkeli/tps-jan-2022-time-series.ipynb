{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS - Jan 2022 - Time Series\n\nIn this notebook, I will try to implement what I have learned from the [time series course](https://www.kaggle.com/learn/time-series).","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries and Loading datasets","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport dateutil.easter as easter\n\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_periodogram, make_lags, make_multistep_target, plot_multistep\n\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.multioutput import RegressorChain","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T23:33:25.589423Z","iopub.execute_input":"2022-01-20T23:33:25.589877Z","iopub.status.idle":"2022-01-20T23:33:25.600679Z","shell.execute_reply.started":"2022-01-20T23:33:25.589827Z","shell.execute_reply":"2022-01-20T23:33:25.599681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\n    '../input/tabular-playground-series-jan-2022/train.csv',\n    usecols=['country', 'store', 'product', 'date', 'num_sold'],\n    dtype={\n        'country': 'category',\n        'store': 'category',\n        'product': 'category',\n        'num_sold': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\ntest_df = pd.read_csv(\n    '../input/tabular-playground-series-jan-2022/test.csv',\n    usecols=['country', 'store', 'product', 'date'],\n    dtype={\n        'country': 'category',\n        'store': 'category',\n        'product': 'category',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\naverage_sales = (\n    train_df\n    .groupby('date').mean()\n    .squeeze()\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:26.206047Z","iopub.execute_input":"2022-01-20T22:44:26.206309Z","iopub.status.idle":"2022-01-20T22:44:26.318197Z","shell.execute_reply.started":"2022-01-20T22:44:26.206277Z","shell.execute_reply":"2022-01-20T22:44:26.317233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore Data","metadata":{}},{"cell_type":"code","source":"train_df.head(6)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.319606Z","iopub.execute_input":"2022-01-20T22:44:26.319822Z","iopub.status.idle":"2022-01-20T22:44:26.339174Z","shell.execute_reply.started":"2022-01-20T22:44:26.319797Z","shell.execute_reply":"2022-01-20T22:44:26.338355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Columns: {0}\".format(list(train_df.columns)))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.341124Z","iopub.execute_input":"2022-01-20T22:44:26.34141Z","iopub.status.idle":"2022-01-20T22:44:26.346125Z","shell.execute_reply.started":"2022-01-20T22:44:26.341381Z","shell.execute_reply":"2022-01-20T22:44:26.345542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countries = train_df['country'].unique()\nprint(\"Countries: {0}\".format(countries))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.347121Z","iopub.execute_input":"2022-01-20T22:44:26.347729Z","iopub.status.idle":"2022-01-20T22:44:26.360404Z","shell.execute_reply.started":"2022-01-20T22:44:26.347699Z","shell.execute_reply":"2022-01-20T22:44:26.359818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stores = train_df['store'].unique()\nprint(\"Stores: {0}\".format(stores))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.361605Z","iopub.execute_input":"2022-01-20T22:44:26.362169Z","iopub.status.idle":"2022-01-20T22:44:26.372288Z","shell.execute_reply.started":"2022-01-20T22:44:26.362139Z","shell.execute_reply":"2022-01-20T22:44:26.371707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"products = train_df['product'].unique()\nprint(\"Products: {0}\".format(products))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.373441Z","iopub.execute_input":"2022-01-20T22:44:26.373714Z","iopub.status.idle":"2022-01-20T22:44:26.385493Z","shell.execute_reply.started":"2022-01-20T22:44:26.373676Z","shell.execute_reply":"2022-01-20T22:44:26.384541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_date = train_df.date.min()\nend_date = train_df.date.max()\nprint(\"Start and end date of the data: ({0}, {1})\".format(start_date, end_date))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.387099Z","iopub.execute_input":"2022-01-20T22:44:26.387558Z","iopub.status.idle":"2022-01-20T22:44:26.3991Z","shell.execute_reply.started":"2022-01-20T22:44:26.387492Z","shell.execute_reply":"2022-01-20T22:44:26.398212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic Data Check","metadata":{}},{"cell_type":"code","source":"print('Train data shape:', train_df.shape)\nprint('Test data shape:', test_df.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.400366Z","iopub.execute_input":"2022-01-20T22:44:26.400622Z","iopub.status.idle":"2022-01-20T22:44:26.410836Z","shell.execute_reply.started":"2022-01-20T22:44:26.40059Z","shell.execute_reply":"2022-01-20T22:44:26.410091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_train = train_df.isna().any().sum()\nprint('Missing values in train data: {0}'.format(missing_values_train[missing_values_train > 0]))\n\nmissing_values_test = test_df.isna().any().sum()\nprint('Missing values in test data: {0}'.format(missing_values_test[missing_values_test > 0]))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.414288Z","iopub.execute_input":"2022-01-20T22:44:26.414668Z","iopub.status.idle":"2022-01-20T22:44:26.429064Z","shell.execute_reply.started":"2022-01-20T22:44:26.414633Z","shell.execute_reply":"2022-01-20T22:44:26.428343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicates_train = train_df.duplicated().sum()\nprint('Duplicates in train data: {0}'.format(duplicates_train))\n\nduplicates_test = test_df.duplicated().sum()\nprint('Duplicates in test data: {0}'.format(duplicates_test))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.430584Z","iopub.execute_input":"2022-01-20T22:44:26.43103Z","iopub.status.idle":"2022-01-20T22:44:26.449896Z","shell.execute_reply.started":"2022-01-20T22:44:26.430988Z","shell.execute_reply":"2022-01-20T22:44:26.448791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions\n\n## Split data\n\nIn the time series course the first course is creating a Time-step feature and a Lag feature. The data it is using only contains the dates and the target. Hence, I will try to create the same features, but I need to split the data to the same format. I am not sure doing that will cause information to be lost since I will apply a regression algorithm for each piece separately.","metadata":{}},{"cell_type":"code","source":"def split_data(data):\n    splitted_data = []\n    for country in countries:\n        for store in stores:\n            for product in products:\n                splitted_data.append(data.loc[(data['country'] == country) & (data['store'] == store) & (data['product'] == product)])\n    return splitted_data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.451782Z","iopub.execute_input":"2022-01-20T22:44:26.452233Z","iopub.status.idle":"2022-01-20T22:44:26.457598Z","shell.execute_reply.started":"2022-01-20T22:44:26.452199Z","shell.execute_reply":"2022-01-20T22:44:26.45681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitted_train = split_data(train_df)\nsplitted_test = split_data(test_df)\nsplitted_train[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:26.458929Z","iopub.execute_input":"2022-01-20T22:44:26.45961Z","iopub.status.idle":"2022-01-20T22:44:26.529678Z","shell.execute_reply.started":"2022-01-20T22:44:26.459575Z","shell.execute_reply":"2022-01-20T22:44:26.528358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge predictions\n\nFunction to merge predictions and sort the indices again, so that they can be used to create a submission after running the model.","metadata":{}},{"cell_type":"code","source":"def merge_predictions(test_predictions):\n    predictions = pd.concat(test_predictions)\n    predictions.sort_index(inplace=True)\n    return predictions","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.531788Z","iopub.execute_input":"2022-01-20T22:44:26.532318Z","iopub.status.idle":"2022-01-20T22:44:26.538061Z","shell.execute_reply.started":"2022-01-20T22:44:26.532271Z","shell.execute_reply":"2022-01-20T22:44:26.537243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission\n\nVery simple helper function to create a submission.","metadata":{}},{"cell_type":"code","source":"def create_submission(submission, predictions):\n    output = pd.DataFrame({'row_id': test_df.index + len(train_df), 'num_sold': predictions})\n    output.to_csv(submission, index=False)\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:26.539169Z","iopub.execute_input":"2022-01-20T22:44:26.540199Z","iopub.status.idle":"2022-01-20T22:44:26.553943Z","shell.execute_reply.started":"2022-01-20T22:44:26.540158Z","shell.execute_reply":"2022-01-20T22:44:26.552781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features and Modelling\n\n","metadata":{}},{"cell_type":"markdown","source":"# [Time-step feature](https://www.kaggle.com/ryanholbrook/linear-regression-with-time-series)\n\nLet's apply I have learned from the first lesson, the time-step feature.  \n\nStart with the linear regression on number of sales.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\n\n# Format the date columns so that it can be used with regplot\ndf = splitted_train[0].reset_index()\ndf = df.sort_values('date')\ndf['date_f'] = pd.factorize(df['date'])[0]\nmapping = dict(zip(df['date_f'], df['date'].dt.date))\n\n# Plot\nax.plot('date_f', 'num_sold', data=df, color='0.75')\nax = sns.regplot(x='date_f', y='num_sold', data=df, scatter_kws=dict(color='0.25'), line_kws=dict(linewidth=5))\n\n# Set ticks, labels and titles\nticks = np.array([df['date_f'][date] for date in range(0, len(df), 365)])\nax.set_xticks(ticks)\nlabels = pd.Series(ax.get_xticks()).map(mapping).fillna('')\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:26.555543Z","iopub.execute_input":"2022-01-20T22:44:26.555873Z","iopub.status.idle":"2022-01-20T22:44:27.122656Z","shell.execute_reply.started":"2022-01-20T22:44:26.555827Z","shell.execute_reply":"2022-01-20T22:44:27.121681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create the time dummy and get the predictions.","metadata":{}},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train)):\n    train = splitted_train[i].copy()\n    test = splitted_test[i].copy()\n\n    # Create a time dummy\n    train['time'] = np.arange(len(train.index))\n    test['time'] = np.arange(len(test.index)) + len(train)\n\n    # Create training data\n    X = train.loc[:, ['time']]        # features\n    y = train.loc[:, 'num_sold']      # target\n    test_X = test.loc[:, ['time']]    # features\n\n    # Train the model\n    model = LinearRegression()\n    model.fit(X, y)\n    \n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X), index=X.index))\n    test_predictions.append(pd.Series(model.predict(test_X), index=test_X.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:27.124402Z","iopub.execute_input":"2022-01-20T22:44:27.124888Z","iopub.status.idle":"2022-01-20T22:44:27.246189Z","shell.execute_reply.started":"2022-01-20T22:44:27.124843Z","shell.execute_reply":"2022-01-20T22:44:27.245255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"# Plot\nax = splitted_train[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = train_predictions[0].plot(ax=ax, linewidth=5)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:27.2476Z","iopub.execute_input":"2022-01-20T22:44:27.248076Z","iopub.status.idle":"2022-01-20T22:44:27.591095Z","shell.execute_reply.started":"2022-01-20T22:44:27.248044Z","shell.execute_reply":"2022-01-20T22:44:27.590183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge predictions\npredictions = merge_predictions(test_predictions)\n# Create submission\noutput = create_submission('submission_time-step.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:27.592663Z","iopub.execute_input":"2022-01-20T22:44:27.592943Z","iopub.status.idle":"2022-01-20T22:44:27.635475Z","shell.execute_reply.started":"2022-01-20T22:44:27.592915Z","shell.execute_reply":"2022-01-20T22:44:27.634445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Trend feature](https://www.kaggle.com/ryanholbrook/trend)\n\nFrom the second lesson create the trend feature.  \n\nMake a moving average plot to estimate and identify the trend.","metadata":{}},{"cell_type":"code","source":"trend = average_sales.rolling(\n    window=240,\n    center=True,\n    min_periods=120,\n).mean()\n\nax = average_sales.plot(**plot_params, alpha=0.5)\nax = trend.plot(ax=ax, linewidth=5)\n\n# Set titles\nax.set_title('Average sales')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:27.636699Z","iopub.execute_input":"2022-01-20T22:44:27.636938Z","iopub.status.idle":"2022-01-20T22:44:27.98318Z","shell.execute_reply.started":"2022-01-20T22:44:27.63691Z","shell.execute_reply":"2022-01-20T22:44:27.982272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create the feature and get the predictions.","metadata":{}},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train)):\n    train = splitted_train[i].copy()\n    test = splitted_test[i].copy()\n    \n    # Target\n    y = train.loc[:, 'num_sold']\n    \n    # Instantiate `DeterministicProcess` with arguments appropriate trend model\n    dp = DeterministicProcess(index=y.index, order=3)\n    \n    # Create features\n    X = dp.in_sample()\n    test_X = dp.out_of_sample(steps=len(test), forecast_index=test.index)\n    \n    # Train the model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X), index=X.index))\n    test_predictions.append(pd.Series(model.predict(test_X), index=test_X.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:27.984948Z","iopub.execute_input":"2022-01-20T22:44:27.985187Z","iopub.status.idle":"2022-01-20T22:44:28.302556Z","shell.execute_reply.started":"2022-01-20T22:44:27.985158Z","shell.execute_reply":"2022-01-20T22:44:28.301368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"ax = splitted_train[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = train_predictions[0].plot(ax=ax, linewidth=5)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:28.304288Z","iopub.execute_input":"2022-01-20T22:44:28.304838Z","iopub.status.idle":"2022-01-20T22:44:28.635868Z","shell.execute_reply.started":"2022-01-20T22:44:28.3048Z","shell.execute_reply":"2022-01-20T22:44:28.63443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge predictions\npredictions = merge_predictions(test_predictions)\n# Create submission\noutput = create_submission('submission_trend.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:28.637164Z","iopub.execute_input":"2022-01-20T22:44:28.637423Z","iopub.status.idle":"2022-01-20T22:44:28.683763Z","shell.execute_reply.started":"2022-01-20T22:44:28.637392Z","shell.execute_reply":"2022-01-20T22:44:28.682799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Seasonality](https://www.kaggle.com/ryanholbrook/seasonality)\n\nNow try to discover the trend and the seasonal patterns according to the third lesson.  \n\nLet's examine the periodogram.","metadata":{}},{"cell_type":"code","source":"plot_periodogram(average_sales);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:28.685293Z","iopub.execute_input":"2022-01-20T22:44:28.685666Z","iopub.status.idle":"2022-01-20T22:44:29.269526Z","shell.execute_reply.started":"2022-01-20T22:44:28.685609Z","shell.execute_reply":"2022-01-20T22:44:29.268591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Periodogram suggest a strong annual and weekly seasonality.\n\nUse DeterministicProcess and CalendarFourier to create:\n  * indicators for weekly seasons and\n  * Fourier features of order 4 for yearly seasons.","metadata":{}},{"cell_type":"code","source":"y = average_sales.copy()\nfourier = CalendarFourier(freq='Y', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\nX = dp.in_sample()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:29.270897Z","iopub.execute_input":"2022-01-20T22:44:29.271144Z","iopub.status.idle":"2022-01-20T22:44:29.298879Z","shell.execute_reply.started":"2022-01-20T22:44:29.271113Z","shell.execute_reply":"2022-01-20T22:44:29.297774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's fit and check the seasonal model.","metadata":{}},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X, y)\ny_pred = pd.Series(model.predict(X), index=X.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"sales\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:29.300655Z","iopub.execute_input":"2022-01-20T22:44:29.301273Z","iopub.status.idle":"2022-01-20T22:44:29.732051Z","shell.execute_reply.started":"2022-01-20T22:44:29.301217Z","shell.execute_reply":"2022-01-20T22:44:29.731451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the periodogram of the deseasonalized series.","metadata":{}},{"cell_type":"code","source":"y_deseason = y - y_pred\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodogram(y, ax=ax1)\nax1.set_title(\"Sales Frequency Components\")\nax2 = plot_periodogram(y_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:29.733202Z","iopub.execute_input":"2022-01-20T22:44:29.733819Z","iopub.status.idle":"2022-01-20T22:44:30.682278Z","shell.execute_reply.started":"2022-01-20T22:44:29.733784Z","shell.execute_reply":"2022-01-20T22:44:30.681255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create the features and get the predictions.","metadata":{}},{"cell_type":"code","source":"splitted_train_df = split_data(train_df)\nsplitted_test_df = split_data(test_df)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:30.68804Z","iopub.execute_input":"2022-01-20T22:44:30.688296Z","iopub.status.idle":"2022-01-20T22:44:30.734981Z","shell.execute_reply.started":"2022-01-20T22:44:30.688266Z","shell.execute_reply":"2022-01-20T22:44:30.733957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train_df)):\n    df_train = splitted_train_df[i].copy()\n    df_train = df_train.set_index('date')\n    \n    df_test = splitted_test_df[i].copy()\n    df_test = df_test.set_index('date')\n    \n    # Target\n    y = df_train.loc[:, 'num_sold']\n\n    # Use DeterministicProcess and CalendarFourier to create:\n    # indicators for weekly seasons and\n    # Fourier features of order 4 for yearly seasons.\n    fourier = CalendarFourier(freq='Y', order=4)\n    dp = DeterministicProcess(\n        index=y.index,\n        constant=True,\n        order=1,\n        seasonal=True,\n        additional_terms=[fourier],\n        drop=True,\n    )\n    # Create the feature set for the dates given in y.index\n    X = dp.in_sample()\n    \n    # Create features for forecast.\n    test_X = dp.out_of_sample(steps=len(df_test), forecast_index=df_test.index)\n    \n    # Train the model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X), index=X.index))\n    test_predictions.append(pd.Series(model.predict(test_X), index=test_X.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:30.736489Z","iopub.execute_input":"2022-01-20T22:44:30.736839Z","iopub.status.idle":"2022-01-20T22:44:31.346577Z","shell.execute_reply.started":"2022-01-20T22:44:30.736797Z","shell.execute_reply":"2022-01-20T22:44:31.345446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"ax = splitted_train_df[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = pd.Series(data=train_predictions[0].values, index=splitted_train_df[0].index).plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:31.348307Z","iopub.execute_input":"2022-01-20T22:44:31.34934Z","iopub.status.idle":"2022-01-20T22:44:31.63253Z","shell.execute_reply.started":"2022-01-20T22:44:31.349285Z","shell.execute_reply":"2022-01-20T22:44:31.63167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.zeros(len(test_predictions) * len(test_predictions[0]))\nfor i in range(len(test_predictions)):\n    for j in range(len(test_predictions[i])):\n        predictions[len(test_predictions) * j + i] = test_predictions[i][j]\noutput = create_submission('submission_seasonality.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:31.633943Z","iopub.execute_input":"2022-01-20T22:44:31.634962Z","iopub.status.idle":"2022-01-20T22:44:31.703531Z","shell.execute_reply.started":"2022-01-20T22:44:31.634914Z","shell.execute_reply":"2022-01-20T22:44:31.702431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create features for holidays\n\nIn the exercise of the third lesson, there is also a part about creating the holiday features.  \n\nSo, I have used [this notebook's](https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model) feature engineering about holidays to reach the same goal. Credits to https://www.kaggle.com/ambrosm.","metadata":{}},{"cell_type":"code","source":"# Credits to https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model, https://www.kaggle.com/ambrosm\n# Feature engineering for holidays\ndef engineer_holidays(df):\n    # May\n    df = pd.concat([df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}) * 1, #  + list(range(17, 25))\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(19, 26))}) * 1],\n                       axis=1)\n    \n    # June and July\n    df = pd.concat([df,\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))}) * 1,\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(22, 31))}) * 1,\n                        pd.DataFrame({f\"july{d}\":\n                                      (df.date.dt.month == 7) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(1, 3))}) * 1],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    df = pd.concat([df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))}) * 1],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    df = pd.concat([df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))}) * 1],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    df = pd.concat([df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))}) * 1],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    df = pd.concat([df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))}) * 1],\n                       axis=1)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:31.70492Z","iopub.execute_input":"2022-01-20T22:44:31.705177Z","iopub.status.idle":"2022-01-20T22:44:31.730317Z","shell.execute_reply.started":"2022-01-20T22:44:31.705146Z","shell.execute_reply":"2022-01-20T22:44:31.729367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create the features and get the predictions.","metadata":{}},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train_df)):\n    df_train = splitted_train_df[i].copy()\n    df_train = df_train.set_index('date')\n    \n    df_test = splitted_test_df[i].copy()\n    df_test = df_test.set_index('date')\n    \n    # Target\n    y = df_train.loc[:, 'num_sold']\n\n    # Use DeterministicProcess and CalendarFourier to create:\n    # indicators for weekly seasons and\n    # Fourier features of order 4 for yearly seasons.\n    fourier = CalendarFourier(freq='Y', order=4)\n    dp = DeterministicProcess(\n        index=y.index,\n        constant=True,\n        order=1,\n        seasonal=True,\n        additional_terms=[fourier],\n        drop=True,\n    )\n    # Create the feature set for the dates given in y.index\n    X = dp.in_sample()\n    X['date'], X['country'] = X.index, df_train['country']\n    X = engineer_holidays(X)\n    X.drop(['date', 'country'], axis=1, inplace=True)\n    \n    # Create features for forecast.\n    test_X = dp.out_of_sample(steps=len(df_test), forecast_index=df_test.index)\n    test_X['date'], test_X['country'] = test_X.index, df_test['country']\n    test_X = engineer_holidays(test_X)\n    test_X.drop(['date', 'country'], axis=1, inplace=True)\n    \n    # Train the model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X), index=X.index))\n    test_predictions.append(pd.Series(model.predict(test_X), index=test_X.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:31.732006Z","iopub.execute_input":"2022-01-20T22:44:31.73225Z","iopub.status.idle":"2022-01-20T22:44:37.043319Z","shell.execute_reply.started":"2022-01-20T22:44:31.732223Z","shell.execute_reply":"2022-01-20T22:44:37.042213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"ax = splitted_train_df[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = pd.Series(data=train_predictions[0].values, index=splitted_train_df[0].index).plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:37.044897Z","iopub.execute_input":"2022-01-20T22:44:37.048389Z","iopub.status.idle":"2022-01-20T22:44:37.327253Z","shell.execute_reply.started":"2022-01-20T22:44:37.048347Z","shell.execute_reply":"2022-01-20T22:44:37.326259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.zeros(len(test_predictions) * len(test_predictions[0]))\nfor i in range(len(test_predictions)):\n    for j in range(len(test_predictions[i])):\n        predictions[len(test_predictions) * j + i] = test_predictions[i][j]\noutput = create_submission('submission_seasonality_holidays.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:37.328924Z","iopub.execute_input":"2022-01-20T22:44:37.329281Z","iopub.status.idle":"2022-01-20T22:44:37.40037Z","shell.execute_reply.started":"2022-01-20T22:44:37.329234Z","shell.execute_reply":"2022-01-20T22:44:37.399431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Time Series as Features](https://www.kaggle.com/ryanholbrook/time-series-as-features)\n\nAccording to our fourth lesson trend and seasonality will both create serial dependence that shows up in correlograms and lag plots.  \nTo isolate any purely cyclic behavior, we'll start by deseasonalizing the series.","metadata":{}},{"cell_type":"code","source":"df_train = splitted_train_df[0]\ndf_train = df_train.set_index('date')\ny = df_train.loc[:, 'num_sold']\n\nfourier = CalendarFourier(freq='Y', order=4)\ndp = DeterministicProcess(\n    constant=True,\n    index=y.index,\n    order=1,\n    seasonal=True,\n    drop=True,\n    additional_terms=[fourier],\n)\nX_time = dp.in_sample()\n\nmodel = LinearRegression(fit_intercept=False).fit(X_time, y)\ndeseason = y - model.predict(X_time)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:37.401783Z","iopub.execute_input":"2022-01-20T22:44:37.401999Z","iopub.status.idle":"2022-01-20T22:44:37.432067Z","shell.execute_reply.started":"2022-01-20T22:44:37.401972Z","shell.execute_reply":"2022-01-20T22:44:37.430878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = deseason.plot()\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug (deseasonalized)')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:37.433838Z","iopub.execute_input":"2022-01-20T22:44:37.434891Z","iopub.status.idle":"2022-01-20T22:44:37.746188Z","shell.execute_reply.started":"2022-01-20T22:44:37.434836Z","shell.execute_reply":"2022-01-20T22:44:37.745574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create time series features and get the predictions.","metadata":{}},{"cell_type":"code","source":"# Create lag features\nX_lags = make_lags(deseason, lags=1)\n\nX = X_lags.dropna()\ny, X = y.align(X, join='inner')\n\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.Series(model.predict(X), index=X.index)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:37.747208Z","iopub.execute_input":"2022-01-20T22:44:37.747621Z","iopub.status.idle":"2022-01-20T22:44:37.765111Z","shell.execute_reply.started":"2022-01-20T22:44:37.747588Z","shell.execute_reply":"2022-01-20T22:44:37.763876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y.plot(**plot_params, alpha=0.5)\nax = y_pred.plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(labels.to_list())\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:37.766403Z","iopub.execute_input":"2022-01-20T22:44:37.766878Z","iopub.status.idle":"2022-01-20T22:44:38.119942Z","shell.execute_reply.started":"2022-01-20T22:44:37.766847Z","shell.execute_reply":"2022-01-20T22:44:38.118875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create and add statistical features and get the predictions.","metadata":{}},{"cell_type":"code","source":"y_lag = df_train.loc[:, 'num_sold'].shift(1)\n\n# 28-day mean of lagged target\nX['mean_7'] = y_lag.rolling(7).mean()\n# 14-day median of lagged target\nX['median_14'] = y_lag.rolling(14).median()\n# 7-day rolling standard deviation of lagged target\nX['std_7'] = y_lag.rolling(7).std()\n\nX = X.dropna()\ny, X = y.align(X, join='inner')\n\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.Series(model.predict(X), index=X.index)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:38.121675Z","iopub.execute_input":"2022-01-20T22:44:38.122009Z","iopub.status.idle":"2022-01-20T22:44:38.146141Z","shell.execute_reply.started":"2022-01-20T22:44:38.121965Z","shell.execute_reply":"2022-01-20T22:44:38.145351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y.plot(**plot_params, alpha=0.5)\nax = y_pred.plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(labels.to_list())\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:38.147254Z","iopub.execute_input":"2022-01-20T22:44:38.147757Z","iopub.status.idle":"2022-01-20T22:44:38.769795Z","shell.execute_reply.started":"2022-01-20T22:44:38.147714Z","shell.execute_reply":"2022-01-20T22:44:38.769184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create the features and get the predictions.","metadata":{}},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train_df)):\n    df_train = splitted_train_df[i].copy()\n    df_train = df_train.set_index('date')\n\n    df_test = splitted_test_df[i].copy()\n    df_test = df_test.set_index('date')\n\n    # Target\n    y = df_train.loc[:, 'num_sold']\n\n    # Start by deseasonalizing the series \n    fourier = CalendarFourier(freq='Y', order=4)\n    dp = DeterministicProcess(\n        constant=True,\n        index=y.index,\n        order=1,\n        seasonal=True,\n        drop=True,\n        additional_terms=[fourier],\n    )\n    X_time = dp.in_sample()\n    test_X_time = dp.out_of_sample(steps=len(df_test), forecast_index=df_test.index)\n\n    model = LinearRegression(fit_intercept=False).fit(X_time, y)\n    deseason = y - model.predict(X_time)\n    test_X_y = pd.Series(model.predict(test_X_time), index=df_test.index)\n    \n    # Make features from `deseason`\n    X = make_lags(deseason, lags=1)\n    X.fillna(X.mean(), inplace=True)\n    \n    test_X = make_lags(test_X_y, lags=1)\n    test_X.fillna(test_X_y.mean(), inplace=True)\n\n    # Create lagged targets\n    y_lag = df_train.loc[:, 'num_sold'].shift(1)\n    test_X_y_lag = test_X_y.shift(1)\n\n    # 28-day mean of lagged target\n    X['mean_7'] = y_lag.rolling(7).mean()\n    X.fillna(y_lag.mean(), inplace=True)\n    \n    test_X['mean_7'] = test_X_y_lag.rolling(7).mean()\n    test_X.fillna(test_X_y_lag.mean(), inplace=True)\n    \n    # 14-day median of lagged target\n    X['median_14'] = y_lag.rolling(14).median()\n    X.fillna(y_lag.median(), inplace=True)\n    \n    test_X['median_14'] = test_X_y_lag.rolling(14).median()\n    test_X.fillna(test_X_y_lag.median(), inplace=True)\n    \n    # 7-day rolling standard deviation of lagged target\n    X['std_7'] = y_lag.rolling(7).std()\n    X.fillna(y_lag.std(), inplace=True)\n    \n    test_X['std_7'] = test_X_y_lag.rolling(7).std()\n    test_X.fillna(test_X_y_lag.std(), inplace=True)\n    \n    # Train the model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X), index=X.index))\n    test_predictions.append(pd.Series(model.predict(test_X), index=test_X.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:38.770941Z","iopub.execute_input":"2022-01-20T22:44:38.771263Z","iopub.status.idle":"2022-01-20T22:44:39.972221Z","shell.execute_reply.started":"2022-01-20T22:44:38.771234Z","shell.execute_reply":"2022-01-20T22:44:39.970982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"ax = splitted_train_df[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = pd.Series(data=train_predictions[0].values, index=splitted_train_df[0].index).plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:39.974075Z","iopub.execute_input":"2022-01-20T22:44:39.974679Z","iopub.status.idle":"2022-01-20T22:44:40.353401Z","shell.execute_reply.started":"2022-01-20T22:44:39.974629Z","shell.execute_reply":"2022-01-20T22:44:40.352407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.zeros(len(test_predictions) * len(test_predictions[0]))\nfor i in range(len(test_predictions)):\n    for j in range(len(test_predictions[i])):\n        predictions[len(test_predictions) * j + i] = test_predictions[i][j]\noutput = create_submission('submission_time-series.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:44:40.354773Z","iopub.execute_input":"2022-01-20T22:44:40.355024Z","iopub.status.idle":"2022-01-20T22:44:40.439987Z","shell.execute_reply.started":"2022-01-20T22:44:40.354994Z","shell.execute_reply":"2022-01-20T22:44:40.439038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Future engineering from another notebook\n\nCredits to https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model, https://www.kaggle.com/ambrosm","metadata":{}},{"cell_type":"code","source":"gdp_df = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\ngdp_df.set_index('year', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:40.441337Z","iopub.execute_input":"2022-01-20T22:44:40.441619Z","iopub.status.idle":"2022-01-20T22:44:40.462386Z","shell.execute_reply.started":"2022-01-20T22:44:40.44159Z","shell.execute_reply":"2022-01-20T22:44:40.461468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Future Engineering for the end of the year\ndef engineer_end_of_year(df):\n    df = pd.concat([df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}) * 1,\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(24, 32)}) * 1,\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 14)}) * 1,\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}) * 1,\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)}) * 1],\n                       axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:40.466192Z","iopub.execute_input":"2022-01-20T22:44:40.466721Z","iopub.status.idle":"2022-01-20T22:44:40.478853Z","shell.execute_reply.started":"2022-01-20T22:44:40.466672Z","shell.execute_reply":"2022-01-20T22:44:40.477949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\ndef engineer(df):\n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n\n    df = pd.concat([df,\n                    pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'wd4': (df.date.dt.weekday == 4) * 1, # Friday\n                           'wd56': (df.date.dt.weekday >= 5) * 1, # Saturday and Sunday\n                          })],\n                       axis=1)\n\n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n\n    # Apply other engineering methods and drop the unwanted columns\n    df = engineer_end_of_year(df)\n    df = engineer_holidays(df)\n    df = df.drop(['date', 'country', 'store', 'product'], axis=1)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:44:40.480561Z","iopub.execute_input":"2022-01-20T22:44:40.481092Z","iopub.status.idle":"2022-01-20T22:44:40.50062Z","shell.execute_reply.started":"2022-01-20T22:44:40.481059Z","shell.execute_reply":"2022-01-20T22:44:40.499422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create the features and get the predictions.","metadata":{}},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train_df)):\n    df_train = splitted_train_df[i].copy()\n    df_test = splitted_test_df[i].copy()\n    \n    # Target\n    y = df_train.loc[:, 'num_sold']\n    df_train = df_train.drop('num_sold', axis=1)\n\n    # Create the feature set for the dates given in y.index\n    X = df_train.copy()\n    X = engineer(X)\n    \n    # Create features for forecast.\n    test_X = df_test.copy()\n    test_X = engineer(test_X)\n    \n    # Train the model - Instead of linear regression,\n    # I have used CatBoostRegressor now.\n    model = CatBoostRegressor(silent=True)\n    model.fit(X, y)\n\n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X), index=X.index))\n    test_predictions.append(pd.Series(model.predict(test_X), index=test_X.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T23:01:17.868449Z","iopub.execute_input":"2022-01-20T23:01:17.868861Z","iopub.status.idle":"2022-01-20T23:01:22.002921Z","shell.execute_reply.started":"2022-01-20T23:01:17.86879Z","shell.execute_reply":"2022-01-20T23:01:22.002013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"ax = splitted_train[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = train_predictions[0].plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:45:11.05805Z","iopub.execute_input":"2022-01-20T22:45:11.058303Z","iopub.status.idle":"2022-01-20T22:45:11.298606Z","shell.execute_reply.started":"2022-01-20T22:45:11.058274Z","shell.execute_reply":"2022-01-20T22:45:11.297564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge predictions\npredictions = merge_predictions(test_predictions)\n# Create submission\noutput = create_submission('submission_fe_other.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:45:11.300464Z","iopub.execute_input":"2022-01-20T22:45:11.300812Z","iopub.status.idle":"2022-01-20T22:45:11.343529Z","shell.execute_reply.started":"2022-01-20T22:45:11.300766Z","shell.execute_reply":"2022-01-20T22:45:11.342585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Hybrid Models](https://www.kaggle.com/ryanholbrook/hybrid-models)\n\nAs the fifth lesson suggests, create a boosted hybrid by implementing a new Python class.  \nAlso, add the fit and predict methods to give it a scikit-learn like interface.","metadata":{}},{"cell_type":"code","source":"class BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        \n    def fit(self, X_1, X_2, y):\n        # Fit self.model_1\n        self.model_1.fit(X_1, y)\n        \n        # Make predictions with self.model_1\n        y_fit = pd.Series(self.model_1.predict(X_1), index=X_1.index,\n                          dtype=np.float32, name='num_sold')\n        \n        # Fit self.model_2 on residuals\n        y_resid = y - y_fit\n        self.model_2.fit(X_2, y_resid)\n        \n    def predict(self, X_1, X_2):\n        # Predict with self.model_1\n        y_pred = self.model_1.predict(X_1)\n        \n        # Add self.model_2 predictions to y_pred\n        y_pred += self.model_2.predict(X_2)\n        \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:45:11.345083Z","iopub.execute_input":"2022-01-20T22:45:11.345316Z","iopub.status.idle":"2022-01-20T22:45:11.353317Z","shell.execute_reply.started":"2022-01-20T22:45:11.345289Z","shell.execute_reply":"2022-01-20T22:45:11.352399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create the features and get the predictions.","metadata":{}},{"cell_type":"code","source":"train_predictions = []\ntest_predictions = []\nfor i in range(len(splitted_train_df)):\n    df_train = splitted_train_df[i].copy()\n    df_test = splitted_test_df[i].copy()\n    \n    # Target\n    y = df_train.loc[:, 'num_sold']\n    df_train = df_train.drop('num_sold', axis=1)\n    \n    # Features\n    X = engineer(df_train.copy())\n    test_X = engineer(df_test.copy())\n    \n    # X_1: Features for LinearRegression\n    features = ['gdp']\n    X_1 = X.loc[:, features].copy()\n    test_X_1 = test_X.loc[:, features].copy()\n    \n    # X_2: Features for CatBoostRegressor \n    X_2 = X.drop(features, axis=1).copy()\n    test_X_2 = test_X.drop(features, axis=1).copy()\n    \n    # Create LinearRegression + CatBoostRegressor hybrid with BoostedHybrid\n    model = BoostedHybrid(\n        model_1=LinearRegression(),\n        model_2=CatBoostRegressor(silent=True),\n    )\n    # Fit the model\n    model.fit(X_1, X_2, y)\n\n    # Make predictions\n    train_predictions.append(pd.Series(model.predict(X_1, X_2), index=X_1.index))\n    test_predictions.append(pd.Series(model.predict(test_X_1, test_X_2), index=test_X_1.index))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T22:45:11.354858Z","iopub.execute_input":"2022-01-20T22:45:11.355248Z","iopub.status.idle":"2022-01-20T22:45:42.215341Z","shell.execute_reply.started":"2022-01-20T22:45:11.355203Z","shell.execute_reply":"2022-01-20T22:45:42.214581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the predictions and use test predictions to create submission.","metadata":{}},{"cell_type":"code","source":"ax = splitted_train[0].loc[:, 'num_sold'].plot(**plot_params, alpha=0.5)\nax = train_predictions[0].plot(ax=ax)\n\n# Set ticks, labels and titles,\n# Since splitted data has different indices, apply it to ticks\nax.set_xticks(ticks * 18)\nax.set_xticklabels(labels)\nax.set_title('Finland - KaggleMart - Kaggle Mug')\nax.set(xlabel='Date', ylabel='Number of sales');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:45:42.217088Z","iopub.execute_input":"2022-01-20T22:45:42.217404Z","iopub.status.idle":"2022-01-20T22:45:42.455318Z","shell.execute_reply.started":"2022-01-20T22:45:42.217362Z","shell.execute_reply":"2022-01-20T22:45:42.454436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge predictions\npredictions = merge_predictions(test_predictions)\n# Create submission\noutput = create_submission('submission_hybrid.csv', predictions)\noutput","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-20T22:45:42.456921Z","iopub.execute_input":"2022-01-20T22:45:42.457681Z","iopub.status.idle":"2022-01-20T22:45:42.500824Z","shell.execute_reply.started":"2022-01-20T22:45:42.45763Z","shell.execute_reply":"2022-01-20T22:45:42.499856Z"},"trusted":true},"execution_count":null,"outputs":[]}]}