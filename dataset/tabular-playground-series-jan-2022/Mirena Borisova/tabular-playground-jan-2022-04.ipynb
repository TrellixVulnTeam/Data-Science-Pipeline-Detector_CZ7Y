{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nsns.set(style='darkgrid', font_scale=1.4)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom itertools import combinations\nimport math\nimport statistics\nimport scipy.stats\nfrom scipy.stats import pearsonr\nimport time\nfrom datetime import datetime\nimport matplotlib.dates as mdates\nimport dateutil.easter as easter\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, TimeSeriesSplit\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LinearRegression, Ridge\n\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-31T17:09:28.221993Z","iopub.execute_input":"2022-01-31T17:09:28.222335Z","iopub.status.idle":"2022-01-31T17:09:31.511387Z","shell.execute_reply.started":"2022-01-31T17:09:28.222236Z","shell.execute_reply":"2022-01-31T17:09:31.510451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv', index_col='row_id')\nprint(train_data.dtypes)\nprint(train_data.date.dtype)\ntrain_data.info()\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.513112Z","iopub.execute_input":"2022-01-31T17:09:31.513434Z","iopub.status.idle":"2022-01-31T17:09:31.590399Z","shell.execute_reply.started":"2022-01-31T17:09:31.51339Z","shell.execute_reply":"2022-01-31T17:09:31.589624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv', index_col='row_id')\nprint(test_data.date.dtype)\ntest_data","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.591596Z","iopub.execute_input":"2022-01-31T17:09:31.592453Z","iopub.status.idle":"2022-01-31T17:09:31.621741Z","shell.execute_reply.started":"2022-01-31T17:09:31.592415Z","shell.execute_reply":"2022-01-31T17:09:31.620939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.date.dtype)\ntrain_data.date = pd.to_datetime(train_data.date)\nprint(train_data.date.dtype)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.62367Z","iopub.execute_input":"2022-01-31T17:09:31.623909Z","iopub.status.idle":"2022-01-31T17:09:31.650131Z","shell.execute_reply.started":"2022-01-31T17:09:31.62388Z","shell.execute_reply":"2022-01-31T17:09:31.649283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.date = pd.to_datetime(test_data.date)\nprint(test_data.date.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.651248Z","iopub.execute_input":"2022-01-31T17:09:31.651454Z","iopub.status.idle":"2022-01-31T17:09:31.660288Z","shell.execute_reply.started":"2022-01-31T17:09:31.651428Z","shell.execute_reply":"2022-01-31T17:09:31.659279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[(train_data.date.dt.month == 2) & (train_data.date.dt.day == 29)])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.661756Z","iopub.execute_input":"2022-01-31T17:09:31.662172Z","iopub.status.idle":"2022-01-31T17:09:31.687136Z","shell.execute_reply.started":"2022-01-31T17:09:31.662129Z","shell.execute_reply":"2022-01-31T17:09:31.686258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[7632:7650, 0] = pd.to_datetime('2016-03-01')\ntrain_data.iloc[7632:7650, 0]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.688351Z","iopub.execute_input":"2022-01-31T17:09:31.688567Z","iopub.status.idle":"2022-01-31T17:09:31.698351Z","shell.execute_reply.started":"2022-01-31T17:09:31.68854Z","shell.execute_reply":"2022-01-31T17:09:31.697451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_data[(test_data.date.dt.month == 2) & (test_data.date.dt.day == 29)])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.700024Z","iopub.execute_input":"2022-01-31T17:09:31.700348Z","iopub.status.idle":"2022-01-31T17:09:31.714238Z","shell.execute_reply.started":"2022-01-31T17:09:31.700297Z","shell.execute_reply":"2022-01-31T17:09:31.713233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data.drop(train_data[(train_data.date.dt.month==2) & (train_data.date.dt.day==29)].index, axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.7159Z","iopub.execute_input":"2022-01-31T17:09:31.716314Z","iopub.status.idle":"2022-01-31T17:09:31.721415Z","shell.execute_reply.started":"2022-01-31T17:09:31.716265Z","shell.execute_reply":"2022-01-31T17:09:31.720572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\naa = train_data.groupby(['date', 'store']).agg(num_sold=('num_sold','sum'))\n\nsns.lineplot(data=aa, x='date', y='num_sold', hue='store')\n\nplt.title('NUM_SOLD BY STORE')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:31.722668Z","iopub.execute_input":"2022-01-31T17:09:31.722885Z","iopub.status.idle":"2022-01-31T17:09:32.826984Z","shell.execute_reply.started":"2022-01-31T17:09:31.72286Z","shell.execute_reply":"2022-01-31T17:09:32.825816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n\nKR = train_data[train_data.store=='KaggleRama']\nKM = train_data[train_data.store=='KaggleMart']\n\nbb = KR.groupby(['date', 'product']).agg(num_sold=('num_sold', 'sum'))\ncc = KM.groupby(['date', 'product']).agg(num_sold=('num_sold', 'sum'))\n\nax1 = sns.lineplot(ax=axes[0], data=bb, x='date', y='num_sold', hue='product')\nax2 = sns.lineplot(ax=axes[1], data=cc, x='date', y='num_sold', hue='product')\n\nax1.title.set_text('KAGGLE RAMA')\nax2.title.set_text('KAGGLE MART')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:32.82879Z","iopub.execute_input":"2022-01-31T17:09:32.829157Z","iopub.status.idle":"2022-01-31T17:09:34.786012Z","shell.execute_reply.started":"2022-01-31T17:09:32.829113Z","shell.execute_reply":"2022-01-31T17:09:34.785043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n\ndd = KR.groupby(['date', 'country']).agg(num_sold=('num_sold', 'sum'))\nee = KM.groupby(['date', 'country']).agg(num_sold=('num_sold', 'sum'))\n\nax1 = sns.lineplot(ax=axes[0], data=dd, x='date', y='num_sold', hue='country')\nax2 = sns.lineplot(ax=axes[1], data=ee, x='date', y='num_sold', hue='country')\n\nax1.title.set_text('KAGGLE RAMA')\nax2.title.set_text('KAGGLE MART')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:34.787505Z","iopub.execute_input":"2022-01-31T17:09:34.78777Z","iopub.status.idle":"2022-01-31T17:09:36.709545Z","shell.execute_reply.started":"2022-01-31T17:09:34.787737Z","shell.execute_reply":"2022-01-31T17:09:36.708526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_data.num_sold\nX = train_data.drop('num_sold', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.713399Z","iopub.execute_input":"2022-01-31T17:09:36.713725Z","iopub.status.idle":"2022-01-31T17:09:36.720851Z","shell.execute_reply.started":"2022-01-31T17:09:36.71368Z","shell.execute_reply":"2022-01-31T17:09:36.719997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unofficial_hol(df):\n    countries = {\n        'Finland': 1,\n        'Norway': 2,\n        'Sweden': 3\n    }\n    \n    stores = {\n        'KaggleMart': 1,\n        'KaggleRama': 2\n    }\n    \n    product = {\n        'Kaggle Mug': 1,\n        'Kaggle Hat': 2,\n        'Kaggle Sticker': 3\n    }\n    \n    hol_path = '../input/public-and-unofficial-holidays-nor-fin-swe-201519/holidays.csv'\n    holiday = pd.read_csv(hol_path)\n    \n    fin_holiday = holiday.loc[holiday.country=='Finland']\n    swe_holiday = holiday.loc[holiday.country=='Sweden']\n    nor_holiday = holiday.loc[holiday.country=='Norway']\n    \n    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    df.loc[df.country=='Finland', 'holiday'] = df.loc[df.country=='Finland', 'fin holiday']\n    df.loc[df.country=='Sweden', 'holiday'] = df.loc[df.country=='Sweden', 'swe holiday']\n    df.loc[df.country=='Norway', 'holiday'] = df.loc[df.country=='Norway', 'nor holiday']\n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.722279Z","iopub.execute_input":"2022-01-31T17:09:36.722582Z","iopub.status.idle":"2022-01-31T17:09:36.735671Z","shell.execute_reply.started":"2022-01-31T17:09:36.72254Z","shell.execute_reply":"2022-01-31T17:09:36.734933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_holidays(df):\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'dec{d}': (df.date.dt.month == 12) & (df.date.dt.day == d) for d in range(24, 32)\n                    }),\n                    pd.DataFrame({\n                        f'n-dec{d}': (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway') for d in range(24, 32)\n                    }),\n                    pd.DataFrame({\n                        f'f-jan{d}': (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland') for d in range(1, 14)\n                    }),\n                    pd.DataFrame({\n                        f'jan{d}': (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway') for d in range(1, 10)\n                    }),\n                    pd.DataFrame({\n                        f's-jan{d}': (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden') for d in range(1, 15)\n                    })],\n                   axis=1)\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'may{d}': (df.date.dt.month == 5) & (df.date.dt.day == d) for d in list(range(1, 10))\n                    }),\n                    pd.DataFrame({\n                        f'may{d}': (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway') for d in list(range(19, 26))\n                    })], \n                   axis=1)\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'june{d}': (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden') for d in list(range(8, 14))\n                    })],\n                   axis=1)\n    swed_rock_fest = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-06-6')),\n        2016: pd.Timestamp(('2016-06-11')),\n        2017: pd.Timestamp(('2017-06-10')),\n        2018: pd.Timestamp(('2018-06-10')),\n        2019: pd.Timestamp(('2019-06-8'))\n    })\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'swed_rock_fest{d}': (df.date - swed_rock_fest == np.timedelta64(d, 'D')) & (df.country == 'Sweden') for d in list(range(-3, 3))\n                    })], \n                   axis=1)\n    wed_june_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-06-24')),\n        2016: pd.Timestamp(('2016-06-29')),\n        2017: pd.Timestamp(('2017-06-28')),\n        2018: pd.Timestamp(('2018-06-27')),\n        2019: pd.Timestamp(('2019-06-26'))\n    })\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'wed_june{d}': (df.date - wed_june_date == np.timedelta64(d, 'D')) & (df.country != 'Norway') for d in list(range(-4, 6))\n                    })], \n                   axis=1)\n    sun_nov_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-11-1')),\n        2016: pd.Timestamp(('2016-11-6')),\n        2017: pd.Timestamp(('2017-11-5')),\n        2018: pd.Timestamp(('2018-11-4')),\n        2019: pd.Timestamp(('2019-11-3'))\n    })\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'sun_nov{d}': (df.date - sun_nov_date == np.timedelta64(d, 'D')) & (df.country != 'Norway') for d in list(range(0, 9))\n                    })],\n                   axis=1)\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'dec{d}': (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland') for d in list(range(6, 14))\n                    })],\n                   axis=1)\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    df = pd.concat([df,\n                    pd.DataFrame({\n                        f'easter{d}': (df.date - easter_date == np.timedelta64(d, 'D')) for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))\n                    })],\n                   axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.736907Z","iopub.execute_input":"2022-01-31T17:09:36.737731Z","iopub.status.idle":"2022-01-31T17:09:36.76811Z","shell.execute_reply.started":"2022-01-31T17:09:36.737682Z","shell.execute_reply":"2022-01-31T17:09:36.767334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def date_feat_eng_X1(df):\n    df['year'] = df['date'].dt.year\n    return df\n\ndef date_feat_eng_X2(df):\n    df['day_of_week'] = df['date'].dt.dayofweek\n    df['day_of_month'] = df['date'].dt.day\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df.loc[(df.date.dt.year==2016) & (df.dayofyear>60), 'dayofyear'] -= 1\n    df['week'] = df['date'].dt.isocalendar().week\n    df['week'] = df['week'].astype('int')\n    df['month'] = df['date'].dt.month\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.769263Z","iopub.execute_input":"2022-01-31T17:09:36.770044Z","iopub.status.idle":"2022-01-31T17:09:36.78577Z","shell.execute_reply.started":"2022-01-31T17:09:36.769994Z","shell.execute_reply":"2022-01-31T17:09:36.784796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_GDP(df):\n    GDP_data = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv', index_col='year')\n    GDP_data.columns = ['Finland', 'Norway', 'Sweden']\n    GDP_dictionary = GDP_data.unstack().to_dict()\n    df['GDP'] = df.set_index(['country', 'year']).index.map(GDP_dictionary.get)\n    df['GDP'] = np.log(df['GDP'])\n    df['GDP_Finland'] = df['GDP'] * (df['country'] == 'Finland')\n    df['GDP_Norway'] = df['GDP'] * (df['country'] == 'Norway')  \n    df['GDP_Sweden'] = df['GDP'] * (df['country'] == 'Sweden')\n    df = df.drop(['GDP', 'year'], axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.787151Z","iopub.execute_input":"2022-01-31T17:09:36.787661Z","iopub.status.idle":"2022-01-31T17:09:36.801945Z","shell.execute_reply.started":"2022-01-31T17:09:36.787614Z","shell.execute_reply":"2022-01-31T17:09:36.80115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GDP_PC(df):\n    GDP_PC_data = pd.read_csv('../input/gdp-per-capita-finland-norway-sweden-201519/GDP_per_capita_2015_to_2019_Finland_Norway_Sweden.csv', index_col=year)\n    GDP_PC_dictionary = GDP_PC_data.unstack().to_dict()\n    df['GDP_PC'] = df.set_index(['country', 'year']).index.map(GDP_PC_dictionary.get)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.803078Z","iopub.execute_input":"2022-01-31T17:09:36.80341Z","iopub.status.idle":"2022-01-31T17:09:36.813294Z","shell.execute_reply.started":"2022-01-31T17:09:36.803382Z","shell.execute_reply":"2022-01-31T17:09:36.812739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GDP_corr(df):\n    GDP_data = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv', index_col='year')\n    GDP_PC_data = pd.read_csv('../input/gdp-per-capita-finland-norway-sweden-201519/GDP_per_capita_2015_to_2019_Finland_Norway_Sweden.csv', index_col='year')\n    \n    GDP_data.columns = ['Finland', 'Norway', 'Sweden']\n    GDP_dictionary = GDP_data.unstack().to_dict()\n    GDP_PC_dictionary = GDP_PC_data.unstack().to_dict()\n    \n    df['year'] = df.date.dt.year\n    df['GDP'] = df.set_index(['country', 'year']).index.map(GDP_dictionary.get)\n    df['GDP_PC'] = df.set_index(['country', 'year']).index.map(GDP_PC_dictionary.get)\n    \n    feat_corr = []\n    \n    for SS in ['KaggleMart', 'KaggleRama']:\n        for CC in ['Finland', 'Norway', 'Sweden']:\n            for PP in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n                subset = df[(df.store == SS) & (df.country == CC) & (df['product'] == PP)].groupby(['year']).agg(num_sold=('num_sold', 'sum'), GDP=('GDP', 'mean'), GDP_PC=('GDP_PC', 'mean'))\n                v1=subset.num_sold\n                v2=subset.GDP\n                v3=subset.GDP_PC\n                \n                r1, _ = pearsonr(v1, v2)\n                r2, _ = pearsonr(v1, v3)\n                \n                feat_corr.append([f'{SS}, {CC}, {PP}', r1, r2])\n    \n    return pd.DataFrame(feat_corr, columns=['Features', 'GDP_corr', 'CDP_PC_corr'])\n\ncorr_df = GDP_corr(train_data)\ncorr_df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:36.814344Z","iopub.execute_input":"2022-01-31T17:09:36.814673Z","iopub.status.idle":"2022-01-31T17:09:37.494408Z","shell.execute_reply.started":"2022-01-31T17:09:36.814646Z","shell.execute_reply":"2022-01-31T17:09:37.493543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FourierFeatures(df):\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        df[product] = df['product'] == product\n        \n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 2):\n        df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        df[f'mug_sin'] = df[f'sin{k}'] * df['Kaggle Mug']\n        df[f'mug_cos'] = df[f'cos{k}'] * df['Kaggle Mug']\n        df[f'hat_sin'] = df[f'sin{k}'] * df['Kaggle Hat']\n        df[f'hat_cos'] = df[f'cos{k}'] * df['Kaggle Hat']\n        \n        df = df.drop([f'sin{k}', f'cos{k}'], axis=1)\n        \n    df = df.drop(['Kaggle Mug', 'Kaggle Hat'], axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:37.495681Z","iopub.execute_input":"2022-01-31T17:09:37.495907Z","iopub.status.idle":"2022-01-31T17:09:37.505495Z","shell.execute_reply.started":"2022-01-31T17:09:37.495879Z","shell.execute_reply":"2022-01-31T17:09:37.504569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_interactions(df):\n    df['KR_Sweden_Mug'] = (df.country == 'Sweden') * (df.product == 'Kaggle Mug') * (df.store == 'KaggleRama')\n    df['KR_Sweden_Hat'] = (df.country == 'Sweden') * (df.product == 'Kaggle Hat') * (df.store == 'KaggleRama')\n    df['KR_Sweden_Sticker'] = (df.country == 'Sweden') * (df.product == 'Kaggle Sticker') * (df.store == 'KaggleRama')\n    \n    df['KR_Norway_Mug'] = (df.country == 'Norway') * (df.product == 'Kaggle Mug') * (df.store == 'KaggleRama')\n    df['KR_Norway_Hat'] = (df.country == 'Norway') * (df.product == 'Kaggle Hat') * (df.store == 'KaggleRama')\n    df['KR_Norway_Sticker'] = (df.country == 'Norway') * (df.product == 'Kaggle Sticker') * (df.store == 'KaggleRama')\n    \n    df['KR_Finland_Mug'] = (df.country == 'Finland') * (df.product == 'Kaggle Mug') * (df.store == 'KaggleRama')\n    df['KR_Finland_Hat'] = (df.country == 'Finland') * (df.product == 'Kaggle Hat') * (df.store == 'KaggleRama')\n    df['KR_Finland_Sticker'] = (df.country == 'Finland') * (df.product == 'Kaggle Sticker') * (df.store == 'KaggleRama')\n    \n    df['KR_Sweden_Mug'] = (df.country == 'Sweden') * (df.product == 'Kaggle Mug') * (df.store == 'KaggleMart')\n    df['KR_Sweden_Hat'] = (df.country == 'Sweden') * (df.product == 'Kaggle Hat') * (df.store == 'KaggleMart')\n    df['KR_Sweden_Sticker'] = (df.country == 'Sweden') * (df.product == 'Kaggle Sticker') * (df.store == 'KaggleMart')\n    \n    df['KR_Norway_Mug'] = (df.country == 'Norway') * (df.product == 'Kaggle Mug') * (df.store == 'KaggleMart')\n    df['KR_Norway_Hat'] = (df.country == 'Norway') * (df.product == 'Kaggle Hat') * (df.store == 'KaggleMart')\n    df['KR_Norway_Sticker'] = (df.country == 'Norway') * (df.product == 'Kaggle Sticker') * (df.store == 'KaggleMart')\n    \n    df['KR_Finland_Mug'] = (df.country == 'Finland') * (df.product == 'Kaggle Mug') * (df.store == 'KaggleMart')\n    df['KR_Finland_Hat'] = (df.country == 'Finland') * (df.product == 'Kaggle Hat') * (df.store == 'KaggleMart')\n    df['KR_Finland_Sticker'] = (df.country == 'Finland') * (df.product == 'Kaggle Sticker') * (df.store == 'KaggleMart')\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:37.506548Z","iopub.execute_input":"2022-01-31T17:09:37.50706Z","iopub.status.idle":"2022-01-31T17:09:37.524872Z","shell.execute_reply.started":"2022-01-31T17:09:37.507026Z","shell.execute_reply":"2022-01-31T17:09:37.524012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dropdate(df):\n    df = df.drop('date', axis=1)\n    return df\n\ndef onehot(df, columns):\n    df = pd.get_dummies(df, columns)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:37.52621Z","iopub.execute_input":"2022-01-31T17:09:37.526669Z","iopub.status.idle":"2022-01-31T17:09:37.540495Z","shell.execute_reply.started":"2022-01-31T17:09:37.526638Z","shell.execute_reply":"2022-01-31T17:09:37.539579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FeatEng_X1(df):\n    df = date_feat_eng_X1(df)\n    df = get_GDP(df)\n    df = FourierFeatures(df)\n    df = get_interactions(df)\n    df = dropdate(df)\n    df = onehot(df, ['store', 'product', 'country'])\n    \n    return df\n\ndef FeatEng_X2(df):\n    df = date_feat_eng_X2(df)\n    df = unofficial_hol(df)\n    df = get_holidays(df)\n    df = dropdate(df)\n    df = onehot(df, ['store', 'product', 'country'])\n    \n    return df\n\nX_train_1 = FeatEng_X1(X)\nX_train_2 = FeatEng_X2(X)\nX_test_1 = FeatEng_X1(test_data)\nX_test_2 = FeatEng_X2(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:37.541682Z","iopub.execute_input":"2022-01-31T17:09:37.542378Z","iopub.status.idle":"2022-01-31T17:09:39.711436Z","shell.execute_reply.started":"2022-01-31T17:09:37.542332Z","shell.execute_reply":"2022-01-31T17:09:39.710354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HybridModel:\n    def __init__(self, model_1, model_2, grid=None):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.grid = grid\n        \n    def fit(self, X_train_1, X_train_2, y):\n        self.model_1.fit(X_train_1, y)\n        y_trend = self.model_1.predict(X_train_1)\n        \n        if self.grid:\n            tscv = TimeSeriesSplit(n_splits=3)\n            grid_model = GridSearchCV(estimator=self.model_2, cv=tscv, param_grid=self.grid)\n            grid_model.fit(X_train_2, y - y_trend)\n            \n            y_resid = grid_model.predict(X_train_2)\n            self.grid_model = grid_model\n        else:\n            self.model_2.fit(X_train_2, y - y_trend)\n            y_resid = self.model_2.predict(X_train_2)\n            \n        self.y_train_trend = y_trend\n        self.y_train_resid = y_resid\n        \n    def predict(self, X_test_1, X_test_2):\n        y_trend = self.model_1.predict(X_test_1)\n        if self.grid:\n            y_resid = self.grid_model.predict(X_test_2)\n        else:\n            y_resid = self.model_2.predict(X_test_2)\n            \n        y_pred = y_trend + y_resid\n        \n        self.y_test_trend = y_trend\n        self.y_test_resid = y_resid\n        \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:39.713206Z","iopub.execute_input":"2022-01-31T17:09:39.71353Z","iopub.status.idle":"2022-01-31T17:09:39.724731Z","shell.execute_reply.started":"2022-01-31T17:09:39.71348Z","shell.execute_reply":"2022-01-31T17:09:39.723845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1 = LinearRegression()\nmodels_2 = [LGBMRegressor(random_state=0), CatBoostRegressor(random_state=0, verbose=False), XGBRegressor(random_state=0)]\n\nparam_grid = {\n    'n_estimators': [100, 150, 200, 225, 250, 275, 300],\n    'max_depth': [4, 5, 6, 7],\n    'learning_rate': [0.1, 0.12, 0.13, 0.14, 0.15]\n}\n\ny_pred = np.zeros(len(test_data))\ntrain_preds = np.zeros(len(y))\n\nfor model_2 in models_2:\n    start = time.time()\n    \n    model = HybridModel(model_1, model_2, grid=param_grid)\n    model.fit(X_train_1, X_train_2, np.log(y))\n    \n    y_pred += np.exp(model.predict(X_test_1, X_test_2))\n    train_preds += np.exp(model.y_train_trend + model.y_train_resid)\n    \n    stop = time.time()\n    \n    print(f'MODEL_2:{model_2} -- TIME:{round((stop-start)/60, 2)} mins')\n    \n    if model.grid:\n        print('BEST PARAMETERS:', model.grid_model.best_params_, '\\n')\n        \ny_pred /= len(models_2)\ntrain_preds /= len(models_2)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:09:39.726128Z","iopub.execute_input":"2022-01-31T17:09:39.72684Z","iopub.status.idle":"2022-01-31T18:30:09.894621Z","shell.execute_reply.started":"2022-01-31T17:09:39.726799Z","shell.execute_reply":"2022-01-31T18:30:09.8917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def geometric_round(arr):\n    result_array = arr\n    result_array = np.where(result_array < np.sqrt(np.floor(arr) * np.ceil(arr)), np.floor(arr), result_array)\n    result_array = np.where(result_array >= np.sqrt(np.floor(arr) * np.ceil(arr)), np.ceil(arr), result_array)\n    \n    return result_array\n\ny_pred = geometric_round(y_pred)\noutput = pd.DataFrame({\n    'row_id': test_data.index,\n    'num_sold': y_pred\n})\n\noutput","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:30:56.984079Z","iopub.execute_input":"2022-01-31T18:30:56.98511Z","iopub.status.idle":"2022-01-31T18:30:57.025978Z","shell.execute_reply.started":"2022-01-31T18:30:56.985061Z","shell.execute_reply":"2022-01-31T18:30:57.025026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission_hybrid_01.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:31:02.488568Z","iopub.execute_input":"2022-01-31T18:31:02.488855Z","iopub.status.idle":"2022-01-31T18:31:02.535062Z","shell.execute_reply.started":"2022-01-31T18:31:02.488824Z","shell.execute_reply":"2022-01-31T18:31:02.533596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_predictions(SS, CC, PP, series=output):\n    train_subset = train_data[(train_data.store == SS) & (train_data.country == CC) & (train_data['product'] == PP)]\n    plot_index = test_data[(test_data.store == SS) & (test_data.country == CC) & (test_data['product'] == PP)].index\n    \n    pred_subset = series[series.row_id.isin(plot_index)].reset_index(drop=True)\n    \n    plt.figure(figsize=(12, 5))\n    n1 = len(train_subset['num_sold'])\n    n2 = len(pred_subset['num_sold'])\n    plt.plot(np.arange(n1), train_subset['num_sold'], label='TRAINING')\n    plt.plot(np.arange(n1, n1 + n2), pred_subset['num_sold'], label='PREDICTIONS')\n    plt.title('\\n' + f'STORE:{SS}, COUNTRY:{CC}, PRODUCT:{PP}')\n    plt.legend()\n    plt.xlabel('DAYS SINCE 2015-01-01')\n    plt.ylabel('NUM_SOLD')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:31:06.729941Z","iopub.execute_input":"2022-01-31T18:31:06.730359Z","iopub.status.idle":"2022-01-31T18:31:06.743241Z","shell.execute_reply.started":"2022-01-31T18:31:06.730307Z","shell.execute_reply":"2022-01-31T18:31:06.742391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_trend = pd.DataFrame({\n    'row_id': test_data.index,\n    'num_sold': np.exp(model.y_test_trend)\n})\ny_resid = pd.DataFrame({\n    'row_id': test_data.index,\n    'num_sold': np.exp(model.y_test_resid)\n})\ny_pred = pd.DataFrame({\n    'row_id': test_data.index,\n    'num_sold': np.exp(model.y_test_trend + model.y_test_resid)\n})\n\nSS = 'KaggleMart'\nCC = 'Norway'\n\nplot_predictions(SS, CC, 'Kaggle Hat', series=y_trend)\nplot_predictions(SS, CC, 'Kaggle Mug', series=y_trend)\nplot_predictions(SS, CC, 'Kaggle Sticker', series=y_trend)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:31:14.155526Z","iopub.execute_input":"2022-01-31T18:31:14.15589Z","iopub.status.idle":"2022-01-31T18:31:15.342493Z","shell.execute_reply.started":"2022-01-31T18:31:14.155854Z","shell.execute_reply":"2022-01-31T18:31:15.341169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for SS in ['KaggleMart', 'KaggleRama']:\n    for CC in ['Finland', 'Norway', 'Sweden']:\n        for PP in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n            plot_predictions(SS, CC, PP)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:31:39.35405Z","iopub.execute_input":"2022-01-31T18:31:39.354422Z","iopub.status.idle":"2022-01-31T18:31:45.707799Z","shell.execute_reply.started":"2022-01-31T18:31:39.354386Z","shell.execute_reply":"2022-01-31T18:31:45.707067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preds = np.exp(model.y_train_trend + model.y_train_resid)\n\nresiduals = 200 * (train_preds - y) / (train_preds + y)\nplt.figure(figsize=(12, 4))\nplt.scatter(np.arange(len(residuals)), residuals, s=1)\nplt.hlines([0], 0, residuals.index.max(), color='k')\nplt.title('RESIDUALS ON TRAINING SET')\nplt.xlabel('SAMPLE')\nplt.ylabel('SMAPE')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:35:12.760317Z","iopub.execute_input":"2022-01-31T18:35:12.760718Z","iopub.status.idle":"2022-01-31T18:35:13.100525Z","shell.execute_reply.started":"2022-01-31T18:35:12.760671Z","shell.execute_reply":"2022-01-31T18:35:13.099461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mu, std = scipy.stats.norm.fit(residuals)\n\nplt.figure(figsize=(12, 4))\nplt.hist(residuals, bins=100, density=True)\nx = np.linspace(plt.xlim()[0], plt.xlim()[1], 200)\nplt.plot(x, scipy.stats.norm.pdf(x, mu, std), 'r', linewidth=2)\nplt.title(f'HISTOGRAM OF RESIDUALS: MEAN = {residuals.mean():.4f}, '\n          f'$\\sigma = {residuals.std():.1f}$, SMAPE = {residuals.abs().mean():.5f}')\nplt.xlabel('RESIDUAL {percent}')\nplt.ylabel('DENSITY')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:47:37.015524Z","iopub.execute_input":"2022-01-31T18:47:37.016709Z","iopub.status.idle":"2022-01-31T18:47:38.662141Z","shell.execute_reply.started":"2022-01-31T18:47:37.016627Z","shell.execute_reply":"2022-01-31T18:47:38.659193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}