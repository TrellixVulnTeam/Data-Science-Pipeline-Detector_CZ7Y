{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T05:34:40.212435Z","iopub.execute_input":"2022-01-06T05:34:40.212759Z","iopub.status.idle":"2022-01-06T05:34:40.221509Z","shell.execute_reply.started":"2022-01-06T05:34:40.212727Z","shell.execute_reply":"2022-01-06T05:34:40.220671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport random\n\nfrom IPython import display as ipd\nfrom tqdm import tqdm\nimport lightgbm as lgb\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nimport optuna \nfrom optuna.visualization.matplotlib import plot_optimization_history\nfrom optuna.visualization.matplotlib import plot_param_importances","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:40.999355Z","iopub.execute_input":"2022-01-06T05:34:41.000097Z","iopub.status.idle":"2022-01-06T05:34:43.903667Z","shell.execute_reply.started":"2022-01-06T05:34:41.000052Z","shell.execute_reply":"2022-01-06T05:34:43.902977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"def seeding(SEED, use_tf=False):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    if use_tf:\n        tf.random.set_seed(SEED)\n    print('seeding done!!!')\n    \n## https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/298201\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)    ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:43.90533Z","iopub.execute_input":"2022-01-06T05:34:43.906085Z","iopub.status.idle":"2022-01-06T05:34:43.913836Z","shell.execute_reply.started":"2022-01-06T05:34:43.906039Z","shell.execute_reply":"2022-01-06T05:34:43.913043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Load","metadata":{}},{"cell_type":"code","source":"RANDOM_SEED = 42\nDEBUG = True\nTUNING = False\n\nseeding(RANDOM_SEED)\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:43.915166Z","iopub.execute_input":"2022-01-06T05:34:43.915414Z","iopub.status.idle":"2022-01-06T05:34:44.003358Z","shell.execute_reply.started":"2022-01-06T05:34:43.915387Z","shell.execute_reply":"2022-01-06T05:34:44.002341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:44.005351Z","iopub.execute_input":"2022-01-06T05:34:44.005611Z","iopub.status.idle":"2022-01-06T05:34:44.026534Z","shell.execute_reply.started":"2022-01-06T05:34:44.005573Z","shell.execute_reply":"2022-01-06T05:34:44.025546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Targets distribution display","metadata":{}},{"cell_type":"code","source":"## targets distribution by country\n\nf, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(16, 16))\nsns.despine(f)\ng1 = sns.histplot( data=train[train['country'] == 'Finland'], x = 'num_sold', hue='product', ax=ax1,  palette=\"rainbow\")\ng1.set_title(\"Finland\")\ng2 = sns.histplot( data=train[train['country'] == 'Norway'], x = 'num_sold', hue='product', ax=ax2,  palette=\"rainbow\")\ng2.set_title(\"Norway\")\ng3 = sns.histplot( data=train[train['country'] == 'Sweden'], x = 'num_sold', hue='product', ax=ax3,  palette=\"rainbow\")\ng3.set_title(\"Sweden\")","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:44.770733Z","iopub.execute_input":"2022-01-06T05:34:44.771004Z","iopub.status.idle":"2022-01-06T05:34:47.84633Z","shell.execute_reply.started":"2022-01-06T05:34:44.770976Z","shell.execute_reply":"2022-01-06T05:34:47.845505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax1 = plt.subplots(1, 1, figsize=(16, 6))\n\nsns.boxplot( data=train, x=\"country\", y=\"num_sold\", hue=\"product\", ax=ax1, palette=\"Spectral\")\nsns.despine(left=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:47.848202Z","iopub.execute_input":"2022-01-06T05:34:47.849865Z","iopub.status.idle":"2022-01-06T05:34:48.28095Z","shell.execute_reply.started":"2022-01-06T05:34:47.849814Z","shell.execute_reply":"2022-01-06T05:34:48.280156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Another nice way of showing distribution\n\nf, ax1 = plt.subplots(1, 1, figsize=(16, 6))\nproduct_order = [\"Kaggle Mug\", \"Kaggle Hat\", \"Kaggle Sticker\"]\nsns.boxenplot(x=\"product\", y=\"num_sold\", palette=\"rainbow\", hue='country', order=product_order, scale=\"linear\", data=train)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:48.282463Z","iopub.execute_input":"2022-01-06T05:34:48.282949Z","iopub.status.idle":"2022-01-06T05:34:48.685726Z","shell.execute_reply.started":"2022-01-06T05:34:48.282895Z","shell.execute_reply":"2022-01-06T05:34:48.684714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Very simple date-based FE","metadata":{}},{"cell_type":"code","source":"def process_dates(df):\n    df.date = pd.to_datetime(df.date)\n    df['month'] = df.date.dt.month\n    df['week'] = df.date.dt.week\n    df['weekday'] = df.date.dt.weekday\n    df['dayofweek'] = df.date.dt.dayofweek\n    df['dayofyear'] = df.date.dt.dayofyear\n    df['day'] = df.date.dt.day\n    return df\n\ntrain = process_dates(train)\ntest = process_dates(test)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:48.688015Z","iopub.execute_input":"2022-01-06T05:34:48.688532Z","iopub.status.idle":"2022-01-06T05:34:48.756148Z","shell.execute_reply.started":"2022-01-06T05:34:48.688487Z","shell.execute_reply":"2022-01-06T05:34:48.754447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train unique days: {train.day.unique().size}, test: {test.day.unique().size}')\nprint(f'Train unique weeks: {train.week.unique().size}, test: {test.week.unique().size}')\nprint(f'Train unique dayofweeks: {train.dayofweek.unique().size}, test: {train.dayofweek.unique().size}')\nprint(f'Train unique months: {train.month.unique().size}, test: {train.month.unique().size}')\nprint(f'Train unique dayofyear: {train.dayofyear.unique().size}, test: {train.dayofyear.unique().size}')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:48.757216Z","iopub.execute_input":"2022-01-06T05:34:48.757444Z","iopub.status.idle":"2022-01-06T05:34:48.767591Z","shell.execute_reply.started":"2022-01-06T05:34:48.757416Z","shell.execute_reply":"2022-01-06T05:34:48.766698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train.num_sold\ntrain.drop(['row_id','num_sold','date'], axis=1, inplace=True)\ntest.drop(['row_id', 'date'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:48.768677Z","iopub.execute_input":"2022-01-06T05:34:48.768929Z","iopub.status.idle":"2022-01-06T05:34:48.779269Z","shell.execute_reply.started":"2022-01-06T05:34:48.768894Z","shell.execute_reply":"2022-01-06T05:34:48.778643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode category columns ","metadata":{}},{"cell_type":"code","source":"country_encoder = LabelEncoder()\ntrain['country_enc'] = country_encoder.fit_transform(train['country'])\ntest['country_enc'] = country_encoder.transform(test['country'])\n\nstore_encoder = LabelEncoder()\ntrain['store_enc'] = store_encoder.fit_transform(train['store'])\ntest['store_enc'] = store_encoder.transform(test['store'])\n\nproduct_encoder = LabelEncoder()\ntrain['product_enc'] = product_encoder.fit_transform(train['product'])\ntest['product_enc'] = product_encoder.transform(test['product'])\n\ntrain.drop(['country','store','product'], axis=1, inplace=True)\ntest.drop(['country','store','product'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:49.988828Z","iopub.execute_input":"2022-01-06T05:34:49.989549Z","iopub.status.idle":"2022-01-06T05:34:50.037458Z","shell.execute_reply.started":"2022-01-06T05:34:49.989514Z","shell.execute_reply":"2022-01-06T05:34:50.036857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    train[col] = pd.Categorical(train[col])\nfor col in test.columns:\n    test[col] = pd.Categorical(test[col])","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:50.629288Z","iopub.execute_input":"2022-01-06T05:34:50.629996Z","iopub.status.idle":"2022-01-06T05:34:50.658647Z","shell.execute_reply.started":"2022-01-06T05:34:50.629947Z","shell.execute_reply":"2022-01-06T05:34:50.657717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tuning","metadata":{}},{"cell_type":"code","source":"NUM_BOOST_ROUND = 2000\nEARLY_STOPPING_ROUNDS = 50\nVERBOSE_EVAL = 100\n\ndef objective(trial, X, y):\n    \n    param_grid = {\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'n_estimators': trial.suggest_categorical('n_estimators', [2000]),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n        'num_leaves': trial.suggest_int('num_leaves', 50, 2000, step=50),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 200, 2000, step=100),\n        'max_bin': trial.suggest_int('max_bin', 200, 300),\n        'lambda_l1': trial.suggest_int('lambda_l1', 0, 100, step=5),\n        'lambda_l2': trial.suggest_int('lambda_l2', 0, 100, step=5),        \n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n    }    \n        \n    X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.25, random_state=RANDOM_SEED, shuffle=True)\n    eval_results = {}  # to record eval results for plotting\n    \n    model = lgb.train(\n        param_grid, valid_names=[\"train\", \"valid\"], \n        train_set=lgb.Dataset(X_train, y_train ), \n        num_boost_round = NUM_BOOST_ROUND,\n        valid_sets = [lgb.Dataset(X_valid, y_valid)],\n        callbacks=[lgb.log_evaluation(VERBOSE_EVAL), \n           lgb.early_stopping(EARLY_STOPPING_ROUNDS, False, True),\n           lgb.record_evaluation(eval_result=eval_results)],        \n    )    \n    \n    oof_pred = model.predict(X_valid)\n    return SMAPE(y_valid, oof_pred)        ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:51.938883Z","iopub.execute_input":"2022-01-06T05:34:51.93916Z","iopub.status.idle":"2022-01-06T05:34:51.95287Z","shell.execute_reply.started":"2022-01-06T05:34:51.939121Z","shell.execute_reply":"2022-01-06T05:34:51.951873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRIALS = 100\n\nif TUNING:\n    study = optuna.create_study(direction='minimize')\n    objective_func = lambda trial: objective(trial, train, target)\n    study.optimize(objective_func, n_trials=N_TRIALS)  # number of iterations\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n    print(\"Best trial:\")\n    trial = study.best_trial\n    print(\"  Value: {}\".format(trial.value))\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:34:53.533699Z","iopub.execute_input":"2022-01-06T05:34:53.534286Z","iopub.status.idle":"2022-01-06T05:34:53.541928Z","shell.execute_reply.started":"2022-01-06T05:34:53.534233Z","shell.execute_reply":"2022-01-06T05:34:53.541088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model and train","metadata":{}},{"cell_type":"code","source":"def run_train(X, y, run_params, splits, num_boost_round, verbose_eval, early_stopping_rounds ):\n    scores = []\n    models = []\n    eval_results = {}  # to record eval results for plotting\n    folds = StratifiedKFold(n_splits=splits)\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print(f'Fold {fold_n+1} started')\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        model = lgb.train(\n            run_params, valid_names=[\"train\", \"valid\"], \n            train_set=lgb.Dataset(X_train, y_train ), \n            num_boost_round = num_boost_round,\n            valid_sets = [lgb.Dataset(X_valid, y_valid)],\n            callbacks=[lgb.log_evaluation(verbose_eval), \n               lgb.early_stopping(early_stopping_rounds, False, True),\n               lgb.record_evaluation(eval_result=eval_results)],\n        )\n\n        y_predicted = model.predict(X_valid)\n        score = SMAPE(y_valid, y_predicted)   \n        print(f'SMAPE: {score}')\n\n        models.append(model)\n        scores.append(score)\n    return scores, models, eval_results\n\n\nTOTAL_SPLITS = 5\nNUM_BOOST_ROUND = 8000\nEARLY_STOPPING_ROUNDS = 100\nVERBOSE_EVAL = 200\n    \nrun_params = {\n    'verbose': -1, \n    'boosting_type': 'gbdt', \n    'objective': 'regression', \n    'metric': ['rmse'],\n    'learning_rate': 0.03600124778051181,\n    'num_leaves': 1400,\n    'max_depth': 9,\n    'min_data_in_leaf': 200,\n    'max_bin': 240,\n    'lambda_l1': 45,\n    'lambda_l2': 20,\n    'feature_fraction': 0.9033256488572796,\n    'bagging_fraction': 0.9728721582350929,\n    'bagging_freq': 1,\n    'min_child_samples': 69,\n}\n\nscores, models, eval_results = run_train(train, target, run_params, TOTAL_SPLITS, NUM_BOOST_ROUND, \n                                          VERBOSE_EVAL, EARLY_STOPPING_ROUNDS)\nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:35:36.248448Z","iopub.execute_input":"2022-01-06T05:35:36.24874Z","iopub.status.idle":"2022-01-06T05:36:52.379009Z","shell.execute_reply.started":"2022-01-06T05:35:36.24871Z","shell.execute_reply":"2022-01-06T05:36:52.378341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot metrics","metadata":{}},{"cell_type":"code","source":"ax = lgb.plot_metric(eval_results, metric='rmse')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:36:58.679129Z","iopub.execute_input":"2022-01-06T05:36:58.679381Z","iopub.status.idle":"2022-01-06T05:36:58.900666Z","shell.execute_reply.started":"2022-01-06T05:36:58.679355Z","shell.execute_reply":"2022-01-06T05:36:58.899715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.zeros(len(test))\nfor model in models:\n    y_pred += model.predict(test).reshape(-1)\n    \ny_pred = y_pred / len(models)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:37:07.236427Z","iopub.execute_input":"2022-01-06T05:37:07.237129Z","iopub.status.idle":"2022-01-06T05:37:15.243893Z","shell.execute_reply.started":"2022-01-06T05:37:07.237092Z","shell.execute_reply":"2022-01-06T05:37:15.243157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['num_sold'] = np.round(y_pred).astype(int)\nsubmission.to_csv('submission.csv', index=False, float_format='%.6f')\nsubmission.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:37:15.248355Z","iopub.execute_input":"2022-01-06T05:37:15.248985Z","iopub.status.idle":"2022-01-06T05:37:15.28118Z","shell.execute_reply.started":"2022-01-06T05:37:15.248944Z","shell.execute_reply":"2022-01-06T05:37:15.28026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}