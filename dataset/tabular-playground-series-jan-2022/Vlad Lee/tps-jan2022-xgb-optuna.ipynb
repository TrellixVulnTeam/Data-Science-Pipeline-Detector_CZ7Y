{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T17:33:47.397103Z","iopub.execute_input":"2022-01-06T17:33:47.397935Z","iopub.status.idle":"2022-01-06T17:33:47.407343Z","shell.execute_reply.started":"2022-01-06T17:33:47.397895Z","shell.execute_reply":"2022-01-06T17:33:47.406506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport random\n\nfrom IPython import display as ipd\nfrom tqdm import tqdm\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nimport optuna \nfrom optuna.visualization.matplotlib import plot_optimization_history\nfrom optuna.visualization.matplotlib import plot_param_importances","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:47.888146Z","iopub.execute_input":"2022-01-06T17:33:47.889041Z","iopub.status.idle":"2022-01-06T17:33:47.896188Z","shell.execute_reply.started":"2022-01-06T17:33:47.889003Z","shell.execute_reply":"2022-01-06T17:33:47.895599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"def seeding(SEED, use_tf=False):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    if use_tf:\n        tf.random.set_seed(SEED)\n    print('seeding done!!!')\n    \n## https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/298201\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)    ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:48.616828Z","iopub.execute_input":"2022-01-06T17:33:48.617359Z","iopub.status.idle":"2022-01-06T17:33:48.623922Z","shell.execute_reply.started":"2022-01-06T17:33:48.617326Z","shell.execute_reply":"2022-01-06T17:33:48.623051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Load","metadata":{}},{"cell_type":"code","source":"RANDOM_SEED = 42\nTUNING = False\n\nseeding(RANDOM_SEED)\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:49.257043Z","iopub.execute_input":"2022-01-06T17:33:49.257368Z","iopub.status.idle":"2022-01-06T17:33:49.300261Z","shell.execute_reply.started":"2022-01-06T17:33:49.257331Z","shell.execute_reply":"2022-01-06T17:33:49.299397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:49.591381Z","iopub.execute_input":"2022-01-06T17:33:49.592812Z","iopub.status.idle":"2022-01-06T17:33:49.60945Z","shell.execute_reply.started":"2022-01-06T17:33:49.592753Z","shell.execute_reply":"2022-01-06T17:33:49.607881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Targets distribution display\n\nCheck my other notebooks: \n\nhttps://www.kaggle.com/vladlee/tps-jan2022-lgbm-optuna\n\nhttps://www.kaggle.com/vladlee/tps-jan-2022-eda-baseline\n","metadata":{}},{"cell_type":"markdown","source":"### Date-based FE","metadata":{}},{"cell_type":"code","source":"def process_dates(df):\n    df.date = pd.to_datetime(df.date)\n    df['month'] = df.date.dt.month\n    df['week'] = df.date.dt.week\n    df['weekday'] = df.date.dt.weekday\n    df['dayofweek'] = df.date.dt.dayofweek\n    df['dayofyear'] = df.date.dt.dayofyear\n    df['day'] = df.date.dt.day\n    return df\n\ntrain = process_dates(train)\ntest = process_dates(test)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:50.901634Z","iopub.execute_input":"2022-01-06T17:33:50.901929Z","iopub.status.idle":"2022-01-06T17:33:50.964625Z","shell.execute_reply.started":"2022-01-06T17:33:50.90189Z","shell.execute_reply":"2022-01-06T17:33:50.963616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train unique days: {train.day.unique().size}, test: {test.day.unique().size}')\nprint(f'Train unique weeks: {train.week.unique().size}, test: {test.week.unique().size}')\nprint(f'Train unique dayofweeks: {train.dayofweek.unique().size}, test: {train.dayofweek.unique().size}')\nprint(f'Train unique months: {train.month.unique().size}, test: {train.month.unique().size}')\nprint(f'Train unique dayofyear: {train.dayofyear.unique().size}, test: {train.dayofyear.unique().size}')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:51.235975Z","iopub.execute_input":"2022-01-06T17:33:51.236247Z","iopub.status.idle":"2022-01-06T17:33:51.249211Z","shell.execute_reply.started":"2022-01-06T17:33:51.236212Z","shell.execute_reply":"2022-01-06T17:33:51.248495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train.num_sold\ntrain.drop(['row_id','num_sold','date'], axis=1, inplace=True)\ntest.drop(['row_id', 'date'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:51.629724Z","iopub.execute_input":"2022-01-06T17:33:51.630123Z","iopub.status.idle":"2022-01-06T17:33:51.639278Z","shell.execute_reply.started":"2022-01-06T17:33:51.630093Z","shell.execute_reply":"2022-01-06T17:33:51.638461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode category columns ","metadata":{}},{"cell_type":"code","source":"country_encoder = LabelEncoder()\ntrain['country_enc'] = country_encoder.fit_transform(train['country'])\ntest['country_enc'] = country_encoder.transform(test['country'])\n\nstore_encoder = LabelEncoder()\ntrain['store_enc'] = store_encoder.fit_transform(train['store'])\ntest['store_enc'] = store_encoder.transform(test['store'])\n\nproduct_encoder = LabelEncoder()\ntrain['product_enc'] = product_encoder.fit_transform(train['product'])\ntest['product_enc'] = product_encoder.transform(test['product'])\n\ntrain.drop(['country','store','product'], axis=1, inplace=True)\ntest.drop(['country','store','product'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:52.428713Z","iopub.execute_input":"2022-01-06T17:33:52.429211Z","iopub.status.idle":"2022-01-06T17:33:52.48231Z","shell.execute_reply.started":"2022-01-06T17:33:52.429169Z","shell.execute_reply":"2022-01-06T17:33:52.481378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for col in train.columns:\n#    train[col] = pd.Categorical(train[col])\n#for col in test.columns:\n#    test[col] = pd.Categorical(test[col])","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:53.048279Z","iopub.execute_input":"2022-01-06T17:33:53.049178Z","iopub.status.idle":"2022-01-06T17:33:53.053052Z","shell.execute_reply.started":"2022-01-06T17:33:53.049117Z","shell.execute_reply":"2022-01-06T17:33:53.052282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune","metadata":{}},{"cell_type":"code","source":"NUM_BOOST_ROUND = 1000\nEARLY_STOPPING_ROUNDS = 20\nVERBOSE_EVAL = 100\n    \ndef objective(trial, X, y):\n    \n    param_grid = {\n        'verbosity': 1,\n        'objective': 'reg:squarederror', \n        'eval_metric': 'rmse',\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1),\n        'eta': trial.suggest_float('eta', 0.1, 0.9),\n        'max_depth': trial.suggest_int('max_depth', 50, 500),     \n        'min_child_weight': trial.suggest_float('min_child_weight', 10, 100),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n        'gamma': trial.suggest_float('gamma', 0, 100),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n        'lambda': trial.suggest_float('lambda', 1, 10),\n        'alpha': trial.suggest_float('alpha', 0, 9),\n    }    \n        \n    X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.25, random_state=RANDOM_SEED, shuffle=False)\n    \n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n    model = xgb.train( param_grid, dtrain,\n        num_boost_round = NUM_BOOST_ROUND,\n        evals=[(dvalid, 'evals')], \n        verbose_eval = VERBOSE_EVAL,\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS\n    )   \n    \n    oof_pred = model.predict(dvalid)\n    oof_score = SMAPE(y_valid, oof_pred) \n    print(f\"OOF SMAPE: {oof_score}\")\n    return oof_score","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:53.835802Z","iopub.execute_input":"2022-01-06T17:33:53.836506Z","iopub.status.idle":"2022-01-06T17:33:53.847551Z","shell.execute_reply.started":"2022-01-06T17:33:53.836468Z","shell.execute_reply":"2022-01-06T17:33:53.846732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRIALS = 100\n\nif TUNING:\n    study = optuna.create_study(direction='minimize')\n    objective_func = lambda trial: objective(trial, train, target)\n    study.optimize(objective_func, n_trials=N_TRIALS)  # number of iterations\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n    print(\"Best trial:\")\n    trial = study.best_trial\n    print(\"  Value: {}\".format(trial.value))\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:33:54.938156Z","iopub.execute_input":"2022-01-06T17:33:54.938624Z","iopub.status.idle":"2022-01-06T17:33:54.944934Z","shell.execute_reply.started":"2022-01-06T17:33:54.938589Z","shell.execute_reply":"2022-01-06T17:33:54.943971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model and train","metadata":{}},{"cell_type":"code","source":"def run_train(X, y, run_params, splits, num_boost_round, verbose_eval, early_stopping_rounds ):\n    scores = []\n    models = []\n    folds = StratifiedKFold(n_splits=splits)\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print(f'Fold {fold_n+1} started')\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        \n        dtrain = xgb.DMatrix(X_train, label=y_train)\n        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n        model = xgb.train( run_params, dtrain,\n            num_boost_round = num_boost_round,\n            evals=[(dvalid, 'evals')], \n            verbose_eval = verbose_eval,\n            early_stopping_rounds=early_stopping_rounds\n        )   \n\n        oof_pred = model.predict(dvalid)\n        oof_score = SMAPE(y_valid, oof_pred) \n        print(f\"OOF SMAPE: {oof_score}\")        \n        \n        models.append(model)\n        scores.append(oof_score)\n    return scores, models\n\n\nNUM_BOOST_ROUND = 2000\nEARLY_STOPPING_ROUNDS = 100\nVERBOSE_EVAL = 100\nTOTAL_SPLITS = 5\n    \nrun_params = {\n    'verbosity': 1,\n    'objective': 'reg:squarederror', \n    'eval_metric': 'rmse',\n    'learning_rate': 0.01729433116660487,\n    'eta': 0.4954283685809021,\n    'max_depth': 476,\n    'min_child_weight': 12.875223150484498,\n    'colsample_bytree': 0.7890238951483045,\n    'gamma': 96.89423371529557,\n    'subsample': 0.8862703289885544,\n    'lambda': 8.869246442053491,\n    'alpha': 4.132837689865073,\n}\n\nFEATURES = [col for col in train.columns if col.endswith('enc')]\nscores, models = run_train(train, target, run_params, TOTAL_SPLITS, NUM_BOOST_ROUND, \n                                          VERBOSE_EVAL, EARLY_STOPPING_ROUNDS)\n\nprint('----------------------')\nprint(f'CV SMAPE mean score: {np.mean(scores)}, std: {np.std(scores)}.')\nprint('----------------------')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:35:17.184729Z","iopub.execute_input":"2022-01-06T17:35:17.185576Z","iopub.status.idle":"2022-01-06T17:41:01.069442Z","shell.execute_reply.started":"2022-01-06T17:35:17.185532Z","shell.execute_reply":"2022-01-06T17:41:01.06861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.zeros(len(test))\nfor model in models:\n    y_pred += model.predict(xgb.DMatrix(test)).reshape(-1)\n    \ny_pred = y_pred / len(models)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:50:26.13154Z","iopub.execute_input":"2022-01-06T17:50:26.131965Z","iopub.status.idle":"2022-01-06T17:50:29.241329Z","shell.execute_reply.started":"2022-01-06T17:50:26.131925Z","shell.execute_reply":"2022-01-06T17:50:29.240632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['num_sold'] = np.round(y_pred).astype(int)\nsubmission.to_csv('submission.csv', index=False, float_format='%.6f')\nsubmission.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T17:51:44.675136Z","iopub.execute_input":"2022-01-06T17:51:44.675643Z","iopub.status.idle":"2022-01-06T17:51:44.70596Z","shell.execute_reply.started":"2022-01-06T17:51:44.675604Z","shell.execute_reply":"2022-01-06T17:51:44.704923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}