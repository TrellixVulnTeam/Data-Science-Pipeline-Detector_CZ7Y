{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Many thanks to these amazing notebooks created by:\n\n@ambrosm \n- the nice EDA for this dataset conveyed per https://www.kaggle.com/ambrosm/tpsjan22-01-eda-which-makes-sense\n- the feature engineering routines invented per https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model\n\n@gvyshnya\n-- uses featurewiz to select 200 features out of ~625 features https://www.kaggle.com/gvyshnya/jan22-tpc-feature-importance-with-featurewiz/comments","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport pickle\nimport itertools\nimport gc\nimport math\nfrom typing import Tuple, List, Dict\nimport matplotlib.dates as md\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import host_subplot\nimport mpl_toolkits.axisartist as AA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.covariance import EllipticEnvelope\nimport dateutil.easter as easter\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/tabular-playground-series-jan-2022/train.csv'\ntest_path = '../input/tabular-playground-series-jan-2022/test.csv'\nsample_submission_path = '../input/tabular-playground-series-jan-2022/sample_submission.csv'\noriginal_train_df = pd.read_csv(train_path)\noriginal_test_df = pd.read_csv(test_path)\nsubm = pd.read_csv(sample_submission_path)\nprint(original_train_df.shape, original_test_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xlrd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install featurewiz --ignore-installed --no-deps","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import featurewiz as FW","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install autoviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# The dates are read as strings and must be converted\nfor df in [original_train_df, original_test_df]:\n    df['date'] = pd.to_datetime(df.date)\n    df.set_index('date', inplace=True, drop=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Feature engineering\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    new_df = pd.DataFrame({'year': df.date.dt.year, # This feature makes it possible to fit an annual growth rate\n                           'dayofyear': df.date.dt.dayofyear,\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                           'dec29': (df.date.dt.month == 12) & (df.date.dt.day == 29), # end-of-year peak\n                           'dec30': (df.date.dt.month == 12) & (df.date.dt.day == 30),\n                          })\n\n    # Easter\n    new_df['easter_week'] = False\n    for year in range(2015, 2020):\n        easter_date = easter.easter(year)\n        easter_diff = df.date - np.datetime64(easter_date)\n        new_df['easter_week'] = new_df['easter_week'] | (easter_diff > np.timedelta64(0, \"D\")) & (easter_diff < np.timedelta64(8, \"D\"))\n    \n    # Growth is country-specific\n    #for country in ['Finland', 'Norway', 'Sweden']:\n    #    new_df[f\"{country}_year\"] = (df.country == country) * df.date.dt.year\n        \n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Sticker']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 100): # 100\n        new_df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n        new_df[f'sticker_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Sticker']\n        new_df[f'sticker_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Sticker']\n\n    return new_df\n\ntrain_df = engineer(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer(original_test_df)\ntest_df.year = 2018 # no growth patch, see https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/298318\n#### George: You forgot to add two extra lines below for test_df. Without these two vars, train_df and test_df will be different.\ntest_df['date'] = original_test_df.date\n\nfeatures = test_df.columns\nprint(len(features))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape, test_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'num_sold'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ntrain_df.drop('date', axis=1, inplace=True)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.reset_index(drop=True)\ntest_df.drop('date', axis=1, inplace=True)\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's use Autoviz to select the best 100 features out of 607 features","metadata":{}},{"cell_type":"code","source":"from autoviz.AutoViz_Class import AutoViz_Class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AV = AutoViz_Class()\nfilename = \"\"\nsep = \",\"\ndft = AV.AutoViz(\n    filename,\n    sep=\",\",\n    depVar=target,\n    dfte=train_df,\n    header=0,\n    verbose=0,\n    lowess=False,\n    chart_format=\"svg\",\n    max_rows_analyzed=150000,\n    max_cols_analyzed=100,\n    save_plot_dir=None\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = dft.columns.tolist()\nlen(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_best = train_df[preds]\ntest_best = test_df[preds[:-1]]\nprint(train_best.shape, test_best.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# It look ~10 mins to select features in this dataset. We have 86 important features now","metadata":{}},{"cell_type":"markdown","source":"# This simple LightGBM model works wonders since it is highly effective in many competitions","metadata":{}},{"cell_type":"code","source":"outputs = FW.simple_lightgbm_model(X_XGB=train_best[preds[:-1]], Y_XGB=train_best[target],\n                               X_XGB_test=test_best[preds[:-1]], modeltype='Regression', verbose=-1)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# It took less than 1 min to build a model with RMSE average = 207 over 5 folds","metadata":{}},{"cell_type":"code","source":"y_preds = outputs[0]\ny_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm[target] = y_preds\nsubm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(y_preds).hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[target].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}