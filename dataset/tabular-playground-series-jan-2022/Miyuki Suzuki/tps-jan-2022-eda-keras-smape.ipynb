{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS_Jan_2022(Time series)_EDA & Keras(SMAPE)📈\n\n**Reference: Kaggle's Time series course**\n* > I Acknowledge the notebook of AmbrosM, Fergus Findley,Luca Massaron, Samuel Cortinhas, Ruma and Rayan Holbrook.\n* > It was very helpful and useful. I am very grateful for all of you.I have learned a lot fron them!.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.004693Z","iopub.execute_input":"2022-01-30T03:20:20.006095Z","iopub.status.idle":"2022-01-30T03:20:20.023933Z","shell.execute_reply.started":"2022-01-30T03:20:20.006037Z","shell.execute_reply":"2022-01-30T03:20:20.022939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.026307Z","iopub.execute_input":"2022-01-30T03:20:20.027067Z","iopub.status.idle":"2022-01-30T03:20:20.087062Z","shell.execute_reply.started":"2022-01-30T03:20:20.027018Z","shell.execute_reply":"2022-01-30T03:20:20.086154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check(df):\n    col_list = df.columns.values\n    rows = []\n    for col in col_list:\n        tmp = (col,\n              train[col].dtype,\n              train[col].isnull().sum(),\n              train[col].count(),\n              train[col].nunique(),\n              train[col].unique())\n        rows.append(tmp)\n    df = pd.DataFrame(rows) \n    df.columns = ['feature','dtype','nan','count','nunique','unique']\n    return df\n\ncheck(train)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:20.089077Z","iopub.execute_input":"2022-01-30T03:20:20.089336Z","iopub.status.idle":"2022-01-30T03:20:20.161303Z","shell.execute_reply.started":"2022-01-30T03:20:20.089309Z","shell.execute_reply":"2022-01-30T03:20:20.16057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check(df):\n    col_list = df.columns.values\n    rows = []\n    for col in col_list:\n        tmp = (col,\n              test[col].dtype,\n              test[col].isnull().sum(),\n              test[col].count(),\n              test[col].nunique(),\n              test[col].unique())\n        rows.append(tmp)\n    df = pd.DataFrame(rows) \n    df.columns = ['feature','dtype','nan','count','nunique','unique']\n    return df\n\ncheck(test)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:20.16303Z","iopub.execute_input":"2022-01-30T03:20:20.163454Z","iopub.status.idle":"2022-01-30T03:20:20.198595Z","shell.execute_reply.started":"2022-01-30T03:20:20.163421Z","shell.execute_reply":"2022-01-30T03:20:20.197706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GDP\ngdp = pd.read_csv('/kaggle/input/gdp-data-2015-2019finnorswecsv/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\ngdp.set_index('year', inplace=True)\ngdp","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.200193Z","iopub.execute_input":"2022-01-30T03:20:20.200962Z","iopub.status.idle":"2022-01-30T03:20:20.215636Z","shell.execute_reply.started":"2022-01-30T03:20:20.200917Z","shell.execute_reply":"2022-01-30T03:20:20.215051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------\n# Occasional events (FI : Finland, NO : Norway, SE : Sweden)\n \n**New year🎉(1/1)**\n\n**Valentin's Day💘(2/14)**\n> *  FI: Friend's Day\n> *  NO: February 14 the same manner as in the Uk\n> *  SE: \"All Hearts'Day\" they are planning to buy presents for somone\n\n**Easter🐣(2015: 4/5, 2016: 3/27, 2017: 4/16, 2018: 4/1, 2019:4/21 )**\n> * First Sunday after the first full moon on or after 21 March \n> * Public Holidays  Good Friday, Easter Sunday and Easter Monday :Easter eggs, Easter Bunny,Easter Busket\n\n**Mother's Day💐**\n> * 2015 FI: 5/10(Sun), NO: 2/8(Sun), SE: 5/31(Sun)\n> * 2016 FI: 5/8(Sun), NO: 2/14(Sun), SE: 5/29(Sun)\n> * 2017 FI: 5/14(Sun), NO: 2/12(Sun), SE: 5/28(Sun)\n> * 2018 FI: 5/13(Sun), NO: 2/11(Sun), SE: 5/27(Sun)\n> * 2019 FI: 5/10(Sun), NO: 2/10(Sun), SE: 5/31(Sun)\n> * FI: The secopmd sunday in May, pick flowers\n> * NO: The second Sunday in februrary.family day, children make card and gifts\n> * SE: The last sunday in May, pick flowers\n\n**Midsummer's Days🌞**\n> * 2015 FI: 6/20(Sat), NO: 6/24(Wed), SE: 6/20(Sat)\n> * 2016 FI: 6/25(Sat), NO: 6/24(Fri), SE: 6/25(Sat)\n> * 2017 FI: 6/24(Sat), NO: 6/24(Sat), SE: 6/24(Sat)\n> * 2018 FI: 6/23(Sat), NO: 6/24(Sun), SE: 6/23(Sat)\n> * 2019 FI: 6/22(Sat), NO: 6/24(Mon), SE: 6/22(Sat)\n\n**Father's Day😎(2015: 11/8, 2016: 11/13, 2017: 11/12, 2018: 11/11, 2019: 11/10 )**\n> * The second sunday in November\n\n**Halloween🎃(10/31)**\n\n**Independence Day📅(FI:: 12/6, NO:: 6/7, SE:: 6/6)**\n\n**Christmas🎄(12/25)**\n\n**Election year📰(SE:: 2018: 9/9)**\n","metadata":{}},{"cell_type":"markdown","source":"------\n# Holidays(2019)","metadata":{}},{"cell_type":"code","source":"# DateTime\nfrom datetime import datetime, date, time\nimport holidays\nimport dateutil.easter as easter","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.21656Z","iopub.execute_input":"2022-01-30T03:20:20.216988Z","iopub.status.idle":"2022-01-30T03:20:20.221405Z","shell.execute_reply.started":"2022-01-30T03:20:20.216954Z","shell.execute_reply":"2022-01-30T03:20:20.220426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FI\nprint('**Finland**')\n#fin_holidays = holidays.Finland()\n#for ptr in holidays.Finland(years = 2019).items():\n    #print(ptr)\nfestivities1 = pd.read_csv(\"/kaggle/input/public-holidays-of-nordic-countries-tps-jan-22/Finlandholidays15_18.csv\")                     \nfestivities1[:60]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.222929Z","iopub.execute_input":"2022-01-30T03:20:20.223443Z","iopub.status.idle":"2022-01-30T03:20:20.256204Z","shell.execute_reply.started":"2022-01-30T03:20:20.223398Z","shell.execute_reply":"2022-01-30T03:20:20.255613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO\nprint('**Norway**')\n#nor_holidays = holidays.Norway()\n#for ptr in holidays.Norway(years = 2019).items():\n    #print(ptr)\n    \nfestivities2 = pd.read_csv(\"/kaggle/input/public-holidays-of-nordic-countries-tps-jan-22/Norwayholidays15_18.csv\")                       \nfestivities2[:48] ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.2571Z","iopub.execute_input":"2022-01-30T03:20:20.257608Z","iopub.status.idle":"2022-01-30T03:20:20.280236Z","shell.execute_reply.started":"2022-01-30T03:20:20.257572Z","shell.execute_reply":"2022-01-30T03:20:20.279434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SE\nprint('**Sweden**söndag = Sunday')\n#swe_holidays = holidays.Sweden()\n#for ptr in holidays.Sweden(years = 2019).items():\n    #print(ptr)\n    \nfestivities3 = pd.read_csv(\"/kaggle/input/public-holidays-of-nordic-countries-tps-jan-22/Swedenholidays15_18.csv\")\nfestivities3[:60]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.283224Z","iopub.execute_input":"2022-01-30T03:20:20.283454Z","iopub.status.idle":"2022-01-30T03:20:20.309533Z","shell.execute_reply.started":"2022-01-30T03:20:20.283426Z","shell.execute_reply":"2022-01-30T03:20:20.308618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"festivities3[60:65]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.310841Z","iopub.execute_input":"2022-01-30T03:20:20.31148Z","iopub.status.idle":"2022-01-30T03:20:20.323513Z","shell.execute_reply.started":"2022-01-30T03:20:20.311432Z","shell.execute_reply":"2022-01-30T03:20:20.322821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------\n# 📊Visualizations📈","metadata":{}},{"cell_type":"code","source":"# PLOT\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nimport seaborn as sns\n%matplotlib inline\n\nsns.set('notebook','darkgrid','Accent')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:20.324897Z","iopub.execute_input":"2022-01-30T03:20:20.32521Z","iopub.status.idle":"2022-01-30T03:20:20.336032Z","shell.execute_reply.started":"2022-01-30T03:20:20.325178Z","shell.execute_reply":"2022-01-30T03:20:20.335089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert date to datetime\ntrain.date=pd.to_datetime(train.date)\ntest.date=pd.to_datetime(test.date)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:20.338326Z","iopub.execute_input":"2022-01-30T03:20:20.338857Z","iopub.status.idle":"2022-01-30T03:20:20.3575Z","shell.execute_reply.started":"2022-01-30T03:20:20.338821Z","shell.execute_reply":"2022-01-30T03:20:20.356802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\naxs = sns.barplot(data = train, x =\"country\" , y =\"num_sold\")\naxs.bar_label(axs.containers[0])\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:20.360179Z","iopub.execute_input":"2022-01-30T03:20:20.360884Z","iopub.status.idle":"2022-01-30T03:20:20.909372Z","shell.execute_reply.started":"2022-01-30T03:20:20.360837Z","shell.execute_reply":"2022-01-30T03:20:20.908448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"axs = sns.barplot(data = train,  x =\"country\" , y =\"num_sold\" , hue =\"store\")\naxs.bar_label(axs.containers[0])\naxs.bar_label(axs.containers[1])\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:20.910577Z","iopub.execute_input":"2022-01-30T03:20:20.910832Z","iopub.status.idle":"2022-01-30T03:20:21.60585Z","shell.execute_reply.started":"2022-01-30T03:20:20.910801Z","shell.execute_reply":"2022-01-30T03:20:21.60496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"axs = sns.barplot(data = train, x =\"store\", y =\"num_sold\", hue =\"product\")\naxs.bar_label(axs.containers[0])\naxs.bar_label(axs.containers[1])\naxs.bar_label(axs.containers[2])\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:21.609129Z","iopub.execute_input":"2022-01-30T03:20:21.609352Z","iopub.status.idle":"2022-01-30T03:20:22.347127Z","shell.execute_reply.started":"2022-01-30T03:20:21.609325Z","shell.execute_reply":"2022-01-30T03:20:22.346098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.lineplot(data = gdp,)\nplt.title('GDP')\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:22.348599Z","iopub.execute_input":"2022-01-30T03:20:22.349055Z","iopub.status.idle":"2022-01-30T03:20:22.813183Z","shell.execute_reply.started":"2022-01-30T03:20:22.34902Z","shell.execute_reply":"2022-01-30T03:20:22.812332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rc(\"figure\", autolayout=True, figsize=(24, 10))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,)\n\nsns.set('notebook','whitegrid','Accent',font_scale = 1.5)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:22.814434Z","iopub.execute_input":"2022-01-30T03:20:22.814639Z","iopub.status.idle":"2022-01-30T03:20:22.821642Z","shell.execute_reply.started":"2022-01-30T03:20:22.814612Z","shell.execute_reply":"2022-01-30T03:20:22.820715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Num_sold \nstore = train.groupby(['date','store']).agg(num_sold = ('num_sold','sum'))\nsns.lineplot(data = store, x ='date', y ='num_sold', hue ='store')\nplt.title('Num_sold')\n\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:22.823117Z","iopub.execute_input":"2022-01-30T03:20:22.823496Z","iopub.status.idle":"2022-01-30T03:20:23.842669Z","shell.execute_reply.started":"2022-01-30T03:20:22.823445Z","shell.execute_reply":"2022-01-30T03:20:23.841791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# country\nfig, axes = plt.subplots(2, 1, figsize = (24,18))\n\nKM = train[train.store =='KaggleMart']\nKR = train[train.store =='KaggleRama']\n\ncsm = KM.groupby(['date','country']).agg(num_sold = ('num_sold','sum'))\ncsr = KR.groupby(['date','country']).agg(num_sold = ('num_sold','sum'))\n\nax1 = sns.lineplot(ax = axes[0], data = csm, x ='date', y ='num_sold', hue ='country')\nax2 = sns.lineplot(ax = axes[1], data =csr, x ='date', y ='num_sold', hue ='country')\n\nax1.title.set_text('KaggleMart')\nax2.title.set_text('KaggleRama')\n\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:23.84408Z","iopub.execute_input":"2022-01-30T03:20:23.844762Z","iopub.status.idle":"2022-01-30T03:20:26.515629Z","shell.execute_reply.started":"2022-01-30T03:20:23.844727Z","shell.execute_reply":"2022-01-30T03:20:26.514775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# product \nfig, axes = plt.subplots(6, 1, figsize = (24,52))\n\n# Finland\nf1 = pd.DataFrame(train[(train[\"country\"] == \"Finland\") & (train[\"store\"] == \"KaggleMart\")])\nax1 = sns.lineplot(ax = axes[0], data = f1 , x =\"date\", y =\"num_sold\", hue =\"product\")\nf2 = pd.DataFrame(train[(train[\"country\"] == \"Finland\") & (train[\"store\"] == \"KaggleRama\")])\nax2 = sns.lineplot(ax = axes[1], data = f2 , x =\"date\", y =\"num_sold\", hue =\"product\")\n\n# Norway\nn1 = pd.DataFrame(train[(train[\"country\"] == \"Norway\") & (train[\"store\"] == \"KaggleMart\")])\nax3 = sns.lineplot(ax = axes[2], data = n1, x =\"date\", y =\"num_sold\", hue =\"product\")\nn2 = pd.DataFrame(train[(train[\"country\"] == \"Norway\") & (train[\"store\"] == \"KaggleRama\")])\nax4 = sns.lineplot(ax = axes[3], data = n2, x =\"date\", y =\"num_sold\", hue =\"product\")\n\n# Sweden\ns1 = pd.DataFrame(train[(train[\"country\"] == \"Sweden\") & (train[\"store\"] == \"KaggleMart\")])\nax5 = sns.lineplot(ax = axes[4], data = s1, x =\"date\", y =\"num_sold\", hue =\"product\")\ns2 = pd.DataFrame(train[(train[\"country\"] == \"Sweden\") & (train[\"store\"] == \"KaggleRama\")])\nax6 = sns.lineplot(ax = axes[5], data = s2, x =\"date\", y =\"num_sold\", hue =\"product\")\n\nax1.title.set_text('Finland KaggleMart')\nax2.title.set_text('Finland KaggleRama')\nax3.title.set_text('Norway KaggleMart')\nax4.title.set_text('Norway KaggleRama')\nax5.title.set_text('Sweden KaggleMart')\nax6.title.set_text('Sweden KaggleRama')\n\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:26.517006Z","iopub.execute_input":"2022-01-30T03:20:26.517228Z","iopub.status.idle":"2022-01-30T03:20:31.645173Z","shell.execute_reply.started":"2022-01-30T03:20:26.517202Z","shell.execute_reply":"2022-01-30T03:20:31.644109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_time(df):\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['week'] = df['date'].dt.isocalendar().week\n    df['week'][df['week']>52] = 52\n    df['day'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['dayofyear'] = df['date'].dt.dayofyear\n    return df\n\ntrain = process_time(train)\ntest = process_time(test)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:31.646404Z","iopub.execute_input":"2022-01-30T03:20:31.64662Z","iopub.status.idle":"2022-01-30T03:20:31.70744Z","shell.execute_reply.started":"2022-01-30T03:20:31.646593Z","shell.execute_reply":"2022-01-30T03:20:31.706728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set('notebook','darkgrid',font_scale = 1.5)\n\nfor product in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n    fig = plt.figure(figsize=(24, 14), dpi=100)\n    fig.subplots_adjust(hspace=0.25)\n    for i, store in enumerate(['KaggleMart', 'KaggleRama']):\n        for j, country in enumerate(['Finland', 'Norway', 'Sweden']):\n            ax = fig.add_subplot(2, 3, (i*3+j+1))\n            selection = (train['country']==country)&(train['store']==store)&(train['product']==product)\n            selected = train[selection]\n            for year in [2015, 2016, 2017, 2018]:\n                selected[selected.year==year].set_index('date').groupby('month')['num_sold'].mean().plot(ax=ax, label=year)\n            ax.set_title(f\"{product} | {country}:{store}\")\n            ax.legend()\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:31.708674Z","iopub.execute_input":"2022-01-30T03:20:31.709107Z","iopub.status.idle":"2022-01-30T03:20:38.086758Z","shell.execute_reply.started":"2022-01-30T03:20:31.709071Z","shell.execute_reply":"2022-01-30T03:20:38.085791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for product in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n    print(f\"\\n--- {product} ---\\n\")\n    fig = plt.figure(figsize=(24, 14), dpi=100)\n    fig.subplots_adjust(hspace=0.25)\n    for i, store in enumerate(['KaggleMart', 'KaggleRama']):\n        for j, country in enumerate(['Finland', 'Norway', 'Sweden']):\n            ax = fig.add_subplot(2, 3, (i*3+j+1))\n            selection = (train['country']==country)&(train['store']==store)&(train['product']==product)\n            selected = train[selection]\n            for year in [2015, 2016, 2017, 2018]:\n                selected[selected.year==year].set_index('date').groupby('dayofweek')['num_sold'].sum().plot(ax=ax, label=year)\n            ax.set_title(f\"{country}:{store}\")\n            ax.legend()\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:38.088109Z","iopub.execute_input":"2022-01-30T03:20:38.088334Z","iopub.status.idle":"2022-01-30T03:20:44.112838Z","shell.execute_reply.started":"2022-01-30T03:20:38.088307Z","shell.execute_reply":"2022-01-30T03:20:44.11198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Kaggle hat > Kaggle Mug > Kaggle Sticker\n* Kaggle Rama > Kaggle Mart\n* Norway > Sweden > Finland\n* These Graph shows the waves pattern.\n* December(Holiday season) > April(Easter) > other (The end of October : Halloween,November : Father's day etc.)\n* Weekend > Friday > weekday\n\n----\n\n#  Feature engineering and Modeling⚙","metadata":{}},{"cell_type":"code","source":"import math\nimport statistics\nimport pickle\nimport gc\n\nfrom itertools import combinations\nimport itertools\n\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom matplotlib.lines import Line2D\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import GroupKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Add\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:44.117695Z","iopub.execute_input":"2022-01-30T03:20:44.118378Z","iopub.status.idle":"2022-01-30T03:20:44.12776Z","shell.execute_reply.started":"2022-01-30T03:20:44.118334Z","shell.execute_reply":"2022-01-30T03:20:44.126781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\ndef plot_history(history, *, n_epochs = None, plot_lr = False, plot_acc = True, title = None, bottom = None, top = None):\n    \"\"\"Plot (the last unique n_epochs epochs of) the training history\"\"\"\n    plt.figure(figsize=(15, 8))\n    from_epoch = 0 if n_epochs is None else len(history['loss']) - n_epochs\n    \n    # Plot training and validation losses\n    plt.plot(np.arange(from_epoch, len(history['loss'])), history['loss'][from_epoch:], label ='Training loss')\n    try:\n        plt.plot(np.arange(from_epoch, len(history['loss'])), history['val_loss'][from_epoch:], label ='Validation loss')\n        best_epoch = np.argmin(np.array(history['val_loss']))\n        best_val_loss = history['val_loss'][best_epoch]\n        if best_epoch >= from_epoch:\n            plt.scatter([best_epoch], [best_val_loss], c ='r', label = f'Best val_loss = {best_val_loss:.5f}')\n        if best_epoch > 0:\n            almost_epoch = np.argmin(np.array(history['val_loss'])[:best_epoch])\n            almost_val_loss = history['val_loss'][almost_epoch]\n            if almost_epoch >= from_epoch:\n                plt.scatter([almost_epoch], [almost_val_loss], c ='orange', label ='Second best val_loss')\n    except KeyError:\n        pass\n    if bottom is not None: plt.ylim(bottom = bottom)\n    if top is not None: plt.ylim(top = top)\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer = True))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower left')\n    if title is not None: plt.title(title)\n        \n    # Plot learning rate\n    if plot_lr and 'lr' in history:\n        ax2 = plt.gca().twinx()\n        ax2.plot(np.arange(from_epoch, len(history['lr'])), np.array(history['lr'][from_epoch:]), color ='g', label ='Learning rate')\n        ax2.set_ylabel('Learning rate')\n        ax2.legend(loc='upper right')\n        \n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:44.1292Z","iopub.execute_input":"2022-01-30T03:20:44.129499Z","iopub.status.idle":"2022-01-30T03:20:44.147934Z","shell.execute_reply.started":"2022-01-30T03:20:44.129452Z","shell.execute_reply":"2022-01-30T03:20:44.14704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return tf.abs(y_true - y_pred) / (y_true + tf.abs(y_pred)) * 200","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:44.14948Z","iopub.execute_input":"2022-01-30T03:20:44.149993Z","iopub.status.idle":"2022-01-30T03:20:44.163125Z","shell.execute_reply.started":"2022-01-30T03:20:44.149939Z","shell.execute_reply":"2022-01-30T03:20:44.162371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SMAPE(Symmetric mean absolute percentage error) : an accuracy measure based on percentage errors.**","metadata":{}},{"cell_type":"code","source":"train_d = train.copy()\ntest_d = test.copy()\n\nfor df in [train_d, test_d]:\n    df['date'] = pd.to_datetime(df.date)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:44.164782Z","iopub.execute_input":"2022-01-30T03:20:44.165371Z","iopub.status.idle":"2022-01-30T03:20:44.204685Z","shell.execute_reply.started":"2022-01-30T03:20:44.165327Z","shell.execute_reply":"2022-01-30T03:20:44.203457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\ndef feature_e(df):\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp.loc[row.date.year, country]\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis = 1)),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    dayofyear = df.date.dt.dayofyear\n    \n    for k in range(1, 3):\n        new_df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Hat']\n        \n        \n    # End and new year\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) &\n                                      (df.country == 'Norway')\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & \n                                      (df.country == 'Finland')\n                                      for d in range(1, 14)}),\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) &\n                                      (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & \n                                      (df.country == 'Sweden')\n                                      for d in range(1, 15)})], axis=1)    \n     \n    # valentain's day & Mother's day(Norway)\n    # new_df = pd.concat([new_df,\n                       # pd.DataFrame({f\"feb{d}\":\n                                      #(df.date.dt.month == 2) & (df.date.dt.day == d) \n                                      #for d in list(range(1, 15))})],axis=1)\n                \n    #  May( mother's day etc.)  \n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\": \n                                     (df.date.dt.month == 5) & (df.date.dt.day == d)\n                                      for d in list(range(1, 10))}),\n    \n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(18, 28))})], axis=1)\n                                     \n    \n    \n    # June and July (mid_summer)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"june{d}\":\n                                     (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))}),], axis=1)\n    \n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))})], axis=1)\n    \n    \n     # First Sunday of November( second sunday: father's day)\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})], axis=1)\n    \n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))})], axis=1)\n             \n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})],axis=1)\n        \n    return new_df.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:44.207675Z","iopub.execute_input":"2022-01-30T03:20:44.20831Z","iopub.status.idle":"2022-01-30T03:20:44.244416Z","shell.execute_reply.started":"2022-01-30T03:20:44.208268Z","shell.execute_reply":"2022-01-30T03:20:44.243777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = feature_e(train_d)\ntrain['date'] = train_d.date\ntrain['num_sold'] = train_d.num_sold.astype(np.float32)\n\ntest = feature_e(test_d)\n\nfeatures = list(test.columns)\nprint(list(features))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-30T03:20:44.245909Z","iopub.execute_input":"2022-01-30T03:20:44.246208Z","iopub.status.idle":"2022-01-30T03:20:47.834403Z","shell.execute_reply.started":"2022-01-30T03:20:44.246168Z","shell.execute_reply":"2022-01-30T03:20:47.833447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:47.836179Z","iopub.execute_input":"2022-01-30T03:20:47.836816Z","iopub.status.idle":"2022-01-30T03:20:47.868437Z","shell.execute_reply.started":"2022-01-30T03:20:47.836755Z","shell.execute_reply":"2022-01-30T03:20:47.867562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1000 # increase the number of epochs if the training curve indicates that a better result is possible\nEPOCHS_COSINEDECAY = 120\nVERBOSE = 0 \nRUNS = 1 \nDIAGRAMS = True\nUSE_PLATEAU = True\nINFERENCE = False","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:47.869785Z","iopub.execute_input":"2022-01-30T03:20:47.87066Z","iopub.status.idle":"2022-01-30T03:20:47.876481Z","shell.execute_reply.started":"2022-01-30T03:20:47.870615Z","shell.execute_reply":"2022-01-30T03:20:47.875447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wd_features = [f for f in features if f.startswith('wd')]\nother_features = [f for f in features if f not in wd_features]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:47.878169Z","iopub.execute_input":"2022-01-30T03:20:47.878646Z","iopub.status.idle":"2022-01-30T03:20:47.889143Z","shell.execute_reply.started":"2022-01-30T03:20:47.878603Z","shell.execute_reply":"2022-01-30T03:20:47.888474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jan_model():\n    \"\"\"Linear model with flexible regularization\n    \n    The model is to be used with a log-transformed target.\n    \"\"\"\n    wd = Input(shape = (len(wd_features), ))\n    other = Input(shape = (len(other_features), ))\n    wd_contribution = Dense(1, use_bias = False)(wd) # no regularization\n    other_contribution = Dense(1, kernel_regularizer = tf.keras.regularizers.l2(1e-10),\n                               use_bias = True,\n                               bias_initializer = tf.keras.initializers.Constant(value = 5.7))(other)\n    output = Add()([wd_contribution, other_contribution])\n    model = Model([wd, other], output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:47.890808Z","iopub.execute_input":"2022-01-30T03:20:47.891448Z","iopub.status.idle":"2022-01-30T03:20:47.901608Z","shell.execute_reply.started":"2022-01-30T03:20:47.891401Z","shell.execute_reply":"2022-01-30T03:20:47.900825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_model(X_train, X_valid = None):\n    \"\"\"Scale the data, fit a model, plot the training history and validate the model\"\"\"\n\n    # Preprocess the data (select columns and scale)\n    preproc = StandardScaler()\n    X_train_f = pd.DataFrame(preproc.fit_transform(X_train[features]), columns = features, index = X_train.index)\n    y_train = X_train.num_sold.values.reshape(-1, 1)\n\n    if X_valid is not None:\n        # Preprocess the validation data\n        X_valid_f = pd.DataFrame(preproc.transform(X_valid[features]), columns = features, index = X_valid.index)\n        y_valid = X_valid.num_sold.values.reshape(-1, 1)\n        validation_data = ([X_valid_f[wd_features], X_valid_f[other_features]], np.log(y_valid))\n    else:\n        validation_data = None\n        \n    # Define the learning rate schedule and EarlyStopping\n    if USE_PLATEAU and X_valid is not None:\n        epochs = EPOCHS\n        lr = ReduceLROnPlateau(monitor =\"val_loss\", factor = 0.75, \n                               patience = 4, verbose = VERBOSE)\n        es = EarlyStopping(monitor =\"val_loss\",\n                           patience = 25, \n                           verbose = 1,\n                           mode =\"min\", \n                           restore_best_weights = True)\n        callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n\n    else:\n        epochs = EPOCHS_COSINEDECAY\n        lr_start = 0.01\n        lr_end = 0.00001\n        def cosine_decay(epoch):\n            if epochs > 1:\n                w = (1 + math.cos(epoch / (epochs - 1) * math.pi)) / 2\n            else:\n                w = 1\n            return w * lr_start + (1 - w) * lr_end\n        \n        lr = LearningRateScheduler(cosine_decay, verbose = 0)\n        callbacks = [lr, tf.keras.callbacks.TerminateOnNaN()]\n\n    # Construct and compile the model\n    model = jan_model()\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01), loss ='mse')\n    \n     # Train the model\n    history = model.fit([X_train_f[wd_features], X_train_f[other_features], ], np.log(y_train), \n                        validation_data = validation_data, \n                        epochs = epochs,\n                        verbose = VERBOSE,\n                        batch_size = 512,\n                        shuffle = True,\n                        callbacks = callbacks)\n\n    history_list.append(history.history)\n    callbacks, es, lr, history = None, None, None, None\n    \n    if X_valid is not None:\n        # Inference for validation\n        y_valid_pred = np.exp(model.predict([X_valid_f[wd_features], X_valid_f[other_features]]))\n        oof[run][valid_idx] = y_valid_pred\n        \n        # Evaluation: Execution time and SMAPE\n        smape = np.mean(smape_loss(y_valid, y_valid_pred))\n        score.append(smape)\n        \n        if DIAGRAMS and fold == 0 and run == 0:\n         # Plot training history\n            plot_history(history_list[-1], title=f\"Validation SMAPE = {smape:.5f}\", plot_lr = True)\n\n            # Plot y_true vs. y_pred\n            plt.figure(figsize = (10, 10))\n            plt.scatter(y_valid, y_valid_pred, s=1, color='r')\n            plt.plot([plt.xlim()[0], plt.xlim()[1]], [plt.xlim()[0], plt.xlim()[1]], '--', color = 'k')\n            plt.gca().set_aspect('equal')\n            plt.xlabel('y_true')\n            plt.ylabel('y_pred')\n            plt.title('OOF Predictions')\n            plt.show()\n\n    return preproc, model","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:47.903286Z","iopub.execute_input":"2022-01-30T03:20:47.903809Z","iopub.status.idle":"2022-01-30T03:20:47.927532Z","shell.execute_reply.started":"2022-01-30T03:20:47.903776Z","shell.execute_reply":"2022-01-30T03:20:47.926698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(2022) # 42 change the seed \n\nhistory_list, score, test_pred = [], [], []\noof = [np.full((len(train), 1), -1.0, dtype='float32') for run in range(RUNS)]\n\nfor run in range(RUNS):\n    preproc, model = None, None\n    kf = GroupKFold(n_splits = 4)\n    \n    for fold, (train_idx, valid_idx) in enumerate(kf.split(train, groups = train.date.dt.year)):\n        X_train = train.iloc[train_idx]\n        X_valid = train.iloc[valid_idx]\n        print(f\"Fold {run}.{fold}\")\n        \n        preproc, model = fit_model(X_train, X_valid)\n        if INFERENCE:\n            test_f = pd.DataFrame(preproc.transform(test[features]), columns = features, index = test.index)\n            test_pred.append(np.exp(model.predict([test_f[wd_features], test_f[other_features]])))\n\n            ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:20:47.928796Z","iopub.execute_input":"2022-01-30T03:20:47.929512Z","iopub.status.idle":"2022-01-30T03:21:31.26965Z","shell.execute_reply.started":"2022-01-30T03:20:47.929456Z","shell.execute_reply":"2022-01-30T03:21:31.268727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"            \nprint(f\"Average SMAPE: {sum(score) / len(score):.5f}\") # Average over all runs and folds\n\nwith open('oof.pickle', 'wb') as handle: pickle.dump(oof, handle) # for further analysis\n    \nif RUNS > 1:\n    y_valid = train.num_sold\n    print(f\"Ensemble SMAPE: {np.mean(smape_loss(y_valid, sum(oof).ravel() / len(oof))):.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:21:31.270997Z","iopub.execute_input":"2022-01-30T03:21:31.271302Z","iopub.status.idle":"2022-01-30T03:21:31.279483Z","shell.execute_reply.started":"2022-01-30T03:21:31.27126Z","shell.execute_reply":"2022-01-30T03:21:31.278564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Retrain the network on the full training data several times\nRETRAIN_RUNS = 20\n\nif RETRAIN_RUNS > 0:\n   \n    test_pred = []\n    for run in range(RETRAIN_RUNS):\n        preproc, model = None, None\n        print(f\"Retraining {run}\")\n        \n        preproc, model = fit_model(train)\n        print(f\"Loss:            {history_list[-1]['loss'][-1]:.6f}\")\n        \n        test_f = pd.DataFrame(preproc.transform(test[features]), columns = features, index = test.index)\n        test_pred.append(np.exp(model.predict([test_f[wd_features], test_f[other_features]])))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-30T03:21:31.281094Z","iopub.execute_input":"2022-01-30T03:21:31.281385Z","iopub.status.idle":"2022-01-30T03:24:47.974859Z","shell.execute_reply.started":"2022-01-30T03:21:31.281345Z","shell.execute_reply":"2022-01-30T03:24:47.973887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import ceil, floor, sqrt\n# from https://www.kaggle.com/fergusfindley/ensembling-and-rounding-techniques-comparison\ndef geometric_round(arr):\n    result_array = arr\n    result_array = np.where(result_array < np.sqrt(np.floor(arr)*np.ceil(arr)), np.floor(arr), result_array)\n    result_array = np.where(result_array >= np.sqrt(np.floor(arr)*np.ceil(arr)), np.ceil(arr), result_array)\n\n    return result_array","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:24:47.976184Z","iopub.execute_input":"2022-01-30T03:24:47.97645Z","iopub.status.idle":"2022-01-30T03:24:47.983218Z","shell.execute_reply.started":"2022-01-30T03:24:47.976407Z","shell.execute_reply":"2022-01-30T03:24:47.982268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the submission file\nsub = test_d[['row_id']].copy()\nsub['num_sold'] = sum(test_pred) / len(test_pred)\n    \nsub['num_sold'] = geometric_round( sub['num_sold']).astype(int) \nsub.to_csv('submission.csv', index = False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-01-30T03:24:47.984678Z","iopub.execute_input":"2022-01-30T03:24:47.985102Z","iopub.status.idle":"2022-01-30T03:24:48.024065Z","shell.execute_reply.started":"2022-01-30T03:24:47.985057Z","shell.execute_reply":"2022-01-30T03:24:48.023032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of the test predictions\n\nplt.figure(figsize = (16, 8))\nplt.hist(train['num_sold'], bins = np.linspace(0, 3000, 201), density = True, label ='Training')\nplt.hist(sub['num_sold'], bins = np.linspace(0, 3000, 201), density = True, rwidth = 0.5, label= 'Test predictions')\nplt.xlabel('num_sold')\nplt.ylabel('Frequency')\nplt.title(\"the distribution of the test predictions\")\nplt.legend()\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:24:48.025469Z","iopub.execute_input":"2022-01-30T03:24:48.025887Z","iopub.status.idle":"2022-01-30T03:24:49.37364Z","shell.execute_reply.started":"2022-01-30T03:24:48.025842Z","shell.execute_reply":"2022-01-30T03:24:49.372855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_five_years(feature_e, S,P,C, series ):\n\n    demo = pd.DataFrame({'row_id': 0,\n                            'date': pd.date_range('2015-01-01', '2019-12-31', freq='D'),\n                            'country': C,\n                            'store': S,\n                            'product': P})\n    demo.set_index('date', inplace=True, drop=False)\n    demo = feature_e(demo)\n    demo_f = pd.DataFrame(preproc.transform(demo[features]), columns = features, index = demo.index)\n    demo['num_sold'] = np.exp(model.predict([demo_f[wd_features], demo_f[other_features]]))\n    \n    plt.figure(figsize=(20, 8))\n    plt.plot(np.arange(len(demo)), demo.num_sold, label ='prediction')\n    train_subset = train[(train_d.country == C) & (train_d.store == S) & (train_d['product'] == P)]\n    plt.scatter(np.arange(len(train_subset)), train_subset.num_sold, label ='true', alpha = 0.5, color ='red', s = 3)\n    \n    plot_index = test_d[(test_d.store == S) & (test_d.country == C) & (test_d['product'] == P)].index\n    pred_subset = series[series.row_id.isin(plot_index)].reset_index(drop = True)\n   \n    \n    n1 = len(train_subset['num_sold'])\n    n2 = len(pred_subset['num_sold'])\n    \n    plt.plot(np.arange(n1,n1 + n2),pred_subset['num_sold'], label ='Predictions')\n\n    plt.xlabel('Days since 2015-01-01')\n    plt.ylabel('num_sold')\n    \n    plt.legend()\n    plt.title('Predictions and true num_sold for five years by ' + S +' : '+ P + ' : ' + C)\n    plt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:24:49.374875Z","iopub.execute_input":"2022-01-30T03:24:49.375187Z","iopub.status.idle":"2022-01-30T03:24:49.388154Z","shell.execute_reply.started":"2022-01-30T03:24:49.375156Z","shell.execute_reply":"2022-01-30T03:24:49.387463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trend = pd.DataFrame({'row_id': test_d.index, 'num_sold': sub['num_sold']})\n\nfor S in ['KaggleMart','KaggleRama']:\n    print(f\"\\n--- {S} ---\\n\")\n    for P in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n        for C in ['Finland', 'Norway', 'Sweden']:\n            plot_five_years(feature_e, S, P, C, series = trend)\n            ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-30T03:24:49.389202Z","iopub.execute_input":"2022-01-30T03:24:49.389825Z","iopub.status.idle":"2022-01-30T03:25:06.509043Z","shell.execute_reply.started":"2022-01-30T03:24:49.389791Z","shell.execute_reply":"2022-01-30T03:25:06.508456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thank you for reading!**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}