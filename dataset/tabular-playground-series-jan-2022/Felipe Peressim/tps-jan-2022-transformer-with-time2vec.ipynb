{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T23:41:54.690394Z","iopub.execute_input":"2022-01-24T23:41:54.69068Z","iopub.status.idle":"2022-01-24T23:41:54.700451Z","shell.execute_reply.started":"2022-01-24T23:41:54.690647Z","shell.execute_reply":"2022-01-24T23:41:54.69951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport gc\nimport tensorflow as tf\nimport holidays\n\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:41:54.717592Z","iopub.execute_input":"2022-01-24T23:41:54.71819Z","iopub.status.idle":"2022-01-24T23:42:01.66003Z","shell.execute_reply.started":"2022-01-24T23:41:54.71814Z","shell.execute_reply":"2022-01-24T23:42:01.659095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer with TIME2VEC\n\nHere I tried a transformer model with almost nothing of preprocessing on the data. The results aren't that good yet, so next time\nI am going do some feature engineering, like adding information extracted from the dates, like holidays, weekends and month of the year for instance.","metadata":{}},{"cell_type":"code","source":"def smape(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    num = tf.math.abs(tf.math.subtract(y_true, y_pred))\n    denom = tf.math.add(tf.math.abs(y_true), tf.math.abs(y_pred))\n    denom = tf.math.divide(denom,200.0)\n    \n    val = tf.math.divide(num,denom)\n    val = tf.where(denom == 0.0, 0.0, val) \n    return tf.reduce_mean(val)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.661459Z","iopub.execute_input":"2022-01-24T23:42:01.661685Z","iopub.status.idle":"2022-01-24T23:42:01.667554Z","shell.execute_reply.started":"2022-01-24T23:42:01.661657Z","shell.execute_reply":"2022-01-24T23:42:01.666843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_sequences(sequences, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequences)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the dataset\n\t\tif end_ix > len(sequences):\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn np.array(X), np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.668453Z","iopub.execute_input":"2022-01-24T23:42:01.669305Z","iopub.status.idle":"2022-01-24T23:42:01.689418Z","shell.execute_reply.started":"2022-01-24T23:42:01.669267Z","shell.execute_reply":"2022-01-24T23:42:01.688388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Time2Vector(tf.keras.layers.Layer):\n    def __init__(self, seq_len, **kwargs):\n        super(Time2Vector, self).__init__()\n        self.seq_len = seq_len\n\n    def build(self, input_shape):\n        self.weights_linear = self.add_weight(name='weight_linear',\n                                    shape=(int(self.seq_len),),\n                                    initializer='uniform',\n                                    trainable=True)\n\n        self.bias_linear = self.add_weight(name='bias_linear',\n                                    shape=(int(self.seq_len),),\n                                    initializer='uniform',\n                                    trainable=True)\n\n        self.weights_periodic = self.add_weight(name='weight_periodic',\n                                    shape=(int(self.seq_len),),\n                                    initializer='uniform',\n                                    trainable=True)\n\n        self.bias_periodic = self.add_weight(name='bias_periodic',\n                                    shape=(int(self.seq_len),),\n                                    initializer='uniform',\n                                    trainable=True)\n\n    def call(self, x):\n        x = tf.math.reduce_mean(x[:,:,:], axis=-1) # Convert (batch, seq_len, 5) to (batch, seq_len)\n        time_linear = self.weights_linear * x + self.bias_linear\n        time_linear = tf.expand_dims(time_linear, axis=-1) # (batch, seq_len, 1)\n        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n        time_periodic = tf.expand_dims(time_periodic, axis=-1) # (batch, seq_len, 1)\n        return tf.concat([time_linear, time_periodic], axis=-1) # (batch, seq_len, 2","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.691661Z","iopub.execute_input":"2022-01-24T23:42:01.692276Z","iopub.status.idle":"2022-01-24T23:42:01.701807Z","shell.execute_reply.started":"2022-01-24T23:42:01.692242Z","shell.execute_reply":"2022-01-24T23:42:01.701117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n        super().__init__()\n        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.attn(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n\n\nclass Transformer(keras.Model):\n    def __init__(\n            self,\n            num_hid=64, # embed_dim - num of features\n            time_steps=7,\n            num_head = 2,\n            num_feed_forward=128, # pointwise dim\n            num_layers_enc = 4,\n            time_embedding = False,\n    ):\n        super().__init__()\n        self.num_hid = num_hid\n        if time_embedding:\n            self.num_hid += 2\n            self.tv = Time2Vector(time_steps)\n        else:\n            self.tv = None\n        self.numlayers_enc = num_layers_enc\n        self.enc_input = layers.Input((time_steps, self.num_hid))\n        self.encoder = keras.Sequential(\n            [self.enc_input]\n            + [\n                TransformerEncoder(self.num_hid, num_head, num_feed_forward)\n                for _ in range(num_layers_enc)\n            ]\n        )\n        self.GlobalAveragePooling1D = layers.GlobalAveragePooling1D(data_format='channels_last')\n        self.out = layers.Dense(units=1, activation='linear')        \n        self.concat = tf.keras.layers.Concatenate(axis=-1)\n        \n    def call(self, inputs):\n        if self.tv:\n            x = self.tv(inputs)\n            x = self.concat([inputs, x])\n            x = self.encoder(x)\n        else:\n            x = self.encoder(inputs)\n        x = self.GlobalAveragePooling1D(x)\n        y = self.out(x)\n        return y","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.703188Z","iopub.execute_input":"2022-01-24T23:42:01.703656Z","iopub.status.idle":"2022-01-24T23:42:01.718999Z","shell.execute_reply.started":"2022-01-24T23:42:01.703615Z","shell.execute_reply":"2022-01-24T23:42:01.717722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(df):\n    country = {c : i for i, c in enumerate(df['country'].unique())}\n    store = {s : i for i, s in enumerate(df['store'].unique())}\n    product = {p : i for i, p in enumerate(df['product'].unique())}\n    df = df.copy()\n    df['country'] = df['country'].replace(country)\n    df['store'] = df['store'].replace(store)\n    df['product'] = df['product'].replace(product)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.720399Z","iopub.execute_input":"2022-01-24T23:42:01.720793Z","iopub.status.idle":"2022-01-24T23:42:01.732917Z","shell.execute_reply.started":"2022-01-24T23:42:01.72075Z","shell.execute_reply":"2022-01-24T23:42:01.732019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\ndef preprocess_dates(df):\n    df = df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    df['weekday'] = df['date'].dt.weekday\n    df['quarter'] = df['date'].dt.quarter\n    df['day_of_year'] = df['date'].dt.day_of_year\n    df['is_month_start'] = df['date'].dt.is_month_start.astype(\"int8\")\n    df['is_month_end'] = df['date'].dt.is_month_end.astype(\"int8\")\n    df['month'] = df['date'].dt.month\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.733932Z","iopub.execute_input":"2022-01-24T23:42:01.735801Z","iopub.status.idle":"2022-01-24T23:42:01.747817Z","shell.execute_reply.started":"2022-01-24T23:42:01.735752Z","shell.execute_reply":"2022-01-24T23:42:01.746952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_holidays(df):\n    holiday_finland = holidays.CountryHoliday(country='FI', years=[2015, 2016, 2017, 2018, 2019])\n    holiday_norway = holidays.CountryHoliday(country='NO', years=[2015, 2016, 2017, 2018, 2019])\n    holiday_sweden = holidays.CountryHoliday(country='SE', years=[2015, 2016, 2017, 2018, 2019])\n    holidays_fin_nor_swe = holiday_finland.copy()\n    holidays_fin_nor_swe.update(holiday_norway)\n    holidays_fin_nor_swe.update(holiday_sweden)\n    dates = list(holidays_fin_nor_swe.keys())\n    dates = sorted(pd.to_datetime(dates))\n    df = df.copy()\n    df['is_holiday'] = df['date'].apply(lambda x : 1 if x in dates else 0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.749335Z","iopub.execute_input":"2022-01-24T23:42:01.74993Z","iopub.status.idle":"2022-01-24T23:42:01.758569Z","shell.execute_reply.started":"2022-01-24T23:42:01.749885Z","shell.execute_reply":"2022-01-24T23:42:01.757892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_timeseries(df):\n    df = df.copy()\n    df['sin_day_of_year'] = np.sin(df['day_of_year'])\n    df['sin_month'] = np.sin(df['month'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.759751Z","iopub.execute_input":"2022-01-24T23:42:01.760097Z","iopub.status.idle":"2022-01-24T23:42:01.767642Z","shell.execute_reply.started":"2022-01-24T23:42:01.760066Z","shell.execute_reply":"2022-01-24T23:42:01.766751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 47\nTIMESTEPS = 1\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.769744Z","iopub.execute_input":"2022-01-24T23:42:01.770123Z","iopub.status.idle":"2022-01-24T23:42:01.776991Z","shell.execute_reply.started":"2022-01-24T23:42:01.770094Z","shell.execute_reply":"2022-01-24T23:42:01.776374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jan-2022/train.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:01.778088Z","iopub.execute_input":"2022-01-24T23:42:01.778385Z","iopub.status.idle":"2022-01-24T23:42:01.833423Z","shell.execute_reply.started":"2022-01-24T23:42:01.778359Z","shell.execute_reply":"2022-01-24T23:42:01.832764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"train_df = label_encoder(train_df)\ntrain_df = preprocess_dates(train_df)\ntrain_df = preprocess_holidays(train_df)\ntrain_df = preprocess_timeseries(train_df)\nx_train = train_df.drop(['row_id', 'date', 'num_sold'], axis=1)\ny_train = train_df['num_sold']\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=seed, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:02.435178Z","iopub.execute_input":"2022-01-24T23:42:02.435665Z","iopub.status.idle":"2022-01-24T23:42:02.984438Z","shell.execute_reply.started":"2022-01-24T23:42:02.435627Z","shell.execute_reply":"2022-01-24T23:42:02.983765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Converte the data to 3D array shape</h3>","metadata":{}},{"cell_type":"code","source":"x_train = np.append(x_train, y_train.values.reshape(-1, 1), axis=1)\nx_test = np.append(x_test, y_test.values.reshape(-1, 1), axis=1)\nx_train, y_train = split_sequences(x_train, TIMESTEPS)\nx_test, y_test = split_sequences(x_test, TIMESTEPS)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:02.986006Z","iopub.execute_input":"2022-01-24T23:42:02.986571Z","iopub.status.idle":"2022-01-24T23:42:03.032709Z","shell.execute_reply.started":"2022-01-24T23:42:02.986533Z","shell.execute_reply":"2022-01-24T23:42:03.031963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_heads=2\nnum_layers_enc=2\nnum_feed_forward=64\nnum_features = x_train.shape[-1]\ntime_steps = TIMESTEPS\nepochs = 100\nbatch_size = 128\n\nmodel = Transformer(num_hid=num_features,\n                        time_steps=time_steps,\n                        time_embedding=True,\n                        num_head=num_heads,\n                        num_layers_enc=num_layers_enc,\n                        num_feed_forward=num_feed_forward)\n\nopt = tf.keras.optimizers.Adam()\nloss = tf.keras.losses.mse\nmodel.compile(optimizer=opt, loss=smape)\nmodel.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\nprint()\nresults = model.evaluate(x_test, y_test)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:42:03.034044Z","iopub.execute_input":"2022-01-24T23:42:03.034267Z","iopub.status.idle":"2022-01-24T23:44:29.417022Z","shell.execute_reply.started":"2022-01-24T23:42:03.03424Z","shell.execute_reply":"2022-01-24T23:44:29.416235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"del train_df, x_train, y_train, x_test, y_test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:47:49.725711Z","iopub.execute_input":"2022-01-24T23:47:49.725986Z","iopub.status.idle":"2022-01-24T23:47:49.923886Z","shell.execute_reply.started":"2022-01-24T23:47:49.725958Z","shell.execute_reply":"2022-01-24T23:47:49.923292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jan-2022/test.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:47:50.003038Z","iopub.execute_input":"2022-01-24T23:47:50.003311Z","iopub.status.idle":"2022-01-24T23:47:50.031123Z","shell.execute_reply.started":"2022-01-24T23:47:50.00328Z","shell.execute_reply":"2022-01-24T23:47:50.030374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = label_encoder(test_df)\ntest_df = preprocess_dates(test_df)\ntest_df = preprocess_holidays(test_df)\ntest_df = preprocess_timeseries(test_df)\nx_test = test_df.drop(['row_id', 'date'], axis=1)\nx_test = np.append(x_test, np.ones((x_test.shape[0], 1)), axis=1)\nx_test, _ = split_sequences(x_test, TIMESTEPS)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:47:59.886102Z","iopub.execute_input":"2022-01-24T23:47:59.886606Z","iopub.status.idle":"2022-01-24T23:48:00.066783Z","shell.execute_reply.started":"2022-01-24T23:47:59.886553Z","shell.execute_reply":"2022-01-24T23:48:00.065923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = model.predict(x_test).squeeze()\nrow_id =  test_df['row_id'].values\nsubmission = pd.DataFrame({'row_id' : row_id, 'num_sold' : target})","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:48:01.046851Z","iopub.execute_input":"2022-01-24T23:48:01.047239Z","iopub.status.idle":"2022-01-24T23:48:01.83577Z","shell.execute_reply.started":"2022-01-24T23:48:01.047205Z","shell.execute_reply":"2022-01-24T23:48:01.834917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:48:01.837433Z","iopub.execute_input":"2022-01-24T23:48:01.837737Z","iopub.status.idle":"2022-01-24T23:48:01.852347Z","shell.execute_reply.started":"2022-01-24T23:48:01.837697Z","shell.execute_reply":"2022-01-24T23:48:01.85164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T23:48:01.853733Z","iopub.execute_input":"2022-01-24T23:48:01.853941Z","iopub.status.idle":"2022-01-24T23:48:01.874677Z","shell.execute_reply.started":"2022-01-24T23:48:01.853915Z","shell.execute_reply":"2022-01-24T23:48:01.873657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}