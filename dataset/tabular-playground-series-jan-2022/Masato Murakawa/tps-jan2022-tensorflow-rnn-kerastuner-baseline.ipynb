{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n# [Tabular Playground Series - Jan 2022][1]\n---\n\n---\n[1]: https://www.kaggle.com/c/tabular-playground-series-jan-2022","metadata":{}},{"cell_type":"markdown","source":"# 0. Settings","metadata":{}},{"cell_type":"code","source":"# Import dependencies \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os\nimport pathlib\nimport gc\nimport sys\nimport re\nimport math \nimport random\nimport time \nfrom tqdm import tqdm \nfrom pprint import pprint\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\n\nimport xgboost as xgb\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport transformers \nimport datasets \n\nprint('import done!')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T16:42:09.62112Z","iopub.execute_input":"2022-01-21T16:42:09.622888Z","iopub.status.idle":"2022-01-21T16:42:17.275845Z","shell.execute_reply.started":"2022-01-21T16:42:09.622758Z","shell.execute_reply":"2022-01-21T16:42:17.2751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global config\nconfig = {'window_size': 7,\n          'batch_size': 8,\n          'valid_num': 200,\n          #'rnn_hidden': 128,\n          #'learning_rate': 5e-4,\n          'num_epochs': 20,\n          'max_trials': 20,\n         }\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \n    print('Seeds setted!')\nglobal_seed = 42\nseed_all(global_seed)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.277301Z","iopub.execute_input":"2022-01-21T16:42:17.278885Z","iopub.status.idle":"2022-01-21T16:42:17.288198Z","shell.execute_reply.started":"2022-01-21T16:42:17.278837Z","shell.execute_reply":"2022-01-21T16:42:17.287509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Data Check","metadata":{}},{"cell_type":"code","source":"data_config = {'train_csv_path': '../input/tabular-playground-series-jan-2022/train.csv',\n              'test_csv_path': '../input/tabular-playground-series-jan-2022/test.csv',\n              'sample_submission_path': '../input/tabular-playground-series-jan-2022/sample_submission.csv',\n              }\n\ntrain_df = pd.read_csv(data_config['train_csv_path'])\ntest_df = pd.read_csv(data_config['test_csv_path'])\nsubmission_df = pd.read_csv(data_config['sample_submission_path'])\n\nprint(train_df.shape, test_df.shape, submission_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.289383Z","iopub.execute_input":"2022-01-21T16:42:17.289759Z","iopub.status.idle":"2022-01-21T16:42:17.395239Z","shell.execute_reply.started":"2022-01-21T16:42:17.289727Z","shell.execute_reply":"2022-01-21T16:42:17.394565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['num_sold'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.397233Z","iopub.execute_input":"2022-01-21T16:42:17.397955Z","iopub.status.idle":"2022-01-21T16:42:17.4135Z","shell.execute_reply.started":"2022-01-21T16:42:17.397919Z","shell.execute_reply":"2022-01-21T16:42:17.412752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_df))\nprint()\ntrain_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.414484Z","iopub.execute_input":"2022-01-21T16:42:17.414677Z","iopub.status.idle":"2022-01-21T16:42:17.424921Z","shell.execute_reply.started":"2022-01-21T16:42:17.414653Z","shell.execute_reply":"2022-01-21T16:42:17.423805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unique_category(df, column):\n    print(f'unique_category_number: {df[column].nunique()}')\n    print(f'cagetories: {df[column].unique()}')\n    print()\n\nunique_category(train_df, 'country')\nunique_category(train_df, 'store')\nunique_category(train_df, 'product')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.426659Z","iopub.execute_input":"2022-01-21T16:42:17.427462Z","iopub.status.idle":"2022-01-21T16:42:17.451553Z","shell.execute_reply.started":"2022-01-21T16:42:17.42742Z","shell.execute_reply":"2022-01-21T16:42:17.450846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.452608Z","iopub.execute_input":"2022-01-21T16:42:17.453221Z","iopub.status.idle":"2022-01-21T16:42:17.472535Z","shell.execute_reply.started":"2022-01-21T16:42:17.453185Z","shell.execute_reply":"2022-01-21T16:42:17.471715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Feature Engneering -1","metadata":{}},{"cell_type":"code","source":"def date_features(df):\n    df['date'] = pd.to_datetime(df['date'])\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    return df \n\ntrain_df = date_features(train_df)\ntrain_df = train_df.drop(['date', 'year'], axis=1)\n\ntest_df = date_features(test_df)\ntest_df = test_df.drop(['date', 'year'], axis=1)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.473757Z","iopub.execute_input":"2022-01-21T16:42:17.474207Z","iopub.status.idle":"2022-01-21T16:42:17.519967Z","shell.execute_reply.started":"2022-01-21T16:42:17.474172Z","shell.execute_reply":"2022-01-21T16:42:17.519291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Feature Engneering -2","metadata":{}},{"cell_type":"code","source":"train_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.521115Z","iopub.execute_input":"2022-01-21T16:42:17.521787Z","iopub.status.idle":"2022-01-21T16:42:17.536394Z","shell.execute_reply.started":"2022-01-21T16:42:17.521752Z","shell.execute_reply":"2022-01-21T16:42:17.535727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_num = len(train_df['country'].unique()) * len(train_df['store'].unique()) * len(train_df['product'].unique()) # 18\nseries_data_num = int(len(train_df) / feature_num) # 1461\n\nseries_features = []\nfor i in range(series_data_num):\n    feature = list(train_df['num_sold'][i* feature_num : (i+1) * feature_num])\n    series_features.append(feature)\n\nseries_columns = []\nfor country in train_df['country'].unique():\n    for store in train_df['store'].unique():\n        for product in train_df['product'].unique():\n            name = f'{country}_{store}_{product}'\n            series_columns.append(name)\n            \nseries_df = pd.DataFrame(series_features, columns=series_columns)\nprint(len(series_df))\n\nseries_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.539812Z","iopub.execute_input":"2022-01-21T16:42:17.540158Z","iopub.status.idle":"2022-01-21T16:42:17.665419Z","shell.execute_reply.started":"2022-01-21T16:42:17.540123Z","shell.execute_reply":"2022-01-21T16:42:17.664592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.666824Z","iopub.execute_input":"2022-01-21T16:42:17.667139Z","iopub.status.idle":"2022-01-21T16:42:17.725383Z","shell.execute_reply.started":"2022-01-21T16:42:17.667103Z","shell.execute_reply":"2022-01-21T16:42:17.724656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_series_df = series_df[:-200].copy()\nvalid_series_df = series_df[-200:].copy()\n\nprint(len(train_series_df), len(valid_series_df))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.726484Z","iopub.execute_input":"2022-01-21T16:42:17.727163Z","iopub.status.idle":"2022-01-21T16:42:17.733107Z","shell.execute_reply.started":"2022-01-21T16:42:17.727125Z","shell.execute_reply":"2022-01-21T16:42:17.732291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(train_series_df)\nprint(sc.mean_, sc.scale_)\n\ntrain_series_df = pd.DataFrame(sc.transform(train_series_df), columns=series_columns)\nvalid_series_df = pd.DataFrame(sc.transform(valid_series_df), columns=series_columns)\nall_series_df = pd.DataFrame(sc.transform(series_df), columns=series_columns)\nprint(len(train_series_df), len(valid_series_df), len(all_series_df))\n\ntrain_series_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.7342Z","iopub.execute_input":"2022-01-21T16:42:17.73468Z","iopub.status.idle":"2022-01-21T16:42:17.774275Z","shell.execute_reply.started":"2022-01-21T16:42:17.734641Z","shell.execute_reply":"2022-01-21T16:42:17.773569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Dataset","metadata":{}},{"cell_type":"code","source":"window_size = config['window_size']\n\ntrain_X = []\ntrain_y = []\n\nfor i in range(len(train_series_df) - window_size):\n    tmp_X = np.array(train_series_df.iloc[i:(i+window_size)])\n    tmp_y = np.array(train_series_df.iloc[(i+1):(i+window_size+1)])\n    train_X.append(tmp_X)\n    train_y.append(tmp_y)\n\ntrain_X = tf.constant(train_X, dtype=tf.float32)\ntrain_y = tf.constant(train_y, dtype=tf.float32)\nprint(train_X.shape, train_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:17.775502Z","iopub.execute_input":"2022-01-21T16:42:17.775961Z","iopub.status.idle":"2022-01-21T16:42:23.400755Z","shell.execute_reply.started":"2022-01-21T16:42:17.775925Z","shell.execute_reply":"2022-01-21T16:42:23.400036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_X = []\nvalid_y = []\nfor i in range(len(valid_series_df) - window_size):\n    tmp_X = np.array(valid_series_df.iloc[i:(i+window_size)])\n    tmp_y = np.array(valid_series_df.iloc[(i+1):(i+window_size+1)])\n    valid_X.append(tmp_X)\n    valid_y.append(tmp_y)\nvalid_X = tf.constant(valid_X, dtype=tf.float32)\nvalid_y = tf.constant(valid_y, dtype=tf.float32)\nprint(valid_X.shape, valid_y.shape)\n\nall_X = []\nall_y = []\nfor i in range(len(all_series_df) - window_size):\n    tmp_X = np.array(all_series_df.iloc[i:(i+window_size)])\n    tmp_y = np.array(all_series_df.iloc[(i+1):(i+window_size+1)])\n    all_X.append(tmp_X)\n    all_y.append(tmp_y)\nall_X = tf.constant(all_X, dtype=tf.float32)\nall_y = tf.constant(all_y, dtype=tf.float32)\nprint(all_X.shape, all_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:23.401913Z","iopub.execute_input":"2022-01-21T16:42:23.402596Z","iopub.status.idle":"2022-01-21T16:42:23.815273Z","shell.execute_reply.started":"2022-01-21T16:42:23.402556Z","shell.execute_reply":"2022-01-21T16:42:23.814486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X_ds = tf.data.Dataset.from_tensor_slices(train_X)\ntrain_y_ds = tf.data.Dataset.from_tensor_slices(train_y)\ntrain_ds = tf.data.Dataset.zip((train_X_ds, train_y_ds))\nprint(train_ds, len(train_ds) )\n\nvalid_X_ds = tf.data.Dataset.from_tensor_slices(valid_X)\nvalid_y_ds = tf.data.Dataset.from_tensor_slices(valid_y)\nvalid_ds = tf.data.Dataset.zip((valid_X_ds, valid_y_ds))\nprint(valid_ds, len(valid_ds))\n\nall_X_ds = tf.data.Dataset.from_tensor_slices(all_X)\nall_y_ds = tf.data.Dataset.from_tensor_slices(all_y)\nall_ds = tf.data.Dataset.zip((all_X_ds, all_y_ds))\nprint(all_ds, len(all_ds))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:23.816426Z","iopub.execute_input":"2022-01-21T16:42:23.817095Z","iopub.status.idle":"2022-01-21T16:42:23.844059Z","shell.execute_reply.started":"2022-01-21T16:42:23.817056Z","shell.execute_reply":"2022-01-21T16:42:23.843369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = config['batch_size']\n\ntrain_ds = train_ds.batch(BATCH_SIZE)\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nprint(train_ds)\n\nvalid_ds = valid_ds.batch(BATCH_SIZE)\nvalid_ds = valid_ds.prefetch(buffer_size=AUTOTUNE)\nprint(valid_ds)\n\nall_ds = all_ds.batch(BATCH_SIZE)\nall_ds = all_ds.prefetch(buffer_size=AUTOTUNE)\nprint(all_ds)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:23.845108Z","iopub.execute_input":"2022-01-21T16:42:23.845333Z","iopub.status.idle":"2022-01-21T16:42:23.860219Z","shell.execute_reply.started":"2022-01-21T16:42:23.845299Z","shell.execute_reply":"2022-01-21T16:42:23.859559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Training","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Hyperparameter Tuning with keras-tuner","metadata":{}},{"cell_type":"code","source":"import kerastuner as kt\n\nNUM_TRAIN_STEPS = len(train_ds) * config['batch_size'] * config['num_epochs']\n\ndef build_model(hp):\n    \n    feature_num = len(train_series_df.columns)\n\n    hp_rnn_hidden = hp.Int('rnn_hidden', min_value=16, max_value=256, step=16)\n    hp_dense_hidden = hp.Int('dense_hidden', min_value=16, max_value=256, step=16)\n    hp_activation = hp.Choice('activation', values=['selu', 'relu', 'tanh'])\n\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.GRU(hp_rnn_hidden, return_sequences=True, input_shape=[None, feature_num]),\n        tf.keras.layers.GRU(hp_rnn_hidden, return_sequences=True),\n        tf.keras.layers.Dense(hp_dense_hidden, activation=hp_activation),\n        tf.keras.layers.Dense(18)\n        ])\n    \n    hp_initial_learning_rate = hp.Float('initial_learning_rate', 1e-4, 1e-3, sampling='log')\n    lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n        initial_learning_rate=hp_initial_learning_rate,\n        end_learning_rate=1e-5,\n        decay_steps=NUM_TRAIN_STEPS)\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss=tf.keras.losses.MeanSquaredError(),\n              )\n  \n    return model\n\n\ntuner = kt.BayesianOptimization(\n    build_model,\n    objective='val_loss',\n    max_trials=config['max_trials'],\n    directory = 'hp_tuning',\n    project_name = 'ex_no_1',\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:23.861267Z","iopub.execute_input":"2022-01-21T16:42:23.861906Z","iopub.status.idle":"2022-01-21T16:42:24.501302Z","shell.execute_reply.started":"2022-01-21T16:42:23.861871Z","shell.execute_reply":"2022-01-21T16:42:24.500601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(train_ds, epochs=config['num_epochs'], validation_data=valid_ds)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:24.502777Z","iopub.execute_input":"2022-01-21T16:42:24.50303Z","iopub.status.idle":"2022-01-21T16:42:52.636632Z","shell.execute_reply.started":"2022-01-21T16:42:24.502984Z","shell.execute_reply":"2022-01-21T16:42:52.635681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary(num_trials=3)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:52.638131Z","iopub.execute_input":"2022-01-21T16:42:52.638391Z","iopub.status.idle":"2022-01-21T16:42:52.645582Z","shell.execute_reply.started":"2022-01-21T16:42:52.638355Z","shell.execute_reply":"2022-01-21T16:42:52.644907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Model Training with Best Parameters","metadata":{}},{"cell_type":"code","source":"best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\nmodel = tuner.hypermodel.build(best_hps)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:52.646895Z","iopub.execute_input":"2022-01-21T16:42:52.647123Z","iopub.status.idle":"2022-01-21T16:42:53.090653Z","shell.execute_reply.started":"2022-01-21T16:42:52.647092Z","shell.execute_reply":"2022-01-21T16:42:53.089896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TRAIN_STEPS = len(all_ds) * config['batch_size'] * config['num_epochs']\nmodel.fit(all_ds, epochs=config['num_epochs'])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:42:53.091762Z","iopub.execute_input":"2022-01-21T16:42:53.092141Z","iopub.status.idle":"2022-01-21T16:43:17.718489Z","shell.execute_reply.started":"2022-01-21T16:42:53.092104Z","shell.execute_reply":"2022-01-21T16:43:17.717787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Prediction and Submission","metadata":{}},{"cell_type":"code","source":"def prediction(model, prediction_num):\n    input_for_predict = tf.constant(series_df[-window_size:], dtype=tf.float32)\n    input_for_predict = tf.expand_dims(input_for_predict, 0)\n    predictions = []\n\n    for i in range(prediction_num):\n        pred = model(input_for_predict) # TensorShape([1, window_size, 18])\n        pred = pred[:, -1, :] # TensorShape([1, 18])\n        predictions.append(pred)\n        \n        pred = tf.expand_dims(pred, 0)\n        input_for_predict = input_for_predict[:, 1:, :]\n        input_for_predict = tf.concat([input_for_predict, pred], axis=1)\n\n    return np.array(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:43:17.71993Z","iopub.execute_input":"2022-01-21T16:43:17.720185Z","iopub.status.idle":"2022-01-21T16:43:17.727279Z","shell.execute_reply.started":"2022-01-21T16:43:17.720151Z","shell.execute_reply":"2022-01-21T16:43:17.726537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = prediction(model, int(len(test_df)/feature_num) )\npredictions = np.squeeze(predictions, axis=1)\n\npred_num_sold = (predictions * sc.scale_) + sc.mean_\npred_num_sold = pred_num_sold.ravel()\n\nsubmission_df['num_sold'] = pred_num_sold\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:43:17.728878Z","iopub.execute_input":"2022-01-21T16:43:17.729356Z","iopub.status.idle":"2022-01-21T16:43:20.310596Z","shell.execute_reply.started":"2022-01-21T16:43:17.729318Z","shell.execute_reply":"2022-01-21T16:43:20.309957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}