{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{"papermill":{"duration":0.03502,"end_time":"2022-01-06T13:49:37.117474","exception":false,"start_time":"2022-01-06T13:49:37.082454","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression,HuberRegressor,Ridge,TweedieRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n\nimport dateutil.easter as easter\n\nimport datetime\nimport optuna\nimport math","metadata":{"papermill":{"duration":1.990349,"end_time":"2022-01-06T13:49:39.143441","exception":false,"start_time":"2022-01-06T13:49:37.153092","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.298831Z","iopub.execute_input":"2022-01-31T20:34:31.299174Z","iopub.status.idle":"2022-01-31T20:34:31.30676Z","shell.execute_reply.started":"2022-01-31T20:34:31.299141Z","shell.execute_reply":"2022-01-31T20:34:31.305376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Holidays\nHOLIDAYS = False     \nNEXT_HOLIDAY = False  \n\nSEASONS = True \nWEATHER = True \n\nLAG_FEATURES = True\n\nPOST_PROCESSING = False\nMODEL_TYPE = \"Ridge Regression\"\n\nVAL_SPLIT = \"2017-12-31\" #\"2018-05-31\"","metadata":{"papermill":{"duration":0.043435,"end_time":"2022-01-06T13:49:39.224513","exception":false,"start_time":"2022-01-06T13:49:39.181078","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.308483Z","iopub.execute_input":"2022-01-31T20:34:31.308769Z","iopub.status.idle":"2022-01-31T20:34:31.320006Z","shell.execute_reply.started":"2022-01-31T20:34:31.308738Z","shell.execute_reply":"2022-01-31T20:34:31.319301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10000    \nEARLY_STOPPING = 30\nDEVICE = \"cpu\"\n\nSCALER_NAME = \"MinMaxScaler\"  #None MinMax Standard\nSCALER = MinMaxScaler()  #MinMaxScaler StandardScaler","metadata":{"papermill":{"duration":0.042964,"end_time":"2022-01-06T13:49:39.30297","exception":false,"start_time":"2022-01-06T13:49:39.260006","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.321506Z","iopub.execute_input":"2022-01-31T20:34:31.321958Z","iopub.status.idle":"2022-01-31T20:34:31.335503Z","shell.execute_reply.started":"2022-01-31T20:34:31.321925Z","shell.execute_reply":"2022-01-31T20:34:31.334532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"obj is the objective function of the algorithm, i.e. what it's trying to maximize or minimize, e.g. \"regression\" means it's minimizing squared residuals.\n\nMetric and eval are essentially the same. They are used for Early stopping ","metadata":{"papermill":{"duration":0.03505,"end_time":"2022-01-06T13:49:39.373475","exception":false,"start_time":"2022-01-06T13:49:39.338425","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Load Data","metadata":{"papermill":{"duration":0.034757,"end_time":"2022-01-06T13:49:39.443432","exception":false,"start_time":"2022-01-06T13:49:39.408675","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tabular-playground-series-jan-2022/train.csv\",index_col = 0)\ntest_df = pd.read_csv(\"../input/tabular-playground-series-jan-2022/test.csv\",index_col = 0)\nsub = pd.read_csv(\"../input/tabular-playground-series-jan-2022/sample_submission.csv\",index_col = 0)\ngdp_df = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\ngdp_df.set_index('year', inplace=True)\n\nif HOLIDAYS:\n    holidays = pd.read_csv(\"../input/holidays-finland-norway-sweden-20152019/Holidays_Finland_Norway_Sweden_2015-2019.csv\",usecols = [\"Date\",\"Country\",\"Name\"]                      )\n    holidays.rename(columns = {\"Date\":\"date\",\"Country\":\"country\",\"Name\":\"holiday\"},inplace= True)\n    holidays[\"holiday\"]= 1\n    holidays[\"holiday\"]= holidays[\"holiday\"].astype(\"int32\")\n    holidays[\"date\"] = pd.to_datetime(holidays[\"date\"])","metadata":{"papermill":{"duration":0.154073,"end_time":"2022-01-06T13:49:39.632746","exception":false,"start_time":"2022-01-06T13:49:39.478673","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.336944Z","iopub.execute_input":"2022-01-31T20:34:31.337203Z","iopub.status.idle":"2022-01-31T20:34:31.405332Z","shell.execute_reply.started":"2022-01-31T20:34:31.337163Z","shell.execute_reply":"2022-01-31T20:34:31.404386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_weather = pd.read_csv('../input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv', parse_dates=['date'])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:31.407368Z","iopub.execute_input":"2022-01-31T20:34:31.407632Z","iopub.status.idle":"2022-01-31T20:34:31.789731Z","shell.execute_reply.started":"2022-01-31T20:34:31.407598Z","shell.execute_reply":"2022-01-31T20:34:31.788781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make date\ntrain_df[\"date\"] = pd.to_datetime(train_df[\"date\"])\ntest_df[\"date\"] = pd.to_datetime(test_df[\"date\"])","metadata":{"papermill":{"duration":0.055319,"end_time":"2022-01-06T13:49:39.723796","exception":false,"start_time":"2022-01-06T13:49:39.668477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.791282Z","iopub.execute_input":"2022-01-31T20:34:31.791569Z","iopub.status.idle":"2022-01-31T20:34:31.808599Z","shell.execute_reply.started":"2022-01-31T20:34:31.791507Z","shell.execute_reply":"2022-01-31T20:34:31.807717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"papermill":{"duration":0.055686,"end_time":"2022-01-06T13:49:39.894209","exception":false,"start_time":"2022-01-06T13:49:39.838523","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.810446Z","iopub.execute_input":"2022-01-31T20:34:31.810867Z","iopub.status.idle":"2022-01-31T20:34:31.824186Z","shell.execute_reply.started":"2022-01-31T20:34:31.810822Z","shell.execute_reply":"2022-01-31T20:34:31.82301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions ","metadata":{"papermill":{"duration":0.035697,"end_time":"2022-01-06T13:49:39.966368","exception":false,"start_time":"2022-01-06T13:49:39.930671","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Thanks to [ambrosm](https://www.kaggle.com/anirudhg15) \\\nFor this amazing feature engineering\nhttps://www.kaggle.com/ambrosm/tpsjan22-03-linear-model/notebook#More-feature-engineering-(advanced-model)","metadata":{"papermill":{"duration":0.035816,"end_time":"2022-01-06T13:49:40.528863","exception":false,"start_time":"2022-01-06T13:49:40.493047","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Feature engineering\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n      \n    \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    #new_df['daysinmonth'] = df['date'].dt.days_in_month         \n    \n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    \n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        new_df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Hat']\n\n    return new_df\n#train = engineer(train_df)","metadata":{"papermill":{"duration":0.052476,"end_time":"2022-01-06T13:49:40.617426","exception":false,"start_time":"2022-01-06T13:49:40.56495","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:31.8258Z","iopub.execute_input":"2022-01-31T20:34:31.82674Z","iopub.status.idle":"2022-01-31T20:34:31.841595Z","shell.execute_reply.started":"2022-01-31T20:34:31.826693Z","shell.execute_reply":"2022-01-31T20:34:31.84053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering for holidays\ndef engineer_more(df):\n    \"\"\"Return a new dataframe with more engineered features\"\"\"\n    new_df = engineer(df)\n\n    # End of year\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 14)}),\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})],\n                       axis=1)\n    \n    # May\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}), #  + list(range(17, 25))\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(19, 26))})],\n                       axis=1)\n    \n    # June and July\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))}),\n                        #pd.DataFrame({f\"june{d}\":\n                        #              (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Norway')\n                        #              for d in list(range(22, 31))}),\n                        #pd.DataFrame({f\"july{d}\":\n                        #              (df.date.dt.month == 7) & (df.date.dt.day == d) & (df.country == 'Norway')\n                        #              for d in list(range(1, 3))})],\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))})],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})],\n                       axis=1)\n    \n    #new_df = pd.get_dummies(new_df)\n\n    return new_df.astype(np.float64)\n\ntrain = engineer_more(train_df)\n\ntrain['num_sold'] = train_df.num_sold.astype(np.float32)\ntest = engineer_more(test_df)\n\n#features = list(test.columns)\n#print(features)\n\ntest['date'] = test_df.date\ntrain['date'] = train_df.date","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:31.844965Z","iopub.execute_input":"2022-01-31T20:34:31.845515Z","iopub.status.idle":"2022-01-31T20:34:35.283632Z","shell.execute_reply.started":"2022-01-31T20:34:31.845471Z","shell.execute_reply":"2022-01-31T20:34:35.282726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[[\"store\",\"product\",\"country\"]]= train_df[[\"store\",\"product\",\"country\"]]\ntest[[\"store\",\"product\",\"country\"]]= test_df[[\"store\",\"product\",\"country\"]]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.284869Z","iopub.execute_input":"2022-01-31T20:34:35.285093Z","iopub.status.idle":"2022-01-31T20:34:35.29698Z","shell.execute_reply.started":"2022-01-31T20:34:35.285065Z","shell.execute_reply":"2022-01-31T20:34:35.29612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SEASONS:\n    \n    print(\"Adding Seasons \")\n    seasons = [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1]\n\n    month_to_season = dict(zip(range(1,13), seasons))\n\n    train[\"season\"] = train[\"date\"].dt.month.map(month_to_season)\n    test[\"season\"] = test[\"date\"].dt.month.map(month_to_season)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.298247Z","iopub.execute_input":"2022-01-31T20:34:35.298476Z","iopub.status.idle":"2022-01-31T20:34:35.314267Z","shell.execute_reply.started":"2022-01-31T20:34:35.298448Z","shell.execute_reply":"2022-01-31T20:34:35.313561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if WEATHER:\n    w_feats = ['country', 'date', 'tavg','precipitation']\n    #w_feats = ['country', 'date', 'precipitation', 'snow_depth', 'tavg', 'tmax','tmin']\n    print(\"Adding weather\")\n    train = train.merge(df_weather[w_feats], on=['date', 'country'], how='left')\n    train.index = train_df.index \n    test = test.merge(df_weather[w_feats], on=['date', 'country'], how='left')\n    test.index = test_df.index ","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.315344Z","iopub.execute_input":"2022-01-31T20:34:35.315751Z","iopub.status.idle":"2022-01-31T20:34:35.358297Z","shell.execute_reply.started":"2022-01-31T20:34:35.315716Z","shell.execute_reply":"2022-01-31T20:34:35.357436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.359443Z","iopub.execute_input":"2022-01-31T20:34:35.359785Z","iopub.status.idle":"2022-01-31T20:34:35.39075Z","shell.execute_reply.started":"2022-01-31T20:34:35.359755Z","shell.execute_reply":"2022-01-31T20:34:35.389978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def public_hols(df):\n    df = pd.merge(df, holidays, how='left', on=['date', 'country'])\n    df.fillna(value = 0,inplace=True)\n    return df","metadata":{"papermill":{"duration":0.043867,"end_time":"2022-01-06T13:49:40.046156","exception":false,"start_time":"2022-01-06T13:49:40.002289","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:35.392042Z","iopub.execute_input":"2022-01-31T20:34:35.392584Z","iopub.status.idle":"2022-01-31T20:34:35.396997Z","shell.execute_reply.started":"2022-01-31T20:34:35.39253Z","shell.execute_reply":"2022-01-31T20:34:35.396145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if HOLIDAYS:\n    train = public_hols(train)\n    test = public_hols(test)\n    test.index = test_df.index ","metadata":{"papermill":{"duration":0.29343,"end_time":"2022-01-06T13:49:40.454326","exception":false,"start_time":"2022-01-06T13:49:40.160896","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:35.398378Z","iopub.execute_input":"2022-01-31T20:34:35.398773Z","iopub.status.idle":"2022-01-31T20:34:35.408688Z","shell.execute_reply.started":"2022-01-31T20:34:35.398731Z","shell.execute_reply":"2022-01-31T20:34:35.407898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def next_holiday(x):\n    i=1\n    while sum(holidays[\"date\"] == pd.Timestamp(x) + pd.DateOffset(days=i)) ==0:\n        i+=1\n        if i >200:\n            i=0\n            break\n            break\n    return i\n\nif NEXT_HOLIDAY:\n    holidays[\"date\"] = pd.to_datetime(holidays[\"date\"])\n    train[\"to_holiday\"] = train[\"date\"].apply(lambda x : next_holiday(x))\n    test[\"to_holiday\"] = test[\"date\"].apply(lambda x : next_holiday(x))","metadata":{"papermill":{"duration":0.046404,"end_time":"2022-01-06T13:49:42.721584","exception":false,"start_time":"2022-01-06T13:49:42.67518","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:35.409784Z","iopub.execute_input":"2022-01-31T20:34:35.410012Z","iopub.status.idle":"2022-01-31T20:34:35.420776Z","shell.execute_reply.started":"2022-01-31T20:34:35.409984Z","shell.execute_reply":"2022-01-31T20:34:35.419869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","metadata":{"papermill":{"duration":0.044421,"end_time":"2022-01-06T13:49:42.802374","exception":false,"start_time":"2022-01-06T13:49:42.757953","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:35.421925Z","iopub.execute_input":"2022-01-31T20:34:35.422128Z","iopub.status.idle":"2022-01-31T20:34:35.431938Z","shell.execute_reply.started":"2022-01-31T20:34:35.422103Z","shell.execute_reply":"2022-01-31T20:34:35.431194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lag Features ","metadata":{}},{"cell_type":"code","source":"def create_lag(DAYS,df):\n    df[f\"shift{DAYS}\"] = df.groupby([\"store\",\"product\",\"country\"])[\"num_sold\"].shift(DAYS,fill_value = 0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.433354Z","iopub.execute_input":"2022-01-31T20:34:35.434093Z","iopub.status.idle":"2022-01-31T20:34:35.443357Z","shell.execute_reply.started":"2022-01-31T20:34:35.434049Z","shell.execute_reply":"2022-01-31T20:34:35.4428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rolling_mean_std(roll_window, df):\n    shift_days=0\n    col_name = 'rolling_'+str(shift_days)+'_'+str(roll_window)\n    df[col_name+\"_mean\"] = df.groupby([\"store\",\"product\",\"country\"])[\"num_sold\"].shift(shift_days).rolling(roll_window).mean()\n    df[col_name+\"_std\"] = df.groupby([\"store\",\"product\",\"country\"])[\"num_sold\"].shift(shift_days).rolling(roll_window).std()\n    \n    return df.fillna(0,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.444309Z","iopub.execute_input":"2022-01-31T20:34:35.444559Z","iopub.status.idle":"2022-01-31T20:34:35.456185Z","shell.execute_reply.started":"2022-01-31T20:34:35.444516Z","shell.execute_reply":"2022-01-31T20:34:35.455523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def day_roll(df,day_shift,roll_window):\n    #Shift values and rolling mean\n    for day in days_shift:\n        create_lag(day,df)\n    for window in roll_window:\n        pass\n        #rolling_mean_std(window,df)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.459875Z","iopub.execute_input":"2022-01-31T20:34:35.460455Z","iopub.status.idle":"2022-01-31T20:34:35.466804Z","shell.execute_reply.started":"2022-01-31T20:34:35.460413Z","shell.execute_reply":"2022-01-31T20:34:35.465963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shift Days","metadata":{}},{"cell_type":"code","source":"'''days_shift = [1,7,14, 30]\nroll_window = [7,14,30]'''\ndays_shift = [i for i in range(1,30)]\nroll_window = [7]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.467863Z","iopub.execute_input":"2022-01-31T20:34:35.468077Z","iopub.status.idle":"2022-01-31T20:34:35.478036Z","shell.execute_reply.started":"2022-01-31T20:34:35.468051Z","shell.execute_reply":"2022-01-31T20:34:35.477307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def roll_lag_run(df):\n        df = day_roll(df,days_shift,roll_window)\n    return df '''\n\nif LAG_FEATURES:\n    print(\"Running Lag features\")\n    train = day_roll(train,days_shift,roll_window)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:35.480586Z","iopub.execute_input":"2022-01-31T20:34:35.48112Z","iopub.status.idle":"2022-01-31T20:34:36.001934Z","shell.execute_reply.started":"2022-01-31T20:34:35.481084Z","shell.execute_reply":"2022-01-31T20:34:36.001154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Features","metadata":{}},{"cell_type":"code","source":"features_base= list(test.columns)\nfeatures= list(train.columns)\n\n\nfor feat in [features_base, features]:\n    feat.remove(\"store\")\n    feat.remove(\"product\")\n    feat.remove(\"country\")\n    feat.remove(\"date\")\n\nfeatures.remove(\"num_sold\")\n\nprint(features_base)\nprint()\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.003106Z","iopub.execute_input":"2022-01-31T20:34:36.003314Z","iopub.status.idle":"2022-01-31T20:34:36.009805Z","shell.execute_reply.started":"2022-01-31T20:34:36.003288Z","shell.execute_reply":"2022-01-31T20:34:36.008921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split and Scale","metadata":{"papermill":{"duration":0.036013,"end_time":"2022-01-06T13:49:43.157706","exception":false,"start_time":"2022-01-06T13:49:43.121693","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X = train[features_base]\ny= train[\"num_sold\"]\n\nX_train = train[train[\"date\"]<=VAL_SPLIT][features]\nX_test = train[train[\"date\"]>VAL_SPLIT][features]\n\ny_train = train[train[\"date\"]<=VAL_SPLIT][\"num_sold\"]\ny_test = train[train[\"date\"]>VAL_SPLIT][\"num_sold\"]","metadata":{"papermill":{"duration":0.055147,"end_time":"2022-01-06T13:49:43.249507","exception":false,"start_time":"2022-01-06T13:49:43.19436","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:36.011686Z","iopub.execute_input":"2022-01-31T20:34:36.011987Z","iopub.status.idle":"2022-01-31T20:34:36.08328Z","shell.execute_reply.started":"2022-01-31T20:34:36.011949Z","shell.execute_reply":"2022-01-31T20:34:36.082446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scale_data(X_train, X_test= None, test=None,):\n     \n    scaler= SCALER\n    \n    #this can be X or X_train \n    X_train_s = scaler.fit_transform(X_train)\n\n    if X_test is None: #full train \n        test_s = scaler.transform(test)\n        return X_train_s, test_s\n    \n    else: # validation \n        X_test_s = scaler.transform(X_test)\n    \n    return   X_train_s , X_test_s","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.084619Z","iopub.execute_input":"2022-01-31T20:34:36.085242Z","iopub.status.idle":"2022-01-31T20:34:36.090656Z","shell.execute_reply.started":"2022-01-31T20:34:36.085206Z","shell.execute_reply":"2022-01-31T20:34:36.089597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run model","metadata":{"papermill":{"duration":0.037597,"end_time":"2022-01-06T13:49:45.227958","exception":false,"start_time":"2022-01-06T13:49:45.190361","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def fit_model(X,y,test = None, X_test = None,y_test= None):\n    \n    model = Ridge(max_iter=EPOCHS)\n\n    \n    if X_test is not None: #validation prediction \n        X_train_s , X_test_s = scale_data(X, X_test)\n        model.fit(X_train_s,np.log1p(y))\n        preds = np.expm1(model.predict(X_test_s))\n        \n        smape = SMAPE(y_test,preds)\n        \n        return preds, model, smape\n        \n    else:\n        X_s, test_s = scale_data(X, test)\n        \n        model.fit(X_s,np.log1p(y))\n        preds = np.expm1(model.predict(test_s))\n        \n        return preds, model","metadata":{"papermill":{"duration":0.044526,"end_time":"2022-01-06T13:49:45.390317","exception":false,"start_time":"2022-01-06T13:49:45.345791","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:36.091709Z","iopub.execute_input":"2022-01-31T20:34:36.092487Z","iopub.status.idle":"2022-01-31T20:34:36.102706Z","shell.execute_reply.started":"2022-01-31T20:34:36.092453Z","shell.execute_reply":"2022-01-31T20:34:36.101991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_predictions , model ,smape = fit_model(X= X_train,y = y_train,test= None, X_test = X_test,y_test = y_test)","metadata":{"papermill":{"duration":30.725025,"end_time":"2022-01-06T13:50:16.152347","exception":false,"start_time":"2022-01-06T13:49:45.427322","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:36.104598Z","iopub.execute_input":"2022-01-31T20:34:36.10482Z","iopub.status.idle":"2022-01-31T20:34:36.220135Z","shell.execute_reply.started":"2022-01-31T20:34:36.104794Z","shell.execute_reply":"2022-01-31T20:34:36.219172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"SMAPE :\",smape )\nprint(f\"\\n EPOCHS: {EPOCHS}\")\nprint(f\"\\n SCALER: {SCALER_NAME}\")\nprint(f\"\\n POST_PROCESSING: {POST_PROCESSING}\")","metadata":{"papermill":{"duration":0.050399,"end_time":"2022-01-06T13:50:16.257996","exception":false,"start_time":"2022-01-06T13:50:16.207597","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-31T20:34:36.221658Z","iopub.execute_input":"2022-01-31T20:34:36.222131Z","iopub.status.idle":"2022-01-31T20:34:36.228448Z","shell.execute_reply.started":"2022-01-31T20:34:36.222088Z","shell.execute_reply":"2022-01-31T20:34:36.227613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"residuals = y_test - val_predictions\nplt.figure(figsize = (20,7))\nplt.scatter(y_test,val_predictions)\nplt.title(\"Residual Analysis\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.230019Z","iopub.execute_input":"2022-01-31T20:34:36.230568Z","iopub.status.idle":"2022-01-31T20:34:36.461717Z","shell.execute_reply.started":"2022-01-31T20:34:36.23051Z","shell.execute_reply":"2022-01-31T20:34:36.460886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run on Full training data ","metadata":{}},{"cell_type":"code","source":"# fit on full dataset\nonesplit_preds , model = fit_model(X,y,test[features_base])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.46332Z","iopub.execute_input":"2022-01-31T20:34:36.463881Z","iopub.status.idle":"2022-01-31T20:34:36.57798Z","shell.execute_reply.started":"2022-01-31T20:34:36.463836Z","shell.execute_reply":"2022-01-31T20:34:36.577021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_base  = sub.copy(deep = True)\nsub_base_full  = sub.copy(deep = True)\nsub_base[\"num_sold\"] =  val_predictions\nsub_base_full[\"num_sold\"] =  onesplit_preds","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.579876Z","iopub.execute_input":"2022-01-31T20:34:36.580517Z","iopub.status.idle":"2022-01-31T20:34:36.587794Z","shell.execute_reply.started":"2022-01-31T20:34:36.580456Z","shell.execute_reply":"2022-01-31T20:34:36.58694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_base_full","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.589511Z","iopub.execute_input":"2022-01-31T20:34:36.59027Z","iopub.status.idle":"2022-01-31T20:34:36.610165Z","shell.execute_reply.started":"2022-01-31T20:34:36.590219Z","shell.execute_reply":"2022-01-31T20:34:36.609344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multi - Step Recursive \nWe will loop through a time period (days), predict the data and append to the training data for re-training \\\nThis will continue till the end of test ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T15:27:24.671427Z","iopub.execute_input":"2022-01-16T15:27:24.672171Z","iopub.status.idle":"2022-01-16T15:27:24.67658Z","shell.execute_reply.started":"2022-01-16T15:27:24.672114Z","shell.execute_reply":"2022-01-16T15:27:24.675599Z"}}},{"cell_type":"code","source":"FREQUENCY = 1 #prediction period\n\nstart_date = min(test[\"date\"]) \nend_date = max(test[\"date\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:36.611921Z","iopub.execute_input":"2022-01-31T20:34:36.612485Z","iopub.status.idle":"2022-01-31T20:34:36.81415Z","shell.execute_reply.started":"2022-01-31T20:34:36.612426Z","shell.execute_reply":"2022-01-31T20:34:36.813534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multi_step_recursive(start_date, end_date, freq, sub, train_i, test_i):\n    delta = pd.DateOffset(days = freq)\n\n    all_df = pd.concat([train_i.assign(ds=\"a\"),test_i.assign(ds=\"b\")],axis =0)\n    \n    #Shift values and rolling \n    if LAG_FEATURES:\n        all_df = day_roll(all_df,days_shift,roll_window)\n\n    while start_date <= end_date:\n\n        #Select slice to predict\n        test_split = all_df [  (all_df[\"date\"]>= start_date ) & (all_df[\"date\"]< start_date+delta) ][features]\n        \n        X = all_df[ all_df[\"date\"]< start_date][features]\n        y = all_df[ all_df[\"date\"]< start_date][\"num_sold\"]\n        \n        #predict 1 timeframe - full data\n        one_period_preds , model = fit_model(X,y,test_split[features])\n\n        #Add prediction test data to X and preds to y\n        test_split[\"num_sold\"] = one_period_preds\n        all_df.loc[test_split.index, \"num_sold\"]  = test_split[\"num_sold\"]\n\n        sub.loc[test_split.index , \"num_sold\"] = one_period_preds\n        \n        #Shift values and rolling \n        if LAG_FEATURES:\n            all_df = day_roll(all_df,days_shift,roll_window)\n\n        #update start date\n        start_date += delta\n    \n    #val prediction\n    X_train = train_i[train_i[\"date\"]<=VAL_SPLIT][features]\n    X_test = train_i[train_i[\"date\"]>VAL_SPLIT][features]\n    y_train = train_i[train_i[\"date\"]<=VAL_SPLIT][\"num_sold\"]\n    y_test = train_i[train_i[\"date\"]>VAL_SPLIT][\"num_sold\"]\n\n    val_predictions , model ,smape = fit_model(X= X_train,y = y_train,test= None, X_test = X_test,y_test = y_test)\n    print(\"SMAPE:\",smape)\n    \n    return sub ,smape","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:34:37.527824Z","iopub.execute_input":"2022-01-31T20:34:37.528301Z","iopub.status.idle":"2022-01-31T20:34:37.540956Z","shell.execute_reply.started":"2022-01-31T20:34:37.528254Z","shell.execute_reply":"2022-01-31T20:34:37.539999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_recursive , smape = multi_step_recursive(start_date, end_date, FREQUENCY, sub.copy(deep=True), train, test)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-01-31T20:34:37.54235Z","iopub.execute_input":"2022-01-31T20:34:37.542977Z","iopub.status.idle":"2022-01-31T20:39:59.044457Z","shell.execute_reply.started":"2022-01-31T20:34:37.542932Z","shell.execute_reply":"2022-01-31T20:39:59.043576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_recursive","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:39:59.046062Z","iopub.execute_input":"2022-01-31T20:39:59.046933Z","iopub.status.idle":"2022-01-31T20:39:59.062609Z","shell.execute_reply.started":"2022-01-31T20:39:59.046881Z","shell.execute_reply":"2022-01-31T20:39:59.061501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split on Store, Product , Country","metadata":{}},{"cell_type":"code","source":"import pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:39:59.064734Z","iopub.execute_input":"2022-01-31T20:39:59.065256Z","iopub.status.idle":"2022-01-31T20:39:59.075454Z","shell.execute_reply.started":"2022-01-31T20:39:59.065201Z","shell.execute_reply":"2022-01-31T20:39:59.074531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_models(split_on, sub_df, train ,test):    \n\n    split_smape=0\n    \n    # split training on product/ store/ country\n    for split in train[split_on].unique():\n        print(f\"\\nPredicting for {split_on} {split}\")\n\n        train_split= train[train[split_on] ==split]\n        test_split =test[test[split_on] ==split]\n        \n        #train on Full dataset\n        final_predictions , smape = multi_step_recursive(start_date, end_date, FREQUENCY, sub.copy(deep=True), train_split, test_split)\n        split_smape += smape/train[split_on].nunique()\n        \n        sub_df.loc[test_split.index,\"num_sold\"] = final_predictions[\"num_sold\"]\n\n    print(f\"\\n Final mean smape:\",split_smape)\n    \n    return split_smape, sub_df, model","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:39:59.07719Z","iopub.execute_input":"2022-01-31T20:39:59.077773Z","iopub.status.idle":"2022-01-31T20:39:59.088382Z","shell.execute_reply.started":"2022-01-31T20:39:59.077726Z","shell.execute_reply":"2022-01-31T20:39:59.087077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_smape, sub_store, model = split_models(\"store\", sub.copy(deep=True), train ,test)\n#sub_store","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:39:59.09022Z","iopub.execute_input":"2022-01-31T20:39:59.090907Z","iopub.status.idle":"2022-01-31T20:45:57.351589Z","shell.execute_reply.started":"2022-01-31T20:39:59.090858Z","shell.execute_reply":"2022-01-31T20:45:57.350683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product_smape, sub_product, model = split_models(\"product\", sub.copy(deep=True), train ,test)\n#sub_product","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:45:57.353528Z","iopub.execute_input":"2022-01-31T20:45:57.354203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_smape, sub_country,model = split_models(\"country\", sub.copy(deep=True), train ,test)\n#sub_country","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Notes:**\n\n* best----- Kaggle Hat (product)  ,   Norway (Country) , Sweden (country)\n* good----- all store splits \n* bad------ Finland (Country)-worst   -- Kaggle Sticker(product) --KaggleMug(product) \n\n#### summary\n* Country split is good  but Finland is bad \\\n* Try focus on Finland and see where stickers fits in ","metadata":{}},{"cell_type":"markdown","source":"# All Split ","metadata":{}},{"cell_type":"code","source":"import itertools\nall_splits = list(itertools.product(['KaggleMart', 'KaggleRama'],['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker'],['Finland', 'Norway', 'Sweden']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_models_ALL(split_on, sub_df):    \n\n    split_smape=0\n    split_dict = {}\n\n    # split training on product/ store/ country\n    for idx ,split in enumerate(split_on):\n        print(f\"\\nPredicting for store: {split[0]}, product: {split[1]}, country: {split[2]} \")\n\n        train_split= train[ (train[\"store\"] == split[0]) & (train[\"product\"] == split[1]) & (train[\"country\"] == split[2])]\n        test_split =test[ (test[\"store\"] == split[0]) & (test[\"product\"] == split[1]) & (test[\"country\"] == split[2])]\n\n        X_train = train_split[train_split[\"date\"]<=VAL_SPLIT][features]\n        X_test = train_split[train_split[\"date\"]>VAL_SPLIT][features]\n        y_train= train_split[train_split[\"date\"]<=VAL_SPLIT][\"num_sold\"]\n        y_test= train_split[train_split[\"date\"]>VAL_SPLIT][\"num_sold\"]\n\n        #run model for each split type\n        val_predictions , model ,smape = fit_model(X_train,y_train,test_split[features], X_test,y_test)\n\n        split_smape += smape/len(all_splits)\n        split_dict[split] = smape\n\n        #train on Full dataset\n        #final_predictions , model = fit_model(train_split[features]  ,train_split[\"num_sold\"]  ,  test_split[features])\n        final_predictions , smape = multi_step_recursive(start_date, end_date, FREQUENCY, sub.copy(deep=True), train_split, test_split)\n        sub_df.loc[test_split.index,\"num_sold\"] = final_predictions[\"num_sold\"]\n                \n\n    print(f\"\\n final all_split smape:\",split_smape)\n    \n    return split_smape, sub_df , split_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smape_all, sub_all, split_dict = split_models_ALL(all_splits, sub.copy(deep=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post Processing & Submission ","metadata":{"papermill":{"duration":0.037828,"end_time":"2022-01-06T13:50:16.633993","exception":false,"start_time":"2022-01-06T13:50:16.596165","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Targeted rounding \nhttps://www.kaggle.com/c/petfinder-pawpularity-score/discussion/300992","metadata":{}},{"cell_type":"code","source":"if POST_PROCESSING: \n    dec = sub_recursive % 1\n    to_round = (dec<=0.2)|(dec>=0.8)\n    sub_recursive[to_round] = np.round(sub_recursive[to_round])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_base[\"num_sold\"]= sub_base[\"num_sold\"].round()\nsub_base_full[\"num_sold\"]= sub_base_full[\"num_sold\"].round()\nsub_recursive[\"num_sold\"]= sub_recursive[\"num_sold\"].round()\nsub_store[\"num_sold\"]= sub_store[\"num_sold\"].round()\nsub_product[\"num_sold\"]= sub_product[\"num_sold\"].round()\nsub_country[\"num_sold\"]= sub_country[\"num_sold\"].round()\nsub_all[\"num_sold\"]= sub_all[\"num_sold\"].round()\n\nsub_base.to_csv(\"submission_base.csv\")\nsub_base_full.to_csv(\"submission_base_full.csv\")\n\nsub_recursive.to_csv(\"submission_recursive.csv\")\n\nsub_store.to_csv(\"submission_store.csv\")\nsub_product.to_csv(\"submission_product.csv\")\nsub_country.to_csv(\"submission_country.csv\")\nsub_all.to_csv(\"submission_all.csv\")","metadata":{"papermill":{"duration":0.075505,"end_time":"2022-01-06T13:50:16.930483","exception":false,"start_time":"2022-01-06T13:50:16.854978","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Visualization","metadata":{"papermill":{"duration":0.039336,"end_time":"2022-01-06T13:50:17.09802","exception":false,"start_time":"2022-01-06T13:50:17.058684","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\nsns.lineplot(data = train[train[\"date\"]>=VAL_SPLIT], x= \"date\" , y = \"num_sold\", label =\"actual\" ,ci=None)\nsns.lineplot(data = sub_base, x= test[\"date\"] , y = \"num_sold\", label =\"Base prediction\" ,ci=None)\nsns.lineplot(data = sub_base_full, x= test[\"date\"] , y = \"num_sold\", label =\"Base full train prediction\" ,ci=None)\nsns.lineplot(data = sub_recursive, x= test[\"date\"] , y = \"num_sold\", label =\"Mutistep recursive prediction\" ,ci=None)\n\nplt.title(\"Recursive vs Baseline\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\n#sns.lineplot(data = train[train[\"date\"]>=VAL_SPLIT], x= \"date\" , y = \"num_sold\", label =\"actual\" ,ci=None)\nsns.lineplot(data = sub_base, x= test[\"date\"] , y = \"num_sold\", label =\"Baseline prediction\" ,ci=None)\nsns.lineplot(data = sub_store,x = test[\"date\"] , y = \"num_sold\", label =\"Store recursive\" ,ci=None)\nsns.lineplot(data = sub_product, x= test[\"date\"] , y = \"num_sold\", label =\"Product recursive\" ,ci=None)\nsns.lineplot(data = sub_country, x= test[\"date\"] , y = \"num_sold\", label =\"Country recursive\" ,ci=None)\nsns.lineplot(data = sub_all, x= test[\"date\"] , y = \"num_sold\", label =\"ALL recursive\" ,ci=None)\n\nplt.axvline(pd.to_datetime(\"2019-04-21\"),label= \"easter\",  c = \"r\", linestyle=\"--\")\nplt.text(x =pd.to_datetime(\"2019-04-21\") ,y = 0,s ='EASTER',rotation=90)\nplt.title(\"Split recursive predctions \")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\nsns.lineplot(data = sub_recursive, x= test[\"date\"] , y = \"num_sold\", label =\"Mutistep recursive\" ,ci=None)\nsns.lineplot(data = sub_country, x= test[\"date\"] , y = \"num_sold\", label =\"Country recursive\" ,ci=None)\nsns.lineplot(data = sub_store,x = test[\"date\"] , y = \"num_sold\", label =\"Store recursive\" ,ci=None)\nplt.title(\" Baseline Muti-step vs Store Multi-step\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Residuals comparison ","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(2,1, figsize=(25,15))\n\n\n#sns.lineplot(ax=ax[0],data = train[train[\"date\"]>=VAL_SPLIT], x= \"date\" , y = \"num_sold\", label =\"actual\" ,ci=None)\nsns.lineplot(ax=ax[0],data = sub_base_full, x= test[\"date\"] , y = \"num_sold\", label =\"Baseline full train prediction\" ,ci=None)\nsns.lineplot(ax=ax[0],data = sub_recursive, x= test[\"date\"] , y = \"num_sold\", label =\"Mutistep recursive prediction\" ,ci=None)\nax[0].set_title(f\"Baseline vs Recursive Baseline\")\n\nres_base_rec = sub_base_full[\"num_sold\"] - sub_recursive[\"num_sold\"]\nsns.lineplot(ax=ax[1], y = res_base_rec,  x= test[\"date\"] ,  label =\"Residuals\",ci=None )\nax[1].set_title(f\"Residuals baseline - recursive\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(2,1, figsize=(25,15))\n\nsns.lineplot(ax=ax[0],data = sub_recursive, x= test[\"date\"] , y = \"num_sold\", label =\"Mutistep recursive\" ,ci=None)\nsns.lineplot(ax=ax[0],data = sub_store,x = test[\"date\"] , y = \"num_sold\", label =\"Store recursive\" ,ci=None)\nax[0].set_title(\" Baseline recursive vs Store split recursive\")\n\nbase_store = sub_recursive[\"num_sold\"] -  sub_store[\"num_sold\"] \nsns.lineplot(ax=ax[1], y = base_store,  x= test[\"date\"] ,  label =\"Residuals\",ci=None )\nax[1].set_title(f\"Recursive baseline - Store split\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note**: \n* Store is less than full recursive ","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(2,1, figsize=(25,15))\n\nsns.lineplot(ax=ax[0],data = sub_recursive, x= test[\"date\"] , y = \"num_sold\", label =\"Mutistep recursive\" ,ci=None)\nsns.lineplot(ax=ax[0],data = sub_all,x = test[\"date\"] , y = \"num_sold\", label =\"ALL recursive\" ,ci=None)\nax[0].set_title(\" Baseline Muti-step vs ALL Multi-step\")\n\nbase_store = sub_recursive[\"num_sold\"] -  sub_all[\"num_sold\"] \nsns.lineplot(ax=ax[1], y = base_store,  x= test[\"date\"] ,  label =\"Residuals\",ci=None )\nax[1].set_title(f\"Recursive baseline - ALL Split\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}