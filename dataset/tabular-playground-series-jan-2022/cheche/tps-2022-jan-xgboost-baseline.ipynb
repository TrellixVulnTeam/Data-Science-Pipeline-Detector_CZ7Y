{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T05:58:41.589843Z","iopub.execute_input":"2022-01-06T05:58:41.590091Z","iopub.status.idle":"2022-01-06T05:58:41.598665Z","shell.execute_reply.started":"2022-01-06T05:58:41.590063Z","shell.execute_reply":"2022-01-06T05:58:41.597813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom optuna.samplers import TPESampler\n\nimport holidays","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.600633Z","iopub.execute_input":"2022-01-06T05:58:41.601058Z","iopub.status.idle":"2022-01-06T05:58:41.60728Z","shell.execute_reply.started":"2022-01-06T05:58:41.600871Z","shell.execute_reply":"2022-01-06T05:58:41.606504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.678611Z","iopub.execute_input":"2022-01-06T05:58:41.678824Z","iopub.status.idle":"2022-01-06T05:58:41.711811Z","shell.execute_reply.started":"2022-01-06T05:58:41.6788Z","shell.execute_reply":"2022-01-06T05:58:41.71117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Country List:['Finland' 'Norway' 'Sweden']\nholiday_FI = holidays.CountryHoliday('FI', years=[2015, 2016, 2017, 2018, 2019])\nholiday_NO = holidays.CountryHoliday('NO', years=[2015, 2016, 2017, 2018, 2019])\nholiday_SE = holidays.CountryHoliday('SE', years=[2015, 2016, 2017, 2018, 2019])\n\nholiday_dict = holiday_FI.copy()\nholiday_dict.update(holiday_NO)\nholiday_dict.update(holiday_SE)\n\ntrain_df['date'] = pd.to_datetime(train_df['date']) # Convert the date to datetime.\ntrain_df['holiday_name'] = train_df['date'].map(holiday_dict)\ntrain_df['is_holiday'] = np.where(train_df['holiday_name'].notnull(), 1, 0)\ntrain_df['holiday_name'] = train_df['holiday_name'].fillna('Not Holiday')\n\ntest_df['date'] = pd.to_datetime(test_df['date']) # Convert the date to datetime.\ntest_df['holiday_name'] = test_df['date'].map(holiday_dict)\ntest_df['is_holiday'] = np.where(test_df['holiday_name'].notnull(), 1, 0)\ntest_df['holiday_name'] = test_df['holiday_name'].fillna('Not Holiday')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.714139Z","iopub.execute_input":"2022-01-06T05:58:41.714588Z","iopub.status.idle":"2022-01-06T05:58:41.749265Z","shell.execute_reply.started":"2022-01-06T05:58:41.714551Z","shell.execute_reply":"2022-01-06T05:58:41.748659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef create_time_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Create features base on the date variable, the idea is to extract as much \n    information from the date componets.\n    Args\n        df: Input data to create the features.\n    Returns\n        df: A DataFrame with the new time base features.\n    \"\"\"\n    \n    df['date'] = pd.to_datetime(df['date']) # Convert the date to datetime.\n    \n    # Start the creating future process.\n    df['year'] = df['date'].dt.year\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['dayofmonth'] = df['date'].dt.days_in_month\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['weekofyear'] = df['date'].dt.weekofyear\n    df['weekday'] = df['date'].dt.weekday\n    df['is_weekend'] = np.where((df['weekday'] == 5) | (df['weekday'] == 6), 1, 0)\n    \n    return df\n\ntrain_df = create_time_features(train_df)\ntest_df = create_time_features(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.75042Z","iopub.execute_input":"2022-01-06T05:58:41.750652Z","iopub.status.idle":"2022-01-06T05:58:41.8282Z","shell.execute_reply.started":"2022-01-06T05:58:41.75062Z","shell.execute_reply":"2022-01-06T05:58:41.827484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = train_df.drop(['row_id', 'date', 'num_sold'], axis=1)\ny_data = train_df.num_sold\n\nx_test = test_df.drop(['row_id', 'date'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.829191Z","iopub.execute_input":"2022-01-06T05:58:41.829453Z","iopub.status.idle":"2022-01-06T05:58:41.84151Z","shell.execute_reply.started":"2022-01-06T05:58:41.82942Z","shell.execute_reply":"2022-01-06T05:58:41.840524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CATEGORICAL = ['country', 'store', 'product', 'holiday_name']","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.844921Z","iopub.execute_input":"2022-01-06T05:58:41.84511Z","iopub.status.idle":"2022-01-06T05:58:41.84888Z","shell.execute_reply.started":"2022-01-06T05:58:41.845087Z","shell.execute_reply":"2022-01-06T05:58:41.847973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.850468Z","iopub.execute_input":"2022-01-06T05:58:41.850716Z","iopub.status.idle":"2022-01-06T05:58:41.85779Z","shell.execute_reply.started":"2022-01-06T05:58:41.850683Z","shell.execute_reply":"2022-01-06T05:58:41.856816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_categ_features(df, categ_colums = CATEGORICAL):\n    \"\"\"\n    Use the label encoder to encode categorical features...\n    Args\n        df\n        categ_colums\n    Returns\n        df\n    \"\"\"\n    le = LabelEncoder()\n    for col in categ_colums:\n        df[col] = le.fit_transform(df[col])\n    return df\n\nx_data = encode_categ_features(x_data)\nx_test = encode_categ_features(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.859238Z","iopub.execute_input":"2022-01-06T05:58:41.859743Z","iopub.status.idle":"2022-01-06T05:58:41.908636Z","shell.execute_reply.started":"2022-01-06T05:58:41.859691Z","shell.execute_reply":"2022-01-06T05:58:41.907835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_data, y_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.961567Z","iopub.execute_input":"2022-01-06T05:58:41.961799Z","iopub.status.idle":"2022-01-06T05:58:41.973117Z","shell.execute_reply.started":"2022-01-06T05:58:41.961738Z","shell.execute_reply":"2022-01-06T05:58:41.972154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.974272Z","iopub.execute_input":"2022-01-06T05:58:41.974518Z","iopub.status.idle":"2022-01-06T05:58:41.979277Z","shell.execute_reply.started":"2022-01-06T05:58:41.974484Z","shell.execute_reply":"2022-01-06T05:58:41.978529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.982572Z","iopub.execute_input":"2022-01-06T05:58:41.98348Z","iopub.status.idle":"2022-01-06T05:58:41.988311Z","shell.execute_reply.started":"2022-01-06T05:58:41.983439Z","shell.execute_reply":"2022-01-06T05:58:41.9872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n\n    param_grid = {\n              'n_estimators': trial.suggest_int('n_estimators', 500, 5000),\n              'learning_rate': trial.suggest_discrete_uniform('learning_rate',0.01,0.1,0.01),\n              'subsample': trial.suggest_categorical ('subsample', [0.2,0.3,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n              'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree',0.1,1.0, 0.1),\n              'max_depth': trial.suggest_int('max_depth', 2, 20),\n              'booster': 'gbtree',\n              'gamma': trial.suggest_uniform('gamma',1.0,10.0),\n              'reg_alpha': trial.suggest_int('reg_alpha',50,100),\n              'reg_lambda': trial.suggest_int('reg_lambda',50,100),\n              'random_state': 42,\n                 }\n\n    xgb_model = XGBRegressor(**param_grid, tree_method='gpu_hist', predictor='gpu_predictor')\n\n    xgb_model.fit(x_train, y_train, verbose=False)\n    y_pred = xgb_model.predict(x_val)\n    return SMAPE(y_val, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:41.989406Z","iopub.execute_input":"2022-01-06T05:58:41.989666Z","iopub.status.idle":"2022-01-06T05:58:42.000134Z","shell.execute_reply.started":"2022-01-06T05:58:41.98963Z","shell.execute_reply":"2022-01-06T05:58:41.999408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_time = 1 * 30 * 60 # h * m * s\nstudy = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='XGBRegressor')\nstudy.optimize(objective, timeout=train_time)\n\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial:')\ntrial = study.best_trial\n\nprint('\\tValue: {}'.format(trial.value))\nprint('\\tParams: ')\nfor key, value in trial.params.items():\n    print('\\t\\t{}: {}'.format(key, value))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:58:42.00124Z","iopub.execute_input":"2022-01-06T05:58:42.002211Z","iopub.status.idle":"2022-01-06T06:10:45.47518Z","shell.execute_reply.started":"2022-01-06T05:58:42.002172Z","shell.execute_reply":"2022-01-06T06:10:45.473846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = trial.params\n# xgb_params = {\n#                 'n_estimators': 4492,\n#                 'learning_rate': 0.01,\n#                 'subsample': 1.0,\n#                 'colsample_bytree': 0.2,\n#                 'max_depth': 15,\n#                 'gamma': 1.0328829988080024,\n#                 'reg_alpha': 100,\n#                 'reg_lambda': 93 }\n\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['predictor'] = 'gpu_predictor'","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:10:45.476528Z","iopub.execute_input":"2022-01-06T06:10:45.476789Z","iopub.status.idle":"2022-01-06T06:10:45.48368Z","shell.execute_reply.started":"2022-01-06T06:10:45.476754Z","shell.execute_reply":"2022-01-06T06:10:45.483082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBRegressor(**xgb_params)\nmodel.fit(x_train, y_train)\n\ny_val_pred = model.predict(x_val)\nsmape_val = SMAPE(y_val, y_val_pred)\n\nprint(f'smape val: {smape_val}')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:10:45.485179Z","iopub.execute_input":"2022-01-06T06:10:45.485567Z","iopub.status.idle":"2022-01-06T06:10:45.944342Z","shell.execute_reply.started":"2022-01-06T06:10:45.48553Z","shell.execute_reply":"2022-01-06T06:10:45.943681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:10:45.947373Z","iopub.execute_input":"2022-01-06T06:10:45.949564Z","iopub.status.idle":"2022-01-06T06:10:45.976242Z","shell.execute_reply.started":"2022-01-06T06:10:45.949522Z","shell.execute_reply":"2022-01-06T06:10:45.975773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-jan-2022/sample_submission.csv')\nsubmission.num_sold = y_test\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:10:45.979571Z","iopub.execute_input":"2022-01-06T06:10:45.981802Z","iopub.status.idle":"2022-01-06T06:10:46.027476Z","shell.execute_reply.started":"2022-01-06T06:10:45.981756Z","shell.execute_reply":"2022-01-06T06:10:46.02685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:11:15.961972Z","iopub.execute_input":"2022-01-06T06:11:15.962514Z","iopub.status.idle":"2022-01-06T06:11:15.971499Z","shell.execute_reply.started":"2022-01-06T06:11:15.962474Z","shell.execute_reply":"2022-01-06T06:11:15.970599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}