{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install darts","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-24T09:43:21.221914Z","iopub.execute_input":"2022-01-24T09:43:21.222545Z","iopub.status.idle":"2022-01-24T09:45:52.887011Z","shell.execute_reply.started":"2022-01-24T09:43:21.22245Z","shell.execute_reply":"2022-01-24T09:45:52.88592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom darts import TimeSeries\nfrom darts.models import Prophet\nfrom darts.metrics import smape\n\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-24T09:57:51.565124Z","iopub.execute_input":"2022-01-24T09:57:51.565391Z","iopub.status.idle":"2022-01-24T09:57:51.576791Z","shell.execute_reply.started":"2022-01-24T09:57:51.565362Z","shell.execute_reply":"2022-01-24T09:57:51.576035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook will use Prophet model. Please note that I have no idea what I'm doing, and I'm just fooling around, so if I'm doing anything that seems dumb, please notify me in the comments.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/train.csv', parse_dates=['date'])\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2022/test.csv', parse_dates=['date'])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:57:52.604423Z","iopub.execute_input":"2022-01-24T09:57:52.604723Z","iopub.status.idle":"2022-01-24T09:57:52.669045Z","shell.execute_reply.started":"2022-01-24T09:57:52.60469Z","shell.execute_reply":"2022-01-24T09:57:52.668146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll concatenate the train and test data in order to dissect them into different groups based on country, store and product for time series prediction, then I'll extract the test prediction later and concatenate them for submission.","metadata":{}},{"cell_type":"code","source":"train_len = train.shape[0]\ntest_len = test.shape[0]\n\ntrain_len, test_len","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:57.285287Z","iopub.execute_input":"2022-01-24T09:45:57.285519Z","iopub.status.idle":"2022-01-24T09:45:57.293733Z","shell.execute_reply.started":"2022-01-24T09:45:57.285492Z","shell.execute_reply":"2022-01-24T09:45:57.292447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.date.plot();","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:57.295889Z","iopub.execute_input":"2022-01-24T09:45:57.296274Z","iopub.status.idle":"2022-01-24T09:45:57.670053Z","shell.execute_reply.started":"2022-01-24T09:45:57.296236Z","shell.execute_reply":"2022-01-24T09:45:57.669064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.date.plot();","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:57.671344Z","iopub.execute_input":"2022-01-24T09:45:57.671666Z","iopub.status.idle":"2022-01-24T09:45:58.038443Z","shell.execute_reply.started":"2022-01-24T09:45:57.671627Z","shell.execute_reply":"2022-01-24T09:45:58.037625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test set is one year, so I'll make a validation set that is also one year starting from 2018.\n\nI'll make a pipeline for prediciton using the validation set, then I'll apply the same pipeline on the test after training using the entire training set.","metadata":{}},{"cell_type":"code","source":"dev = train.query('date < \"2018-01-01\"')\nval = train.query('date >= \"2018-01-01\"')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:58.039752Z","iopub.execute_input":"2022-01-24T09:45:58.040665Z","iopub.status.idle":"2022-01-24T09:45:58.060666Z","shell.execute_reply.started":"2022-01-24T09:45:58.040612Z","shell.execute_reply":"2022-01-24T09:45:58.059546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev.date.plot(label='Dev set');\nval.date.plot(label='Val set');\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:58.062137Z","iopub.execute_input":"2022-01-24T09:45:58.062377Z","iopub.status.idle":"2022-01-24T09:45:58.528376Z","shell.execute_reply.started":"2022-01-24T09:45:58.062348Z","shell.execute_reply":"2022-01-24T09:45:58.527546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now I'll group the dev set by country, store and product and fit the model for each group.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\ndev.groupby(['country', 'store', 'product']).num_sold.plot();\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:58.529621Z","iopub.execute_input":"2022-01-24T09:45:58.529843Z","iopub.status.idle":"2022-01-24T09:45:59.566384Z","shell.execute_reply.started":"2022-01-24T09:45:58.529816Z","shell.execute_reply":"2022-01-24T09:45:59.56538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_groups = dev.groupby(['country', 'store', 'product'])\nval_groups = val.groupby(['country', 'store', 'product'])\nmodels = {}\n\nprint('Training')\nfor group, df in dev_groups:\n    dev_series = TimeSeries.from_dataframe(df, time_col='date', value_cols='num_sold')    \n    prophet = Prophet()\n    prophet.fit(dev_series)\n    models[group] = prophet\n    \n\nprint('Evaluation')\nfor group, df in val_groups:\n    val_series = TimeSeries.from_dataframe(df, time_col='date', value_cols='num_sold')\n    prophet = models[group]\n    forecast = prophet.predict(len(val_series))\n    print(group, 'SMAPE:', smape(forecast, val_series))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:45:59.569459Z","iopub.execute_input":"2022-01-24T09:45:59.570072Z","iopub.status.idle":"2022-01-24T09:47:11.986265Z","shell.execute_reply.started":"2022-01-24T09:45:59.57001Z","shell.execute_reply":"2022-01-24T09:47:11.985047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's working, so let's add holidays.","metadata":{}},{"cell_type":"code","source":"import holidays\nimport dateutil.easter as easter\n\nholiday_list = []\n\nfor date in holidays.Finland(years=[2014, 2015, 2016, 2017, 2018, 2019, 2020], observed=True).items():\n    holiday_list.append([date[0], date[1], \"Finland\"])\n    \nfor date in holidays.Norway(years=[2014, 2015, 2016, 2017, 2018, 2019, 2020], observed=True).items():\n    holiday_list.append([date[0], date[1], \"Norway\"])\n    \nfor date in holidays.Sweden(years=[2014, 2015, 2016, 2017, 2018, 2019, 2020], observed=True).items():\n    if date[1]!='Söndag':\n        holiday_list.append([date[0], date[1].replace(\", Söndag\", \"\"), \"Sweden\"])\n    \n    \n# Last week of the year\nfor year in [2014, 2015, 2016, 2017, 2018, 2019, 2020]:\n    for i, day in enumerate(range(24, 32)):\n        for country in ['Finland', 'Sweden', 'Norway']:\n             holiday_list.append([pd.to_datetime(f\"{year}-{12}-{day}\").date(), \n                                  f\"Last week of the year (day {i+1})\", \n                                  country])\n# Swedish Rock Concert\nfor start, end, year in [[4,7,2014],[3,6,2015],[8,11,2016],[7,10,2017],[6,10,2018],[5,8,2019]]:\n    for i, day in enumerate(range(start, end+1)):\n        holiday_list.append([pd.to_datetime(f\"{year}-{6}-{day}\").date(), \n                                  f\"Swedish Rock Concert (day {i+1})\", \n                                  \"Sweden\"])\n        \n# Last Wednesday of June\nfor date in ['2014-06-25', '2015-06-24', '2016-06-29', '2017-06-28', '2018-06-27', '2019-06-26', '2020-06-24']:\n    for country in ['Finland', 'Sweden', 'Norway']:\n         holiday_list.append([pd.to_datetime(date).date(), \n                                  f\"Last Wednesday of June\", \n                                  country])\n            \n# First Sunday of November\nfor date in ['2014-11-02', '2015-11-1', '2016-11-6', '2017-11-5', '2018-11-4', '2019-11-3', '2020-11-01']:\n    for country in ['Finland', 'Sweden', 'Norway']:\n         holiday_list.append([pd.to_datetime(date).date(), \n                                  f\"First Sunday of November\", \n                                  country])\n            \n# Independence Day of Finland\nfor year in [2014, 2015, 2016, 2017, 2018, 2019, 2020]:\n    holiday_list.append([pd.to_datetime(f\"{year}-{12}-{6}\").date(), \n                                      f\"Independence Day of Finland\", \n                                      'Finland'])\n\n# Easter\neaster_date = [easter.easter(y) for y in [2014, 2015, 2016, 2017, 2018, 2019, 2020]]\nfor date in easter_date:\n    for country in ['Finland', 'Sweden', 'Norway']:\n         holiday_list.append([pd.to_datetime(date).date(), \n                                  f\"Easter\", \n                                  country])\n            \n\n\nholidays = pd.DataFrame(holiday_list, columns=['ds', 'holiday', 'country'])\nholidays = holidays.drop_duplicates(['ds', 'country'], keep='first')\nholidays = holidays.sort_values(['ds', 'country'])\nholidays['ds'] = pd.to_datetime(holidays['ds'])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:47:11.98792Z","iopub.execute_input":"2022-01-24T09:47:11.988258Z","iopub.status.idle":"2022-01-24T09:47:12.062568Z","shell.execute_reply.started":"2022-01-24T09:47:11.988214Z","shell.execute_reply":"2022-01-24T09:47:12.061976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_groups = dev.groupby(['country', 'store', 'product'])\nval_groups = val.groupby(['country', 'store', 'product'])\nmodels = {}\n\nprint('Training')\nfor group, df in dev_groups:\n    country = group[0]\n    country_holidays = holidays.query('country == @country').drop('country', axis=1)\n    dev_series = TimeSeries.from_dataframe(df, time_col='date', value_cols='num_sold')    \n    prophet = Prophet(holidays=country_holidays)\n    prophet.fit(dev_series)\n    models[group] = prophet\n    \n\nprint('Evaluation')\nfor group, df in val_groups:\n    val_series = TimeSeries.from_dataframe(df, time_col='date', value_cols='num_sold')\n    prophet = models[group]\n    forecast = prophet.predict(len(val_series))\n    print(group, 'SMAPE:', smape(forecast, val_series))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:47:12.063736Z","iopub.execute_input":"2022-01-24T09:47:12.064616Z","iopub.status.idle":"2022-01-24T09:48:31.599468Z","shell.execute_reply.started":"2022-01-24T09:47:12.06457Z","shell.execute_reply":"2022-01-24T09:48:31.59857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's make put these into predictions into a dataframe.","metadata":{}},{"cell_type":"code","source":"val_groups = val.groupby(['country', 'store', 'product'])\nval_pred = pd.DataFrame()\n\nfor group, df in val_groups:\n    val_series = TimeSeries.from_dataframe(df, time_col='date', value_cols='num_sold')\n    prophet = models[group]\n    forecast = prophet.predict(len(val_series))\n    df['pred'] = forecast.values().reshape(-1,)\n    val_pred = pd.concat([val_pred, df], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:48:31.60115Z","iopub.execute_input":"2022-01-24T09:48:31.601476Z","iopub.status.idle":"2022-01-24T09:49:35.331078Z","shell.execute_reply.started":"2022-01-24T09:48:31.601435Z","shell.execute_reply":"2022-01-24T09:49:35.33005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred.plot(x='num_sold', y='pred', kind='scatter', figsize=(10, 4));","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:49:35.33281Z","iopub.execute_input":"2022-01-24T09:49:35.333297Z","iopub.status.idle":"2022-01-24T09:49:35.65265Z","shell.execute_reply.started":"2022-01-24T09:49:35.333246Z","shell.execute_reply":"2022-01-24T09:49:35.652082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's train with full training set and predict test set.","metadata":{}},{"cell_type":"code","source":"def training(df):\n    df_groups = df.groupby(['country', 'store', 'product'])\n    models = {}\n    print('Training')\n    for group, df in df_groups:\n        country = group[0]\n        country_holidays = holidays.query('country == @country').drop('country', axis=1)\n        series = TimeSeries.from_dataframe(df, time_col='date', value_cols='num_sold')    \n        prophet = Prophet(holidays=country_holidays)\n        prophet.fit(series)\n        models[group] = prophet\n    return models\n\ndef inference(models, df):\n    df_groups = df.groupby(['country', 'store', 'product'])\n    df_pred = pd.DataFrame()\n\n    for group, df in df_groups:\n        prophet = models[group]\n        forecast = prophet.predict(len(df))\n        df['pred'] = forecast.values().reshape(-1,)\n        df_pred = pd.concat([df_pred, df], axis=0)\n        \n    return df_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:59:34.285185Z","iopub.execute_input":"2022-01-24T09:59:34.285859Z","iopub.status.idle":"2022-01-24T09:59:34.299551Z","shell.execute_reply.started":"2022-01-24T09:59:34.285801Z","shell.execute_reply":"2022-01-24T09:59:34.298627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = training(train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = inference(models, test)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:59:35.632203Z","iopub.execute_input":"2022-01-24T09:59:35.633224Z","iopub.status.idle":"2022-01-24T10:00:37.513673Z","shell.execute_reply.started":"2022-01-24T09:59:35.633168Z","shell.execute_reply":"2022-01-24T10:00:37.51264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:01:25.016746Z","iopub.execute_input":"2022-01-24T10:01:25.017255Z","iopub.status.idle":"2022-01-24T10:01:25.03244Z","shell.execute_reply.started":"2022-01-24T10:01:25.01722Z","shell.execute_reply":"2022-01-24T10:01:25.031405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\ntest_pred.groupby(['country', 'store', 'product']).pred.plot();\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:01:06.512384Z","iopub.execute_input":"2022-01-24T10:01:06.512744Z","iopub.status.idle":"2022-01-24T10:01:07.340221Z","shell.execute_reply.started":"2022-01-24T10:01:06.512707Z","shell.execute_reply":"2022-01-24T10:01:07.338829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_pred[['row_id', 'pred']].rename({'pred': 'num_sold'}, axis=1).sort_values('row_id')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:01:59.93274Z","iopub.execute_input":"2022-01-24T10:01:59.933556Z","iopub.status.idle":"2022-01-24T10:01:59.948616Z","shell.execute_reply.started":"2022-01-24T10:01:59.933516Z","shell.execute_reply":"2022-01-24T10:01:59.947846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now submit the results.","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:02:33.201787Z","iopub.execute_input":"2022-01-24T10:02:33.20216Z","iopub.status.idle":"2022-01-24T10:02:33.239313Z","shell.execute_reply.started":"2022-01-24T10:02:33.202116Z","shell.execute_reply":"2022-01-24T10:02:33.238045Z"},"trusted":true},"execution_count":null,"outputs":[]}]}