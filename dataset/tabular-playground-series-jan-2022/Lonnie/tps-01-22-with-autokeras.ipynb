{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS-01-22 with AutoKeras\n\n## Overview\nIn this notebook I will use AutoKeras to build models for [Tabular Playground Series - Jan 2022 Competition](https://www.kaggle.com/c/tabular-playground-series-jan-2022). I will explore using [AutoModel](https://autokeras.com/auto_model/#automodel-class) which is keras functional API style with more flexibility. Before Modeling, I will also perform some Exploratory data analysis and feature engineering to find insights.","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport os\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.527224Z","iopub.execute_input":"2022-01-01T17:46:18.527492Z","iopub.status.idle":"2022-01-01T17:46:18.531636Z","shell.execute_reply.started":"2022-01-01T17:46:18.52746Z","shell.execute_reply":"2022-01-01T17:46:18.530722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    input_path = \"../input/tabular-playground-series-jan-2022\"\n    train_path = os.path.join(input_path, \"train.csv\")\n    test_path = os.path.join(input_path, \"test.csv\")\n    n_folds = 5\n    batch_size = 128\n    label_name = \"num_sold\"\n    modes = [\"train\", \"inference\"]\n    mode = modes[1]\n    output_dataset_paths = [\"../input/tps0122-with-autokeras-output-v1/\"]\n    submission_path = os.path.join(input_path, \"sample_submission.csv\")\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.533244Z","iopub.execute_input":"2022-01-01T17:46:18.533857Z","iopub.status.idle":"2022-01-01T17:46:18.542594Z","shell.execute_reply.started":"2022-01-01T17:46:18.533821Z","shell.execute_reply":"2022-01-01T17:46:18.541831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.mode == config.modes[0]:\n    !pip install autokeras","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.543579Z","iopub.execute_input":"2022-01-01T17:46:18.543894Z","iopub.status.idle":"2022-01-01T17:46:18.55244Z","shell.execute_reply.started":"2022-01-01T17:46:18.54384Z","shell.execute_reply":"2022-01-01T17:46:18.551556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(config.train_path)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.593259Z","iopub.execute_input":"2022-01-01T17:46:18.593891Z","iopub.status.idle":"2022-01-01T17:46:18.633733Z","shell.execute_reply.started":"2022-01-01T17:46:18.593831Z","shell.execute_reply":"2022-01-01T17:46:18.632995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(config.test_path)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.63482Z","iopub.execute_input":"2022-01-01T17:46:18.637002Z","iopub.status.idle":"2022-01-01T17:46:18.662292Z","shell.execute_reply.started":"2022-01-01T17:46:18.636964Z","shell.execute_reply":"2022-01-01T17:46:18.661653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(config.submission_path)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.663424Z","iopub.execute_input":"2022-01-01T17:46:18.664117Z","iopub.status.idle":"2022-01-01T17:46:18.68239Z","shell.execute_reply.started":"2022-01-01T17:46:18.664084Z","shell.execute_reply":"2022-01-01T17:46:18.681748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA & Preprocessing","metadata":{}},{"cell_type":"code","source":"def visualize(df, column):\n    df[column].value_counts().plot(kind=\"bar\")\n    plt.title(\"Distribution of %s\"%(column))\n    plt.show()\n    df.groupby(column)[\"num_sold\"].sum().plot(kind=\"bar\")\n    plt.title(\"Total Sale Data in different %s\"%(column))\n    plt.show()\n    df.groupby(column)[\"num_sold\"].mean().plot(kind=\"bar\")\n    plt.title(\"Average Sale Data in different %s\"%(column))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.684145Z","iopub.execute_input":"2022-01-01T17:46:18.684358Z","iopub.status.idle":"2022-01-01T17:46:18.689725Z","shell.execute_reply.started":"2022-01-01T17:46:18.684328Z","shell.execute_reply":"2022-01-01T17:46:18.688917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For different countries, Norway has the highest Sale Data; For different products, Kaggle Hat has the highest Sale Data; For different stores, KaggleRama has the highest Sale Data.","metadata":{}},{"cell_type":"code","source":"for column in [\"country\", \"product\", \"store\"]:\n    visualize(train, column)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:18.690791Z","iopub.execute_input":"2022-01-01T17:46:18.691648Z","iopub.status.idle":"2022-01-01T17:46:20.400672Z","shell.execute_reply.started":"2022-01-01T17:46:18.691613Z","shell.execute_reply":"2022-01-01T17:46:20.39983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering for datetime","metadata":{}},{"cell_type":"code","source":"def day_of_year(date):\n    daysInMonth = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n    year = 0\n    month = 0\n    day = 0\n    i = 0\n    value = 0\n    for c in date:\n        value = ord(c) - 48\n        if value >= 0:\n            if i == 0:\n                year = year * 10 + value\n            elif i == 1:\n                month = month * 10 + value\n            else:\n                day = day * 10 + value\n        else:\n            i += 1\n    num_days = day + daysInMonth[month - 1]\n    is_leap = year % 400 == 0 if year % 100 == 0 else year % 4 == 0\n    if is_leap and month > 2:\n        num_days += 1\n    return num_days\n\ndef add_datetime_features(df):\n    new_df = df.copy()\n    years = []\n    months = []\n    days = []\n    weekdays = []\n    weekends = []\n    seasons = []\n    day_of_years = []\n    for item in df[\"date\"]:\n        dt = time.strptime(item, '%Y-%m-%d')\n        is_weekend = 1 if dt.tm_wday >= 5 else 0\n        season = (dt.tm_mon - 3) // 3 % 4\n        years.append(dt.tm_year)\n        months.append(dt.tm_mon)\n        days.append(dt.tm_mday)\n        weekdays.append(dt.tm_wday)\n        weekends.append(is_weekend)\n        seasons.append(season)\n        day_of_years.append(day_of_year(item))\n    new_df[\"year\"] = years\n    new_df[\"month\"] = months\n    new_df[\"day\"] = days\n    new_df[\"weekday\"] = weekdays\n    new_df[\"weekend\"] = weekends\n    new_df[\"season\"] = seasons\n    new_df[\"day_of_year\"] = day_of_years\n    new_df[\"end_of_year\"] = new_df[\"day_of_year\"] >= 350\n    new_df[\"end_of_year\"] = new_df[\"end_of_year\"]\n    new_df[\"end_of_year\"] = new_df[\"end_of_year\"].astype(int)\n    new_df.pop(\"date\")\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:20.401931Z","iopub.execute_input":"2022-01-01T17:46:20.402333Z","iopub.status.idle":"2022-01-01T17:46:20.416525Z","shell.execute_reply.started":"2022-01-01T17:46:20.402297Z","shell.execute_reply":"2022-01-01T17:46:20.415735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = add_datetime_features(train)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:20.418009Z","iopub.execute_input":"2022-01-01T17:46:20.41829Z","iopub.status.idle":"2022-01-01T17:46:20.895957Z","shell.execute_reply.started":"2022-01-01T17:46:20.418252Z","shell.execute_reply":"2022-01-01T17:46:20.895264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = add_datetime_features(test)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:20.897214Z","iopub.execute_input":"2022-01-01T17:46:20.897604Z","iopub.status.idle":"2022-01-01T17:46:21.024277Z","shell.execute_reply.started":"2022-01-01T17:46:20.897567Z","shell.execute_reply":"2022-01-01T17:46:21.023613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop Id columns\n","metadata":{}},{"cell_type":"code","source":"train_df.pop(\"row_id\")\ntest_df.pop(\"row_id\");","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:21.025345Z","iopub.execute_input":"2022-01-01T17:46:21.027019Z","iopub.status.idle":"2022-01-01T17:46:21.032403Z","shell.execute_reply.started":"2022-01-01T17:46:21.026979Z","shell.execute_reply":"2022-01-01T17:46:21.031759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### More EDA\nAs we can see that Sale Data is increasing with year, but it is greater in end of month, end of week and Spring and Winter. It has strong cyclicity.","metadata":{}},{"cell_type":"code","source":"for column in [\"year\", \"month\", \"day\", \"weekday\", \"season\", \"weekend\", \"end_of_year\"]:\n    visualize(train_df, column)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:21.037108Z","iopub.execute_input":"2022-01-01T17:46:21.037306Z","iopub.status.idle":"2022-01-01T17:46:24.883828Z","shell.execute_reply.started":"2022-01-01T17:46:21.037276Z","shell.execute_reply":"2022-01-01T17:46:24.88308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:24.88519Z","iopub.execute_input":"2022-01-01T17:46:24.885655Z","iopub.status.idle":"2022-01-01T17:46:24.902444Z","shell.execute_reply.started":"2022-01-01T17:46:24.885618Z","shell.execute_reply":"2022-01-01T17:46:24.901778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:24.903518Z","iopub.execute_input":"2022-01-01T17:46:24.903831Z","iopub.status.idle":"2022-01-01T17:46:24.919833Z","shell.execute_reply.started":"2022-01-01T17:46:24.903794Z","shell.execute_reply":"2022-01-01T17:46:24.919223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([train_df, test_df])\ncategorical_columns = ['country', 'store', 'product', 'year', \"month\", 'weekday', 'season']\nfor column in categorical_columns:\n    item = pd.get_dummies(data[column])\n    item.columns = [\"_\".join([column, \"_\".join(str(item).split(\" \"))]) for item in item.columns]\n    data = pd.concat([data, item], axis=1)\n    data.pop(column)\ntrain_df = data[0:len(train_df)]\ntest_df = data[len(train_df):]\ntest_df.pop(\"num_sold\");","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:24.921659Z","iopub.execute_input":"2022-01-01T17:46:24.922121Z","iopub.status.idle":"2022-01-01T17:46:24.961179Z","shell.execute_reply.started":"2022-01-01T17:46:24.922086Z","shell.execute_reply":"2022-01-01T17:46:24.960444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:24.962447Z","iopub.execute_input":"2022-01-01T17:46:24.962693Z","iopub.status.idle":"2022-01-01T17:46:24.985206Z","shell.execute_reply.started":"2022-01-01T17:46:24.962661Z","shell.execute_reply":"2022-01-01T17:46:24.984542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:24.986504Z","iopub.execute_input":"2022-01-01T17:46:24.987081Z","iopub.status.idle":"2022-01-01T17:46:25.007457Z","shell.execute_reply.started":"2022-01-01T17:46:24.987045Z","shell.execute_reply":"2022-01-01T17:46:25.006786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in [train_df, test_df]:\n    for column in data.columns:\n        data[column] =  data[column].astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:25.008722Z","iopub.execute_input":"2022-01-01T17:46:25.009012Z","iopub.status.idle":"2022-01-01T17:46:25.045262Z","shell.execute_reply.started":"2022-01-01T17:46:25.008976Z","shell.execute_reply":"2022-01-01T17:46:25.044587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Validation Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit, KFold, train_test_split\nX_train, X_val = train_test_split(train_df, random_state=42)\ny_train = X_train.pop(config.label_name)\ny_val = X_val.pop(config.label_name)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:25.046539Z","iopub.execute_input":"2022-01-01T17:46:25.046962Z","iopub.status.idle":"2022-01-01T17:46:25.889618Z","shell.execute_reply.started":"2022-01-01T17:46:25.046921Z","shell.execute_reply":"2022-01-01T17:46:25.888916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:25.890818Z","iopub.execute_input":"2022-01-01T17:46:25.891094Z","iopub.status.idle":"2022-01-01T17:46:25.924404Z","shell.execute_reply.started":"2022-01-01T17:46:25.891061Z","shell.execute_reply":"2022-01-01T17:46:25.923762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_ds = train_ds.shuffle(256).batch(config.batch_size).prefetch(tf.data.AUTOTUNE).cache()\nvalid_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\nvalid_ds = valid_ds.batch(config.batch_size).prefetch(tf.data.AUTOTUNE).cache()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:25.925756Z","iopub.execute_input":"2022-01-01T17:46:25.926022Z","iopub.status.idle":"2022-01-01T17:46:32.164367Z","shell.execute_reply.started":"2022-01-01T17:46:25.925988Z","shell.execute_reply":"2022-01-01T17:46:32.163668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"def inference(models, X):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(X)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)\ndef smape(y_true, y_pred):\n    return 2.0 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:50:41.096449Z","iopub.execute_input":"2022-01-01T17:50:41.096749Z","iopub.status.idle":"2022-01-01T17:50:41.102791Z","shell.execute_reply.started":"2022-01-01T17:50:41.096712Z","shell.execute_reply":"2022-01-01T17:50:41.102119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.mode == config.modes[0]:\n    import autokeras as ak\n    inputs = ak.StructuredDataInput()\n    x1 = ak.DenseBlock()(inputs)\n    x2 = ak.DenseBlock()(inputs)\n    x = ak.Merge()([x1, x2])\n    output = ak.RegressionHead()(x)\n    auto_model = ak.AutoModel(\n        overwrite=True, inputs=inputs, outputs=output, max_trials=20\n    )\n    auto_model.fit(train_ds, validation_data=valid_ds, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:32.17198Z","iopub.execute_input":"2022-01-01T17:46:32.172388Z","iopub.status.idle":"2022-01-01T17:46:32.181419Z","shell.execute_reply.started":"2022-01-01T17:46:32.17235Z","shell.execute_reply":"2022-01-01T17:46:32.180583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save the Model","metadata":{}},{"cell_type":"code","source":"if config.mode == config.modes[0]:\n    tf_auto_model = auto_model.export_model()\n    tf_auto_model.save(\"auto_model.tf\")","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:46:32.182508Z","iopub.execute_input":"2022-01-01T17:46:32.183373Z","iopub.status.idle":"2022-01-01T17:46:32.19133Z","shell.execute_reply.started":"2022-01-01T17:46:32.183334Z","shell.execute_reply":"2022-01-01T17:46:32.190461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the Model","metadata":{}},{"cell_type":"code","source":"models = []\nif config.mode == config.modes[0]:\n    model = tf.keras.models.load_model(\"auto_model.tf\")\n    models.append(model)\n    tf.keras.utils.plot_model(model, show_shapes=True)\nelse:\n    for path in config.output_dataset_paths:\n        model = tf.keras.models.load_model(path + \"auto_model.tf\")\n        models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:53:29.951592Z","iopub.execute_input":"2022-01-01T17:53:29.951886Z","iopub.status.idle":"2022-01-01T17:53:30.427673Z","shell.execute_reply.started":"2022-01-01T17:53:29.951836Z","shell.execute_reply":"2022-01-01T17:53:30.42692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:53:32.311157Z","iopub.execute_input":"2022-01-01T17:53:32.31173Z","iopub.status.idle":"2022-01-01T17:53:32.327165Z","shell.execute_reply.started":"2022-01-01T17:53:32.311692Z","shell.execute_reply":"2022-01-01T17:53:32.326426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"for model in models:\n    y_pred = inference([model], valid_ds)\n    print(\"SMAPE:\", smape(y_val, y_pred.reshape(-1)))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:53:55.40981Z","iopub.execute_input":"2022-01-01T17:53:55.410668Z","iopub.status.idle":"2022-01-01T17:53:55.521285Z","shell.execute_reply.started":"2022-01-01T17:53:55.410617Z","shell.execute_reply":"2022-01-01T17:53:55.52054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices((test_df))\ntest_ds = test_ds.batch(config.batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:54:30.956789Z","iopub.execute_input":"2022-01-01T17:54:30.957407Z","iopub.status.idle":"2022-01-01T17:54:30.989654Z","shell.execute_reply.started":"2022-01-01T17:54:30.957366Z","shell.execute_reply":"2022-01-01T17:54:30.988915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = inference(models, test_ds)\nsubmission[\"num_sold\"] = y_pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T17:54:32.950153Z","iopub.execute_input":"2022-01-01T17:54:32.950976Z","iopub.status.idle":"2022-01-01T17:54:33.092506Z","shell.execute_reply.started":"2022-01-01T17:54:32.95093Z","shell.execute_reply":"2022-01-01T17:54:33.091739Z"},"trusted":true},"execution_count":null,"outputs":[]}]}