{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport dateutil.easter as easter\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-28T04:41:09.619532Z","iopub.execute_input":"2022-01-28T04:41:09.620197Z","iopub.status.idle":"2022-01-28T04:41:09.66633Z","shell.execute_reply.started":"2022-01-28T04:41:09.620073Z","shell.execute_reply":"2022-01-28T04:41:09.665693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearly all of our data is categorical, and we do not know a clear correlation between categories and num_sold, so we will hot encode using scikit-learn's OneHotEnocder\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\ndef dataProcess(x):\n    one_hot = ce.OneHotEncoder(cols = ['country'])\n    x = one_hot.fit_transform(x)\n\n    one_hot1 = ce.OneHotEncoder(cols = ['store']) # Creating a new hot encoder for each column may not be the most efficient, feel free to optimize this\n    x = one_hot1.fit_transform(x)\n\n    one_hot2 = ce.OneHotEncoder(cols = ['product'])\n    x = one_hot2.fit_transform(x)\n    return x\n    \n\ndef dateProcess1(df, gdp_df):\n    # Make a bunch of columns for the dates\n    day_mon_list = []\n    mon_list = []\n    year_list = []\n\n    for k in range(len(df['date'])):\n        splt = df.iloc[k]['date'].split('-')\n        day_mon_list.append(int(splt[2]))\n        mon_list.append(int(splt[1]))\n        year_list.append(int(splt[0]) - 2015)\n    \n\n    df['day_of_month'] = day_mon_list\n    df['month'] = mon_list\n    df['year'] = year_list\n\n    gdp_list = []\n    for i in range(len(df['year'])):\n        if(df.iloc[i]['country'] == 'Finland'):\n            gdp_list.append(gdp_df.iloc[(3*df.iloc[i]['year'])]['GDP'])\n        elif(df.iloc[i]['country'] == 'Norway'):\n            gdp_list.append(gdp_df.iloc[(3*df.iloc[i]['year']) + 1]['GDP'])\n        elif(df.iloc[i]['country'] == 'Sweden'):\n            gdp_list.append(gdp_df.iloc[(3*df.iloc[i]['year']) + 2]['GDP'])\n    df['gdp_list'] = gdp_list\n\n    df['date'] = pd.to_datetime(df['date'])\n    df['weekend'] = df.date.dt.weekday >= 5 # Saturday and Sunday\n    df['friday'] = df.date.dt.weekday == 4 # Friday\n    df['day_of_year'] = df.date.dt.dayofyear\n    \n    # Christmas\n    xmas_date = df.date.dt.year.apply(lambda year: pd.Timestamp(str(year)+'-12-25'))\n    df['xmas_adjust'] = (df.date - xmas_date).dt.days.clip(lower=-20,upper=16).astype(str)\n          \n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    df['easter_adj']= (df.date - easter_date).dt.days.clip(lower =-3,upper = 60).astype(float)\n    df.loc[df['easter_adj'].isin(range(12, 39)), 'easter_adj'] = 12 \n    \n    # Black Friday\n    black_fri_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-27')),\n                                         2016: pd.Timestamp(('2016-11-25')),\n                                         2017: pd.Timestamp(('2017-11-24')),\n                                         2018: pd.Timestamp(('2018-11-23')),\n                                         2019: pd.Timestamp(('2019-11-29'))})\n    df['days_from_black_friday'] = (df.date - black_fri_date).dt.days.clip(-5, 5)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    df['days_from_wed_jun'] = (df.date - wed_june_date).dt.days.clip(-5, 5)\n    \n    #First Sunday of November (second Sunday is Father's Day)\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    df['days_from_sun_nov'] = (df.date - sun_nov_date).dt.days.clip(-1, 9)\n    \n    print(df['date'])\n    df.drop(columns=['date'],inplace=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:09.667915Z","iopub.execute_input":"2022-01-28T04:41:09.668317Z","iopub.status.idle":"2022-01-28T04:41:10.97935Z","shell.execute_reply.started":"2022-01-28T04:41:09.668286Z","shell.execute_reply":"2022-01-28T04:41:10.978541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\nnordic_gdp = pd.read_csv('../input/consumer-price-index-20152019-nordic-countries/Best_CPI.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:10.98138Z","iopub.execute_input":"2022-01-28T04:41:10.981719Z","iopub.status.idle":"2022-01-28T04:41:11.067587Z","shell.execute_reply.started":"2022-01-28T04:41:10.981678Z","shell.execute_reply":"2022-01-28T04:41:11.066664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dateProcess1(train_df, nordic_gdp)\ndateProcess1(test_df, nordic_gdp)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:11.070172Z","iopub.execute_input":"2022-01-28T04:41:11.070437Z","iopub.status.idle":"2022-01-28T04:41:32.102256Z","shell.execute_reply.started":"2022-01-28T04:41:11.070402Z","shell.execute_reply":"2022-01-28T04:41:32.10122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nobject_cols = ['weekend', 'friday', 'xmas_adjust']\n\nordinal_encoder = OrdinalEncoder()\ntrain_df[object_cols] = ordinal_encoder.fit_transform(train_df[object_cols])\ntest_df[object_cols] = ordinal_encoder.transform(test_df[object_cols])","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:32.103775Z","iopub.execute_input":"2022-01-28T04:41:32.10409Z","iopub.status.idle":"2022-01-28T04:41:32.136858Z","shell.execute_reply.started":"2022-01-28T04:41:32.104046Z","shell.execute_reply":"2022-01-28T04:41:32.135891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = dataProcess(train_df)\ntest_df = dataProcess(test_df)\ndisplay(train_df)\ndisplay(test_df)\nrow_id = test_df.pop('row_id')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:32.138119Z","iopub.execute_input":"2022-01-28T04:41:32.138504Z","iopub.status.idle":"2022-01-28T04:41:32.417023Z","shell.execute_reply.started":"2022-01-28T04:41:32.138435Z","shell.execute_reply":"2022-01-28T04:41:32.416088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:32.418562Z","iopub.execute_input":"2022-01-28T04:41:32.418891Z","iopub.status.idle":"2022-01-28T04:41:32.426666Z","shell.execute_reply.started":"2022-01-28T04:41:32.418849Z","shell.execute_reply":"2022-01-28T04:41:32.425747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.copy()\ny = X.pop('num_sold')\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 0)\nx_train.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:32.428063Z","iopub.execute_input":"2022-01-28T04:41:32.428275Z","iopub.status.idle":"2022-01-28T04:41:32.508761Z","shell.execute_reply.started":"2022-01-28T04:41:32.42825Z","shell.execute_reply":"2022-01-28T04:41:32.507927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smape(act,forc):\n    return 100/len(act) * np.sum(2 * np.abs(forc - act) / (np.abs(act) + np.abs(forc)))","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:32.510096Z","iopub.execute_input":"2022-01-28T04:41:32.510624Z","iopub.status.idle":"2022-01-28T04:41:32.516834Z","shell.execute_reply.started":"2022-01-28T04:41:32.510584Z","shell.execute_reply":"2022-01-28T04:41:32.516135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ndef corrplot(df, method=\"pearson\", annot=True, **kwargs):\n    sns.clustermap(\n        df.corr(method),\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n        method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\n\n\ncorrplot(train_df, annot=None)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:32.519006Z","iopub.execute_input":"2022-01-28T04:41:32.51974Z","iopub.status.idle":"2022-01-28T04:41:33.535507Z","shell.execute_reply.started":"2022-01-28T04:41:32.519701Z","shell.execute_reply":"2022-01-28T04:41:33.534265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef cluster_labels(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    X_new = pd.DataFrame()\n    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n    return X_new\n\n\ndef cluster_distance(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n    X_cd = kmeans.fit_transform(X_scaled)\n    # Label features and join to dataset\n    X_cd = pd.DataFrame(\n        X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])]\n    )\n    return X_cd\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:33.53718Z","iopub.execute_input":"2022-01-28T04:41:33.537627Z","iopub.status.idle":"2022-01-28T04:41:33.549199Z","shell.execute_reply.started":"2022-01-28T04:41:33.537581Z","shell.execute_reply":"2022-01-28T04:41:33.548523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = x_train\n\ns = (new_df.dtypes == 'object')\nobject_cols = list(s[s].index)\nobject_cols\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:33.550455Z","iopub.execute_input":"2022-01-28T04:41:33.551172Z","iopub.status.idle":"2022-01-28T04:41:33.568867Z","shell.execute_reply.started":"2022-01-28T04:41:33.551135Z","shell.execute_reply":"2022-01-28T04:41:33.567771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.xmas_adjust","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:33.570307Z","iopub.execute_input":"2022-01-28T04:41:33.570978Z","iopub.status.idle":"2022-01-28T04:41:33.593111Z","shell.execute_reply.started":"2022-01-28T04:41:33.570928Z","shell.execute_reply":"2022-01-28T04:41:33.591831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import  XGBRegressor\n\nmodel_x = XGBRegressor(n_estimators = 382, learning_rate = 0.008281241354242047, max_depth=10, random_state=0)\nmodel_x.fit(x_train, y_train)\npreds_x = model_x.predict(x_test)\nscore = smape(preds_x, y_test)\n\nscore","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:33.594442Z","iopub.execute_input":"2022-01-28T04:41:33.594869Z","iopub.status.idle":"2022-01-28T04:41:46.553314Z","shell.execute_reply.started":"2022-01-28T04:41:33.594838Z","shell.execute_reply":"2022-01-28T04:41:46.552629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.pop('row_id')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:46.556906Z","iopub.execute_input":"2022-01-28T04:41:46.559062Z","iopub.status.idle":"2022-01-28T04:41:46.567891Z","shell.execute_reply.started":"2022-01-28T04:41:46.55902Z","shell.execute_reply":"2022-01-28T04:41:46.566957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:41:46.569366Z","iopub.execute_input":"2022-01-28T04:41:46.569766Z","iopub.status.idle":"2022-01-28T04:41:46.610007Z","shell.execute_reply.started":"2022-01-28T04:41:46.569715Z","shell.execute_reply":"2022-01-28T04:41:46.609011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:42:16.689244Z","iopub.execute_input":"2022-01-28T04:42:16.689589Z","iopub.status.idle":"2022-01-28T04:42:16.697884Z","shell.execute_reply.started":"2022-01-28T04:42:16.689553Z","shell.execute_reply":"2022-01-28T04:42:16.696764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.columns\nx_train.pop('row_id')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:52:28.972987Z","iopub.execute_input":"2022-01-28T04:52:28.973356Z","iopub.status.idle":"2022-01-28T04:52:28.984821Z","shell.execute_reply.started":"2022-01-28T04:52:28.973319Z","shell.execute_reply":"2022-01-28T04:52:28.983562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final = XGBRegressor(n_estimators = 382, learning_rate = 0.008281241354242047, max_depth=10, random_state=0)\nfinal.fit(x_train, y_train)\npreds = final.predict(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:52:30.611684Z","iopub.execute_input":"2022-01-28T04:52:30.612511Z","iopub.status.idle":"2022-01-28T04:52:40.680541Z","shell.execute_reply.started":"2022-01-28T04:52:30.612432Z","shell.execute_reply":"2022-01-28T04:52:40.679698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'row_id': row_id, 'num_sold': preds})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-01-28T04:52:47.109166Z","iopub.execute_input":"2022-01-28T04:52:47.109447Z","iopub.status.idle":"2022-01-28T04:52:47.142516Z","shell.execute_reply.started":"2022-01-28T04:52:47.109407Z","shell.execute_reply":"2022-01-28T04:52:47.141201Z"},"trusted":true},"execution_count":null,"outputs":[]}]}