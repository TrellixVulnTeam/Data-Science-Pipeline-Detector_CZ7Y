{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sb\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport array\n\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T10:38:21.170163Z","iopub.execute_input":"2022-01-25T10:38:21.170417Z","iopub.status.idle":"2022-01-25T10:38:22.137115Z","shell.execute_reply.started":"2022-01-25T10:38:21.170339Z","shell.execute_reply":"2022-01-25T10:38:22.136298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining preprocessing function to extract/make features**","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:13:05.37227Z","iopub.status.idle":"2022-01-20T14:13:05.37293Z","shell.execute_reply.started":"2022-01-20T14:13:05.372591Z","shell.execute_reply":"2022-01-20T14:13:05.37262Z"}}},{"cell_type":"code","source":"# check seasonality of every sub group (country, product, store)\ndef plot_seasonality(df):\n      \n    splitter = {'option1': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Hat'},\n                'option2': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Sticker'},\n                'option3': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Mug'},\n                'option4': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Hat'},\n                'option5': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Sticker'},\n                'option6': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Mug'},\n                \n                'option7': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Hat'},\n                'option8': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Sticker'},\n                'option9': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Mug'},\n                'option10': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Hat'},\n                'option11': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Sticker'},\n                'option12': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Mug'},\n                \n                'option13': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Hat'},\n                'option14': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Sticker'},\n                'option15': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Mug'},\n                'option16': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Hat'},\n                'option17': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Sticker'},\n                'option18': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Mug'},\n    }\n    \n    \n    \n    for k, v in splitter.items():\n        tmp_df = df[(df['country']==v['country']) & (df['store']==v['store']) \n                    & (df['product']==v['product'])][['date', 'num_sold']]\n        \n        tmp_df['date'] = pd.to_datetime(tmp_df['date'])\n        tmp_df['date'] = tmp_df.date.dt.to_period('D')\n        tmp_df = tmp_df.set_index(['date']).sort_index()\n\n        average_sales = (\n            tmp_df\n            .groupby('date').mean()\n            .squeeze()\n        )\n\n\n        X = average_sales.to_frame()\n        X[\"week\"] = X.index.week\n        X[\"day\"] = X.index.dayofweek\n        X[\"dayofyear\"] = X.index.dayofyear\n        X[\"year\"] = X.index.year\n\n        fig, (ax0, ax1, ax2) = plt.subplots(3, 1, figsize=(11, 8))\n        ax0.set_title(f\"Country: {v['country']}, Product: {v['product']}, Store: {v['store']}\");\n        seasonal_plot(X, y=\"num_sold\", period=\"week\", freq=\"day\", ax=ax0)\n        seasonal_plot(X, y=\"num_sold\", period=\"year\", freq=\"dayofyear\", ax=ax1);\n\n        plot_periodogram(average_sales, ax=ax2);        ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:38:29.861682Z","iopub.execute_input":"2022-01-25T10:38:29.862403Z","iopub.status.idle":"2022-01-25T10:38:29.874863Z","shell.execute_reply.started":"2022-01-25T10:38:29.862361Z","shell.execute_reply":"2022-01-25T10:38:29.874069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\nplot_seasonality(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:38:30.403291Z","iopub.execute_input":"2022-01-25T10:38:30.403902Z","iopub.status.idle":"2022-01-25T10:41:01.02279Z","shell.execute_reply.started":"2022-01-25T10:38:30.403855Z","shell.execute_reply":"2022-01-25T10:41:01.021887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preparing data and Splitting it into Train & Validation sets**","metadata":{}},{"cell_type":"code","source":"def get_lags(df, df_test):\n    \n    X = pd.DataFrame()\n    X_rev = pd.DataFrame()\n      \n    splitter = {'option1': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Hat'},\n                'option2': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Sticker'},\n                'option3': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Mug'},\n                'option4': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Hat'},\n                'option5': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Sticker'},\n                'option6': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Mug'},\n                \n                'option7': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Hat'},\n                'option8': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Sticker'},\n                'option9': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Mug'},\n                'option10': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Hat'},\n                'option11': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Sticker'},\n                'option12': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Mug'},\n                \n                'option13': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Hat'},\n                'option14': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Sticker'},\n                'option15': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Mug'},\n                'option16': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Hat'},\n                'option17': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Sticker'},\n                'option18': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Mug'},\n    }\n    \n    def make_lags(ts, lags):\n        return pd.concat(\n            {\n                f'y_lag_{i}': ts.shift(i)\n                for i in range(1, lags + 1)\n            },\n            axis=1)\n    def make_rev_lags(ts, steps):\n        return pd.concat(\n            {\n                f'y_lag_{i + 1}': ts.shift(-i)\n                for i in range(steps)},\n            axis=1\n        )\n    \n    for k, v in splitter.items():\n        tmp_df = df[(df['country']==v['country']) & (df['store']==v['store']) \n                    & (df['product']==v['product'])]\n        tmp_df_test = df_test[(df_test['country']==v['country']) & (df_test['store']==v['store']) \n                    & (df_test['product']==v['product'])]\n        n = tmp_df_test.shape[0]\n        \n        lags = make_lags(tmp_df.num_sold, lags=7)\n        rev_lags = make_rev_lags(tmp_df['num_sold'].tail(n), steps=7).dropna()\n        \n        tmp_df = pd.concat([tmp_df, lags], axis=1)\n        X = pd.concat([X, tmp_df], axis=0)\n        rev_lags = rev_lags.reset_index()\n        tmp_df_test = tmp_df_test.join(rev_lags, how='left')\n        X_rev = pd.concat([X_rev, tmp_df_test], axis=0)\n        \n    return X, X_rev","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:41:01.024621Z","iopub.execute_input":"2022-01-25T10:41:01.024841Z","iopub.status.idle":"2022-01-25T10:41:01.041368Z","shell.execute_reply.started":"2022-01-25T10:41:01.024814Z","shell.execute_reply":"2022-01-25T10:41:01.040885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features(df, train=True):\n    df['date'] = pd.to_datetime(df['date'])\n    \n    # add holidays\n    holidays = pd.read_csv('../input/holidays-finland-norway-sweden-20152019/Holidays_Finland_Norway_Sweden_2015-2019.csv')\n    \n    fin_hol = holidays[(holidays['Country']=='Finland')&(holidays['Fixed']==True)]['Date']\n    swe_hol = holidays[(holidays['Country']=='Norway')&(holidays['Fixed']==True)]['Date']\n    nor_hol = holidays[(holidays['Country']=='Sweden')&(holidays['Fixed']==True)]['Date']\n    \n    df['fin holiday'] = df.date.isin(fin_hol).astype(int)\n    df['swe holiday'] = df.date.isin(swe_hol).astype(int)\n    df['nor holiday'] = df.date.isin(nor_hol).astype(int)\n    \n    df['is_holiday'] = np.zeros(df.shape[0]).astype(int)\n    df.loc[df.country == 'Finland', 'is_holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'is_holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'is_holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    # add month, weekday, is_weekend, dayofyear features\n    df['month'] = df['date'].apply(lambda x: x.month)\n    df['weekday'] = df['date'].apply(lambda x:x.weekday())\n    df['is_weekend'] = df['date'].apply(lambda x:1 if x.weekday() > 4 else 0)\n    df['day_of_year'] = df['date'].apply(lambda x: x.strftime('%j')).astype(int)\n    df[\"week\"] = df['date'].apply(lambda x: x.week)\n    df[\"year\"] = df['date'].apply(lambda x: x.year)\n    \n    # change categorical features into numerical\n    df[['Finland','Norway','Sweden']] = pd.get_dummies(df['country'])\n    df[['KaggleRama','KaggleMart']] = pd.get_dummies(df['store'])\n    df[['KaggleMug','KaggleSticker', 'KaggleHat']] = pd.get_dummies(df['product'])\n    \n    # select final features \n    features = ['row_id', 'date', 'country', 'store', 'product','Finland','Norway','KaggleRama'\n             ,'KaggleMug', 'KaggleHat', 'weekday', 'week', 'year',\n               'is_weekend', 'month', 'day_of_year', 'is_holiday']\n    \n    if(train):\n        features.append('num_sold')\n        return df[features]\n    else:\n        return df[features]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:41:01.042086Z","iopub.execute_input":"2022-01-25T10:41:01.042265Z","iopub.status.idle":"2022-01-25T10:41:01.057845Z","shell.execute_reply.started":"2022-01-25T10:41:01.042242Z","shell.execute_reply":"2022-01-25T10:41:01.057207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess data and add seasonality components based on above charts\n\n# from sklearn.preprocessing import RobustScaler\n# robu = RobustScaler()\n\ndef compute_seasonality(df, df_test):\n    x_index = 0\n    x_out_index = 0\n    \n    cols = ['row_id', 'date', 'country', 'store', 'product','Finland','Norway','KaggleRama'\n             ,'KaggleMug', 'KaggleHat', 'weekday', 'week', 'year',\n               'is_weekend', 'month', 'day_of_year', 'is_holiday', \n                'y_lag_1','y_lag_2','y_lag_3','y_lag_4','y_lag_5','y_lag_6','y_lag_7',\n            'const', 'trend', 's(2,7)', 's(3,7)', 's(4,7)', 's(5,7)', 's(6,7)',\n       's(7,7)', 'sin(1,freq=A-DEC)', 'cos(1,freq=A-DEC)', 'sin(2,freq=A-DEC)',\n       'cos(2,freq=A-DEC)', 'sin(3,freq=A-DEC)', 'cos(3,freq=A-DEC)',\n       'sin(4,freq=A-DEC)', 'cos(4,freq=A-DEC)', 'sin(5,freq=A-DEC)',\n       'cos(5,freq=A-DEC)']\n    \n    X = pd.DataFrame(columns=cols.append('num_sold'))\n    X_out = pd.DataFrame(columns=cols)\n    \n    fourier = CalendarFourier(freq=\"A\", order=5)  # 5 sin/cos pairs for \"A\"nnual seasonality\n    \n    splitter = {'option1': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Hat',\n                 'weekly': False, 'annual': [fourier]},\n                'option2': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Sticker',\n                 'weekly': True, 'annual': []},\n                'option3': \n                {'country': 'Finland', 'store': 'KaggleRama', 'product':'Kaggle Mug',\n                 'weekly': True, 'annual': [fourier]},\n                'option4': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Hat',\n                 'weekly': False, 'annual': [fourier]},\n                'option5': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Sticker',\n                 'weekly': True, 'annual': []},\n                'option6': \n                {'country': 'Finland', 'store': 'KaggleMart', 'product':'Kaggle Mug',\n                 'weekly': True, 'annual': [fourier]},\n                \n                'option7': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Hat',\n                 'weekly': False, 'annual': [fourier]},\n                'option8': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Sticker',\n                 'weekly': True, 'annual': []},\n                'option9': \n                {'country': 'Sweden', 'store': 'KaggleRama', 'product':'Kaggle Mug',\n                 'weekly': True, 'annual': [fourier]},\n                'option10': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Hat',\n                 'weekly': False, 'annual': [fourier]},\n                'option11': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Sticker',\n                 'weekly': True, 'annual': []},\n                'option12': \n                {'country': 'Sweden', 'store': 'KaggleMart', 'product':'Kaggle Mug',\n                 'weekly': True, 'annual': [fourier]},\n                \n                'option13': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Hat',\n                 'weekly': False, 'annual': [fourier]},\n                'option14': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Sticker',\n                 'weekly': True, 'annual': []},\n                'option15': \n                {'country': 'Norway', 'store': 'KaggleRama', 'product':'Kaggle Mug',\n                 'weekly': True, 'annual': [fourier]},\n                'option16': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Hat',\n                 'weekly': False, 'annual': [fourier]},\n                'option17': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Sticker',\n                 'weekly': True, 'annual': []},\n                'option18': \n                {'country': 'Norway', 'store': 'KaggleMart', 'product':'Kaggle Mug',\n                 'weekly': True, 'annual': [fourier]},\n    }\n    \n    for k, v in splitter.items():\n\n        part_df = df[(df['country']==v['country']) & (df['store']==v['store']) \n                    & (df['product']==v['product'])]\n        \n        part_df_test = df_test[(df_test['country']==v['country']) & (df_test['store']==v['store']) \n                    & (df_test['product']==v['product'])]\n\n        for col in part_df.columns:\n            j = 0\n            for i in range(x_index, (x_index+part_df.shape[0])):\n                X.at[i, col] = part_df.iloc[j, part_df.columns.get_loc(col)]\n                j=j+1\n                \n        for col in part_df_test.columns:\n            j = 0\n            for i in range(x_out_index, (x_out_index+part_df_test.shape[0])):\n                X_out.at[i, col] = part_df_test.iloc[j, part_df_test.columns.get_loc(col)]\n                j=j+1\n                \n        tmp_df = part_df[['date', 'num_sold']]\n\n        tmp_df['date'] = tmp_df.date.dt.to_period('D')\n        tmp_df = tmp_df.set_index(['date']).sort_index()\n\n        tmp_df = (\n            tmp_df\n            .groupby('date').mean()\n            .squeeze()\n        )\n\n\n        dp = DeterministicProcess(\n            index=tmp_df.index,\n            constant=True,               # dummy feature for bias (y-intercept)\n            order=1,                     # trend (order 1 means linear)\n            seasonal=v['weekly'],               # weekly seasonality (indicators)\n            additional_terms=v['annual'],  # annual seasonality (fourier)\n            drop=True,                   # drop terms to avoid collinearity\n        )  \n\n\n        dp_sample = dp.in_sample()\n        dp_out_sample = dp.out_of_sample(steps=part_df_test.shape[0])\n\n        for col in dp_sample.columns:\n            j = 0\n            for i in range(x_index, x_index+dp_sample.shape[0]):\n                X.at[i, col] = dp_sample.iloc[j, dp_sample.columns.get_loc(col)]\n                j = j+1\n        \n        for col in dp_out_sample.columns:\n            j = 0\n            for i in range(x_out_index, x_out_index+dp_out_sample.shape[0]):\n                X_out.at[i, col] = dp_out_sample.iloc[j, dp_out_sample.columns.get_loc(col)]\n                j = j+1\n        \n        \n        x_index = x_index + dp_sample.shape[0]\n        x_out_index = x_out_index + dp_out_sample.shape[0]\n\n    return X, X_out","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:41:01.059696Z","iopub.execute_input":"2022-01-25T10:41:01.059885Z","iopub.status.idle":"2022-01-25T10:41:01.083163Z","shell.execute_reply.started":"2022-01-25T10:41:01.059851Z","shell.execute_reply":"2022-01-25T10:41:01.082488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Fetch all features using above created functions","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:57:30.671808Z","iopub.execute_input":"2022-01-24T09:57:30.672092Z","iopub.status.idle":"2022-01-24T09:57:30.714327Z","shell.execute_reply.started":"2022-01-24T09:57:30.672062Z","shell.execute_reply":"2022-01-24T09:57:30.713399Z"}}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\n\ntrain_df = get_features(train_df, train=True)\ntest_df = get_features(test_df, train=False)\n\nlags, rev_lags = get_lags(train_df, test_df)\nlags = lags.fillna(0.0)\nrev_lags = rev_lags.fillna(0.0)\n\nX, X_out = compute_seasonality(lags, rev_lags)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:47:56.516863Z","iopub.execute_input":"2022-01-25T10:47:56.517711Z","iopub.status.idle":"2022-01-25T10:49:55.038519Z","shell.execute_reply.started":"2022-01-25T10:47:56.517671Z","shell.execute_reply":"2022-01-25T10:49:55.037596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sanity check to ensure everything is okay!\nprint(X.shape), print(train_df.shape)\nprint(X_out.shape), print(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:49:55.040629Z","iopub.execute_input":"2022-01-25T10:49:55.041069Z","iopub.status.idle":"2022-01-25T10:49:55.049803Z","shell.execute_reply.started":"2022-01-25T10:49:55.041029Z","shell.execute_reply":"2022-01-25T10:49:55.048808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prepare data for pycaret","metadata":{}},{"cell_type":"code","source":"X_out_1 = X_out.drop(['country', 'store', 'product'\n                      , 'row_id', 'num_sold', 'index', 'date'], axis=1)\n# X_out_1 = X_out_1.set_index(['date']).sort_index()\n\nX_1 = X.drop(['country', 'store', 'product',\n              'row_id', 'date'], axis=1)\n# X_1 = X_1.set_index(['date']).sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:05.467152Z","iopub.execute_input":"2022-01-25T13:25:05.467464Z","iopub.status.idle":"2022-01-25T13:25:05.496505Z","shell.execute_reply.started":"2022-01-25T13:25:05.467434Z","shell.execute_reply":"2022-01-25T13:25:05.495401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prepare data for manual algorithms","metadata":{}},{"cell_type":"code","source":"# # drop unneeded columns, split data to train and validation sets, and set date as an index\n# y_train, y_val = X[X['year']<2018]['num_sold'], X[X['year']==2018]['num_sold']\n\n# X_train, X_val = X[X['year']<2018], X[X['year']==2018]\n# X_train.drop(['country', 'product', 'store', 'row_id', 'num_sold'], axis=1, inplace=True)\n# X_val.drop(['country', 'product', 'store', 'row_id', 'num_sold'], axis=1, inplace=True)\n\n# X_train = X_train.set_index(['date']).sort_index()\n# X_val = X_val.set_index(['date']).sort_index()\n\n# # apply same concept to test data\n# X_test = X_out.drop(['country', 'product', 'store', 'row_id', 'num_sold', 'index'], axis=1)\n# X_test = X_test.set_index(['date']).sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:50:16.220387Z","iopub.execute_input":"2022-01-25T10:50:16.220967Z","iopub.status.idle":"2022-01-25T10:50:16.273893Z","shell.execute_reply.started":"2022-01-25T10:50:16.220929Z","shell.execute_reply":"2022-01-25T10:50:16.273081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace NAs with zeros\n\n# X_train.fillna(0.0, inplace=True), X_val.fillna(0.0, inplace=True), X_test.fillna(0.0, inplace=True)\n\nX_1.fillna(0.0, inplace=True), X_out_1.fillna(0.0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:08.801039Z","iopub.execute_input":"2022-01-25T13:25:08.801677Z","iopub.status.idle":"2022-01-25T13:25:08.875327Z","shell.execute_reply.started":"2022-01-25T13:25:08.801637Z","shell.execute_reply":"2022-01-25T13:25:08.874412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # convert targets to ints\n# y_train = y_train.astype(str).astype(int)\n# y_val = y_val.astype(str).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:51:38.732949Z","iopub.execute_input":"2022-01-25T10:51:38.733495Z","iopub.status.idle":"2022-01-25T10:51:38.736969Z","shell.execute_reply.started":"2022-01-25T10:51:38.733454Z","shell.execute_reply":"2022-01-25T10:51:38.736202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n# X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n# X_val = X_val.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n\nX_1 = X_1.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\nX_out_1 = X_out_1.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:11.426474Z","iopub.execute_input":"2022-01-25T13:25:11.427064Z","iopub.status.idle":"2022-01-25T13:25:11.438468Z","shell.execute_reply.started":"2022-01-25T13:25:11.427023Z","shell.execute_reply":"2022-01-25T13:25:11.43793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is an aesthetic choice and just removes the many warnings that some functions and comands produce\n#it helps significantly declutter the workbook\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:13.475072Z","iopub.execute_input":"2022-01-25T13:25:13.475359Z","iopub.status.idle":"2022-01-25T13:25:13.479507Z","shell.execute_reply.started":"2022-01-25T13:25:13.475329Z","shell.execute_reply":"2022-01-25T13:25:13.478932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install pycaret[full]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:51:43.34827Z","iopub.execute_input":"2022-01-25T10:51:43.348519Z","iopub.status.idle":"2022-01-25T10:52:53.828421Z","shell.execute_reply.started":"2022-01-25T10:51:43.34849Z","shell.execute_reply":"2022-01-25T10:52:53.827526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycaret.regression import *\n\n#setting up the pyCaret regression algorithm\nreg = setup(data = X_1,\n            target = 'num_sold',\n            train_size = 0.75, #75:25 train/validation split\n            normalize = True, #normalisation helps some algorithms\n            normalize_method = 'robust', #resilient to outliers\n            transform_target = True, #applies transformation to target column\n            data_split_shuffle = False, #so that we do not use \"future\" observations to predict \"past\" observations\n            #create_clusters = True, #adds additional feature by assigning clusters\n            feature_interaction = True, #new features are created by interacting (a * b) all the numeric variables in the dataset\n#             use_gpu = True, #use GPU acceleration to train models\n            silent = True, #removes need for confirmation step\n            fold = 15, #number of cross-fold validation folds\n#             pca=True, #apply dimentionality reduction to data\n#             session_id = 42, #set random seed\n#             feature_selection=True, #a subset of features are selected using a combination of various permutation importance techniques \n            n_jobs = -1); #use all processor threads","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:17.021271Z","iopub.execute_input":"2022-01-25T13:25:17.021988Z","iopub.status.idle":"2022-01-25T13:25:28.628502Z","shell.execute_reply.started":"2022-01-25T13:25:17.021952Z","shell.execute_reply":"2022-01-25T13:25:28.627643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#list all available models\nmodels()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T10:53:09.879654Z","iopub.execute_input":"2022-01-25T10:53:09.879851Z","iopub.status.idle":"2022-01-25T10:53:10.015776Z","shell.execute_reply.started":"2022-01-25T10:53:09.879826Z","shell.execute_reply":"2022-01-25T10:53:10.015013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Credit to https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:53.192594Z","iopub.execute_input":"2022-01-25T13:25:53.193501Z","iopub.status.idle":"2022-01-25T13:25:53.198556Z","shell.execute_reply.started":"2022-01-25T13:25:53.193449Z","shell.execute_reply":"2022-01-25T13:25:53.197811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adds the metric created previously to the pyCaret suite of metrics\nadd_metric('SMAPE', 'SMAPE', SMAPE, greater_is_better = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:53.447716Z","iopub.execute_input":"2022-01-25T13:25:53.44838Z","iopub.status.idle":"2022-01-25T13:25:53.456454Z","shell.execute_reply.started":"2022-01-25T13:25:53.448341Z","shell.execute_reply":"2022-01-25T13:25:53.455902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compares all models available and returns top N models to then be used\nN = 3\ntop = compare_models(sort = 'SMAPE', n_select = N)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:25:58.520335Z","iopub.execute_input":"2022-01-25T13:25:58.521071Z","iopub.status.idle":"2022-01-25T13:49:29.04417Z","shell.execute_reply.started":"2022-01-25T13:25:58.521035Z","shell.execute_reply":"2022-01-25T13:49:29.043496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Voting Classifier that blends predictions of individial models\n#only uses training set and predicts on valiation set\nblend_voting = blend_models(top)\npredict_model(blend_voting);","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:49:45.13555Z","iopub.execute_input":"2022-01-25T13:49:45.136058Z","iopub.status.idle":"2022-01-25T13:56:18.372782Z","shell.execute_reply.started":"2022-01-25T13:49:45.136011Z","shell.execute_reply":"2022-01-25T13:56:18.372062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use test and validation to train model and predicts on validation set\nfinal_blend_voting = finalize_model(blend_voting)\npredict_model(final_blend_voting);","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:57:37.355416Z","iopub.execute_input":"2022-01-25T13:57:37.355771Z","iopub.status.idle":"2022-01-25T14:02:30.310244Z","shell.execute_reply.started":"2022-01-25T13:57:37.355733Z","shell.execute_reply":"2022-01-25T14:02:30.309443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voting_preds = predict_model(final_blend_voting, data=X_out_1)\nvoting_preds.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:02:39.988491Z","iopub.execute_input":"2022-01-25T14:02:39.988805Z","iopub.status.idle":"2022-01-25T14:02:40.566698Z","shell.execute_reply.started":"2022-01-25T14:02:39.98877Z","shell.execute_reply":"2022-01-25T14:02:40.565866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = (voting_preds['Label']/2).round()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:05:25.387002Z","iopub.execute_input":"2022-01-25T14:05:25.387469Z","iopub.status.idle":"2022-01-25T14:05:25.391463Z","shell.execute_reply.started":"2022-01-25T14:05:25.387438Z","shell.execute_reply":"2022-01-25T14:05:25.39093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-jan-2022/sample_submission.csv')\n\nsubmission['num_sold'] = preds\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:06:27.755652Z","iopub.execute_input":"2022-01-25T14:06:27.756292Z","iopub.status.idle":"2022-01-25T14:06:27.782622Z","shell.execute_reply.started":"2022-01-25T14:06:27.75625Z","shell.execute_reply":"2022-01-25T14:06:27.781946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try:\n#     import xgboost\n# except ImportError as ex:\n#     print(\"Error: the xgboost library is not installed.\")\n#     xgboost = None\n    \n# blend_stack = stack_models(top, meta_model=xgboost.XGBRegressor())\n# predict_model(blend_stack);","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:30:40.873436Z","iopub.execute_input":"2022-01-25T11:30:40.874198Z","iopub.status.idle":"2022-01-25T12:14:56.823557Z","shell.execute_reply.started":"2022-01-25T11:30:40.874146Z","shell.execute_reply":"2022-01-25T12:14:56.822936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # use test and validation to train model and predicts on validation set\n# final_blend_stack = finalize_model(blend_stack)\n# predict_model(final_blend_stack);","metadata":{"execution":{"iopub.status.busy":"2022-01-25T12:16:57.664138Z","iopub.execute_input":"2022-01-25T12:16:57.664729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stack_preds = predict_model(final_blend_stack, data=X_test)\n# stack_preds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Trying Stacking Ensemble Technique, with Ridge, SVR & Random Forest**","metadata":{}},{"cell_type":"code","source":"# # Applying Stacking Regression to predict values\n# from sklearn.linear_model import RidgeCV, HuberRegressor\n# # from sklearn.svm import LinearSVR\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.ensemble import StackingRegressor\n# from catboost import CatBoostRegressor\n\n# try:\n#     import lightgbm as ltb\n# except:\n#     print(\"Error: the lightgbm library is not installed.\")\n#     ltb = None\n\n# try:\n#     import xgboost\n# except ImportError as ex:\n#     print(\"Error: the xgboost library is not installed.\")\n#     xgboost = None\n\n    \n# estimators = [\n#     ('xgb', xgboost.XGBRegressor(random_state=42, n_estimators=1000, learning_rate=0.15, max_depth=4)),\n# #     ('ridge', RidgeCV()),\n# #     ('hb', HuberRegressor(fit_intercept=False, epsilon=1.20, max_iter=500)),\n# #     ('svr', LinearSVR(random_state=42)),\n#     ('lgb', ltb.LGBMRegressor(objective='regression', n_estimators=1000, random_state=42)),\n#     ('cat', CatBoostRegressor(silent=True)),\n#     ('rf', RandomForestRegressor(n_estimators=500,random_state=42))\n# ]\n# reg = StackingRegressor(\n#     estimators=estimators,\n#     final_estimator=RidgeCV()\n# )\n\n# reg.fit(X_train, y_train).score(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T12:59:10.731911Z","iopub.execute_input":"2022-01-25T12:59:10.732971Z","iopub.status.idle":"2022-01-25T13:12:36.248671Z","shell.execute_reply.started":"2022-01-25T12:59:10.732931Z","shell.execute_reply":"2022-01-25T13:12:36.247312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Trying Voting Ensemble Technique, with Ridge, XGBoost, SVR & Random Forest**","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import VotingRegressor\n\n# estimators = [\n#     ('rf', RandomForestRegressor(n_estimators=500,random_state=42)),\n# #     ('hb', HuberRegressor(fit_intercept=False, epsilon=1.20, max_iter=500)),\n# #     ('svr', LinearSVR(random_state=42)),\n#     ('lgb', ltb.LGBMRegressor(objective='regression', n_estimators=1000, random_state=42)),\n#     ('cat', CatBoostRegressor(silent=True)),\n#     ('xgb_reg', xgboost.XGBRegressor(random_state=42, n_estimators=1000, learning_rate=0.15, max_depth=4))\n# ]\n\n# vot_reg = VotingRegressor(estimators)\n\n# vot_reg.fit(X_train, y_train).score(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:40:43.460388Z","iopub.execute_input":"2022-01-24T10:40:43.460877Z","iopub.status.idle":"2022-01-24T10:43:27.159415Z","shell.execute_reply.started":"2022-01-24T10:40:43.460831Z","shell.execute_reply":"2022-01-24T10:43:27.158703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From above, XGBoost produced the best score, next, I will try out different hyperparameters**","metadata":{}},{"cell_type":"code","source":"# # Getting best number of estimators\n# from sklearn.model_selection import GridSearchCV\n\n# n_estimators = [500, 1500, 1000, 2000]\n# learning_rate = [0.01, 0.1, 0.15, 0.05]\n\n# model = xgboost.XGBRegressor(random_state=42)\n\n# parameters = {'learning_rate': learning_rate,\n#               'max_depth': [5, 6, 7],\n#               'n_estimators': n_estimators}\n\n# xgb_grid = GridSearchCV(model,\n#                         parameters,\n#                         cv = 2,\n#                         n_jobs = -1,\n#                         verbose=True)\n\n# grid_result = xgb_grid.fit(X_train, y_train)\n\n# # summarize results\n# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# # means = grid_result.cv_results_['mean_test_score']\n# # stds = grid_result.cv_results_['std_test_score']\n# # params = grid_result.cv_results_['params']\n# # for mean, stdev, param in zip(means, stds, params):\n# #     print(\"%f (%f) with: %r\" % (mean, stdev, param))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Trying XGBoost alone","metadata":{}},{"cell_type":"code","source":"# xgb = xgboost.XGBRegressor(random_state=42, n_estimators=1000, learning_rate=0.15, max_depth=5)\n# print(xgb.fit(X_train, y_train).score(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:15:06.854546Z","iopub.execute_input":"2022-01-25T13:15:06.854911Z","iopub.status.idle":"2022-01-25T13:15:24.62418Z","shell.execute_reply.started":"2022-01-25T13:15:06.85486Z","shell.execute_reply":"2022-01-25T13:15:24.623372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds = xgb.predict(X_test).round()\n# preds","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:19:51.985397Z","iopub.execute_input":"2022-01-25T13:19:51.986257Z","iopub.status.idle":"2022-01-25T13:19:52.049363Z","shell.execute_reply.started":"2022-01-25T13:19:51.986219Z","shell.execute_reply":"2022-01-25T13:19:52.048763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.read_csv('../input/tabular-playground-series-jan-2022/sample_submission.csv')\n\n# submission['num_sold'] = preds\n\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}