{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# data processing\nimport numpy as np \nimport pandas as pd\n\n# for extracting holidays\nimport dateutil.easter as easter\n\n# sklearn baseline models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\n# scale numerical features\nfrom sklearn.preprocessing import MinMaxScaler\n\n# for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# for visualizing decission tree\nfrom sklearn import tree\n\n# for reproducibility\nRANDOM_SEED = 42\n\nplt.style.use('ggplot')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-23T13:13:02.608496Z","iopub.execute_input":"2022-01-23T13:13:02.609102Z","iopub.status.idle":"2022-01-23T13:13:03.218266Z","shell.execute_reply.started":"2022-01-23T13:13:02.608967Z","shell.execute_reply":"2022-01-23T13:13:03.21744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## My scores on public leaderboad\n\n* **linear regression:** 25.46780,\n* **decision tree:** 9.56904 (basic data).\n* **decision tree:** 9.77822 (added holiday data).\n* **decision tree:** 6.45971 (added GDP data).\n\n## 1. Load data","metadata":{}},{"cell_type":"code","source":"# Read basic data\ndf_train = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\n\n# convert dates to datetimes\nfor _df in [df_train, df_test]:\n    _df.date = pd.to_datetime(_df.date)\n    \n# create features from datetime object\nfor _df in [df_train, df_test]:\n    _df['year'] = _df['date'].apply(lambda x: x.year)\n    _df['month'] = _df['date'].apply(lambda x: x.month)\n    _df['quarter'] = _df.date.dt.quarter\n    _df['day'] = _df['date'].apply(lambda x: x.day)\n    _df['wd'] = _df['date'].apply(lambda x: x.weekday())\n    _df['weekend'] = _df['wd'].isin([5, 6]).astype(int)\n    _df['day_of_year'] = _df.date.dt.dayofyear  \n    _df['week_of_year'] = _df.date.dt.isocalendar().week\n    _df['is_friday'] = np.where((_df['wd'] == 4), 1, 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:03.223425Z","iopub.execute_input":"2022-01-23T13:13:03.223683Z","iopub.status.idle":"2022-01-23T13:13:04.322501Z","shell.execute_reply.started":"2022-01-23T13:13:03.223643Z","shell.execute_reply":"2022-01-23T13:13:04.321532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def holiday_features(holiday_df, df):\n    \"\"\"\n    This function taken from:\n    https://www.kaggle.com/maxencefzr/tps-jan22-catboost-using-pycaret\n    \"\"\"\n    fin_holiday = holiday_df.loc[holiday_df.country == 'Finland']\n    swe_holiday = holiday_df.loc[holiday_df.country == 'Sweden']\n    nor_holiday = holiday_df.loc[holiday_df.country == 'Norway']\n    \n    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n    \n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    \n    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    \n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    df['days_from_easter'] = (df.date - easter_date).dt.days.clip(-5, 65)\n    \n    # Last Sunday of May (Mother's Day)\n    sun_may_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-5-31')),\n        2016: pd.Timestamp(('2016-5-29')),\n        2017: pd.Timestamp(('2017-5-28')),\n        2018: pd.Timestamp(('2018-5-27')),\n        2019: pd.Timestamp(('2019-5-26'))\n    })\n    #new_df['days_from_sun_may'] = (df.date - sun_may_date).dt.days.clip(-1, 9)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-06-24')),\n        2016: pd.Timestamp(('2016-06-29')),\n        2017: pd.Timestamp(('2017-06-28')),\n        2018: pd.Timestamp(('2018-06-27')),\n        2019: pd.Timestamp(('2019-06-26'))\n    })\n    df['days_from_wed_jun'] = (df.date - wed_june_date).dt.days.clip(-5, 5)\n    \n    # First Sunday of November (second Sunday is Father's Day)\n    sun_nov_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-11-1')),\n        2016: pd.Timestamp(('2016-11-6')),\n        2017: pd.Timestamp(('2017-11-5')),\n        2018: pd.Timestamp(('2018-11-4')),\n        2019: pd.Timestamp(('2019-11-3'))\n    })\n    df['days_from_sun_nov'] = (df.date - sun_nov_date).dt.days.clip(-1, 9)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:04.323928Z","iopub.execute_input":"2022-01-23T13:13:04.324189Z","iopub.status.idle":"2022-01-23T13:13:04.342379Z","shell.execute_reply.started":"2022-01-23T13:13:04.324156Z","shell.execute_reply":"2022-01-23T13:13:04.341062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read outsourced data\nfestivities = pd.read_csv(\"../input/festivities-in-finland-norway-sweden-tsp-0122/nordic_holidays.csv\",\n                          parse_dates=['date'],\n                          usecols=['date', 'country', 'holiday'])\n\n# add holiday information\ndf_train = holiday_features(festivities, df_train)\ndf_test = holiday_features(festivities, df_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:04.345618Z","iopub.execute_input":"2022-01-23T13:13:04.346017Z","iopub.status.idle":"2022-01-23T13:13:04.884879Z","shell.execute_reply.started":"2022-01-23T13:13:04.345969Z","shell.execute_reply":"2022-01-23T13:13:04.883836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# process GDP\ngdp = pd.read_csv(\"../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv\")\ngdp = np.concatenate([gdp[['year', 'GDP_Finland']].values, \n                      gdp[['year', 'GDP_Norway']].values, \n                      gdp[['year', 'GDP_Sweden']].values])\ngdp = pd.DataFrame(gdp, columns=['year', 'gdp'])\ngdp['country'] = ['Finland']*5 + ['Norway']*5 +['Sweden']*5\n\n# add data\nfor _df in [df_train, df_test]:\n    gdp_countries = _df.merge(gdp, on=['country', 'year'], how='left')['gdp'].values\n    for country in ['Finland', 'Norway', 'Sweden']:\n        _df['gdp_'+ country] = gdp_countries * (_df['country']==country).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:04.886401Z","iopub.execute_input":"2022-01-23T13:13:04.88683Z","iopub.status.idle":"2022-01-23T13:13:04.959559Z","shell.execute_reply.started":"2022-01-23T13:13:04.886784Z","shell.execute_reply":"2022-01-23T13:13:04.958305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data visualizations\n\n### 2.1 Yearly results","metadata":{}},{"cell_type":"code","source":"# aggregate data\ndf_g = df_train.groupby(['year', 'product', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(2, 2, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _year in enumerate(range(2015, 2019)):\n    _df =  df_g[_year].reset_index()\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='product', linewidth=2.5, ax=axes[i])\n    \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:04.961688Z","iopub.execute_input":"2022-01-23T13:13:04.96212Z","iopub.status.idle":"2022-01-23T13:13:06.648779Z","shell.execute_reply.started":"2022-01-23T13:13:04.962036Z","shell.execute_reply":"2022-01-23T13:13:06.648112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 sales by product group","metadata":{}},{"cell_type":"code","source":"# aggregate data\ndf_g = df_train.groupby(['product', 'year', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(3, 1, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _product in enumerate(df_train['product'].unique()):\n    _df =  df_g[_product].reset_index()\n    axes[i].set_title(_product)\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='year', linewidth=2.5, ax=axes[i], palette=\"tab10\")\n    \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:06.649882Z","iopub.execute_input":"2022-01-23T13:13:06.650701Z","iopub.status.idle":"2022-01-23T13:13:08.24447Z","shell.execute_reply.started":"2022-01-23T13:13:06.650655Z","shell.execute_reply":"2022-01-23T13:13:08.243201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 sales by store","metadata":{}},{"cell_type":"code","source":"# aggregate data\ndf_g = df_train.groupby(['store', 'year', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(2, 1, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _store in enumerate(df_train['store'].unique()):\n    _df =  df_g[_store].reset_index()\n    axes[i].set_title(_store)\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='year', linewidth=2.5, ax=axes[i], palette=\"tab10\")\n    \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:08.246454Z","iopub.execute_input":"2022-01-23T13:13:08.247519Z","iopub.status.idle":"2022-01-23T13:13:09.360372Z","shell.execute_reply.started":"2022-01-23T13:13:08.247458Z","shell.execute_reply":"2022-01-23T13:13:09.359237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 sales by country","metadata":{"execution":{"iopub.status.busy":"2022-01-22T13:10:08.113343Z","iopub.execute_input":"2022-01-22T13:10:08.113619Z","iopub.status.idle":"2022-01-22T13:10:08.117825Z","shell.execute_reply.started":"2022-01-22T13:10:08.11359Z","shell.execute_reply":"2022-01-22T13:10:08.11675Z"}}},{"cell_type":"code","source":"# aggregate data\ndf_g = df_train.groupby(['country', 'year', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(3, 1, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _country in enumerate(df_train['country'].unique()):\n    _df =  df_g[_country].reset_index()\n    axes[i].set_title(_country)\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='year', linewidth=2.5, ax=axes[i], palette=\"tab10\")\n    \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:09.362121Z","iopub.execute_input":"2022-01-23T13:13:09.362496Z","iopub.status.idle":"2022-01-23T13:13:10.791492Z","shell.execute_reply.started":"2022-01-23T13:13:09.362435Z","shell.execute_reply":"2022-01-23T13:13:10.7908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Feature engineering\n\n### 3.1 `min`-`max` scale days.\n\nIn 2015 Februrary had 28 days and in 2016 29. `days` feature will be `min-max` scaled based on the number of days durring specific year, i.e. 28th of Febuary will be equal to the 31-st of January.","metadata":{}},{"cell_type":"code","source":"# create new DataFrames for transformed features\nX_train = df_train.copy()\nX_test = df_test.copy()\n\n# extract targets\ny_train = X_train.pop('num_sold')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.792638Z","iopub.execute_input":"2022-01-23T13:13:10.792967Z","iopub.status.idle":"2022-01-23T13:13:10.805493Z","shell.execute_reply.started":"2022-01-23T13:13:10.792937Z","shell.execute_reply":"2022-01-23T13:13:10.804486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate days per month\nDAYS_PER_MONTH = pd.concat([df_train, df_test])\nDAYS_PER_MONTH = DAYS_PER_MONTH.groupby(['year','month']).agg({'day': ['max']})\nDAYS_PER_MONTH = DAYS_PER_MONTH.reset_index()\nDAYS_PER_MONTH.columns = ['year', 'month', 'max_days']\nDAYS_PER_MONTH.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.80713Z","iopub.execute_input":"2022-01-23T13:13:10.808063Z","iopub.status.idle":"2022-01-23T13:13:10.837928Z","shell.execute_reply.started":"2022-01-23T13:13:10.807988Z","shell.execute_reply":"2022-01-23T13:13:10.83713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get max days for both train and test datasets\nX_train = pd.merge(X_train, DAYS_PER_MONTH, on=['year', 'month'], how='left')\nX_train['day'] = X_train['day'] / X_train['max_days']\ndel X_train['max_days']\n\nX_test = pd.merge(X_test, DAYS_PER_MONTH, on=['year', 'month'], how='left')\nX_test['day'] = X_test['day'] / X_test['max_days']\ndel X_test['max_days']","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.839174Z","iopub.execute_input":"2022-01-23T13:13:10.8395Z","iopub.status.idle":"2022-01-23T13:13:10.864314Z","shell.execute_reply.started":"2022-01-23T13:13:10.839464Z","shell.execute_reply":"2022-01-23T13:13:10.863545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale other numerical features\nfor col in ['day_of_year', 'days_from_easter', 'days_from_wed_jun', 'days_from_sun_nov']:\n    scaler = MinMaxScaler()\n    scaler.fit(X_train[col].values.reshape(-1, 1))\n    # transform\n    X_train[col] = scaler.transform(X_train[col].values.reshape(-1, 1))\n    X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.867071Z","iopub.execute_input":"2022-01-23T13:13:10.867444Z","iopub.status.idle":"2022-01-23T13:13:10.879638Z","shell.execute_reply.started":"2022-01-23T13:13:10.867413Z","shell.execute_reply":"2022-01-23T13:13:10.878329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 one-hot-encoding","metadata":{}},{"cell_type":"code","source":"# one-hot encode categorical features\nX_train = pd.get_dummies(X_train, columns=['country', 'store', 'product', 'month'])\nX_test = pd.get_dummies(X_test, columns=['country', 'store', 'product', 'month'])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.880888Z","iopub.execute_input":"2022-01-23T13:13:10.881152Z","iopub.status.idle":"2022-01-23T13:13:10.922723Z","shell.execute_reply.started":"2022-01-23T13:13:10.881124Z","shell.execute_reply":"2022-01-23T13:13:10.921497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split train data into train and validation sections\n_X_train = X_train.loc[X_train.year != 2018].copy()\n_X_valid = X_train.loc[X_train.year == 2018].copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.924209Z","iopub.execute_input":"2022-01-23T13:13:10.924493Z","iopub.status.idle":"2022-01-23T13:13:10.939343Z","shell.execute_reply.started":"2022-01-23T13:13:10.924456Z","shell.execute_reply":"2022-01-23T13:13:10.938426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Modeling\n\n### Helper functions","metadata":{"execution":{"iopub.status.busy":"2022-01-22T13:49:34.169332Z","iopub.execute_input":"2022-01-22T13:49:34.169971Z","iopub.status.idle":"2022-01-22T13:49:34.199802Z","shell.execute_reply.started":"2022-01-22T13:49:34.169918Z","shell.execute_reply":"2022-01-22T13:49:34.198932Z"}}},{"cell_type":"code","source":"# https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\ndef smape_loss(y_true, y_pred):\n    \"\"\"\n    SMAPE Loss\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Ground truth (correct) target values.\n    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Estimated target values.\n    Returns\n    -------\n    loss : float or ndarray of floats\n        If multioutput is 'raw_values', then mean absolute error is returned\n        for each output separately.\n        If multioutput is 'uniform_average' or an ndarray of weights, then the\n        weighted average of all output errors is returned.\n        SMAPE output is non-negative floating point. The best value is 0.0.\n\n    \"\"\"\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.940927Z","iopub.execute_input":"2022-01-23T13:13:10.941479Z","iopub.status.idle":"2022-01-23T13:13:10.949617Z","shell.execute_reply.started":"2022-01-23T13:13:10.941421Z","shell.execute_reply":"2022-01-23T13:13:10.948578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1 `linear regression` baseline model","metadata":{}},{"cell_type":"code","source":"# create simple lin. Regression\nmodel_lin_reg = LinearRegression()\n\n# train model\nmodel_lin_reg.fit(_X_train.iloc[:, 3:], y_train.loc[_X_train.index])\n\n# make predictions on validation data\n_pred_lin_reg = model_lin_reg.predict(_X_valid.iloc[:, 3:])\n\n# calcualte SMAPE\nsmape_loss_lin_reg = smape_loss(y_train.loc[_X_valid.index], _pred_lin_reg)\nprint(f'Vadidation data SMAPE:')\nprint(f'Lin. reg.: {smape_loss_lin_reg:.2f}')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:10.950691Z","iopub.execute_input":"2022-01-23T13:13:10.951304Z","iopub.status.idle":"2022-01-23T13:13:11.021189Z","shell.execute_reply.started":"2022-01-23T13:13:10.951266Z","shell.execute_reply":"2022-01-23T13:13:11.020171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new DataFrame for comparing predictions on validation dataset\nvalid_res = _X_valid.copy()\n# add predictions for proting\nvalid_res['observed'] = y_train.loc[_X_valid.index]\nvalid_res['Linear regression'] = _pred_lin_reg\nvalid_res.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:11.022983Z","iopub.execute_input":"2022-01-23T13:13:11.023586Z","iopub.status.idle":"2022-01-23T13:13:11.06814Z","shell.execute_reply.started":"2022-01-23T13:13:11.023532Z","shell.execute_reply":"2022-01-23T13:13:11.067141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_predictions(df_val, model_name='Linear regression'):\n    \"\"\"\n    This function plots predictions on validation Dataset.\n    \"\"\"\n    # get data for ploting\n    df_plot = df_val.groupby('date')[['observed', model_name]].sum()\n    \n    # greate plotting function\n    fig, axes = plt.subplots(2, 1, figsize=(24, 8))\n\n    # temporal visualization\n    axes[0].scatter(df_plot.index, df_plot['observed'], label='Observed', color='#348ABD')\n    axes[0].plot(df_plot.index, df_plot[model_name], label='Model', linewidth=2.5)\n\n    # add legend\n    legend = axes[0].legend(frameon=1)\n    frame = legend.get_frame()\n    frame.set_facecolor('w')\n\n    axes[0].set_xlabel('Date')\n    axes[0].set_title(f'{model_name} model.')\n\n    # histograms\n    axes[1].hist([y_train.loc[_X_valid.index], _pred_lin_reg], bins=np.linspace(0, 3000, 201),\n                 label=['Observed', 'Model'], color=[ '#348ABD', '#E24A33'])\n\n    # add legends with white backgrounds\n    for i in range(2):\n        legend = axes[i].legend(frameon=1)\n        frame = legend.get_frame()\n        frame.set_facecolor('w')\n\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:11.070027Z","iopub.execute_input":"2022-01-23T13:13:11.070654Z","iopub.status.idle":"2022-01-23T13:13:11.087314Z","shell.execute_reply.started":"2022-01-23T13:13:11.070602Z","shell.execute_reply":"2022-01-23T13:13:11.086047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_predictions(valid_res, 'Linear regression')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:11.089712Z","iopub.execute_input":"2022-01-23T13:13:11.090146Z","iopub.status.idle":"2022-01-23T13:13:13.22534Z","shell.execute_reply.started":"2022-01-23T13:13:11.090076Z","shell.execute_reply":"2022-01-23T13:13:13.224163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Decision Tree Regressor\n\n* baseline features.","metadata":{}},{"cell_type":"code","source":"# create simple lin. Regression\nmodel_des_tree = DecisionTreeRegressor(random_state=RANDOM_SEED)\n\n# train model\nmodel_des_tree.fit(_X_train.iloc[:, 3:], y_train.loc[_X_train.index])\n\n# make predictions on validation data\n_pred_des_tree = model_des_tree.predict(_X_valid.iloc[:, 3:])\n\n# calcualte SMAPE\nsmape_loss_des_tree = smape_loss(y_train.loc[_X_valid.index], _pred_des_tree)\nprint(f'Vadidation data SMAPE:')\nprint(f'Des. tree: {smape_loss_des_tree:.2f}')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:13.227109Z","iopub.execute_input":"2022-01-23T13:13:13.227488Z","iopub.status.idle":"2022-01-23T13:13:13.414406Z","shell.execute_reply.started":"2022-01-23T13:13:13.227454Z","shell.execute_reply":"2022-01-23T13:13:13.413363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add predictions on validation data\nvalid_res['Decision Tree'] = _pred_des_tree\nvalid_res.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:13.416221Z","iopub.execute_input":"2022-01-23T13:13:13.416556Z","iopub.status.idle":"2022-01-23T13:13:13.444473Z","shell.execute_reply.started":"2022-01-23T13:13:13.416502Z","shell.execute_reply":"2022-01-23T13:13:13.443527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_predictions(valid_res, 'Decision Tree')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:13.446043Z","iopub.execute_input":"2022-01-23T13:13:13.446669Z","iopub.status.idle":"2022-01-23T13:13:15.285249Z","shell.execute_reply.started":"2022-01-23T13:13:13.446615Z","shell.execute_reply":"2022-01-23T13:13:15.284194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_predictions_2(df_val, model_name='Linear regression'):\n    \"\"\"\n    This function plots predictions on validation Dataset.\n    \"\"\"\n    # select data for proting\n    df_plot = df_train.loc[df_val.index].copy()\n    # add predictions data\n    df_plot['model'] = df_val[model_name]\n    # agregate data\n    df_plot = df_plot.groupby(['date', 'country', 'store'])[['num_sold', 'model']].sum().reset_index()\n    \n    # greate plotting function\n    fig, axes = plt.subplots(3, 2, figsize=(24, 10))\n    \n    for i, country in enumerate(df_plot.country.unique()):\n        for ii, store in enumerate(df_plot.store.unique()):\n            # select data\n            _df = df_plot.loc[(df_plot.store == store) & (df_plot.country == country)]\n            axes[i, ii].scatter(_df.date, _df.num_sold, label='Observed', color='#348ABD')\n            axes[i, ii].plot(_df.date, _df.model, label='Model', linewidth=2.5)\n            \n            # calculate smape for subsection\n            _smape = smape_loss(_df.num_sold, _df.model)\n            \n            # add labels and legend\n            axes[i, ii].set_title(f'{country.title()} - {store}. SMAPE: {_smape:.1f}')\n            axes[i, ii].set_ylabel('num. sold')\n            legend = axes[i, ii].legend(frameon=1)\n            frame = legend.get_frame()\n            frame.set_facecolor('w')\n            \n\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:15.286985Z","iopub.execute_input":"2022-01-23T13:13:15.287963Z","iopub.status.idle":"2022-01-23T13:13:15.303672Z","shell.execute_reply.started":"2022-01-23T13:13:15.287897Z","shell.execute_reply":"2022-01-23T13:13:15.302545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_predictions_2(valid_res, model_name='Decision Tree')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:15.305435Z","iopub.execute_input":"2022-01-23T13:13:15.305921Z","iopub.status.idle":"2022-01-23T13:13:17.283604Z","shell.execute_reply.started":"2022-01-23T13:13:15.305872Z","shell.execute_reply":"2022-01-23T13:13:17.282619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Submission","metadata":{"execution":{"iopub.status.busy":"2022-01-22T14:00:28.586901Z","iopub.execute_input":"2022-01-22T14:00:28.587947Z","iopub.status.idle":"2022-01-22T14:00:28.592595Z","shell.execute_reply.started":"2022-01-22T14:00:28.587893Z","shell.execute_reply":"2022-01-22T14:00:28.591758Z"}}},{"cell_type":"code","source":"# create simple lin. Regression\nfinal_model = DecisionTreeRegressor(random_state=RANDOM_SEED)\n\n# train model\nfinal_model.fit(X_train.iloc[:, 3:], y_train);\n\n# make predictions on test data\npred_test = final_model.predict(X_test.iloc[:, 3:])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:17.285389Z","iopub.execute_input":"2022-01-23T13:13:17.285952Z","iopub.status.idle":"2022-01-23T13:13:17.556675Z","shell.execute_reply.started":"2022-01-23T13:13:17.285901Z","shell.execute_reply":"2022-01-23T13:13:17.555494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make submission\nsubmission = X_test[['row_id']].copy()\nsubmission['num_sold'] = pred_test\n# round results\nsubmission['num_sold'] = submission['num_sold'].round()\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:13:17.55868Z","iopub.execute_input":"2022-01-23T13:13:17.559104Z","iopub.status.idle":"2022-01-23T13:13:17.592377Z","shell.execute_reply.started":"2022-01-23T13:13:17.559034Z","shell.execute_reply":"2022-01-23T13:13:17.591396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}