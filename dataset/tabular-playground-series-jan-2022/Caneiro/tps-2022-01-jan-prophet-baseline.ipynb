{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', 999)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport itertools\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T00:55:18.320944Z","iopub.execute_input":"2022-01-25T00:55:18.32135Z","iopub.status.idle":"2022-01-25T00:55:18.329475Z","shell.execute_reply.started":"2022-01-25T00:55:18.321318Z","shell.execute_reply":"2022-01-25T00:55:18.327987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pystan==2.19.1.1\n!pip install prophet\n\nfrom prophet import Prophet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T00:55:18.331485Z","iopub.execute_input":"2022-01-25T00:55:18.332292Z","iopub.status.idle":"2022-01-25T00:55:34.808401Z","shell.execute_reply.started":"2022-01-25T00:55:18.332256Z","shell.execute_reply":"2022-01-25T00:55:34.807797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ntrain['date'] = pd.to_datetime(train.date)\nprint(train.info())\ntrain.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T00:55:34.809627Z","iopub.execute_input":"2022-01-25T00:55:34.809902Z","iopub.status.idle":"2022-01-25T00:55:34.88754Z","shell.execute_reply.started":"2022-01-25T00:55:34.809868Z","shell.execute_reply":"2022-01-25T00:55:34.88629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\ntest['date'] = pd.to_datetime(test.date)\nprint(test.info())\ntest.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T00:55:34.889571Z","iopub.execute_input":"2022-01-25T00:55:34.890011Z","iopub.status.idle":"2022-01-25T00:55:34.930856Z","shell.execute_reply.started":"2022-01-25T00:55:34.889981Z","shell.execute_reply":"2022-01-25T00:55:34.930119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competition Metric\nhttps://www.kaggle.com/cpmpml/smape-weirdness","metadata":{}},{"cell_type":"code","source":"def SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:55:34.932096Z","iopub.execute_input":"2022-01-25T00:55:34.933947Z","iopub.status.idle":"2022-01-25T00:55:34.941567Z","shell.execute_reply.started":"2022-01-25T00:55:34.933799Z","shell.execute_reply":"2022-01-25T00:55:34.940043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"code","source":"sns.relplot(data=train, x='date', y='num_sold', row='country', col='store', hue='product',\n            aspect=3, height=2.5, kind='line')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:55:34.943883Z","iopub.execute_input":"2022-01-25T00:55:34.945624Z","iopub.status.idle":"2022-01-25T00:55:39.205003Z","shell.execute_reply.started":"2022-01-25T00:55:34.94557Z","shell.execute_reply":"2022-01-25T00:55:39.203535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Val Split","metadata":{}},{"cell_type":"code","source":"val = train[train.date >= '2018-01-01'].copy()\nval.reset_index(drop=True, inplace=True)\n\ntrain = train[train.date < '2018-01-01'].copy()\ntrain.reset_index(drop=True, inplace=True)\n\ntrain.rename({'date':'ds', 'num_sold':'y'}, axis=1, inplace=True)\nval.rename({'date':'ds', 'num_sold':'y'}, axis=1, inplace=True)\ntest.rename({'date':'ds'}, axis=1, inplace=True)\n\nprint('Train', train.shape, '| Start', train.ds.min(), '| End', train.ds.max())\nprint('Val', val.shape, '| Start', val.ds.min(), '| End', val.ds.max())\nprint('Test', test.shape, '| Start', test.ds.min(), '| End', test.ds.max())","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:55:39.206379Z","iopub.execute_input":"2022-01-25T00:55:39.206613Z","iopub.status.idle":"2022-01-25T00:55:39.228502Z","shell.execute_reply.started":"2022-01-25T00:55:39.206573Z","shell.execute_reply":"2022-01-25T00:55:39.227575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Base Prophet","metadata":{}},{"cell_type":"code","source":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet()\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = train_preds.yhat.values\n            val.loc[val_idx, 'yhat'] = val_preds.yhat.values\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:55:39.230425Z","iopub.execute_input":"2022-01-25T00:55:39.230678Z","iopub.status.idle":"2022-01-25T00:57:11.047541Z","shell.execute_reply.started":"2022-01-25T00:55:39.230647Z","shell.execute_reply":"2022-01-25T00:57:11.046849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add Holidays\nhttps://www.kaggle.com/gunesevitan/tabular-playground-series-jan-2022-prophet","metadata":{}},{"cell_type":"code","source":"new_year = pd.DataFrame({\n  'holiday': 'new_year',\n  'ds': pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01']),\n  'lower_window': -1,\n  'upper_window': 0,\n})\n\neaster = pd.DataFrame({\n  'holiday': 'easter',\n  'ds': pd.to_datetime(['2015-04-05', '2016-03-27', '2017-04-16', '2018-04-01', '2019-04-21']),\n  'lower_window': 0,\n  'upper_window': 7,\n})\n\nholidays = pd.concat((new_year, easter))\nholidays","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:57:11.049087Z","iopub.execute_input":"2022-01-25T00:57:11.049527Z","iopub.status.idle":"2022-01-25T00:57:11.074258Z","shell.execute_reply.started":"2022-01-25T00:57:11.049487Z","shell.execute_reply":"2022-01-25T00:57:11.073566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(holidays=holidays)\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = train_preds.yhat.values\n            val.loc[val_idx, 'yhat'] = val_preds.yhat.values\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:57:11.077864Z","iopub.execute_input":"2022-01-25T00:57:11.078437Z","iopub.status.idle":"2022-01-25T00:58:38.081694Z","shell.execute_reply.started":"2022-01-25T00:57:11.078397Z","shell.execute_reply":"2022-01-25T00:58:38.080635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tuned Parameters\nhttps://www.kaggle.com/gunesevitan/tabular-playground-series-jan-2022-prophet","metadata":{}},{"cell_type":"code","source":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = train_preds.yhat.values\n            val.loc[val_idx, 'yhat'] = val_preds.yhat.values\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:58:38.083426Z","iopub.execute_input":"2022-01-25T00:58:38.084368Z","iopub.status.idle":"2022-01-25T00:58:45.778161Z","shell.execute_reply.started":"2022-01-25T00:58:38.084333Z","shell.execute_reply":"2022-01-25T00:58:45.777149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Rounding","metadata":{}},{"cell_type":"code","source":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = np.round(train_preds.yhat.values, 0)\n            val.loc[val_idx, 'yhat'] = np.round(val_preds.yhat.values, 0)\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:58:45.779729Z","iopub.execute_input":"2022-01-25T00:58:45.780451Z","iopub.status.idle":"2022-01-25T00:58:54.656949Z","shell.execute_reply.started":"2022-01-25T00:58:45.780406Z","shell.execute_reply":"2022-01-25T00:58:54.655976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ceiling","metadata":{}},{"cell_type":"code","source":"for country in train.country.unique():\n    for store in train.store.unique():\n        for product in train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = train[(train.country==country) & \n                              (train.store==store) &\n                              (train['product']==product)].index\n            \n            train_sub = train.loc[train_idx].copy()\n            \n            val_idx = val[(val.country==country) & \n                          (val.store==store) &\n                          (val['product']==product)].index\n            \n            val_sub = val.loc[val_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            val_preds = model.predict(val_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            val_score = SMAPE(val_sub.y.values, val_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('Val Score', country, store, product, 'SMAPE: {:f}'.format(val_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            train.loc[train_idx, 'yhat'] = np.ceil(train_preds.yhat.values)\n            val.loc[val_idx, 'yhat'] = np.ceil(val_preds.yhat.values)\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(train.y.values, train.yhat.values)))\nprint('Val Score', 'SMAPE: {:f}'.format(SMAPE(val.y.values, val.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:58:54.658473Z","iopub.execute_input":"2022-01-25T00:58:54.659013Z","iopub.status.idle":"2022-01-25T00:59:02.31088Z","shell.execute_reply.started":"2022-01-25T00:58:54.658968Z","shell.execute_reply":"2022-01-25T00:59:02.309885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Training","metadata":{}},{"cell_type":"code","source":"all_train = pd.concat([train, val], axis=0, ignore_index=True).reset_index(drop=True)\n\nfor country in all_train.country.unique():\n    for store in all_train.store.unique():\n        for product in all_train['product'].unique():    \n            print(country, store, product)\n            \n            # Subsets for current country, stores and product\n            train_idx = all_train[(all_train.country==country) & \n                                  (all_train.store==store) &\n                                  (all_train['product']==product)].index\n            \n            train_sub = all_train.loc[train_idx].copy()\n            \n            test_idx = test[(test.country==country) & \n                            (test.store==store) &\n                            (test['product']==product)].index\n            \n            test_sub = test.loc[test_idx].copy()\n            \n            # Define the model and fit it on the train subset of data\n            model = Prophet(\n                growth='linear',\n                holidays=holidays,\n                n_changepoints=10,\n                changepoint_range=0.4,\n                yearly_seasonality=True,\n                weekly_seasonality=True,\n                daily_seasonality=False,\n                seasonality_mode='additive',\n                seasonality_prior_scale=25,\n                holidays_prior_scale=100,\n                changepoint_prior_scale=0.01,\n                interval_width=0.5,\n                uncertainty_samples=False\n            )\n            model.fit(train_sub)\n            \n            # Predict for train e validation datasets\n            train_preds = model.predict(train_sub)\n            test_preds = model.predict(test_sub)\n            \n            # Calculate scores base on comp metric SMAPE\n            train_score = SMAPE(train_sub.y.values, train_preds.yhat.values)\n            \n            print()\n            print('--------------------------------------------------------------------------')\n            print('Train Score', country, store, product, 'SMAPE: {:f}'.format(train_score))\n            print('--------------------------------------------------------------------------')\n            print()            \n            \n            # Add predictions to train and validation datasets\n            all_train.loc[train_idx, 'yhat'] = np.round(train_preds.yhat.values, 0)\n            test.loc[test_idx, 'yhat'] = np.round(test_preds.yhat.values, 0)\n\nprint()\nprint('--------------------------------------------------------------------------')\nprint('Train Score', 'SMAPE: {:f}'.format(SMAPE(all_train.y.values, all_train.yhat.values)))\nprint('--------------------------------------------------------------------------')\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:02.312281Z","iopub.execute_input":"2022-01-25T00:59:02.312811Z","iopub.status.idle":"2022-01-25T00:59:11.246883Z","shell.execute_reply.started":"2022-01-25T00:59:02.312773Z","shell.execute_reply":"2022-01-25T00:59:11.245876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tunning Parameters","metadata":{}},{"cell_type":"code","source":"# growth='linear',\n# holidays=holidays,\n# n_changepoints=10,\n# changepoint_range=0.4,\n# yearly_seasonality=True,\n# weekly_seasonality=True,\n# daily_seasonality=False,\n# seasonality_mode='additive',\n# seasonality_prior_scale=25,\n# holidays_prior_scale=100,\n# changepoint_prior_scale=0.01,\n# interval_width=0.5,\n# uncertainty_samples=False","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.247925Z","iopub.execute_input":"2022-01-25T00:59:11.248117Z","iopub.status.idle":"2022-01-25T00:59:11.256053Z","shell.execute_reply.started":"2022-01-25T00:59:11.248089Z","shell.execute_reply":"2022-01-25T00:59:11.255089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from prophet.diagnostics import cross_validation\n# from prophet.diagnostics import performance_metrics\n\n# all_data = pd.concat([train, val], axis=0, ignore_index=True).reset_index(drop=True)\n\n# df = all_data[(all_data.country=='Finland') & \n#               (all_data.store=='KaggleMart') &\n#               (all_data['product']=='Kaggle Mug')].copy()\n\n# param_grid = {  \n#     'changepoint_prior_scale': [0.001, 0.01, 0.1],\n#     'seasonality_prior_scale': [0.01, 0.1, 1, 10, 25],\n#     'holidays_prior_scale':[0.01, 0.1, 1, 10],\n#     'changepoint_range':[0.7, 0.8, 0.9],\n#     'holidays':[holidays]\n# }\n\n# cutoffs = pd.to_datetime(['2015-12-31', '2016-12-31', '2017-12-31'])\n\n# # Generate all combinations of parameters\n# all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n# print(len(all_params))\n# smapes = []  # Store the RMSEs for each params here","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.257416Z","iopub.execute_input":"2022-01-25T00:59:11.25764Z","iopub.status.idle":"2022-01-25T00:59:11.268651Z","shell.execute_reply.started":"2022-01-25T00:59:11.257611Z","shell.execute_reply":"2022-01-25T00:59:11.267996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Use cross validation to evaluate all parameters\n# for params in all_params:\n#     m = Prophet(**params).fit(df)  # Fit model with given params\n#     df_cv = cross_validation(m, initial=1095, cutoffs=cutoffs, horizon='365 days', parallel=\"processes\")\n#     df_p = performance_metrics(df_cv, rolling_window=1)\n#     smapes.append(df_p['smape'].values[0])\n\n# # Find the best parameters\n# tuning_results = pd.DataFrame(all_params)\n# tuning_results['smape'] = smapes","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.2701Z","iopub.execute_input":"2022-01-25T00:59:11.270477Z","iopub.status.idle":"2022-01-25T00:59:11.287993Z","shell.execute_reply.started":"2022-01-25T00:59:11.270445Z","shell.execute_reply":"2022-01-25T00:59:11.287348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning_results.sort_values('smape', ascending=False).head(50)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.289608Z","iopub.execute_input":"2022-01-25T00:59:11.290024Z","iopub.status.idle":"2022-01-25T00:59:11.302897Z","shell.execute_reply.started":"2022-01-25T00:59:11.289991Z","shell.execute_reply":"2022-01-25T00:59:11.301638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = test[['row_id', 'yhat']].copy()\nsubmission.rename({'yhat':'num_sold'}, axis=1, inplace=True)\nsubmission['num_sold'] = np.ceil(submission.num_sold)\nsubmission.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.304463Z","iopub.execute_input":"2022-01-25T00:59:11.304799Z","iopub.status.idle":"2022-01-25T00:59:11.334327Z","shell.execute_reply.started":"2022-01-25T00:59:11.304749Z","shell.execute_reply":"2022-01-25T00:59:11.333679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.338176Z","iopub.execute_input":"2022-01-25T00:59:11.340402Z","iopub.status.idle":"2022-01-25T00:59:11.353262Z","shell.execute_reply.started":"2022-01-25T00:59:11.340351Z","shell.execute_reply":"2022-01-25T00:59:11.352669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.tail()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.354616Z","iopub.execute_input":"2022-01-25T00:59:11.355714Z","iopub.status.idle":"2022-01-25T00:59:11.368257Z","shell.execute_reply.started":"2022-01-25T00:59:11.355658Z","shell.execute_reply":"2022-01-25T00:59:11.367471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:59:11.369724Z","iopub.execute_input":"2022-01-25T00:59:11.369979Z","iopub.status.idle":"2022-01-25T00:59:11.397669Z","shell.execute_reply.started":"2022-01-25T00:59:11.369942Z","shell.execute_reply":"2022-01-25T00:59:11.396435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}