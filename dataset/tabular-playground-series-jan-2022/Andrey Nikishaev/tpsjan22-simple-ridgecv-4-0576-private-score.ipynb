{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install holidays","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-02T09:47:01.102871Z","iopub.execute_input":"2022-02-02T09:47:01.103527Z","iopub.status.idle":"2022-02-02T09:47:10.997961Z","shell.execute_reply.started":"2022-02-02T09:47:01.103417Z","shell.execute_reply":"2022-02-02T09:47:10.996967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://gist.githubusercontent.com/creotiv/a9385c95afa076240144a447e050f572/raw/8d5d4326f6c3db12b642a7218a1a1c66b6d6911b/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:50:54.96057Z","iopub.execute_input":"2022-02-02T09:50:54.961273Z","iopub.status.idle":"2022-02-02T09:50:56.090487Z","shell.execute_reply.started":"2022-02-02T09:50:54.96124Z","shell.execute_reply":"2022-02-02T09:50:56.089466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport math\nimport os\nimport dateutil.easter as easter\nfrom datetime import datetime, date, timedelta\nfrom collections import defaultdict\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom scipy.signal import periodogram\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.linear_model import RidgeCV\n\nimport holidays","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:52:00.626791Z","iopub.execute_input":"2022-02-02T09:52:00.627095Z","iopub.status.idle":"2022-02-02T09:52:00.634778Z","shell.execute_reply.started":"2022-02-02T09:52:00.627063Z","shell.execute_reply":"2022-02-02T09:52:00.633853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR = \"/kaggle/input/tabular-playground-series-jan-2022\"\n\ntrain = pd.read_csv(os.path.join(DIR,'train.csv'))\ntest = pd.read_csv(os.path.join(DIR,'test.csv'))\ngdp = pd.read_csv('./GDP_data_2015_to_2019_Finland_Norway_Sweden.csv').set_index('year')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:52:03.795699Z","iopub.execute_input":"2022-02-02T09:52:03.796123Z","iopub.status.idle":"2022-02-02T09:52:03.885441Z","shell.execute_reply.started":"2022-02-02T09:52:03.796082Z","shell.execute_reply":"2022-02-02T09:52:03.884814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_scale(y, y_t, model, preproc, limits=[0.8,1.2], threshold=0, step=0.01, correction=False):\n    i = limits[0]\n    scores = []\n    scales = []\n    while i <= limits[1]:\n        scale = i\n        test_pred_list = []\n        res = np.exp(model.predict(preproc.transform(y[features])))\n        if correction:\n            res *= scale\n        test_pred_list.append(res)\n        sub = pd.DataFrame()\n        sub['num_sold'] = sum(test_pred_list) / len(test_pred_list)\n        sub['num_sold'] = sub['num_sold'].apply(lambda x: x*scale if x > threshold and not correction else x)\n        sub['num_sold'] = sub['num_sold'].round()\n        score = np.mean(smape_loss(y_t['num_sold'], sub['num_sold']))\n        scores.append(score)\n        scales.append(scale)\n        i += step\n    best = np.argmin(scores)\n    print(\"SMAPE Best\", scores[best], scales[best])\n    return scores[best], scales[best]\n\ndef smape_loss(y_true, y_pred):\n    diff = np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200\n    return diff.mean()\n\ndef check_missing(df):\n    missing = False\n    if df.isna().astype('int').max().max() == 1:\n        print('NaN values detected.')\n        missing = True\n    if df.isnull().astype('int').max().max() == 1:\n        print('Null values detected.')\n        missing == True\n    return missing\n\n\"\"\"\n    residuals - pd.Series(index=date, values=values)\n\"\"\"\ndef plot_all_residuals(residuals):\n    plt.figure(figsize=(20,6))\n    plt.scatter(residuals.index,\n                residuals,\n                s=1, color='k')\n    plt.vlines(pd.date_range(residuals.index.min(), residuals.index.max(), freq='M'),\n               plt.ylim()[0], plt.ylim()[1], alpha=0.5)\n    plt.vlines(pd.date_range(residuals.index.min(), residuals.index.max(), freq='Y'),\n               plt.ylim()[0], plt.ylim()[1], alpha=1 , color='r')\n    plt.title('Residuals')\n    plt.show()\n\n\n\"\"\"\n    ts         - pd.Series(index=doesnt_matter, values=values) | np.array\n\"\"\"\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots(figsize=(20,6))\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=90,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\ndef plot_result(y_true, y_pred):\n    plt.figure(figsize=(10, 10))\n    plt.scatter(y_true, y_pred, s=1, color='r')\n    plt.plot([plt.xlim()[0], plt.xlim()[1]], [plt.xlim()[0], plt.xlim()[1]], '--', color='k')\n    plt.gca().set_aspect('equal')\n    plt.xlabel('True')\n    plt.ylabel('Pred')\n    plt.title('Predictions')\n    plt.show()\n\ndef plot_ts(dd, name):\n    plt.figure(figsize=(30, 5))\n    for d in dd:\n        plt.plot(d['date'],d['num_sold'])\n    plt.xlabel('Date')\n    plt.ylabel('Sold')\n    plt.title(name)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:55:09.733322Z","iopub.execute_input":"2022-02-02T09:55:09.733972Z","iopub.status.idle":"2022-02-02T09:55:09.760114Z","shell.execute_reply.started":"2022-02-02T09:55:09.73393Z","shell.execute_reply":"2022-02-02T09:55:09.759504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_features_simple(_df, gdp):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    df = _df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    \n    def get_gdp(row):\n        country = 'GDP_' +row.country # \n        return gdp.loc[row.date.year, country]\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'friday': df.date.dt.weekday == 4, # Friday\n                           'weekends': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n\n    ## Seasonal variations (Fourier series)\n    ## The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in [1,2,3,4,5,6, 7, 14, 21, 28, 30, 31, 91]:\n        new_df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        for product in ['Kaggle Mug', 'Kaggle Hat']:\n            name = product.replace(' ','_').lower()\n            new_df[f'{name}_sin{k}'] = new_df[f'sin{k}'] * new_df[product]\n            new_df[f'{name}_cos{k}'] = new_df[f'cos{k}'] * new_df[product]\n        for country in ['Finland', 'Norway']:\n            name = country.replace(' ','_').lower()\n            new_df[f'{name}_sin{k}'] = new_df[f'sin{k}'] * new_df[country]\n            new_df[f'{name}_cos{k}'] = new_df[f'cos{k}'] * new_df[country]\n\n    features = new_df.columns\n    new_df[features] = new_df[features].astype(np.float32) \n    # new_df['year'] = df.date.dt.year.astype(int)\n    new_df['country'] = df.country\n    new_df['product'] = df['product']\n    new_df['store'] = df.store\n    new_df['date'] = pd.to_datetime(df['date'])\n    if 'num_sold' in df.columns:\n        new_df['num_sold'] = df.num_sold.astype(np.float32)\n\n    return new_df\n\ndef add_holiday(df, name, date, country=None, product=None, store=None, offset=[-3,3]):\n    if not isinstance(country, list):\n        country = pd.Series([country])\n    if not isinstance(product, list):\n        product = pd.Series([product])\n    if not isinstance(store, list):\n        store = pd.Series([store])\n    if not isinstance(date, list):\n        dates = {y: pd.Timestamp((date)).replace(year=y) for y in df.date.dt.year.unique().astype(int).tolist()}\n        dates = df.date.dt.year.map(dates)\n    else:\n        dates = {pd.Timestamp((d)).year: pd.Timestamp((d)) for d in date}\n        dates = df.date.dt.year.map(dates)\n\n    select = (df.date.dt.year > 0)\n    if country is not None:\n        select = select & (df.country.isin(country))\n    if product is not None:\n        select = select & (df['product'].isin(product))\n    if store is not None:\n        select = select & (df.store.isin(store))\n    df = pd.concat([df,\n        pd.DataFrame({f\"{name.lower().replace(' ','-')}{d}\": \n             (df.date - dates == np.timedelta64(d, \"D\")) & select\n            for d in list(range(offset[0], offset[1]))})\n    ],axis=1)\n    return df\n\ndef add_holidays(df):\n    \n    dates = defaultdict(list)\n    for date, name in holidays.SE(years=[2015,2016,2017,2018,2019], include_sundays=False).items():\n        dates[name].append(str(date))\n    for i, (name, dd) in enumerate(dates.items()):\n        if len(dd) < 5:\n            continue\n        df = add_holiday(df, f'se_hol_{i}', dd, ['Sweden'])\n\n    dates = defaultdict(list)\n    for date, name in holidays.FI(years=[2015,2016,2017,2018,2019]).items():\n        dates[name].append(str(date))\n    for i, (name, dd) in enumerate(dates.items()):\n        if len(dd) < 5:\n            continue\n        df = add_holiday(df, f'fin_hol_{i}', dd, ['Finland'])\n\n    dates = defaultdict(list)\n    for date, name in holidays.NO(years=[2015,2016,2017,2018,2019], include_sundays=False).items():\n        dates[name].append(str(date))\n    for i, (name, dd) in enumerate(dates.items()):\n        if len(dd) < 5:\n            continue\n        df = add_holiday(df, f'nor_hol_{i}', dd, ['Norway'])\n    \n    df = add_holiday(df, f'1st_apr', '2015-04-01', ['Norway','Sweden','Finland'])\n\n    df = add_holiday(df, f'a1', '2016-12-14', ['Finland'])\n    df = add_holiday(df, f'a2', '2016-04-05', ['Sweden'])\n    df = add_holiday(df, f'a3', '2016-04-03', ['Norway'])\n    df = add_holiday(df, f'a4', '2016-04-07', ['Norway'])\n    df = add_holiday(df, f'a5', '2016-05-18', ['Norway'])\n    df = add_holiday(df, f'a6', '2016-05-27', ['Norway'])\n    df = add_holiday(df, f'a7', '2016-05-30', ['Norway'])\n    df = add_holiday(df, f'a8', '2016-11-25', ['Norway'])\n\n    # outliers for norway and KaggleHat\n    df = add_holiday(df, f'N1', '2019-12-31', ['Norway'],['Kaggle Hat'],['KaggleRama'],[-5,1])\n    df = add_holiday(df, f'N2', '2019-06-16', ['Norway'],['Kaggle Hat'],['KaggleRama'],[-1,1])\n    df = add_holiday(df, f'N3', '2019-05-05', ['Norway'],['Kaggle Hat'],['KaggleRama'],[-1,1])\n    df = add_holiday(df, f'N4', '2019-04-28', ['Norway'],['Kaggle Hat'],['KaggleRama'],[-5,1])\n    df = add_holiday(df, f'N5', '2019-04-21', ['Norway'],['Kaggle Hat'],['KaggleRama'],[-1,1])\n\n    return df\n\n\ndef make_features_adv(_df, gdp):\n    df = _df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    \n    new_df = make_features_simple(_df, gdp)\n    new_df = add_holidays(new_df)\n    \n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 14)}),\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})],\n                       axis=1)\n    \n    # May\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}), #  + list(range(17, 25))\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(19, 26))})],\n                       axis=1)\n    \n    # June and July\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))})\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))})],\n                       axis=1)\n    \n    new_df['first_half'] = df.date.dt.month <= 6\n    \n    # # Swedish rock concert\n    swed_rock_fest  = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-6')),\n                                         2016: pd.Timestamp(('2016-06-11')),\n                                         2017: pd.Timestamp(('2017-06-10')),\n                                         2018: pd.Timestamp(('2018-06-10')),\n                                         2019: pd.Timestamp(('2019-06-8'))})\n\n\n    new_df = pd.concat([new_df, pd.DataFrame({f\"swed_rock_fest{d}\":\n                                      (df.date - swed_rock_fest == np.timedelta64(d, \"D\")) & (df.country == 'Sweden')\n                                      for d in list(range(-3, 3))})], axis=1)\n    \n    # First Sunday of November - Daylight Saving Time ends\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})],\n                       axis=1)\n    \n    new_df.drop(['date','country','store','product'],axis='columns', inplace=True)\n    new_df = new_df.astype(np.float32)\n    if 'num_sold' in df.columns:\n        new_df['date'] = pd.to_datetime(df['date'])\n\n    return new_df\n\ntrain_df = make_features_adv(train, gdp)\ntest_df = make_features_adv(test, gdp) \n\nprint(len(train_df.columns),len(test_df.columns))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:57:13.27079Z","iopub.execute_input":"2022-02-02T09:57:13.2711Z","iopub.status.idle":"2022-02-02T09:57:20.380681Z","shell.execute_reply.started":"2022-02-02T09:57:13.271066Z","shell.execute_reply":"2022-02-02T09:57:20.379685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_model(X_tr, X_va=None,features=None):\n    \"\"\"Scale the data, fit a model, plot the training history and validate the model\"\"\"\n    start_time = datetime.now()\n    # Preprocess the data\n    X_tr_f = X_tr[features]\n    preproc = StandardScaler()\n    X_tr_f = preproc.fit_transform(X_tr_f)\n    y_tr = X_tr.num_sold.values.reshape(-1, 1)\n    \n    # Train the model\n    model = RidgeCV(alphas=(0.1,0.2,0.4,0.5,0.7,1,5,10))\n    model.fit(X_tr_f, np.log(y_tr).ravel())\n\n    if X_va is not None:\n        # Preprocess the validation data\n        X_va_f = X_va[features]\n        X_va_f = preproc.transform(X_va_f)\n        y_va = X_va.num_sold.values.reshape(-1, 1)\n\n        # Inference for validation\n        y_va_pred = np.exp(model.predict(X_va_f)).reshape(-1, 1)\n        oof.update(pd.Series(y_va_pred.ravel(), index=X_va.index))\n        \n        # Evaluation: Execution time and SMAPE\n        smape = np.mean(smape_loss(y_va, y_va_pred))\n        print(f\"Fold {fold} | {str(datetime.now() - start_time)[-12:-7]}\"\n              f\" | SMAPE: {smape:.5f}\")\n        score_list.append(smape)\n        \n        # Plot y_true vs. y_pred\n        plt.figure(figsize=(10, 10))\n        plt.scatter(y_va, y_va_pred, s=1, color='r')\n        plt.plot([plt.xlim()[0], plt.xlim()[1]], [plt.xlim()[0], plt.xlim()[1]], '--', color='k')\n        plt.gca().set_aspect('equal')\n        plt.xlabel('y_true')\n        plt.ylabel('y_pred')\n        plt.title('OOF Predictions')\n        plt.show()\n        \n    return preproc, model\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:58:17.523434Z","iopub.execute_input":"2022-02-02T09:58:17.524085Z","iopub.status.idle":"2022-02-02T09:58:17.536951Z","shell.execute_reply.started":"2022-02-02T09:58:17.524048Z","shell.execute_reply":"2022-02-02T09:58:17.535974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make the results reproducible\nnp.random.seed(202100)\n\ntotal_start_time = datetime.now()\noof = pd.Series(0.0, index=train_df.index)\nscore_list = []\nkf = GroupKFold(n_splits=4)\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train_df, groups=train_df.date.dt.year)):\n    X_tr = train_df.iloc[train_idx]\n    X_va = train_df.iloc[val_idx]\n    preproc, model = fit_model(X_tr, X_va, features=test_df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T09:58:49.773323Z","iopub.execute_input":"2022-02-02T09:58:49.773635Z","iopub.status.idle":"2022-02-02T09:59:05.602769Z","shell.execute_reply.started":"2022-02-02T09:58:49.773604Z","shell.execute_reply":"2022-02-02T09:59:05.601757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features =   test_df.columns \n\nX_tr = train_df[train_df.date.dt.year<=2017]\ny = train_df[(train_df.date.dt.year>2017) & (train_df.date.dt.year<2019)].reset_index()[features]\ny_t = train_df[(train_df.date.dt.year>2017) & (train_df.date.dt.year<2019)].reset_index()\npreproc, model = fit_model(X_tr, None, features=features)\n\nsub = pd.DataFrame()\nsub['num_sold'] = np.exp(model.predict(preproc.transform(y[features])))\nsub['num_sold'] = sub['num_sold'].round()\nprint(\"SMAPE SUB: \",np.mean(smape_loss(y_t['num_sold'], sub['num_sold'])))\ny_t['diff'] = np.abs(y_t['num_sold']-sub['num_sold'])\ny_t.plot(y='diff',x='num_sold',kind='scatter')\nplt.show()\n\n_,scale = find_scale(y, y_t, model, preproc, correction=1)\n\nsub = pd.DataFrame()\nsub['num_sold'] = np.exp(model.predict(preproc.transform(y[features]))) * scale\nsub['num_sold'] = sub['num_sold'].round()\ny_t['diff'] = np.abs(y_t['num_sold']-sub['num_sold'])\ny_t.plot(y='diff',x='num_sold',kind='scatter')\nplt.show()\n\nX_tr = train_df\ny = test_df[features]\npreproc, model = fit_model(X_tr, None, features=features)\nsub = test[['row_id']].copy()\nsub['num_sold'] = res = np.exp(model.predict(preproc.transform(y[features]))) * scale\nsub['num_sold'] = sub['num_sold'].round()\nsub.to_csv('submission.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:05:18.076752Z","iopub.execute_input":"2022-02-02T10:05:18.077085Z","iopub.status.idle":"2022-02-02T10:05:30.433995Z","shell.execute_reply.started":"2022-02-02T10:05:18.077039Z","shell.execute_reply":"2022-02-02T10:05:30.433018Z"},"trusted":true},"execution_count":null,"outputs":[]}]}