{"cells":[{"metadata":{},"cell_type":"markdown","source":"LAYOUT :)   \n\n                 EDA       :\n                 \n                 PIPELINE  :\n                 \n                              ML MODELS :)\n                              LinearRegression\n                                                          \n                              XGBoostingRegressor\n                              XGBoostingRegressor with optuna\n                              \n                 ALL IN PLOT:\n                              RMSE of All MOdels\n                 PREDICTIONS:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Datasets Loading...."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df2  = train_df[train_df.target<9.523992259999998]\n#train_df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape,test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train_df.drop(['target','id'],axis=1),test_df.drop(['id'],axis=1)],axis=0)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def divideFeatures(df):\n    numerical_features = df.select_dtypes(include=[np.number])\n    categorical_features = df.select_dtypes(include=[np.object])\n    return numerical_features, categorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features, cat_features =divideFeatures(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplots of numerical features for outlier detection\n\nfig = plt.figure(figsize=(16,16))\nfor i in range(len(cont_features.columns)):\n    fig.add_subplot(5, 4, i+1)\n    sns.boxplot(y=cont_features.iloc[:,i])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distplots for categorical data\n\nfig = plt.figure(figsize=(16,10))\nfor i in range(len(cat_features.columns[:])):\n    fig.add_subplot(5, 4, i+1)\n    cat_features.iloc[:,i].hist()\n    plt.xlabel(cat_features.columns[i])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation heatmap for all features\nplt.figure(figsize=(18,10),dpi=200)\ncorr = train_df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, mask = mask, annot=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot sample skewed feature\nplt.figure(figsize=(10,4))\nsns.distplot(train_df['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skewed_features = cont_features.apply(lambda x: x.skew()).sort_values(ascending=False)\nskewed_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfig = plt.figure(figsize=(16,30))\nfor i in range(len(cont_features.columns)):\n    fig.add_subplot(10,5,i+1)\n    sns.distplot(cont_features.iloc[:,i])\n    plt.xlabel(cont_features.columns[i])\nplt.tight_layout()\nplt.show();\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape,test_df.shape,df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder , LabelEncoder\nfrom sklearn.pipeline import make_pipeline ,Pipeline\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.compose import make_column_transformer ,ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split ,cross_val_score,validation_curve,learning_curve\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV ,RandomizedSearchCV\nfrom sklearn.tree import plot_tree\nfrom sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one = OneHotEncoder(handle_unknown='ignore')\nscaler =StandardScaler()\n\nfs = SelectKBest()\nle =LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.select_dtypes(include='object').columns)\ndf.select_dtypes(exclude='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lencode(df):\n    for i in df.columns:\n        for k in cat_features.columns:\n            if i ==k:\n                df[i]= le.fit_transform(df[i])\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lencode(df)\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df[:300000] \nXf_test = df[300000:]\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ct = make_column_transformer((one,['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8','cat9']),\n                             #(scaler,['id', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']),\n                              #remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlinear = LinearRegression()\nrandom = RandomForestRegressor(n_estimators=100,random_state=42,n_jobs=-1,max_features=4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgbr = xgb.XGBRegressor(tree_method='gpu_hist')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\ndef objective(trial):\n    params = {\n        'random_state': 0,\n        'n_estimators': trial.suggest_categorical('n_estimators', [10000]),\n        'max_depth': trial.suggest_int('max_depth', 3, 8),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10),\n        'gamma': trial.suggest_float('gamma', 0.0, 10),\n        'subsample': trial.suggest_categorical('subsample', [0.8, 0.9, 1.0]),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.1, 0.2, 0.3, 0.4, 0.5]),\n        'tree_method':'gpu_hist'    # comment this line if GPU is off\n    }\n    model = xgb.XGBRegressor(**params) \n    model.fit(X_train, y_train, eval_set=[(X_test,y_test)], early_stopping_rounds=1000, verbose=0)\n    y_pred = model.predict(X_test)\n    rmse = mean_squared_error(y_test, y_pred, squared=False)\n    \n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstudy = optuna.create_study(direction='minimize',sampler=optuna.samplers.TPESampler(seed=0))\nstudy.optimize(objective, n_trials=100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best parameters:', study.best_trial.params)\nprint('Best RMSE:', study.best_trial.value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = study.best_params\nparams['random_state'] = 0\nparams['n_estimators'] = 10000\nparams['tree_method'] = 'gpu_hist'\n\nmodel3 = xgb.XGBRegressor(**params)\nmodel3.fit(X_train,y_train,eval_set=[(X_test, y_test)],early_stopping_rounds=1000,verbose=2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = make_pipeline(linear)\nmodel.fit(X_train,y_train)\n\nmodel2 = make_pipeline(xgbr)\nmodel2.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models ={'linear':model}\nmodels['xgbr'] = model2\nmodels['optuna_xbg'] =model3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(y_test,y_pred):\n    rmse= np.sqrt(mean_squared_error(y_test,y_pred))\n    return rmse\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.base import clone\n\ndef cross_val_rmse(model):\n    model =clone(model)\n    five_fold = KFold(n_splits=5)\n    rmse_val =[]\n    for tr_ind,val_ind in five_fold.split(X_train):\n        model.fit(X_train.iloc[tr_ind,:],y.iloc[tr_ind])\n        rmse_val.append(rmse(y.iloc[val_ind],model.predict(X_train.iloc[val_ind,:])))\n        \n    return np.mean(rmse_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\ndef compare_models(models):\n    training_rmse = [rmse(y_train,model.predict(X_train)) for model in models.values()]\n    validate_rmse = [cross_val_rmse(model) for model in models.values()] \n    testing_rmse = [rmse(y_test,model.predict(X_test)) for model in models.values()]\n    names = list(models.keys())\n    fig = go.Figure([\n                      go.Bar(x=names ,y=training_rmse ,name='traing_rmse'),\n                      go.Bar(x=names ,y=validate_rmse ,name='validate_rmse'),\n                      go.Bar(x=names ,y=testing_rmse ,name='testing_rmse',opacity=.3)])\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = compare_models(models)\nfig.update_yaxes(range=[0,2],title=\"RMSE\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model3.predict(X_test)\ny_pred =np.round(y_pred,6)\nprint('min',y_pred.min())\nprint('max',y_pred.max())\nRMSE = np.sqrt(mean_squared_error(y_test,y_pred))\nprint('RMSE',RMSE)\nprint(y_pred.tolist()) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"ys_pred =model3.predict(Xf_test)\nys_pred =np.round(ys_pred,6)\nys_pred.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'id':test_df.id,'target':ys_pred})\nsub.to_csv('TPS.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Upvote if u like :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}