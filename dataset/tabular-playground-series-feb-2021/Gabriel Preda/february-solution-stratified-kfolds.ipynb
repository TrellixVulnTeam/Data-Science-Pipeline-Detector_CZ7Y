{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import pandas  as pd\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nimport lightgbm as lgb\nfrom sklearn import datasets\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ntest_df  = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"columns = train_df.columns\nprint(columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [a for a in train_df.columns if a.startswith('cat')]\n\nall_data = pd.concat([train_df[cat_features], test_df[cat_features]], axis=0)\nprint(all_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in cat_features:\n    temp = pd.get_dummies(pd.Series(all_data[column]), prefix=column, prefix_sep=\"_\")\n    temp_train = temp[0:train_df.shape[0]]\n    temp_test = temp[train_df.shape[0]:]\n    \n    train_df = pd.concat([train_df,temp_train],axis=1)\n    train_df = train_df.drop([column],axis=1)\n    \n    test_df = pd.concat([test_df,temp_test],axis=1)\n    test_df = test_df.drop([column],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [a for a in train_df.columns if a.startswith('c')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_stratified_folds_for_regression(data_df, n_splits=5):\n    \"\"\"\n    @param data_df: training data to split in Stratified K Folds for a continous target value\n    @param n_splits: number of splits\n    @return: the training data with a column with kfold id\n    \"\"\"\n    data_df['kfold'] = -1\n    # randomize the data\n    data_df = data_df.sample(frac=1).reset_index(drop=True)\n    # calculate the optimal number of bins based on log2(data_df.shape[0])\n    num_bins = np.int(np.floor(1 + np.log2(len(data_df))))\n    print(f\"Num bins: {num_bins}\")\n    # bins value will be the equivalent of class value of target feature used by StratifiedKFold to \n    # distribute evenly the classed over each fold\n    data_df.loc[:, \"bins\"] = pd.cut(pd.to_numeric(data_df['target'], downcast=\"signed\"), bins=num_bins, labels=False)\n    kf = model_selection.StratifiedKFold(n_splits=n_splits)\n    \n    # set the fold id as a new column in the train data\n    for f, (t_, v_) in enumerate(kf.split(X=data_df, y=data_df.bins.values)):\n        data_df.loc[v_, 'kfold'] = f\n    \n    # drop the bins column (no longer needed)\n    data_df = data_df.drop(\"bins\", axis=1)\n    \n    return data_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_splits = 5\ntrain_df = create_stratified_folds_for_regression(train_df, n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.kfold.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of target values\")\nsns.distplot(train_df['target'],color=\"darkblue\", kde=True,bins=120, label='target')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of target values (StratifiedKFolds with bins)\")\nfor k in range(0,n_splits):\n    df = train_df.loc[train_df.kfold==k]\n    sns.distplot(df['target'],kde=True,hist=False, bins=120, label=k)\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"kf = model_selection.KFold(n_splits=n_splits)\n\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of target values (KFold)\")\n    \nfor f, (t_, v_) in enumerate(kf.split(X=train_df)):\n    df = train_df.iloc[v_]\n    sns.distplot(df['target'],kde=True,hist=False, bins=120, label=f)\n    \nplt.legend(); plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kfold_splits(n_splits, train_df):\n    \"\"\"\n    Returns a collection of (fold, train indexes, validation indexes)\n    @param n_splits: number of splits\n    @param train_df: training data\n    @return: a collection of (fold, train indexes, validation indexes)\n    \"\"\"\n    all_folds = list(range(0, n_splits))\n    kf_splits = []\n    for fold in range(0, n_splits):\n        train_folds = [x for x in all_folds if x != fold]\n        trn_idx = train_df[train_df.kfold!=fold].index\n        val_idx = train_df[train_df.kfold==fold].index\n        kf_splits.append((fold, trn_idx, val_idx))\n    return kf_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'objective': 'regression',\n 'metric': 'rmse',\n 'verbosity': -1,\n 'boosting_type': 'gbdt',\n 'feature_pre_filter': False,\n  'learning_rate': 0.0035,\n 'lambda_l1': 18.42,\n 'lambda_l2': 4.02,\n 'num_leaves': 128,\n 'min_data_in_leaf': 81,\n 'sub_feature': 0.5,\n 'sub_row': 0.8,\n 'subsample_freq': 10}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df['target']\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nrandom_state = 42\nnum_round = 15000\nfor fold, trn_idx, val_idx in kfold_splits(n_splits, train_df):\n    print(f\"fold: {fold}, train len: {len(trn_idx)}, val len: {len(val_idx)}\")\n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=y.iloc[trn_idx])\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=y.iloc[val_idx])\n    clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 500)\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / n_splits\nprint(f'CV score: {np.round(mean_squared_error(y, oof, squared=False),5)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"id\":test_df.id, \"target\":predictions})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}