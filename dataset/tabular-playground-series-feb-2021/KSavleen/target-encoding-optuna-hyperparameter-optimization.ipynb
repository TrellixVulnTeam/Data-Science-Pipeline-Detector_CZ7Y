{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The original dataset deals with predicting the amount of an insurance claim","metadata":{}},{"cell_type":"code","source":"#Importing libraries\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nfrom xgboost import XGBRegressor\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:47:52.987512Z","iopub.execute_input":"2022-03-10T19:47:52.987831Z","iopub.status.idle":"2022-03-10T19:47:54.667039Z","shell.execute_reply.started":"2022-03-10T19:47:52.987745Z","shell.execute_reply":"2022-03-10T19:47:54.666287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the training dataset\ndf_train = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:47:54.670137Z","iopub.execute_input":"2022-03-10T19:47:54.670345Z","iopub.status.idle":"2022-03-10T19:47:56.781436Z","shell.execute_reply.started":"2022-03-10T19:47:54.670319Z","shell.execute_reply":"2022-03-10T19:47:56.780727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For this regression problem, we'll use K Fold","metadata":{}},{"cell_type":"markdown","source":"### Creating 5 Folds","metadata":{}},{"cell_type":"code","source":"df_train[\"K_Fold\"] = -1\nkf = model_selection.KFold(n_splits = 5, shuffle= True, random_state = 42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X = df_train)):\n    print(fold, train_indicies, valid_indicies)\n    df_train.loc[valid_indicies, \"K_Fold\"] = fold\n    \ndf_train.to_csv(\"KFolds_5.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:47:56.782879Z","iopub.execute_input":"2022-03-10T19:47:56.783416Z","iopub.status.idle":"2022-03-10T19:48:05.297492Z","shell.execute_reply.started":"2022-03-10T19:47:56.783376Z","shell.execute_reply":"2022-03-10T19:48:05.296681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the K fold data, test and submission datasets\ndf = pd.read_csv(\"./KFolds_5.csv\")\ndf_test = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\ndf_samSub = pd.read_csv(\"../input/tabular-playground-series-feb-2021/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:48:05.299294Z","iopub.execute_input":"2022-03-10T19:48:05.29957Z","iopub.status.idle":"2022-03-10T19:48:07.570001Z","shell.execute_reply.started":"2022-03-10T19:48:05.299533Z","shell.execute_reply":"2022-03-10T19:48:07.569249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Target Encoding of Categorical Data","metadata":{}},{"cell_type":"code","source":"useful_features = [uc for uc in df.columns if uc not in (\"id\",\"target\",\"K_Fold\")]\n#Categorical Features\nobject_cols = [col for col in useful_features if 'cat' in col]\n\ndf_test = df_test[useful_features]\n\nfor col in object_cols: #go through each column in object columns\n    temp_df = [] #empty list to store dataframes (training dfs)\n    temp_test_features = None #none feature for test set\n    for fold in range(5):\n        x_train = df[df.K_Fold != fold].reset_index(drop = True)\n        x_valid = df[df.K_Fold == fold].reset_index(drop = True)\n        feat_enc = x_train.groupby(col)[\"target\"].agg(\"mean\")\n        feat_enc = feat_enc.to_dict()\n        x_valid.loc[:, f\"tar_enc_{col}\"] = x_valid[col].map(feat_enc)\n        temp_df.append(x_valid)\n        if temp_test_features is None:   #if None i.e first fold - fold 0\n            temp_test_features = df_test[col].map(feat_enc)\n        else:\n            temp_test_features += df_test[col].map(feat_enc)\n        \n    temp_test_features /= 5\n    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_features\n    df = pd.concat(temp_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:48:07.571255Z","iopub.execute_input":"2022-03-10T19:48:07.571519Z","iopub.status.idle":"2022-03-10T19:48:14.192164Z","shell.execute_reply.started":"2022-03-10T19:48:07.571484Z","shell.execute_reply":"2022-03-10T19:48:14.191402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Updating the features\nuseful_features = [uc for uc in df.columns if uc not in (\"id\",\"target\",\"K_Fold\")]\nobject_cols = [col for col in useful_features if col.startswith('cat')]\nnumerical_cols = [clm for clm in useful_features if clm.startswith('cont')]\ndf_test = df_test[useful_features]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:48:14.193842Z","iopub.execute_input":"2022-03-10T19:48:14.19412Z","iopub.status.idle":"2022-03-10T19:48:14.252127Z","shell.execute_reply.started":"2022-03-10T19:48:14.194085Z","shell.execute_reply":"2022-03-10T19:48:14.25137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Hyperparameter Tuning using Optuna","metadata":{}},{"cell_type":"code","source":"def obj_func(trial):\n    fold = 1\n    #for fold in range(5):  #running for 5 folds means fitting model 5 time , huge data and time consuming\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5,0.25, log = True)#from 0.001 to 0.25\n    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8,100.0)#regularisation lambda\n    reg_alpha =trial.suggest_loguniform(\"reg_alpha\",1e-8, 100.0)\n    subsample = trial.suggest_float(\"subsample\",0.1,1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\",0.1,1.0)\n    max_depth = trial.suggest_int(\"max_depth\",1,7)\n\n    x_train = df[df.K_Fold != fold].reset_index(drop = True)\n    x_valid = df[df.K_Fold == fold].reset_index(drop = True)\n\n    y_train = x_train.target\n    y_valid = x_valid.target\n\n    x_train = x_train[useful_features]\n    x_valid = x_valid[useful_features]\n\n    ord_enc = preprocessing.OrdinalEncoder()\n    x_train[object_cols] = ord_enc.fit_transform(x_train[object_cols])\n    x_valid[object_cols] = ord_enc.transform(x_valid[object_cols])\n\n    std_scaler = preprocessing.StandardScaler()\n    x_train[numerical_cols] = std_scaler.fit_transform(x_train[numerical_cols])\n    x_valid[numerical_cols] = std_scaler.transform(x_valid[numerical_cols])\n\n    xgb_model = XGBRegressor(random_state = 42,\n                             tree_method = \"gpu_hist\",\n                             gpu_id = 0,\n                             predictor = \"gpu_predictor\",\n                             n_estimators = 7000, #keep it low(7k/10k/15k) to get good results\n                             learning_rate = learning_rate,\n                             reg_lambda = reg_lambda,\n                             reg_alpha = reg_alpha,\n                             subsample = subsample,\n                             colsample_bytree = colsample_bytree,\n                             max_depth = max_depth)\n\n    xgb_model.fit(x_train,y_train, early_stopping_rounds=500, eval_set=[(x_valid,y_valid)],verbose = 1000)\n    pred_valid = xgb_model.predict(x_valid)\n    rsme = mean_squared_error(y_valid,pred_valid, squared = False)\n    return rsme","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:57:03.70273Z","iopub.execute_input":"2022-03-10T19:57:03.703046Z","iopub.status.idle":"2022-03-10T19:57:03.716436Z","shell.execute_reply.started":"2022-03-10T19:57:03.703012Z","shell.execute_reply":"2022-03-10T19:57:03.715268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = \"minimize\")\nstudy.optimize(obj_func, n_trials=7)   \nstudy.best_params","metadata":{"execution":{"iopub.status.busy":"2022-03-10T19:57:06.587681Z","iopub.execute_input":"2022-03-10T19:57:06.58838Z","iopub.status.idle":"2022-03-10T19:59:05.217749Z","shell.execute_reply.started":"2022-03-10T19:57:06.588343Z","shell.execute_reply":"2022-03-10T19:59:05.217014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Optimized XGBoost ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"./KFolds_5.csv\")\ndf_test = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\ndf_samSub = pd.read_csv(\"../input/tabular-playground-series-feb-2021/sample_submission.csv\")\n\nuseful_features = [uc for uc in df.columns if uc not in (\"id\",\"target\",\"K_Fold\")]\nobject_cols = [col for col in useful_features if col.startswith('cat')]\nnumerical_cols = [clm for clm in useful_features if clm.startswith('cont')]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    x_train = df[df.K_Fold != fold].reset_index(drop = True)\n    x_valid = df[df.K_Fold == fold].reset_index(drop = True)\n    x_test = df_test.copy()\n    \n    y_train = x_train.target\n    y_valid = x_valid.target\n    \n    x_train = x_train[useful_features]\n    x_valid = x_valid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    x_train[object_cols] = ordinal_encoder.fit_transform(x_train[object_cols])\n    x_valid[object_cols] = ordinal_encoder.transform(x_valid[object_cols])\n    x_test[object_cols] = ordinal_encoder.transform(x_test[object_cols])\n    \n    #Standardizing the Numerical Data\n    std_scaler = preprocessing.StandardScaler()\n    x_train[numerical_cols] = std_scaler.fit_transform(x_train[numerical_cols])\n    x_valid[numerical_cols] = std_scaler.transform(x_valid[numerical_cols])\n    x_test[numerical_cols] = std_scaler.transform(x_test[numerical_cols])\n    \n    #using the optimized parameters to train the model\n    params = {'learning_rate': 0.014521078138264957,\n              'reg_lambda': 0.031156935545308233,\n              'reg_alpha': 23.3283725457658,\n              'subsample': 0.6477780845025514, \n              'colsample_bytree': 0.55158309424606,\n              'max_depth': 2}\n    \n    model = XGBRegressor(random_state = 42,\n                         tree_method = \"gpu_hist\",\n                         gpu_id = 0,\n                         predictor = \"gpu_predictor\",\n                         n_estimators = 7000,\n                         **params)\n    \n    model.fit(x_train,y_train)\n    valid_pred = model.predict(x_valid)\n    test_pred = model.predict(x_test)\n    final_predictions.append(test_pred)\n    rsme = mean_squared_error(y_valid,valid_pred, squared = False)\n    #we set squared=False to get the root mean squared error (RMSE) on the validation data.\n    print(f\"Fold {fold} RSME : {rsme}\")\n    scores.append(rsme)\n\nprint(f\"Mean of Scores : {np.mean(scores)}  and Standard Deviation of Scores : {np.std(scores)}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:01:00.308914Z","iopub.execute_input":"2022-03-10T20:01:00.309745Z","iopub.status.idle":"2022-03-10T20:01:56.881621Z","shell.execute_reply.started":"2022-03-10T20:01:00.309694Z","shell.execute_reply":"2022-03-10T20:01:56.880855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the submission dataset\ndf_samSub.target = np.mean(np.column_stack(final_predictions), axis = 1)\ndf_samSub.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:03:51.597371Z","iopub.execute_input":"2022-03-10T20:03:51.598127Z","iopub.status.idle":"2022-03-10T20:03:52.045182Z","shell.execute_reply.started":"2022-03-10T20:03:51.598087Z","shell.execute_reply":"2022-03-10T20:03:52.044422Z"},"trusted":true},"execution_count":null,"outputs":[]}]}