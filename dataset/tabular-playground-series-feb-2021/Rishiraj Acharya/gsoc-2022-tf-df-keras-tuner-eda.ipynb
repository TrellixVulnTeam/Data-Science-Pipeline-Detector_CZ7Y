{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A lot of the code here was inspired from Paul Mooney's [notebook on TF-DF](https://www.kaggle.com/code/paultimothymooney/getting-started-with-tensorflow-decision-forests). Make sure to check that out as well.","metadata":{}},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"A learning algorithm trains a machine learning model on a training dataset. The parameters of a learning algorithm–called \"hyper-parameters\"–control how the model is trained and impact its quality. Therefore, finding the best hyper-parameters is an important stage of modeling.\n\nAutomated tuning algorithms work by generating and evaluating a large number of hyper-parameter values. Each of those iterations is called a \"trial\". The evaluation of a trial is expensive as it requires to train a new model each time. At the end of the tuning, the hyper-parameter with the best evaluation is used.\n\nTo demonstrate automated hyper-parameter tuning in TF-DF we'll be working with the Tabular Playground Series Feb 2021 Kaggle Dataset. It is a tabular dataset with 300,000 rows and 26 columns in training (93.66 MiB .CSV training dataset + 58.85 MiB .CSV test set) that is suitable for training algorithms to solve regression problems.\n\nWe'll be predicting a continuous target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat9 are categorical, and the feature columns cont0 - cont13 are continuous.\n\nBy studying this tutorial you will learn how to quickly and automatically tune hyper-parameters of a GradientBoostedTrees model to perform a regression task using tabular data.","metadata":{}},{"cell_type":"markdown","source":"# Installing TensorFlow Decision Forests & Keras Tuner","metadata":{}},{"cell_type":"code","source":"# Display only the messages with ERROR, CRITICAL log levels\n!pip install tensorflow_decision_forests -U -qq\n# Install the Keras tuner\n!pip install keras-tuner -U -qq","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"# Import Python packages\nimport os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras_tuner as kt\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nprint(\"TensorFlow Decision Forests v\" + tfdf.__version__)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"# Define helper functions for plotting training evaluation curves\n\ndef plot_tfdf_model_training_curves(model):\n    # This function was adapted from the following tutorial:\n    # https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\n    logs = model.make_inspector().training_logs()\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    # Plot RMSE vs number of trees\n    plt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\n    plt.xlabel(\"Number of trees\")\n    plt.ylabel(\"RMSE (out-of-bag)\")\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print list of all data and files attached to this notebook\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the dataset and convert it in a tf.Dataset","metadata":{}},{"cell_type":"markdown","source":"The dataset contains a mix of numerical (e.g. cont0 - cont13) and categorical (e.g. cat0 - cat9) features. TF-DF supports all these feature types natively (differently than NN based models), therefore there is no need for preprocessing in the form of one-hot encoding or normalization. Also by default the task is set to Classification in TF-DF, we'll change that to Regression.","metadata":{}},{"cell_type":"code","source":"def split_dataset(dataset, test_ratio=0.30):\n  \"\"\"Splits a panda dataframe in two.\"\"\"\n  test_indices = np.random.rand(len(dataset)) < test_ratio\n  return dataset[~test_indices], dataset[test_indices]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load to pandas dataframe (for data exploration)\ntrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/test.csv')\n\n# load to tensorflow dataset (for model training)\ntrain_tfds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"target\", task=tfdf.keras.Task.REGRESSION)\ntest_tfds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, task=tfdf.keras.Task.REGRESSION)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis","metadata":{}},{"cell_type":"code","source":"# print column names\nprint(train_df.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preview first few rows of data\ntrain_df.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print basic summary statistics\ntrain_df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for missing values\nsns.heatmap(train_df.isnull(), cbar=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Automatic hyper-parameter tuning","metadata":{}},{"cell_type":"markdown","source":"Hyper-paramter tuning is enabled by specifying the tuner constructor argument of the model. The tuner object contains all the configuration of the tuner (search space, optimizer, trial and objective).","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n  \"\"\"Creates a model.\"\"\"\n\n  model = tfdf.keras.GradientBoostedTreesModel(task=tfdf.keras.Task.REGRESSION,\n      min_examples=hp.Choice(\"min_examples\", [2, 5, 7, 10]),\n      categorical_algorithm=hp.Choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"]),\n      max_depth=hp.Choice(\"max_depth\", [4, 5, 6, 7]),\n#       # The keras tuner convert automaticall boolean parameters to integers.\n#       # Regression tasks currently does not support hessian optimization in TF-DF\n#       # https://github.com/tensorflow/decision-forests/issues/116\n#       use_hessian_gain=bool(hp.Choice(\"use_hessian_gain\", [True, False])),\n      shrinkage=hp.Choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15]),\n      num_candidate_attributes_ratio=hp.Choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0]),\n  )\n\n  # Optimize the model accuracy as computed on the validation dataset.\n  model.compile(metrics=[tf.keras.metrics.RootMeanSquaredError()])\n  return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition to having a default set of hyper-parameters, TF-DF also provides you with a list of additional hyper-parameter choices to consider.","metadata":{}},{"cell_type":"code","source":"print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, here we'll not be using the default hyper-parameter choices and tune them to get the best results instead. Also by default the task is set to Classification in TF-DF, we'll change that to Regression.","metadata":{}},{"cell_type":"code","source":"keras_tuner = kt.RandomSearch(\n    build_model,\n    objective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"),\n    max_trials=10,\n    overwrite=True,\n    directory=\"/tmp/keras_tuning\")\n\n# Important: The tuning should not be done on the test dataset.\n\n# Extract a validation dataset from the training dataset. The new training\n# dataset is called the \"sub-training-dataset\".\nsub_train_df, sub_valid_df = split_dataset(train_df)\nsub_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(sub_train_df, label=\"target\", task=tfdf.keras.Task.REGRESSION)\nsub_valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(sub_valid_df, label=\"target\", task=tfdf.keras.Task.REGRESSION)\n\n# Tune the model\nkeras_tuner.search(sub_train_ds, validation_data=sub_valid_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best hyper-parameters.\nbest_hyper_parameters = keras_tuner.get_best_hyperparameters()[0].values\nprint(\"Best hyper-parameters:\", keras_tuner.get_best_hyperparameters()[0].values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n# # The keras tuner convert automaticall boolean parameters to integers.\n# best_hyper_parameters[\"use_hessian_gain\"] = bool(best_hyper_parameters[\"use_hessian_gain\"])\nbest_model = tfdf.keras.GradientBoostedTreesModel(**best_hyper_parameters, task=tfdf.keras.Task.REGRESSION)\nbest_model.fit(train_tfds, verbose=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot the model","metadata":{}},{"cell_type":"markdown","source":"We plot the evoluation of the best score during the training and then the tuning.","metadata":{}},{"cell_type":"code","source":"plot_tfdf_model_training_curves(best_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model","metadata":{}},{"cell_type":"markdown","source":"For this dataset, submissions are scored on the root mean squared error. Hence we evaluate the model on that metrics.","metadata":{}},{"cell_type":"code","source":"best_model.compile(metrics=[tf.keras.metrics.RootMeanSquaredError()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model.evaluate(train_tfds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variable importances generally indicates how much a variable contributes to the model predictions or quality. Variable importance SUM_SCORE is sum of the split scores using a specific feature. The larger, the most important.","metadata":{}},{"cell_type":"code","source":"best_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"sample_submission_df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/sample_submission.csv')\nsample_submission_df['target'] = best_model.predict(test_tfds)\nsample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\nsample_submission_df.head()","metadata":{},"execution_count":null,"outputs":[]}]}