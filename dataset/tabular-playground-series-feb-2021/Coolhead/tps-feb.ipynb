{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Importing the files"},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE = \"../input/tabular-playground-series-feb-2021\"\nTest = pd.read_csv(BASE + '/test.csv')\n\ntrain = pd.read_csv(BASE + '/train.csv')\n\nsample_sub = pd.read_csv(BASE + '/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA of the tabular data\n* We have two types of features here \n1. Categorical = 'Cat'\n2. Continuous = 'Cont'\n<h1>ideas</h1>\n* We would have to do Categorical encoding for categorical features\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Rows and Columns in train dataset:', train.shape)\nprint('Rows and Columns in test dataset:', Test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Checking for any null-data in the dataset\nprint('Rows and Columns in train dataset:', sum(train.isnull().sum()))\nprint('Rows and Columns in test dataset:', sum(Test.isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's see how the submission file looks"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [feature for feature in train.columns if 'cat' in feature]\ncont_features = [feature for feature in train.columns if 'cont' in feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Target')\ntrain['target'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 10), facecolor='#f6f5f5')\n## a grid of 4 \ngs = fig.add_gridspec(4, 4)\n## to create space\ngs.update(wspace=0.2, hspace=0.05)\n\n## background-color \nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor col in range(0, 4):\n    for row in range(0, 4):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        for s in [\"top\",\"right\", 'left']:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nax0.text(-0.3, 5.3, 'Continuous Features Distribution on Train Dataset', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-0.3, 4.7, 'Continuous features have multimodal', fontsize=13, fontweight='light', fontfamily='serif')        \n\nrun_no = 0\nfor col in cont_features:\n    sns.kdeplot(train[col], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#2f5586', edgecolor='black', linewidth=1.5, alpha=0.9, zorder=3)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n    locals()[\"ax\"+str(run_no)].set_ylabel(col, fontsize=10, fontweight='bold').set_rotation(0)\n    locals()[\"ax\"+str(run_no)].yaxis.set_label_coords(1, 0)\n    locals()[\"ax\"+str(run_no)].set_xlim(-0.2, 1.2)\n    locals()[\"ax\"+str(run_no)].set_xlabel('')\n    run_no += 1\n    \nax14.remove()\nax15.remove()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(train['target'], shade=True, color=\"#003f5c\", edgecolor=\"black\", linewidth= 1.5, alpha=0.9, zorder=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Count of Categorical Features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Count_diagram(data, background_color=\"#f5f3f3\",cat_features = cat_features):\n    background_color = \"#f5f3f3\"\n\n    fig = plt.figure(figsize=(25, 10), facecolor=background_color)\n    gs = fig.add_gridspec(2, 5)\n    gs.update(wspace=0.2, hspace=0.2)\n\n    run_no = 0\n    for row in range(0,2):\n        for col in range(0,5):\n            locals()[\"ax\"+ str(run_no)] = fig.add_subplot(gs[row, col])\n            locals()[\"ax\" + str(run_no)].set_facecolor(background_color)\n            for s in ['top', 'right', 'left']:\n                locals()[\"ax\"+ str(run_no)].spines[s].set_visible(False)\n            run_no += 1\n\n\n    ax0.text(0, 0,'Count of categorical features on Train dataset (%)', fontsize=20, fontweight=\"bold\", fontfamily=\"serif\")\n    ax0.text(0,0, 'Some features are dominated by one category', fontsize=13, fontweight='light', fontfamily=\"serif\")\n\n\n    run_no = 0\n    for col in cat_features: \n        dataformating = data[col].value_counts() /len(data) * 100\n        chart_df = pd.DataFrame(dataformating)\n        sns.barplot(x=chart_df.index, y=chart_df[col], ax=locals()[\"ax\" + str(run_no)], color=\"#003f5c\", zorder=3, edgeColor=\"black\", linewidth=1.5)\n        locals()['ax'+str(run_no)].grid(which='major', axis= 'y', zorder=0, color='grey', linestyle=':', dashes=(1,5))\n        run_no += 1\n        \n    plt.show()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Count_diagram(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Count_diagram(Test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation with Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"background_color = \"#f6f5f5\"\n\nfig = plt.figure(figsize=(12, 8), facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\nax0 = fig.add_subplot(gs[0, 0])\ncolors = [\"#2f5586\", \"#f6f5f5\",\"#2f5586\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nax0.set_facecolor(background_color)\nax0.text(-1.1, 0.048, 'Correlation of Continuous Features with Target', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-1.1, 0.045, 'There is no features that pass 0.04 correlation with target', fontsize=13, fontweight='light', fontfamily='serif')\n\nchart_df = pd.DataFrame(train[cont_features].corrwith(train['target']))\nchart_df.columns = ['corr']\nsns.barplot(x=chart_df.index, y=chart_df['corr'], ax=ax0, color='#2f5586', zorder=3, edgecolor='black', linewidth=1.5)\nax0.grid(which='major', axis='y', zorder=0, color='gray', linestyle=':', dashes=(1,5))\nax0.set_ylabel('')\n\nfor s in [\"top\",\"right\", 'left']:\n    ax0.spines[s].set_visible(False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15), facecolor = '#f6f5f5')\ngs = fig.add_gridspec(4, 4)\ngs.update(wspace=0.5, hspace=0.5)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 4):\n    for col in range(0, 4):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\",\"left\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor feature in cont_features:\n        sns.scatterplot(x=train[feature], y=train['target'] ,ax=locals()[\"ax\"+str(run_no)], color='#2f5586', linewidth=0.3, edgecolor='black')\n        locals()[\"ax\"+str(run_no)].grid(which='major', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        run_no += 1\n        \nax0.text(-0.5, 14, 'Features and Target Relation', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-0.5, 12.4, 'cont1 has a distinct separation', fontsize=13, fontweight='light', fontfamily='serif')\n\nax14.remove()\nax15.remove()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.2.2 Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in cat_features:\n    value = pd.Series(train[cat].value_counts().sort_index().index)\n\n    fig = plt.figure(figsize=(60, 5), facecolor='#f6f5f5')\n    gs = fig.add_gridspec(len(value), 5)\n    gs.update(wspace=0.2, hspace=0.05)\n\n    background_color = \"#f6f5f5\"\n\n    run_no = 0\n    for row in range(0, len(value)):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, 0])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        for s in [\"top\",\"right\", 'left']:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\n    ax0.text(-0.5, 0.52, 'Target Distribution on {cat} feature '.format(cat=cat), fontsize=20, fontweight='bold', fontfamily='serif')\n    ax0.text(-0.5, 0.46, 'To see how target is distributed across each value', fontsize=13, fontweight='light', fontfamily='serif')        \n\n    run_no = 0\n    for val in value:\n        sns.kdeplot(train[train[cat]==val]['target'], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#2f5586', edgecolor='black', linewidth=1.5, alpha=0.9, zorder=3)\n        locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        locals()[\"ax\"+str(run_no)].set_ylabel(val, fontsize=20, fontweight='bold').set_rotation(0)\n        locals()[\"ax\"+str(run_no)].yaxis.set_label_coords(1.015, 0)\n        locals()[\"ax\"+str(run_no)].set_xlim(-0.5, 10.5)\n        run_no += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport gc\nimport matplotlib.pyplot as plt\nimport shap\n\n# load JS visualization code to notebook\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = Test.columns[1:]\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['target'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label encoding the categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = columns[:10]\ncat_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in cat_features:\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])\n    Test[feature] = le.transform(Test[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# using the xgBoost model for featuree engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade xgboost\nimport xgboost as xgb\nxgb.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_params= {\n        \"objective\": \"reg:squarederror\",\n        \"max_depth\": 6,\n        \"learning_rate\": 0.01,\n        \"colsample_bytree\": 0.4,\n        \"subsample\": 0.6,\n        \"reg_alpha\" : 6,\n        \"min_child_weight\": 100,\n        \"n_jobs\": 2,\n        \"seed\": 2001,\n        'tree_method': \"gpu_hist\",\n        \"gpu_id\": 0,\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_oof = np.zeros((300000,))\ntest_preds = 0\ntrain_oof.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test = xgb.DMatrix(Test[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        \n        train_df = xgb.DMatrix(train_df, label=train_target)\n        val_df = xgb.DMatrix(val_df, label=val_target)\n        \n        model =  xgb.train(xgb_params, train_df, 3600)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(Test)\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test/NUM_FOLDS\n        \n        print(mean_squared_error(temp_oof, val_target, squared=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(train_oof, target, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof', train_oof)\nnp.save('test_preds', test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nshap_preds = model.predict(test, pred_contribs=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\nfor feature in cat_features:\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])\n    test[feature] = le.transform(test[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize the effects of all the features\nshap.summary_plot(shap_preds[:,:-1], test[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub['target'] = test_preds\nsample_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}