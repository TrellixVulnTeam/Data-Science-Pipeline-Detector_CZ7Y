{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Purpose: Importing Libraries\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore, chi2_contingency\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_validate, learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Purpose: Reading data in from Kaggle\ntraining = \"/kaggle/input//tabular-playground-series-feb-2021/train.csv\"\ntraining_df = pd.read_csv(training)\n\ntesting = \"/kaggle/input//tabular-playground-series-feb-2021/test.csv\"\ntesting_df = pd.read_csv(testing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#QC: Displaying head\ntraining_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Describe function\ntraining_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation Matrix \nfig, scatter = plt.subplots(figsize = (16,9))\ncorrMatrix = training_df.corr()\nscatter = sn.heatmap(corrMatrix, annot = True)\nscatter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Findings: (pearson corr p value)\n1. cont0 has a +ve corr with cont5(0.58) cont8(0.58) cont9(0.52)\n2. cont5 has a +ve corr with cont8(0.61) cont9(0.62) cont11(0.51) cont12(0.63)\n3. cont8 has a +ve corr with cont9(0.56) cont12(0.53)\n4. cont9 has a +ve corr with cont11(0.52) cont12(0.54)\n5. cont10 has a +ve corr with cont11(0.56)\n\n6. cont2 has a -ve corr with cont0 cont3 cont5 cont6 cont7 cont8 cont9 cont10 cont11 cont12 cont13"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Purpose: Plotting a histogram to see the distribution\nfig = plt.figure(figsize = (15,20))\nax = fig.gca()\ntraining_df.hist(ax = ax, bins = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a dummy dataframe and removing id and target \ntraining_wo_id_target = training_df.drop(columns = [\"id\", \"target\"]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Purpose: Plotting a boxplot to see the outlier distribution\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\ntraining_wo_id_target.boxplot(ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Outlier Detection using Z Score!** \n\n\nA negative Z-score means an observation is below the mean, while a positive one means it above it. The further away from 0 the Z-Score is, the further away from the mean your observation is.\n\nOne way to identify outliers is to determine which points have a z-score that's far from 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the score\nnumeric_cols = training_wo_id_target.select_dtypes(include=[np.number]).columns\nscores = training_wo_id_target[numeric_cols].apply(zscore)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the upper whisker outliers \nscore_max = pd.DataFrame(scores>3)\nfor col in score_max:\n    print(score_max[col].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the lower whisker outliers \nscore_min = pd.DataFrame(scores<-3)\nfor col in score_min:\n    print(score_min[col].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['cat0','cat1','cat2','cat3','cat4','cat5','cat6','cat7','cat8','cat9']\nfor column in columns:\n    print(column)\n    print(training_df[column].value_counts())\n    print(\"======\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = training_df['target']\nx = training_df.drop(['target','id'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_df_cat = training_df.select_dtypes(\"object\").columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_df_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct = ColumnTransformer(transformers=[['oe',OrdinalEncoder(),training_df_cat]],remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline(steps=[['ord_encoder',ct],\n                          ['rfe',RFE(estimator=xgb.XGBRegressor(tree_method='gpu_hist',random_state=11,n_jobs=-1),\n                                    n_features_to_select=20)],\n                          ['regressor',xgb.XGBRegressor(tree_method='gpu_hist',random_state=11,n_jobs=-1,\n                                                       max_depth=4,n_estimators=200,reg_lambda=100)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = cross_validate(estimator=pipeline,X=x,y=y,scoring='neg_root_mean_squared_error',cv=5,n_jobs=-1,return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_cont = x.select_dtypes(\"float64\")\nx_cont","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_breast = PCA(n_components=2)\nprincipalComponents_breast = pca_breast.fit_transform(x_cont)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principal_breast_Df = pd.DataFrame(data = principalComponents_breast, columns = ['pc1', 'pc2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new  = training_df[training_df_cat].join(principal_breast_Df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = cross_validate(estimator=pipeline,X=new,y=y,scoring='neg_root_mean_squared_error',cv=5,n_jobs=-1,return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}