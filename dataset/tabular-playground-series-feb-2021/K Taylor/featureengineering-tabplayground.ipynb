{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering Approach towards Tabular Playground Feb"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I use several feature engineering and selection methods on the February Tabular Playground dataset. Due to this being synthetic data,feature engineering and selection produces lower accuracy results for prediction submissions than those without. However, I think it is worth sharing my approaches for others to learn from and potentially use in other competitions which use real data, where this appraoch would be appropriate."},{"metadata":{},"cell_type":"markdown","source":" - Requirements: feature_engine-1.0.2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install feature_engine","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom category_encoders import *\nfrom feature_engine.encoding import CountFrequencyEncoder\nfrom matplotlib.lines import Line2D\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15,15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/tabular-playground-series-feb-2021/\"\ntrain = pd.read_csv(path + \"train.csv\", index_col=\"id\")\ntest = pd.read_csv(path + \"test.csv\", index_col=\"id\")\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicates:\n\nduplicates = train.duplicated()\nduplicates.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numerical columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = train[[\"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\"]]\nnumerical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.to_csv(\"numerical_columns.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.hist(figsize=((20,20)), alpha=0.5, animated=True, edgecolor='blue', color='lightblue', grid=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.boxplot(showcaps=True, showfliers=True)\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### \"cont0\" has outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(numerical_columns[\"cont0\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont0\"], color='red', alpha=0.01);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont0\"]))\nprint(z)\n\nprint(np.where(z > 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows that there is only one outlier that has a z-score greater than 3. We must locate this in order to remove it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns[\"cont0\"].iloc[[132579]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove this outlier:\nnumerical_columns = numerical_columns.loc[numerical_columns[\"cont0\"] >= -0.093]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check it is removed:\nnumerical_columns[\"cont0\"].sort_values(ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### \"cont2\" outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(numerical_columns[\"cont2\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont2\"], color='red', alpha=0.01);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont2\"]))\nprint(z)\n\nprint(np.where(z > 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The outliers we see on the boxplot for \"cont2\" are not too bad according to the zscore, so we leave them in."},{"metadata":{},"cell_type":"markdown","source":"##### \"cont6\" outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(numerical_columns[\"cont6\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont6\"], color='red', alpha=0.01);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont6\"]))\nprint(z)\nprint(np.where(z > 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find where z is greater than three:\nx = z.tolist()\nx = sorted(x, reverse=True)\nprint(x[110:130])\nprint(\"Index of first value with z-score > 3: \", np.where(z == 3.0010249691534847))\nprint(\"Index of last value with z-score < 3: \", np.where(z == 2.999924948184652))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(numerical_columns[\"cont6\"].iloc[[16410]])\nprint(numerical_columns[\"cont6\"].iloc[[254380]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the outliers with value greater than 1.055627:\nnumerical_columns = numerical_columns.loc[numerical_columns[\"cont6\"] <= 1.055627]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check they are removed:\nnumerical_columns[\"cont6\"].sort_values(ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### \"cont8\" outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(numerical_columns[\"cont8\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont8\"], color='red', alpha=0.01);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont8\"]))\nprint(z)\nprint(np.where(z > 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The outliers we see on the boxplot for \"cont8\" are not too bad according to the zscore, so we leave them in."},{"metadata":{},"cell_type":"markdown","source":"#### Correlation matrix:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns[\"target\"] = train[\"target\"]\ncorr = numerical_columns.corr()\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Numerical columns most correlated with target column:\\n\", abs(corr[\"target\"]).sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Numerical columns dataframe with removed outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns.to_csv(\"numerical_columns_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = train[[\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"]]\ncategorical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_rows, num_cols = 3,4\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(12, 12))\nfor index, column in enumerate(categorical_columns.columns):\n    i,j = (index // num_cols, index % num_cols)\n    sns.histplot(x=column, data=categorical_columns, ax=axes[i,j]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target:"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train[\"target\"]\ntarget.to_csv(\"target.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.kdeplot(target, shade=True, color='red', edgecolor='black', alpha=0.5, zorder=3)\nplt.title('Target Distribution', fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(target, showcaps=True, showfliers=True)\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(target))\nprint(z)\n\nprint(np.where(z > 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find where z is greater than three:\nx = z.tolist()\nx = sorted(x, reverse=True)\nprint(x[400:450])\nprint(\"Index of first value with z-score > 3: \", np.where(z == 3.0000214311993463))\nprint(\"Index of first value with z-score < 3: \", np.where(z == 2.9997811336456435))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(target.iloc[[3882]])\nprint(target.iloc[[9720]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the outliers with value less than 4.794575:\ntarget = target.loc[target >= 4.794575]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check they are removed:\nplt.boxplot(target, showcaps=True, showfliers=True)\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.to_csv(\"target_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicates:\n\nduplicates = test.duplicated()\nduplicates.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_test = test[[\"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\"]]\nnumerical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_test = test[[\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"]]\ncategorical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_test.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see the test set has the same features and range of values as the train set. So we do not make any changes to the train set in relation to the test set."},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n## Categorical columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ordinal Encoder:"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OrdinalEncoder()\nX = categorical_columns\nenc.fit(X)\nordinal_categorical_columns = enc.transform(categorical_columns)\nordinal_categorical_columns = pd.DataFrame(ordinal_categorical_columns)\nordinal_categorical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_categorical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_categorical_columns.to_csv(\"ordinal_categorical_columns.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One-Hot Encoding:"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(categorical_columns)\nonehot_categorical_columns = enc.transform(categorical_columns)\nonehot_categorical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_categorical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_categorical_columns.to_csv(\"onehot_categorical_columns.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Binary Encoding:"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = BinaryEncoder().fit(categorical_columns)\nbinary_categorical_columns = enc.transform(categorical_columns)\nbinary_categorical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_categorical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_categorical_columns.to_csv(\"binary_categorical_columns.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Frequency encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = CountFrequencyEncoder(encoding_method='frequency')\nencoder.fit(categorical_columns)\nfreq_categorical_columns = encoder.transform(categorical_columns)\nfreq_categorical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_categorical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_categorical_columns.to_csv(\"freq_categorical_columns.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Point for next step - modelling:\n- Try each different encoded set for the categorical_columns.\n- See which one gives best result in modelling."},{"metadata":{},"cell_type":"markdown","source":"## Numerical columns"},{"metadata":{},"cell_type":"markdown","source":"### Numerical Columns with Outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nnumerical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.DataFrame()\nlog_numerical_columns[\"id\"] = numerical_columns[\"id\"]\n\nlog_numerical_columns['cont0_log'] = np.log((1+ numerical_columns['cont0']))\ncont0_log_mean = np.round(np.mean(log_numerical_columns['cont0_log']), 2)\n\nlog_numerical_columns['cont1_log'] = np.log((1+ numerical_columns['cont1']))\ncont1_log_mean = np.round(np.mean(log_numerical_columns['cont1_log']), 2)\n\nlog_numerical_columns['cont2_log'] = np.log((1+ numerical_columns['cont2']))\ncont2_log_mean = np.round(np.mean(log_numerical_columns['cont2_log']), 2)\n\nlog_numerical_columns['cont3_log'] = np.log((1+ numerical_columns['cont3']))\ncont3_log_mean = np.round(np.mean(log_numerical_columns['cont3_log']), 2)\n\nlog_numerical_columns['cont4_log'] = np.log((1+ numerical_columns['cont4']))\ncont4_log_mean = np.round(np.mean(log_numerical_columns['cont4_log']), 2)\n\nlog_numerical_columns['cont5_log'] = np.log((1+ numerical_columns['cont5']))\ncont5_log_mean = np.round(np.mean(log_numerical_columns['cont5_log']), 2)\n\nlog_numerical_columns['cont6_log'] = np.log((1+ numerical_columns['cont6']))\ncont6_log_mean = np.round(np.mean(log_numerical_columns['cont6_log']), 2)\n\nlog_numerical_columns['cont7_log'] = np.log((1+ numerical_columns['cont7']))\ncont7_log_mean = np.round(np.mean(log_numerical_columns['cont7_log']), 2)\n\nlog_numerical_columns['cont8_log'] = np.log((1+ numerical_columns['cont8']))\ncont8_log_mean = np.round(np.mean(log_numerical_columns['cont8_log']), 2)\n\nlog_numerical_columns['cont9_log'] = np.log((1+ numerical_columns['cont9']))\ncont9_log_mean = np.round(np.mean(log_numerical_columns['cont9_log']), 2)\n\nlog_numerical_columns['cont10_log'] = np.log((1+ numerical_columns['cont10']))\ncont10_log_mean = np.round(np.mean(log_numerical_columns['cont10_log']), 2)\n\nlog_numerical_columns['cont11_log'] = np.log((1+ numerical_columns['cont11']))\ncont11_log_mean = np.round(np.mean(log_numerical_columns['cont11_log']), 2)\n\nlog_numerical_columns['cont12_log'] = np.log((1+ numerical_columns['cont12']))\ncont12_log_mean = np.round(np.mean(log_numerical_columns['cont12_log']), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns.to_csv(\"log_numerical_columns.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Plots comparing original with log transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(numerical_columns[\"cont0\"], color='green', alpha=0.5, edgecolor='black')\nplt.hist(log_numerical_columns['cont0_log'], bins=30, color='lightblue', edgecolor='black')\nplt.axvline(cont0_log_mean, color='red')\nplt.title('cont0 histogram before and after Log Transform', fontsize=20)\nplt.xlabel('cont0 (log scale)', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n# custom legend\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='lightblue', lw=4),\n                Line2D([0], [0], color='red', lw=4)]\n\nplt.legend(custom_lines, ['cont0', 'cont0_log', 'cont0_log_mean']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(numerical_columns[\"cont1\"], color='green', alpha=0.5, edgecolor='black')\nplt.hist(log_numerical_columns['cont1_log'], bins=30, color='lightblue', edgecolor='black')\nplt.axvline(cont1_log_mean, color='red')\nplt.title('cont1 histogram before and after Log Transform', fontsize=20)\nplt.xlabel('cont1 (log scale)', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n# custom legend\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='lightblue', lw=4),\n                Line2D([0], [0], color='red', lw=4)]\n\nplt.legend(custom_lines, ['cont1', 'cont1_log', 'cont1_log_mean']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check how the log transformations are correlated with target:"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_test = log_numerical_columns.merge(target, on=\"id\")\ncorr_test = corr_test.iloc[::, 1:]\ncorr = corr_test.corr()\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Numerical columns most correlated with target column:\\n\", abs(corr[\"target\"]).sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical Columns without Outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nnumerical_columns_NO.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.DataFrame()\nlog_numerical_columns[\"id\"] = numerical_columns_NO[\"id\"]\n\nlog_numerical_columns['cont0_log'] = np.log((1+ numerical_columns_NO['cont0']))\ncont0_log_mean = np.round(np.mean(log_numerical_columns['cont0_log']), 2)\n\nlog_numerical_columns['cont1_log'] = np.log((1+ numerical_columns_NO['cont1']))\ncont1_log_mean = np.round(np.mean(log_numerical_columns['cont1_log']), 2)\n\nlog_numerical_columns['cont2_log'] = np.log((1+ numerical_columns_NO['cont2']))\ncont2_log_mean = np.round(np.mean(log_numerical_columns['cont2_log']), 2)\n\nlog_numerical_columns['cont3_log'] = np.log((1+ numerical_columns_NO['cont3']))\ncont3_log_mean = np.round(np.mean(log_numerical_columns['cont3_log']), 2)\n\nlog_numerical_columns['cont4_log'] = np.log((1+ numerical_columns_NO['cont4']))\ncont4_log_mean = np.round(np.mean(log_numerical_columns['cont4_log']), 2)\n\nlog_numerical_columns['cont5_log'] = np.log((1+ numerical_columns_NO['cont5']))\ncont5_log_mean = np.round(np.mean(log_numerical_columns['cont5_log']), 2)\n\nlog_numerical_columns['cont6_log'] = np.log((1+ numerical_columns_NO['cont6']))\ncont6_log_mean = np.round(np.mean(log_numerical_columns['cont6_log']), 2)\n\nlog_numerical_columns['cont7_log'] = np.log((1+ numerical_columns_NO['cont7']))\ncont7_log_mean = np.round(np.mean(log_numerical_columns['cont7_log']), 2)\n\nlog_numerical_columns['cont8_log'] = np.log((1+ numerical_columns_NO['cont8']))\ncont8_log_mean = np.round(np.mean(log_numerical_columns['cont8_log']), 2)\n\nlog_numerical_columns['cont9_log'] = np.log((1+ numerical_columns_NO['cont9']))\ncont9_log_mean = np.round(np.mean(log_numerical_columns['cont9_log']), 2)\n\nlog_numerical_columns['cont10_log'] = np.log((1+ numerical_columns_NO['cont10']))\ncont10_log_mean = np.round(np.mean(log_numerical_columns['cont10_log']), 2)\n\nlog_numerical_columns['cont11_log'] = np.log((1+ numerical_columns_NO['cont11']))\ncont11_log_mean = np.round(np.mean(log_numerical_columns['cont11_log']), 2)\n\nlog_numerical_columns['cont12_log'] = np.log((1+ numerical_columns_NO['cont12']))\ncont12_log_mean = np.round(np.mean(log_numerical_columns['cont12_log']), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns.to_csv(\"log_numerical_columns_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Plots comparing original with log transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(numerical_columns[\"cont0\"], color='green', alpha=0.5, edgecolor='black')\nplt.hist(log_numerical_columns['cont0_log'], bins=30, color='lightblue', edgecolor='black')\nplt.axvline(cont0_log_mean, color='red')\nplt.title('cont0 histogram before and after Log Transform', fontsize=20)\nplt.xlabel('cont0 (log scale)', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n# custom legend\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='lightblue', lw=4),\n                Line2D([0], [0], color='red', lw=4)]\n\nplt.legend(custom_lines, ['cont0', 'cont0_log', 'cont0_log_mean']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check how the log transformations are correlated with target:"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_test = log_numerical_columns.merge(target, on=\"id\")\ncorr_test = corr_test.iloc[::, 1:]\ncorr = corr_test.corr()\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Numerical columns most correlated with target column:\\n\", abs(corr[\"target\"]).sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the log transformations are more correlated with the target when the outliers from the original numerical columns are **NOT REMOVED**."},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"# Test Dataset\n### Possible transformations"},{"metadata":{},"cell_type":"markdown","source":"### Point:\nWhatever transformations we do to the train dataset, we must be consistent and do those changes to the test dataset too - to take as different csv's for the modelling step.\n\nFor example:\n- Binary encoded train set - must also have binary encoded test set.\n- Log transformed train set - must also have log transformed test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical transformations:\n#### Log transformations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.reset_index(level=0, inplace=True)\ntest.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_test = test[[\"id\", \"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\"]]\nnumerical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_test.to_csv(\"numerical_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_test = pd.DataFrame()\nlog_numerical_test[\"id\"] = numerical_test[\"id\"]\n\nlog_numerical_test['cont0_log'] = np.log((1+ numerical_test['cont0']))\ncont0_log_mean = np.round(np.mean(log_numerical_test['cont0_log']), 2)\n\nlog_numerical_test['cont1_log'] = np.log((1+ numerical_test['cont1']))\ncont1_log_mean = np.round(np.mean(log_numerical_test['cont1_log']), 2)\n\nlog_numerical_test['cont2_log'] = np.log((1+ numerical_test['cont2']))\ncont2_log_mean = np.round(np.mean(log_numerical_test['cont2_log']), 2)\n\nlog_numerical_test['cont3_log'] = np.log((1+ numerical_test['cont3']))\ncont3_log_mean = np.round(np.mean(log_numerical_test['cont3_log']), 2)\n\nlog_numerical_test['cont4_log'] = np.log((1+ numerical_test['cont4']))\ncont4_log_mean = np.round(np.mean(log_numerical_test['cont4_log']), 2)\n\nlog_numerical_test['cont5_log'] = np.log((1+ numerical_test['cont5']))\ncont5_log_mean = np.round(np.mean(log_numerical_test['cont5_log']), 2)\n\nlog_numerical_test['cont6_log'] = np.log((1+ numerical_test['cont6']))\ncont6_log_mean = np.round(np.mean(log_numerical_test['cont6_log']), 2)\n\nlog_numerical_test['cont7_log'] = np.log((1+ numerical_test['cont7']))\ncont7_log_mean = np.round(np.mean(log_numerical_test['cont7_log']), 2)\n\nlog_numerical_test['cont8_log'] = np.log((1+ numerical_test['cont8']))\ncont8_log_mean = np.round(np.mean(log_numerical_test['cont8_log']), 2)\n\nlog_numerical_test['cont9_log'] = np.log((1+ numerical_test['cont9']))\ncont9_log_mean = np.round(np.mean(log_numerical_test['cont9_log']), 2)\n\nlog_numerical_test['cont10_log'] = np.log((1+ numerical_test['cont10']))\ncont10_log_mean = np.round(np.mean(log_numerical_test['cont10_log']), 2)\n\nlog_numerical_test['cont11_log'] = np.log((1+ numerical_test['cont11']))\ncont11_log_mean = np.round(np.mean(log_numerical_test['cont11_log']), 2)\n\nlog_numerical_test['cont12_log'] = np.log((1+ numerical_test['cont12']))\ncont12_log_mean = np.round(np.mean(log_numerical_test['cont12_log']), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_test.to_csv(\"log_numerical_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Transformations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_test = test[[\"id\", \"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"]]\ncategorical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ordinal Encoder:"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OrdinalEncoder()\nX = categorical_test\nenc.fit(X)\nordinal_categorical_test = enc.transform(X)\nordinal_categorical_test = pd.DataFrame(ordinal_categorical_test)\nordinal_categorical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_categorical_test.to_csv(\"ordinal_categorical_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One-Hot Encoding:"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(categorical_test)\nonehot_categorical_test = enc.transform(categorical_test)\nonehot_categorical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_categorical_test.to_csv(\"onehot_categorical_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Binary Encoding:"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = BinaryEncoder().fit(categorical_test)\nbinary_categorical_test = enc.transform(categorical_test)\nbinary_categorical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_categorical_test.to_csv(\"binary_categorical_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Frequency encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = CountFrequencyEncoder(encoding_method='frequency')\nencoder.fit(categorical_test)\nfreq_categorical_test = encoder.transform(categorical_test)\nfreq_categorical_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_categorical_test.to_csv(\"freq_categorical_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"# Combining csv's accordingly:"},{"metadata":{},"cell_type":"markdown","source":"### Training datasets:"},{"metadata":{},"cell_type":"markdown","source":"### **binary_categorical_columns** with:\n- numerical_columns\n- log_numerical_columns\n- numerical_columns_NO\n- log_numerical_columns_NO\n\n* ***target***\n* ***target_NO***\n\n### **ordinal_categorical_columns** with:\n- numerical_columns\n- log_numerical_columns\n- numerical_columns_NO\n- log_numerical_columns_NO\n\n* ***target***\n* ***target_NO***\n\n### **freq_categorical_columns** with:\n- numerical_columns\n- log_numerical_columns\n- numerical_columns_NO\n- log_numerical_columns_NO\n\n- ***target***\n* ***target_NO***"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = pd.read_csv(\"target.csv\")\ntarget.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_categorical_columns = pd.read_csv(\"binary_categorical_columns.csv\")\nnumerical_columns = pd.read_csv(\"numerical_columns.csv\")\nbinary_num = binary_categorical_columns.merge(numerical_columns, on='id')\nbinary_num = binary_num.merge(target, on='id')\nbinary_num.to_csv(\"binary_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nbinary_log = binary_categorical_columns.merge(log_numerical_columns, on='id')\nbinary_log = binary_log.merge(target, on='id')\nbinary_log.to_csv(\"binary_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nbinary_num_NO = binary_categorical_columns.merge(numerical_columns_NO, on='id')\nbinary_num_NO = binary_num_NO.merge(target, on='id')\nbinary_num_NO.to_csv(\"binary_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nbinary_log_NO = binary_categorical_columns.merge(log_numerical_columns_NO, on='id')\nbinary_log_NO = binary_log_NO.merge(target, on='id')\nbinary_log_NO.to_csv(\"binary_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_NO = pd.read_csv(\"target_NO.csv\")\ntarget_NO.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nbinary_num_TNO = binary_categorical_columns.merge(numerical_columns, on='id')\nbinary_num_TNO = binary_num_TNO.merge(target_NO, on='id')\nbinary_num_TNO.to_csv(\"binary_num_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nbinary_log_TNO = binary_categorical_columns.merge(log_numerical_columns, on='id')\nbinary_log_TNO = binary_log_TNO.merge(target_NO, on='id')\nbinary_log_TNO.to_csv(\"binary_log_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nbinary_num_NO_TNO = binary_categorical_columns.merge(numerical_columns_NO, on='id')\nbinary_num_NO_TNO = binary_num_NO_TNO.merge(target_NO, on='id')\nbinary_num_NO_TNO.to_csv(\"binary_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nbinary_log_NO_TNO = binary_categorical_columns.merge(log_numerical_columns_NO, on='id')\nbinary_log_NO_TNO = binary_log_NO_TNO.merge(target_NO, on='id')\nbinary_log_NO_TNO.to_csv(\"binary_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_categorical_columns = pd.read_csv(\"ordinal_categorical_columns.csv\")\nnumerical_columns = pd.read_csv(\"numerical_columns.csv\")\nordinal_num = ordinal_categorical_columns.merge(numerical_columns, on='id')\nordinal_num = ordinal_num.merge(target, on='id')\nordinal_num.to_csv(\"ordinal_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nordinal_log = ordinal_categorical_columns.merge(log_numerical_columns, on='id')\nordinal_log = ordinal_log.merge(target, on='id')\nordinal_log.to_csv(\"ordinal_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nordinal_num_NO = ordinal_categorical_columns.merge(numerical_columns_NO, on='id')\nordinal_num_NO = ordinal_num_NO.merge(target, on='id')\nordinal_num_NO.to_csv(\"ordinal_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nordinal_log_NO = ordinal_categorical_columns.merge(log_numerical_columns_NO, on='id')\nordinal_log_NO = ordinal_log_NO.merge(target, on='id')\nordinal_log_NO.to_csv(\"ordinal_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nordinal_num_TNO = ordinal_categorical_columns.merge(numerical_columns, on='id')\nordinal_num_TNO = ordinal_num_TNO.merge(target_NO, on='id')\nordinal_num_TNO.to_csv(\"ordinal_log_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nordinal_log_TNO = ordinal_categorical_columns.merge(log_numerical_columns, on='id')\nordinal_log_TNO = ordinal_log_TNO.merge(target_NO, on='id')\nordinal_log_TNO.to_csv(\"ordinal_log_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nordinal_num_NO_TNO = ordinal_categorical_columns.merge(numerical_columns_NO, on='id')\nordinal_num_NO_TNO = ordinal_num_NO_TNO.merge(target_NO, on='id')\nordinal_num_NO_TNO.to_csv(\"ordinal_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nordinal_log_NO_TNO = ordinal_categorical_columns.merge(log_numerical_columns_NO, on='id')\nordinal_log_NO_TNO = ordinal_log_NO_TNO.merge(target_NO, on='id')\nordinal_log_NO_TNO.to_csv(\"ordinal_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_categorical_columns = pd.read_csv(\"freq_categorical_columns.csv\")\nnumerical_columns = pd.read_csv(\"numerical_columns.csv\")\nfreq_num = freq_categorical_columns.merge(numerical_columns, on='id')\nfreq_num = freq_num.merge(target, on='id')\nfreq_num.to_csv(\"freq_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nfreq_log = freq_categorical_columns.merge(log_numerical_columns, on='id')\nfreq_log = freq_log.merge(target, on='id')\nfreq_log.to_csv(\"freq_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nfreq_num_NO = freq_categorical_columns.merge(numerical_columns_NO, on='id')\nfreq_num_NO = freq_num_NO.merge(target, on='id')\nfreq_num_NO.to_csv(\"freq_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nfreq_log_NO = freq_categorical_columns.merge(log_numerical_columns_NO, on='id')\nfreq_log_NO = freq_log_NO.merge(target, on='id')\nfreq_log_NO.to_csv(\"freq_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nfreq_num_TNO = freq_categorical_columns.merge(numerical_columns, on='id')\nfreq_num_TNO = freq_num_TNO.merge(target_NO, on='id')\nfreq_num_TNO.to_csv(\"freq_log_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nfreq_log_TNO = freq_categorical_columns.merge(log_numerical_columns, on='id')\nfreq_log_TNO = freq_log_TNO.merge(target_NO, on='id')\nfreq_log_TNO.to_csv(\"freq_log_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nfreq_num_NO_TNO = freq_categorical_columns.merge(numerical_columns_NO, on='id')\nfreq_num_NO_TNO = freq_num_NO_TNO.merge(target_NO, on='id')\nfreq_num_NO_TNO.to_csv(\"freq_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nfreq_log_NO_TNO = freq_categorical_columns.merge(log_numerical_columns_NO, on='id')\nfreq_log_NO_TNO = freq_log_NO_TNO.merge(target_NO, on='id')\nfreq_log_NO_TNO.to_csv(\"freq_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test datasets:\n\n### **binary_categorical_test** with:\n- numerical_test\n- log_numerical_test\n\n### **ordinal_categorical_test** with:\n- numerical_test\n- log_numerical_test\n\n### **freq_categorical_test** with:\n- numerical_test\n- log_numerical_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_categorical_test = pd.read_csv(\"binary_categorical_test.csv\")\nnumerical_test = pd.read_csv(\"numerical_test.csv\")\nbinary_num_test = binary_categorical_test.merge(numerical_test, on='id')\nbinary_num_test.to_csv(\"binary_num_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_test = pd.read_csv(\"log_numerical_test.csv\")\nbinary_log_test = binary_categorical_test.merge(log_numerical_test, on='id')\nbinary_log_test.to_csv(\"binary_log_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_categorical_test = pd.read_csv(\"ordinal_categorical_test.csv\")\nnumerical_test = pd.read_csv(\"numerical_test.csv\")\nordinal_num_test = ordinal_categorical_test.merge(numerical_test, on='id')\nordinal_num_test.to_csv(\"ordinal_num_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_test = pd.read_csv(\"log_numerical_test.csv\")\nordinal_log_test = ordinal_categorical_test.merge(log_numerical_test, on='id')\nordinal_log_test.to_csv(\"ordinal_log_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_categorical_test = pd.read_csv(\"freq_categorical_test.csv\")\nnumerical_test = pd.read_csv(\"numerical_test.csv\")\nfreq_num_test = freq_categorical_test.merge(numerical_test, on='id')\nfreq_num_test.to_csv(\"freq_num_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_numerical_test = pd.read_csv(\"log_numerical_test.csv\")\nfreq_log_test = freq_categorical_test.merge(log_numerical_test, on='id')\nfreq_log_test.to_csv(\"freq_log_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"## Univariate Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training datasets:"},{"metadata":{},"cell_type":"markdown","source":"1. binary_log:"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_log = pd.read_csv(\"binary_log.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log[[\"id\", \"target\"]]\nbinary_log = binary_log.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test[\"id\"])\nbinary_log_test = binary_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_log.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_log[feature_train], binary_log['target'])\nX_cat_train = pd.DataFrame(X_cat_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_test = binary_log_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_log_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\nX_cat_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_log.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_log[feature_train], binary_log['target'])\nX_num_train = pd.DataFrame(X_num_train)\nX_num_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_test = binary_log_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_log_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\nX_num_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_log.index, \n                                 columns=feature_train)\nselected_features_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_log_test.index, \n                                 columns=feature_test)\nselected_features_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n\n# Get the valid dataset with the selected features.\nUNI_train_binary_log = binary_log[selected_columns_train]\nUNI_train_binary_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n\n# Get the valid dataset with the selected features.\nUNI_test_binary_log = binary_log_test[selected_columns_test]\nUNI_test_binary_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_log = UNI_train_binary_log.merge(X_cat_train, left_index=True, right_index=True)\nUNI_train_binary_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_test_binary_log = UNI_test_binary_log.merge(X_cat_test, left_index=True, right_index=True)\nUNI_test_binary_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_log = pd.merge(UNI_train_binary_log, train_id, left_index=True, right_index=True)\nUNI_train_binary_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_test_binary_log = pd.merge(UNI_test_binary_log, test_id, left_index=True, right_index=True)\nUNI_test_binary_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_log.to_csv(\"UNI_train_binary_log.csv\")\nUNI_test_binary_log.to_csv(\"UNI_test_binary_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"2. binary_log_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_log_NO = pd.read_csv(\"binary_log_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_log_NO.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = binary_log_NO[[\"id\", \"target\"]]\nbinary_log_NO = binary_log_NO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO[\"id\"])\nbinary_log_test_NO = binary_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_log_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_log_NO[feature_train], binary_log_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_log_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_log_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_log_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_log_NO[feature_train], binary_log_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_log_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_log_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_log_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_log_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_log_NO = binary_log_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_log_NO = binary_log_test_NO[selected_columns_test]\n\n# merges\nUNI_train_binary_log_NO = UNI_train_binary_log_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_log_NO = UNI_test_binary_log_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_log_NO = pd.merge(UNI_train_binary_log_NO, train_id, left_index=True, right_index=True)\nUNI_test_binary_log_NO = pd.merge(UNI_test_binary_log_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_log_NO.to_csv(\"UNI_train_binary_log_NO.csv\")\nUNI_test_binary_log_NO.to_csv(\"UNI_test_binary_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. binary_log_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_log_NO_TNO = pd.read_csv(\"binary_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log_NO_TNO[[\"id\", \"target\"]]\nbinary_log_NO_TNO = binary_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO_TNO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO_TNO[\"id\"])\nbinary_log_test_NO_TNO = binary_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_log_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_log_NO_TNO[feature_train], binary_log_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_log_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_log_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_log_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_log_NO_TNO[feature_train], binary_log_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_log_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_log_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_log_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_log_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_log_NO_TNO = binary_log_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_log_NO_TNO = binary_log_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_binary_log_NO_TNO = UNI_train_binary_log_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_log_NO_TNO = UNI_test_binary_log_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_log_NO_TNO = pd.merge(UNI_train_binary_log_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_binary_log_NO_TNO = pd.merge(UNI_test_binary_log_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_log_NO_TNO.to_csv(\"UNI_train_binary_log_NO_TNO.csv\")\nUNI_test_binary_log_NO_TNO.to_csv(\"UNI_test_binary_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. binary_num:"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num = pd.read_csv(\"binary_num.csv\", index_col=\"Unnamed: 0\")\nbinary_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num[[\"id\", \"target\"]]\nbinary_num = binary_num.drop(\"id\", axis=1)\nbinary_num_test = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test[\"id\"])\nbinary_num_test = binary_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_num.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_num[feature_train], binary_num['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_num_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_num_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_num.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_num[feature_train], binary_num['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_num_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_num_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_num.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_num_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_num = binary_num[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_num = binary_num_test[selected_columns_test]\n\n# merges\nUNI_train_binary_num = UNI_train_binary_num.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_num = UNI_test_binary_num.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_num = pd.merge(UNI_train_binary_num, train_id, left_index=True, right_index=True)\nUNI_test_binary_num = pd.merge(UNI_test_binary_num, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_num.to_csv(\"UNI_train_binary_num.csv\")\nUNI_test_binary_num.to_csv(\"UNI_test_binary_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. binary_num_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num_NO = pd.read_csv(\"binary_num_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO[[\"id\", \"target\"]]\nbinary_num_NO = binary_num_NO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO[\"id\"])\nbinary_num_test_NO = binary_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_num_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_num_NO[feature_train], binary_num_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_num_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_num_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_num_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_num_NO[feature_train], binary_num_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_num_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_num_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_num_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_num_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_num_NO = binary_num_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_num_NO = binary_num_test_NO[selected_columns_test]\n\n# merges\nUNI_train_binary_num_NO = UNI_train_binary_num_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_num_NO = UNI_test_binary_num_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_num_NO = pd.merge(UNI_train_binary_num_NO, train_id, left_index=True, right_index=True)\nUNI_test_binary_num_NO = pd.merge(UNI_test_binary_num_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_num_NO.to_csv(\"UNI_train_binary_num_NO.csv\")\nUNI_test_binary_num_NO.to_csv(\"UNI_test_binary_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. binary_num_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num_NO_TNO = pd.read_csv(\"binary_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO_TNO[[\"id\", \"target\"]]\nbinary_num_NO_TNO = binary_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO_TNO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO_TNO[\"id\"])\nbinary_num_test_NO_TNO = binary_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = binary_num_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_num_NO_TNO[feature_train], binary_num_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_num_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_num_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_num_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_num_NO_TNO[feature_train], binary_num_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_num_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_num_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_num_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_num_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_num_NO_TNO = binary_num_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_num_NO_TNO = binary_num_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_binary_num_NO_TNO = UNI_train_binary_num_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_num_NO_TNO = UNI_test_binary_num_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_num_NO_TNO = pd.merge(UNI_train_binary_num_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_binary_num_NO_TNO = pd.merge(UNI_test_binary_num_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_binary_num_NO_TNO.to_csv(\"UNI_train_binary_num_NO_TNO.csv\")\nUNI_test_binary_num_NO_TNO.to_csv(\"UNI_test_binary_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7. ordinal_num"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_num = pd.read_csv(\"ordinal_num.csv\", index_col=\"Unnamed: 0\")\nordinal_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num[[\"id\", \"target\"]]\nordinal_num = ordinal_num.drop(\"id\", axis=1)\nordinal_num_test = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test[\"id\"])\nordinal_num_test = ordinal_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = ordinal_num.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_num[feature_train], ordinal_num['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_num_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_num_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_num.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_num[feature_train], ordinal_num['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_num_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_num_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_num.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_num_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_num = ordinal_num[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_num = ordinal_num_test[selected_columns_test]\n\n# merges\nUNI_train_ordinal_num = UNI_train_ordinal_num.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_num = UNI_test_ordinal_num.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_num = pd.merge(UNI_train_ordinal_num, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_num = pd.merge(UNI_test_ordinal_num, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_ordinal_num.to_csv(\"UNI_train_ordinal_num.csv\")\nUNI_test_ordinal_num.to_csv(\"UNI_test_ordinal_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. ordinal_num_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_num_NO = pd.read_csv(\"ordinal_num_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO[[\"id\", \"target\"]]\nordinal_num_NO = ordinal_num_NO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO[\"id\"])\nordinal_num_test_NO = ordinal_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = ordinal_num_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_num_NO[feature_train], ordinal_num_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_num_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_num_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_num_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_num_NO[feature_train], ordinal_num_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_num_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_num_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_num_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_num_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_num_NO = ordinal_num_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_num_NO = ordinal_num_test_NO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_num_NO = UNI_train_ordinal_num_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO = UNI_test_ordinal_num_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_num_NO = pd.merge(UNI_train_ordinal_num_NO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO = pd.merge(UNI_test_ordinal_num_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_ordinal_num_NO.to_csv(\"UNI_train_ordinal_num_NO.csv\")\nUNI_test_ordinal_num_NO.to_csv(\"UNI_test_ordinal_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"9. ordinal_num_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_num_NO_TNO = pd.read_csv(\"ordinal_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO_TNO[[\"id\", \"target\"]]\nordinal_num_NO_TNO = ordinal_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO_TNO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO_TNO[\"id\"])\nordinal_num_test_NO_TNO = ordinal_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = ordinal_num_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_num_NO_TNO[feature_train], ordinal_num_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_num_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_num_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_num_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_num_NO_TNO[feature_train], ordinal_num_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_num_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_num_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_num_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_num_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_num_NO_TNO = ordinal_num_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_num_NO_TNO = ordinal_num_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_num_NO_TNO = UNI_train_ordinal_num_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO_TNO = UNI_test_ordinal_num_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_num_NO_TNO = pd.merge(UNI_train_ordinal_num_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO_TNO = pd.merge(UNI_test_ordinal_num_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_ordinal_num_NO_TNO.to_csv(\"UNI_train_ordinal_num_NO_TNO.csv\")\nUNI_test_ordinal_num_NO_TNO.to_csv(\"UNI_test_ordinal_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"10. ordinal_log"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_log = pd.read_csv(\"ordinal_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_log.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = ordinal_log[[\"id\", \"target\"]]\nordinal_log = ordinal_log.drop([\"target_x\", \"id\"], axis=1)\n \nordinal_log_test = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test[\"id\"])\nordinal_log_test = ordinal_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = ordinal_log.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_log[feature_train], ordinal_log['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_log_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_log_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_log.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_log[feature_train], ordinal_log['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_log_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_log_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_log.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_log_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_log = ordinal_log[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_log = ordinal_log_test[selected_columns_test]\n\n# merges\nUNI_train_ordinal_log = UNI_train_ordinal_log.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_log = UNI_test_ordinal_log.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_log = pd.merge(UNI_train_ordinal_log, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_log = pd.merge(UNI_test_ordinal_log, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_ordinal_log.to_csv(\"UNI_train_ordinal_log.csv\")\nUNI_test_ordinal_log.to_csv(\"UNI_test_ordinal_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"11. ordinal_log_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_log_NO = pd.read_csv(\"ordinal_log_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO = ordinal_log_NO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO[[\"target\", \"id\"]]\nordinal_log_NO = ordinal_log_NO.drop(\"id\", axis=1)\nordinal_log_test_NO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO[\"id\"])\nordinal_log_test_NO = ordinal_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = ordinal_log_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_log_NO[feature_train], ordinal_log_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_log_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_log_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_log_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_log_NO[feature_train], ordinal_log_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_log_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_log_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_log_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_log_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_log_NO = ordinal_log_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_log_NO = ordinal_log_test_NO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_log_NO = UNI_train_ordinal_log_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO = UNI_test_ordinal_log_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_log_NO = pd.merge(UNI_train_ordinal_log_NO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO = pd.merge(UNI_test_ordinal_log_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_ordinal_log_NO.to_csv(\"UNI_train_ordinal_log_NO.csv\")\nUNI_test_ordinal_log_NO.to_csv(\"UNI_test_ordinal_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"12. ordinal_log_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_log_NO_TNO = pd.read_csv(\"ordinal_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO_TNO[[\"target\", \"id\"]]\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"id\", axis=1)\nordinal_log_test_NO_TNO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO_TNO[\"id\"])\nordinal_log_test_NO_TNO = ordinal_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = ordinal_log_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_log_NO_TNO[feature_train], ordinal_log_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_log_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_log_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_log_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_log_NO_TNO[feature_train], ordinal_log_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_log_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_log_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_log_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_log_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_log_NO_TNO = ordinal_log_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_log_NO_TNO = ordinal_log_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_log_NO_TNO = UNI_train_ordinal_log_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO_TNO = UNI_test_ordinal_log_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_log_NO_TNO = pd.merge(UNI_train_ordinal_log_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO_TNO = pd.merge(UNI_test_ordinal_log_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_ordinal_log_NO_TNO.to_csv(\"UNI_train_ordinal_log_NO_TNO.csv\")\nUNI_test_ordinal_log_NO_TNO.to_csv(\"UNI_test_ordinal_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13. freq_num"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_num = pd.read_csv(\"freq_num.csv\", index_col=\"Unnamed: 0\")\nfreq_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num[[\"target\", \"id\"]]\nfreq_num = freq_num.drop(\"id\", axis=1)\nfreq_num_test = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test[\"id\"])\nfreq_num_test = freq_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = freq_num.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_num[feature_train], freq_num['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_num_test.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_num_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_num.loc[:, \"cont0\":\"cont12\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_num[feature_train], freq_num['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_num_test.loc[:, \"cont0\":\"cont12\"].columns\nX_num_test = selector.transform(freq_num_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_num.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_num_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_freq_num = freq_num[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_num = freq_num_test[selected_columns_test]\n\n# merges\nUNI_train_freq_num = UNI_train_freq_num.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_num = UNI_test_freq_num.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_num = pd.merge(UNI_train_freq_num, train_id, left_index=True, right_index=True)\nUNI_test_freq_num = pd.merge(UNI_test_freq_num, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_freq_num.to_csv(\"UNI_train_freq_num.csv\")\nUNI_test_freq_num.to_csv(\"UNI_test_freq_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"14. freq_num_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_num_NO = pd.read_csv(\"freq_num_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO[[\"target\", \"id\"]]\nfreq_num_NO = freq_num_NO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO[\"id\"])\nfreq_num_test_NO = freq_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = freq_num_NO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_num_NO[feature_train], freq_num_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_num_test_NO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_num_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_num_NO.loc[:, \"cont0\":\"cont12\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_num_NO[feature_train], freq_num_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_num_test_NO.loc[:, \"cont0\":\"cont12\"].columns\nX_num_test = selector.transform(freq_num_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_num_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_num_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_freq_num_NO = freq_num_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_num_NO = freq_num_test_NO[selected_columns_test]\n\n# merges\nUNI_train_freq_num_NO = UNI_train_freq_num_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_num_NO = UNI_test_freq_num_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_num_NO = pd.merge(UNI_train_freq_num_NO, train_id, left_index=True, right_index=True)\nUNI_test_freq_num_NO = pd.merge(UNI_test_freq_num_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_freq_num_NO.to_csv(\"UNI_train_freq_num_NO.csv\")\nUNI_test_freq_num_NO.to_csv(\"UNI_test_freq_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"15. freq_num_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_num_NO_TNO = pd.read_csv(\"freq_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO_TNO[[\"target\", \"id\"]]\nfreq_num_NO_TNO = freq_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO_TNO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO_TNO[\"id\"])\nfreq_num_test_NO_TNO = freq_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = freq_num_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_num_NO_TNO[feature_train], freq_num_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_num_test_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_num_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_num_NO_TNO.loc[:, \"cont0\":\"cont12\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_num_NO_TNO[feature_train], freq_num_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_num_test_NO_TNO.loc[:, \"cont0\":\"cont12\"].columns\nX_num_test = selector.transform(freq_num_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_num_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_num_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_freq_num_NO_TNO = freq_num_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_num_NO_TNO = freq_num_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_freq_num_NO_TNO = UNI_train_freq_num_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_num_NO_TNO = UNI_test_freq_num_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_num_NO_TNO = pd.merge(UNI_train_freq_num_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_freq_num_NO_TNO = pd.merge(UNI_test_freq_num_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_freq_num_NO_TNO.to_csv(\"UNI_train_freq_num_NO_TNO.csv\")\nUNI_test_freq_num_NO_TNO.to_csv(\"UNI_test_freq_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"16. freq_log"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_log = pd.read_csv(\"freq_log.csv\", index_col=\"Unnamed: 0\")\nfreq_log.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log[[\"target\", \"id\"]]\nfreq_log = freq_log.drop([\"id\",\"Unnamed: 0.1\"], axis=1)\nfreq_log_test = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test[\"id\"])\nfreq_log_test = freq_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = freq_log.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_log[feature_train], freq_log['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_log_test.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_log_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_log.loc[:, \"cont0_log\":\"cont12_log\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_log[feature_train], freq_log['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_log_test.loc[:, \"cont0_log\":\"cont12_log\"].columns\nX_num_test = selector.transform(freq_log_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_log.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_log_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selectedfreq features.\nUNI_train_freq_log = freq_log[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_log = freq_log_test[selected_columns_test]\n\n# merges\nUNI_train_freq_log = UNI_train_freq_log.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_log = UNI_test_freq_log.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_log = pd.merge(UNI_train_freq_log, train_id, left_index=True, right_index=True)\nUNI_test_freq_log = pd.merge(UNI_test_freq_log, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_freq_log.to_csv(\"UNI_train_freq_log.csv\")\nUNI_test_freq_log.to_csv(\"UNI_test_freq_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"17. freq_log_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_log_NO = pd.read_csv(\"freq_log_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO[[\"target\", \"id\"]]\nfreq_log_NO = freq_log_NO.drop([\"id\", \"Unnamed: 0.1\"], axis=1)\nfreq_log_test_NO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO[\"id\"])\nfreq_log_test_NO = freq_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = freq_log_NO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_log_NO[feature_train], freq_log_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_log_test_NO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_log_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_log_NO.loc[:, \"cont0_log\":\"cont12_log\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_log_NO[feature_train], freq_log_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_log_test_NO.loc[:, \"cont0_log\":\"cont12_log\"].columns\nX_num_test = selector.transform(freq_log_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_log_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_log_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selectedfreq features.\nUNI_train_freq_log_NO = freq_log_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_log_NO = freq_log_test_NO[selected_columns_test]\n\n# merges\nUNI_train_freq_log_NO = UNI_train_freq_log_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_log_NO = UNI_test_freq_log_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_log_NO = pd.merge(UNI_train_freq_log_NO, train_id, left_index=True, right_index=True)\nUNI_test_freq_log_NO = pd.merge(UNI_test_freq_log_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_freq_log_NO.to_csv(\"UNI_train_freq_log_NO.csv\")\nUNI_test_freq_log_NO.to_csv(\"UNI_test_freq_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"18. freq_log_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_log_NO_TNO = pd.read_csv(\"freq_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO_TNO[[\"target\", \"id\"]]\nfreq_log_NO_TNO = freq_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nfreq_log_test_NO_TNO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO_TNO[\"id\"])\nfreq_log_test_NO_TNO = freq_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_train = freq_log_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_log_NO_TNO[feature_train], freq_log_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_log_test_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_log_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_log_NO_TNO.loc[:, \"cont0_log\":\"cont12_log\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_log_NO_TNO[feature_train], freq_log_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_log_test_NO_TNO.loc[:, \"cont0_log\":\"cont12_log\"].columns\nX_num_test = selector.transform(freq_log_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_log_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_log_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selectedfreq features.\nUNI_train_freq_log_NO_TNO = freq_log_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_log_NO_TNO = freq_log_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_freq_log_NO_TNO = UNI_train_freq_log_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_log_NO_TNO = UNI_test_freq_log_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_log_NO_TNO = pd.merge(UNI_train_freq_log_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_freq_log_NO_TNO = pd.merge(UNI_test_freq_log_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNI_train_freq_log_NO_TNO.to_csv(\"UNI_train_freq_log_NO_TNO.csv\")\nUNI_test_freq_log_NO_TNO.to_csv(\"UNI_test_freq_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Principle Component Analysis (PCA) Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. binary_num"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"display.max_columns\", None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num = pd.read_csv(\"binary_num.csv\", index_col=\"Unnamed: 0\")\nbinary_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num_test = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\nbinary_num_test = binary_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\"], axis=1)\nbinary_num_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = binary_num.loc[:, \"cat0_0\":\"cont12\"]\nX_test = binary_num_test.loc[:, \"cat0_0\":\"cont12\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=10)\npca.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_num = pca.transform(X_train)\nPCA_train_binary_num = pd.DataFrame(PCA_train_binary_num)\nPCA_train_binary_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_test_binary_num = pca.transform(X_test)\nPCA_test_binary_num = pd.DataFrame(PCA_test_binary_num)\nPCA_test_binary_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = binary_num[[\"id\", \"target\"]]\ni_d = pd.DataFrame(binary_num_test[\"id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_num = pd.merge(PCA_train_binary_num, target, left_index=True, right_index=True)\nPCA_train_binary_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_test_binary_num = pd.merge(PCA_test_binary_num, i_d, left_index=True, right_index=True)\nPCA_test_binary_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_num.to_csv(\"PCA_train_binary_num.csv\")\nPCA_test_binary_num.to_csv(\"PCA_test_binary_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. binary_num_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num_NO = pd.read_csv(\"binary_num_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO[[\"id\", \"target\"]]\nbinary_num_NO = binary_num_NO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO[\"id\"])\nbinary_num_test_NO = binary_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = binary_num_NO.loc[:, \"cat0_0\":\"cont12\"]\nX_test = binary_num_test_NO.loc[:, \"cat0_0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_num_NO = pca.transform(X_train)\nPCA_train_binary_num_NO = pd.DataFrame(PCA_train_binary_num_NO)\n\nPCA_test_binary_num_NO = pca.transform(X_test)\nPCA_test_binary_num_NO = pd.DataFrame(PCA_test_binary_num_NO)\n\n# merge dataframes\nPCA_train_binary_num_NO = pd.merge(PCA_train_binary_num_NO, train_id, left_index=True, right_index=True)\nPCA_test_binary_num_NO = pd.merge(PCA_test_binary_num_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_num_NO.to_csv(\"PCA_train_binary_num_NO.csv\")\nPCA_test_binary_num_NO.to_csv(\"PCA_test_binary_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. binary_num_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_num_NO_TNO = pd.read_csv(\"binary_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO_TNO[[\"id\", \"target\"]]\nbinary_num_NO_TNO = binary_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO_TNO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO_TNO[\"id\"])\nbinary_num_test_NO_TNO = binary_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = binary_num_NO_TNO.loc[:, \"cat0_0\":\"cont12\"]\nX_test = binary_num_test_NO_TNO.loc[:, \"cat0_0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_num_NO_TNO = pca.transform(X_train)\nPCA_train_binary_num_NO_TNO = pd.DataFrame(PCA_train_binary_num_NO_TNO)\n\nPCA_test_binary_num_NO_TNO = pca.transform(X_test)\nPCA_test_binary_num_NO_TNO = pd.DataFrame(PCA_test_binary_num_NO_TNO)\n\n# merge dataframes\nPCA_train_binary_num_NO_TNO = pd.merge(PCA_train_binary_num_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_binary_num_NO_TNO = pd.merge(PCA_test_binary_num_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_num_NO_TNO.to_csv(\"PCA_train_binary_num_NO_TNO.csv\")\nPCA_test_binary_num_NO_TNO.to_csv(\"PCA_test_binary_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. binary_log"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_log = pd.read_csv(\"binary_log.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log[[\"id\", \"target\"]]\nbinary_log = binary_log.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test[\"id\"])\nbinary_log_test = binary_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = binary_log.loc[:, \"cat0_0\":\"cont12_log\"]\nX_test = binary_log_test.loc[:, \"cat0_0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_log = pca.transform(X_train)\nPCA_train_binary_log = pd.DataFrame(PCA_train_binary_log)\n\nPCA_test_binary_log = pca.transform(X_test)\nPCA_test_binary_log = pd.DataFrame(PCA_test_binary_log)\n\n# merge dataframes\nPCA_train_binary_log = pd.merge(PCA_train_binary_log, train_id, left_index=True, right_index=True)\nPCA_test_binary_log = pd.merge(PCA_test_binary_log, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_log.to_csv(\"PCA_train_binary_log.csv\")\nPCA_test_binary_log.to_csv(\"PCA_test_binary_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. binary_log_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_log_NO = pd.read_csv(\"binary_log_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_log_NO.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = binary_log_NO[[\"id\", \"target\"]]\nbinary_log_NO = binary_log_NO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO[\"id\"])\nbinary_log_test_NO = binary_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = binary_log_NO.loc[:, \"cat0_0\":\"cont12_log\"]\nX_test = binary_log_test_NO.loc[:, \"cat0_0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_log_NO = pca.transform(X_train)\nPCA_train_binary_log_NO = pd.DataFrame(PCA_train_binary_log_NO)\n\nPCA_test_binary_log_NO = pca.transform(X_test)\nPCA_test_binary_log_NO = pd.DataFrame(PCA_test_binary_log_NO)\n\n# merge dataframes\nPCA_train_binary_log_NO = pd.merge(PCA_train_binary_log_NO, train_id, left_index=True, right_index=True)\nPCA_test_binary_log_NO = pd.merge(PCA_test_binary_log_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_log_NO.to_csv(\"PCA_train_binary_log_NO.csv\")\nPCA_test_binary_log_NO.to_csv(\"PCA_test_binary_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. binary_log_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_log_NO_TNO = pd.read_csv(\"binary_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log_NO_TNO[[\"id\", \"target\"]]\nbinary_log_NO_TNO = binary_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO_TNO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO_TNO[\"id\"])\nbinary_log_test_NO_TNO = binary_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = binary_log_NO_TNO.loc[:, \"cat0_0\":\"cont12_log\"]\nX_test = binary_log_test_NO_TNO.loc[:, \"cat0_0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_log_NO_TNO = pca.transform(X_train)\nPCA_train_binary_log_NO_TNO = pd.DataFrame(PCA_train_binary_log_NO_TNO)\n\nPCA_test_binary_log_NO_TNO = pca.transform(X_test)\nPCA_test_binary_log_NO_TNO = pd.DataFrame(PCA_test_binary_log_NO_TNO)\n\n# merge dataframes\nPCA_train_binary_log_NO_TNO = pd.merge(PCA_train_binary_log_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_binary_log_NO_TNO = pd.merge(PCA_test_binary_log_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_binary_log_NO_TNO.to_csv(\"PCA_train_binary_log_NO_TNO.csv\")\nPCA_test_binary_log_NO_TNO.to_csv(\"PCA_test_binary_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7. ordinal_num"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_num = pd.read_csv(\"ordinal_num.csv\", index_col=\"Unnamed: 0\")\nordinal_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num[[\"id\", \"target\"]]\nordinal_num = ordinal_num.drop(\"id\", axis=1)\nordinal_num_test = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test[\"id\"])\nordinal_num_test = ordinal_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ordinal_num.loc[:, \"cat0\":\"cont12\"]\nX_test = ordinal_num_test.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_num = pca.transform(X_train)\nPCA_train_ordinal_num = pd.DataFrame(PCA_train_ordinal_num)\n\nPCA_test_ordinal_num = pca.transform(X_test)\nPCA_test_ordinal_num = pd.DataFrame(PCA_test_ordinal_num)\n\n# merge dataframes\nPCA_train_ordinal_num = pd.merge(PCA_train_ordinal_num, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_num = pd.merge(PCA_test_ordinal_num, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_ordinal_num.to_csv(\"PCA_train_ordinal_num.csv\")\nPCA_test_ordinal_num.to_csv(\"PCA_test_ordinal_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. ordinal_num_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_num_NO = pd.read_csv(\"ordinal_num_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO[[\"id\", \"target\"]]\nordinal_num_NO = ordinal_num_NO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO[\"id\"])\nordinal_num_test_NO = ordinal_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ordinal_num_NO.loc[:, \"cat0\":\"cont12\"]\nX_test = ordinal_num_test_NO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_num_NO = pca.transform(X_train)\nPCA_train_ordinal_num_NO = pd.DataFrame(PCA_train_ordinal_num_NO)\n\nPCA_test_ordinal_num_NO = pca.transform(X_test)\nPCA_test_ordinal_num_NO = pd.DataFrame(PCA_test_ordinal_num_NO)\n\n# merge dataframes\nPCA_train_ordinal_num_NO = pd.merge(PCA_train_ordinal_num_NO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_num_NO = pd.merge(PCA_test_ordinal_num_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_ordinal_num_NO.to_csv(\"PCA_train_ordinal_num_NO.csv\")\nPCA_test_ordinal_num_NO.to_csv(\"PCA_test_ordinal_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"9. ordinal_num_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_num_NO_TNO = pd.read_csv(\"ordinal_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO_TNO[[\"id\", \"target\"]]\nordinal_num_NO_TNO = ordinal_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO_TNO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO_TNO[\"id\"])\nordinal_num_test_NO_TNO = ordinal_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ordinal_num_NO_TNO.loc[:, \"cat0\":\"cont12\"]\nX_test = ordinal_num_test_NO_TNO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_num_NO_TNO = pca.transform(X_train)\nPCA_train_ordinal_num_NO_TNO = pd.DataFrame(PCA_train_ordinal_num_NO_TNO)\n\nPCA_test_ordinal_num_NO_TNO = pca.transform(X_test)\nPCA_test_ordinal_num_NO_TNO = pd.DataFrame(PCA_test_ordinal_num_NO_TNO)\n\n# merge dataframes\nPCA_train_ordinal_num_NO_TNO = pd.merge(PCA_train_ordinal_num_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_num_NO_TNO = pd.merge(PCA_test_ordinal_num_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_ordinal_num_NO_TNO.to_csv(\"PCA_train_ordinal_num_NO_TNO.csv\")\nPCA_test_ordinal_num_NO_TNO.to_csv(\"PCA_test_ordinal_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"10. ordinal_log"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_log = pd.read_csv(\"ordinal_log.csv\", index_col=\"Unnamed: 0\")\nordinal_log.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = ordinal_log[[\"id\", \"target\"]]\nordinal_log = ordinal_log.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\n \nordinal_log_test = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test[\"id\"])\nordinal_log_test = ordinal_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ordinal_log.loc[:, \"cat0\":\"cont12_log\"]\nX_test = ordinal_log_test.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_log = pca.transform(X_train)\nPCA_train_ordinal_log = pd.DataFrame(PCA_train_ordinal_log)\n\nPCA_test_ordinal_log = pca.transform(X_test)\nPCA_test_ordinal_log = pd.DataFrame(PCA_test_ordinal_log)\n\n# merge dataframes\nPCA_train_ordinal_log = pd.merge(PCA_train_ordinal_log, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_log = pd.merge(PCA_test_ordinal_log, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_ordinal_log.to_csv(\"PCA_train_ordinal_log.csv\")\nPCA_test_ordinal_log.to_csv(\"PCA_test_ordinal_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"11. ordinal_log_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_log_NO = pd.read_csv(\"ordinal_log_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO = ordinal_log_NO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO[[\"target\", \"id\"]]\nordinal_log_NO = ordinal_log_NO.drop(\"id\", axis=1)\nordinal_log_test_NO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO[\"id\"])\nordinal_log_test_NO = ordinal_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ordinal_log_NO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = ordinal_log_test_NO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_log_NO = pca.transform(X_train)\nPCA_train_ordinal_log_NO = pd.DataFrame(PCA_train_ordinal_log_NO)\n\nPCA_test_ordinal_log_NO = pca.transform(X_test)\nPCA_test_ordinal_log_NO = pd.DataFrame(PCA_test_ordinal_log_NO)\n\n# merge dataframes\nPCA_train_ordinal_log_NO = pd.merge(PCA_train_ordinal_log_NO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_log_NO = pd.merge(PCA_test_ordinal_log_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_ordinal_log_NO.to_csv(\"PCA_train_ordinal_log_NO.csv\")\nPCA_test_ordinal_log_NO.to_csv(\"PCA_test_ordinal_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"12. ordinal_log_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_log_NO_TNO = pd.read_csv(\"ordinal_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO_TNO[[\"target\", \"id\"]]\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"id\", axis=1)\nordinal_log_test_NO_TNO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO_TNO[\"id\"])\nordinal_log_test_NO_TNO = ordinal_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ordinal_log_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = ordinal_log_test_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_log_NO_TNO = pca.transform(X_train)\nPCA_train_ordinal_log_NO_TNO = pd.DataFrame(PCA_train_ordinal_log_NO_TNO)\n\nPCA_test_ordinal_log_NO_TNO = pca.transform(X_test)\nPCA_test_ordinal_log_NO_TNO = pd.DataFrame(PCA_test_ordinal_log_NO_TNO)\n\n# merge dataframes\nPCA_train_ordinal_log_NO_TNO = pd.merge(PCA_train_ordinal_log_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_log_NO_TNO = pd.merge(PCA_test_ordinal_log_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_ordinal_log_NO_TNO.to_csv(\"PCA_train_ordinal_log_NO_TNO.csv\")\nPCA_test_ordinal_log_NO_TNO.to_csv(\"PCA_test_ordinal_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13. freq_num"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_num = pd.read_csv(\"freq_num.csv\", index_col=\"Unnamed: 0\")\nfreq_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num[[\"target\", \"id\"]]\nfreq_num = freq_num.drop(\"id\", axis=1)\nfreq_num_test = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test[\"id\"])\nfreq_num_test = freq_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = freq_num.loc[:, \"cat0\":\"cont12\"]\nX_test = freq_num_test.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_num = pca.transform(X_train)\nPCA_train_freq_num = pd.DataFrame(PCA_train_freq_num)\n\nPCA_test_freq_num = pca.transform(X_test)\nPCA_test_freq_num = pd.DataFrame(PCA_test_freq_num)\n\n# merge dataframes\nPCA_train_freq_num = pd.merge(PCA_train_freq_num, train_id, left_index=True, right_index=True)\nPCA_test_freq_num = pd.merge(PCA_test_freq_num, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_freq_num.to_csv(\"PCA_train_freq_num.csv\")\nPCA_test_freq_num.to_csv(\"PCA_test_freq_num.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"14. freq_num_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_num_NO = pd.read_csv(\"freq_num_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO[[\"target\", \"id\"]]\nfreq_num_NO = freq_num_NO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO[\"id\"])\nfreq_num_test_NO = freq_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = freq_num_NO.loc[:, \"cat0\":\"cont12\"]\nX_test = freq_num_NO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_num_NO = pca.transform(X_train)\nPCA_train_freq_num_NO = pd.DataFrame(PCA_train_freq_num_NO)\n\nPCA_test_freq_num_NO = pca.transform(X_test)\nPCA_test_freq_num_NO = pd.DataFrame(PCA_test_freq_num_NO)\n\n# merge dataframes\nPCA_train_freq_num_NO = pd.merge(PCA_train_freq_num_NO, train_id, left_index=True, right_index=True)\nPCA_test_freq_num_NO = pd.merge(PCA_test_freq_num_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_freq_num_NO.to_csv(\"PCA_train_freq_num_NO.csv\")\nPCA_test_freq_num_NO.to_csv(\"PCA_test_freq_num_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"15. freq_num_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_num_NO_TNO = pd.read_csv(\"freq_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO_TNO[[\"target\", \"id\"]]\nfreq_num_NO_TNO = freq_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO_TNO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO_TNO[\"id\"])\nfreq_num_test_NO_TNO = freq_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = freq_num_NO_TNO.loc[:, \"cat0\":\"cont12\"]\nX_test = freq_num_NO_TNO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_num_NO_TNO = pca.transform(X_train)\nPCA_train_freq_num_NO_TNO = pd.DataFrame(PCA_train_freq_num_NO_TNO)\n\nPCA_test_freq_num_NO_TNO = pca.transform(X_test)\nPCA_test_freq_num_NO_TNO = pd.DataFrame(PCA_test_freq_num_NO_TNO)\n\n# merge dataframes\nPCA_train_freq_num_NO_TNO = pd.merge(PCA_train_freq_num_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_freq_num_NO_TNO = pd.merge(PCA_test_freq_num_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_freq_num_NO_TNO.to_csv(\"PCA_train_freq_num_NO_TNO.csv\")\nPCA_test_freq_num_NO_TNO.to_csv(\"PCA_test_freq_num_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"16. freq_log"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_log = pd.read_csv(\"freq_log.csv\", index_col=\"Unnamed: 0\")\nfreq_log.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log[[\"target\", \"id\"]]\nfreq_log = freq_log.drop([\"id\",\"Unnamed: 0.1\"], axis=1)\nfreq_log_test = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test[\"id\"])\nfreq_log_test = freq_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = freq_log.loc[:, \"cat0\":\"cont12_log\"]\nX_test = freq_log_test.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_log = pca.transform(X_train)\nPCA_train_freq_log = pd.DataFrame(PCA_train_freq_log)\n\nPCA_test_freq_log = pca.transform(X_test)\nPCA_test_freq_log = pd.DataFrame(PCA_test_freq_log)\n\n# merge dataframes\nPCA_train_freq_log = pd.merge(PCA_train_freq_log, train_id, left_index=True, right_index=True)\nPCA_test_freq_log = pd.merge(PCA_test_freq_log, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_freq_log.to_csv(\"PCA_train_freq_log.csv\")\nPCA_test_freq_log.to_csv(\"PCA_test_freq_log.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"17. freq_log_NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_log_NO = pd.read_csv(\"freq_log_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO[[\"target\", \"id\"]]\nfreq_log_NO = freq_log_NO.drop([\"id\", \"Unnamed: 0.1\"], axis=1)\nfreq_log_test_NO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO[\"id\"])\nfreq_log_test_NO = freq_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = freq_log_NO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = freq_log_test_NO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_log_NO = pca.transform(X_train)\nPCA_train_freq_log_NO = pd.DataFrame(PCA_train_freq_log_NO)\n\nPCA_test_freq_log_NO = pca.transform(X_test)\nPCA_test_freq_log_NO = pd.DataFrame(PCA_test_freq_log_NO)\n\n# merge dataframes\nPCA_train_freq_log_NO = pd.merge(PCA_train_freq_log_NO, train_id, left_index=True, right_index=True)\nPCA_test_freq_log_NO = pd.merge(PCA_test_freq_log_NO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_freq_log_NO.to_csv(\"PCA_train_freq_log_NO.csv\")\nPCA_test_freq_log_NO.to_csv(\"PCA_test_freq_log_NO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"18. freq_log_NO_TNO"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_log_NO_TNO = pd.read_csv(\"freq_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO_TNO[[\"target\", \"id\"]]\nfreq_log_NO_TNO = freq_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nfreq_log_test_NO_TNO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO_TNO[\"id\"])\nfreq_log_test_NO_TNO = freq_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = freq_log_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = freq_log_test_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_log_NO_TNO = pca.transform(X_train)\nPCA_train_freq_log_NO_TNO = pd.DataFrame(PCA_train_freq_log_NO_TNO)\n\nPCA_test_freq_log_NO_TNO = pca.transform(X_test)\nPCA_test_freq_log_NO_TNO = pd.DataFrame(PCA_test_freq_log_NO_TNO)\n\n# merge dataframes\nPCA_train_freq_log_NO_TNO = pd.merge(PCA_train_freq_log_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_freq_log_NO_TNO = pd.merge(PCA_test_freq_log_NO_TNO, test_id, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_train_freq_log_NO_TNO.to_csv(\"PCA_train_freq_log_NO_TNO.csv\")\nPCA_test_freq_log_NO_TNO.to_csv(\"PCA_test_freq_log_NO_TNO.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import SGDRegressor                    \nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.linear_model import Lars\nfrom sklearn.linear_model import LarsCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import LassoLars\nfrom sklearn.linear_model import LassoLarsCV\nfrom sklearn.linear_model import LassoLarsIC\nfrom sklearn.linear_model import OrthogonalMatchingPursuit\nfrom sklearn.linear_model import OrthogonalMatchingPursuitCV                        \nfrom sklearn.linear_model import ARDRegression\nfrom sklearn.linear_model import BayesianRidge                       \nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import TheilSenRegressor\nfrom sklearn.linear_model import TweedieRegressor\nfrom sklearn.linear_model import GammaRegressor\nfrom sklearn.linear_model import PassiveAggressiveRegressor\nfrom sklearn.linear_model import enet_path\nfrom sklearn.linear_model import lars_path\nfrom sklearn.linear_model import lars_path_gram\nfrom sklearn.linear_model import lasso_path\nfrom sklearn.linear_model import orthogonal_mp\nfrom sklearn.linear_model import orthogonal_mp_gram\nfrom sklearn.linear_model import ridge_regression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import RadiusNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import ExtraTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.svm import LinearSVR\nfrom sklearn.svm import NuSVR\nfrom sklearn.svm import SVR\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import pipeline \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import model_selection # train_test_split\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressors = {\n    \"xgboost\": xgb.XGBRegressor(objective ='reg:linear', \n                  n_estimators = 10, seed = 123),\n    \"LinearRegression\": LinearRegression(),\n    \"Ridge\": Ridge(),\n    \"RidgeCV\": RidgeCV(),\n    \"SGDRegressor\": SGDRegressor(),              \n    \"ElasticNet\": ElasticNet(),\n    \"ElasticNetCV\": ElasticNetCV(),\n    \"Lars\": Lars(),\n    \"LarsCV\": LarsCV(),\n    \"Lasso\": Lasso(),\n    \"LassoCV\": LassoCV(),\n    \"LassoLars\": LassoLars(),\n    \"LassoLarsCV\": LassoLarsCV(),\n    \"LassoLarsIC\": LassoLarsIC(),\n    \"OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit(),\n    \"OrthogonalMatchingPursuitCV\": OrthogonalMatchingPursuitCV(),                        \n    \"ARDRegression\": ARDRegression(),\n    \"BayesianRidge\": BayesianRidge(),                       \n    \"HuberRegressor\": HuberRegressor(),\n    \"RANSACRegressor\": RANSACRegressor(),\n    \"TheilSenRegressor\": TheilSenRegressor(),\n    \"TweedieRegressor\": TweedieRegressor(),\n    \"GammaRegressor\": GammaRegressor(),\n    \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(),\n    \"KNeighborsRegressor\": KNeighborsRegressor(),\n    \"RadiusNeighborsRegressor\": RadiusNeighborsRegressor(),\n    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n    \"ExtraTreeRegressor\": ExtraTreeRegressor(),\n    \"AdaBoostRegressor\": AdaBoostRegressor(),\n    \"BaggingRegressor\": BaggingRegressor(),\n    \"ExtraTreesRegressor\": ExtraTreesRegressor(),\n    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n    \"RandomForestRegressor\": RandomForestRegressor(),\n    \"IsotonicRegression\": IsotonicRegression(),\n    \"KernelRidge\": KernelRidge(),\n    \"LinearSVR\": LinearSVR(),\n    \"NuSVR\": NuSVR(),\n    \"SVR\": SVR(),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressors = {name: pipeline.make_pipeline(model) for name, model in regressors.items()}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. UNI_binary_num"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = UNI_train_binary_num.drop(columns=[\"id\"]) # X DATA (WILL BE TRAIN+VALID DATA)\ny = UNI_train_binary_num[\"target\"]\n\nx_test = UNI_test_binary_num.drop(columns=['id']) # # X_TEST DATA (NEW DATA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = model_selection.train_test_split(\n    x, y,\n    test_size=0.2,\n    random_state=4  # Recommended for reproducibility\n)\n\nresults = pd.DataFrame({'Model': [], 'RMSE': []})\n\nfor model_name, model in regressors.items():\n\n    model.fit(x_train, y_train)\n    \n    pred = model.predict(x_val)\n    \n    results = results.append({\"Model\":    model_name,\n                              \"RMSE\": mean_squared_error(y_val, pred, squared=False)},\n                              ignore_index=True)\n    \n    results_ord = results.sort_values(by=['RMSE'], ascending=False, ignore_index=True)\n    results_ord.index += 1 \n    \n    clear_output(wait=True)\n    display(results_ord.style.bar(subset=['RMSE'], vmin=0, vmax=100, color='#5fba7d'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Put each of the full csv combinations through a pipeline like so. Not enough memory on this kaggle notebook to do this - continued on another notebook.\n\n# **Best result with train validation: 0.854**\n# **Best result with Kaggle test validation: 0.84186**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}