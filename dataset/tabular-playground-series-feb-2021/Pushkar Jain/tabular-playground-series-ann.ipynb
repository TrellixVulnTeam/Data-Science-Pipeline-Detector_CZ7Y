{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ndf = pd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Information"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = df.columns  #getting list of column names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing column wise %ge of NaN values they contains \n\nfor i in col:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since data does'nt contain any null values, we can move further"},{"metadata":{},"cell_type":"markdown","source":"> Since the given dataset contains both categorical and numerical dataset we have to separate them for further analysis. "},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df = df.select_dtypes(exclude=['object'])\ncat_df= df.drop(num_df, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now start analysis with numerical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df = num_df.drop([\"id\"], axis = 1)   #Since Id does not has any role in price prediction of houses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cormap = num_df.corr()\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(cormap, annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now let's analyse the categorical part of dataset.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's first encode the categorical data into numerical for futher analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ncat_col = cat_df.columns\nfor i in cat_col:\n  enc = LabelEncoder()\n  cat_df[i] = enc.fit_transform(cat_df[i].astype('str'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df['target'] = df['target']  # to get coreltion with target attribute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cormat = cat_df.corr()\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cormat, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.concat([ cat_df.drop(['target'], axis=1), num_df], axis = 1, sort=False)\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_df.drop(['target'], axis=1)\ny = final_df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since range of data in different columns veries significantly we need to scale the independent variable i.e. X. For this we will use _Min-Max Scaling_.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ANN"},{"metadata":{},"cell_type":"markdown","source":"> Here to determine no of hidden layers and no of neurons in each layer, I'm using [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner). Keras Tuner can be proved very helpful for hyperparameter tunning of neural networks."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(hp):\n    model = keras.Sequential()\n    \n    model.add(layers.Dense(24, activation='relu'))\n    \n    for i in range(hp.Int('num_layers', 2, 20)):\n        model.add(layers.Dense(units = hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n                               activation = 'relu'))\n        model.add(layers.Dropout(0.5))\n        \n    model.add(layers.Dense(1, activation='linear'))\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n        loss='mean_absolute_error',\n        metrics=['mean_absolute_error'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Using Random Search for itereating over parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuner = RandomSearch(\n    build_model,\n    objective='mean_absolute_error',\n    max_trials=10,\n    executions_per_trial=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuner.search(X_train, y_train, epochs=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing model with least Mean Absolute Error\n\nreg = tuner.get_best_models(num_models=1)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(X_train, y_train, epochs=20, validation_split=0.1, initial_epoch=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\n\ny_pred = reg.predict(X_test)\npred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluating the Model\n\nfrom sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As we can see that the value of root mean squared error is 0.879, which is slightly lesser than 15% of the mean value."},{"metadata":{},"cell_type":"markdown","source":"*****"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we ready the Test Data\ntest_data = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\ntest_df = pd.DataFrame(test_data)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_test_df = test_df.select_dtypes(exclude=['object'])\ncat_test_df= test_df.drop(num_test_df, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id = num_test_df['id']\nnum_test_df = num_test_df.drop([\"id\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's Encode the test categorical dataset also\n\nfor i in cat_test_df.columns:\n    enc = LabelEncoder()\n    cat_test_df[i] = enc.fit_transform(cat_test_df[i].astype('str'))\n\ncat_test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test_df = pd.concat([ cat_test_df, num_test_df], axis = 1, sort=False)\nfinal_test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(scaler.transform(final_test_df), columns=final_test_df.columns)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = reg.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.DataFrame({'id': Id, 'target': Y_pred.flatten()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}