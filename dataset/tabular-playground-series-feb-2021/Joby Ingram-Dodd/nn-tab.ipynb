{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Tabular Playground with PyTorch \nI this notebook I have attempted to use PyTorch to get the best result, so far I have not managed to beat score obtained with Tree regressors, but it is a work in progress. \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%config Completer.use_jedi = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\nnumerical_features = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5','cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df   = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/test.csv')\ny = df.target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing \nIn the function below I have done some simple preprocessing, scaling the numerical data and one hot encoding the catergorical data.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"oh = ce.OneHotEncoder()\nss = QuantileTransformer()\ndef pre_pipe(fr, train=True):\n    if train:\n        c = fr[cat_features]\n        c = oh.fit_transform(c)\n        n = fr[numerical_features]\n        n = pd.DataFrame(ss.fit_transform(n), columns=numerical_features)\n        f = c.merge(n, left_index=True, right_index=True)\n        return f\n    else: \n        c = fr[cat_features]\n        c = oh.transform(c)\n        n = fr[numerical_features]\n        n = pd.DataFrame(ss.transform(n), columns=numerical_features)\n        f = c.merge(n, left_index=True, right_index=True)\n        return f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pre_pipe(df).columns), len(pre_pipe(test, False).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = 70\nhid = 440\nhid2 = 530\nhid3 = 378\nhid4 = 137\nhid5 = 52","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self, input_dim, num_hidden):\n        super().__init__()\n        self.linear1    = nn.Linear(input_dim, num_hidden)\n        self.linear2    = nn.Linear(num_hidden, hid2)\n        self.linear3    = nn.Linear(hid2,hid3)\n        self.linear4    = nn.Linear(hid3,hid4)\n        self.linear5    = nn.Linear(hid4,hid5)\n        self.batchNorm1 = nn.BatchNorm1d(num_hidden)\n        self.batchNorm2 = nn.BatchNorm1d(hid2)\n        self.batchNorm3 = nn.BatchNorm1d(hid3)\n        self.batchNorm4 = nn.BatchNorm1d(hid4)\n        self.batchNorm5 = nn.BatchNorm1d(hid5)\n        self.dropout    = nn.Dropout(p=0.48)\n        self.relu       = nn.ReLU()\n        self.sigmoid    = nn.Sigmoid()\n        self.out        = nn.Linear(hid5, 1)\n\n    def forward(self, x):\n        l1   = self.linear1(x)\n        n1   = self.batchNorm1(l1)\n        d1   = self.dropout(n1)\n        act1 = self.relu(d1)\n        l2   = self.linear2(act1)\n        n2   = self.batchNorm2(l2)\n        d2   = self.dropout(n2)\n        act2 = self.relu(d2)\n        l3   = self.linear3(act2)\n        n3   = self.batchNorm3(l3)\n        d3   = self.dropout(n3)\n        act3 = self.relu(d3)\n        l4   = self.linear4(act3)\n        n4   = self.batchNorm4(l4)\n        d4   = self.dropout(n4)\n        act4 = self.relu(d4)\n        l5   = self.linear5(act4)\n        n5   = self.batchNorm5(l5)\n        d5   = self.dropout(n5)\n        act5 = self.relu(d5)\n        l6   = self.out(act5)\n        output = l6 #self.sigmoid(l6)\n        return output\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RMSELoss(torch.nn.Module):\n    def init(self):\n        super(RMSELoss,self).init()\n\n    def forward(self,x,y):\n        criterion = nn.MSELoss()\n        loss = torch.sqrt(criterion(x, y))\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = RMSELoss()\nmodel = NeuralNetwork(inp,hid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def torch_fit(x, y, x_val, y_val,model, loss, lr, num_epochs):\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,nesterov=False)#torch.optim.Adam(model.parameters(), lr=lr) # #torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)#torch.optim.Adagrad(model.parameters(), lr=lr, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)#torch.optim.Adadelta(model.parameters(), rho=0.9, eps=1e-06, weight_decay=0)# # #torch.optim.Adam(model.parameters(), lr=lr)\n    count = -1\n    pvl = 0\n    for epoch in range(num_epochs):\n        optimizer.zero_grad()\n        y_pred_tensor = model(x)\n        loss_value = loss(y_pred_tensor, y)\n        val_loss   = loss(model(x_val),y_val)\n        print(f'Epoch {epoch}, loss {loss_value.item():.4f} val loss: {val_loss.item():.4f} count: {count}')\n        loss_value.backward()\n        optimizer.step()\n        if val_loss.item() > pvl:\n            count += 1\n        pvl = val_loss\n        if count > 3750: \n            break\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pre_pipe(df).values\nx_train, x_val, y_train, y_val = train_test_split(x,y)\nl = len(y_train)\nlv = len(y_val)\nl,lv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tensor = torch.tensor(x_train).float().cuda()\nx_val_tensor = torch.tensor(x_val).float().cuda()\ny_tensor = torch.tensor(y_train.values).float().cuda()\ny_val_tensor = torch.tensor(y_val.values).float().cuda()\ny_tensor = y_tensor.view(l,1).cuda()\ny_val_tensor = y_val_tensor.view(lv,1).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tensor.size(), y_tensor.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.cuda()\nnn_model = torch_fit(x_tensor, y_tensor, x_val_tensor, y_val_tensor, model=model, loss=loss, lr=0.00728, num_epochs=9550)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/sample_submission.csv')\ns_df.head()\n#/kaggle/working/subs.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tes_tensor = torch.tensor(pre_pipe(test, False).values).float().cuda()\ntes_tensor.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model(tes_tensor)\npreds = preds.detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_df.target = preds \ns_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_df.to_csv('/kaggle/working/subs4.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}