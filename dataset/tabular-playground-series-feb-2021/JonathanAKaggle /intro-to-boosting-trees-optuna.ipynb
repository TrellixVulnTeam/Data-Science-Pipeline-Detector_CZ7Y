{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What are some simple commands for notebooks?\nCTRL+ENTER - run the current cell  \nLEFT CLICK ON CELL/ENTER - start text editing cell  \nLEFT CLICK OFF CELL/ESC - stop text editing cell  \nb - create new code cell"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib as plt\nimport optuna\nimport pickle\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ninput_path = Path('/kaggle/input/tabular-playground-series-feb-2021/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(input_path / \"train.csv\", index_col=\"id\")\ndf_test = pd.read_csv(input_path / \"test.csv\", index_col=\"id\")\ndf_preds_example = pd.read_csv(input_path / \"sample_submission.csv\")\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in df_train.columns:\n    if df_train[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df_train[c].values) + list(df_test[c].values))\n        df_train[c] = lbl.transform(df_train[c].values).astype(\"int32\")\n        df_test[c] = lbl.transform(df_test[c].values).astype(\"int32\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target = df_train.pop('target')\nX_train, X_val, y_train, y_val = train_test_split(df_train, df_target, test_size=0.5, random_state=43)\nX_test = df_test\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_xgb(X_train, X_val, y_train, y_val):\n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dval = xgb.DMatrix(X_val, label=y_val)\n    param = {'tree_method':'gpu_hist'}\n    num_round = 100\n    return xgb.train(param, dtrain, num_round, early_stopping_rounds=10, evals=[(dval, \"eval\")])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = get_model_xgb(X_train, X_val, y_train, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison\n\n#Median: 0.889\n#Linear regression: 0.870\n#Boosting trees: 0.851","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtest = xgb.DMatrix(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_xgb = xgb_model.predict(dtest)\ndf_preds_example[\"target\"] = preds_xgb\ndf_preds_example.to_csv(\"preds_xgb_solo.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# If you are already familiar with boosting trees:\nHave a look at the hyper parameter list for XGBoost here: https://xgboost.readthedocs.io/en/latest/parameter.html  \nWe will be doing a hyper parameter search later, so make a shortlist of what you think would be good to experiment with!  \n# If you are not familiar with boosting trees:\nI will run through a high level overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_df = pd.DataFrame([\n    [\"Yes\", 0, 0.1, 0, 0, 0.9],\n    [\"Yes\", 0, 0.15, 0, 5, 0.96],\n    [\"Yes\", 50, 0.5, 3, 0, 0.5],\n    [\"No\", 10, 0.4, 5, 5, 0.2],    \n    [\"No\", 11, 0.6, 25, 0, 0.3],\n], columns=[\"Is ferrari\", \"Years on license\", \"Crime rate\", \"Car age\", \"Penalty points\", \"Chance of insurance claim\"])\ndummy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\ndef GetChance(row):\n    if row[\"Is ferrari\"] == \"Yes\":\n        if row[\"Years on license\"] < 25:\n            return 0.93\n        else:\n            return 0.5\n    else:\n        return 0.25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boosting tree\ndef GetFerrariPenalty(row):\n    if row[\"Is ferrari\"] == \"Yes\":\n        if row[\"Years on license\"] < 25:\n            return 0.93\n        else:\n            return 0.5\n    else:\n        return 0.25\n\ndummy_df_residualised_1 = pd.DataFrame([\n    [\"Yes\", 0, 0.1, 0, 0, -0.03],\n    [\"Yes\", 0, 0.15, 0, 5, 0.03],\n    [\"Yes\", 50, 0.5, 3, 0, 0.0],\n    [\"No\", 10, 0.4, 5, 5, -0.05],    \n    [\"No\", 11, 0.6, 25, 0, 0.05],\n], columns=[\"Is ferrari\", \"Years on license\", \"Crime rate\", \"Car age\", \"Penalty points\", \"Chance of insurance claim\"])\ndummy_df_residualised_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetGoodDrinvingBoost(row):\n    if row[\"Penalty points\"] > 3:\n        return 0.04\n    else:\n        return -0.04\n    \ndummy_df_residualised_2 = pd.DataFrame([\n    [\"Yes\", 0, 0.1, 0, 0, 0.01],\n    [\"Yes\", 0, 0.15, 0, 5, -0.01],\n    [\"Yes\", 50, 0.5, 3, 0, -0.04],\n    [\"No\", 10, 0.4, 5, 5, -0.01],    \n    [\"No\", 11, 0.6, 25, 0, 0.01],\n], columns=[\"Is ferrari\", \"Years on license\", \"Crime rate\", \"Car age\", \"Penalty points\", \"Chance of insurance claim\"])\ndummy_df_residualised_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_lgb(X_train, X_val, y_train, y_val):\n    cat_columns = [f'cat{cat_index}' for cat_index in range(10)]\n    \n    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_columns)\n    validation_data = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_columns)\n    param = {'objective': 'regression', 'metric':'rmse'}\n    \n    return lgb.train(param, train_data, 1000,  valid_sets=validation_data, early_stopping_rounds=10, categorical_feature=cat_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = get_model_lgb(X_train, X_val, y_train, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_cat(X_train, X_val, y_train, y_val):\n    cat_columns = [f'cat{cat_index}' for cat_index in range(10)]\n    model = CatBoostRegressor(\n        eval_metric='RMSE',\n        task_type='GPU',\n        iterations=1000,\n        od_type=\"Iter\",\n        od_wait=10,\n        learning_rate=0.3,\n        metric_period=25\n    )\n    \n    model.fit(X_train, y=y_train, cat_features=cat_columns, eval_set=(X_val, y_val))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_model = get_model_cat(X_train, X_val, y_train, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_xgb = xgb_model.predict(dtest)\npreds_lgb = lgb_model.predict(X_test)\npreds_cat = cat_model.predict(X_test)\n\ndf_preds_example[\"target\"] = np.mean(np.vstack([preds_xgb, preds_lgb, preds_cat]), axis=0)\ndf_preds_example.to_csv(\"preds_combined_mean.csv\", index=False)\n\ndf_preds_example[\"target\"] = np.median(np.vstack([preds_xgb, preds_lgb, preds_cat]), axis=0)\ndf_preds_example.to_csv(\"preds_combined_median.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial, X_train, X_val, y_train, y_val):\n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dval = xgb.DMatrix(X_val, label=y_val)\n    \n    max_depth = trial.suggest_int('max_depth', 3, 6)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.1, 0.5)\n    subsample = trial.suggest_uniform('subsample', 0.1, 1)\n    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 1)\n    num_parallel_tree = trial.suggest_int('num_parallel_tree', 1, 2)\n    min_child_weight = trial.suggest_uniform('min_child_weight', 1, 250)\n    lambd = trial.suggest_uniform('lambd', 1, 1.1)\n    alpha = trial.suggest_uniform('alpha', 0, 0.2)\n    num_round = 1000\n    \n    param = {'max_depth':max_depth,\n             'learning_rate':learning_rate,\n             'objective':'reg:squarederror',\n             'subsample':subsample,\n             'colsample_bytree':colsample_bytree,\n             'num_parallel_tree':num_parallel_tree,\n             'lambda':lambd,\n             'alpha':alpha,\n            'tree_method':'gpu_hist'}\n    \n    bst = xgb.train(param, dtrain, num_round, early_stopping_rounds=2, evals=[(dval, \"eval\")])\n    return float(bst.eval(dval).split(\":\")[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study()\n\nstudy.optimize(lambda trial: objective(trial, X_train, X_val, y_train, y_val), n_trials=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Possible future steps\n# Feature engineering\n# Cross validation\n# Adding a Neural Network to the ensemble(Pytorch/Tensorflow)\n# Model stacking"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}