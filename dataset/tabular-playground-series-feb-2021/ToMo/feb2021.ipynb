{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ===== 概要 =====\nkaggleを始めたての人。これから機械学習を勉強したい人。基礎知識だけで実際に予測したことがない人向け。\n\nザックリデータを眺めるところからモデル作成までを解説します。"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ライブラリをインポートします。\n\npandas:データを表に起こす\n\nnumpy:計算処理などに使う"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\nsample = pd.read_csv(\"../input/tabular-playground-series-feb-2021/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pandasでデータを読み込みます。\n\n右端の|<と書いてある部分からデータを開き、\"input\"にあるcsvデータの右端\"Copy file path\"をクリックするとパスをコピーできます。\n\ntrainが学習データでtestが提出するためのデータ。"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sample.shape)\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sampleは提出形式を確認するためのデータです。\n\nidとtargetの２列にしてcsvファイルを提出しましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape, test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"学習データのtrainは30万行です。\n\n26列のデータがあり、targetが予測したいデータですね。"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"display.max_columns\", 30)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"panasのset_optionを使えば途中に省略された列も表示できます。最大30列にしました。\n\ncatが文字のカテゴリデータ、contが数値データです。"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [c for c in train.columns if \"cat\" in c]\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"モデル作成のために前処理が必要なのでカテゴリデータの列を抽出しました。\n\n[変数 for 変数 条件]でリストを作れます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = [c for c in train.columns if \"cont\" in c]\nnum_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"数値データも同様。"},{"metadata":{},"cell_type":"markdown","source":"# ===== データ確認 =====\nここからはデータの中身を見るだけなので、モデル作成だけを知りたい方は\"モデル作成\"まで飛んでください。"},{"metadata":{},"cell_type":"markdown","source":"## ○カテゴリデータ"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"cat0\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".value_count()で値ごとのデータ数を見れます。\n\n\"cat0\"の列では\"A\"が281471行\"B\"が18529行あるみたいです。"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    print(col)\n    print(train[col].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for文を使って全カテゴリを確認しましょう。\n\n列によってカテゴリ数が違います。"},{"metadata":{},"cell_type":"markdown","source":"## ○数値データ"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train[\"cont0\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"matplotlib.pyplotはグラフ描画のライブラリです。とりあえずインポートしてもいいくらい多用します。\n\n.histでヒストグラムを作れるので\"cont0\"の分布を見ましょう。\n\n外れ値だったり極端な偏りがあるのかザっと確認できます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(2, 2, figsize = (16, 8))\nax[0][0].hist(train[\"cont0\"])\nax[0][1].hist(train[\"cont1\"])\nax[1][0].hist(train[\"cont2\"])\nax[1][1].hist(train[\"cont3\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".subplotsを使えば複数のグラフを一気に描画できます。\n\n.subplots(行数, 列数)を設定してax[行][列]で描画する位置を指定します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(num_cols)):\n    r = i // 5\n    c = i % 5\n    print(r, c, num_cols[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for文と.subplotsを組み合わせたいのでそれぞれの項目と行列番号を振り分けます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(3, 5, figsize = (30, 12))\nfor i in range(len(num_cols)):\n    r = i // 5\n    c = i % 5\n    ax[r][c].hist(train[num_cols[i]], bins = 100)\n    ax[r][c].set_title(num_cols[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".subplotsで３行５列のグラフエリアを作成し、さっきのfor文の要領で行番号と列番号を振り分けました。\n\nbinsはヒストグラムの分割数を決める引数です。大きいほど細かな分布を確認できます。\n\n例えば\"cont1\",\"cont4\"はデータが離散してたり極端に偏っています。"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n_, ax = plt.subplots(figsize = (16, 6))\nsns.boxplot(data = train[num_cols], ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seabornもグラフ描画によく使われるライブラリです。よくsnsと略されます。\n\n.boxplotはデータ分布や外れ値を簡単に確認するために便利です。\n\n\"cont1\"～\"cont13\"にかけてだいたい0.2～0.8の間にデータが多く存在し、またスケールもほぼ同じだとわかります。"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(train[\"cont0\"], train[\"target\"], alpha = 0.3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".scatterで散布図を描けます。\n\n横軸は特徴量で縦軸はtargetにしました。\n\nalphaを設定すると濃い部分にデータが偏っているとわかるので便利。（今回は意味を成してませんが...）"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(3, 5, figsize = (30, 12))\nfor i in range(len(num_cols)):\n    r = i // 5\n    c = i % 5\n    ax[r][c].scatter(train[num_cols[i]], train[\"target\"], alpha = 0.3)\n    ax[r][c].set_title(num_cols[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ヒストグラムの時と同じ要領で各項目とtargetとの散布図を描きました。\n\nどれも四角に分布していてとても相関があるように見えませんね。\n\nまたヒストグラムでも確認しましたが\"cont1\"では謎の間隔があります。\n\n\"なんか意味ありげだなー\"くらいに最初はとらえておきます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[num_cols + [\"target\"]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ここから相関係数を確認します。\n\nまずは数値データとtargetのみを取り出すようにリストの結合(num_cols + [\"target\"])を使ってみましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train[num_cols + [\"target\"]].corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".corr()で相関係数が計算されます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr.style.background_gradient(cmap = \"bwr\", axis = None, vmax = 1.0, vmin = -1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".style.background_gradient()で表にカラーマップを施すことができます。\n\naxis = Noneにしないと各列(行)方向に対してカラーリングするので気を付けましょう。\n\n同じ値同士は当然1.0です。\n\ntargetと各数値データの相関係数を見るとどれも絶対値が0.1未満でほとんど相関していないとわかりますね。"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(figsize = (8, 6))\nsns.heatmap(corr, cmap = \"bwr\", vmax = 1.0, vmin = -1.0, ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seabornの.heatmapでもヒートマップを作れます。\n\nほとんどtargetと相関がないとわかりますね。数値データは予測に貢献しないかもしれません。\n\nまた数値データ同士、例えば\"cont5\"と\"cont12\"の色が濃いつまり相関が高いように見えます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(train[\"cont5\"], train[\"cont12\"], alpha = 0.3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"相関が高そうな\"cont5\"と\"cont12\"を確認しました。\n\nうーん...。"},{"metadata":{},"cell_type":"markdown","source":"## ○総括\n・カテゴリは2～14くらいに分かれている\n\n・数値データはどれもスケールが似ている\n\n・\"cont1\"は意味ありげな分布をしている\n\n・数値データとtargetで相関がない（カテゴリデータが重要？主成分分析で見ると変わりそう？）"},{"metadata":{},"cell_type":"markdown","source":"# ===== モデル作成 =====\nLightGBMを作ります。\n\nランダムフォレストなどもっと初心者向けのモデルがありますが、作る労力はほぼ変わらないのでLightGBMの方がおススメです。\n\nまたXgboostを好む人もいます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"再度学習データを確認します。\"cat0\"～\"cont13\"までの列を使って\"target\"を予測します。\n\nここで大事なことは、カテゴリデータは文字のままではモデルに使えない点です。\n\nなので例えば\"A\"を数値の１に置き換えるような変換をしましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    print(np.sort(train[col].unique()))\n    print(np.sort(test[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"trainもtestも変換が必要なのでそれぞれ片方にしかないカテゴリがないか確認します。\n\ntestにはあってtrainにないカテゴリがあると致命的ですが、trainにしかないのはセーフ。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\nfor col in cat_cols:\n    train[col] = label.fit_transform(train[col])\n    test[col] = label.transform(test[col])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sklearnにLabelEncoderがあるので、これで文字を数値に変換していきます。\n\n.fit_transformで例えば\"A\"を0に\"B\"を1に置き換える(fitする)作業と実際にデータを変換する(transformする)作業の両方を実行します。\n\ntestの方はすでにtrainでfitしているのでtransformだけでOKです。"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    print(np.sort(train[col].unique()))\n    print(np.sort(test[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"数値に変換されていますね。"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(columns = [\"id\", \"target\"])\ny = train[\"target\"]\nprint(X.shape, y.shape)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"学習に使う特徴量Xと予測したい目的変数yに分けます。\n\n大文字X小文字yを使うのは人の好みですが、２次元データを大文字で１次元データを小文字で表す慣習があります。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkfold = KFold(n_splits = 5)\nfor train_idx, valid_idx in kfold.split(X):\n    print(len(train_idx), len(valid_idx))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"実際に学習に使うデータ(train)とモデル性能を確認するためのデータ(valid)に分けます。\n\nこれをしないとモデルの良し悪しがわからないまま分析することになってしまいます。\n\n分割方法はKFoldが一般的ですがコンペによっては違う分割をするので、ここは個人差（成績に差がつくところ）です。\n\n今回は５回分割にしました。\n\nKFoldはそれぞれ必ず１回は評価用データに回されるので５回分割すると全体の1/5が評価用データになります。つまり6万行です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"for train_idx, valid_idx in kfold.split(X):\n    X_train = X.iloc[train_idx, :]\n    X_valid = X.iloc[valid_idx, :]\n    y_train = y.iloc[train_idx]\n    y_valid = y.iloc[valid_idx]\n    print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KFoldの分割をデータにあてはめます。\n\n.splitでインデックス(行番号)として分割してくれるので、これを.iloc[行, 列]に使いましょう。\n\n：は全てを意味するので、例えば.iloc[0, :]は０行目の全列です。"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import lightgbm as lgb\n\nparams = {\n    \"objective\" : \"regression\",\n    \"metrics\" : \"rmse\"\n}\n\nfor train_idx, valid_idx in kfold.split(X):\n    X_train = X.iloc[train_idx, :]\n    X_valid = X.iloc[valid_idx, :]\n    y_train = y.iloc[train_idx]\n    y_valid = y.iloc[valid_idx]\n    \n    train_set = lgb.Dataset(X_train, y_train)\n    valid_set = lgb.Dataset(X_valid, y_valid)\n    \n    model = lgb.train(\n        params = params,\n        train_set = train_set,\n        valid_sets = [train_set, valid_set],\n        num_boost_round = 300,\n        early_stopping_rounds = 10,\n        verbose_eval = 50\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"モデルを作成します。\n\nLightGBMに必要な行程は３つ。\n\n①パラメータ設定\n\nobjectiveはモデルの種類を設定します。regressionは回帰です。分類だったらbinaryとかを使います。\n\nmetricsは評価指標(どうなったらモデルが良いのか)を決めます。今回は平均二乗誤差の平方根(rmse)です。\n\n②.DatasetでLightGBM専用データに変換\n\n.Dataset(特徴量, 目的変数)で変換します。\n\n③.trainで学習\n\nparamsは①のパラメータです。train_setは学習用データ。valid_setsは少なくとも評価用データだけは渡しましょう。\n\nnum_boost_roundは学習回数です。多ければ多いほど好ましいですがどこかで性能が頭打ちになるので多すぎると時間のムダです。\n\nearly_stopping_roundsはモデル性能(metrics)が指定した回数向上しなければ学習を止めます。今回は10にしました。\n\nつまりnum_boost_roundを多めにしてearly_stopping_roundsを指定しておけばだいたい丸く収まります。\n\nverbose_evalは何回目の学習ごとに結果出力するかを決めます。デフォルトは１ですが、出力結果が長すぎるので好みで変えましょう。\n"},{"metadata":{},"cell_type":"markdown","source":"これで\"モデルを作る\"という目的までは達成できます。\n\nただしあくまでモデルを作っただけなので性能が不明です。\n\nテニスで例えるなら、ボールを打つことができたけどコートに入ったのかフェンスに直撃したのかわからないといった感じ。\n\nなので少し工夫を加えましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    \"objective\" : \"regression\",\n    \"metrics\" : \"rmse\",\n    \"verbosity\" : -1\n}\n\nmodels = []\nOOF = np.zeros(y.shape[0])\nresults = []\nfor train_idx, valid_idx in kfold.split(X):\n    X_train = X.iloc[train_idx, :]\n    X_valid = X.iloc[valid_idx, :]\n    y_train = y.iloc[train_idx]\n    y_valid = y.iloc[valid_idx]\n    \n    train_set = lgb.Dataset(X_train, y_train)\n    valid_set = lgb.Dataset(X_valid, y_valid)\n    fold_results = {}\n    model = lgb.train(\n        params = params,\n        train_set = train_set,\n        valid_sets = [train_set, valid_set],\n        num_boost_round = 300,\n        early_stopping_rounds = 10,\n        verbose_eval = 50,\n        evals_result = fold_results\n    )\n    models.append(model)\n    OOF[valid_idx] = model.predict(X_valid)\n    results.append(fold_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"modelsに各分割で作成したモデルを保存します。\n\nOOFはOut Of Foldsの略で正解データyと予測値の誤差を確認するために用意しました。\n\nresultsには学習過程を入れましょう。\n\nparamsのverbosityを-1にすると余計な情報を出力しなくなります。\n\nfold_resultsに各分割の学習過程を入れます。evals_resultに渡してください。\n\nmodels.append()で作成したモデルをリストに追加します。\n\nOOF[valid_idx]で評価用データのインデックスに予測結果を入れます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.shape, OOF.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OOFのサイズが実際のデータyと同じであると確認しました。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y, OOF)\nrmse = np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"mean_squared_errorで平均二乗誤差を計算できます。\n\nyとOOFとの誤差を計算してmseにしましたが単位もスケールも二乗になるので平方根(rmse)をとりました。\n\nrmseが0.845です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"実際のデータyは標準偏差が0.887なのでボチボチの誤差です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"results[0].keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"resultsには学習過程を入れました。\n\n辞書型になっていてキーは\"training\"と\"valid_1\"です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"results[0][\"training\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"training\"の中にはmetricsで指定した\"rmse\"が入っています。"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(1, 5, figsize = (40, 6))\nfor i in range(len(results)):\n    ax[i].plot(results[i][\"training\"][\"rmse\"], color = \"red\", label = \"train\")\n    ax[i].plot(results[i][\"valid_1\"][\"rmse\"], color = \"blue\", label = \"valid\")\nplt.legend(fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"この\"rmse\"を.plotでプロットしました。横軸が学習回数で縦軸が誤差(rmse)です。\n\n赤線が学習用データ(train)で青線が評価用データ(valid)です。\n\ntrainの方が誤差が小さいですが、これは答えを知っているのであまり参考になりません。\n\nvalidは100回目くらいで頭打ちになっていますね。\n\ntrainとvalidとの差が大きすぎると過学習しているので、今回も若干過学習気味です。"},{"metadata":{},"cell_type":"markdown","source":"# ===== 提出 ====="},{"metadata":{"trusted":true},"cell_type":"code","source":"models[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"modelsには学習モデルを保存しました。\n\nこのモデルを使って提出データを作ります。"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"testには予測したいtarget以外のデータが入っています。"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test.drop(columns = \"id\")\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"id\"だけは予測に使わないので除去しました。"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = models[0].predict(X_test)\npred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"models[0]で１個目のモデルが取り出せます。\n\n.predictで予測結果を出しましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sample.shape, pred.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"予測結果のサイズがsampleのサイズと同じです。"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_preds = []\nfor model in models:\n    pred = model.predict(X_test)\n    submit_preds.append(pred)\nprint(len(submit_preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"おなじように.predictを作成したモデル数分繰り返します。\n\nその結果をsubmit_predsに入れました。"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(submit_preds, axis = 0).shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"５モデルそれぞれの予測結果をだしたので、その平均をとりましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(submit_preds, axis = 1).shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"axisは０か１で設定します。これは行方向か列方向かを設定します。\n\n今回は１にすると\"各モデルの予測結果の平均\"となるので、全数が５になります。\n\nさっきの０は\"各予測結果の平均\"になるので全数が200000です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"提出する形式を確認します。200000行2列です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"id\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"id\"にはtestの\"id\"をそのまま使います。"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_preds = np.mean(submit_preds, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"target\"には予測結果の平均をとりましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame()\nsubmit[\"id\"] = test[\"id\"].copy()\nsubmit[\"target\"] = submit_preds\nsubmit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pandasの.DataFrame()でカラのデータを作りました。\n\n\"id\"と\"target\"のそれぞれにデータを入れましょう。\n\nサイズもsampleと同じサイズです。"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv(\"submit.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".to_csv()でcsvファイルを出力します。\n\n実行すると右端|<をクリックして出てくる\"output\"にファイルが入っているはずです。\n\nこのファイルをダウンロードするか\"Save Version\"でノートブックを保存して提出しましょう。"},{"metadata":{},"cell_type":"markdown","source":"# ===== 今後 =====\n簡単なデータ確認からモデル作成までを解説しました。\n\n後は特徴量を作ってみたりモデルのパラメータを変えたり別のモデルを試したりしてスコアを上げます。\n\nただしリーダーボード上のスコアが絶対ではなく、リーダーボードのデータに過剰フィットすると最終順位が決まるデータでのスコアが落ちます。\n\nなのでこのノートで作ったOOFとの誤差が改善され、かつ、リーダーボードでの順位も上がるように調整したりします。"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}