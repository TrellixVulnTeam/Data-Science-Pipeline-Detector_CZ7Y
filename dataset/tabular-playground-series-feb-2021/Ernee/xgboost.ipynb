{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Basic XGBoost model with parameter tunning"},{"metadata":{},"cell_type":"markdown","source":"In this notebook I used XGBoost to fit the data and did some parameter tunning. If you have any hints on how to improve it, please feel free to comment below :)\n\nThank you!"},{"metadata":{},"cell_type":"markdown","source":"### Load libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import ParameterGrid\n\nfrom xgboost import XGBRegressor\nimport copy\n        \ninput_path = Path('/kaggle/input/tabular-playground-series-feb-2021/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(input_path / 'train.csv', index_col='id')\n#display(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(input_path / 'test.csv', index_col='id')\n#display(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')\n#display(submission.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in train.columns:\n    if train[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(train[c].values)\n        test[c] = lbl.transform(test[c].values)\n\n#display(train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pull out the target and make a validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train, target, train_size=0.80)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First model: XGBoost regressor with default settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model with default settings\nmodel = XGBRegressor()\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions and compute MSE on the validation set\npredictions = model.predict(X_valid)\nprint(\"MSE: \" + str(mean_squared_error(predictions, y_valid, squared=False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create first submission file\nsubmission['target'] = model.predict(test)\nsubmission.to_csv('xgboost_1.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this first submission file, LB score was **0.84924**."},{"metadata":{},"cell_type":"markdown","source":"## Second model using some parameter tunning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add a few parameters to improve the performance of the model\nmodel = XGBRegressor(n_estimators=500, \n                     learning_rate=0.05, \n                     n_jobs=-1)\nmodel.fit(X_train, y_train, \n          early_stopping_rounds=5,\n          eval_set=[(X_valid, y_valid)],\n          verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions and compute MSE on the validation set\npredictions = model.predict(X_valid)\nprint(\"MSE: \" + str(mean_squared_error(predictions, y_valid, squared=False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create second submission file\nsubmission['target'] = model.predict(test)\nsubmission.to_csv('xgboost_2.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this second submission file, LB score was **0.84586**. A little better than the first one."},{"metadata":{},"cell_type":"markdown","source":"## Thrid model with parameter tunning after a simple grid search"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell takes a long time to run, so I have commented it.\n\n#model = XGBRegressor()\n\n# Create a dictionary of hyperparameters to search\n#grid = {'max_depth': [6, 7], 'n_estimators': [100, 500, 1000], 'n_jobs': [-1], 'learning_rate': [0.05, 0.10],}\n\n#model_scores = []\n\n# Loop through the parameter grid, set the hyperparameters, and save the scores\n#for g in ParameterGrid(grid):\n#    model.set_params(**g) \n#    model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n#    predictions = model.predict(X_valid)\n#    model_score = mean_squared_error(y_valid, predictions, squared=False)\n#    model_scores.append(model_score)\n#    print('MSE =', f'{model_score:0.5f} ', 'Parameters:', g)\n\n# Find best hyperparameters from the validation score and print\n#best_idx = np.argmin(model_scores)\n#print()\n#print('Best score: ', model_scores[best_idx], ParameterGrid(grid)[best_idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These were the results:\n\n`MSE = 0.85165  Parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'n_jobs': -1}`\n`MSE = 0.84347  Parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 500, 'n_jobs': -1}`\n`MSE = 0.84347  Parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 1000, 'n_jobs': -1}`\n`MSE = 0.85032  Parameters: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}`\n`MSE = 0.84367  Parameters: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500, 'n_jobs': -1}`\n`MSE = 0.84367  Parameters: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 1000, 'n_jobs': -1}`\n`MSE = 0.84582  Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'n_jobs': -1}`\n`MSE = 0.84375  Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500, 'n_jobs': -1}`\n`MSE = 0.84375  Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 1000, 'n_jobs': -1}`\n`MSE = 0.84526  Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'n_jobs': -1}`\n`MSE = 0.84426  Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500, 'n_jobs': -1}`\n`MSE = 0.84426  Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 1000, 'n_jobs': -1}`\n\n`Best score:  0.8434681452062144 {'n_jobs': -1, 'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.05}`"},{"metadata":{},"cell_type":"markdown","source":"The best set of parameters found was ... the same I had tried before! The only difference is that `n_jobs` was set to `-1`.\n\nAnd it seems that setting `n_estimators` to more than 500 did not make a difference.\n\nIn any case, I will fit the model once again."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model with the best parameters found\nmodel = XGBRegressor(n_estimators=500,\n                     learning_rate=0.05,\n                     n_jobs=-1)\nmodel.fit(X_train, y_train, \n          early_stopping_rounds=5,\n          eval_set=[(X_valid, y_valid)],\n          verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions and compute MSE on the validation set\npredictions = model.predict(X_valid)\nprint(\"MSE: \" + str(mean_squared_error(predictions, y_valid, squared=False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create third submission file\nsubmission['target'] = model.predict(test)\nsubmission.to_csv('xgboost_3.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this third submission file, LB score was **0.84586**, the same as the second model's."},{"metadata":{},"cell_type":"markdown","source":"### So this is what I have so far. As mentioned before, any tips on how to improve this simple model are welcome. Thank you! :D"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}