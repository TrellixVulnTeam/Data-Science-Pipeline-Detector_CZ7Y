{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook uses [https://www.kaggle.com/tunguz](http://) s [https://www.kaggle.com/tunguz/tps-02-21-feature-importance-with-xgboost-and-shap](http://)  work as base. \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import lightgbm as lgbm\nimport xgboost as xgb\nimport catboost as cb\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nimport category_encoders as ce\nimport shap\nimport matplotlib.pyplot as plt\nxgb.__version__\n%matplotlib inline\nshap.initjs()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\nsample_sub = pd.read_csv(\"../input/tabular-playground-series-feb-2021/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features = [col for col in train.columns if 'cont' in col]\ncat_features = [col for col in train.columns if 'cat' in col]\ntarget = 'target'\n\ny_train = train[target]\ntrain.drop(['id'], inplace=True, axis=1)\ntest.drop(['id'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#frequency_encoding\nfor variable in cat_features:\n    count_dict = train[variable].value_counts().to_dict()\n    factor = 1.0 / sum(count_dict.values())\n    normalised_count_dict = {k: v * factor for k, v in count_dict.items()}\n    train[f'fe_{variable}'] = train[variable].map(normalised_count_dict)\n    test[f'fe_{variable}'] = test[variable].map(normalised_count_dict)\n\n#target_encoding\nfor variable in cat_features:\n    # create dictionary of category:mean values.\n    dict = train.groupby([variable])[target].mean().to_dict()\n    # apply the encoding to the train and test sets.\n    train[f'te_{variable}'] = train[variable].map(dict)\n    test[f'te_{variable}'] = test[variable].map(dict)\n    \n#label_encoding\nfor variable in cat_features:\n    le = LabelEncoder()\n    le.fit(train[variable])\n    train[f'le_{variable}'] = le.transform(train[variable])\n    test[f'le_{variable}'] = le.transform(test[variable])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([target], inplace=True, axis=1)\n\ntrain.drop(cat_features, inplace=True, axis=1)\ntest.drop(cat_features, inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_parameters = {\n        \"objective\": \"reg:squarederror\",\n        \"max_depth\": 10,\n        \"learning_rate\": 0.01,\n        \"colsample_bytree\": 0.5,\n        \"subsample\": 0.5,\n        \"reg_alpha\" : 6,\n        \"min_child_weight\": 100,\n        \"n_jobs\": 8,\n        \"seed\": 22,\n        'tree_method': \"gpu_hist\",\n        \"gpu_id\": 0,\n    }\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remind that these parameters are just default values and not tuned to have best score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=22)\noof = np.zeros(len(X_train))\nscore_list = []\nfold = 1\ntest_preds = []\ntest_df = xgb.DMatrix(X_test)\n\nfor train_index, test_index in kf.split(X_train):\n    Xoof_train, Xoof_val = X_train.iloc[train_index], X_train.iloc[test_index]\n    yoof_train, yoof_val = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    train_df = xgb.DMatrix(Xoof_train, label=yoof_train)\n    val_df = xgb.DMatrix(Xoof_val, label=yoof_val)\n\n    model = xgb.train(xgb_parameters, train_df, 3000)\n\n    yoof_pred = model.predict(val_df)\n    test_preds.append(model.predict(test_df))\n\n    oof[test_index] = yoof_pred\n    score = np.sqrt(mean_squared_error(yoof_val, yoof_pred))\n    score_list.append(score)\n    print(f\"RMSE Seed 22 Fold-{fold} : {score}\")\n    fold += 1\n\nprint(f\"Seed 22 folds average = {np.mean(score_list)} ({np.std(score_list)})\")\ntest_pred = np.mean(test_preds, axis=0)\ntest_pred_df = pd.DataFrame(test_pred, columns=['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_preds = model.predict(test_df, pred_contribs=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_preds[:,:-1], X_test, max_display=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_preds[:,:-1], X_test, plot_type=\"bar\",  max_display=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nshap_interactions = model.predict(test_df, pred_interactions=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_columns = [col for col in X_test.columns if 'cat' in col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I want to focus on interactions between categorical features."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_top_k_interactions(feature_names, shap_interactions, k):\n    # Get the mean absolute contribution for each feature interaction\n    aggregate_interactions = np.mean(np.abs(shap_interactions[:, :-1, :-1]), axis=0)\n    interactions = []\n    for i in range(aggregate_interactions.shape[0]):\n        for j in range(aggregate_interactions.shape[1]):\n            if j < i:\n                try:\n                    interactions.append((feature_names[i] + \"-\" + feature_names[j], aggregate_interactions[i][j] * 2))\n                except:\n                    pass\n    # sort by magnitude\n    interactions.sort(key=lambda x: x[1], reverse=True)\n    interaction_features, interaction_values = map(tuple, zip(*interactions))\n    print(interaction_features[:20])\n    plt.bar(interaction_features[:k], interaction_values[:k])\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    plt.show()\n    \nplot_top_k_interactions(cat_columns, shap_interactions, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5 most gain category interaction pairs are (\"cat8\", \"cat0\"), (\"cat9\", \"cat8\"), (\"cat9\", \"cat5\"), (\"cat8\", \"cat5\"), (\"cat9\", \"cat0\")"},{"metadata":{},"cell_type":"markdown","source":"We are starting from scratch to add interactions as new features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\nsample_sub = pd.read_csv(\"../input/tabular-playground-series-feb-2021/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features = [col for col in train.columns if 'cont' in col]\ncat_features = [col for col in train.columns if 'cat' in col]\ntarget = 'target'\n\ny_train = train[target]\ntrain.drop(['id'], inplace=True, axis=1)\ntest.drop(['id'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_interactions = []\ncat_pairs = [(\"cat8\", \"cat0\"), (\"cat9\", \"cat8\"), (\"cat9\", \"cat5\"), (\"cat8\", \"cat5\"), (\"cat9\", \"cat0\")]\nfor pair in cat_pairs:\n    cat_interactions.append(f'{pair[0]}_{pair[1]}')\n    train[f'{pair[0]}_{pair[1]}'] = (train[pair[0]] + train[pair[1]]).astype(\"category\")\n    test[f'{pair[0]}_{pair[1]}'] = (test[pair[0]] + test[pair[1]]).astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#frequency_encoding\nfor variable in cat_features:\n    count_dict = train[variable].value_counts().to_dict()\n    factor = 1.0 / sum(count_dict.values())\n    normalised_count_dict = {k: v * factor for k, v in count_dict.items()}\n    train[f'fe_{variable}'] = train[variable].map(normalised_count_dict)\n    test[f'fe_{variable}'] = test[variable].map(normalised_count_dict)\n\n#target_encoding\nfor variable in cat_features:\n    # create dictionary of category:mean values.\n    dict = train.groupby([variable])[target].mean().to_dict()\n    # apply the encoding to the train and test sets.\n    train[f'te_{variable}'] = train[variable].map(dict)\n    test[f'te_{variable}'] = test[variable].map(dict)\n    \n#label_encoding\nfull_data = pd.concat([train,test], axis=0)\nfor variable in cat_features + cat_interactions:\n    le = LabelEncoder()\n    le.fit(full_data[variable])\n    train[f'le_{variable}'] = le.transform(train[variable])\n    test[f'le_{variable}'] = le.transform(test[variable])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([target], inplace=True, axis=1)\n\ntrain.drop(cat_features + cat_interactions, inplace=True, axis=1)\ntest.drop(cat_features + cat_interactions, inplace=True, axis=1)\n\nX_train = train\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=22)\noof = np.zeros(len(X_train))\nscore_list = []\nfold = 1\ntest_preds = []\ntest_df = xgb.DMatrix(X_test, enable_categorical=True)\n\nfor train_index, test_index in kf.split(X_train):\n    Xoof_train, Xoof_val = X_train.iloc[train_index], X_train.iloc[test_index]\n    yoof_train, yoof_val = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n    train_df = xgb.DMatrix(Xoof_train, label=yoof_train, enable_categorical=True)\n    val_df = xgb.DMatrix(Xoof_val, label=yoof_val, enable_categorical=True)\n\n    model = xgb.train(xgb_parameters, train_df, 3000)\n\n    yoof_pred = model.predict(val_df)\n    test_preds.append(model.predict(test_df))\n\n    oof[test_index] = yoof_pred\n    score = np.sqrt(mean_squared_error(yoof_val, yoof_pred))\n    score_list.append(score)\n    print(f\"RMSE Seed 22 Fold-{fold} : {score}\")\n    fold += 1\n\nprint(f\"Seed 22 folds average = {np.mean(score_list)} ({np.std(score_list)})\")\ntest_pred = np.mean(test_preds, axis=0)\ntest_pred_df = pd.DataFrame(test_pred, columns=['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Folds average improved 0.8441617327137406 (0.0008574847655632837) =>  0.8440450262413028 (0.0008286076422571708)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}