{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tabular Playground Series - Feb 2021\n\nThis notebook presents starter EDA and trains a RandomForestRegressor"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.figure_factory as ff\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/test.csv', index_col='id')\nsample = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/sample_submission.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Train shape :\",train.shape, \"\\n  Test shape:\", test.shape, \"\\nSample shape:\", sample.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',None)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Any missing values? - NO"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import missingno as msno \nmisshing_info = msno.bar(train)\nmisshing_info.set_title('Training data missing values chart',fontdict={'fontsize':25})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test_missing_info = msno.bar(test)\ntest_missing_info.set_title('Test data missing values chart',fontdict={'fontsize':25})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the target variable\n> We are dealing with bimodal distribution with outliers !"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(train, x=\"target\",marginal=\"box\",color_discrete_sequence=['forestgreen'])\nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Distribution of target variable<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                  yaxis={\"title\": \"Count\",\n                         \"zeroline\":False, \"showgrid\":False,\n                         \"fixedrange\": False\n                        },\n                  plot_bgcolor=\"#ffffff\",\n                  margin={\"r\":20, \"l\":30},\n                 )\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Explore Categorical Attribute\n> There are 10 categorical attributes cat0 - cat9"},{"metadata":{},"cell_type":"markdown","source":"## Value Counts"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cat_cols = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8','cat9']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=5, cols=2,subplot_titles=cat_cols,shared_yaxes=True)\n\n\ncol = 0\nfor i in range(0,2):\n    col = i+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=1, col=col\n    )\ncol = 0    \nfor i in range(2,4):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=2, col=col\n    )\n\ncol = 0    \nfor i in range(4,6):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=3, col=col\n    )\ncol = 0    \nfor i in range(6,8):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=4, col=col\n    )    \ncol = 0    \nfor i in range(8,10):\n    col = col+1\n    cat=train[cat_cols[i]].value_counts().reset_index()\n    fig.add_trace(\n        go.Bar(\n                x=cat['index'], y=cat[cat_cols[i]],\n                text=cat[cat_cols[i]],\n                textposition='auto',\n                name=cat_cols[i]\n            ),\n        row=5, col=col\n    )     \nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Categorical column value counts<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                  yaxis={\"title\": \"Count\",\n                         \"zeroline\":False, \"showgrid\":False,\n                         \"fixedrange\": False\n                        },\n                  plot_bgcolor=\"#ffffff\",\n                  margin={\"r\":20, \"l\":30},\n                 )\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* cat0 - cat5 has upto 4 categories\n* cat6 - cat 9 has upt 8 categories"},{"metadata":{},"cell_type":"markdown","source":"### Lets zoom in and look at each category"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, sharey=True, figsize=(8, 15))\nsns.set_theme(palette=\"spring_r\",style=\"ticks\")\nfor i, ax in zip(range(10), axes.flat):\n    sub_plot = sns.boxplot(x=\"cat{}\".format(i), y=\"target\",\n            data=train,  ax=ax)\n    if (i % 2) != 0:\n        sub_plot.yaxis.set_visible(False) \n    sub_plot.set_xlabel(\"cat{}\".format(i),fontsize=18)\n    sub_plot.set_ylabel(\"target\",fontsize=18)\n\nsns.despine(offset=5, trim=True)\nsns.despine(left=True)     \nfig.tight_layout(pad=3.0)\nfig.suptitle('Distribution of target per category across categorical attributes', fontsize=16)\nfig.subplots_adjust(top=0.95)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Numerical Attributes\n\nThere are 14 numerical attributes cont0 - cont13"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"numeric_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = make_subplots(rows=2, cols=7,subplot_titles=numeric_cols, shared_yaxes=True)\n\ncol = 0\nfor i in range(0,7):\n    col = col+1\n    fig.add_trace(go.Box(y=train[numeric_cols[i]], name=numeric_cols[i],\n                    marker_color = 'indianred'),\n                     row=1, col=col)\ncol = 0\nfor i in range(7,14):\n    col = col+1\n    fig.add_trace(go.Box(y=train[numeric_cols[i]], name=numeric_cols[i],\n                    marker_color = 'indianred'),\n                     row=2, col=col)\n    \nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Numerical column distribution<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                  yaxis={\"title\": \"Count\",\n                         \"zeroline\":False, \"showgrid\":False,\n                         \"fixedrange\": False\n                        },\n                  plot_bgcolor=\"#ffffff\",\n                  margin={\"r\":20, \"l\":30},\n                 )\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns with Outliers are \n* cont0\n* cont2\n* cont6\n* cont8\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"numeric_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13','target']\ncorr=train[numeric_cols].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set_theme(palette=\"mako\",style=\"ticks\")\nfig, axes = plt.subplots(7, 2, sharey=True, figsize=(8, 15))\nfor i, ax in zip(range(14), axes.flat):\n    sub_plot = sns.scatterplot(data=train, x=\"cont{}\".format(i), y=\"target\", ax=ax)\n    if (i % 2) != 0:\n        sub_plot.yaxis.set_visible(False) \n    sub_plot.set_xlabel(\"cont{}\".format(i),fontsize=18)\n    sub_plot.set_ylabel(\"target\",fontsize=18)\n\nsns.despine(offset=5, trim=True)\nsns.despine(left=True)     \nfig.tight_layout(pad=3.0)\nfig.suptitle('Scatter plot of numerical attributes vs target', fontsize=16)\nfig.subplots_adjust(top=0.95)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.imshow(corr)\nfig.update_layout(showlegend=True,\n                  title = { 'text' : '<b>Correlation Matrix of numerical attributes<b>',\n                          'x':0.5,\n                        'xanchor': 'center',\n                        'yanchor': 'top'\n                        },\n                  title_font_color='black',\n                 \n                 )\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  No significant linear correlation "},{"metadata":{},"cell_type":"markdown","source":"# Pipeline"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import set_config\n\nnumeric_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\nX = train.drop(\"target\", axis = 1)  \ny = train['target'] # label to predict\n\ndef build_model(model):\n    #numerical_pipe = Pipeline([('std_scaler',StandardScaler())])\n    categorical_pipe = Pipeline([('one_hot',OneHotEncoder())])\n    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_cols),\n            ('cat', categorical_transformer, cat_cols)])\n    regr = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regression_model', model)])   \n    set_config(display='diagram')\n    return regr\n\ndef get_pipeline():\n    #numerical_pipe = Pipeline([('std_scaler',StandardScaler())])\n    categorical_pipe = Pipeline([('one_hot',OneHotEncoder())])\n    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_cols),\n            ('cat', categorical_transformer, cat_cols)])\n    return preprocessor\n\ndef calculate_train_rmse(name, model):\n    runs_predictions = model.predict(X)\n    mse = mean_squared_error(y, runs_predictions)\n    rmse = np.sqrt(mse)\n    print(\"Training RMSE of {} : {}\".format(name,rmse))\n\ndef sample_prediction(name, model, num_records):\n    some_data = X.iloc[:num_records]\n    some_labels = y.iloc[:num_records]\n    preds = []\n    for label in list(model.predict(some_data)):\n        preds.append(math.floor(label))\n\n    print(\"Predictions on training data using :\", name)    \n    print(\"Predictions    :\", preds)\n    print(\"Actual labels  :\", list(some_labels))    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForestRegressor\nLet's train RandomForestRegressor base version with standard scaler and one-hot encoding. Nothing fancy here. Just an initial version"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = build_model(RandomForestRegressor(random_state = 42))\nforest_reg.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculate_train_rmse(\"RandomForestRegressor\",forest_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['target'] = forest_reg.predict(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('random_forest_v1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib as jbl\njbl.dump(forest_reg, \"forest_reg.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To be continued. Thanks for going through. Long way to go. Please upvote if you find it useful!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}