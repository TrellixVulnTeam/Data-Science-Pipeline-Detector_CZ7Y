{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries ðŸ“—"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport time\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n \nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.manifold import TSNE\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport optuna\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoost, Pool\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.metrics import roc_auc_score, mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.decomposition import TruncatedSVD, PCA\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import (StandardScaler,RobustScaler ,\n                                   PowerTransformer,KBinsDiscretizer,\n                                   QuantileTransformer ,LabelEncoder, \n                                   OneHotEncoder,OrdinalEncoder)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data ðŸ’½"},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/tabular-playground-series-feb-2021'\ntrain_data = pd.read_csv(f'{folder_path}/train.csv')\ntest_data = pd.read_csv(f'{folder_path}/test.csv')\nsample = pd.read_csv(f'{folder_path}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features = [f'cont{i}' for i in range(14)]\ncat_features = [f'cat{i}' for i in range(10)] \n# cat_features = ['cat1','cat3','cat5','cat8','cat9']\nall_features =   cat_features + cont_features\ntarget_feature = 'target'\n\nnum_bins = int(1 + np.log2(len(train_data)))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'].to_numpy(),bins=num_bins,labels=False)\nbins = train_data['bins'].to_numpy()\n\ntarget = train_data[target_feature].to_numpy()\ntrain_data = train_data[all_features].to_numpy()\ntest_data = test_data[all_features].to_numpy()\n\nct = ColumnTransformer([('onehot',OrdinalEncoder(),slice(len(cat_features))),\n                        ('at',QuantileTransformer(),slice(len(cat_features),\n                        len(cat_features)+len(cont_features)))])\n\ntrain_data = ct.fit_transform(train_data)\ntest_data = ct.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LGBM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"nfolds = 5\nseed = 0\n\nparams = {'reg_alpha': 6.147694913504962,\n 'reg_lambda': 0.002457826062076097,\n 'colsample_bytree': 0.3,\n 'subsample': 0.8,\n 'learning_rate': 0.001,\n 'max_depth': 20,\n 'num_leaves': 111,\n 'min_child_samples': 285,\n'categorical_features': list(range(len(cat_features))),\n 'random_state': 48,\n'verbose':-1,\n 'n_estimators': 10000,\n 'metric': 'rmse',\n 'cat_smooth': 39}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_preds = np.zeros(test_data.shape[0])\n\nkfold = StratifiedKFold(n_splits=nfolds,random_state=seed)\nlgbm_scores = list()\nfor k, (train_idx, valid_idx) in enumerate(kfold.split(X=train_data,y=bins)):\n    lgb_train = lgb.Dataset(train_data[train_idx],target[train_idx])\n    lgb_valid = lgb.Dataset(train_data[valid_idx],target[valid_idx],reference=lgb_train)\n    lgb_model = lgb.train(params,\n                      lgb_train, \n                      valid_sets=[lgb_train,lgb_valid],\n                      verbose_eval=0,\n                      early_stopping_rounds=800,\n                      )\n    rmse = rmse_score(target[valid_idx],lgb_model.predict(train_data[valid_idx]))\n    print(f\"fold {k}: rmse:{rmse}\")\n    lgbm_scores.append(rmse)\n    lgbm_preds += lgb_model.predict(test_data)/nfolds\n#     break\n\nprint(\"mean rmse score\",np.mean(lgbm_scores))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_feature_importance(model,features):\n    feature_importance = pd.DataFrame({\"feature\":features,\"importance\":model.feature_importance(importance_type='gain')})\n    feature_importance = feature_importance.sort_values(by='importance',ascending=False)\n    \n    plt.figure(figsize=(10,10))\n    plt.subplot(211)\n    sns.barplot(data=feature_importance,x='importance',y='feature')\n    \n    for idx, v in enumerate(feature_importance.importance):\n            plt.text(v, idx, \"  {:.2e}\".format(v))\n    \n    feature_importance = pd.DataFrame({\"feature\":features,\"importance\":model.feature_importance(importance_type='split')})\n    feature_importance = feature_importance.sort_values(by='importance',ascending=False)\n    \n    plt.subplot(212)\n    sns.barplot(data=feature_importance,x='importance',y='feature')\n    \n    for idx, v in enumerate(feature_importance.importance):\n        plt.text(v, idx, \"  {:.2e}\".format(v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(lgb_model,all_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Catboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'l2_leaf_reg': 0.02247766515106271, \n          'max_bin': 364,\n          'subsample': 0.6708650091202213,\n          'learning_rate': 0.0010290546311954876,\n          'max_depth': 10,\n          'verbose':0,\n          'random_state': seed, \n          'min_data_in_leaf': 300,\n          'loss_function': 'RMSE',\n          'n_estimators':  1600000,\n          'rsm':0.5,\n          'early_stopping_rounds':800}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_preds = np.zeros(test_data.shape[0])\nkfold = StratifiedKFold(n_splits=nfolds, random_state =seed)\ncat_scores = list()\nfor train_idx, valid_idx in kfold.split(X=train_data,y=bins):\n    cat_train = Pool(train_data[train_idx],target[train_idx])\n    cat_valid = Pool(train_data[valid_idx],target[valid_idx])\n    \n    cat_model = CatBoost(params)\n    cat_model.fit(cat_train,eval_set=cat_valid)\n    score = rmse_score(target[valid_idx],cat_model.predict(train_data[valid_idx]))\n    print(f\"fold: {k}, score: {score}\")\n    cat_scores.append(score)\n    cat_preds += cat_model.predict(test_data)/nfolds\n    \nprint('mean rmse score:',np.mean(cat_scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## correlation matrix"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"predictions = pd.DataFrame({\"lgbm\":lgbm_preds,'catboost':cat_preds})\nplt.figure(figsize=(7,7))\nsns.heatmap(predictions.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.target = (lgbm_preds.ravel() + cat_preds.ravel())/2\nsample.to_csv(\"submission.csv\",index=False)\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(131)\nsns.distplot(sample.target)\nplt.title(\"test-target distribution\")\nplt.subplot(132)\nsns.distplot(target)\nplt.title(\"train-target distribution\")\nplt.subplot(133)\nsns.distplot(sample.target.to_numpy(),label='test')\nsns.distplot(target,label='target')\nplt.legend()\nplt.title(\"train and test target distribution\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}