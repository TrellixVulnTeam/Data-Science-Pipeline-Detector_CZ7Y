{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>TabularPlaygroundRegressor Feb2021</center>\n<img src= \"https://assets.thesmartcube.com/smartcube/app/uploads/2020/10/shutterstock_image-12.jpg\" height=\"200\" align=\"center\"/>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<a id=\"Table-Of-Contents\"></a>\n# Table Of Contents\n* [Table Of Contents](#Table-Of-Contents)\n* [Introduction](#Introduction)\n* [Importing Libraries](#Importing-Libraries)\n* [Task Details](#Task-Details)\n* [Read in Data](#Read-in-Data)\n    - [Train.csv](#Train.csv)\n    - [Test.csv](#Test.csv)\n    - [Notes](#Notes)\n* [Data Visualization](#Data-Visualization)\n    - [Categorical Features](#Categorical-Features)\n    - [Continuous Features](#Continuous-Features)\n    - [Target](#Target)\n* [Preprocessing Data](#Preprocessing-Data)\n    - [Label Encoding](#Label-Encoding)\n    - [Train-Test Split](#Train-Test-Split)\n* [Initial Models](#Initial-Models)\n* [Random Firest  Regressor](#Random-Forest-Regressor)\n    - [RF Cross Validation](#RF-Cross-Validation)\n* [LightGBM Regressor](#LightGBM-Regressor)\n    - [Bayesian Optimization](#Bayesian-Optimization)\n    - [Tuning LightGBM](#Tuning-LightGBM)\n* [Prediction for Test Data](#Prediction-for-Test-Data)\n* [Conclusion](#Conclusion)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Introduction\"></a>\n# Introduction\nThis is my second competition notebook on Kaggle. I hope to learn more about working with tabular data and I hope anyone who reads this learns more as well! I will be using various machine learning techniques such as LightGBM, Random Forest, Support Vector Machine, and XGBoost. If you have any questions or comments please leave below! As always leave a upvote as well!  "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Importing-Libraries\"></a>\n# Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Imports\n\n# Basic Imports \nimport numpy as np\nimport pandas as pd\n\n# Plotting \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n%matplotlib inline\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\n# Metrics \nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# ML Models\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor \nimport xgboost as xg \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import svm\n\n# Model Tuning \nfrom bayes_opt import BayesianOptimization\n\n# Feature Importance \nimport shap\n\n# Ignore Warnings \nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Task-Details\"></a>\n# Task Detail \n\n## Goal\nFor this competition, you will be predicting a continuous **target** based on a number of feature columns given in the data. All of the feature columns, **cat0** - **cat9** are **categorical**, and the feature columns **cont0** - **cont13** are **continuous**.\n\n## Metric\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n\nwhere  is the predicted value,  is the original value, and  is the number of rows in the test data."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id=\"Read-in-Data\"></a>\n# Read in Data"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Train.csv\"></a>\n## Train.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Read train.csv\ntrain_csv = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\n\n# Initial glance at train.csv\nprint(train_csv.info(verbose = True,show_counts=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Test.csv\"></a>\n## Test.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Read train.csv\ntest_csv = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\n\n# Initial glance at train.csv\nprint(test_csv.info(verbose = True,show_counts=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Notes\"></a>\n## Notes\n\nTrain.csv and Test.csv have no missing values so imputation is not needed. Since there aren't many features in this dataset I can do a quick explanatory data analysis on the features and target."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Data-Visualization\"></a>\n# Data Visualization "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Categorical-Features\"></a>\n## Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% PlotMultiplePie \n# Input: df = Pandas dataframe, categorical_features = list of features , dropna = boolean variable to use NaN or not\n# Output: prints multiple px.pie() \n\ndef PlotMultiplePie(df,categorical_features = None,dropna = False):\n    # set a threshold of 30 unique variables, more than 50 can lead to ugly pie charts \n    threshold = 30\n    \n    # if user did not set categorical_features \n    if categorical_features == None: \n        categorical_features = df.select_dtypes(['object','category']).columns.to_list()\n        \n    print(\"The Categorical Features are:\",categorical_features)\n    \n    # loop through the list of categorical_features \n    for cat_feature in categorical_features: \n        num_unique = df[cat_feature].nunique(dropna = dropna)\n        num_missing = df[cat_feature].isna().sum()\n        # prints pie chart and info if unique values below threshold \n        if num_unique <= threshold:\n            print('Pie Chart for: ', cat_feature)\n            print('Number of Unique Values: ', num_unique)\n            print('Number of Missing Values: ', num_missing)\n            fig = px.pie(df[cat_feature].value_counts(dropna = dropna), values=cat_feature, \n                 names = df[cat_feature].value_counts(dropna = dropna).index,title = cat_feature,template='ggplot2')\n            fig.show()\n        else: \n            print('Pie Chart for ',cat_feature,' is unavailable due high number of Unique Values ')\n            print('Number of Unique Values: ', num_unique)\n            print('Number of Missing Values: ', num_missing)\n            print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Use PlotMultiplePie to see the distribution of the categorical variables \nPlotMultiplePie(train_csv.drop(\"id\",axis = \"columns\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Continuous-Features\"></a>\n## Continuous Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Print the continous features in the dataset \ncontinous_features = train_csv.drop([\"id\",\"target\"],axis = \"columns\").select_dtypes(['float64']).columns.to_list()\n\nfor cont_feature in continous_features: \n    plt.figure()\n    plt.title(cont_feature)\n    ax = sns.histplot(train_csv[cont_feature])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Target\"></a>\n## Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.title(\"target\")\nax = sns.histplot(train_csv[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Preprocessing-Data\"></a>\n# Preprocessing Data\nBecause Train.csv and Test.csv have no missing data imputation is not needed.  \nLabel encoding is still require as this dataset has categorical features "},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the 'id' for Train and Test \ntrain_csv_id = train_csv['id'].to_list()\ntest_csv_id = test_csv['id'].to_list()\n\n# Seperate train_clean into target and features \ny = train_csv['target']\nX_train_clean = train_csv.drop('target',axis = 'columns')\n\n# Save the index for X_train_clean \nX_train_clean_index = X_train_clean.index.to_list()\n\n# Row bind train.csv features with test.csv features \n# this makes it easier to apply label encoding onto the entire dataset \nX_total = X_train_clean.append(test_csv,ignore_index = True)\n\n# save the index for test.csv \nX_test_clean_index = np.setdiff1d(X_total.index.to_list() ,X_train_clean_index) \n\n# drop id from X_total\nX_total = X_total.drop('id',axis = 'columns')\n\nX_total.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Label-Encoding.csv\"></a>\n## Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% MultiColumnLabelEncoder\n# Code snipet found on Stack Exchange \n# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n# from sklearn.preprocessing import LabelEncoder\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                # convert float NaN --> string NaN\n                output[col] = output[col].fillna('NaN')\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n\n# store the catagorical features names as a list      \ncat_features = X_total.select_dtypes(['object']).columns.to_list()\n\n# use MultiColumnLabelEncoder to apply LabelEncoding on cat_features \n# uses NaN as a value , no imputation will be used for missing data\nX_total_encoded = MultiColumnLabelEncoder(columns = cat_features).fit_transform(X_total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##% Split X_total_encoded \nX_train_clean_encoded = X_total_encoded.iloc[X_train_clean_index, :]\nX_test_clean_encoded = X_total_encoded.iloc[X_test_clean_index, :].reset_index(drop = True) \nX_train_clean_encoded.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##% Before and After LabelEncoding for train.csv \ndisplay(X_train_clean.head().drop(\"id\",axis = 'columns'))\ndisplay(X_train_clean_encoded.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##% Before and After LabelEncoding for test.csv \ndisplay(test_csv.head().drop(\"id\",axis = 'columns'))\ndisplay(X_test_clean_encoded.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"#Train-Test-Split\"></a>\n# Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create test and train set 80-20\n#%%  train-test stratified split using a 80-20 split\ntrain_X, valid_X, train_y, valid_y = train_test_split(X_train_clean_encoded, y, shuffle = True, test_size=0.2, random_state=0)\n\ntrain_X.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Initial Models\"></a>\n# Initial Models\nI applied different machine learning algorthims to test which model perform better on this dataset. I've listed below various machine learning techniques applied in this section.\n \n1. RandomForest\n2. LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"##% evaluateRegressor\n# from sklearn.metrics import mean_squared_error, mean_absolute_error\ndef evaluateRegressor(true,predicted,message):\n    MSE = mean_squared_error(true,predicted,squared = True)\n    MAE = mean_absolute_error(true,predicted)\n    RMSE = mean_squared_error(true,predicted,squared = False)\n    print(message)\n    print(\"MSE:\", MSE)\n    print(\"MAE:\", MAE)\n    print(\"RMSE:\", RMSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def PlotPrediction(true,predicted, title = \"Dataset: \"):\n    fig = plt.figure(figsize=(20,20))\n    ax1 = fig.add_subplot(111)\n    ax1.set_title(title + 'True vs Predicted')\n    ax1.scatter(list(range(0,len(true))),true, s=10, c='r', marker=\"o\", label='True')\n    ax1.scatter(list(range(0,len(predicted))), predicted, s=10, c='b', marker=\"o\", label='Predicted')\n    plt.legend(loc='upper right');\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#% Initial Models\n# from sklearn.ensemble import RandomForestRegressor\n# import lightgbm as lgb\n\nRFReg = RandomForestRegressor(n_estimators = 10, criterion = \"mse\", max_depth = 10, n_jobs = -1,random_state = 0).fit(train_X, train_y)\nLGBMReg = lgb.LGBMRegressor(max_depth = 10,random_state=0).fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# % Model Metrics\n\nprint(\"Random Forest Regressor\") \npredicted_train_y = RFReg.predict(train_X)\nevaluateRegressor(train_y,predicted_train_y,\"    Training Set\")\npredicted_valid_y = RFReg.predict(valid_X)\nevaluateRegressor(valid_y,predicted_valid_y,\"    Test Set\")\nprint(\"\\n\")\n\nprint(\"LightGBM Regressor\") \npredicted_train_y = LGBMReg.predict(train_X)\nevaluateRegressor(train_y,predicted_train_y,\"    Training Set\")\npredicted_valid_y = LGBMReg.predict(valid_X)\nevaluateRegressor(valid_y,predicted_valid_y,\"    Test Set\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Random-Forest-Regressor\"></a>\n# Random Forest Regressor\nThe model can be improved by using cross validation. I used 5-fold cross validation. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"RF-Cross-Validation\"></a>\n## RF Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation using Random Forest\nfrom sklearn.model_selection import KFold\n\nparam_rf = {'n_estimators': 20, \n            'criterion': 'mse', \n            'max_depth':100,\n            'n_jobs' : -1,\n            'random_state' : 0}\n\ndef K_Fold_RandomForest(X_train,y_train, params_set, num_folds = 5):\n    models = []\n    folds = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n\n    y_preds = np.zeros_like(y_train, dtype=np.float64)\n    feature_importance_df = pd.DataFrame()\n\n        # 5 times \n    for n_fold, (train_idx, valid_idx) in enumerate (folds.split(X_train, y_train)):\n        train_X, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        valid_X, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n\n        CV_RF = RandomForestRegressor(**params_set).fit(train_X, train_y)\n        models.append(CV_RF)\n        \n    for num in range(0,len(models)): \n        print(f\"     model {num}\")\n        print(\"Train set RMSE:\", mean_squared_error(train_y,models[num].predict(train_X),squared = False))\n        print(\" Test set RMSE:\", mean_squared_error(valid_y,models[num].predict(valid_X),squared = False))\n        print(\"\\n\")\n    return models\n\nrf_models = K_Fold_RandomForest(X_train_clean_encoded,y,param_rf,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict y_prds using models from crossvalidation \ndef predict_cv(models_cv,X):\n    y_preds = np.zeros(shape = X.shape[0])\n    for model in models_cv:\n        y_preds += model.predict(X)\n        \n    return y_preds/len(models_cv)\npredicted_y = predict_cv(rf_models,X_train_clean_encoded)\n# evalute model using the entire dataset from Train.csv\nevaluateRegressor(y,predicted_y,\"Train.csv\")\nPlotPrediction(y[0:5000],predicted_y[0:5000], title = \"Train.csv: \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"LightGBM-Regressor\"></a>\n# LightGBM Regressor\nthe LightGBM model can be imporved by applying cross validation as well. I also used parameter tuning to obtain a better model. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Bayesian-Optimization\"></a>\n## Bayesian Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"##% Parameter Tuning for LightGBM\n# store the catagorical features names as a list      \ncat_features = X_train_clean_encoded.select_dtypes(['object']).columns.to_list()\n\n# https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9\n# from lightgbm import LGBMRegressor \n# from bayes_opt import BayesianOptimization\ndef search_best_param(X,y,cat_features):\n    \n    trainXY = lgb.Dataset(data=X, label=y,categorical_feature = cat_features,free_raw_data=False)\n    # define the lightGBM cross validation\n    def lightGBM_CV(max_depth, num_leaves, n_estimators, learning_rate, subsample, colsample_bytree, \n                lambda_l1, lambda_l2, min_child_weight):\n    \n        params = {'boosting_type': 'gbdt', 'objective': 'regression', 'metric':'rmse', 'verbose': -1,\n                  'early_stopping_round':100}\n        \n        params['max_depth'] = int(round(max_depth))\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params[\"n_estimators\"] = int(round(n_estimators))\n        params['learning_rate'] = learning_rate\n        params['subsample'] = subsample\n        params['colsample_bytree'] = colsample_bytree\n        params['lambda_l1'] = max(lambda_l1, 0)\n        params['lambda_l2'] = max(lambda_l2, 0)\n        params['min_child_weight'] = min_child_weight\n    \n        score = lgb.cv(params, trainXY, nfold=5, seed=1, stratified=False, verbose_eval =False, metrics=['rmse'])\n\n        return -np.min(score['rmse-mean']) # min or max can change best_param\n\n    # use bayesian optimization to search for the best hyper-parameter combination\n    # https://github.com/fmfn/BayesianOptimization/blob/master/bayes_opt/bayesian_optimization.pyta\n    lightGBM_Bo = BayesianOptimization(lightGBM_CV, \n                                      {\n                                          'max_depth': (5, 50),\n                                          'num_leaves': (20, 100),\n                                          'n_estimators': (50, 1000),\n                                          'learning_rate': (0.01, 0.3),\n                                          'subsample': (0.7, 0.8),\n                                          'colsample_bytree' :(0.5, 0.99),\n                                          'lambda_l1': (0, 5),\n                                          'lambda_l2': (0, 3),\n                                          'min_child_weight': (2, 50) \n                                      },\n                                       random_state = 1,\n                                       verbose = -1\n                                      )\n    np.random.seed(1)\n    \n    lightGBM_Bo.maximize(init_points=5, n_iter=25) # 20 combinations \n    \n    params_set = lightGBM_Bo.max['params']\n    \n    # get the params of the maximum target     \n    max_target = -np.inf\n    for i in lightGBM_Bo.res: # loop thru all the residuals \n        if i['target'] > max_target:\n            params_set = i['params']\n            max_target = i['target']\n    \n    params_set.update({'verbose': -1})\n    params_set.update({'metric': 'rmse'})\n    params_set.update({'boosting_type': 'gbdt'})\n    params_set.update({'objective': 'regression'})\n    \n    params_set['max_depth'] = int(round(params_set['max_depth']))\n    params_set['num_leaves'] = int(round(params_set['num_leaves']))\n    params_set['n_estimators'] = int(round(params_set['n_estimators']))\n    params_set['seed'] = 1 #set seed\n    \n    return params_set\n\nbest_params = search_best_param(X_train_clean_encoded,y,cat_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print best_params\nfor key, value in best_params.items():\n    print(key, ' : ', value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"LightGBM-Cross-Validation\"></a>\n## LightGBM Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def K_Fold_LightGBM(X_train, y_train , cat_features, params_set, num_folds = 5):\n    num = 0\n    models = []\n    folds = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n\n        # 5 times \n    for n_fold, (train_idx, valid_idx) in enumerate (folds.split(X_train, y_train)):\n        print(f\"     model{num}\")\n        train_X, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        valid_X, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n        \n        train_data=lgb.Dataset(train_X,label=train_y, categorical_feature = cat_features,free_raw_data=False)\n        valid_data=lgb.Dataset(valid_X,label=valid_y, categorical_feature = cat_features,free_raw_data=False)\n        \n        CV_LGBM = lgb.train(params_set,\n                 train_data,\n                 num_boost_round = 2500,\n                 valid_sets = valid_data,\n                 early_stopping_rounds = 100,\n                 verbose_eval = 50\n                 )\n        # increase early_stopping_rounds can lead to overfitting \n        models.append(CV_LGBM)\n        \n        print(\"Train set RMSE:\", mean_squared_error(train_y,models[num].predict(train_X),squared = False))\n        print(\" Test set RMSE:\", mean_squared_error(valid_y,models[num].predict(valid_X),squared = False))\n        print(\"\\n\")\n        num = num + 1\n        \n    return models\n\nlgbm_models = K_Fold_LightGBM(X_train_clean_encoded,y,cat_features,best_params,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evalute model using the entire dataset from Train.csv\npredicted_y = predict_cv(lgbm_models,X_train_clean_encoded)\nevaluateRegressor(y,predicted_y,\"Train.csv\")\nPlotPrediction(y[0:5000],predicted_y[0:5000], title = \"Train.csv: \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Prediction-for-Test.csv\"></a>\n# Prediction for Test.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for Test.csv\npredictLGBM = predict_cv(rf_models,X_test_clean_encoded) \npredictRF = predict_cv(lgbm_models,X_test_clean_encoded)\n\nsubmissionLGBM = pd.DataFrame({'id':test_csv_id,'target':predictLGBM})\nsubmissionRF = pd.DataFrame({'id':test_csv_id,'target':predictRF})\n\ndisplay(submissionLGBM.head())\ndisplay(submissionRF.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#% Submit Predictions \nsubmissionLGBM.to_csv('submissionCV_LGBM4.csv',index=False)\nsubmissionRF.to_csv('submissionCV_RF4.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Conclusion\"></a>\n<a id=\"Conclusion\"></a>\n# Conclusion\n\n**Conclusion**\n* Cross validation is useful in getting a better model and to lessen overfitting.   \n\n**Challenges**\n* The dataset was rather large which led to long computation time.\n* Although I used various machine learning algorithims, I wasn't able to improve on score much.    \n\n**Closing Remarks**  \n* Please comment and like the notebook if it of use to you! Have a wonderful year! \n\n**Other Notebooks** \n* [https://www.kaggle.com/josephchan524/hranalytics-lightgbm-classifier-auc-80](https://www.kaggle.com/josephchan524/hranalytics-lightgbm-classifier-auc-80)\n* [https://www.kaggle.com/josephchan524/bankchurnersclassifier-recall-97-accuracy-95](https://www.kaggle.com/josephchan524/bankchurnersclassifier-recall-97-accuracy-95)\n\n2-7-2020\nJoseph Chan "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}