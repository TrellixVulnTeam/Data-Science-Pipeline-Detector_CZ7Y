{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nimport collections\nimport itertools\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nfrom sklearn import model_selection, linear_model, metrics\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = pathlib.Path(\"../input/tabular-playground-series-feb-2021\")\nlist(data_folder.iterdir())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filepath = data_folder / \"train.csv\"\ntest_filepath = data_folder / \"test.csv\"\nsubmission_filepath = data_folder / \"sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(train_filepath)\ntest_df = pd.read_csv(test_filepath)\n\nprint(f\"Total train feats: {len(train_df.columns)}, Features names: {list(train_df.columns)}\\n\")\nprint(f\"Total test feats: {len(test_df.columns)}, Features names: {list(test_df.columns)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic aggreagate stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualise data"},{"metadata":{},"cell_type":"markdown","source":"#### Feature distributions"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\n\naxes = fig.subplots(7, 4).ravel()\n\nfor i, column in enumerate(train_df.columns):\n    if \"cont\" in column:\n        x_pos = np.linspace(0, 1, 100)\n        kde = stats.gaussian_kde(train_df.loc[:, column].values)(x_pos)\n\n        axis = axes[i]\n        axis.plot(x_pos, kde, color=\"b\", linewidth=1.5)\n        axis.fill_between(x_pos, kde, color=\"b\", alpha=0.5)\n        \n        axis.set_title(f\"Feature: {column}\")\n        axis.set_xlabel(f\"x\")\n        axis.set_ylabel(f\"kde\")\n    if \"cat\" in column:\n        value_counts = train_df.loc[:, column].value_counts().to_dict()\n        labels, count = value_counts.keys(), value_counts.values()\n        \n        axis = axes[i]\n        axis.bar(labels, count)\n        \n        axis.set_xticks(range(len(labels)))\n        axis.set_xticklabels(labels, rotation=-10)\n        axis.set_title(f\"Feature: {column}\")\n        axis.set_xlabel(\"Categories\")\n        axis.set_ylabel(\"count\")\n    \nfig.suptitle(\"Feature distributions\")\nfig.show()\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a lot of under-represented categories in the data. Hopefully, the ML algorithm will learn the difference without us interfering alot."},{"metadata":{},"cell_type":"markdown","source":"### Correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr = train_df.drop([\"id\"], axis=1).corr()\nfor x_idx, y_idx in itertools.product(range(len(df_corr.index)), range(len(df_corr.columns))):\n    if x_idx <= y_idx:\n        df_corr.loc[df_corr.index[x_idx], df_corr.columns[y_idx]] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\nax = fig.add_subplot(111)\n\nimg = ax.imshow(df_corr.values, cmap=\"plasma\")\nfig.colorbar(img, ax=ax)\n\nax.set_title(\"Continuous feature correlations\")\nax.set_xlabel(\"continuous features\")\nax.set_ylabel(\"continuous features\")\n\nax.set_xticks(range(len(df_corr.index)))\nax.set_yticks(range(len(df_corr.columns)))\n\nax.set_xticklabels(df_corr.index, rotation=20)\nax.set_yticklabels(df_corr.columns, rotation=20)\n\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the data is not highly correlated. We can safely move onto training the regressor, without much feature engineerng dedicated towards reducing the redundancy of data."},{"metadata":{},"cell_type":"markdown","source":"## Transform features/ encode categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encoder(train_df, test_df):\n    \"\"\"\n    Function used for label encoding. Inspiried from: https://www.kaggle.com/rizdelhi/tabular-playground-competition-feb-21#Read-in-the-data-files\n    \"\"\"\n    for column in train_df.columns:\n        if \"cat\" in column:\n            lbl = LabelEncoder()\n            lbl.fit(np.hstack((train_df.loc[:, column].values, test_df.loc[:, column].values)))\n\n            train_df.loc[:, column] = lbl.transform(train_df.loc[:, column].values)\n            test_df.loc[:, column] = lbl.transform(test_df.loc[:, column].values)\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = label_encoder(train_df, test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train a base linear regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train = train_df.drop([\"id\", \"target\"], axis=1).values, train_df.loc[:, \"target\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = linear_model.LinearRegression()\nreg.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = reg.predict(test_df.drop([\"id\"], axis=1))\ndf_submission = pd.read_csv(submission_filepath)\ndf_submission.loc[:, \"target\"] = y_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_filename = submission_filepath.name\ndf_submission.to_csv(submission_filename, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}