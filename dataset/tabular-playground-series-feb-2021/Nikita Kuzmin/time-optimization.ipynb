{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Добрый день, дорогие друзья!\n\nКод для статьи портала [NTA](https:\\\\newtechaudit.ru).   \nОптимизация рутинных задач в машинном обучении.  \n\nМы обучим три модели - LGBM с ручной настройкой параметров, градиентный буст с оптимизированными параметрами с применением optuna и результат работы фреймворка h2o.automl. Алгоритм работы featuretools представлен в качестве базового примера автоматизации инжиниринга новых фич.","metadata":{}},{"cell_type":"markdown","source":"## Подготовка библиотек и данных","metadata":{}},{"cell_type":"markdown","source":"Загружаем классические библиотеки и данные","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport math, random\n\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\n\npd.set_option('display.max_columns', 100)\n\nfrom lightgbm import LGBMRegressor\n\nSEED = 47","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/tabular-playground-series-jan-2021/'\n\ndf_train = pd.read_csv(PATH + '/train.csv')\ndf_test = pd.read_csv(PATH + '/test.csv')\ndf_sub = pd.read_csv(PATH + '/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = df_train['target']\nfeatures = df_train.drop('target', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Featuretools","metadata":{}},{"cell_type":"code","source":"# Загрузка фреймворка\nimport featuretools as ft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создаем новую сущность - EntitySet\n\nes = ft.EntitySet(id = 'data')\nes.entity_from_dataframe(entity_id = 'january', \n                         dataframe = features, \n                         index='id')\n                         #make_index = True, index = 'index') # Эта строка поможет создать новый индекс, при его отсутсвии\n\n# Запускаем создание новых признаков\nfeature_matrix, feature_defs = ft.dfs(entityset = es,                                          # Какой EntiteSet обрабатываем\n                                      target_entity = 'january',                               # Какой датафрейм изменяем\n                                      trans_primitives = ['add_numeric', 'multiply_numeric'],  # Какие фичи создаем\n                                      verbose=1)                                               # Показывать ли прогресс выполнения","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обновленный датайфрем содержит сгенерированные признаки\nfeature_matrix.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Мы не будем обучать модель на полученных данных, так как предполагаем сильную мультиколлениарность. Пример приведен в качестве учебного и для знакомства с фреймворком.","metadata":{}},{"cell_type":"markdown","source":"## Optuna","metadata":{}},{"cell_type":"code","source":"# Подгружаем фреймворк и встроенные средства визуализации результатов\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# В учебном примере некоторые гиперпараметры выключены из пространства поиска с целью ускорения процесса. \n# Для более глубокого подбора, раскомментируйте интересующие строки.\n\ndef objective(trial, data=features, target=target):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n    \n    params = {\n        'metric': 'rmse', \n        'random_state': SEED,\n        'n_estimators': 10000,\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        #'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.35,0.4,0.45,0.5,0.6,0.7,0.75,0.8,0.85]),\n        'subsample': trial.suggest_categorical('subsample', [0.6,0.65,0.7,0.75,0.8,0.85]),\n        'learning_rate': trial.suggest_categorical('learning_rate', \n                                                   [0.005,0.006,0.008,0.01,0.015,0.02,0.03]),\n        #'max_depth': trial.suggest_categorical('max_depth', [-1,10,20]),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 300),\n        #'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        #'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n    }\n    \n    # Создаем и обучаем модель с мониторингом переобучения\n    model = LGBMRegressor(**params)      \n    model.fit(X_train, y_train, eval_set=[(X_test,y_test)], early_stopping_rounds=300, verbose=False)\n    preds = model.predict(X_test)\n    \n    #Смотрим финальную метрику RMSE\n    rmse = mean_squared_error(y_test, preds, squared=False)\n    \n    return rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Посчитаем время оптимизации\n\n# Создаем задание для фреймворка\nstudy = optuna.create_study(direction='minimize')  # Минимизируем ошибку\nstudy.optimize(objective, n_trials=5)              # Количество итераций = 5\n\n# Смотрим на финальные метрики\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best score:', study.best_trial.value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# История оптимизации\nplot_optimization_history(study)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Значимость гиперпараметров при настройке\nplot_param_importances(study)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выводим лучшие гиперпараметры\nstudy.best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создаем словарь с обновленными параметрами, обучаем модель и создаем файл для сабмита. В новый словарь необходимо добавить постоянные значения, такие, как random_state, исходная метрика и количество деревьев.","metadata":{}},{"cell_type":"code","source":"optuna_params = study.best_params\n\noptuna_params['metric'] = 'rmse'\noptuna_params['random_state'] = SEED\noptuna_params['n_estimators'] = 10000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выделяем валидационный сет из обучающего набора данных\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=SEED)\n\n# Создаем и обучаем модель с подобранными гиперпараметрами\nmodel_optuna = LGBMRegressor(**optuna_params)\nmodel_optuna.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=300, verbose=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cоздаем предсказание и файл для сабмита\n\npred_optuna = model_optuna.predict(df_test)\n\ndf_sub['target'] = pred_optuna\ndf_sub.to_csv('submission_optuna.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AutoML","metadata":{}},{"cell_type":"markdown","source":"**В этом разделе мы сравним классический процесс обучения модели и работу automl.**\n\n\nОбучим LGBM с простой ручной настройкой гиперпараметров на сырых данных. В конце сравним этот результат с результатом работы AutoML. Применяем стандартный процесс обучения и предикта без кросс-валидации и отложенных семплов. ","metadata":{}},{"cell_type":"code","source":"# Создаем модель с небольшой ручной настройкой гиперпараметров\n\nmodel_default = LGBMRegressor(n_estimators=10000,\n                      max_depth=-1, \n                      reg_alpha=2,\n                      reg_lambda=1.5,\n                      num_leaves=37,\n                      metric='rmse',\n                      random_state=SEED)\n\n# Обучаем созданную модель с мониторингом переобучения\nmodel_default.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=300, verbose=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cоздаем предсказание и файл для сабмита\n\npred_default = model_default.predict(df_test)\n\ndf_sub['target'] = pred_default\ndf_sub.to_csv('submission_default.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Очередь AutoML","metadata":{}},{"cell_type":"code","source":"# Загружаем фреймворк и устанавливаем максимальный размер используемой оперативной памяти\n\nimport h2o\nprint(h2o.__version__)\n\nfrom h2o.automl import H2OAutoML\n\nh2o.init(max_mem_size='16G')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = h2o.import_file(\"../input/tabular-playground-series-jan-2021/train.csv\")\ntest = h2o.import_file(\"../input/tabular-playground-series-jan-2021/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = test.columns[1:]\ny = 'target'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Запускаем автоматическое обучение на трех моделях\naml = H2OAutoML(max_models=2, \n                seed=SEED, \n                max_runtime_secs=31000)\n\naml.train(x=x, y=y, training_frame=train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Смотрим на лучшие модели\n\nlb = aml.leaderboard\nlb.head(rows=lb.nrows)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Изучаем модель - лидера\n\naml.leader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создаем предсказания и отправляем сабмит\n\npreds = aml.predict(test)\n\ndf_sub['target'] = preds.as_data_frame().values.flatten()\ndf_sub.to_csv('submission_automl.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}