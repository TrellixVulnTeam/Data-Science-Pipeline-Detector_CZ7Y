{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        \n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install catboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(os.path.join(dirname,'train.csv'))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn import preprocessing\nfrom sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.feature_selection import f_regression\nfrom matplotlib import pyplot\nimport tensorflow\ntensorflow.random.set_seed(1)\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.python.keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport xgboost as xg \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import mean_squared_error as MSE \nfrom catboost import CatBoostRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.concat([df_train,pd.get_dummies(df_train.cat0,prefix='cat0')],axis=1)\ndf_train=df_train.drop(['cat0','cat0_B'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat1,prefix='cat1')],axis=1)\ndf_train=df_train.drop(['cat1','cat1_B'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat2,prefix='cat2')],axis=1)\ndf_train=df_train.drop(['cat2','cat2_B'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat3,prefix='cat3')],axis=1)\ndf_train=df_train.drop(['cat3','cat3_D'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat4,prefix='cat4')],axis=1)\ndf_train=df_train.drop(['cat4','cat4_D'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat5,prefix='cat5')],axis=1)\ndf_train=df_train.drop(['cat5','cat5_D'],axis=1)\n#df_train=pd.concat([df_train,pd.get_dummies(df_train.cat6,prefix='cat6')],axis=1)\ndf_train=df_train.drop(['cat6'],axis=1)\n#df_train=df_train.drop(['cat6','cat6_I'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat7,prefix='cat7')],axis=1)\ndf_train=df_train.drop(['cat7','cat7_I'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat8,prefix='cat8')],axis=1)\ndf_train=df_train.drop(['cat8','cat8_G'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat9,prefix='cat9')],axis=1)\ndf_train=df_train.drop(['cat9','cat9_O'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df_train['target'].values\ndf_train=df_train.drop(['target'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df_train.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_columns=np.any(X,axis=0)\nprint(negative_columns,negative_columns.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalizing Input features"},{"metadata":{"trusted":true},"cell_type":"code","source":"names = df_train.iloc[:,1:].columns\nscaler = preprocessing.MinMaxScaler((0,1))\nscaled_df = scaler.fit_transform(df_train.iloc[:,1:])\nscaled_df = pd.DataFrame(scaled_df, columns=names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=scaled_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.decomposition import PCA \n   \npca = PCA(n_components = 20) \npca.fit(X) \nx_pca = pca.transform(X) \n  \nx_pca.shape '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv(os.path.join(dirname,'test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.concat([df_test,pd.get_dummies(df_test.cat0,prefix='cat0')],axis=1)\ndf_test=df_test.drop(['cat0','cat0_B'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat1,prefix='cat1')],axis=1)\ndf_test=df_test.drop(['cat1','cat1_B'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat2,prefix='cat2')],axis=1)\ndf_test=df_test.drop(['cat2','cat2_B'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat3,prefix='cat3')],axis=1)\ndf_test=df_test.drop(['cat3','cat3_D'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat4,prefix='cat4')],axis=1)\ndf_test=df_test.drop(['cat4','cat4_D'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat5,prefix='cat5')],axis=1)\ndf_test=df_test.drop(['cat5','cat5_D'],axis=1)\n#df_test=pd.concat([df_test,pd.get_dummies(df_test.cat6,prefix='cat6')],axis=1)\ndf_test=df_test.drop(['cat6'],axis=1)\n#df_test=df_test.drop(['cat6','cat6_I'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat7,prefix='cat7')],axis=1)\ndf_test=df_test.drop(['cat7','cat7_I'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat8,prefix='cat8')],axis=1)\ndf_test=df_test.drop(['cat8','cat8_G'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat9,prefix='cat9')],axis=1)\ndf_test=df_test.drop(['cat9','cat9_O'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=df_test.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_test_pca = pca.transform(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_=df_test.iloc[:,0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names_test= df_test.iloc[:,1:].columns\nscaled_df_test = scaler.transform(df_test.iloc[:,1:])\nscaled_df_test = pd.DataFrame(scaled_df_test, columns=names_test)\nX_test=scaled_df_test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Selection ( MUTUAL INFORMATION)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef select_features(X_train, y_train, X_test):\n    # configure to select all features\n    fs = SelectKBest(score_func=f_regression, k='all')\n    # learn relationship from training data\n    fs.fit(X_train, y_train)\n    # transform train input data\n    X_train_fs = fs.transform(X_train)\n    # transform test input data\n    X_test_fs = fs.transform(X_test)\n    return X_train_fs, X_test_fs, fs\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape,X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_fs, X_test_fs, fs = select_features(X, y, X_test)\n\nfor i in range(len(fs.scores_)):\n    print('Feature %d: %f' % (i, fs.scores_[i]))\n\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_fs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = xg.XGBRegressor(objective ='reg:linear', \n                  n_estimators = 53, seed = 123) \n  \nxgb.fit(X_train_fs, y) \n  \npred = xgb.predict(X_test_fs) \n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvlist=[]\nfor i in range(pred.shape[0]):\n    csvlist.append([id_[i],pred[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Output=pd.DataFrame(csvlist,columns=['id','target'])\nOutput.to_csv('output_XGB.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CATBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=CatBoostRegressor(iterations=100, depth=10, learning_rate=0.01, loss_function='RMSE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_fs,y ,plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(X_test_fs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvlist=[]\nfor i in range(pred.shape[0]):\n    csvlist.append([id_[i],pred[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Output=pd.DataFrame(csvlist,columns=['id','target'])\nOutput.to_csv('output_CATBOOST.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(53, input_dim=20, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(2670, activation='relu'))\nmodel.add(Dense(1345, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\nearlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\nmcp_save = ModelCheckpoint('model_pca_MLP.h5', save_best_only=True, monitor='val_loss', mode='min')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1, epsilon=1e-4, mode='min')\nhistory_pl = model.fit(X_train_fs,y, batch_size=128, epochs=30, verbose=1, \n                       callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.25 )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(53, input_dim=20, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(2670, activation='relu'))\nmodel.add(Dense(1345, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\nmodel.summary()\nmodel.load_weights('model_pca_MLP.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_fs.shape,X_test_fs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test_fs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.shape,id_.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(predictions[:,0]),list(id_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.shape,id_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvlist=[]\nfor i in range(predictions.shape[0]):\n    csvlist.append([id_[i],predictions[i][0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Output=pd.DataFrame(csvlist,columns=['id','target'])\nOutput.to_csv('output.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}