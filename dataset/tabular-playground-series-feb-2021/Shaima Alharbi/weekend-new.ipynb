{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Weekend Project (TPS)**\n## Machine Learning Section (week 3)\n\n### Group Members:\n* Shaima Alharbi\n* Shaikha AlBilais"},{"metadata":{},"cell_type":"markdown","source":"# **Project Specifications**"},{"metadata":{},"cell_type":"markdown","source":"## TPS Feb 2021\nStarter Notebook\n\n### Deleverables\n1. EDA\n    - What's going on?\n    - Show me the data...\n2. Model\n    - Baseline...\n    - Simple...\n    - Evaluation...\n    - Improvement...\n3. RAPIDS Bonus\n    - Apply RAPIDS ([Starter Notebook](https://www.kaggle.com/tunguz/tps-feb-2021-rapids-starter))\n    - Replace pandas with cuDF & sklearn with cuML\n    \n    \n#### Troubleshooting\n- [Data](https://www.kaggle.com/c/tabular-playground-series-feb-2021/data)\n- [Overview](https://www.kaggle.com/c/tabular-playground-series-feb-2021/overview)\n- [RF Starter Notebook](https://www.kaggle.com/warobson/tps-feb-2021-rf-starter)\n- [ML repo on GitHub](https://github.com/gumdropsteve/intro_to_machine_learning)\n- [Most simple RAPIDS Notebook submission](https://www.kaggle.com/warobson/simple-rapids-live) (Has stuff like `train_test_split()` with cuml..)"},{"metadata":{},"cell_type":"markdown","source":"# **Libraries Importing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cudf\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom cuml.metrics import r2_score\nfrom cuml.metrics import mean_squared_error\nfrom cuml.ensemble import RandomForestRegressor\n\nsns.set_palette('husl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Loading**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = cudf.read_csv(\"/kaggle/input/tabular-playground-series-feb-2021/train.csv\")\ntest = cudf.read_csv(\"/kaggle/input/tabular-playground-series-feb-2021/test.csv\")\nsample_submission = cudf.read_csv('../input/tabular-playground-series-feb-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Data Exploring"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape , test.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(train.isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visulization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train.to_pandas().sample(500))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_sample=train.to_pandas().sample(1000) #visulize only 1000 samples ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(27,25))\nplt.subplot(4, 3 , 1)\ndf_train_sample.cat0.value_counts().plot.pie(explode= (0.05 , 0), autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14},\n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT0');\n\nplt.subplot(4 , 3 , 2)\ndf_train_sample.cat1.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT1');\n\n\nplt.subplot(4 , 3 , 3)\ndf_train_sample.cat2.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT2');\n\nplt.subplot(4 , 3 , 4)\ndf_train_sample.cat3.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT3');\n\nplt.subplot(4, 3 , 5)\ndf_train_sample.cat4.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT4');\n\nplt.subplot(4 , 3 , 6)\ndf_train_sample.cat5.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT5');\n\nplt.subplot(4 , 3 , 7)\ndf_train_sample.cat6.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT6');\n\nplt.subplot(4 , 3 , 8)\ndf_train_sample.cat7.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT7');\n\nplt.subplot(4 , 3 , 9)\ndf_train_sample.cat8.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT8');\n\n\nplt.subplot(4 , 3 , 10)\ndf_train_sample.cat9.value_counts().plot.pie(autopct='%1.1f%%', startangle=45 , textprops={'fontsize': 14} , \n                                  wedgeprops = {\"edgecolor\" : \"black\",'linewidth': 1,'antialiased': True}).set(title = 'CAT9')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About the Above Pie Charts:\n* We noticed that A values are the highest amount in most of the columns among all other values. \n* CAT9 & CAT8 are having large diversities in thier values, especially CAT9 "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.histplot(data=df_train_sample, x=\"target\").set(title = 'Distribution the target');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About the Above Histogram:\n* The distibution of the target show that it's reaching its highest values between 8 and 9.\n* We think that there are some outliers near 4 and 5."},{"metadata":{},"cell_type":"markdown","source":"### Checking for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(train.isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainp = train.to_pandas()\nfig=plt.figure(figsize=(25,11))\ncol=['id','target']\nsns.boxplot(data=trainp.drop(columns=col,axis=1))\nplt.title('Train Outliers Before Cleaning')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"* We want to see the difference after removing the outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"before = len(train)\nprint('Data length before removing the outliers = ', before)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= train[(train['cont0']>train['cont0'].quantile(.05))&\n      (train['cont2']>train['cont2'].quantile(.05))&\n      (train['cont2']<train['cont2'].quantile(.95))&\n      (train['cont6']<train['cont6'].quantile(.95))&\n      (train['cont8']<train['cont8'].quantile(.95))&     \n      (train['target']<train['target'].quantile(.95))&\n      (train['target']>train['target'].quantile(.05))]\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(25,11))\ncol=['id','target']\nsns.boxplot(data=train.to_pandas().drop(columns=col,axis=1))\nplt.title('Train Outliers After Cleaning')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"after = len(train) #after removing outliers \nprint('Data length after removing the outliers = ', after)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About the Above Box Plot:\n* We noticed increasing in the outliers, but we assumed that these became closer after removing the selected outliers."},{"metadata":{},"cell_type":"markdown","source":"## Data Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_pandas().corr() #to know the suitable fetures to be split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Getting the Dummies and Split Data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml.preprocessing import train_test_split\n\nX = train.drop('target', axis=1)\nX = cudf.get_dummies(X)\n\ny = train.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstandrd = StandardScaler()\ncol=X_train.columns\nX_train = standrd.fit_transform(X_train.to_pandas()) # Switching between pandas & rapids\nX_test = standrd.transform(X_test.to_pandas()) # Switching between pandas & rapids\nprint('The scaled data are:')\nX_train,X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Switching between pandas & rapids\nt= pd.DataFrame(X_train)\nX_train=cudf.DataFrame.from_pandas(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Switching between pandas & rapids \nt_test= pd.DataFrame(X_test)\nX_test=cudf.DataFrame.from_pandas(t_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Modeling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline_model(n_preds, pred):\n    return cudf.Series([pred for n in range(n_preds)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline_preds = baseline_model(len(y_test), np.mean(y_train))\nprint('Baseline Predections Are:')\nbaseline_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bl_mse = mean_squared_error(y_true=y_test,y_pred=baseline_preds,squared=False)\nprint('Baseline Mean Squared Error = ', bl_mse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Regressor Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"for n in X_train.columns:\n    X_train[n]=X_train[n].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr =RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr.fit(X_train, y_train)\nprint('Fit completed.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rfr = rfr.predict(X_test)\nprint('Random Forest Regressor Predections Are:')\npred_rfr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_rmse =mean_squared_error(y_true=y_test.astype(np.float64),\n                   y_pred=pred_rfr.astype(np.float64),\n                   squared=False)\nprint('Random Forest Regressor Mean Squared Error = ', rfr_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Switching Between pandas and rapids\nX_train_pandas=X_train.to_pandas()\ny_train_pandas=y_train.to_pandas()\n\n# X_train_tcd=cudf.DataFrame.from_pandas(t)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid SearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n# rfr  = RandomForestRegressor()\n\n# from sklearn.model_selection import GridSearchCV\n# p_grid = {'max_features': ['auto', 'sqrt', 'log2']}\n# grid = GridSearchCV(rfr, p_grid,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid.fit(X_train_pandas, y_train_pandas)\n# print('Fit completed.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best = grid.best_params_\n# print('The best parameters for the model are:', best)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Selection**"},{"metadata":{},"cell_type":"markdown","source":"* We noticed that the Mean Squared Error (MSE) has decreased after removing the outliers and scaling the data.\n* Also, we tried different parametes inside the Random Forest Regressor model to have the best result.\n* MSE Before: around 0.7351\n* MSE After: around 0.7322\n\nHowever,\n* We tried to obtain the GridSearchCV to decrease the MSE of the used model (Random Forest Regressor).\n* The fiiting of the GridSearchCV took so long, and the notebook's CPU became full and bussy.\n* So, we decided to remain on the last result that we came with for the Random Forest Regressor model and with the same parameters that we used."},{"metadata":{},"cell_type":"markdown","source":"# To submit the result in Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# data load\ntrain = cudf.read_csv(\"/kaggle/input/tabular-playground-series-feb-2021/train.csv\")\ntest = cudf.read_csv(\"/kaggle/input/tabular-playground-series-feb-2021/test.csv\")\nsample_submission = cudf.read_csv('../input/tabular-playground-series-feb-2021/sample_submission.csv')\n\n# data prep\nX = train.drop('target', axis=1)\nX = cudf.get_dummies(X)\n\ny = train.target\n\ntest = cudf.get_dummies(test)\ntest['cat6_G'] = 0  # fix lack of Gs in test data\nfor n in X.columns:\n    X[n]=X[n].astype(np.float32)\n# modeling\nrfr = RandomForestRegressor()\nrfr.fit(X,y)\n \nrf_preds =rfr.predict(test)\n\n# save results & submit\nsample_submission['target'] = rf_preds\n\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}