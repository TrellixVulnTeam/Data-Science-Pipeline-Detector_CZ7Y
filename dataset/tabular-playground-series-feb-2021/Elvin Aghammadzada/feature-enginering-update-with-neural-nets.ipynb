{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pandas_profiling import ProfileReport\nfrom lightgbm import LGBMRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nimport datetime\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport gc\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\nsub = pd.read_csv('../input/tabular-playground-series-feb-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = test.columns[1:]\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['target'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = columns[:10]\ncat_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in cat_features:\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])\n    test[feature] = le.transform(test[feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features = test.columns[11:25]\ncont_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nalldata = pd.concat([train[cont_features],test[cont_features]],axis=0)\nalldata.shape\nn=2\n\nmax_cat_values = []\nfor c in cont_features:\n    le = LabelEncoder()\n    x = le.fit_transform(alldata[c].round(n))\n    train[c+'_cat'] = le.transform(train[c].round(n))\n    test[c+'_cat'] = le.transform(test[c].round(n))\n    max_cat_values.append(np.max(x)+1)\n    \nn=1\n\nmax_cat_values3 = []\nfor c in cont_features:\n    le = LabelEncoder()\n    x = le.fit_transform(alldata[c].round(n))\n    train[c+'_cat3'] = le.transform(train[c].round(n))\n    test[c+'_cat3'] = le.transform(test[c].round(n))\n    max_cat_values3.append(np.max(x)+1)\n    \nn=10\n\nmax_cat_values4 = []\nfor c in cont_features:\n    alldata[c] = pd.cut(alldata[c],bins=n,labels=np.arange(n))\n    train[c+'_cat4'] = alldata.iloc[:len(train)][c].astype(\"int32\")\n    test[c+'_cat4'] = alldata.iloc[len(train):][c].astype(\"int32\")\n    max_cat_values4.append(np.max(alldata[c])+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_oof = np.zeros((300000,))\ntest_preds = 0\ntrain_oof.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'reg_alpha': 6.147694913504962,\n 'reg_lambda': 0.002457826062076097,\n 'colsample_bytree': 0.3,\n 'subsample': 0.8,\n 'learning_rate': 0.0005,\n 'max_depth': 20,\n 'num_leaves': 111,\n 'min_child_samples': 285,\n 'random_state': 48,\n 'n_estimators': 320000,\n 'metric': 'rmse',\n 'cat_smooth': 39}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input,Dense,Dropout\nfrom tensorflow.keras import Model\nfrom  tensorflow.keras.regularizers import l2\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,BatchNormalization,Dropout,Embedding,Flatten,Concatenate\nfrom keras import backend as K\nimport tensorflow as tf\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\ndef get_model():\n    inputs = []\n    flatten_layers = []\n    for e, c in enumerate(cont_features):\n        input_c = Input(shape=(1, ), dtype='int32')\n        num_c = max_cat_values[e]\n        embed_c = Embedding(\n            num_c,\n            3,\n        )(input_c)\n        embed_c = Dropout(0.6)(embed_c)\n        flatten_c = Flatten()(embed_c)\n        inputs.append(input_c)\n        flatten_layers.append(flatten_c)\n        \n    flatten_layers2 = []\n    for e, c in enumerate(cont_features):\n        input_c = Input(shape=(1, ), dtype='int32')\n        num_c = max_cat_values3[e]\n        embed_c = Embedding(\n            num_c,\n            12,\n        )(input_c)\n        embed_c = Dropout(0.5)(embed_c)\n        flatten_c = Flatten()(embed_c)\n        inputs.append(input_c)\n        flatten_layers2.append(flatten_c)\n        \n    flatten_layers3 = []\n    for e, c in enumerate(cont_features):\n        input_c = Input(shape=(1, ), dtype='int32')\n        num_c = max_cat_values4[e]\n        embed_c = Embedding(\n            num_c,\n            12,\n        )(input_c)\n        embed_c = Dropout(0.5)(embed_c)\n        flatten_c = Flatten()(embed_c)\n        inputs.append(input_c)\n        flatten_layers3.append(flatten_c)\n\n    input_num = Input(shape=(14,), dtype='float32')\n    inputs.append(input_num)\n    \n    # 1st embeddings with main continous features.\n    flatten_layers.append(input_num) # This line is important. I'm concatenating original features with the first type of categorical features' embeddings.\n    flatten = Concatenate()(flatten_layers)\n    x = Dense(1024, activation='relu',bias_initializer=\"normal\",kernel_regularizer=regularizers.l2(0.0001),\n              bias_regularizer=regularizers.l2(0.00000),\n             activity_regularizer = regularizers.l2(0.0001))(flatten) \n    x = Dropout(0.)(x)\n    x = Dense(1024, activation='relu',kernel_initializer='normal')(x) \n    \n    # 2nd embeddings.\n    flatten2 = Concatenate()(flatten_layers2)\n    x2 = Dense(2048, activation='relu',bias_initializer=\"normal\")(flatten2) \n    x2 = Dense(2048, activation='relu',kernel_initializer='normal')(x2) # 1500 original\n    \n    # 3rd embeddings.\n    flatten3 = Concatenate()(flatten_layers3)\n    x3 = Dense(2048, activation='relu',bias_initializer=\"normal\")(flatten3) \n    x3 = Dense(2048, activation='relu',kernel_initializer='normal')(x3)\n    \n    \n    x = Concatenate()([x,x2,x3]) # Concating all there outputs.\n  \n    \n    outputs = Dense(1, activation='linear')(x)\n    model = Model(inputs=inputs, outputs=outputs)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n    model.compile(loss=\"mse\", optimizer=opt)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else: \n        return lr * 0.95","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [col for col in train.columns if col not in [\"target\",\"id\",\"preds\",\"scaled_target\",\"lgbm_preds\"]][-14:]\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = X.abs()\ny = train[\"target\"]\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\noof = np.zeros(len(train))\nscore_list = []\nfold = 1\ntest_preds = []\n\n    \nfor train_index, test_index in kf.split(train):\n    X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n\n    # Preparing model inputs.\n    X_train_list=[]\n    X_val_list = []\n    test_list = []\n    for col in cont_features:\n        X_train_list.append(X_train[col+'_cat'].values)\n        X_val_list.append(X_val[col+'_cat'].values)\n        test_list.append(test[col+'_cat'].values)\n    for col in cont_features:\n        X_train_list.append(X_train[col+'_cat3'].values)\n        X_val_list.append(X_val[col+'_cat3'].values)\n        test_list.append(test[col+'_cat3'].values)\n    for col in cont_features:\n        X_train_list.append(X_train[col+'_cat4'].values)\n        X_val_list.append(X_val[col+'_cat4'].values)\n        test_list.append(test[col+'_cat4'].values)\n        \n    X_train_list.append(X_train[cont_features].values)\n    X_val_list.append(X_val[cont_features].values)\n    test_list.append(test[cont_features].values)\n\n    y_pred_list = []\n\n    # Callbacks\n    estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n    \n    model = get_model()\n    history = model.fit(X_train_list, y_train,validation_data=(X_val_list,y_val), \n              callbacks=[lr_callback,estop], epochs=10, batch_size=1024, verbose=1)\n   \n   \n        \n    y_pred_list.append(model.predict(X_val_list).ravel())\n    oof[test_index] = np.mean(y_pred_list,axis=0)\n    score = np.sqrt(mean_squared_error(y_val, oof[test_index]))\n    score_list.append(score)\n    print(f\"RMSE Fold-{fold} : {score}\")\n    \n    test_preds.append(model.predict(test_list).ravel())\n    \n    fold+=1\n\nnp.mean(score_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.mean(score_list))\nscore_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"4_preds\"] = oof\ntest[\"4_preds\"] = np.mean(test_preds,axis=0)\nnp.sqrt(mean_squared_error(train[\"target\"], train[\"4_preds\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"id\",\"4_preds\"]].to_csv(\"nn_preds_train.csv\",index=False)\ntest[[\"id\",\"4_preds\"]].to_csv(\"nn_preds_test.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = train.rename(columns={'4_preds': 'target'})\n# train\ntest = test.rename(columns={'4_preds': 'target'})\n# train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"id\",\"target\"]].to_csv(\"nn_preds_train.csv\",index=False)\ntest[[\"id\",\"target\"]].to_csv(\"nn_preds_test.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_FOLDS = 1\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        \n        model = LGBMRegressor(**params)\n        model.fit(train_df, train_target, eval_set=[(val_df,val_target)],early_stopping_rounds=1600,verbose=False)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(test[columns])\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test/NUM_FOLDS\n        \n        print(mean_squared_error(temp_oof, val_target, squared=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(train_oof, target, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof', train_oof)\nnp.save('test_preds', test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = test_preds\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}