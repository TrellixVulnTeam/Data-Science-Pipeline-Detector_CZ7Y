{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we will be using Optuna to fine tune our hyperparameters for our LightGBM model.\n\nDataset: https://www.kaggle.com/c/tabular-playground-series-feb-2021"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, KFold\nimport lightgbm as lgb\nimport optuna\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/tabular-playground-series-feb-2021/'\nSEED = 25\ndf = pd.read_csv(PATH + 'train.csv')\ndf.drop('id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in df.columns if x not in 'target']\ntarget = ['target']\n\ncont_features = [x for x in features if x.find('cont') != -1]\ncat_features = [x for x in features if x.find('cat') != -1]\n\ndf[cat_features] = df[cat_features].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(PATH + 'test.csv')\nids = test_df['id']\ntest_df.drop('id', axis=1, inplace=True)\ntest_df[cat_features] = test_df[cat_features].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"Target Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.histplot(x='target', data=df, kde=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a bimodal distribution in our target."},{"metadata":{},"cell_type":"markdown","source":"Distributions"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(20,10))\nfor i, row in enumerate(ax):\n    for j, col in enumerate(row):\n        sns.histplot(x=cat_features[i*5+j], data=df, ax=col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see some very imbalanced data in some categorical features like 'cat4', 'cat6', 'cat7'."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(20,15))\nfor i, row in enumerate(ax):\n    for j, col in enumerate(row):\n        try:\n            sns.histplot(x=cont_features[i*4+j], data=df, ax=col)\n        except IndexError:\n            continue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see several multimodal distributions in our continuous features."},{"metadata":{},"cell_type":"markdown","source":"Continuous Features x Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(20,20))\nfor i, row in enumerate(ax):\n    for j, col in enumerate(row):\n        try:\n            sns.scatterplot(x=cont_features[i*4+j], y='target', data=df, ax=col)\n        except IndexError:\n            continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(df.corr(), annot=True, square=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's no linear correlation between our target and continous features. Let's try mutual info correlation..."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mi_corr = mutual_info_regression(df[cont_features].values, df['target'].values, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(12,4))\nplt.title('Mutual Information Correlation')\nsns.barplot(x=cont_features, y=mi_corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = df.sample(frac=0.8, random_state=SEED)[features]\nx_val = df.drop(x_train.index, axis=0)[features]\ny_train = df.iloc[x_train.index][target]\ny_val = df.drop(x_train.index, axis=0)[target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"def objective(trial):  \n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'verbose': -1,\n        'boosting_type': 'gbdt',\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.002, 0.02),\n        'max_depth': trial.suggest_int('max_depth', 12, 30),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 20.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 16,  102),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.2, 0.8),\n        'subsample': trial.suggest_uniform('subsample', 0.4, 1.0),\n        'subsample_freq': trial.suggest_int('subsample_freq', 1, 9),\n        'min_child_samples': trial.suggest_int('min_child_samples', 50, 500)\n    }\n    \n    gbm = lgb.LGBMRegressor(**params)\n    gbm = gbm.fit(x_train, y_train,\n                  verbose=0)\n\n    val_pred = gbm.predict(x_val)\n    return mean_squared_error(y_val, val_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_param_importances(study)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM Inference"},{"metadata":{},"cell_type":"markdown","source":"5 Fold Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = study.best_params\n\nscores = []\npreds = []\n\nkf = KFold(n_splits=5)\n\nfor k, (train_idx, val_idx) in enumerate(kf.split(df)):\n    x_train = df.iloc[train_idx][features]\n    x_val = df.iloc[val_idx][features]\n    y_train = df.iloc[train_idx][target]\n    y_val = df.iloc[val_idx][target]\n\n    gbm = lgb.LGBMRegressor(**best_params)\n    gbm.fit(x_train,\n            y_train,\n            eval_set=(x_val, y_val),\n            verbose=0,\n            early_stopping_rounds=500,\n            eval_metric='rmse')\n\n    test_pred = gbm.predict(x_val)\n    rmse = mean_squared_error(y_val, test_pred, squared=False)\n    print(f'Fold {k} CV: {rmse:.4f}')\n    scores.append(rmse)\n    preds.append(gbm.predict(test_df))\n    \nprint(f'CV: {np.mean(scores):.4f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.mean(preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"f_importance = gbm.booster_.feature_importance()\nx_df = df.drop('target', axis=1)\n\nimportances = pd.DataFrame(sorted(zip(f_importance, x_df.columns), reverse=True), columns=['Feature Importance', 'Feature Name'])[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(12,6))\nsns.barplot(x='Feature Importance', y='Feature Name', data=importances)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': ids, 'target': predictions})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}