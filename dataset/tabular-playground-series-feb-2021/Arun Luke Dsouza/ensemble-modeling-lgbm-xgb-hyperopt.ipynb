{"cells":[{"metadata":{},"cell_type":"markdown","source":"### This Notebook has been Forked from Vladyslav Zabudko's Ensemble (LGB + XGB) with Hyperopt\n\n[Parameter Tuning with Hyperopt](https://medium.com/district-data-labs/parameter-tuning-with-hyperopt-faa86acdfdce)\n"},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Modeling with LGBM & XGB and Hyperparameter Optimization using Hyperopt "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":" "},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nfrom hyperopt.pyll.base import scope\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\ntarget = train.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The data consists of a continuous target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat9 are categorical, and the feature columns cont0 - cont13 are continuous.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df, encoder=None,\n               scaler=None, cols_to_drop=None,\n               cols_to_encode=None, cols_to_scale=None):\n    \"\"\"\n    Preprocess input data\n    :param df: DataFrame with data\n    :param encoder: encoder object with fit_transform method\n    :param scaler: scaler object with fit_transform method\n    :param cols_to_drop: columns to be removed\n    :param cols_to_encode: columns to be encoded\n    :param cols_to_scale: columns to be scaled\n    :return: DataFrame\n    \"\"\"\n\n    if encoder:\n        for col in cols_to_encode:\n            df[col] = encoder.fit_transform(df[col])\n\n    if scaler:\n        for col in cols_to_scale:\n            df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n\n    if cols_to_drop:\n        df = df.drop(cols_to_drop, axis=1)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding the Categorical Features\n#### A machine learning model unfortunately cannot deal with categorical variables (except for some models such as LightGBM). Therefore, we label encode them.\n#### Label encoding assigns each unique category in a categorical variable with an integer. No new columns are created. An example is shown below\n![](https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/label_encoding.png)\n#### The problem with label encoding is that it gives the categories an arbitrary ordering. The value assigned to each of the categories is random and does not reflect any inherent aspect of the category. In the example above, programmer recieves a 4 and data scientist a 1, but if we did the same process again, the labels could be reversed or completely different. The actual assignment of the integers is arbitrary. Therefore, when we perform label encoding, the model might use the relative value of the feature (for example programmer = 4 and data scientist = 1) to assign weights which is not what we want. If we only have two unique values for a categorical variable (such as Male/Female), then label encoding is fine, but for more than 2 unique categories, one-hot encoding is the safe option because it does not impose arbitrary values to categories. \n#### The only downside to one-hot encoding is that the number of features (dimensions of the data) can explode with categorical variables with many categories. To deal with this, we can perform one-hot encoding followed by PCA or other dimensionality reduction methods to reduce the number of dimensions (while still trying to preserve information).\n\n[Source](https://huntdatascience.wordpress.com/2019/07/26/encoding-categorical-variables/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['cat' + str(i) for i in range(10)]\ncont_cols = ['cont' + str(i) for i in range(14)]\n\ntrain = preprocess(train, encoder=LabelEncoder(), scaler=StandardScaler(),\n                  cols_to_drop=['id', 'target'], cols_to_encode=cat_cols,\n                  cols_to_scale=cont_cols)\n\ntest = preprocess(test, encoder=LabelEncoder(), scaler=StandardScaler(),\n                 cols_to_drop=['id'], cols_to_encode=cat_cols,\n                 cols_to_scale=cont_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining the EnsembleModel Class "},{"metadata":{"trusted":true},"cell_type":"code","source":"class EnsembleModel:\n    def __init__(self, params):\n        \"\"\"\n        LGB + XGB model\n        \"\"\"\n        self.lgb_params = params['lgb']\n        self.xgb_params = params['xgb']\n\n        self.lgb_model = LGBMRegressor(**self.lgb_params)\n        self.xgb_model = XGBRegressor(**self.xgb_params)\n\n    def fit(self, x, y, *args, **kwargs):\n        return (self.lgb_model.fit(x, y, *args, **kwargs),\n                self.xgb_model.fit(x, y, *args, **kwargs))\n\n    def predict(self, x, weights=[1.0, 1.0]):\n        \"\"\"\n        Generate model predictions\n        :param x: data\n        :param weights: weights on model prediction, first one is the weight on lgb model\n        :return: array with predictions\n        \"\"\"\n        return (weights[0] * self.lgb_model.predict(x) +\n                weights[1] * self.xgb_model.predict(x)) / 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning with Hyperopt\n![](https://camo.githubusercontent.com/e98afeb0a769a1d6ad1e56214324a18ac426d189196c622ac9dc56de04534d2d/68747470733a2f2f692e706f7374696d672e63632f54506d66665772702f68797065726f70742d6e65772e706e67)"},{"metadata":{},"cell_type":"markdown","source":"#### There are two common methods of parameter tuning: grid search and random search. Each path has it's own puddles. \n\n#### Grid search is slow but effective at searching the whole search space, while random search is fast, but could miss important points in the search space. \n\n#### Luckily, a third option exists: Bayesian optimization. Using Bayesian optimization for parameter tuning allows us to obtain the best parameters for a given model, e.g., logistic regression. This also allows us to perform optimal model selection.\n"},{"metadata":{},"cell_type":"markdown","source":"## Defining the Objective Function"},{"metadata":{},"cell_type":"markdown","source":"#### The function fmin first takes a function to minimize, denoted fn, which we here specify with ensemble_search"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ensemble_search(params):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n\n    model = EnsembleModel(params)\n\n    evaluation = [(X_test, y_test)]\n\n    model.fit(X_train, y_train,\n              eval_set=evaluation, eval_metric='rmse',\n              early_stopping_rounds=100, verbose=False)\n\n    val_preds = model.predict(X_test)\n    rmse = mean_squared_error(y_test, val_preds, squared=False)\n\n    return {\"loss\": rmse, \"status\": STATUS_OK}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the Search Space"},{"metadata":{},"cell_type":"markdown","source":"#### The search space is the continuous range of numbers between lower and upperbound,              specified by *hp.uniform(label, lower bound, upper bound)*"},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_params = {\n    \"lgb\" : {\n        \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 31, 200, 1)),\n        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 10, 24, 1)),\n        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n        'min_split_gain': hp.uniform('min_split_gain', 0, 1.0),\n        'min_child_samples': scope.int(hp.quniform(\"min_child_samples\", 2, 700, 1)),\n        \"subsample\": hp.uniform(\"subsample\", 0.2, 1.0),\n        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n        'reg_alpha': hp.uniform('reg_alpha', 1e-5, 1.0),\n        'reg_lambda': hp.uniform('reg_lambda', 0, 50),\n        'n_jobs': -1,\n        'n_estimators': 2000},\n    'xgb': {\n        'max_depth': scope.int(hp.quniform('xgb.max_depth', 10, 24, 1)),\n        'learning_rate': hp.uniform('xgb.learning_rate', 0.01, 0.3),\n        'gamma': hp.uniform('xgb.gamma', 1, 10),\n        'min_child_weight': scope.int(hp.quniform('xgb.min_child_weight', 2, 700, 1)),\n        'n_estimators': 2000,\n        'colsample_bytree': hp.uniform('xgb.colsample_bytree', 0.5, 0.9),\n        'subsample': hp.uniform('xgb.subsample', 0.5, 1.0),\n        'reg_lambda': hp.uniform('xgb.reg_lambda', 0, 100),\n        'reg_alpha': hp.uniform('xgb.reg_alpha', 1e-5, 0.5),\n        'objective': 'reg:squarederror',\n        'tree_method': 'gpu_hist',\n        'n_jobs': -1}\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Algo, Max_Evals and Trials"},{"metadata":{},"cell_type":"markdown","source":"#### The parameter algo takes a search algorithm, in this case tpe which stands for tree of Parzen estimators.\n\n#### We then specify the maximum number of evaluations max_evals the fmin function will perform. This fmin function returns a python dictionary of values.\n\n#### The Trials object allows us to store info at each time step. We can then print them out and see what the evaluations of the function were for a given parameter at a given time step."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.copy()\ny = target\n\ntrials = Trials()\n\nbest_hyperparams = fmin(fn=ensemble_search,\n                       space=ensemble_params,\n                       algo=tpe.suggest,\n                       max_evals=100,\n                       trials=trials)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimal Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_hyperparams","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"since = time.time()\ncolumns = train.columns\n\nensemble_params = {\n    \"lgb\" : {\n        \"num_leaves\": 36,\n        \"max_depth\": 21,\n        'learning_rate': 0.049019854828962754,\n        'min_split_gain': 0.2579555416739361,\n        'min_child_samples': 500,\n        \"subsample\": 0.2595537456780356,\n        \"colsample_bytree\": 0.6203517996970486,\n        'reg_alpha': 0.33867231210286647,\n        'reg_lambda': 42.071411120949854,\n        'n_jobs': -1,\n        'n_estimators': 5000},\n    'xgb': {\n        'max_depth': 13,\n        'learning_rate': 0.020206705089028228,\n        'gamma': 3.5746731812451156,\n        'min_child_weight': 564,\n        'n_estimators': 5000,\n        'colsample_bytree': 0.5015940592112956,\n        'subsample': 0.6839489639112909,\n        'reg_lambda': 18.085502002853246,\n        'reg_alpha': 0.17532087359570606,\n        'objective': 'reg:squarederror',\n        'tree_method': 'gpu_hist',\n        'n_jobs': -1}\n}\n    \npreds = np.zeros(test.shape[0])\nkf = KFold(n_splits=10, random_state=22, shuffle=True)\nrmse = []\nn = 0\n\nfor trn_idx, test_idx in kf.split(train[columns], target):\n\n    X_tr, X_val=train[columns].iloc[trn_idx], train[columns].iloc[test_idx]\n    y_tr, y_val=target.iloc[trn_idx], target.iloc[test_idx]\n\n    model = EnsembleModel(ensemble_params)\n\n    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n\n    preds += model.predict(test[columns]) / kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    \n    print(f\"Fold {n+1}, RMSE: {rmse[n]}\")\n    n += 1\n\n\nprint(\"Mean RMSE: \", np.mean(rmse))\nend_time = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(\n        end_time // 60, end_time % 60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions = pd.read_csv(\"../input/tabular-playground-series-feb-2021/sample_submission.csv\")\nsubmissions['target'] = preds\n\nsubmissions.to_csv(\"ensemble_model_2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}