{"cells":[{"metadata":{},"cell_type":"markdown","source":"## EDA & Visualization\n\n> Still WIP(Work in Progress)"},{"metadata":{},"cell_type":"markdown","source":"## Import Library & Dataset"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install seaborn==0.11\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\nfrom matplotlib.offsetbox import AnchoredText\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2021/test.csv')\n\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Feature\n\nOne point of this competition is to encode the categorical value again, unlike the previous competition."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 4, figsize=(15, 12))\nfig.set_facecolor('#d0d0d0') \n\nfor i in range(10):\n    # count \n    cnt_tmp = train[f'cat{i}'].value_counts().sort_index()\n    ax[i%3][i//3].bar(cnt_tmp.index, cnt_tmp, color='#244747', label='Count')\n    ax[i%3][i//3].set_yticks([])\n    ax[i%3][i//3].margins(0.05, 0.2)\n    \n    # target\n    target_tmp = train.groupby(f'cat{i}').mean()['target']\n    ax2=ax[i%3][i//3].twinx()\n    ax2.set_yticks([])\n    ax2.bar(target_tmp.index, target_tmp, color='#d4dddd', alpha=0.7, label='Mean of Target')\n    ax2.set_ylim(7, 8.4)\n    \n    divider = make_axes_locatable(ax[i%3][i//3])\n    cax = divider.append_axes(\"top\", size=\"8%\", pad=0)\n    cax.get_xaxis().set_visible(False)\n    cax.get_yaxis().set_visible(False)\n    cax.set_facecolor('black')\n\n    at = AnchoredText(f'cat{i}', loc=10, \n                      prop=dict(backgroundcolor='black',\n                                size=10, color='white', weight='bold'))\n    cax.add_artist(at)\n    \nax[1][3].set_visible(False)\nax[2][3].set_visible(False)\n\nfig.text(0.018, 1.03, 'Categorical Feature Distribution', fontsize=20, fontweight='bold', fontfamily='serif')\nfig.text(0.018, 1, 'Gray is mean of target', fontsize=15, fontweight='light', fontfamily='serif')\n\n\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Value Relation Heatmap\n\n\nsome combination between `cat6`~`cat9` have **absolutly** lower value(mean of target)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(30, 30))\ngs = fig.add_gridspec(sum([len(train[f'cat{i}'].unique()) for i in range(1, 10)]), \n                     sum([len(train[f'cat{i}'].unique()) for i in range(10)]))\n\nidx = np.cumsum([0] + [len(train[f'cat{i}'].unique()) for i in range(10)])\n\n         \nfor i in range(10):\n    for j in range(10):\n        if i <= j : \n            continue\n        pivot_tmp = pd.pivot_table(train, values='target', index=[f'cat{i}'], columns=[f'cat{j}'], aggfunc=np.mean, fill_value=0)\n        ax = fig.add_subplot(gs[idx[i]-2:idx[i+1]-2, idx[j]:idx[j+1]])\n        \n        sns.heatmap(pivot_tmp, \n                    square=True, \n                    center=7.456, # mean of target\n                    cbar=False, \n                    cmap=sns.diverging_palette(240, 10),\n                    xticklabels=(i==9), yticklabels=(j==0),\n                    ax=ax)\n\n        if j : ax.set_ylabel('')    \n        if i<9 : ax.set_xlabel('')\n\nfig.text(0.125, 0.89, 'Categorical Feature Relation Heatmap', fontsize=20, fontweight='bold', fontfamily='serif')            \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Continuous \n\n\n\nObviously, continuous variables also have a bias according to their central distribution.\n\nFor visualization, sample and visualize some."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 5, figsize=(17, 12), sharex=True)\nfig.set_facecolor('#d0d0d0') \n\nfor i in range(14): \n    sns.kdeplot(data=train, x=f'cont{i}', \n                fill=True,\n                linewidth=0,\n                color='#244747', alpha=1,\n                ax=ax[i%3][i//3])\n    ax[i%3][i//3].set_yticks([])\n    ax[i%3][i//3].set_xlabel('',visible=False)\n    ax[i%3][i//3].margins(0.05, 0.2)\n    \n    # dviider\n    divider = make_axes_locatable(ax[i%3][i//3])\n    cax = divider.append_axes(\"top\", size=\"8%\", pad=0)\n    cax.get_xaxis().set_visible(False)\n    cax.get_yaxis().set_visible(False)\n    cax.set_facecolor('black')\n\n    at = AnchoredText(f'cont{i}', loc=10, \n                      prop=dict(backgroundcolor='black',\n                                size=10, color='white', weight='bold'))\n    cax.add_artist(at)\n    \nax[-1][-1].set_visible(False)\nfig.text(0.018, 1.03, 'Continuous Feature Density Plot', fontsize=20, fontweight='bold', fontfamily='serif')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(10, 10))\nfig.set_facecolor('#d0d0d0') \ncorr = train.drop('id', axis=1).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nsns.heatmap(corr, \n            square=True, \n            linewidth=0.2,\n            cbar=False,\n            mask=mask,\n            annot=True,\n            center=0,\n            cmap=sns.diverging_palette(240, 10),\n            ax=ax)\n\nfig.text(0.075, 1, 'Correlation: Continuous Feature & Target', fontweight='bold', fontfamily='serif', fontsize=15) \nax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation=90, fontsize=11)\nax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=11)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For relation, check i use `pariplot`\n\nSampling is nice choices for Large data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train.iloc[:,11:].sample(10000), kind=\"hist\", corner=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}