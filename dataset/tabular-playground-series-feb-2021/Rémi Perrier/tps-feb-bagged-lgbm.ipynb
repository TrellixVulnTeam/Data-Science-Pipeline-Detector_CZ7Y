{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Librairies\nimport pandas as pd\nimport numpy as np\n\nfrom lightgbm import LGBMRegressor\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ntrain = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv', index_col='id')\ntest = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictors & Target\npredictors = train.columns[:-1]\ntarget = train.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Processing\ncat_cols = [col for col in train.columns if 'cat' in col]\ntrain[cat_cols] = train[cat_cols].astype('category')\ntest[cat_cols] = test[cat_cols].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bagging LGBM\n# Didn't use sklearn BaggingRegressor, I wanted more in-depth on the model\nclass BaggingLGBM():\n    \"\"\"Estimator using bagged LGBM etimators.\"\"\"\n    \n    def __init__(self, n_estimators=5, max_sample=0.8, params=None):\n        params = params if params else dict()\n        self.estimators = [LGBMRegressor(**params) for _ in range(n_estimators)]\n        self.max_sample = max_sample\n    \n    \n    def fit(self, X, y):\n        scores = []\n        \n        for estimator in self.estimators:\n            # Create bag\n            idx = X.sample(frac=self.max_sample, replace=True).index\n            X_train, y_train = X.loc[idx], y.loc[idx]\n            X_test, y_test = X[~X.index.isin(idx)], y[~y.index.isin(idx)]\n            \n            # Fit model\n            estimator.fit(X_train, \n                          y_train,\n                          eval_set =(X_test, \n                                     y_test),\n                          eval_metric='rmse',\n                          early_stopping_rounds=500,\n                          verbose=False\n                         )\n            \n            # Test model\n            y_pred = estimator.predict(X_test)\n            rmse = mean_squared_error(y_test, y_pred, squared=False)\n            scores.append(rmse)\n            \n        return scores\n            \n            \n    def predict(self, X):\n        pred = np.zeros(X.shape[0])\n        \n        for estimator in self.estimators:\n            pred += estimator.predict(X) / len(self.estimators)\n            \n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test\nparams = {\n     'reg_alpha': 6.147694913504962,\n     'reg_lambda': 0.002457826062076097,\n     'colsample_bytree': 0.3,\n     'subsample': 0.8,\n     'learning_rate': 0.008,\n     'max_depth': 20,\n     'num_leaves': 111,\n     'min_child_samples': 285,\n     'random_state': 48,\n     'n_estimators': 20000,\n     'metric': 'rmse',\n     'cat_smooth': 39\n}\n\n\nmodel = BaggingLGBM(n_estimators=15, max_sample=0.90, params=params)\nscores = model.fit(train[predictors], train[target])\n\nnp.mean(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission\ntest[target] = model.predict(test[predictors])\ntest[target].to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}