{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome to Spaceship Titanic!\n\nThis is going to be a basic EDA using Pandas Profiling which will give you details about each feature. ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import (\n    ensemble,\n    model_selection,    \n    preprocessing,\n    tree,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-03T14:50:31.600081Z","iopub.execute_input":"2022-04-03T14:50:31.600731Z","iopub.status.idle":"2022-04-03T14:50:33.098863Z","shell.execute_reply.started":"2022-04-03T14:50:31.600593Z","shell.execute_reply":"2022-04-03T14:50:33.097651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load dataset\ntrain=pd.read_csv(\"../input/spaceship-titanic/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.100458Z","iopub.execute_input":"2022-04-03T14:50:33.100726Z","iopub.status.idle":"2022-04-03T14:50:33.194907Z","shell.execute_reply.started":"2022-04-03T14:50:33.100696Z","shell.execute_reply":"2022-04-03T14:50:33.193949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.195955Z","iopub.execute_input":"2022-04-03T14:50:33.19616Z","iopub.status.idle":"2022-04-03T14:50:33.203522Z","shell.execute_reply.started":"2022-04-03T14:50:33.196134Z","shell.execute_reply":"2022-04-03T14:50:33.20238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 8693 passengers and 14 features!","metadata":{}},{"cell_type":"markdown","source":"# Clean Data\n\nThe original Titanic dataset had leaky features which are variables that contain information about the future or target. There’s nothing bad in having data about the target, and we often have that data during model creation time. However, if those variables are not available when we perform a prediction on a new sample, we should remove them from the model as they are leaking data from the future.","metadata":{}},{"cell_type":"code","source":"# Lets have a look to see if there is missing data\nmissing = train.isnull().sum().sort_values(ascending=False)\nmissing","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.206283Z","iopub.execute_input":"2022-04-03T14:50:33.206621Z","iopub.status.idle":"2022-04-03T14:50:33.231625Z","shell.execute_reply.started":"2022-04-03T14:50:33.206588Z","shell.execute_reply":"2022-04-03T14:50:33.230737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of features that require deeper investigations into missing values. Those numbers aren't massive when there are 8693 passengers, but still need to be dealt with. ","metadata":{}},{"cell_type":"code","source":"# what types of data are we dealing with?\ntrain.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.232897Z","iopub.execute_input":"2022-04-03T14:50:33.233591Z","iopub.status.idle":"2022-04-03T14:50:33.245707Z","shell.execute_reply.started":"2022-04-03T14:50:33.233552Z","shell.execute_reply":"2022-04-03T14:50:33.244749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**object** typically means that it is holding string data, though it could be a combination of string and other types.\n\n**float64** is a numeric types.\n\n**bool** is True/False or 0/1.","metadata":{}},{"cell_type":"code","source":"train.describe().iloc[:,:2]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.246982Z","iopub.execute_input":"2022-04-03T14:50:33.247752Z","iopub.status.idle":"2022-04-03T14:50:33.297489Z","shell.execute_reply.started":"2022-04-03T14:50:33.247702Z","shell.execute_reply":"2022-04-03T14:50:33.29661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **count** statistic only includes values that are not NaN, so it is useful for checking whether a column is missing data. \n\nSpot-check the **minimum and maximum values** to see if there are outliers. \n\n","metadata":{}},{"cell_type":"code","source":"# lets look at missing data in each column again so we can work on it\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.299256Z","iopub.execute_input":"2022-04-03T14:50:33.299599Z","iopub.status.idle":"2022-04-03T14:50:33.316989Z","shell.execute_reply.started":"2022-04-03T14:50:33.299555Z","shell.execute_reply":"2022-04-03T14:50:33.316314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By default, calling these methods will apply the operation along axis 0, which is along the index. If you want to get the counts of missing features for each sample, you can apply this along axis 1 (along the columns):","metadata":{}},{"cell_type":"code","source":"mask = train.isnull().any(axis=1)\nmask.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.318359Z","iopub.execute_input":"2022-04-03T14:50:33.319354Z","iopub.status.idle":"2022-04-03T14:50:33.340702Z","shell.execute_reply.started":"2022-04-03T14:50:33.319299Z","shell.execute_reply":"2022-04-03T14:50:33.33996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will look at individual columns to better understand the data we have.","metadata":{}},{"cell_type":"code","source":"# If you want to include null or NaN values use dropna=False\ntrain.Name.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.341783Z","iopub.execute_input":"2022-04-03T14:50:33.342113Z","iopub.status.idle":"2022-04-03T14:50:33.355719Z","shell.execute_reply.started":"2022-04-03T14:50:33.342084Z","shell.execute_reply":"2022-04-03T14:50:33.354832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there are all individual names. Not sure yet if they are all unique. \n\nYou could use NLP but more than likely, your model will not be able to take advantage of this column. The name column is an example of this.","metadata":{}},{"cell_type":"markdown","source":"# View Features\n\nRoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. Lets have a look.","metadata":{}},{"cell_type":"code","source":"train.VRDeck.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.358731Z","iopub.execute_input":"2022-04-03T14:50:33.359108Z","iopub.status.idle":"2022-04-03T14:50:33.372883Z","shell.execute_reply.started":"2022-04-03T14:50:33.359078Z","shell.execute_reply":"2022-04-03T14:50:33.371941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's a wide number of decks. Again, something that will have to be dealt with later and perhaps a decision is made that it's not that valuable.","metadata":{}},{"cell_type":"code","source":"train.Spa.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.37429Z","iopub.execute_input":"2022-04-03T14:50:33.374717Z","iopub.status.idle":"2022-04-03T14:50:33.387564Z","shell.execute_reply.started":"2022-04-03T14:50:33.374672Z","shell.execute_reply":"2022-04-03T14:50:33.38664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.ShoppingMall.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.388881Z","iopub.execute_input":"2022-04-03T14:50:33.389598Z","iopub.status.idle":"2022-04-03T14:50:33.403015Z","shell.execute_reply.started":"2022-04-03T14:50:33.389559Z","shell.execute_reply":"2022-04-03T14:50:33.401882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.FoodCourt.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.405187Z","iopub.execute_input":"2022-04-03T14:50:33.405549Z","iopub.status.idle":"2022-04-03T14:50:33.418251Z","shell.execute_reply.started":"2022-04-03T14:50:33.405506Z","shell.execute_reply":"2022-04-03T14:50:33.417022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.RoomService.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.419627Z","iopub.execute_input":"2022-04-03T14:50:33.42003Z","iopub.status.idle":"2022-04-03T14:50:33.43756Z","shell.execute_reply.started":"2022-04-03T14:50:33.419993Z","shell.execute_reply":"2022-04-03T14:50:33.436732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.VIP.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.438943Z","iopub.execute_input":"2022-04-03T14:50:33.43971Z","iopub.status.idle":"2022-04-03T14:50:33.456177Z","shell.execute_reply.started":"2022-04-03T14:50:33.439663Z","shell.execute_reply":"2022-04-03T14:50:33.455329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Age.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.458473Z","iopub.execute_input":"2022-04-03T14:50:33.459378Z","iopub.status.idle":"2022-04-03T14:50:33.474895Z","shell.execute_reply.started":"2022-04-03T14:50:33.459324Z","shell.execute_reply":"2022-04-03T14:50:33.473852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Destination.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.476457Z","iopub.execute_input":"2022-04-03T14:50:33.477298Z","iopub.status.idle":"2022-04-03T14:50:33.488486Z","shell.execute_reply.started":"2022-04-03T14:50:33.477247Z","shell.execute_reply":"2022-04-03T14:50:33.487226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Cabin.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.489802Z","iopub.execute_input":"2022-04-03T14:50:33.490132Z","iopub.status.idle":"2022-04-03T14:50:33.511606Z","shell.execute_reply.started":"2022-04-03T14:50:33.490104Z","shell.execute_reply":"2022-04-03T14:50:33.510851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.CryoSleep.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.512715Z","iopub.execute_input":"2022-04-03T14:50:33.513161Z","iopub.status.idle":"2022-04-03T14:50:33.522126Z","shell.execute_reply.started":"2022-04-03T14:50:33.513129Z","shell.execute_reply":"2022-04-03T14:50:33.521062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.HomePlanet.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.523742Z","iopub.execute_input":"2022-04-03T14:50:33.524459Z","iopub.status.idle":"2022-04-03T14:50:33.53731Z","shell.execute_reply.started":"2022-04-03T14:50:33.524382Z","shell.execute_reply":"2022-04-03T14:50:33.536538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.PassengerId.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.538873Z","iopub.execute_input":"2022-04-03T14:50:33.539354Z","iopub.status.idle":"2022-04-03T14:50:33.558568Z","shell.execute_reply.started":"2022-04-03T14:50:33.539322Z","shell.execute_reply":"2022-04-03T14:50:33.557718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop columns","metadata":{}},{"cell_type":"code","source":"train = train.drop(['PassengerId','Cabin', 'Name'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.559876Z","iopub.execute_input":"2022-04-03T14:50:33.560142Z","iopub.status.idle":"2022-04-03T14:50:33.574122Z","shell.execute_reply.started":"2022-04-03T14:50:33.560109Z","shell.execute_reply":"2022-04-03T14:50:33.57314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Features","metadata":{}},{"cell_type":"markdown","source":"We need to create dummy columns from string columns. This will create new columns for sex and embarked. Pandas has a convenient get_dummies function for that.","metadata":{}},{"cell_type":"code","source":"train = pd.get_dummies(train)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.57541Z","iopub.execute_input":"2022-04-03T14:50:33.575711Z","iopub.status.idle":"2022-04-03T14:50:33.600864Z","shell.execute_reply.started":"2022-04-03T14:50:33.575677Z","shell.execute_reply":"2022-04-03T14:50:33.600029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.602747Z","iopub.execute_input":"2022-04-03T14:50:33.604015Z","iopub.status.idle":"2022-04-03T14:50:33.611541Z","shell.execute_reply.started":"2022-04-03T14:50:33.603962Z","shell.execute_reply":"2022-04-03T14:50:33.610521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.613963Z","iopub.execute_input":"2022-04-03T14:50:33.615102Z","iopub.status.idle":"2022-04-03T14:50:33.644395Z","shell.execute_reply.started":"2022-04-03T14:50:33.61505Z","shell.execute_reply":"2022-04-03T14:50:33.643679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At this point the \"VIP_True\" and \"CryoSleep_True\" columns are perfectly inverse correlated with False columns. Typically we remove any columns with perfect or very high positive or negative correlation. Multicollinearity can impact interpretation of feature importance and coefficients in some models.","metadata":{}},{"cell_type":"code","source":"train = train.drop(columns=[\"VIP_True\",\n                            \"CryoSleep_True\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.645801Z","iopub.execute_input":"2022-04-03T14:50:33.646123Z","iopub.status.idle":"2022-04-03T14:50:33.654655Z","shell.execute_reply.started":"2022-04-03T14:50:33.646081Z","shell.execute_reply":"2022-04-03T14:50:33.653654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train.Transported\nX = train.drop(columns=\"Transported\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.655994Z","iopub.execute_input":"2022-04-03T14:50:33.6566Z","iopub.status.idle":"2022-04-03T14:50:33.66863Z","shell.execute_reply.started":"2022-04-03T14:50:33.656566Z","shell.execute_reply":"2022-04-03T14:50:33.667701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(\n    X, y, test_size=0.3, random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.672834Z","iopub.execute_input":"2022-04-03T14:50:33.673248Z","iopub.status.idle":"2022-04-03T14:50:33.686108Z","shell.execute_reply.started":"2022-04-03T14:50:33.673216Z","shell.execute_reply":"2022-04-03T14:50:33.684953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Many of the columns have missing values. We need to impute the numeric values. We only want to impute on the training set and then use that imputer to fill in the date for the test set. Otherwise we are leaking data (cheating by giving future information to the model).","metadata":{}},{"cell_type":"code","source":"# we can look at the data once more to see missing values\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.688306Z","iopub.execute_input":"2022-04-03T14:50:33.689226Z","iopub.status.idle":"2022-04-03T14:50:33.703742Z","shell.execute_reply.started":"2022-04-03T14:50:33.689181Z","shell.execute_reply":"2022-04-03T14:50:33.702702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.experimental import (\n    enable_iterative_imputer,\n)\nfrom sklearn import impute\nnum_cols = [\n    \"Age\",\n    \"RoomService\",\n    \"FoodCourt\",\n    \"ShoppingMall\",\n    \"Spa\",\n    \"VRDeck\",\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.705174Z","iopub.execute_input":"2022-04-03T14:50:33.705629Z","iopub.status.idle":"2022-04-03T14:50:33.724099Z","shell.execute_reply.started":"2022-04-03T14:50:33.705585Z","shell.execute_reply":"2022-04-03T14:50:33.723418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use Sklearn impute to fill in the missing data.","metadata":{}},{"cell_type":"code","source":"imputer = impute.IterativeImputer()\nimputed = imputer.fit_transform(\n    X_train[num_cols]\n)\nX_train.loc[:, num_cols] = imputed\nimputed = imputer.transform(X_test[num_cols])\nX_test.loc[:, num_cols] = imputed","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.72524Z","iopub.execute_input":"2022-04-03T14:50:33.725874Z","iopub.status.idle":"2022-04-03T14:50:33.933917Z","shell.execute_reply.started":"2022-04-03T14:50:33.725827Z","shell.execute_reply":"2022-04-03T14:50:33.93281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at all of our columns again\ntrain.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.935781Z","iopub.execute_input":"2022-04-03T14:50:33.936385Z","iopub.status.idle":"2022-04-03T14:50:33.947044Z","shell.execute_reply.started":"2022-04-03T14:50:33.93633Z","shell.execute_reply":"2022-04-03T14:50:33.946025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalize the data\n\nNormalizing or preprocessing the data will help many models perform better after this is done. Particularly those that depend on a distance metric to determine similarity.","metadata":{}},{"cell_type":"code","source":"cols = [\"Age\",\n        \"RoomService\",\n        \"FoodCourt\",\n        \"ShoppingMall\",\n        \"Spa\",\n        \"VRDeck\",\n        \"HomePlanet_Earth\",\n        \"HomePlanet_Europa\",\n       \"HomePlanet_Mars\",\n        \"CryoSleep_False\",\n        \"Destination_55 Cancri e\",\n        \"Destination_PSO J318.5-22\",\n        \"Destination_TRAPPIST-1e\",\n        \"VIP_False\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.948973Z","iopub.execute_input":"2022-04-03T14:50:33.949564Z","iopub.status.idle":"2022-04-03T14:50:33.956345Z","shell.execute_reply.started":"2022-04-03T14:50:33.949513Z","shell.execute_reply":"2022-04-03T14:50:33.955347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n\nWe are going to standardize the data for the preprocessing. Standardizing is translating the data so that it has a mean value of zero and a standard deviation of one. This way models don’t treat variables with larger scales as more important than smaller scaled variables. I’m going to stick the result (numpy array) back into a pandas DataFrame for easier manipulation (and to keep column names).","metadata":{}},{"cell_type":"code","source":"sca = preprocessing.StandardScaler()\nX_train = sca.fit_transform(X_train)\nX_train = pd.DataFrame(X_train, columns=cols)\nX_test = sca.transform(X_test)\nX_test = pd.DataFrame(X_test, columns=cols)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.958103Z","iopub.execute_input":"2022-04-03T14:50:33.95872Z","iopub.status.idle":"2022-04-03T14:50:33.986214Z","shell.execute_reply.started":"2022-04-03T14:50:33.958665Z","shell.execute_reply":"2022-04-03T14:50:33.985195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model\n\nCreating a baseline model that does something really simple can give us something to compare our model to. Note that using the default .score result gives us the accuracy which can be misleading. A problem where a positive case is 1 in 10,000 can easily get over 99% accuracy by always predicting negative.","metadata":{}},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nbm = DummyClassifier()\nbm.fit(X_train, y_train)\nbm.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:33.987982Z","iopub.execute_input":"2022-04-03T14:50:33.988587Z","iopub.status.idle":"2022-04-03T14:50:33.999792Z","shell.execute_reply.started":"2022-04-03T14:50:33.988531Z","shell.execute_reply":"2022-04-03T14:50:33.998843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nmetrics.precision_score(\ny_test, bm.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:34.001629Z","iopub.execute_input":"2022-04-03T14:50:34.002205Z","iopub.status.idle":"2022-04-03T14:50:34.013748Z","shell.execute_reply.started":"2022-04-03T14:50:34.002143Z","shell.execute_reply":"2022-04-03T14:50:34.012944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Tests\n\nThis code tries a variety of algorithm families. The “No Free Lunch” theorem states that no algorithm performs well on all data. However, for some finite set of data, there may be an algorithm that does well on that set. (A popular choice for structured learning these days is a tree-boosted algorithm such as XGBoost.)","metadata":{}},{"cell_type":"code","source":"# Because we are using k-fold cross-validation, \n# we will feed the model all of X and y:\nX = pd.concat([X_train, X_test])\ny = pd.concat([y_train, y_test])","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:34.014898Z","iopub.execute_input":"2022-04-03T14:50:34.015175Z","iopub.status.idle":"2022-04-03T14:50:34.023348Z","shell.execute_reply.started":"2022-04-03T14:50:34.015137Z","shell.execute_reply":"2022-04-03T14:50:34.022501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import (\n    LogisticRegression,\n)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import (\n    KNeighborsClassifier,\n)\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n)\nimport xgboost","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:34.024698Z","iopub.execute_input":"2022-04-03T14:50:34.025089Z","iopub.status.idle":"2022-04-03T14:50:34.131266Z","shell.execute_reply.started":"2022-04-03T14:50:34.025043Z","shell.execute_reply":"2022-04-03T14:50:34.130589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build our models","metadata":{}},{"cell_type":"code","source":"for model in [\n    DummyClassifier,\n    LogisticRegression,\n    DecisionTreeClassifier,\n    KNeighborsClassifier,\n    GaussianNB,\n    SVC,\n    RandomForestClassifier,\n    xgboost.XGBClassifier,\n]:\n    cls = model()\n    kfold = model_selection.KFold(\n        n_splits=10\n    )\n    s = model_selection.cross_val_score(\n        cls, X, y, scoring=\"roc_auc\", cv=kfold\n    )\n    print(\n        f\"{model.__name__:22} AUC: \"\n        f\"{s.mean():.3f} STD: {s.std():.2f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:50:34.132384Z","iopub.execute_input":"2022-04-03T14:50:34.132764Z","iopub.status.idle":"2022-04-03T14:51:19.821769Z","shell.execute_reply.started":"2022-04-03T14:50:34.132734Z","shell.execute_reply":"2022-04-03T14:51:19.821062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.metrics import accuracy_score","metadata":{}},{"cell_type":"code","source":"for model in [\n    DummyClassifier,\n    LogisticRegression,\n    DecisionTreeClassifier,\n    KNeighborsClassifier,\n    GaussianNB,\n    SVC,\n    RandomForestClassifier,\n    xgboost.XGBClassifier,\n]:\n    cls = model()\n    kfold = model_selection.KFold(\n        n_splits=10\n    )\n    s = model_selection.cross_val_score(\n        cls, X, y, scoring=\"accuracy\", cv=kfold\n    )\n    print(\n        f\"{model.__name__:22} Accuracy: \"\n        f\"{s.mean():.3f} STD: {s.std():.2f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:51:19.82288Z","iopub.execute_input":"2022-04-03T14:51:19.823673Z","iopub.status.idle":"2022-04-03T14:52:05.429042Z","shell.execute_reply.started":"2022-04-03T14:51:19.823632Z","shell.execute_reply":"2022-04-03T14:52:05.428381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If this helped you please don't forget to upvote :)","metadata":{}}]}