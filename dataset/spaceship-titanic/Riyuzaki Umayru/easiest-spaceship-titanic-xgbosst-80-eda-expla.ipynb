{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T06:44:20.608401Z","iopub.execute_input":"2022-05-12T06:44:20.608742Z","iopub.status.idle":"2022-05-12T06:44:20.617459Z","shell.execute_reply.started":"2022-05-12T06:44:20.608706Z","shell.execute_reply":"2022-05-12T06:44:20.616478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Importing Libraries*","metadata":{}},{"cell_type":"code","source":"# Libraries for EDA\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import figure\n\n#Libraries for Feature Engineering\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler\n\n#Library for model training\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.64643Z","iopub.execute_input":"2022-05-12T06:44:20.646761Z","iopub.status.idle":"2022-05-12T06:44:20.65215Z","shell.execute_reply.started":"2022-05-12T06:44:20.646727Z","shell.execute_reply":"2022-05-12T06:44:20.651396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Importing Datasets*","metadata":{}},{"cell_type":"code","source":"#  Imported training data as 'train'\ntrain = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n\n#  Imported test data as 'test'\ntest = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.681103Z","iopub.execute_input":"2022-05-12T06:44:20.681745Z","iopub.status.idle":"2022-05-12T06:44:20.726746Z","shell.execute_reply.started":"2022-05-12T06:44:20.681695Z","shell.execute_reply":"2022-05-12T06:44:20.725713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *EDA*","metadata":{}},{"cell_type":"markdown","source":"### Let's see how our data looks like","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.728669Z","iopub.execute_input":"2022-05-12T06:44:20.729083Z","iopub.status.idle":"2022-05-12T06:44:20.75178Z","shell.execute_reply.started":"2022-05-12T06:44:20.729038Z","shell.execute_reply":"2022-05-12T06:44:20.750791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now let's look into shape of our Data","metadata":{}},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.753266Z","iopub.execute_input":"2022-05-12T06:44:20.753985Z","iopub.status.idle":"2022-05-12T06:44:20.768125Z","shell.execute_reply.started":"2022-05-12T06:44:20.75395Z","shell.execute_reply":"2022-05-12T06:44:20.766943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So our data contains 8693 rows and 14 diifferent columns","metadata":{}},{"cell_type":"markdown","source":"### Let's now look if there are any null values and what are dtypes of rows in our data","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.77094Z","iopub.execute_input":"2022-05-12T06:44:20.771654Z","iopub.status.idle":"2022-05-12T06:44:20.793721Z","shell.execute_reply.started":"2022-05-12T06:44:20.771583Z","shell.execute_reply":"2022-05-12T06:44:20.7927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The describe() method gives a quick summary of the statistical information of the numerical columns","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:18:57.465125Z","iopub.execute_input":"2022-05-11T14:18:57.465575Z","iopub.status.idle":"2022-05-11T14:18:57.473121Z","shell.execute_reply.started":"2022-05-11T14:18:57.465535Z","shell.execute_reply":"2022-05-11T14:18:57.471808Z"}}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.798881Z","iopub.execute_input":"2022-05-12T06:44:20.799672Z","iopub.status.idle":"2022-05-12T06:44:20.834194Z","shell.execute_reply.started":"2022-05-12T06:44:20.799634Z","shell.execute_reply":"2022-05-12T06:44:20.832903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Our output column in 'Transported' so lets see how much counts is has","metadata":{}},{"cell_type":"code","source":"train['Transported'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.839407Z","iopub.execute_input":"2022-05-12T06:44:20.839724Z","iopub.status.idle":"2022-05-12T06:44:20.848279Z","shell.execute_reply.started":"2022-05-12T06:44:20.83969Z","shell.execute_reply":"2022-05-12T06:44:20.847345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Almost 50% of the travellers were transported","metadata":{}},{"cell_type":"markdown","source":"## Let's see correlations in our Data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 15))\ncorrelations = train.corr()\nsns.heatmap(correlations, cmap=\"coolwarm\", annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:20.864485Z","iopub.execute_input":"2022-05-12T06:44:20.865072Z","iopub.status.idle":"2022-05-12T06:44:21.325853Z","shell.execute_reply.started":"2022-05-12T06:44:20.865029Z","shell.execute_reply":"2022-05-12T06:44:21.324678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now let us look into value counts our features (columns) have","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(2,2, figsize=(15,10))\nsns.countplot(train['HomePlanet'] , palette='Paired_r', ax=ax[0][0])\nsns.countplot(train['CryoSleep'] , palette='Paired_r', ax=ax[0][1])\nsns.countplot(train['Destination'] , palette='Paired_r', ax=ax[1][0])\nsns.countplot(train['VIP'] , palette='Paired_r', ax=ax[1][1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:21.328062Z","iopub.execute_input":"2022-05-12T06:44:21.328689Z","iopub.status.idle":"2022-05-12T06:44:21.748476Z","shell.execute_reply.started":"2022-05-12T06:44:21.328642Z","shell.execute_reply":"2022-05-12T06:44:21.74734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(train[train['Transported']==0]['Age'],hist=False)\nsns.distplot(train[train['Transported']==1]['Age'],hist=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:21.75036Z","iopub.execute_input":"2022-05-12T06:44:21.750717Z","iopub.status.idle":"2022-05-12T06:44:21.951439Z","shell.execute_reply.started":"2022-05-12T06:44:21.750671Z","shell.execute_reply":"2022-05-12T06:44:21.949787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This graph shows us density of person transported according to their age","metadata":{}},{"cell_type":"markdown","source":"# Adding columns and handling null values","metadata":{}},{"cell_type":"markdown","source":"##### Features like cabin contains information of deck , num and side so we will first split that and , other feature like RoomService , FoodCourt , ShoppingMall , Spa , VRDeck  contain info about person's bill which he spent on this features so, we will make another colum as ToalBill for that having sum of all the bills","metadata":{}},{"cell_type":"code","source":"train[['deck','num','side']] = train['Cabin'].str.split('/', expand=True)\ntrain['TotalBill'] =  train[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].sum(axis=1)\ntrain.drop(['Cabin','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck'],1,inplace=True)\n\n\ntest[['deck','num','side']] = test['Cabin'].str.split('/', expand=True)\ntest['TotalBill'] =  test[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].sum(axis=1)\ntest.drop(['Cabin','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck'],1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:21.954703Z","iopub.execute_input":"2022-05-12T06:44:21.955087Z","iopub.status.idle":"2022-05-12T06:44:22.166461Z","shell.execute_reply.started":"2022-05-12T06:44:21.955041Z","shell.execute_reply":"2022-05-12T06:44:22.165458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now lets again see into our data if there are any outliers","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(train['Age'],train['TotalBill'],hue=train['Transported'])","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.167699Z","iopub.execute_input":"2022-05-12T06:44:22.167915Z","iopub.status.idle":"2022-05-12T06:44:22.853912Z","shell.execute_reply.started":"2022-05-12T06:44:22.16789Z","shell.execute_reply":"2022-05-12T06:44:22.852976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Here we can see that therer are very less values having their total bill greater than 2500 so we will remove that values and also there less values in age above 75 so we will also remove them","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now lets see how much null values are there in our data","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.855385Z","iopub.execute_input":"2022-05-12T06:44:22.855649Z","iopub.status.idle":"2022-05-12T06:44:22.869236Z","shell.execute_reply.started":"2022-05-12T06:44:22.855596Z","shell.execute_reply":"2022-05-12T06:44:22.86814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So we will now fill the null values according to their max occuring values ","metadata":{}},{"cell_type":"code","source":"'''CATEGORICAL DATA'''\n\n\n# Training Data\ntrain['HomePlanet']= train['HomePlanet'].fillna('Earth')\ntrain['Destination']= train['Destination'].fillna('TRAPPIST-1e')\ntrain[\"deck\"] = train[\"deck\"].fillna('F')\ntrain['side']= train['side'].fillna('S')\n\n#Test Data\ntest['HomePlanet']= test['HomePlanet'].fillna('Earth')\ntest['Destination']= test['Destination'].fillna('TRAPPIST-1e')\ntest[\"deck\"] = test[\"deck\"].fillna('F')\ntest['side']= test['side'].fillna('S')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.870802Z","iopub.execute_input":"2022-05-12T06:44:22.871311Z","iopub.status.idle":"2022-05-12T06:44:22.891102Z","shell.execute_reply.started":"2022-05-12T06:44:22.871264Z","shell.execute_reply":"2022-05-12T06:44:22.890334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here we will convert true/false to 1/0\n \ntrain['CryoSleep']= train['CryoSleep'].fillna(False).astype(int)\ntest['CryoSleep']= test['CryoSleep'].fillna(False).astype(int)\n\ntrain['VIP']= train['VIP'].fillna(False).astype(int)\ntest['VIP']= test['VIP'].fillna(False).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.892566Z","iopub.execute_input":"2022-05-12T06:44:22.892927Z","iopub.status.idle":"2022-05-12T06:44:22.914971Z","shell.execute_reply.started":"2022-05-12T06:44:22.892892Z","shell.execute_reply":"2022-05-12T06:44:22.913916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''NUMERICAL DATA'''\n\n#Training Data\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\ntrain['num'] = train['num'].astype(float)\ntrain['num']= train['num'].fillna(train['num'].mean())\n\n#Test Data\ntest[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())\ntest['num'] = test['num'].astype(float)\ntest['num']= test['num'].fillna(train['num'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.916659Z","iopub.execute_input":"2022-05-12T06:44:22.917178Z","iopub.status.idle":"2022-05-12T06:44:22.933832Z","shell.execute_reply.started":"2022-05-12T06:44:22.917132Z","shell.execute_reply":"2022-05-12T06:44:22.932872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We can't fill values of name column , so we will drop it","metadata":{}},{"cell_type":"code","source":"train.drop(columns='Name',inplace=True)\n\ntest.drop(columns='Name',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.936556Z","iopub.execute_input":"2022-05-12T06:44:22.937121Z","iopub.status.idle":"2022-05-12T06:44:22.944512Z","shell.execute_reply.started":"2022-05-12T06:44:22.936949Z","shell.execute_reply":"2022-05-12T06:44:22.943834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.isnull().sum())\nprint(test.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.945699Z","iopub.execute_input":"2022-05-12T06:44:22.946128Z","iopub.status.idle":"2022-05-12T06:44:22.961218Z","shell.execute_reply.started":"2022-05-12T06:44:22.946077Z","shell.execute_reply":"2022-05-12T06:44:22.960497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So now our null values are handled","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Now lets split our data into input and output","metadata":{}},{"cell_type":"code","source":"X_train=train.drop(columns='Transported')\ny_train=train['Transported']","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.962387Z","iopub.execute_input":"2022-05-12T06:44:22.962816Z","iopub.status.idle":"2022-05-12T06:44:22.971399Z","shell.execute_reply.started":"2022-05-12T06:44:22.96277Z","shell.execute_reply":"2022-05-12T06:44:22.970701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### test.copy() will copy its data into X_test so we that we can identify train and test data easily","metadata":{}},{"cell_type":"code","source":"X_test=test.copy(deep=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.972629Z","iopub.execute_input":"2022-05-12T06:44:22.973464Z","iopub.status.idle":"2022-05-12T06:44:22.982537Z","shell.execute_reply.started":"2022-05-12T06:44:22.973428Z","shell.execute_reply":"2022-05-12T06:44:22.981654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now we want to apply OneHotEncoder to our categorical columns & StandardScaler to numerical data so we will use make_column_transformer() function\n","metadata":{}},{"cell_type":"code","source":"transformer=make_column_transformer(\n    (OneHotEncoder(drop='first',sparse=False,dtype=np.int32),['HomePlanet','Destination','deck' ,'side']),\n    (StandardScaler(),['Age','num','TotalBill']),\n    remainder='passthrough')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.983747Z","iopub.execute_input":"2022-05-12T06:44:22.98397Z","iopub.status.idle":"2022-05-12T06:44:22.99518Z","shell.execute_reply.started":"2022-05-12T06:44:22.983942Z","shell.execute_reply":"2022-05-12T06:44:22.994419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we will fit and transform our train and test data","metadata":{}},{"cell_type":"code","source":"X_train=transformer.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:22.996172Z","iopub.execute_input":"2022-05-12T06:44:22.996751Z","iopub.status.idle":"2022-05-12T06:44:23.032492Z","shell.execute_reply.started":"2022-05-12T06:44:22.996718Z","shell.execute_reply":"2022-05-12T06:44:23.030985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=transformer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:23.035463Z","iopub.execute_input":"2022-05-12T06:44:23.03607Z","iopub.status.idle":"2022-05-12T06:44:23.056708Z","shell.execute_reply.started":"2022-05-12T06:44:23.036023Z","shell.execute_reply":"2022-05-12T06:44:23.055919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Our output column is categorical so we will use LabelEncoder","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ny_train = le.fit_transform(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:23.058091Z","iopub.execute_input":"2022-05-12T06:44:23.058635Z","iopub.status.idle":"2022-05-12T06:44:23.064596Z","shell.execute_reply.started":"2022-05-12T06:44:23.058573Z","shell.execute_reply":"2022-05-12T06:44:23.063524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":" ### Here we are using XGBClassifier as our model","metadata":{}},{"cell_type":"code","source":"\nxgb_model = XGBClassifier()\nmodel = xgb_model.fit(X_train, y_train, eval_metric='logloss')\n\nprint(\"Performance on train data:\", model.score(X_train, y_train)*100)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:23.06645Z","iopub.execute_input":"2022-05-12T06:44:23.0668Z","iopub.status.idle":"2022-05-12T06:44:24.174174Z","shell.execute_reply.started":"2022-05-12T06:44:23.066748Z","shell.execute_reply":"2022-05-12T06:44:24.173399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nreg=DecisionTreeRegressor()\nmodel_2=reg.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:24.175196Z","iopub.execute_input":"2022-05-12T06:44:24.176394Z","iopub.status.idle":"2022-05-12T06:44:24.23454Z","shell.execute_reply.started":"2022-05-12T06:44:24.176307Z","shell.execute_reply":"2022-05-12T06:44:24.233385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### So our model's performance on train data was almost 90%","metadata":{}},{"cell_type":"markdown","source":"#### Now lets predict output with optimized model","metadata":{}},{"cell_type":"code","source":"optimized_xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8,\n              enable_categorical=False, gamma=5, gpu_id=-1,\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.02, max_delta_step=0, max_depth=5,\n              min_child_weight=5, monotone_constraints='()',\n              n_estimators=600, n_jobs=1, nthread=1, num_parallel_tree=1,\n              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n              scale_pos_weight=1, silent=True, subsample=0.8,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n\noptimized_model = optimized_xgb.fit(X_train, y_train, eval_metric='logloss')\n\nprint(\"Performance on train data:\", optimized_model.score(X_train, y_train)*100)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:24.23593Z","iopub.execute_input":"2022-05-12T06:44:24.236176Z","iopub.status.idle":"2022-05-12T06:44:31.620439Z","shell.execute_reply.started":"2022-05-12T06:44:24.236147Z","shell.execute_reply":"2022-05-12T06:44:31.619494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### So performance on optimized model is 78%","metadata":{}},{"cell_type":"markdown","source":"# Submitting The Data","metadata":{}},{"cell_type":"code","source":"y_pred = model_2.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:31.62174Z","iopub.execute_input":"2022-05-12T06:44:31.621973Z","iopub.status.idle":"2022-05-12T06:44:31.630901Z","shell.execute_reply.started":"2022-05-12T06:44:31.621942Z","shell.execute_reply":"2022-05-12T06:44:31.6302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Our outpute values are ture/false in kaggle submission data so we also need to convert our output to boolean form to calculate ou score","metadata":{}},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:31.631987Z","iopub.execute_input":"2022-05-12T06:44:31.6328Z","iopub.status.idle":"2022-05-12T06:44:31.650182Z","shell.execute_reply.started":"2022-05-12T06:44:31.632756Z","shell.execute_reply":"2022-05-12T06:44:31.649313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_df = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')\n# submission_df[\"Transported\"] = y_pred.astype('bool')\n\n# submission_df.to_csv('my_submission_final.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:31.652284Z","iopub.execute_input":"2022-05-12T06:44:31.652968Z","iopub.status.idle":"2022-05-12T06:44:31.681036Z","shell.execute_reply.started":"2022-05-12T06:44:31.652918Z","shell.execute_reply":"2022-05-12T06:44:31.679772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('my_submission_final.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:31.682556Z","iopub.execute_input":"2022-05-12T06:44:31.683182Z","iopub.status.idle":"2022-05-12T06:44:31.700457Z","shell.execute_reply.started":"2022-05-12T06:44:31.683145Z","shell.execute_reply":"2022-05-12T06:44:31.699498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_true,submission_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:44:31.701931Z","iopub.execute_input":"2022-05-12T06:44:31.702175Z","iopub.status.idle":"2022-05-12T06:44:31.719293Z","shell.execute_reply.started":"2022-05-12T06:44:31.702145Z","shell.execute_reply":"2022-05-12T06:44:31.718347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nreg=DecisionTreeRegressor()\nmodel_2.fit(X_train,y_train)\ny_pred_temp=model_2.predict(X_test)\nsubmission_df[\"Transported\"] = y_pred.astype('bool')\nsubmission_df.to_csv('my_submission_Temp.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:45:23.708749Z","iopub.execute_input":"2022-05-12T06:45:23.709244Z","iopub.status.idle":"2022-05-12T06:45:23.779103Z","shell.execute_reply.started":"2022-05-12T06:45:23.709192Z","shell.execute_reply":"2022-05-12T06:45:23.77823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}