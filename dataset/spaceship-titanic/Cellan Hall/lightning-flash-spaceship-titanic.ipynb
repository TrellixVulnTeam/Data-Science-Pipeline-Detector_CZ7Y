{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ⚡️ Lightning Flash - Spaceship Titanic 🚀\n\n## Goal of this Notebook\nI have used Lightning for several projects and I have really enjoyed using it. I haven't had the chance to use Flash and I am interested to use Flash's out-of-the-box tools for training a deep learning model. Also, there has been a lot of debate on Twitter regarding using deep learning for tabular data. Personally, I have only built deep learning models for image or text-based tasks and not for tabular data (all hail XGBoost!). However, I am intrigued by Flash's tabular data backbones! \n\n## Why  Flash?\nTo get started with Deep Learning.\n\n### Easy to learn\nIf you are just getting started with deep learning, Flash offers common deep learning tasks you can use out-of-the-box in a few lines of code, no math, fancy nn.Modules or research experience required!\n\n### Easy to scale\nFlash is built on top of PyTorch Lightning, a powerful deep learning research framework for training models at scale. With the power of Lightning, you can train your flash tasks on any hardware: CPUs, GPUs or TPUs without any code changes.\n\n### Easy to upskill\nIf you want to create more complex and customized models, you can refactor any part of flash with PyTorch or PyTorch Lightning components to get all the flexibility you need. Lightning is just organized PyTorch with the unnecessary engineering details abstracted away.\n\n- Flash (high-level)\n- Lightning (mid-level)\n- PyTorch (low-level)\n\nWhen you need more flexibility you can build your own tasks or simply use Lightning directly.\n\n## More Information\n- Check out Flash on GitHub: https://github.com/PyTorchLightning/lightning-flash\n- See the Flash docs for more information: https://lightning-flash.readthedocs.io/en/latest/\n- Join the community on Slack: https://www.pytorchlightning.ai/community\n- A great Flash tutorial that I followed to structure this notebook: https://lightning-flash.readthedocs.io/en/latest/notebooks/flash_tutorials/electricity_forecasting.html\n\n# References\n- I would like to thank Jirka Borovec for their notebook! Check it out: https://www.kaggle.com/code/jirkaborovec/starter-flash-spaceship-titanic\n- A great starter notebook: https://www.kaggle.com/code/odins0n/spaceship-titanic-eda-27-different-models\n\n# Competition\nThe competition is organised by Kaggle and is in the GettingStarted Prediction Competition series.\n\nIn this competition, you are supposed to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n\nSubmissions are evaluated on Classification Accuracy.","metadata":{}},{"cell_type":"markdown","source":"# Install Packages\n\nI found that the latest version`lightning-flash==0.7.5` had several behaviours that were unexpected and had been updated in the pre-release version on GitHub (`0.8.0dev`).","metadata":{}},{"cell_type":"code","source":"! pip uninstall -y torchtext\n! pip install 'git+https://github.com/PyTorchLightning/lightning-flash.git#egg=lightning-flash[tabular]'\n! pip install -q \"omegaconf==2.1.*\" \"matplotlib==3.1.1\" \"pandas==1.3.5\" --force-reinstall\n! pip list | grep -e lightning -e torch -e tab","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T20:15:06.363033Z","iopub.execute_input":"2022-06-26T20:15:06.363409Z","iopub.status.idle":"2022-06-26T20:16:21.912096Z","shell.execute_reply.started":"2022-06-26T20:15:06.363371Z","shell.execute_reply":"2022-06-26T20:16:21.910697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries\n\nUse the function `seed_everything` from `pytorch_lightning` for reproducible results.","metadata":{}},{"cell_type":"code","source":"import itertools\nfrom pprint import pprint\n\nimport flash\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport seaborn as sns\nimport torch\nfrom flash import tabular\n\npl.seed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:21.917216Z","iopub.execute_input":"2022-06-26T20:16:21.917552Z","iopub.status.idle":"2022-06-26T20:16:21.929659Z","shell.execute_reply.started":"2022-06-26T20:16:21.917519Z","shell.execute_reply":"2022-06-26T20:16:21.928457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def process_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Creating additional features.\n    \n    Args:\n        df: spaceship-titanic dataframe.\n        \n    Returns:\n        pd.DataFrame\n    \"\"\"\n    df = _split_cabin_number(df)\n    df = _bin_age(df)\n    df = _money_spent(df)\n    return df\n\ndef _split_cabin_number(df: pd.DataFrame) -> pd.DataFrame:\n    df[[\"CabinNumber\", \"CabinDeck\", \"CabinSide\"]] = [\n        c.split(\"/\") if isinstance(c, str) else [c] * 3 \n        for c in df[\"Cabin\"]\n    ]\n    return df\n\n\ndef _bin_age(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"AgeCategorized\"] = np.where(\n        df[\"Age\"] < 20,\n        \"Below 20\",\n        np.where(\n            df[\"Age\"] > 38,\n            \"Above 38\",\n            \"Between 20 and 38\",\n        ),\n    )\n    return df\n\ndef _money_spent(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"MoneySpent\"] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n    return df\n\ndef plot_metrics() -> None:\n    \"\"\"Plot training logged training metrics\"\"\"\n    sns.set()\n    metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n    metrics.set_index(\"step\", inplace=True)\n    del metrics[\"epoch\"]\n    sns.relplot(data=metrics, kind=\"line\")\n    plt.gca().set_ylim([0, 1.25])\n    plt.gcf().set_size_inches(10, 5)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:21.931622Z","iopub.execute_input":"2022-06-26T20:16:21.93266Z","iopub.status.idle":"2022-06-26T20:16:21.948252Z","shell.execute_reply.started":"2022-06-26T20:16:21.932605Z","shell.execute_reply":"2022-06-26T20:16:21.947291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data\n\n- `PassengerId` - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n- `HomePlanet` - The planet the passenger departed from, typically their planet of permanent residence.\n- `CryoSleep` - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n- `Cabin` - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n- `Destination` - The planet the passenger will be debarking to.\n- `Age` - The age of the passenger.\n- `VIP` - Whether the passenger has paid for special VIP service during the voyage.\n- `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck` - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n- `Name` - The first and last names of the passenger.\n- `Transported` - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:21.953441Z","iopub.execute_input":"2022-06-26T20:16:21.954101Z","iopub.status.idle":"2022-06-26T20:16:22.008565Z","shell.execute_reply.started":"2022-06-26T20:16:21.95406Z","shell.execute_reply":"2022-06-26T20:16:22.007497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Training Data\n\nBefore loading data into Flash, we need to pre-process the data as I want to create some extra features. Also, for modelling, the target variable needs to be label encoded. ","metadata":{}},{"cell_type":"code","source":"df = process_data(df)\ndf[\"Transported\"] = df[\"Transported\"].apply(int)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:22.01014Z","iopub.execute_input":"2022-06-26T20:16:22.010525Z","iopub.status.idle":"2022-06-26T20:16:22.06959Z","shell.execute_reply.started":"2022-06-26T20:16:22.010488Z","shell.execute_reply":"2022-06-26T20:16:22.068624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Flash DataModule\n\nCreate a `TabularClassificationData` to split the data into training and validation samples for modelling. We need to specify our numerical, categorical, and target variables. \n\nFor this version of Flash, **numerical missing** values are imputed using the **median** and **categorical missing** values are labelled as **0**.\n\nSet the `pin_memory` argument in DataLoader to `True` when working with GPUs. This allocates the data into page-locked memory, which speeds up data transfer to the GPU.\n\nOnce initialised, we can see the parameters of `TabularClassificationData` module:","metadata":{}},{"cell_type":"code","source":"train_datamodule = tabular.TabularClassificationData.from_data_frame(\n    categorical_fields=[\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"CabinNumber\", \"CabinDeck\", \"CabinSide\", \"AgeCategorized\"],\n    numerical_fields=[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"MoneySpent\"],\n    target_fields=\"Transported\",\n    train_data_frame=df,\n    val_split=0.05,\n    batch_size=128,\n    pin_memory=True,\n)\n\npprint(train_datamodule.parameters)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T20:16:22.070974Z","iopub.execute_input":"2022-06-26T20:16:22.071543Z","iopub.status.idle":"2022-06-26T20:16:22.19097Z","shell.execute_reply.started":"2022-06-26T20:16:22.071504Z","shell.execute_reply":"2022-06-26T20:16:22.189993Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Flash Task\n\nWe can use the `TabularClassifier`to create a tabular classification task. Let's try out the `tabtransformer` backbone for tabular tasks.","metadata":{}},{"cell_type":"code","source":"model = tabular.TabularClassifier.from_data(\n    train_datamodule, \n    backbone=\"tabtransformer\",\n    optimizer=\"adamax\",\n    out_ff_activation=\"SiLU\",\n    num_attn_blocks=14,\n    attn_dropout = 0.2,\n    ff_dropout = 0.2,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:22.192642Z","iopub.execute_input":"2022-06-26T20:16:22.193307Z","iopub.status.idle":"2022-06-26T20:16:22.288628Z","shell.execute_reply.started":"2022-06-26T20:16:22.193268Z","shell.execute_reply":"2022-06-26T20:16:22.287558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Flash Trainer\n\nLet's initial the Flash Trainer. We apply gradient clipping (a common technique for tabular tasks) with `gradient_clip_val=0.01` to help prevent our model from over-fitting. Let's also use the `ÈarlyStopping` callback to monitor our validation loss.\n\nUsing `precision=16` Lightning will use half-precision whenever possible while retaining single-precision elsewhere. With minimal code modifications, we can achieve a 1.5x — 2x speed boost to our model training times.\n\nWe can also log all of our training metrics to a `.csv` file so we can visualise them later.","metadata":{}},{"cell_type":"code","source":"early_stopping = pl.callbacks.EarlyStopping(monitor=\"valid_loss\", patience=10, mode=\"min\")\n\ntrainer = flash.Trainer(\n    max_epochs=100, \n    gpus=torch.cuda.device_count(), \n    precision=16,\n    gradient_clip_val=0.01,\n    callbacks=[early_stopping],\n    logger=pl.loggers.CSVLogger(save_dir='logs/')\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:22.290029Z","iopub.execute_input":"2022-06-26T20:16:22.290637Z","iopub.status.idle":"2022-06-26T20:16:22.300747Z","shell.execute_reply.started":"2022-06-26T20:16:22.290574Z","shell.execute_reply":"2022-06-26T20:16:22.298774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Automatical find the Learning Rate\n\nTabular models can be particularly sensitive to the choice of learning rate. Helpfully, Lightning provides a built-in learning rate finder that suggests a suitable learning rate automatically. Here’s how to find the learning rate:","metadata":{}},{"cell_type":"code","source":"res = trainer.tuner.lr_find(model, datamodule=train_datamodule, min_lr=1e-5)\nprint(f\"Suggested learning rate: {res.suggestion()}\")\nres.plot(show=True, suggest=True).show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:22.302979Z","iopub.execute_input":"2022-06-26T20:16:22.303941Z","iopub.status.idle":"2022-06-26T20:16:31.024226Z","shell.execute_reply.started":"2022-06-26T20:16:22.303898Z","shell.execute_reply":"2022-06-26T20:16:31.023105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once the suggest learning rate has been found, we can update our model with it:","metadata":{}},{"cell_type":"code","source":"model.learning_rate = res.suggestion()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:31.025888Z","iopub.execute_input":"2022-06-26T20:16:31.026258Z","iopub.status.idle":"2022-06-26T20:16:31.032879Z","shell.execute_reply.started":"2022-06-26T20:16:31.026217Z","shell.execute_reply":"2022-06-26T20:16:31.03098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model\n\nFinally, let's train the model!","metadata":{}},{"cell_type":"code","source":"trainer.fit(model, datamodule=train_datamodule)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:16:31.037712Z","iopub.execute_input":"2022-06-26T20:16:31.038611Z","iopub.status.idle":"2022-06-26T20:22:05.340406Z","shell.execute_reply.started":"2022-06-26T20:16:31.038567Z","shell.execute_reply":"2022-06-26T20:22:05.339369Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Awesome! Let's visualise the training metrics:","metadata":{}},{"cell_type":"code","source":"plot_metrics()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:22:05.342233Z","iopub.execute_input":"2022-06-26T20:22:05.342685Z","iopub.status.idle":"2022-06-26T20:22:05.836531Z","shell.execute_reply.started":"2022-06-26T20:22:05.342625Z","shell.execute_reply":"2022-06-26T20:22:05.835588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction\n\nWe use the parameters from the `train_datamodule` so that `df_test` can be transformed correctly for inference.","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\ndf_test = process_data(df_test)\n\npredict_datamodule = tabular.TabularClassificationData.from_data_frame(\n    predict_data_frame=df_test,\n    parameters=train_datamodule.parameters,\n    batch_size=8\n)\n    \npredictions = trainer.predict(model, datamodule=predict_datamodule, output=\"classes\")\npredictions = list(itertools.chain(*predictions))\ndf_test[\"Transported\"] = [str(bool(p)) for p in predictions]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:22:05.838699Z","iopub.execute_input":"2022-06-26T20:22:05.83939Z","iopub.status.idle":"2022-06-26T20:22:15.066301Z","shell.execute_reply.started":"2022-06-26T20:22:05.839348Z","shell.execute_reply":"2022-06-26T20:22:15.065003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"df_test.set_index(\"PassengerId\")[[\"Transported\"]].to_csv(\"submission.csv\")\n\n! head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:22:15.06771Z","iopub.execute_input":"2022-06-26T20:22:15.068894Z","iopub.status.idle":"2022-06-26T20:22:15.845567Z","shell.execute_reply.started":"2022-06-26T20:22:15.068857Z","shell.execute_reply":"2022-06-26T20:22:15.8444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thanks for reading!\n\nIf you made it this far, thank you! As you've seen there is a lot you can do with Flash. The performance of neural networks depends greatly on the parameters that are used. Next, I will investigate how packages like Optuna integrate with the Lightning eco-system for hyperparameter tuning. ","metadata":{}}]}