{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-31T15:04:24.392155Z","iopub.execute_input":"2022-03-31T15:04:24.392921Z","iopub.status.idle":"2022-03-31T15:04:24.400427Z","shell.execute_reply.started":"2022-03-31T15:04:24.392882Z","shell.execute_reply":"2022-03-31T15:04:24.399563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the data","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:27.779008Z","iopub.execute_input":"2022-03-31T15:04:27.779507Z","iopub.status.idle":"2022-03-31T15:04:27.866781Z","shell.execute_reply.started":"2022-03-31T15:04:27.779475Z","shell.execute_reply":"2022-03-31T15:04:27.865733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets check the training data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:23:37.730367Z","iopub.execute_input":"2022-03-30T14:23:37.730647Z","iopub.status.idle":"2022-03-30T14:23:37.757173Z","shell.execute_reply.started":"2022-03-30T14:23:37.730619Z","shell.execute_reply":"2022-03-30T14:23:37.756633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataframe information\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:23:38.201598Z","iopub.execute_input":"2022-03-30T14:23:38.202176Z","iopub.status.idle":"2022-03-30T14:23:38.228807Z","shell.execute_reply.started":"2022-03-30T14:23:38.202141Z","shell.execute_reply":"2022-03-30T14:23:38.227951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Exploration to understand the features \n\n# util for getting info about dataframe\ndef get_info(df):\n    for col in df.columns:\n        print(f'{col !r:20}{df[col].dtype !r:20} missing : {df[col].isna().sum() :3} percentage : {(df[col].isna().sum())/len(df) :.2f}')\n    \nprint('TRAINING DATA \\n','*'*100)\nget_info(train)\nprint('\\nTESTING DATA \\n','*'*100)\nget_info(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:23:45.522587Z","iopub.execute_input":"2022-03-30T14:23:45.522877Z","iopub.status.idle":"2022-03-30T14:23:45.557594Z","shell.execute_reply.started":"2022-03-30T14:23:45.522838Z","shell.execute_reply":"2022-03-30T14:23:45.556774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features for category encoding\n\ncat_types = []\n\n\nprint('length of dataframe',len(train))\nprint('\\nNumber of unique values')\nprint('Feature',' '*12,'Train',' '*4,'Test')\nfor col in train.select_dtypes(['O']).columns:\n    print(f'{col !r:20} {train[col].nunique() !r:10} {test[col].nunique() !r:10}')\n\nprint('\\n\\n')\nfor col in train.select_dtypes(['O']).columns:\n    if train[col].nunique()<5:\n        print(f'Feature : {col} \\n{train[col].value_counts()}\\n')\n        cat_types.append(col)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:24:11.433439Z","iopub.execute_input":"2022-03-30T14:24:11.434046Z","iopub.status.idle":"2022-03-30T14:24:11.469184Z","shell.execute_reply.started":"2022-03-30T14:24:11.434009Z","shell.execute_reply":"2022-03-30T14:24:11.468369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Numerical data stats : Training","metadata":{}},{"cell_type":"code","source":"train.select_dtypes(['float64']).describe().iloc[:3,:]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:24:27.603044Z","iopub.execute_input":"2022-03-30T14:24:27.60333Z","iopub.status.idle":"2022-03-30T14:24:27.638128Z","shell.execute_reply.started":"2022-03-30T14:24:27.603294Z","shell.execute_reply":"2022-03-30T14:24:27.63755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Numerical data stats : Testing","metadata":{}},{"cell_type":"code","source":"test.select_dtypes(['float64']).describe().iloc[:3,:]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:24:28.137592Z","iopub.execute_input":"2022-03-30T14:24:28.138023Z","iopub.status.idle":"2022-03-30T14:24:28.166178Z","shell.execute_reply.started":"2022-03-30T14:24:28.137981Z","shell.execute_reply":"2022-03-30T14:24:28.165321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Encode the data with correct datatype\n\nEncoding each feature with its correct type helps ensure each feature is treated appropriately by whatever functions we use, and makes it easier for us to apply transformations consistently. ","metadata":{}},{"cell_type":"code","source":"# let combine the train and test to apply preprocessing steps\n# After preprocessing is done we'll split them\ntrain_ = train.set_index('PassengerId')\ntest_ = test.set_index('PassengerId')\ntemp = pd.concat([train_,test_])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:35.161456Z","iopub.execute_input":"2022-03-31T15:04:35.161789Z","iopub.status.idle":"2022-03-31T15:04:35.186546Z","shell.execute_reply.started":"2022-03-31T15:04:35.16174Z","shell.execute_reply":"2022-03-31T15:04:35.185653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numeric features are already encoded correctly (`float` for continuous, `int` for discrete), but the categoricals we'll need to do ourselves.","metadata":{}},{"cell_type":"code","source":"for col in temp.select_dtypes(['O']):\n    temp[col] = temp[col].astype('category')\n    if 'None' not in temp[col].cat.categories:\n        temp[col] = temp[col].cat.add_categories('None')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:37.925061Z","iopub.execute_input":"2022-03-31T15:04:37.925551Z","iopub.status.idle":"2022-03-31T15:04:38.009868Z","shell.execute_reply.started":"2022-03-31T15:04:37.925517Z","shell.execute_reply":"2022-03-31T15:04:38.008836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling the missing data","metadata":{}},{"cell_type":"code","source":"for col in temp.select_dtypes(['float64']):\n    temp[col] = temp[col].fillna(0.0)\n    \nfor col in temp.select_dtypes(['category']):\n    temp[col] = temp[col].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:40.782802Z","iopub.execute_input":"2022-03-31T15:04:40.783144Z","iopub.status.idle":"2022-03-31T15:04:40.82815Z","shell.execute_reply.started":"2022-03-31T15:04:40.783109Z","shell.execute_reply":"2022-03-31T15:04:40.827192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the  temp into train and test\ntrain_ = temp.loc[train_.index,:]\ntest_ = temp.loc[test_.index,:]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:44.853054Z","iopub.execute_input":"2022-03-31T15:04:44.853683Z","iopub.status.idle":"2022-03-31T15:04:44.870773Z","shell.execute_reply.started":"2022-03-31T15:04:44.853623Z","shell.execute_reply":"2022-03-31T15:04:44.86954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets get the data back to the way it was before by making `PassengerId` a column ","metadata":{}},{"cell_type":"code","source":"train_ = train_.reset_index('PassengerId')\ntest_ = test_.reset_index('PassengerId')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:49.503231Z","iopub.execute_input":"2022-03-31T15:04:49.503571Z","iopub.status.idle":"2022-03-31T15:04:49.511667Z","shell.execute_reply.started":"2022-03-31T15:04:49.503529Z","shell.execute_reply":"2022-03-31T15:04:49.510939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In training data -- we've the label column `Transported`, let's fix it","metadata":{}},{"cell_type":"code","source":"# fixing train labels \ntrain_['Transported'] = train_['Transported'].astype('bool')\n# there are no labels in test data \ntest_.drop(columns=['Transported'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:04:52.864064Z","iopub.execute_input":"2022-03-31T15:04:52.864574Z","iopub.status.idle":"2022-03-31T15:04:52.873667Z","shell.execute_reply.started":"2022-03-31T15:04:52.864541Z","shell.execute_reply":"2022-03-31T15:04:52.872777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAINING DATA -- after processing \ntrain_.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T10:34:19.526637Z","iopub.execute_input":"2022-03-31T10:34:19.527523Z","iopub.status.idle":"2022-03-31T10:34:19.551156Z","shell.execute_reply.started":"2022-03-31T10:34:19.52748Z","shell.execute_reply":"2022-03-31T10:34:19.55053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST DATA -- after processing \ntest_.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T10:34:44.808257Z","iopub.execute_input":"2022-03-31T10:34:44.808551Z","iopub.status.idle":"2022-03-31T10:34:44.824994Z","shell.execute_reply.started":"2022-03-31T10:34:44.808517Z","shell.execute_reply":"2022-03-31T10:34:44.824339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features and labels","metadata":{}},{"cell_type":"code","source":"def get_features_for_ensemble_models(data, drop_feat=[]):\n    df = data.copy()\n    df = df.drop(columns=drop_feat)\n\n    for col in df.select_dtypes(['category']):\n        df[col],_ = df[col].factorize()\n    \n    return df\n\nX = get_features_for_ensemble_models(train_, drop_feat=['PassengerId','Name','Transported'])\ny = train_['Transported'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:05:00.586573Z","iopub.execute_input":"2022-03-31T15:05:00.587337Z","iopub.status.idle":"2022-03-31T15:05:00.603192Z","shell.execute_reply.started":"2022-03-31T15:05:00.587299Z","shell.execute_reply":"2022-03-31T15:05:00.602237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline model\n\nlets create a tree based model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# CLASSIFICATION LINEAR MODELS\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\n\n# CLASSIFICATION TREE BASED MODEL\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:05:04.986303Z","iopub.execute_input":"2022-03-31T15:05:04.986584Z","iopub.status.idle":"2022-03-31T15:05:06.556842Z","shell.execute_reply.started":"2022-03-31T15:05:04.986553Z","shell.execute_reply":"2022-03-31T15:05:06.555771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_list = [\n    ('RandomForestClassifier',RandomForestClassifier()),\n    ('GradientBoostingClassifier',GradientBoostingClassifier()),\n    ('XGBClassifier',XGBClassifier(eval_metric='logloss',use_label_encoder=False)),\n    ('LogisticRegression',LogisticRegression(max_iter=1000)),\n    ('SVC',SVC()),\n    ('KNeighborsClassifier',KNeighborsClassifier()),\n    ('SGDClassifier',SGDClassifier())\n]\n\n\n\ndef model_performance(X,y,models=model_list):\n    for name, model in models:\n        cv = cross_val_score(model,X,y,scoring='accuracy',cv=5)\n        print(f'{name !r:30} : {np.mean(cv)}')\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:05:45.717742Z","iopub.execute_input":"2022-03-31T15:05:45.718041Z","iopub.status.idle":"2022-03-31T15:05:45.725482Z","shell.execute_reply.started":"2022-03-31T15:05:45.717996Z","shell.execute_reply":"2022-03-31T15:05:45.724422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_performance(X,y,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T10:22:44.003627Z","iopub.execute_input":"2022-03-31T10:22:44.0044Z","iopub.status.idle":"2022-03-31T10:23:13.001816Z","shell.execute_reply.started":"2022-03-31T10:22:44.004359Z","shell.execute_reply":"2022-03-31T10:23:13.000862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model improvement \nOk, We have our baseline scores, now let's try to improve the classification\n\n**How can we improve the model**\n* While handling missing values we use `None` for categorical features and '0' for numerical features , we can try other imputations like using mean,mode,etc.. for numerical features and try using most_frequent values for categorical features\n* Use standard scaler to standardize the numerical features\n* Hyperparameter tuning \n* Throw away poor predictors \n* Check correlation score for insights \n* Cheek mutual information\n* Feature engineering ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nX_ = pd.concat([X,y],axis=1)\nplt.figure(figsize=(10,10))\nsns.heatmap(X_.corr(), annot=True)\nplt.title('Correlation',fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:46:13.205163Z","iopub.execute_input":"2022-03-30T15:46:13.205669Z","iopub.status.idle":"2022-03-30T15:46:14.037181Z","shell.execute_reply.started":"2022-03-30T15:46:13.205629Z","shell.execute_reply":"2022-03-30T15:46:14.036326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# mutual information\nfrom sklearn.feature_selection import mutual_info_classif\n\ndiscrete = []\nfor col in X.columns:\n    discrete.append(X[col].dtype == int)\n\nmi_score = pd.DataFrame(mutual_info_classif(X,y,discrete_features=discrete), index=X.columns, columns=['Mutual information'])\n\nplt.barh(np.arange(len(discrete)), mi_score['Mutual information'])\nplt.yticks(ticks=np.arange(len(discrete)),labels=mi_score.index)\nplt.xlabel('Mutual information')\nmi_score\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:04:08.770849Z","iopub.execute_input":"2022-03-30T16:04:08.771521Z","iopub.status.idle":"2022-03-30T16:04:09.228141Z","shell.execute_reply.started":"2022-03-30T16:04:08.771474Z","shell.execute_reply":"2022-03-30T16:04:09.227233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  It looks like these features ['VIP','Age','Destination'] have some interation \nmodel_performance(X.drop(columns=['VIP','Age','Destination']), y,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:16:23.649271Z","iopub.execute_input":"2022-03-30T16:16:23.650201Z","iopub.status.idle":"2022-03-30T16:16:48.00671Z","shell.execute_reply.started":"2022-03-30T16:16:23.650156Z","shell.execute_reply":"2022-03-30T16:16:48.005801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='CryoSleep', y='Age', hue='Transported',data=train_);","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:41:01.3182Z","iopub.execute_input":"2022-03-30T16:41:01.318514Z","iopub.status.idle":"2022-03-30T16:41:01.859174Z","shell.execute_reply.started":"2022-03-30T16:41:01.318467Z","shell.execute_reply":"2022-03-30T16:41:01.858618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='VIP',y='Age',hue='Transported',data=train_ );","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:40:11.446856Z","iopub.execute_input":"2022-03-30T16:40:11.447139Z","iopub.status.idle":"2022-03-30T16:40:11.989385Z","shell.execute_reply.started":"2022-03-30T16:40:11.447112Z","shell.execute_reply":"2022-03-30T16:40:11.988543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# droping the neumerical features -- not a good idea\nX_ = X.drop(columns=['FoodCourt','Spa','VRDeck','ShoppingMall','RoomService'])\nmodel_performance(X_,y,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:51:54.131549Z","iopub.execute_input":"2022-03-30T16:51:54.132179Z","iopub.status.idle":"2022-03-30T16:52:19.403132Z","shell.execute_reply.started":"2022-03-30T16:51:54.132139Z","shell.execute_reply":"2022-03-30T16:52:19.402258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = ['FoodCourt','Spa','VRDeck','ShoppingMall','RoomService','Age']\n# Lets trying standardize the continuous numerical features, it helps the linear models\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_ = scaler.fit_transform(X.loc[:,feats])\nmodel_performance(X_,y,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T17:00:53.56705Z","iopub.execute_input":"2022-03-30T17:00:53.567762Z","iopub.status.idle":"2022-03-30T17:01:14.374793Z","shell.execute_reply.started":"2022-03-30T17:00:53.567722Z","shell.execute_reply":"2022-03-30T17:01:14.373931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standardized numerical feats and categorical features\n\nnum_feats = ['FoodCourt','Spa','VRDeck','ShoppingMall','RoomService','Age']\ncat_feats = ['HomePlanet','CryoSleep','Destination']\n# Lets trying standardize the continuous numerical features, it helps the linear models\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nscaler = StandardScaler()\nohe = OneHotEncoder()\nscaled = scaler.fit_transform(X.loc[:,num_feats])\none_hot = ohe.fit_transform(X.loc[:,cat_feats])\n\nX_ = np.column_stack((one_hot.todense(),scaled))\n\n\nmodel_performance(np.asarray(X_),y,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T17:12:37.368919Z","iopub.execute_input":"2022-03-30T17:12:37.369226Z","iopub.status.idle":"2022-03-30T17:13:02.273576Z","shell.execute_reply.started":"2022-03-30T17:12:37.369198Z","shell.execute_reply":"2022-03-30T17:13:02.2727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check for number of values in Cabin\n# We want features that help our model to Generalize not to overfit\nX['Cabin'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:17:32.956065Z","iopub.execute_input":"2022-03-30T16:17:32.956562Z","iopub.status.idle":"2022-03-30T16:17:32.965133Z","shell.execute_reply.started":"2022-03-30T16:17:32.956529Z","shell.execute_reply":"2022-03-30T16:17:32.964138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cabin has so many categories , Lets try classification without Cabin as a feature\n# Simplicity can break Complexity\nmodel_performance(X.drop(columns=['Cabin']), y, model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T10:23:37.694867Z","iopub.execute_input":"2022-03-31T10:23:37.695168Z","iopub.status.idle":"2022-03-31T10:23:59.605344Z","shell.execute_reply.started":"2022-03-31T10:23:37.695139Z","shell.execute_reply":"2022-03-31T10:23:59.604397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_imputer_param = {'strategy':'mean', 'fill_value':0}\ncat_imputer_param = {'strategy':'most_frequent', 'fill_value':'None'}\n\n\ndef make_model_pipeline(model, num_imputer_param, cat_imputer_param):\n    num_feats = ['FoodCourt','Spa','VRDeck','ShoppingMall','RoomService','Age']\n    cat_feats = ['HomePlanet','CryoSleep','Destination']\n\n    num_transformer = Pipeline(steps=[('inpute', SimpleImputer(**num_imputer_param)),\n                                      ('scaler', StandardScaler())])\n\n    cat_transformer = Pipeline(steps=[('inpute', SimpleImputer(**cat_imputer_param)),\n                                      ('encode', OneHotEncoder(handle_unknown='ignore'))])\n\n    transformer = ColumnTransformer(transformers=[\n        ('numerical', num_transformer, num_feats),\n        ('categorical', cat_transformer, cat_feats)\n    ])\n\n\n    modeling = Pipeline(steps=[\n        ('preprocessing',transformer),\n        ('modeling',model)\n    ])\n    \n    return modeling\n\n\ndef evaluate_pipeline(X, y, num_imputer_param, cat_imputer_param, models=model_list):\n    for name, model in models:\n        pipe = make_model_pipeline(model,num_imputer_param, cat_imputer_param)\n        cv = cross_val_score(pipe,X,y,scoring='accuracy',cv=5)\n        print(f'{name !r:30} : {np.mean(cv)}')\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:17:41.107847Z","iopub.execute_input":"2022-03-31T15:17:41.108546Z","iopub.status.idle":"2022-03-31T15:17:41.121616Z","shell.execute_reply.started":"2022-03-31T15:17:41.108507Z","shell.execute_reply":"2022-03-31T15:17:41.120461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets try imputing missing values with mean, median, most_frequent etc...\n","metadata":{}},{"cell_type":"code","source":"num_imputer_param = {'strategy':'median'}\ncat_imputer_param = {'strategy':'most_frequent'}\nclf = make_model_pipeline(SVC(),num_imputer_param, cat_imputer_param)\ncv_scores = cross_val_score(clf, train, y, cv=5, scoring='accuracy')\nprint(cv_scores,'\\nmean score',np.mean(cv_scores))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T10:44:49.977069Z","iopub.execute_input":"2022-03-31T10:44:49.977363Z","iopub.status.idle":"2022-03-31T10:45:01.332994Z","shell.execute_reply.started":"2022-03-31T10:44:49.977328Z","shell.execute_reply":"2022-03-31T10:45:01.332014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_imputer_param = {'strategy':'mean'}\ncat_imputer_param = {'strategy':'most_frequent'}\nevaluate_pipeline(train,y,num_imputer_param,cat_imputer_param,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:09:59.612108Z","iopub.execute_input":"2022-03-31T15:09:59.612812Z","iopub.status.idle":"2022-03-31T15:10:26.526485Z","shell.execute_reply.started":"2022-03-31T15:09:59.612775Z","shell.execute_reply":"2022-03-31T15:10:26.52526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_imputer_param = {'strategy':'median'}\ncat_imputer_param = {'strategy':'most_frequent'}\nevaluate_pipeline(train,y,num_imputer_param,cat_imputer_param,model_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:17:48.446345Z","iopub.execute_input":"2022-03-31T15:17:48.447189Z","iopub.status.idle":"2022-03-31T15:18:16.593641Z","shell.execute_reply.started":"2022-03-31T15:17:48.447148Z","shell.execute_reply":"2022-03-31T15:18:16.592493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyper parameter tuning ","metadata":{}},{"cell_type":"code","source":"models__to_tune= [\n          ('RandomForest', \\\n           RandomForestClassifier(), \\\n           {'modeling__max_depth':[i for i in range(4,12)]}), \\\n          \n          ('LogisticRegression', \\\n           LogisticRegression(), \\\n           {'modeling__C':[i*0.1 for i in range(10,15)]}), \\\n          \n          ('GradientBoosting', \\\n           GradientBoostingClassifier(), \\\n           {'modeling__n_estimators':[i for i in range(100,300,50)]}), \\\n          \n          ('SVC', \\\n           SVC(), \\\n           {'modeling__C':[i for i in range(1,10)]}), \\\n          \n          ('SGDClassifier',SGDClassifier(), \\\n           {'modeling__warm_start':[True,False], \\\n            'modeling__early_stopping':[True,False], \\\n            'modeling__average':[True,False]}), \\\n          \n         ('XGBClassifier', \\\n           XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \\\n           {'modeling__colsample_bytree':[0.7], \\\n            'modeling__colsample_bylevel':[0.5], \\\n            'modeling__colsample_bynode':[0.7], \\\n            'modeling__subsample':[0.6,0.7]}) \\\n         ]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:19:59.945034Z","iopub.execute_input":"2022-03-31T15:19:59.945319Z","iopub.status.idle":"2022-03-31T15:19:59.954614Z","shell.execute_reply.started":"2022-03-31T15:19:59.945287Z","shell.execute_reply":"2022-03-31T15:19:59.953741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nnum_imputer_param = {'strategy':'mean'}\ncat_imputer_param = {'strategy':'most_frequent'}\n\nfor name, model, param_grid in models__to_tune:\n    pipe = make_model_pipeline(model, num_imputer_param, cat_imputer_param)\n    gs = GridSearchCV(pipe, param_grid)\n    gs.fit(X,y)\n    print(f'{name :30} {gs.best_score_}')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:22:59.958574Z","iopub.execute_input":"2022-03-31T15:22:59.958909Z","iopub.status.idle":"2022-03-31T15:26:28.85261Z","shell.execute_reply.started":"2022-03-31T15:22:59.958876Z","shell.execute_reply":"2022-03-31T15:26:28.85162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets find the best parameters ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nnum_imputer_param = {'strategy':'mean'}\ncat_imputer_param = {'strategy':'most_frequent'}\nparam_grid = {'modeling__n_estimators':[i for i in range(100,500,50)]}\nclf = GradientBoostingClassifier()\npipe = make_model_pipeline(clf, num_imputer_param, cat_imputer_param)\ngs = GridSearchCV(pipe, param_grid)\ngs.fit(train,y)\nprint(f'GradientBoostingClassifier: {gs.best_score_}')\nprint(gs.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:31:20.525329Z","iopub.execute_input":"2022-03-31T15:31:20.525645Z","iopub.status.idle":"2022-03-31T15:32:50.479819Z","shell.execute_reply.started":"2022-03-31T15:31:20.525612Z","shell.execute_reply":"2022-03-31T15:32:50.478761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets submit","metadata":{}},{"cell_type":"code","source":"# classifier\nclf = GradientBoostingClassifier(n_estimators=200)\n\n# # modeling\nnum_imputer_param = {'strategy':'mean'}\ncat_imputer_param = {'strategy':'most_frequent'}\npipe = make_model_pipeline(clf,num_imputer_param,cat_imputer_param)\n# # training \npipe.fit(train,y)\n\n# # prediction\ny_preds = pipe.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:34:08.720047Z","iopub.execute_input":"2022-03-31T15:34:08.720354Z","iopub.status.idle":"2022-03-31T15:34:10.709342Z","shell.execute_reply.started":"2022-03-31T15:34:08.72032Z","shell.execute_reply":"2022-03-31T15:34:10.708346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(data={'PassengerId':test['PassengerId'].values,\n                                'Transported':y_preds.astype('bool')})","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:34:13.243737Z","iopub.execute_input":"2022-03-31T15:34:13.244017Z","iopub.status.idle":"2022-03-31T15:34:13.249201Z","shell.execute_reply.started":"2022-03-31T15:34:13.243985Z","shell.execute_reply":"2022-03-31T15:34:13.248559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the submission\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:34:17.81238Z","iopub.execute_input":"2022-03-31T15:34:17.813104Z","iopub.status.idle":"2022-03-31T15:34:17.827217Z","shell.execute_reply.started":"2022-03-31T15:34:17.813049Z","shell.execute_reply":"2022-03-31T15:34:17.826215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}