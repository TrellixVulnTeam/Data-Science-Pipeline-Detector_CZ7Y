{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-15T06:54:12.538609Z","iopub.execute_input":"2022-03-15T06:54:12.539919Z","iopub.status.idle":"2022-03-15T06:54:12.573474Z","shell.execute_reply.started":"2022-03-15T06:54:12.539765Z","shell.execute_reply":"2022-03-15T06:54:12.572322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:12.575672Z","iopub.execute_input":"2022-03-15T06:54:12.575899Z","iopub.status.idle":"2022-03-15T06:54:13.708769Z","shell.execute_reply.started":"2022-03-15T06:54:12.575871Z","shell.execute_reply":"2022-03-15T06:54:13.708081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:13.709809Z","iopub.execute_input":"2022-03-15T06:54:13.710198Z","iopub.status.idle":"2022-03-15T06:54:13.82576Z","shell.execute_reply.started":"2022-03-15T06:54:13.710162Z","shell.execute_reply":"2022-03-15T06:54:13.824654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Expanding Features\nSome of the features like Cabin and PassengerID have more information about the passenger within their features. By expanding these features we can have more information about a passenger which could be important for training the ML model. ","metadata":{}},{"cell_type":"code","source":"train[[\"Deck\", \"Cabin_Num\", \"Side\"]] = train.Cabin.str.split(\"/\", expand=True)\ntest[[\"Deck\", \"Cabin_Num\", \"Side\"]] = test.Cabin.str.split(\"/\", expand=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:13.827258Z","iopub.execute_input":"2022-03-15T06:54:13.827506Z","iopub.status.idle":"2022-03-15T06:54:13.888745Z","shell.execute_reply.started":"2022-03-15T06:54:13.827471Z","shell.execute_reply":"2022-03-15T06:54:13.887659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[[\"Group\", \"Group_Num\"]] = train.PassengerId.str.split(\"_\", expand=True)\ntest[[\"Group\", \"Group_Num\"]] = test.PassengerId.str.split(\"_\", expand=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:13.891407Z","iopub.execute_input":"2022-03-15T06:54:13.891659Z","iopub.status.idle":"2022-03-15T06:54:13.947879Z","shell.execute_reply.started":"2022-03-15T06:54:13.891629Z","shell.execute_reply":"2022-03-15T06:54:13.94706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Replacing NaN values\n\nI will first replace values using a simple method such as using the median or mode to replace values. But later might look into replacing values using unsupervised learning like clustering. \n\nAlso fill in the test set's NaNs with the same values from the training data so there is no leakage of data.","metadata":{}},{"cell_type":"code","source":"for i in train.columns:\n    if train[i].isna().sum() > 0:\n        print(f\"{i}: {train[i].isna().sum()}\")\n\nprint(\"\\n\", \"test NaNs\", \"\\n\")\nfor i in test.columns:\n    if test[i].isna().sum() > 0:\n        print(f\"{i}: {test[i].isna().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:13.949336Z","iopub.execute_input":"2022-03-15T06:54:13.950107Z","iopub.status.idle":"2022-03-15T06:54:14.012681Z","shell.execute_reply.started":"2022-03-15T06:54:13.950067Z","shell.execute_reply":"2022-03-15T06:54:14.011917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train.columns:\n    print(f\"{i}: {train[i].nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.01404Z","iopub.execute_input":"2022-03-15T06:54:14.014531Z","iopub.status.idle":"2022-03-15T06:54:14.050495Z","shell.execute_reply.started":"2022-03-15T06:54:14.014493Z","shell.execute_reply":"2022-03-15T06:54:14.049696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a list of columns that only have a couple of values to replace with mode\nmode_list = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\n\n# Replace these columns NaN values with the mode. \nfor i in mode_list:\n    train[i] = train[i].fillna(train[i].mode()[0])\n    test[i] = test[i].fillna(train[i].mode()[0])     # Fill in the test with same values\n    \nfor i in train.columns:\n    if train[i].isna().sum() > 0:\n        print(f\"{i}: {train[i].isna().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.051992Z","iopub.execute_input":"2022-03-15T06:54:14.05309Z","iopub.status.idle":"2022-03-15T06:54:14.116537Z","shell.execute_reply.started":"2022-03-15T06:54:14.053031Z","shell.execute_reply":"2022-03-15T06:54:14.115703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a list of numeric columns to replace with the median\nmedian_list = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n\nfor i in median_list:\n    train[i] = train[i].fillna(train[i].median())\n    test[i] = test[i].fillna(train[i].median())     # Fill in the test with same values\n    \nfor i in train.columns:\n    if train[i].isna().sum() > 0:\n        print(f\"{i}: {train[i].isna().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.117788Z","iopub.execute_input":"2022-03-15T06:54:14.118595Z","iopub.status.idle":"2022-03-15T06:54:14.150858Z","shell.execute_reply.started":"2022-03-15T06:54:14.118551Z","shell.execute_reply":"2022-03-15T06:54:14.149991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These last columns will have NaN values replaced with a value that indicates that there wasn't a value.\ntrain[\"Cabin\"] = train[\"Cabin\"].fillna(f\"{train.Deck}/-1/{train.Side}\")\ntrain[\"Name\"] = train[\"Name\"].fillna(\"No name listed\")\ntrain[\"Cabin_Num\"] = train[\"Cabin_Num\"].fillna(\"-1\")\n\ntest[\"Cabin\"] = test[\"Cabin\"].fillna(f\"{train.Deck}/-1/{train.Side}\")\ntest[\"Name\"] = test[\"Name\"].fillna(\"No name listed\")\ntest[\"Cabin_Num\"] = test[\"Cabin_Num\"].fillna(\"-1\")\n\nfor i in train.columns:\n    if train[i].isna().sum() > 0:\n        print(f\"{i}: {train[i].isna().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.152182Z","iopub.execute_input":"2022-03-15T06:54:14.152423Z","iopub.status.idle":"2022-03-15T06:54:14.19016Z","shell.execute_reply.started":"2022-03-15T06:54:14.152394Z","shell.execute_reply":"2022-03-15T06:54:14.189121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple Pipeline\n\nBecause this is a simple model, I will use a pipeline to change categorical features to numeric, scale the data, and make predictions. \n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom category_encoders.ordinal import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\noe = OrdinalEncoder()\nscaler = StandardScaler()\nlogit = LogisticRegression()\n\npipe = Pipeline([(\"Encoder\", oe), (\"Scaler\", scaler), (\"Logistic Regression\", logit)])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.191531Z","iopub.execute_input":"2022-03-15T06:54:14.191754Z","iopub.status.idle":"2022-03-15T06:54:14.733025Z","shell.execute_reply.started":"2022-03-15T06:54:14.191727Z","shell.execute_reply":"2022-03-15T06:54:14.731791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train.drop(\"Transported\", axis=1)\ny = train[\"Transported\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.73584Z","iopub.execute_input":"2022-03-15T06:54:14.736209Z","iopub.status.idle":"2022-03-15T06:54:14.762398Z","shell.execute_reply.started":"2022-03-15T06:54:14.736163Z","shell.execute_reply":"2022-03-15T06:54:14.761182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:14.76416Z","iopub.execute_input":"2022-03-15T06:54:14.764431Z","iopub.status.idle":"2022-03-15T06:54:15.045216Z","shell.execute_reply.started":"2022-03-15T06:54:14.764395Z","shell.execute_reply":"2022-03-15T06:54:15.044154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch model\n\nUse a neural network for prediction.","metadata":{}},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:15.053884Z","iopub.execute_input":"2022-03-15T06:54:15.056847Z","iopub.status.idle":"2022-03-15T06:54:15.069555Z","shell.execute_reply.started":"2022-03-15T06:54:15.056777Z","shell.execute_reply":"2022-03-15T06:54:15.06863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_pipe = Pipeline([(\"Encoder\", oe), (\"Scaler\", scaler)])\ntransform_pipe.fit(X_train)\nX_train_transform = transform_pipe.transform(X_train)\nX_test_transform = transform_pipe.transform(X_test)\n\nprint(X_train_transform.shape, X_test_transform.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:15.076001Z","iopub.execute_input":"2022-03-15T06:54:15.078868Z","iopub.status.idle":"2022-03-15T06:54:15.273925Z","shell.execute_reply.started":"2022-03-15T06:54:15.078809Z","shell.execute_reply":"2022-03-15T06:54:15.272993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n\n# Change the train and test data to type tensor. \nclass trainData(Dataset):\n    def __init__(self, x_data, y_data):\n        self.x_data = x_data\n        self.y_data = y_data\n    \n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n    \n    def __len__(self):\n        return len(self.x_data)\n\ntrain_data = trainData(torch.tensor(X_train_transform, dtype=torch.float, requires_grad=True), \n                       torch.tensor(y_train.to_numpy(), dtype=torch.float, requires_grad=True))\n\nclass testData(Dataset):\n    def __init__(self, x_data):\n        self.x_data = x_data\n    \n    def __getitem__(self, index):\n        return self.x_data[index]\n    \n    def __len__(self):\n        return len(self.x_data)\n\ntest_data = testData(torch.tensor(X_test_transform, dtype=torch.float))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:15.277244Z","iopub.execute_input":"2022-03-15T06:54:15.27748Z","iopub.status.idle":"2022-03-15T06:54:16.619911Z","shell.execute_reply.started":"2022-03-15T06:54:15.277449Z","shell.execute_reply":"2022-03-15T06:54:16.619104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set hyperparameters for neural network.\nEpochs = 50\nbatch_size = 64\nlearning_rate = 3e-4\n\n# Load the data into a data loader\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:16.622886Z","iopub.execute_input":"2022-03-15T06:54:16.623292Z","iopub.status.idle":"2022-03-15T06:54:16.633745Z","shell.execute_reply.started":"2022-03-15T06:54:16.623242Z","shell.execute_reply":"2022-03-15T06:54:16.632849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create neural network for binary classification\nclass BinaryClass(nn.Module):\n    def __init__(self):\n        super(BinaryClass, self).__init__()\n        self.fc1 = nn.Linear(18, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.result = nn.Linear(32, 1)\n        \n        self.relu = nn.ReLU()\n        self.drop = nn.Dropout(p=0.2)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(32)\n    \n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.bn1(x)\n        x = self.relu(self.fc2(x))\n        x = self.bn2(x)\n        x = self.drop(x)\n        x = self.result(x)\n        \n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:16.636418Z","iopub.execute_input":"2022-03-15T06:54:16.637726Z","iopub.status.idle":"2022-03-15T06:54:16.654481Z","shell.execute_reply.started":"2022-03-15T06:54:16.637659Z","shell.execute_reply":"2022-03-15T06:54:16.653319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:16.656114Z","iopub.execute_input":"2022-03-15T06:54:16.656635Z","iopub.status.idle":"2022-03-15T06:54:16.675448Z","shell.execute_reply.started":"2022-03-15T06:54:16.65658Z","shell.execute_reply":"2022-03-15T06:54:16.67405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BinaryClass()\nmodel.to(device)\nprint(model)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:16.677285Z","iopub.execute_input":"2022-03-15T06:54:16.678359Z","iopub.status.idle":"2022-03-15T06:54:16.725278Z","shell.execute_reply.started":"2022-03-15T06:54:16.678311Z","shell.execute_reply":"2022-03-15T06:54:16.724326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:16.726469Z","iopub.execute_input":"2022-03-15T06:54:16.726699Z","iopub.status.idle":"2022-03-15T06:54:16.733285Z","shell.execute_reply.started":"2022-03-15T06:54:16.72667Z","shell.execute_reply":"2022-03-15T06:54:16.732337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\nfor e in range(1, Epochs+1):\n    epoch_loss = 0\n    epoch_acc = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_pred = model(X_batch)\n        \n        loss = criterion(y_pred, y_batch.unsqueeze(1))\n        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:16.734397Z","iopub.execute_input":"2022-03-15T06:54:16.735029Z","iopub.status.idle":"2022-03-15T06:54:58.680655Z","shell.execute_reply.started":"2022-03-15T06:54:16.734976Z","shell.execute_reply":"2022-03-15T06:54:58.680001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_list = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:58.68214Z","iopub.execute_input":"2022-03-15T06:54:58.682579Z","iopub.status.idle":"2022-03-15T06:54:59.007405Z","shell.execute_reply.started":"2022-03-15T06:54:58.682498Z","shell.execute_reply":"2022-03-15T06:54:59.006197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, y_pred_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:59.011041Z","iopub.execute_input":"2022-03-15T06:54:59.011365Z","iopub.status.idle":"2022-03-15T06:54:59.023264Z","shell.execute_reply.started":"2022-03-15T06:54:59.011331Z","shell.execute_reply":"2022-03-15T06:54:59.022146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_list))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:59.0248Z","iopub.execute_input":"2022-03-15T06:54:59.025141Z","iopub.status.idle":"2022-03-15T06:54:59.04225Z","shell.execute_reply.started":"2022-03-15T06:54:59.025097Z","shell.execute_reply":"2022-03-15T06:54:59.041363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit Predictions\n\nUse this simple model to submit predictions and see how well it does. ","metadata":{}},{"cell_type":"code","source":"# y_real_pred = pipe.predict(test)\n\ntest_transform = transform_pipe.transform(test)\nreal_test_data = testData(torch.tensor(test_transform, dtype=torch.float))\nreal_test_loader = DataLoader(real_test_data, batch_size=1)\ny_real_pred = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in real_test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_real_pred.append(y_pred_tag.cpu().numpy())\n\ny_real_pred = [a.squeeze().tolist() for a in y_real_pred]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:59.043565Z","iopub.execute_input":"2022-03-15T06:54:59.043909Z","iopub.status.idle":"2022-03-15T06:54:59.827018Z","shell.execute_reply.started":"2022-03-15T06:54:59.043878Z","shell.execute_reply":"2022-03-15T06:54:59.826036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:54:59.829357Z","iopub.execute_input":"2022-03-15T06:54:59.829592Z","iopub.status.idle":"2022-03-15T06:54:59.854739Z","shell.execute_reply.started":"2022-03-15T06:54:59.829564Z","shell.execute_reply":"2022-03-15T06:54:59.853255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_real_pred = pd.Series(y_real_pred, name=\"Transported\")\ndf_pred = pd.concat([test.PassengerId, y_real_pred], axis=1)\ndf_pred[\"Transported\"] = df_pred[\"Transported\"].replace({1.0: True, 0.0: False})\ndf_pred.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:57:30.436133Z","iopub.execute_input":"2022-03-15T06:57:30.437196Z","iopub.status.idle":"2022-03-15T06:57:30.454408Z","shell.execute_reply.started":"2022-03-15T06:57:30.437143Z","shell.execute_reply":"2022-03-15T06:57:30.453158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T06:57:36.626341Z","iopub.execute_input":"2022-03-15T06:57:36.627354Z","iopub.status.idle":"2022-03-15T06:57:36.641689Z","shell.execute_reply.started":"2022-03-15T06:57:36.627303Z","shell.execute_reply":"2022-03-15T06:57:36.641011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}