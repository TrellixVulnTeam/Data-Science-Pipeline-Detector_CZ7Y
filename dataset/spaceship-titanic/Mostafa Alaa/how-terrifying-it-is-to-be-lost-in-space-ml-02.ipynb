{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://www.108themes.com/hubble/slider/11.jpg\" style=\"border-radius:50%\">\n<h1 style=\"font-size:45px;color:#35858B;text-align:center\"><strong>Titanic</strong> <strong style=\"color:black\">Spaceship Story (Part 2)</strong></h1>\n\n<i style=\"font-size:100%\">&nbsp;&nbsp;&nbsp;&nbsp;In 2912, there was a spaceship of 13,000 passengers launched to tranport emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars...And this was the first voyage from its kind.</i>\n<i style=\"font-size:100%\">On its way and nothing happen, suddenly it has been collided with a spacetime anomaly hidden within a dust cloud, which ends up with what happen to it since 1000 years ago, almost half of the passengers were transported to an alternate dimension!</i>\n\n### This notebook came with another one for EDA:\n<a href=\"https://www.kaggle.com/mostafaalaa123/how-terrifying-it-is-to-be-lost-in-space-eda-01?scriptVersionId=88800839\">EDA Notebook</a>","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML, Javascript\n\n# ----- Notebook Theme -----\ncolor_map = ['#35858B', '#f6f0e8', '#ecdfd0', '#d9c1a2', '#AEFEFF', '#072227', \n                        '#35858B', '#8d6213', '#117a65', '#7a5211', '#4FBDBA']\n\nprompt = color_map[-1]\nmain_color = color_map[0]\nstrong_main_color = color_map[1]\ncustom_colors = [strong_main_color, main_color]\n\ncss_file = ''' \n\ndiv #notebook {\nbackground-color: white;\nline-height: 20px;\n}\n\n#notebook-container {\n%s\nmargin-top: 2em;\npadding-top: 2em;\nborder-top: 4px solid %s; /* light orange */\n-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n}\n\ndiv .input {\nmargin-bottom: 1em;\n}\n\n.rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\ncolor: %s; /* light orange */\nfont-weight: 600;\n}\n\ndiv.input_area {\nborder: none;\n    background-color: %s; /* rgba(229, 143, 101, 0.1); light orange [exactly #E58F65] */\n    border-top: 2px solid %s; /* light orange */\n}\n\ndiv.input_prompt {\ncolor: %s; /* light blue */\n}\n\ndiv.output_prompt {\ncolor: %s; /* strong orange */\n}\n\ndiv.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\nbackground: %s; /* light orange */\n}\n\ndiv.cell.selected, div.cell.selected.jupyter-soft-selected {\n    border-color: %s; /* light orange */\n}\n\n.edit_mode div.cell.selected:before {\nbackground: %s; /* light orange */\n}\n\n.edit_mode div.cell.selected {\nborder-color: %s; /* light orange */\n\n}\n'''\ndef to_rgb(h): \n    return tuple(int(h[i:i+2], 16) for i in [0, 2, 4])\n\nmain_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:]))\nopen('notebook.css', 'w').write(css_file % ('width: 95%;', main_color, main_color, main_color_rgba, main_color,  main_color, prompt, main_color, main_color, main_color, main_color))\n\ndef nb(): \n    return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\nnb()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-01T12:08:17.648497Z","iopub.execute_input":"2022-03-01T12:08:17.648879Z","iopub.status.idle":"2022-03-01T12:08:17.667196Z","shell.execute_reply.started":"2022-03-01T12:08:17.648838Z","shell.execute_reply":"2022-03-01T12:08:17.666383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initial Cell\n\n# Importing Libraries\n\n# For Data Preprocessing and Analysis\nimport pandas as pd\nimport numpy as np\n\n# For Data Viz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# Removing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, make_scorer\nfrom sklearn.model_selection import GridSearchCV\n\n# Data\ntrain_df = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest_df = pd.read_csv('../input/spaceship-titanic/test.csv')\nsample_sub = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\ndfs = [train_df, test_df]","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:17.668782Z","iopub.execute_input":"2022-03-01T12:08:17.669662Z","iopub.status.idle":"2022-03-01T12:08:17.762886Z","shell.execute_reply.started":"2022-03-01T12:08:17.669614Z","shell.execute_reply":"2022-03-01T12:08:17.761746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;Here what we're going, God willing, focus on is cleaning the  data and preparing it for ML part, the columns of interest at this notebook will be as said at the EDA notebook, which are the following:\n1. **PassengerId**: Dividing it into five columns\n    - Low_#group\n    - Medium_#group\n    - High_#group\n    - Id_is_1\n    - Id_is_2_or_3\n2. **Home Planet**: Dividing it into two columns\n    - Is_Europa\n    - Is_Earth\n3. **CryoSleep**: Just transform the boolean values into 0 and 1(True)\n4. **Cabin**: Dividing it into four columns\n    - Is_safe_decks (F, E, and D)\n    - Is_danger_decks (B, and C)\n    - Port_S\n    - Port_P\n5. **Age**: Divided into two columns\n    - Nine_or_less\n    - Is_between_19_24\n6. **RoomService, FoodCourt, ShoppingMall, Spa, and VRDeck**: will be transformed into one column called \"Total_payment\"\n7. **Destination**: Divided into two columns:\n    - \"Is_TRAPPIST-1e\"\n    - \"Is_55 Cancri e\"","metadata":{}},{"cell_type":"markdown","source":"> # PassengerId","metadata":{}},{"cell_type":"code","source":"# No need to clean it's full\n\n# Dividing PassengerId into #Group and id\nfor idx in range(2):\n    dfs[idx]['#Group'], dfs[idx]['id'] = dfs[idx]['PassengerId'].str[:4].astype('int'), dfs[idx]['PassengerId'].str[5:].astype('int')\n\n    \n    \n    \n    \n# Making The three columns from #Group\nfor idx in range(2):\n    \n    # \"Low_#group\" Less than or equal 3400\n    dfs[idx]['Low_#group'] = 0\n    dfs[idx].loc[dfs[idx]['#Group'] <= 3400, 'Low_#group'] = 1\n    \n    # \"Medium_#group\" in this range 3401, 7350\n    dfs[idx]['Medium_#group'] = 0\n    dfs[idx].loc[(dfs[idx]['#Group'] >= 3401) & (dfs[idx]['#Group'] <= 7350), 'Medium_#group'] = 1\n    \n    # \"High_#group\" higher than 7350\n    dfs[idx][\"High_#group\"] = 0\n    dfs[idx].loc[dfs[idx]['#Group'] >= 7351, \"High_#group\"] = 1\n\n    \n    \n    \n    \n# Making The three columns from id\nfor idx in range(2):\n    # Id_is_1\n    dfs[idx][\"Id_is_1\"] = 0\n    dfs[idx].loc[dfs[idx]['id'] == 1, \"Id_is_1\"] = 1\n    \n    # Id_is_2_or_3\n    dfs[idx][\"Id_is_2_or_3\"] = 0\n    dfs[idx].loc[(dfs[idx]['id'] == 2) | (dfs[idx]['id'] == 3), \"Id_is_2_or_3\"] = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:17.764899Z","iopub.execute_input":"2022-03-01T12:08:17.765286Z","iopub.status.idle":"2022-03-01T12:08:17.819989Z","shell.execute_reply.started":"2022-03-01T12:08:17.765234Z","shell.execute_reply":"2022-03-01T12:08:17.818703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Home Planet","metadata":{}},{"cell_type":"code","source":"# Cleaning up Home Planet will be by the mode\nfor idx in range(2):\n    dfs[idx].loc[dfs[idx]['HomePlanet'].isna(), 'HomePlanet'] = dfs[idx]['HomePlanet'].mode().values[0]\n    \n# Making the columns\nfor idx in range(2):\n    \n    # \"Is_Europa\"\n    dfs[idx]['Is_Europa'] = 0\n    dfs[idx].loc[dfs[idx]['HomePlanet'] == \"Europa\", 'Is_Europa'] = 1\n    \n    # \"Is_Earth\"\n    dfs[idx]['Is_Earth'] = 0\n    dfs[idx].loc[dfs[idx]['HomePlanet'] == \"Earth\", 'Is_Earth'] = 1\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:17.82209Z","iopub.execute_input":"2022-03-01T12:08:17.822799Z","iopub.status.idle":"2022-03-01T12:08:17.852622Z","shell.execute_reply.started":"2022-03-01T12:08:17.822748Z","shell.execute_reply":"2022-03-01T12:08:17.851614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # CryoSleep","metadata":{}},{"cell_type":"code","source":"# Cleaning up Home Planet will be by the mode\nfor idx in range(2):\n    dfs[idx].loc[dfs[idx]['CryoSleep'].isna(), 'CryoSleep'] = False\n    \n# Transform Boolean values into 0 and 1\nfor idx in range(2):\n    dfs[idx].loc[dfs[idx]['CryoSleep'] == False, 'CryoSleep'] = 0\n    dfs[idx].loc[dfs[idx]['CryoSleep'] == True, 'CryoSleep'] = 1\n    dfs[idx]['CryoSleep'] = dfs[idx]['CryoSleep'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:17.854131Z","iopub.execute_input":"2022-03-01T12:08:17.855836Z","iopub.status.idle":"2022-03-01T12:08:17.890816Z","shell.execute_reply.started":"2022-03-01T12:08:17.855619Z","shell.execute_reply":"2022-03-01T12:08:17.888589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Cabin","metadata":{}},{"cell_type":"code","source":"# Separation\nfor idx in range(2):\n    dfs[idx]['deck'], dfs[idx]['num'], dfs[idx]['side'] = dfs[idx]['Cabin'].str[0], dfs[idx]['Cabin'].str[2:-2], dfs[idx]['Cabin'].str[-1]\n\n# Cleaning\nfor idx in range(2):\n    \n    # Deck\n    dfs[idx]['ref'] = pd.Series(list(range(dfs[idx].shape[0]))) \n    dfs[idx].loc[dfs[idx]['deck'].isna(), 'deck'] = 'F' # Most Frequent\n    \n    # Side\n    side_indices = list(dfs[idx].loc[dfs[idx]['side'].isna(), 'side'].index)\n    num_missed = len(side_indices)\n    dfs[idx].loc[(dfs[idx]['side'].isna()) & (dfs[idx]['ref'].isin(side_indices[:num_missed//2])), 'side'] = 'S'\n    dfs[idx].loc[(dfs[idx]['side'].isna()) & (dfs[idx]['ref'].isin(side_indices[num_missed//2:])), 'side'] = 'P' \n    \n\n    \n# Making the columns\nfor idx in range(2):\n    \n    # Is_safe_deck (F, E, and D)\n    dfs[idx][\"Is_safe_deck\"] = 0\n    dfs[idx].loc[dfs[idx]['deck'].isin(list('FED')), \"Is_safe_deck\"] = 1\n    \n    # Is_danger_deck (B, C)\n    dfs[idx][\"Is_danger_deck\"] = 0\n    dfs[idx].loc[dfs[idx]['deck'].isin(list('BC')), \"Is_danger_deck\"] = 1\n    \n    # Port_S\n    dfs[idx][\"Port_S\"] = 0\n    dfs[idx].loc[dfs[idx]['side'] == 'S', \"Port_S\"] = 1\n    \n    # Port_P\n    dfs[idx][\"Port_P\"] = 0\n    dfs[idx].loc[dfs[idx]['side'] == 'P', \"Port_P\"] = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:17.899108Z","iopub.execute_input":"2022-03-01T12:08:17.899474Z","iopub.status.idle":"2022-03-01T12:08:17.993053Z","shell.execute_reply.started":"2022-03-01T12:08:17.899427Z","shell.execute_reply":"2022-03-01T12:08:17.991727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Age","metadata":{}},{"cell_type":"code","source":"# Cleaning\nfor idx in range(2):\n    dfs[idx].loc[dfs[idx]['Age'].isna(), 'Age'] = dfs[idx]['Age'].median()\n\n# Making The three columns from Age\nfor idx in range(2):\n    \n    # \"Nine_or_less\"\n    dfs[idx]['Nine_or_less'] = 0\n    dfs[idx].loc[dfs[idx]['Age'] <= 9, 'Nine_or_less'] = 1\n    \n    # \"Is_between_19_24\"\n    dfs[idx]['Is_between_19_24'] = 0\n    dfs[idx].loc[(dfs[idx]['Age'] >= 19) & (dfs[idx]['Age'] <= 24), 'Is_between_19_24'] = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:17.995767Z","iopub.execute_input":"2022-03-01T12:08:17.996136Z","iopub.status.idle":"2022-03-01T12:08:18.016944Z","shell.execute_reply.started":"2022-03-01T12:08:17.996088Z","shell.execute_reply":"2022-03-01T12:08:18.016051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Destination","metadata":{}},{"cell_type":"code","source":"# Cleaning\nfor idx in range(2):\n    dfs[idx].loc[dfs[idx]['Destination'].isna(), 'Destination'] = dfs[idx]['Destination'].mode().values[0] # Most Frequent\n    \n# Making columns\nfor idx in range(2):\n    \n    # \"Is_TRAPPIST-1e\"\n    dfs[idx]['Is_TRAPPIST-1e'] = 0\n    dfs[idx].loc[dfs[idx]['Destination'] == \"TRAPPIST-1e\", 'Is_TRAPPIST-1e'] = 1\n    dfs[idx]['Is_TRAPPIST-1e'] = dfs[idx]['Is_TRAPPIST-1e'].astype('int')\n    \n    # \"Is_55 Cancri e\"\n    dfs[idx]['Is_55 Cancri e'] = 0\n    dfs[idx].loc[dfs[idx]['Destination'] == \"55 Cancri e\", 'Is_55 Cancri e'] = 1\n    dfs[idx]['Is_55 Cancri e'] = dfs[idx]['Is_55 Cancri e'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:18.018439Z","iopub.execute_input":"2022-03-01T12:08:18.018738Z","iopub.status.idle":"2022-03-01T12:08:18.04998Z","shell.execute_reply.started":"2022-03-01T12:08:18.018703Z","shell.execute_reply":"2022-03-01T12:08:18.048733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Total Payment","metadata":{}},{"cell_type":"code","source":"pay_list = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n\n# Cleaning & Making a column for total payments\nfor idx in range(2):\n    for pay_item in pay_list:\n        dfs[idx].loc[dfs[idx][pay_item].isna(), pay_item] = 0\n\n    dfs[idx]['Total_payment'] = dfs[idx]['RoomService'] + dfs[idx]['FoodCourt'] + dfs[idx]['ShoppingMall'] + dfs[idx]['Spa'] + dfs[idx]['VRDeck']","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:18.051836Z","iopub.execute_input":"2022-03-01T12:08:18.052281Z","iopub.status.idle":"2022-03-01T12:08:18.077922Z","shell.execute_reply.started":"2022-03-01T12:08:18.052229Z","shell.execute_reply":"2022-03-01T12:08:18.077088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Gender","metadata":{}},{"cell_type":"code","source":"pip install gender_guesser","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:18.082333Z","iopub.execute_input":"2022-03-01T12:08:18.083166Z","iopub.status.idle":"2022-03-01T12:08:28.243916Z","shell.execute_reply.started":"2022-03-01T12:08:18.083126Z","shell.execute_reply":"2022-03-01T12:08:28.242645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gender_guesser.detector as gender\n# d = gender.Detector()\n\n# data_gender = pd.read_csv('../input/gender-new/gender_refine-csv.csv')\n# data_gender2 = pd.read_csv('../input/gender-by-name/name_gender_dataset.csv')\n# data_gender3 = pd.read_csv('../input/gender-50k-african-american/gender.txt')\n# data_gender4 = pd.read_csv('../input/gender-40k-caucasian/gender.txt')\n# data_gender5 = pd.read_csv('../input/male-indian/gender.txt')\n# data_gender6 = pd.read_csv('../input/governmentusbabynamessincemorethanacentury/government-us-baby-names-by-yob/babyNamesUSYOB-full.csv.txt')\n# data_gender7 = pd.read_csv('../input/governmentusbabynamessincemorethanacentury/government-us-baby-names-by-yob/babyNamesUSYOB-mostpopular.csv')\n# data_gender7","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.245902Z","iopub.execute_input":"2022-03-01T12:08:28.246282Z","iopub.status.idle":"2022-03-01T12:08:28.252508Z","shell.execute_reply.started":"2022-03-01T12:08:28.246242Z","shell.execute_reply":"2022-03-01T12:08:28.251266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_gender7.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.25442Z","iopub.execute_input":"2022-03-01T12:08:28.25474Z","iopub.status.idle":"2022-03-01T12:08:28.268019Z","shell.execute_reply.started":"2022-03-01T12:08:28.254703Z","shell.execute_reply":"2022-03-01T12:08:28.267069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mapping = {name:gender for name, gender in zip(data_gender.name, data_gender.gender)}\n# mapping2 = {name:gender for name, gender in zip(data_gender2.Name, data_gender2.Gender)}\n# mapping3 = {name:gender for name, gender in zip(data_gender3['first name'], data_gender3.gender)}\n# mapping4 = {name:gender for name, gender in zip(data_gender4[' first name'], data_gender4.gender)}\n# mapping5 = {name:gender for name, gender in zip(data_gender5['name'], data_gender5.gender)}\n# mapping6 = {name:gender for name, gender in zip(data_gender6['Name'], data_gender6.Sex)}\n# mapping7 = {name:gender for name, gender in zip(data_gender7['Name'], data_gender7.Sex)}\n# main_cols = [#'Low_#group', \n#             #'is_female',\n#             #'is_male',\n#             'Medium_#group',\n#             'CryoSleep', \n#             'High_#group',\n#             'Is_TRAPPIST-1e', 'Is_55 Cancri e',\n#             'Age',\n#             #'Id_is_1',\n#             'Id_is_2_or_3',\n#              'Is_Europa', 'Is_Earth', #'Is_safe_deck', \n#              'RoomService',\n#              'FoodCourt',\n#              'ShoppingMall',\n#              'Spa',\n#             'VRDeck',\n#              'Is_danger_deck',\n#              'Port_S', 'Port_P',\n#              'Nine_or_less',\n#              'Is_between_19_24',\n#              'Total_payment', 'VIP'\n#                 ]\n\n# model = RandomForestClassifier(criterion='gini', oob_score=True, max_features='auto', \n#                                            random_state=42,\n#                                            n_jobs=-1,\n#                                            n_estimators=1750,\n#                                            max_depth=7,\n#                                            min_samples_split=6,\n#                                            min_samples_leaf=6,\n#                                            verbose=1)\n# for idx in range(2):\n#     dfs[idx][['first_name',  'last_name']] = dfs[idx]['Name'].str.split(expand=True)\n#     dfs[idx]['Gender'] = pd.Series([mapping[name] if name in mapping.keys() else 'not_yet' for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'Gender'] = pd.Series([mapping2[name] if name in mapping2.keys() else 'not_yet' for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'Gender'] = pd.Series([mapping3[name] if name in mapping3.keys() else 'not_yet' for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'Gender'] = pd.Series([mapping4[name] if name in mapping4.keys() else 'not_yet' for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'Gender'] = pd.Series([mapping5[name] if name in mapping5.keys() else 'not_yet' for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'Gender'] = pd.Series([d.get_gender(name) for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'unknown', 'Gender'] = pd.Series([mapping6[name] if name in mapping6.keys() else 'not_yet' for name in dfs[idx].first_name])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'Gender'] = pd.Series([mapping7[name] if name in mapping7.keys() else 'not_yet' for name in dfs[idx].first_name])\n\n#     # Uniforming names\n#     dfs[idx].loc[dfs[idx]['Gender'].notnull(), 'Gender'] = dfs[idx].loc[dfs[idx]['Gender'].notnull(), 'Gender'].astype('str')\n#     dfs[idx].loc[dfs[idx]['Gender'].isin(['0', 'F', 'female']), 'Gender'] = 'Female'\n#     dfs[idx].loc[dfs[idx]['Gender'].isin(['1', 'm', 'M', 'male', 'mostly_male', 'andy', '3']), 'Gender'] = 'Male'\n    \n    \n#     # Adding column \"is_female\"\n#     dfs[idx]['is_female'] = 0\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'Female', 'is_female'] = 1\n    \n    \n#     # We will predict the rest of the not_yet\n#     known = dfs[idx][dfs[idx]['Gender'] != 'not_yet']\n#     unknown = dfs[idx][dfs[idx]['Gender'] == 'not_yet']\n#     model.fit(known[main_cols], known['is_female'])\n#     dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'is_female'] = model.predict(unknown[main_cols])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.269577Z","iopub.execute_input":"2022-03-01T12:08:28.269846Z","iopub.status.idle":"2022-03-01T12:08:28.285947Z","shell.execute_reply.started":"2022-03-01T12:08:28.269814Z","shell.execute_reply":"2022-03-01T12:08:28.284729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in range(2):\n    dfs[idx]['num'] = dfs[idx]['num'].astype('float')\n    dfs[idx].loc[dfs[idx]['num'].isna(), 'num'] = dfs[idx]['num'].median()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.287626Z","iopub.execute_input":"2022-03-01T12:08:28.287891Z","iopub.status.idle":"2022-03-01T12:08:28.313896Z","shell.execute_reply.started":"2022-03-01T12:08:28.287859Z","shell.execute_reply":"2022-03-01T12:08:28.312763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(train_df.query('Transported == True')['num'].astype('int'), alpha=0.7)\nplt.hist(train_df.query('Transported == False')['num'].astype('int'), alpha=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.316147Z","iopub.execute_input":"2022-03-01T12:08:28.316861Z","iopub.status.idle":"2022-03-01T12:08:28.674847Z","shell.execute_reply.started":"2022-03-01T12:08:28.316808Z","shell.execute_reply":"2022-03-01T12:08:28.674123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dfs[0]['is_female'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.676042Z","iopub.execute_input":"2022-03-01T12:08:28.676994Z","iopub.status.idle":"2022-03-01T12:08:28.681922Z","shell.execute_reply.started":"2022-03-01T12:08:28.676947Z","shell.execute_reply":"2022-03-01T12:08:28.680814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dfs[idx].loc[dfs[idx]['Gender'] == 'not_yet', 'first_name']","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.684005Z","iopub.execute_input":"2022-03-01T12:08:28.684433Z","iopub.status.idle":"2022-03-01T12:08:28.697004Z","shell.execute_reply.started":"2022-03-01T12:08:28.684382Z","shell.execute_reply":"2022-03-01T12:08:28.69576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-size:30px;color:#35858B;text-align:left\"><strong style=\"color:black\">Preparing and </strong><strong>ML</strong></h1> ","metadata":{}},{"cell_type":"code","source":"additional_features = set()\nservices = ['Spa'] # I tried the last services, this is what has successed\n\nfor idx in range(2):\n    for service in services:\n        dfs[idx]['Rat_'+service] = 0\n        dfs[idx].loc[dfs[idx]['Total_payment'] != 0, 'Rat_'+service] = ( dfs[idx][service] / dfs[idx]['Total_payment'] )\n        additional_features.add('Rat_'+service)\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.699512Z","iopub.execute_input":"2022-03-01T12:08:28.700635Z","iopub.status.idle":"2022-03-01T12:08:28.72145Z","shell.execute_reply.started":"2022-03-01T12:08:28.700573Z","shell.execute_reply":"2022-03-01T12:08:28.719957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in range(1):\n    dfs[idx].loc[dfs[idx]['Transported'] == False, 'Transported'] = 0\n    dfs[idx].loc[dfs[idx]['Transported'] == True, 'Transported'] = 1\n    dfs[idx]['Transported'] = dfs[idx]['Transported'].astype('int')\n    \nfor idx in range(2):\n    dfs[idx].loc[dfs[idx]['VIP'].isna(), 'VIP'] = 0\n    dfs[idx].loc[dfs[idx]['VIP'] == False, 'VIP'] = 0\n    dfs[idx].loc[dfs[idx]['VIP'] == True, 'VIP'] = 1\n    dfs[idx]['VIP'] = dfs[idx]['VIP'].astype('int')\n    \n    \nmain_cols = [#'Low_#group', \n            'Medium_#group',\n            'CryoSleep', \n            'High_#group',\n            'Is_TRAPPIST-1e', 'Is_55 Cancri e',\n            'Age',\n#             'Id_is_1',\n#             'Is_safe_deck',\n#             'is_female',\n#             'Id_is_2_or_3',\n             'Is_Europa', 'Is_Earth',\n             'RoomService',\n             'FoodCourt',\n             'ShoppingMall',\n             'Spa',\n             'VRDeck',\n             'Is_danger_deck',\n             'Port_S',\n             'Port_P',\n             'Nine_or_less',\n             'Is_between_19_24',\n             'Total_payment'\n                ] + list(additional_features)\n\nX, y = dfs[0][main_cols], dfs[0]['Transported']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.724997Z","iopub.execute_input":"2022-03-01T12:08:28.725357Z","iopub.status.idle":"2022-03-01T12:08:28.774963Z","shell.execute_reply.started":"2022-03-01T12:08:28.72532Z","shell.execute_reply":"2022-03-01T12:08:28.773691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rf = RandomForestClassifier(criterion='gini', oob_score=True,\n#                                            random_state=42,\n#                                            n_jobs=-1,\n#                                            verbose=1)\n# params = {\n#     'n_estimators': [5, 10, 15, 20, 50, 1500],\n#     'max_depth': [2, 5, 7, 10, 20],\n#     'min_samples_split': [1, 2, 3, 5, 8],\n#     'min_samples_leaf': [3, 5, 7, 10, 15]\n# }\n# rf_grid = GridSearchCV(rf, params, scoring=make_scorer(accuracy_score))\n# rf_fitted = rf_grid.fit(X_train, y_train)\n\n# preds = rf_fitted.best_estimator_.predict(X_test)\n# print(rf_fitted.best_estimator_)\n# print(accuracy_score(y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.776404Z","iopub.execute_input":"2022-03-01T12:08:28.77671Z","iopub.status.idle":"2022-03-01T12:08:28.782807Z","shell.execute_reply.started":"2022-03-01T12:08:28.776674Z","shell.execute_reply":"2022-03-01T12:08:28.781404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best = RandomForestClassifier(criterion='gini', oob_score=True, max_features='auto', \n                                           random_state=42,\n                                           n_jobs=-1,\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.784705Z","iopub.execute_input":"2022-03-01T12:08:28.785626Z","iopub.status.idle":"2022-03-01T12:08:28.807884Z","shell.execute_reply.started":"2022-03-01T12:08:28.785571Z","shell.execute_reply":"2022-03-01T12:08:28.806521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best.fit(X_train, y_train)\npreds = best.predict(X_test)\nprint(accuracy_score(y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:28.810194Z","iopub.execute_input":"2022-03-01T12:08:28.810853Z","iopub.status.idle":"2022-03-01T12:08:40.196169Z","shell.execute_reply.started":"2022-03-01T12:08:28.810795Z","shell.execute_reply":"2022-03-01T12:08:40.194911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import xgboost\n# best = xgboost.XGBClassifier(learning_rate=0.3, max_depth=10, n_estimators=20,\n#                        random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:40.198287Z","iopub.execute_input":"2022-03-01T12:08:40.198697Z","iopub.status.idle":"2022-03-01T12:08:40.205018Z","shell.execute_reply.started":"2022-03-01T12:08:40.198648Z","shell.execute_reply":"2022-03-01T12:08:40.203423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def feature_importance(model):\n#     importances = model.feature_importances_\n#     indices = np.argsort(importances)\n#     features = main_cols\n#     plt.title('Feature Importance')\n#     plt.barh(range(len(indices)), importances[indices], align='center')\n#     plt.yticks(range(len(indices)), [features[i] for i in indices])\n#     plt.xlabel('Relative Importance')\n#     plt.show()\n    \n# feature_importance(best)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:40.207191Z","iopub.execute_input":"2022-03-01T12:08:40.207583Z","iopub.status.idle":"2022-03-01T12:08:40.223864Z","shell.execute_reply.started":"2022-03-01T12:08:40.207548Z","shell.execute_reply":"2022-03-01T12:08:40.222332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best = AdaBoostClassifier(n_estimators=500)\n# best.fit(X_train, y_train)\n# preds = best.predict(X_test)\n# print(accuracy_score(y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:40.22559Z","iopub.execute_input":"2022-03-01T12:08:40.226381Z","iopub.status.idle":"2022-03-01T12:08:40.241815Z","shell.execute_reply.started":"2022-03-01T12:08:40.226322Z","shell.execute_reply":"2022-03-01T12:08:40.240308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best.fit(X, y)\npreds = best.predict(dfs[1][main_cols])\nsample_sub['Transported'] = pd.Series(preds)\n\nsample_sub.loc[sample_sub['Transported'] == 0, 'Transported'] = False\nsample_sub.loc[sample_sub['Transported'] == 1, 'Transported'] = True\nsample_sub.to_csv('Submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T12:08:40.244063Z","iopub.execute_input":"2022-03-01T12:08:40.244426Z","iopub.status.idle":"2022-03-01T12:08:53.45926Z","shell.execute_reply.started":"2022-03-01T12:08:40.244385Z","shell.execute_reply":"2022-03-01T12:08:53.457893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-size:30px;color:#35858B;text-align:left\"><strong style=\"color:black\">Don't Forget to </strong><strong>Upvote</strong></h1> ","metadata":{}}]}