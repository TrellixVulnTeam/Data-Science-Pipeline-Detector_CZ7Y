{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-21T11:03:53.327511Z","iopub.execute_input":"2022-03-21T11:03:53.327795Z","iopub.status.idle":"2022-03-21T11:03:53.336121Z","shell.execute_reply.started":"2022-03-21T11:03:53.327761Z","shell.execute_reply":"2022-03-21T11:03:53.335544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('max_columns', None)\nsns.set_theme(style=\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.337418Z","iopub.execute_input":"2022-03-21T11:03:53.337855Z","iopub.status.idle":"2022-03-21T11:03:53.354098Z","shell.execute_reply.started":"2022-03-21T11:03:53.337825Z","shell.execute_reply":"2022-03-21T11:03:53.353532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_raw = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\ntest_data_raw = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.355307Z","iopub.execute_input":"2022-03-21T11:03:53.355803Z","iopub.status.idle":"2022-03-21T11:03:53.409344Z","shell.execute_reply.started":"2022-03-21T11:03:53.355762Z","shell.execute_reply":"2022-03-21T11:03:53.408761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting data types","metadata":{}},{"cell_type":"code","source":"train_data_raw.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.410629Z","iopub.execute_input":"2022-03-21T11:03:53.41095Z","iopub.status.idle":"2022-03-21T11:03:53.428485Z","shell.execute_reply.started":"2022-03-21T11:03:53.410923Z","shell.execute_reply":"2022-03-21T11:03:53.427954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Things to do\n- Fill na values by most frequent strategy\n- Onehotencoding\n- Ordinal encoding\n- Cabin data manipulation\n- making new feature - age_group\n- deal with outliers\n    - how? - change them to 2.5 of std\n    - or find log of the features\n    - or encode them as boolean\n    \n## Columns that will not be used - 'Name', 'PassengerId'","metadata":{}},{"cell_type":"markdown","source":"# Not doing Visualizing in this one. Here is the link that has good visualization of this data","metadata":{}},{"cell_type":"code","source":"data1 = train_data_raw.copy()\n\nattr_for_le = ['CryoSleep','Transported','VIP']\n\n# 'CabinNum' not using in onehotencoding because too many features\nattr_for_ohe = ['HomePlanet','Destination', 'CabinDeck',\n               'age_group','CabinSide'] # new features to \n# be added after sorting Cabin\nattr_numerical = ['Age','RoomService','FoodCourt',\n                  'ShoppingMall', 'Spa','VRDeck']\nall_attr = list(data1.columns)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.429381Z","iopub.execute_input":"2022-03-21T11:03:53.429672Z","iopub.status.idle":"2022-03-21T11:03:53.435541Z","shell.execute_reply.started":"2022-03-21T11:03:53.429635Z","shell.execute_reply":"2022-03-21T11:03:53.434803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import OneHotEncoder\n\nclass CatTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        idx = X.index\n        cols = list(X.columns)\n        imputer = SimpleImputer(strategy='most_frequent')\n        X[:] = imputer.fit_transform(X)\n        # print(X.head(5))\n        # X = pd.DataFrame(im_tr, columns=cols, index=idx)\n        \n        X['CabinDeck'] = [s.split('/')[0] for s in X['Cabin']]\n        X['CabinNum'] = [s.split('/')[1] for s in X['Cabin']]\n        X['CabinSide'] = [s.split('/')[2] for s in X['Cabin']]\n        \n        def decide_age_group(a):\n            if a<=5:\n                return 'infant'\n            elif 5<a<14:\n                return 'child'\n            elif 14<=a<26:\n                return 'youth'\n            elif 26<=a<=60:\n                return 'adult'\n            elif a>60:\n                return 'elder'\n            \n        X['age_group'] = X['Age'].apply(decide_age_group)\n        \n        onehot = OneHotEncoder(sparse=False)\n        onehot_tr = onehot.fit_transform(X[attr_for_ohe])\n        ohe_cols = list(onehot.get_feature_names_out())\n        onehot_df = pd.DataFrame(onehot_tr, columns=ohe_cols,\n                                index =idx)\n        \n        X = X.drop(attr_for_ohe, axis = 1)\n        X = X.drop('Cabin',axis=1)\n        print(\"done dropping \")\n        X = pd.concat([X, onehot_df,], axis=1)\n        print('Done concate')\n        return X","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.437473Z","iopub.execute_input":"2022-03-21T11:03:53.437812Z","iopub.status.idle":"2022-03-21T11:03:53.450763Z","shell.execute_reply.started":"2022-03-21T11:03:53.437774Z","shell.execute_reply":"2022-03-21T11:03:53.449951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nclass ForOE(BaseException, TransformerMixin):\n    def __init__(self, feature_names):\n        self._feature_names = feature_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        # print(X.head())\n        oe = OrdinalEncoder()\n        # X[:] = oe.fit_transform(X[self._feature_names])\n        for col in self._feature_names:\n            if 'Transported' != list(X.columns):\n                continue\n            col_val = X[col].values.reshape(-1,1)\n            print('\\ncol_val',col_val[10])\n            X[col] = oe.fit_transform(col_val)\n        print(oe.get_params())\n        return X\n    \nclass NumTransformation(BaseEstimator, TransformerMixin):\n    def __init__(self, method):\n        self.method = method\n        # error\n        # TypeError: NumTransformation() takes no arguments\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        if self.method == 'to_bool':\n            def num_to_bool(a):\n                if a>0.0:\n                    return 1\n                elif a==0.0:\n                    return 0\n            for col in attr_numerical:\n                if 'Transported' != list(X.columns):\n                    continue\n                X[col] = X[col].apply(num_to_bool)\n            return X\n        elif self.method == 'log':\n            for col in [attr_numerical]:\n                X[col] = np.log1p(X[col])\n            return X\n        \n        # not doing because i feel lazy\n        # elif self.method == 'boxcox':\n            ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.452172Z","iopub.execute_input":"2022-03-21T11:03:53.452988Z","iopub.status.idle":"2022-03-21T11:03:53.465821Z","shell.execute_reply.started":"2022-03-21T11:03:53.452948Z","shell.execute_reply":"2022-03-21T11:03:53.465296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nft = ['CryoSleep','VIP','Transported']\n\nct = Pipeline([\n    ('cat_tr', CatTransformer()),\n    ('oe', ForOE(ft)),\n    ('num', NumTransformation(method='log')),\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.510702Z","iopub.execute_input":"2022-03-21T11:03:53.511243Z","iopub.status.idle":"2022-03-21T11:03:53.517623Z","shell.execute_reply.started":"2022-03-21T11:03:53.511201Z","shell.execute_reply":"2022-03-21T11:03:53.516951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2 = ct.fit_transform(data1)\ndata2.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.519573Z","iopub.execute_input":"2022-03-21T11:03:53.520083Z","iopub.status.idle":"2022-03-21T11:03:53.649924Z","shell.execute_reply.started":"2022-03-21T11:03:53.520044Z","shell.execute_reply":"2022-03-21T11:03:53.649219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.651014Z","iopub.execute_input":"2022-03-21T11:03:53.651232Z","iopub.status.idle":"2022-03-21T11:03:53.733106Z","shell.execute_reply.started":"2022-03-21T11:03:53.651205Z","shell.execute_reply":"2022-03-21T11:03:53.732364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = data2.drop([ 'PassengerId','Name'], axis=1).corr()\ncorr['Transported'].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.73471Z","iopub.execute_input":"2022-03-21T11:03:53.734926Z","iopub.status.idle":"2022-03-21T11:03:53.765979Z","shell.execute_reply.started":"2022-03-21T11:03:53.7349Z","shell.execute_reply":"2022-03-21T11:03:53.765222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_copy = test_data_raw.copy()\ntest_prepared = ct.fit_transform(test_data_copy)\ntest_prepared.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.767099Z","iopub.execute_input":"2022-03-21T11:03:53.767317Z","iopub.status.idle":"2022-03-21T11:03:53.83916Z","shell.execute_reply.started":"2022-03-21T11:03:53.767294Z","shell.execute_reply":"2022-03-21T11:03:53.838356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n\n\n# best_clf = RandomForestClassifier(min_samples_leaf=4, min_samples_split=6)\nbest_gbc = GradientBoostingClassifier(loss='exponential', max_depth=15, n_estimators=200,\n                           subsample=1)\n\nbagging = BaggingClassifier(best_gbc)\n    \nX = data2.drop(['Transported', 'PassengerId','Name'], axis=1)\ny= data2['Transported']\n\n# best_clf.fit(X, y)\nbagging.fit(X, y)\nprint(bagging.score(X,y))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:03:53.840621Z","iopub.execute_input":"2022-03-21T11:03:53.841134Z","iopub.status.idle":"2022-03-21T11:06:46.100533Z","shell.execute_reply.started":"2022-03-21T11:03:53.841094Z","shell.execute_reply":"2022-03-21T11:06:46.099672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prepared_x = test_prepared.drop(['PassengerId','Name'], axis=1)\n# preds = best_clf.predict(test_prepared_x)\npreds = bagging.predict(test_prepared_x)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:06:46.102077Z","iopub.execute_input":"2022-03-21T11:06:46.10255Z","iopub.status.idle":"2022-03-21T11:06:47.121694Z","shell.execute_reply.started":"2022-03-21T11:06:46.102507Z","shell.execute_reply":"2022-03-21T11:06:47.120936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame({\n    'PassengerId': test_prepared['PassengerId'],\n    'Transported': preds,\n})\n\nsubmission = sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:06:47.122815Z","iopub.execute_input":"2022-03-21T11:06:47.123048Z","iopub.status.idle":"2022-03-21T11:06:47.137794Z","shell.execute_reply.started":"2022-03-21T11:06:47.123021Z","shell.execute_reply":"2022-03-21T11:06:47.136918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-03-21T11:06:47.13897Z","iopub.execute_input":"2022-03-21T11:06:47.139168Z","iopub.status.idle":"2022-03-21T11:06:47.155468Z","shell.execute_reply.started":"2022-03-21T11:06:47.139144Z","shell.execute_reply":"2022-03-21T11:06:47.15469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}