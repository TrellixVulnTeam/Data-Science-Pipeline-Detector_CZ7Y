{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spaceship Titanic Kaggle Challenge!","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### Label Descriptions (for self reference)","metadata":{"tags":[]}},{"cell_type":"markdown","source":"- PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n- HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n- CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n- Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n- Destination - The planet the passenger will be debarking to.\n- Age - The age of the passenger.\n- VIP - Whether the passenger has paid for special VIP service during the voyage.\n- RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n- Name - The first and last names of the passenger.\n- Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.","metadata":{}},{"cell_type":"markdown","source":"## Preliminary Processing","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### Make imports and configure","metadata":{"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(style='whitegrid')\nsns.set_palette('viridis')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read in and inspect data","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/spaceship-titanic/train.csv\")\ntest = pd.read_csv(\"../input/spaceship-titanic/test.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The data has {df.shape[0]} rows and {df.shape[1]} columns')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T.sort_values(by='mean', ascending=False).style.background_gradient(cmap='BuGn')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Splitting Cabin","metadata":{}},{"cell_type":"code","source":"def split_cabin(cabin):\n    if not pd.isna(cabin):\n        return pd.Series(cabin.split('/'), index=['Deck','Number', 'Side'])\n    else:\n        return pd.Series(dtype='object')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_and_concat(df):\n    cabin = df['Cabin'].apply(split_cabin)\n    return pd.concat([df, cabin], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = apply_and_concat(df)\ntest = apply_and_concat(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Convert Data to Correct Type","metadata":{}},{"cell_type":"code","source":"def convert_dtype(df):\n\n    df['VIP'] = df['VIP'].astype(bool)\n    df['CryoSleep'] = df['CryoSleep'].astype(bool)\n    df['Number'] = df['Number'].astype(float)\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = convert_dtype(df)\ntest = convert_dtype(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Null Value Analysis","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"print(f'Total of {df.isna().sum().sum()} null values')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Column and Row Null Distribution","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n\nnull_cols = df.isnull().sum().sort_values(ascending=False)\nnull_cols.plot(kind='bar', ax = ax1)\nax1.set_xlabel('')\n\nnull_rows = x=df.isnull().sum(axis=1)\nsns.countplot(x=null_rows[null_rows!=0], ax=ax2)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"### Distribution of Target Variable","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='Transported', data=df)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Variables","metadata":{"tags":[]}},{"cell_type":"markdown","source":"#### Origin and Destinations","metadata":{"tags":[]}},{"cell_type":"code","source":"data = []\norigins = list(df['HomePlanet'].dropna().unique())\ndestinations = list(df['Destination'].dropna().unique())\n\nfor origin in origins:\n    for destination in destinations:\n        temp = df[(df['HomePlanet'] == origin) & (df['Destination'] == destination)]\n        row = [origin, destination, temp.shape[0]]\n        data.append(row)\n        # d[origin + ' -> ' + destination] = temp.shape[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trip_data = pd.DataFrame(data, columns=['Origin', 'Destination', 'Number of Trips'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x='Origin', y='Number of Trips', data=trip_data, hue='Destination')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Distribution of Categorical Values","metadata":{"tags":[]}},{"cell_type":"code","source":"cat_var = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\nfor col in cat_var:\n    print(df[col].value_counts())\n    print('\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 3, figsize=(20,10))\naxs = axs.flatten()\n\ni = 0\nfor col in cat_var:\n    sns.countplot(x=col, data=df, ax=axs[i])\n    i+=1\n\nplt.tight_layout()\n# plt.delaxes(axs[7])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Which categories correlate to transportation?","metadata":{"tags":[]}},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 3, figsize=(16,8))\naxs = axs.flatten()\n\ni = 0\nfor col in cat_var[:6]:\n    sns.countplot(x=col, data=df, ax=axs[i], hue='Transported')\n    i+=1\n    \nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Europa have disproportionately more passengers being transported\n- Passengers in Cryosleep are disproportionately transported\n- Passengers departing for 55 Cancri e are disproportionately transported\n- Passengers in decks B, G and C are more likely to be transported\n- Passengers on Starboard more likely to be transported","metadata":{}},{"cell_type":"markdown","source":"### Continuous Variables","metadata":{"tags":[]}},{"cell_type":"markdown","source":"#### Distribution Of Spending","metadata":{"tags":[]}},{"cell_type":"code","source":"spending = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalSpend'] = df[spending].sum(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for spend in (spending + ['TotalSpend']):\n    zeros = df[spend].value_counts()\n    print(f'Number of 0 values in {spend} Spending is {zeros[0]} out of {zeros.sum()} or {(zeros[0]/zeros.sum())*100:.2f}%')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(3, 2, figsize=(20,20))\naxs = axs.flatten()\n\ni = 0\nfor spend in (spending + ['TotalSpend']):\n    x = df[df[spend] > 0]\n    sns.histplot(x=x[spend], bins=35, kde=True, ax=axs[i], hue=x['Transported'])\n    i+=1\n    \nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Distribution Of Age","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,6))\nsns.histplot(x='Age', data=df, kde=True, bins=35, ax=ax1)\nsns.histplot(x='Age', data=df, kde=True, bins=35, hue='Transported', ax=ax2)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Distribution of Cabin Number","metadata":{"tags":[]}},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,6))\nsns.histplot(x='Number', data=df, kde=True, bins=35, ax=ax1)\nsns.histplot(x='Number', data=df, kde=True, bins=35, hue='Transported', ax=ax2)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Matrix","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nmask = np.triu(df.corr())\nsns.heatmap(df.corr(), annot=True, mask=mask)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-Processing","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"# Save PassengerId Column\n\nids = test['PassengerId']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping Unneeded Columns","metadata":{"tags":[]}},{"cell_type":"code","source":"def drop_rows(df):\n    if 'TotalSpend' in df.columns:\n        return df.drop(columns=['PassengerId' ,'Name', 'Cabin', 'TotalSpend'])\n    else:\n        return df.drop(columns=['PassengerId' ,'Name', 'Cabin'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = drop_rows(df)\ntest = drop_rows(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NA Removal","metadata":{}},{"cell_type":"markdown","source":"#### Continuous Variables","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Use the median values for the spending variables (think they're all 0 which is reasonable) and the mean value for the age","metadata":{}},{"cell_type":"code","source":"def del_na_cont(df):\n    for spend in spending:\n        med = df[spend].median()\n        # print(f'Median for {spend} is {med}')\n        df[spend] = df[spend].fillna(med)\n    \n    mean_age = df['Age'].mean()\n    # print(f'Mean of Ages is {mean_age:.2f}')\n    df['Age'] = df['Age'].fillna(mean_age)\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = del_na_cont(df)\ntest = del_na_cont(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Categorical Variables and Cabin Number","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Replace values by a weighted sampling of variables using np.choice","metadata":{}},{"cell_type":"code","source":"cat_var = cat_var + ['Number']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def del_na_cat(df):\n    for var in cat_var:\n        \n        # Get the length of na columns\n        length_of_na = len(df[df[var].isnull()])\n        \n        # Get the names of the variables\n        var_list = df[var].dropna().unique()\n        \n        # Find the prior distribution we need for random assignment\n        probs = list(df[var].value_counts()) / (df[var].value_counts().sum())\n        \n        # Choice method to randomly assign\n        inserts = np.random.choice(var_list, length_of_na, p=probs)\n        \n        # Insert it into the dataframe with loc\n        df.loc[df[var].isnull(), var] = np.random.choice(var_list, length_of_na, p=probs)\n        \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = del_na_cat(df)\ntest = del_na_cat(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding Categorical Data","metadata":{"tags":[]}},{"cell_type":"code","source":"def encode(df):\n\n    # Nominal Data\n    df = pd.concat([df, pd.get_dummies(df['HomePlanet'], drop_first=True), \n                    pd.get_dummies(df['Destination'], drop_first=True),\n                    pd.get_dummies(df['Deck'], drop_first=True)],\n                axis=1)\n    \n    df.drop(columns=['HomePlanet', 'Destination', 'Deck'], inplace=True)\n    \n    # Binary Data\n    df['CryoSleep'] = df['CryoSleep'].map({True: 1, False:0})\n    df['VIP'] = df['VIP'].map({True: 1, False:0})\n    df['Side'] = df['Side'].map({'S': 1, 'P': 0})\n    \n    # Target Variable\n    if 'Transported' in df.columns:\n        df['Transported'] = df['Transported'].map({True: 1, False:0})\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = encode(df)\ntest = encode(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building","metadata":{"tags":[]}},{"cell_type":"code","source":"X = df.drop(columns=['Transported'])\ny = df['Transported']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the Dataset","metadata":{"tags":[]}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{"tags":[]}},{"cell_type":"code","source":"model_logit = LogisticRegression(max_iter=1000).fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model_logit.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(\npd.DataFrame(confusion_matrix(y_test, preds), \n             columns = ['Predicted Not Transported', 'Predicted Transported'],\n             index=['Not Transported', 'Transported'])\n, annot=True, fmt='g', cbar=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df = pd.DataFrame(\n            [accuracy_score(y_test, preds)] + list(precision_recall_fscore_support(y_test, preds, average='binary')), \n            index=['Accuracy','Precision', 'Recall', 'F-Score', 'Support'],\n            columns=['Logistic Regression']\n            ).T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Neural Network","metadata":{"tags":[]}},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{}},{"cell_type":"code","source":"n_input = len(X_train.columns)\nn_hidden = 32\nn_classes = 2\nbatch_size = 256\nlearning_rate = 0.001\nn_epochs = 300","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Instantiate Dataloaders","metadata":{"tags":[]}},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train.values)\ny_train_tensor = torch.tensor(y_train.values)\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n\nX_test_tensor = torch.tensor(X_test.values)\ny_test_tensor = torch.tensor(y_test.values)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, \n                              batch_size=batch_size,\n                              shuffle=True\n                            ) \n\ntest_dataloader = DataLoader(test_dataset, \n                              batch_size=batch_size,\n                              shuffle=False\n                            ) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create Network","metadata":{"tags":[]}},{"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(NeuralNet, self).__init__()\n        self.l1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.l2 = nn.Linear(hidden_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.l3 = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, train_data):\n        out = self.l1(train_data)\n        out = self.relu(out)\n        out = self.l2(out) \n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Instantiate model, loss function and optimizer","metadata":{}},{"cell_type":"code","source":"model_nn = NeuralNet(n_input, n_hidden, n_classes)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_nn.parameters(), lr=learning_rate)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training Loop","metadata":{}},{"cell_type":"code","source":"losses = []\n\nfor epoch in range(n_epochs):\n    running_loss = 0\n    \n    for batch_no, (features, labels) in enumerate(train_dataloader):\n        \n        # forward \n        outputs = model_nn(features.float())\n        loss = loss_fn(outputs, labels)\n        \n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # adam step\n        optimizer.step()\n        \n        # add \n        running_loss += loss.item()\n\n        \n    loss = running_loss / len(train_dataloader)\n    losses.append(loss)\n    \n    if ((epoch + 1) % 10) == 0:\n        print(f'epoch --> {epoch+1} | loss --> {loss}')\n    \nprint('Finished Training')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(n_epochs), losses)\nplt.xlabel('Epoch Number')\nplt.ylabel('Loss')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate","metadata":{}},{"cell_type":"code","source":"test_output = model_nn(X_test_tensor.float())\n_, preds = torch.max(test_output, 1)\nacc = accuracy_score(y_test, preds)\n\neval_df.loc['Neural Network'] = [acc] + list(precision_recall_fscore_support(y_test, preds, average='binary'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(\npd.DataFrame(confusion_matrix(y_test, preds), \n             columns = ['Predicted Not Transported', 'Predicted Transported'],\n             index=['Not Transported', 'Transported'])\n, annot=True, fmt='g', cbar=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prep for Submission","metadata":{}},{"cell_type":"code","source":"test_scores = model_nn(torch.tensor(test.values).float())\n_, test_labels = torch.max(test_scores, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub_logistic = pd.DataFrame([\n                ids,\n                model_logit.predict(test).astype(bool)],\n                index = ['PassengerId', 'Transported']\n            ).T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_logistic.to_csv('submissions/logit.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_nn = pd.DataFrame([\n        ids,\n        test_labels.numpy().astype(bool)],\n        index = ['PassengerId', 'Transported']\n    ).T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_nn.to_csv('submissions/nn.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}