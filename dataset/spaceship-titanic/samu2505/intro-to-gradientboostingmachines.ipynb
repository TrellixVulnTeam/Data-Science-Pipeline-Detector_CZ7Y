{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-31T12:13:01.457672Z","iopub.execute_input":"2022-03-31T12:13:01.457983Z","iopub.status.idle":"2022-03-31T12:13:01.472287Z","shell.execute_reply.started":"2022-03-31T12:13:01.457949Z","shell.execute_reply":"2022-03-31T12:13:01.471448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**IMPORT LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import gc\nfrom tqdm.auto import tqdm\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import RepeatedStratifiedKFold, train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import classification_report, accuracy_score\n\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:15:55.220447Z","iopub.execute_input":"2022-03-31T12:15:55.220791Z","iopub.status.idle":"2022-03-31T12:15:55.230465Z","shell.execute_reply.started":"2022-03-31T12:15:55.220729Z","shell.execute_reply":"2022-03-31T12:15:55.229514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/spaceship-titanic/train.csv\", index_col=0)\ntest_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:02.761331Z","iopub.execute_input":"2022-03-31T12:13:02.76192Z","iopub.status.idle":"2022-03-31T12:13:02.817399Z","shell.execute_reply.started":"2022-03-31T12:13:02.761881Z","shell.execute_reply":"2022-03-31T12:13:02.816356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:03.432093Z","iopub.execute_input":"2022-03-31T12:13:03.432423Z","iopub.status.idle":"2022-03-31T12:13:03.454136Z","shell.execute_reply.started":"2022-03-31T12:13:03.432383Z","shell.execute_reply":"2022-03-31T12:13:03.453107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the distribution of the targets\n# very close, not that much separate them\ntrain_df['Transported'].value_counts().plot(kind='bar')\nplt.title('Distribution of Transported', fontsize=15);","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:03.941701Z","iopub.execute_input":"2022-03-31T12:13:03.942123Z","iopub.status.idle":"2022-03-31T12:13:04.120812Z","shell.execute_reply.started":"2022-03-31T12:13:03.942094Z","shell.execute_reply":"2022-03-31T12:13:04.119853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA TYPES AND THEIR QUANTITY**\n\nKnowing the quantity of specific data type will help in choosing the right algorithms for modelling.\n\nBased on the analysis below, the number of object datatype is equal to the number of floats.\n\nThere are also some Boolean","metadata":{}},{"cell_type":"code","source":"# checking for the distribution of the data types\ntrain_df.dtypes.value_counts().plot(kind='bar')\nplt.title(\"Distribution of data types\", fontsize=15);","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:04.49248Z","iopub.execute_input":"2022-03-31T12:13:04.492794Z","iopub.status.idle":"2022-03-31T12:13:04.67667Z","shell.execute_reply.started":"2022-03-31T12:13:04.492749Z","shell.execute_reply":"2022-03-31T12:13:04.675842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MISSING DATA IN BOTH TRAINING AND TEST SET**\n\nIt's also important to handle missing values in appropriate ways, depending on the data types.\n\nFollowing this, then, it's good to visualize the the categories that are missing the missing amounts of the data.","metadata":{}},{"cell_type":"code","source":"# checking for missing data\nprint(\"Shape of the training set: \", train_df.shape)\nprint(\"Total missing data in training set: \", train_df.isna().sum().sum())\nprint(\"\\nShape of the test set: \", test_df.shape)\nprint(\"Total missing data in test set: \", test_df.isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:05.111561Z","iopub.execute_input":"2022-03-31T12:13:05.112353Z","iopub.status.idle":"2022-03-31T12:13:05.133896Z","shell.execute_reply.started":"2022-03-31T12:13:05.112315Z","shell.execute_reply":"2022-03-31T12:13:05.132932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is a condensed form of getting the missing values.\n# First getting the missing the features and their respective percentages, \n# Afterwards, construct data frames for both the missing training and test set features\nmissing_train_data = [(col, (train_df[col].isna().sum()/len(train_df))*100) for col in train_df.columns.tolist()\n                      if train_df[col].isna().sum() > 0]\n\nmissing_test_data = [(col, (test_df[col].isna().sum()/len(test_df))*100) for col in test_df.columns.tolist()\n                    if test_df[col].isna().sum() > 0]\n\n# Data frames for both the training and test set missing values\n# Sort the values so as to find out which feature has the most missing data\nmissing_train_data = pd.DataFrame(missing_train_data, columns=['feature', 'MissingPct']).sort_values(by='MissingPct', ascending=False)\nmissing_test_data = pd.DataFrame(missing_test_data, columns=['feature', 'MissingPct']).sort_values(by='MissingPct', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:06.225898Z","iopub.execute_input":"2022-03-31T12:13:06.226461Z","iopub.status.idle":"2022-03-31T12:13:06.269628Z","shell.execute_reply.started":"2022-03-31T12:13:06.226418Z","shell.execute_reply":"2022-03-31T12:13:06.269002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**VISUAL DISTRIBUTION OF MISSING VALUES**","metadata":{}},{"cell_type":"code","source":"sns.histplot(x=missing_train_data['MissingPct'], \n             data=missing_train_data, bins=10)\nplt.title('Distribution of missing data from the training set', fontsize=15);","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:06.865994Z","iopub.execute_input":"2022-03-31T12:13:06.866725Z","iopub.status.idle":"2022-03-31T12:13:07.107168Z","shell.execute_reply.started":"2022-03-31T12:13:06.866684Z","shell.execute_reply":"2022-03-31T12:13:07.106307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(x=missing_test_data['MissingPct'],\n            data=missing_test_data, bins=10)\nplt.title('Distribution of missing values from the test set');","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:07.433034Z","iopub.execute_input":"2022-03-31T12:13:07.433317Z","iopub.status.idle":"2022-03-31T12:13:07.67904Z","shell.execute_reply.started":"2022-03-31T12:13:07.433285Z","shell.execute_reply":"2022-03-31T12:13:07.678228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SEPARATING NUMERICAL AND CATEGORICAL DATA**\n\nNow, it's time to work on numerical and categorical data independently.","metadata":{}},{"cell_type":"code","source":"# use the test set columns to assign both the numerical and categorical columns\n# Use .select_dtypes to identify the data types\nnumerical_cols = test_df.select_dtypes(include=[np.number, np.bool8]).columns.tolist()\n\n# the categorical includes object and category data types\ncategorical_col = test_df.select_dtypes(include=['object', 'category']).columns.tolist()\n\n# Our Target columns\ntarget = 'Transported'","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:07.977202Z","iopub.execute_input":"2022-03-31T12:13:07.977514Z","iopub.status.idle":"2022-03-31T12:13:07.987223Z","shell.execute_reply.started":"2022-03-31T12:13:07.977471Z","shell.execute_reply":"2022-03-31T12:13:07.986186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FILL IN THE MISSING VALUES**\n\nNow, that numerical and categorical features have been separated.\n\nUsing, scikit-learn's SimpleImputer, the missing values filled in.","metadata":{}},{"cell_type":"code","source":"# imputing the numerical values first\nimputer_num = SimpleImputer(strategy='mean')\ntrain_df[numerical_cols] = imputer_num.fit_transform(train_df[numerical_cols])\ntest_df[numerical_cols] = imputer_num.fit_transform(test_df[numerical_cols])\n\n# imputing the categorical values\nimputer_cat = SimpleImputer(strategy='constant')\ntrain_df[categorical_col] = imputer_cat.fit_transform(train_df[categorical_col])\ntest_df[categorical_col] = imputer_cat.fit_transform(test_df[categorical_col])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:08.429513Z","iopub.execute_input":"2022-03-31T12:13:08.430246Z","iopub.status.idle":"2022-03-31T12:13:08.462766Z","shell.execute_reply.started":"2022-03-31T12:13:08.430203Z","shell.execute_reply":"2022-03-31T12:13:08.462104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CORRELATION**\n\nThis mainly works with numerical features, therefore, its good to write a function that will be applied anywhere","metadata":{}},{"cell_type":"code","source":"# train_df[numerical_cols].corrwith(train_df[target])\n\n# the correlation function\ndef corr_func(df, features=numerical_cols, target=target):\n    # correlations\n    corr = df[features].corrwith(df[target])\n    # return it as a dataframe\n    return pd.DataFrame({'feature': corr.index, 'correlation': corr.values}).sort_values(by='correlation', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:08.903449Z","iopub.execute_input":"2022-03-31T12:13:08.90373Z","iopub.status.idle":"2022-03-31T12:13:08.909346Z","shell.execute_reply.started":"2022-03-31T12:13:08.903697Z","shell.execute_reply":"2022-03-31T12:13:08.908609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I have considered taking the absolute values of the correlation, \ncorr_func(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:09.399984Z","iopub.execute_input":"2022-03-31T12:13:09.400555Z","iopub.status.idle":"2022-03-31T12:13:09.416182Z","shell.execute_reply.started":"2022-03-31T12:13:09.400501Z","shell.execute_reply":"2022-03-31T12:13:09.415576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"# Convert the categoricals into numbers\n# I will be using .factorize(), but there are many other ways to perform\n# This include label encoding, getting dummies, one hot encoding etc.\n# factorize() returns an array, and index.\n# for this case, index is not needed\nfor col in categorical_col:\n    train_df[col], _ = train_df[col].factorize()\n    test_df[col], _ = test_df[col].factorize()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:09.843816Z","iopub.execute_input":"2022-03-31T12:13:09.84441Z","iopub.status.idle":"2022-03-31T12:13:09.866514Z","shell.execute_reply.started":"2022-03-31T12:13:09.84436Z","shell.execute_reply":"2022-03-31T12:13:09.86584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking for correlation categorical data that have been converted into integers\n# categorical features have stronger correlations as compared to the numeric features. \ncorr_func(train_df, features=categorical_col)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:10.230072Z","iopub.execute_input":"2022-03-31T12:13:10.230384Z","iopub.status.idle":"2022-03-31T12:13:10.248487Z","shell.execute_reply.started":"2022-03-31T12:13:10.23035Z","shell.execute_reply":"2022-03-31T12:13:10.247667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation of the numerical features\ncorr_func(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:13:10.541311Z","iopub.execute_input":"2022-03-31T12:13:10.541855Z","iopub.status.idle":"2022-03-31T12:13:10.558223Z","shell.execute_reply.started":"2022-03-31T12:13:10.541817Z","shell.execute_reply":"2022-03-31T12:13:10.557595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MODELLING**\n\nConsidering the correlations, it's best to use CatBoost for this first model, but any kind of model would work\n\nI will be starting with xgboost. I just like it.","metadata":{}},{"cell_type":"code","source":"# using all the features, provides better results\nfeatures = [*numerical_cols, *categorical_col]\n# checking for features with positive correlations\n# features = ['CryoSleep', 'Cabin', 'Destination', 'Name', 'FoodCourt', 'ShoppingMall']","metadata":{"execution":{"iopub.status.busy":"2022-03-31T12:18:18.932856Z","iopub.execute_input":"2022-03-31T12:18:18.933415Z","iopub.status.idle":"2022-03-31T12:18:18.937303Z","shell.execute_reply.started":"2022-03-31T12:18:18.933379Z","shell.execute_reply":"2022-03-31T12:18:18.936624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(train_df[features], \n                                                      train_df[target], \n                                                      test_size=0.1, \n                                                      random_state=1223, \n                                                      shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:17.197853Z","iopub.execute_input":"2022-03-31T13:23:17.198192Z","iopub.status.idle":"2022-03-31T13:23:17.208929Z","shell.execute_reply.started":"2022-03-31T13:23:17.198141Z","shell.execute_reply":"2022-03-31T13:23:17.208245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = {\n#     'eta': 1e-3,\n#     'objective': 'binary:logitraw',\n#     'eval_metric': 'auc',\n# #     'use_label_encoder': False\n# }","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:25.294989Z","iopub.execute_input":"2022-03-31T13:23:25.29547Z","iopub.status.idle":"2022-03-31T13:23:25.298247Z","shell.execute_reply.started":"2022-03-31T13:23:25.295421Z","shell.execute_reply":"2022-03-31T13:23:25.297687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, HistGradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n# search = RandomizedSearchCV(\n#     n_iter=10,\n#     estimator=ExtraTreesClassifier(),\n#     param_distributions=params,\n#     random_state=1223,\n#     n_jobs=-1\n# )\n\nada_clf = AdaBoostClassifier(n_estimators=300, learning_rate=0.265)\nhist_clf = HistGradientBoostingClassifier(learning_rate=0.02)\nextra_clf = ExtraTreesClassifier(n_estimators=600, max_leaf_nodes=13, max_depth=9)\n\nmodel_ada = ada_clf.fit(X_train, y_train)\nmodel_hist = hist_clf.fit(X_train, y_train)\nmodel_extra = extra_clf.fit(X_train, y_train)\n# search.fit(X_train, y_train)\n\n# model = xgb.XGBClassifier(**params).fit(X_train, y_train)\n\n# pred_tr = model.predict(X_train)\n# print(\"Training classification report\\n\", classification_report(pred_tr, y_train))\n# pred_val = model.predict(X_valid)\n# print(\"\\nValidation classification report\\n\", classification_report(pred_val, y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:27.262932Z","iopub.execute_input":"2022-03-31T13:23:27.263392Z","iopub.status.idle":"2022-03-31T13:23:31.688716Z","shell.execute_reply.started":"2022-03-31T13:23:27.263342Z","shell.execute_reply":"2022-03-31T13:23:31.687595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print metrics\ndef print_metrics(model, name='boosting'):\n    pred_tr = model.predict(X_train)\n    print(f\"\\nModel {name}\")\n    print('-'*60)\n    print(\"Training classification report:\\n\", classification_report(pred_tr, y_train))\n    pred_val = model.predict(X_valid)\n    print(\"\\nValidation classification report: \\n\", classification_report(pred_val, y_valid))\n    print(\".\"*60)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:31.690578Z","iopub.execute_input":"2022-03-31T13:23:31.690901Z","iopub.status.idle":"2022-03-31T13:23:31.696269Z","shell.execute_reply.started":"2022-03-31T13:23:31.690857Z","shell.execute_reply":"2022-03-31T13:23:31.695771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_metrics(model_ada, 'AdaBoost')\nprint_metrics(model_extra, 'ExtraTrees')\nprint_metrics(model_hist, 'HistBoost')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:23:32.529341Z","iopub.execute_input":"2022-03-31T13:23:32.529804Z","iopub.status.idle":"2022-03-31T13:23:33.495234Z","shell.execute_reply.started":"2022-03-31T13:23:32.529741Z","shell.execute_reply":"2022-03-31T13:23:33.494412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ensembling\npreds_ada = model_ada.predict(test_df[features])\npreds_extra = model_extra.predict(test_df[features])\npreds_hist = model_hist.predict(test_df[features])\npreds_ensemble = 0.65*preds_ada + 0.1*preds_extra + 0.25*preds_hist","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:28:14.382461Z","iopub.execute_input":"2022-03-31T13:28:14.382839Z","iopub.status.idle":"2022-03-31T13:28:14.833219Z","shell.execute_reply.started":"2022-03-31T13:28:14.382804Z","shell.execute_reply":"2022-03-31T13:28:14.832385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.round(preds_ensemble,0)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:30:07.219941Z","iopub.execute_input":"2022-03-31T13:30:07.220405Z","iopub.status.idle":"2022-03-31T13:30:07.223591Z","shell.execute_reply.started":"2022-03-31T13:30:07.220356Z","shell.execute_reply":"2022-03-31T13:30:07.223065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\nsample_df['Transported'] = predictions.astype(bool)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:30:11.118534Z","iopub.execute_input":"2022-03-31T13:30:11.119007Z","iopub.status.idle":"2022-03-31T13:30:11.129612Z","shell.execute_reply.started":"2022-03-31T13:30:11.118959Z","shell.execute_reply":"2022-03-31T13:30:11.129083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SUBMISSION**","metadata":{}},{"cell_type":"code","source":"sample_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:30:15.128402Z","iopub.execute_input":"2022-03-31T13:30:15.128893Z","iopub.status.idle":"2022-03-31T13:30:15.141988Z","shell.execute_reply.started":"2022-03-31T13:30:15.128844Z","shell.execute_reply":"2022-03-31T13:30:15.141254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:30:17.442609Z","iopub.execute_input":"2022-03-31T13:30:17.443178Z","iopub.status.idle":"2022-03-31T13:30:17.460435Z","shell.execute_reply.started":"2022-03-31T13:30:17.443126Z","shell.execute_reply":"2022-03-31T13:30:17.459673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}