{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\n#train.dropna(inplace=True)\ntrain.drop_duplicates(inplace=True)\ntrain.head()\nlabel = train['Transported'].astype('bool')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train.csv - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n\nPassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n\nHomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n\nCryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n\nCabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n\nDestination - The planet the passenger will be debarking to.\n\nAge - The age of the passenger.\n\nVIP - Whether the passenger has paid for special VIP service during the voyage.\n\nRoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n\nName - The first and last names of the passenger.\n\nTransported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['HomePlanet']= train['HomePlanet'].fillna('Earth')\ntest['HomePlanet']= test['HomePlanet'].fillna('Earth')\ntrain['Destination']= train['Destination'].fillna('TRAPPIST-1e')\ntest['Destination']= test['Destination'].fillna('TRAPPIST-1e')\ntrain['CryoSleep']= train['CryoSleep'].fillna(False)\ntest['CryoSleep']= test['CryoSleep'].fillna(False)\ntrain['VIP']= train['VIP'].fillna(False)\ntest['VIP']= test['VIP'].fillna(False)\ntrain['Age']= train['Age'].fillna(train['Age'].mean())\ntest['Age']= test['Age'].fillna(train['Age'].mean())\ntrain['Spa']= train['Spa'].fillna(train['Spa'].mean())\ntest['Spa']= test['Spa'].fillna(train['Spa'].mean())\ntrain['FoodCourt']= train['FoodCourt'].fillna(train['FoodCourt'].mean())\ntest['FoodCourt']= test['FoodCourt'].fillna(train['FoodCourt'].mean())\ntrain['ShoppingMall']= train['ShoppingMall'].fillna(train['ShoppingMall'].mean())\ntest['ShoppingMall']= test['ShoppingMall'].fillna(train['ShoppingMall'].mean())\ntrain['RoomService']= train['RoomService'].fillna(train['RoomService'].mean())\ntest['RoomService']= test['RoomService'].fillna(test['RoomService'].mean())\ntrain['VRDeck']= train['VRDeck'].fillna(train['VRDeck'].mean())\ntest['VRDeck']= test['VRDeck'].fillna(test['VRDeck'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain['PassengerGrp']= train['PassengerId'].str.split(\"_\",expand=True)[0]\ntest['PassengerGrp']= test['PassengerId'].str.split(\"_\",expand=True)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Group'] = train.groupby('PassengerGrp')['PassengerId'].transform('count')>1\ntest['Group'] = test.groupby('PassengerGrp')['PassengerId'].transform('count')>1\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train[\"CryoSleep\"].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.countplot(data=train, x=\"Transported\", hue='VIP');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['Deck','Num','Side']] = train.Cabin.str.split(\"/\", expand=True)\ntest[['Deck','Num','Side']] = test.Cabin.str.split(\"/\", expand=True)\n\ntrain['Num'] =train['Num'].astype('float64')\ntest['Num'] =test['Num'].astype('float64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Deck']= train['Deck'].fillna('G')\ntrain['Num']= train['Num'].fillna(train['Num'].mean())\ntrain['Side']= train['Side'].fillna('S')\n\ntest['Deck']= test['Deck'].fillna('G')\ntest['Num']= test['Num'].fillna(train['Num'].mean())\ntest['Side']= test['Side'].fillna('S')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['VIP'] = train['VIP'].astype(int)\ntrain['Group'] = train['Group'].astype(int)\ntrain['Transported'] = train['Transported'].astype(int)\ntrain['CryoSleep'] = train['CryoSleep'].astype(int)\n\ntest['VIP'] = test['VIP'].astype(int)\ntest['Group'] = test['Group'].astype(int)\ntest['CryoSleep'] = test['CryoSleep'].astype(int)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop([\"Cabin\",\"PassengerId\",\"PassengerGrp\",\"Name\"], axis=1, inplace=True)\ntest.drop([\"Cabin\",\"PassengerId\",\"PassengerGrp\",\"Name\"], axis=1, inplace=True)\ncat_columns = train.select_dtypes(include='object').columns.values\nnum_columns = train.select_dtypes(exclude='object').columns.values\nprint(f\"\"\" \nCategorical columns:{cat_columns}\n\nNumerical columns: {num_columns}\n\"\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unique values; first 20\nfor col in cat_columns:\n    print(f\"\"\"{col} :\n------------------------------------\nUnique_value:   {train[col].nunique()}\nNull values: {train[col].isna().sum()}\nValues:   \n-------\n{train[col].value_counts(dropna=False) if train[col].nunique()<20 else train[col].unique()[:20]}\n\n    \"\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unique values; \nfor col in num_columns:\n    print(f\"\"\"{col} :\n------------------------------------\nUnique_value:   {train[col].nunique()}\nNull values: {train[col].isna().sum()}\nRange: {train[col].min()} - {train[col].max()} \nValues\n-------\n{train[col].value_counts(dropna=False) if train[col].nunique()<20 else train[col][:20].values}\n\n    \"\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = train.corr()\nfrom pandas.plotting import scatter_matrix\n\nattributes = abs(corr_matrix['Transported'].sort_values(ascending=False))\nprint(attributes)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = num_columns[num_columns!='Transported']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"churn_retain_stat = pd.DataFrame()\nfor col in cat_columns:\n  # create crosstab for each attribute\n  index = train[col]\n  ct = pd.crosstab(index=index, columns=train['Transported'], normalize='index', colnames=[None]).reset_index()\n\n  ct[col] = ct[col].apply(lambda x: f'{col.title()} ({x})')\n\n  # rename the column\n  ct.rename(columns={col:'attribute'}, inplace=True)\n\n  # create a single dataframe\n  churn_retain_stat = pd.concat([churn_retain_stat, ct])\n\nchurn_retain_stat.rename({0:'Transported',1:'NotTransported'}, axis=1,inplace=True)\nchurn_retain_stat.sort_values(by='Transported', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pipeline = Pipeline([\n                         ('imputer', SimpleImputer(strategy=\"median\")),\n                         ('std,scaler', StandardScaler())\n                         ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nfull_pipeline = ColumnTransformer([\n                                   (\"num\", num_pipeline, num_columns),\n                                   (\"cat\", OneHotEncoder(), cat_columns)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prepared = full_pipeline.fit_transform(train.drop('Transported', axis=1))\ntest_prepared = full_pipeline.transform(test)\ntrain_prepared","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\ntree_reg = RandomForestClassifier(n_estimators=100,random_state=1)\n# Run cross validation\ncv_results = cross_val_score(tree_reg, train_prepared, label, cv=5, scoring='roc_auc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cv_results)\nprint(np.mean(cv_results))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(train_prepared,label,test_size=0.33,random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nmodel_lgb = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)\nmodel_lgb.fit(x_train,y_train,eval_set=[(x_test,y_test),(x_train,y_train)],\n          eval_metric='logloss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training accuracy {:.4f}'.format(model_lgb.score(x_train,y_train)))\nprint('Testing accuracy {:.4f}'.format(model_lgb.score(x_test,y_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb.plot_importance(model_lgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model_lgb.predict(train_prepared)\nlen(pred),len(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(pred, label)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model_lgb.predict(test_prepared)\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred), len(test_prepared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\nsubmission = pd.DataFrame({'PassengerId':test.PassengerId,'Transported':pred})\n#submission['Transported']=submission['Transported'].apply(lambda x: x==1)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}