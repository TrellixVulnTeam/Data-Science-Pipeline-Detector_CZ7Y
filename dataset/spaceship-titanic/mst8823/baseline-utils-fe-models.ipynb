{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class CFG:\n    n_fold = 5\n    target_col = \"Transported\"\n    cv_strategy = \"kfold\"\n    seed = 2022\n    \n    model = \"LGB\"\n    model_params = {\n            'n_estimators' : 10000,\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            'max_depth': -1,\n            'num_leaves' :31,\n            'min_child_weight': 1,\n            'learning_rate': 0.01,\n            'random_state': 42,\n            'colsample_bytree': 0.8,\n            'importance_type': 'gain'\n                    }\n\n    fit_params=dict(\n        early_stopping_rounds=100, \n        verbose=100, \n        eval_metric=\"auc\")\n    save_model = False","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:45:04.413165Z","iopub.execute_input":"2022-03-08T08:45:04.413792Z","iopub.status.idle":"2022-03-08T08:45:04.420281Z","shell.execute_reply.started":"2022-03-08T08:45:04.413755Z","shell.execute_reply":"2022-03-08T08:45:04.419598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport joblib\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedGroupKFold, KFold\nfrom sklearn.metrics import roc_auc_score\n\nimport tensorflow as tf\nimport category_encoders as ce\n\nfrom matplotlib_venn import venn2\nfrom xgboost import XGBModel\nfrom lightgbm import LGBMModel","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:45:44.648774Z","iopub.execute_input":"2022-03-08T08:45:44.649273Z","iopub.status.idle":"2022-03-08T08:45:44.655462Z","shell.execute_reply.started":"2022-03-08T08:45:44.649239Z","shell.execute_reply":"2022-03-08T08:45:44.654672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def setup(CFG):\n    CFG.INPUT = \"../input/spaceship-titanic\"\n    CFG.OUTPUT = \".\"\n    CFG.OUTPUT_MODELS = f\"{CFG.OUTPUT}/models\"\n    CFG.OUTPUT_PREDS = f\"{CFG.OUTPUT}/preds\"\n    CFG.OUTPUT_FIGS = f\"{CFG.OUTPUT}/figs\"\n    CFG.SUBMISSION = f\"{CFG.OUTPUT}\"\n    \n    dirs = [CFG.OUTPUT_MODELS, CFG.OUTPUT_PREDS, CFG.OUTPUT_FIGS]\n    for d in dirs:\n        os.makedirs(d, exist_ok=True)\n    \n    # load raw data\n    load_raw_data(CFG)\n    \n    # setup\n    warnings.filterwarnings(\"ignore\")\n        \n        \ndef load_raw_data(CFG):\n    CFG.train_df = pd.read_csv(f\"{CFG.INPUT}/train.csv\")\n    CFG.test_df = pd.read_csv(f\"{CFG.INPUT}/test.csv\")\n    CFG.sample_submission_df = pd.read_csv(f\"{CFG.INPUT}/sample_submission.csv\")\n\nsetup(CFG)\ndisplay(CFG.train_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:28.125611Z","iopub.execute_input":"2022-03-08T08:46:28.125905Z","iopub.status.idle":"2022-03-08T08:46:28.213261Z","shell.execute_reply.started":"2022-03-08T08:46:28.125875Z","shell.execute_reply":"2022-03-08T08:46:28.212372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=2021):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n\nclass Util:\n    @classmethod\n    def dump(cls, value, path):\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        joblib.dump(value, path, compress=True)\n\n    @classmethod\n    def load(cls, path):\n        return joblib.load(path)\n\n    \ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    for col in df.columns:\n        if verbose:\n            print(col)\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'\n              .format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n\n\ndef plot_intersection(left, right, column, set_labels, ax=None):\n    left_set = set(left[column])\n    right_set = set(right[column])\n    venn2(subsets=(left_set, right_set), set_labels=set_labels, ax=ax)\n    return ax\n\n\ndef plot_right_left_intersection(train_df, test_df, columns='__all__'):\n    if columns == '__all__':\n        columns = set(train_df.columns) & set(test_df.columns)\n\n    columns = list(columns)\n    nfigs = len(columns)\n    ncols = 6\n    nrows = - (- nfigs // ncols)\n    fig, axes = plt.subplots(figsize=(3 * ncols, 3 * nrows), ncols=ncols, nrows=nrows)\n    axes = np.ravel(axes)\n    for c, ax in zip(columns, axes):\n        plot_intersection(train_df, test_df, column=c, set_labels=('Train', 'Test'), ax=ax)\n        ax.set_title(c)\n    return fig\n\n# plot_intersection (object)\ndef plot_intersection_object(CFG):\n    cols = CFG.train_df.dtypes[CFG.train_df.dtypes==\"object\"].index.tolist()\n    fig = plot_right_left_intersection(CFG.train_df, CFG.test_df, columns=cols)\n    return fig","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:29.544421Z","iopub.execute_input":"2022-03-08T08:46:29.545084Z","iopub.status.idle":"2022-03-08T08:46:29.570753Z","shell.execute_reply.started":"2022-03-08T08:46:29.545046Z","shell.execute_reply":"2022-03-08T08:46:29.570018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =========================================\n#  EDA\n# =========================================\nfig = plot_intersection_object(CFG)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:29.793436Z","iopub.execute_input":"2022-03-08T08:46:29.79446Z","iopub.status.idle":"2022-03-08T08:46:31.274522Z","shell.execute_reply.started":"2022-03-08T08:46:29.794417Z","shell.execute_reply":"2022-03-08T08:46:31.273413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =========================================\n#  CV\n# =========================================\ndef fold(CFG):\n    \n    CFG.train_df[\"fold\"] = -1\n    CFG.test_df[\"fold\"] = -1\n    \n    if CFG.cv_strategy == \"group\":\n        cv = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n        for i_fold, (trn_idx, va_idx) in enumerate(cv.split(CFG.train_df, \n                                                            CFG.train_df[CFG.target_col], \n                                                            groups=CFG.train_df[CFG.groups])):\n            CFG.train_df.loc[va_idx, \"fold\"] = i_fold\n        \n    else:\n        cv = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n        for i_fold, (trn_idx, va_idx) in enumerate(cv.split(CFG.train_df, \n                                                            CFG.train_df[CFG.target_col])):\n            CFG.train_df.loc[va_idx, \"fold\"] = i_fold\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:31.276577Z","iopub.execute_input":"2022-03-08T08:46:31.276861Z","iopub.status.idle":"2022-03-08T08:46:31.286665Z","shell.execute_reply.started":"2022-03-08T08:46:31.276826Z","shell.execute_reply":"2022-03-08T08:46:31.28555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =========================================\n#  FE\n# =========================================\ndef symmetric_difference2nan(train_df, test_df, cols):\n    for col in cols:\n        vals = list(set(train_df[col].unique()) ^ set(test_df[col].unique()))\n        print(f\"{col}... #{len(vals)} to Null\")\n        train_df[train_df[col].isin(vals)] = np.nan\n        test_df[test_df[col].isin(vals)] = np.nan\n    \n    return train_df, test_df\n\n\ndef target_encoding_cv(train_df, test_df, target_col, fold_col, cat_cols, cat_encoder=ce.TargetEncoder()):\n    \"\"\"\n    CatBoostEncoder\n    QuantileEncoder\n    JamesSteinEncoder\n    etc\n    \"\"\"\n    n_fold = train_df[fold_col].nunique()\n    \n    out_train_df = pd.DataFrame()\n    out_test_lst = []\n    for i_fold in range(n_fold):\n        val_mask = train_df[fold_col] == i_fold\n        trn_df = train_df[~val_mask].reset_index(drop=True)\n        val_df = train_df[val_mask]\n        val_idx = val_df.index.tolist()\n        \n        cat_encoder.fit(X=trn_df[cat_cols], y=trn_df[target_col])\n        te_val_df = cat_encoder.transform(X=val_df[cat_cols]).add_prefix(\"TE=\")\n        te_val_df.index = val_idx\n        out_train_df = pd.concat([out_train_df, te_val_df])\n        \n        te_test_vals= cat_encoder.transform(X=test_df[cat_cols]).values\n        out_test_lst.append(te_test_vals)\n    \n    out_train_df = out_train_df.sort_index()\n    out_test_df = pd.DataFrame(np.mean(out_test_lst, axis=0), columns=cat_cols).add_prefix(\"TE=\")\n    return out_train_df, out_test_df\n\n\ndef concat_out(input_df, output_df):\n    return pd.concat([input_df, output_df], axis=1)\n\n\ndef aggregation(input_df, group_key, group_values, agg_methods):\n    \"\"\"ref:https://github.com/pfnet-research/xfeat/blob/master/xfeat/helper.py\"\"\"\n    new_df = []\n    for agg_method in agg_methods:\n        for col in group_values:\n            if callable(agg_method):\n                agg_method_name = agg_method.__name__\n            else:\n                agg_method_name = agg_method\n            new_col = f\"agg_{agg_method_name}_{col}_grpby_{group_key}\"\n            df_agg = (input_df[[col] + [group_key]].groupby(group_key)[[col]].agg(agg_method))\n            df_agg.columns = [new_col]\n            new_df.append(df_agg)\n\n    _df = pd.concat(new_df, axis=1).reset_index()\n    output_df = pd.merge(input_df[[group_key]], _df, on=group_key, how=\"left\")\n    return output_df.drop(group_key, axis=1)\n\n    \ndef fe(CFG):\n    output_df = pd.DataFrame()\n    input_df = pd.concat([CFG.train_df, CFG.test_df]).reset_index(drop=True)\n    print(\"# ----------- # change type # ----------- #\")\n    input_df[CFG.target_col] = input_df[CFG.target_col].astype(float)\n    \n    \n    print(\"# ----------- # not features # ----------- #\")\n    cols = [\"fold\",  CFG.target_col]\n    output_df = concat_out(input_df[cols], output_df)\n    \n    \n    print(\"# ----------- # raw features # ----------- #\")\n    cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n    output_df = concat_out(input_df[cols], output_df)\n    \n    \n    print(\"# ----------- # ordinal encode # ----------- #\")\n    cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\"]\n    _df = ce.OrdinalEncoder().fit_transform(input_df[cols])\n    output_df = concat_out(_df, output_df)\n    \n    \n    print(\"# ----------- # agg features # ----------- #\")\n    group_keys = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\"]\n    group_values = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n    agg_methods = [\"min\", \"mean\", \"max\"]\n    _df = pd.DataFrame()\n    for group_key in group_keys:\n        agg_df = aggregation(input_df, group_key, group_values, agg_methods)\n        _df = pd.concat([_df, agg_df], axis=1)\n    output_df = concat_out(_df, output_df)\n    \n    \n    print(\"# ----------- # target encoding # ----------- #\")\n    fold_col = \"fold\"\n    cat_cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\"]\n    cat_encoder = ce.TargetEncoder()\n    _train_df, _test_df = target_encoding_cv(CFG.train_df, CFG.test_df, CFG.target_col, fold_col, cat_cols, cat_encoder)\n    _df = pd.concat([_train_df, _test_df]).reset_index(drop=True)\n    output_df = concat_out(_df, output_df)\n    display(output_df)\n    \n    print(\"# ----------- # finish fe # ----------- #\")\n    out_train_df = output_df.iloc[:len(CFG.train_df)]\n    out_test_df = output_df.iloc[len(CFG.train_df):].reset_index(drop=True)\n    return out_train_df, out_test_df","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:31.288364Z","iopub.execute_input":"2022-03-08T08:46:31.28862Z","iopub.status.idle":"2022-03-08T08:46:31.319858Z","shell.execute_reply.started":"2022-03-08T08:46:31.288589Z","shell.execute_reply":"2022-03-08T08:46:31.319071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold(CFG)\ntrain_df, test_df = fe(CFG)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:31.321746Z","iopub.execute_input":"2022-03-08T08:46:31.322139Z","iopub.status.idle":"2022-03-08T08:46:32.218772Z","shell.execute_reply.started":"2022-03-08T08:46:31.322108Z","shell.execute_reply":"2022-03-08T08:46:32.218023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    return roc_auc_score(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:32.220016Z","iopub.execute_input":"2022-03-08T08:46:32.220371Z","iopub.status.idle":"2022-03-08T08:46:32.226331Z","shell.execute_reply.started":"2022-03-08T08:46:32.220323Z","shell.execute_reply":"2022-03-08T08:46:32.22528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train & Predict","metadata":{}},{"cell_type":"code","source":"def get_model(CFG):\n    if CFG.model == \"XGB\":\n        return XGBModel\n    \n    elif CFG.model == \"LGB\":\n        return LGBMModel\n    \n    else:\n        raise NotImplementedError\n\n\ndef train_cv(CFG, df, no_feature_cols=[\"fold\", CFG.target_col]):\n    \n    oof_df = pd.DataFrame()\n    oof = np.zeros(len(df))\n    \n    feature_cols = [x for x in df.columns if x not in no_feature_cols]\n    X = df[feature_cols]\n    y = df[CFG.target_col]\n\n    models = []\n    for i_fold in range(CFG.n_fold):\n\n        filepath = f\"{CFG.OUTPUT_MODELS}/XGB-Fold{i_fold}.pkl\"\n        val_mask = (df[\"fold\"] == i_fold).astype(bool)\n        tr_x, tr_y = X[~val_mask].reset_index(drop=True), y[~val_mask].reset_index(drop=True)\n        va_x, va_y = X[val_mask].reset_index(drop=True), y[val_mask].reset_index(drop=True)\n\n        if not os.path.isfile(filepath):    \n            model = get_model(CFG)(**CFG.model_params)\n            model.fit(tr_x, tr_y, eval_set=[(va_x, va_y)], **CFG.fit_params)\n            if CFG.save_model:\n                Util.dump(model, filepath)\n        if CFG.save_model:\n            model = Util.load(filepath)\n            \n        preds = model.predict(va_x)\n        models.append(model)\n\n        # get score\n        score = get_score(va_y, preds)\n        print(f\"target:{CFG.target_col}_fold{i_fold}={score:.5f}\")\n        oof[val_mask] = preds\n\n    oof_df[CFG.target_col] = oof\n    # save fold preds\n    oof_df.to_csv(CFG.OUTPUT_PREDS + \"/raw_oof_df.csv\", index=False)\n\n    # get score\n    score = get_score(y, oof)\n    print(f\"target:{CFG.target_col}={score:.5f}\")\n\n    return oof_df, models\n\n\ndef predict_cv(CFG, df, models=None, no_feature_cols=[\"fold\", CFG.target_col]):\n\n    feature_cols = [x for x in df.columns if x not in no_feature_cols]\n    X = df[feature_cols]\n    y = df[CFG.target_col]\n\n    preds_df = pd.DataFrame()\n    fold_preds = []\n    for i_fold in range(CFG.n_fold):\n        if models is None:\n            filepath = f\"{CFG.EXP_MODEL}/XGB-Fold{i_fold}.pkl\"\n            model = Util.load(filepath)\n        else:\n            model =models[i_fold]\n            \n        preds = model.predict(X)\n        fold_preds.append(preds)\n\n        # save fold preds\n        Util.dump(preds, CFG.OUTPUT_PREDS + f\"/raw_preds_target{CFG.target_col}_fold{i_fold}.pkl\")\n        \n    preds_df[CFG.target_col] = np.mean(fold_preds, axis=0)\n    preds_df.to_csv(CFG.OUTPUT_PREDS + \"/raw_preds_df.csv\", index=False)\n    return preds_df\n","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:32.229572Z","iopub.execute_input":"2022-03-08T08:46:32.230084Z","iopub.status.idle":"2022-03-08T08:46:32.252884Z","shell.execute_reply.started":"2022-03-08T08:46:32.229988Z","shell.execute_reply":"2022-03-08T08:46:32.25209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df, models = train_cv(CFG, df=train_df, no_feature_cols=[\"fold\", CFG.target_col])\npreds_df = predict_cv(CFG, df=test_df, models=models, no_feature_cols=[\"fold\", CFG.target_col])           ","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:32.253983Z","iopub.execute_input":"2022-03-08T08:46:32.254208Z","iopub.status.idle":"2022-03-08T08:46:39.621616Z","shell.execute_reply.started":"2022-03-08T08:46:32.25418Z","shell.execute_reply":"2022-03-08T08:46:39.620708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importance","metadata":{}},{"cell_type":"code","source":"def visualize_importance(models, feat_train_df, no_feature_cols=[\"fold\", CFG.target_col]):\n    \"\"\"lightGBM の model 配列の feature importance を plot する\n    CVごとのブレを boxen plot として表現します.\n\n    args:\n        models:\n            List of lightGBM models\n        feat_train_df:\n            学習時に使った DataFrame\n    \"\"\"\n    feature_importance_df = pd.DataFrame()\n    \n    feature_cols = [x for x in feat_train_df.columns if x not in no_feature_cols]\n    for i, model in enumerate(models):\n        _df = pd.DataFrame()\n        _df[\"feature_importance\"] = model.feature_importances_\n        _df[\"column\"] = feature_cols\n        _df[\"fold\"] = i + 1\n        feature_importance_df = pd.concat([feature_importance_df, _df], \n                                          axis=0, ignore_index=True)\n\n    order = feature_importance_df.groupby(\"column\")\\\n        .sum()[[\"feature_importance\"]]\\\n        .sort_values(\"feature_importance\", ascending=False).index[:50]\n\n    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n    sns.boxenplot(data=feature_importance_df, \n                  x=\"feature_importance\", \n                  y=\"column\", \n                  order=order, \n                  ax=ax, \n                  palette=\"viridis\", \n                  orient=\"h\")\n    ax.tick_params(axis=\"x\", rotation=90)\n    ax.set_title(\"Importance\")\n    ax.grid()\n    fig.tight_layout()\n    return fig, ax\n\nfig, ax = visualize_importance(models, train_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:46:54.315968Z","iopub.execute_input":"2022-03-08T08:46:54.31626Z","iopub.status.idle":"2022-03-08T08:46:56.567438Z","shell.execute_reply.started":"2022-03-08T08:46:54.31623Z","shell.execute_reply":"2022-03-08T08:46:56.566402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub = CFG.sample_submission_df.copy()\nsub[CFG.target_col] = (preds_df[CFG.target_col] >= 0.5).astype(int)\ndisplay(sub)\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T08:48:52.643122Z","iopub.execute_input":"2022-03-08T08:48:52.643462Z","iopub.status.idle":"2022-03-08T08:48:52.659905Z","shell.execute_reply.started":"2022-03-08T08:48:52.643429Z","shell.execute_reply":"2022-03-08T08:48:52.65908Z"},"trusted":true},"execution_count":null,"outputs":[]}]}