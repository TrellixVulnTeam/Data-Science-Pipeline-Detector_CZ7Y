{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"class Config:\n\n    # inital config\n    author : str = \"mst8823\"\n    name : str = \"exp001\"\n    competition : str = \"spaceship-titanic\"\n    debug : bool = False\n\n    # exp config\n    target_col = \"Transported\"\n    seed : int = 33\n    num_fold : int = 5\n    train_fold : list = [0, 1, 2, 3, 4]\n    overwrite : bool = False\n\n    # model config\n    model_name : str = \"LGB\"\n    model_params : dict = dict(\n        objective=\"binary\",\n        n_estimators=10000, \n        num_leaves=31, \n        colsample_bytree=.1, \n        learning_rate=0.01,\n        importance_type=\"gain\", \n        random_state=seed\n        )\n    fit_params : dict = dict(\n        early_stopping_rounds=300, \n        verbose=100,\n        eval_metric=\"auc\"\n        )\n    \n    # colab config\n    HOME : str = \"/content/drive/MyDrive/spaceship-titanic\"\n    API : str = \"/content/drive/MyDrive/competition/kaggle.json\"\n    upload_from_colab = False\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-11T12:52:21.661461Z","iopub.execute_input":"2022-06-11T12:52:21.662031Z","iopub.status.idle":"2022-06-11T12:52:21.694202Z","shell.execute_reply.started":"2022-06-11T12:52:21.661919Z","shell.execute_reply":"2022-06-11T12:52:21.693183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport random\nimport joblib\nimport shutil\nimport logging\nimport warnings\nimport datetime\nimport requests\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom lightgbm import LGBMModel\nfrom xgboost import XGBModel\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:21.764997Z","iopub.execute_input":"2022-06-11T12:52:21.765994Z","iopub.status.idle":"2022-06-11T12:52:25.551251Z","shell.execute_reply.started":"2022-06-11T12:52:21.765925Z","shell.execute_reply":"2022-06-11T12:52:25.550133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"def setup(config):\n    config.COLAB = \"google.colab\" in sys.modules\n    if config.COLAB:\n        print(\"This environment is Google Colab\")\n\n        # mount\n        from google.colab import drive\n        if not os.path.isdir(\"/content/drive\"):\n            drive.mount(\"/content/drive\") \n\n        # use kaggle api (need kaggle token)\n        f = open(config.API, 'r')\n        json_data = json.load(f) \n        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n        os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n\n        # set dirs\n        config.EXP = (config.name if config.name is not None \n            else requests.get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6]\n        )\n        config.INPUT = os.path.join(config.HOME, \"input\")\n        config.OUTPUT = os.path.join(config.HOME, \"output\")\n        config.SUBMISSION = os.path.join(config.HOME, \"submission\")\n\n        config.OUTPUT_EXP = os.path.join(config.OUTPUT, config.EXP) \n        config.EXP_MODEL = os.path.join(config.OUTPUT_EXP, \"model\")\n        config.EXP_FIG = os.path.join(config.OUTPUT_EXP, \"fig\")\n        config.EXP_PREDS = os.path.join(config.OUTPUT_EXP, \"preds\")\n\n        # make dirs\n        for d in [\n                config.HOME,\n                config.INPUT, \n                config.SUBMISSION, \n                config.EXP_MODEL, \n                config.EXP_FIG, \n                config.EXP_PREDS\n                ]:\n            os.makedirs(d, exist_ok=True)\n        \n        if not os.path.isfile(os.path.join(config.INPUT, 'sample_submission.csv')):\n            # load dataset\n            ! pip install --upgrade --force-reinstall --no-deps kaggle\n            ! kaggle competitions download -c $config.competition -p $config.INPUT\n            filepath = os.path.join(config.INPUT, config.competition+'.zip')\n            ! unzip -d $config.INPUT $filepath\n\n    else:\n        print(\"This environment is Kaggle Kernel\")\n\n        # set dirs\n        config.INPUT = f\"../input/{config.competition}\"\n        config.EXP = config.name\n        config.OUTPUT_EXP = config.name\n        config.SUBMISSION = \"./\"\n        config.DATASET = \"../input/\"\n        config.EXP_MODEL = os.path.join(config.EXP, \"model\")\n        config.EXP_FIG = os.path.join(config.EXP, \"fig\")\n        config.EXP_PREDS = os.path.join(config.EXP, \"preds\")\n\n        # make dirs\n        for d in [config.EXP_MODEL, config.EXP_FIG, config.EXP_PREDS]:\n            os.makedirs(d, exist_ok=True)\n\n    config.logger = Logger(config.OUTPUT_EXP)\n    seed_everything(config.seed)\n    warnings.filterwarnings(\"ignore\")\n    return config\n\n\ndef seed_everything(seed=2022):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef dataset_create_new(dataset_name, upload_dir):\n    from kaggle.api.kaggle_api_extended import KaggleApi\n\n    dataset_metadata = {}\n    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n    dataset_metadata['title'] = dataset_name\n    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n        json.dump(dataset_metadata, f, indent=4)\n    api = KaggleApi()\n    api.authenticate()\n    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n\n\nclass Logger:\n    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n    def __init__(self, path):\n        self.general_logger = logging.getLogger(path)\n        stream_handler = logging.StreamHandler()\n        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n        if len(self.general_logger.handlers) == 0:\n            self.general_logger.addHandler(stream_handler)\n            self.general_logger.addHandler(file_general_handler)\n            self.general_logger.setLevel(logging.INFO)\n\n    def info(self, message):\n        # display time\n        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n\n    @staticmethod\n    def now_string():\n        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\n\nclass Util:\n    @classmethod\n    def dump(cls, value, path):\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        joblib.dump(value, path, compress=True)\n\n    @classmethod\n    def load(cls, path):\n        return joblib.load(path)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.55325Z","iopub.execute_input":"2022-06-11T12:52:25.554215Z","iopub.status.idle":"2022-06-11T12:52:25.636554Z","shell.execute_reply.started":"2022-06-11T12:52:25.554178Z","shell.execute_reply":"2022-06-11T12:52:25.635132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV & Metrics","metadata":{}},{"cell_type":"code","source":"def add_fold(config, train_df):\n    \"\"\"get fold number\"\"\"\n    cv = StratifiedKFold(\n        n_splits=config.num_fold, \n        shuffle=True, \n        random_state=config.seed\n        )\n    train_df[\"fold\"] = -1\n    for i_fold, (trn_idx, val_idx) in enumerate(cv.split(train_df, y=train_df[config.target_col])):\n        train_df.loc[val_idx, \"fold\"] =  i_fold\n    train_df[\"fold\"] = train_df[\"fold\"].astype(int) \n    return train_df","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.638138Z","iopub.execute_input":"2022-06-11T12:52:25.638545Z","iopub.status.idle":"2022-06-11T12:52:25.653004Z","shell.execute_reply.started":"2022-06-11T12:52:25.638509Z","shell.execute_reply":"2022-06-11T12:52:25.651949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(config, y_true, y_pred):\n    score = roc_auc_score(y_true=y_true, y_score=y_pred)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.655097Z","iopub.execute_input":"2022-06-11T12:52:25.65608Z","iopub.status.idle":"2022-06-11T12:52:25.669711Z","shell.execute_reply.started":"2022-06-11T12:52:25.656024Z","shell.execute_reply":"2022-06-11T12:52:25.668735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"def get_raw_features(input_df):\n    cols = [\n        \"Age\", \n        \"RoomService\", \n        \"FoodCourt\", \n        \"ShoppingMall\", \n        \"Spa\", \n        \"VRDeck\"\n        ]\n    return input_df[cols]\n\n\ndef preprocess(config, raw_train_df, raw_test_df):\n    raw_train_df[config.target_col] = raw_train_df[config.target_col].astype(int)\n\n    # concat train & test\n    input_df = pd.concat(\n        [raw_train_df, raw_test_df]).reset_index(drop=True)\n\n    # select no features\n    config.no_feature_cols = [\n                    config.target_col, \n                    \"fold\"\n                    ]\n    output_df = input_df[config.no_feature_cols]\n    \n    # select fe funcs\n    funcs = [\n        get_raw_features\n    ]\n\n    # fe\n    for func in funcs:\n        print(func.__name__)\n        _df = func(input_df)\n        output_df = pd.concat([output_df, _df], axis=1)\n\n    train_df = output_df.iloc[:len(raw_train_df)]\n    test_df = output_df.iloc[len(raw_train_df):].reset_index(drop=True)\n    return train_df, test_df","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.671278Z","iopub.execute_input":"2022-06-11T12:52:25.671721Z","iopub.status.idle":"2022-06-11T12:52:25.683506Z","shell.execute_reply.started":"2022-06-11T12:52:25.671682Z","shell.execute_reply":"2022-06-11T12:52:25.682503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"def get_model(config):\n    if config.model_name == \"XGB\":\n        return XGBModel\n    \n    elif config.model_name == \"LGB\":\n        return LGBMModel\n    \n    else:\n        raise NotImplementedError\n\n\ndef train_cv(config, train_df):\n    # oof\n    oof = np.zeros(len(train_df))\n    models = []\n    \n    # split X and y\n    feature_cols = [x for x in train_df.columns if x not in config.no_feature_cols]\n    X = train_df[feature_cols]\n    y = train_df[config.target_col]\n\n    for i_fold in range(config.num_fold):\n        if i_fold not in config.train_fold:\n            continue\n        prefix = f\"fold{i_fold}\"\n\n        # split train val\n        val_mask = (train_df[\"fold\"] == i_fold).astype(bool)\n        tr_x, tr_y = X[~val_mask].reset_index(drop=True), y[~val_mask].reset_index(drop=True)\n        va_x, va_y = X[val_mask].reset_index(drop=True), y[val_mask].reset_index(drop=True)\n\n        # get fit params\n        fit_params = config.fit_params.copy()\n        if config.model_name in [\"LGB\", \"XGB\", \"CAT\"]:\n            fit_params[\"eval_set\"] = [(va_x, va_y)]\n\n        # fit and save\n        filepath = f\"{config.EXP_MODEL}/{prefix}.pkl\"\n        if (not os.path.isfile(filepath)) or (config.overwrite):    \n            model = get_model(config)(**config.model_params)\n            model.fit(tr_x, tr_y, **fit_params)\n            Util.dump(model, filepath)\n        else:\n            model = Util.load(filepath)\n        \n        # predict\n        preds = np.array(model.predict(va_x), dtype=np.float64)\n        models.append(model)\n\n        # get score\n        score = get_score(config, va_y, preds)\n        config.logger.info(f\"seed{config.seed}_fold{i_fold}={score:.5f}\")\n        oof[val_mask] = preds \n\n        # save fold predictions\n        filepath = f\"{config.EXP_PREDS}/oof__{prefix}.pkl\"\n        Util.dump(preds, filepath)\n\n    # save fold preds\n    filepath = f\"{config.EXP_PREDS}/oof.pkl\"\n    Util.dump(oof, filepath)\n\n    # get score\n    score = get_score(config, y, oof)\n    config.logger.info(f\"target:{config.target_col}={score:.5f}\")\n\n    return oof, models","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.685417Z","iopub.execute_input":"2022-06-11T12:52:25.68613Z","iopub.status.idle":"2022-06-11T12:52:25.70343Z","shell.execute_reply.started":"2022-06-11T12:52:25.68609Z","shell.execute_reply":"2022-06-11T12:52:25.702396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"def predict_cv(config, test_df, models=None):\n\n    feature_cols = [x for x in test_df.columns if x not in config.no_feature_cols]\n    X = test_df[feature_cols]\n\n    fold_preds = []\n    for i_fold in range(config.num_fold):\n        if i_fold not in config.train_fold:\n            continue\n        prefix = f\"fold{i_fold}\"\n        if models is None:\n            filepath = f\"{config.EXP_MODEL}/{prefix}.pkl\"\n            model = Util.load(filepath)\n        else:\n            model = models[i_fold]\n            \n        preds = model.predict(X)\n        fold_preds.append(preds)\n\n        # save fold preds\n        filepath = f\"{config.EXP_PREDS}/preds__{prefix}.pkl\"\n        Util.dump(preds, filepath)\n    \n    predictions = np.mean(fold_preds, axis=0)\n    filepath = f\"{config.EXP_PREDS}/preds.pkl\"\n    Util.dump(predictions, filepath)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.705914Z","iopub.execute_input":"2022-06-11T12:52:25.706593Z","iopub.status.idle":"2022-06-11T12:52:25.722513Z","shell.execute_reply.started":"2022-06-11T12:52:25.706516Z","shell.execute_reply":"2022-06-11T12:52:25.721466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_importance(models, feat_train_df, no_feature_cols):\n    \"\"\"lightGBM の model 配列の feature importance を plot する\n    CVごとのブレを boxen plot として表現します.\n\n    args:\n        models:\n            List of lightGBM models\n        feat_train_df:\n            学習時に使った DataFrame\n    \"\"\"\n    feature_importance_df = pd.DataFrame()\n    \n    feature_cols = [x for x in feat_train_df.columns if x not in no_feature_cols]\n    for i, model in enumerate(models):\n        _df = pd.DataFrame()\n        _df[\"feature_importance\"] = model.feature_importances_\n        _df[\"column\"] = feature_cols\n        _df[\"fold\"] = i + 1\n        feature_importance_df = pd.concat([feature_importance_df, _df], \n                                          axis=0, ignore_index=True)\n\n    order = feature_importance_df.groupby(\"column\")\\\n        .sum()[[\"feature_importance\"]]\\\n        .sort_values(\"feature_importance\", ascending=False).index[:50]\n\n    fig, ax = plt.subplots(figsize=(12, max(6, len(order) * .25)))\n    sns.boxenplot(data=feature_importance_df, \n                  x=\"feature_importance\", \n                  y=\"column\", \n                  order=order, \n                  ax=ax, \n                  palette=\"viridis\", \n                  orient=\"h\")\n    ax.tick_params(axis=\"x\", rotation=90)\n    ax.set_title(\"Importance\")\n    ax.grid()\n    fig.tight_layout()\n    return fig, ax","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.723987Z","iopub.execute_input":"2022-06-11T12:52:25.724802Z","iopub.status.idle":"2022-06-11T12:52:25.739241Z","shell.execute_reply.started":"2022-06-11T12:52:25.724748Z","shell.execute_reply":"2022-06-11T12:52:25.738119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"# setup\nConfig = setup(Config)\n\n# get data\nraw_train_df = pd.read_csv(Config.INPUT + \"/train.csv\")\nraw_test_df = pd.read_csv(Config.INPUT + \"/test.csv\")\nsubmission_df = pd.read_csv(Config.INPUT + \"/sample_submission.csv\")\n\nif Config.debug:\n    raw_train_df = raw_train_df.sample(1000).reset_index(drop=True)\n\n# cv split & preprocess\ntrain_df = add_fold(Config, raw_train_df)\ntrain_df, test_df = preprocess(Config, raw_train_df, raw_test_df)\n\n# train\noof, models = train_cv(Config, train_df)\n\n# importanceAA\nfig, ax = visualize_importance(models, train_df, no_feature_cols=Config.no_feature_cols)\nfig.savefig(Config.EXP_FIG + \"/tree_importance.png\", dpi=300)\n\n# predict\npreds = predict_cv(Config, test_df, models=models)\n\n# make submission\nsubmission_df[Config.target_col] = 1 * (preds >= 0.5)\ndisplay(submission_df)\nsubmission_df.to_csv(f\"{Config.SUBMISSION}/{Config.name}.csv\", index=False)\n\n# upload to kaggle dataset from colab\nif Config.upload_from_colab:\n    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T12:52:25.740906Z","iopub.execute_input":"2022-06-11T12:52:25.74145Z","iopub.status.idle":"2022-06-11T12:52:50.435859Z","shell.execute_reply.started":"2022-06-11T12:52:25.741414Z","shell.execute_reply":"2022-06-11T12:52:50.434622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}