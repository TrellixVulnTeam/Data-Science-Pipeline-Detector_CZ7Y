{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-24T19:27:01.963544Z","iopub.execute_input":"2022-06-24T19:27:01.964282Z","iopub.status.idle":"2022-06-24T19:27:01.999988Z","shell.execute_reply.started":"2022-06-24T19:27:01.964141Z","shell.execute_reply":"2022-06-24T19:27:01.999194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading the data and combining training and test dfs.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n\ndisplay(df)\ndisplay(test)\n\ndf_train = df.drop(['Transported'], axis=1)\n\nto_train = pd.concat([df_train, test], axis=0).reset_index().drop('index', axis=1)\ndisplay(to_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T19:27:04.950592Z","iopub.execute_input":"2022-06-24T19:27:04.951062Z","iopub.status.idle":"2022-06-24T19:27:05.165031Z","shell.execute_reply.started":"2022-06-24T19:27:04.951027Z","shell.execute_reply":"2022-06-24T19:27:05.164076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Engineering.","metadata":{}},{"cell_type":"code","source":"to_train['Cabin'] = to_train['Cabin'].fillna('Null/5000/Null')\nto_train['Cabin Section A'] = [x.split('/')[0] for x in to_train['Cabin']]\nto_train['Cabin Section B'] = [x.split('/')[1] for x in to_train['Cabin']]\nto_train['Cabin Section C'] = [x.split('/')[2] for x in to_train['Cabin']]\n\nto_train['Passenger Sub ID'] = [x.split('_')[1] for x in to_train['PassengerId']]\nto_train['Passenger Group ID'] = [x.split('_')[0] for x in to_train['PassengerId']]\n\nto_train['Name'] = to_train['Name'].fillna('Null Null')\nto_train['Family'] = [x.split(' ')[1] for x in to_train['Name']]\n\nto_train = to_train.drop(['Name','Cabin'], axis=1)\n\ndisplay(to_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T19:27:08.814945Z","iopub.execute_input":"2022-06-24T19:27:08.816155Z","iopub.status.idle":"2022-06-24T19:27:08.940064Z","shell.execute_reply.started":"2022-06-24T19:27:08.816095Z","shell.execute_reply":"2022-06-24T19:27:08.938931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\nage_range_cat = []\nfor age in to_train['Age']:\n    if (age>=-100) & (age<=10):\n        age_range_cat.append(1)\n    if (age>10) & (age<=20):\n        age_range_cat.append(2)\n    if (age>20) & (age<=30):\n        age_range_cat.append(3)\n    if (age>30) & (age<=40):\n        age_range_cat.append(4)\n    if (age>40) & (age<=50):\n        age_range_cat.append(5)\n    if (age>50) & (age<=60):\n        age_range_cat.append(6)\n    if (age>60) & (age<=70):\n        age_range_cat.append(7)\n    if (age>70) & (age<=80):\n        age_range_cat.append(8)\n    if (age>80) & (age<=90):\n        age_range_cat.append(9)\n    if (age>90) & (age<=100):\n        age_range_cat.append(10)\n    if math.isnan(float(age))==True:\n        age_range_cat.append(11)\n\nto_train['Age Category'] = age_range_cat\nto_train['Age Category'] = to_train['Age Category'].astype('category').cat.codes\nto_train['Is Adult'] = [1 if x<18 else 0 for x in to_train['Age']]\nto_train = to_train.drop('Age', axis=1)\n\ndisplay(to_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T19:27:11.920138Z","iopub.execute_input":"2022-06-24T19:27:11.921522Z","iopub.status.idle":"2022-06-24T19:27:12.021815Z","shell.execute_reply.started":"2022-06-24T19:27:11.921459Z","shell.execute_reply":"2022-06-24T19:27:12.020653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datawig","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:26:07.366575Z","iopub.execute_input":"2022-06-24T17:26:07.367431Z","iopub.status.idle":"2022-06-24T17:27:22.797237Z","shell.execute_reply.started":"2022-06-24T17:26:07.367392Z","shell.execute_reply":"2022-06-24T17:27:22.796115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imputation of missing values across columns.","metadata":{}},{"cell_type":"code","source":"import datawig\n\ndf_train_hpl = to_train[to_train['HomePlanet'].isnull()==False]\ndf_test_hpl = to_train[to_train['HomePlanet'].isnull()==True]\n\ndf_train_cry = to_train[to_train['CryoSleep'].isnull()==False]\ndf_test_cry = to_train[to_train['CryoSleep'].isnull()==True]\n\ndf_train_des = to_train[to_train['Destination'].isnull()==False]\ndf_test_des = to_train[to_train['Destination'].isnull()==True]\n\ndf_train_VIP = to_train[to_train['VIP'].isnull()==False]\ndf_test_VIP = to_train[to_train['VIP'].isnull()==True]\n\ndf_train_cba = to_train[to_train['Cabin Section A'] !='Null']\ndf_test_cba = to_train[to_train['Cabin Section A'] =='Null']\n\ndf_train_cbc = to_train[to_train['Cabin Section C'] !='Null']\ndf_test_cbc = to_train[to_train['Cabin Section C'] =='Null']\n\nimputer_hpl = datawig.SimpleImputer(\n    input_columns= ['Destination','Age Category','RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin Section A', 'Cabin Section B', 'Cabin Section C', 'Passenger Sub ID','Passenger Group ID','Is Adult','Family'], # column(s) containing information about the column we want to impute\n    output_column= 'HomePlanet', # the column we'd like to impute values for\n    output_path = 'imputer_model' # stores model data and metrics\n    )\n\nimputer_cry = datawig.SimpleImputer(\n    input_columns= ['HomePlanet','Destination','Age Category', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin Section A', 'Cabin Section B', 'Cabin Section C', 'Passenger Sub ID','Passenger Group ID','Is Adult','Family'], # column(s) containing information about the column we want to impute\n    output_column= 'CryoSleep', # the column we'd like to impute values for\n    output_path = 'imputer_model' # stores model data and metrics\n    )\nimputer_des = datawig.SimpleImputer(\n    input_columns= ['HomePlanet','Age Category', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin Section A', 'Cabin Section B', 'Cabin Section C', 'Passenger Sub ID','Passenger Group ID','Is Adult','Family'], # column(s) containing information about the column we want to impute\n    output_column= 'Destination', # the column we'd like to impute values for\n    output_path = 'imputer_model' # stores model data and metrics\n    )\nimputer_VIP = datawig.SimpleImputer(\n    input_columns= ['HomePlanet','Age Category','Destination', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Cabin Section A', 'Cabin Section B', 'Cabin Section C', 'Passenger Sub ID','Passenger Group ID','Is Adult','Family'], # column(s) containing information about the column we want to impute\n    output_column= 'VIP', # the column we'd like to impute values for\n    output_path = 'imputer_model' # stores model data and metrics\n    )\n\nimputer_cba = datawig.SimpleImputer(\n    input_columns= ['HomePlanet','Age Category','Destination', 'RoomService', 'ShoppingMall','Spa', 'Cabin Section B', 'Cabin Section C', 'Passenger Sub ID','Passenger Group ID','Is Adult','Family'], # column(s) containing information about the column we want to impute\n    output_column= 'Cabin Section A', # the column we'd like to impute values for\n    output_path = 'imputer_model' # stores model data and metrics\n    )\nimputer_cbc = datawig.SimpleImputer(\n    input_columns= ['HomePlanet','Age Category','Destination', 'RoomService', 'ShoppingMall','Spa', 'Cabin Section B', 'Passenger Sub ID','Passenger Group ID','Is Adult','Family'], # column(s) containing information about the column we want to impute\n    output_column= 'Cabin Section C', # the column we'd like to impute values for\n    output_path = 'imputer_model' # stores model data and metrics\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:27:32.582943Z","iopub.execute_input":"2022-06-24T17:27:32.583367Z","iopub.status.idle":"2022-06-24T17:27:34.123018Z","shell.execute_reply.started":"2022-06-24T17:27:32.583329Z","shell.execute_reply":"2022-06-24T17:27:34.122022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer_hpl.fit(train_df=df_train_hpl, num_epochs=10)\nimputed_hpl = imputer_hpl.predict(df_test_hpl)\n\nimputer_cry.fit(train_df=df_train_cry, num_epochs=10)\nimputed_cry = imputer_cry.predict(df_test_cry)\n\nimputer_des.fit(train_df=df_train_des, num_epochs=10)\nimputed_des = imputer_des.predict(df_test_des)\n\nimputer_VIP.fit(train_df=df_train_VIP, num_epochs=10)\nimputed_VIP = imputer_VIP.predict(df_test_VIP)\n\nimputer_cba.fit(train_df=df_train_cba, num_epochs=10)\nimputed_cba = imputer_cba.predict(df_test_cba)\n\nimputer_cbc.fit(train_df=df_train_cbc, num_epochs=10)\nimputed_cbc = imputer_cbc.predict(df_test_cbc)\n\ndisplay(imputed_hpl)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:27:51.512306Z","iopub.execute_input":"2022-06-24T17:27:51.512892Z","iopub.status.idle":"2022-06-24T17:37:04.120952Z","shell.execute_reply.started":"2022-06-24T17:27:51.512843Z","shell.execute_reply":"2022-06-24T17:37:04.118671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(imputed_cry['CryoSleep_imputed_proba'].mean())\nprint(imputed_des['Destination_imputed_proba'].mean())\nprint(imputed_VIP['VIP_imputed_proba'].mean())\nprint(imputed_cba['Cabin Section A_imputed_proba'].mean())\nprint(imputed_cbc['Cabin Section C_imputed_proba'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T18:01:50.079413Z","iopub.execute_input":"2022-06-24T18:01:50.080427Z","iopub.status.idle":"2022-06-24T18:01:50.090085Z","shell.execute_reply.started":"2022-06-24T18:01:50.080379Z","shell.execute_reply":"2022-06-24T18:01:50.088625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x,y in zip(imputed_hpl['HomePlanet_imputed'].index, imputed_hpl['HomePlanet_imputed']):\n    to_train.at[x,'HomePlanet'] = y\n    \nfor x,y in zip(imputed_cry['CryoSleep_imputed'].index, imputed_cry['CryoSleep_imputed']):\n    to_train.at[x,'CryoSleep'] = y\n    \nfor x,y in zip(imputed_des['Destination_imputed'].index, imputed_des['Destination_imputed']):\n    to_train.at[x,'Destination'] = y\n    \nfor x,y in zip(imputed_VIP['VIP_imputed'].index, imputed_VIP['VIP_imputed']):\n    to_train.at[x,'VIP'] = y\n    \nfor x,y in zip(imputed_cba['Cabin Section A_imputed'].index, imputed_cba['Cabin Section A_imputed']):\n    to_train.at[x,'Cabin Section A'] = y\n    \nfor x,y in zip(imputed_cbc['Cabin Section C_imputed'].index, imputed_cbc['Cabin Section C_imputed']):\n    to_train.at[x,'Cabin Section C'] = y\n    \nto_train['RoomService'] = to_train['RoomService'].fillna(0)\nto_train['FoodCourt'] = to_train['FoodCourt'].fillna(0)\nto_train['ShoppingMall'] = to_train['ShoppingMall'].fillna(0)\nto_train['Spa'] = to_train['Spa'].fillna(0)\nto_train['VRDeck'] = to_train['VRDeck'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:40:02.07655Z","iopub.execute_input":"2022-06-24T17:40:02.077081Z","iopub.status.idle":"2022-06-24T17:40:02.121788Z","shell.execute_reply.started":"2022-06-24T17:40:02.077042Z","shell.execute_reply":"2022-06-24T17:40:02.120705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Processing for ML.","metadata":{}},{"cell_type":"code","source":"to_train['VIP'] = to_train['VIP'].astype('category').cat.codes\nto_train['HomePlanet'] = to_train['HomePlanet'].astype('category').cat.codes\nto_train['CryoSleep'] = to_train['CryoSleep'].astype('category').cat.codes\nto_train['Destination'] = to_train['Destination'].astype('category').cat.codes\nto_train['Cabin Section A'] = to_train['Cabin Section A'].astype('category').cat.codes\nto_train['Cabin Section C'] = to_train['Cabin Section C'].astype('category').cat.codes\nto_train['Passenger Sub ID'] = to_train['Passenger Sub ID'].astype('category').cat.codes\nto_train['Passenger Group ID'] = to_train['Passenger Group ID'].astype('category').cat.codes\nto_train['Cabin Section B'] = to_train['Cabin Section B'].astype('int')\nto_train['Family'] = to_train['Family'].astype('category').cat.codes\n\nto_train = to_train.drop('PassengerId', axis=1)\nto_train['Total Spent'] = to_train['RoomService'] + to_train['FoodCourt'] + to_train['ShoppingMall'] + to_train['Spa'] + to_train['VRDeck']\nto_train['Essentials Spend'] = to_train['FoodCourt'] + to_train['ShoppingMall']\nto_train['Luxuries Spend'] = to_train['Spa'] + to_train['VRDeck'] + to_train['RoomService']","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:40:12.176032Z","iopub.execute_input":"2022-06-24T17:40:12.176532Z","iopub.status.idle":"2022-06-24T17:40:12.242943Z","shell.execute_reply.started":"2022-06-24T17:40:12.176497Z","shell.execute_reply":"2022-06-24T17:40:12.241532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just a little more feature engineering...","metadata":{}},{"cell_type":"code","source":"Group_Size = []\ngroups = to_train['Passenger Group ID'].unique()\ngrouped_df = to_train.groupby('Passenger Group ID')\n\nfor g in groups:\n    Group_Size = len(grouped_df.get_group(g))\n\ngroup_size = pd.DataFrame()\ngroup_size['Passenger Group ID'] = groups\ngroup_size['Group Size'] = Group_Size\n\nto_train = pd.merge(to_train, group_size, on='Passenger Group ID', how='inner')","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:40:16.340075Z","iopub.execute_input":"2022-06-24T17:40:16.341268Z","iopub.status.idle":"2022-06-24T17:40:18.242482Z","shell.execute_reply.started":"2022-06-24T17:40:16.341201Z","shell.execute_reply":"2022-06-24T17:40:18.241228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scaling the df.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaled_features = StandardScaler().fit_transform(to_train.values)\nscaled_df_train = pd.DataFrame(scaled_features, index=to_train.index, columns=to_train.columns)\n\ndf['Transported'] = df['Transported'].astype('category').cat.codes\ntraining_setup = pd.concat([scaled_df_train[:8693], df['Transported']], axis=1)\ndisplay(training_setup)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:40:22.382082Z","iopub.execute_input":"2022-06-24T17:40:22.382504Z","iopub.status.idle":"2022-06-24T17:40:22.438113Z","shell.execute_reply.started":"2022-06-24T17:40:22.38247Z","shell.execute_reply":"2022-06-24T17:40:22.437317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall pandas -y\n!pip install pandas\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:40:27.784637Z","iopub.execute_input":"2022-06-24T17:40:27.785044Z","iopub.status.idle":"2022-06-24T17:40:55.349691Z","shell.execute_reply.started":"2022-06-24T17:40:27.785011Z","shell.execute_reply":"2022-06-24T17:40:55.348095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fitting the CatBoostClassifier and creating a CSV from the predictions of the test data .","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom catboost import CatBoostClassifier\n\ncb = CatBoostClassifier(iterations=100000,eval_metric='Accuracy',verbose=5000).fit(training_setup.drop('Transported', axis=1), training_setup['Transported'])\ncb_preds = np.array(cb.predict(scaled_df_train[8693:]))\nto_sub = [True if int(x)==1 else False for x in cb_preds]\n\nsubmision = pd.DataFrame(data={'PassengerId':test['PassengerId'], 'Transported':to_sub})\n\n\nprint(submision)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T17:40:58.295987Z","iopub.execute_input":"2022-06-24T17:40:58.296464Z","iopub.status.idle":"2022-06-24T17:48:53.212798Z","shell.execute_reply.started":"2022-06-24T17:40:58.296425Z","shell.execute_reply":"2022-06-24T17:48:53.211554Z"},"trusted":true},"execution_count":null,"outputs":[]}]}