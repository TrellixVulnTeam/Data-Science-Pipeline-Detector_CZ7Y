{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\nimport copy","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:30.154996Z","iopub.execute_input":"2022-06-20T02:08:30.155404Z","iopub.status.idle":"2022-06-20T02:08:30.162917Z","shell.execute_reply.started":"2022-06-20T02:08:30.155372Z","shell.execute_reply":"2022-06-20T02:08:30.161888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data sets\nX_train_full = pd.read_csv(\"../input/spaceship-titanic/train.csv\", index_col=\"PassengerId\")\nX_test_full = pd.read_csv(\"../input/spaceship-titanic/test.csv\", index_col=\"PassengerId\")\n\nX_train_full.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:30.453278Z","iopub.execute_input":"2022-06-20T02:08:30.453729Z","iopub.status.idle":"2022-06-20T02:08:30.526031Z","shell.execute_reply.started":"2022-06-20T02:08:30.453695Z","shell.execute_reply":"2022-06-20T02:08:30.525128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 1: When in cryo sleep, you will not use any facilities like ShoppingMall, RoomService etc.\n# All missing values will be replaced with 0.0.\n# Assumption 2: If no facilities have been used, CrySleep-NaN will be changed to True.\n# Assumption 3: If food is consumed or roomservice has been used, CryoSleep-NaN will be changed to False\ndef cryosleep(df):\n    df['ShoppingMall'] = np.where((df['ShoppingMall'].isnull()) & (df['CryoSleep'] == True), 0.0, df['ShoppingMall'])\n    df['RoomService'] = np.where((df['RoomService'].isnull()) & (df['CryoSleep'] == True), 0.0, df['RoomService'])\n    df['FoodCourt'] = np.where((df['FoodCourt'].isnull()) & (df['CryoSleep'] == True), 0.0, df['FoodCourt'])\n    df['Spa'] = np.where((df['Spa'].isnull()) & (df['CryoSleep'] == True), 0.0, df['Spa'])\n    df['VRDeck'] = np.where((df['VRDeck'].isnull()) & (df['CryoSleep'] == True), 0.0, df['VRDeck'])\n    df['CryoSleep'] = np.where((df['CryoSleep'].isnull()) & ((df['RoomService'] == 0.0) & (df['FoodCourt'] == 0.0) & (df['ShoppingMall'] == 0.0) & (df['Spa'] == 0.0) & (df['VRDeck'] == 0.0)), True, df['CryoSleep'])\n    df['CryoSleep'] = np.where((df['CryoSleep'].isnull()) & ((df['RoomService'] > 0.0) | (df['FoodCourt'] > 0.0) | (df['ShoppingMall'] > 0.0) | (df['Spa'] > 0.0) | (df['VRDeck'] > 0.0)), False, df['CryoSleep'])\n    mask = X_train_full[X_train_full[\"CryoSleep\"].isnull()]\n    mask = mask.fillna(0.0)\n    return df\n\ncryosleep(X_train_full)\ncryosleep(X_test_full)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:30.672726Z","iopub.execute_input":"2022-06-20T02:08:30.673126Z","iopub.status.idle":"2022-06-20T02:08:30.750811Z","shell.execute_reply.started":"2022-06-20T02:08:30.673095Z","shell.execute_reply":"2022-06-20T02:08:30.749861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change type Boolean to Object and dropping the \"Name\" column\nX_train_full = X_train_full.drop(\"Name\", axis=1)\nX_test_full = X_test_full.drop(\"Name\", axis=1)\n\nX_train_full[\"CryoSleep\"] = X_train_full[\"CryoSleep\"].map({False:\"No\", True:\"Yes\"})\nX_train_full[\"VIP\"] = X_train_full[\"VIP\"].map({False:\"No\", True:\"Yes\"})\nX_test_full[\"CryoSleep\"] = X_test_full[\"CryoSleep\"].map({False:\"No\", True:\"Yes\"})\nX_test_full[\"VIP\"] = X_test_full[\"VIP\"].map({False:\"No\", True:\"Yes\"})\n\nX_train_full.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:30.823378Z","iopub.execute_input":"2022-06-20T02:08:30.824233Z","iopub.status.idle":"2022-06-20T02:08:30.857997Z","shell.execute_reply.started":"2022-06-20T02:08:30.824198Z","shell.execute_reply":"2022-06-20T02:08:30.856665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cabin column is assumed decklevel/cabinno./Portside or Starboard. Cabin no. should not have any relation to the event, however the location might.\n# Below function splits the \"Cabin\" up in 2 new columns --> Deck level & Portside or Starboard\n# Divide NaN over Portside and Starboard 50/50\ndef deck_side(df):\n    np.random.seed(48)\n    df[\"Deck\"] = df[\"Cabin\"].str[0]\n    df[\"Side\"] = df[\"Cabin\"].str[-1]\n    data = np.random.choice(a = list(df[\"Side\"].value_counts().index) ,p  = [0.5,0.5] , size =df[\"Side\"].isnull().sum())\n    fill = pd.DataFrame(index= df.index[df[\"Side\"].isnull()] , data=data , columns =[\"Side\"])\n    df.fillna(fill, inplace=True)\n    df = df.drop(\"Cabin\", axis=1, inplace=True)\n    return df\n\ndeck_side(X_train_full)\ndeck_side(X_test_full)\n\nX_train_full","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:31.014007Z","iopub.execute_input":"2022-06-20T02:08:31.014411Z","iopub.status.idle":"2022-06-20T02:08:31.114284Z","shell.execute_reply.started":"2022-06-20T02:08:31.014372Z","shell.execute_reply":"2022-06-20T02:08:31.112977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_full[X_train_full.isnull().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:31.154167Z","iopub.execute_input":"2022-06-20T02:08:31.154571Z","iopub.status.idle":"2022-06-20T02:08:31.195762Z","shell.execute_reply.started":"2022-06-20T02:08:31.154538Z","shell.execute_reply":"2022-06-20T02:08:31.194573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the rows with unknown label\nX_train_full = X_train_full.dropna(axis=0, subset=[\"Transported\"])\nX = X_train_full.drop(\"Transported\", axis=1)\ny = X_train_full[\"Transported\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:31.313409Z","iopub.execute_input":"2022-06-20T02:08:31.315756Z","iopub.status.idle":"2022-06-20T02:08:31.326931Z","shell.execute_reply.started":"2022-06-20T02:08:31.315718Z","shell.execute_reply":"2022-06-20T02:08:31.32592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create tensor from label\ny = torch.zeros(len(X), dtype=torch.long)\ny[X_train_full.Transported == False] = 0\ny[X_train_full.Transported == True] = 1","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:31.48768Z","iopub.execute_input":"2022-06-20T02:08:31.488245Z","iopub.status.idle":"2022-06-20T02:08:31.562809Z","shell.execute_reply.started":"2022-06-20T02:08:31.488208Z","shell.execute_reply":"2022-06-20T02:08:31.561643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify numerical columns in features/data\ncol_numeric = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n\n# Identify categorical columns based on cardinality below 10\ncategorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and X[cname].dtype == \"object\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:31.672973Z","iopub.execute_input":"2022-06-20T02:08:31.673671Z","iopub.status.idle":"2022-06-20T02:08:31.687269Z","shell.execute_reply.started":"2022-06-20T02:08:31.67362Z","shell.execute_reply":"2022-06-20T02:08:31.686531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine categorical with numerical columns\nmy_cols = col_numeric + categorical_cols\nX = X[my_cols]\nX_test = X_test_full[my_cols]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:31.853028Z","iopub.execute_input":"2022-06-20T02:08:31.853776Z","iopub.status.idle":"2022-06-20T02:08:31.861151Z","shell.execute_reply.started":"2022-06-20T02:08:31.853736Z","shell.execute_reply":"2022-06-20T02:08:31.860467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numerical columns will be scaled and imputed\nnumerical_transformer = Pipeline(steps=[\n    (\"scaler\", MinMaxScaler()),\n    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n])\n\n# Categorical columns will be imputed and dummy encoded.\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\n# Numerical and categorical preprocessing will be combined.\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, col_numeric),\n    ('cat', categorical_transformer, categorical_cols)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.033059Z","iopub.execute_input":"2022-06-20T02:08:32.033814Z","iopub.status.idle":"2022-06-20T02:08:32.041123Z","shell.execute_reply.started":"2022-06-20T02:08:32.033782Z","shell.execute_reply":"2022-06-20T02:08:32.040037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare data\nX = preprocessor.fit_transform(X)\nX_test = preprocessor.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.203071Z","iopub.execute_input":"2022-06-20T02:08:32.20369Z","iopub.status.idle":"2022-06-20T02:08:32.263077Z","shell.execute_reply.started":"2022-06-20T02:08:32.203634Z","shell.execute_reply":"2022-06-20T02:08:32.261926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20, random_state=48)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.574248Z","iopub.execute_input":"2022-06-20T02:08:32.574914Z","iopub.status.idle":"2022-06-20T02:08:32.584818Z","shell.execute_reply.started":"2022-06-20T02:08:32.574868Z","shell.execute_reply":"2022-06-20T02:08:32.583855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert data to tensors\nX_train = torch.tensor(X_train).float()\nX_valid = torch.tensor(X_valid).float()\nX_test = torch.tensor(X_test).float()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.635112Z","iopub.execute_input":"2022-06-20T02:08:32.637366Z","iopub.status.idle":"2022-06-20T02:08:32.645624Z","shell.execute_reply.started":"2022-06-20T02:08:32.637329Z","shell.execute_reply":"2022-06-20T02:08:32.644625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert into datasets\ntrain_data = TensorDataset(X_train,y_train)\nvalid_data = TensorDataset(X_valid, y_valid)\n\n# Translate to DataLoader objects\nbatchsize = 64\ntrain_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)\nvalid_loader = DataLoader(valid_data, batch_size=valid_data.tensors[0].shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.686672Z","iopub.execute_input":"2022-06-20T02:08:32.687065Z","iopub.status.idle":"2022-06-20T02:08:32.694014Z","shell.execute_reply.started":"2022-06-20T02:08:32.687034Z","shell.execute_reply":"2022-06-20T02:08:32.69266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create class for the model\ndef createSpaceTitanicNet():\n    \n    class titanicNet(nn.Module):\n        def __init__(self):\n            super().__init__()\n            \n            ## Input layer\n            self.input = nn.Linear(X_train.shape[1], 300)\n            \n            ## Hidden layer\n            self.fc1 = nn.Linear(300, 600)\n            self.bnorm1 = nn.BatchNorm1d(300)\n            self.fc2 = nn.Linear(600, 600)\n            self.bnorm2 = nn.BatchNorm1d(600)\n            self.fc3 = nn.Linear(600, 200)\n            self.bnorm3 = nn.BatchNorm1d(600)\n            \n            ## Output layer\n            self.output = nn.Linear(200, 2)\n        \n        ## Forward pass\n        def forward(self, x):\n            x = F.relu(self.input(x))\n            x = F.dropout(x, p=0.6)\n            x = self.bnorm1(x)\n            x = F.relu(self.fc1(x))\n            x = F.dropout(x, p=0.5)\n            x = self.bnorm2(x)\n            x = F.relu(self.fc2(x))\n            x = F.dropout(x, p=0.4)\n            x = self.bnorm3(x)\n            x = F.relu(self.fc3(x))\n            x = F.dropout(x, p=0.4)\n            return self.output(x)\n        \n    ## Create the model instance\n    net = titanicNet()\n    \n    ## Loss function\n    lossfun = nn.CrossEntropyLoss()\n    \n    ## Optimizer\n    optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001)\n    \n    return net, lossfun, optimizer","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.786308Z","iopub.execute_input":"2022-06-20T02:08:32.787087Z","iopub.status.idle":"2022-06-20T02:08:32.800337Z","shell.execute_reply.started":"2022-06-20T02:08:32.787046Z","shell.execute_reply":"2022-06-20T02:08:32.79911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to train the model\ndef function2trainTheModel():\n    \n    # Create a dictionary for the best model\n    theBestModel = {\"Accuracy\":0,\"net\":None}\n    \n    # Number of epochs\n    numepochs = 400\n    \n    # Create a new model\n    net, lossfun, optimizer = createSpaceTitanicNet()\n    \n    # Initialise losses\n    losses = torch.zeros(numepochs)\n    trainAcc = []\n    validAcc = []\n    loops = 0\n    \n    # Loop over epochs\n    for epochi in range(numepochs):\n        \n        ## Switch on training mode\n        net.train()\n        \n        ## Loop over training batch data\n        batchAcc = []\n        batchLoss = []\n\n        for X, y in train_loader:\n            \n            ### Forward pass\n            yHat = net(X)\n            loss = lossfun(yHat,y)\n            \n            ### Back propagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            ### Batch Loss\n            batchLoss.append(loss.item())\n            \n            ### Compute Accuracy\n            batchAcc.append(100 * torch.mean((torch.argmax(yHat,axis=1) == y).float()))\n        \n        ## Training accuracy\n        trainAcc.append(np.mean(batchAcc))\n        \n        ## Average losses across batches\n        losses[epochi] = np.mean(batchLoss)\n        \n        ## Test accuracy\n        net.eval()\n        X, y = next(iter(valid_loader))\n        with torch.no_grad():\n            yHat = net(X)\n        \n        ## Test accuracy\n        validAcc.append(100 * torch.mean((torch.argmax(yHat,axis=1) == y).float()))\n        \n        if validAcc[-1] > theBestModel[\"Accuracy\"]:\n            theBestModel[\"Accuracy\"] = validAcc[-1].item()\n            theBestModel[\"net\"] = copy.deepcopy(net.state_dict())\n        \n        ## End of epochs\n        loops += 1\n        print(f\"Epoch [{loops}/{numepochs}]\",end='\\r')\n        \n    # Function output\n    return trainAcc, validAcc, losses, theBestModel","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:32.873056Z","iopub.execute_input":"2022-06-20T02:08:32.873465Z","iopub.status.idle":"2022-06-20T02:08:32.886602Z","shell.execute_reply.started":"2022-06-20T02:08:32.873423Z","shell.execute_reply":"2022-06-20T02:08:32.885657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainAcc, validAcc, losses, theBestModel = function2trainTheModel()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:08:33.044048Z","iopub.execute_input":"2022-06-20T02:08:33.044468Z","iopub.status.idle":"2022-06-20T02:16:29.710286Z","shell.execute_reply.started":"2022-06-20T02:08:33.044436Z","shell.execute_reply":"2022-06-20T02:16:29.709112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize losses and accuracy\nfig, ax = plt.subplots(1,2,figsize=(16,5))\n\nax[0].plot(losses.detach())\nax[0].set_ylabel(\"Loss\")\nax[0].set_xlabel(\"Epoch\")\nax[0].set_title(\"Losses\")\nax[0].grid()\n\nax[1].plot(trainAcc,label=\"Train\")\nax[1].plot(validAcc,label=\"Validation\")\nax[1].set_ylabel(\"Accuracy (%)\")\nax[1].set_xlabel(\"Epoch\")\nax[1].set_ylim([72,85])\nax[1].set_title(f\"Validation Accuracy: {theBestModel['Accuracy']:.2f}\")\nax[1].legend()\nax[1].grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:16:29.711806Z","iopub.execute_input":"2022-06-20T02:16:29.712246Z","iopub.status.idle":"2022-06-20T02:16:30.304293Z","shell.execute_reply.started":"2022-06-20T02:16:29.712208Z","shell.execute_reply":"2022-06-20T02:16:30.303549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-create the best performing model\nbestnet = createSpaceTitanicNet()[0]\nbestnet.load_state_dict(theBestModel[\"net\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:16:30.305428Z","iopub.execute_input":"2022-06-20T02:16:30.305871Z","iopub.status.idle":"2022-06-20T02:16:30.32334Z","shell.execute_reply.started":"2022-06-20T02:16:30.30584Z","shell.execute_reply":"2022-06-20T02:16:30.322646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create predictions on the test data\npreds = bestnet(X_test)\n\npredictions = []\nfor p in preds.detach().numpy():\n    predictions.append(np.argmax(p))","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:16:30.325039Z","iopub.execute_input":"2022-06-20T02:16:30.325486Z","iopub.status.idle":"2022-06-20T02:16:30.45361Z","shell.execute_reply.started":"2022-06-20T02:16:30.325457Z","shell.execute_reply":"2022-06-20T02:16:30.452514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create output submission file\noutput = pd.DataFrame({'PassengerId': X_test_full.index,\n                       'Transported': predictions})\noutput[\"Transported\"] = output[\"Transported\"].map({0:False,1:True})","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:16:30.454869Z","iopub.execute_input":"2022-06-20T02:16:30.45526Z","iopub.status.idle":"2022-06-20T02:16:30.468135Z","shell.execute_reply.started":"2022-06-20T02:16:30.455229Z","shell.execute_reply":"2022-06-20T02:16:30.467057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:16:30.469699Z","iopub.execute_input":"2022-06-20T02:16:30.470433Z","iopub.status.idle":"2022-06-20T02:16:30.482885Z","shell.execute_reply.started":"2022-06-20T02:16:30.47037Z","shell.execute_reply":"2022-06-20T02:16:30.481855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T02:16:30.48455Z","iopub.execute_input":"2022-06-20T02:16:30.485821Z","iopub.status.idle":"2022-06-20T02:16:30.504079Z","shell.execute_reply.started":"2022-06-20T02:16:30.485722Z","shell.execute_reply":"2022-06-20T02:16:30.50304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}