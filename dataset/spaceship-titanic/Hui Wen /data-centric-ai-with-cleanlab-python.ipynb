{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spaceship Titanic Cleanlab Tutorial \n\nThis notebook improves the XGBoost model from this [EDA + XGBoost notebook](https://www.kaggle.com/code/meetnagadia/titanic-spaceship-eda-xgboost-0-75-score) using the [cleanlab](https://github.com/cleanlab/cleanlab/) data cleaning library. \n\n`cleanlab` improves any model by automatically removing datapoints with label errors from the model's training set. With less than 5 extra lines of code, we can obtain a **4% reduction in error** without changing the model at all.\n\n| Model      | Public Score |\n| ----------- | ----------- |\n| XGBoost      | 0.7587       |\n| XGBoost + `cleanlab`   | 0.76782         |","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Loading Libraries and Data Preprocessing\n\nThe data preprocessing steps are identical to those in the [original notebook](https://www.kaggle.com/code/meetnagadia/titanic-spaceship-eda-xgboost-0-75-score).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nimport xgboost as xgb\nimport warnings\nwarnings.simplefilter('ignore')\n\nSEED = 123  # for reproducibility\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\ntrain_df =pd.read_csv(\"../input/spaceship-titanic/train.csv\") \ntest_df = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\n\nimputer_cols = [\"Age\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\" ,\"RoomService\"]\nimputer = SimpleImputer(strategy=\"median\")\nimputer.fit(train_df[imputer_cols])\ntrain_df[imputer_cols] = imputer.transform(train_df[imputer_cols])\ntest_df[imputer_cols] = imputer.transform(test_df[imputer_cols])\ntrain_df[\"HomePlanet\"].fillna('Z', inplace=True)\ntest_df[\"HomePlanet\"].fillna('Z', inplace=True)\n\nlabel_cols = [\"HomePlanet\", \"CryoSleep\",\"Cabin\", \"Destination\" ,\"VIP\"]\ndef label_encoder(train,test,columns):\n    for col in columns:\n        train[col] = train[col].astype(str)\n        test[col] = test[col].astype(str)\n        train[col] = LabelEncoder().fit_transform(train[col])\n        test[col] =  LabelEncoder().fit_transform(test[col])\n    return train, test\n\ntrain_df ,test_df = label_encoder(train_df,test_df ,label_cols)\n\np_id = test_df[\"PassengerId\"]\n\ny_train = train_df[\"Transported\"]\nX_train = train_df.drop([\"Transported\",\"Name\", \"PassengerId\"], axis =1)\nX_test = test_df.drop([\"Name\", \"PassengerId\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:57:12.949807Z","iopub.execute_input":"2022-06-21T20:57:12.95076Z","iopub.status.idle":"2022-06-21T20:57:13.662273Z","shell.execute_reply.started":"2022-06-21T20:57:12.950675Z","shell.execute_reply":"2022-06-21T20:57:13.66104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training\n\nFirst a regular XGBoost model is trained (as demonstrated in the [original notebook](https://www.kaggle.com/code/meetnagadia/titanic-spaceship-eda-xgboost-0-75-score)). Then we add `cleanlab` to see how much it improves the performance of the base XGBoost model.","metadata":{}},{"cell_type":"markdown","source":"### XGBoost [0.7587]","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:32:22.064809Z","iopub.execute_input":"2022-06-21T20:32:22.065308Z","iopub.status.idle":"2022-06-21T20:32:22.070485Z","shell.execute_reply.started":"2022-06-21T20:32:22.065264Z","shell.execute_reply":"2022-06-21T20:32:22.069269Z"}}},{"cell_type":"code","source":"# Training regular XGBoost\n\nxgb_base = xgb.XGBClassifier(eval_metric='error')\nxgb_base.fit(X_train, y_train)\n\ny_pred_base = xgb_base.predict(X_test)  # base model predictions for test data","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:59:53.5177Z","iopub.execute_input":"2022-06-21T20:59:53.518108Z","iopub.status.idle":"2022-06-21T20:59:55.72281Z","shell.execute_reply.started":"2022-06-21T20:59:53.51808Z","shell.execute_reply":"2022-06-21T20:59:55.721647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Estimating performance of base XGB model via cross-validation\n\ncv_results = cross_validate(xgb_base, X_train, y_train)\nprint(f\"Mean accuracy using 5-fold cv: {np.mean(cv_results['test_score'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:57:15.454286Z","iopub.execute_input":"2022-06-21T20:57:15.45727Z","iopub.status.idle":"2022-06-21T20:57:18.879076Z","shell.execute_reply.started":"2022-06-21T20:57:15.457212Z","shell.execute_reply":"2022-06-21T20:57:18.877795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost + `cleanlab` [0.76782]","metadata":{}},{"cell_type":"code","source":"# install + import cleanlab library\n# make sure internet is toggled on (Settings > Internet)\n\n!pip install cleanlab\nfrom cleanlab.classification import CleanLearning","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:57:18.886713Z","iopub.execute_input":"2022-06-21T20:57:18.887727Z","iopub.status.idle":"2022-06-21T20:57:29.702882Z","shell.execute_reply.started":"2022-06-21T20:57:18.887675Z","shell.execute_reply":"2022-06-21T20:57:29.701579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training improved XGBoost model with cleanlab\n\nxgb_base = xgb.XGBClassifier(eval_metric='error')\ncl = CleanLearning(clf=xgb_base, verbose=True)\ncl.fit(X_train.values, y_train.values)\n\ny_pred_cl = cl.predict(X_test.values)  # cleanlab-improved model predictions for test data","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:59:00.512088Z","iopub.execute_input":"2022-06-21T20:59:00.512738Z","iopub.status.idle":"2022-06-21T20:59:08.905603Z","shell.execute_reply.started":"2022-06-21T20:59:00.512701Z","shell.execute_reply":"2022-06-21T20:59:08.904518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Estimating performance of XGB model with cleanlab via cross-validation\n\ncv_results = cross_validate(CleanLearning(clf=xgb_base), X_train.values, y_train.values);\nprint(f\"Mean accuracy using 5-fold cv: {np.mean(cv_results['test_score'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:57:34.551738Z","iopub.execute_input":"2022-06-21T20:57:34.554747Z","iopub.status.idle":"2022-06-21T20:57:59.420394Z","shell.execute_reply.started":"2022-06-21T20:57:34.554695Z","shell.execute_reply":"2022-06-21T20:57:59.419198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n\nLoading the predictions into a format ready for submission. \n\n**Note that you can switch between `submission_base` and `submission_cl` to compare the results of adding cleanlab.**\n","metadata":{}},{"cell_type":"code","source":"submission_base = pd.DataFrame(\n    {'PassengerId': p_id,\n     'Transported': y_pred_base.astype(bool)},columns=['PassengerId', 'Transported'])\n\nsubmission_base.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:00:18.343252Z","iopub.execute_input":"2022-06-21T21:00:18.34364Z","iopub.status.idle":"2022-06-21T21:00:18.35735Z","shell.execute_reply.started":"2022-06-21T21:00:18.343607Z","shell.execute_reply":"2022-06-21T21:00:18.356105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_cl = pd.DataFrame(\n    {'PassengerId': p_id,\n     'Transported': y_pred_cl.astype(bool)},columns=['PassengerId', 'Transported'])\n\nsubmission_cl.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:00:16.23232Z","iopub.execute_input":"2022-06-21T21:00:16.232708Z","iopub.status.idle":"2022-06-21T21:00:16.247045Z","shell.execute_reply.started":"2022-06-21T21:00:16.232676Z","shell.execute_reply":"2022-06-21T21:00:16.244644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# switch between the two submission files here\n\nsubmission_cl.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T20:57:59.467618Z","iopub.execute_input":"2022-06-21T20:57:59.467988Z","iopub.status.idle":"2022-06-21T20:57:59.489306Z","shell.execute_reply.started":"2022-06-21T20:57:59.467957Z","shell.execute_reply":"2022-06-21T20:57:59.488341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Notes\n\nThe above XGBoost + `cleanlab` model was trained with default XGBoost hyperparameters. The `cleanlab` parameters can also be tuned to further improve overall performance.\n\nWhile this notebook used an XGBoost model, `cleanlab` can be used with any classifier. Feel free to experiment this with other models and let me know if you see an improvement!","metadata":{}}]}