{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train = pd.read_csv(r'train.csv')\nDf_test = pd.read_csv(r'test.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_test.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_test['Planet_Code'] = pd.factorize(Df_test.HomePlanet)[0]\nDf_test['Planet_Code']=Df_test.Planet_Code.replace(-1,Df_test['Planet_Code'].median())\n\nDf_test['CryoSleep_Code']=pd.factorize(Df_test.CryoSleep)[0]\nDf_test['Cabin_Code'] = pd.factorize(Df_test.Cabin)[0]\nDf_test['Destination_Code'] = pd.factorize(Df_test.Destination)[0]\nDf_test['VIP_Code'] = pd.factorize(Df_test.VIP)[0]\n\nDf_test['CryoSleep_Code']= Df_test.CryoSleep_Code.replace(-1,Df_test['CryoSleep_Code'].median())\nDf_test['Cabin_Code'] = Df_test.Cabin_Code.replace(-1,Df_test['Cabin_Code'].median())\nDf_test['Destination_Code'] = Df_test.Destination_Code.replace(-1,Df_test['Destination_Code'].median())\nDf_test['VIP_Code'] = Df_test.VIP_Code.replace(-1,Df_test['VIP_Code'].median())\n\nDf_test['Age'] = Df_test['Age'].fillna(Df_test['Age'].median())\nDf_test['RoomService']=Df_test['RoomService'].fillna(Df_test['RoomService'].median())\nDf_test['FoodCourt'] = Df_test['FoodCourt'].fillna(Df_test['FoodCourt'].median())\nDf_test['ShoppingMall']= Df_test['ShoppingMall'].fillna(Df_test['ShoppingMall'].median())\nDf_test['Spa'] = Df_test['Spa'].fillna(Df_test['Spa'].median())\nDf_test['VRDeck']= Df_test['VRDeck'].fillna(Df_test['VRDeck'].median())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_test.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = Df_test[['PassengerId','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','Planet_Code','CryoSleep_Code','Cabin_Code','Destination_Code','VIP_Code']]\ndf_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Age.median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.HomePlanet.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.CryoSleep.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Cabin.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Destination.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Age.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.VIP.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.RoomService.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.FoodCourt.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.ShoppingMall.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Spa.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.VRDeck.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Name.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.Transported.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['Planet_Code'] = pd.factorize(Df_train.HomePlanet)[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['Planet_Code']=Df_train.Planet_Code.replace(-1,Df_train['Planet_Code'].median())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['Planet_Code'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['CryoSleep_Code']=pd.factorize(Df_train.CryoSleep)[0]\nDf_train['Cabin_Code'] = pd.factorize(Df_train.Cabin)[0]\nDf_train['Destination_Code'] = pd.factorize(Df_train.Destination)[0]\nDf_train['VIP_Code'] = pd.factorize(Df_train.VIP)[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['CryoSleep_Code']= Df_train.CryoSleep_Code.replace(-1,Df_train['CryoSleep_Code'].median())\nDf_train['Cabin_Code'] = Df_train.Cabin_Code.replace(-1,Df_train['Cabin_Code'].median())\nDf_train['Destination_Code'] = Df_train.Destination_Code.replace(-1,Df_train['Destination_Code'].median())\nDf_train['VIP_Code'] = Df_train.VIP_Code.replace(-1,Df_train['VIP_Code'].median())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['Age'] = Df_train['Age'].fillna(Df_train['Age'].median())\nDf_train['RoomService']=Df_train['RoomService'].fillna(Df_train['RoomService'].median())\nDf_train['FoodCourt'] = Df_train['FoodCourt'].fillna(Df_train['FoodCourt'].median())\nDf_train['ShoppingMall']= Df_train['ShoppingMall'].fillna(Df_train['ShoppingMall'].median())\nDf_train['Spa'] = Df_train['Spa'].fillna(Df_train['Spa'].median())\nDf_train['VRDeck']= Df_train['VRDeck'].fillna(Df_train['VRDeck'].median())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train['Age'].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Df_train.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = Df_train[['PassengerId','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','Planet_Code','CryoSleep_Code','Cabin_Code','Destination_Code','VIP_Code','Transported']]\ndf_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split #for split the data\nfrom sklearn.metrics import accuracy_score  #for accuracy_score\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.metrics import confusion_matrix #for confusion matrix\nall_features = df_train.drop(\"Transported\",axis=1)\nTargeted_feature = df_train[\"Transported\"]\nX_train,X_test,y_train,y_test = train_test_split(all_features,Targeted_feature,test_size=0.3,random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression # Logistic Regression\n\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\nprediction_lr=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the Logistic Regression is',round(accuracy_score(prediction_lr,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_lr=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for Logistic REgression is:',round(result_lr.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"# Random Forests\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(criterion='gini', n_estimators=700,\n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto',oob_score=True,\n                             random_state=1,n_jobs=-1)\nmodel.fit(X_train,y_train)\nprediction_rm=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the Random Forest Classifier is',round(accuracy_score(prediction_rm,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_rm=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for Random Forest Classifier is:',round(result_rm.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM","metadata":{}},{"cell_type":"code","source":"# Support Vector Machines\nfrom sklearn.svm import SVC, LinearSVC\n\nmodel = SVC()\nmodel.fit(X_train,y_train)\nprediction_svm=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the Support Vector Machines Classifier is',round(accuracy_score(prediction_svm,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_svm=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for Support Vector Machines Classifier is:',round(result_svm.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\nmodel = KNeighborsClassifier(n_neighbors = 4)\nmodel.fit(X_train,y_train)\nprediction_knn=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the K Nearst Neighbors Classifier is',round(accuracy_score(prediction_knn,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_knn=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for K Nearest Neighbors Classifier is:',round(result_knn.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nmodel= GaussianNB()\nmodel.fit(X_train,y_train)\nprediction_gnb=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the Gaussian Naive Bayes Classifier is',round(accuracy_score(prediction_gnb,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_gnb=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for Gaussian Naive Bayes classifier is:',round(result_gnb.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"code","source":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nmodel= DecisionTreeClassifier(criterion='gini', \n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto')\nmodel.fit(X_train,y_train)\nprediction_tree=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the DecisionTree Classifier is',round(accuracy_score(prediction_tree,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_tree=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for Decision Tree classifier is:',round(result_tree.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ada Boost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel= AdaBoostClassifier()\nmodel.fit(X_train,y_train)\nprediction_adb=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the AdaBoostClassifier is',round(accuracy_score(prediction_adb,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_adb=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for AdaBoostClassifier is:',round(result_adb.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Discriminant Analysis","metadata":{}},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nmodel= LinearDiscriminantAnalysis()\nmodel.fit(X_train,y_train)\nprediction_lda=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the LinearDiscriminantAnalysis is',round(accuracy_score(prediction_lda,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_lda=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for AdaBoostClassifier is:',round(result_lda.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmodel= GradientBoostingClassifier()\nmodel.fit(X_train,y_train)\nprediction_gbc=model.predict(X_test)\nprint('--------------The Accuracy of the model----------------------------')\nprint('The accuracy of the Gradient Boosting Classifier is',round(accuracy_score(prediction_gbc,y_test)*100,2))\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nresult_gbc=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\nprint('The cross validated score for AdaBoostClassifier is:',round(result_gbc.mean()*100,2))\ny_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)\nsns.heatmap(confusion_matrix(Targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = df_train.drop(\"Transported\", axis=1)\ntrain_Y=df_train[\"Transported\"]\ntest_X  = df_test.copy()\ntrain_X.shape, train_Y.shape, test_X.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gradient boosting tunning\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\nmodel = GradientBoostingClassifier()\nparam_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300,400],\n              'learning_rate': [0.1, 0.05, 0.01,0.001],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.2,0.1] \n              }\n\nmodelf = GridSearchCV(model,param_grid = param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodelf.fit(train_X,train_Y)\n\n# Best score\nmodelf.best_score_\n\n# Best Estimator\nmodelf.best_estimator_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nGBC = GradientBoostingClassifier(learning_rate=0.05, max_depth=8, max_features=0.1,\n                           min_samples_leaf=150, n_estimators=200)\nGBC.fit(train_X, train_Y)\nY_pred_rf = GBC.predict(test_X)\nGBC.score(train_X,train_Y)\nacc_GBC = round(GBC.score(train_X, train_Y) * 100, 2)\n\nprint(\"Important features\")\npd.Series(GBC.feature_importances_,train_X.columns).sort_values(ascending=True).plot.barh(width=0.8)\nprint('__'*30)\nprint(acc_GBC)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": Y_pred_rf})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(r'Submission.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}