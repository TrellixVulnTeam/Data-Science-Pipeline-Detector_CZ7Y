{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">INTRODUCTION</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"<p>It is the year 2912. We've received a transmission from four lightyears away and things aren't looking good.</p>\n    \n    \n<p>The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n\nWhile rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n\nTo help rescue crews and retrieve the lost passengers, We predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.</h4>","metadata":{}},{"cell_type":"markdown","source":"<center><img src= \"https://as2.ftcdn.net/v2/jpg/02/24/24/23/1000_F_224242336_f7ekk6EoCmz5061Si58wEWUqizXAEUJk.jpg\" alt =\"Titanic\" style='width: 800px;'></center>","metadata":{}},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">IMPORT PACKAGES</span></center></h1>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-16T20:31:37.67258Z","iopub.execute_input":"2022-05-16T20:31:37.672853Z","iopub.status.idle":"2022-05-16T20:31:40.344879Z","shell.execute_reply.started":"2022-05-16T20:31:37.672822Z","shell.execute_reply":"2022-05-16T20:31:40.343801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">LOAD DATASET</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"*We read the two data files to the kaggle environment*","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/spaceship-titanic/test.csv\")\ntrain = pd.read_csv(\"../input/spaceship-titanic/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.346896Z","iopub.execute_input":"2022-05-16T20:31:40.347213Z","iopub.status.idle":"2022-05-16T20:31:40.455755Z","shell.execute_reply.started":"2022-05-16T20:31:40.347178Z","shell.execute_reply":"2022-05-16T20:31:40.454751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">EXPLORING AND PREPARING THE DATASET</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Explore the datatypes of all the features</span></h3>","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.457325Z","iopub.execute_input":"2022-05-16T20:31:40.457576Z","iopub.status.idle":"2022-05-16T20:31:40.469951Z","shell.execute_reply.started":"2022-05-16T20:31:40.457524Z","shell.execute_reply":"2022-05-16T20:31:40.469296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The features in the dataset are not uniform and need to be converted to make the features more usable. Categorical features need to be label encoded, Age Variable needs to be binned and categorised so as to make our analytics easier.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Basic statistics about the Test and Train Data</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Finding the Statistical information about all the Numeric features of the dataset. Statistical knowledge can be critical for identifying skewness and outliers in the dataset.*","metadata":{}},{"cell_type":"code","source":"print(\"Test statistics: \\n\", test.describe())\nprint(\"\\n\")\nprint(\"Train statistics: \\n\", train.describe())","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.47177Z","iopub.execute_input":"2022-05-16T20:31:40.472559Z","iopub.status.idle":"2022-05-16T20:31:40.547046Z","shell.execute_reply.started":"2022-05-16T20:31:40.472459Z","shell.execute_reply":"2022-05-16T20:31:40.546034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Explore Missingness in Data</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Missing Values in the data need to be delt with before performing Analysis. If this step is missed, the predictions could be less reliable and might have biases. The various missing values imputation methods are discussed later in this notebook.*","metadata":{}},{"cell_type":"code","source":"missing_test = pd.DataFrame(test.isna().sum())\nmissing_test.sort_values(by=0, ascending=False)\n\nmissing_train = pd.DataFrame(train.isna().sum())\nmissing_train.sort_values(by=0, ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.548741Z","iopub.execute_input":"2022-05-16T20:31:40.549016Z","iopub.status.idle":"2022-05-16T20:31:40.582167Z","shell.execute_reply.started":"2022-05-16T20:31:40.548981Z","shell.execute_reply":"2022-05-16T20:31:40.581123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(go.Bar(y=missing_train[0], x=missing_train.index,\n                    marker=dict(color=[n for n in range(14)], \n                                coloraxis=\"coloraxis\")),\n              1, 1)\n\nfig.add_trace(go.Bar(y=missing_test[0], x=missing_test.index,\n                    marker=dict(color=[n for n in range(14)], \n                                coloraxis=\"coloraxis\")),\n              1, 2)\n\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'), showlegend=False, title_text=\"Features' Null Value Distribution in Train and Test Data\", title_x=0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.584442Z","iopub.execute_input":"2022-05-16T20:31:40.584793Z","iopub.status.idle":"2022-05-16T20:31:40.863888Z","shell.execute_reply.started":"2022-05-16T20:31:40.58475Z","shell.execute_reply":"2022-05-16T20:31:40.862832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*On plotting the missing values we can see that the Feature, \"PassengerId\", and \"Transported\" in the train data have no missing values, whereas \"CryoSleep\" has the most no of missing values.*\n\n*Similarly, in the test dataset, \"PassengerId has no missing values, and we also notice that there is no \"Transported\" feature in the test dataset. \"FoodCourt\" spends has the most no of missing data in this dataset.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Handle Missing Values In The Dataset, And Prepare It For Modelling</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*The First step in dealing with missing values is to generalise all the missing values and give them a standard notation. Here, we replace All Missing Values With NaN.*","metadata":{}},{"cell_type":"code","source":"train = train.replace(['', ' '], np.NaN)\ntest = test.replace(['', ' '], np.NaN)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.865867Z","iopub.execute_input":"2022-05-16T20:31:40.866159Z","iopub.status.idle":"2022-05-16T20:31:40.90049Z","shell.execute_reply.started":"2022-05-16T20:31:40.866121Z","shell.execute_reply":"2022-05-16T20:31:40.899511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Deal With Missing Values, Using Appropriate Imputations</span></h3>\n\nMISSING DATA IMPUTATION FOR EACH FEATURE:\n\n* 'HomePlanet', The Home Planet is set to the most common planet in HomePlanet feature.\n* 'CryoSleep', CryoSleep is set to False.\n* 'Cabin', Cabin is set as the same from previous record, because cabins are very likely to be same or very similar for families, and they tend to occur in groups.\n* 'Destination', Destination is set to the most frequently occuring Destination in Destination feature.\n* 'Age', is set to average\n* 'VIP', is set to False, because more than 90% of the records are not VIP.\n* 'RoomService', Spend is set to 0.\n* 'FoodCourt', Spend is set to 0.\n* 'ShoppingMall', Spend is set to 0.\n* 'Spa', Spend is set to 0.\n* 'VRDeck', Spend is set to 0.\n* 'Name', is set to Mr. XXXX as the Default value.\n\n","metadata":{}},{"cell_type":"markdown","source":"*On Deciding how to treat missing values in each of the features, we create Imputers. Imputers for this Dataset are of 3 strategies.*\n1. Mean Imputation\n    Here, the mean of the whole feature is calculated and is appended wherever values are missing. This can be performed only on Numerical Features.\n2. Constant Imputation\n    In this type of Imputation, a constant value is imputed in all the missing value indexes. This can be the Default value of the feature or a Boolean Value.\n3. Most Frequent Value Imputation\n    This is one of the most common Imputation method, where the most frequently occuring value is imputed in all the missing value indexes.","metadata":{}},{"cell_type":"code","source":"impmean = SimpleImputer(strategy='mean', missing_values=np.nan)\nimpcomm = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\nimpconst0 = SimpleImputer(strategy='constant', missing_values=np.nan, fill_value=0)\nimpconstf = SimpleImputer(strategy='constant', missing_values=np.nan, fill_value= False)\nimpconstx = SimpleImputer(strategy='constant', missing_values=np.nan, fill_value=\"Mr. XXXX\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.902088Z","iopub.execute_input":"2022-05-16T20:31:40.902461Z","iopub.status.idle":"2022-05-16T20:31:40.910804Z","shell.execute_reply.started":"2022-05-16T20:31:40.902415Z","shell.execute_reply":"2022-05-16T20:31:40.909602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impmean = impmean.fit(train[['Age']])\ntrain[['Age']] = impmean.transform(train[['Age']])\nimpmean = impmean.fit(test[['Age']])\ntest[['Age']] = impmean.transform(test[['Age']])\n\nimpcomm = impcomm.fit(train[['HomePlanet', 'Destination']])\ntrain[['HomePlanet', 'Destination']] = impcomm.transform(train[['HomePlanet', 'Destination']])\nimpcomm = impcomm.fit(test[['HomePlanet', 'Destination']])\ntest[['HomePlanet', 'Destination']] = impcomm.transform(test[['HomePlanet', 'Destination']])\n\n\nimpconstf = impconstf.fit(train[['CryoSleep', 'VIP']])\ntrain[['CryoSleep', 'VIP']] = impconstf.transform(train[['CryoSleep', 'VIP']])\nimpconstf = impconstf.fit(test[['CryoSleep', 'VIP']])\ntest[['CryoSleep', 'VIP']] = impconstf.transform(test[['CryoSleep', 'VIP']])\n\nimpconst0 = impconst0.fit(train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']])\ntrain[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = impconst0.transform(train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']])\nimpconst0 = impconst0.fit(test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']])\ntest[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = impconst0.transform(test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']])\n\n\nimpconstx = impconstx.fit(train[['Name']])\ntrain[['Name']] = impconstx.transform(train[['Name']])\nimpconstx = impconstx.fit(test[['Name']])\ntest[['Name']] = impconstx.transform(test[['Name']])\n\ntrain[['Cabin']] = train[['Cabin']].fillna(method='ffill')\ntest[['Cabin']] = test[['Cabin']].fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.912306Z","iopub.execute_input":"2022-05-16T20:31:40.913393Z","iopub.status.idle":"2022-05-16T20:31:40.990074Z","shell.execute_reply.started":"2022-05-16T20:31:40.913347Z","shell.execute_reply":"2022-05-16T20:31:40.989305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">EXPLORATORY DATA ANALYTICS</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Check Feature Correlation</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Feature Correlation is done to identify the extent of correlation between the features in dataset. It is very important to get rid of Features that are correlated because if the variables are correlated, they result to bias while making predictions, and also leads to the model getting overfit in some cases.*","metadata":{}},{"cell_type":"code","source":"corr1 = train.corr(method=\"pearson\")\n\nfig, ax =plt.subplots(1,2, figsize=(15,6))\nc1 = sns.heatmap(corr1, annot=True, linewidths=.5, ax=ax[0])\nc1.set_title('Train Features Correlation')\n\ncorr2 = test.corr(method=\"pearson\")\nc2 = sns.heatmap(corr2, annot=True, linewidths=.5, ax=ax[1])\nc2.set_title('Test Features Correlation')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:40.992983Z","iopub.execute_input":"2022-05-16T20:31:40.993311Z","iopub.status.idle":"2022-05-16T20:31:42.251996Z","shell.execute_reply.started":"2022-05-16T20:31:40.993276Z","shell.execute_reply":"2022-05-16T20:31:42.250793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*On finding the correlations between the features of the dataset, we see that there is no string correlation between any of the features of the dataset. But it is clear that there is a small correlation between the different spends('RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'). There is also a small correlation between the spends and the fact of being Transported.*\n\n*The highest Negative correlation for Train dataset was between 'RoomService' and 'Transported', where as the highest positive correlation is between 'Spa'-'FoodCourt', and 'VRDeck'-'FoodCourt'.*\n\n*The highest correlation in the test data is between 'FoodCourt'-'VRDeck'. The most negative correlation is between 'VRDeck'-'RoomService'*","metadata":{}},{"cell_type":"code","source":"bins = [0, 12, 18, 32, 60, 120]\n\nlabels = [\"Child\", \"Teen\" , \"Young Adult\", \"Adult\", \"Old\"]\ntrain['Age_Cat'] = pd.cut(train['Age'], bins = bins, labels=labels)\ntest['Age_Cat'] = pd.cut(test['Age'], bins = bins, labels=labels)\n\ntrain.drop(columns=['Age', 'Name', 'Cabin'], inplace=True)\ntest.drop(columns=['Age', 'Name', 'Cabin'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.253929Z","iopub.execute_input":"2022-05-16T20:31:42.254193Z","iopub.status.idle":"2022-05-16T20:31:42.276396Z","shell.execute_reply.started":"2022-05-16T20:31:42.254154Z","shell.execute_reply":"2022-05-16T20:31:42.275664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Since Age is a continuous numerical variable, its hard to perform any analysis on it directly. Hence we categorise the feature by binning. Here, we have categorised age into five categories,*\n1. Child (0-12)years\n2. Teen (12-18)years\n3. Yound Adult (18-32)years\n4. Adult (32-60)years\n5. Old (>60)years\n\n*This enables us to use Age in our Analysis in a better way, helping us perform better data analysis.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Check Age Distribution of Passengers</span></h3>","metadata":{}},{"cell_type":"code","source":"values = train['Age_Cat'].value_counts().values\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])\nfig.update_layout(margin=dict(t=50, b=0, l=0, r=0), title_text=\"Passengers' Age Distribution\", title_x=0.3)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.279713Z","iopub.execute_input":"2022-05-16T20:31:42.280149Z","iopub.status.idle":"2022-05-16T20:31:42.318001Z","shell.execute_reply.started":"2022-05-16T20:31:42.280117Z","shell.execute_reply":"2022-05-16T20:31:42.317209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*From the Donut Chart we can see that 77.6% of the passengers in the spaceship are aged below 18 years of age, And There are only 2.58% of passengers aged above 60 years. This can probably explain the high spends on('RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck').*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Check Age Distribution of VIP Passengers</span></h3>","metadata":{}},{"cell_type":"code","source":"vip_train = train[train['VIP'] == True]\n\nvalues = vip_train['Age_Cat'].value_counts().values\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])\nfig.update_layout(margin=dict(t=40, b=0, l=0, r=0), title_text=\"VIP Passengers' Age Distribution\", title_x=0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.31963Z","iopub.execute_input":"2022-05-16T20:31:42.320166Z","iopub.status.idle":"2022-05-16T20:31:42.341555Z","shell.execute_reply.started":"2022-05-16T20:31:42.320122Z","shell.execute_reply":"2022-05-16T20:31:42.340726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*It is evident from the chart above that 95% of the VIPs are aged below 18 years.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Check Spending Levels of VIP vs Normal Passengers</span></h3>","metadata":{}},{"cell_type":"code","source":"rs_t_val = train['RoomService'].sum()/train.shape[0]\nrs_v_val = vip_train['RoomService'].sum()/vip_train.shape[0]\n\nfc_t_val = train['FoodCourt'].sum()/train.shape[0]\nfc_v_val = vip_train['FoodCourt'].sum()/vip_train.shape[0]\n\nsm_t_val = train['ShoppingMall'].sum()/train.shape[0]\nsm_v_val = vip_train['ShoppingMall'].sum()/vip_train.shape[0]\n\ns_t_val = train['Spa'].sum()/train.shape[0]\ns_v_val = vip_train['Spa'].sum()/vip_train.shape[0]\n\nvr_t_val = train['VRDeck'].sum()/train.shape[0]\nvr_v_val = vip_train['VRDeck'].sum()/vip_train.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.342583Z","iopub.execute_input":"2022-05-16T20:31:42.343198Z","iopub.status.idle":"2022-05-16T20:31:42.35427Z","shell.execute_reply.started":"2022-05-16T20:31:42.343162Z","shell.execute_reply":"2022-05-16T20:31:42.353301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=3, vertical_spacing = 0.1 ,subplot_titles=('Room Service','Food Court', 'Shopping Mall', 'Spa', 'VR Deck'), y_title=\"Average Amount Spent Per Person\")\n\n\nfig.add_trace(go.Bar(y=[rs_t_val, rs_v_val], x=[\"Normal\", \"VIP\"],\n                    marker=dict(color=[4, 7], coloraxis=\"coloraxis\")),\n              1, 1)\n\nfig.add_trace(go.Bar(y=[fc_t_val, fc_v_val], x=[\"Normal\", \"VIP\"],\n                    marker=dict(color=[2, 3, 5], coloraxis=\"coloraxis\")),\n              1, 2)\n\nfig.add_trace(go.Bar(y=[sm_t_val, sm_v_val], x=[\"Normal\", \"VIP\"],\n                    marker=dict(color=[4, 7], coloraxis=\"coloraxis\")),\n              1, 3)\n\nfig.add_trace(go.Bar(y=[s_t_val, s_v_val], x=[\"Normal\", \"VIP\"],\n                    marker=dict(color=[2, 3, 5], coloraxis=\"coloraxis\")),\n              2, 1)\n\nfig.add_trace(go.Bar(y=[vr_t_val, vr_v_val], x=[\"Normal\", \"VIP\"],\n                    marker=dict(color=[4, 7], coloraxis=\"coloraxis\")),\n              2, 2)\n\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'), showlegend=False, height=800, width=900)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.355687Z","iopub.execute_input":"2022-05-16T20:31:42.35601Z","iopub.status.idle":"2022-05-16T20:31:42.471636Z","shell.execute_reply.started":"2022-05-16T20:31:42.355971Z","shell.execute_reply":"2022-05-16T20:31:42.470759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The spends comparisions between the VIPs and Normal Passengers is a very interesting comparision, it can be inferred that the spending amount for shopping is very similar to both the class of passengers. The money spent on VR Deck is very contrary, where VIP passengers spend 1200 on average whereas Normal passengers spend about 300 on average.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Transportation of Normal vs VIP Percentage wise</span></h3>","metadata":{}},{"cell_type":"code","source":"normal_trans = train.loc[(train['VIP'] == False) & (train['Transported'] == True)].shape[0]\nnormal_ntrans = train.loc[(train['VIP'] == False) & (train['Transported'] == False)].shape[0]\nvip_trans = train.loc[(train['VIP'] == True) & (train['Transported'] == True)].shape[0]\nvip_ntrans = train.loc[(train['VIP'] == True) & (train['Transported'] == False)].shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.472833Z","iopub.execute_input":"2022-05-16T20:31:42.473054Z","iopub.status.idle":"2022-05-16T20:31:42.490278Z","shell.execute_reply.started":"2022-05-16T20:31:42.473018Z","shell.execute_reply":"2022-05-16T20:31:42.489588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2, vertical_spacing = 0.1 ,subplot_titles=('NORMAL CLASS', 'VIP'), y_title=\"Number of Passengers\")\n\nfig.add_trace(go.Bar(y=[normal_trans, normal_ntrans], x=[\"Transported\", \"Not Transported\"],\n                    marker=dict(color=[4, 7], coloraxis=\"coloraxis\")),\n              1, 1)\n\nfig.add_trace(go.Bar(y=[vip_trans, vip_ntrans], x=[\"Transported\", \"Not Transported\"],\n                    marker=dict(color=[2, 3, 5], coloraxis=\"coloraxis\")),\n              1, 2)\n\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'),margin=dict(t=40, b=0, l=0, r=0), showlegend=False, height=400, width=500)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.493549Z","iopub.execute_input":"2022-05-16T20:31:42.493886Z","iopub.status.idle":"2022-05-16T20:31:42.535897Z","shell.execute_reply.started":"2022-05-16T20:31:42.493857Z","shell.execute_reply":"2022-05-16T20:31:42.534954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*From the Column Chart we can see that there is  50%-50% chance of normal passengers being transported, whereas, in VIP the no of passengers transported are less. From this we can infer that there was no priority or advantages for VIP passengers.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">HomePlanet Density of all Passengers</span></h3>","metadata":{}},{"cell_type":"code","source":"dest_df = train.groupby('HomePlanet').sum()['Transported']\ny_list = [dest_df[0], dest_df[1], dest_df[2]]\n\nfig = go.Figure(go.Bar(\n            x=y_list,\n            y=dest_df.index,\n            orientation='h', marker=dict(color=[3, 1, 5], coloraxis=\"coloraxis\")))\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'), title_text=\"Popular Source Planet\", title_x=0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.537593Z","iopub.execute_input":"2022-05-16T20:31:42.538562Z","iopub.status.idle":"2022-05-16T20:31:42.565741Z","shell.execute_reply.started":"2022-05-16T20:31:42.538509Z","shell.execute_reply":"2022-05-16T20:31:42.564787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Out of all the passengers, majority of passengers are from Earth having a count of a little over 2000, after which we have Europa at around 1400 passengers and finally Mars having the least no of Passengers at under 1000.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Destination Planet Density of all Passengers</span></h3>","metadata":{}},{"cell_type":"code","source":"dest_df = train.groupby('Destination').sum()['Transported']\ny_list = [dest_df[0], dest_df[1], dest_df[2]]\n\nfig = go.Figure(go.Bar(\n            x=y_list,\n            y=dest_df.index,\n            orientation='h', marker=dict(color=[3, 1, 5], coloraxis=\"coloraxis\")))\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'), title_text=\"Popular Destination Planet\", title_x=0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.567801Z","iopub.execute_input":"2022-05-16T20:31:42.568096Z","iopub.status.idle":"2022-05-16T20:31:42.589382Z","shell.execute_reply.started":"2022-05-16T20:31:42.568055Z","shell.execute_reply":"2022-05-16T20:31:42.588618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The most popular Destination seems to be 'Trappist-1e', at almost 3000 passengers heading over there. Second favourable place was '55 Canceri e' at little over 1000. The least favourable planet is 'PSO J318.5-22' with less than 500 passengers.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Count the Successful and Unsuccessful Destination transportation for all Passengers</span></h3>","metadata":{}},{"cell_type":"code","source":"train.groupby(['Destination', 'Transported']).count()['PassengerId']","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.590608Z","iopub.execute_input":"2022-05-16T20:31:42.591323Z","iopub.status.idle":"2022-05-16T20:31:42.610283Z","shell.execute_reply.started":"2022-05-16T20:31:42.59129Z","shell.execute_reply":"2022-05-16T20:31:42.609304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The Passengers who chose their destination as \"55 Cancri e\" are more likely to have suceeded in reaching the destination than passengers who chose to travel to a different planet. The Success rate of being transported to the three planets are,*\n1. \"55 Cancri e\"  : 61.0% \n2. \"PSO J318.5-22\": 50.3%\n3. \"TRAPPIST-1e\"  : 47.2%","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Cheking Which Home Planet's transportation was most successful</span></h3>","metadata":{}},{"cell_type":"code","source":"train.groupby(['HomePlanet', 'Transported']).count()['PassengerId']","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.611826Z","iopub.execute_input":"2022-05-16T20:31:42.612218Z","iopub.status.idle":"2022-05-16T20:31:42.631734Z","shell.execute_reply.started":"2022-05-16T20:31:42.612175Z","shell.execute_reply":"2022-05-16T20:31:42.630758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*We can see that that Passengers who started their journey from \"Europa\" are more likely to have suceeded in reaching the destination than passengers who started from a different planet.*","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Label Encoding Categorical Features</span></h3>","metadata":{}},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nlabel_cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\" ,\"VIP\", \"Age_Cat\"]\n\nfor col in label_cols:\n        train[col] = train[col].astype(str)\n        test[col] = test[col].astype(str)\n        train[col] = le.fit_transform(train[col])\n        test[col] =  le.fit_transform(test[col])","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.633163Z","iopub.execute_input":"2022-05-16T20:31:42.634148Z","iopub.status.idle":"2022-05-16T20:31:42.677911Z","shell.execute_reply.started":"2022-05-16T20:31:42.634102Z","shell.execute_reply":"2022-05-16T20:31:42.677269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Identify the Most successful Route in this Journey</span></h3>","metadata":{}},{"cell_type":"code","source":"ts_earth = train.groupby(['HomePlanet']).count()['PassengerId'][0]\nts_europa = train.groupby(['HomePlanet']).count()['PassengerId'][1]\nts_mars = train.groupby(['HomePlanet']).count()['PassengerId'][2]\n\nplanet_journeys = ['earth_canceri', 'earth_pso', 'earth_trappist', 'europa_canceri', 'europa_pso', 'europa_trappist', 'mars_canceri', 'mars_pso', 'mars_trappist']\nsuccess_rates = []\n\nearth_canceri = train.loc[(train['HomePlanet'] == 0) & (train['Destination'] == 0) & (train['Transported'] == True)].shape[0]\nearth_canceri_rate = earth_canceri/ts_earth*100\nsuccess_rates.append(earth_canceri_rate)\n\nearth_pso = train.loc[(train['HomePlanet'] == 0) & (train['Destination'] == 1) & (train['Transported'] == True)].shape[0]\nearth_pso_rate = earth_pso/ts_earth*100\nsuccess_rates.append(earth_pso_rate)\n\nearth_trappist = train.loc[(train['HomePlanet'] == 0) & (train['Destination'] == 2) & (train['Transported'] == True)].shape[0]\nearth_trappist_rate = earth_trappist/ts_earth*100\nsuccess_rates.append(earth_trappist_rate)\n\neuropa_canceri = train.loc[(train['HomePlanet'] == 1) & (train['Destination'] == 0) & (train['Transported'] == True)].shape[0]\neuropa_canceri_rate = europa_canceri/ts_europa*100\nsuccess_rates.append(europa_canceri_rate)\n\neuropa_pso = train.loc[(train['HomePlanet'] == 1) & (train['Destination'] == 1) & (train['Transported'] == True)].shape[0]\neuropa_canceri_rate = europa_pso/ts_europa*100\nsuccess_rates.append(europa_canceri_rate)\n\neuropa_trappist = train.loc[(train['HomePlanet'] == 1) & (train['Destination'] == 2) & (train['Transported'] == True)].shape[0]\neuropa_trappist_rate = europa_trappist/ts_europa*100\nsuccess_rates.append(europa_trappist_rate)\n\nmars_canceri = train.loc[(train['HomePlanet'] == 2) & (train['Destination'] == 0) & (train['Transported'] == True)].shape[0]\nmars_canceri_rate = mars_canceri/ts_mars*100\nsuccess_rates.append(mars_canceri_rate)\n\nmars_pso = train.loc[(train['HomePlanet'] == 2) & (train['Destination'] == 1) & (train['Transported'] == True)].shape[0]\nmars_pso_rate = mars_pso/ts_mars*100\nsuccess_rates.append(mars_pso_rate)\n\nmars_trappist = train.loc[(train['HomePlanet'] == 2) & (train['Destination'] == 2) & (train['Transported'] == True)].shape[0]\nmars_trappist_rate = mars_trappist/ts_mars*100\nsuccess_rates.append(mars_trappist_rate)\n\nsuccess_df = pd.DataFrame({\"Passenger_Route\" : planet_journeys, \"Success_rate_in_Percentage\" : success_rates})\nsuccess_df.columns\nsuccess_df.sort_values(by = 'Success_rate_in_Percentage', ascending=False, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.679483Z","iopub.execute_input":"2022-05-16T20:31:42.679889Z","iopub.status.idle":"2022-05-16T20:31:42.720545Z","shell.execute_reply.started":"2022-05-16T20:31:42.679858Z","shell.execute_reply":"2022-05-16T20:31:42.71987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(go.Bar(\n            x=success_df['Passenger_Route'],\n            y=success_df['Success_rate_in_Percentage'],\n            marker=dict(color=[n for n in range(9)], coloraxis=\"coloraxis\")))\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'), title_text=\"Inter-Planet Transportation Success Rate(%)\", title_x=0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.721916Z","iopub.execute_input":"2022-05-16T20:31:42.722152Z","iopub.status.idle":"2022-05-16T20:31:42.735839Z","shell.execute_reply.started":"2022-05-16T20:31:42.722122Z","shell.execute_reply":"2022-05-16T20:31:42.735314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*On calculating the Success rates of each of the 9 journeys in the dataset, it was evident that journey from Mars to Trappist -1e was the most successful route, at almost 45% success rate. The second most successful route was from Europa to Trappist -1e, at a little over 36%.*\n\n*The least successful route was from Europa to PSO J318.5-22, at 1% success rate. Followed by Mars to PSO J318.5-22 at 2%.*","metadata":{}},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">MODELLING</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Import The Necessary Packages</span></h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm, metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.736784Z","iopub.execute_input":"2022-05-16T20:31:42.737214Z","iopub.status.idle":"2022-05-16T20:31:42.828808Z","shell.execute_reply.started":"2022-05-16T20:31:42.737168Z","shell.execute_reply":"2022-05-16T20:31:42.828163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Split the Data into Test and Train</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*For our analysis and interpretations, we split the train data to 2 parts, train and test. we train our models using this train data and test it on the test data, to get the accuracy and determine which model performs better.*","metadata":{}},{"cell_type":"code","source":"X = train.drop(columns=['Transported'], axis =1 )\ny = train['Transported']\nX_train , X_test , y_train , y_test = train_test_split(X , y, random_state = 12 ,test_size =0.33)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.830151Z","iopub.execute_input":"2022-05-16T20:31:42.830661Z","iopub.status.idle":"2022-05-16T20:31:42.840772Z","shell.execute_reply.started":"2022-05-16T20:31:42.830616Z","shell.execute_reply":"2022-05-16T20:31:42.840116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*We build 6 most popular clusterinng models to predict if the passengers are Transported to the Planets or no. The 6 models are,*\n1. Linear SVM (https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n2. K Neighbours Classifier (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n3. Naive Bayes (https://scikit-learn.org/stable/modules/naive_bayes.html)\n4. Decision Tree (https://scikit-learn.org/stable/modules/tree.html)\n5. Random Forest (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n6. Logistic Regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)","metadata":{}},{"cell_type":"code","source":"model_list = ['Linear SVM', 'K Neighbors Classifier', 'Naive Bayes', 'Decision Tree', 'Random Forest', 'Logistic Regression']\naccuracy_list = []","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.842275Z","iopub.execute_input":"2022-05-16T20:31:42.842749Z","iopub.status.idle":"2022-05-16T20:31:42.85176Z","shell.execute_reply.started":"2022-05-16T20:31:42.842705Z","shell.execute_reply":"2022-05-16T20:31:42.851062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Linear SVM Classifier</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Linear SVM is used for linearly separable data, which means if a dataset can be classified into two classes by using a single straight line, then such data is termed as linearly separable data, and classifier is used called as Linear SVM classifier.*","metadata":{}},{"cell_type":"code","source":"svc = svm.SVC()\nsvc.fit(X_train, y_train)\n\ny_pred_svm = svc.predict(X_test)\n\naccuracy_svm = metrics.accuracy_score(y_test, y_pred_svm)\naccuracy_list.append(round(accuracy_svm, 2)*100)\nsvm_cm = metrics.confusion_matrix(y_test, y_pred_svm)\n\nprint(\"The Accuracy of this model is: \", round(accuracy_svm, 2)*100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:42.855609Z","iopub.execute_input":"2022-05-16T20:31:42.856028Z","iopub.status.idle":"2022-05-16T20:31:45.736691Z","shell.execute_reply.started":"2022-05-16T20:31:42.855984Z","shell.execute_reply":"2022-05-16T20:31:45.735819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">K Nearest Neighbour Classifier</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*It is one of the simplest and widely used classification algorithms in which a new data point is classified based on similarity in the specific group of neighboring data points.*","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\ny_pred_knn = knn.predict(X_test)\n\naccuracy_knn = metrics.accuracy_score(y_test, y_pred_knn)\naccuracy_list.append(round(accuracy_knn, 2)*100)\nknn_cm = metrics.confusion_matrix(y_test, y_pred_knn)\n\nprint(\"The Accuracy of this model is: \", round(accuracy_knn, 2)*100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:45.738099Z","iopub.execute_input":"2022-05-16T20:31:45.738417Z","iopub.status.idle":"2022-05-16T20:31:45.875163Z","shell.execute_reply.started":"2022-05-16T20:31:45.738375Z","shell.execute_reply":"2022-05-16T20:31:45.87435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Naive Bayes Classifier</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*A naive Bayes classifier is an algorithm that uses Bayes' theorem to classify objects. Naive Bayes classifiers assume strong, or naive, independence between attributes of data points.*","metadata":{}},{"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)\n\ny_pred_nb = gnb.predict(X_test)\n\naccuracy_nb = metrics.accuracy_score(y_test, y_pred_nb)\naccuracy_list.append(round(accuracy_nb, 2)*100)\nnb_cm = metrics.confusion_matrix(y_test, y_pred_nb)\n\nprint(\"The Accuracy of this model is: \", round(accuracy_nb, 2)*100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:45.876844Z","iopub.execute_input":"2022-05-16T20:31:45.877136Z","iopub.status.idle":"2022-05-16T20:31:45.906954Z","shell.execute_reply.started":"2022-05-16T20:31:45.877095Z","shell.execute_reply":"2022-05-16T20:31:45.905921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Decision Tree</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Decision Trees are a supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.*","metadata":{}},{"cell_type":"code","source":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\ny_pred_dt = dtc.predict(X_test)\n\naccuracy_dt = metrics.accuracy_score(y_test, y_pred_dt)\naccuracy_list.append(round(accuracy_dt, 2)*100)\ndt_cm = metrics.confusion_matrix(y_test, y_pred_dt)\n\nprint(\"The Accuracy of this model is: \", round(accuracy_dt, 2)*100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:45.908294Z","iopub.execute_input":"2022-05-16T20:31:45.908616Z","iopub.status.idle":"2022-05-16T20:31:45.964766Z","shell.execute_reply.started":"2022-05-16T20:31:45.908573Z","shell.execute_reply":"2022-05-16T20:31:45.963919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Random Forest Classifier</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.*","metadata":{}},{"cell_type":"code","source":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\n\ny_pred_rf = rfc.predict(X_test)\n\naccuracy_rf = metrics.accuracy_score(y_test, y_pred_rf)\naccuracy_list.append(round(accuracy_rf, 2)*100)\nrf_cm = metrics.confusion_matrix(y_test, y_pred_rf)\n\nprint(\"The Accuracy of this model is: \", round(accuracy_rf, 2)*100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:45.96619Z","iopub.execute_input":"2022-05-16T20:31:45.966818Z","iopub.status.idle":"2022-05-16T20:31:46.805066Z","shell.execute_reply.started":"2022-05-16T20:31:45.966772Z","shell.execute_reply":"2022-05-16T20:31:46.804203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Logistic Regression</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Logistic regression is a statistical analysis method to predict a binary outcome, such as yes or no, based on prior observations of a data set.*","metadata":{}},{"cell_type":"code","source":"reg = LogisticRegression()\nreg.fit(X_train, y_train)\n\ny_pred_reg = reg.predict(X_test)\n\naccuracy_reg = metrics.accuracy_score(y_test, y_pred_reg)\naccuracy_list.append(round(accuracy_reg, 2)*100)\nlr_cm = metrics.confusion_matrix(y_test, y_pred_reg)\n\nprint(\"The Accuracy of this model is: \", round(accuracy_reg, 2)*100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:46.806544Z","iopub.execute_input":"2022-05-16T20:31:46.806842Z","iopub.status.idle":"2022-05-16T20:31:46.91626Z","shell.execute_reply.started":"2022-05-16T20:31:46.806803Z","shell.execute_reply":"2022-05-16T20:31:46.915393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">MODEL EVALUATION</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Plot Confusion Matrix</span></h3>","metadata":{}},{"cell_type":"markdown","source":"*Confusion matrices are used to visualize important predictive analytics like recall, specificity, accuracy, and precision.*","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 10))\nfig.subplots_adjust(hspace=0.325)\nsub = fig.add_subplot(2, 3, 1).set_title(\"Support Vector Machine\")\ncm_plot1 = sns.heatmap (svm_cm, annot=True, cmap = 'gist_heat')\ncm_plot1.set_xlabel('Predicted Values')\ncm_plot1.set_ylabel('Actual Values')\n\nsub = fig.add_subplot(2, 3, 2).set_title(\"K Nearest Neighbours\")\ncm_plot2 = sns.heatmap (knn_cm, annot=True, cmap = 'gist_heat')\ncm_plot2.set_xlabel('Predicted Values')\ncm_plot2.set_ylabel('Actual Values')\n\nsub = fig.add_subplot(2, 3, 3).set_title(\"Naive Bayes\")\ncm_plot = sns.heatmap (nb_cm, annot=True, cmap = 'gist_heat')\ncm_plot.set_xlabel('Predicted Values')\ncm_plot.set_ylabel('Actual Values')\n\nsub = fig.add_subplot(2, 3, 4).set_title(\"Decision Trees\")\ncm_plot = sns.heatmap (dt_cm, annot=True, cmap = 'gist_heat')\ncm_plot.set_xlabel('Predicted Values')\ncm_plot.set_ylabel('Actual Values')\n\nsub = fig.add_subplot(2, 3, 5).set_title(\"Random Forest\")\ncm_plot = sns.heatmap (rf_cm, annot=True, cmap = 'gist_heat')\ncm_plot.set_xlabel('Predicted Values')\ncm_plot.set_ylabel('Actual Values')\n\nsub = fig.add_subplot(2, 3, 6).set_title(\"Logistic Regression\")\ncm_plot = sns.heatmap (lr_cm, annot=True, cmap = 'gist_heat')\ncm_plot.set_xlabel('Predicted Values')\ncm_plot.set_ylabel('Actual Values')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:53.207553Z","iopub.status.idle":"2022-05-16T20:31:53.207871Z","shell.execute_reply.started":"2022-05-16T20:31:53.207707Z","shell.execute_reply":"2022-05-16T20:31:53.207724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Accuracy Table</span></h3>","metadata":{}},{"cell_type":"code","source":"comparision = pd.DataFrame({\"Models\" : model_list, \"Model_Accuracy\" : accuracy_list})\ncomparision","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:53.21006Z","iopub.status.idle":"2022-05-16T20:31:53.210424Z","shell.execute_reply.started":"2022-05-16T20:31:53.210219Z","shell.execute_reply":"2022-05-16T20:31:53.210263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(go.Bar(\n            x=model_list,\n            y=accuracy_list,\n            marker=dict(color=[3, 1, 5, 6, 9, 3], coloraxis=\"coloraxis\")))\nfig.update_layout(coloraxis=dict(colorscale='Bluered_r'), title_text=\"Model Accuracies In (%)\", title_x=0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:53.211453Z","iopub.status.idle":"2022-05-16T20:31:53.212629Z","shell.execute_reply.started":"2022-05-16T20:31:53.212317Z","shell.execute_reply":"2022-05-16T20:31:53.212351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**On Plotting all the models' accuracies, we see that Logistic regression and Random Forest Give us the best Accuracy(77%) for predicting the passengers that were transported.**","metadata":{}},{"cell_type":"markdown","source":"<center><img src= \"https://i0.wp.com/dariusforoux.com/wp-content/uploads/2018/11/success.png?fit=665%2C499&ssl=1\" alt =\"Titanic\" style='width: 500px;'></center>","metadata":{}},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:Red;\">PLEASE UPVOTE IF YOU FOUND THIS NOTEBOOK HELPFUL, THANK YOU. :D</span></center></h1>","metadata":{}},{"cell_type":"markdown","source":"<h1><center> <span style=\"color:DarkBlue;\">SUBMISSION</span></center></h1>","metadata":{"_kg_hide-output":true}},{"cell_type":"markdown","source":"<h3><span style=\"color:purple;\">Predicting the test data using the best model we have built (Logistic Regression)</span></h3>","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"test_pred_reg = reg.predict(test)\ntest_pred_reg = test_pred_reg.astype(\"bool\")\ntest_id = test['PassengerId']","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:31:53.213961Z","iopub.status.idle":"2022-05-16T20:31:53.214423Z","shell.execute_reply.started":"2022-05-16T20:31:53.214159Z","shell.execute_reply":"2022-05-16T20:31:53.214184Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sklearn\ntest.drop(columns='PassengerId', inplace=True)\npredictions = (model.predict(test) > 0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T22:01:34.64241Z","iopub.execute_input":"2022-05-16T22:01:34.643157Z","iopub.status.idle":"2022-05-16T22:01:34.946886Z","shell.execute_reply.started":"2022-05-16T22:01:34.643116Z","shell.execute_reply":"2022-05-16T22:01:34.94599Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\" : test_id, \"Transported\" : test_pred_reg})\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T22:02:48.282509Z","iopub.execute_input":"2022-05-16T22:02:48.282832Z","iopub.status.idle":"2022-05-16T22:02:48.320271Z","shell.execute_reply.started":"2022-05-16T22:02:48.282798Z","shell.execute_reply":"2022-05-16T22:02:48.319056Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]}]}