{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Before","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n! pip install -q 'https://github.com/PyTorchLightning/lightning-flash/archive/refs/heads/master.zip#egg=lightning-flash[tabular]'\n! pip install -q \"matplotlib==3.1.1\" \"pandas\" --force-reinstall\nclear_output()\n\nimport numpy as np\nimport pandas as pd\nimport os,random\n\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport flash\nfrom flash.tabular import TabularClassificationData, TabularClassifier\n\nTRAIN_PATH = \"../input/spaceship-titanic/train.csv\"\nTEST_PATH = \"../input/spaceship-titanic/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"../input/spaceship-titanic/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nNEW_TRAIN_PATH = \"new_train.csv\"\nNEW_TEST_PATH = \"new_test.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Transported\"\n\nDELETE_COL = [\"Name\"]\nBOOL_COL = [\"CryoSleep\",\"VIP\"]\n\nSEED = 2022\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()\n\nVAL_SPLIT = 0.2\nBATCH_SIZE = 16\n\nMODEL_NAME = \"fttransformer\"\nMAX_EPOCHS = 20\n\nOUTPUT_FOLDER = \"classes\"\nMODEL_SAVE_PATH = \"tabular_classification_model.pt\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-05T09:13:57.471026Z","iopub.execute_input":"2022-03-05T09:13:57.47383Z","iopub.status.idle":"2022-03-05T09:15:03.261206Z","shell.execute_reply.started":"2022-03-05T09:13:57.473773Z","shell.execute_reply":"2022-03-05T09:15:03.260013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre","metadata":{}},{"cell_type":"code","source":"# load \ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\ntrain = train.drop(DELETE_COL,axis=1)\ntest = test.drop(DELETE_COL,axis=1)\n\n# check null\ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].median()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n    \n# object -> int\ntrain[TARGET] = train[TARGET].astype(int)\nfor col in BOOL_COL:\n    train[col] = train[col].astype(int)\n    test[col] = test[col].astype(int)\n    \ntrain.to_csv(NEW_TRAIN_PATH,index=False)\ntest.to_csv(NEW_TEST_PATH,index=False)\n\nstr_col = train.describe(include=\"O\").columns.tolist()\nnum_col = train.describe(exclude=\"O\").columns.tolist()\n\nSTR_COL = [col for col in str_col if col != ID and col != TARGET]\nNUM_COL = [col for col in num_col if col != ID and col != TARGET]\n\nprint(\"STR_COL = \",STR_COL)\nprint(\"NUM_COL = \",NUM_COL)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:22:35.285856Z","iopub.execute_input":"2022-03-05T09:22:35.286138Z","iopub.status.idle":"2022-03-05T09:22:35.406535Z","shell.execute_reply.started":"2022-03-05T09:22:35.286107Z","shell.execute_reply":"2022-03-05T09:22:35.405547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build ","metadata":{}},{"cell_type":"code","source":"# prepare data\ntrain_data = TabularClassificationData.from_csv(\n    categorical_fields=STR_COL,\n    numerical_fields=NUM_COL,\n    target_fields=TARGET,\n    train_file=NEW_TRAIN_PATH,\n    val_split=VAL_SPLIT,\n    batch_size=BATCH_SIZE,\n)\n\n# defain model\nmodel = TabularClassifier.from_data(train_data, backbone=MODEL_NAME)\n\n# build model\ntrainer = flash.Trainer(max_epochs=MAX_EPOCHS, gpus=torch.cuda.device_count())\ntrainer.fit(model, datamodule=train_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:23:05.615658Z","iopub.execute_input":"2022-03-05T09:23:05.616349Z","iopub.status.idle":"2022-03-05T09:23:48.041448Z","shell.execute_reply.started":"2022-03-05T09:23:05.616282Z","shell.execute_reply":"2022-03-05T09:23:48.040552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After","metadata":{}},{"cell_type":"code","source":"# prediction\ntest_data = TabularClassificationData.from_csv(\n    predict_file=NEW_TEST_PATH,\n    parameters=train_data.parameters,\n    batch_size=1,\n)\npred_test = trainer.predict(model, datamodule=test_data, output=OUTPUT_FOLDER)\n# print(pred_test)\n\n# save model\ntrainer.save_checkpoint(MODEL_SAVE_PATH)\n\npred_result = []\n\nfor i in range(len(pred_test)):\n#     print(pred_test[i])\n    row = pred_test[i]\n    for j in range(len(row)):\n#         print(row[j])\n        pred_result.append(row[j])\n\nsub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = pred_result\nsub[TARGET] = sub[TARGET].astype(bool)\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T09:31:34.729231Z","iopub.execute_input":"2022-03-05T09:31:34.72958Z","iopub.status.idle":"2022-03-05T09:32:19.002072Z","shell.execute_reply.started":"2022-03-05T09:31:34.729546Z","shell.execute_reply":"2022-03-05T09:32:19.000817Z"},"trusted":true},"execution_count":null,"outputs":[]}]}