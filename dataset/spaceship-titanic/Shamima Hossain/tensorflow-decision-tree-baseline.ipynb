{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T17:38:38.129822Z","iopub.execute_input":"2022-04-22T17:38:38.130198Z","iopub.status.idle":"2022-04-22T17:38:38.143343Z","shell.execute_reply.started":"2022-04-22T17:38:38.130163Z","shell.execute_reply":"2022-04-22T17:38:38.142266Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Installing tensorflow Decision tree forest library\n### We need to explicitly install this library since it's not supported on kaggle yet","metadata":{}},{"cell_type":"code","source":"\npip install tensorflow_decision_forests","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:38:38.145218Z","iopub.execute_input":"2022-04-22T17:38:38.146229Z","iopub.status.idle":"2022-04-22T17:39:59.168102Z","shell.execute_reply.started":"2022-04-22T17:38:38.14618Z","shell.execute_reply":"2022-04-22T17:39:59.166815Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the necessary libraries\n### We need to explicitly install this library since it's not supported on kaggle yet","metadata":{}},{"cell_type":"code","source":"import tensorflow_decision_forests as tfdf\ntry:\n  from wurlitzer import sys_pipes\nexcept:\n  from colabtools.googlelog import CaptureLog as sys_pipes\n\nfrom IPython.core.magic import register_line_magic\nfrom IPython.display import Javascript","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:39:59.171441Z","iopub.execute_input":"2022-04-22T17:39:59.171763Z","iopub.status.idle":"2022-04-22T17:40:04.682815Z","shell.execute_reply.started":"2022-04-22T17:39:59.171728Z","shell.execute_reply":"2022-04-22T17:40:04.68203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.684206Z","iopub.execute_input":"2022-04-22T17:40:04.684429Z","iopub.status.idle":"2022-04-22T17:40:04.788853Z","shell.execute_reply.started":"2022-04-22T17:40:04.684403Z","shell.execute_reply":"2022-04-22T17:40:04.787895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The dataset contains 13 features and the column `transported` is the label column. Let's quickly do a basic exploration before diving deep into the dataset.","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.79116Z","iopub.execute_input":"2022-04-22T17:40:04.791405Z","iopub.status.idle":"2022-04-22T17:40:04.839563Z","shell.execute_reply.started":"2022-04-22T17:40:04.791376Z","shell.execute_reply":"2022-04-22T17:40:04.838904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.840893Z","iopub.execute_input":"2022-04-22T17:40:04.841749Z","iopub.status.idle":"2022-04-22T17:40:04.867685Z","shell.execute_reply.started":"2022-04-22T17:40:04.84171Z","shell.execute_reply":"2022-04-22T17:40:04.866796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking how many missing values are there ","metadata":{}},{"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.868985Z","iopub.execute_input":"2022-04-22T17:40:04.871163Z","iopub.status.idle":"2022-04-22T17:40:04.891656Z","shell.execute_reply.started":"2022-04-22T17:40:04.871112Z","shell.execute_reply":"2022-04-22T17:40:04.890542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing \n\n### Tf Decision Trees will work with both categorical and numerical data and account for any missing data as well. However notice carefully in this dataset that there are also columns containing`Boolean` values and they also have missing values. We can of course choose an easy strategy to fill missing values with 0. üßêüßê TF-Df expects it's label column to be of integer type so we will convert the `Tranported` column which is boolean into `int` as well. **Note**: We will leave categorical columns as they are since tf-df can deal with them and their missing values natively","metadata":{}},{"cell_type":"code","source":"data[['Transported', 'VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = data[['Transported', 'VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(value=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.895113Z","iopub.execute_input":"2022-04-22T17:40:04.895358Z","iopub.status.idle":"2022-04-22T17:40:04.912549Z","shell.execute_reply.started":"2022-04-22T17:40:04.89533Z","shell.execute_reply":"2022-04-22T17:40:04.911835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Transported'] = data['Transported'].astype(int)\ndata['VIP'] = data['VIP'].astype(int)\ndata['CryoSleep'] = data['CryoSleep'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.914341Z","iopub.execute_input":"2022-04-22T17:40:04.914666Z","iopub.status.idle":"2022-04-22T17:40:04.925475Z","shell.execute_reply.started":"2022-04-22T17:40:04.914623Z","shell.execute_reply":"2022-04-22T17:40:04.924522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and evaluation\n\n### We will split the dataset into train and test set with a 90%-10% split percentage. I just like keeping most of the data for training purposes. You will also notice that we ditched scikit-learn and used nuumpy and pandas to do the splitting by utilizing randomness from the numpy module. Although there remains a question for reproducability since there are no random_seed param here unlike that in Scikit-learn. This something to explore in future as well","metadata":{}},{"cell_type":"code","source":"# Split the dataset into a training and a testing dataset.\n\ndef split_dataset(dataset, test_ratio=0.10):\n  \"\"\"Splits a panda dataframe in two.\"\"\"\n  test_indices = np.random.rand(len(dataset)) < test_ratio\n  return dataset[~test_indices], dataset[test_indices]\n\n\ntrain_ds_pd, test_ds_pd = split_dataset(data)\nprint(\"{} examples in training, {} examples for testing.\".format(\n    len(train_ds_pd), len(test_ds_pd)))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.926772Z","iopub.execute_input":"2022-04-22T17:40:04.92819Z","iopub.status.idle":"2022-04-22T17:40:04.942441Z","shell.execute_reply.started":"2022-04-22T17:40:04.92814Z","shell.execute_reply":"2022-04-22T17:40:04.941805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tf Datasets\n\n#### We convert the pandas dataframes to tensorflow datasets which are more efficient and provide faster operations. Check out them [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)","metadata":{}},{"cell_type":"code","source":"train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=\"Transported\")\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=\"Transported\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:04.943667Z","iopub.execute_input":"2022-04-22T17:40:04.944397Z","iopub.status.idle":"2022-04-22T17:40:05.032016Z","shell.execute_reply.started":"2022-04-22T17:40:04.94436Z","shell.execute_reply":"2022-04-22T17:40:05.031111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and model selection\n\n#### Tf-df provides a few variants learning algorithms for Decision trees namely:\n- RandomForest\n- GradientBoosted Trees\n- CartModel,\n- DistributedGradientBoostedTreesModel\n\n##### For this notebook I tried the first two and found the second to perform better","metadata":{}},{"cell_type":"code","source":"# Specify the model.\nmodel_1 = tfdf.keras.GradientBoostedTreesModel(\n    num_trees=500,\n    growing_strategy=\"BEST_FIRST_GLOBAL\",\n    max_depth=8,\n    split_axis=\"SPARSE_OBLIQUE\",\n    categorical_algorithm=\"RANDOM\",)\n\n# Optionally, add evaluation metrics.\nmodel_1.compile(\n    metrics=[\"accuracy\"])\n\n# Train the model.\n\nmodel_1.fit(x=train_ds, validation_data=test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.033305Z","iopub.execute_input":"2022-04-22T17:40:05.03371Z","iopub.status.idle":"2022-04-22T17:40:05.043494Z","shell.execute_reply.started":"2022-04-22T17:40:05.033677Z","shell.execute_reply":"2022-04-22T17:40:05.041307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation\n#### When the model finishes training you can evaluate it on the test dataset that we set aside earlier. Based on the performance here we can then decide to tune hyperparameters or change the learning algorithm to suit our needs","metadata":{}},{"cell_type":"code","source":"evaluation = model_1.evaluate(test_ds, return_dict=True)\nprint()\n\nfor name, value in evaluation.items():\n  print(f\"{name}: {value:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.044462Z","iopub.status.idle":"2022-04-22T17:40:05.044995Z","shell.execute_reply.started":"2022-04-22T17:40:05.044771Z","shell.execute_reply":"2022-04-22T17:40:05.044792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspecting model structures and hidden score\n### The different algorithms of Decision Trees will score the features differently and assign importance, we can inspect them like so","metadata":{}},{"cell_type":"code","source":"model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.04682Z","iopub.status.idle":"2022-04-22T17:40:05.047185Z","shell.execute_reply.started":"2022-04-22T17:40:05.047Z","shell.execute_reply":"2022-04-22T17:40:05.047023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.make_inspector().features()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.048778Z","iopub.status.idle":"2022-04-22T17:40:05.04945Z","shell.execute_reply.started":"2022-04-22T17:40:05.049229Z","shell.execute_reply":"2022-04-22T17:40:05.049257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.make_inspector().variable_importances()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.051335Z","iopub.status.idle":"2022-04-22T17:40:05.051678Z","shell.execute_reply.started":"2022-04-22T17:40:05.051497Z","shell.execute_reply":"2022-04-22T17:40:05.051521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspecting and Plotting the training logs üìàüìâ\n### The training logs which are availbale through the `make_inspector()` method contain wealth of information of how the training progresses. It is more useful to plot the result and inpect the trend","metadata":{}},{"cell_type":"code","source":"model_1.make_inspector().training_logs()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.052674Z","iopub.status.idle":"2022-04-22T17:40:05.053022Z","shell.execute_reply.started":"2022-04-22T17:40:05.05282Z","shell.execute_reply":"2022-04-22T17:40:05.052843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlogs = model_1.make_inspector().training_logs()\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Accuracy (out-of-bag)\")\n\nplt.subplot(1, 2, 2)\nplt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Logloss (out-of-bag)\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.054741Z","iopub.status.idle":"2022-04-22T17:40:05.055135Z","shell.execute_reply.started":"2022-04-22T17:40:05.054908Z","shell.execute_reply":"2022-04-22T17:40:05.054932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that training process fluctuates quite a lot but the model converges after 25 or so number of trees","metadata":{}},{"cell_type":"markdown","source":"## Submission Time","metadata":{}},{"cell_type":"code","source":"updated_test = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\nupdated_test[['VIP', 'CryoSleep']] = updated_test[['VIP', 'CryoSleep']].fillna(value=0)\nupdated_test['VIP'] = updated_test['VIP'].astype(int)\nupdated_test['CryoSleep'] = updated_test['CryoSleep'].astype(int)\ntest = tfdf.keras.pd_dataframe_to_tf_dataset(updated_test)\npreds = model_1.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.056756Z","iopub.status.idle":"2022-04-22T17:40:05.057319Z","shell.execute_reply.started":"2022-04-22T17:40:05.057041Z","shell.execute_reply":"2022-04-22T17:40:05.057138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')\nsubmission['Transported'] = preds","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.05839Z","iopub.status.idle":"2022-04-22T17:40:05.058961Z","shell.execute_reply.started":"2022-04-22T17:40:05.058681Z","shell.execute_reply":"2022-04-22T17:40:05.058781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally we shouldn't forget that the model is returning a probability between 0 and 1 and we need to define a threshold above which the prediction is true and false otherwise","metadata":{}},{"cell_type":"code","source":"def transformTo_bool(x):\n    if x < 0.4:\n        return False\n    else:\n        return True\n\nsubmission['Transported'] = submission['Transported'].apply(transformTo_bool)\n\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.060022Z","iopub.status.idle":"2022-04-22T17:40:05.060602Z","shell.execute_reply.started":"2022-04-22T17:40:05.060302Z","shell.execute_reply":"2022-04-22T17:40:05.060417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', header=True, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:40:05.061645Z","iopub.status.idle":"2022-04-22T17:40:05.062167Z","shell.execute_reply.started":"2022-04-22T17:40:05.061918Z","shell.execute_reply":"2022-04-22T17:40:05.061935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References:\n* [Official Tensorflow Decision Forest Blog](https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html)\n* [Official Tensorflow Page for Decision Forest](https://www.tensorflow.org/decision_forests)\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}