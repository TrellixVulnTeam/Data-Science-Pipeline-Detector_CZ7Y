{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font color='navy'>Spaceship Titanic</font>\n#### Author: Anton Khnykin - Data Engineer from Earth","metadata":{}},{"cell_type":"markdown","source":"##### **Special thanks for some ideas:**\nSARDOR ABDIRAYIMOV - https://www.kaggle.com/code/sardorabdirayimov/best-way-of-dealing-with-missing-values-titanic-2/notebook<br>\nOPAMUSORA - https://www.kaggle.com/code/opamusora/top-10-notebook/comments","metadata":{}},{"cell_type":"markdown","source":"### Contents\n#### <a href='#step1'>Step 1. Import libraries and datasets</a>\n#### <a href='#step2'>Step 2. Data preprocessing</a>\n#### <a href='#step3'>Step 3. Make predictions</a>","metadata":{}},{"cell_type":"markdown","source":"### Step 1. Import libraries and datasets<span id='step1'></span>","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport missingno \n\n# import datasets\ntrain_data = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-22T14:28:30.079652Z","iopub.execute_input":"2022-06-22T14:28:30.080265Z","iopub.status.idle":"2022-06-22T14:28:31.567889Z","shell.execute_reply.started":"2022-06-22T14:28:30.080167Z","shell.execute_reply":"2022-06-22T14:28:31.566855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2. Data preprocessing <span id='step2'></span>","metadata":{}},{"cell_type":"code","source":"# check duplicates\ntrain_data.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.569708Z","iopub.execute_input":"2022-06-22T14:28:31.569947Z","iopub.status.idle":"2022-06-22T14:28:31.603901Z","shell.execute_reply.started":"2022-06-22T14:28:31.569915Z","shell.execute_reply":"2022-06-22T14:28:31.602892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Note\n**We haven't duplicates**","metadata":{}},{"cell_type":"code","source":"# check data's structure\ntrain_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.606293Z","iopub.execute_input":"2022-06-22T14:28:31.607074Z","iopub.status.idle":"2022-06-22T14:28:31.636776Z","shell.execute_reply.started":"2022-06-22T14:28:31.607026Z","shell.execute_reply":"2022-06-22T14:28:31.635819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Note\n**There are a lot of gaps in dataset. Only PassengerId and Transported haven't gaps.**","metadata":{}},{"cell_type":"code","source":"# see first rows\ndisplay(train_data.head(5))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.639383Z","iopub.execute_input":"2022-06-22T14:28:31.639721Z","iopub.status.idle":"2022-06-22T14:28:31.667355Z","shell.execute_reply.started":"2022-06-22T14:28:31.639675Z","shell.execute_reply":"2022-06-22T14:28:31.666706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Devide PassengerId, Cabin, Name to several columns\ndef update_dataset(df):\n    df[['Cabin_deck', 'Cabin_num', 'Cabin_side']] = df['Cabin'].str.split('/', expand=True)\n    df['PassengerGroup'] = df['PassengerId'].map(lambda x: x[:4])\n    df[['Name_name', 'Name_family']] = df['Name'].str.split(' ', expand=True)\n    df.drop([\"Cabin\", \"Name\"], axis=1, inplace=True)\n    return df\n    \nfor df in [train_data, test_data]:\n    df = update_dataset(df)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.668504Z","iopub.execute_input":"2022-06-22T14:28:31.668906Z","iopub.status.idle":"2022-06-22T14:28:31.738453Z","shell.execute_reply.started":"2022-06-22T14:28:31.668876Z","shell.execute_reply":"2022-06-22T14:28:31.737731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find minimal Age with which has used Services or VIP. \n# in case of less than min - fill gaps by zero\n\ndef update_by_age(df, column):\n    query_str = column + \" > 0\"\n    min_age = df[['Age', column]].groupby('Age').sum().reset_index().query(query_str).iloc[0, 0]\n    df.loc[df['Age'] < min_age, column] = df.loc[df['Age'] < min_age, column].fillna(0)\n    return df\n\nfor df in [train_data, test_data]:\n    for column in ['VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n        df = update_by_age(df, column)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.739683Z","iopub.execute_input":"2022-06-22T14:28:31.740077Z","iopub.status.idle":"2022-06-22T14:28:31.837053Z","shell.execute_reply.started":"2022-06-22T14:28:31.740046Z","shell.execute_reply":"2022-06-22T14:28:31.83611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if person in CryoSleep than it can't use Services. Fill gaps by zero if it is\ndef update_by_cryo(df, column):\n    df.loc[df['CryoSleep'] == True, column] = df.loc[df['CryoSleep'] == True, column].fillna(0)\n    return df\n    \nfor df in [train_data, test_data]:\n    for column in ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n        df = update_by_age(df, column)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.838411Z","iopub.execute_input":"2022-06-22T14:28:31.839134Z","iopub.status.idle":"2022-06-22T14:28:31.918657Z","shell.execute_reply.started":"2022-06-22T14:28:31.839088Z","shell.execute_reply":"2022-06-22T14:28:31.917661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check gaps by map\nmissingno.matrix(train_data, figsize=(15,5), fontsize=12, \n                 color=(0.5, 0.5, 0.5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:31.920351Z","iopub.execute_input":"2022-06-22T14:28:31.920672Z","iopub.status.idle":"2022-06-22T14:28:32.37032Z","shell.execute_reply.started":"2022-06-22T14:28:31.920629Z","shell.execute_reply":"2022-06-22T14:28:32.369708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:32.371561Z","iopub.execute_input":"2022-06-22T14:28:32.372504Z","iopub.status.idle":"2022-06-22T14:28:32.398051Z","shell.execute_reply.started":"2022-06-22T14:28:32.372457Z","shell.execute_reply":"2022-06-22T14:28:32.397017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill gaps by median (for Age) and zero for Services (if we haven't know about \n# expenses, so we decide than it was absent)\n\ndef update_by_mean(df, column):\n    if column == 'Age':\n        df[column].fillna(df[column].median(), inplace=True)\n    elif column == 'HomePlanet':\n        df[column].fillna('Earth', inplace=True)\n    elif column == 'Destination':\n        df[column].fillna('55 Cancri e', inplace=True)\n    elif column == 'CryoSleep':\n        df[column].fillna(False, inplace=True)\n    elif column == 'VIP':\n        df[column].fillna(False, inplace=True)\n    else:\n        df[column].fillna(0, inplace=True)\n    return df\n    \nfor df in [train_data, test_data]:\n    for column in ['Age', 'RoomService', 'HomePlanet', 'Destination', 'VIP',\n                   'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CryoSleep']:\n        df = update_by_mean(df, column)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:32.4001Z","iopub.execute_input":"2022-06-22T14:28:32.400347Z","iopub.status.idle":"2022-06-22T14:28:32.424498Z","shell.execute_reply.started":"2022-06-22T14:28:32.400305Z","shell.execute_reply":"2022-06-22T14:28:32.423289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change a type of data\ntrain_data['Age'] = train_data['Age'].astype('int32')\ntest_data['Age'] = test_data['Age'].astype('int32')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:28:32.425881Z","iopub.execute_input":"2022-06-22T14:28:32.426185Z","iopub.status.idle":"2022-06-22T14:28:32.433471Z","shell.execute_reply.started":"2022-06-22T14:28:32.426141Z","shell.execute_reply":"2022-06-22T14:28:32.432486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3. Make predictions<span id='step3'></span>","metadata":{}},{"cell_type":"code","source":"# set target\ny_train = train_data[\"Transported\"]\n\n# make X \nfeatures = [\"Age\", \"Destination\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\nX_train = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\n# scale X\nss = StandardScaler()\nX_train_scaled = ss.fit_transform(X_train)\nX_test_scaled = ss.transform(X_test)\n\n# learn a model\nmodel = RandomForestClassifier(n_estimators=100, max_depth=6, \n                               random_state=42)\n\nmodel.fit(X_train_scaled, y_train)\n\n# make predictions\npredictions = model.predict(X_test_scaled)\n\n# save submission\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Transported': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:32:42.108879Z","iopub.execute_input":"2022-06-22T14:32:42.109201Z","iopub.status.idle":"2022-06-22T14:32:42.699198Z","shell.execute_reply.started":"2022-06-22T14:32:42.109169Z","shell.execute_reply":"2022-06-22T14:32:42.69828Z"},"trusted":true},"execution_count":null,"outputs":[]}]}