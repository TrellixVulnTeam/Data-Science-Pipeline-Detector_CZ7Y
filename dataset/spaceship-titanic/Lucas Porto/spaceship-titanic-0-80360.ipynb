{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Spaceship Titanic<center>","metadata":{}},{"cell_type":"markdown","source":"The objective of this work is to present my solution for the Spaceship Titanic competition.\n\nMore information about the competition at https://www.kaggle.com/competitions/spaceship-titanic/overview","metadata":{}},{"cell_type":"code","source":"# First of all: Some necessary imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC , NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier , GradientBoostingClassifier , VotingClassifier, StackingClassifier\nfrom sklearn.model_selection import cross_val_score , KFold , StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom IPython.display import Image\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading training and test files\n\ntrain = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest = pd.read_csv('../input/spaceship-titanic/test.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Size of training dataset\n\ntrain.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Size of test dataset\n\ntest.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the first 5 lines of the training dataset\n\ntrain.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at data types\n\ntrain.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some statistics\n\ntrain.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with Missing Values","metadata":{}},{"cell_type":"code","source":"# First let's see which features have missing values ​​in the training dataset\n\ntrain.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Doing the same for the test dataset\n\ntest.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's adopt the following strategy: For numeric variables we will replace the missing values with the average of the column and for categorical variables we will replace the missing values with the most common category.","metadata":{}},{"cell_type":"markdown","source":"### HomePlanet","metadata":{}},{"cell_type":"code","source":"train['HomePlanet'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing missing values with \"Earth\"\n\ntrain.loc[train['HomePlanet'].isnull() , 'HomePlanet'] = 'Earth'\ntest.loc[test['HomePlanet'].isnull() , 'HomePlanet'] = 'Earth'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CryoSleep","metadata":{}},{"cell_type":"code","source":"train['CryoSleep'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing missing values with \"False\"\n\ntrain.loc[train['CryoSleep'].isnull() , 'CryoSleep'] = False\ntest.loc[test['CryoSleep'].isnull() , 'CryoSleep'] = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cabin","metadata":{}},{"cell_type":"code","source":"train['Cabin'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing missing values with \"X/Num/XPS\"\n\ntrain.loc[train['Cabin'].isnull() , 'Cabin'] = 'X/Num/XPS'\ntest.loc[test['Cabin'].isnull() , 'Cabin'] = 'X/Num/XPS'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Destination","metadata":{}},{"cell_type":"code","source":"train['Destination'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing missing values with \"TRAPPIST-1e\"\n\ntrain.loc[train['Destination'].isnull() , 'Destination'] = 'TRAPPIST-1e'\ntest.loc[test['Destination'].isnull() , 'Destination'] = 'TRAPPIST-1e'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Age","metadata":{}},{"cell_type":"code","source":"train['Age']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the missing values with the average of the Age column\n\ntrain.loc[train['Age'].isnull() , 'Age'] = train['Age'].mean()\ntest.loc[test['Age'].isnull() , 'Age'] = train['Age'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VIP","metadata":{}},{"cell_type":"code","source":"train['VIP'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing missing values with \"False\"\n\ntrain.loc[train['VIP'].isnull() , 'VIP'] = False\ntest.loc[test['VIP'].isnull() , 'VIP'] = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RoomService","metadata":{}},{"cell_type":"code","source":"train['RoomService']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the missing values with the average of the RoomService column\n\ntrain.loc[train['RoomService'].isnull() , 'RoomService'] = train['RoomService'].mean()\ntest.loc[test['RoomService'].isnull() , 'RoomService'] = train['RoomService'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### FoodCourt","metadata":{}},{"cell_type":"code","source":"train['FoodCourt']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the missing values with the average of the FoodCourt column\n\ntrain.loc[train['FoodCourt'].isnull() , 'FoodCourt'] = train['FoodCourt'].mean()\ntest.loc[test['FoodCourt'].isnull() , 'FoodCourt'] = train['FoodCourt'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ShoppingMall","metadata":{}},{"cell_type":"code","source":"train['ShoppingMall']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the missing values with the average of the ShoppingMall column\n\ntrain.loc[train['ShoppingMall'].isnull() , 'ShoppingMall'] = train['ShoppingMall'].mean()\ntest.loc[test['ShoppingMall'].isnull() , 'ShoppingMall'] = train['ShoppingMall'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Spa","metadata":{}},{"cell_type":"code","source":"train['Spa']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the missing values with the average of the Spa column\n\ntrain.loc[train['Spa'].isnull() , 'Spa'] = train['Spa'].mean()\ntest.loc[test['Spa'].isnull() , 'Spa'] = train['Spa'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VRDeck","metadata":{}},{"cell_type":"code","source":"train['VRDeck']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the missing values with the average of the VRDeck column\n\ntrain.loc[train['VRDeck'].isnull() , 'VRDeck'] = train['VRDeck'].mean()\ntest.loc[test['VRDeck'].isnull() , 'VRDeck'] = train['VRDeck'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only the Name column with missing values. No problem, as we will not use this variable in the modeling.\n\ntrain.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### HomePlanet","metadata":{}},{"cell_type":"code","source":"train['HomePlanet'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(train['HomePlanet'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding Earth, Europe and Mars variables to training and testing datasets\n\ntrain = pd.concat([train , pd.get_dummies(train['HomePlanet'])] , axis = 1)\ntest = pd.concat([test , pd.get_dummies(test['HomePlanet'])] , axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CryoSleep","metadata":{}},{"cell_type":"code","source":"test['CryoSleep'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing False with 0 and True with 1\n\nlista = []\nfor i in train['CryoSleep'] :\n    if i == False :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['CryoSleep'] = lista\n\nlista = []\nfor i in test['CryoSleep'] :\n    if i == False :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['CryoSleep'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cabin","metadata":{}},{"cell_type":"code","source":"# Extracting deck and side from the Cabin variable and creating the Deck and Side variables in the training dataset\n\ndeck = []\nnum = []\nside = []\nfor i in train['Cabin'].str.split('/') :\n    deck.append(i[0])\n    num.append(i[1])\n    side.append(i[2])\n\ntrain['Deck'] = deck\ntrain['Side'] = side","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Doing the same for the test dataset\n\ndeck = []\nnum = []\nside = []\nfor i in test['Cabin'].str.split('/') :\n    deck.append(i[0])\n    num.append(i[1])\n    side.append(i[2])\n    \ntest['Deck'] = deck\ntest['Side'] = side","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(train['Deck'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(train['Side'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables A, B, C, D, E, F, G, T, X, P, S and XPS in training and test datasets\n\ntrain = pd.concat([train , pd.get_dummies(train['Deck'])] , axis = 1)\ntrain = pd.concat([train , pd.get_dummies(train['Side'])] , axis = 1)\n\ntest = pd.concat([test , pd.get_dummies(test['Deck'])] , axis = 1)\ntest = pd.concat([test , pd.get_dummies(test['Side'])] , axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Destination","metadata":{}},{"cell_type":"code","source":"train['Destination'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding TRAPPIST-1e, 55 Cancri and PSO J318.5-22 variables to training and testing datasets\n\ntrain = pd.concat([train , pd.get_dummies(train['Destination'])] , axis = 1)\ntest = pd.concat([test , pd.get_dummies(test['Destination'])] , axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Age","metadata":{}},{"cell_type":"code","source":"SS = StandardScaler()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling\n\ntrain['Age_SS'] = SS.fit_transform(train[['Age']])\ntest['Age_SS'] = SS.fit_transform(test[['Age']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VIP","metadata":{}},{"cell_type":"code","source":"train['VIP'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing False with 0 and True with 1 in the training dataset\n\nlista = []\nfor i in train['VIP'] :\n    if i == False :\n        lista.append(0)\n    else :\n        lista.append(1)\n\ntrain['VIP'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Doing the same on the test dataset\n\nlista = []\nfor i in test['VIP'] :\n    if i == False :\n        lista.append(0)\n    else :\n        lista.append(1)\n        \ntest['VIP'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RoomService","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\n\ntrain['RoomService_SS'] = SS.fit_transform(train[['RoomService']])\ntest['RoomService_SS'] = SS.fit_transform(test[['RoomService']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the variable RoomService? which receives the value 1 if someone spent on this service and 0 otherwise.\n\nlista = []\nfor i in train['RoomService'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['RoomService?'] = lista\n\nlista = []\nfor i in test['RoomService'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['RoomService?'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### FoodCourt","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\n\ntrain['FoodCourt_SS'] = SS.fit_transform(train[['FoodCourt']])\ntest['FoodCourt_SS'] = SS.fit_transform(test[['FoodCourt']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the variable FoodCourt? which receives the value 1 if someone spent on this service and 0 otherwise.\n\nlista = []\nfor i in train['FoodCourt'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['FoodCourt?'] = lista\n\nlista = []\nfor i in test['FoodCourt'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['FoodCourt?'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ShoppingMall","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\n\ntrain['ShoppingMall_SS'] = SS.fit_transform(train[['ShoppingMall']])\ntest['ShoppingMall_SS'] = SS.fit_transform(test[['ShoppingMall']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the variable ShoppingMall? which receives the value 1 if someone spent on this service and 0 otherwise.\n\nlista = []\nfor i in train['ShoppingMall'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['ShoppingMall?'] = lista\n\nlista = []\nfor i in test['ShoppingMall'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['ShoppingMall?'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Spa","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\n\ntrain['Spa_SS'] = SS.fit_transform(train[['Spa']])\ntest['Spa_SS'] = SS.fit_transform(test[['Spa']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the variable Spa? which receives the value 1 if someone spent on this service and 0 otherwise.\n\nlista = []\nfor i in train['Spa'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['Spa?'] = lista\n\nlista = []\n\nfor i in test['Spa'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['Spa?'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VRDeck","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\n\ntrain['VRDeck_SS'] = SS.fit_transform(train[['VRDeck']])\ntest['VRDeck_SS'] = SS.fit_transform(test[['VRDeck']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the variable VRDeck? which receives the value 1 if someone spent on this service and 0 otherwise.\n\nlista = []\nfor i in train['VRDeck'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['VRDeck?'] = lista\n\nlista = []\nfor i in test['VRDeck'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['VRDeck?'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### N","metadata":{}},{"cell_type":"markdown","source":"Creating the variable N which indicates the **N**umber of services a person has spent their money on. The services considered are RoomService, FoodCourt, ShoppingMall, Spa and VRDeck. Therefore, this variable can assume the values 0, 1, 2, 3, 4 or 5.","metadata":{}},{"cell_type":"code","source":"train['N'] = train['RoomService?'] + train['FoodCourt?'] + train['ShoppingMall?'] + train['Spa?'] + train['VRDeck?']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['N'] = test['RoomService?'] + test['FoodCourt?'] + test['ShoppingMall?'] + test['Spa?'] + test['VRDeck?']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### M","metadata":{}},{"cell_type":"markdown","source":"Creating the variable M which receives the value 1 if a person has spent on at least one service and receives the value 0 otherwise.","metadata":{}},{"cell_type":"code","source":"lista = []\nfor i in train['N'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntrain['M'] = lista\n\nlista = []\nfor i in test['N'] :\n    if i == 0 :\n        lista.append(0)\n    else :\n        lista.append(1)\ntest['M'] = lista","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Total_Spent","metadata":{}},{"cell_type":"markdown","source":"Creating the Total_Spent variable that indicates the sum of expenses in RoomService, FoodCourt, ShoppingMall, Spa and VRDeck.","metadata":{}},{"cell_type":"code","source":"train['Total_Spent'] = train['RoomService_SS']+ train['FoodCourt_SS']+train['ShoppingMall_SS']+train['Spa_SS']+train['VRDeck_SS']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Total_Spent'] = test['RoomService_SS']+test['FoodCourt_SS']+test['ShoppingMall_SS']+test['Spa_SS']+test['VRDeck_SS']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Spa_SS+VRDeck_SS","metadata":{}},{"cell_type":"code","source":"train['Spa_SS+VRDeck_SS'] = train['Spa_SS'] + train['VRDeck_SS']\ntest['Spa_SS+VRDeck_SS'] = test['Spa_SS'] + test['VRDeck_SS']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### FoodCourt_SS+Spa_SS","metadata":{}},{"cell_type":"code","source":"train['FoodCourt_SS+Spa_SS'] = train['FoodCourt_SS'] + train['Spa_SS']\ntest['FoodCourt_SS+Spa_SS'] = test['FoodCourt_SS'] + test['Spa_SS']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"markdown","source":"After performing tests with several sets of variables, I concluded that the set below seems to provide the best results:","metadata":{}},{"cell_type":"code","source":"features =  ['Earth', 'Mars', 'A', 'B', 'C', 'D', 'E', 'F','T','X',\n        'S', 'P', '55 Cancri e', 'PSO J318.5-22',\n        'Age_SS' ,'RoomService?', 'FoodCourt?' , 'ShoppingMall?' , \n           'Spa?' , 'VRDeck?', 'N', 'M', 'CryoSleep', 'VIP' ,\n             'RoomService_SS' , 'FoodCourt_SS' , 'ShoppingMall_SS' , 'Spa_SS' , 'VRDeck_SS' , 'Total_Spent' , 'Spa_SS+VRDeck_SS',\n             'FoodCourt_SS+Spa_SS' ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Models\n\nmodels = [LogisticRegression(max_iter = 1000) , KNeighborsClassifier() , SVC(), LinearSVC(max_iter = 50000) ,\n          DecisionTreeClassifier(), GaussianNB() , RandomForestClassifier() , AdaBoostClassifier() ,\n          GradientBoostingClassifier(), XGBClassifier(use_label_encoder = False) ,\n          CatBoostClassifier() , LGBMClassifier() ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Name\n\nmodels_name = ['Logistic Regression' , 'KNN' , 'SVC' , 'Linear SVC' , 'Decision Tree' , 'Naive Bayes' , 'Random Forest',\n               'AdaBoost' , 'GradientBoosting' , 'XGB' , 'CatBoost' , 'LGBM']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Transported'] = train['Transported'].astype('int32')\nX_train = train[features]\ny_train = train['Transported']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Storing each model's accuracy when doing a 3-fold cross-validation\n\ncv_scores = []\nfor model in models :\n    cv_scores.append(np.mean(cross_val_score(model , X_train, y_train, cv = 3 )))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying the  mean accuracy that each model obtained in cross-validation\n\ndictionary = {'Model' : models_name , 'Mean Accuracy' : cv_scores}\ndf_cv = pd.DataFrame(dictionary)\ndf_cv","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen above, the model that had the best performance in cross-validation was CatBoost, so we will choose this model. After a long process of hyperparameter optimization, I found a CatBoost model with the following hyperparameters as the best model:","metadata":{}},{"cell_type":"markdown","source":"**learning_rate = 0,01**","metadata":{}},{"cell_type":"markdown","source":"**n_estimators = 1500**","metadata":{}},{"cell_type":"markdown","source":"**depth = 6**","metadata":{}},{"cell_type":"markdown","source":"## First submission to Kaggle","metadata":{}},{"cell_type":"code","source":"model = CatBoostClassifier(learning_rate = 0.01 , n_estimators = 1500 , depth = 6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Transported'] = model.predict(test[features])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Transported'] = test['Transported'].astype('bool')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = test[['PassengerId' , 'Transported']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission1.csv' , index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This submission gave us a score of 0.80336 on Kaggle. Let's try to improve our score using Stacking.","metadata":{}},{"cell_type":"markdown","source":"## Stacking","metadata":{}},{"cell_type":"code","source":"estimators = [('catboost1', model) , ('catboost2' , model)]\n\nfinal_estimator = LogisticRegression()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StackingClassifier(estimators = estimators , final_estimator = final_estimator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc.fit(X_train , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Second Submission to Kaggle","metadata":{}},{"cell_type":"code","source":"test['Transported'] = sc.predict(test[features])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Transported'] = test['Transported'].astype('bool')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = test[['PassengerId' , 'Transported']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission2.csv' , index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image('../input/imagem-score/kaggle.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see in the image we managed to get an improvement in our score getting 0.80360","metadata":{}}]}