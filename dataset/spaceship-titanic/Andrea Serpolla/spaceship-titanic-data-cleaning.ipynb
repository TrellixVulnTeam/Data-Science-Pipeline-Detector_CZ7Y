{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-10T10:26:40.808681Z","iopub.execute_input":"2022-04-10T10:26:40.809004Z","iopub.status.idle":"2022-04-10T10:26:40.818562Z","shell.execute_reply.started":"2022-04-10T10:26:40.808948Z","shell.execute_reply":"2022-04-10T10:26:40.817915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\") # read training data\ndf.head() # print first 5 lines of dataframe","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:40.821977Z","iopub.execute_input":"2022-04-10T10:26:40.822188Z","iopub.status.idle":"2022-04-10T10:26:40.887181Z","shell.execute_reply.started":"2022-04-10T10:26:40.82216Z","shell.execute_reply":"2022-04-10T10:26:40.886376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape # dataframe dimensions","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:40.88864Z","iopub.execute_input":"2022-04-10T10:26:40.889206Z","iopub.status.idle":"2022-04-10T10:26:40.895631Z","shell.execute_reply.started":"2022-04-10T10:26:40.889164Z","shell.execute_reply":"2022-04-10T10:26:40.894688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe() # main properties of numeric features","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:40.898417Z","iopub.execute_input":"2022-04-10T10:26:40.898906Z","iopub.status.idle":"2022-04-10T10:26:40.935899Z","shell.execute_reply.started":"2022-04-10T10:26:40.898864Z","shell.execute_reply":"2022-04-10T10:26:40.93496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(exclude=\"number\") # main properties of non-numeric features","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:40.938866Z","iopub.execute_input":"2022-04-10T10:26:40.939108Z","iopub.status.idle":"2022-04-10T10:26:40.994374Z","shell.execute_reply.started":"2022-04-10T10:26:40.939078Z","shell.execute_reply":"2022-04-10T10:26:40.993515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datatypes parsing","metadata":{}},{"cell_type":"markdown","source":"First, let's parse aggregated data into their components.\nIn particular let's split `PassengerId`, `Cabin`, and `Name` information.","metadata":{}},{"cell_type":"markdown","source":"## `PasssengerId` parsing","metadata":{}},{"cell_type":"markdown","source":"As documentations reports, Passenger ID is formed as `gggg_pp` where `gggg` identifies the group the passenger is travelling with and `pp` the passenger itself.","metadata":{}},{"cell_type":"code","source":"df.insert(loc=0, column=\"GroupMember\", value=df.PassengerId.apply(lambda x: x.split(\"_\")[-1]))\ndf.insert(loc=0, column=\"Group\", value=df.PassengerId.apply(lambda x: x.split(\"_\")[-2]))\ndf = df.drop(columns=\"PassengerId\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:40.996077Z","iopub.execute_input":"2022-04-10T10:26:40.996953Z","iopub.status.idle":"2022-04-10T10:26:41.038432Z","shell.execute_reply.started":"2022-04-10T10:26:40.996905Z","shell.execute_reply":"2022-04-10T10:26:41.037488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Group` and `GroupMember` are still represented by strings.","metadata":{}},{"cell_type":"code","source":"df.iloc[:, :2].dtypes","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.040123Z","iopub.execute_input":"2022-04-10T10:26:41.040456Z","iopub.status.idle":"2022-04-10T10:26:41.049389Z","shell.execute_reply.started":"2022-04-10T10:26:41.040413Z","shell.execute_reply":"2022-04-10T10:26:41.048504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's parse as numbers.","metadata":{}},{"cell_type":"code","source":"df.Group = df.Group.astype(int)\ndf.GroupMember = df.GroupMember.astype(int)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.051033Z","iopub.execute_input":"2022-04-10T10:26:41.05137Z","iopub.status.idle":"2022-04-10T10:26:41.084612Z","shell.execute_reply.started":"2022-04-10T10:26:41.051329Z","shell.execute_reply":"2022-04-10T10:26:41.083797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## `Cabin` parsing","metadata":{}},{"cell_type":"markdown","source":"As the documentation reports, the cabin number takes the form `deck/num/side`, where side can be either $P$ for Port or $S$ for Starboard.","metadata":{}},{"cell_type":"code","source":"n = df.columns.tolist().index(\"Cabin\") # Cabin column position in dataframe\n\nfor i, col in enumerate([\"Side\", \"CabinNumber\", \"Deck\"]):\n    df.insert(loc=n, column=col, value=df.Cabin.apply(lambda x: x.split(\"/\")[-i-1] if type(x) == str else np.nan)) # there are NaNs to consider!\n    \ndf = df.drop(columns=\"Cabin\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.08597Z","iopub.execute_input":"2022-04-10T10:26:41.086182Z","iopub.status.idle":"2022-04-10T10:26:41.136024Z","shell.execute_reply.started":"2022-04-10T10:26:41.086156Z","shell.execute_reply":"2022-04-10T10:26:41.135104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[:, [\"Deck\", \"CabinNumber\", \"Side\"]].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.137385Z","iopub.execute_input":"2022-04-10T10:26:41.137599Z","iopub.status.idle":"2022-04-10T10:26:41.149729Z","shell.execute_reply.started":"2022-04-10T10:26:41.137574Z","shell.execute_reply":"2022-04-10T10:26:41.148934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Null values remained the same. This is correct.","metadata":{}},{"cell_type":"markdown","source":"## `Name` parsing","metadata":{}},{"cell_type":"code","source":"df.Name.apply(lambda x: len(x.split()) if type(x) == str else 0).value_counts() # count words in names","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.150939Z","iopub.execute_input":"2022-04-10T10:26:41.15141Z","iopub.status.idle":"2022-04-10T10:26:41.175869Z","shell.execute_reply.started":"2022-04-10T10:26:41.151365Z","shell.execute_reply":"2022-04-10T10:26:41.175008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are names with first and family name and missing values. Let's split first and family name. This can be useful to search for family connections.","metadata":{}},{"cell_type":"code","source":"n = df.columns.tolist().index(\"Name\") # Cabin column position in dataframe\n\nfor i, col in enumerate([\"FamilyName\", \"FirstName\"]):\n    df.insert(loc=n, column=col, value=df.Name.apply(lambda x: x.split()[-i-1] if type(x) == str else np.nan)) # there are NaNs to consider!\n    \ndf = df.drop(columns=\"Name\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.177134Z","iopub.execute_input":"2022-04-10T10:26:41.178008Z","iopub.status.idle":"2022-04-10T10:26:41.234089Z","shell.execute_reply.started":"2022-04-10T10:26:41.177971Z","shell.execute_reply":"2022-04-10T10:26:41.233165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[:, [\"FirstName\", \"FamilyName\"]].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.237053Z","iopub.execute_input":"2022-04-10T10:26:41.237328Z","iopub.status.idle":"2022-04-10T10:26:41.24957Z","shell.execute_reply.started":"2022-04-10T10:26:41.237297Z","shell.execute_reply":"2022-04-10T10:26:41.24871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Null values remained the same. This is correct.","metadata":{}},{"cell_type":"markdown","source":"## Final parsing","metadata":{}},{"cell_type":"markdown","source":"Let's check if all datatypes arre correctly parsed.","metadata":{}},{"cell_type":"code","source":"df.dtypes.loc[lambda x: x == \"object\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.25068Z","iopub.execute_input":"2022-04-10T10:26:41.252416Z","iopub.status.idle":"2022-04-10T10:26:41.263391Z","shell.execute_reply.started":"2022-04-10T10:26:41.252366Z","shell.execute_reply":"2022-04-10T10:26:41.262435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`CryoSleep` and `VIP` should be boolean.","metadata":{}},{"cell_type":"code","source":"df.loc[:, [\"CryoSleep\", \"VIP\"]] = df.loc[:, [\"CryoSleep\", \"VIP\"]].astype(bool)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.264739Z","iopub.execute_input":"2022-04-10T10:26:41.265387Z","iopub.status.idle":"2022-04-10T10:26:41.278918Z","shell.execute_reply.started":"2022-04-10T10:26:41.265341Z","shell.execute_reply":"2022-04-10T10:26:41.277873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.280594Z","iopub.execute_input":"2022-04-10T10:26:41.281137Z","iopub.status.idle":"2022-04-10T10:26:41.288813Z","shell.execute_reply.started":"2022-04-10T10:26:41.281102Z","shell.execute_reply":"2022-04-10T10:26:41.287867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing values cleaning","metadata":{}},{"cell_type":"markdown","source":"Null values can be replaced with valid ones or they can just be dropped.\nUsually trying to keep more information is better since we will have more data to train a model but sometimes is quite difficult find the best way to replace all missing values.\n\nThere are various techniques that can be used:\n- for numeric series interpolation (i.e. fit a function between two valid values to fill missing ones);\n- find out some useful relation between data and use another feature (i.e. column) to get information on another one;\n- generate random values using valid ones distribution;\n- [...]\n\nThere are also various ways to drop missing data:\n- drop all entries (i.e. rows) with any null value;\n- drop an entire feature with missing values.\n\nIn addition, when dropping values we could also use a threshold one the missing values percentage above all values.\n\nDuring training, entries drop is not so painful because we are just discarding some data loosing information but the same information remains in other data.\nOn the contrary, when an entire feature is discarded its information is totally lost and a model trained without it will not be able to use it anymore.","metadata":{}},{"cell_type":"markdown","source":"In this notebook entries with missing values are just dropped but one of the techniques mentioned above can be used.","metadata":{}},{"cell_type":"code","source":"df.isna().any(axis=1).sum() / df.shape[0] * 100 # percentage of rows with missing values","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.290335Z","iopub.execute_input":"2022-04-10T10:26:41.290854Z","iopub.status.idle":"2022-04-10T10:26:41.309129Z","shell.execute_reply.started":"2022-04-10T10:26:41.290822Z","shell.execute_reply":"2022-04-10T10:26:41.308189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to drop $24\\%$ of the original data. ","metadata":{}},{"cell_type":"code","source":"df = df.dropna() # drop rows with missing values\ndf = df.reset_index(drop=True) # reset the incremental index dropping the current one\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.310532Z","iopub.execute_input":"2022-04-10T10:26:41.310936Z","iopub.status.idle":"2022-04-10T10:26:41.348279Z","shell.execute_reply.started":"2022-04-10T10:26:41.310889Z","shell.execute_reply":"2022-04-10T10:26:41.347422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any(axis=None) # is there any missing value in the dataframe?","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.349613Z","iopub.execute_input":"2022-04-10T10:26:41.350496Z","iopub.status.idle":"2022-04-10T10:26:41.36523Z","shell.execute_reply.started":"2022-04-10T10:26:41.35045Z","shell.execute_reply":"2022-04-10T10:26:41.363725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Non-numeric values encoding","metadata":{}},{"cell_type":"markdown","source":"Libraries tools work only on numeric data. Because of this we have to encode all objects to numeric values.\n\nThe resulting range is not so important, here the main key is that every qualitative value is represented by a different number.\nNext numeric values will be transformed some way based on the supervised model to train so at that time is important to choose wich range values should have.\n\nTo encode numeric values we will use _Scikit-learn_ instruments.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.366986Z","iopub.execute_input":"2022-04-10T10:26:41.36736Z","iopub.status.idle":"2022-04-10T10:26:41.856799Z","shell.execute_reply.started":"2022-04-10T10:26:41.367315Z","shell.execute_reply":"2022-04-10T10:26:41.855857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes.loc[lambda x: x == \"object\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.857922Z","iopub.execute_input":"2022-04-10T10:26:41.858165Z","iopub.status.idle":"2022-04-10T10:26:41.86866Z","shell.execute_reply.started":"2022-04-10T10:26:41.858135Z","shell.execute_reply":"2022-04-10T10:26:41.867698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = df.dtypes.loc[lambda x: x == \"object\"].index.tolist() # features with non-numeric values\nencoders = {col: LabelEncoder() for col in cols} # one encoder per feature\n\nfor col in encoders.keys():\n    encoders[col] = encoders[col].fit(df.loc[:, col]) # determine number of labels to use\n    df.loc[:, col] = encoders[col].transform(df.loc[:, col]) # encode labels","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.86984Z","iopub.execute_input":"2022-04-10T10:26:41.870103Z","iopub.status.idle":"2022-04-10T10:26:41.920292Z","shell.execute_reply.started":"2022-04-10T10:26:41.870062Z","shell.execute_reply":"2022-04-10T10:26:41.919281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.92405Z","iopub.execute_input":"2022-04-10T10:26:41.924615Z","iopub.status.idle":"2022-04-10T10:26:41.94666Z","shell.execute_reply.started":"2022-04-10T10:26:41.924567Z","shell.execute_reply":"2022-04-10T10:26:41.945817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.94814Z","iopub.execute_input":"2022-04-10T10:26:41.94863Z","iopub.status.idle":"2022-04-10T10:26:41.957452Z","shell.execute_reply.started":"2022-04-10T10:26:41.948587Z","shell.execute_reply":"2022-04-10T10:26:41.956362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Notebook output","metadata":{}},{"cell_type":"markdown","source":"Now encoders and final dataframe are saved for further processing in other notebooks.\nEncoders are saved if inverse transformation of labels is needed.","metadata":{}},{"cell_type":"code","source":"import pickle as pkl","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.958895Z","iopub.execute_input":"2022-04-10T10:26:41.959298Z","iopub.status.idle":"2022-04-10T10:26:41.970017Z","shell.execute_reply.started":"2022-04-10T10:26:41.959258Z","shell.execute_reply":"2022-04-10T10:26:41.969145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save encoders using pickle serialization\nwith open(\"encoders.pkl\", \"wb\") as file: \n    pkl.dump(encoders, file)\n\n# save dataframe to a csv file\ndf.to_csv(\"train.csv\", index=False) # don't save incremental index","metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:26:41.971076Z","iopub.execute_input":"2022-04-10T10:26:41.971745Z","iopub.status.idle":"2022-04-10T10:26:42.052225Z","shell.execute_reply.started":"2022-04-10T10:26:41.971712Z","shell.execute_reply":"2022-04-10T10:26:42.051339Z"},"trusted":true},"execution_count":null,"outputs":[]}]}