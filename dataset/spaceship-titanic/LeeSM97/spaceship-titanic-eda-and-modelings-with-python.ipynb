{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Introduction \nThe goal of this competition aims to predicting whether or not passengers are transported.\n\nIn the data, there are lots of features. \nBelow is the description of each feature\n- `PassengerId` - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n- `HomePlanet` - The planet the passenger departed from, typically their planet of permanent residence.\n- `CryoSleep` - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n- `Cabin` - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n- `Destination` - The planet the passenger will be debarking to.\n- `Age` - The age of the passenger.\n- `VIP` - Whether the passenger has paid for special VIP service during the voyage.\n- `RoomService, FoodCourt, ShoppingMall, Spa, VRDeck` - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n- `Name` - The first and last names of the passenger.\n- `Transported` - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n\nWe will look at feature engineering to see what form it is appropriate to refine data with these features before refining them.\n\n(This notebook gets help on below notebooks.)\n\n* [Spaceship Titanic EDA & classification](https://www.kaggle.com/code/marianobasili/spaceship-titanic-eda-classification)\n* [ðŸš€Spaceship Titanic -ðŸ“ŠEDA + 27 different modelsðŸ“ˆ](https://www.kaggle.com/code/odins0n/spaceship-titanic-eda-27-different-models)\n","metadata":{}},{"cell_type":"markdown","source":"# 2. EDA\n## 2-1. Importing data and preparation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport plotly.express as px\nimport missingno as msno\nimport matplotlib.ticker as mtick\nimport time\nimport re\n\n\npd.set_option('float_format', '{:f}'.format)\n\nimport warnings\nwarnings.filterwarnings(action='ignore') \n\n%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:56:12.056155Z","iopub.execute_input":"2022-03-23T08:56:12.05663Z","iopub.status.idle":"2022-03-23T08:56:13.532559Z","shell.execute_reply.started":"2022-03-23T08:56:12.056556Z","shell.execute_reply":"2022-03-23T08:56:13.5311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"org_train = pd.read_csv('../input/spaceship-titanic/train.csv')\norg_test = pd.read_csv('../input/spaceship-titanic/test.csv')\norg_sample_sub = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:56:13.538259Z","iopub.execute_input":"2022-03-23T08:56:13.538532Z","iopub.status.idle":"2022-03-23T08:56:13.621211Z","shell.execute_reply.started":"2022-03-23T08:56:13.538496Z","shell.execute_reply":"2022-03-23T08:56:13.620356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-2. Overview of features and data","metadata":{}},{"cell_type":"code","source":"train = org_train.copy()\ntest = org_test.copy()\nsample_sub = org_sample_sub\n\ntrain.info()\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:59:55.141615Z","iopub.execute_input":"2022-03-23T08:59:55.14206Z","iopub.status.idle":"2022-03-23T08:59:55.181146Z","shell.execute_reply.started":"2022-03-23T08:59:55.142017Z","shell.execute_reply":"2022-03-23T08:59:55.179795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:06:43.473746Z","iopub.execute_input":"2022-03-23T09:06:43.474094Z","iopub.status.idle":"2022-03-23T09:06:43.505434Z","shell.execute_reply.started":"2022-03-23T09:06:43.47406Z","shell.execute_reply":"2022-03-23T09:06:43.504759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The overview of features in data**\\\nIn the categorical feature, there are two things we have to split the data before we build the model.\n\n\n\n1. **PassengerId**\\\nPassengerId formed by `gggg_pp`.\nThe `pp` is information about the individual passenger, but `gggg` is information about the group, so it is necessary to separate the information about the group because individual transfer can depend on the group.\n\n2. **Cabin**\\\nCabin combines `deck/num/side` information into one.\nIf two passengers are the same deck, they may be confused with different information when training the model if they are different num or sides, so it is necessary to separate them into three.\n","metadata":{}},{"cell_type":"code","source":"train[['Group','Id']] = train['PassengerId'].str.split('_', expand=True)\ntest[['Group','Id']] = test['PassengerId'].str.split('_', expand=True)\n\ntrain['Group'] = pd.to_numeric(train['Group'])\ntest['Group'] = pd.to_numeric(test['Group'])\n\ntrain.drop(['Id','PassengerId'], inplace=True, axis=1)\ntest.drop(['Id','PassengerId'], inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:59:57.608661Z","iopub.execute_input":"2022-03-23T08:59:57.60902Z","iopub.status.idle":"2022-03-23T08:59:57.666501Z","shell.execute_reply.started":"2022-03-23T08:59:57.608983Z","shell.execute_reply":"2022-03-23T08:59:57.665332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['Cabin_deck','Cabin_num','Cabin_side']] = train['Cabin'].str.split('/', expand=True)\ntest[['Cabin_deck','Cabin_num','Cabin_side']] = test['Cabin'].str.split('/', expand=True)\n\ntrain['Cabin_num'] = pd.to_numeric(train['Cabin_num'])\ntest['Cabin_num'] = pd.to_numeric(test['Cabin_num'])\n\ntrain.drop('Cabin', inplace=True, axis=1)\ntest.drop('Cabin', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:59:59.308221Z","iopub.execute_input":"2022-03-23T08:59:59.309413Z","iopub.status.idle":"2022-03-23T08:59:59.364885Z","shell.execute_reply.started":"2022-03-23T08:59:59.309329Z","shell.execute_reply":"2022-03-23T08:59:59.364075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('Name', inplace=True, axis=1)\ntest.drop('Name', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:00:01.203439Z","iopub.execute_input":"2022-03-23T09:00:01.203933Z","iopub.status.idle":"2022-03-23T09:00:01.214074Z","shell.execute_reply.started":"2022-03-23T09:00:01.203892Z","shell.execute_reply":"2022-03-23T09:00:01.213231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Target = 'Transported'\nFeatures = [col for col in train.columns]\ncat_feat = [col for col in train.columns if (train[col].dtypes == 'object') & ( col not in [Target])]\nnum_feat = [col for col in train.columns if (train[col].dtypes != 'object') & ( col not in [Target])]","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:00:03.65341Z","iopub.execute_input":"2022-03-23T09:00:03.653884Z","iopub.status.idle":"2022-03-23T09:00:03.661104Z","shell.execute_reply.started":"2022-03-23T09:00:03.65385Z","shell.execute_reply":"2022-03-23T09:00:03.660379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train set's dimension : \",train.shape)\nprint(\"Test set's dimension : \",test.shape)\nprint(\"numbers of categorical feature : \" ,len(cat_feat))\nprint(\"numbers of numerical feature : \" ,len(num_feat))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:56:17.865222Z","iopub.execute_input":"2022-03-23T08:56:17.865539Z","iopub.status.idle":"2022-03-23T08:56:17.875416Z","shell.execute_reply.started":"2022-03-23T08:56:17.865507Z","shell.execute_reply":"2022-03-23T08:56:17.874483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Is there missing values?\", train.isnull().sum().sum())\nprint(\"Is there missing values?\", test.isnull().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:00:07.365306Z","iopub.execute_input":"2022-03-23T09:00:07.365846Z","iopub.status.idle":"2022-03-23T09:00:07.389652Z","shell.execute_reply.started":"2022-03-23T09:00:07.365809Z","shell.execute_reply":"2022-03-23T09:00:07.388012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The overview of train/test data**\n\n* In the train data, there are total 15 columns and 8693 rows \n* 15 columns contain 1 target(6 for categorical, 8 for numerical, 1 for target)\n* There are missing values in both train / test data\n\n$\\Rightarrow$ Missing values are important issues before data analysis.\nWe can eliminate or fill missing values.\nBut later we'll fill it by multiple imputations.","metadata":{}},{"cell_type":"code","source":"print(\"train data missing columns\\n\\n\",train.isnull().sum())\nprint(\"\\n\\ntest data missing columns\\n\\n\",test.isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Approximate visualization of missing value distribution\nmsno.matrix(train)\nplt.title('Missing Value Distribution in train set');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(test)\nplt.title('Missing Value Distribution in test set');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(1,1, figsize=(12,8))\n(train.isnull().mean()*100).plot(kind='bar', ax=ax, align='center', width=.4, color='violet')\n(test.isnull().mean()*100).plot(kind='bar', ax=ax, align='edge',width=.4, color='dodgerblue')\nplt.legend(labels=['Train Set','Test Set'])\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.tick_params(axis='x', labelrotation=80)\nax.set_ylabel('Missing Values (%)')\nax.set_title('Percentage of missing values in train and test set');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The overview of missing value**\\\nIt can be seen that the distribution ratio of missing values in both train set and test set is similar.\n\nAlso, since the missing value distribution is different, removing all missing values can cause a lot of data loss\\\n$\\rightarrow$So we will replace missing values.\n\nWe will replace missing value by *Multiple Imputation by Chained Equation*(MICE).\\\nMice simulates and creates multiple missing substitution sets, performs certain statistical modeling 'with' functions, and averages the substitution sets generated with 'pool' functions to derive results\nIt can be the most optimal missing data replacement value.\n\nMICE : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/","metadata":{}},{"cell_type":"markdown","source":"## 2-3. Overview of Target\n\nWe will identify the distribution of Transported.\n\nIf it is balanced, we will apply Kfold, otherwise we will apply stratifiedKfold.","metadata":{}},{"cell_type":"code","source":"plt.title('Distribution of Trasported')\nsns.countplot(x= 'Transported',data=train);\nplt.show()\nprint(\"Total number of Transported : \", len(train[train[Target]==True]))\nprint(\"Total number of Not transported : \", len(train[train[Target]==False]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The distribution is balanced so we are gonna use Kfold*","metadata":{}},{"cell_type":"markdown","source":"## 2-4. Overview of the distribution of Categorical Features\n","metadata":{}},{"cell_type":"code","source":"cat_feat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(3,2,1)\nplt.title('HomePlanet distribution based on Transported')\nsns.countplot(x= 'HomePlanet', hue='Transported', data=train)\n\nplt.subplot(3,2,2)\nplt.title('CryoSleep distribution based on Transported')\nsns.countplot(x= 'CryoSleep', hue='Transported', data=train)\n\nplt.subplot(3,2,3)\nplt.title('Destination distribution based on Transported')\nsns.countplot(x= 'Destination', hue='Transported', data=train)\n\nplt.subplot(3,2,4)\nplt.title('VIP distribution based on Transported')\nsns.countplot(x= 'VIP', hue='Transported', data=train)\n\nplt.subplot(3,2,5)\nplt.title('Cabin_deck distribution based on Transported')\nsns.countplot(x= 'Cabin_deck', hue='Transported', data=train)\n\nplt.subplot(3,2,6)\nplt.title('Cabin_side distribution based on Transported')\nsns.countplot(x= 'Cabin_side', hue='Transported', data=train)\n\nplt.subplots_adjust(hspace=0.6)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The overview of Categorical features**\\\nAs you can see, the Target distribution of categorical features isn't balanced.\\\nPeople who are from Earth have a lower percentage of transfers, and the Europa is the opposite.\n\nThose who didn't do Cryosleep had a higher percentage of transfers than those who did.\n\nVarious other distributions can be identified.","metadata":{}},{"cell_type":"markdown","source":"## 2-5. Overview of the distribution of Numerical Features","metadata":{}},{"cell_type":"code","source":"num_feat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\n\nplt.subplot(4,2,1)\nplt.title('Age distribution based on Transported')\nsns.histplot(x=\"Age\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"Age\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,2)\nplt.title('RoomService distribution based on Transported')\nsns.histplot(x=\"RoomService\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"RoomService\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,3)\nplt.title('FoodCourt distribution based on Transported')\nsns.histplot(x=\"FoodCourt\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"FoodCourt\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,4)\nplt.title('ShoppingMall distribution based on Transported')\nsns.histplot(x=\"ShoppingMall\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"ShoppingMall\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,5)\nplt.title('Spa distribution based on Transported')\nsns.histplot(x=\"Spa\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"Spa\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,6)\nplt.title('VRDeck distribution based on Transported')\nsns.histplot(x=\"VRDeck\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"VRDeck\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,7)\nplt.title('Group distribution based on Transported')\nsns.histplot(x=\"Group\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"Group\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplot(4,2,8)\nplt.title('Cabin_num distribution based on Transported')\nsns.histplot(x=\"Cabin_num\", data=train, kde=True, alpha = 0.1, color='#E6104C')\nsns.histplot(x=\"Cabin_num\", data=train, hue=\"Transported\", multiple=\"stack\")\n\nplt.subplots_adjust(hspace=0.6)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The overview of Numerical features**\\\nRed line is the kernel density estimator for an entire continuous variable\nand Bar is the histogram divided by Transported.\n\nAge and Cabin_num features seem to be biased\n\nGroup feature seems to be balanced\n\nand rest of features is biased toward zero","metadata":{}},{"cell_type":"markdown","source":"## 2-6. Handling missing value and out \n\nNumerical features have different distributions for each feature,\\\nCategorical features have distribution differences depending on whether they are transported.\n\nIn consideration of this, we do not replace the missing values with simple 0 or average or median values, but rather use MICE to be more statistically significant.\n","metadata":{}},{"cell_type":"code","source":"train = pd.get_dummies(train)\ntest = pd.get_dummies(test)\nFeatures = [col for col in train.columns if col not in ['PassengerId',Target]]\n\n#Replace missing value by Multiple Imputation\n!pip install impyute\nfrom impyute.imputation.cs import mice\ntrain_imputed=mice(train.drop([Target],axis=1).values) # mice í•™ìŠµì‹œìž‘\ntest_imputed=mice(test.values)\n\nfeat_colum_list = list(train.columns)\nfeat_colum_list.remove('Transported')\n\ntrain[Features] = pd.DataFrame(train_imputed, columns =feat_colum_list)\ntest[Features] = pd.DataFrame(test_imputed, columns =feat_colum_list)\n\ntrain[Features].head()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:05:24.157619Z","iopub.execute_input":"2022-03-23T09:05:24.158134Z","iopub.status.idle":"2022-03-23T09:05:33.526198Z","shell.execute_reply.started":"2022-03-23T09:05:24.15809Z","shell.execute_reply":"2022-03-23T09:05:33.525093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Is there missing values?\", train.isnull().sum().sum())\nprint(\"Is there missing values?\", test.isnull().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:05:37.722158Z","iopub.execute_input":"2022-03-23T09:05:37.722648Z","iopub.status.idle":"2022-03-23T09:05:37.73409Z","shell.execute_reply.started":"2022-03-23T09:05:37.722612Z","shell.execute_reply":"2022-03-23T09:05:37.733315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Modelings\n\nNow that the data preprocessing is over, let's make a prediction through various models.\nWe are gonna use 5 models\n\n1. Decision Tree\n2. Random Forest\n3. Extratree\n4. CatBoost\n5. LGBM\n\nFinally, we will submit the final results through hard-voting for five models.","metadata":{}},{"cell_type":"markdown","source":"## 3-1. Decision Tree","metadata":{}},{"cell_type":"code","source":"# 1.Decision Tree classfy(with KFold)\nfrom sklearn import tree\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\n\nDTC = tree.DecisionTreeClassifier(random_state=0)\n\nDTC_pred_result = []\nDTC_scores = []\nDTC_feature_imp =[]\n\nsplitter = KFold(n_splits=10, shuffle=True, random_state=0)\n\nprint(\"Start Decision Tree Classify\")\nfor fold, (train_index, valid_index) in enumerate(splitter.split(train[Features],train[Target])) :\n    print(10*\"=\",f\"Fold : {fold+1}\",10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_index][Features], train.iloc[valid_index][Features]\n    y_train , y_valid = train[Target].iloc[train_index] , train[Target].iloc[valid_index]\n\n    model=DTC\n    model.fit(X_train, y_train)\n    \n    pred_valid_result = model.predict(X_valid)\n    acc = accuracy_score(y_valid,pred_valid_result)\n    DTC_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold : {fold+1}, Accuracy : {acc:.3f}, Run Time : {run_time:.3f}s\" )\n    \n    feature_imp = pd.DataFrame(index=Features,data=model.feature_importances_,columns=[f'{fold}_importance'])\n    DTC_feature_imp.append(feature_imp)\n    \n    test_pred_result = model.predict(test[Features])\n    DTC_pred_result.append(test_pred_result)\n    \nprint(f\"Decision Tree Classify Mean Accuracy : {(np.mean(DTC_scores)):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:08:50.064264Z","iopub.execute_input":"2022-03-23T09:08:50.064601Z","iopub.status.idle":"2022-03-23T09:08:50.862331Z","shell.execute_reply.started":"2022-03-23T09:08:50.064569Z","shell.execute_reply":"2022-03-23T09:08:50.86145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance for Decision Tree (Top 10 Features)","metadata":{}},{"cell_type":"code","source":"DTC_feature_imp\nDTC_feature_imp_df = pd.concat(DTC_feature_imp, axis=1).head(10)\nDTC_feature_imp_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:57:27.503999Z","iopub.execute_input":"2022-03-23T08:57:27.50435Z","iopub.status.idle":"2022-03-23T08:57:28.090875Z","shell.execute_reply.started":"2022-03-23T08:57:27.504316Z","shell.execute_reply":"2022-03-23T08:57:28.089827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy of Decision tree is 0.751, and Cabin_num is most important Features.","metadata":{}},{"cell_type":"markdown","source":"## 3-2. Random Forest","metadata":{}},{"cell_type":"code","source":"# 2.Random Forest classfy(with KFold)\nfrom sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(random_state=0)\n\nRFC_pred_result = []\nRFC_scores = []\nRFC_feature_imp =[]\n\nsplitter = KFold(n_splits=10, shuffle=True, random_state=0)\n\nprint(\"Start Random Forest Classify\")\nfor fold, (train_index, valid_index) in enumerate(splitter.split(train[Features],train[Target])) :\n    print(10*\"=\",f\"Fold : {fold+1}\",10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_index][Features], train.iloc[valid_index][Features]\n    y_train , y_valid = train[Target].iloc[train_index] , train[Target].iloc[valid_index]\n    \n    model=RFC\n    model.fit(X_train, y_train)\n    \n    pred_valid_result = model.predict(X_valid)\n    acc = accuracy_score(y_valid,pred_valid_result)\n    RFC_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold : {fold+1}, Accuracy : {acc:.3f}, Run Time : {run_time:.3f}s\" )\n    \n    feature_imp = pd.DataFrame(index=Features,data=model.feature_importances_,columns=[f'{fold}_importance'])\n    RFC_feature_imp.append(feature_imp)\n    \n    test_pred_result = model.predict(test[Features])\n    RFC_pred_result.append(test_pred_result)\n    \nprint(f\"Random Forest Classify Mean Accuracy : {(np.mean(RFC_scores)):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:08:56.670196Z","iopub.execute_input":"2022-03-23T09:08:56.670494Z","iopub.status.idle":"2022-03-23T09:09:09.784937Z","shell.execute_reply.started":"2022-03-23T09:08:56.670463Z","shell.execute_reply":"2022-03-23T09:09:09.783531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance for Random Forest (Top 10 Features)","metadata":{}},{"cell_type":"code","source":"RFC_feature_imp\nRFC_feature_imp_df = pd.concat(RFC_feature_imp, axis=1).head(10)\nRFC_feature_imp_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy of Random Forest is 0.8, and Cabin_num is most important Features.","metadata":{}},{"cell_type":"code","source":"# 3.Extra Tree classfy(with KFold)\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nETC = ExtraTreesClassifier(random_state=0)\n\nETC_pred_result = []\nETC_scores = []\nETC_feature_imp =[]\n\nsplitter = KFold(n_splits=10, shuffle=True, random_state=0)\n\nprint(\"Start Extra Tree Classify\")\nfor fold, (train_index, valid_index) in enumerate(splitter.split(train[Features],train[Target])) :\n    print(10*\"=\",f\"Fold : {fold+1}\",10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_index][Features], train.iloc[valid_index][Features]\n    y_train , y_valid = train[Target].iloc[train_index] , train[Target].iloc[valid_index]\n    \n    model=ETC\n    model.fit(X_train, y_train)\n    \n    pred_valid_result = model.predict(X_valid)\n    acc = accuracy_score(y_valid,pred_valid_result)\n    ETC_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold : {fold+1}, Accuracy : {acc:.3f}, Run Time : {run_time:.3f}s\" )\n    \n    feature_imp = pd.DataFrame(index=Features,data=model.feature_importances_,columns=[f'{fold}_importance'])\n    ETC_feature_imp.append(feature_imp)\n    \n    test_pred_result = model.predict(test[Features])\n    ETC_pred_result.append(test_pred_result)\n    \nprint(f\"Extra Tree Classify Mean Accuracy : {(np.mean(ETC_scores)):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:09:23.736348Z","iopub.execute_input":"2022-03-23T09:09:23.736653Z","iopub.status.idle":"2022-03-23T09:09:34.786115Z","shell.execute_reply.started":"2022-03-23T09:09:23.736622Z","shell.execute_reply":"2022-03-23T09:09:34.784889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ETC_feature_imp\nETC_feature_imp_df = pd.concat(ETC_feature_imp, axis=1).head(10)\nETC_feature_imp_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:09:34.788546Z","iopub.execute_input":"2022-03-23T09:09:34.788963Z","iopub.status.idle":"2022-03-23T09:09:35.372553Z","shell.execute_reply.started":"2022-03-23T09:09:34.788911Z","shell.execute_reply":"2022-03-23T09:09:35.371741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy of Extra tree is 0.79, and Age is most important Features.","metadata":{}},{"cell_type":"code","source":"# 4.Catboost classfy(with KFold)\nfrom catboost import CatBoostClassifier\n\nCAT = CatBoostClassifier(silent=True,random_state=0)\n\nCAT_pred_result = []\nCAT_scores = []\nCAT_feature_imp =[]\n\nsplitter = KFold(n_splits=10, shuffle=True, random_state=0)\n\nprint(\"Start Extra Tree Classify\")\nfor fold, (train_index, valid_index) in enumerate(splitter.split(train[Features],train[Target])) :\n    print(10*\"=\",f\"Fold : {fold+1}\",10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_index][Features], train.iloc[valid_index][Features]\n    y_train , y_valid = train[Target].iloc[train_index] , train[Target].iloc[valid_index]\n    \n    model=CAT\n    model.fit(X_train, y_train)\n    \n    pred_valid_result = model.predict(X_valid)\n    pred_valid_result = [ele == \"True\" for ele in pred_valid_result]\n    acc = accuracy_score(y_valid,pred_valid_result)\n    CAT_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold : {fold+1}, Accuracy : {acc:.3f}, Run Time : {run_time:.3f}s\" )\n    \n    feature_imp = pd.DataFrame(index=Features,data=model.feature_importances_,columns=[f'{fold}_importance'])\n    CAT_feature_imp.append(feature_imp)\n    \n    test_pred_result = model.predict(test[Features])\n    CAT_pred_result.append(test_pred_result)\n    \nprint(f\"CATBoost Classify Mean Accuracy : {(np.mean(CAT_scores)):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:09:44.591027Z","iopub.execute_input":"2022-03-23T09:09:44.591555Z","iopub.status.idle":"2022-03-23T09:10:32.006828Z","shell.execute_reply.started":"2022-03-23T09:09:44.591518Z","shell.execute_reply":"2022-03-23T09:10:32.005783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CAT_feature_imp\nCAT_feature_imp_df = pd.concat(CAT_feature_imp, axis=1).head(10)\nCAT_feature_imp_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:10:55.756511Z","iopub.execute_input":"2022-03-23T09:10:55.756936Z","iopub.status.idle":"2022-03-23T09:10:56.332144Z","shell.execute_reply.started":"2022-03-23T09:10:55.756894Z","shell.execute_reply":"2022-03-23T09:10:56.331139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy of Catboost is 0.813, and Spa is most important Features.","metadata":{}},{"cell_type":"code","source":"# 5.LGBM classfy(with KFold)\nfrom lightgbm import LGBMClassifier\nLGB = LGBMClassifier(random_state=0)\n\nLGB_pred_result = []\nLGB_scores = []\nLGB_feature_imp =[]\n\nsplitter = KFold(n_splits=10, shuffle=True, random_state=0)\n\nprint(\"Start LGBM Classify\")\nfor fold, (train_index, valid_index) in enumerate(splitter.split(train[Features],train[Target])) :\n    print(10*\"=\",f\"Fold : {fold+1}\",10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_index][Features], train.iloc[valid_index][Features]\n    y_train , y_valid = train[Target].iloc[train_index] , train[Target].iloc[valid_index]\n    \n    model=LGB\n    model.fit(X_train, y_train)\n    \n    pred_valid_result = model.predict(X_valid)\n    acc = accuracy_score(y_valid,pred_valid_result)\n    LGB_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold : {fold+1}, Accuracy : {acc:.3f}, Run Time : {run_time:.3f}s\" )\n    \n    feature_imp = pd.DataFrame(index=Features,data=model.feature_importances_,columns=[f'{fold}_importance'])\n    LGB_feature_imp.append(feature_imp)\n    \n    test_pred_result = model.predict(test[Features])\n    LGB_pred_result.append(test_pred_result)\n    \nprint(f\"LGBM Classify Mean Accuracy : {(np.mean(LGB_scores)):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:10:41.435903Z","iopub.execute_input":"2022-03-23T09:10:41.436254Z","iopub.status.idle":"2022-03-23T09:10:44.423163Z","shell.execute_reply.started":"2022-03-23T09:10:41.436217Z","shell.execute_reply":"2022-03-23T09:10:44.422198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LGB_feature_imp\nLGB_feature_imp_df = pd.concat(LGB_feature_imp, axis=1).head(10)\nLGB_feature_imp_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10), title='Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:11:17.506209Z","iopub.execute_input":"2022-03-23T09:11:17.506591Z","iopub.status.idle":"2022-03-23T09:11:18.291048Z","shell.execute_reply.started":"2022-03-23T09:11:17.506549Z","shell.execute_reply":"2022-03-23T09:11:18.289813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy of LGBM is 0.81, and Cabin_num is most important Features.","metadata":{}},{"cell_type":"markdown","source":"# 4. Submission\n\nWe constructed five different models for predicting results.\\\nWe will combine these models into ensemble to complete the submission of the test data.\n\nThe ensemble will proceed with hard-voting.\\\nHard voting is a method of voting by majority based on the predicted results of each weak learner.\n\nThe more information about hard-voting : https://en.wikipedia.org/wiki/Ensemble_learning","metadata":{}},{"cell_type":"code","source":"#Ensemble(hard-voting)\n\nfrom sklearn.ensemble import VotingClassifier\nvoting = VotingClassifier(estimators=[\n         ('DecisionTree', DTC), ('RandomForest', RFC), ('ExtraTree', ETC), ('Catboost', CAT), ('LGBMboost', LGB)],\n           voting='hard', n_jobs=5)\nvoting = voting.fit(train[Features],train[Target])\n\nprediction = voting.predict(test[Features])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:12:48.873568Z","iopub.execute_input":"2022-03-23T09:12:48.87398Z","iopub.status.idle":"2022-03-23T09:12:58.626278Z","shell.execute_reply.started":"2022-03-23T09:12:48.873942Z","shell.execute_reply":"2022-03-23T09:12:58.624798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId': org_test['PassengerId'], 'Transported': prediction})\nsubmission.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T09:20:50.098276Z","iopub.execute_input":"2022-03-23T09:20:50.098576Z","iopub.status.idle":"2022-03-23T09:20:50.116513Z","shell.execute_reply.started":"2022-03-23T09:20:50.098544Z","shell.execute_reply":"2022-03-23T09:20:50.11576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}