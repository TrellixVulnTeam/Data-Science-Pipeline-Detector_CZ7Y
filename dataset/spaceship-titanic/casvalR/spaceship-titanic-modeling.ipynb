{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T08:07:33.452386Z","iopub.execute_input":"2022-04-20T08:07:33.452717Z","iopub.status.idle":"2022-04-20T08:07:33.462807Z","shell.execute_reply.started":"2022-04-20T08:07:33.452681Z","shell.execute_reply":"2022-04-20T08:07:33.46178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef get_position(cabin):\n    position_search = re.search(r'(\\w)/\\d+/\\w',cabin)\n    if position_search:\n        return position_search.group(1)\n    return \"\"\n\n\ndef get_position2(cabin):\n    position_search = re.search(r'\\w/\\d+/(\\w)',cabin)\n    if position_search:\n        return position_search.group(1)\n    return\"\"\n\ndef add_label(df):\n    df[\"Age\"].describe()\n    df[\"Age\"].fillna(df[\"Age\"].median(),inplace=True)\n    col = [\"Age\"]\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    scaler.fit(df[col])\n    df[col] = scaler.transform(df[col])\n\n    def get_id(PassengerId):\n        id_search = re.search(r'(\\d{4})\\w\\d{2}',PassengerId)\n        \n        if id_search:\n            return id_search.group(1)\n        return \"\"\n\n    df[\"id_1\"]=df[\"PassengerId\"].apply(get_id)\n    col = [\"id_1\"]\n    scaler.fit(df[col])\n    df[col] = scaler.transform(df[col])\n\n    df[\"Group_num\"] = df.groupby('id_1')['PassengerId'].transform('count')\n    from sklearn.preprocessing import PowerTransformer\n    ptb = PowerTransformer(method='box-cox')\n    pty = PowerTransformer(method='yeo-johnson')\n    col = [\"Group_num\"]\n    ptb.fit(df[col])\n    df[col] = ptb.transform(df[col])\n\n    def get_id(PassengerId):\n        id_search = re.search(r'\\d{4}\\w(\\d{2})',PassengerId)\n        \n        if id_search:\n            return id_search.group(1)\n        return \"\"\n\n    df[\"id_2\"]=df[\"PassengerId\"].apply(get_id)\n    from sklearn.preprocessing import PowerTransformer\n    ptb = PowerTransformer(method='box-cox')\n    pty = PowerTransformer(method='yeo-johnson')\n    col = [\"id_2\"]\n    ptb.fit(df[col])\n    df[col] = ptb.transform(df[col])\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-20T08:07:33.481068Z","iopub.execute_input":"2022-04-20T08:07:33.481406Z","iopub.status.idle":"2022-04-20T08:07:33.498465Z","shell.execute_reply.started":"2022-04-20T08:07:33.481368Z","shell.execute_reply":"2022-04-20T08:07:33.497512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time \nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics \nimport pandas as pd\nimport optuna\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, PowerTransformer\nfrom sklearn.impute import SimpleImputer\n\ntrain = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntrain = add_label(train)\n\nlist_cols = [\"HomePlanet\",\"CryoSleep\",\"Destination\",\"VIP\"]\nlist_cat = [\"Area\", \"Side\", 'isChild', 'isOld']\ntarget = \"Transported\"\n\ntrain[\"Cabin\"].fillna('Z/00/Z',inplace=True)\ntrain[\"Area\"] = train[\"Cabin\"].apply(get_position)\ntrain[\"Side\"] = train[\"Cabin\"].apply(get_position2)\ntrain['GroupId'] = train['PassengerId'].str[:4]\ntrain['PeopleInGroup1'] = train.groupby('GroupId')['PassengerId'].transform('count')\ntrain['PersonalId'] = train['PassengerId'].str[-2:]\ntrain['PeopleInGroup2'] = train.groupby('PersonalId')['PassengerId'].transform('count')\ntrain['isChild'] = train['Age'].apply(lambda x: 1 if x < 10 else 0)\ntrain['isOld'] = train['Age'].apply(lambda x: 1 if x > 60 else 0)\n\ndel train[\"Cabin\"], train[\"Name\"]\n\noe = OrdinalEncoder()\noe.fit(train[list_cat])\ntrain.loc[:,list_cat]  = oe.transform(train[list_cat])\n\nohe = OneHotEncoder(sparse=False)\nohe.fit(train[list_cols])\n\nptr = PowerTransformer()\nnum_col = list(set(train.columns)-set(list_cols)-set(list_cat)-set([target]))\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean', fill_value=None)\ntrain[num_col] = imp_mean.fit_transform(train[num_col])\nptr.fit(train[num_col])\ntrain.loc[:,num_col]  = ptr.transform(train[num_col])\n\ndf_new = pd.DataFrame(ohe.transform(train[list_cols]), \n                      columns=ohe.get_feature_names(), \n                      dtype=np.int64)\ntrain = train.drop(list_cols, axis=1)\n\ndf_session_ce_onehot = pd.concat([train, df_new] ,axis=1)\nprint(df_session_ce_onehot.head(3))\ny = df_session_ce_onehot[target].values\nX = df_session_ce_onehot[df_session_ce_onehot.columns[df_session_ce_onehot.columns != target]].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n\nK_fold = KFold(n_splits=5, shuffle=True,  random_state=42)\n\nrow_no_list = list(range(len(y_train)))\n\ndef objective(trial):\n    param = {\n        'objective': 'binary',\n        'metric': trial.suggest_categorical('metric', ['binary_error',\"binary_logloss\"]),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 100),#7\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth':trial.suggest_int('max_depth',1,100),\n        \"verbose\": -1,\n    }\n\n    accuracy = 0\n    for train_cv_no, eval_cv_no in K_fold.split(row_no_list, y_train):\n        X_train_cv = X_train[train_cv_no, :]\n        y_train_cv = pd.Series(y_train)[train_cv_no]\n        X_test_cv = X_train[eval_cv_no, :]\n        y_test_cv = pd.Series(y_train)[eval_cv_no]\n\n        train_data = lgb.Dataset(X_train_cv, label=y_train_cv)\n        eval_data = lgb.Dataset(X_test_cv, label=y_test_cv, reference= train_data)\n\n    \n        gbm = lgb.train(\n                param,\n                train_data,\n                num_boost_round=1000,\n                )\n        preds = gbm.predict(X_test_cv)\n        pred_labels = np.rint(preds)\n        ac_cv = sklearn.metrics.accuracy_score(y_test_cv, pred_labels)\n        if accuracy < ac_cv: accuracy = ac_cv \n    return accuracy\n\noptuna.logging.disable_default_handler()\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=1000)\n\nbestparams = study.best_trial.params\n\ntrain_data = lgb.Dataset(X_train, label=y_train)\neval_data = lgb.Dataset(X_test, label=y_test, reference= train_data)\n\nstart = time.time()\nmodel = lgb.train(bestparams,train_data)\nprint(\"fit time = {}\".format(time.time()-start))\n\npred = model.predict(X_train)\npred = (pred > 0.5) * 1\nac_train = sklearn.metrics.accuracy_score(y_train, pred)\nprint(ac_train)\n\nmodel = lgb.train(bestparams,eval_data)\npred = model.predict(X_test)\npred = (pred > 0.5) * 1\nac_test = sklearn.metrics.accuracy_score(y_test, pred)\nprint(ac_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T08:07:33.51313Z","iopub.execute_input":"2022-04-20T08:07:33.513684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')\ntest = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\n\ntest = add_label(test)\ntest[\"Cabin\"].fillna('Z/00/Z',inplace=True)\ntest[\"Area\"] = test[\"Cabin\"].apply(get_position)\ntest[\"Side\"] = test[\"Cabin\"].apply(get_position2)\ntest['GroupId'] = test['PassengerId'].str[:4]\ntest['PeopleInGroup1'] = test.groupby('GroupId')['PassengerId'].transform('count')\ntest['PersonalId'] = test['PassengerId'].str[-2:]\ntest['PeopleInGroup2'] = test.groupby('PersonalId')['PassengerId'].transform('count')\ntest['isChild'] = test['Age'].apply(lambda x: 1 if x < 10 else 0)\ntest['isOld'] = test['Age'].apply(lambda x: 1 if x > 60 else 0)\n\ndel test[\"Cabin\"], test[\"Name\"]\n\ntest.loc[:,list_cat]  = oe.transform(test[list_cat])\ntest.loc[:,num_col]  = ptr.transform(test[num_col])\nnum_col = list(set(train.columns)-set(list_cols)-set(list_cat)-set([target]))\ntest[num_col] = imp_mean.transform(test[num_col])\ndf_new = pd.DataFrame(ohe.transform(test[list_cols]), \n                      columns=ohe.get_feature_names(), \n                      dtype=np.int64)\ntest = test.drop(list_cols, axis=1)\n\ndf_session_ce_onehot = pd.concat([test, df_new] ,axis=1)\n\ndf_session_ce_onehot.head()\nX = df_session_ce_onehot[df_session_ce_onehot.columns[df_session_ce_onehot.columns != target]].values\ny_pred = model.predict(X,predict_disable_shape_check=True)\ny_pred = (y_pred>0.5).astype(bool)\nsub[target] = list(y_pred)\nsub.to_csv(\"./submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}