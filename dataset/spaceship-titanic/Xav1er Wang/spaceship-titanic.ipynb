{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(pd.__version__)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-27T08:54:05.769605Z","iopub.execute_input":"2022-06-27T08:54:05.770043Z","iopub.status.idle":"2022-06-27T08:54:05.801061Z","shell.execute_reply.started":"2022-06-27T08:54:05.76996Z","shell.execute_reply":"2022-06-27T08:54:05.799814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib\nimport sklearn\nfrom sklearn import tree\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import LabelEncoder\nprint(sklearn.__version__)\nprint(matplotlib.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T08:55:53.204421Z","iopub.execute_input":"2022-06-27T08:55:53.204763Z","iopub.status.idle":"2022-06-27T08:55:53.211959Z","shell.execute_reply.started":"2022-06-27T08:55:53.204735Z","shell.execute_reply":"2022-06-27T08:55:53.211161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file = '/kaggle/input/spaceship-titanic/train.csv'\ntest_file = '/kaggle/input/spaceship-titanic/test.csv'\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\n\nprint(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:28.584105Z","iopub.execute_input":"2022-06-27T03:05:28.584838Z","iopub.status.idle":"2022-06-27T03:05:28.685053Z","shell.execute_reply.started":"2022-06-27T03:05:28.584791Z","shell.execute_reply":"2022-06-27T03:05:28.683728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 数据分析\n需要分析数据的分布和与结果的相关性，以及对空值的处理","metadata":{}},{"cell_type":"markdown","source":"## 数据信息展示","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:30.419493Z","iopub.execute_input":"2022-06-27T03:05:30.420121Z","iopub.status.idle":"2022-06-27T03:05:30.453821Z","shell.execute_reply.started":"2022-06-27T03:05:30.420073Z","shell.execute_reply":"2022-06-27T03:05:30.452743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 数据空值分析","metadata":{}},{"cell_type":"code","source":"null_cols = train_data.columns[train_data.isnull().any()].tolist()\nnull_count_cols = train_data[null_cols].isnull().sum()\n\nprint(\"missing values in train data:\")\nprint(null_cols)\nplt.figure(figsize=(20,10))\nplt.bar(null_cols, null_count_cols)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:31.408192Z","iopub.execute_input":"2022-06-27T03:05:31.408954Z","iopub.status.idle":"2022-06-27T03:05:31.621445Z","shell.execute_reply.started":"2022-06-27T03:05:31.408898Z","shell.execute_reply":"2022-06-27T03:05:31.620282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 数值数据分析","metadata":{}},{"cell_type":"markdown","source":"### 数值分布分析","metadata":{}},{"cell_type":"code","source":"# 选取数值类型数据\nnum_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\nprint(\"numeric columns:\", num_cols)\n\n# 画出数值数据的分布图\nfor col in num_cols:\n    plt.figure(figsize=(15,7))\n    plt.title(col)\n    plt.hist(train_data[col], bins=100)\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:32.94333Z","iopub.execute_input":"2022-06-27T03:05:32.944459Z","iopub.status.idle":"2022-06-27T03:05:34.920661Z","shell.execute_reply.started":"2022-06-27T03:05:32.944376Z","shell.execute_reply":"2022-06-27T03:05:34.919492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"从上述结果来看，'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'均有大量0值，因此对于空值替换，应该用0值替换，而Age分布较为均匀，因此替换时可以使用平均值替换","metadata":{}},{"cell_type":"markdown","source":"### 相关性分析","metadata":{}},{"cell_type":"code","source":"corr_mat = train_data[train_data.columns].corr(method='spearman')\ncorr = corr_mat['Transported'].drop('Transported').sort_values(ascending=False)\nprint(corr)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:35.125184Z","iopub.execute_input":"2022-06-27T03:05:35.125569Z","iopub.status.idle":"2022-06-27T03:05:35.174204Z","shell.execute_reply.started":"2022-06-27T03:05:35.125535Z","shell.execute_reply":"2022-06-27T03:05:35.173161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"可以看出数值数据相关性都不强","metadata":{}},{"cell_type":"markdown","source":"# 数据处理","metadata":{}},{"cell_type":"markdown","source":"首先PassengerId 中可以得到有效信息：group，我们可以认为，同一个group的乘客，HomePlanet 、 Destination 和 Cabin相同。这对处理空数据有很大帮助。","metadata":{}},{"cell_type":"code","source":"def fill_null_according_PassengerId(data:pd.DataFrame):\n    data['Group'] = data['PassengerId'].apply(lambda x: x.split('_')[0])\n    fill_cols = ['HomePlanet', 'Destination', 'Cabin']\n    for col in fill_cols:\n        # 将col中空值填充为与该行有相同Group的值，否则用最常见的值填充\n        # data[col] = data.groupby('Group')[col].fillna(data[col].value_counts().idxmax())\n        groupby_col = data.groupby('Group', dropna=False)[col]\n        # print('group by', groupby_col.get_group('0064').value_counts().idxmax())\n        # print('group by', groupby_col.get_group('0064'))\n        for group in groupby_col.groups:\n            if groupby_col.get_group(group).isnull().any():\n                # 如果有空值\n                if(groupby_col.get_group(group).any()):\n                    data.loc[data['Group'] == group, col] = groupby_col.get_group(group).value_counts().idxmax()\n                else:\n                    data.loc[data['Group'] == group, col] = data[col].mode()[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:38.977997Z","iopub.execute_input":"2022-06-27T03:05:38.979083Z","iopub.status.idle":"2022-06-27T03:05:38.98704Z","shell.execute_reply.started":"2022-06-27T03:05:38.979026Z","shell.execute_reply":"2022-06-27T03:05:38.986027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'HomePlanet', 'Destination', 'Cabin' 的空值都被填充","metadata":{}},{"cell_type":"markdown","source":"其次 'Cabin' 也具有层次信息，deck和side对预测有帮助，可以新建列将数据分割","metadata":{}},{"cell_type":"code","source":"def split_cabin_info(data:pd.DataFrame):\n    data['Deck'] = data['Cabin'].apply(lambda x: x.split('/')[0])\n    data['Side'] = data['Cabin'].apply(lambda x: x.split('/')[2])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:40.50998Z","iopub.execute_input":"2022-06-27T03:05:40.510329Z","iopub.status.idle":"2022-06-27T03:05:40.516137Z","shell.execute_reply.started":"2022-06-27T03:05:40.510301Z","shell.execute_reply":"2022-06-27T03:05:40.51491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"之后填充其他数据的空值\n* 'age' 数据用平均值填充\n* 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck' 使用0填充\n* 'VIP' 中False压倒性的多，因此用False填充\n* 'CryoSleep' 也是用占大多数的False填充","metadata":{}},{"cell_type":"code","source":"def fill_other_null(data:pd.DataFrame):\n    fill_mean_cols = ['Age']\n    for col in fill_mean_cols:\n        data[col] = data[col].fillna(data[col].mean())\n    fill_zero_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n    for col in fill_zero_cols:\n        data[col] = data[col].fillna(0)\n    fill_false_cols = ['CryoSleep', 'VIP']\n    for col in fill_false_cols:\n        data[col] = data[col].fillna(False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:41.673702Z","iopub.execute_input":"2022-06-27T03:05:41.674061Z","iopub.status.idle":"2022-06-27T03:05:41.680746Z","shell.execute_reply.started":"2022-06-27T03:05:41.674024Z","shell.execute_reply":"2022-06-27T03:05:41.679284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'Name' 数据和 'PassengerId' 、'Group'在预测中没有用，因此直接删除该列，同时Cabin的有效信息也被分离，同样可以删除","metadata":{}},{"cell_type":"code","source":"def del_cols(data:pd.DataFrame):\n    del_cols = ['PassengerId', 'Name', 'Group', 'Cabin']\n    data.drop(del_cols, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:42.673552Z","iopub.execute_input":"2022-06-27T03:05:42.673937Z","iopub.status.idle":"2022-06-27T03:05:42.679483Z","shell.execute_reply.started":"2022-06-27T03:05:42.673906Z","shell.execute_reply":"2022-06-27T03:05:42.678226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"除了上述处理外，string类型数据，还要转化为数字类型","metadata":{}},{"cell_type":"code","source":"def preprocess(data:pd.DataFrame):\n    new_data = data.copy()\n    fill_null_according_PassengerId(new_data)\n    split_cabin_info(new_data)\n    fill_other_null(new_data)\n    del_cols(new_data)\n    for col in new_data.columns:\n        if new_data[col].dtype == 'object' or new_data[col].dtype == 'bool':\n            encoder = LabelEncoder()\n            encoder.fit(new_data[col])\n            new_data[col] = encoder.transform(new_data[col])\n    return new_data\n\nprocessed_train = preprocess(train_data)\nprint(processed_train.isnull().sum())\nprocessed_test = preprocess(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:44.533515Z","iopub.execute_input":"2022-06-27T03:05:44.534239Z","iopub.status.idle":"2022-06-27T03:05:51.990447Z","shell.execute_reply.started":"2022-06-27T03:05:44.534193Z","shell.execute_reply":"2022-06-27T03:05:51.989188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_mat = processed_train[processed_train.columns].corr(method='spearman')\ncorr = corr_mat['Transported'].drop('Transported').sort_values(ascending=False)\nprint(corr)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:05:51.992218Z","iopub.execute_input":"2022-06-27T03:05:51.99274Z","iopub.status.idle":"2022-06-27T03:05:52.013495Z","shell.execute_reply.started":"2022-06-27T03:05:51.992703Z","shell.execute_reply":"2022-06-27T03:05:52.012395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学习","metadata":{}},{"cell_type":"markdown","source":"## 基础决策树","metadata":{}},{"cell_type":"code","source":"clf = tree.DecisionTreeClassifier(max_depth=5)\nprint(processed_train)\ntrain_data = processed_train.drop('Transported', axis=1)\nclf.fit(train_data, processed_train['Transported'])\nimport graphviz \ndot_data = tree.export_graphviz(clf, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"spaceship\") ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T03:29:45.090697Z","iopub.execute_input":"2022-06-27T03:29:45.091153Z","iopub.status.idle":"2022-06-27T03:29:45.182301Z","shell.execute_reply.started":"2022-06-27T03:29:45.091114Z","shell.execute_reply":"2022-06-27T03:29:45.18083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = clf.predict(processed_test)\nid_col = test_data['PassengerId']\nresult_df = pd.DataFrame(result, columns=['Transported'])\nresult_df['PassengerId'] = id_col\n\nresult_df = result_df[['PassengerId', 'Transported']]\nresult_df.replace(0, 'False', inplace=True)\nresult_df.replace(1, 'True', inplace=True)\nresult_df.to_csv('/kaggle/working/dicision_tree_result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:20.178215Z","iopub.execute_input":"2022-06-27T01:42:20.178682Z","iopub.status.idle":"2022-06-27T01:42:20.206159Z","shell.execute_reply.started":"2022-06-27T01:42:20.178636Z","shell.execute_reply":"2022-06-27T01:42:20.20457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM","metadata":{}},{"cell_type":"code","source":"SVC_clf = SVC(kernel='rbf', C=1, gamma=0.1)\nSVC_clf.fit(train_data, processed_train['Transported'])\nresult = SVC_clf.predict(processed_test)\nid_col = test_data['PassengerId']\nresult_df = pd.DataFrame(result, columns=['Transported'])\nresult_df['PassengerId'] = id_col\nresult_df = result_df[['PassengerId', 'Transported']]\nresult_df.replace(0, 'False', inplace=True)\nresult_df.replace(1, 'True', inplace=True)\nresult_df.to_csv('/kaggle/working/SVM_result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:20.207923Z","iopub.execute_input":"2022-06-27T01:42:20.208395Z","iopub.status.idle":"2022-06-27T01:42:27.325796Z","shell.execute_reply.started":"2022-06-27T01:42:20.208356Z","shell.execute_reply":"2022-06-27T01:42:27.324114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adaboost","metadata":{}},{"cell_type":"code","source":"Ada_clf = AdaBoostClassifier(n_estimators=100)\nAda_clf.fit(train_data, processed_train['Transported'])\nresult = Ada_clf.predict(processed_test)\nid_col = test_data['PassengerId']\nresult_df = pd.DataFrame(result, columns=['Transported'])\nresult_df['PassengerId'] = id_col\nresult_df = result_df[['PassengerId', 'Transported']]\nresult_df.replace(0, 'False', inplace=True)\nresult_df.replace(1, 'True', inplace=True)\nresult_df.to_csv('/kaggle/working/Ada_result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:27.328174Z","iopub.execute_input":"2022-06-27T01:42:27.328609Z","iopub.status.idle":"2022-06-27T01:42:28.157804Z","shell.execute_reply.started":"2022-06-27T01:42:27.328574Z","shell.execute_reply":"2022-06-27T01:42:28.156293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 神经网络","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:28.160695Z","iopub.execute_input":"2022-06-27T01:42:28.161125Z","iopub.status.idle":"2022-06-27T01:42:30.190497Z","shell.execute_reply.started":"2022-06-27T01:42:28.161089Z","shell.execute_reply":"2022-06-27T01:42:30.188957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:30.192445Z","iopub.execute_input":"2022-06-27T01:42:30.193431Z","iopub.status.idle":"2022-06-27T01:42:30.201011Z","shell.execute_reply.started":"2022-06-27T01:42:30.193377Z","shell.execute_reply":"2022-06-27T01:42:30.199747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NN(torch.nn.Module):\n    def __init__(self):\n        super(NN, self).__init__()\n        self.layer1 = nn.Linear(12, 20)\n        self.layer2 = nn.Linear(20, 40)\n        self.layer3 = nn.Linear(40, 2)\n    def forward(self, input_tensor):\n        out = self.layer1(input_tensor)\n        out = F.relu(out)\n        out = self.layer2(out)\n        out = F.relu(out)\n        out = self.layer3(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:30.202358Z","iopub.execute_input":"2022-06-27T01:42:30.204049Z","iopub.status.idle":"2022-06-27T01:42:30.222379Z","shell.execute_reply.started":"2022-06-27T01:42:30.203987Z","shell.execute_reply":"2022-06-27T01:42:30.221003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataSet(Dataset):\n    def __init__(self, data:pd.DataFrame):\n        self.data = data\n        train_data = self.data.drop('Transported', axis=1)\n        self.train_data = torch.from_numpy(train_data[7000:].values).float()\n        label = self.data['Transported']\n        self.label = torch.from_numpy(label[7000:].values).float()\n    def __getitem__(self, index):\n        return self.train_data[index], self.label[index]\n    def __len__(self):\n        return len(self.train_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:30.224354Z","iopub.execute_input":"2022-06-27T01:42:30.225323Z","iopub.status.idle":"2022-06-27T01:42:30.237959Z","shell.execute_reply.started":"2022-06-27T01:42:30.225268Z","shell.execute_reply":"2022-06-27T01:42:30.236684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data:pd.DataFrame, epochs):\n    dataset = MyDataSet(data)\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n    model = NN().to(device)\n    criterion = nn.CrossEntropyLoss().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    for epoch in range(epochs):\n        for i, (data, label) in enumerate(dataloader):\n            data = data.to(device)\n            label = label.type(torch.LongTensor).to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, label)\n            loss.backward()\n            optimizer.step()\n            if i % 100 == 0:\n                print('epoch:', epoch, 'loss:', loss.item())\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:30.240185Z","iopub.execute_input":"2022-06-27T01:42:30.240915Z","iopub.status.idle":"2022-06-27T01:42:30.256425Z","shell.execute_reply.started":"2022-06-27T01:42:30.240872Z","shell.execute_reply":"2022-06-27T01:42:30.25517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train(processed_train, 10)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:30.258Z","iopub.execute_input":"2022-06-27T01:42:30.259265Z","iopub.status.idle":"2022-06-27T01:42:30.925566Z","shell.execute_reply.started":"2022-06-27T01:42:30.259175Z","shell.execute_reply":"2022-06-27T01:42:30.923919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_data = train_data[7000:]\neval_label = processed_train['Transported']\neval_label = eval_label[7000:]\nlength = eval_data.shape[0]\nright = 0\nfor i in range(length):\n    # evaluate model\n    data = torch.from_numpy(eval_data.iloc[i].values).float().to(device)\n    label = eval_label.iloc[i]\n    output = model(data)\n    predicted = torch.argmax(output, 0)\n    if predicted == label:\n        right += 1\nprint('acc:', right/length)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:30.929506Z","iopub.execute_input":"2022-06-27T01:42:30.930283Z","iopub.status.idle":"2022-06-27T01:42:31.601392Z","shell.execute_reply.started":"2022-06-27T01:42:30.930224Z","shell.execute_reply":"2022-06-27T01:42:31.600034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = torch.from_numpy(processed_test.values).float().to(device)\npredict = model(data)\npredict = torch.argmax(predict, 1)\npredict = predict.to('cpu')\npredict = predict.numpy()\n\ntest_data = pd.read_csv(test_file)\nid_col = test_data['PassengerId']\nresult_df = pd.DataFrame(predict, columns=['Transported'])\nresult_df['PassengerId'] = id_col\nresult_df = result_df[['PassengerId', 'Transported']]\nresult_df.replace(0, 'False', inplace=True)\nresult_df.replace(1, 'True', inplace=True)\nresult_df.to_csv('/kaggle/working/nn_result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:42:31.603494Z","iopub.execute_input":"2022-06-27T01:42:31.603864Z","iopub.status.idle":"2022-06-27T01:42:31.654258Z","shell.execute_reply.started":"2022-06-27T01:42:31.603831Z","shell.execute_reply":"2022-06-27T01:42:31.65279Z"},"trusted":true},"execution_count":null,"outputs":[]}]}