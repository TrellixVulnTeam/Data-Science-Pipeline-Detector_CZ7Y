{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom copy import copy\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.392711,"end_time":"2022-05-27T16:29:33.485278","exception":false,"start_time":"2022-05-27T16:29:32.092567","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:54:39.018408Z","iopub.execute_input":"2022-05-30T18:54:39.018738Z","iopub.status.idle":"2022-05-30T18:54:39.033195Z","shell.execute_reply.started":"2022-05-30T18:54:39.018708Z","shell.execute_reply":"2022-05-30T18:54:39.032009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this competition your task is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal records recovered from the ship's **damaged** computer system.","metadata":{"papermill":{"duration":0.06538,"end_time":"2022-05-27T16:29:33.746634","exception":false,"start_time":"2022-05-27T16:29:33.681254","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"`PassengerId` - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. **People in a group are often family members, but not always**.\n\n\n`HomePlanet` - The planet the passenger departed from, typically their planet of permanent residence.\n\n\n`CryoSleep` - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n\n\n`Cabin` - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n\n\n`Destination` - The planet the passenger will be debarking to.\n\n\n`Age` - The age of the passenger.\n\n\n`VIP` - Whether the passenger has paid for special VIP service during the voyage.\n\n\n`RoomService`, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n\n\n`Name` - The first and last names of the passenger.\n\n\n`Transported` - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.","metadata":{"papermill":{"duration":0.064604,"end_time":"2022-05-27T16:29:33.876503","exception":false,"start_time":"2022-05-27T16:29:33.811899","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Loading data + preprocessing","metadata":{"papermill":{"duration":0.064542,"end_time":"2022-05-27T16:29:34.007287","exception":false,"start_time":"2022-05-27T16:29:33.942745","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_orig = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n#df_orig = pd.read_csv('data/train.csv')\n\n\ndef preprocess_df(df_orig, dropna = True):\n    df_orig = df_orig.copy()\n    df_orig.replace({False: 0, True: 1}, inplace=True)\n    \n    if dropna:\n        print('DROPPING NANs')\n        df_orig = df_orig.dropna()\n    else:    \n        print('FILLING NANs with median')\n        df_orig = df_orig.fillna(df_orig.median())\n        \n    df_orig.head()\n\n    #grouping data and making new columns\n    df = df_orig.copy()\n\n    #get deck, number and side\n    df[['deck','num', 'side']] = df_orig['Cabin'].str.split('/', expand=True)\n\n    #get passenger group, and put it into integer format\n    df['Passenger_group'] = df_orig['PassengerId'].str.split('_', expand=True).loc[:, 0]\n    df['Passenger_group'] = df['Passenger_group'].apply(lambda gr_str: int(gr_str))\n\n    #group by passenger group and count number of people in a group\n    gr_tmp = df.groupby('Passenger_group')['HomePlanet'].agg(['count'])\n\n    #assign each passenger the number of people in his group\n    df['Passenger_group_size'] = df['Passenger_group'].apply(lambda x: gr_tmp.loc[x])   \n\n    #drop stuff\n    df.drop(['Cabin'], axis = 1, inplace = True)\n    df.drop(['PassengerId'], axis = 1, inplace = True)\n    df.drop(['Passenger_group'], axis = 1, inplace = True)\n    df.drop(['num'], axis = 1, inplace = True) #I assume the number of the room does not matter. It has ~1700 unique values out of the 6600 entries\n    df.drop(['Name'], axis = 1, inplace = True) # and name also!\n    df['side']=df['side'].apply(lambda x: int(x=='P')) #side would be 1 if it is P (portside)    \n     \n    \n    df_numeric = pd.get_dummies(df, columns = ['HomePlanet', 'Destination', 'deck'])\n        \n        \n    return df, df_numeric\n\ndf, df_numeric = preprocess_df(df_orig)\n\ndf_numeric.head(5)","metadata":{"papermill":{"duration":0.212359,"end_time":"2022-05-27T16:29:34.288852","exception":false,"start_time":"2022-05-27T16:29:34.076493","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T19:05:49.643478Z","iopub.execute_input":"2022-05-30T19:05:49.644132Z","iopub.status.idle":"2022-05-30T19:05:50.718538Z","shell.execute_reply.started":"2022-05-30T19:05:49.644091Z","shell.execute_reply":"2022-05-30T19:05:50.717674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis","metadata":{"papermill":{"duration":0.069322,"end_time":"2022-05-27T16:29:34.42578","exception":false,"start_time":"2022-05-27T16:29:34.356458","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Note that the `CryoSleep` has quite impact on the teleportation rate.","metadata":{"papermill":{"duration":0.065452,"end_time":"2022-05-27T16:29:36.599322","exception":false,"start_time":"2022-05-27T16:29:36.53387","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df.groupby(['CryoSleep', 'HomePlanet'])['Transported'].agg(['mean', 'count'])","metadata":{"papermill":{"duration":0.096449,"end_time":"2022-05-27T16:29:36.762664","exception":false,"start_time":"2022-05-27T16:29:36.666215","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:54:40.50427Z","iopub.execute_input":"2022-05-30T18:54:40.50449Z","iopub.status.idle":"2022-05-30T18:54:40.520927Z","shell.execute_reply.started":"2022-05-30T18:54:40.504464Z","shell.execute_reply":"2022-05-30T18:54:40.519896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print top correlations with `transported`:","metadata":{"papermill":{"duration":0.073794,"end_time":"2022-05-27T16:29:38.792339","exception":false,"start_time":"2022-05-27T16:29:38.718545","status":"completed"},"tags":[]}},{"cell_type":"code","source":"corr = df_numeric.corr()\n#fig, ax = plt.subplots(figsize=(18, 18))\n#sns.heatmap(corr, ax=ax, annot=True)\n#plt.show()\n\ncorr['Transported'].apply(lambda x: np.abs(x)).sort_values(ascending = False)","metadata":{"papermill":{"duration":0.095633,"end_time":"2022-05-27T16:29:38.960808","exception":false,"start_time":"2022-05-27T16:29:38.865175","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:54:40.522244Z","iopub.execute_input":"2022-05-30T18:54:40.523141Z","iopub.status.idle":"2022-05-30T18:54:40.546269Z","shell.execute_reply.started":"2022-05-30T18:54:40.523103Z","shell.execute_reply":"2022-05-30T18:54:40.545392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import phik\n#fig, ax = plt.subplots(figsize=(18, 18))\n#sns.heatmap(df.phik_matrix(),  ax=ax, annot=True)\n#plt.show()\n#df.phik_matrix()['Transported'].apply(lambda x: np.abs(x)).sort_values(ascending = False)\n#from pandas_profiling import ProfileReport\n#train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n#profile = ProfileReport(train_df, title=\"Pandas Profiling Report\")\n#profile","metadata":{"papermill":{"duration":3.98761,"end_time":"2022-05-27T16:29:46.697802","exception":false,"start_time":"2022-05-27T16:29:42.710192","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:54:40.549742Z","iopub.execute_input":"2022-05-30T18:54:40.549989Z","iopub.status.idle":"2022-05-30T18:54:40.554167Z","shell.execute_reply.started":"2022-05-30T18:54:40.549953Z","shell.execute_reply":"2022-05-30T18:54:40.553265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{"papermill":{"duration":0.085891,"end_time":"2022-05-27T16:29:48.205262","exception":false,"start_time":"2022-05-27T16:29:48.119371","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Data preprocessing for models","metadata":{"papermill":{"duration":0.093376,"end_time":"2022-05-27T16:29:48.385866","exception":false,"start_time":"2022-05-27T16:29:48.29249","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n\n","metadata":{"papermill":{"duration":0.409807,"end_time":"2022-05-27T16:29:48.884237","exception":false,"start_time":"2022-05-27T16:29:48.47443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:54:40.555881Z","iopub.execute_input":"2022-05-30T18:54:40.556196Z","iopub.status.idle":"2022-05-30T18:54:40.5669Z","shell.execute_reply.started":"2022-05-30T18:54:40.556155Z","shell.execute_reply":"2022-05-30T18:54:40.566239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numeric.columns","metadata":{"papermill":{"duration":0.10281,"end_time":"2022-05-27T16:29:49.24823","exception":false,"start_time":"2022-05-27T16:29:49.14542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:54:40.567834Z","iopub.execute_input":"2022-05-30T18:54:40.568088Z","iopub.status.idle":"2022-05-30T18:54:40.584006Z","shell.execute_reply.started":"2022-05-30T18:54:40.568059Z","shell.execute_reply":"2022-05-30T18:54:40.583152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do NOT scale categorical columns. Scale only numerical:","metadata":{"papermill":{"duration":0.091191,"end_time":"2022-05-27T16:29:49.429338","exception":false,"start_time":"2022-05-27T16:29:49.338147","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\ndef scale_data(df_numeric):\n    cols_to_scale = ['Age','RoomService', 'FoodCourt','ShoppingMall', 'Spa', 'VRDeck', 'Passenger_group_size']\n\n    scaler = sklearn.preprocessing.StandardScaler()\n    df_numeric_scaled = copy(df_numeric)\n    scaler.fit(df_numeric[cols_to_scale])\n    df_numeric_scaled[cols_to_scale] = scaler.transform(df_numeric[cols_to_scale])\n    return df_numeric_scaled, scaler, cols_to_scale\n\ndf_numeric_scaled, scaler, cols_to_scale = scale_data(df_numeric)","metadata":{"papermill":{"duration":0.102368,"end_time":"2022-05-27T16:29:49.624889","exception":false,"start_time":"2022-05-27T16:29:49.522521","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:56:10.700214Z","iopub.execute_input":"2022-05-30T18:56:10.700659Z","iopub.status.idle":"2022-05-30T18:56:10.713858Z","shell.execute_reply.started":"2022-05-30T18:56:10.700629Z","shell.execute_reply":"2022-05-30T18:56:10.713035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test/train(/cv) split\nX = df_numeric_scaled.loc[:, df_numeric_scaled.columns != 'Transported']\ny = df_numeric_scaled['Transported']\n\n\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y, test_size = 0.3, random_state = 42)\nprint(X_train.shape, y_train.shape,X_test.shape,y_test.shape)","metadata":{"papermill":{"duration":0.107736,"end_time":"2022-05-27T16:29:50.925435","exception":false,"start_time":"2022-05-27T16:29:50.817699","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:56:13.73212Z","iopub.execute_input":"2022-05-30T18:56:13.732421Z","iopub.status.idle":"2022-05-30T18:56:13.745848Z","shell.execute_reply.started":"2022-05-30T18:56:13.732383Z","shell.execute_reply":"2022-05-30T18:56:13.744689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: k-nearest neighbors classifier","metadata":{"papermill":{"duration":0.093212,"end_time":"2022-05-27T16:29:51.108769","exception":false,"start_time":"2022-05-27T16:29:51.015557","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nparam_grid = {'n_neighbors': np.arange(1,50,2)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, param_grid, cv = 3, verbose = 1)\nknn_cv.fit(X_train,y_train)\n\nprint('best par knn:', knn_cv.best_params_)\nprint('best score knn:', knn_cv.best_score_)\n\ny_pred_knn = knn_cv.predict(X_test)\nscore_knn = knn_cv.score(X_test,y_test)\nprint(f'knn  score: {score_knn}')","metadata":{"papermill":{"duration":27.424852,"end_time":"2022-05-27T16:30:20.043851","exception":false,"start_time":"2022-05-27T16:29:52.618999","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:55:32.447588Z","iopub.execute_input":"2022-05-30T18:55:32.448165Z","iopub.status.idle":"2022-05-30T18:55:47.649099Z","shell.execute_reply.started":"2022-05-30T18:55:32.448112Z","shell.execute_reply":"2022-05-30T18:55:47.648092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: logistic regression","metadata":{"papermill":{"duration":0.092493,"end_time":"2022-05-27T16:30:22.07554","exception":false,"start_time":"2022-05-27T16:30:21.983047","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(penalty = 'l2',  max_iter = 500)\nlogreg_cv = GridSearchCV(logreg, {'C': [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2]}, cv = 5, verbose = 1)\nlogreg_cv.fit(X_train, y_train)\n\nprint('best par logreg:', logreg_cv.best_params_)\nprint('best score logreg:', logreg_cv.best_score_)\n\nscore_logreg = logreg_cv.score(X_test,y_test)\nprint(f\"logreg score: {score_logreg}\")","metadata":{"papermill":{"duration":0.326822,"end_time":"2022-05-27T16:30:22.498842","exception":false,"start_time":"2022-05-27T16:30:22.17202","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:56:17.151395Z","iopub.execute_input":"2022-05-30T18:56:17.151831Z","iopub.status.idle":"2022-05-30T18:56:18.888615Z","shell.execute_reply.started":"2022-05-30T18:56:17.151801Z","shell.execute_reply":"2022-05-30T18:56:18.887679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3: Random Forest","metadata":{"papermill":{"duration":0.097343,"end_time":"2022-05-27T16:30:23.857109","exception":false,"start_time":"2022-05-27T16:30:23.759766","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nn_estimators = [30, 250,  500] # number of trees in the random forest\nmax_features = ['auto'] # number of features in consideration at every split\nmax_depth = [int(x) for x in np.linspace(10, 150, 5)] # maximum number of levels allowed in each decision tree\nmin_samples_split = [5, 10] # minimum sample number to split a node\nmin_samples_leaf = [3, 6] # minimum sample number that can be stored in a leaf node\nbootstrap = [True] # method used to sample data points\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf = RandomForestClassifier(random_state=42)\n\nrf_cv = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n                               n_iter=120, cv=5, verbose=1, random_state=35, n_jobs=-1)\n\nrf_cv.fit(X_train, y_train)\n\n\n\nprint('best par rf:', rf_cv.best_params_)\nprint('best score rf:', rf_cv.best_score_)\n\nscore_rf = rf_cv.score(X_test,y_test)\nprint(f\"rf score: {score_rf}\")","metadata":{"papermill":{"duration":1.247355,"end_time":"2022-05-27T16:30:25.203438","exception":false,"start_time":"2022-05-27T16:30:23.956083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:57:04.24412Z","iopub.execute_input":"2022-05-30T18:57:04.244443Z","iopub.status.idle":"2022-05-30T18:59:06.036126Z","shell.execute_reply.started":"2022-05-30T18:57:04.244404Z","shell.execute_reply":"2022-05-30T18:59:06.035105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 4: SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nparam_grid = {'C': [1e0,1e1,1e2, 1e3],\n              #'gamma': [0.1, 0.01, 0.001, 0.0001]}\n              'gamma': ['auto', 'scale']}\n \nsvm_cv = GridSearchCV(SVC(), param_grid, refit=True, verbose=1)\n \nsvm_cv.fit(X_train, y_train)\n\n\n\nprint('best par svm:', svm_cv.best_params_)\nprint('best score svm:', svm_cv.best_score_)\n\n\nscore_svm = svm_cv.score(X_test,y_test)\nprint(f\"svm score: {score_svm}\")\n","metadata":{"papermill":{"duration":0.106792,"end_time":"2022-05-27T16:30:26.549087","exception":false,"start_time":"2022-05-27T16:30:26.442295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-30T18:59:14.162056Z","iopub.execute_input":"2022-05-30T18:59:14.162812Z","iopub.status.idle":"2022-05-30T19:00:34.187543Z","shell.execute_reply.started":"2022-05-30T18:59:14.162766Z","shell.execute_reply":"2022-05-30T19:00:34.186473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 5: Multi-layer perceptrons (artificial neural network)","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nparam_grid = {'alpha': [1e-2, 1e-1, 1e0,1e1,1e2,],\n             'hidden_layer_sizes': [(10,3), (20,3), (10,5), (20,5)],\n             'learning_rate': ['adaptive', 'constant']}\n \n\nnn = MLPClassifier(max_iter = 500)\n\nnn_cv = RandomizedSearchCV(estimator=nn, param_distributions=param_grid, cv=5, verbose=1, random_state=35, n_jobs=-1)\n\nnn_cv.fit(X_train, y_train)\n\n\n\nprint('best par nn:', nn_cv.best_params_)\nprint('best score nn:', nn_cv.best_score_)\n\nscore_nn = nn_cv.score(X_test,y_test)\nprint(f\"nn score: {score_nn}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:00:34.189736Z","iopub.execute_input":"2022-05-30T19:00:34.190081Z","iopub.status.idle":"2022-05-30T19:01:48.728964Z","shell.execute_reply.started":"2022-05-30T19:00:34.190034Z","shell.execute_reply":"2022-05-30T19:01:48.728009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compile results","metadata":{}},{"cell_type":"code","source":"print(f\"score_knn={score_knn:.3f}\")\nprint(f\"score_logreg={score_logreg:.3f}\")\nprint(f\"score_rf={score_rf:.3f}\")\nprint(f\"score_svm={score_svm:.3f}\")\nprint(f\"score_nn={score_nn:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:01:52.971844Z","iopub.execute_input":"2022-05-30T19:01:52.972166Z","iopub.status.idle":"2022-05-30T19:01:52.978323Z","shell.execute_reply.started":"2022-05-30T19:01:52.972137Z","shell.execute_reply":"2022-05-30T19:01:52.977381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit the best model. I opt here the Random Forest classifier we trained above.","metadata":{}},{"cell_type":"code","source":"!head /kaggle/input/spaceship-titanic/sample_submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:07:47.205644Z","iopub.execute_input":"2022-05-30T19:07:47.205953Z","iopub.status.idle":"2022-05-30T19:07:47.960778Z","shell.execute_reply.started":"2022-05-30T19:07:47.2059Z","shell.execute_reply":"2022-05-30T19:07:47.959996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_orig = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n\ndf_test,df_test_numeric = preprocess_df(df_test_orig, dropna = False)\n\ndf_test_numeric_scaled = copy(df_test_numeric)\ndf_test_numeric_scaled[cols_to_scale] = scaler.transform(df_test_numeric_scaled[cols_to_scale])\ndf_test_numeric_scaled.head()\n\n\ntest_prediction = rf_cv.predict(df_test_numeric_scaled)\ndf_test_numeric_scaled['Transported'] = test_prediction\nmy_submission = pd.DataFrame({'PassengerId': df_test_orig['PassengerId'], 'Transported': test_prediction.astype(bool)})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:10:14.171805Z","iopub.execute_input":"2022-05-30T19:10:14.17211Z","iopub.status.idle":"2022-05-30T19:10:15.092254Z","shell.execute_reply.started":"2022-05-30T19:10:14.172078Z","shell.execute_reply":"2022-05-30T19:10:15.091282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_test = df_test_numeric_scaled.corr()\n#fig, ax = plt.subplots(figsize=(18, 18))\n#sns.heatmap(corr, ax=ax, annot=True)\n#plt.show()\n\ncorr_test['Transported'].apply(lambda x: np.abs(x)).sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:10:16.61805Z","iopub.execute_input":"2022-05-30T19:10:16.618353Z","iopub.status.idle":"2022-05-30T19:10:16.63689Z","shell.execute_reply.started":"2022-05-30T19:10:16.618319Z","shell.execute_reply":"2022-05-30T19:10:16.636308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}