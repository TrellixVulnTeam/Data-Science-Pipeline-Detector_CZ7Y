{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-11T06:42:54.810991Z","iopub.execute_input":"2022-04-11T06:42:54.811549Z","iopub.status.idle":"2022-04-11T06:42:54.841409Z","shell.execute_reply.started":"2022-04-11T06:42:54.811439Z","shell.execute_reply":"2022-04-11T06:42:54.840361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 개요\n[참고한 사이트](https://www.kaggle.com/code/heyrobin/spaceship-titanic-a-cosmic-mystery) SpaceTitanic Kaggle Competition 링크 글을 참고하여 코드를 따라쓰며 필자가 해석한 부분을 설명하면서 머신러닝에 대해 이해하기 위한 목적으로 작성하게 되었습니다.","metadata":{}},{"cell_type":"markdown","source":"<strong>Data</strong> - 승객의 약 3분의 2(~8700)에 대한 개인 기록은 훈련 데이터로 사용됩니다.\n<ul><li><code>PassengerId</code> - 각 승객의 고유 ID. 각 ID는 <code>gggg_pp</code> 형식을 취하며, 여기서 <code>gggg</code>는 승객이 함께 여행하는 그룹을 나타내며, <code>pp</code>는 그룹 내 번호를 나타냅니다. 그룹의 사람들은 대게 가족 구성원이지만 항상 그렇만은 않습니다.</li>\n<li><code>HomePlanet</code> - 승객이 출발한 행성으로, 일반적으로 그들의 영구 거주지 행성입니다.</li>\n<li><code>CryoSleep</code> - 객이 항해가 진행되는 동안 가사상태로 전환되도록 선택했는지 여부를 나타냅니다. 저온 수면 중인 승객들은 객실에 있게 된다.</li>\n<li><code>Cabin</code> - 승객이 머물고 있는 객실 번호입니다. 갑판/번호/측면<code>deck/num/side</code>형식을 취합니다. 여기서 측면<code>side</code>은 좌측이 <code>P</code>, <em>Port</em> 또는 우측이 <code>S</code>, <em>Starboard</em>가 될 수 있습니다.</li>\n<li><code>Destination</code> - 승객이 정박할 목적지 행성입니다.</li>\n<li><code>Age</code> - 승객의 나이를 나타냅니다.</li>\n<li><code>VIP</code> - 승객이 항해 중 특별 VIP 서비스를 위해 비용을 지불했는지 여부를 나타낸 것 입니다.</li>\n<li><code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code> - 승객들이 <em>Spaceship Titanic</em>의 많은 고급 편의시설에서 청구한 금액입니다. </li>\n<li><code>Name</code> - 승객들의 이름을 나타냅니다.</li>\n<li><code>Transported</code> - 승객이 다른 차원으로 이송되었는지 여부. 예측하려는 대상 열입니다.</li></ul></li>","metadata":{}},{"cell_type":"markdown","source":"# Step 1. 라이브러리 및 데이터 불러오기\n- 본 프로젝트 수행을 위한 필수 라이브러리를 불러온다.","metadata":{}},{"cell_type":"code","source":"'''Analysis(분석)'''\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\n\n'''Pre-Processing(데이터 전처리)'''\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n'''Model-Metrics(모형 개발 및 평가)'''\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore') # 경고 메세지 숨기기 참고사이트 [https://rfriend.tistory.com/346]\n\n'''Dataset'''\ntrain = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest = pd.read_csv('../input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:54.843248Z","iopub.execute_input":"2022-04-11T06:42:54.843568Z","iopub.status.idle":"2022-04-11T06:42:57.525424Z","shell.execute_reply.started":"2022-04-11T06:42:54.843525Z","shell.execute_reply":"2022-04-11T06:42:57.524466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model-Metrics 라이브러리 참고 사이트\n- [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n- [XGBClassifier](https://xgboost.readthedocs.io/en/stable/python/python_api.html)\n- [LGBMClassifier](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n- [CatBoostClassifier](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier)\n- [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n- [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n- [Classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), [Accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), [Confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)","metadata":{}},{"cell_type":"markdown","source":"- 라이브러리 버전 확인","metadata":{}},{"cell_type":"code","source":"print(np.__version__)\nprint(pd.__version__)\nprint(sns.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:57.52711Z","iopub.execute_input":"2022-04-11T06:42:57.527562Z","iopub.status.idle":"2022-04-11T06:42:57.53302Z","shell.execute_reply.started":"2022-04-11T06:42:57.527529Z","shell.execute_reply":"2022-04-11T06:42:57.532138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 데이터 확인\n    + 훈련데이터는 8,693개, 테스트 데이터는 4,277개로 구성이 되어 있음\n    + 독립변수 컬럼 갯수는 13개이며, 종속 변수는 1개로 구성되어 있음","metadata":{}},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:57.536653Z","iopub.execute_input":"2022-04-11T06:42:57.53689Z","iopub.status.idle":"2022-04-11T06:42:57.544371Z","shell.execute_reply.started":"2022-04-11T06:42:57.536862Z","shell.execute_reply":"2022-04-11T06:42:57.54345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:57.546113Z","iopub.execute_input":"2022-04-11T06:42:57.546463Z","iopub.status.idle":"2022-04-11T06:42:57.580035Z","shell.execute_reply.started":"2022-04-11T06:42:57.546429Z","shell.execute_reply":"2022-04-11T06:42:57.57942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:57.581092Z","iopub.execute_input":"2022-04-11T06:42:57.581417Z","iopub.status.idle":"2022-04-11T06:42:57.612748Z","shell.execute_reply.started":"2022-04-11T06:42:57.58139Z","shell.execute_reply":"2022-04-11T06:42:57.611913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 컬럼별 레이블의 개수 확인\n    + data_Frame.nunique() = 데이터셋에 존재하는 컬럼별 레이블의 개수를 확인하기 위해 사용","metadata":{}},{"cell_type":"code","source":"train.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:57.613982Z","iopub.execute_input":"2022-04-11T06:42:57.61441Z","iopub.status.idle":"2022-04-11T06:42:57.637639Z","shell.execute_reply.started":"2022-04-11T06:42:57.614377Z","shell.execute_reply":"2022-04-11T06:42:57.637088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 대회주제\n    + Transported Column 설명을 보면, 다른 차원으로 이동하기 위한, 각 승객의 탑승을 했는지 못했는지를 예측하는 문제이며, 평가지표는 정확도로 판정함.\n- 분류 정확도(Classification Accuracy)의 설명은 [Classification Accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy)에서 확인할 수 있다. ","metadata":{}},{"cell_type":"markdown","source":"# Step 2. 탐색적 자료 분석 (EDA)\n- 데이터 시각화\n- 산점도, 막대 그래프 등\n- 그래프 해석 및 설명\n- 약간의 데이터 전처리","metadata":{}},{"cell_type":"markdown","source":"- HomePlanet","metadata":{}},{"cell_type":"code","source":"from plotly.offline import iplot, init_notebook_mode\nfrom plotly.subplots import make_subplots\ninit_notebook_mode()\nimport plotly.graph_objs as go\n\ncnt_srs = train['HomePlanet'].value_counts()\n\ntrace = go.Scatter(\n    x = cnt_srs.index,\n    y = cnt_srs.values,\n    mode = 'markers',\n    marker = dict(\n        sizemode = 'diameter',\n        sizeref = 20,\n        size = cnt_srs.values,\n        color = ['#1D7595','#B9B596','#864D29']\n\n    ),\n)\n\nlayout = go.Layout(\n    title = '<b>Home Planets</b>', \n    title_x = 0.5,\n    titlefont = dict(size =20, color='black', family='Space Mono'),\n    plot_bgcolor = 'rgba(0,0,0,0)'\n)\n\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\nfig.update_xaxes(showline = True, linewidth = 2,\n                 #linecolor = colors[3]\n                )\nfig.update_yaxes(showline = True, linewidth = 2,\n                 #linecolor = colors[3]\n                )\npy.iplot(fig, filename = \"Size of the Company/Clan\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:56:54.757706Z","iopub.execute_input":"2022-04-11T06:56:54.758413Z","iopub.status.idle":"2022-04-11T06:56:54.90047Z","shell.execute_reply.started":"2022-04-11T06:56:54.758368Z","shell.execute_reply":"2022-04-11T06:56:54.899655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    + Earth: 4602\n    + Europa: 2131\n    + Mars: 1759","metadata":{}},{"cell_type":"markdown","source":"- Destination","metadata":{}},{"cell_type":"code","source":"from plotly.offline import iplot, init_notebook_mode\nfrom plotly.subplots import make_subplots\ninit_notebook_mode()\nimport plotly.graph_objs as go\n\ncnt_srs = train['Destination'].value_counts()\n\ntrace = go.Scatter(\n    x = cnt_srs.index,\n    y = cnt_srs.values,\n    mode = 'markers',\n    marker = dict(\n        sizemode = 'diameter',\n        sizeref = 20,\n        size = cnt_srs.values,\n        color = ['#048B95','#A1231F','#602F58']\n    ),\n)\n\n\n\nlayout = go.Layout(\n    title = '<b>Destination</b>', \n    title_x = 0.5,\n    titlefont = dict(size = 20, color = 'black', family = 'Space Mono'),\n    \n    plot_bgcolor = 'rgba(0,0,0,0)'\n)\n\nfig = go.Figure(data = [trace], layout = layout)\n\nsources = \"https://assets.stickpng.com/images/580b585b2edbce24c47b2d2a.png\"\n# add images\n\nfig.add_layout_image(\n        source=sources,\n        xref = \"x domain\",\n        yref = \"y domain\",\n        x = 0.2,\n        y = 0.8,\n        xanchor = \"right\",\n        yanchor = \"top\",\n        sizex = 1,\n        sizey = 0.7,\n        opacity = False\n    )\n\nfig.update_xaxes(showline=True, linewidth=2)\nfig.update_yaxes(showline=True, linewidth=2)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:57:09.23251Z","iopub.execute_input":"2022-04-11T06:57:09.232825Z","iopub.status.idle":"2022-04-11T06:57:09.319575Z","shell.execute_reply.started":"2022-04-11T06:57:09.232788Z","shell.execute_reply":"2022-04-11T06:57:09.319028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    + TRAPPIST-1e: 5915\n    + 55 Cancri e: 1800\n    + PSO J318.5-22: 796","metadata":{}},{"cell_type":"markdown","source":"- Age Distribution","metadata":{}},{"cell_type":"code","source":"from plotly.offline import iplot, init_notebook_mode\nfrom plotly.subplots import make_subplots\ninit_notebook_mode()\nimport plotly.graph_objs as go\n\ntrace = go.Histogram(x = train['Age'],\n                            histnorm = 'percent',\n                            xbins = dict(\n                                start = 0,\n                                end = 100,\n                                size = 1),\n                            marker_color = '#048B95',\n                            )\n\n\nlayout = go.Layout(\n    title = '<b>Age Distribution</b>',\n    title_x = 0.5,\n    titlefont = dict(size = 20, color = 'black', family = 'Space Mono'),\n    plot_bgcolor = 'rgba(0, 0, 0, 0)',\n    xaxis_title = 'Age',\n    yaxis_title = 'Percent'\n)\n\n\nfig = go.Figure(data = [trace], layout = layout)\n\nfig.update_xaxes(showline = True, linewidth = 2)\nfig.update_yaxes(showline = True, linewidth = 2)\n\npy.iplot(fig, filename = \"planets\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:57:17.639187Z","iopub.execute_input":"2022-04-11T06:57:17.639813Z","iopub.status.idle":"2022-04-11T06:57:17.767469Z","shell.execute_reply.started":"2022-04-11T06:57:17.639776Z","shell.execute_reply":"2022-04-11T06:57:17.766612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3. 데이터 전처리\n- Feature Engineering\n- ML 모형을 돌리기 위해 표준화 등\n- 파생변수 (도출 변수)\n    + 왜 이 변수를 만들었는지에 대한 설명 필요","metadata":{}},{"cell_type":"markdown","source":"- 필요없는 특성 정리\n    + drop(inplce = True) : 기존 프레임에 변경된 설정으로 덮어쓰겠다는 의미, 그렇기 때문에 다시 데이터 프레임을 가져왔을때 출력되지 않음.","metadata":{}},{"cell_type":"code","source":"# taking target variable and droping it\ny = train['Transported']\ntrain = train.drop('Transported', axis = 1)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:58.839015Z","iopub.execute_input":"2022-04-11T06:42:58.839456Z","iopub.status.idle":"2022-04-11T06:42:58.873847Z","shell.execute_reply.started":"2022-04-11T06:42:58.839422Z","shell.execute_reply":"2022-04-11T06:42:58.872939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 불필요한 변수 제거\n    + Name, PassengerId, Cabin\n    + Cabin은 모형 개선 시, 문자열 처리를 통해 추가 변수를 도출 할수는 있지만, 일단 제거한다.","metadata":{}},{"cell_type":"code","source":"#cols_to_drop = ['Name', 'PassengerId']\ncols_to_drop = ['Name', 'PassengerId', 'Cabin']\ndef drop(train,test,cols):\n    train.drop(cols, axis = 1, inplace = True)\n    test.drop(cols, axis = 1, inplace = True)\n    print('sucessfully droped features')\n    \ndrop(train, test, cols_to_drop)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:58.875358Z","iopub.execute_input":"2022-04-11T06:42:58.875902Z","iopub.status.idle":"2022-04-11T06:42:58.886583Z","shell.execute_reply.started":"2022-04-11T06:42:58.875857Z","shell.execute_reply":"2022-04-11T06:42:58.885735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:58.887887Z","iopub.execute_input":"2022-04-11T06:42:58.888223Z","iopub.status.idle":"2022-04-11T06:42:58.9212Z","shell.execute_reply.started":"2022-04-11T06:42:58.888178Z","shell.execute_reply":"2022-04-11T06:42:58.920019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train[['Deck', 'Num', 'Side']] = train['Cabin'].str.split('/', expand = True)\n#test[['Deck', 'Num', 'Side']] = train['Cabin'].str.split('/', expand=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:58.923319Z","iopub.execute_input":"2022-04-11T06:42:58.924404Z","iopub.status.idle":"2022-04-11T06:42:58.930803Z","shell.execute_reply.started":"2022-04-11T06:42:58.924352Z","shell.execute_reply":"2022-04-11T06:42:58.93013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 결측치에 넣을 categorical and numerical feature 파생 변수 생성","metadata":{}},{"cell_type":"code","source":"# getting categorical and numerical feature\ncat_col = [col for col in train.columns if train[col].dtype not in [\"float64\"]]\nnum_col = [col for col in train.columns if train[col].dtype in [\"float64\"]]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:58.931832Z","iopub.execute_input":"2022-04-11T06:42:58.932284Z","iopub.status.idle":"2022-04-11T06:42:58.943475Z","shell.execute_reply.started":"2022-04-11T06:42:58.932247Z","shell.execute_reply":"2022-04-11T06:42:58.942752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Handling Missing Values /Imputation (결측치)**\n- 결측치 데이터를 추가하도록 한다. 결측치를 추가하기 위해 필자는 [Sklearn.IterativeImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html) 클래스를 사용하였다.","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimputer = IterativeImputer(random_state = 0, max_iter = 10, initial_strategy = 'mean')\n\ntrain[num_col] = imputer.fit_transform(train[num_col])\ntest[num_col] = imputer.fit_transform(test[num_col])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:58.945117Z","iopub.execute_input":"2022-04-11T06:42:58.945975Z","iopub.status.idle":"2022-04-11T06:42:59.221648Z","shell.execute_reply.started":"2022-04-11T06:42:58.945925Z","shell.execute_reply":"2022-04-11T06:42:59.220622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[cat_col] = train[cat_col].fillna('Nan')\ntest[cat_col] = test[cat_col].fillna('Nan')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.227411Z","iopub.execute_input":"2022-04-11T06:42:59.230418Z","iopub.status.idle":"2022-04-11T06:42:59.256197Z","shell.execute_reply.started":"2022-04-11T06:42:59.227986Z","shell.execute_reply":"2022-04-11T06:42:59.255164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[cat_col]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.261762Z","iopub.execute_input":"2022-04-11T06:42:59.264601Z","iopub.status.idle":"2022-04-11T06:42:59.292551Z","shell.execute_reply.started":"2022-04-11T06:42:59.264517Z","shell.execute_reply":"2022-04-11T06:42:59.291595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[num_col]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.297951Z","iopub.execute_input":"2022-04-11T06:42:59.300871Z","iopub.status.idle":"2022-04-11T06:42:59.338095Z","shell.execute_reply.started":"2022-04-11T06:42:59.300775Z","shell.execute_reply":"2022-04-11T06:42:59.337144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Feature Encoding\n- 머신러닝 알고리즘은 수식으로 구성이 되어 있기 때문에 문자열의 경우 인코딩으로 변환을 주어야 한다. ","metadata":{}},{"cell_type":"markdown","source":"- 필자의 경우 [Labelencoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) 모델을 사용하여 인코딩 진행\n    + 문자열을 데이터 프레임형식으로 인코딩 후 훈련 진행","metadata":{}},{"cell_type":"code","source":"def label_encoder(df, df2, columns):\n    for col in columns:\n        df[col] = df[col].astype(str)\n        df2[col] = df2[col].astype(str)\n        df[col] = LabelEncoder().fit_transform(df[col])\n        df2[col] = LabelEncoder().fit_transform(df2[col])\n    return df\n\nlabel_encoder(train,test,cat_col)\ntype(label_encoder(train,test,cat_col))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.339696Z","iopub.execute_input":"2022-04-11T06:42:59.340199Z","iopub.status.idle":"2022-04-11T06:42:59.460491Z","shell.execute_reply.started":"2022-04-11T06:42:59.340156Z","shell.execute_reply":"2022-04-11T06:42:59.459617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4. 머신러닝 모형 개발\n- 모형에 대한 설명 필요\n- 모형을 1-2개 사용\n- 교차 검증\n- 하이퍼 파라미터 튜닝","metadata":{}},{"cell_type":"markdown","source":"- 훈련데이터와 검증데이터 분리 및 교차 검증 3회 적용.","metadata":{}},{"cell_type":"code","source":"X = train\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.461724Z","iopub.execute_input":"2022-04-11T06:42:59.462428Z","iopub.status.idle":"2022-04-11T06:42:59.471419Z","shell.execute_reply.started":"2022-04-11T06:42:59.462379Z","shell.execute_reply":"2022-04-11T06:42:59.470469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 적용 할 모형(모델)별 스코어 확인\n    + Dictionary 형식으로 name 과 values 값을 형성하여 for 문 사용\n    + 선형회귀, K-최근접이웃, 서포트벡터, 결정트리, XGB, LightGBM 클래스를 사용하여 모형(모델)별 정확도 비교","metadata":{}},{"cell_type":"code","source":"models = {\"LogisticClassifier\":LogisticRegression(solver='liblinear'),\n          \"KNearest\": KNeighborsClassifier(),\n          \"Support Vector Classifier\": SVC(),\n          \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n          \"XGBClassifier\":XGBClassifier(),\n          \"LightLGBM Classifier\":LGBMClassifier(),\n          #\"CatBoostClassifier\":CatBoostClassifier()\n          }","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.472762Z","iopub.execute_input":"2022-04-11T06:42:59.47302Z","iopub.status.idle":"2022-04-11T06:42:59.480797Z","shell.execute_reply.started":"2022-04-11T06:42:59.472968Z","shell.execute_reply":"2022-04-11T06:42:59.480133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, vals in models.items():\n    model = vals.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    score = accuracy_score(y_test,y_pred)\n    print(f'{name} accuracy is {score}')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:42:59.481963Z","iopub.execute_input":"2022-04-11T06:42:59.482703Z","iopub.status.idle":"2022-04-11T06:43:02.26566Z","shell.execute_reply.started":"2022-04-11T06:42:59.482658Z","shell.execute_reply":"2022-04-11T06:43:02.264999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- LightLGBM Classifier 모델이 0.789로 가장 높은 스코어를 가진것을 확인","metadata":{}},{"cell_type":"markdown","source":"# Step 5. 모형 평가\n- 훈련데이터 쪼갠다. 훈련데이터 + 검증데이터 분리\n- 정확도 비교\n- 혼동 행렬 (Confusion Matrix) 설명 ** [오분류비용](http://contents.kocw.net/KOCW/document/2014/Chungbuk/choisanghyun/6.pdf)","metadata":{}},{"cell_type":"markdown","source":"- optuna 사용하여 최적의 하이퍼파라미터 확인\n    + 그리드 서치는 시간이 조금 오래 걸릴 뿐만 아니라, 하이퍼 파라미터 값을 직접 지정해주어야 한다는 단점이 있다. Optuna도 물론 값을 지정해주어야 하지만, 조금 더 러프하게 값을 지정해주면, Optuna가 범위내에서 자동탐색을 통해 최적의 하이퍼파라미터를 도출해준다는 점과 시간이 조금 더 빠르다는 점에서 GridSearchCV보다 좋은 것 같다. [설명 출처 사이트](https://hojjimin-statistic.tistory.com/27)","metadata":{}},{"cell_type":"code","source":"'''import optuna\nfrom sklearn.model_selection import cross_val_score\n\n# LGBM 하이퍼 파라미터 값 지정\ndef objective(trial):\n             \n      n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n      learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n      num_leaves = trial.suggest_int(\"num_leaves\", 20, 3000, step=20)\n      max_depth = trial.suggest_int(\"max_depth\", 3, 12)\n      min_data_in_leaf = trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100)\n      lambda_l1 = trial.suggest_int(\"lambda_l1\", 0, 100, step=5)\n      lambda_l2 = trial.suggest_int(\"lambda_l2\", 0, 100, step=5)\n      min_gain_to_split = trial.suggest_float(\"min_gain_to_split\", 0, 15)\n      bagging_fraction = trial.suggest_float(\"bagging_fraction\", 0.2, 0.95, step=0.1)\n      bagging_freq = trial.suggest_categorical(\"bagging_freq\", [1])\n      feature_fraction = trial.suggest_float(\"feature_fraction\", 0.2, 0.95, step=0.1)\n      \n      # LGBM 클래스로 학습 모델 설정\n      lgbc = LGBMClassifier(n_estimators=n_estimators,\n                            #max_depth=max_depth,\n                            learning_rate=learning_rate,\n                            #num_leaves =num_leaves,\n                            max_depth=max_depth,\n                            min_data_in_leaf=min_data_in_leaf,\n                            #lambda_l1=lambda_l1,\n                            #lambda_l2=lambda_l2,\n                            #min_gain_to_split=min_gain_to_split,\n                            #bagging_fraction=bagging_fraction,\n                            #bagging_freq=bagging_freq,\n                            #feature_fraction=feature_fraction\n                           )\n    \n      return cross_val_score(lgbc,\n                             X,\n                             y,\n                             n_jobs=-1,\n                             cv=3).mean()                             \nstudy = optuna.create_study(direction='maximize') # MAE(평균절대오차)가 최대가 되는 방향으로 학습을 진행\nstudy.optimize(objective, n_trials=100)           # n_trials 지정해주지 않으면, 무한 반복\n\ntrial = study.best_trial\nprint('Accuracy: {}'.format(trial.value))\n\nprint(\"Best hyperparameters: {}\".format(trial.params))\n\nbest_params = trial.params\n\n'''","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:43:02.267038Z","iopub.execute_input":"2022-04-11T06:43:02.267546Z","iopub.status.idle":"2022-04-11T06:43:02.277049Z","shell.execute_reply.started":"2022-04-11T06:43:02.267509Z","shell.execute_reply":"2022-04-11T06:43:02.276297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Accuracy: 0.7977694653941446\n- Best hyperparameters: {'n_estimators': 68, 'learning_rate': 0.14320356701453069, 'num_leaves': 2220, 'max_depth': 7, 'min_data_in_leaf': 200, 'lambda_l1': 90, 'lambda_l2': 45, 'min_gain_to_split': 1.516682995396741, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.5}","metadata":{}},{"cell_type":"code","source":"#optuna.visualization.plot_optimization_history(study)\n#optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:43:02.280187Z","iopub.execute_input":"2022-04-11T06:43:02.281144Z","iopub.status.idle":"2022-04-11T06:43:02.289759Z","shell.execute_reply.started":"2022-04-11T06:43:02.281093Z","shell.execute_reply":"2022-04-11T06:43:02.288999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbc = LGBMClassifier(\n    #**best_params\n).fit(X_train, y_train)\ny_pred = lgbc.predict(X_test)\nscore=accuracy_score(y_test,y_pred)\nprint(score) # 정확도 확인","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:43:02.291019Z","iopub.execute_input":"2022-04-11T06:43:02.291303Z","iopub.status.idle":"2022-04-11T06:43:02.447879Z","shell.execute_reply.started":"2022-04-11T06:43:02.291273Z","shell.execute_reply":"2022-04-11T06:43:02.447181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 혼동 행렬(confusion matrix)\n    + 모델의 성능을 평가할때 사용되는 지표\n    + 예측값이 실제 관측값을 얼마나 정확히 예측했는지 보여주는 행렬\n    + [혼동 행렬 설명 참조](https://truman.tistory.com/179)\n    + from sklearn.[metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) import confusion_matrix 모델 사용","metadata":{}},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred),\n                annot = True,\n                cbar= False,\n                fmt='g',\n               #cmap= theme\n               )\nplt.ylabel('Actual Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion-Matrix');","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:43:02.451631Z","iopub.execute_input":"2022-04-11T06:43:02.453741Z","iopub.status.idle":"2022-04-11T06:43:02.641695Z","shell.execute_reply.started":"2022-04-11T06:43:02.453695Z","shell.execute_reply":"2022-04-11T06:43:02.640998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = 964 # True Positive 분석 모델이 1로 예측했는데 실제 데이터도 1인 경우\nFN = 325 # False Negative 분석 모델이 0로 예측했는데 실제 데이터는 1인 경우\nFP = 224 # False Positive 분석 모델이 0로 예측했는데 실제 데이터는 0인 경우\nTN = 1095 # True Negative 분석 모델이 1로 예측했는데 실제 데이터는 0인 경우\n# Precision(정밀도): 모델이 1로 예측한 결과 중 실제 데이터도 1인 경우의 비율\nP = TP / (TP + FP)\n# Accurancy(정확도): 모델이 제대로 예측한 비율\nA = (TP + TN) / (TP + FP + FN + TN)\n# Error Rate(오차 비율): 1-Accyracy\nER = (FP + FN) / (TP + FP + FN + TN)\n# False Poitive Rate(FPR, 거짓긍정률): 1-Specificity\nFPR = FP / (FP + TN)\n# Sensitivity(or Recall, 민감도): 실제 값이 1인 데이터 중 모델이 1로 예측한 비율\nS = TP / (TP + FN)\n# Specificity(특이도): 실제 값이 0인 데이터 중 모델이 0으로 예측한 비율\nSpe = TN / (TN + FP)\n# F1 Score (F-Measure): 정밀도와 재현율의 조화평균, 1에 가까울수록 모델의 예측 성능이 좋음 \nF1 = 2 / ((1 / P) + (1 / S))\nprint('Precision:', P,\n      'Accurancy(score):', A,\n      'Error_Rate:', ER,\n      'False_Positive_Rate:', FPR,\n      'Sensitivity:', S,\n      'Specificity:', Spe,\n      'F1_Score:', F1, sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:43:02.642966Z","iopub.execute_input":"2022-04-11T06:43:02.643653Z","iopub.status.idle":"2022-04-11T06:43:02.654047Z","shell.execute_reply.started":"2022-04-11T06:43:02.643616Z","shell.execute_reply":"2022-04-11T06:43:02.653232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- [위 참고 자료 출처_1](https://bibimnews.com/entry/%EB%A7%A4%ED%8A%B8%EB%A6%AD%EC%8A%A4%EB%A5%BC-%ED%86%B5%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EA%B8%B0%EB%B2%95-%ED%98%BC%EB%8F%99%ED%96%89%EB%A0%ACConfusion-Matrix)\n- [위 참고 자료 출처_2](https://yogyui.tistory.com/entry/Confusion-Matrix-%ED%98%BC%EB%8F%99%ED%96%89%EB%A0%AC)","metadata":{}},{"cell_type":"markdown","source":"# 참고\n- 다른 사람의 code 설명을 쭉 따라치고 필자가 해석한 것을 추가로 작성함.\n- Robin, Spaceship Titanic: A cosmic mystery , [링크 주소](https://www.kaggle.com/code/heyrobin/spaceship-titanic-a-cosmic-mystery)","metadata":{}},{"cell_type":"markdown","source":"# Step 6. 제출","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\nsub['Transported'] = lgbc.predict(test)\nsub.to_csv('submission.csv',index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:43:02.657016Z","iopub.execute_input":"2022-04-11T06:43:02.657258Z","iopub.status.idle":"2022-04-11T06:43:02.714107Z","shell.execute_reply.started":"2022-04-11T06:43:02.657231Z","shell.execute_reply":"2022-04-11T06:43:02.713391Z"},"trusted":true},"execution_count":null,"outputs":[]}]}