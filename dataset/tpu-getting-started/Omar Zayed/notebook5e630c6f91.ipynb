{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\nimport tensorflow as tf\nimport numpy as np\nfrom PIL import Image\nimport io\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:17.087604Z","iopub.execute_input":"2021-09-24T05:53:17.087891Z","iopub.status.idle":"2021-09-24T05:53:17.09461Z","shell.execute_reply.started":"2021-09-24T05:53:17.087857Z","shell.execute_reply":"2021-09-24T05:53:17.093445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as tt\nimport torchvision.models as models","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:20.977958Z","iopub.execute_input":"2021-09-24T05:53:20.978829Z","iopub.status.idle":"2021-09-24T05:53:20.982289Z","shell.execute_reply.started":"2021-09-24T05:53:20.978786Z","shell.execute_reply":"2021-09-24T05:53:20.981512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:22.698919Z","iopub.execute_input":"2021-09-24T05:53:22.6992Z","iopub.status.idle":"2021-09-24T05:53:22.705813Z","shell.execute_reply.started":"2021-09-24T05:53:22.699148Z","shell.execute_reply":"2021-09-24T05:53:22.704954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:23.684575Z","iopub.execute_input":"2021-09-24T05:53:23.68513Z","iopub.status.idle":"2021-09-24T05:53:23.691314Z","shell.execute_reply.started":"2021-09-24T05:53:23.68509Z","shell.execute_reply":"2021-09-24T05:53:23.690362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nstats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\ntsfm = tt.Compose([\n    tt.Resize(224),\n    tt.CenterCrop(224),\n    tt.ToTensor(),\n    tt.Normalize(*stats)])","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:25.910264Z","iopub.execute_input":"2021-09-24T05:53:25.910829Z","iopub.status.idle":"2021-09-24T05:53:25.915648Z","shell.execute_reply.started":"2021-09-24T05:53:25.91079Z","shell.execute_reply":"2021-09-24T05:53:25.914872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\ntrain_files = glob.glob(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/*.tfrec\")\nval_files = glob.glob(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/*.tfrec\")\ntest_files = glob.glob(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/*.tfrec\")","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:51.285042Z","iopub.execute_input":"2021-09-24T05:53:51.285903Z","iopub.status.idle":"2021-09-24T05:53:51.296459Z","shell.execute_reply.started":"2021-09-24T05:53:51.285857Z","shell.execute_reply":"2021-09-24T05:53:51.295714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feature_description = {\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n    return tf.io.parse_single_example(example_proto, train_feature_description)\n\ntrain_ids = []\ntrain_class = []\ntrain_images = []\nfor i in train_files:\n    train_image_dataset = tf.data.TFRecordDataset(i)\ntrain_image_dataset = train_image_dataset.map(_parse_image_function)\nids = [str(id_features['id'].numpy())[2:-1] for id_features in train_image_dataset]\ntrain_ids = train_ids + ids\nclasses = [int(class_features['class'].numpy()) for class_features in train_image_dataset]\ntrain_class = train_class + classes\nimages = [image_features['image'].numpy() for image_features in train_image_dataset]\ntrain_images = train_images + images","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:54.165448Z","iopub.execute_input":"2021-09-24T05:53:54.165726Z","iopub.status.idle":"2021-09-24T05:53:55.206753Z","shell.execute_reply.started":"2021-09-24T05:53:54.165696Z","shell.execute_reply":"2021-09-24T05:53:55.205996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_array_images = []\ntrain_array_class = []\nfor x in train_images:\n    x = np.array(Image.open(io.BytesIO(x))).reshape(3,224,224).astype('float32')\n    train_array_images.append(x)\ntrain_array_images = torch.Tensor(train_array_images)\ntrain_array_class = torch.tensor(train_class)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:53:55.372394Z","iopub.execute_input":"2021-09-24T05:53:55.372635Z","iopub.status.idle":"2021-09-24T05:54:25.977623Z","shell.execute_reply.started":"2021-09-24T05:53:55.372607Z","shell.execute_reply":"2021-09-24T05:54:25.97675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_feature_description = {\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\nval_ids = []\nval_class = []\nval_images = []\nfor i in val_files:\n    val_image_dataset = tf.data.TFRecordDataset(i)\nval_image_dataset = val_image_dataset.map(_parse_image_function)\nids = [str(id_features['id'].numpy())[2:-1] for id_features in val_image_dataset]\nval_ids = val_ids + ids\nclasses = [int(class_features['class'].numpy()) for class_features in val_image_dataset]\nval_class = val_class + classes\nimages = [image_features['image'].numpy() for image_features in val_image_dataset]\nval_images = val_images + images","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:54:56.397252Z","iopub.execute_input":"2021-09-24T05:54:56.398005Z","iopub.status.idle":"2021-09-24T05:54:56.775029Z","shell.execute_reply.started":"2021-09-24T05:54:56.397969Z","shell.execute_reply":"2021-09-24T05:54:56.774102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_array_images = []\nval_array_class = []\nfor x in val_images:\n    x = np.array(Image.open(io.BytesIO(x))).reshape(3,224,224).astype('float32')\n    val_array_images.append(x)\nval_array_images = torch.Tensor(val_array_images)\nval_array_class = torch.tensor(val_class)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:54:57.881287Z","iopub.execute_input":"2021-09-24T05:54:57.88198Z","iopub.status.idle":"2021-09-24T05:55:06.883212Z","shell.execute_reply.started":"2021-09-24T05:54:57.881945Z","shell.execute_reply":"2021-09-24T05:55:06.882466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = TensorDataset(train_array_images, train_array_class)\nval_set = TensorDataset(val_array_images, val_array_class)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:06.884746Z","iopub.execute_input":"2021-09-24T05:55:06.885012Z","iopub.status.idle":"2021-09-24T05:55:06.889218Z","shell.execute_reply.started":"2021-09-24T05:55:06.884977Z","shell.execute_reply":"2021-09-24T05:55:06.888495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:10.744157Z","iopub.execute_input":"2021-09-24T05:55:10.744729Z","iopub.status.idle":"2021-09-24T05:55:10.75072Z","shell.execute_reply.started":"2021-09-24T05:55:10.74469Z","shell.execute_reply":"2021-09-24T05:55:10.749631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DeviceDataLoader(DataLoader(train_set, batch_size, shuffle=True), device)\nval_loader = DeviceDataLoader(DataLoader(val_set, batch_size), device)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:14.740463Z","iopub.execute_input":"2021-09-24T05:55:14.741154Z","iopub.status.idle":"2021-09-24T05:55:14.767322Z","shell.execute_reply.started":"2021-09-24T05:55:14.741112Z","shell.execute_reply":"2021-09-24T05:55:14.766136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nmax_lr = 0.0001\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:34.254096Z","iopub.execute_input":"2021-09-24T05:55:34.254801Z","iopub.status.idle":"2021-09-24T05:55:34.261Z","shell.execute_reply.started":"2021-09-24T05:55:34.254763Z","shell.execute_reply":"2021-09-24T05:55:34.259987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n\n\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:39.350322Z","iopub.execute_input":"2021-09-24T05:55:39.350649Z","iopub.status.idle":"2021-09-24T05:55:39.370025Z","shell.execute_reply.started":"2021-09-24T05:55:39.350615Z","shell.execute_reply":"2021-09-24T05:55:39.369232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNetModel(ImageClassificationBase):\n  def __init__(self, num_classes):\n        super().__init__()\n        self.network = models.resnet101()\n        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n        \n  def forward(self, xb):\n        return self.network(xb)\n\n\nmodel = to_device(ResNetModel(104), device)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:41.314629Z","iopub.execute_input":"2021-09-24T05:55:41.314889Z","iopub.status.idle":"2021-09-24T05:55:42.092045Z","shell.execute_reply.started":"2021-09-24T05:55:41.314858Z","shell.execute_reply":"2021-09-24T05:55:42.091313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:42.449717Z","iopub.execute_input":"2021-09-24T05:55:42.449964Z","iopub.status.idle":"2021-09-24T05:55:43.126736Z","shell.execute_reply.started":"2021-09-24T05:55:42.449934Z","shell.execute_reply":"2021-09-24T05:55:43.1258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = []","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:45.518817Z","iopub.execute_input":"2021-09-24T05:55:45.519087Z","iopub.status.idle":"2021-09-24T05:55:45.525482Z","shell.execute_reply.started":"2021-09-24T05:55:45.519056Z","shell.execute_reply":"2021-09-24T05:55:45.524653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history += fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:55:49.862382Z","iopub.execute_input":"2021-09-24T05:55:49.863049Z","iopub.status.idle":"2021-09-24T05:57:40.716359Z","shell.execute_reply.started":"2021-09-24T05:55:49.863013Z","shell.execute_reply":"2021-09-24T05:57:40.714794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('done')","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:57:40.718365Z","iopub.execute_input":"2021-09-24T05:57:40.718637Z","iopub.status.idle":"2021-09-24T05:57:40.72323Z","shell.execute_reply.started":"2021-09-24T05:57:40.7186Z","shell.execute_reply":"2021-09-24T05:57:40.722302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}