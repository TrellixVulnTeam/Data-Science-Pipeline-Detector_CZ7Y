{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data preparation for models training #","metadata":{"id":"0x0vaE6ojYto"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"MWhPjrtYg6rr","outputId":"4f13cf3f-bdae-4c32-965d-fcfc40fe4309"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS\nimport os\nimport shutil\nimport numpy as np\nimport zipfile\nimport math\nfrom functools import partial\nimport tensorflow as tf\nimport random","metadata":{"id":"C8Qe2A_1UGG3","execution":{"iopub.status.busy":"2022-01-12T11:51:40.726754Z","iopub.execute_input":"2022-01-12T11:51:40.727545Z","iopub.status.idle":"2022-01-12T11:51:45.862536Z","shell.execute_reply.started":"2022-01-12T11:51:40.727392Z","shell.execute_reply":"2022-01-12T11:51:45.861472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade --force-reinstall --no-deps kaggle","metadata":{"id":"9LgxddaDUWu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir ~/.kaggle","metadata":{"id":"YohtBc6oXIcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cp kaggle.json ~/.kaggle/","metadata":{"id":"V1NWKflvU9j0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! chmod 600 ~/.kaggle/kaggle.json","metadata":{"id":"aNd4RjK4VkQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! kaggle competitions download tpu-getting-started","metadata":{"id":"84qDUiD5Vw4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with zipfile.ZipFile(\"/content/tpu-getting-started.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\"/content\")","metadata":{"id":"EN5EUK1mVyjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS\n\nos.mkdir(\"flower_classification\")\nos.mkdir(\"flower_classification/data_before_split\")\nos.mkdir(\"flower_classification/training\")\nos.mkdir(\"flower_classification/validation\")\nos.mkdir(\"flower_classification/test\")","metadata":{"id":"PvwrUjOfe0mp","execution":{"iopub.status.busy":"2022-01-12T11:52:31.500268Z","iopub.execute_input":"2022-01-12T11:52:31.500735Z","iopub.status.idle":"2022-01-12T11:52:31.507419Z","shell.execute_reply.started":"2022-01-12T11:52:31.500701Z","shell.execute_reply":"2022-01-12T11:52:31.506131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS\n\ntemp_classes = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']\n\nclasses = {}\n\nfor i in range( len( temp_classes  ) ):\n  classes[i] = temp_classes[i]\n  ","metadata":{"id":"h38C2yqTAV-_","execution":{"iopub.status.busy":"2022-01-12T11:52:44.208357Z","iopub.execute_input":"2022-01-12T11:52:44.20864Z","iopub.status.idle":"2022-01-12T11:52:44.221335Z","shell.execute_reply.started":"2022-01-12T11:52:44.208611Z","shell.execute_reply":"2022-01-12T11:52:44.220083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS AFTER RUNNING THE NEXT TWO CELLS\n\n\ndatasets = [ \"../input/tpu-getting-started/tfrecords-jpeg-192x192\" ,\n            \"../input/tpu-getting-started/tfrecords-jpeg-224x224\" ,\n            \"../input/tpu-getting-started/tfrecords-jpeg-331x331\" ,\n            \"../input/tpu-getting-started/tfrecords-jpeg-512x512\"]\nimage_sizes = [[192,192] , [224,224] , [331,331] , [512,512] ]\nid_labeled = 0\nid_unlabeled = 0 \nfor i in range( len(datasets) ) :\n  labeled_data_file_names = []\n  unlabeled_data_file_names = []\n  for j in os.listdir(datasets[i] + \"/train\"):\n    labeled_data_file_names.append( datasets[i] + \"/train\" + \"/\" + j )\n  for j in os.listdir(datasets[i] + \"/val\"):\n    labeled_data_file_names.append( datasets[i] + \"/val\" + \"/\" + j )\n  for j in os.listdir(datasets[i] + \"/test\"):\n    unlabeled_data_file_names.append( datasets[i] + \"/test\" + \"/\" + j )\n  examples = convert_tfrecords_to_jpeg( labeled_data_file_names )\n  for example in examples:\n    save_image( example , image_sizes[i] , \"./flower_classification/data_before_split/\" , id_labeled )\n    id_labeled += 1\n  examples = convert_tfrecords_to_jpeg( unlabeled_data_file_names , labeled = False )\n  for example in examples:\n    save_image( example , image_sizes[i] , \"./flower_classification/test/\" , id_unlabeled , labeled = False )\n    id_unlabeled += 1","metadata":{"id":"XdjW3dOvkDS_","execution":{"iopub.status.busy":"2022-01-12T11:53:04.577278Z","iopub.execute_input":"2022-01-12T11:53:04.577701Z","iopub.status.idle":"2022-01-12T12:07:43.425761Z","shell.execute_reply.started":"2022-01-12T11:53:04.577668Z","shell.execute_reply":"2022-01-12T12:07:43.424813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS\n\ndef save_image( example , image_size , save_path , id , labeled = True ):\n  image = tf.image.decode_jpeg( example['image'] , channels=3)\n  image = tf.cast(image, tf.float32)\n  image = tf.reshape(image, [ *image_size  , 3])\n  image = image.numpy()\n  if labeled:\n    if not os.path.isdir( save_path + classes[ example['class'].numpy().squeeze() ] ):\n      os.mkdir( save_path + classes[ example['class'].numpy().squeeze() ] )\n    tf.keras.utils.save_img(\n        save_path + classes [ example['class'].numpy().squeeze() ] + \"/\" + str(id) + '.jpeg'  , image , scale=True\n    )\n  else:\n    tf.keras.utils.save_img(\n        save_path  + str(id) + '.jpeg'  , image , scale=True\n    )","metadata":{"id":"s1Rs195XDPHc","execution":{"iopub.status.busy":"2022-01-12T11:52:56.162375Z","iopub.execute_input":"2022-01-12T11:52:56.162635Z","iopub.status.idle":"2022-01-12T11:52:56.173179Z","shell.execute_reply.started":"2022-01-12T11:52:56.162606Z","shell.execute_reply":"2022-01-12T11:52:56.17107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS\n\ndef convert_tfrecords_to_jpeg( files_paths , labeled = True ):\n  # Define features\n  read_features = (\n        {\n            \"image\": tf.io.FixedLenFeature([], tf.string),\n            \"class\": tf.io.FixedLenFeature([], tf.int64),\n        }\n        if labeled\n        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n  )\n  examples = []\n  for path in files_paths:\n    for example in tf.compat.v1.io.tf_record_iterator( path ):\n      example = tf.io.parse_single_example( example , read_features )\n      examples.append(example)\n  return examples","metadata":{"id":"M0y8FdavteJk","execution":{"iopub.status.busy":"2022-01-12T11:52:59.573701Z","iopub.execute_input":"2022-01-12T11:52:59.573974Z","iopub.status.idle":"2022-01-12T11:52:59.582397Z","shell.execute_reply.started":"2022-01-12T11:52:59.573945Z","shell.execute_reply":"2022-01-12T11:52:59.581439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RUN THIS\n\n\nfor class_name in os.listdir(\"./flower_classification/data_before_split\"):\n  os.mkdir(\"./flower_classification/training/\" + class_name )\n  os.mkdir(\"./flower_classification/validation/\" + class_name )\n  class_images = os.listdir( \"./flower_classification/data_before_split/\" + class_name )\n  random.shuffle(class_images)\n  training_images = class_images[ : int( 0.9 * len(class_images) ) ]\n  val_images = class_images[ int( 0.9 * len(class_images) ) :  ]\n  for image in training_images:\n    shutil.copyfile( \"./flower_classification/data_before_split/\" + class_name + \"/\" + image ,\n                \"./flower_classification/training/\" + class_name + '/' + image )\n  for image in val_images:\n    shutil.copyfile( \"./flower_classification/data_before_split/\" + class_name + \"/\" + image ,\n                \"./flower_classification/validation/\" + class_name + '/' + image )","metadata":{"id":"y-kPklphPAAO","execution":{"iopub.status.busy":"2022-01-12T12:09:16.702018Z","iopub.execute_input":"2022-01-12T12:09:16.702354Z","iopub.status.idle":"2022-01-12T12:09:30.858402Z","shell.execute_reply.started":"2022-01-12T12:09:16.702322Z","shell.execute_reply":"2022-01-12T12:09:30.857268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.flush_and_unmount()","metadata":{"id":"h8A7m3aPUuh6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models part #","metadata":{"id":"AbMPw_eSfOos"}},{"cell_type":"markdown","source":"----------------------------------------------- Setting image data generators ------------------------------------","metadata":{"id":"-PYDa9COj-Bd"}},{"cell_type":"code","source":"!pip install tensorflow_addons==0.15.0","metadata":{"id":"sTA8xTz7NVuA","outputId":"84c4e558-58fe-408c-f816-17854f44c929","execution":{"iopub.status.busy":"2022-01-12T12:09:53.113832Z","iopub.execute_input":"2022-01-12T12:09:53.114125Z","iopub.status.idle":"2022-01-12T12:10:14.755094Z","shell.execute_reply.started":"2022-01-12T12:09:53.114096Z","shell.execute_reply":"2022-01-12T12:10:14.753884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random \nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D,BatchNormalization,LayerNormalization\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.models import Model\nfrom keras import optimizers\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.metrics import Accuracy","metadata":{"id":"NOc4AHO4Zzk1","execution":{"iopub.status.busy":"2022-01-12T16:35:35.307439Z","iopub.execute_input":"2022-01-12T16:35:35.308192Z","iopub.status.idle":"2022-01-12T16:35:41.53697Z","shell.execute_reply.started":"2022-01-12T16:35:35.308148Z","shell.execute_reply":"2022-01-12T16:35:41.535922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batch_size = 1024\nval_batch_size =  512                \nimage_size = ( 299 , 299 )               \n\ntrain_datagen = ImageDataGenerator( rescale = 1./255 ,\n                                   rotation_range = 40 ,\n                                   width_shift_range = 0.2 ,\n                                   height_shift_range = 0.2,\n                                   zoom_range = 0.2,\n                                   fill_mode = 'nearest',\n                                   horizontal_flip = True )\n\nval_datagen = ImageDataGenerator(rescale = 1./255)\n\ntrain_path = \"./flower_classification/training\"\n\nval_path = \"./flower_classification/validation\"\n\ntrain_data = train_datagen.flow_from_directory( train_path ,\n                                               target_size = image_size ,\n                                               class_mode = 'categorical',\n                                               batch_size = train_batch_size)\n\nval_data = val_datagen.flow_from_directory( val_path ,\n                                          target_size = image_size ,\n                                          class_mode = 'categorical',\n                                          batch_size = val_batch_size )","metadata":{"id":"bcOHphq2fhBI","outputId":"b9aa14d6-6729-4675-e42e-f783d1d31b9b","execution":{"iopub.status.busy":"2022-01-12T16:36:23.442292Z","iopub.execute_input":"2022-01-12T16:36:23.443462Z","iopub.status.idle":"2022-01-12T16:36:27.907888Z","shell.execute_reply.started":"2022-01-12T16:36:23.443409Z","shell.execute_reply":"2022-01-12T16:36:27.906788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_resnet = InceptionResNetV2(\n    include_top=False, weights='imagenet',\n    input_shape= (299,299,3)\n)\n\nfor layer in inception_resnet.layers:\n  layer.trainable = False\n\nx = Flatten()(inception_resnet.output)\nx = Dense ( 256 , activation = 'relu' )(x)\nx = Dense( 128 , activation = 'relu' )(x)\nx = Dense ( 128 , activation = 'relu' ) (x)\nx = Dense(104, activation='softmax')(x)\nmodel = Model(inputs= inception_resnet.input , outputs = x )\nmodel.summary()","metadata":{"id":"X7_rCjA14kO0","execution":{"iopub.status.busy":"2022-01-12T18:43:20.303385Z","iopub.execute_input":"2022-01-12T18:43:20.304579Z","iopub.status.idle":"2022-01-12T18:43:27.585319Z","shell.execute_reply.started":"2022-01-12T18:43:20.304524Z","shell.execute_reply":"2022-01-12T18:43:27.584267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove(\"./fscore_weights.h5\")\nos.remove(\"./acc_weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:35:53.980828Z","iopub.execute_input":"2022-01-12T13:35:53.98112Z","iopub.status.idle":"2022-01-12T13:35:53.989635Z","shell.execute_reply.started":"2022-01-12T13:35:53.98109Z","shell.execute_reply":"2022-01-12T13:35:53.988483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.remove(\"./model_history_log.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-12T18:45:12.271315Z","iopub.execute_input":"2022-01-12T18:45:12.271656Z","iopub.status.idle":"2022-01-12T18:45:12.277652Z","shell.execute_reply.started":"2022-01-12T18:45:12.271624Z","shell.execute_reply":"2022-01-12T18:45:12.276238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_checkpoint_filepath = './acc_weights.h5'\nfscore_checkpoint_filepath = './fscore_weights.h5'\n\naccuracy_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath= accuracy_checkpoint_filepath ,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)\n\nfscore_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath= fscore_checkpoint_filepath ,\n    save_weights_only=True,\n    monitor='val_my_fscore',\n    mode='max',\n    save_best_only=True)","metadata":{"id":"E0AU0QxRJBk3","execution":{"iopub.status.busy":"2022-01-12T18:43:38.353494Z","iopub.execute_input":"2022-01-12T18:43:38.354013Z","iopub.status.idle":"2022-01-12T18:43:38.368351Z","shell.execute_reply.started":"2022-01-12T18:43:38.353964Z","shell.execute_reply":"2022-01-12T18:43:38.366602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fscore_metric = tfa.metrics.F1Score(num_classes=104,average = 'macro' , name = 'my_fscore')\n\n#accuracy_metric = Accuracy(name = 'my_accuracy')\n\nadam = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=adam , loss=\"categorical_crossentropy\" , metrics=[ fscore_metric , 'accuracy' ])","metadata":{"id":"JAx5JTkmM7i9","execution":{"iopub.status.busy":"2022-01-12T18:44:25.980818Z","iopub.execute_input":"2022-01-12T18:44:25.981795Z","iopub.status.idle":"2022-01-12T18:44:26.0174Z","shell.execute_reply.started":"2022-01-12T18:44:25.981756Z","shell.execute_reply":"2022-01-12T18:44:26.016429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import CSVLogger\ncsv_logger = CSVLogger(\"./model_history_log.csv\", append=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T18:45:23.66602Z","iopub.execute_input":"2022-01-12T18:45:23.666761Z","iopub.status.idle":"2022-01-12T18:45:23.671961Z","shell.execute_reply.started":"2022-01-12T18:45:23.666718Z","shell.execute_reply":"2022-01-12T18:45:23.670855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"./fscore_weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-12T18:38:48.223677Z","iopub.execute_input":"2022-01-12T18:38:48.223989Z","iopub.status.idle":"2022-01-12T18:38:50.181458Z","shell.execute_reply.started":"2022-01-12T18:38:48.223934Z","shell.execute_reply":"2022-01-12T18:38:50.180333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = model.fit(\n    x=train_data, epochs=15 , verbose='auto',validation_data=val_data,\n    steps_per_epoch = int(59234. / train_batch_size) , validation_steps = int( 6626. / val_batch_size) ,\n    callbacks = [ fscore_callback , accuracy_callback , csv_logger ]\n)","metadata":{"id":"pmLAVw8qNAsB","execution":{"iopub.status.busy":"2022-01-12T18:45:28.148467Z","iopub.execute_input":"2022-01-12T18:45:28.149594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}