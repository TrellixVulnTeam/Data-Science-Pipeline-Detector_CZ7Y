{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Introduction #\n\nWelcome to the [**Petals to the Metal**](https://www.kaggle.com/c/tpu-getting-started) competition! In this competition, you’re challenged to build a machine learning model to classify 104 types of flowers based on their images.\n\nIn this tutorial notebook, you'll learn how to build an image classifier in Keras and train it on a [Tensor Processing Unit (TPU)](https://www.kaggle.com/docs/tpu). At the end, you'll have a complete project you can build off of with ideas of your own.\n\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n    <strong>Fork This Notebook!</strong><br>\nCreate your own editable copy of this notebook by clicking on the <strong>Copy and Edit</strong> button in the top right corner.\n</blockquote>","metadata":{}},{"cell_type":"markdown","source":"\n# Introduction #\n\n[**Petals to the Metal**](https://www.kaggle.com/c/tpu-getting-started) yarışmasına hoş geldiniz! Bu yarışmada, 104 çiçek türünü görüntülerine göre sınıflandırmak için bir makine öğrenimi modeli oluşturmanız isteniyor.\nBu eğitici not defterinde, Keras'ta bir görüntü sınıflandırıcıyı nasıl oluşturacağınızı ve bunu bir [Tensor İşleme Birimi (TPU)](https://www.kaggle.com/docs/tpu) üzerinde nasıl eğiteceğinizi öğreneceksiniz. Sonunda, kendi fikirlerinizle inşa edebileceğiniz eksiksiz bir projeniz olacak.\n\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n    <strong>Fork This Notebook!</strong><br>\nCreate your own editable copy of this notebook by clicking on the <strong>Copy and Edit</strong> button in the top right corner.\n</blockquote>","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Imports #\n\nİlk önce python pakettlerini import ediyoruz.","metadata":{}},{"cell_type":"code","source":"import math, re, os\nimport numpy as np\nimport tensorflow as tf\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:53:05.49832Z","iopub.execute_input":"2021-09-13T10:53:05.499248Z","iopub.status.idle":"2021-09-13T10:53:11.165506Z","shell.execute_reply.started":"2021-09-13T10:53:05.499155Z","shell.execute_reply":"2021-09-13T10:53:11.164581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Distribution Strategy #\n\nA TPU has eight different *cores* and each of these cores acts as its own accelerator. (A TPU is sort of like having eight GPUs in one machine.) We tell TensorFlow how to make use of all these cores at once through a **distribution strategy**. Run the following cell to create the distribution strategy that we'll later apply to our model.","metadata":{}},{"cell_type":"markdown","source":"# Step 2: TPU Tanımlaması ve Kullanımı ile Dağıtım Stratejisi (Distribution Strategy) #\n\nBir TPU'nun *sekiz farklı çekirdeği* vardır ve bu çekirdeklerin her biri kendi hızlandırıcısı olarak işlev görür. (Bir TPU, bir makinede sekiz GPU'ya sahip olmak gibidir.) TensorFlow'a bir **Dağıtım Stratejisi (Distribution Strategy)** aracılığıyla tüm bu çekirdeklerin bir kerede nasıl kullanılacağını anlatıyoruz. Daha sonra modelimize uygulayacağımız dağıtım stratejisini oluşturmak için aşağıdaki hücreyi çalıştırın.\n","metadata":{}},{"cell_type":"code","source":"#TPU'yu algılıyoruz, uygun olan dağıtım stratejisini (Distribution Strategy) döndürüyoruz\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:57:33.668888Z","iopub.execute_input":"2021-09-13T10:57:33.669224Z","iopub.status.idle":"2021-09-13T10:57:39.094596Z","shell.execute_reply.started":"2021-09-13T10:57:33.669191Z","shell.execute_reply":"2021-09-13T10:57:39.09387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sinir ağı modelimizi oluştururken dağıtım stratejisini kullanacağız. Ardından TensorFlow, her çekirdek için bir model olmak üzere sekiz farklı model *replika* oluşturarak eğitimi sekiz TPU çekirdeği arasında dağıtır.\n# Step 3: Loading the Competition Data -  Yarışma Verilerinin Yüklenmesi #\n\n## Get GCS Path - GCS Yolunu Alın ##\n\nTPU'larla kullanıldığında veri kümelerinin bir [Google Cloud Storage paketinde](https://cloud.google.com/storage/) depolanması gerekir. Herhangi bir genel GCS paketindeki verileri, tıpkı `'/kaggle/input'`taki veriler gibi yolunu vererek kullanabilirsiniz. Aşağıdakiler, bu yarışmanın veri kümesi için GCS yolunu alacaktır.","metadata":{}},{"cell_type":"code","source":"# Veri kümesi için GCS yolunu alacak\nfrom kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(GCS_DS_PATH) # what do gcs paths look like?","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:02:36.67021Z","iopub.execute_input":"2021-09-13T11:02:36.670909Z","iopub.status.idle":"2021-09-13T11:02:37.099515Z","shell.execute_reply.started":"2021-09-13T11:02:36.670874Z","shell.execute_reply":"2021-09-13T11:02:37.098594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can use data from any public dataset here on Kaggle in just the same way. If you'd like to use data from one of your private datasets, see [here](https://www.kaggle.com/docs/tpu#tpu3pt5).\n\n## Load Data - Veri yükle ##\n\nTPU'larla kullanıldığında, veri kümeleri genellikle [TFRecords](https://www.kaggle.com/ryanholbrook/tfrecords-basics) olarak serileştirilir. Bu, her bir TPU çekirdeğine veri dağıtmak için uygun bir biçimdir. İşlem biraz uzun olduğu için veri setimiz için TFRecords'u okuyan hücreyi gizledik. TPU'larla kendi veri kümelerinizi kullanma konusunda bazı rehberlik için daha sonra geri dönebilirsiniz.","metadata":{}},{"cell_type":"code","source":"\nIMAGE_SIZE = [512, 512]\nGCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\nAUTO = tf.data.experimental.AUTOTUNE\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T11:02:41.354423Z","iopub.execute_input":"2021-09-13T11:02:41.354815Z","iopub.status.idle":"2021-09-13T11:02:41.654035Z","shell.execute_reply.started":"2021-09-13T11:02:41.354786Z","shell.execute_reply":"2021-09-13T11:02:41.653464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Data Pipelines - Veri İşlem Hatları Oluşturun ##\n\nBu son adımda, eğitim, doğrulama ve test bölümlerinin her biri için verimli bir veri hattı tanımlamak üzere `tf.data` API'sini kullanacağız.","metadata":{}},{"cell_type":"code","source":"\ndef data_augment(image, label):\n    # Thanks to the dataset.prefetch(AUTO)\n    # statement in the next function (below), this happens essentially\n    # for free on TPU. Data pipeline code is executed on the \"CPU\"\n    # part of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec\n    # files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T11:04:02.352969Z","iopub.execute_input":"2021-09-13T11:04:02.353279Z","iopub.status.idle":"2021-09-13T11:04:02.366969Z","shell.execute_reply.started":"2021-09-13T11:04:02.353246Z","shell.execute_reply":"2021-09-13T11:04:02.365748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sonraki hücre, eğitim ve çıkarım sırasında Keras ile kullanacağımız veri kümelerini oluşturacaktır. Partilerin boyutunu TPU çekirdeği sayısına nasıl ölçeklendirdiğimize dikkat edin.","metadata":{}},{"cell_type":"code","source":"# Define the batch size. This will be 16 with TPU off and 128 (=16*8) with TPU on\n# Parti boyutunu tanımlayın. Bu, TPU kapalıyken 16 ve TPU açıkken 128 (=16*8) olacaktır.\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:05:34.724625Z","iopub.execute_input":"2021-09-13T11:05:34.724925Z","iopub.status.idle":"2021-09-13T11:05:35.002316Z","shell.execute_reply.started":"2021-09-13T11:05:34.724893Z","shell.execute_reply":"2021-09-13T11:05:35.001477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu veri kümeleri `tf.data.Dataset` nesneleridir. TensorFlow'daki bir veri kümesini bir *veri kaydı akışı (stream)* olarak düşünebilirsiniz. Eğitim ve doğrulama kümeleri, `(image, label)` çiftlerinin akışlarıdır.","metadata":{}},{"cell_type":"code","source":"#Eğitim verilerinin boyutları\n\nnp.set_printoptions(threshold=15, linewidth=80)\n\nprint(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:06:27.179873Z","iopub.execute_input":"2021-09-13T11:06:27.180751Z","iopub.status.idle":"2021-09-13T11:06:35.546344Z","shell.execute_reply.started":"2021-09-13T11:06:27.180696Z","shell.execute_reply":"2021-09-13T11:06:35.545496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test seti, `(image, idnum)` çiftlerinin bir akışıdır; Buradaki `idnum`, daha sonra `csv` dosyası olarak gönderimimizi yaptığımızda kullanacağımız resme verilen benzersiz tanımlayıcıdır.","metadata":{}},{"cell_type":"code","source":"# Test verilerinin Boyutları.\nprint(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:07:37.773647Z","iopub.execute_input":"2021-09-13T11:07:37.773938Z","iopub.status.idle":"2021-09-13T11:07:41.234466Z","shell.execute_reply.started":"2021-09-13T11:07:37.773909Z","shell.execute_reply":"2021-09-13T11:07:41.233574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Explore Data - Verileri Keşfedin #\n\nVeri setindeki bazı resimlere bir göz atalım.","metadata":{}},{"cell_type":"code","source":"\nfrom matplotlib import pyplot as plt\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case,\n                                     # these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is\n    # the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square\n    # or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n\n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T11:08:48.100553Z","iopub.execute_input":"2021-09-13T11:08:48.100828Z","iopub.status.idle":"2021-09-13T11:08:48.1183Z","shell.execute_reply.started":"2021-09-13T11:08:48.100801Z","shell.execute_reply":"2021-09-13T11:08:48.117529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Başka bir yardımcı işlevimizle bir veri kümesinden tek bir toplu resim görüntüleyebilirsiniz. Sonraki hücre, veri kümesini 20 görüntüden oluşan toplu bir yineleyiciye dönüştürecektir.","metadata":{}},{"cell_type":"code","source":"ds_iter = iter(ds_train.unbatch().batch(20))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:09:26.756027Z","iopub.execute_input":"2021-09-13T11:09:26.756678Z","iopub.status.idle":"2021-09-13T11:09:26.773055Z","shell.execute_reply.started":"2021-09-13T11:09:26.756642Z","shell.execute_reply":"2021-09-13T11:09:26.771979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Akıştaki bir sonraki grubu çıkarmak ve yardımcı işlevle görüntülemek için Python `next` işlevini kullanın.","metadata":{}},{"cell_type":"code","source":"one_batch = next(ds_iter)\ndisplay_batch_of_images(one_batch)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:09:29.454905Z","iopub.execute_input":"2021-09-13T11:09:29.455494Z","iopub.status.idle":"2021-09-13T11:09:33.554024Z","shell.execute_reply.started":"2021-09-13T11:09:29.455455Z","shell.execute_reply":"2021-09-13T11:09:33.553331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`ds_iter` ve `one_batch`'i ayrı hücrelerde tanımlayarak, yeni bir toplu resim görmek için yalnızca yukarıdaki hücreyi yeniden çalıştırmanız gerekir.","metadata":{}},{"cell_type":"markdown","source":"# Step 5: Define Model - Modeli Tanımlayın #\n\nArtık görüntüleri sınıflandırmak için bir sinir ağı oluşturmaya hazırız! **Transfer öğrenimi (transfer learning)** olarak bilinen yöntemi kullanacağız. Aktarım öğrenimi ile, yeni bir veri kümesine önde başlamak için önceden eğitilmiş bir modelin bir bölümünü yeniden kullanırsınız.\n\n\nBu eğitim için, [ImageNet](http://image-net.org/) üzerinde önceden eğitilmiş **VGG16** adlı bir model kullanacağız. Daha sonra, Keras'ta bulunan [diğer modelleri](https://www.tensorflow.org/api_docs/python/tf/keras/applications) denemek isteyebilirsiniz. ([Xception](https://www.tensorflow.org/api_docs/python/tf/keras/applications/Xception) kötü bir seçim olmaz.)\n\nDaha önce oluşturduğumuz dağıtım stratejisi bir [bağlam yöneticisi](https://docs.python.org/3/reference/compound_stmts.html#with), `strategy.scope` içerir. Bu bağlam yöneticisi, TensorFlow'a eğitim çalışmasının sekiz TPU çekirdeği arasında nasıl bölüneceğini söyler. TensorFlow'u bir TPU ile kullanırken, modelinizi bir `strategy.scope()` bağlamında tanımlamanız önemlidir.\n","metadata":{}},{"cell_type":"code","source":"EPOCHS = 12\n\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.VGG16(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:13:22.70409Z","iopub.execute_input":"2021-09-13T11:13:22.705008Z","iopub.status.idle":"2021-09-13T11:13:25.486459Z","shell.execute_reply.started":"2021-09-13T11:13:22.704969Z","shell.execute_reply":"2021-09-13T11:13:25.485804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kayıp ve metriklerin `'sparse_categorical'`sürümleri, bunun gibi ikiden fazla etiket içeren bir sınıflandırma görevi için uygundur.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:14:29.906766Z","iopub.execute_input":"2021-09-13T11:14:29.907627Z","iopub.status.idle":"2021-09-13T11:14:29.95231Z","shell.execute_reply.started":"2021-09-13T11:14:29.907581Z","shell.execute_reply":"2021-09-13T11:14:29.951483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6: Training - Eğitim #\n\n## Learning Rate Schedule - Öğrenme Hızı Çizelgesi ##\n\nBu ağı özel bir öğrenme oranı programıyla eğiteceğiz.","metadata":{}},{"cell_type":"code","source":"\n# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T11:15:29.374899Z","iopub.execute_input":"2021-09-13T11:15:29.375205Z","iopub.status.idle":"2021-09-13T11:15:29.580966Z","shell.execute_reply.started":"2021-09-13T11:15:29.375172Z","shell.execute_reply":"2021-09-13T11:15:29.579998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit Model  - Modeli Eğiteceğiz ##\n\nVe şimdi modeli eğitmeye hazırız. Birkaç parametre tanımladıktan sonra, gitmeye hazırız!","metadata":{}},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 12\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:16:19.528589Z","iopub.execute_input":"2021-09-13T11:16:19.528887Z","iopub.status.idle":"2021-09-13T11:21:18.991362Z","shell.execute_reply.started":"2021-09-13T11:16:19.528858Z","shell.execute_reply":"2021-09-13T11:21:18.990513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu sonraki hücre, eğitim sırasında kaybın ve ölçümlerin nasıl ilerlediğini gösterir. Neyse ki, birleşiyor!","metadata":{}},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:24:20.955273Z","iopub.execute_input":"2021-09-13T11:24:20.955599Z","iopub.status.idle":"2021-09-13T11:24:21.437781Z","shell.execute_reply.started":"2021-09-13T11:24:20.955565Z","shell.execute_reply":"2021-09-13T11:24:21.437062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7: Evaluate Predictions - Tahminleri Değerlendirin #\n\nTest setinde son tahminlerinizi yapmadan önce, modelinizin tahminlerini doğrulama setinde değerlendirmek iyi bir fikirdir. Bu, eğitimdeki sorunları teşhis etmenize veya modelinizin iyileştirilebileceği yollar önermenize yardımcı olabilir. İki yaygın doğrulama yöntemine bakacağız: **karışıklık matrisinin (confusion matrix)** çizilmesi ve **görsel doğrulama (visual validation)**.","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n    \ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T11:24:21.439121Z","iopub.execute_input":"2021-09-13T11:24:21.439341Z","iopub.status.idle":"2021-09-13T11:24:22.178721Z","shell.execute_reply.started":"2021-09-13T11:24:21.439315Z","shell.execute_reply":"2021-09-13T11:24:22.177933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Confusion Matrix - Karışıklık Matrisi ##\n\nBir [karışıklık matrisi (confusion matrix)](https://en.wikipedia.org/wiki/Confusion_matrix), tahmini sınıfına göre tablo haline getirilmiş bir görüntünün gerçek sınıfını gösterir. Bir sınıflandırıcının performansını değerlendirmek için sahip olduğunuz en iyi araçlardan biridir.\n\nAşağıdaki hücre, doğrulama verileri üzerinde bazı işlemler yapar ve ardından [`scikit-learn`](https://scikit-learn.org/stable/index.html) içinde bulunan `confusion_matrix` işleviyle matrisi oluşturur.","metadata":{}},{"cell_type":"code","source":"cmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:24:22.180201Z","iopub.execute_input":"2021-09-13T11:24:22.180479Z","iopub.status.idle":"2021-09-13T11:24:34.445869Z","shell.execute_reply.started":"2021-09-13T11:24:22.180448Z","shell.execute_reply":"2021-09-13T11:24:34.444933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[F1 puanı(score)](https://en.wikipedia.org/wiki/F1_score) veya [kesinlik ve hatırlama (precision and recall)](https://en.wikipedia.org/wiki/Precision_and_recall) gibi metriklere aşina olabilirsiniz. Bu hücre, bu metrikleri hesaplayacak ve bunları karışıklık matrisinin bir grafiğiyle görüntüleyecektir. (Bu metrikler, Scikit-learn modülü `sklearn.metrics` içinde tanımlanmıştır; bunları sizin için yardımcı komut dosyasına aktardık.)","metadata":{}},{"cell_type":"code","source":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:24:34.447534Z","iopub.execute_input":"2021-09-13T11:24:34.447839Z","iopub.status.idle":"2021-09-13T11:24:38.951542Z","shell.execute_reply.started":"2021-09-13T11:24:34.447802Z","shell.execute_reply":"2021-09-13T11:24:38.950465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visual Validation - Görsel Doğrulama ##\n\nDoğrulama setinden bazı örneklere bakmak ve modelinizin hangi sınıfı tahmin ettiğini görmek de yardımcı olabilir. Bu, modelinizin sorun yaşadığı görüntü türlerindeki kalıpları ortaya çıkarmaya yardımcı olabilir.\n\nBu hücre, doğrulama setini bir seferde 20 görüntü gösterecek şekilde ayarlayacaktır - isterseniz bunu daha fazla veya daha az görüntülenecek şekilde değiştirebilirsiniz.","metadata":{}},{"cell_type":"code","source":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:24:38.95383Z","iopub.execute_input":"2021-09-13T11:24:38.954124Z","iopub.status.idle":"2021-09-13T11:24:38.990461Z","shell.execute_reply.started":"2021-09-13T11:24:38.954088Z","shell.execute_reply":"2021-09-13T11:24:38.989701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ve burada tahmin edilen türleriyle bir dizi çiçek var. Başka bir küme görmek için hücreyi tekrar çalıştırın.","metadata":{}},{"cell_type":"code","source":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:24:38.991591Z","iopub.execute_input":"2021-09-13T11:24:38.991793Z","iopub.status.idle":"2021-09-13T11:24:52.531341Z","shell.execute_reply.started":"2021-09-13T11:24:38.991771Z","shell.execute_reply":"2021-09-13T11:24:52.530454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8: Make Test Predictions - Test Tahminleri Yapın #\n\nHer şeyden memnun kaldığınızda, test setinde tahminler yapmaya hazırsınız.","metadata":{}},{"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:24:52.532548Z","iopub.execute_input":"2021-09-13T11:24:52.532776Z","iopub.status.idle":"2021-09-13T11:25:06.353733Z","shell.execute_reply.started":"2021-09-13T11:24:52.532749Z","shell.execute_reply":"2021-09-13T11:25:06.352921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bir `submission.csv` dosyası oluşturacağız. Bu dosya, skor tablosunda puanınızı almak için göndereceğiniz dosyadır.","metadata":{}},{"cell_type":"code","source":"print('Generating submission.csv file...')\n\n# Get image ids from test set and convert to unicode\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n\n# Write the submission file\nnp.savetxt(\n    'submission.csv',\n    np.rec.fromarrays([test_ids, predictions]),\n    fmt=['%s', '%d'],\n    delimiter=',',\n    header='id,label',\n    comments='',\n)\n\n# Look at the first few predictions\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2021-09-13T11:25:06.355006Z","iopub.execute_input":"2021-09-13T11:25:06.355591Z","iopub.status.idle":"2021-09-13T11:25:09.4605Z","shell.execute_reply.started":"2021-09-13T11:25:06.355548Z","shell.execute_reply":"2021-09-13T11:25:09.459671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9: Make a submission #\n\nIf you haven't already, create your own editable copy of this notebook by clicking on the **Copy and Edit** button in the top right corner. Then, submit to the competition by following these steps:\n\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161321) to chat with other Learners.*","metadata":{}}]}