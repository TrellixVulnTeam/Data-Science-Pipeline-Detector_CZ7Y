{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-15T04:47:34.122576Z","iopub.execute_input":"2022-05-15T04:47:34.122938Z","iopub.status.idle":"2022-05-15T04:47:34.191155Z","shell.execute_reply.started":"2022-05-15T04:47:34.122906Z","shell.execute_reply":"2022-05-15T04:47:34.190189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_imgs = os.listdir(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train\")\ntest_imgs = os.listdir(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test\")\nval_imgs = os.listdir(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:34.238118Z","iopub.execute_input":"2022-05-15T04:47:34.238454Z","iopub.status.idle":"2022-05-15T04:47:34.2452Z","shell.execute_reply.started":"2022-05-15T04:47:34.238421Z","shell.execute_reply":"2022-05-15T04:47:34.244514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:34.326408Z","iopub.execute_input":"2022-05-15T04:47:34.327109Z","iopub.status.idle":"2022-05-15T04:47:46.507799Z","shell.execute_reply.started":"2022-05-15T04:47:34.327067Z","shell.execute_reply":"2022-05-15T04:47:46.506847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nimport io\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset , DataLoader\nfrom torchvision import transforms , models\nfrom torch.optim import SGD\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:46.511405Z","iopub.execute_input":"2022-05-15T04:47:46.511689Z","iopub.status.idle":"2022-05-15T04:47:46.520948Z","shell.execute_reply.started":"2022-05-15T04:47:46.511655Z","shell.execute_reply":"2022-05-15T04:47:46.519946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feature_description = {\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\ntest_feature_description = {\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:46.521887Z","iopub.execute_input":"2022-05-15T04:47:46.522118Z","iopub.status.idle":"2022-05-15T04:47:46.532994Z","shell.execute_reply.started":"2022-05-15T04:47:46.522089Z","shell.execute_reply":"2022-05-15T04:47:46.531973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _parse_image_function(example_proto):\n return tf.io.parse_single_example(example_proto, train_feature_description)\ndef second_parse_image_function(example_proto):\n return tf.io.parse_single_example(example_proto, test_feature_description)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:46.535459Z","iopub.execute_input":"2022-05-15T04:47:46.535747Z","iopub.status.idle":"2022-05-15T04:47:46.551373Z","shell.execute_reply.started":"2022-05-15T04:47:46.535716Z","shell.execute_reply":"2022-05-15T04:47:46.550465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_lis = []\nval_lis = []\ntest_lis = []\n\nfor i in train_imgs:\n  train_lis.append(tf.data.TFRecordDataset(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/\"+i))\n\nfor i in val_imgs:\n  val_lis.append(tf.data.TFRecordDataset(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/\"+i))\n\nfor i in test_imgs:\n  test_lis.append(tf.data.TFRecordDataset(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/\"+i))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:46.552879Z","iopub.execute_input":"2022-05-15T04:47:46.553122Z","iopub.status.idle":"2022-05-15T04:47:46.832006Z","shell.execute_reply.started":"2022-05-15T04:47:46.553094Z","shell.execute_reply":"2022-05-15T04:47:46.831243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids = []\ntrain_classes = []\ntrain_images = []\n\nval_ids = []\nval_classes = []\nval_images = []\n\ntest_ids = []\ntest_images = []\n\nfor tl in train_lis:\n  temp = tl.map(_parse_image_function)\n  for t in temp:\n    train_classes.append(t[\"class\"].numpy())\n    train_ids.append(str(t[\"id\"].numpy())[2:-1])\n    train_images.append(t[\"image\"].numpy())\n    \nfor tl in val_lis:\n  temp = tl.map(_parse_image_function)\n  for t in temp:\n    val_classes.append(t[\"class\"].numpy())\n    val_ids.append(str(t[\"id\"].numpy())[2:-1])\n    val_images.append(t[\"image\"].numpy())\n\nfor tl in test_lis:\n  temp = tl.map(second_parse_image_function)\n  for t in temp:\n    test_ids.append(str(t[\"id\"].numpy())[2:-1])\n    test_images.append(t[\"image\"].numpy())","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:46.833223Z","iopub.execute_input":"2022-05-15T04:47:46.833885Z","iopub.status.idle":"2022-05-15T04:47:56.573159Z","shell.execute_reply.started":"2022-05-15T04:47:46.833847Z","shell.execute_reply":"2022-05-15T04:47:56.57227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustDat(Dataset):\n    def __init__(self , images , classes , ids , transform , mode):\n        self.images = images\n        self.classes = classes\n        self.ids = ids\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self , idx):\n        img = Image.open(io.BytesIO(self.images[idx]))\n        img = self.transform(img)\n        if self.mode == \"test\":\n            idd = self.ids[idx]\n            return (img , idd)\n        else:\n            label = self.classes[idx]\n            return (img , label)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:56.574537Z","iopub.execute_input":"2022-05-15T04:47:56.57479Z","iopub.status.idle":"2022-05-15T04:47:56.583347Z","shell.execute_reply.started":"2022-05-15T04:47:56.574762Z","shell.execute_reply":"2022-05-15T04:47:56.582219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((120 , 120)) , \n    transforms.ToTensor() , \n    transforms.Normalize((0 , 0 , 0) , (1 , 1 , 1))\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:56.58454Z","iopub.execute_input":"2022-05-15T04:47:56.584826Z","iopub.status.idle":"2022-05-15T04:47:56.601172Z","shell.execute_reply.started":"2022-05-15T04:47:56.584797Z","shell.execute_reply":"2022-05-15T04:47:56.600188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cust = CustDat(train_images , train_classes , None , transform , \"train\")\nval_cust = CustDat(val_images , val_classes , None , transform , \"val\")\ntest_cust = CustDat(test_images , None , test_ids , transform , \"test\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:56.602864Z","iopub.execute_input":"2022-05-15T04:47:56.603248Z","iopub.status.idle":"2022-05-15T04:47:56.656448Z","shell.execute_reply.started":"2022-05-15T04:47:56.603189Z","shell.execute_reply":"2022-05-15T04:47:56.65518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_model = models.resnet18(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:56.660623Z","iopub.execute_input":"2022-05-15T04:47:56.661126Z","iopub.status.idle":"2022-05-15T04:47:56.989656Z","shell.execute_reply.started":"2022-05-15T04:47:56.661089Z","shell.execute_reply":"2022-05-15T04:47:56.988856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tot_fr = temp_model.fc.in_features","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:56.990775Z","iopub.execute_input":"2022-05-15T04:47:56.991525Z","iopub.status.idle":"2022-05-15T04:47:56.995509Z","shell.execute_reply.started":"2022-05-15T04:47:56.991491Z","shell.execute_reply":"2022-05-15T04:47:56.994742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_model.fc = nn.Linear(tot_fr , len(train_classes))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:56.996667Z","iopub.execute_input":"2022-05-15T04:47:56.996893Z","iopub.status.idle":"2022-05-15T04:47:57.067892Z","shell.execute_reply.started":"2022-05-15T04:47:56.996867Z","shell.execute_reply":"2022-05-15T04:47:57.06677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SERIAL_EXEC = xmp.MpSerialExecutor()\nWRAPPED_MODEL = xmp.MpModelWrapper(temp_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:57.06925Z","iopub.execute_input":"2022-05-15T04:47:57.069893Z","iopub.status.idle":"2022-05-15T04:47:57.081316Z","shell.execute_reply.started":"2022-05-15T04:47:57.069847Z","shell.execute_reply":"2022-05-15T04:47:57.080199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(rank):\n  train_sampler = torch.utils.data.distributed.DistributedSampler(\n      train_cust , \n      num_replicas = 8 , \n      rank = xm.get_ordinal() , \n      shuffle = True , \n      seed = 0\n  )\n  val_sampler = torch.utils.data.distributed.DistributedSampler(\n      val_cust , \n      num_replicas = 8 , \n      rank = xm.get_ordinal() , \n      shuffle = True , \n      seed = 0\n  )\n  train_loader = DataLoader(\n      train_cust , \n      batch_size = 16 , \n      sampler = train_sampler , \n      num_workers = 1 , \n      drop_last = False\n  )\n  val_loader = DataLoader(\n      val_cust , \n      batch_size = 16 , \n      sampler = val_sampler , \n      num_workers = 1 , \n      drop_last = False\n  )\n  test_loader = DataLoader(\n      test_cust , \n      batch_size = 16 ,\n      num_workers = 1 , \n      drop_last = False\n  )\n  device = xm.xla_device()\n  model = WRAPPED_MODEL.to(device)\n  lr = 0.01 * xm.xrt_world_size()\n  optimizer = SGD(model.parameters() , lr = lr)\n  loss_fn = nn.CrossEntropyLoss()\n\n  num_epochs = 10\n\n  for epoch in range(num_epochs):\n\n    #training\n    para_loader = pl.ParallelLoader(train_loader , [device])\n    train_loss = []\n    train_corr = 0\n    train_sam = 0\n    model.train()\n    for x , (data , label) in enumerate(para_loader.per_device_loader(device)):\n      optimizer.zero_grad()\n      output = model(data)\n      loss = loss_fn(output , label)\n      #accuracy\n      _ , pred = torch.max(output , 1)\n      train_corr += (pred == label).sum()\n      train_sam += label.shape[0]\n      loss.backward()\n      train_loss.append(loss.item())\n      xm.optimizer_step(optimizer)\n      \n    #evaluation\n    model.eval()\n    val_loss = []\n    val_corr = 0\n    val_sam = 0\n    with torch.no_grad():\n      para_loader = pl.ParallelLoader(val_loader , [device])\n      for x , (data , label) in enumerate(para_loader.per_device_loader(device)):\n        output = model(data)\n        loss = loss_fn(output , label)\n        #accuracy\n        _ , pred = torch.max(output , 1)\n        val_corr += (pred == label).sum()\n        val_sam += label.shape[0]\n        val_loss.append(loss.item())\n\n    t_ac = 100.0 * train_corr / train_sam\n    v_ac = 100.0 * val_corr / val_sam\n    t_lo = torch.sum(torch.Tensor(train_loss))\n    v_lo = torch.sum(torch.Tensor(val_loss))\n    \n    print(\"epoch is \",epoch,\" train accu \",t_ac,\" train loss \",t_lo,\" val accu \",v_ac,\" val loss \",v_lo)\n  \n  if xm.is_master_ordinal():\n    dic = {}\n    model.eval()\n    with torch.no_grad():\n      para_loader = pl.ParallelLoader(test_loader , [device])\n      for x , (data , ids) in enumerate(para_loader.per_device_loader(device)):\n        output = model(data)\n        _ , pred = torch.max(output , 1)\n        for i in range(pred.shape[0]):\n          dic[ids[i]] = int(pred[i].cpu().detach().numpy())\n      df = pd.DataFrame(dic.items())\n      df.to_csv(\"fin_sub.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:57.08323Z","iopub.execute_input":"2022-05-15T04:47:57.083577Z","iopub.status.idle":"2022-05-15T04:47:57.106037Z","shell.execute_reply.started":"2022-05-15T04:47:57.083517Z","shell.execute_reply":"2022-05-15T04:47:57.105203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xmp.spawn(run , nprocs = 8 , start_method = \"fork\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:47:57.107299Z","iopub.execute_input":"2022-05-15T04:47:57.107532Z","iopub.status.idle":"2022-05-15T04:52:52.212016Z","shell.execute_reply.started":"2022-05-15T04:47:57.1075Z","shell.execute_reply":"2022-05-15T04:52:52.208577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:52:59.988759Z","iopub.execute_input":"2022-05-15T04:52:59.991727Z","iopub.status.idle":"2022-05-15T04:53:00.004632Z","shell.execute_reply.started":"2022-05-15T04:52:59.991474Z","shell.execute_reply":"2022-05-15T04:53:00.002942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dff = pd.read_csv('fin_sub.csv')\ndff.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:53:01.396087Z","iopub.execute_input":"2022-05-15T04:53:01.396836Z","iopub.status.idle":"2022-05-15T04:53:01.473616Z","shell.execute_reply.started":"2022-05-15T04:53:01.396789Z","shell.execute_reply":"2022-05-15T04:53:01.471955Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin = pd.DataFrame({\"id\":dff[\"0\"].values , \"label\":dff[\"1\"].values})","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:52:52.321633Z","iopub.execute_input":"2022-05-15T04:52:52.322298Z","iopub.status.idle":"2022-05-15T04:52:52.338345Z","shell.execute_reply.started":"2022-05-15T04:52:52.32222Z","shell.execute_reply":"2022-05-15T04:52:52.335973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin.to_csv('submission.csv' , index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:52:52.341735Z","iopub.execute_input":"2022-05-15T04:52:52.342329Z","iopub.status.idle":"2022-05-15T04:52:52.401855Z","shell.execute_reply.started":"2022-05-15T04:52:52.342267Z","shell.execute_reply":"2022-05-15T04:52:52.39955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:53:21.23853Z","iopub.execute_input":"2022-05-15T04:53:21.238892Z","iopub.status.idle":"2022-05-15T04:53:21.244947Z","shell.execute_reply.started":"2022-05-15T04:53:21.238856Z","shell.execute_reply":"2022-05-15T04:53:21.244029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove(\"fin_sub.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:52:52.427816Z","iopub.execute_input":"2022-05-15T04:52:52.430387Z","iopub.status.idle":"2022-05-15T04:52:52.44292Z","shell.execute_reply.started":"2022-05-15T04:52:52.430322Z","shell.execute_reply":"2022-05-15T04:52:52.439509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T04:52:52.44641Z","iopub.execute_input":"2022-05-15T04:52:52.447607Z","iopub.status.idle":"2022-05-15T04:52:52.484495Z","shell.execute_reply.started":"2022-05-15T04:52:52.447484Z","shell.execute_reply":"2022-05-15T04:52:52.482187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}