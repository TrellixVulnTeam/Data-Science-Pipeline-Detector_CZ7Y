{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T17:53:08.530421Z","iopub.execute_input":"2022-04-04T17:53:08.530792Z","iopub.status.idle":"2022-04-04T17:53:08.640051Z","shell.execute_reply.started":"2022-04-04T17:53:08.530759Z","shell.execute_reply":"2022-04-04T17:53:08.639352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read tfrec","metadata":{}},{"cell_type":"code","source":"import glob\n\ntrain_files = glob.glob('../input/tpu-getting-started/tfrecords-jpeg-331x331/train/*.tfrec')\nval_files = glob.glob('../input/tpu-getting-started/tfrecords-jpeg-331x331/val/*.tfrec')\ntest_files = glob.glob('../input/tpu-getting-started/tfrecords-jpeg-331x331/test/*.tfrec')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:53:08.641788Z","iopub.execute_input":"2022-04-04T17:53:08.642032Z","iopub.status.idle":"2022-04-04T17:53:08.647978Z","shell.execute_reply.started":"2022-04-04T17:53:08.641997Z","shell.execute_reply":"2022-04-04T17:53:08.647236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ntf.random.set_seed(3407)\n\ntf.config.set_visible_devices([], 'GPU')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:53:08.648996Z","iopub.execute_input":"2022-04-04T17:53:08.649594Z","iopub.status.idle":"2022-04-04T17:53:13.075818Z","shell.execute_reply.started":"2022-04-04T17:53:08.649555Z","shell.execute_reply":"2022-04-04T17:53:13.074417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feature_description = {\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n    return tf.io.parse_single_example(example_proto, train_feature_description)\n\ntrain_ids, train_class, train_images = [], [], []\n\nfor i in train_files:\n    train_image_dataset = tf.data.TFRecordDataset(i)\n\n    train_image_dataset = train_image_dataset.map(_parse_image_function)\n\n    ids = [str(id_features['id'].numpy())[2:-1] for id_features in train_image_dataset]\n    train_ids = train_ids + ids\n\n    classes = [int(class_features['class'].numpy()) for class_features in train_image_dataset]\n    train_class = train_class + classes\n\n    images = [image_features['image'].numpy() for image_features in train_image_dataset]\n    train_images = train_images + images\n    \nval_ids, val_class, val_images = [], [], []\n\nfor i in val_files:\n    val_image_dataset = tf.data.TFRecordDataset(i)\n\n    val_image_dataset = val_image_dataset.map(_parse_image_function)\n\n    ids = [str(image_features['id'].numpy())[2:-1] for image_features in val_image_dataset]\n    val_ids += ids\n\n    classes = [int(image_features['class'].numpy()) for image_features in val_image_dataset]\n    val_class += classes \n\n    images = [image_features['image'].numpy() for image_features in val_image_dataset]\n    val_images += images\n    \ntest_feature_description = {\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function_test(example_proto):\n    return tf.io.parse_single_example(example_proto, test_feature_description)\n\ntest_ids, test_images = [], []\nfor i in test_files:\n    test_image_dataset = tf.data.TFRecordDataset(i)\n    \n    test_image_dataset = test_image_dataset.map(_parse_image_function_test)\n\n    ids = [str(id_features['id'].numpy())[2:-1] for id_features in test_image_dataset]\n    test_ids = test_ids + ids\n\n    images = [image_features['image'].numpy() for image_features in test_image_dataset]\n    test_images = test_images + images","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:53:13.078048Z","iopub.execute_input":"2022-04-04T17:53:13.078566Z","iopub.status.idle":"2022-04-04T17:54:02.924056Z","shell.execute_reply.started":"2022-04-04T17:53:13.078525Z","shell.execute_reply":"2022-04-04T17:54:02.923309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as display\n\ndisplay.display(display.Image(data=val_images[1]))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:02.927141Z","iopub.execute_input":"2022-04-04T17:54:02.927338Z","iopub.status.idle":"2022-04-04T17:54:02.936196Z","shell.execute_reply.started":"2022-04-04T17:54:02.927313Z","shell.execute_reply":"2022-04-04T17:54:02.935564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"!pip install -qU albumentations","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:02.937287Z","iopub.execute_input":"2022-04-04T17:54:02.938014Z","iopub.status.idle":"2022-04-04T17:54:11.799745Z","shell.execute_reply.started":"2022-04-04T17:54:02.937977Z","shell.execute_reply":"2022-04-04T17:54:11.798745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\n\ncrop_h, crop_w = 224, 224\n\ntransform = A.Compose([\n    A.RandomCrop(crop_h, crop_w),\n    A.HorizontalFlip(),\n    A.VerticalFlip(),\n    A.Rotate(10),\n    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n    A.CoarseDropout(max_holes=10, max_height=20, max_width=20, p=0.2),\n])\n\nval_transform = A.Compose([\n    A.CenterCrop(crop_h, crop_w),\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:11.803206Z","iopub.execute_input":"2022-04-04T17:54:11.803445Z","iopub.status.idle":"2022-04-04T17:54:13.532498Z","shell.execute_reply.started":"2022-04-04T17:54:11.803413Z","shell.execute_reply":"2022-04-04T17:54:13.531731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nfrom io import BytesIO\nimport numpy as np\n\nnrows, ncol = 3, 3\n_, axs = plt.subplots(nrows, ncol, figsize=(14, 14))\n\nimg = np.array(Image.open(BytesIO(train_images[-1])))\n\nfor i in range(nrows):\n    for j in range(ncol):\n        transformed = transform(image=img)[\"image\"]\n        axs[i][j].imshow(transformed)\n        axs[i][j].axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:13.533762Z","iopub.execute_input":"2022-04-04T17:54:13.534004Z","iopub.status.idle":"2022-04-04T17:54:14.597715Z","shell.execute_reply.started":"2022-04-04T17:54:13.533972Z","shell.execute_reply":"2022-04-04T17:54:14.595413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import torch\n\ntorch.manual_seed(3407)\ntorch.cuda.manual_seed_all(3407)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:14.598695Z","iopub.execute_input":"2022-04-04T17:54:14.59895Z","iopub.status.idle":"2022-04-04T17:54:14.61325Z","shell.execute_reply.started":"2022-04-04T17:54:14.598911Z","shell.execute_reply":"2022-04-04T17:54:14.612689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms \n\nclass FlowerDS(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images, self.labels = images, labels\n        self.transform = transform\n        self.to_tensor = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        img = self.images[idx]\n        img = np.array(Image.open(BytesIO(img)))\n        img = self.transform(image=img)[\"image\"]\n        img = self.to_tensor(img)\n        return img, self.labels[idx]\n    \ntrain_ds = FlowerDS(train_images, train_class, transform)\nval_ds = FlowerDS(val_images, val_class, val_transform)\ntest_ds = FlowerDS(test_images, test_ids, val_transform)\n\nbatch_size = 8\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\ntest_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:14.616148Z","iopub.execute_input":"2022-04-04T17:54:14.616661Z","iopub.status.idle":"2022-04-04T17:54:14.828622Z","shell.execute_reply.started":"2022-04-04T17:54:14.616625Z","shell.execute_reply":"2022-04-04T17:54:14.827866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"!pip install -q vistrans","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:14.830027Z","iopub.execute_input":"2022-04-04T17:54:14.830281Z","iopub.status.idle":"2022-04-04T17:54:22.521891Z","shell.execute_reply.started":"2022-04-04T17:54:14.830247Z","shell.execute_reply":"2022-04-04T17:54:22.521077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vistrans import VisionTransformer\n\nVisionTransformer.list_pretrained()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:22.524474Z","iopub.execute_input":"2022-04-04T17:54:22.525229Z","iopub.status.idle":"2022-04-04T17:54:22.537853Z","shell.execute_reply.started":"2022-04-04T17:54:22.525188Z","shell.execute_reply":"2022-04-04T17:54:22.537086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass ViT(nn.Module):\n    def __init__(self, num_classes=104):\n        super().__init__()\n        \n        self.model = VisionTransformer.create_pretrained(\"vit_l16_224\", num_classes=num_classes)\n\n        for param in self.model.parameters():\n            param.require_grad = True\n\n    def forward(self, x):\n        return self.model(x)\n    \nmodel = ViT()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:22.539564Z","iopub.execute_input":"2022-04-04T17:54:22.542448Z","iopub.status.idle":"2022-04-04T17:54:46.71739Z","shell.execute_reply.started":"2022-04-04T17:54:22.54242Z","shell.execute_reply":"2022-04-04T17:54:46.716723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"!pip -q install madgrad","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:46.718618Z","iopub.execute_input":"2022-04-04T17:54:46.718989Z","iopub.status.idle":"2022-04-04T17:54:56.744041Z","shell.execute_reply.started":"2022-04-04T17:54:46.718944Z","shell.execute_reply":"2022-04-04T17:54:56.743204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nfrom madgrad import MADGRAD\n\nepochs = 20\n\noptimizer = MADGRAD(model.parameters(), lr=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 1e-5)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:58:26.081611Z","iopub.execute_input":"2022-04-04T17:58:26.082385Z","iopub.status.idle":"2022-04-04T17:58:26.090494Z","shell.execute_reply.started":"2022-04-04T17:58:26.08233Z","shell.execute_reply":"2022-04-04T17:58:26.089493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\nimport gc\n\nbest_val_loss, best_state_dict = float(\"inf\"), None\ntrain_losses, val_losses = [], []\nfor e in range(epochs):\n    print(f\"Epoch {e + 1}\")\n    \n    model.train()\n    running_loss, running_acc = 0, 0\n    for x, y in train_dl:\n        x, y = x.to(device), y.to(device)\n        \n        optimizer.zero_grad()\n        \n        out = model(x)\n        \n        loss = criterion(out, y)\n        running_loss += loss.item()\n    \n        _, pred = out.max(dim=1)\n        running_acc += torch.sum(pred == y.data) / len(pred)\n    \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n    scheduler.step()\n    \n    print(f\"Train loss {running_loss / len(train_dl)} accuracy {running_acc / len(train_dl)}\")\n    train_losses.append(running_loss / len(train_dl))\n    \n    model.eval()\n    running_loss, running_acc = 0, 0\n    for x, y in val_dl:\n        x, y = x.to(device), y.to(device)\n                \n        with torch.no_grad():\n            out = model(x)\n            \n            loss = criterion(out, y)\n            running_loss += loss.item()\n\n            _, pred = out.max(dim=1)\n            running_acc += torch.sum(pred == y.data) / len(pred)\n\n    print(f\"Validation loss {running_loss / len(val_dl)} accuracy {running_acc / len(val_dl)}\")\n    val_losses.append(running_loss / len(val_dl))\n    \n    if running_loss < best_val_loss:\n        best_val_loss = running_loss\n        best_state_dict = copy.deepcopy(model.state_dict())\n        \n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:58:28.744484Z","iopub.execute_input":"2022-04-04T17:58:28.745056Z","iopub.status.idle":"2022-04-04T18:14:42.491035Z","shell.execute_reply.started":"2022-04-04T17:58:28.745017Z","shell.execute_reply":"2022-04-04T18:14:42.489596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = np.arange(0, epochs)\n\nplt.figure(figsize=(8, 8))\nplt.plot(n, train_losses, label=\"Train loss\")\nplt.plot(n, val_losses, label=\"Val loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:14:42.492166Z","iopub.status.idle":"2022-04-04T18:14:42.493105Z","shell.execute_reply.started":"2022-04-04T18:14:42.492844Z","shell.execute_reply":"2022-04-04T18:14:42.492871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(best_state_dict, \"best_model.pt\")\nmodel.load_state_dict(torch.load(\"best_model.pt\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:14:42.494318Z","iopub.status.idle":"2022-04-04T18:14:42.494923Z","shell.execute_reply.started":"2022-04-04T18:14:42.494681Z","shell.execute_reply":"2022-04-04T18:14:42.494707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test_id, test_label = np.array([]), np.array([])\nmodel.eval()\nfor x, y in test_dl:\n    x = x.to(device) \n    \n    with torch.no_grad():\n        pred = model(x)\n\n    test_label = np.append(test_label, pred.argmax(dim=1).cpu().detach().numpy()) \n    test_id = np.append(test_id, y)\ntest_label = list(map(int, test_label))\ntest_label[:10]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:14:42.496419Z","iopub.status.idle":"2022-04-04T18:14:42.496816Z","shell.execute_reply.started":"2022-04-04T18:14:42.496599Z","shell.execute_reply":"2022-04-04T18:14:42.496621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame({\"id\": test_id, \"label\": test_label}).to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:14:42.498233Z","iopub.status.idle":"2022-04-04T18:14:42.498652Z","shell.execute_reply.started":"2022-04-04T18:14:42.498432Z","shell.execute_reply":"2022-04-04T18:14:42.498455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:57.172991Z","iopub.status.idle":"2022-04-04T17:54:57.173572Z","shell.execute_reply.started":"2022-04-04T17:54:57.173359Z","shell.execute_reply":"2022-04-04T17:54:57.173383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-04-04T17:54:57.169581Z","iopub.status.idle":"2022-04-04T17:54:57.170161Z","shell.execute_reply.started":"2022-04-04T17:54:57.169936Z","shell.execute_reply":"2022-04-04T17:54:57.169958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:14:42.499836Z","iopub.status.idle":"2022-04-04T18:14:42.500418Z","shell.execute_reply.started":"2022-04-04T18:14:42.500159Z","shell.execute_reply":"2022-04-04T18:14:42.500187Z"},"trusted":true},"execution_count":null,"outputs":[]}]}