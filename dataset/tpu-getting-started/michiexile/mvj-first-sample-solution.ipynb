{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-06T15:11:45.649733Z","iopub.execute_input":"2022-04-06T15:11:45.650129Z","iopub.status.idle":"2022-04-06T15:11:45.704861Z","shell.execute_reply.started":"2022-04-06T15:11:45.65008Z","shell.execute_reply":"2022-04-06T15:11:45.704059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nprint(f\"Tensorflow version ${tf.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:11:56.246562Z","iopub.execute_input":"2022-04-06T15:11:56.247505Z","iopub.status.idle":"2022-04-06T15:11:56.253399Z","shell.execute_reply.started":"2022-04-06T15:11:56.247454Z","shell.execute_reply":"2022-04-06T15:11:56.252406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU Distribution Strategies\n\nWe are going to be using the Tensor Processing Units (TPUs) in this competition. These are specialized co-processors built specifically for machine learning type computations. You can think of a single TPU as having 8 GPUs running in parallel to each other. We will need to tell Tensorflow how to best utilize the entire spread of 8 cores.","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f\"Running on TPU: ${tpu.master()}\")\nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(f\"REPLICAS: {strategy.num_replicas_in_sync}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:11:58.110309Z","iopub.execute_input":"2022-04-06T15:11:58.110633Z","iopub.status.idle":"2022-04-06T15:12:04.147636Z","shell.execute_reply.started":"2022-04-06T15:11:58.110587Z","shell.execute_reply":"2022-04-06T15:12:04.146736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Kaggle data to a TPU\n\nThe TPU system reads from a specialized google cloud filesystem, called Google Cloud Storage (GCS). So we will need to find our kaggle data on GCS to use it in our models.\n\nTo use any other Kaggle dataset, replace `tpu-getting-started` with the path slug for that dataset. Non-Kaggle datasets are more difficult.","metadata":{}},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(\"tpu-getting-started\")\nprint(GCS_DS_PATH)\n!gsutil ls $GCS_DS_PATH","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:04.149064Z","iopub.execute_input":"2022-04-06T15:12:04.149383Z","iopub.status.idle":"2022-04-06T15:12:07.674551Z","shell.execute_reply.started":"2022-04-06T15:12:04.14935Z","shell.execute_reply":"2022-04-06T15:12:07.673682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224] # or 192, 224, 331, 512\nGCS_PATH = f\"{GCS_DS_PATH}/tfrecords-jpeg-{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}\"\n\nTRAINING_FILENAMES = tf.io.gfile.glob(f\"{GCS_PATH}/train/*.tfrec\")\nVALIDATION_FILENAMES = tf.io.gfile.glob(f\"{GCS_PATH}/val/*.tfrec\")\nTEST_FILENAMES = tf.io.gfile.glob(f\"{GCS_PATH}/test/*.tfrec\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:07.676296Z","iopub.execute_input":"2022-04-06T15:12:07.676564Z","iopub.status.idle":"2022-04-06T15:12:07.94047Z","shell.execute_reply.started":"2022-04-06T15:12:07.676531Z","shell.execute_reply":"2022-04-06T15:12:07.939462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.data.experimental import AUTOTUNE\n\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', \n           'canterbury bells', 'sweet pea',     \n           'wild geranium',    'tiger lily',           \n           'moon orchid',      'bird of paradise', \n           'monkshood',        'globe thistle',         # 00 - 09\n           \n           'snapdragon',       \"colt's foot\",               \n           'king protea',      'spear thistle', \n           'yellow iris',      'globe-flower',\n           'purple coneflower','peruvian lily',\n           'balloon flower',   'giant white arum lily', # 10 - 19\n           \n           'fire lily',        'pincushion flower',\n           'fritillary',       'red ginger',\n           'grape hyacinth',    'corn poppy',\n           'prince of wales feathers', 'stemless gentian',\n           'artichoke',        'sweet william',         # 20 - 29\n           \n           'carnation',        'garden phlox',\n           'love in the mist', 'cosmos',\n           'alpine sea holly', 'ruby-lipped cattleya',\n           'cape flower',      'great masterwort',\n           'siam tulip',       'lenten rose',           # 30 - 39\n           \n           'barberton daisy',  'daffodil',\n           'sword lily',       'poinsettia',\n           'bolero deep blue', 'wallflower',\n           'marigold',         'buttercup',\n           'daisy',            'common dandelion',      # 40 - 49\n           \n           'petunia',          'wild pansy',\n           'primula',          'sunflower',\n           'lilac hibiscus',   'bishop of llandaff',\n           'gaura',            'geranium',\n           'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           \n           'cautleya spicata', 'japanese anemone',\n           'black-eyed susan', 'silverbush',\n           'californian poppy','osteospermum',\n           'spring crocus',    'iris',\n           'windflower',       'tree poppy',            # 60 - 69\n           \n           'gazania',          'azalea',\n           'water lily',       'rose',\n           'thorn apple',      'morning glory',\n           'passion flower',   'lotus',\n           'toad lily',        'anthurium',             # 70 - 79\n           \n           'frangipani',       'clematis',\n           'hibiscus',         'columbine',\n           'desert-rose',      'tree mallow',\n           'magnolia',         'cyclamen ',\n           'watercress',       'canna lily',            # 80 - 89\n           \n           'hippeastrum ',     'bee balm',\n           'pink quill',       'foxglove',\n           'bougainvillea',    'camellia',\n           'mallow',           'mexican petunia',\n           'bromelia',         'blanket flower',        # 90 - 99\n           \n           'trumpet creeper',  'blackberry lily',\n           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32)/255.0\n    image = tf.reshape(image, [*IMAGE_SIZE,3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFR_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFR_FORMAT)\n    image = decode_image(example[\"image\"])\n    label = tf.cast(example[\"class\"], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFR_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFR_FORMAT)\n    image = decode_image(example[\"image\"])\n    idnum = example[\"id\"]\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n    dataset = dataset.with_options(ignore_order)\n    if labeled:\n        dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTOTUNE)\n    else:\n        dataset = dataset.map(read_unlabeled_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:10.881868Z","iopub.execute_input":"2022-04-06T15:12:10.882173Z","iopub.status.idle":"2022-04-06T15:12:10.904303Z","shell.execute_reply.started":"2022-04-06T15:12:10.882131Z","shell.execute_reply":"2022-04-06T15:12:10.903354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nrng = tf.random.Generator.from_seed(4711, alg='philox')\ndef data_augment(image, label):\n    #seed = rng.make_seeds(2)[0]\n    #image = tf.image.stateless_random_brightness(image, 0.1, seed)\n    return image, label\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n    \ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n\nprint(f\"\"\"\n{NUM_TRAINING_IMAGES} training images\n{NUM_VALIDATION_IMAGES} validation images\n{NUM_TEST_IMAGES} unlabeled testing images\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:21.342647Z","iopub.execute_input":"2022-04-06T15:12:21.34294Z","iopub.status.idle":"2022-04-06T15:12:21.360509Z","shell.execute_reply.started":"2022-04-06T15:12:21.34291Z","shell.execute_reply":"2022-04-06T15:12:21.359389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = get_training_dataset()\nds_val = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(f\"\"\"\nTraining data: {ds_train}\nValidation data: {ds_val}\nTest data: {ds_test}\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:23.749222Z","iopub.execute_input":"2022-04-06T15:12:23.74972Z","iopub.status.idle":"2022-04-06T15:12:23.97306Z","shell.execute_reply.started":"2022-04-06T15:12:23.749683Z","shell.execute_reply":"2022-04-06T15:12:23.972096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(f\"Training data labels: \\n{label.numpy()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:25.548118Z","iopub.execute_input":"2022-04-06T15:12:25.548424Z","iopub.status.idle":"2022-04-06T15:12:26.622311Z","shell.execute_reply.started":"2022-04-06T15:12:25.548394Z","shell.execute_reply":"2022-04-06T15:12:26.621428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(f\"Test data labels: \\n{idnum.numpy().astype('U')}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:28.124389Z","iopub.execute_input":"2022-04-06T15:12:28.12471Z","iopub.status.idle":"2022-04-06T15:12:28.952794Z","shell.execute_reply.started":"2022-04-06T15:12:28.124677Z","shell.execute_reply":"2022-04-06T15:12:28.951757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\n\nimage, label = next(ds_train.take(1).as_numpy_iterator())\npyplot.figure(figsize=(20,20))\nfor i in range(16):\n    pyplot.subplot(4,4,i+1)\n    pyplot.imshow(image[i,:,:,:])\n    pyplot.axis(\"off\")\n    pyplot.title(CLASSES[label[i]])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:44.490129Z","iopub.execute_input":"2022-04-06T15:12:44.49044Z","iopub.status.idle":"2022-04-06T15:12:47.254588Z","shell.execute_reply.started":"2022-04-06T15:12:44.490404Z","shell.execute_reply":"2022-04-06T15:12:47.253433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\nwith strategy.scope():\n    inputs = keras.Input(shape=[*IMAGE_SIZE, 3])\n    preprocess = keras.applications.mobilenet_v2.preprocess_input(inputs)\n    base_model = keras.applications.mobilenet_v2.MobileNetV2(\n        include_top=False, weights='imagenet', pooling='max')\n    base_model.trainable = False\n    features = base_model(preprocess)\n    outputs = keras.layers.Dense(len(CLASSES), activation=\"softmax\")(features)\n    model = keras.Model(inputs=inputs, outputs=outputs)\nprint(model.summary())\nkeras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:12:53.045691Z","iopub.execute_input":"2022-04-06T15:12:53.046483Z","iopub.status.idle":"2022-04-06T15:13:03.74701Z","shell.execute_reply.started":"2022-04-06T15:12:53.046436Z","shell.execute_reply":"2022-04-06T15:13:03.745844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First train with `base_model.trainable=False` and a high learning rate to get the top layer setup.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:13:03.749548Z","iopub.execute_input":"2022-04-06T15:13:03.749969Z","iopub.status.idle":"2022-04-06T15:13:03.798241Z","shell.execute_reply.started":"2022-04-06T15:13:03.749928Z","shell.execute_reply":"2022-04-06T15:13:03.797338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 24\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nhistories = []\nlocal_save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nhistories.append(model.fit(\n    ds_train,\n    validation_data=ds_val,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[keras.callbacks.ModelCheckpoint(\n        #\"weights.{epoch:02d}-{val_sparse_categorical_accuracy:.2f}.hdf5\",\n        \"best_model.hdf5\",\n        monitor=\"val_sparse_categorical_accuracy\",\n        save_best_only=True,\n        verbose=1,\n        options=local_save_options\n    ),\n    ]\n))\nmodel.load_weights(\"best_model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:13:03.799416Z","iopub.execute_input":"2022-04-06T15:13:03.79969Z","iopub.status.idle":"2022-04-06T15:16:23.757095Z","shell.execute_reply.started":"2022-04-06T15:13:03.799656Z","shell.execute_reply":"2022-04-06T15:16:23.756057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then gradually unfreeze the `base_model`, and train the entire ensemble as a unit.","metadata":{}},{"cell_type":"code","source":"EPOCHS = 12\n\n#base_model.trainable=True\nfor layer in base_model.layers[-20:]:\n    if not isinstance(layer, keras.layers.BatchNormalization):\n        layer.trainable = True\n        \nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy']\n)\nhistories.append(model.fit(\n    ds_train,\n    validation_data=ds_val,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[keras.callbacks.ModelCheckpoint(\n        #\"weights.{epoch:02d}-{val_sparse_categorical_accuracy:.2f}.hdf5\",\n        \"best_model.hdf5\",\n        monitor=\"val_sparse_categorical_accuracy\",\n        save_best_only=True,\n        verbose=1,\n        options=local_save_options\n    ),\n    ]\n))\nmodel.load_weights(\"best_model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:16:23.758946Z","iopub.execute_input":"2022-04-06T15:16:23.759157Z","iopub.status.idle":"2022-04-06T15:18:09.457349Z","shell.execute_reply.started":"2022-04-06T15:16:23.759132Z","shell.execute_reply":"2022-04-06T15:18:09.456368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 12\n\n#base_model.trainable=True\nfor layer in base_model.layers[-40:]:\n    if not isinstance(layer, keras.layers.BatchNormalization):\n        layer.trainable = True\n        \nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy']\n)\nhistories.append(model.fit(\n    ds_train,\n    validation_data=ds_val,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[keras.callbacks.ModelCheckpoint(\n        #\"weights.{epoch:02d}-{val_sparse_categorical_accuracy:.2f}.hdf5\",\n        \"best_model.hdf5\",\n        monitor=\"val_sparse_categorical_accuracy\",\n        save_best_only=True,\n        verbose=1,\n        options=local_save_options\n    ),\n    ]\n))\nmodel.load_weights(\"best_model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:18:09.459084Z","iopub.execute_input":"2022-04-06T15:18:09.459881Z","iopub.status.idle":"2022-04-06T15:19:53.545514Z","shell.execute_reply.started":"2022-04-06T15:18:09.459826Z","shell.execute_reply":"2022-04-06T15:19:53.544558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 12\n\n#base_model.trainable=True\nfor layer in base_model.layers:\n    if not isinstance(layer, keras.layers.BatchNormalization):\n        layer.trainable = True\n        \nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy']\n)\nhistories.append(model.fit(\n    ds_train,\n    validation_data=ds_val,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[keras.callbacks.ModelCheckpoint(\n        #\"weights.{epoch:02d}-{val_sparse_categorical_accuracy:.2f}.hdf5\",\n        \"best_model.hdf5\",\n        monitor=\"val_sparse_categorical_accuracy\",\n        save_best_only=True,\n        verbose=1,\n        options=local_save_options\n    ),\n    ]\n))\nmodel.load_weights(\"best_model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:19:53.547116Z","iopub.execute_input":"2022-04-06T15:19:53.547708Z","iopub.status.idle":"2022-04-06T15:21:38.846514Z","shell.execute_reply.started":"2022-04-06T15:19:53.547671Z","shell.execute_reply":"2022-04-06T15:21:38.845687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pyplot.figure(figsize=(16,8))\npyplot.plot(np.hstack([history.history[\"loss\"] for history in histories]))\npyplot.plot(np.hstack([history.history[\"val_loss\"] for history in histories]))\npyplot.title(\"Loss vs. Validation Loss\")\npyplot.xlabel(\"Epoch\")\npyplot.legend([\"train\", \"valid.\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:26:21.427758Z","iopub.execute_input":"2022-04-06T15:26:21.42819Z","iopub.status.idle":"2022-04-06T15:26:21.715322Z","shell.execute_reply.started":"2022-04-06T15:26:21.428159Z","shell.execute_reply":"2022-04-06T15:26:21.714556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pyplot.figure(figsize=(16,8))\npyplot.plot(np.hstack([history.history[\"sparse_categorical_accuracy\"] \n                  for history in histories]))\npyplot.plot(np.hstack([history.history[\"val_sparse_categorical_accuracy\"]\n                 for history in histories]))\npyplot.title(\"Accuracy vs. Validation Accuracy\")\npyplot.xlabel(\"Epoch\")\npyplot.legend([\"train\", \"valid.\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:26:31.532664Z","iopub.execute_input":"2022-04-06T15:26:31.533396Z","iopub.status.idle":"2022-04-06T15:26:31.80601Z","shell.execute_reply.started":"2022-04-06T15:26:31.533355Z","shell.execute_reply":"2022-04-06T15:26:31.805427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation work\n\nAt this point it would be helpful to display a confusion matrix, compute F1-scores, precision, recall, and to look at examples of validation images and how they get classified. We'll add that later.","metadata":{}},{"cell_type":"markdown","source":"# Test predictions and submission\n\nTime to make predictions on our data set and prepare a submission!","metadata":{}},{"cell_type":"code","source":"ds_test = get_test_dataset(ordered=True)\nds_test_images = ds_test.map(lambda image,idnum: image)\nds_test_idnums = ds_test.map(lambda image,idnum: idnum)\n\nprint(\"Computing predictions...\")\nprobabilities = model.predict(ds_test_images)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:09:28.997912Z","iopub.status.idle":"2022-04-06T15:09:28.998661Z","shell.execute_reply.started":"2022-04-06T15:09:28.998432Z","shell.execute_reply":"2022-04-06T15:09:28.998456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': next(iter(ds_test_idnums.unbatch().batch(NUM_TEST_IMAGES))).numpy().astype(\"U\"),\n    'label': predictions\n}).set_index('id')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:09:28.999863Z","iopub.status.idle":"2022-04-06T15:09:29.000211Z","shell.execute_reply.started":"2022-04-06T15:09:29.000028Z","shell.execute_reply":"2022-04-06T15:09:29.000048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:09:29.001534Z","iopub.status.idle":"2022-04-06T15:09:29.002384Z","shell.execute_reply.started":"2022-04-06T15:09:29.002118Z","shell.execute_reply":"2022-04-06T15:09:29.002149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}