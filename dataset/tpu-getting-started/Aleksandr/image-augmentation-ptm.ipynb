{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\n\n# работа с изображениями\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\n%matplotlib inline ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем seed рандомизатора\nimport os\nimport numpy as np\nfrom tensorflow.random import set_seed\ndef seed_everything(seed):\n    np.random.seed(seed)\n    set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 42\nseed_everything(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Подсасываем датасет\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(f'GCS_DS_PATH = {GCS_DS_PATH}\\n')\nIMAGE_SIZE = (512, 512)\n\nHEIGHT = IMAGE_SIZE[0]\nWIDTH = IMAGE_SIZE[1]\nCHANNELS = 3\nBATCH_SIZE = 32\n\nGCS_PATH_SELECT = {\n    (192, 192) : GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n    (224, 224): GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n    (331, 331): GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n    (512, 512): GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n}\n# Дергаем путь к картинкам в нужном разрешении\nGCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE]\nprint(GCS_PATH)\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Функции аугментации изображения\ndef random_brightness(image, label):\n    image = tf.image.random_brightness(image, max_delta=0.5, seed=seed)\n    return image, label\n\ndef random_contrast(image, label):\n    image = image = tf.image.random_contrast(image, lower=.2, upper=3, seed=seed)\n    return image, label\n\ndef random_saturation(image, label):\n    image = tf.image.random_saturation(image, lower=0, upper=2, seed=seed)\n    return image, label\n\ndef random_crop(image, label):\n    image = tf.image.random_crop(image, size=[int(HEIGHT*.8), int(WIDTH*.8), CHANNELS], seed=seed)\n    return image, label\n\ndef random_flip(image, label):\n    if all(np.random.randint(2, size=1)):\n        image = tf.image.random_flip_up_down(image, seed=seed)\n    if all(np.random.randint(2, size=1)):\n        tf.image.random_flip_left_right(image, seed=seed)\n    return image, label\n\ndef random_hue(image, label):\n    image = tf.image.random_hue(image, max_delta=0.5, seed=seed)\n    return image, label\n\ndef random_quality(image, label):\n    image = tf.image.random_jpeg_quality(image, min_jpeg_quality=1,max_jpeg_quality=100, seed=seed)\n    return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_plot(row, col, augmented_element, name):\n    for (img,label) in augmented_element:\n        plt.figure(figsize=(15,int(15*row/col)))\n        \n        for j in range(row*col):\n            plt.subplot(row,col,j+1)\n            plt.axis('off')\n            plt.imshow(img[j,])\n        plt.suptitle(name)\n        plt.show()\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_with(augment_function):\n    all_elements = get_training_dataset().unbatch()\n    one_element = tf.data.Dataset.from_tensors( next(iter(all_elements)) )\n    augmented_element = one_element.repeat().map(augment_function).batch(row*col)\n\n    make_plot(row, col,augmented_element,  augment_function.__name__)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = 3; col = 4;\naugment_with(random_brightness)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_with(random_contrast)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_with(random_saturation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_with(random_crop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_with(random_flip)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_with(random_hue)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_with(random_quality)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Использование ImageDataGenerator\nall_elements = get_training_dataset().unbatch()\none_element = next(iter(all_elements))\nsamples = np.expand_dims(one_element[0], 0)\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\ndatagen.fit(samples)\nit = datagen.flow(samples, batch_size=1)\n# Эмулируем эпохи\nrow = 3; col = 4;\n\nplt.figure(figsize=(15,int(15*row/col)))\nfor i in range(row*col):\n    plt.subplot(row,col,i+1)\n    plt.axis('off')\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}