{"cells":[{"metadata":{"papermill":{"duration":0.032087,"end_time":"2020-10-01T11:50:13.871075","exception":false,"start_time":"2020-10-01T11:50:13.838988","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Introduction\n\nThis is my solution to the Hash Code drone delivery problem, using optimization and routing routines from the Google OR-Tools package. Let me know what you think and feel free to leave an upvote if you like this kernel! Please comment if you have any ideas on how to improve this code - there surely are lots of improvements possible.\n\nCredits for data extraction:\n[Application of Google OR-Tools](https://www.kaggle.com/jpmiller/application-of-google-or-tools)\n\nThe general process of this solution is quite straightforward:\n* We determine where each product unit is to be delivered from to minimize total delivery distance. This does not make use of redistributing units between warehouses, we simply look at where products are now and where they need to go and attempt to deliver them on the most direct route possible. Certain products are only stored in one or two warehouses and may need to be delivered across the entire map.\n* For each warehouse separately, we look at all deliveries which need to be executed from there and combine them into single delivery routes as efficiently as possible to maximize the load utilization and minimize the travel distance of each route. We group orders by their \"difficulty\" (i.e., total weight and distance) to get a higher score, aka minimize the overall waiting time for the completion of an order.\n* Combining all single routes from all warehouses, we attempt to schedule each drone such that the distance between the end of a single route and the start of the next one are as close together as possible (this is the most computing-intensive part). We do this in steps, such that \"easy/fast\" orders are completed first for a higher score."},{"metadata":{"papermill":{"duration":0.031072,"end_time":"2020-10-01T11:50:13.932533","exception":false,"start_time":"2020-10-01T11:50:13.901461","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's start by importing some handy packages:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-01T11:50:13.999913Z","iopub.status.busy":"2020-10-01T11:50:13.99905Z","iopub.status.idle":"2020-10-01T11:50:14.275153Z","shell.execute_reply":"2020-10-01T11:50:14.27428Z"},"papermill":{"duration":0.312698,"end_time":"2020-10-01T11:50:14.275288","exception":false,"start_time":"2020-10-01T11:50:13.96259","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport matplotlib.cm as mcm\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom ortools.constraint_solver import routing_enums_pb2\nfrom ortools.constraint_solver import pywrapcp\nfrom ortools.graph import pywrapgraph\nimport pandas as pd\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.029422,"end_time":"2020-10-01T11:50:14.334563","exception":false,"start_time":"2020-10-01T11:50:14.305141","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Settings\nSet some parameters which change performance a bit (100k points should be possible with a wide range of these)."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:50:14.400919Z","iopub.status.busy":"2020-10-01T11:50:14.399824Z","iopub.status.idle":"2020-10-01T11:50:14.403152Z","shell.execute_reply":"2020-10-01T11:50:14.402508Z"},"papermill":{"duration":0.039009,"end_time":"2020-10-01T11:50:14.403277","exception":false,"start_time":"2020-10-01T11:50:14.364268","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"RND_STATE = 123123\n# fixing random seed\n# only used for plotting\n\nLOCSPLIT = 1\n# how often to split the delivery map of a single warehouse before optimizing delivery routes\n# LOCSPLIT = 1, no map splitting is performed\n# LOCSPLIT = 2, map is split into 4 sections (2 on the row level and 2 on the column level)\n# LOCSPLIT = 3, map is split into 9 sections\n# etc etc\n\n\nWDSPLIT = 8\n# how often to split list of deliveries of a single warehouse by priority (weight-distance)\n# before optimizing delivery routes\n\nBATCHES = 10\n# number of route batches which are to be turned into schedules\n# processing time increases significantly with less batches\n# (higher = more focus on priority, lower = more focus on efficiency)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.029025,"end_time":"2020-10-01T11:50:14.461875","exception":false,"start_time":"2020-10-01T11:50:14.43285","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Extract Data\nFirst step is extracting the data into a useful format, credits to the kernel [Data Extraction and EDA](https://www.kaggle.com/jpmiller/demo-one-delivery-per-drone) where I essentially copied this code over from."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:50:14.543614Z","iopub.status.busy":"2020-10-01T11:50:14.529923Z","iopub.status.idle":"2020-10-01T11:50:14.642613Z","shell.execute_reply":"2020-10-01T11:50:14.643174Z"},"papermill":{"duration":0.151918,"end_time":"2020-10-01T11:50:14.643336","exception":false,"start_time":"2020-10-01T11:50:14.491418","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print('Extracting data')\n\n# =============================================================================\n# load problem file\n# =============================================================================\nwith open('/kaggle/input/hashcode-drone-delivery/busy_day.in') as file:\n    line_list = file.read().splitlines()\n    \n# =============================================================================\n# problem parameters\n# =============================================================================\nROWS, COLS, DRONES, TURNS, MAXLOAD = map(int, line_list[0].split())\n   \n# =============================================================================\n# load product information\n# =============================================================================\nweights = line_list[2].split()\nproducts_df = pd.DataFrame({'weight': weights})\n\nwh_count = int(line_list[3])\nwh_endline = (wh_count*2)+4\n\nwh_invs = line_list[5:wh_endline+1:2]\nfor i, wh_inv in enumerate(wh_invs):\n    products_df[f'wh{i}_inv'] = wh_inv.split()\n\n# products_df has shape [400,11]\n# (# of products, [weight, wh0_inv, wh1_inv,...])\nproducts_df = products_df.astype(int)\n\n# =============================================================================\n# load warehouse locations\n# =============================================================================\nwh_locs = line_list[4:wh_endline:2]\nwh_rows = [wl.split()[0] for wl in wh_locs]\nwh_cols = [wl.split()[1] for wl in wh_locs]\n\nwarehouse_df = pd.DataFrame(\n    {'wh_row': wh_rows, 'wh_col': wh_cols}).astype(np.uint16)\n\n# =============================================================================\n# load order information\n# =============================================================================\norder_locs = line_list[wh_endline+1::3]\no_rows = [ol.split()[0] for ol in order_locs]\no_cols = [ol.split()[1] for ol in order_locs]\n\norders_df = pd.DataFrame({'row': o_rows, 'col': o_cols})\n\norders_df[orders_df.duplicated(keep=False)].sort_values('row')\n\norders_df['product_count'] = line_list[wh_endline+2::3]\n\norder_array = np.zeros((len(orders_df), len(products_df)), dtype=np.uint16)\norders = line_list[wh_endline+3::3]\nfor i,order in enumerate(orders):\n    products = [int(prod) for prod in order.split()]\n    for p in products:\n        order_array[i, p] += 1\n\ndf = pd.DataFrame(data=order_array,\n                  columns=['p_'+ str(i) for i in range(400)],\n                  index=orders_df.index)\n\norders_df = orders_df.astype(int).join(df)\n\nprint('... success')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.029542,"end_time":"2020-10-01T11:50:14.703184","exception":false,"start_time":"2020-10-01T11:50:14.673642","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Now, let's have a look what that looks like in format of a map. Simply plotting all warehouses (colors) and all orders (black) here."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:50:14.783092Z","iopub.status.busy":"2020-10-01T11:50:14.782294Z","iopub.status.idle":"2020-10-01T11:50:15.12853Z","shell.execute_reply":"2020-10-01T11:50:15.129121Z"},"papermill":{"duration":0.396292,"end_time":"2020-10-01T11:50:15.129274","exception":false,"start_time":"2020-10-01T11:50:14.732982","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"cmap = mcm.get_cmap('plasma')\nwh_colors = [cmap(iii) for iii in np.linspace(0, 1, num=10)]\n\nfig = plt.figure(figsize=(12,8))\nax = plt.subplot()\nax.scatter(warehouse_df['wh_col'], warehouse_df['wh_row'],\n           color=wh_colors, ec='k', s=48, zorder=10)\nax.scatter(orders_df['col'], orders_df['row'],\n           color='k', s=1)\nax.set_xlabel('Column')\nax.set_ylabel('Row')\nax.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.031512,"end_time":"2020-10-01T11:50:15.192267","exception":false,"start_time":"2020-10-01T11:50:15.160755","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Optimize product distribution\nNow the first real step toward a solution is to figure out where products are needed and where they are currently located. We look at this for each product separately, determining the current storage location (source) for all available units and all locations where this product needs to be delivered to (sink). From this information we can figure out the optimal way of distributing this product to all customers while minimizing the total distance which has to be covered to satisfy all needs.\nThis is done by constructing a graph connecting all sources and sinks, where the cost of each connection is equal to the distance between the adjoining source (warehouse) and sink (customer). A solution is found by performing a minimum-cost flow optimization and the results for each product are saved in a combined dataframe."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:50:15.282504Z","iopub.status.busy":"2020-10-01T11:50:15.281661Z","iopub.status.idle":"2020-10-01T11:50:22.842288Z","shell.execute_reply":"2020-10-01T11:50:22.842988Z"},"papermill":{"duration":7.619607,"end_time":"2020-10-01T11:50:22.843182","exception":false,"start_time":"2020-10-01T11:50:15.223575","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print('Optimizing product distribution')\n\n# we use this array to note which warehouse\n# each item is to be delivered from\nfrom_wh_df = np.full((len(orders_df), len(products_df), np.max(order_array)), -1)\n\n# number of warehouses\nNWH = len(warehouse_df)\n\nfor ppp in range(len(products_df)):\n    # how many units of this product are in each warehouse\n    sources = warehouse_df.copy()\n    sources['inv'] = products_df.loc[ppp][1:].values\n    sources = sources[sources['inv'] > 0]\n    \n    # where does this product need to be delivered to\n    sinks = orders_df.loc[:, ['row', 'col', 'p_{}'.format(ppp)]]\n    sinks = sinks[sinks['p_{}'.format(ppp)] > 0]\n    \n    # set up simple min cost flow solver\n    min_cost_flow = pywrapgraph.SimpleMinCostFlow()\n    \n    # add all arcs\n    for iii in sources.index:\n        for jjj in sinks.index:\n            dist = np.ceil(np.sqrt(\n                (sources.loc[iii, 'wh_row'] - sinks.loc[jjj, 'row'])**2 +\n                (sources.loc[iii, 'wh_col'] - sinks.loc[jjj, 'col'])**2\n                ))\n            # add NWH to keep nodes uniquely identifiable\n            min_cost_flow.AddArcWithCapacityAndUnitCost(\n                iii, jjj+NWH, int(sinks.loc[jjj, 'p_{}'.format(ppp)]), int(dist))\n        # add arcs to \"overflow\" node collecting exceed product\n        min_cost_flow.AddArcWithCapacityAndUnitCost(\n                iii, int(1e4), int(1e4), int(1e4))\n    \n    # add supplies\n    for iii in sources.index:\n        min_cost_flow.SetNodeSupply(iii, int(sources.loc[iii, 'inv']))\n    for jjj in sinks.index:\n        min_cost_flow.SetNodeSupply(jjj+NWH, -int(sinks.loc[jjj, 'p_{}'.format(ppp)]))\n    min_cost_flow.SetNodeSupply(\n        int(1e4), int(sinks['p_{}'.format(ppp)].sum()) - int(sources['inv'].sum()))\n        \n    # solve and put result into from_wh_df\n    if min_cost_flow.Solve() == min_cost_flow.OPTIMAL:\n        for iii in range(min_cost_flow.NumArcs()):\n            if not min_cost_flow.Flow(iii):\n                continue\n            if min_cost_flow.UnitCost(iii) == int(1e4):\n                continue\n            # need to subtract NWH again to get actual order number\n            thisorder = min_cost_flow.Head(iii)-NWH\n            thiswh = int(min_cost_flow.Tail(iii))\n            thisnum = min_cost_flow.Flow(iii)\n            for ttt in range(from_wh_df.shape[-1]):\n                if not thisnum:\n                    break\n                if from_wh_df[thisorder, ppp, ttt] == -1:\n                    from_wh_df[thisorder, ppp, ttt] = thiswh\n                    thisnum -= 1\n    else:\n        print('product_id', ppp, 'distribution could not be optimized')\n        raise Exception(f'product_id {ppp}: distribution could not be optimized')\n\nprint('... success')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.032262,"end_time":"2020-10-01T11:50:22.909755","exception":false,"start_time":"2020-10-01T11:50:22.877493","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Define \"weight-distance\"\nWeight-distance indicates the \"difficulty\" of an order, i.e. the amount of resources needed for its fulfillment. We define it as the sum of the product **weight units * distance units** for each product which is to be delivered in order to fully ship this order.\n\nFor example, order A includes product 1 with weight 50 which needs to be shipped over a distance of 10 distance units (50 * 10 = 500 wd units) and product 2 with weigth 100 which needs to be shipped over a distance of 150 distance units (100 * 150 = 15000 wd units) - a total WD score of 15500. \n\nWe use these scores to \n* bundle products for easy-to-finish orders together on single delivery flights (routes)\n* give these routes priority when assigning delivery schedules (combinations of routes)\n\nin order to finish \"easy/quick\" orders first and longer ones later. In a real life problem this might not be the perfect way of optimizing, as we prioritize finishing certain orders before others for the cost of a somewhat less optimal (but still pretty good) resource utilization (drones might not be loaded as much as they could or might travel a bit further than absolutely necessary)."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:50:22.987649Z","iopub.status.busy":"2020-10-01T11:50:22.986819Z","iopub.status.idle":"2020-10-01T11:50:23.252611Z","shell.execute_reply":"2020-10-01T11:50:23.251955Z"},"papermill":{"duration":0.310685,"end_time":"2020-10-01T11:50:23.252748","exception":false,"start_time":"2020-10-01T11:50:22.942063","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"weight_dist = np.zeros((len(orders_df)), dtype=int)\nweight_sum = np.zeros((len(orders_df)), dtype=int)\n\nfor www in warehouse_df.index:\n    tmp = np.where(from_wh_df == www)\n    weight_this_wh = np.zeros((len(orders_df)), dtype=int)\n    for iii in range(len(tmp[0])):\n        weight_this_wh[tmp[0][iii]] += products_df.loc[tmp[1][iii], 'weight']\n\n    weight_sum += weight_this_wh\n    weight_dist += np.ceil(np.sqrt(\n        (orders_df['row'] - warehouse_df.loc[www,'wh_row'])**2 +\n        (orders_df['col'] - warehouse_df.loc[www,'wh_col'])**2\n        )).astype(int) * weight_this_wh\n    \norders_df['weight_dist'] = weight_dist\norders_df['weight_sum'] = weight_sum","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.032024,"end_time":"2020-10-01T11:50:23.317157","exception":false,"start_time":"2020-10-01T11:50:23.285133","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Create delivery routes\nWe now know all single deliveries which need to be executed and try to combine them into delivery routes where load utilization is maximum and travel distance is minimum. Essentially, we combine products with appropriate weights which need to be delivered from the same warehouse into the same region of the map into efficient delivery routes using Google OR-Tools' routing logic.\n\nDepending on the number of single products needing to be delivered this can be somewhat inefficient and slow if we wanted to calculate in one go *all* routes for *all* products which are to be delivered from the same warehouse - we can hence form subgroups depending on the delivery location before attempting this optimization.\n\nHowever, in order to obtain better scores (deliver orders as early as possible, rather than as efficiently as possible) we can also create routes from subgroups of all product deliveries from a warehouse but grouped by the weight-distance score introduced above. \n\nOr simply a combination of the two."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:50:23.422538Z","iopub.status.busy":"2020-10-01T11:50:23.385725Z","iopub.status.idle":"2020-10-01T11:55:46.775783Z","shell.execute_reply":"2020-10-01T11:55:46.775028Z"},"papermill":{"duration":323.426678,"end_time":"2020-10-01T11:55:46.775926","exception":false,"start_time":"2020-10-01T11:50:23.349248","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"try:\n    routes_df = pd.read_pickle('routes_df')\n    raise Exception\nexcept:\n    # dataframe to store all single routes\n    routes_df = pd.DataFrame()\n\n    # for each warehouse\n    for www in warehouse_df.index:\n        print(f'Calculating routes from warehouse {www}')\n\n        # get list with all orders receiving items from this warehouse and\n        # make dataframe of sink locations for this warehouse\n        #####itemtable = from_wh_df.drop(['row','col','product_count'], axis=1)\n        idx = np.where(from_wh_df == www)\n        orderlist = idx[0]\n        rowlist = orders_df.loc[idx[0],'row'].values\n        collist = orders_df.loc[idx[0],'col'].values\n        itemlist = idx[1]\n        weightlist = products_df['weight'].iloc[itemlist].values\n        distlist = np.ceil(np.sqrt((warehouse_df.loc[www,'wh_col'] - collist) ** 2 + \n                                   (warehouse_df.loc[www,'wh_row'] - rowlist) ** 2)).astype(int)\n        weightdistlist = orders_df.loc[idx[0], 'weight_dist'].values\n\n\n        all_sinks_df = pd.DataFrame(\n            {'order': orderlist,\n             'row': rowlist,\n             'col': collist,\n             'item': itemlist,\n             'weight': weightlist,\n             'dist': distlist,\n             'weight_dist': weightdistlist})\n\n        # split into sections by delivery location on map before calculating routes\n        # by col\n        sort_col = all_sinks_df['col'].sort_values().values\n        lims_col = np.linspace(0, len(sort_col), num=LOCSPLIT+1).astype(int)\n        lims_col = [0, *sort_col[lims_col[1:-1]], COLS]        \n        for ccc in range(LOCSPLIT):\n            mincol = lims_col[ccc]\n            maxcol = lims_col[ccc+1]\n            c_sinks_df = all_sinks_df[(all_sinks_df['col'] >= mincol) &\n                                      (all_sinks_df['col'] < maxcol)]\n            # by row\n            sort_row = c_sinks_df['row'].sort_values().values\n            lims_row = np.linspace(0, len(sort_row), num=LOCSPLIT+1).astype(int)\n            lims_row = [0, *sort_row[lims_row[1:-1]], ROWS]\n            for rrr in range(LOCSPLIT):\n                minrow = lims_row[rrr]\n                maxrow = lims_row[rrr+1]\n                r_sinks_df = c_sinks_df[(c_sinks_df['row'] >= minrow) &\n                                    (c_sinks_df['row'] < maxrow)]\n                # by weight-distance (group \"easier\"/faster orders)\n                wd_sinks_df = r_sinks_df.sort_values(by='weight_dist').reset_index(drop=True)\n                for ddd in range(WDSPLIT):\n                    minidx = int(ddd / WDSPLIT * len(wd_sinks_df))\n                    maxidx = int((ddd+1) / WDSPLIT * len(wd_sinks_df))\n                    sinks_df = wd_sinks_df[minidx:maxidx].reset_index(drop=True)\n                    \n                    print('Warehouse:', www, '\\t section:', ccc, rrr, ddd, '\\t # of items:', len(sinks_df))\n                    if not len(sinks_df):\n                        continue\n\n                    # add warehouse to list of nodes\n                    sinks_df.loc[len(sinks_df)] = [\n                        -1, warehouse_df.loc[www,'wh_row'], warehouse_df.loc[www,'wh_col'], -1, 0, 0, 0] \n\n                    # calculate distance matrix\n                    R, C = np.meshgrid(sinks_df['row'].values, sinks_df['col'].values)\n                    distance_matrix = np.ceil(np.sqrt((R-R.T)**2 + (C-C.T)**2)).astype(int)\n                    # set distances for return to warehouse from any point to zero\n                    # i.e., choose an arbitrary end for the route\n                    distance_matrix[:-1, -1] = 0\n\n                    # maximum number of vehicles (routes) allowed\n                    NV = int(len(sinks_df))\n\n                    # set up routing index manager\n                    manager = pywrapcp.RoutingIndexManager(\n                        len(distance_matrix),                 # problem size\n                        NV,                                   # max number of vehicles (routes)\n                        len(distance_matrix)-1                # start node identification\n                        )\n                    # create routing model\n                    routing = pywrapcp.RoutingModel(manager)\n\n                    # create and register a transit callback\n                    def distance_callback(from_index, to_index):\n                        # convert from routing variable Index to distance matrix NodeIndex.\n                        from_node = manager.IndexToNode(from_index)\n                        to_node = manager.IndexToNode(to_index)\n                        return distance_matrix[from_node][to_node]\n                    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n\n                    # define arc costs\n                    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n\n                    # set up weight constraints    \n                    def demand_callback(from_index):\n                        from_node = manager.IndexToNode(from_index)\n                        return int(sinks_df['weight'][from_node])\n                    demand_callback_index = routing.RegisterUnaryTransitCallback(\n                        demand_callback)\n                    routing.AddDimension(\n                        demand_callback_index,\n                        0,                                     # no capacity slack\n                        MAXLOAD,                               # maximum drone weight\n                        True,                                  # start cumul to zero\n                        'Capacity')\n                    \n                    # set first solution heuristic\n                    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n                    search_parameters.first_solution_strategy = (\n                        routing_enums_pb2.FirstSolutionStrategy.AUTOMATIC)\n\n                    # solve\n                    solution = routing.SolveWithParameters(search_parameters)\n\n                    # create routes from solution    \n                    for vehicle_id in range(NV):\n                        index = routing.Start(vehicle_id)\n                        route_distance = 0\n                        route_load = 0\n                        route_nodes = []\n                        while not routing.IsEnd(index):\n                            node_index = manager.IndexToNode(index)\n\n                            previous_index = index\n                            index = solution.Value(routing.NextVar(index))\n\n                            this_dist = routing.GetArcCostForVehicle(\n                                previous_index, index, vehicle_id)\n\n                            route_distance += this_dist\n                            route_load += sinks_df.loc[node_index, 'weight']\n                            route_nodes.append(node_index)\n                        if not route_distance:\n                            continue\n                        \n                        # pre-build command structure for submission\n                        items = sinks_df.loc[route_nodes[1:], 'item'].values\n                        orders = sinks_df.loc[route_nodes[1:], 'order'].values.astype(int)\n                        cmds = []                        \n                        # load \n                        unique_items, item_count = np.unique(items, return_counts=True)\n                        for i in range(len(unique_items)):\n                            cmds.append('L {} {} {}'.format(www, unique_items[i], item_count[i]))\n                        # deliver \n                        unique_orders, order_idx = np.unique(orders, return_index=True)\n                        unique_orders = unique_orders[np.argsort(order_idx)]\n                        for o in unique_orders:\n                            orderitems = items[orders == o]\n                            uq_oi, uq_oicnt = np.unique(orderitems, return_counts=True)\n                            for i in range(len(uq_oi)):\n                                cmds.append('D {} {} {}'.format(o, uq_oi[i], uq_oicnt[i]))\n                                \n                        # save useful route details in routes_df\n                        routes_df = routes_df.append(\n                            {'start_row': sinks_df.loc[route_nodes[0], 'row'],\n                             'start_col': sinks_df.loc[route_nodes[0], 'col'],\n                             'end_row': sinks_df.loc[route_nodes[-1], 'row'],\n                             'end_col': sinks_df.loc[route_nodes[-1], 'col'],\n                             'dist': route_distance,\n                             'weight': route_load,\n                             'weight_dists': list(sinks_df.loc[\n                                 route_nodes[1:], 'weight_dist']),\n                             'orders': list(orders),\n                             'order_dists': list(sinks_df.loc[\n                                 route_nodes[1:], 'dist']),\n                             'cmds': cmds},\n                            ignore_index=True)\n                        \n    # save optimized route list to pickle for later use\n    pd.to_pickle(routes_df, 'routes_df')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.063305,"end_time":"2020-10-01T11:55:46.902985","exception":false,"start_time":"2020-10-01T11:55:46.83968","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The dataframe <code>routes_df</code> holds all the information we need for solving this problem, including pre-built command structures to give to whichever drone will eventually fly a given route."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:55:47.049792Z","iopub.status.busy":"2020-10-01T11:55:47.048949Z","iopub.status.idle":"2020-10-01T11:55:47.066927Z","shell.execute_reply":"2020-10-01T11:55:47.066201Z"},"papermill":{"duration":0.099227,"end_time":"2020-10-01T11:55:47.067048","exception":false,"start_time":"2020-10-01T11:55:46.967821","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"routes_df.head()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.064379,"end_time":"2020-10-01T11:55:47.195498","exception":false,"start_time":"2020-10-01T11:55:47.131119","status":"completed"},"tags":[]},"cell_type":"markdown","source":"To get a measure of the efficiency of this assignment, we can check the average weight a drone leaves a depot with - here more than 90% load utilization."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:55:47.331139Z","iopub.status.busy":"2020-10-01T11:55:47.330231Z","iopub.status.idle":"2020-10-01T11:55:47.334653Z","shell.execute_reply":"2020-10-01T11:55:47.333868Z"},"papermill":{"duration":0.075116,"end_time":"2020-10-01T11:55:47.334786","exception":false,"start_time":"2020-10-01T11:55:47.25967","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"routes_df['weight'].mean()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.064825,"end_time":"2020-10-01T11:55:47.465036","exception":false,"start_time":"2020-10-01T11:55:47.400211","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's have a look at some random routes. Lines are color-coded by the warehouse which they start from."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:55:47.655828Z","iopub.status.busy":"2020-10-01T11:55:47.63437Z","iopub.status.idle":"2020-10-01T11:55:48.506801Z","shell.execute_reply":"2020-10-01T11:55:48.507513Z"},"papermill":{"duration":0.960425,"end_time":"2020-10-01T11:55:48.507681","exception":false,"start_time":"2020-10-01T11:55:47.547256","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"cmap = mcm.get_cmap('plasma')\nwh_colors = [cmap(iii) for iii in np.linspace(0, 1, num=10)]\n\nfig = plt.figure(figsize=(12,8))\nax = plt.subplot()\n# plot warehouses\nax.scatter(warehouse_df['wh_col'], warehouse_df['wh_row'],\n           color=wh_colors, ec='k', s=48, zorder=10)\n\nselec_routes = routes_df.sample(n=50, random_state=RND_STATE)\n\nfor iii in range(len(selec_routes.index)):\n    # get orders covered by this route\n    idxs = np.unique(selec_routes.iloc[iii]['orders'], return_index=True)[1]\n    tmp_orders = [selec_routes.iloc[iii]['orders'][idx] for idx in sorted(idxs)]\n    # get warehouse this route starts from\n    tmp_wh = warehouse_df[(selec_routes['start_col'].iloc[iii] == warehouse_df['wh_col']) & \n                          (selec_routes['start_row'].iloc[iii] == warehouse_df['wh_row'])].index[0]\n    # plot drop-off locations\n    ax.scatter(orders_df.loc[tmp_orders]['col'], orders_df.loc[tmp_orders]['row'],\n               color=wh_colors[tmp_wh], s=20)\n    # plot route lines\n    tmp_cols = np.concatenate([[selec_routes['start_col'].iloc[iii]], orders_df.loc[tmp_orders]['col'].values])\n    tmp_rows = np.concatenate([[selec_routes['start_row'].iloc[iii]], orders_df.loc[tmp_orders]['row'].values])\n    for jjj in range(len(tmp_cols)-1):\n        ax.plot(tmp_cols[jjj:jjj+2], tmp_rows[jjj:jjj+2],\n                color=wh_colors[tmp_wh])\n\n# plot all order locations\nax.scatter(orders_df['col'], orders_df['row'],\n           color='k', s=1, alpha=0.7)\n\nax.set_xlabel('Column')\nax.set_ylabel('Row')\nax.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.069076,"end_time":"2020-10-01T11:55:48.647064","exception":false,"start_time":"2020-10-01T11:55:48.577988","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Turn routes into schedules\nWe now have a stack of single delivery routes which optimize load utilization and delivery distance. These need to be distributed across all available drones while minimizing total travel distance / distribution time and prioritizing short/quick orders. Following the same scheme as in the previous step, we use Google OR-Tools' routing logic to determine a schedule for each drone. Note that we batch the available routes by weight-distance value, i.e. by priority. This does not only lead to better scores but also to shorter computation times, compared to trying to find a single optimal solution using all routes (where distance and total time are minimized)."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T11:55:48.840467Z","iopub.status.busy":"2020-10-01T11:55:48.806465Z","iopub.status.idle":"2020-10-01T16:14:40.342866Z","shell.execute_reply":"2020-10-01T16:14:40.340986Z"},"papermill":{"duration":15531.626499,"end_time":"2020-10-01T16:14:40.34306","exception":false,"start_time":"2020-10-01T11:55:48.716561","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"routes_df = pd.read_pickle('routes_df')\n\n# calculate average weight distance of deliveries (partly) fulfilled with each route\n# and use for ordering / prioritisation\nroutes_df['wd_avg'] = routes_df['weight_dists'].apply(lambda x: int(np.mean(x)))\nroutes_df = routes_df.sort_values(by='wd_avg')\n\ntry:\n    schedules_df = pd.read_pickle('schedules_df')\nexcept:\n    # dataframe to save list of routes for each drone\n    schedules_df = pd.DataFrame()\n\n    # process in batches\n    route_split = np.linspace(0, len(routes_df), num=BATCHES+1).astype(int)\n\n    # last drone location\n    start_loc = np.full((DRONES), -1, dtype=int)\n\n    for bbb in tqdm(range(BATCHES)):\n        #print(datetime.now(), 'Optimizing route distribution for batch', bbb+1, 'of', BATCHES)\n\n        all_routes_df = routes_df.copy()\n        all_routes_df = all_routes_df.iloc[route_split[bbb]:route_split[bbb+1]]\n        all_idx = all_routes_df.index.values\n        all_routes_df = all_routes_df.reset_index(drop=True)\n\n        def getRouteID(node_idx: int):\n            if node_idx >= len(all_idx):\n                return -1\n            else:\n                return all_idx[node_idx]\n\n        # add depot to all_routes_df (first start point and dummy endpoint)\n        all_routes_df = all_routes_df.append(\n            {'start_row': warehouse_df.loc[0, 'wh_row'],\n             'start_col': warehouse_df.loc[0, 'wh_col'],\n             'end_row': warehouse_df.loc[0, 'wh_row'],\n             'end_col': warehouse_df.loc[0, 'wh_col'],\n             'dist': 0,\n             'cmds': []},\n            ignore_index=True)\n        WH_IDX = len(all_routes_df)-1\n\n        # add other start points to all_routes_df\n        for lll in range(len(start_loc)):\n            if start_loc[lll] == -1:\n                # drone starts at depot\n                start_loc[lll] = WH_IDX\n            else:\n                # drone starts at other location which needs to be added\n\n                all_routes_df = all_routes_df.append(\n                    {'start_row': routes_df.loc[start_loc[lll], 'end_row'],\n                     'start_col': routes_df.loc[start_loc[lll], 'end_col'],\n                     'end_row': routes_df.loc[start_loc[lll], 'end_row'],\n                     'end_col': routes_df.loc[start_loc[lll], 'end_col'],\n                     'dist': 0,\n                     'cmds': []},\n                    ignore_index=True)\n                start_loc[lll] = len(all_routes_df)-1\n\n        end_loc = np.full((DRONES), WH_IDX, dtype=int)\n\n        # calculate distance matrix\n        # distance is from the end of route A to the end of route B\n        # while following the prescribed route B\n        TO, FROM = np.meshgrid(np.arange(len(all_routes_df), dtype=int),\n                               np.arange(len(all_routes_df), dtype=int))\n        flat_from = np.ravel(FROM)\n        flat_to = np.ravel(TO)\n        SHP = flat_from.shape\n        # distance to start point\n        to_start = np.ceil(np.sqrt(\n                    (all_routes_df.lookup(flat_from, np.full(SHP, 'end_col')) -\n                     all_routes_df.lookup(flat_to, np.full(SHP, 'start_col')))**2 +\n                    (all_routes_df.lookup(flat_from, np.full(SHP, 'end_row')) -\n                     all_routes_df.lookup(flat_to, np.full(SHP, 'start_row')))**2\n                    ))\n        # distance of route itself\n        route_dist = all_routes_df.lookup(flat_to, np.full(SHP, 'dist'))\n        # total distance = getting to start + route distance\n        distance_matrix = (to_start + route_dist).reshape(FROM.shape).astype(int)\n        # replace some values\n        for fromroute in range(len(all_routes_df)):\n            # self node distance is zero\n            distance_matrix[fromroute, fromroute] = 0\n            # distance back to depot is zero (arbitrary end location)\n            # (drones don't have to return to depot by the end of their tour)\n            distance_matrix[fromroute, WH_IDX] = 0\n\n        # set up route optimizer\n        manager = pywrapcp.RoutingIndexManager(len(distance_matrix), DRONES,\n                                               start_loc.tolist(), end_loc.tolist())  \n        routing = pywrapcp.RoutingModel(manager)\n\n        # create and register a transit callback\n        def distance_callback(from_index, to_index):\n            from_node = manager.IndexToNode(from_index)\n            to_node = manager.IndexToNode(to_index)\n            return distance_matrix[from_node][to_node]\n        transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n\n        # define arc cost\n        routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n\n        # force routes to have roughly the same length\n        dimension_name = 'Distance'\n        routing.AddDimension(transit_callback_index,\n            0,  # no slack\n            int(1e5),  # vehicle maximum travel distance\n            True,  # start cumul to zero\n            dimension_name)\n        distance_dimension = routing.GetDimensionOrDie(dimension_name)\n        distance_dimension.SetGlobalSpanCostCoefficient(int(100))\n\n        # set first solution heuristic\n        search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n        search_parameters.first_solution_strategy = (\n            routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n        # solve\n        solution = routing.SolveWithParameters(search_parameters)\n\n        # create schedules from solution\n        for drone_id in range(DRONES):  \n            index = routing.Start(drone_id)\n            route_distance = 0\n            route_nodes = []\n            while not routing.IsEnd(index):\n                node_index = manager.IndexToNode(index)\n\n                previous_index = index\n                index = solution.Value(routing.NextVar(index))\n\n                this_dist = routing.GetArcCostForVehicle(\n                    previous_index, index, drone_id)\n\n                route_distance += this_dist\n                route_nodes.append(getRouteID(node_index))\n            # create empty in schedules_df if first schedule for this drone is empty\n            if not route_distance and schedules_df.index.max() < drone_id:\n                schedules_df = schedules_df.append(\n                    {'routes': [],\n                     'cmds': [],\n                     'dist': 0,\n                     'load_count': 0},\n                    ignore_index=True)\n                start_loc[lll] = -1\n                continue\n\n            # combine pre-built command structures\n            cmds = []\n            load_count = 0\n            for i in route_nodes[1:]:\n                for c in routes_df.loc[i, 'cmds']:\n                    cmds.append(c)\n                    if 'L' in c:\n                        load_count += 1\n\n            # save to dataframe\n            if schedules_df.index.max() < drone_id or np.isnan(schedules_df.index.max()):\n                schedules_df = schedules_df.append(\n                    {'routes': route_nodes[1:],\n                     'cmds': cmds,\n                     'dist': route_distance,\n                     'load_count': load_count},\n                    ignore_index=True)\n            else:\n                schedules_df.at[drone_id, 'routes'] = schedules_df.loc[drone_id, 'routes'] + route_nodes[1:]\n                schedules_df.at[drone_id, 'cmds'] = schedules_df.loc[drone_id, 'cmds'] + cmds\n                schedules_df.at[drone_id, 'dist'] = schedules_df.loc[drone_id, 'dist'] + route_distance\n                schedules_df.at[drone_id, 'load_count'] = schedules_df.loc[drone_id, 'load_count'] + load_count\n\n            start_loc[lll] = route_nodes[-1]\n\n    pd.to_pickle(schedules_df, 'schedules_df')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.072905,"end_time":"2020-10-01T16:14:40.490074","exception":false,"start_time":"2020-10-01T16:14:40.417169","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Now we have created <code>schedules_df</code> which holds information on the single drone schedules."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:14:40.674568Z","iopub.status.busy":"2020-10-01T16:14:40.672031Z","iopub.status.idle":"2020-10-01T16:14:40.679227Z","shell.execute_reply":"2020-10-01T16:14:40.678512Z"},"papermill":{"duration":0.115587,"end_time":"2020-10-01T16:14:40.679346","exception":false,"start_time":"2020-10-01T16:14:40.563759","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"schedules_df.head()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.073658,"end_time":"2020-10-01T16:14:40.827615","exception":false,"start_time":"2020-10-01T16:14:40.753957","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's have a look at a single drone's route throughout the simulation. Blue lines indicate routes flown with a load, red ones indicate return trips back to deposits without loads. That looks pretty messy!"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:14:40.998747Z","iopub.status.busy":"2020-10-01T16:14:40.985156Z","iopub.status.idle":"2020-10-01T16:14:42.642778Z","shell.execute_reply":"2020-10-01T16:14:42.643351Z"},"papermill":{"duration":1.74184,"end_time":"2020-10-01T16:14:42.643516","exception":false,"start_time":"2020-10-01T16:14:40.901676","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"cmap = mcm.get_cmap('plasma')\nwh_colors = [cmap(iii) for iii in np.linspace(0, 1, num=10)]\n\nfig = plt.figure(figsize=(12,8))\nax = plt.subplot()\n# plot warehouses\nax.scatter(warehouse_df['wh_col'], warehouse_df['wh_row'],\n           color='tab:red', ec='k', s=48, zorder=10)\n\nselec_schedule = schedules_df.loc[1]\n\n# get routes covered by this schedule\ntmp_routes = selec_schedule['routes']\n\nfor iii, rrr in enumerate(tmp_routes):\n    # get orders covered by this route\n    idxs = np.unique(routes_df.loc[rrr]['orders'], return_index=True)[1]\n    tmp_orders = [routes_df.loc[rrr]['orders'][idx] for idx in sorted(idxs)]\n    # plot drop-off locations\n    ax.scatter(orders_df.loc[tmp_orders]['col'], orders_df.loc[tmp_orders]['row'],\n               color='tab:blue', s=20)\n    # plot route lines\n    tmp_cols = np.concatenate([[routes_df['start_col'].loc[rrr]], orders_df.loc[tmp_orders]['col'].values])\n    tmp_rows = np.concatenate([[routes_df['start_row'].loc[rrr]], orders_df.loc[tmp_orders]['row'].values])\n    for jjj in range(len(tmp_cols)-1):\n        ax.plot(tmp_cols[jjj:jjj+2], tmp_rows[jjj:jjj+2],\n                color='tab:blue')\n    # plot connection between last route dropoff and start of next route\n    if iii < len(tmp_routes)-1:\n        ax.plot([tmp_cols[-1], routes_df['start_col'].loc[tmp_routes[iii+1]]],\n                [tmp_rows[-1], routes_df['start_row'].loc[tmp_routes[iii+1]]],\n                color='tab:red', alpha=0.5)\n\n\n# plot all order locations\nax.scatter(orders_df['col'], orders_df['row'],\n           color='k', s=1, alpha=0.7)\n\nax.set_xlabel('Column')\nax.set_ylabel('Row')\nax.axis('equal')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.080316,"end_time":"2020-10-01T16:14:42.805369","exception":false,"start_time":"2020-10-01T16:14:42.725053","status":"completed"},"tags":[]},"cell_type":"markdown","source":"And in animated form..."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:14:43.120378Z","iopub.status.busy":"2020-10-01T16:14:43.119599Z","iopub.status.idle":"2020-10-01T16:15:23.635511Z","shell.execute_reply":"2020-10-01T16:15:23.634857Z"},"papermill":{"duration":40.749808,"end_time":"2020-10-01T16:15:23.635639","exception":false,"start_time":"2020-10-01T16:14:42.885831","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from IPython.display import display, clear_output\nfrom IPython.display import HTML\n\nfrom matplotlib import animation\n\ncmap = mcm.get_cmap('plasma')\nwh_colors = [cmap(iii) for iii in np.linspace(0, 1, num=10)]\n\nselec_schedule = schedules_df.loc[1]\n\n# get routes covered by this schedule\ntmp_routes = selec_schedule['routes']\n\ndef getCoords(num: int):\n    if num < 0:\n        # warehouse\n        wh_id = - (num + 1)\n        col = warehouse_df['wh_col'].loc[wh_id]\n        row = warehouse_df['wh_row'].loc[wh_id]\n        kind = 'W'\n    else:\n        # order\n        col = orders_df['col'].loc[num]\n        row = orders_df['row'].loc[num]\n        kind = 'O'\n    return col, row, kind\n\nfull_sched = []\n\nfor iii, rrr in enumerate(tmp_routes):\n    # get start warehouse\n    if not iii:\n        full_sched = [-1]\n    # get orders covered by this route\n    idxs = np.unique(routes_df.loc[rrr]['orders'], return_index=True)[1]\n    tmp_orders = [routes_df.loc[rrr]['orders'][idx] for idx in sorted(idxs)]\n    full_sched = full_sched + tmp_orders\n    # get start warehouse of the next route\n    if iii < len(tmp_routes)-1:\n        tmp_wh = warehouse_df[(routes_df['start_col'].loc[tmp_routes[iii+1]] == warehouse_df['wh_col']) & \n                              (routes_df['start_row'].loc[tmp_routes[iii+1]] == warehouse_df['wh_row'])].index[0]\n\n        full_sched = full_sched + [-tmp_wh-1]\n        \nplot_cols = []\nplot_rows = []\nplot_kind = []\nfor nnn in full_sched:\n    thiscol, thisrow, thiskind = getCoords(nnn)\n    plot_cols.append(thiscol)\n    plot_rows.append(thisrow)\n    plot_kind.append(thiskind)\n    \nfig = plt.figure(figsize=(12,8))\nax = plt.subplot()\n# plot warehouses\nax.scatter(warehouse_df['wh_col'], warehouse_df['wh_row'],\n           color='tab:red', ec='k', s=48, zorder=10)\n# plot all order locations\nax.scatter(orders_df['col'], orders_df['row'],\n           color='k', s=1, alpha=0.7)\n\n# plot settings\nax.set_xlabel('Column')\nax.set_ylabel('Row')\nax.axis('equal')\n\nlines = [ax.plot([], [], color='tab:blue' if plot_kind[j+1]=='O' else 'tab:red',\n                 alpha=1 if plot_kind[j+1]=='O' else 0.5)[0]\n         for j in range(len(plot_cols)-1)]\n\ndef animate(i):\n    lines[i].set_data(plot_cols[i:i+2], plot_rows[i:i+2])\n    \nanim = animation.FuncAnimation(fig, animate, frames=len(plot_cols)-1, interval=200)\n\nHTML(anim.to_jshtml())","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.768947,"end_time":"2020-10-01T16:15:25.16978","exception":false,"start_time":"2020-10-01T16:15:24.400833","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Create submission file\nWe simply iterate through the schedules created in the previous step and write the submission file."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:15:26.767002Z","iopub.status.busy":"2020-10-01T16:15:26.765751Z","iopub.status.idle":"2020-10-01T16:15:26.776305Z","shell.execute_reply":"2020-10-01T16:15:26.775718Z"},"papermill":{"duration":0.844414,"end_time":"2020-10-01T16:15:26.776452","exception":false,"start_time":"2020-10-01T16:15:25.932038","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# =============================================================================\n# format output\n# =============================================================================\ncmd_len = 0\nwith open('submission.csv', 'w') as file:\n    # get length of commands\n    for iii in schedules_df.index:\n        cmd_len += len(schedules_df.loc[iii, 'cmds'])\n    # write commands\n    file.write('{}\\n'.format(int(cmd_len)))\n    for iii in schedules_df.index:\n        for jjj in schedules_df.loc[iii, 'cmds']:\n            file.write('{} {}\\n'.format(iii, jjj))\n        ","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.804619,"end_time":"2020-10-01T16:15:28.351248","exception":false,"start_time":"2020-10-01T16:15:27.546629","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Calculate score\n\nLet's go through the commands, drone by drone, carefully tracking time as well as currently loaded weight. We make sure to note a timestamp for each delivery, and we create a list of inventory actions (loading / unloading) which we'll use in the next cell to track warehouse inventory."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:15:30.057225Z","iopub.status.busy":"2020-10-01T16:15:30.056474Z","iopub.status.idle":"2020-10-01T16:16:24.147904Z","shell.execute_reply":"2020-10-01T16:16:24.148569Z"},"papermill":{"duration":54.894112,"end_time":"2020-10-01T16:16:24.148737","exception":false,"start_time":"2020-10-01T16:15:29.254625","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nallcommands = submission[submission.columns[0]].values\n\ndelivery_times = orders_df.copy()\nmissing_items = orders_df.copy()\n\ninventory_ops = pd.DataFrame(columns=['action', 'wh', 'item', 'count', 'turn'])\n\nfor ddd in tqdm(range(DRONES)):\n    dronecommands = [iii for iii in allcommands if iii.split()[0] == str(ddd)]\n    currentloc = warehouse_df.loc[0].values\n    currenttime = 0\n    currentweight = 0\n    for cmd in dronecommands:\n        _, action, locidx, prod, count = cmd.split(' ')\n\n        # add time steps required to reach new location and perform loading / unloading / delivery\n        if action == 'L' or action == 'U':\n            newloc = warehouse_df.loc[int(locidx)].values\n        elif action == 'D':\n            newloc = orders_df.loc[int(locidx), ['row', 'col']].values\n        elif action == 'W':\n            # no further action needed in case of \"wait\" commands\n            currenttime += locidx\n            continue\n        dist = int(np.ceil(np.sqrt(np.sum((currentloc-newloc)**2))))\n        currenttime += dist\n        # add one step for loading / unloading / delivery itself\n        currenttime += 1\n        # check if end of simulation is reached\n        if currenttime > TURNS:\n            raise Exception('Maximum simulation time exceeded')\n\n        # update current location\n        currentloc = np.copy(newloc)\n        \n        # update drone weight\n        if action == 'L':\n            currentweight += int(count) * products_df.loc[int(prod),'weight']\n        elif action == 'D' or action == 'U':\n            currentweight -= int(count) * products_df.loc[int(prod),'weight']\n            \n        if currentweight > MAXLOAD:\n            raise Exception('Maximum drone load exceeded')\n        \n        # note latest delivery time of each item for each order\n        # and note how many items were delivered\n        if action == 'D':\n            if missing_items.at[int(locidx), 'p_{}'.format(prod)]:\n                delivery_times.at[int(locidx), 'p_{}'.format(prod)] = currenttime\n                missing_items.at[int(locidx), 'p_{}'.format(prod)] -= int(count)\n            else:\n                raise Exception('Too many items delivered')\n                \n        # save list of loading / unloading operations for checking warehouse inventory\n        if action == 'L' or action == 'U':\n            inventory_ops = inventory_ops.append({\n                'action': action,\n                'wh': int(locidx),\n                'item': int(prod),\n                'count': int(count),\n                'turn': currenttime\n            }, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:16:25.73335Z","iopub.status.busy":"2020-10-01T16:16:25.723629Z","iopub.status.idle":"2020-10-01T16:16:25.749994Z","shell.execute_reply":"2020-10-01T16:16:25.750549Z"},"papermill":{"duration":0.819301,"end_time":"2020-10-01T16:16:25.750704","exception":false,"start_time":"2020-10-01T16:16:24.931403","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"delivery_times","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.783408,"end_time":"2020-10-01T16:16:27.316078","exception":false,"start_time":"2020-10-01T16:16:26.53267","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's quickly check whether we don't happen to try and remove products which aren't in stock..."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:16:29.057126Z","iopub.status.busy":"2020-10-01T16:16:29.056347Z","iopub.status.idle":"2020-10-01T16:16:45.299264Z","shell.execute_reply":"2020-10-01T16:16:45.29836Z"},"papermill":{"duration":17.166067,"end_time":"2020-10-01T16:16:45.299469","exception":false,"start_time":"2020-10-01T16:16:28.133402","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"for wh in range(len(warehouse_df)):\n    for item in tqdm(range(len(products_df))):\n        # all inventory operations at this warehouse involving this product\n        tmp = inventory_ops[\n            (inventory_ops['wh'] == wh) &\n            (inventory_ops['item'] == item)\n        ]\n        if not len(tmp):\n            continue\n        tmp = tmp.sort_values(by='turn')\n        # get initial stock\n        inv = products_df.loc[item, f'wh{wh}_inv']\n        # if overall fewer or just as many products are removed as are stored\n        # in the warehouse, all good\n        if len(tmp[tmp['action'] == 'L']) <= inv:\n            continue\n        # otherwise, \"simulate\" loading and unloading to see whether inventory goes negative\n        for iii in tmp.index:\n            if tmp.loc[iii, 'action'] == 'L':\n                inv -= 1\n            else:\n                inv += 1\n            # check inventory after each step\n            if inv < 0:\n                raise Exception('Removal of unstocked product attempted')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.840309,"end_time":"2020-10-01T16:16:47.104636","exception":false,"start_time":"2020-10-01T16:16:46.264327","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Lastly, we check out when the last item was delivered for each order (using delivery_times) and whether all required items were delivered (using missing_items), and then calculate the final score according to the equation given in the instruction file."},{"metadata":{"execution":{"iopub.execute_input":"2020-10-01T16:16:48.827103Z","iopub.status.busy":"2020-10-01T16:16:48.826305Z","iopub.status.idle":"2020-10-01T16:16:48.83335Z","shell.execute_reply":"2020-10-01T16:16:48.832761Z"},"papermill":{"duration":0.886556,"end_time":"2020-10-01T16:16:48.833528","exception":false,"start_time":"2020-10-01T16:16:47.946972","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"completion_times = np.max(delivery_times.iloc[:,3:-2].values, axis=1)\ncompleted = np.max(missing_items.iloc[:,3:-2].values > 0, axis=1) <= 0\ntmp = np.where(completed)[0]\norder_scores = np.ceil(100 * (TURNS - completion_times[tmp]) / TURNS)\nprint('Score:', int(np.sum(order_scores)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}