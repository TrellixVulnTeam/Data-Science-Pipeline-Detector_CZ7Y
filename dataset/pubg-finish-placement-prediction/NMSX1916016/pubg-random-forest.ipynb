{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport datetime\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MultipleLocator\nfrom sklearn.ensemble import RandomForestClassifier as forest\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib\n# Metric used for the PUBG competition (Mean Absolute Error (MAE))\nfrom sklearn.metrics import mean_absolute_error\ndef split_vals(a, n: int):\n    # Function for splitting training and validation data\n    return a[:n].copy(), a[n:].copy()\n# Function to print the MAE (Mean Absolute Error) score\n# This is the metric used by Kaggle in this competition\n\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train),\n           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)\ndef get_sample(df,n):\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\ndef readcsv(path):\n    df =pd.read_csv(path)\n    return df\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols': df.columns, 'imp': m.feature_importances_}\n                        ).sort_values('imp', ascending=False)\n\n\ndef set_rf_samples(n):\n    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n    n random rows.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n                                       forest.check_random_state(rs).randint(0, n_samples, n))\n\n\ndef reset_rf_samples():\n    \"\"\" Undoes the changes produced by set_rf_samples.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\n\n\n\ndef delete_cheater(train = 'none'):\n    # Create feature totalDistance\n    train['totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']\n    # Create feature killsWithoutMoving\n    train['killsWithoutMoving'] = ((train['kills'] > 0) & (train['totalDistance'] == 0))\n    train['headshot_rate'] = train['headshotKills'] / train['kills']\n    train['headshot_rate'] = train['headshot_rate'].fillna(0)\n    train.drop(train[train['killsWithoutMoving'] == True].index, inplace=True)\n    # Players who got more than 10 roadKills\n    train[train['roadKills'] > 10]\n    # Drop roadKill 'cheaters'\n    train.drop(train[train['roadKills'] > 10].index, inplace=True)\n    # Remove outliers\n    train.drop(train[train['kills'] > 30].index, inplace=True)\n\n    # Players who made a minimum of 10 kills and have a headshot_rate of 100%\n    train[(train['headshot_rate'] == 1) & (train['kills'] > 9)].head(10)\n    train.drop(train[train['longestKill'] >= 1000].index, inplace=True)\n    train.drop(train[train['walkDistance'] >= 10000].index, inplace=True)\n    train.drop(train[train['rideDistance'] >= 20000].index, inplace=True)\n    train.drop(train[train['swimDistance'] >= 2000].index, inplace=True)\n    train.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)\n    train.drop(train[train['heals'] >= 40].index, inplace=True)\n    return train\ndef test_modify(test ='none',to_keep ='none'):\n    # Add engineered features to the test set\n    test['headshot_rate'] = test['headshotKills'] / test['kills']\n    test['headshot_rate'] = test['headshot_rate'].fillna(0)\n    test['totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\n    test['playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\n    test['healsandboosts'] = test['heals'] + test['boosts']\n    test['killsWithoutMoving'] = ((test['kills'] > 0) & (test['totalDistance'] == 0))\n\n    # Turn groupId and match Id into categorical types\n    test['groupId'] = test['groupId'].astype('category')\n    test['matchId'] = test['matchId'].astype('category')\n\n    # Get category coding for groupId and matchID\n    test['groupId_cat'] = test['groupId'].cat.codes\n    test['matchId_cat'] = test['matchId'].cat.codes\n\n\n    return test[to_keep].copy()\nif __name__ == '__main__':\n    start_time = datetime.datetime.now()\n    train_path = '../input/pubg-finish-placement-prediction/train_V2.csv'\n    test_path = '../input/pubg-finish-placement-prediction/test_V2.csv'\n    n = 10\n    train = readcsv(train_path)\n    test = readcsv(test_path)\n\n    #删除只有一名玩家的样本\n    #print(train[train['winPlacePerc'].isnull()])\n    train.drop(2744604, inplace=True)\n\n    #删除作弊者:\n    train=delete_cheater(train)\n    #print('There are {} different Match types in the dataset.'.format(train['matchType'].nunique()))\n    # One hot encode matchType\n    train = pd.get_dummies(train, columns=['matchType'])\n\n    # Take a look at the encoding\n    matchType_encoding = train.filter(regex='matchType')\n\n    matchType_encoding.head()\n    #将两个ID转化为category编码\n    train['groupId'] = train['groupId'].astype('category')\n    train['matchId'] = train['matchId'].astype('category')\n\n    train['groupId_cat'] = train['groupId'].cat.codes\n    train['matchId_cat'] = train['matchId'].cat.codes\n\n    train.drop(columns=['groupId', 'matchId'], inplace=True)\n\n    train[['groupId_cat', 'matchId_cat']].head()\n    train.drop(columns = ['Id'], inplace=True)\n\n\n    # Take sample for debugging and exploration\n    sample = 500000\n    df_sample = train\n   # df_sample = train.sample(sample)\n    # Split sample into training data and target variable\n    df = df_sample.drop(columns=['winPlacePerc'])  # all columns except target\n    y = df_sample['winPlacePerc']  # Only target variable\n\n\n   \n   \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    val_perc = 0.12  # % to use for validation set\n    n_valid = int(val_perc * sample)\n    n_trn = len(df) - n_valid\n    # Split data\n    raw_train, raw_valid = split_vals(df_sample, n_trn)\n    X_train, X_valid = split_vals(df, n_trn)\n    y_train, y_valid = split_vals(y, n_trn)\n\n    # Check dimensions of samples\n    print('Sample train shape: ', X_train.shape,\n           'Sample target shape: ', y_train.shape,\n           'Sample validation shape: ', X_valid.shape)\n    # Train basic model\n    m1 = RandomForestRegressor(n_estimators=70, min_samples_leaf=3, max_features='sqrt',\n                               n_jobs=-1)\n    m1.fit(X_train, y_train)\n    print_score(m1)\n\n    # What are the most predictive features according to our basic random forest model\n    fi = rf_feat_importance(m1, df);\n   # fi[:10]\n\n    # Plot a feature importance graph for the 20 most important features\n\n    plot1 = fi[:30].plot('cols', 'imp', figsize=(14, 6), legend=False, kind='barh')\n   # x_major_locator = MultipleLocator(0.005)\n    # 把x轴的刻度间隔设置为1，并存在变量里\n    ax = plt.gca()\n    # # ax为两条坐标轴的实例\n    # ax.xaxis.set_major_locator(x_major_locator)\n    ax.axvline(x=0.005, linestyle = '--',color='r', linewidth=1,label='x=0.005');\n    #plt.show()\n\n    # Use this code if you want to save the figure\n    # fig = plot1.get_figure()\n    # fig.savefig(\"Feature_importances(AllFeatures).png\")\n\n    # Keep only significant features\n    to_keep = fi[fi.imp > 0.005].cols\n    print('after m1:Significant features: ', len(to_keep))\n    print(to_keep)\n\n    # Make a DataFrame with only significant features\n    df_keep = df[to_keep].copy()\n    X_train, X_valid = split_vals(df_keep, n_trn)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"    val_perc_full = 0.12  # % to use for validation set\n    n_valid_full = int(val_perc_full * len(train))\n    n_trn_full = len(train) - n_valid_full\n    df_full = train.drop(columns=['winPlacePerc'])  # all columns except target\n    y = train['winPlacePerc']  # target variable\n    df_full = df_full[to_keep]  # Keep only relevant features\n    X_train, X_valid = split_vals(df_full, n_trn_full)\n    y_train, y_valid = split_vals(y, n_trn_full)\n\n    # Check dimensions of data\n    print('Sample train shape: ', X_train.shape,\n           'Sample target shape: ', y_train.shape,\n           'Sample validation shape: ', X_valid.shape)\n    # Train final model\n    # You should get better results by increasing n_estimators\n    # and by playing around with the parameters\n   ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"m3 = RandomForestRegressor(n_estimators=70, min_samples_leaf=3, max_features=0.5,\n                       n_jobs=-1)\nm3.fit(X_train, y_train)\n#print_score(m3)\ntest_pred = test_modify(test, to_keep)\n# Fill NaN with 0 (temporary)\ntest_pred.fillna(0, inplace=True)\nprint(test_pred.head())\n# Make submission ready for Kaggle\n# We use our final Random Forest model (m3) to get the predictions\npredictions = np.clip(a=m3.predict(test_pred), a_min=0.0, a_max=1.0)\npred_df = pd.DataFrame({'Id': test['Id'], 'winPlacePerc': predictions})\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Create submission file\npred_df.to_csv(\"submission.csv\", index=False)\nprint(\"运行完毕\")\nend_time = datetime.datetime.now()\nprint('耗费时间:',(end_time-start_time))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}