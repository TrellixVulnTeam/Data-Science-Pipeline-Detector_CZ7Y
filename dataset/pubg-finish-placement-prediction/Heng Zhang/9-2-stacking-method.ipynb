{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nimport time\nimport datetime\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train_V2.csv\")\ntest = pd.read_csv(\"../input/test_V2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(how = \"any\",axis = 0,inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = pd.concat([train,test],axis=0)\ncombine.reset_index(inplace = True)\ncombine = pd.get_dummies(data=combine,columns=[\"matchType\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = combine[combine[\"winPlacePerc\"].notna()]\ntest = combine[combine[\"winPlacePerc\"].isna()]\nfeatures = ['DBNOs',\n 'heals',\n 'killPlace',\n 'killStreaks',\n 'kills',\n 'matchDuration',\n 'numGroups',\n 'revives',\n 'rideDistance',\n 'roadKills',\n 'swimDistance',\n 'teamKills',\n 'walkDistance',\n 'winPoints',\n 'matchType_flarefpp',\n 'matchType_flaretpp',\n 'matchType_normal-duo',\n 'matchType_normal-duo-fpp',\n 'matchType_normal-solo',\n 'matchType_normal-squad',\n 'matchType_solo-fpp',\n 'matchType_squad',\n 'matchType_squad-fpp']\ntarget = [\"winPlacePerc\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.svm import  SVR\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import KFold,GridSearchCV\nfrom xgboost import XGBRegressor\n\ndef model_selection(X_train,Y_train,model,grid_params):\n    gscv = GridSearchCV(estimator=model,param_grid=grid_params,scoring='neg_mean_absolute_error',cv=3)\n    gscv.fit(X_train,Y_train)\n    best_params = gscv.best_params_\n    score = gscv.best_score_\n    model.set_params(**best_params)\n    print(best_params)\n    return model,score\ndef get_regression_models(X_train,Y_train):\n    reg_1 = Lasso()\n    paras_1 = {'alpha': [0.001, 0.01, 0.1]}\n    \n#     reg_2 = SVR()\n#     paras_2 = {'C': [0.5], 'gamma': [0.001, 0.01], 'kernel': ['rbf']}\n        \n    reg_3 = RandomForestRegressor()\n    paras_3 = {'n_estimators': [150, 100,200], 'max_depth': [5, 10, 15], }\n        \n    reg_4 = AdaBoostRegressor()\n    paras_4 = {'n_estimators': [150, 100,200], 'learning_rate': [0.03, 0.1, 0.5]}\n        \n    reg_5 = GradientBoostingRegressor()\n    paras_5 = {'learning_rate' :[0.003,0.01,0.1,0.5], 'n_estimators': [150, 100,200]}\n    \n    models = [reg_1,reg_3,reg_4,reg_5]\n    paras = [paras_1,paras_3,paras_4,paras_5]\n    kf = KFold(n_splits=len(models))\n    index = 0\n    for train,test in kf.split(X_train):\n        X = X_train[train]\n        Y = Y_train[train]\n        models[index],error = model_selection(X,Y,models[index],paras[index])\n        index += 1\n    return models\n\ndef stacking_models(models,X_train,X_test,Y_train,kfo):\n    kf = KFold(n_splits=kfo)\n    blend_train = np.zeros([X_train.shape[0],len(models)],dtype=float)\n    blend_test = np.zeros([X_test.shape[0],len(models)],dtype=float)\n    index = 0\n    for model in models:\n        begin = 0\n        end = 0\n        for train, test in kf.split(X_train):\n            model.fit(X_train[train], Y_train[train])\n            pre_Y = model.predict(X_train[test])\n            temp_blend_test = model.predict(X_test)\n            blend_test[:, index] = temp_blend_test\n            end = pre_Y.shape[0] + begin\n            blend_train[begin:end, index] = pre_Y\n            begin = end\n        index += 1\n        print(\"one model\")\n    return blend_train,blend_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf=RandomForestRegressor(n_estimators=260,max_depth=17,min_samples_split=5,min_samples_leaf=5,max_features=9)\ngbdt=GradientBoostingRegressor(n_estimators=360,learning_rate=0.1,max_depth=3,min_samples_split=6,min_samples_leaf=1)\nXGB=XGBRegressor(n_estimators = 290,booster='gbtree',learning_rate=0.1,max_depth=5,subsample=0.7,colsample_bytree=0.9)\n\nmodels = [rf,gbdt,XGB]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_models = []\nresult = []\nfor i in range(1):\n    temp = train.sample(frac=1.0,random_state = i)\n    X_train = temp[features].values\n    Y_train = temp[target].values\n    X_test = test[features].values\n#     models = get_regression_models(X_train,Y_train)\n    blend_train,blend_test = stacking_models(models,X_train,X_test,Y_train,3)\n    from xgboost import XGBRegressor\n    final_model = XGBRegressor()\n    paras = {'n_estimators' : [50,100,200,300,400],\"learning_rate\" : [0.0001,0.003,0.01,0.1],\"max_depth\" : [2,3,5,10],\n        \"gamma\" : [ 0.003,0.01]}\n    final_model,error = model_selection(blend_train,Y_train,final_model,paras)\n    final_model.fit(blend_train,Y_train)\n    final_models.append(final_model)\n    res_Y = final_model.predict(blend_test)\n    result.append(res_Y)\n    print(error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in range(len(result)):\n    if index ==0:\n        continue\n    result[0] = result[0]  + result[index]\nres_Y = result[0] / len(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_Y = pd.DataFrame(res_Y,columns=[\"winPlacePerc\"])\nusid = test[\"Id\"]\nusid = pd.DataFrame(usid,columns=[\"Id\"])\nusid = usid.reset_index()[\"Id\"]\nres_Y = res_Y.reset_index()[\"winPlacePerc\"]\n\npredict_PUBG = pd.concat([usid,res_Y],axis=1,ignore_index=\"True\")\npredict_PUBG.columns = [\"Id\",\"winPlacePerc\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_PUBG.to_csv(\"submission.csv\",index=False,encoding = \"utf-8\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}