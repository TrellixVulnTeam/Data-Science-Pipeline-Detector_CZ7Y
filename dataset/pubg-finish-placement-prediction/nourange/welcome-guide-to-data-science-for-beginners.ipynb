{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nThis kernel-based competition started and ended a while ago, so it already has some great notebooks to look at. As a kaggle novice myself, I'll try to illustrate the basic precedure of data science with this interesting dataset, starting from EDA(Exploratory Data Analysis), feature engineering and modelling. To briefly explain,\n\n* EDA : looking for patterns and correlations of/between given columns\n* Feature Engineering : creating and manipulating columns based on your observations from EDA\n* Modelling : choosing the best features from what you've got so far, and coming up with the best model to use them\n\nLet's begin with EDA first!"},{"metadata":{},"cell_type":"markdown","source":"## EDA\n\nThe goal of EDA is to have a general view of the dataset. This includes finding out what columns there are, in what data type they are in, how's the general distribution of values in those columns and how one column correlates to another. Here, by column I generally refer to features, which is a more data-sciencish term.\n\nSince human brain is more suited for understanding visual patterns than text or numbers, a good EDA comes with good visualization a lot of times. So we'll need some descent libraries to help visualization."},{"metadata":{"trusted":true},"cell_type":"code","source":"# The classic visualization tool in Python. Old, but still powerful.\nimport matplotlib.pyplot as plt \n# A easy-to-use tool based on matplotlib\nimport seaborn as sns\n# A handy library for missing value detection\nimport missingno as msno","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to load our dataset! It consists of train, test and sample submission. This is the simplest form of dataset for a Kaggle competition. Train is a dataset that comes with a label which you can use to perform supervised learning, and test is the one without the labels, so to predict them with your model would be your job. Sample submission gives you the guideline for how your submission csv file should look like, such as what the column name should be, whether you should include the index, etc. \n\nI'll bring in train and test for now."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/train_V2.csv')\ntest = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/test_V2.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"I prefer pd.DataFrame.head() function for my first action after loading a dataset. It gives you the general idea of the columns, their data types and their format(ex: % or decimal). However, this dataset came with so many columns that you can't see them at once. In this case, pd.DataFrame.columns function comes in handy."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Columns: {}\".format(len(train.columns)))\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay. We have four columns in object type(roughly equivalent to string) and all the others are in numbers. And since three of the four are IDs, there won't be much need for label encoding - type of preprocessing done to handle categorical data. Lucky for us!\n\nAnd I think the column 'winPlacePerc' would be our label, but let's check to be safe."},{"metadata":{"trusted":true},"cell_type":"code","source":"[x for x in train.columns if x not in test.columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, the column 'winPlacePerc' is in train.csv but not in test.csv, so that must be our label.\n\nBefore anything, I recommend you to check for missing values so that later on your lines of code do not return errors, which can make you really frustrating. I'll use the library missingno for this."},{"metadata":{},"cell_type":"markdown","source":"### Handling Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow. This really is a set of nice dataset! There is only one missing value in winPlacePerc column. We will have to see what happened there."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[np.isnan(train['winPlacePerc'])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since this person has no assists, boosts, damageDealt, riderDistance, swimDistance, walkDistance, etc whatsoever, I think I can call this not valid. Just to make sure, let's see if the match itself was null."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['matchId']=='224a123c53e008']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All right. So there was only that guy in the game, so we should call that no game. We'll just drop this row, and finally begin our EDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time for actual EDA. Let's check for the general distributions of values first.\n\nSince I'll want to plot many distributions, to make it handy I'll just define a function for that visualization."},{"metadata":{},"cell_type":"markdown","source":"### Overall Distriutions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dist_plot(col, data=train):\n    plt.figure(figsize=(10,6.5))\n    sns.distplot(data[col])\n    plt.title(\"Distribution_{}\".format(col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('winPlacePerc')\n\n# Rather evenly distributed, as it ought to be.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('kills')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('assists')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('heals')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('damageDealt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('walkDistance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could do this a lot more, but I'm sure you've got the point. If you have to make similar type of visualizations repeatly, calling a function could make it a lot easier.\n\nInsights from Distribution Visulization : \n* Most of in-game indicators show long tail (clearly it's a battle royal game with less and less survivors as it goes on)\n* Many people tend to walk all right, but only the chosen ones get to shoot at others much (especially uneven distribution of kills and damagDealt)"},{"metadata":{},"cell_type":"markdown","source":"The distplot is great at giving you the general picture, yet you need a little more effort to make 'insights'. A lot of times, it requires you to come up with some hypotheses. In my case, I chose to focus on four parts: kills(damages), rides, walks and number of weapons acquired."},{"metadata":{},"cell_type":"markdown","source":"### Hypothesis 1 : Kills and Win Place"},{"metadata":{},"cell_type":"markdown","source":"Number of kills gotta have some relationship with the final rank of the player. How many kills do people get in the first place?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['kills'].describe(percentiles=[0.1*x for x in range(10)])\n# This prints the threshold value for each 10th percentile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Over 50% of the players get no kills at all, and almost 80% get less than 2. At the same time, a guy slayed 72. (John Wick is that you?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby('kills')['winPlacePerc'].mean()\n\nplt.figure(figsize=(10, 7))\nplt.bar(temp.index, temp, color='peachpuff')\nplt.plot(temp, color='chocolate')\nplt.plot(temp.index, np.ones(len(temp)), ls='--', alpha=0.5, color='k')\nplt.title(\"Kills and Win Place\")\nplt.xlabel(\"# Kills\")\nplt.ylabel(\"Win Place\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How do you like this visualization? It's a very simple one using matplotlib barplots and lineplots, but I think it catches what we wanted to see effectively. \n\nAlso, it's my personal hobby, but if you visit the url below, you can check out some charming colors that matplotlib allows you to use with simple english names. Try out some cool color combinations of your own. \n\nhttps://matplotlib.org/3.1.0/gallery/color/named_colors.html"},{"metadata":{},"cell_type":"markdown","source":"Back to our EDA, it shows that until like 8 kills, getting another kill greatly lifts your Win Place Percentage (almost 6%/kill)\n\nHowever, after certain point, more kills doesn't necessarily guarantee a higher rank. There is even a downslide in kill-winplace correlation. Perhaps as one says, to know when to fight and when not to is also crucial in winning a war!\n\nSo to sum up, a certain level of aiming skill is definitely required to survive long, but after that it's more of some other strategies and positioning (+ luck!) rather than simple shooting and killing that count.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.scatter(train['kills'], train['winPlacePerc'], s=1, color='plum')\nplt.title('kills-winPlace')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}