{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PUGB CHALLENGE\n## What's the best strategy to win in PUBG? Should you sit in one spot and hide your way into victory, or do you need to be the top shot? Let's let the data do the talking!\n"},{"metadata":{},"cell_type":"markdown","source":"### **Data fields**\n* **DBNOs** - Number of enemy players knocked.\n* **assists** - Number of enemy players this player damaged that were killed by teammates.\n* **boosts** - Number of boost items used.\n* **damageDealt** - Total damage dealt. Note: Self inflicted damage is subtracted.\n* **headshotKills** - Number of enemy players killed with headshots.\n* **heals** - Number of healing items used.\n* **Id** - Player’s Id\n* **killPlace** - Ranking in match of number of enemy players killed.\n* **killPoints** - Kills-based external ranking of player. (Think of this as an Elo ranking where only kills matter.) If there is a value other than -1 in rankPoints, then any 0 in killPoints should be treated as a “None”.\n* **killStreaks** - Max number of enemy players killed in a short amount of time.\n* **kills** - Number of enemy players killed.\n* **longestKill** - Longest distance between player and player killed at time of death. This may be misleading, as downing a player and driving away may lead to a large longestKill stat.\n* **matchDuration** - Duration of match in seconds.\n* **matchId** - ID to identify match. There are no matches that are in both the training and testing set.\n* **matchType** - String identifying the game mode that the data comes from. The standard modes are “solo”, “duo”, “squad”, “solo-fpp”, “duo-fpp”, and “squad-fpp”; other modes are from events or custom matches.\n* **rankPoints** - Elo-like ranking of player. This ranking is inconsistent and is being deprecated in the API’s next version, so use with caution. Value of -1 takes place of “None”.\n* **revives** - Number of times this player revived teammates.\n* **rideDistance** - Total distance traveled in vehicles measured in meters.\n* **roadKills** - Number of kills while in a vehicle.\n* **swimDistance** - Total distance traveled by swimming measured in meters.\n* **teamKills** - Number of times this player killed a teammate.\n* **vehicleDestroys** - Number of vehicles destroyed.\n* **walkDistance** - Total distance traveled on foot measured in meters.\n* **weaponsAcquired** - Number of weapons picked up.\n* **winPoints** - Win-based external ranking of player. (Think of this as an Elo ranking where only winning matters.) If there is a value other than -1 in rankPoints, then any 0 in winPoints should be treated as a “None”.\n* **groupId** - ID to identify a group within a match. If the same group of players plays in different matches, they will have a different groupId each time.\n* **numGroups** - Number of groups we have data for in the match.\n* **maxPlace** - Worst placement we have data for in the match. This may not match with numGroups, as sometimes the data skips over placements.\n* **winPlacePerc** - The target of prediction. This is a percentile winning placement, where 1 corresponds to 1st place, and 0 corresponds to last place in the match. It is calculated off of maxPlace, not numGroups, so it is possible to have missing chunks in a match."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\nimport numpy as np\nimport os\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npalette = sns.color_palette('Paired', 10)\n\nimport numpy as np\nimport pandas as pd\n# Pandas display options\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\n\n#setting fontsize and style for all the plots\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['figure.figsize'] = (16,5)\n\n%matplotlib inline \n#plotting directly without requering the plot()\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\") #ignoring most of warnings, cleaning up the notebook for better visualization\n\npd.set_option('display.max_columns', 500) #fixing the number of rows and columns to be displayed\npd.set_option('display.max_rows', 500)\n\nprint(os.listdir(\"../input\")) #showing all the files in the ../input directory\n\n# Set random seed \nrandomseed = 42\n\n# Any results you write to the current directory are saved as output. Kaggle message :D","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_V2.csv')\ntest = pd.read_csv('../input/test_V2.csv')\n\nprint('Train dataset shape: {}'.format(train.shape))\nprint('Test dataset shape: {}'.format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,10))\nplt.subplot(2,1,1)\nsns.countplot(train['kills'])\nplt.xlabel('kills',fontsize = 15,color='blue')\nplt.ylabel('Count',fontsize = 15,color='blue')\nplt.subplot(2,1,2)\nsns.countplot(train['headshotKills'])\nplt.xlabel('Head Shot Kills',fontsize = 15,color='blue')\nplt.ylabel('Count',fontsize = 15,color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['kills'] >= 8]['kills'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,10))\nplt.subplot(4,1,1)\nsns.scatterplot(x='kills', y='winPlacePerc', data=train.sample(500000, random_state = randomseed))\nplt.xlabel('kills',fontsize = 15,color='blue')\nplt.ylabel('Win Percentage',fontsize = 15,color='blue')\nplt.subplot(4,1,2)\nsns.scatterplot(x='revives', y='winPlacePerc', data=train.sample(500000, random_state = randomseed))\nplt.xlabel('revives',fontsize = 15,color='blue')\nplt.ylabel('Win Percentage',fontsize = 15,color='blue')\nplt.subplot(4,1,3)\nsns.scatterplot(x='headshotKills', y='winPlacePerc', data=train.sample(500000, random_state = randomseed))\nplt.xlabel('headshot Kills',fontsize = 15,color='blue')\nplt.ylabel('Win Percentage',fontsize = 15,color='blue')\nplt.subplot(4,1,4)\nsns.scatterplot(x='damageDealt', y='winPlacePerc', data=train.sample(500000, random_state = randomseed))\nplt.xlabel('Damage Dealt',fontsize = 15,color='blue')\nplt.ylabel('Win Percentage',fontsize = 15,color='blue')\nplt.tight_layout(h_pad=1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def point_plot(x,target, df):\n    fig = plt.figure(figsize=(16,10))\n    sns.set_context(\"notebook\", font_scale=1.5)\n    num_plots = len(x)\n    for i, variable in enumerate(x):\n        plt.subplot(num_plots,1,1+i)\n        sns.pointplot(x=variable,y=target,data=df,color='#606060',alpha=0.8)\n        plt.xlabel('',fontsize = 15,color='blue')\n        plt.ylabel('Target variable: {}'.format(target),fontsize = 15,color='blue')\n        plt.title(variable + \"/\" + target,fontsize = 20,color='blue')\n    plt.tight_layout(h_pad=1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"point_plot(['vehicleDestroys','weaponsAcquired'],'winPlacePerc', train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"point_plot(['heals','boosts'],'winPlacePerc', train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"point_plot(['kills','revives','headshotKills'],'winPlacePerc', train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's create this function to make it easier and clean to fit the model and use the cross_val_score and obtain results\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,Imputer, RobustScaler\nimport time #implementing in this function the time spent on training the model\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import  GridSearchCV,train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nimport gc\n\n#imputing all NaN value(if any) and scalling\npipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")), \n        #('scale', MinMaxScaler(feature_range = (0, 1))),\n        ('robustScaler', RobustScaler()),\n])\n\n\n\n#Generic function for making a classification model and accessing performance:\ndef fit_model(train, train_labels, test_set, params={},model=None, \n                         GridSearch=False, plot_features_importances=False):\n    \n    time_start = time.perf_counter() #start counting the time\n    #creating our validation set out of the training set and labels provided\n    \n    X_train, x_val, y_train, y_val = train_test_split(train, train_labels, test_size=0.1, random_state=randomseed)\n    X_train = pipeline.fit_transform(X_train) #fiting and transforming the dataset using the pipeline provided\n    x_val = pipeline.fit_transform(x_val)\n    \n    test_sub = np.zeros(test_set.shape[0])\n    test_set = pipeline.fit_transform(test_set)\n    \n    predict_val = np.zeros(train.shape[0])\n    score = {}\n    \n    if model != None: grid_model = GridSearchCV(model, params,verbose=1, cv=3) #initializing the grid search model\n\n    if GridSearch:\n        grid_model.fit(X_train, y_train)\n        score_grid = grid_model.best_score_\n        \n        #predicting using the model that has been trained above\n        \n        predict_val = grid_model.predict(x_val)\n        score['MAE'] = mean_absolute_error(y_val, predict_val)\n        score['RMSE'] = np.sqrt(mean_squared_error(y_val, predict_val))\n        \n        print(\"Model Report\")\n\n        print(\"MAE: \"+ str(score[\"MAE\"]))\n        print(\"RMSE: \"+ str(score[\"RMSE\"]))\n        print('\\n')\n    \n        test_sub = grid_model.predict(test_set) \n\n    #################### PLOTTING FEATURES IMPORTANCE ####################\n    \n    # Sort features according to importance\n    if plot_features_importances:\n        if GridSearch:\n            # Extract feature importances\n            feature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': grid_model.best_estimator_.feature_importances_})\n        else:\n            feature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': model.feature_importances_})\n        \n        feature_importances = feature_importances.sort_values('importance', ascending = False).reset_index()\n\n        # Normalize the feature importances to add up to one\n        feature_importances['importance_normalized'] = feature_importances['importance'] / feature_importances['importance'].sum()\n\n        # Make a horizontal bar chart of feature importances\n        plt.figure(figsize = (10, 6))\n        ax = plt.subplot()\n\n        # Need to reverse the index to plot most important on top\n        ax.barh(list(reversed(list(feature_importances.index[:15]))), \n                feature_importances['importance_normalized'].head(15), \n                align = 'center', edgecolor = 'k')\n\n        # Set the yticks and labels\n        ax.set_yticks(list(reversed(list(feature_importances.index[:15]))))\n        ax.set_yticklabels(feature_importances['feature'].head(15))\n\n        # Plot labeling\n        plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n\n    #perm = PermutationImportance(grid_model, random_state=randomseed).fit(x_val,y_val)\n    #eli5.show_weights(perm)\n    \n    time_end = time.perf_counter() #end of counting the time\n    \n    total_time = time_end-time_start #total time spent during training and cross_validation\n    \n    print(\"Amount of time spent during training the model and cross validation: %4.3f seconds\" % (total_time))\n    \n    \n    # Clean up memory\n    gc.enable()\n    del model, X_train, x_val, y_train, y_val,score, total_time, time_end, time_start,predict_val,test_set\n    gc.collect()\n                        \n    return test_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[https://www.kaggle.com/batalov/hardest-way-to-get-a-t-shirt-4th-place-solution](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# add basic player-level features by combining other features together\ndef add_player_features(X):\n    X['headshot_rate'] = X['headshotKills'] / (X['kills'] + 0.00001)\n    X['kill_streak_rate'] = X['killStreaks'] / (X['kills'] + 0.00001)\n    X['kills_assists'] = X['kills'] + X['assists']\n    X['heals_boosts'] = X['heals'] + X['boosts']\n    X['total_distance'] = X['walkDistance'] + X['rideDistance'] + X['swimDistance']\n    X['kills_assists_per_heal_boost'] = X['kills_assists'] / (X['heals_boosts'] + 1)\n    X['damageDealt_per_heal_boost'] = X['damageDealt'] / (X['heals_boosts'] + 1)\n    X['road_kills_per_rideDistance'] = X['roadKills'] / (X['rideDistance'] + 0.01)\n    X['maxPlace_per_numGroups'] = X['maxPlace'] / X['numGroups']\n    X['assists_per_kill'] = X['assists'] / (X['kills'] + X['assists'] + 0.0001)\n    X['killPlace'] = X['killPlace'] - 1\n    X['teamwork'] = X['assists'] + X['revives']\n    agg = X.groupby(['groupId']).size().to_frame('players_in_team')\n    X = X.merge(agg, how='left', on=['groupId'])\n    X['headshotKills_over_kills'] = X['headshotKills'] / X['kills']\n    X['headshotKills_over_kills'].fillna(0, inplace=True)\n    X['killPlace_over_maxPlace'] = X['killPlace'] / X['maxPlace']\n    X['killPlace_over_maxPlace'].fillna(0, inplace=True)\n    X['killPlace_over_maxPlace'].replace(np.inf, 0, inplace=True)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr() #Let's take a look at the pearson's corr, just to have an overall view of how the attributes influence the price.\n#using this correlation, we can have an idea of the linear correlation, positive and negative.\nax = sns.set(rc={'figure.figsize':(40,25)})\nplt.xticks(fontsize=30)\nplt.yticks(fontsize=30)\nsns.heatmap(corr, annot=True,xticklabels=corr.columns.values,\n    yticklabels=corr.columns.values,\n    linecolor='white',\n    linewidths=0.1,\n    cmap=\"RdBu\").set_title('Pearsons Correlation Factors Heat Map', color='blue', size='20')\ngc.enable()\ndel corr\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = add_player_features(train)\ntest = add_player_features(test)\n\ncols_to_drop = ['Id','groupId','matchId','matchType',\n                'headshotKills', 'killStreaks', 'walkDistance', 'rideDistance', 'swimDistance', 'heals']\n\ndummy_train = pd.get_dummies(train['matchType'])\ntrain = pd.concat([train, dummy_train], axis=1)\ndummy_test = pd.get_dummies(test['matchType'])\ntest = pd.concat([test, dummy_test], axis=1)\n\nprint('Training set shape after creating dummies: {}'.format(train.shape))\nprint('Testing set shape after creating dummies: {}'.format(test.shape))\n\n\ntrain_labels = train['winPlacePerc']\ntrain_prepared = train.drop(cols_to_drop + ['winPlacePerc'], axis=1)\ntest_prepared = test.drop(cols_to_drop, axis=1)\n\nprint('Training set shape without ids and the target: {}'.format(train_prepared.shape))\nprint('Testing set shape without ids: {}'.format(test_prepared.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prepared.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the random forest\nparams={}\nrandom_forest = RandomForestRegressor(n_estimators = 20, max_depth = 20,oob_score = True,\n                                      bootstrap = True, verbose = 1, n_jobs = -1)\n\nprediction_random = fit_model(train_prepared,train_labels, test_prepared, params=params,model=random_forest,GridSearch=True,\n                           plot_features_importances=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_lgb = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'subsample_freq': 1,\n        'colsample_bytree': 0.6,\n        'reg_aplha': 1,\n        'reg_lambda': 0.001,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1\n    }\n\nmodel_lgb = lgb.LGBMRegressor(**params_lgb, n_estimators = 3000, nthread = 4, n_jobs = -1)\n\n\nprediction_lgb = fit_model(train_prepared,train_labels, test_prepared, params={},model=model_lgb,GridSearch=True,\n                           plot_features_importances=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/sample_submission_V2.csv')\n\nsub_lgb = pd.DataFrame({'Id': sample_sub['Id'], 'winPlacePerc': prediction_lgb})\nsub_lgb.to_csv('LGB_model_sub.csv', index = False)\nsub_lgb.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}