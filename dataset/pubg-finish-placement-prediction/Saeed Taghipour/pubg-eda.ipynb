{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you run all dataset , you change debug False\ndebug = True\n\nif debug == True:\n    df_train = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\n    df_test = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train: ',df_train.shape)\nprint('test : ',df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    #start_mem = df.memory_usage().sum() / 1024**2\n    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    #end_mem = df.memory_usage().sum() / 1024**2\n    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\ndf_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['groupId'] =='4d4b580de459be']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train[df_train['matchId']=='a10357fd1a4a91']['groupId'].value_counts().sort_values(ascending=False)\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp)\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"GroupId of Match Id: a10357fd1a4a91\",\n    xaxis=dict(\n        title='groupId',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of groupId of type of MatchId a10357fd1a4a91',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['assists'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp)\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='assists',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of assists',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['kills'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp)\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='kills',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of kills',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['kills'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp)\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='kills',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of kills',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['roadKills'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp)\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='roadKills',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of roadKills',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['roadKills'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['teamKills'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='teamKills',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of teamKills',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax = plt.subplots(figsize = (18,8))\nsns.distplot(df_train['longestKill'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['weaponsAcquired'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='weaponsAcquired',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of weaponsAcquired',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['headshotKills'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='headshotKills',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of headshotKills',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['boosts'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='boosts',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of boosts',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['heals'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='heals',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of heals',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax = plt.subplots(figsize = (8,6))\nsns.distplot(df_train['damageDealt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax = plt.subplots(figsize = (8,6))\ndf_train['revives'].value_counts().sort_values(ascending = False).plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram\n\nf , ax = plt.subplots(figsize = (18,8))\nsns.distplot(df_train['walkDistance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax = plt.subplots(figsize = (18,8))\nsns.distplot(df_train['rideDistance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['vehicleDestroys'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='vehicleDestroys',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of vehicleDestroys',\n        titlefont=dict(\n            size=16,\n            color='rgb(105, 105, 105)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(105, 105, 105)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['vehicleDestroys'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['weaponsAcquired'].value_counts().sort_values(ascending=False)\n\n#print(\"Total number of states : \",len(temp))\ntrace = go.Bar(\n    x = temp.index,\n    y = (temp),\n)\ndata = [trace]\nlayout = go.Layout(\n    title = \"\",\n    xaxis=dict(\n        title='weaponsAcquired',\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        title='Count of weaponsAcquired',\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='schoolStateNames')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing Values\n\ntotal = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total , percent],axis = 1,keys = ['Total','Percent'])\nmissing_data.head()\n\n# Histogram\npercent_data = percent.head(20)\npercent_data.plot(kind = 'bar' , figsize = (8,6),fontsize = 10)\nplt.xlabel('columns',fontsize = 20)\nplt.ylabel('Count',fontsize = 20)\nplt.title('total missing value (%) in train',\n         fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test Missing data \ntotal = df_test.isnull().sum().sort_values(ascending = False)\npercent = (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total , percent],axis = 1 ,keys = ['Total','Percent'])\nmissing_data.head(20)\n\n\n# histogram\npercent_data = percent.head(20)\npercent_data.plot(kind = 'bar',figsize=(8,6),fontsize = 10)\nplt.xlabel('Columns',fontsize = 20)\nplt.ylabel('Count',fontsize = 20)\nplt.title('Total Missing value (%) in Test',fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WinPlaceperc correlation matrix\n\nk = 10 # Number of variables for heatmap\n\ncorrmat = df_train.corr()\ncols = corrmat.nlargest(k,'winPlacePerc').index #nlargest :return this many descending sorted values\ncm = np.corrcoef(df_train[cols].values.T) # Corelation\nsns.set(font_scale = 1.25)\nf,ax = plt.subplots(figsize = (8,6))\nhm = sns.heatmap(cm , cbar= True , annot = True , square = True , fmt = '.2f',annot_kws = {'size':8},yticklabels= cols.values,xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.plot(x = 'walkDistance',y = 'winPlacePerc',kind = 'scatter',figsize = (8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize = (8,6))\nfig  = sns.boxplot(x = 'boosts',y = 'winPlacePerc',data = df_train)\nfig.axis(ymin = 0 , ymax = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.plot(x = 'weaponsAcquired',y = 'winPlacePerc',kind = 'scatter',figsize = (8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.plot(x = 'damageDealt',y = 'winPlacePerc',kind = 'scatter',figsize = (8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.plot(x = 'heals',y = 'winPlacePerc',kind = 'scatter',figsize = (8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.plot(x = 'longestKill', y = 'winPlacePerc',kind = 'scatter',figsize = (8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.plot(x = 'kills', y ='winPlacePerc',kind = 'scatter',figsize = (8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax = plt.subplots(figsize = (8,6))\nfig  = sns.boxplot(x = 'killStreaks',y = 'winPlacePerc',data =df_train)\nfig.axis(ymin = 0 , ymax = 1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f , ax  = plt.subplots(figsize = (8,6))\nfig = sns.boxplot(x = 'assists',y = 'winPlacePerc',data = df_train)\nfig.axis(ymin = 0 , ymax = 1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train[df_train['Id'] != 'f70c74418bb064']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headshot = df_train[['kills','winPlacePerc','headshotKills']]\nheadshot['headshotrate'] = headshot['kills'] / headshot['headshotKills']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headshot.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del headshot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['headshotrate'] = df_train['kills']/df_train['headshotKills']\ndf_test['headshotrate'] = df_test['kills']/df_test['headshotKills']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KillStreak Rate\n\nkillStreak = df_train[['kills','winPlacePerc','killStreaks']]\nkillStreak['killStreakrate'] = killStreak['killStreaks'] / killStreak['kills']\nkillStreak.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healthitems = df_train[['heals','winPlacePerc','boosts']]\nhealthitems['healthitems'] = healthitems['heals'] + healthitems['boosts']\nhealthitems.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del healthitems","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kills = df_train[['assists','winPlacePerc','kills']]\nkills['kills_assists'] = (kills['kills'] + kills['assists'])\nkills.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_train , df_test;\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(is_train=True,debug=True):\n    test_idx = None\n    if is_train: \n        print(\"processing train.csv\")\n        if debug == True:\n            df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv', nrows=10000)\n        else:\n            df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')           \n\n        df = df[df['maxPlace'] > 1]\n    else:\n        print(\"processing test.csv\")\n        df = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n        test_idx = df.Id\n    \n    # df = reduce_mem_usage(df)\n    #df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    \n    # df = df[:100]\n    \n    print(\"remove some columns\")\n    target = 'winPlacePerc'\n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    \n    features.remove(\"matchType\")\n    \n    # matchType = pd.get_dummies(df['matchType'])\n    # df = df.join(matchType)    \n    \n    y = None\n    \n    \n    if is_train: \n        print(\"get target\")\n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        features.remove(target)\n\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    else: df_out = df[['matchId','groupId']]\n\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # print(\"get group sum feature\")\n    # agg = df.groupby(['matchId','groupId'])[features].agg('sum')\n    # agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    # df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    # df_out = df_out.merge(agg_rank, suffixes=[\"_sum\", \"_sum_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # print(\"get group sum feature\")\n    # agg = df.groupby(['matchId','groupId'])[features].agg('sum')\n    # agg_rank = agg.groupby('matchId')[features].agg('sum')\n    # df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    # df_out = df_out.merge(agg_rank.reset_index(), suffixes=[\"_sum\", \"_sum_pct\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    # print(\"get match type feature\")\n    # agg = df.groupby(['matchId'])[matchType.columns].agg('mean').reset_index()\n    # df_out = df_out.merge(agg, suffixes=[\"\", \"_match_type\"], how='left', on=['matchId'])\n    \n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n\n    X = df_out\n    \n    feature_names = list(df_out.columns)\n\n    del df, df_out, agg, agg_rank\n    gc.collect()\n\n    return X, y, feature_names, test_idx\nx_train, y_train, train_columns, _ = feature_engineering(True,False)\nx_test, _, _ , test_idx = feature_engineering(False,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train['headshotrate'] = x_train['kills']/x_train['headshotKills']\nx_test['headshotrate'] = x_test['kills']/x_test['headshotKills']\n\nx_train['killStreakrate'] = x_train['killStreaks']/x_train['kills']\nx_test['killStreakrate'] = x_test['killStreaks']/x_test['kills']\n\nx_train['healthitems'] = x_train['heals'] + x_train['boosts']\nx_test['healthitems'] = x_test['heals'] + x_test['boosts']\n\ndel x_train['heals'];del x_test['heals']\n\ntrain_columns.append('headshotrate')\ntrain_columns.append('killStreakrate')\ntrain_columns.append('healthitems')\ntrain_columns.remove('heals')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = reduce_mem_usage(x_train)\nx_test  =reduce_mem_usage(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM\n# model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM\nfolds = KFold(n_splits=3,random_state=6)\noof_preds = np.zeros(x_train.shape[0])\nsub_preds = np.zeros(x_test.shape[0])\n\nstart = time.time()\nvalid_score = 0\n\nfeature_importance_df = pd.DataFrame()\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n    trn_x, trn_y = x_train.iloc[trn_idx], y_train[trn_idx]\n    val_x, val_y = x_train.iloc[val_idx], y_train[val_idx]    \n    \n    train_data = lgb.Dataset(data=trn_x, label=trn_y)\n    valid_data = lgb.Dataset(data=val_x, label=val_y)   \n    \n    params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators':15000, 'early_stopping_rounds':100,\n              \"num_leaves\" : 31, \"learning_rate\" : 0.05, \"bagging_fraction\" : 0.9,\n               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n             }\n    \n    lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=1000) \n    \n    oof_preds[val_idx] = lgb_model.predict(val_x, num_iteration=lgb_model.best_iteration)\n    oof_preds[oof_preds>1] = 1\n    oof_preds[oof_preds<0] = 0\n    sub_pred = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration) \n    sub_pred[sub_pred>1] = 1 # should be greater or equal to 1\n    sub_pred[sub_pred<0] = 0 \n    sub_preds += sub_pred/ folds.n_splits\n    \n    #print('Fold %2d MAE : %.6f' % (n_fold + 1, mean_absolute_error(val_y, oof_preds[val_idx])))\n    #valid_score += mean_absolute_error(val_y, oof_preds[val_idx])\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = train_columns\n    fold_importance_df[\"importance\"] = lgb_model.feature_importance()\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    gc.collect()\n    \n#print('Full MAE score %.6f' % mean_absolute_error(y_train, oof_preds))\nend = time.time()\nprint(\"Take Time :\",(end-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n    by=\"importance\", ascending=False)[:50].index\n\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(14,10))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(14, 14))\nplt.scatter(y_train, oof_preds)\nplt.xlabel(\"y\")\nplt.ylabel(\"predict_y\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/' + 'test_V2.csv')\npred = sub_preds\nprint(\"fix winPlacePerc\")\nfor i in range(len(df_test)):\n    winPlacePerc = pred[i]\n    maxPlace = int(df_test.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    pred[i] = winPlacePerc\n\n    if (i + 1) % 100000 == 0:\n        print(i, flush=True, end=\" \")\n\ndf_test['winPlacePerc'] = pred\n\nsubmission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}