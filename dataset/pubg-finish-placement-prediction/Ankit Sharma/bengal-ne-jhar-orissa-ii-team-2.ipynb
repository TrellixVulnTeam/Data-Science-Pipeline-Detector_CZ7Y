{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc, sys\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)"},{"metadata":{},"cell_type":"markdown","source":"### Reading dataset:\nLets have a look into our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape of the data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some info of the dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for null values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's a pretty much of a clean data."},{"metadata":{},"cell_type":"markdown","source":"## Visualization of some attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"headshot_kill = df[df['headshotKills']>0]\nplt.figure(figsize=(15,5))\nsns.countplot(headshot_kill['headshotKills'].sort_values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df=df[df['kills']>0]\nnew_df=new_df[new_df['headshotKills']>0]\nsns.lineplot(x='headshotKills', y='kills', data=new_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"obvious conclusion for the relation of the headshots and kills during the gameplay."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='DBNOs', y='kills', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obvious variation. We all try to kill the enemy whom we had knocked out. But sometimes their team members revives them, so similarly for such cases we will be having damage dealt higher even if the number of kills is lower"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='winPlacePerc', y='killStreaks', data=df, ratio=3, color='b', )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that teams or players with high kill streaks have a good chance for bagging the chicken dinner."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.lineplot(x='winPlacePerc', y='kills', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variation of kills and winplacepercent. It shows variation across the teams too who have low winplaceperc. but the graphs looks good ;)"},{"metadata":{"trusted":true},"cell_type":"code","source":"xy=df[df['winPlacePerc']==1]\nxy=xy[xy['damageDealt']<1000]\nxy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here this dataset shows that there are many teams who have dealt less damage even less than 1000 still their winplaceperc is 1. And some players with damage dealt with even lower than a single person that is less than 100. Which may shows that the whole game they just might kept running only too the safe zones or they just kept hidding until the last enemy team is left, which maay be considered as a tactic but not a fairplay. XD"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='winPlacePerc', y='DBNOs', data=df, ratio=3, color='r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='winPlacePerc', y='teamKills', data=df, ratio=3, color='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here the comparison between the team kills and winplaceperc we can see sometimes the team/solo players who kills many team but they also gget killed because of exxcitement and barging at a full speed. Here the most variation can be seen at the most 2 exxtreme ends"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.2f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Since the data is huge we had memory usage problem. And this `reduce_mem_usage` funtion helps us to tackle that problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reduce the usage of memory\n# Ref: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(is_train=True):\n    if is_train: \n        print(\"processing train.csv\")\n        df = pd.read_csv(\"../input/pubg-finish-placement-prediction/train_V2.csv\")\n\n        df = df[df['maxPlace'] > 1]\n    else:\n        print(\"processing test.csv\")\n        df = pd.read_csv(\"../input/pubg-finish-placement-prediction/test_V2.csv\")\n        \n    \n    # df = reduce_mem_usage(df)\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    \n    # df = df[:100]\n    \n    print(\"remove some columns\")\n    target = 'winPlacePerc'\n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    \n    features.remove(\"matchType\")\n    \n    \n    y = None\n    \n    print(\"get target\")\n    if is_train: \n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        features.remove(target)\n\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    else: df_out = df[['matchId','groupId']]\n\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group sum feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('sum')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_sum\", \"_sum_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    df_out=reduce_mem_usage(df_out)\n    \n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    df_out=reduce_mem_usage(df_out)\n    \n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    df_out=reduce_mem_usage(df_out)\n    \n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n    \n    \n\n    X = np.array(df_out)\n    \n    feature_names = list(df_out.columns)\n\n    del df, df_out, agg, agg_rank\n    gc.collect()\n\n    return X, y, feature_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y, feature_names = feature_engineering(True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting data into trainig and validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split (x_train, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries for model building"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# data manipulation\n\nimport numpy as np\nimport pandas as pd\n# plot\nimport matplotlib.pyplot as plt\n# model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=lgb.Dataset(X_train, label=y_train)\nval_data= lgb.Dataset(X_val, label=y_val)\n\nparams = {\n    'num_leaves': 144,\n    'learning_rate': 0.1,\n    'n_estimators': 1500,\n    'max_depth':12,\n    'max_bin':55,\n    'bagging_fraction':0.8,\n    'bagging_freq':5,\n    'feature_fraction':0.9,\n    'verbose':50, \n    'early_stopping_rounds':100\n    }\n\nparams['metric'] = 'auc'\nlgb_model= lgb.train(params, train_data, valid_sets=val_data, num_boost_round=3000, early_stopping_rounds=100)\ny_pred=lgb_model.predict(X_val)\nprint(mean_absolute_error(y_val,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction on Validation dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lgb_model.predict(X_val)\nprint(mean_absolute_error(y_val,y_pred))\ndel X_val\ndel y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test, y_test, feature_names = feature_engineering(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred=lgb_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving submission.csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/pubg-finish-placement-prediction/test_V2.csv\")\nvar=pd.DataFrame(columns=['Id','winPlacePerc'])\nvar['Id']= df['Id']\n\nvar['winPlacePerc'] = y_test_pred\n\nsubmission = var[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}