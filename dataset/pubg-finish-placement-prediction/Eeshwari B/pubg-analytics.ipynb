{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/train_V2.csv')\ntrain = reduce_mem_usage(train)\ntest = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/test_V2.csv')\ntest = reduce_mem_usage(test)\ntest1=reduce_mem_usage(test)\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\ntrain.groupby('matchId')['matchType'].first().value_counts().plot.bar(ax=ax[0])\n\nmapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\ntrain['matchType'] = train['matchType'].apply(mapper)\ntrain.groupby('matchId')['matchType'].first().value_counts().plot.bar(ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nf,ax = plt.subplots(figsize=(20, 15))\nsns.heatmap(train.corr(), annot=True, fmt= '.1f',ax=ax, cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()\ndata = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"A total of {} players ({:.4f}%) have won without a single kill!\".format(len(data[data['winPlacePerc']==1]), 100*len(data[data['winPlacePerc']==1])/len(train)))\ndata1 = train[train['damageDealt'] == 0].copy()\nprint(\"A total of {} players ({:.4f}%) have won without dealing damage!\".format(len(data1[data1['winPlacePerc']==1]), 100*len(data1[data1['winPlacePerc']==1])/len(train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train.copy()\ndata = data[data['walkDistance'] < train['walkDistance'].quantile(0.99)]\nplt.figure(figsize=(15,10))\nplt.title(\"Walking Distance Distribution\",fontsize=15)\nsns.distplot(data['walkDistance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# f,ax1 = plt.subplots(figsize =(15,8))\n# sns.pointplot(x='vehicleDestroys',y='winPlacePerc',data=data,color='lime',alpha=0.5)\n# plt.xlabel('Count of Vehicle Destroys',fontsize = 16,color='blue')\n# plt.ylabel('Win Percentage',fontsize = 16,color='blue')\n# plt.title('Vehicle Destroyed/ Win Ratio',fontsize = 20,color='blue')\n# plt.grid()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"In the game on an average a person uses {:.1f} heal items, 99% of people use {} or less, while the doctor used {}.\".format(train['heals'].mean(), train['heals'].quantile(0.99), train['heals'].max()))\nprint(\"In the game on an average a person uses {:.1f} boost items, 99% of people use {} or less, while the doctor used {}.\".format(train['boosts'].mean(), train['boosts'].quantile(0.99), train['boosts'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(train[train['winPlacePerc'].isnull()].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Engineer a new feature _totalDistance\ntrain['_totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Engineer _headshot_rate feature --- headshots made per kill\ntrain['_headshot_rate'] = train['headshotKills'] / train['kills']\ntrain['_headshot_rate'] = train['_headshot_rate'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining some functions for plotting graphs, we will be needing a lot of countplot and distplot\ndef show_countplot(column):\n    plt.figure(figsize=(15,8))\n    sns.countplot(data=train, x=column).set_title(column)\n    plt.show()\n    \ndef show_distplot(column):\n    plt.figure(figsize=(15, 8))\n    sns.distplot(train[column], bins=50)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of Hitman who made more than 10 kills and all the kills were done by headshot(perfect kill)\ndisplay(train[(train['_headshot_rate'] == 1) & (train['kills'] >=10)].shape)\ntrain[(train['_headshot_rate'] == 1) & (train['kills'] >= 10)].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create feature killsWithoutMoving\ntrain['_killsWithoutMoving'] = ((train['kills'] > 0) & (train['_totalDistance'] == 0))\n# Check players who kills without moving\ndisplay(train[train['_killsWithoutMoving'] == True].shape)\ntrain[train['_killsWithoutMoving'] == True].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop longestKill 'fraudsters'\ntrain.drop(train[train['longestKill'] >= 1000].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop roadKill 'fraudsters'\ntrain.drop(train[train['roadKills'] > 10].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop walking anomalies\ntrain.drop(train[(train['walkDistance'] >= 13000) & (train['kills'] == 0)].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop riding anomalies\ntrain.drop(train[(train['rideDistance'] >= 30000) & (train['kills'] == 0)].index, inplace = True)\ntrain.drop(train[(train['walkDistance'] == 0) & (train['rideDistance'] > 0) & (train['kills'] > 0)].index, inplace = True)\ntrain.drop(train[(train['_totalDistance'] == 0)].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ntrain.drop(train[train['swimDistance'] >= 2000].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ntrain.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ntrain.drop(train[train['heals'] >= 40].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data=train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data = reduce_mem_usage(cleaned_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data['_playersJoined'] = cleaned_data.groupby('matchId')['matchId'].transform('count')\ndata = cleaned_data.copy()\ndata = data[data['_playersJoined']>49]\nplt.figure(figsize=(15,10))\nsns.countplot(data['_playersJoined'])\nplt.title(\"Players Joined\",fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create normalized features\ncleaned_data['_killsNorm'] = cleaned_data['kills']*((100-cleaned_data['_playersJoined'])/100 + 1)\ncleaned_data['_damageDealtNorm'] = cleaned_data['damageDealt']*((100-cleaned_data['_playersJoined'])/100 + 1)\ncleaned_data['_maxPlaceNorm'] = cleaned_data['maxPlace']*((100-cleaned_data['_playersJoined'])/100 + 1)\ncleaned_data['_matchDurationNorm'] = cleaned_data['matchDuration']*((100-cleaned_data['_playersJoined'])/100 + 1)\n# Compare standard features and normalized features\nto_show = ['Id', 'kills','_killsNorm','damageDealt', '_damageDealtNorm', 'maxPlace', '_maxPlaceNorm', 'matchDuration', '_matchDurationNorm']\ncleaned_data[to_show][0:11]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match = cleaned_data.groupby('matchId')\ncleaned_data['_killsPerc'] = match['kills'].rank(pct=True).values\ncleaned_data['_killPlacePerc'] = match['killPlace'].rank(pct=True).values\ncleaned_data['_walkDistancePerc'] = match['walkDistance'].rank(pct=True).values\ncleaned_data['_damageDealtPerc'] = match['damageDealt'].rank(pct=True).values\ncleaned_data['_walkPerc_killsPerc'] = cleaned_data['_walkDistancePerc'] / cleaned_data['_killsPerc']\ncleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = cleaned_data[['_killsPerc', '_killPlacePerc','_walkDistancePerc','_damageDealtPerc', '_walkPerc_killsPerc','winPlacePerc']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.heatmap(\n    corr,\n    xticklabels=corr.columns.values,\n    yticklabels=corr.columns.values,\n    annot=True,\n    linecolor='white',\n    linewidths=0.1,\n    cmap=\"BrBG\"\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg = cleaned_data.groupby(['groupId']).size().to_frame('players_in_team')\ncleaned_data = cleaned_data.merge(agg, how='left', on=['groupId'])\ncleaned_data['_healthItems'] = cleaned_data['heals'] + cleaned_data['boosts']\ncleaned_data['_headshotKillRate'] = cleaned_data['headshotKills'] / cleaned_data['kills']\ncleaned_data['_killPlaceOverMaxPlace'] = cleaned_data['killPlace'] / cleaned_data['maxPlace']\ncleaned_data['_killsOverWalkDistance'] = cleaned_data['kills'] / cleaned_data['walkDistance']\ncleaned_data['_killsOverDistance'] = cleaned_data['kills'] / cleaned_data['_totalDistance']\ncleaned_data['_walkDistancePerSec'] = cleaned_data['walkDistance'] / cleaned_data['matchDuration']\ncleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = cleaned_data[['killPlace', 'walkDistance','players_in_team','_healthItems', '_headshotKillRate', '_killPlaceOverMaxPlace', '_killsOverWalkDistance', '_killsOverDistance','_walkDistancePerSec','winPlacePerc']].corr()\nplt.figure(figsize=(15,8))\nsns.heatmap(\n    corr,\n    xticklabels=corr.columns.values,\n    yticklabels=corr.columns.values,\n    annot=True,\n    linecolor='white',\n    linewidths=0.1,\n    cmap=\"BrBG\"\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.drop(['_headshotKillRate','_killsOverDistance', '_killsOverWalkDistance', ], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.drop(['killPoints','matchDuration','maxPlace','numGroups','rankPoints','roadKills','teamKills','winPoints', '_playersJoined', '_maxPlaceNorm', '_matchDurationNorm', '_killsWithoutMoving'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = cleaned_data.corr().abs()\n\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\nprint(to_drop)\n# Drop features \n# cleaned_data.drop(cleaned_data[to_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test.drop(['_playersJoined'], axis=1, inplace=True)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_fit = [col for col in cleaned_data.columns]\ncorr = cleaned_data[cols_to_fit].corr()\nf,ax = plt.subplots(figsize=(30, 20))\nsns.heatmap(corr, annot=True, fmt= '.1f',ax=ax, cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"highly_corr=cleaned_data.copy()\nhighly_corr.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = highly_corr[highly_corr['winPlacePerc'].notnull()].reset_index(drop=True)\nX_test = highly_corr[highly_corr['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis=1).reset_index(drop=True)\n\n\nY_train = X_train.pop('winPlacePerc')\nX_test_grp = X_test[['matchId','groupId']].copy()\ntrain_matchId = X_train['matchId']\n\n# drop matchId,groupId\nX_train.drop(['matchId','groupId','Id'], axis=1, inplace=True)\nX_test.drop(['matchId','groupId','Id'], axis=1, inplace=True)\n\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encode matchType\nhighly_corr = pd.get_dummies(test, columns=['matchType'])\n\n# Take a look at the encoding\nmatchType_encoding = highly_corr.filter(regex='matchType')\nmatchType_encoding.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# highly_corr = pd.get_dummies(highly_corr, columns=['matchType'])\nhighly_corr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# highly_corr = pd.get_dummies(test, columns=['matchType'])\n\n# # Take a look at the encoding\n# matchType_encoding = highly_corr.filter(regex='matchType')\n# matchType_encoding.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn groupId and match Id into categorical types\nhighly_corr['groupId'] = highly_corr['groupId'].astype('category')\nhighly_corr['matchId'] = highly_corr['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\nhighly_corr['groupId_cat'] = highly_corr['groupId'].cat.codes\nhighly_corr['matchId_cat'] = highly_corr['matchId'].cat.codes\n\n# Get rid of old columns\nhighly_corr.drop(columns=['groupId', 'matchId'], inplace=True)\n\n# Lets take a look at our newly created features\nhighly_corr[['groupId_cat', 'matchId_cat']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Id column, because it probably won't be useful for our Machine Learning algorithm,\n# because the test set contains different Id's\nhighly_corr.drop(columns = ['Id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"highly_corr.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take sample for debugging and exploration\nsample = 500000\ndf_sample = highly_corr.sample(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split sample into training data and target variable\ndf = df_sample.drop(columns = ['winPoints']) #all columns except target\ny = df_sample['winPoints'] # Only target variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for splitting training and validation data\ndef split_vals(a, n : int): \n    return a[:n].copy(), a[n:].copy()\nval_perc = 0.12 # % to use for validation set\nn_valid = int(val_perc * sample) \nn_trn = len(df)-n_valid\n# Split data\nraw_train, raw_valid = split_vals(df_sample, n_trn)\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\n\n# Check dimensions of samples\nprint('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metric used for the PUBG competition (Mean Absolute Error (MAE))\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Function to print the MAE (Mean Absolute Error) score\n\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n    #Score of the training dataset obtained using an out-of-bag estimate.\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train basic model\nm1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nm1.fit(X_train, y_train)\nprint_score(m1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}).sort_values('imp', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What are the most predictive features according to our basic random forest model\nfi = rf_feat_importance(m1, df); fi[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a feature importance graph for the 20 most important features\nplot1 = fi[:15].plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep only significant features\nto_keep = fi[fi.imp>0.0001].cols\nprint('Significant features: ', len(to_keep))\nto_keep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a DataFrame with only significant features\ndf_keep = df[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model on top features\nm2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nm2.fit(X_train, y_train)\nprint_score(m2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding same features to test data\nagg = test.groupby(['groupId']).size().to_frame('players_in_team')\ntest = test.merge(agg, how='left', on=['groupId'])\ntest['_headshot_rate'] = test['headshotKills'] / test['kills']\ntest['_headshot_rate'] = test['_headshot_rate'].fillna(0)\ntest['_totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\ntest['_playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\ntest['_killsNorm'] = test['kills']*((100-test['_playersJoined'])/100 + 1)\ntest['_damageDealtNorm'] = test['damageDealt']*((100-test['_playersJoined'])/100 + 1)\ntest['_healthItems'] = test['heals'] + test['boosts']\ntest['killsWithoutMoving'] = ((test['kills'] > 0) & (test['_totalDistance'] == 0))\ntest['_killPlacePerc'] = test['killPlace'].rank(pct=True).values\ntest['_killsPerc'] = test['kills'].rank(pct=True).values\ntest['_walkDistancePerc'] = test['walkDistance'].rank(pct=True).values\ntest['_walkPerc_killsPerc'] = test['_walkDistancePerc'] / test['_killsPerc']\ntest['_killPlaceOverMaxPlace'] = test['killPlace'] / test['maxPlace']\ntest['_killsPerc'] = test['kills'].rank(pct=True).values\ntest['_walkDistancePerc'] = test['walkDistance'].rank(pct=True).values\ntest['_walkDistancePerSec'] = test['walkDistance'] / test['matchDuration']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Turn groupId and match Id into categorical types\ntest['groupId'] = test['groupId'].astype('category')\ntest['matchId'] = test['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntest['groupId_cat'] = test['groupId'].cat.codes\ntest['matchId_cat'] = test['matchId'].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encode matchType\ntest = pd.get_dummies(test, columns=['matchType'])\n\n# Take a look at the encoding\nmatchType_encoding = highly_corr.filter(regex='matchType')\nmatchType_encoding.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop('Id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['groupId','matchId'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m3 = RandomForestRegressor(n_estimators=50, min_samples_leaf=3, max_features=0.5,\n                          n_jobs=-1)\nm3.fit(X_train, y_train)\nprint_score(m3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Remove irrelevant features from the test set\ntest_pred = test[to_keep].copy()\n\n# Fill NaN with 0 (temporary)\ntest_pred.fillna(0, inplace=True)\ntest_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.clip(a = m3.predict(test_pred), a_min = 0.0, a_max = 1.0)\npred_df = pd.DataFrame({'Id' : test1['Id'], 'winPlacePerc' : predictions})\npred_df\n# Create submission file\npred_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#workshop by edureka!","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}