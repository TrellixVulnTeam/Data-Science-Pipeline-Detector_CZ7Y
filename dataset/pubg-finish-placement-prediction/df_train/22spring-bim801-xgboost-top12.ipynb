{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Final Notebook for BIM801 Project**\n## *Kaggle competition / 22 Spring*\n### PUBG Finish Placement Prediction\n- Including feature engineering, model, predict\n- Applied XGB model","metadata":{}},{"cell_type":"code","source":"# Analysis * Visualize * Processing\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport sys\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.options.display.float_format = '{:.5g}'.format\nimport warnings\nwarnings.filterwarnings(action='ignore')\nfrom tqdm import tqdm \nimport gc\nfrom timeit import default_timer as timer\n\n# Train * Test * Model \nfrom lightgbm import LGBMRegressor\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" UDF for Reduce memory use of dataframe by change data type\n\"\"\"\n# Thanks and credited to GUILLAUME MARTIN\n# https://www.kaggle.com/code/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n#     print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n#         start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = \"../input/pubg-finish-placement-prediction/\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" UDF for transform inf values into certain value\n\"\"\"\ndef fillInf(df, val):\n    numcols = df.select_dtypes(include='number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols: df[c].fillna(val, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" UDF for generate Group aggregated features \n\"\"\"\n# Need to predict the order of places for groups within each match.\n# Train on group-level instead of the user-level\ndef grouping(df, agg_col, sum_col):\n    group = df.groupby(['matchId','groupId','matchType'])\n    # group size, mean, sum, max, min\n    gSize = group.size().to_frame('gSize') # players\n    gMean = group.mean()\n    gSum = group[sum_col].sum().rename(columns=lambda s: '_gSum.' + s)\n    gMax = group[agg_col].max().rename(columns=lambda s: '_gMax.' + s)\n    gMin = group[agg_col].min().rename(columns=lambda s: '_gMin.' + s)\n    return pd.concat([gSize, gMean, gSum, gMax, gMin], axis=1).reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Feature Engineering**","metadata":{}},{"cell_type":"code","source":"def feature_engineering(is_train=True):\n    if is_train:\n        print(\"processing TRAIN set\")\n        df = reduce_mem_usage(pd.read_csv(INPUT_DIR + 'train_V2.csv'))\n        # Take the matches that have more than 1 player\n        df = df[df['maxPlace'] > 1]\n        # Anormal data row drop\n        df.drop(df.query('rideDistance == 0 and roadKills > 0').index, inplace=True)\n    else:\n        print(\"processing TEST set\")\n        df = reduce_mem_usage(pd.read_csv(INPUT_DIR + 'test_V2.csv'))\n    \n# LOG Transform features\n    log_target = ['assists', 'boosts', 'DBNOs', 'headshotKills', 'heals', \n              'kills', 'revives', 'roadKills', 'teamKills', 'vehicleDestroys', \n              'weaponsAcquired', 'walkDistance']\n    for col in log_target:\n        df[col] = df[col].apply(lambda x: np.log1p(x))\n    \n# Rank to percentile\n    match = df.groupby('matchId')\n    df['killPlacePerc'] = match['kills'].rank(pct=True).values\n    df['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values\n    df['damageDealtPerc'] = match['damageDealt'].rank(pct=True).values\n    del match\n    gc.collect()\n\n# Drop external point features\n    df.drop(['rankPoints','killPoints','winPoints'], axis=1, inplace=True)\n\n# Linear combination features\n    print(\"i am doing lcf\")\n    df['_totalDistance'] = (df['rideDistance']*0.5 + df[\"walkDistance\"]*0.2 + df[\"swimDistance\"]*0.3) / df['matchDuration']\n    df['_healthItems'] = df['heals'] + df['boosts']\n    df['_teamWork'] = df['revives'] + df['assists']\n    df['_over1km'] = df['longestKill'].apply(lambda x: 1 if x > 1000 else 0)\n    df['_headshotKillRate'] = df['headshotKills'] / df['kills']\n    df['_killsOverWalkDistance'] = df['kills'] / df['walkDistance']\n    df['_killsOverDistance'] = df['kills'] / df['_totalDistance']\n    df['_killPlacePerc'] = df['killPlace'] / df['maxPlace']\n    df['killStreakrate'] = df['killStreaks'] / df['kills']\n    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n    df['distance_over_weapons'] = df['_totalDistance'] / df['weaponsAcquired']\n    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n    df[\"skill\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n    fillInf(df, 0)\n    \n    \n    y = None\n    target = 'winPlacePerc'\n    \n# Grouping features (size, mean, max, min)\n    sum_col = ['kills','assists','teamKills','revives','damageDealt','walkDistance', '_totalDistance', '_healthItems']\n    agg_col = list(df.columns)\n    exclude_agg_col = ['Id','matchId','groupId','matchType','matchDuration','maxPlace','numGroups']\n    for c in exclude_agg_col:\n        agg_col.remove(c)\n        \n    if is_train:\n        y = pd.DataFrame(np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64))\n        df.drop(target, axis=1, inplace=True)\n        agg_col.remove(target)\n    \n    df = reduce_mem_usage(grouping(df, agg_col, sum_col))\n    for c in sum_col:\n        df['_perc.gMean_gMax.' + c] = df[c] / df['_gMax.' + c]\n        \n# Match feature - NumCols\n    numcols = df.select_dtypes(include='number').columns.values\n    numcols = numcols[numcols != target]\n    cols = np.r_[numcols,['matchId']]   \n    \n    # Match Rank\n    match = df[cols].groupby('matchId')\n    matchRank = match.rank(pct=True).rename(columns=lambda s: '_rank.' + s)\n    df = reduce_mem_usage(pd.concat([df, matchRank], axis=1))\n    del matchRank\n    gc.collect()\n\n    # Match Sum\n    cols = np.r_[agg_col,['matchId','gSize']]\n    match = df[cols].groupby('matchId')\n    matchSum = match.sum().rename(columns=lambda s: '_mSum.' + s).reset_index()\n    df = reduce_mem_usage(pd.merge(df, matchSum))\n    del matchSum\n    gc.collect()\n    \n    # Ranking of Kills & killPlace in each match\n    minKills = df.sort_values(['matchId','groupId','kills','killPlace']).groupby(['matchId','groupId','kills']).first().reset_index().copy()\n    for n in np.arange(4):\n        c = 'kills_' + str(n) + '_Place'\n        nKills = (minKills['kills'] == n)\n        minKills.loc[nKills, c] = minKills[nKills].groupby(['matchId'])['killPlace'].rank().values\n        df = pd.merge(df, minKills[nKills][['matchId','groupId',c]], how='left')\n        df[c].fillna(0, inplace=True)\n    df = reduce_mem_usage(df)\n    del minKills, nKills\n\n    \n# Enemy info\n    df['_enemy.sum.gSize'] = df['_mSum.gSize'] - df['gSize'] # 해당 매치에서 우리팀을 뺀 플레이어 수\n    df['_enemy.kills'] = (df['_mSum.kills'] - df['_gSum.kills']) / df['_enemy.sum.gSize'] # 해당 매치에서 에너미 한 명이 평균적으로 몇 명을 죽였는지\n    df['_enemy.damageDealt'] = (df['_mSum.damageDealt'] - df['_gSum.damageDealt']) / df['_enemy.sum.gSize'] # 해당 매치에서 에너미 한 명이 평균적으로 넣은 딜량\n    for c in agg_col:\n        df['_perc.gMax_mSum.' + c] = df['_gMax.' + c] / df['_mSum.' + c]  # 그룹 맥스 / 매치 총량  (for agg_col)\n        if c in sum_col:\n            df['_perc.gSum_mSum.' + c] = df['_gSum.' + c] / df['_mSum.' + c]  #그룹 총 / 매치 총량 (for sum_col)\n    fillInf(df, 0)\n    \n# Match Max\n    matchMax = match.max().rename(columns=lambda s: '_mMax.' + s).reset_index()\n    df = reduce_mem_usage(pd.merge(df, matchMax))\n    del matchMax\n    gc.collect()\n    for c in agg_col:\n        df['_perc.gMax_mMax.' + c] = df['_gMax.' + c] / df['_mMax.' + c] # 그룹 맥스 / 매치 맥스 (for agg_col)\n        df.drop(['_mMax.' + c], axis=1, inplace=True)\n    fillInf(df, 0)\n    \n# Rank of Top / bottom player of each group in match\n    killBottomPlayer = df[['matchId','_gMin.kills','_gMax.killPlace']].copy()\n    group = killBottomPlayer.groupby(['matchId','_gMin.kills'])\n    killBottomPlayer['_rank.bottomPlayer'] = group.rank().values\n    df = pd.merge(df, killBottomPlayer)\n\n    killTopPlayer = df[['matchId','_gMax.kills','_gMin.killPlace']].copy()\n    group = killTopPlayer.groupby(['matchId','_gMax.kills'])\n    killTopPlayer['_rank.topPlayer'] = group.rank().values\n    df = pd.merge(df, killTopPlayer)\n\n    del killBottomPlayer, killTopPlayer\n    gc.collect()\n\n# killPlace rank of group and kills\n# MatchType mapping\n    mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\n    df['matchTypeCat'] = df['matchType'].map(mapper)\n    \n# Drop constant feature\n    const_column = [col for col in df.columns if df[col].nunique() == 1]\n\n# Label Encoding\n    cols = [col for col in df.columns if col not in ['Id','matchId','groupId']]\n    for i, t in df.loc[:, cols].dtypes.iteritems():\n        if t == object:\n            df[i] = pd.factorize(df[i])[0]\n    print('Final df shape', df.shape)\n    return df, y, const_column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Train & Test data set including feature engineering\nX_train, y, trn_cc = feature_engineering(True)\nX_test, _, tst_cc = feature_engineering(False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop constant value filled column for both Train & Test set\nconst_cols = np.r_[trn_cc, tst_cc]\nX_train.drop(const_cols, axis=1, inplace=True)\nX_test.drop(const_cols, axis=1, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model & Predict","metadata":{}},{"cell_type":"code","source":"# make a copy of id columns for later predict result concat\nX_test_id = X_test[['matchId','groupId']].copy()\n# drop matchId,groupId\nX_train.drop(['matchId','groupId'], axis=1, inplace=True)\nX_test.drop(['matchId','groupId'], axis=1, inplace=True)\n\nprint(X_train.shape, X_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import minmax_scale\nimport lightgbm as lgb\n\n# params for xgb\nparams={'eta': 0.05, # learning rate\n        'n_estimators' : 4000,\n        'objective': 'reg:linear',    # default for regression\n        'eval_metric':'mae',\n        'num_leaves': 31,\n        'min_child_weight': 2,        # default = 1, 리프 노드에 포함되는 최소 관측지의 수\n        'sub_sample': 0.8,            # default = 1, 샘플링 비율 지정 -> 과적합 제어\n        'verbosity': 0,\n        'gamma' : 0,\n        'max_depth' : 7,\n        'random_state' : 42,\n       }\nmts = list() # MatchTypes\nfis = list() # Feature Importance\npred = np.zeros(X_test.shape[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Notice that, the prediction was executed grouped by matchType (solo, duo, squad)\n\"\"\"\nfor mt in tqdm(X_train['matchTypeCat'].unique()):\n    idx = X_train[X_train['matchTypeCat'] == mt].index\n    reg = xgb.XGBRegressor(**params)\n    reg.fit(X_train.loc[idx], y.loc[idx])\n\n    idx = X_test[X_test['matchTypeCat'] == mt].index\n    pred[idx] = reg.predict(X_test.loc[idx])\n    mts.append(mt)\n    fis.append(reg.feature_importances_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for mt, feature_importance in zip(mts, fis): \n    # Plot feature importance\n    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n    sorted_idx = np.argsort(feature_importance)\n    sorted_idx = sorted_idx[len(feature_importance) - 30:]\n    pos = np.arange(sorted_idx.shape[0]) + .5\n    plt.figure(figsize=(12,6))\n    plt.barh(pos, feature_importance[sorted_idx], align='center')\n    plt.yticks(pos, X_train.columns[sorted_idx])\n    plt.xlabel('Relative Importance')\n    plt.title('Variable Importance [matchTypeCat:' + str(mt) + ']')\n    plt.show()\n# print columns sort by feature importance\n# X_train.columns[np.argsort(-feature_importance)].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_id['winPlacePerc'] = pred\ngroup = X_test_id.groupby(['matchId'])\nX_test_id['_rank.winPlacePerc'] = group['winPlacePerc'].rank(method='min')\nX_test = pd.concat([X_test, X_test_id], axis=1)\nsub_group = group.count().reset_index()['matchId'].to_frame()\nX_test = pd.merge(X_test, sub_group)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Post processing \n### WinPlacePerc for adjust by the scoring rule of the winPlacePerc","metadata":{}},{"cell_type":"code","source":"# wpp 값을 더 정확한 (매치 상황에서 나올 수 있는) 값으로 보정해주는 과정\n\nfullgroup = (X_test['numGroups'] == X_test['maxPlace'])\n# full group (201,366 개) --> calculate from rank\nsubset = X_test.loc[fullgroup]\nX_test.loc[fullgroup, 'winPlacePerc'] = (subset['_rank.winPlacePerc'].values - 1) / (subset['maxPlace'].values - 1)\n\n# not full group (684,872 개) --> align with maxPlace\nsubset = X_test.loc[~fullgroup]\ngap = 1.0 / (subset['maxPlace'].values - 1)\nnew_perc = np.around(subset['winPlacePerc'].values / gap) * gap  # half&up\nX_test.loc[~fullgroup, 'winPlacePerc'] = new_perc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 위의 작업이 잘 작동하는지 확인 \nX_test.loc[~fullgroup, '_pred.winPlace'] = np.around(X_test.loc[~fullgroup, 'winPlacePerc'].values / gap) + 1\nX_test.loc[~fullgroup & (X_test['matchId'] == '000b598b79aa5e'),\n           ['matchId','groupId','winPlacePerc','maxPlace','numGroups','_pred.winPlace','_rank.winPlacePerc']\n          ].sort_values(['matchId','_pred.winPlace'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# edge cases handling\nX_test.loc[X_test['maxPlace'] == 0, 'winPlacePerc'] = 0\nX_test.loc[X_test['maxPlace'] == 1, 'winPlacePerc'] = 1  # nothing\nX_test.loc[(X_test['maxPlace'] > 1) & (X_test['numGroups'] == 1), 'winPlacePerc'] = 0\nX_test['winPlacePerc'].describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit file generate","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/test_V2.csv')\n\nsubmission = pd.merge(test, X_test[['matchId','groupId','winPlacePerc']])\nsubmission = submission[['Id','winPlacePerc']]\nsub_file_name = \"xgb_0609_ne4k\"\nsubmission.to_csv(\"../build/{}.csv\".format(sub_file_name), index=False)","metadata":{},"execution_count":null,"outputs":[]}]}