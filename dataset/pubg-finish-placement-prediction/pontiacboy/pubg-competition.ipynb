{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notebook explenation\nThis notebook is taken for the challenge of the ADS Minor at Fontys Hogeschool ICT. \n<br><br>\nThe goal of the challenge is to apply what we have learned in the course of the minor.\n<br><br>\nFor the challenge Max de Goede and Wesly Wijnen are working together\n<br><br>\n# Findings:\n## Illegal matches\nWhile exploring the data, an interesting discovery on illegal (games having a higher groupsize than is possible for the matchtype) games was made.\nThis lead to having only 700 useable matches to trian the network with.\n# Table of contents\n## 1. Imports\nImports used within the notebook to run it.\n## 2. Functions\nFunctions used within the notebook to run it.\n## 3. EDA (Exploratory Data Analysis)\nFindings within the data, what have we come up with.\n## 4. Data-Preparation\n## 5. Modelling\n### 5.1 Model without illegal matches (Only contians Solo and SoloFPP matches)\n### 5.2 Model with illegal matches (Contains matches with more than the maximum number of groupsize)"},{"metadata":{},"cell_type":"markdown","source":"# 1. Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport tensorflow as tf\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# 2. Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_elo_of_players_in_match(df,matchnr):\n    getmatchID = df.matchId[matchnr]\n    eloLIstrank  = df.rankPoints[df['matchId'] == getmatchID]\n    eloListWin = df.winPoints[df['matchId'] == getmatchID]\n    eloLIstrank = np.sort(eloLIstrank)\n    eloListWin = np.sort(eloListWin)\n    return  eloLIstrank,eloListWin\ndef create_cat_values(dataframe,column):\n    dataframe[column] = dataframe[column].astype('category')\n    dataframe[column] = dataframe[column].cat.codes\n    column_lenght = len(dataframe[column].unique())\n    print(column + ' columnContains:' + str(column_lenght) + ' categories')\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. EDA (Exploratory Data Analysis)/ 4. Data preparation\nLets take a look at what the data looks like and see if we can get any insights from the data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/train_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a wierd rating system where, the player either has rank or win points. It seems that wehn one is used the other is not"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(get_elo_of_players_in_match(df,20))\nget_elo_of_players_in_match(df,21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rankPoints[df['matchId'] == 'd5f02b7d5ed782']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets create a subset of each match Type. As the results **should** vary pet match type\nHere we do 2 things, we create categorical values for the match,group and ID of the player)"},{"metadata":{"trusted":true},"cell_type":"code","source":"create_cat_values(df,'Id')\ncreate_cat_values(df,'groupId')\ncreate_cat_values(df,'matchId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solo = df[df.matchType == 'solo']\nduo = df[df.matchType == 'duo']\nsquad = df[df.matchType == 'squad']\nsolofpp = df[df.matchType == 'solo-fpp']\nduofpp = df[df.matchType == 'duo-fpp']\nsquadfpp = df[df.matchType == 'squad-fpp']\nprint('Solo subset size ' + str(len(solo)))\nprint('Duo subset size ' + str(len(duo)))\nprint('Squad subset size ' + str(len(squad)))\nprint('SoloFPP subset size ' + str(len(solofpp)))\nprint('DuoFPP subset size '+ str(len(duofpp)))\nprint('SquadFPP subset size '+ str(len(squadfpp)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Dealing with data inconsistencies\n1. Different group size per game.\n  - Some squad matches contain, group sizes that exceed 4. There can be multiple reasons for this, we have for now decided to drop all matches containing a groupsize bigger than 4.\n  - Same can be said for duo games when it comes to having a maximum of 2 people per group.\n  - Same goes for solo where you cant have more than 2 people in the same group.\n2. Certain columns will be dropped.\n  - Not all features actually add any value, features such as killrank in a game doesn't add much. We can much better use the kills themselves"},{"metadata":{},"cell_type":"markdown","source":"### 4.1.1 Different group size per game"},{"metadata":{"trusted":true},"cell_type":"code","source":"squadfpp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = squadfpp.groupby(['groupId','matchId']).count()\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test['Id']> 4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test['Id']> 30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#squadfpp[squadfpp['matchId']== 20999].groupby('groupId').count()\nsquadfpp[squadfpp['groupId']== 1297474]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solofirst = solofpp[['Id','groupId']].groupby('groupId').count().max()[0]\nsolothird = solo[['Id','groupId']].groupby('groupId').count().max()[0]\nsquadfirst = squadfpp[['Id','groupId']].groupby('groupId').count().max()[0]\nsquadthird = squad[['Id','groupId']].groupby('groupId').count().max()[0]\nduofirst = duofpp[['Id','groupId']].groupby('groupId').count().max()[0]\nduothird = duo[['Id','groupId']].groupby('groupId').count().max()[0]\nprint('Solo max group FP:' + str(solofirst) + \" TP:\" + str(solothird) )\nprint('Squad max group FP:' + str(squadfirst) + \" TP:\" +str(squadthird))\nprint('Duo max group FP:' + str(duofirst) + \" TP:\" +str(duothird))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"listofcount = solofpp[['matchId','groupId','Id']].groupby(['groupId','matchId']).count()\nlistofcount.Id >2 \n#listofcount[listofcount['Id'] > solo].index[0][1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Illegal matches\nBelow you can find how we managed to take into account what illegal matches are"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating benchmark of player number\nsolot = 1\nduot = 2\nsquadt = 4\n\ndef get_all_matches(df,maxplayer):\n    matcharr = []\n    listofcount = df[['matchId','groupId','Id']].groupby(['groupId','matchId']).count()\n    listofcount = listofcount[listofcount['Id'] > solot].index\n    i = 0\n    for items in listofcount:\n        matchid = items[1]\n        matcharr.append(matchid)\n        i = i + 1\n    print(\"Unique number of games: \"+str(len(df['matchId'].unique()))+\" Unique number of games with more than the acceptable groupnumbers: \"+str(len(np.unique(matcharr))))\n    matcharr = np.unique(matcharr)\n    return matcharr\nsolofppmatchestodrop = get_all_matches(solofpp,solot)\nsolomatchestodrop = get_all_matches(solo,solot)\nget_all_matches(duofpp,duot)\nget_all_matches(duo,duot)\nget_all_matches(squadfpp,squadt)\nget_all_matches(squad,squadt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(solofppmatchestodrop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenbefore = len(solofpp)\nfor items in solofppmatchestodrop:\n    solofpp = solofpp[solofpp.matchId != items]\nlenafter = len(solofpp)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))\n\nlenbefore = len(solo)\nfor items in solomatchestodrop:\n    solo = solo[solo.matchId != items]\nlenafter = len(solo)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(solofpp['matchId'].unique()))\nlen(solo['matchId'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion, \nThere are only about 500-600 games with the correct number of group size. If the decision is made to use only games with the correct number of maximum group size. Only the games a few solofpp/solo games will be useable."},{"metadata":{},"cell_type":"markdown","source":"### 4.1.2 Dropping unnecesarry columns\nDropping:\n - MatchId\n - group_Id\n - Id\n - Matchtype\n - Num groups\n - maxPlace \n - killplace\n<br><br>\nSince these are solo matches we need to drop the following columns too:\n - Revives\n - DBNOs"},{"metadata":{"trusted":true},"cell_type":"code","source":"solofpp.columns\nsolofpp = solofpp[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints','rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'winPlacePerc']]\nsolo.columns\nsolo = solo[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints','rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'winPlacePerc']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solofpp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createplots(df):\n    coltoplot = ['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'winPlacePerc']\n    for columns in coltoplot:\n        plt.scatter(df.winPlacePerc, df[columns], alpha=0.5)\n        plt.title(columns)\n        plt.xlabel('Placement')\n        plt.ylabel(columns)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"createplots(solofpp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets now normalize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"solofpp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot = solofpp.boxplot(['winPlacePerc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the first version we will be focussing on the SoloFPP subset, as pefromance per player can only be measured by one person."},{"metadata":{"trusted":true},"cell_type":"code","source":"solofpp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will not use all of the variables, lets see if we can find some cool corrolations"},{"metadata":{"trusted":true},"cell_type":"code","source":"solofpp.columns\ncol = ['damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration','winPlacePerc']#,\n       #'rideDistance', 'roadKills',\n       #'swimDistance', 'vehicleDestroys', 'walkDistance',\n       #'weaponsAcquired']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatrix = solofpp[col].corr()\nsn.heatmap(corrMatrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solofpp.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets create a first network to see what the results can look like, But before this we need to normalize"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nsolofpp = solofpp.dropna()\nsolofpp.isnull().sum()\ny_train = solofpp['winPlacePerc']\nX_train = solofpp[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']]\nX_train = X_train[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n###############################\n#           Validate          #\n###############################\ny_val = solo['winPlacePerc']\nX_val = solo[['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(solofpp.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfor items in X_train.columns:\n    plt.figure()\n    X_train.boxplot([items])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is important to note that the accuracy does not mean much here as the network is specificly trying to predict the score. And the score can be pretty precise to predict"},{"metadata":{},"cell_type":"markdown","source":"# 6. Modelling\n## 6.1 Model for legal matches"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential(\n    [\n        tf.keras.layers.Dense(300, activation=\"relu\", name=\"Input_layer\"),\n        tf.keras.layers.Dense(100, activation=\"relu\"),\n        tf.keras.layers.Dense(100, activation=\"relu\"),\n        tf.keras.layers.Dense(80, activation=\"relu\"),\n        tf.keras.layers.Dense(40, activation=\"relu\"),\n        tf.keras.layers.Dense(30, activation=\"relu\"),\n        tf.keras.layers.Dense(20, activation=\"relu\"),\n        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n    ]\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n    # Loss function to minimize\n    loss='mse',\n    # List of metrics to monitor\n    metrics=['MSE'],\n)\nhistory  = model.fit(X_train,y_train,epochs = 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"networkoutput = model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe to hold the predicted, actual and difference between the two.\ndf_to_test_difference = pd.DataFrame(networkoutput,columns = ['Prediction'])\ndf_to_test_difference['Actual'] = prediction\ndf_to_test_difference['Difference'] = df_to_test_difference['Actual']- df_to_test_difference['Prediction']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_to_test_difference","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best way to evaluate the model is by looking at the mean value that deviates from the prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average deviation: \")\nprint(df_to_test_difference['Difference'].mean())\nprint('Maximum deviation: ')\nprint(df_to_test_difference['Difference'].max())\nprint('Minimum deviation: ')\nprint(df_to_test_difference['Difference'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shows the distribution between the prediction and actual. A perfect straight line would be the ideal scenario."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(df_to_test_difference.Prediction,df_to_test_difference.Actual)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This graph displays the distribution when we look at the differnce between the prediction and actual number"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=df_to_test_difference[\"Difference\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test the model\nLuckily we had some Solo games that are also useable we will make them ready for usage and run the model over the data and see what kind of results we get!"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_prediction = model.predict(X_val)\n# Create a dataframe to hold the predicted, actual and difference between the two.\ndf_to_val_difference = pd.DataFrame(val_prediction,columns = ['Prediction'])\ndf_to_val_difference['Actual'] = y_val.values\ndf_to_val_difference['Difference'] = df_to_val_difference['Actual']- df_to_val_difference['Prediction']\ndf_to_val_difference","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets run the same analysis as we did for the test values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average deviation: \")\nprint(df_to_val_difference['Difference'].mean())\nprint('Maximum deviation: ')\nprint(df_to_val_difference['Difference'].max())\nprint('Minimum deviation: ')\nprint(df_to_val_difference['Difference'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_to_val_difference.Prediction,df_to_val_difference.Actual)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=df_to_val_difference[\"Difference\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test the model on the test dataset\nSince the compettiion provides a train/test dataset, we will use the test dataset to see what kind of results we can get. Optimally this will be used in the model itself to further improve the model.\n#### Lets bring the data through the same pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"colls = ['assists', 'boosts', 'damageDealt',\n       'headshotKills', 'heals', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'matchDuration',\n       'rankPoints','rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints']\nrawtest = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/test_V2.csv')\ntesetdf = rawtest\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solotest = tesetdf[df.matchType == 'solo']\nduotest = tesetdf[tesetdf.matchType == 'duo']\nsquadtest = tesetdf[tesetdf.matchType == 'squad']\nsolofpptest = tesetdf[tesetdf.matchType == 'solo-fpp']\nduofpptest = tesetdf[tesetdf.matchType == 'duo-fpp']\nsquadfpptest = tesetdf[tesetdf.matchType == 'squad-fpp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"squadfpp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solotestmatchestodrop = get_all_matches(solotest,solot)\nsolofpptestmatchestodrop = get_all_matches(solofpptest,solot)\nget_all_matches(duotest,duot)\nget_all_matches(duofpptest,duot)\nget_all_matches(squadtest,squadt)\nget_all_matches(squadfpptest,squadt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lenbefore = len(solofpptest)\nfor items in solofpptestmatchestodrop:\n    solofpptest = solofpptest[solofpptest.matchId != items]\nlenafter = len(solofpptest)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))\n\nlenbefore = len(solotest)\nfor items in solotestmatchestodrop:\n    solotest = solotest[solotest.matchId != items]\nlenafter = len(solotest)\nprint('Lenght of data before dropping all wrong group measures: ' + str(lenbefore) + \" Len after: \" + str(lenafter))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Idtouse = solotest['Id']\nsolotest = solotest[colls].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\nsolofpptest = solofpptest[colls].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\ntesetdf = tesetdf[colls].apply(lambda x: (x - x.min()) / (x.max() - x.min()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testoutput = model.predict(solotest)\nsolotest['Id'] = Idtouse\nsolotest['winPlacePerc'] = testoutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solotest[['Id','winPlacePerc']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"legal_model_output = model.predict(tesetdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tesetdf = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/test_V2.csv')\nlegalmodelsub = rawtest\nrawtest['winPlacePerc'] = legal_model_output\nsubmissionlegalmoves = rawtest[['Id','winPlacePerc']]\n#submissionlegalmoves\nsubmissionlegalmoves.to_csv(\"submission.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionlegalmoves","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionlegal_full_games = solotest[['Id','winPlacePerc']]\nsubmissionlegal_full_games\n#submissionlegal_full_games.to_csv(\"submission.csv\",index = False)\n#submissionlegal_full_games","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example of what the submission needs to look like\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"submissiondf = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/sample_submission_V2.csv')\nsubmissiondf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nThe network works fairly well, it is able to predict in such a manner that the difference between the prediction and acutal number can be foreseen. There are some outliers but these seem merely a formality"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 6.2 Model for all matches\n### Running on full dataset, without taking expections out"},{"metadata":{"trusted":true},"cell_type":"code","source":"#traindata = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/train_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#traindata = traindata.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_train2 = traindata['winPlacePerc']\n#X_train2 = traindata[['assists', 'boosts', 'damageDealt',\n#       'headshotKills', 'heals', 'killPoints', 'kills',\n#       'killStreaks', 'longestKill', 'matchDuration',\n#       'rankPoints', 'rideDistance', 'roadKills',\n#       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n#       'weaponsAcquired', 'winPoints']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_fulldata = tf.keras.Sequential(\n#    [\n#        tf.keras.layers.Dense(300, activation=\"relu\", name=\"Input_layer\"),\n#        tf.keras.layers.Dense(100, activation=\"relu\"),\n#        tf.keras.layers.Dense(100, activation=\"relu\"),\n#        tf.keras.layers.Dense(80, activation=\"relu\"),\n#        tf.keras.layers.Dense(40, activation=\"relu\"),\n#        tf.keras.layers.Dense(30, activation=\"relu\"),\n#        tf.keras.layers.Dense(20, activation=\"relu\"),\n#        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n#    ]\n#)\n\n#model_fulldata.compile(\n#    optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n    # Loss function to minimize\n#    loss='mse',\n    # List of metrics to monitor\n#    metrics=['MSE'],\n#)\n#history  = model_fulldata.fit(X_train2,y_train2,epochs = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submitting the full dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#modeloutputfull_data[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tesetdf.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Idtouse = tesetdf['Id']\n#tesetdf\n#tesetdf = tesetdf[colls].apply(lambda x: (x - x.min()) / (x.max() - x.min()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#modeloutputfull_data = model_fulldata.predict(tesetdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tesetdf['Id'] = Idtouse\n#tesetdf['winPlacePerc'] = modeloutputfull_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tesetdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submissionfulldata = tesetdf[['Id','winPlacePerc']]\n#submissionfulldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submissionfulldata.to_csv(\"submission.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}