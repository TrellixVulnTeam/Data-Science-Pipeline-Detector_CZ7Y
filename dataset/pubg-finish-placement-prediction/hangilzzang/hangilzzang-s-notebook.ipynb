{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-14T12:38:57.157635Z","iopub.execute_input":"2022-06-14T12:38:57.158066Z","iopub.status.idle":"2022-06-14T12:38:57.186231Z","shell.execute_reply.started":"2022-06-14T12:38:57.157985Z","shell.execute_reply":"2022-06-14T12:38:57.185038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터분석\nimport pandas as pd\nimport numpy as np \n# 시각화\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# 모델들\nimport lightgbm as lgb\nimport xgboost\n!pip install catboost\nimport catboost \n# 모델 성능 측정을위한\nfrom sklearn.metrics import mean_absolute_error \n# feature 중요도 시각화\nfrom lightgbm import plot_importance\n# 램용량 확보\nimport gc\n# 하이퍼파라미터 세팅(optuna)\n!pip install optuna\nimport optuna\nfrom optuna import Trial\nfrom optuna.samplers import TPESampler\n# train test split\nfrom sklearn.model_selection import train_test_split\n# 앙상블모델\nfrom sklearn.ensemble import RandomForestRegressor\n# 스태킹(KFold)\nfrom sklearn.model_selection import KFold\n# 사이킷런에서 제공하는 점수제공 매써드 확인\nimport sklearn.metrics\n# sorted(sklearn.metrics.SCORERS.keys())\n# 차원축소\nfrom sklearn.decomposition import PCA\n# 정규화 진행\nfrom sklearn.preprocessing import MinMaxScaler\n# 교차검증\nfrom sklearn.model_selection import cross_val_score\n# 표준화\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-06-14T12:38:57.199339Z","iopub.execute_input":"2022-06-14T12:38:57.200006Z","iopub.status.idle":"2022-06-14T12:38:59.550514Z","shell.execute_reply.started":"2022-06-14T12:38:57.199977Z","shell.execute_reply":"2022-06-14T12:38:59.549722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-14T12:38:59.552195Z","iopub.execute_input":"2022-06-14T12:38:59.552741Z","iopub.status.idle":"2022-06-14T12:38:59.579223Z","shell.execute_reply.started":"2022-06-14T12:38:59.552704Z","shell.execute_reply":"2022-06-14T12:38:59.578179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\ntest = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T12:38:59.580284Z","iopub.execute_input":"2022-06-14T12:38:59.581164Z","iopub.status.idle":"2022-06-14T12:39:26.106819Z","shell.execute_reply.started":"2022-06-14T12:38:59.58113Z","shell.execute_reply":"2022-06-14T12:39:26.105809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 결측치 제거(1개)\ntrain=train.drop(index=train[train['winPlacePerc'].isnull()].index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 걷지않았는데 kill이 있을경우\ntrain=train.drop(index=train[ (train['walkDistance']==0) & (train['kills'] > 0)  ].index)\n# 매치 최대 킬수가 해당경기 인원보다 많은경우\ntrain=train.drop(index=train[ train.groupby('matchId')['kills'].transform('max')  > train.groupby('matchId')['Id'].transform('count')  ].index)\n# rideDistance가 0인데 로드킬이 있는경우\ntrain=train.drop(index=train[ (train['rideDistance']==0) & (train['roadKills']>0)  ].index)\n# 데미지를 주지않았는데 킬이 있는경우\ntrain=train.drop(index=train[ (train['damageDealt']==0) & (train['kills']>0)  ].index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 그룹 사이즈를 표시하는 컬럼을 만듭니다\ntrain['group_size']=train.groupby('groupId')['Id'].transform('count')\ntest['group_size']=test.groupby('groupId')['Id'].transform('count')\n\n# 게임내 오류로 만들어진 이상치를 나타내는 컬럼을 만듭니다\n\n# 조건1: numGroups와 maxPlace가 다를경우\ncond1=train['numGroups']!=train['maxPlace']\ncond11=test['numGroups']!=test['maxPlace']\n# 조건2: 한그룹에 5명이상 존재할경우\ncond2=train['group_size']>4\ncond22=test['group_size']>4\n\n# outlier\ntrain.loc[ cond1 , 'outlier']=1\ntrain['outlier'] = train['outlier'].fillna(0)\ntest.loc[ cond11 , 'outlier']=1\ntest['outlier'] = test['outlier'].fillna(0)\n\n# outlier1\ntrain.loc[ cond2 , 'outlier1']=1\ntrain['outlier1'] = train['outlier1'].fillna(0)\ntest.loc[ cond22 , 'outlier1']=1\ntest['outlier1'] = test['outlier1'].fillna(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# matchDuration 맵의 크기에 따라 0과 1로 분류 \ndef func(x):\n    if x < 1625:\n        return 0\n    else:\n        return 1\ntrain['matchDuration_class']=train['matchDuration'].map(func).to_frame()\ntest['matchDuration_class']=test['matchDuration'].map(func).to_frame()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 그룹별 각피쳐들의 평균\nfor i in['assists', 'boosts', 'damageDealt',\n       'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints',\n       'kills', 'killStreaks', 'longestKill', 'matchDuration',  'rankPoints', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']:\n    train[i+'_mean']=train.groupby('groupId')[i].transform('mean')\n\nfor i in['assists', 'boosts', 'damageDealt',\n       'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints',\n       'kills', 'killStreaks', 'longestKill', 'matchDuration',  'rankPoints', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']:\n    test[i+'_mean']=test.groupby('groupId')[i].transform('mean')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 평균화한 피쳐들의 매치안에서 랭킹으로 줄세우기(가장 값이 높을때 1등이 될수있도록 ascending을 조절했습니다)\nfor i in ['assists_mean', 'boosts_mean', 'damageDealt_mean',\n        'DBNOs_mean', 'headshotKills_mean', 'heals_mean', 'killPlace_mean',\n       'killPoints_mean', 'kills_mean', 'killStreaks_mean',\n       'longestKill_mean', 'matchDuration_mean', \n       'rankPoints_mean', 'revives_mean', 'rideDistance_mean',\n       'roadKills_mean', 'swimDistance_mean', 'teamKills_mean',\n       'vehicleDestroys_mean', 'walkDistance_mean',\n       'weaponsAcquired_mean', 'winPoints_mean']:\n    train[i+'_place']=train.groupby('matchId')[i].transform('rank', ascending=False)  \n\nfor i in ['assists_mean', 'boosts_mean', 'damageDealt_mean',\n        'DBNOs_mean', 'headshotKills_mean', 'heals_mean', 'killPlace_mean',\n       'killPoints_mean', 'kills_mean', 'killStreaks_mean',\n       'longestKill_mean', 'matchDuration_mean', \n       'rankPoints_mean', 'revives_mean', 'rideDistance_mean',\n       'roadKills_mean', 'swimDistance_mean', 'teamKills_mean',\n       'vehicleDestroys_mean', 'walkDistance_mean',\n       'weaponsAcquired_mean', 'winPoints_mean']:\n    test[i+'_place']=test.groupby('matchId')[i].transform('rank', ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 그룹안에서 피쳐별 max값을 표시합니다 \nfor i in['assists', 'boosts', 'damageDealt',\n       'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints',\n       'kills', 'killStreaks', 'longestKill', 'matchDuration', 'rankPoints', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']:\n    train[i+'_max']=train.groupby('groupId')[i].transform('max')\n\nfor i in['assists', 'boosts', 'damageDealt',\n       'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints',\n       'kills', 'killStreaks', 'longestKill', 'matchDuration',  'rankPoints', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']:\n    test[i+'_max']=test.groupby('groupId')[i].transform('max')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 그룹안의 max값을 기준으로 매치안에서 랭킹으로 줄세우기를 합니다\nfor i in['assists_max', 'boosts_max',\n       'damageDealt_max', 'DBNOs_max', 'headshotKills_max', 'heals_max',\n       'killPlace_max', 'killPoints_max', 'kills_max', 'killStreaks_max',\n       'longestKill_max', 'matchDuration_max', \n       'rankPoints_max', 'revives_max', 'rideDistance_max',\n       'roadKills_max', 'swimDistance_max', 'teamKills_max',\n       'vehicleDestroys_max', 'walkDistance_max', 'weaponsAcquired_max',\n       'winPoints_max']:\n    train[i+'_place']=train.groupby('matchId')[i].transform('rank', ascending=False)\n\nfor i in['assists_max', 'boosts_max',\n       'damageDealt_max', 'DBNOs_max', 'headshotKills_max', 'heals_max',\n       'killPlace_max', 'killPoints_max', 'kills_max', 'killStreaks_max',\n       'longestKill_max', 'matchDuration_max', \n       'rankPoints_max', 'revives_max', 'rideDistance_max',\n       'roadKills_max', 'swimDistance_max', 'teamKills_max',\n       'vehicleDestroys_max', 'walkDistance_max', 'weaponsAcquired_max',\n       'winPoints_max']:\n    test[i+'_place']=test.groupby('matchId')[i].transform('rank', ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 어시스트/매치인원: 10명있을때 2명 어시스트한것과 100명있을때 2명어시스트한것의 가치는 다르다\ntrain['assists_per']= train['assists']  /  ( train.groupby('matchId')['Id'].transform('count') )\ntest['assists_per']= test['assists']  /  ( test.groupby('matchId')['Id'].transform('count') )\n# 부스트 * 매치인원: 매치인원이 많을수록 부스트먹기가 힘들어집니다(경쟁자가 생김)\ntrain['boosts_value']= train['boosts']  * ( train.groupby('matchId')['Id'].transform('count') )\ntest['boosts_value']= test['boosts']  * ( test.groupby('matchId')['Id'].transform('count') )\n# 데미지양/매치에서발생한 총데미지: 매치안에서 나의 데미지가 차지하는정도\ntrain['damageDealt_per']= train['damageDealt']  / ( train.groupby('matchId')['damageDealt'].transform('sum') )\ntrain['damageDealt_per'] = train['damageDealt_per'].fillna(0)\ntest['damageDealt_per']= test['damageDealt']  / ( test.groupby('matchId')['damageDealt'].transform('sum') )\ntest['damageDealt_per'] = test['damageDealt_per'].fillna(0)\n# DBNO/매치인원: DBNO의 가치\ntrain['DBNOs_per']= train['DBNOs']  / ( train.groupby('matchId')['Id'].transform('count') )\ntest['DBNOs_per']= test['DBNOs']  / ( test.groupby('matchId')['Id'].transform('count') )\n# 헤드샷킬/킬: 헤드샷 비율\ntrain['headshot_rate'] = train['headshotKills'] / train['kills']\ntrain['headshot_rate'] = train['headshot_rate'].fillna(0) # 킬이0인경우 0으로 나눌수없기에 결측치처리됨\ntest['headshot_rate'] = test['headshotKills'] / test['kills']\ntest['headshot_rate'] = test['headshot_rate'].fillna(0) # 킬이0인경우 0으로 나눌수없기에 결측치처리됨\n# 힐 * 매치인원: 매치인원이 많아질수록 힐먹기가 힘들어짐(경쟁자생김)\ntrain['heals_per']= train['heals']  * ( train.groupby('matchId')['Id'].transform('count') )\ntest['heals_per']= test['heals']  * ( test.groupby('matchId')['Id'].transform('count') )\n# 킬플레이스 / 매치인원: 매치인원이 많아질수록 1등의 가치는 높아집니다\ntrain['killPlace_per']= train['killPlace']  / ( train.groupby('matchId')['Id'].transform('count') )\ntest['killPlace_per']= test['killPlace']  / ( test.groupby('matchId')['Id'].transform('count') )\n# 킬 / 매치인원\ntrain['kills_per']= train['kills']  / ( train.groupby('matchId')['Id'].transform('count') )\ntest['kills_per']= test['kills']  / ( test.groupby('matchId')['Id'].transform('count') )\n# 연속킬 / 매치인원\ntrain['killStreaks_per']= train['killStreaks']  / ( train.groupby('matchId')['Id'].transform('count') )\ntest['killStreaks_per']= test['killStreaks']  / ( test.groupby('matchId')['Id'].transform('count') )\n# 부활 / 그룹사이즈: 그룹원이적을수록 부활의 가치가 커짐\ntrain['revives_per']= train['revives']  / ( train['group_size'] )\ntest['revives_per']= test['revives']  / ( test['group_size'] )\n# 차탄거리 * 매치인원: 인원이 많아질수록 돌아다니기 힘들어짐\ntrain['rideDistance_value']= train['rideDistance']  * ( train.groupby('matchId')['Id'].transform('count') )\ntest['rideDistance_value']= test['rideDistance']  * ( test.groupby('matchId')['Id'].transform('count') )\n# 로드킬 / 매치인원\ntrain['roadKills_per']= train['roadKills']  / ( train.groupby('matchId')['Id'].transform('count') )\ntest['roadKills_per']= test['roadKills']  / ( test.groupby('matchId')['Id'].transform('count') )\n# 수영거리 * 매치인원\ntrain['swimDistance_value']= train['swimDistance']  * ( train.groupby('matchId')['Id'].transform('count') )\ntest['swimDistance_value']= test['swimDistance']  * ( test.groupby('matchId')['Id'].transform('count') )\n# 팀킬 / 그룹사이즈\ntrain['teamKills_per']= train['teamKills']  / ( train['group_size'] )\ntest['teamKills_per']= test['teamKills']  / ( test['group_size'] )\n# vehicleDestroys / 맵크기: 맵이 좁을수록 차가 드물게나옴=> 차부시기 힘듬\ntrain['vehicleDestroys_per']= train['vehicleDestroys']  / ( train['matchDuration_class']+1 )\ntest['vehicleDestroys_per']= test['vehicleDestroys']  / ( test['matchDuration_class']+1 )\n# 걸은 거리 * 매치인원수\ntrain['walkDistance_value']= train['walkDistance']  * ( train.groupby('matchId')['Id'].transform('count') )\ntest['walkDistance_value']= test['walkDistance']  * ( test.groupby('matchId')['Id'].transform('count') )\n# 무기 획득수 * 매치인원수\ntrain['weaponsAcquired_per']= train['weaponsAcquired']  * ( train.groupby('matchId')['Id'].transform('count') )\ntest['weaponsAcquired_per']= test['weaponsAcquired']  * ( test.groupby('matchId')['Id'].transform('count') )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 조합 컬럼 평균화\nfor i in ['assists_per', 'boosts_value', 'damageDealt_per',\n       'DBNOs_per', 'headshot_rate', 'heals_per', 'killPlace_per', 'kills_per',\n       'killStreaks_per', 'revives_per', 'rideDistance_value', 'roadKills_per', 'swimDistance_value', 'teamKills_per', 'vehicleDestroys_per',\n       'walkDistance_value', 'weaponsAcquired_per']:\n    train[i+'_mean']=train.groupby('groupId')[i].transform('mean')\n\nfor i in ['assists_per', 'boosts_value', 'damageDealt_per',\n       'DBNOs_per', 'headshot_rate', 'heals_per', 'killPlace_per', 'kills_per',\n       'killStreaks_per', 'revives_per', 'rideDistance_value', 'roadKills_per', 'swimDistance_value', 'teamKills_per', 'vehicleDestroys_per',\n       'walkDistance_value', 'weaponsAcquired_per']:\n    test[i+'_mean']=test.groupby('groupId')[i].transform('mean')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 조합 컬럼 평균화후 랭크화\nfor i in['assists_per_mean',\n       'boosts_value_mean', 'DBNOs_per_mean', 'heals_per_mean',\n       'killPlace_per_mean', 'kills_per_mean', 'killStreaks_per_mean',\n       'revives_per_mean', 'rideDistance_value_mean',\n       'roadKills_per_mean', 'swimDistance_value_mean',\n       'teamKills_per_mean', 'vehicleDestroys_per_mean',\n       'walkDistance_value_mean', 'weaponsAcquired_per_mean','group_size']:\n    train[i+'_place']=train.groupby('matchId')[i].transform('rank', ascending=False)\n\nfor i in['assists_per_mean',\n       'boosts_value_mean', 'DBNOs_per_mean', 'heals_per_mean',\n       'killPlace_per_mean', 'kills_per_mean', 'killStreaks_per_mean',\n       'revives_per_mean', 'rideDistance_value_mean',\n       'roadKills_per_mean', 'swimDistance_value_mean',\n       'teamKills_per_mean', 'vehicleDestroys_per_mean',\n       'walkDistance_value_mean', 'weaponsAcquired_per_mean','group_size']:\n    test[i+'_place']=test.groupby('matchId')[i].transform('rank', ascending=False)\n\nreduce_mem_usage(train)\nreduce_mem_usage(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func(x):\n    if x in ['squad-fpp','squad']:\n        return 'squad'\n    elif x in ['duo-fpp', 'duo']:\n        return 'duo'\n    elif x in ['solo-fpp', 'solo']:\n        return 'solo'\n    elif x in ['normal-squad-fpp', 'normal-squad', 'normal-duo-fpp', 'normal-duo', 'normal-solo-fpp', 'normal-solo']:\n        return 'normal'\n    elif x in ['crashfpp', 'crashtpp']:\n        return 'crash'\n    else:\n        return 'flare'\n\ntrain['matchType']=train['matchType'].map(func).to_frame()\ntest['matchType']=test['matchType'].map(func).to_frame()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 램 용량 확보\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 사본생성\ntrain2=train.copy()\ntest1=test.copy()\n# 칼럼 드랍\n# train1=train1.drop(['assists', 'boosts', 'headshotKills','weaponsAcquired','headshotKills_mean','revives_mean','swimDistance_mean_place','assists_max','DBNOs_max','headshotKills_max','rankPoints_max','headshotKills_max_place','revives_max_place','roadKills_max_place','teamKills_max_place','headshot_rate','swimDistance_value','revives_per_mean_place','teamKills_per_mean_place','revives', 'killPoints_mean', 'swimDistance_max','winPoints_max','killPoints_max_place','rankPoints_max_place','roadKills_per','rideDistance_value_mean_place','assists_mean','headshotKills_mean_place','killPoints_max','weaponsAcquired_max','teamKills_per_mean','assists_per_mean_place'], axis=1)\n# test1=test1.drop(['assists', 'boosts', 'headshotKills','weaponsAcquired','headshotKills_mean','revives_mean','swimDistance_mean_place','assists_max','DBNOs_max','headshotKills_max','rankPoints_max','headshotKills_max_place','revives_max_place','roadKills_max_place','teamKills_max_place','headshot_rate','swimDistance_value','revives_per_mean_place','teamKills_per_mean_place','revives', 'killPoints_mean', 'swimDistance_max','winPoints_max','killPoints_max_place','rankPoints_max_place','roadKills_per','rideDistance_value_mean_place','assists_mean','headshotKills_mean_place','killPoints_max','weaponsAcquired_max','teamKills_per_mean','assists_per_mean_place'], axis=1)\n\n# 샘플링 \ntrain1=train2.sample(n=500000)\n\n# X_train1, Y_train1, X_test1 생성\ntrain1=pd.get_dummies(train1, columns = ['matchType'])\ntest1=pd.get_dummies(test1, columns = ['matchType'])\na=train1.loc[:,['Id','groupId','matchId','maxPlace']]\nb=test1.loc[:,['Id','groupId','matchId','maxPlace']]\ntrain1=train1.drop(['groupId', 'Id', 'matchId'], axis=1)\ntest1=test1.drop(['groupId', 'Id', 'matchId'], axis=1)\nX_train1 = train1.drop(['winPlacePerc'], axis=1) \nY_train1 = train1['winPlacePerc'] \nX_test1  = test1\nX_train1.shape, Y_train1.shape, X_test1.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 표준화 1\nscaler = StandardScaler()\nscaler.fit(X_train1)\nX_train1 = pd.DataFrame(scaler.transform(X_train1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 표준화 2\nscaler = StandardScaler()\nscaler.fit(X_test1)\nX_test1 = pd.DataFrame(scaler.transform(X_test1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation과 train으로 나누기 차원축소 안하는경우\nX_train, X_val, y_train, y_val = train_test_split(X_train1, Y_train1, test_size=0.2, random_state=42)\nX_train.shape, X_val.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost_model = catboost.CatBoostRegressor()\ncatboost_model.fit(X_train, y_train)\nY_pred = catboost_model.predict(X_test1)\ntrain_pred = catboost_model.predict(X_train)\n# 후처리하면 점수는 더 잘나오나?\nprint('Mean Absolute Error is {:.5f}'.format(mean_absolute_error(y_train, train_pred)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 케글용\nsub1 = pd.DataFrame({\n        \"Id\": b['Id'],\n        'matchId': b['matchId'],\n        'maxPlace': b['maxPlace'],\n        'groupId': b['groupId'],\n        \"winPlacePerc\": Y_pred\n    })\nsub1['winPlacePerc']=sub1.groupby('groupId')['winPlacePerc'].transform('mean')\n\nsubmission = pd.DataFrame({\n        \"Id\": b['Id'],\n        \"winPlacePerc\": sub1['winPlacePerc']\n    })\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}