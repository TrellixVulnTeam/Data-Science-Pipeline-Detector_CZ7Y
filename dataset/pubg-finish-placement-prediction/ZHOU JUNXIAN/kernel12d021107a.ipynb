{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy  as np\nfrom scipy.stats import pearsonr\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.linear_model import Lasso,LassoCV,LassoLarsCV   # Lasso回归,LassoCV交叉验证实现alpha的选取，LassoLarsCV基于最小角回归交叉验证实现alpha的选取\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import train_test_split, GridSearchCV\ndef fillInf(df, val):\n    numcols = df.select_dtypes(include='number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols: df[c].fillna(val, inplace=True)\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18e9391a20ed896ee333f554d6779d0e9c84148b"},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train_V2.csv\", nrows=500000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c56d16119c7fbf73d1c72c6707f003f4458c115c"},"cell_type":"code","source":"#%% 对目标值SalePrice进行正态变换\n#sns.distplot(train_data['SalePrice'] , fit=norm);\n#(mu, sigma) = norm.fit(train_data['SalePrice'])\n#print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n#\n#fig = plt.figure()\n#res = stats.probplot(train_data['SalePrice'], plot=plt)\n#plt.show()\n\n#%% 部分算法喜欢正态分布的数据\n#train_data[\"SalePrice\"] = np.log1p(train_data[\"SalePrice\"])\n#sns.distplot(train_data['SalePrice'] , fit=norm);\n#(mu, sigma) = norm.fit(train_data['SalePrice'])\n#print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n#\n#fig = plt.figure()\n#res = stats.probplot(train_data['SalePrice'], plot=plt)\n#plt.show()\n\n\n#%% 特殊\ntest_data.loc[666, \"GarageQual\"] = \"TA\"\ntest_data.loc[666, \"GarageCond\"] = \"TA\"\ntest_data.loc[666, \"GarageFinish\"] = \"Unf\"\ntest_data.loc[666, \"GarageYrBlt\"] = 1980\ntest_data.loc[1116, \"GarageType\"] = np.nan\n\n#%%\nall_data = train_data.append(test_data, sort=False).reset_index()\n\n#%% 删除异常值\nall_data = all_data.drop(all_data[all_data['Id'] == 1299].index)\nall_data = all_data.drop(all_data[all_data['Id'] == 524 ].index)\n# LotArea异常\nall_data = all_data.drop(all_data[all_data['Id'] == 250 ].index)\nall_data = all_data.drop(all_data[all_data['Id'] == 314 ].index)\nall_data = all_data.drop(all_data[all_data['Id'] == 336 ].index)\nall_data = all_data.drop(all_data[all_data['Id'] == 707 ].index)\n# LotFrontage异常\nall_data = all_data.drop(all_data[all_data['Id'] == 935 ].index)\n# GarageArea异常\nall_data = all_data.drop(all_data[all_data['Id'] == 582 ].index)\nall_data = all_data.drop(all_data[all_data['Id'] == 1191 ].index)\n\n#%% 缺失值处理\ntotal = all_data.isnull().sum().sort_values(ascending=False)\npercent = (all_data.isnull().sum())/all_data.isnull().count().sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, sort=False, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent'] > 0]\n\n\n\n\n# PoolQc 泳池面积\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n# MiscFeature 其他特征\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n# Alley 巷子类别\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n# Fence 围墙质量\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n# FireplaceQu 壁炉质量 Fireplaces壁炉数量为0的话 也就没有壁炉了\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n\n# LotFrontage 距离街道的直线距离  这个能否继续优化\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))# GarageQual 车库质量\n# GarageQual 车库质量\n# GarageType 车库类型 一般 删除吧\n# GarageYrBlt 车库建造年份  分箱处理吧 \n# GarageFinish 车库内饰\n# GarageCond 车库条件\nfor col in ('GarageCond', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\n\n# GarageYrBlt 车库建造年份  分箱处理吧 \n# GarageArea 车库面积\n# GarageCars 车库车容量大小\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\n    \n# BsmtExposure 花园地下室墙 删除\n# BsmtCond 地下室概况\n# BsmtQual 地下室高度\n# BsmtFinType2 地下室装饰质量\n# BsmtFinType1 地下室装饰质量\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')    \n    \n    \n# MasVnrType 砌体饰面类型\n# MasVnrArea 砌体饰面面积\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n\n# MSZoning 区域分类\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n\n# Utilities 公共设施类型\nall_data.drop('Utilities', axis=1, inplace=True)\n\n# Functional 房屋功能性评级\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n\n# Exterior2nd 住宅外墙 #类别很多  这确定可以吗  \n# Exterior1st 住宅外墙\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n\n# SaleType 交易类型\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n# BsmtFinSF1 地下室装饰面积\n# BsmtFinSF2 地下室装饰面积 \n# TotalBsmtSF 地下室总面积\n# BsmtUnfSF 地下室未装饰面积\n# BsmtHalfBath 地下室半浴室\n# BsmtFullBath 地下室全浴室\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\n# Electrical 电力系统\ndict = {'SBrkr':'SBrkr', }\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['Electrical'] = all_data['Electrical'].map(lambda x:'SBrkr' if x=='SBrkr' else 'Other')\n\n# KitchenQual 厨房质量\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n\n\n\n#%% 对变量进行编码\nQual_map = (lambda x:4 if x == 'Ex' else 3 if x == 'Gd' else 2 if x =='TA'\n            else 1 if x =='Fa' else 0)\n# Po 比 None更差\n# 序数型参数\nall_data['FireplaceQu'] = all_data['FireplaceQu'].map(Qual_map).astype(int)\nall_data['BsmtQual'] = all_data['BsmtQual'].map(Qual_map).astype(int)\nall_data['BsmtCond'] = all_data['BsmtCond'].map(Qual_map).astype(int)\nall_data['GarageQual'] = all_data['GarageQual'].map(Qual_map).astype(int)\nall_data['GarageCond'] = all_data['GarageCond'].map(Qual_map).astype(int)\nall_data['ExterQual'] = all_data['ExterQual'].map(Qual_map).astype(int)\nall_data['ExterCond'] = all_data['ExterCond'].map(Qual_map).astype(int)\nall_data['HeatingQC'] = all_data['HeatingQC'].map(Qual_map).astype(int)\nall_data['PoolQC'] = all_data['PoolQC'].map(Qual_map).astype(int)              #大部分确实\nall_data['KitchenQual'] = all_data['KitchenQual'].map(Qual_map).astype(int)    #大部分确实\n\nall_data['OverallCond'] = all_data['OverallCond'].astype(int)\nall_data[\"BsmtExposure\"] = all_data[\"BsmtExposure\"].map({'None': 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}).astype(int)\n\n#是序数型 但不是很序数\n#bsmt_fin_dict = {'None': 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6}\n#all_data[\"BsmtFinType1\"] = all_data[\"BsmtFinType1\"].map(bsmt_fin_dict).astype(int)\n#all_data[\"BsmtFinType2\"] = all_data[\"BsmtFinType2\"].map(bsmt_fin_dict).astype(int)\n\n#是序数型 但不是很序数\nall_data[\"Functional\"] = all_data[\"Functional\"].map(lambda x:1 if x=='Typ' else 0).astype(int)\n    \nall_data[\"GarageFinish\"] = all_data[\"GarageFinish\"].map(\n        {'None': 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3}).astype(int)\n\n#是序数型 但不是很序数\n#all_data[\"Fence\"] = all_data[\"Fence\"].map(\n#        {'None': 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\": 3, \"GdPrv\": 4}).astype(int)\n    \n\n#%% 增加重要的特征\nall_data['TotalSF_Bs+Gr'] = all_data['TotalBsmtSF'] + all_data['GrLivArea']\nall_data['allArea'] = all_data['GrLivArea'] + all_data['GarageArea'] + all_data['TotalBsmtSF']\nall_data['is_1Stroy'] = pd.cut(all_data['2ndFlrSF'], bins=[-1,0,100000], labels=[0,1]).astype(int)\n\nall_data['age'] = all_data['YrSold'] - all_data['YearRemodAdd']\nall_data['newhouse_sold'] = all_data['YrSold'] - all_data['YearBuilt']\nall_data['newhouse_sold'] = all_data['newhouse_sold'].map(lambda x:1  if x < 3 else 0)\nall_data[\"Remodeled\"] = (all_data[\"YearRemodAdd\"] != all_data[\"YearBuilt\"]) * 1\nall_data[\"newRemodel_sold\"] = all_data['YrSold'] - all_data['YearRemodAdd']\nall_data[\"newRemodel_sold\"] = all_data['newRemodel_sold'].map(lambda x:1  if x < 3 else 0)\n#all_data.drop(['YrSold', 'YearRemodAdd', 'YearBuilt'], axis=1, inplace=True)\n\nall_data['Porch'] = all_data[['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']].sum(axis=1)\n\ncols = ['ExterQual','BsmtQual','HeatingQC','KitchenQual','FireplaceQu','GarageQual','PoolQC']\nCond = ['BsmtCond', 'GarageCond','ExterCond']\nall_data['Qual_all'] = all_data[cols].sum(axis=1)\nall_data['Cond_all'] = all_data[Cond].sum(axis=1)\n\n\nall_data[\"NewerDwelling\"] = all_data[\"MSSubClass\"].replace(\n        {20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1, 70: 0, 75: 0, 80: 0, 85: 0,\n         90: 0, 120: 1, 150: 0, 160: 0, 180: 0, 190: 0}) \n    \n#%% MSSubClass是数值型，但其实应该是字符型\nall_data[\"MSSubClass\"] = all_data[\"MSSubClass\"].astype('object')\n    \n\nall_data[\"SeasonSold\"] = all_data[\"MoSold\"].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, \n                                                  6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\n    \nall_data[\"SimplOverallQual\"] = all_data.OverallQual.replace(\n        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\nall_data[\"SimplOverallCond\"] = all_data.OverallCond.replace(\n        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n\n#%% 质量型Qual\nall_data[\"SimplPoolQC\"] = all_data.PoolQC.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplGarageQual\"] = all_data.GarageQual.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplFireplaceQu\"] = all_data.FireplaceQu.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplKitchenQual\"] = all_data.KitchenQual.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplHeatingQC\"] = all_data.HeatingQC.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplBsmtQual\"] = all_data.BsmtQual.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplExterQual\"] = all_data.ExterQual.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\n\n#%% 条件型Cond\nall_data[\"SimplBsmtCond\"] = all_data.BsmtCond.replace(\n        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\nall_data[\"SimplGarageCond\"] = all_data.GarageCond.replace(\n        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\nall_data[\"SimplExterCond\"] = all_data.ExterCond.replace(\n        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n\n\n#\n#all_data[\"SimplBsmtFinType1\"] = all_data.BsmtFinType1.replace(\n#        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n#all_data[\"SimplBsmtFinType2\"] = all_data.BsmtFinType2.replace(\n#        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n\n    \nneighborhood_map = {\n        \"MeadowV\" : 0,  #  88000\n        \"IDOTRR\" : 1,   # 103000\n        \"BrDale\" : 1,   # 106000\n        \"OldTown\" : 1,  # 119000\n        \"Edwards\" : 1,  # 119500\n        \"BrkSide\" : 1,  # 124300\n        \"Sawyer\" : 1,   # 135000\n        \"Blueste\" : 1,  # 137500\n        \"SWISU\" : 1,    # 139500\n        \"NAmes\" : 1,    # 140000\n        \"NPkVill\" : 1,  # 146000\n        \"Mitchel\" : 2,  # 153500\n        \"SawyerW\" : 2,  # 179900\n        \"Gilbert\" : 2,  # 181000\n        \"NWAmes\" : 2,   # 182900\n        \"Blmngtn\" : 2,  # 191000\n        \"CollgCr\" : 2,  # 197200\n        \"ClearCr\" : 3,  # 200250\n        \"Crawfor\" : 3,  # 200624\n        \"Veenker\" : 3,  # 218000\n        \"Somerst\" : 3,  # 225500\n        \"Timber\" : 3,   # 228475\n        \"StoneBr\" : 4,  # 278000\n        \"NoRidge\" : 4,  # 290000\n        \"NridgHt\" : 4,  # 315000\n    }\n\nall_data[\"NeighborhoodBin\"] = all_data[\"Neighborhood\"].map(neighborhood_map)\n\n\n\n\n\n#%% 删除的变量\nall_data.drop('BsmtUnfSF', axis=1, inplace=True) #删除后有提升\n\nall_data.drop('OpenPorchSF', axis=1, inplace=True) #删除后有提升\nall_data.drop('EnclosedPorch', axis=1, inplace=True) #删除后有提升\nall_data.drop('3SsnPorch', axis=1, inplace=True) #删除后有提升\nall_data.drop('ScreenPorch', axis=1, inplace=True) #删除后有提升\n\nall_data.drop('MoSold', axis=1, inplace=True) #删除后有提升\nall_data.drop('YrSold', axis=1, inplace=True) #删除后有提升\n\n#%% 离散数值变量，分箱\n#对YearBuilt\nbins = range(all_data['YearBuilt'].min()-1, all_data['YearBuilt'].max()+50, 5)\nlabels = range(len(bins)-1)\nall_data['YearBuilt'] = pd.cut(all_data['YearBuilt'], bins, labels=labels) #cut是cate属性\nall_data['YearBuilt'] = all_data['YearBuilt'].astype(int)\n#YearRemodAdd\nbins = range(all_data['YearRemodAdd'].min()-1, all_data['YearRemodAdd'].max()+50, 5)\nlabels = range(len(bins)-1)\nall_data['YearRemodAdd'] = pd.cut(all_data['YearRemodAdd'], bins, labels=labels) #cut是cate属性\nall_data['YearRemodAdd'] = all_data['YearRemodAdd'].astype(int)\n\n\n#%% 独热编码\nall_data = pd.get_dummies(all_data)\n\n#%% \n#all_data.plot(kind='scatter', x='WoodDeckSF', y='SalePrice')\n#train_data.groupby('MoSold')['SalePrice'].mean()\n\n#%% 数据标准化\n#from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n##\n#cols = ['index', 'Id']\n#numeric_features = list(all_data.dtypes[all_data.dtypes != \"object\"].index)\n#for each in cols:\n#    numeric_features.remove(each)\n#scaler.fit(all_data[numeric_features])\n#scaled = scaler.transform(all_data[numeric_features])\n#for i, col in enumerate(numeric_features):\n#    all_data[col] = scaled[:, i]\n##\n\n\n\n#%% \nX_train = all_data[all_data['SalePrice'].notnull()].reset_index(drop=True)\nX_test = all_data[all_data['SalePrice'].isnull()].drop(['SalePrice'], axis=1).reset_index(drop=True)\n     \nX_train.drop(['index', 'Id'], axis=1, inplace=True)\nX_test_Id = X_test['Id']\nX_test.drop(['index', 'Id'], axis=1, inplace=True)\n\n\nY_train = X_train.pop('SalePrice')\n\n\n\n\n#%% 使用xgboost预测\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import minmax_scale\nimport lightgbm as lgb\n\n\n#train_data = lgb.Dataset(X_train, \n#                         label=Y_train,\n#                         feature_name=list(X_train.columns), \n#                         categorical_feature=[cate_cols])\n\n\n#几个重要参数\n#针对 Leaf-wise (最佳优先) 树的参数优化\n#num_leaves 一棵树上的叶子数\n#min_data_in_leaf 一个叶子上数据的最小数量. 可以用来处理过拟合.默认20\n#max_depth 限制树模型的最大深度\n\n\n#针对更快的训练速度\n#通过设置 bagging_fraction 和 bagging_freq 参数来使用 bagging 方法\n#通过设置 feature_fraction 参数来使用特征的子抽样\n#使用较小的 max_bin\n#使用 save_binary 在未来的学习过程对数据加载进行加速\n\n\n#%%针对更好的准确率\n#使用较大的 max_bin （学习速度可能变慢）\n#使用较小的 learning_rate 和较大的 num_iterations\n#使用较大的 num_leaves （可能导致过拟合）\n#尝试 dart\n\n\n#%% 处理过拟合\n#使用较小的 max_bin\n#使用较小的 num_leaves\n#使用 min_data_in_leaf 和 min_sum_hessian_in_leaf\n#通过设置 bagging_fraction 和 bagging_freq 来使用 bagging\n#通过设置 feature_fraction 来使用特征子抽样\n#使用更大的训练数据\n#使用 lambda_l1, lambda_l2 和 min_gain_to_split 来使用正则\n#尝试 max_depth 来避免生成过深的树\nparams={'learning_rate': 0.005,    #学习速率\n        'n_estimators': 4500, \n        'num_leaves': 10, \n        'max_depth': 7,          #叶的最大深度\n        'min_data_in_leaf': 8,  \n        'metric':'rmse',          #目标函数\n        'objective': 'regression', \n        'verbose': 0,\n        'bagging_fraction': 0.15,    #每次迭代用的数据比例\n        'feature_fraction': 0.25,     #每次迭代用的特征比例\n        'reg_alpha': 0.1,\n        'reg_lambda': 0.01,\n        'random_state': 21}\n\n\n#data_train = lgb.Dataset(X_train, Y_train, silent=True)\n#cv_results = lgb.cv(\n#    params, data_train, num_boost_round=10000, nfold=5, stratified=False, shuffle=True, metrics='rmse',\n#    early_stopping_rounds=50, verbose_eval=100, show_stdv=True)\n#\n#parameters = {'reg_alpha':  [0.001,0.01,0.1,1],\n#              'reg_lambda': [0.001,0.01,0.1,1],\n#              }\n#\nreg = lgb.LGBMRegressor(**params)\n#gsearch = GridSearchCV(reg, param_grid=parameters, scoring='neg_mean_squared_error', cv=5)\n#gsearch.fit(X_train, Y_train)\n#print(gsearch.best_params_)\n\n\nreg.fit(X_train, Y_train)\nresult_xgb = reg.predict(X_test)\nresult_xgb = pd.DataFrame(result_xgb)\nresult_xgb = pd.concat([X_test_Id, result_xgb], axis=1)\nresult_xgb.columns = ['Id', 'SalePrice']\n\n\na = pd.DataFrame(reg.feature_importances_, index=X_train.columns).sort_values(by=0, ascending=False)\n#print('xgboost得分为:', rmsle_cv(reg, X_train, Y_train))\nresult_xgb.to_csv('submission_xgb.csv', index=False)\n\n\n#%% 使用Lasso\n#from sklearn.linear_model import Lasso\n#best_alpht = 0.00099\n#lasso = Lasso(alpha=best_alpht, max_iter=50000)\n#lasso.fit(X_train, Y_train)\n#\n#result_lasoo = lasso.predict(X_test)\n#print('lasso得分为:', rmsle_cv(lasso, X_train, Y_train))\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}