{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport shap\nfrom bayes_opt import BayesianOptimization\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\n\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import LinearSVR\nfrom sklearn.model_selection import cross_val_score\nimport os\nprint(os.listdir(\"../input\"))\n\nsns.set(color_codes=True)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_V2.csv')\ntest = pd.read_csv('../input/test_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['winPlacePerc'].isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(train.index[2744604], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\ncorr = train.corr()\nsns.heatmap(corr, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['winPlacePerc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['matchId']=='a10357fd1a4a91'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train[train['matchId']=='a10357fd1a4a91']['winPlacePerc'], bins=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(24,16))\n\nsns.violinplot(train['winPlacePerc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Match Duration Distribution (s)')\nplt.figure(figsize=(16,16))\nplt.hist(train['matchDuration'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering\n\n\n# Distance and speed\ntrain['total_distance'] = train['swimDistance'] + train['walkDistance'] + train['rideDistance']\ntrain['avg_speed'] = train['total_distance'] / train['matchDuration']\ntrain['avg_swim_speed'] = train['swimDistance'] / train['matchDuration']\ntrain['avg_walk_speed'] = train['walkDistance'] / train['matchDuration']\ntrain['avg_ride_speed'] = train['rideDistance'] / train['matchDuration']\n# Kill rate feature engineering\ntrain['streak_rate'] = train['killStreaks'] / train['kills']\ntrain['kills_rate'] = train['kills'] / train['matchDuration']\ntrain['knocked_kill'] = train['DBNOs'] / train['kills']\ntrain['kill_per_heal'] = train['heals'] / train['kills']\ntrain['kills_per_place'] = train['kills'] / train['killPlace']\ntrain['damage_kill'] = train['damageDealt'] / train['kills']\ntrain['damage_rate'] = train['damageDealt'] / train['matchDuration']\n# Utilities items\ntrain['heals_rate'] = train['heals'] / train['matchDuration']\ntrain['boosts_rate'] = train['boosts'] / train['matchDuration']\ntrain['utility_used'] = train['boosts'] + train['heals']\ntrain['boosts_prop'] = train['boosts'] / train['utility_used']\ntrain['heals_prop'] = train['heals'] / train['utility_used']\ntrain['utility_rate'] = train['utility_used'] / train['matchDuration']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.replace([np.inf, -np.inf], np.nan, inplace=True)\ntrain.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,16))\nplt.title('Distribution: Data for player per matches')\nplt.xlabel('Number of players per match')\nplt.hist(train['numGroups'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,16))\nsns.scatterplot(train[train['matchId']=='a10357fd1a4a91']['walkDistance'], train[train['matchId']=='a10357fd1a4a91']['winPlacePerc'])\nplt.title('Walk Distance vs. Winning Percentile (Match)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,16))\nsns.scatterplot(train['total_distance'], train['winPlacePerc'])\nplt.title('Total Distance vs. Winning Percentile')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,16))\nsns.scatterplot(train['avg_speed'], train['winPlacePerc'])\nplt.title('Average Speed vs. Winning Percentile')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,16))\nplt.title('Kills vs Winning Percentile')\nsns.scatterplot(train['kills'], train['winPlacePerc'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match_types = list(train['matchType'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(4,4, figsize=(16,19))\nplt.subplots_adjust(hspace = 0.7)\n\nfor i,t in enumerate(match_types):\n    axs[i // 4][i % 4].hist(train[train['matchType'] == t]['winPlacePerc'].astype('float'))\n    axs[i // 4][i % 4].set_title(t+' Win Percentile')\n     \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(4,4, figsize=(20,30))\nplt.subplots_adjust(hspace = 0.5)\n\nfor i,t in enumerate(match_types):\n    sns.scatterplot(train[train['matchType'] == t]['total_distance'],train[train['matchType'] == t]['winPlacePerc'], ax=axs[i // 4][i % 4])\n    axs[i // 4][i % 4].set_title(t+': Total Distance vs Win Percentile')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(4,4, figsize=(20,30))\nplt.subplots_adjust(hspace = 0.5)\n\nfor i,t in enumerate(match_types):\n    sns.scatterplot(train[train['matchType'] == t]['weaponsAcquired'],train[train['matchType'] == t]['winPlacePerc'], ax=axs[i // 4][i % 4])\n    axs[i // 4][i % 4].set_title(t+': Weapons Acquired vs Win Percentile')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['matchType'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for fpp\n\ndef oh_matchtype(x, mode_name):\n    if len(mode_name) <= len(x):\n        if mode_name == x[:len(mode_name)]:\n            return 1\n    return 0\n    \n        \nmatch_type = ['crash','flare','duo', 'solo', 'squad' ,'normal-duo','normal-solo','normal-squad']\n\ntrain['fps_mode'] = train['matchType'].apply(lambda x: 1 if 'fpp' in x else 0)\n\nfor i in match_type:\n    train['matchtype_'+i] = train['matchType'].apply(oh_matchtype, args=(i,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['matchType'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n#scale_col = ['damageDealt','matchDuration','rankPoints','killPoints','winPoints','walkDistance',\n#             'rideDistance','damage_kill','total_distance','longestKill']\n#train[scale_col] = StandardScaler().fit_transform(train[scale_col])\nscaler = StandardScaler()\nscaler.fit(train.drop(['Id','groupId','matchId','winPlacePerc'],axis=1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\ntrain_red = train.sample(frac=0.1, random_state=42).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, test_x, train_y, test_y = train_test_split(train_red.drop(['Id','groupId','matchId','winPlacePerc'],axis=1),\n                                                    train_red['winPlacePerc'], \n                                                    test_size=0.25)\n\nscale_train_x, scale_test_x, scale_train_y, scale_test_y = train_test_split(\n    scaler.transform(train_red.drop(['Id','groupId','matchId','winPlacePerc'],axis=1)),\n                                                    train_red['winPlacePerc'], \n                                                    test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(train_x, train_y)\ndtest = xgb.DMatrix(test_x, test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_log_params = {'eta': 0.5,\n              'objective': 'reg:logistic',\n              'max_depth': 7,\n              'subsample': 0.8,\n              'colsample_bytree': 0.8,\n              'eval_metric': ['rmse','mae'],\n              'seed': 11,\n              'silent': True}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"watchlist = [(dtrain, 'train'), (dtest,'test')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_log_model = xgb.train(params=xgb_log_params, dtrain=dtrain, evals=watchlist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(xgb_log_model)\nshap_values = explainer.shap_values(train_x)\nshap.summary_plot(shap_values, train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_evaluate(max_depth, gamma, colsample_bytree):\n    params = {'eval_metric': 'rmse',\n              'max_depth': int(max_depth),\n              'subsample': 0.8,\n              'eta': 0.1,\n              'gamma': gamma,\n              'colsample_bytree': colsample_bytree}\n    # Used around 1000 boosting rounds in the full model\n    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n    \n    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 9), \n                                             'gamma': (0, 1),\n                                             'colsample_bytree': (0.3, 0.9)})\n# Use the expected improvement acquisition function to handle negative numbers\n# Optimally needs quite a few more initiation points and number of iterations\nxgb_bo.maximize(init_points=3, n_iter=5, acq='ei')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in xgb_bo.max['params']:\n    xgb_log_params[param] = int(xgb_bo.max['params'][param])\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_log_params['eta'] = 0.09\nnum_boost_round = 10000\nearly_stopping_rounds=100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_log_model = xgb.train(params=xgb_log_params, \n                          dtrain=dtrain, \n                          evals=[watchlist[1]],\n                         early_stopping_rounds=early_stopping_rounds,\n                         num_boost_round = num_boost_round)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crossfit(model, X, y,n_splits = 5):\n    kf = KFold(n_splits = 5, random_state=42)\n    for train_index, test_index in kf.split(X):\n        model = model\n        train_X, train_Y = X[train_index], Y[train_index]\n        test_X, test_Y = X[test_index], Y[test_index]\n        model.fit(train_X, train_Y) \n        return sqrt(mean_squared_error(model.predict(test_X), test_Y))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del dtrain\ndel dtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.linear_model import SGDRegressor\nsgd = SGDRegressor(max_iter=1000000, penalty='elasticnet')\n\nsgd_score = cross_val_score(sgd, \n                train_x, \n                train_y, \n                cv=5,\n                scoring='neg_mean_squared_error')\n#print(np.mean(np.sqrt(np.negative(sgd_score))))\nprint(sgd_score)"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters = [{'tol': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]}]\n\nclf = GridSearchCV(LinearSVR(), tuned_parameters, cv=4, scoring='neg_mean_squared_error')\nclf.fit(scale_train_x, scale_train_y)\nprint(clf.best_params_)\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"{} (+/-{}) for {}\".format(mean, std * 2, params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr  = LinearSVR(max_iter=10000)\nsvr.set_params(**clf.best_params_)\nsvr_score = cross_val_score(svr, \n                scale_train_x, \n                scale_train_y, \n                cv=5,\n                scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.negative(svr_score))))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}