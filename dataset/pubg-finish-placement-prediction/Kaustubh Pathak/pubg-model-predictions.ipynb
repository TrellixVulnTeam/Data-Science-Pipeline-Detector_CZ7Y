{"cells":[{"metadata":{"trusted":true,"_uuid":"0d511893dfe14372adc3bb9860d5aaaa9d0f94dd","_kg_hide-input":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport lightgbm as lgb\nimport time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading only 10000 rows to fasten the process "},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/train_V2.csv',nrows=1000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82012e2f2d234e7dbc2ac7f4398b92477965c928"},"cell_type":"code","source":"train.corr().style.format(\"{:.2%}\").highlight_min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    # iterate through all the columns of a dataframe and modify the data type\n    #   to reduce memory usage.        \n    \n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" I don't know if maxPlace is < 1  in any of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['maxPlace'] > 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(7).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mapping the matchType and reducing the Memory size."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['matchType'] = train['matchType'].map({\n    'crashfpp':1,\n    'crashtpp':2,\n    'duo':3,\n    'duo-fpp':4,\n    'flarefpp':5,\n    'flaretpp':6,\n    'normal-duo':7,\n    'normal-duo-fpp':8,\n    'normal-solo':9,\n    'normal-solo-fpp':10,\n    'normal-squad':11,\n    'normal-squad-fpp':12,\n    'solo':13,\n    'solo-fpp':14,\n    'squad':15,\n    'squad-fpp':16\n    })\ntrain = train[train['winPlacePerc'].notnull()]\ntrain = reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping the Data and counting the matchsize of each match Id and merge them to original id."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmatchSizeData = train.groupby(['matchId']).size().reset_index(name='matchSize')\ntrain = pd.merge(train, matchSizeData, on=['matchId'])\ndel matchSizeData","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GC collect function is used to clear the memory and empty the RAM."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding the new features to train data.\n<br>\nBut the rankPoints have multiple values and in 10000 rows about 3800 have -1 value and can be replaced by 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[(train['rankPoints']==-1),'rankPoints'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So Features i am  addings are.\n<br>\n* Combining with points as RankPoints and KillPoint\n* Ratio of Head Kills with total Number of his kills.\n* Ratio of streak kills with total kills\n* Ratio of killPlace to MaxPlace\n* and many more ...."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['rankPoints_killPoints'] = train['rankPoints'] + train['killPoints'] \ntrain['headshotKills_ratio'] = train['headshotKills']/train['kills']\ntrain['killStreaks_ratio'] = train['killStreaks']/train['kills']\ntrain['totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']\ntrain['killPlace_maxPlace_Ratio']= train['killPlace']/train['maxPlace']\ntrain['distance_weaponAcquired_Ratio'] = train['totalDistance']/train['weaponsAcquired']\ntrain['distance_kills_Ratio'] =train['kills']/train['totalDistance']\ntrain['distance_heals_Ratio'] = train['heals']/train['totalDistance']\ntrain['walkDistance_kills_Ratio'] = train['kills']/train['walkDistance']\ntrain['walkDistance_heals_Ratio'] = train['heals']/train['walkDistance']\ntrain['walk_duration_Ratio'] = train['walkDistance']/train['matchDuration']\ntrain['distance_duration_Ratio'] = train['totalDistance']/train['matchDuration']\ntrain['killplace_kills_Ratio'] = train['kills']/train['killPlace']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So Basically next code will tell the place or ranking of you in your team on basis of walkDistance or kills or killstreak"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['walkDistancePerc'] = train.groupby('matchId')['walkDistance'].rank(pct=True).values\ntrain['killPerc'] = train.groupby('matchId')['kills'].rank(pct=True).values\ntrain['killPlacePerc'] = train.groupby('matchId')['killPlace'].rank(pct=True).values\ntrain['weaponsAcquiredPerc'] = train.groupby('matchId')['weaponsAcquired'].rank(pct=True).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are Mulltiple rest factors considered in \n<br>\nhttps://www.kaggle.com/kamalchhirang/5th-place-solution-0-0184-score\n<br>\nbut for now consisdering only these only...."},{"metadata":{},"cell_type":"markdown","source":"Filling rest of rows whose values are either NAN or Infinity or - Infinity to 0\n<br>\ndisplay((train.isnull().sum()/train.shape[0])*100)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train == np.Inf] = np.NaN\ntrain[train == np.NINF] = np.NaN\ntrain.fillna(0,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I Am not Sure what he trying to achieve by saying and finding mean Data but lets see"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(train.columns)\nfeatures.remove('Id')\nfeatures.remove('groupId')\nfeatures.remove('matchId')\nfeatures.remove('matchSize')\nfeatures.remove('matchType')\nfeatures.remove('winPlacePerc')\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanData = train.groupby(['matchId','groupId'])[features].agg('mean')\nprint(meanData.shape)\ndisplay(meanData.head().T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So Basically by this code we are trying to find the mean of the team it played with in that match by matching with groupId and MatchId.\n<br>\nDifferent Factors such as Min and Max or Mode can be calculated with and can br merged"},{"metadata":{"trusted":true},"cell_type":"code","source":"meanData = meanData.replace([np.inf , np.NINF , np.NaN] , 0)\nmeanData = reduce_mem_usage(meanData)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In a match there can be muliple teams and each have unique groupId\n<br>\nSo basically we are finding group perfermance in match"},{"metadata":{"trusted":true},"cell_type":"code","source":"meanDataRank = meanData.groupby('matchId')[features].rank(pct=True).reset_index()\nmeanDataRank.sample(7).T\nmeanDataRank = reduce_mem_usage(meanDataRank)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merging the MeanData and MeanDataRank with Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train, meanData.reset_index(), suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\ntrain = pd.merge(train, meanDataRank, suffixes=[\"\", \"_meanRank\"], how='left', on=['matchId', 'groupId']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del meanData\ndel meanDataRank\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.join(reduce_mem_usage(train.groupby('matchId')[features].rank(ascending=False).add_suffix('_rankPlace').astype(int)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now Repeating the process with Standard Deviation"},{"metadata":{"trusted":true},"cell_type":"code","source":"stdData = train.groupby(['matchId','groupId'])[features].agg('std').replace([np.inf, np.NINF,np.nan], 0)\nstdDataRank = reduce_mem_usage(stdData.groupby('matchId')[features].rank(pct=True)).reset_index()\ntrain = pd.merge(train , stdDataRank , suffixes=['','_stdRank'] , how = 'left' , on=['matchId','groupId'])\ndel stdData\ndel stdDataRank\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now Repeating the process with Max..."},{"metadata":{"trusted":true},"cell_type":"code","source":"maxData = train.groupby(['matchId','groupId'])[features].agg('std').replace([np.inf, np.NINF,np.nan], 0)\nmaxDataRank = reduce_mem_usage(maxData.groupby('matchId')[features].rank(pct=True)).reset_index()\ntrain = pd.merge(train , maxDataRank , suffixes=['','_maxRank'] , how = 'left' , on=['matchId','groupId'])\ndel maxData\ndel maxDataRank\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same Process is repeated for min and max and Std with both match and group but i am skipping this process for now"},{"metadata":{"trusted":true},"cell_type":"code","source":"fea = train.columns\nfea\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the Both the test and train will have the data from different matches so data is divided around MatchID"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_val(data, fraction):\n    matchIds = data['matchId'].unique().reshape([-1])\n    train_size = int(len(matchIds)*fraction)\n    \n    random_idx = np.random.RandomState(seed=2).permutation(len(matchIds))\n    train_matchIds = matchIds[random_idx[:train_size]]\n    val_matchIds = matchIds[random_idx[train_size:]]\n    \n    data_train = data.loc[data['matchId'].isin(train_matchIds)]\n    data_val = data.loc[data['matchId'].isin(val_matchIds)]\n    return data_train, data_val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So Basically in original\n<br> \nsplit is done in 2 steps to avoid memory Loss."},{"metadata":{},"cell_type":"markdown","source":"So In Original Tutorial the Light GB Library is used ...\n<br>\nSo I will try to use the same and then use neural network ...\n<br>\nBut i am working only on 10000 rows So i am not expecting great results..\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train , data_val = split_train_val(train , .90)\ndata_train = data_train.drop(columns = ['Id' , 'groupId' , 'matchId'])\ndata_val = data_val.drop(columns = ['Id' , 'groupId' , 'matchId'])\ndata_train_y =data_train['winPlacePerc']\ndata_train = data_train.drop(columns = ['winPlacePerc'])\ndata_val_y = data_val['winPlacePerc']\ndata_val = data_val.drop(columns = ['winPlacePerc'])\ndata_train = np.array(data_train)\ndata_train_y = np.array(data_train_y)\ndata_val = np.array(data_val)\ndata_val_y = np.array(data_val_y)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = lgb.Dataset( data_train , label = data_train_y)\nval_set = lgb.Dataset( data_val , label = data_val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nparams = {\n        \"objective\" : \"regression\", \n        \"metric\" : \"mae\", \n        \"num_leaves\" : 60, \n        \"learning_rate\" : 0.003, \n        \"bagging_fraction\" : 0.9,\n        \"bagging_seed\" : 0, \n        \"num_threads\" : 4,\n        \"colsample_bytree\" : 0.5, \n        'lambda_l2':9\n}\n\nmodel = lgb.train(  params, \n                    train_set = train_set,\n                    num_boost_round=9400,\n                    early_stopping_rounds=200,\n                    verbose_eval=100, \n                    valid_sets=[train_set,val_set]\n                  )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureImp = list(model.feature_importance())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(featureImp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets Make a function for test data to iterate it through test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_set_modify(test):\n    test['matchType'] = test['matchType'].map({\n        'crashfpp':1,\n        'crashtpp':2,\n        'duo':3,\n        'duo-fpp':4,\n        'flarefpp':5,\n        'flaretpp':6,\n        'normal-duo':7,\n        'normal-duo-fpp':8,\n        'normal-solo':9,\n        'normal-solo-fpp':10,\n        'normal-squad':11,\n        'normal-squad-fpp':12,\n        'solo':13,\n        'solo-fpp':14,\n        'squad':15,\n        'squad-fpp':16\n        })\n    test = reduce_mem_usage(test)\n\n    matchSizeData = test.groupby(['matchId']).size().reset_index(name='matchSize')\n    test = pd.merge(test, matchSizeData, on=['matchId'])\n    del matchSizeData\n\n    gc.collect()\n    test = reduce_mem_usage(test)\n    test.loc[(test['rankPoints']==-1),'rankPoints'] = 0\n\n    test['rankPoints_killPoints'] = test['rankPoints'] + test['killPoints'] \n    test['headshotKills_ratio'] = test['headshotKills']/test['kills']\n    test['killStreaks_ratio'] = test['killStreaks']/test['kills']\n    test['totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\n    test['killPlace_maxPlace_Ratio']= test['killPlace']/test['maxPlace']\n    test['distance_weaponAcquired_Ratio'] = test['totalDistance']/test['weaponsAcquired']\n    test['distance_kills_Ratio'] =test['kills']/test['totalDistance']\n    test['distance_heals_Ratio'] = test['heals']/test['totalDistance']\n    test['walkDistance_kills_Ratio'] = test['kills']/test['walkDistance']\n    test['walkDistance_heals_Ratio'] = test['heals']/test['walkDistance']\n    test['walk_duration_Ratio'] = test['walkDistance']/test['matchDuration']\n    test['distance_duration_Ratio'] = test['totalDistance']/test['matchDuration']\n    test['killplace_kills_Ratio'] = test['kills']/test['killPlace']\n\n    test['walkDistancePerc'] = test.groupby('matchId')['walkDistance'].rank(pct=True).values\n    test['killPerc'] = test.groupby('matchId')['kills'].rank(pct=True).values\n    test['killPlacePerc'] = test.groupby('matchId')['killPlace'].rank(pct=True).values\n    test['weaponsAcquiredPerc'] = test.groupby('matchId')['weaponsAcquired'].rank(pct=True).values\n\n    test[test == np.Inf] = np.NaN\n    test[test == np.NINF] = np.NaN\n    test.fillna(0,inplace = True)\n\n    features = list(test.columns)\n    features.remove('Id')\n    features.remove('groupId')\n    features.remove('matchId')\n    features.remove('matchSize')\n    features.remove('matchType')\n\n    meanData = test.groupby(['matchId','groupId'])[features].agg('mean')\n    display(meanData.head().T)\n\n    meanData = meanData.replace([np.inf , np.NINF , np.NaN] , 0)\n    meanData = reduce_mem_usage(meanData)\n\n    meanDataRank = meanData.groupby('matchId')[features].rank(pct=True).reset_index()\n    meanDataRank = reduce_mem_usage(meanDataRank)\n\n    test = pd.merge(test, meanData.reset_index(), suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\n    test = pd.merge(test, meanDataRank, suffixes=[\"\", \"_meanRank\"], how='left', on=['matchId', 'groupId']) \n\n    del meanData\n    del meanDataRank\n    gc.collect()\n\n    test = test.join(reduce_mem_usage(test.groupby('matchId')[features].rank(ascending=False).add_suffix('_rankPlace').astype(int)))\n\n    stdData = test.groupby(['matchId','groupId'])[features].agg('std').replace([np.inf, np.NINF,np.nan], 0)\n    stdDataRank = reduce_mem_usage(stdData.groupby('matchId')[features].rank(pct=True)).reset_index()\n    test = pd.merge(test , stdDataRank , suffixes=['','_stdRank'] , how = 'left' , on=['matchId','groupId'])\n    del stdData\n    del stdDataRank\n    gc.collect()\n\n    maxData = test.groupby(['matchId','groupId'])[features].agg('std').replace([np.inf, np.NINF,np.nan], 0)\n    maxDataRank = reduce_mem_usage(maxData.groupby('matchId')[features].rank(pct=True)).reset_index()\n    test = pd.merge(test , maxDataRank , suffixes=['','_maxRank'] , how = 'left' , on=['matchId','groupId'])\n    del maxData\n    del maxDataRank\n    gc.collect()\n    \n    \n    return test\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test_set_modify(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_test = test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(columns=['Id','groupId' , 'matchId'])\ntest = np.array(test)\nprint('Predicting Start : ', time.ctime())\ny_pred=model.predict(test, num_iteration=model.best_iteration)\nprint('Prediction end : ', time.ctime())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So I don't understand till now why it is  using the the next steps "},{"metadata":{},"cell_type":"markdown","source":"So we are creating a new smaller DataFrame to extract the data..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.DataFrame()\ndf_test = pd.read_csv('../input/test_V2.csv')\ndf_test = reduce_mem_usage(df_test)\ndf_sub['Id'] = df_test['Id']\ndf_sub['winPlacePerc'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Right now we have 3 features in dataFrame\nAdding more\nWe Created a new dataframe with groupId and matchId to find a Rank of With each Id and we "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\ndf_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\ndf_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n# we Find the max_rank for a group in match\ndf_sub_group = df_sub_group.merge(df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(),on=\"matchId\", how=\"left\")\n\ndf_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\ndf_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n# so we find the rank of each player in match \n# So this is whole process is to find that we find the rank of player in match as\n# The predications can be conflicting and this process will remove rank  anomally\n\ndf_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.sample(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\ndf_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\nsubset = df_sub.loc[df_sub.maxPlace > 1]\ngap = 1.0 / (subset.maxPlace.values - 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_perc = np.around(subset.winPlacePerc.values / gap) * gap\ndf_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n# Edge case\ndf_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\nassert df_sub[\"winPlacePerc\"].isnull().sum() == 0\n\ndf_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission_2.csv\", index=False)\nprint(df_sub['winPlacePerc'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}