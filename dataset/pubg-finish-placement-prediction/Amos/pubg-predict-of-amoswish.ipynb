{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras import Sequential\nfrom keras.layers import Dense, Dropout, Input# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nimport seaborn as sns\nfrom scipy import stats\nfrom pylab import mpl\nmpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\nmpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n%matplotlib inline\nsns.set_style('darkgrid')\nsns.set_palette('bone')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"003f0a801f1dfbf6f19a980d2f60defba386453b"},"cell_type":"code","source":"f1=open('../input/train_V2.csv')\nf2=open('../input/test_V2.csv')\ndf_train=pd.read_csv(f1)\ndf_test=pd.read_csv(f2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cdb4cd960a53a934147f306a873885b36895672"},"cell_type":"code","source":"#删除空值\ndf_train.dropna(inplace=True)\ndf_test.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccaf5587d16c8c879902e863aa667d8221766b69"},"cell_type":"markdown","source":"# feature engineering"},{"metadata":{"trusted":true,"_uuid":"a959d7096699192f33ccf46735fdf3ee4a32122b"},"cell_type":"code","source":"# all_data = train.append(test, sort=False).reset_index(drop=True)\n# del df_tatrain, test\n# gc.collect()\nall_data = df_train\nall_data1 = df_test\nall_data1['winPlacePerc'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bae2a4fdbf6cb682ef739a43e33cfbb1538f581"},"cell_type":"code","source":"match = all_data.groupby('matchId')\nall_data['killPlacePerc'] = match['kills'].rank(pct=True).values\nall_data['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"967860c79de226a1c0e6389bc40b177838cede17"},"cell_type":"code","source":"match1 = all_data1.groupby('matchId')\nall_data1['killPlacePerc'] = match1['kills'].rank(pct=True).values\nall_data1['walkDistancePerc'] = match1['walkDistance'].rank(pct=True).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0aefd3ff588d4fd31269388308fcb7a7cddf30c"},"cell_type":"code","source":"all_data['_totalDistance'] = all_data['rideDistance'] + all_data['walkDistance'] + all_data['swimDistance']\nall_data1['_totalDistance'] = all_data1['rideDistance'] + all_data1['walkDistance'] + all_data1['swimDistance']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19203d13d4f14cc185ff56a853c3191a2930fade"},"cell_type":"code","source":"all_data['zombi'] = ((all_data['_totalDistance'] == 0) | (all_data['kills'] == 0)\n                     | (all_data['weaponsAcquired'] == 0) \n                     | (all_data['matchType'].str.contains('solo'))).astype(int)\nall_data['cheater'] = ((all_data['kills'] / all_data['_totalDistance'] >= 1)\n                       | (all_data['kills'] > 30) | (all_data['roadKills'] > 10)).astype(int)\npd.concat([all_data['zombi'].value_counts(), all_data['cheater'].value_counts()], axis=1).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3f3120f2a63ff65b2d535924a9d3f76208e9676"},"cell_type":"code","source":"all_data1['zombi'] = ((all_data1['_totalDistance'] == 0) | (all_data1['kills'] == 0)\n                     | (all_data1['weaponsAcquired'] == 0) \n                     | (all_data1['matchType'].str.contains('solo'))).astype(int)\nall_data1['cheater'] = ((all_data1['kills'] / all_data1['_totalDistance'] >= 1)\n                       | (all_data1['kills'] > 30) | (all_data1['roadKills'] > 10)).astype(int)\npd.concat([all_data1['zombi'].value_counts(), all_data1['cheater'].value_counts()], axis=1).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a43ea768eccf54a0c3383db9077b2c7df34ffe9"},"cell_type":"code","source":"def fillInf(df, val):#删除inf值\n    numcols = df.select_dtypes(include='number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols: df[c].fillna(val, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"918e979619b733d9905342b338da299932839757"},"cell_type":"code","source":"all_data['_healthAndBoosts'] = all_data['heals'] + all_data['boosts']\nall_data['_killDamage'] = all_data['kills'] * 100 + all_data['damageDealt']\n#all_data['_headshotKillRate'] = all_data['headshotKills'] / all_data['kills']\nall_data['_killPlaceOverMaxPlace'] = all_data['killPlace'] / all_data['maxPlace']\nall_data['_killsOverWalkDistance'] = all_data['kills'] / all_data['walkDistance']\n#all_data['_killsOverDistance'] = all_data['kills'] / all_data['_totalDistance']\nall_data['_walkDistancePerSec'] = all_data['walkDistance'] / all_data['matchDuration']\n\n# suicide: solo and teamKills > 0\n#all_data['_suicide'] = ((all_data['players'] == 1) & (all_data['teamKills'] > 0)).astype(int)\n\nfillInf(all_data, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61d852cd1018f419604e24680075f87a66930999"},"cell_type":"code","source":"all_data1['_healthAndBoosts'] = all_data1['heals'] + all_data1['boosts']\nall_data1['_killDamage'] = all_data1['kills'] * 100 + all_data1['damageDealt']\n#all_data['_headshotKillRate'] = all_data['headshotKills'] / all_data['kills']\nall_data1['_killPlaceOverMaxPlace'] = all_data1['killPlace'] / all_data1['maxPlace']\nall_data1['_killsOverWalkDistance'] = all_data1['kills'] / all_data1['walkDistance']\n#all_data['_killsOverDistance'] = all_data['kills'] / all_data['_totalDistance']\nall_data1['_walkDistancePerSec'] = all_data1['walkDistance'] / all_data1['matchDuration']\n\n# suicide: solo and teamKills > 0\n#all_data['_suicide'] = ((all_data['players'] == 1) & (all_data['teamKills'] > 0)).astype(int)\n\nfillInf(all_data1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"843b777e59eca867f736216c2275a27fe39d5705"},"cell_type":"code","source":"all_data.drop(['headshotKills','teamKills','roadKills','vehicleDestroys'], axis=1, inplace=True)\nall_data.drop(['rideDistance','swimDistance','matchDuration'], axis=1, inplace=True)\nall_data.drop(['rankPoints','killPoints','winPoints'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df0102c4fca4d015ba87fd5363fa8b569953a0ab"},"cell_type":"code","source":"all_data1.drop(['headshotKills','teamKills','roadKills','vehicleDestroys'], axis=1, inplace=True)\nall_data1.drop(['rideDistance','swimDistance','matchDuration'], axis=1, inplace=True)\nall_data1.drop(['rankPoints','killPoints','winPoints'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"472525a20b01dd5cfb14722db3698e5a33e8f569"},"cell_type":"code","source":"all_data.drop(['Id','groupId','matchId'], axis=1, inplace=True)\nall_data1.drop(['Id','groupId','matchId'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ede1e3788c3a6a28543be0b9f817f3017bc0105"},"cell_type":"code","source":"mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\n#mapper = lambda x: 'solo' if ('solo' in x) else 'team'\nall_data['matchType'] = all_data['matchType'].map(mapper)\nall_data1['matchType'] = all_data['matchType'].map(mapper)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de767413c07f6d2bf22627843ae01b2deeac8ef9"},"cell_type":"code","source":"# 设置哑变量\na = pd.get_dummies(all_data['matchType'],prefix='matchType')\nall_data = pd.concat([all_data,a],axis=1)\nall_data1 = pd.concat([all_data1,a],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a7fcf3695cf4a553869f3e18c0cbfd058cf98c1"},"cell_type":"code","source":"all_data.drop(['matchType'], axis=1, inplace=True)\nall_data1.drop(['matchType'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ded537b23d2ee3742d68f5deb2b172618762ea5f"},"cell_type":"code","source":"train_y = all_data['winPlacePerc']#吃鸡概率\nall_data.drop(['winPlacePerc'], axis=1, inplace=True)\ntrain_x = all_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82c7c7da6097c31ea3be81a5cb4404f16f55d9ab"},"cell_type":"code","source":"predict = all_data1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a06f4a40babae3e404f4fa80d33fa04073b2c43"},"cell_type":"code","source":"from sklearn import preprocessing\nfor item in list(train_x.columns):\n#     all_data1[item].apply(preprocessing.scale,axis = 0)\n#     all_data1[item] = preprocessing.scale(all_data1[item])\n    train_x[item] = np.log1p(train_x[item])\n    predict[item] = np.log1p(predict[item])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f43ac9fc2b7707b6a0c83d5c8b0679cb5bae348"},"cell_type":"code","source":"predict.drop(['winPlacePerc'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1309f78f2cfb1300a5a1be1830ce6f6a8f6b476a"},"cell_type":"code","source":"#删除空值\npredict.dropna(inplace=True)\ntrain_x.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de3bb157813050df9d96a7f26877b3f1e491bb04"},"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef0dbf1280d0dfca6408c6fb7896bb2925b1c535"},"cell_type":"code","source":"print (X_train.shape)\nprint (y_train.shape)\nprint (X_test.shape)\nprint (y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0555735ef06b4dfb61498f8967ef3a422dfc5394"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c49b63576211d5912859e2f82d1cfe4b927d3750"},"cell_type":"code","source":"print (linreg.intercept_)\nprint (linreg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"315360ca0b933c9e2d1a962dd90f2e993cb97d96"},"cell_type":"code","source":"y_pred = linreg.predict(X_test)\nfrom sklearn import metrics\n# 用scikit-learn计算MSE\nprint (\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n# 用scikit-learn计算RMSE\nprint (\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81e07988612dd13de2a1823b8851a08dd13d9a3c"},"cell_type":"code","source":"#十折交叉验证\ny = train_y#吃鸡概率\nx = train_x\nfrom sklearn.model_selection import cross_val_predict\npredicted = cross_val_predict(linreg, x, y, cv=10)\n# 用scikit-learn计算MSE\nprint (\"MSE:\",metrics.mean_squared_error(y, predicted))\n# 用scikit-learn计算RMSE\nprint (\"RMSE:\",np.sqrt(metrics.mean_squared_error(y, predicted)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a33f9ddc609000ea21ae6b51c481f79ababd9d21"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(y, predicted)\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd05f4a8bb3e4ffa710b540f2b6be4361f0d43d4"},"cell_type":"code","source":"result = linreg.predict(predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fbffee7f3e993522549449e97121c6c3b5e2054"},"cell_type":"code","source":"f3=open('../input/sample_submission_V2.csv')\nsubmit=pd.read_csv(f3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2b416d35a8cde3c5f5f42deff0652fab665a178"},"cell_type":"code","source":"sample_result = pd.DataFrame(result,columns = ['winPlacePerc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39dd1239d02bdce4afc1dc3c127493bab785e2ef"},"cell_type":"code","source":"submit['winPlacePerc'] = sample_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2949f9daeafae316db2fa6e70a633fcc6478bc4f"},"cell_type":"code","source":"submit.to_csv(r'sample_submission_lineregression.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1860011403362afd75883c52c784e96cc8bac2ed"},"cell_type":"markdown","source":"# lasso 回归"},{"metadata":{"trusted":true,"_uuid":"353a04e9ea6a8dbaa2949ec8b878908701ddafb7"},"cell_type":"code","source":"from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV   # Lasso回归,LassoCV交叉验证实现alpha的选取，LassoLarsCV基于最小角回归交叉验证实现alpha的选取\n# ========Lasso回归========\n# model = Lasso(alpha=0.01)  # 调节alpha可以实现对拟合的程度\n# model = LassoCV()  # LassoCV自动调节alpha可以实现选择最佳的alpha。\nalpha = np.logspace(-3,2,10)\nmodel = LassoCV(alphas=alpha,cv=5)  # LassoLarsCV自动调节alpha可以实现选择最佳的alpha\nmodel.fit(X_train, y_train)   # 线性回归建模\nprint('系数矩阵:\\n',model.coef_)\nprint('线性回归模型:\\n',model)\nprint('最佳的alpha：',model.alpha_)  # 只有在使用LassoCV、LassoLarsCV时才有效\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d01d6dcb1db5ffe5ee3ecef2cb01445dde3b6f0"},"cell_type":"code","source":"# 使用模型预测\npredicted_lasso = model.predict(predict)\n# 存储文件\nf4=open('../input/sample_submission_V2.csv')\nsubmit_lasso=pd.read_csv(f4)\nsample_result_lasso = pd.DataFrame(predicted_lasso,columns = ['winPlacePerc'])\nsubmit_lasso['winPlacePerc'] = sample_result_lasso\nsubmit_lasso.to_csv(r'sample_submission_lasso.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"403531273037d4baf7340edb4651d5c702a06b5c"},"cell_type":"markdown","source":"# Ridge回归"},{"metadata":{"trusted":true,"_uuid":"c1c1a85279dfa077aa3fffa29c27d47ee809b08e"},"cell_type":"code","source":"from sklearn.linear_model import RidgeCV,LassoCV#用这个自带交叉验证参数\nfrom sklearn.model_selection import GridSearchCV#如果使用RidgeCV就不用GridSearchCV这个API了\n#使用RidgeCV来建立参数\nalpha = np.logspace(-3,2,10)#生成超参数，10的-3次方到10的2次方的等差数列\nridge = RidgeCV(alpha,cv=5)\nridge.fit(X_train,y_train)\nridge.alpha_#输出超参数的值\n#使用Ridge配合GridSearchCV来做\nfrom sklearn.linear_model import Ridge,Lasso\nridge_model = GridSearchCV(Ridge(),param_grid={'alpha':alpha},cv=5)\nridge_model.fit(X_train,y_train)\nridge_model.best_params_#验证模型效果","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa726f838a3380ee1d4380e2960c442fee0efdc1"},"cell_type":"code","source":"# 使用模型预测\npredicted_ridge = ridge_model.predict(predict)\n# 存储文件\nf4=open('../input/sample_submission_V2.csv')\nsubmit_ridge=pd.read_csv(f4)\nsample_result_ridge = pd.DataFrame(predicted_ridge,columns = ['winPlacePerc'])\nsubmit_ridge['winPlacePerc'] = sample_result_ridge\nsubmit_ridge.to_csv(r'sample_submission_ridge.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04bc1c2fc6a656a8982e4f1a42287f2e7e77d74c"},"cell_type":"markdown","source":"# ElasticNet"},{"metadata":{"trusted":true,"_uuid":"bed336862536821415151aa98cd574aa87b7874d"},"cell_type":"code","source":"from sklearn.linear_model import ElasticNetCV#用这个自带交叉验证参数\nfrom sklearn.model_selection import GridSearchCV#如果使用RidgeCV就不用GridSearchCV这个API了\n#ElasticNetCV\nalpha = np.logspace(-3,2,10)#生成超参数，10的-3次方到10的2次方的等差数列\nelasticNet = ElasticNetCV(alpha,cv=10)\nelasticNet.fit(X_train,y_train)\nelasticNet.alpha_#输出超参数的值\n#使用Ridge配合GridSearchCV来做\nfrom sklearn.linear_model import ElasticNet\nelasticNet_model = GridSearchCV(ElasticNet(),param_grid={'alpha':alpha},cv=10)\nelasticNet_model.fit(X_train,y_train)\nelasticNet_model.best_params_#验证模型效果","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5ece2d2a76cce6a634e2ce45c992a236a9ce5af"},"cell_type":"code","source":"# 使用模型预测\npredicted_elasticNet = elasticNet_model.predict(predict)\n# 存储文件\nf4=open('../input/sample_submission_V2.csv')\nsubmit_elasticNet=pd.read_csv(f4)\nsample_result_elasticNet = pd.DataFrame(predicted_elasticNet,columns = ['winPlacePerc'])\nsubmit_elasticNet['winPlacePerc'] = sample_result_elasticNet\nsubmit_elasticNet.to_csv(r'sample_submission_elasticNet.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad411d0ab1cc90f81994cbd6aada2d657911a1cf"},"cell_type":"markdown","source":"# xgboost"},{"metadata":{"trusted":true,"_uuid":"8151c5426449dccba2e5e366a1a5140dc3f91be1"},"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff9fc89d7592ddab469103f0017b63799b9459f3"},"cell_type":"code","source":"#定义一个函数帮助产生xgboost模型及其效果\ndef modelfit(alg, dtrain,result, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=result.values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n        alg.set_params(n_estimators=cvresult.shape[0])\n\n    #Fit the algorithm on the data\n    alg.fit(dtrain[predictors], result,eval_metric='auc')\n\n    #Predict training set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n\n    #Print model report:\n    print (\"\\nModel Report\")\n    print (\"Accuracy : %.4g\" % metrics.accuracy_score(result.values, dtrain_predictions))\n    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(result, dtrain_predprob))\n\n    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n    feat_imp.plot(kind='bar', title='Feature Importances')\n    plt.ylabel('Feature Importance Score')\n\n#xgboost’s sklearn没有feature_importances，但是#get_fscore() 有相同的功能","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d9a423963be95a1cc7114e8c01a08cc1618acda"},"cell_type":"code","source":"#通过固定的学习率0.1和cv选择合适的树的数量\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import  metrics   #Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n#Choose all predictors except target & IDcols\npredictors = [x for x in X_train.columns ]\nxgb1 = XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'reg:linear',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\nmodelfit(xgb1, X_train, y_train,predictors)\n#作者调整后得到的树的值为140，如果这个值对于当前的系统而言太大了，可以调高学习率重新训练","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33608bacd48e95b4a891f255312e3d1b9a5eb028"},"cell_type":"code","source":"import xgboost as xgb\nimport sklearn\nfrom sklearn.model_selection import GridSearchCV#如果使用RidgeCV就不用GridSearchCV这个API了\nfrom sklearn.model_selection import train_test_split\nX_dtrain, X_deval, y_dtrain, y_deval = train_test_split(train_x, train_y, random_state=1026, test_size=0.3)\ncv_params = {'n_estimators': [400, 500, 600, 700, 800]}\n# cv_params = {'n_estimators': [400]}\nother_params = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 1, 'seed': 2019,\n                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n\nmodel_xgb = xgb.XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model_xgb, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_dtrain, y_dtrain)\nevalute_result = optimized_GBM.grid_scores_\nprint('每轮迭代运行结果:{0}'.format(evalute_result))\nprint('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\nprint('最佳模型得分:{0}'.format(optimized_GBM.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7647cfbaf35cc0297cca31abae8bbcc6c35bb84b"},"cell_type":"markdown","source":"# lightGBM"},{"metadata":{"trusted":true,"_uuid":"0906639826ecc8e1702c3ea76bf75746f1a40f77"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport sklearn.metrics\nfrom sklearn.model_selection import GridSearchCV\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nX_train, X_holdout, y_train, y_holdout =  train_test_split(train_x, train_y, random_state= 666,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8e38d4b4156380659f2197471efcdda8cf103c1"},"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nlgtrain = lgb.Dataset(X_train, label=y_train.reset_index(drop=True))\nres = lgb.cv({'metric': 'mae'},lgtrain, nfold=5,stratified=False,seed=666)\nprint(\"Mean score:\",res['l1-mean'][-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f727b86901870fb0375cdb4a55d3d901c3df15bc"},"cell_type":"code","source":"gridParams = {\n    'num_leaves': [30,50,100], 'max_depth': [-1,8,15], \n    'min_data_in_leaf': [100,300,500], 'max_bin': [250,500], \n    'lambda_l1': [0.01], 'num_iterations': [5], \n    'nthread': [4], 'seed': [666],\n    'learning_rate': [0.05], 'metric': ['mae'],\n    \"bagging_fraction\" : [0.7], \"bagging_seed\" : [0], \"colsample_bytree\" : [0.7]\n    }\nmodel = lgb.LGBMRegressor()\ngrid = GridSearchCV(model, gridParams,\n                    verbose=1,\n                    cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44c9a806ec43def92e216f70f57293b8a6fa916e"},"cell_type":"code","source":"%%time\ngrid.fit(X_train.iloc[:500000,:], y_train.iloc[:500000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0e6a7212c5abee0cbe3e1de74d84636b02aeaab"},"cell_type":"code","source":"print(\"Best params:\", grid.best_params_)\nprint(\"\\nBest score:\", grid.best_score_)\nparams = grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b2bb1aa2d07bd9e9751071d6f4d95d79cb28914"},"cell_type":"code","source":"from sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import learning_curve\nmodel = lgb.LGBMRegressor(learning_rate=0.05,nthread=4)\n\ndef plot_with_err(x, data, **kwargs):\n    mu, std = data.mean(1), data.std(1)\n    lines = plt.plot(x, mu, '-', **kwargs)\n    plt.fill_between(x, mu - std, mu + std, edgecolor='none',\n    facecolor=lines[0].get_color(), alpha=0.2)\n    \ndef plot_learning_curve():\n    train_sizes = [1000,5000,10000,50000,100000,500000]\n    N_train, val_train, val_test = learning_curve(model,\n    X_train, y_train, train_sizes=train_sizes, cv=5,\n    scoring='neg_mean_absolute_error')\n    plot_with_err(N_train, abs(val_train), label='training scores')\n    plot_with_err(N_train, abs(val_test), label='validation scores')\n    plt.xlabel('Training Set Size'); plt.ylabel('MAE')\n    plt.legend()\n\nplot_learning_curve()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32cf8dc8a90245b018b212a66931317211729184"},"cell_type":"code","source":"def iter_vs_score(num_iterations):\n    val_train, val_test = validation_curve(model, X_train[:500000], y_train[:500000],\n        'num_iterations', num_iterations, cv=4,scoring='neg_mean_absolute_error', verbose=1)\n    plot_with_err(num_iterations, abs(val_test), label='validation scores')\n    plot_with_err(num_iterations, abs(val_train), label='training scores')\n    plt.xlabel('Number of iterations'); plt.ylabel('MAE')\n    plt.legend();\n    plt.show();\n\nnum_iterations_small = [5,10,20,30,100,200]\niter_vs_score(num_iterations_small)\nnum_iterations_big = [500,1000,5000,10000]\niter_vs_score(num_iterations_big)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f4040f381926a61480377c1a4f7e8f0e66bf257"},"cell_type":"code","source":"num_iterations_big = [10000,12000,15000,20000]\niter_vs_score(num_iterations_big)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84c56917dc25205da802e4b238f01c9de37096bf"},"cell_type":"markdown","source":"# NN"},{"metadata":{"trusted":true,"_uuid":"8b778be4cb27768a652324e9237c58503160226e"},"cell_type":"code","source":"from keras import Sequential\nfrom keras.layers import Dense, Dropout, Input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43d4a0eb893a3d39590a78cc829fff6329d9f91b"},"cell_type":"code","source":"%%time\n# create NN_model\nNN_model = Sequential()\nNN_model.add(Dense(x_train.shape[1],  input_dim = x_train.shape[1], activation='relu'))\nNN_model.add(Dense(136, activation='relu'))\nNN_model.add(Dense(136, activation='relu'))\nNN_model.add(Dense(136, activation='relu'))\nNN_model.add(Dense(136, activation='relu'))\n\n# output Layer\nNN_model.add(Dense(1, activation='linear'))\n\n# Compile the network :\nNN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\nNN_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00fca1bcfd3923ae96c5696040a2e30f3534dd80"},"cell_type":"code","source":"checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9121b18c2a3202d89a544d991864f39f0d67e17"},"cell_type":"code","source":"%%time\nNN_model.fit(x=x_train, y=y, batch_size=1000,\n             epochs=30, verbose=1, callbacks=callbacks_list,\n             validation_split=0.15, validation_data=None, shuffle=True,\n             class_weight=None, sample_weight=None, initial_epoch=0,\n             steps_per_epoch=None, validation_steps=None)\ndel x_train, y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"234da251a81c2d644fbca2b65c178dfa01e1a1a5"},"cell_type":"code","source":"x_test, _ = feature_engineering(False)\nscaler.transform(x_test)\nprint(\"x_test\", x_test.shape, x_test.max(), x_test.min())\nnp.clip(x_test, out=x_test, a_min=-1, a_max=1)\nprint(\"x_test\", x_test.shape, x_test.max(), x_test.min())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}