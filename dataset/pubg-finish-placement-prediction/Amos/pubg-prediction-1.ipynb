{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f29164bdbc1d4260953e1353ee4e72ab63999732","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom scipy import stats\nfrom pylab import mpl\nmpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\nmpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n%matplotlib inline\nsns.set_style('darkgrid')\nsns.set_palette('bone')\nfrom tqdm import tqdm\nwarnings.filterwarnings('ignore')\nimport gc, sys\ngc.enable()\nINPUT_DIR = \"../input/\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"586167bfcc45cf915a2234c7b035b57314f36b7c"},"cell_type":"markdown","source":"feature engineering"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def fillInf(df, val):  # 删除inf值\n    numcols = df.select_dtypes(include='number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols: df[c].fillna(val, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"865bfa4a86b00feb24ef96ec2bcd150427040e0f","trusted":true},"cell_type":"code","source":"def feature_engineering(is_train=True):\n    if is_train: \n        print(\"processing train.csv\")\n        df = pd.read_csv(INPUT_DIR + 'train_V2.csv')\n\n        df = df[df['maxPlace'] > 1]\n    else:\n        print(\"processing test.csv\")\n        df = pd.read_csv(INPUT_DIR + 'test_V2.csv')\n    df.dropna(inplace=True)\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    match = df.groupby('matchId')\n    df['killPlacePerc'] = match['kills'].rank(pct=True).values\n    df['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values\n    \n    df['_totalDistance'] = df['rideDistance'] + df['walkDistance'] + df['swimDistance']\n    df['zombi'] = ((df['_totalDistance'] == 0) | (df['kills'] == 0)\n                     | (df['weaponsAcquired'] == 0)\n                     | (df['matchType'].str.contains('solo'))).astype(int)\n    df['cheater'] = ((df['kills'] / df['_totalDistance'] >= 1)\n                       | (df['kills'] > 30) | (df['roadKills'] > 10)).astype(int)\n    pd.concat([df['zombi'].value_counts(), df['cheater'].value_counts()], axis=1).T\n    df['_healthAndBoosts'] = df['heals'] + df['boosts']\n    df['_killDamage'] = df['kills'] * 100 + df['damageDealt']\n    # all_data['_headshotKillRate'] = all_data['headshotKills'] / all_data['kills']\n    df['_killPlaceOverMaxPlace'] = df['killPlace'] / df['maxPlace']\n    df['_killsOverWalkDistance'] = df['kills'] / df['walkDistance']\n    # all_data['_killsOverDistance'] = all_data['kills'] / all_data['_totalDistance']\n    df['_walkDistancePerSec'] = df['walkDistance'] / df['matchDuration']\n    # suicide: solo and teamKills > 0\n    # all_data['_suicide'] = ((all_data['players'] == 1) & (all_data['teamKills'] > 0)).astype(int)\n    fillInf(df, 0)\n    mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\n    # mapper = lambda x: 'solo' if ('solo' in x) else 'team'\n    df['matchType'] = df['matchType'].map(mapper)\n    df['matchType'] = df['matchType'].map(mapper)\n    # 设置哑变量\n    a = pd.get_dummies(df['matchType'], prefix='matchType')\n    df = pd.concat([df, a], axis=1)\n    df.drop(['headshotKills','teamKills','roadKills','vehicleDestroys'], axis=1, inplace=True)\n    df.drop(['rideDistance','swimDistance','matchDuration'], axis=1, inplace=True)\n    df.drop(['rankPoints','killPoints','winPoints'], axis=1, inplace=True)\n    df.drop(['matchType'], axis=1, inplace=True)\n    \n    print(\"remove some columns\")\n    target = 'winPlacePerc'\n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    \n    y = None\n    \n    print(\"get target\")\n    if is_train: \n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        features.remove(target)\n\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    else: df_out = df[['matchId','groupId']]\n\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    del agg, agg_rank\n    gc.collect()\n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    del agg, agg_rank\n    gc.collect()\n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    del agg, agg_rank\n    gc.collect()\n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n\n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    del agg\n    gc.collect()\n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    gc.collect()\n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n\n    X = np.array(df_out, dtype=np.float64)\n    \n    feature_names = list(df_out.columns)\n\n    del df, df_out, agg\n    gc.collect()\n    return X, y, feature_names","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29eadb85098d597b26bd17126874c0d62c17b6a3","trusted":true},"cell_type":"code","source":"# transform feature\nfrom sklearn.preprocessing import MinMaxScaler\nx_train, y, feature_names = feature_engineering(True)\nscaler = MinMaxScaler(feature_range=(-1, 1), copy=False).fit(x_train)\nscaler.transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5714c5ff472104b39e524d3f46b3caf751bd779","scrolled":true,"trusted":true},"cell_type":"code","source":"x_prediction, _, _ = feature_engineering(False)\nscaler = MinMaxScaler(feature_range=(-1, 1), copy=False).fit(x_prediction)\nscaler.transform(x_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit_elasticNet.to_csv(r'sample_submission_elasticNet.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test =train_test_split(x_train,y,test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64cce46ef78b17ea055c0e1c0e97bf08a97a69f0"},"cell_type":"markdown","source":"# linear regression"},{"metadata":{"_uuid":"500bf6e48b0f4d932d2c59413470fa6da60e8c30","trusted":false},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)\nprint (linreg.intercept_)\nprint (linreg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time\n# result_test = linreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from sklearn.metrics import mean_absolute_error\n# mean_absolute_error(y_test, result_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from sklearn.metrics import mean_squared_error\n# mean_squared_error(y_test, result_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bde520a2282cfb95bac0e6e8ece081c15731efe1","trusted":false},"cell_type":"code","source":"%%time\nresult = linreg.predict(x_prediction)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f785275613a471de2f2165dce60da6a8d5c560d1","trusted":false},"cell_type":"code","source":"%%time\ntest_data = pd.read_csv(INPUT_DIR+'test_V2.csv')\nprint(\"fix winPlacePerc\")\nfor i in range(len(test_data)):\n    winPlacePerc = result[i]\n    maxPlace = int(test_data.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    result[i] = winPlacePerc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fddc7abba0cb34dba0f890a0ff0c81edc986efa9","trusted":false},"cell_type":"code","source":"f3=open(INPUT_DIR+'sample_submission_V2.csv')\nsubmit=pd.read_csv(f3)\nsample_result = pd.DataFrame(result,columns = ['winPlacePerc'])\nsubmit['winPlacePerc'] = sample_result\nsubmit.to_csv(r'sample_submission_lineregression.csv', index=False)\ndel f3,result,submit\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b76a783520ef42ae9cf5cf2637b5ab422be91669"},"cell_type":"markdown","source":"# lasso Regerssion"},{"metadata":{"_uuid":"503c41371df23042253ea15c18b548fc261b5df6","trusted":false},"cell_type":"code","source":"# %%time\n# from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV   # Lasso回归,LassoCV交叉验证实现alpha的选取，LassoLarsCV基于最小角回归交叉验证实现alpha的选取\n# # ========Lasso回归========\n# # model = Lasso(alpha=0.01)  # 调节alpha可以实现对拟合的程度\n# # model = LassoCV()  # LassoCV自动调节alpha可以实现选择最佳的alpha。\n# alpha = np.logspace(-3,2,10)\n# model = LassoCV(alphas=alpha,cv=5)  # LassoLarsCV自动调节alpha可以实现选择最佳的alpha\n# model.fit(x_train, y)   # 线性回归建模\n# print('系数矩阵:\\n',model.coef_)\n# print('线性回归模型:\\n',model)\n# print('最佳的alpha：',model.alpha_)  # 只有在使用LassoCV、LassoLarsCV时才有效\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import Lasso,LassoCV,LassoLarsCV \nmodel_lasso = Lasso(alpha=0.001) \nmodel_lasso.fit(X_train, y_train)\nprint (model_lasso.intercept_)\nprint (model_lasso.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time\n# result_test_lasso = model_lasso.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from sklearn.metrics import mean_absolute_error\n# from sklearn.metrics import mean_squared_error\n# mean_absolute_error(y_test, result_test_lasso)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean_squared_error(y_test, result_test_lasso)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n# 使用模型预测\npredicted_lasso = model_lasso.predict(x_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntest_data = pd.read_csv(INPUT_DIR+'test_V2.csv')\nprint(\"fix winPlacePerc\")\nfor i in range(len(test_data)):\n    winPlacePerc = predicted_lasso[i]\n    maxPlace = int(test_data.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    predicted_lasso[i] = winPlacePerc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd81c5520b88fbe6a7aca1738f2e26bd18532a31","trusted":false},"cell_type":"code","source":"\n# 存储文件\nf4=open(INPUT_DIR+'sample_submission_V2.csv')\nsubmit_lasso=pd.read_csv(f4)\nsample_result_lasso = pd.DataFrame(predicted_lasso,columns = ['winPlacePerc'])\nsubmit_lasso['winPlacePerc'] = sample_result_lasso\nsubmit_lasso.to_csv(r'sample_submission_lasso.csv', index=False)\ndel f4,submit_lasso,sample_result_lasso\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49b6ee84df5d55a07bc84dbb51bd0c1f6ba210e8"},"cell_type":"markdown","source":"# Ridge回归"},{"metadata":{"_uuid":"7f91fa4cdac2e8f628440d363aa871c965f93749","trusted":false},"cell_type":"code","source":"# from sklearn.linear_model import RidgeCV,LassoCV#用这个自带交叉验证参数\n# from sklearn.model_selection import GridSearchCV#如果使用RidgeCV就不用GridSearchCV这个API了\n# #使用RidgeCV来建立参数\n# alpha = np.logspace(-3,2,10)#生成超参数，10的-3次方到10的2次方的等差数列\n# ridge_model = RidgeCV(alpha,cv=5)\n# ridge_model.fit(x_train,y)\n# ridge_model.alphas #输出超参数的值","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# ridge_model.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import Ridge\nmodel_ridge = Ridge(alpha=0.5994842503189409) \nmodel_ridge.fit(X_train, y_train)\nprint (model_ridge.intercept_)\nprint (model_ridge.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time\n# result_test_ridge = model_ridge.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean_absolute_error(y_test, result_test_ridge)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean_squared_error(y_test, result_test_ridge)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n# 使用模型预测\npredicted_ridge = model_ridge.predict(x_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntest_data = pd.read_csv(INPUT_DIR+'test_V2.csv')\nprint(\"fix winPlacePerc\")\nfor i in range(len(test_data)):\n    winPlacePerc = predicted_ridge[i]\n    maxPlace = int(test_data.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    predicted_ridge[i] = winPlacePerc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99eff5e353a7f15a526f798c3ce6d34bb9376e1a","trusted":false},"cell_type":"code","source":"# 存储文件\nf5=open(INPUT_DIR+'sample_submission_V2.csv')\nsubmit_ridge=pd.read_csv(f5)\nsample_result_ridge = pd.DataFrame(predicted_ridge,columns = ['winPlacePerc'])\nsubmit_ridge['winPlacePerc'] = sample_result_ridge\nsubmit_ridge.to_csv(r'sample_submission_ridge.csv', index=False)\ndel f5,submit_ridge,sample_result_ridge\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cafc15aab2e41e20ee10ee9ee31c9d8d576dc329"},"cell_type":"markdown","source":"# ElasticNet"},{"metadata":{"_uuid":"e534d907567692345ba415bc3c4bbf1cb544613e","trusted":false},"cell_type":"code","source":"# from sklearn.linear_model import ElasticNetCV#用这个自带交叉验证参数\n# from sklearn.model_selection import GridSearchCV#如果使用RidgeCV就不用GridSearchCV这个API了\n# #ElasticNetCV\n# alpha = np.logspace(-3,2,10)#生成超参数，10的-3次方到10的2次方的等差数列\n# elasticNet_model = ElasticNetCV(alpha,cv=10)\n# elasticNet_model.fit(x_train,y)\n# elasticNet_model.alpha_#输出超参数的值","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nfrom sklearn.linear_model import ElasticNet\nmodel_elasticnet = ElasticNet(alpha=1.6152516038498196e-06, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n      max_iter=1000, normalize=False, positive=False, precompute=False,\n      random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\nmodel_elasticnet.fit(X_train, y_train)\nprint (model_elasticnet.intercept_)\nprint (model_elasticnet.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# %%time\n# result_test_elasticnet = model_elasticnet.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean_absolute_error(y_test, result_test_elasticnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean_squared_error(y_test, result_test_elasticnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n# 使用模型预测\npredicted_elasticNet = model_elasticnet.predict(x_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntest_data = pd.read_csv(INPUT_DIR+'test_V2.csv')\nprint(\"fix winPlacePerc\")\nfor i in range(len(test_data)):\n    winPlacePerc = predicted_elasticNet[i]\n    maxPlace = int(test_data.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    predicted_elasticNet[i] = winPlacePerc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39ac4390d42d8e558f13e0bd51dc5707a8aa7825","trusted":true},"cell_type":"code","source":"# 存储文件\nf6=open(INPUT_DIR+'sample_submission_V2.csv')\nsubmit_elasticNet=pd.read_csv(f6)\nsample_result_elasticNet = pd.DataFrame(predicted_elasticNet,columns = ['winPlacePerc'])\nsubmit_elasticNet['winPlacePerc'] = sample_result_elasticNet\nsubmit_elasticNet.to_csv(r'sample_submission_elasticNet.csv', index=False)\ndel f6,submit_elasticNet,sample_result_elasticNet\ngc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}