{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport csv\nimport math\nimport keras\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras import optimizers\nfrom sklearn import preprocessing\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.callbacks import EarlyStopping\nimport lightgbm as lgb\nimport gc, sys\ngc.enable()\n\ndtypes = {\n\t\t'assists'           : 'uint8',\n\t\t'boosts'            : 'uint8',\n\t\t'damageDealt'       : 'float16',\n\t\t'DBNOs'             : 'uint8',\n\t\t'headshotKills'     : 'uint8', \n\t\t'heals'             : 'uint8',    \n\t\t'killPlace'         : 'uint8',    \n\t\t'killPoints'        : 'uint8',    \n\t\t'kills'             : 'uint8',    \n\t\t'killStreaks'       : 'uint8',    \n\t\t'longestKill'       : 'float16',    \n\t\t'maxPlace'          : 'uint8',    \n\t\t'numGroups'         : 'uint8',    \n\t\t'revives'           : 'uint8',    \n\t\t'rideDistance'      : 'float16',    \n\t\t'roadKills'         : 'uint8',    \n\t\t'swimDistance'      : 'float16',    \n\t\t'teamKills'         : 'uint8',    \n\t\t'vehicleDestroys'   : 'uint8',    \n\t\t'walkDistance'      : 'float16',    \n\t\t'weaponsAcquired'   : 'uint8',    \n\t\t'winPoints'         : 'uint8', \n\t\t'winPlacePerc'      : 'float16' \n}\n\ndef feature_engineering(filename,train = False):\n\tdata = pd.read_csv(filename,dtype=dtypes)\n\tdata = data[data['maxPlace'] > 1]\n\tdata['headshotrate'] = data['kills']/data['headshotKills']\n\tdata['killStreakrate'] = data['killStreaks']/data['kills']\n\tdata['healthitems'] = data['heals'] + data['boosts']\n\tdata['totalDistance'] = data['rideDistance'] + data[\"walkDistance\"] + data[\"swimDistance\"]\n\tdata['killPlace_over_maxPlace'] = data['killPlace'] / data['maxPlace']\n\tdata['headshotKills_over_kills'] = data['headshotKills'] / data['kills']\n\tdata['distance_over_weapons'] = data['totalDistance'] / data['weaponsAcquired']\n\tdata['walkDistance_over_heals'] = data['walkDistance'] / data['heals']\n\tdata['walkDistance_over_kills'] = data['walkDistance'] / data['kills']\n\tdata['killsPerWalkDistance'] = data['kills'] / data['walkDistance']\n\tdata[\"skill\"] = data[\"headshotKills\"] + data[\"roadKills\"] \n\tdata[data == np.Inf] = np.NaN\n\tdata[data == np.NINF] = np.NaN\n\n\tdata.fillna(0, inplace=True)\n\tfeature = list(data.columns)\n\tfeature.remove('Id')\n\tfeature.remove('groupId')\n\tfeature.remove('matchId')\n\tfeature.remove('matchType')\n\tif(train):\n\t\tlabels = np.array(data.groupby(['matchId','groupId'])['winPlacePerc'].agg('mean'), dtype=np.float64)\n\t\tfeature.remove('winPlacePerc')\n\telse: \n\t\tlabels = data[['Id']]\n\t\n\tprint(\"group_max\")\n\tagg = data.groupby(['matchId','groupId'])[feature].agg('max')\n\tagg_rank = agg.groupby('matchId')[feature].rank(pct=True).reset_index()\n\tif train: data_out = agg.reset_index()[['matchId','groupId']]\n\telse: data_out = data[['matchId','groupId']]\n\tdata_out = data_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId','groupId'])\n\tdata_out = data_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId','groupId'])\n\t\n\tprint(\"group_mean\")\n\tagg = data.groupby(['matchId','groupId'])[feature].agg('mean')\n\tagg_rank = agg.groupby('matchId')[feature].rank(pct=True).reset_index()\n\tdata_out = data_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId','groupId'])\n\tdata_out = data_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId','groupId'])\n\t\n\tprint(\"group_min\")\n\tagg = data.groupby(['matchId','groupId'])[feature].agg('min')\n\tagg_rank = agg.groupby('matchId')[feature].rank(pct=True).reset_index()\n\tdata_out = data_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId','groupId'])\n\tdata_out = data_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId','groupId'])\n\t\n\tprint(\"match_mean\")\n\tagg = data.groupby(['matchId'])[feature].agg('mean').reset_index()\n\tdata_out = data_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n\t\n\tprint(\"match_max\")\n\tagg = data.groupby(['matchId'])[feature].agg('max').reset_index()\n\tdata_out = data_out.merge(agg, suffixes=[\"\", \"_match_max\"], how='left', on=['matchId'])\n\t\n\tprint(\"match_size\")\n\tagg = data.groupby(['matchId']).size().reset_index(name='match_size')\n\tdata_out = data_out.merge(agg, how='left', on=['matchId'])\n\t\n\n\tdel data,agg,agg_rank\n\tgc.collect()\n\tdata_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n\n\tdata_out = reduce_size(data_out)\n\tX = data_out\n\tdel data_out, feature\n\tgc.collect()\n\treturn X,labels\n\ndef reduce_size(merged_data_out):\n\tprint('      Starting size is %d Mb'%(sys.getsizeof(merged_data_out)/1024/1024))\n\tprint('      Columns: %d'%(merged_data_out.shape[1]))\n\tfeats = merged_data_out.columns[merged_data_out.dtypes == 'float64']\n\tfor feat in feats:\n\t\tmerged_data_out[feat] = merged_data_out[feat].astype('float32')\n\n\tfeats = merged_data_out.columns[merged_data_out.dtypes == 'int16']\n\tfor feat in feats:\n\t\tmm = np.abs(merged_data_out[feat]).max()\n\t\tif mm < 126:\n\t\t\tmerged_data_out[feat] = merged_data_out[feat].astype('int8')\n\n\tfeats = merged_data_out.columns[merged_data_out.dtypes == 'int32']\n\tfor feat in feats:\n\t\tmm = np.abs(merged_data_out[feat]).max()\n\t\tif mm < 126:\n\t\t\tmerged_data_out[feat] = merged_data_out[feat].astype('int8')\n\t\telif mm < 30000:\n\t\t\tmerged_data_out[feat] = merged_data_out[feat].astype('int16')\n\n\tfeats = merged_data_out.columns[merged_data_out.dtypes == 'int64']\n\tfor feat in feats:\n\t\tmm = np.abs(merged_data_out[feat]).max()\n\t\tif mm < 126:\n\t\t\tmerged_data_out[feat] = merged_data_out[feat].astype('int8')\n\t\telif mm < 30000:\n\t\t\tmerged_data_out[feat] = merged_data_out[feat].astype('int16')\n\t\telif mm < 2000000000:\n\t\t\tmerged_data_out[feat] = merged_data_out[feat].astype('int32')\n\tprint('      Ending size is %d Mb'%(sys.getsizeof(merged_data_out)/1024/1024))\n\treturn merged_data_out\n\n\n\nparams = {\n\t'objective': 'regression',\n\t'early_stopping_rounds':200,\n\t'n_estimators':20000,\n\t'metric': 'mae',\n\t\"bagging_seed\" : 0,\n\t'num_leaves': 31,\n\t'learning_rate': 0.05,\n\t'bagging_fraction': 0.9,\n\t\"num_threads\" : 4,\n\t\"colsample_bytree\" : 0.7\n}\n\nif __name__ == '__main__':\n\tbatch_size = 512\n\tnum_of_features  = 0\n\t#features = load_csv_data('../input/train_V2.csv')\n\t#test = load_csv_data('../input/test_V2.csv')\n\ttrainpath = '../input/pubg-finish-placement-prediction/train_V2.csv'\n\ttestpath = '../input/pubg-finish-placement-prediction/test_V2.csv'\n\tfeatures, labels = feature_engineering(trainpath,train = True)\n\tnum_of_features = features.shape[1]\n\t\n\tfilepath = \"best.h5\"\n\tsplit = int(len(labels)*0.8)\n\tlgb_train = lgb.Dataset(features[:split], labels[:split])\n\tlgb_val = lgb.Dataset(features[split:], labels[split:])\n\tdel features, labels\n\tgc.collect()\n\tgbm = lgb.train(params, lgb_train, verbose_eval=100,valid_sets=[lgb_train, lgb_val],early_stopping_rounds = 200)\n\tdel lgb_train,lgb_val\n\tgc.collect()\n\n\tfeatures_test, test = feature_engineering(testpath)\n\tpredict = gbm.predict(features_test,num_iteration=gbm.best_iteration)\n\tdel features_test\n\tgc.collect()\n\tpredict = predict.reshape(-1)\n\ttest['winPlacePerc'] = predict\n\n\n\tdf_test = pd.read_csv(testpath)\n\n\t# Restore some columns\n\ttest = test.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\n\n\t# Sort, rank, and assign adjusted ratio\n\tdf_sub_group = test.groupby([\"matchId\", \"groupId\"]).first().reset_index()\n\tdf_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n\tdf_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n\n\n\ttest = test.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n\ttest[\"winPlacePerc\"] = test[\"adjusted_perc\"]\n\n\t# Deal with edge cases\n\ttest.loc[test.maxPlace == 0, \"winPlacePerc\"] = 0\n\ttest.loc[test.maxPlace == 1, \"winPlacePerc\"] = 1\n\n\t# Align with maxPlace\n\t# Credit: https://www.kaggle.com/anycode/simple-nn-baseline-4\n\tsubset = test.loc[test.maxPlace > 1]\n\tgap = 1.0 / (subset.maxPlace.values - 1)\n\tnew_perc = np.around(subset.winPlacePerc.values / gap) * gap\n\ttest.loc[test.maxPlace > 1, \"winPlacePerc\"] = new_perc\n\n\t# Edge case\n\ttest.loc[(test.maxPlace > 1) & (test.numGroups == 1), \"winPlacePerc\"] = 0\n\tassert test[\"winPlacePerc\"].isnull().sum() == 0\n\n\ttest[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}