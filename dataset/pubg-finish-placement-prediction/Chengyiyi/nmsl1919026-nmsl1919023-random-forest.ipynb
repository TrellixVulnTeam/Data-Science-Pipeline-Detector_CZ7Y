{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this Kernel we will explore the pubg dataset , detect outliers and recognize imortant features，implement a random forest model and optimize it."},{"metadata":{},"cell_type":"markdown","source":"1. Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport gc\nimport os\nimport sys\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport lightgbm as lgb\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"\n# Import dataset\ndf_train = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\ndf_test = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n\n# Reduce memory use\ndf_train=reduce_mem_usage(df_train)\ndf_test=reduce_mem_usage(df_test)\n\n# Show some data\ndf_train.head()\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.Initial Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First five rows (From Head)\nprint('First 5 rows: ')\ndisplay(df_train.head())\n\n# Last five rows (To Tail)\nprint('Last 5 rows: ')\ndisplay(df_train.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Types, Data points, memory usage, etc.\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature descriptions (From Kaggle)\n\nDBNOs - Number of enemy players knocked.\nassists - Number of enemy players this player damaged that were killed by teammates.\nboosts - Number of boost items used.\ndamageDealt - Total damage dealt. Note: Self inflicted damage is subtracted.\nheadshotKills - Number of enemy players killed with headshots.\nheals - Number of healing items used.\nId - Player’s Id\nkillPlace - Ranking in match of number of enemy players killed.\nkillPoints - Kills-based external ranking of player. (Think of this as an Elo ranking where only kills matter.) If there is a value other than -1 in rankPoints, then any 0 in killPoints should be treated as a “None”.\nkillStreaks - Max number of enemy players killed in a short amount of time.\nkills - Number of enemy players killed.\nlongestKill - Longest distance between player and player killed at time of death. This may be misleading, as downing a player and driving away may lead to a large longestKill stat.\nmatchDuration - Duration of match in seconds.\nmatchId - ID to identify match. There are no matches that are in both the training and testing set.\nmatchType - String identifying the game mode that the data comes from. The standard modes are “solo”, “duo”, “squad”, “solo-fpp”, “duo-fpp”, and “squad-fpp”; other modes are from events or custom matches.\nrankPoints - Elo-like ranking of player. This ranking is inconsistent and is being deprecated in the API’s next version, so use with caution. Value of -1 takes place of “None”.\nrevives - Number of times this player revived teammates.\nrideDistance - Total distance traveled in vehicles measured in meters.\nroadKills - Number of kills while in a vehicle.\nswimDistance - Total distance traveled by swimming measured in meters.\nteamKills - Number of times this player killed a teammate.\nvehicleDestroys - Number of vehicles destroyed.\nwalkDistance - Total distance traveled on foot measured in meters.\nweaponsAcquired - Number of weapons picked up.\nwinPoints - Win-based external ranking of player. (Think of this as an Elo ranking where only winning matters.) If there is a value other than -1 in rankPoints, then any 0 in winPoints should be treated as a “None”.\ngroupId - ID to identify a group within a match. If the same group of players plays in different matches, they will have a different groupId each time.\nnumGroups - Number of groups we have data for in the match.\nmaxPlace - Worst placement we have data for in the match. This may not match with numGroups, as sometimes the data skips over placements.\nwinPlacePerc - The target of prediction. This is a percentile winning placement, where 1 corresponds to 1st place, and 0 corresponds to last place in the match. It is calculated off of maxPlace, not numGroups, so it is possible to have missing chunks in a match."},{"metadata":{},"cell_type":"markdown","source":"3.Clean the data"},{"metadata":{},"cell_type":"markdown","source":"3.2 illgal match\n\nFellow Kaggler 'averagemn' brought to our attention that there is one particular player with a 'winPlacePerc' of NaN. The case was that this match had only one player. We will delete this row from our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['winPlacePerc'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(2744604, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['winPlacePerc'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.Feature Engineering "},{"metadata":{},"cell_type":"markdown","source":"Exploratory Analysis - A Single Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_barplot(feature, df_train = df_train, figsize=(15,6), rot = 90, saveimg = False): \n    feat_train = df_train[feature].value_counts()\n    fig_feature, axis1, = plt.subplots(1,1,sharex=True, sharey = True, figsize = figsize)\n    sns.barplot(feat_train.index.values, feat_train.values, ax = axis1)\n    axis1.set_xticklabels(axis1.xaxis.get_majorticklabels(), rotation = rot)\n    axis1.set_title(feature + ' of training dataset')\n    axis1.set_ylabel('Counts')\n    plt.tight_layout()\n    if saveimg == True:\n        figname = feature + \".png\"\n        fig_feature.savefig(figname, dpi = 75)\n\nfeature_barplot('DBNOs') #DBNO\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_train.copy()\ndata.loc[data['kills'] > data['kills'].quantile(0.99)] = '8+'\nplt.figure(figsize=(15,10))\nsns.countplot(data['kills'].astype('str').sort_values())\nplt.title(\"Kill Count\",fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Analysis : Two Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"kills\", data=df_train, height=10, ratio=3, color=\"r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kills = df_train.copy()\n\nkills['killsCategories'] = pd.cut(kills['kills'], [-1, 0, 2, 5, 10, 60], labels=['0_kills','1-2_kills', '3-5_kills', '6-10_kills', '10+_kills'])\n\nplt.figure(figsize=(15,8))\nsns.boxplot(x=\"killsCategories\", y=\"winPlacePerc\", data=kills)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5.Preparation for Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get alldata for feature engineering\nall_data = df_train.append(df_test, sort=False).reset_index(drop=True)\n\n# Map the matchType\nall_data['matchType'] = all_data['matchType'].map({\n    'crashfpp':1,\n    'crashtpp':2,\n    'duo':3,\n    'duo-fpp':4,\n    'flarefpp':5,\n    'flaretpp':6,\n    'normal-duo':7,\n    'normal-duo-fpp':8,\n    'normal-solo':9,\n    'normal-solo-fpp':10,\n    'normal-squad':11,\n    'normal-squad-fpp':12,\n    'solo':13,\n    'solo-fpp':14,\n    'squad':15,\n    'squad-fpp':16\n    })\n\n# Normalize features\nall_data['playersJoined'] = all_data.groupby('matchId')['matchId'].transform('count')\nall_data['killsNorm'] = all_data['kills']*((100-all_data['playersJoined'])/100 + 1)\nall_data['damageDealtNorm'] = all_data['damageDealt']*((100-all_data['playersJoined'])/100 + 1)\nall_data['maxPlaceNorm'] = all_data['maxPlace']*((100-all_data['playersJoined'])/100 + 1)\nall_data['matchDurationNorm'] = all_data['matchDuration']*((100-all_data['playersJoined'])/100 + 1)\n\nall_data['healsandboosts'] = all_data['heals'] + all_data['boosts']\nall_data['totalDistance'] = all_data['rideDistance'] + all_data['walkDistance'] + all_data['swimDistance']\nall_data['killsWithoutMoving'] = ((all_data['kills'] > 0) & (all_data['totalDistance'] == 0))\n\nall_data=reduce_mem_usage(all_data)\n\n# Split the train and the test\ndf_train = all_data[all_data['winPlacePerc'].notnull()].reset_index(drop=True)\ndf_test = all_data[all_data['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis=1).reset_index(drop=True)\n\ntarget = 'winPlacePerc'\nfeatures = list(df_train.columns)\nfeatures.remove(\"Id\")\nfeatures.remove(\"matchId\")\nfeatures.remove(\"groupId\")\nfeatures.remove(\"matchType\")\n\ny_train = np.array(df_train[target])\nfeatures.remove(target)\nx_train = df_train[features]\n\nx_test = df_test[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First basic Random Forest Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the train and the validation set for the fitting\nrandom_seed=1\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.05, random_state=random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF = RandomForestRegressor(n_estimators=10, min_samples_leaf=3, max_features=0.5, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set metrics (MAE)\nMean Absolute Error (MAE) is the metric that is used for this competition. The scikit-learn library already programmed this metric for us so we don't have to implement it from scratch."},{"metadata":{"trusted":true},"cell_type":"code","source":"mae_train_RF = mean_absolute_error(RF.predict(x_train), y_train)\nmae_val_RF = mean_absolute_error(RF.predict(x_val), y_val)\nprint('mae train RF: ', mae_train_RF)\nprint('mae val RF: ', mae_val_RF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npred_test_RF = RF.predict(x_test)\ndf_test['winPlacePerc_RF'] = pred_test_RF\nsubmission = df_test[['Id', 'winPlacePerc_RF']]\nsubmission.to_csv('submission_RF.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}