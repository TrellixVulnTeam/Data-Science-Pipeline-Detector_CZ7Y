{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# **The PUBG CHALLENGE**"},{"metadata":{"trusted":true,"_uuid":"7c6f6a1dda56ea8275f3b9f9eb0bb57d9697c6c9"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n\n\n\ntrain_data_path = \"../input/train_V2.csv\"#getting the path of the file to be inputed and assigned it\ntrain_data = pd.read_csv(train_data_path)#now reading the csv file to continue the proceaa\ntrain_data.head()#to show the first 5 Columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5a788e30b3f55c348faedf22f45f197689fbd36"},"cell_type":"markdown","source":"#### Now looking into the head of the file we can see that the row 'Id', 'groupId' and 'matchId are features which doent affect the result.So we need to remove it from the test data to get better accuracy."},{"metadata":{"trusted":true,"_uuid":"662e8f12862975cf9ea429b25f2cb6631b8a759e"},"cell_type":"code","source":"unwanted_features = ['Id', 'groupId', 'matchId']#making a list of unwanted features\ntrain = train_data.drop(unwanted_features, axis=1)#dropping the unwanted features from the data\ntrain.head()#showing the new head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82ffe2535fbc655265b18c4317fffc627818bbf7"},"cell_type":"markdown","source":"#### After checking our new dataset we could understand we have an important feature 'matchType' but is in object form, which is a problem as models can't train object type files.So we use \"ONE HOT ENCODING\"."},{"metadata":{"trusted":true,"_uuid":"b02d1076dec999d350fb5268501728c03ae5fa31"},"cell_type":"code","source":"new_train = pd.get_dummies(train, columns=['matchType'], drop_first = True)#implementing one hot encoding on matchType and storing it on new train data\nnew_train.head()#displaying its head","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a61ac073039d26a862907b45319f736079844c"},"cell_type":"markdown","source":"#### Now that we have coverted every column of our data to int/float values  lets check wheater the dataset is clean / it contain any NaN values"},{"metadata":{"trusted":true,"_uuid":"84b72e9da4abfd19fae04bff1231b8a14dcf4736","scrolled":true},"cell_type":"code","source":"new_train.isnull().sum()#sum of number of NaN values in each column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17eed640b3e6f268cdaba1cd8587426236d361a5"},"cell_type":"code","source":"new_train.shape#check the number of rows and columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8deefa633a2d5bc3cc37478807795f077d7597df"},"cell_type":"markdown","source":"####  Only one column has missing value out of 4446966 colums.So I'm going to drop the one column. "},{"metadata":{"trusted":true,"_uuid":"c0706b986952f380d7a3843f67b3ce7a0ecfec1d"},"cell_type":"code","source":"new_train.dropna(inplace=True)#dropping all the columns with NaN values\nnew_train.shape#Now again checking the number of columns and rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7e9884e2f75f350a0cc4672937e72f191991952"},"cell_type":"code","source":"new_train.isnull().sum()#YaaaY......!Sum of NaN values became zero","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab31949c92d7ba8713229a8937e9560b8b1560a0"},"cell_type":"markdown","source":"# TRAINING\n### Now we have our clean dataset we can now start training our model.First step is to split tge data to X, y and train and test dat."},{"metadata":{"trusted":true,"_uuid":"7c1d837ed9d1d0a7f633fc03be5323d7c6479465"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n#Splitting my data into features and Label\nX = new_train.drop(['winPlacePerc'], axis=1)\ny = new_train.winPlacePerc\n\n#Splitting my features and label into train and test set so that I could check the accuracy and improve the model\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state= 1, test_size=0.4)\nprint(\"Done◇\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d230bff01a86d7c6415fd0ad5ec8b3ee3cf18f5"},"cell_type":"markdown","source":"#### Now its time to choose an algorithm"},{"metadata":{"trusted":true,"_uuid":"131af896e8a904b326cbb10427b2ac43c3d1e9fc"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom xgboost import XGBRegressor\n\n\n\nmodels = [ RandomForestRegressor , AdaBoostRegressor, XGBRegressor]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5756ffa0d27127249b5ca7a453ab457b750496a"},"cell_type":"markdown","source":"#### Now we should define a function that could give the mae of each models by itrating through each algorithm"},{"metadata":{"trusted":true,"_uuid":"8009bd8d4267d87169f90e160fc856c55e120dc3"},"cell_type":"code","source":"#def best_model(n):\n #   model = n()\n  #  model.fit(train_X, train_y)\n   # pred = model.predict(test_X)\n    #Error = mae(pred, test_y)\n    #return Error\n\n\n\n#for i in models:\n    #print(\"MAE of \", i, best_model(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90cd64deaec7c0210911d3aa72df9ae5f21768be"},"cell_type":"code","source":"test_data_path = \"../input/test_V2.csv\"\ntest_data = pd.read_csv(test_data_path)\ntest_data = test_data.drop(unwanted_features, axis=1)\ntest = pd.get_dummies(test_data, columns=[\"matchType\"], drop_first = True)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fa8fedb8384f44070d9f87232d3a20969e99dd4"},"cell_type":"code","source":"model = RandomForestRegressor()\nmodel.fit(X, y)\npred = model.predict(test)\nprint(\"Done♡\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f06bfb6878d7b2762e94b45e8eb428772b3cd85"},"cell_type":"code","source":"test_data_id = pd.read_csv(test_data_path)\noutput = pd.DataFrame({'Id' : test_data_id.Id , 'winPlacePerc' : pred})\noutput.to_csv(\"output.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a286431b04db849e88ec1a9265d18090ce30ef37"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"baee6520075a8b371773cfa43265d95f9228e305"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"452020d5e37a4e98ae8602ea921cfae305582b20"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8026989c5e37607a9888fed6aca7f340c624ea38"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"fa5aeaad1121e7db9599be61989deda8500658c8"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"9bfc5121669946d607132a2e77737f0046c3a4ac"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"b8b5e32adae79662efa3a5bd02e86ae4194995aa"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"cb1cc4675355f12b3c52d4ca65f64f403f23aa1f"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"457ee9d2630a95251ee359e8b8adcce3f9485838"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}