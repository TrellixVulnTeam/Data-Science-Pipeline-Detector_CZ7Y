{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PUBG: Battle Royal - Finish Placement Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required libraries for this project\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### The size of the PUBG dataset is pretty big for a lower/mid-range laptop so here's a script to make the dataset smaller without losing information.\n\n###### It uses the following approach:\n\n- Iterate over every column\n- Determine if the column is numeric\n- Determine if the column can be represented by an integer\n- Find the min and the max value\n- Determine and apply the smallest datatype that can fit the range of values\n- This reduces the dataset from approx. 900 MB to 466 MB"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading train and test file and reducing its memeory consumption\n#%%time\ntrain = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\ntrain = reduce_mem_usage(train)\ntest = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\ntest = reduce_mem_usage(test)\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at first five train data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at last five train data\ntrain.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at first five test data\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at last five test data\ntest.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To find the datatypes of the columns\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tasks to be performed:\n#### Part 1: Exploratory Data Analysis\n#### Part 2: Data Cleaning: Outlier Detection and Removal - Finding the fraudsters\n#### Part 3: Feature Engineering\n#### Part 4: Final Predition"},{"metadata":{},"cell_type":"markdown","source":"### Part 1: Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique count in column Id, groupId, matchId\nfor i in ['Id', 'groupId', 'matchId']:\n    print(\"Unique values in column '{}' is: {}\".format(i,train[i].nunique()) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Exploring diffrent match types:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['matchType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There classify the matchType into 3 types: Solo, Duo, Squad"},{"metadata":{"trusted":true},"cell_type":"code","source":"mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) else 'squad'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['matchType'] = train['matchType'].apply(mapper)\nsns.countplot(train['matchType'])\nplt.title('Count of different types of match')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Checking correlation of features with Win Percentage:"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nplt.figure(figsize=(20, 15))\nsns.heatmap(train.corr(), annot=True, fmt= '.1f', cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Analysing the Kill"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"On an average a person kills {:.4f} players, 99% of people have {} kills or less, while the maximum kills ever recorded is {}.\".format(train['kills'].mean(),train['kills'].quantile(0.99), train['kills'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train.copy()\ndata.loc[data['kills'] > data['kills'].quantile(0.99)] = '8+'\nplt.figure(figsize=(15,8))\nsns.countplot(data['kills'].astype(str).sort_values())\nplt.title(\"Kill Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train.copy()\ndata = data[data['kills']==0]\nplt.figure(figsize=(15,7))\nplt.title(\"Damage Dealt by 0 killers\")\nsns.distplot(data['damageDealt'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"A total of {} players ({:.4f}%) have won without a single kill!\".format(len(data[data['winPlacePerc']==1]), 100*len(data[data['winPlacePerc']==1])/len(train)))\ndata1 = train[train['damageDealt'] == 0].copy()\nprint(\"A total of {} players ({:.4f}%) have won without dealing damage!\".format(len(data1[data1['winPlacePerc']==1]), 100*len(data1[data1['winPlacePerc']==1])/len(train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Effect of Kiiling on Winning percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"kills = train.copy()\n\nkills['killsCategories'] = pd.cut(kills['kills'], [-1, 0, 2, 5, 10, 60], labels=[\n    '0_kills','1-2_kills', '3-5_kills', '6-10_kills', '10+_kills'])\n\nplt.figure(figsize=(15,8))\nsns.boxplot(x=\"killsCategories\", y=\"winPlacePerc\", data=kills)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 'kills' has a high correlation with winPlacePerc."},{"metadata":{},"cell_type":"markdown","source":"###### Analysing Walk Distance"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} players ({:.4f}%) walked 0 meters. This means that either they die before even taking a step or they have just joined the game but are away from keyboard (more possible).\".format(len(data[data['walkDistance'] == 0]), 100*len(data1[data1['walkDistance']==0])/len(train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train.copy()\ndata = data[data['walkDistance'] < train['walkDistance'].quantile(0.99)]\nplt.figure(figsize=(15,7))\nplt.title(\"Walking Distance Distribution\")\nsns.distplot(data['walkDistance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"walkDistance\",  data=train, height=10, ratio=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Walking has a high correlation with winPlacePerc."},{"metadata":{},"cell_type":"markdown","source":"##### Analysing Riding"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"An average person drives for {:.1f}m, 99% of people have drived {}m or less, while THE RIDER rode for {}m.\".format(train['rideDistance'].mean(), train['rideDistance'].quantile(0.99), train['rideDistance'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Does work in Jupyter\n\"\"\"\ndata = train.copy()\ndata = data[data['rideDistance'] < train['rideDistance'].quantile(0.99)]\nplt.figure(figsize=(15,7))\nplt.title(\"Ride Distance Distribution\")\nsns.distplot(data['rideDistance'])\nplt.show()\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} players ({:.4f}%) drived for 0 meters. This means that they like trekking more than riding.\".format(len(data[data['rideDistance'] == 0]), 100*len(data1[data1['rideDistance']==0])/len(train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"rideDistance\", data=train, height=10, ratio=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Theoretically, if a player is able to destroy the vehicle it indicates the he/she is skilled. Let's check if this theory is correct."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(15,7))\nsns.pointplot(x='vehicleDestroys',y='winPlacePerc',data=data,color='lime',alpha=0.5)\nplt.xlabel('Count of Vehicle Destroys',fontsize = 16,color='blue')\nplt.ylabel('Win Percentage',fontsize = 16,color='blue')\nplt.title('Vehicle Destroyed/ Win Ratio',fontsize = 20,color='blue')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Destroying vehicles increases your chances of winning!"},{"metadata":{},"cell_type":"markdown","source":"### Analysing Healing and Boosting\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"In the game on an average a person uses {:.1f} heal items, 99% of people use {} or less, while the maximun used is {}.\".format(train['heals'].mean(), train['heals'].quantile(0.99), train['heals'].max()))\nprint(\"In the game on an average a person uses {:.1f} boost items, 99% of people use {} or less, while the maximun used is {}.\".format(train['boosts'].mean(), train['boosts'].quantile(0.99), train['boosts'].max()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysing Healing and Boosting: Effect of Healing & Boosting on Winning Percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train.copy()\ndata = data[data['heals'] < data['heals'].quantile(0.99)]\ndata = data[data['boosts'] < data['boosts'].quantile(0.99)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax1 = plt.subplots(figsize =(15,7))\nsns.pointplot(x='heals',y='winPlacePerc',data=data,color='lime',alpha=0.8)\nsns.pointplot(x='boosts',y='winPlacePerc',data=data,color='blue',alpha=0.8)\nplt.text(4,0.6,'Heals',color='lime',fontsize = 16,style = 'italic')\nplt.text(4,0.55,'Boosts',color='blue',fontsize = 16,style = 'italic')\nplt.xlabel('Number of heal/boost items',fontsize = 16,color='blue')\nplt.ylabel('Win Percentage',fontsize = 16,color='blue')\nplt.title('Heals vs Boosts',fontsize = 20,color='blue')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"heals\", data=train, height=10, ratio=3, color=\"lime\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"boosts\", data=train, height=10, ratio=3, color=\"blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Both healing and boosts have a high correlation with winning, however boosts matter more."},{"metadata":{},"cell_type":"markdown","source":"### Analyzing Effect of Knocking (DBNO), Assisting or Reviving on Winning Percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train[train['matchType'] != 'solo']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"DBNOs\", data=train, height=10, ratio=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"assists\", data=train, height=10, ratio=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"winPlacePerc\", y=\"revives\", data=train, height=10, ratio=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 2: Data Cleaning: Outlier Detection and Removal - Finding the fraudsters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking row with NaN value\ntrain[train['winPlacePerc'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(train[train['winPlacePerc'].isnull()].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Engineer a new feature _totalDistance\ntrain['_totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a new feature 'headshot_rate'. We see that the most players score in the 0 to 10% region. However, there are a few anomalies that have a headshot_rate of 100% percent with more than 9 kills!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Engineer _headshot_rate feature --- headshots made per kill\ntrain['_headshot_rate'] = train['headshotKills'] / train['kills']\ntrain['_headshot_rate'] = train['_headshot_rate'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Inhumane kills"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining some functions for plotting graphs\ndef show_countplot(column):\n    plt.figure(figsize=(15,7))\n    sns.countplot(data=train, x=column).set_title(column)\n    plt.show()\n    \ndef show_distplot(column):\n    plt.figure(figsize=(15,7))\n    sns.distplot(train[column],kde=True, bins=50)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_countplot('kills')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is it even possible to kill more than 40 people by acquiring more than 55 weapons and maintaining a total distance of less than 100m?\ntrain[(train['kills'] >= 40) & (train['weaponsAcquired'] > 55) & (train['_totalDistance'] < 100.0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is it even possible to kill more than 40 people without using any heals?\ntrain[(train['kills'] >= 40) & (train['heals'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 'fraudsters' from above df\ntrain.drop(train[(train['kills'] >= 40) & (train['weaponsAcquired'] > 55) & (train['_totalDistance'] < 100.0)].index, inplace=True)\ntrain.drop(train[(train['kills'] >= 40) & (train['heals'] == 0)].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 100% Headshot Kills"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the distribution of headshot_rate\n# Does work in Jupyter\n# show_distplot('_headshot_rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of Hitman who made more than 10 kills and all the kills were done by headshot(perfect kill)\ndisplay(train[(train['_headshot_rate'] == 1) & (train['kills'] >=10)].shape)\ntrain[(train['_headshot_rate'] == 1) & (train['kills'] >= 10)].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The headshotKills looks OK. So we will not delete these as of now."},{"metadata":{},"cell_type":"markdown","source":"#### Killing without Moving"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create feature killsWithoutMoving\ntrain['_killsWithoutMoving'] = ((train['kills'] > 0) & (train['_totalDistance'] == 0))\n# Check players who kills without moving\ndisplay(train[train['_killsWithoutMoving'] == True].shape)\ntrain[train['_killsWithoutMoving'] == True].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping kill without moving 'fraudsters'\ntrain.drop(train[train['_killsWithoutMoving'] == True].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Longest Kill"},{"metadata":{},"cell_type":"markdown","source":"Most kills are made from a distance of 100 meters or closer. However there are some players (outliers) who make a kill from more than 1km away. These players are probably fraudsters."},{"metadata":{"trusted":true},"cell_type":"code","source":"show_distplot('longestKill')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# players who took these shots from more than 1km\ntrain[train['longestKill'] >= 1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping these players\ntrain.drop(train[train['longestKill'] >= 1000].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Road Kills"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Players who got more than 10 roadKills\ntrain[train['roadKills'] > 10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For player Id c3e444f7d1289f rode just 5 meters but has killed 14 players in the roadkill. It is highly unlikely. Hence droping it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop roadKill 'fraudsters'\ntrain.drop(train[train['roadKills'] > 10].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding anomaly in travelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['walkDistance', 'rideDistance', 'swimDistance']].describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Detecting Anomalies in Walking"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_distplot('walkDistance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is not possible for players to play to roam around and explore places without killing anyone \n# and how can they travel 13kms in the game?\ntrain[(train['walkDistance'] >= 13000) & (train['kills'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop walking anomalies\ntrain.drop(train[(train['walkDistance'] >= 13000) & (train['kills'] == 0)].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Detecting Anomalies in Riding"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_distplot('rideDistance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is not possible for players to play to roam around and explore places without killing anyone \n# and how can you ride for 30km?\ntrain[(train['rideDistance'] >= 30000) & (train['kills'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How is it even possible that a player is able to ride and kill without walking even a single meter ?\ntrain[(train['walkDistance'] == 0) & (train['rideDistance'] > 0) & (train['kills'] > 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What was the player doing in the game when total distance travelled by him/her is 0? \ntrain[(train['_totalDistance'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop riding anomalies\ntrain.drop(train[(train['rideDistance'] >= 30000) & (train['kills'] == 0)].index, inplace = True)\ntrain.drop(train[(train['walkDistance'] == 0) & (train['rideDistance'] > 0) & (train['kills'] > 0)].index, inplace = True)\ntrain.drop(train[(train['_totalDistance'] == 0)].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Swim Distance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Does work in Jupyter\n# show_distplot('swimDistance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How can player swim for more than 2 km without breathing?\ntrain[train['swimDistance'] >= 2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ntrain.drop(train[train['swimDistance'] >= 2000].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Anomalies detection in Supplies (WeaponAcquired)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_distplot('weaponsAcquired')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train[train['weaponsAcquired'] >= 80].shape)\ntrain[train['weaponsAcquired'] >= 80].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ntrain.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Anomalies in Heals"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_distplot('heals')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 40 or more healing items used\ndisplay(train[train['heals'] >= 40].shape)\ntrain[train['heals'] >= 40].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ntrain.drop(train[train['heals'] >= 40].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_csv('cleaned_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data = pd.read_csv('cleaned_data.csv')\ncleaned_data = reduce_mem_usage(cleaned_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 3: Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"A game in PUBG can have up to 100 players fighting each other. But most of the times a game isn't \"full\". There is no variable that gives us the number of players joined. So lets create one."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data['_playersJoined'] = cleaned_data.groupby('matchId')['matchId'].transform('count')\ndata = cleaned_data.copy()\ndata = data[data['_playersJoined']>49]\nplt.figure(figsize=(15,7))\nsns.countplot(data['_playersJoined'])\nplt.title(\"Players Joined\",fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are a few matches with less than 75 players that cannot be displayed here. As you can see most of the matches are nearly packed and have almost 100 players."},{"metadata":{},"cell_type":"markdown","source":"#### Normalizing the features\nNow that we have a feature '_playersJoined' we can normalize other features based on the amount of players. Features that can be valuable to normalize are:\n\n- kills\n- damageDealt\n- maxPlace\n- matchDuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create normalized features\ncleaned_data['_killsNorm'] = cleaned_data['kills']*((100-cleaned_data['_playersJoined'])/100 + 1)\ncleaned_data['_damageDealtNorm'] = cleaned_data['damageDealt']*((100-cleaned_data['_playersJoined'])/100 + 1)\ncleaned_data['_maxPlaceNorm'] = cleaned_data['maxPlace']*((100-cleaned_data['_playersJoined'])/100 + 1)\ncleaned_data['_matchDurationNorm'] = cleaned_data['matchDuration']*((100-cleaned_data['_playersJoined'])/100 + 1)\n# Compare standard features and normalized features\nto_show = ['Id', 'kills','_killsNorm','damageDealt', '_damageDealtNorm', 'maxPlace', '_maxPlaceNorm', 'matchDuration', '_matchDurationNorm']\ncleaned_data[to_show][0:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match = cleaned_data.groupby('matchId')\ncleaned_data['_killsPerc'] = match['kills'].rank(pct=True).values\ncleaned_data['_killPlacePerc'] = match['killPlace'].rank(pct=True).values\ncleaned_data['_walkDistancePerc'] = match['walkDistance'].rank(pct=True).values\ncleaned_data['_damageDealtPerc'] = match['damageDealt'].rank(pct=True).values\ncleaned_data['_walkPerc_killsPerc'] = cleaned_data['_walkDistancePerc'] / cleaned_data['_killsPerc']\ncleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = cleaned_data[['_killsPerc', '_killPlacePerc','_walkDistancePerc','_damageDealtPerc', '_walkPerc_killsPerc','winPlacePerc']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.heatmap(corr, annot=True,cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg = cleaned_data.groupby(['groupId']).size().to_frame('players_in_team')\ncleaned_data = cleaned_data.merge(agg, how='left', on=['groupId'])\ncleaned_data['_healthItems'] = cleaned_data['heals'] + cleaned_data['boosts']\ncleaned_data['_headshotKillRate'] = cleaned_data['headshotKills'] / cleaned_data['kills']\ncleaned_data['_killPlaceOverMaxPlace'] = cleaned_data['killPlace'] / cleaned_data['maxPlace']\ncleaned_data['_killsOverWalkDistance'] = cleaned_data['kills'] / cleaned_data['walkDistance']\ncleaned_data['_killsOverDistance'] = cleaned_data['kills'] / cleaned_data['_totalDistance']\ncleaned_data['_walkDistancePerSec'] = cleaned_data['walkDistance'] / cleaned_data['matchDuration']\ncleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = cleaned_data[['killPlace', 'walkDistance','players_in_team','_healthItems', '_headshotKillRate', '_killPlaceOverMaxPlace', '_killsOverWalkDistance', '_killsOverDistance','_walkDistancePerSec','winPlacePerc']].corr()\nplt.figure(figsize=(15,7))\nsns.heatmap(corr, annot=True, cmap=\"BrBG\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Less correlated wrt winPlacePerc\ncleaned_data.drop(['_headshotKillRate','_killsOverDistance', '_killsOverWalkDistance', ], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_fit = [col for col in cleaned_data.columns]\ncorr = cleaned_data[cols_to_fit].corr()\nf,ax = plt.subplots(figsize=(35, 25))\nsns.heatmap(cleaned_data[cols_to_fit].corr(), annot=True, fmt= '.1f',ax=ax, cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing features having 0 correlation with winPlacePerc"},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data.drop(['killPoints','matchDuration','maxPlace','numGroups','rankPoints','roadKills','teamKills','winPoints',\n                   '_playersJoined', '_maxPlaceNorm', '_matchDurationNorm', '_killsWithoutMoving'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cleaned_data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing features having high correlation "},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = cleaned_data.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.85)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop features \ncleaned_data.drop(cleaned_data[to_drop], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_fit = [col for col in cleaned_data.columns]\ncorr = cleaned_data[cols_to_fit].corr()\nf,ax = plt.subplots(figsize=(30, 20))\nsns.heatmap(corr, annot=True, fmt= '.1f',ax=ax, cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving highly correlated data\ncleaned_data.to_csv('Highly_correlated_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modifying the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"highly_corr = pd.read_csv('Highly_correlated_data.csv')\nhighly_corr = reduce_mem_usage(highly_corr)\n\nhighly_corr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = highly_corr[highly_corr['winPlacePerc'].notnull()].reset_index(drop=True)\nX_test = highly_corr[highly_corr['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis=1).reset_index(drop=True)\n\n\nY_train = X_train.pop('winPlacePerc')\nX_test_grp = X_test[['matchId','groupId']].copy()\ntrain_matchId = X_train['matchId']\n\n# drop matchId,groupId\nX_train.drop(['matchId','groupId','Id'], axis=1, inplace=True)\nX_test.drop(['matchId','groupId','Id'], axis=1, inplace=True)\n\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dealing with categorical feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} different Match types in the dataset.'.format(highly_corr['matchType'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encode matchType\nhighly_corr = pd.get_dummies(highly_corr, columns=['matchType'])\n\n# Take a look at the encoding\nmatchType_encoding = highly_corr.filter(regex='matchType')\nmatchType_encoding.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a lot of groupId's and matchId's so one-hot encoding them is computational huge. We will turn them into category codes. That way we can still benefit from correlations between groups and matches in our Random Forest algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn groupId and match Id into categorical types\nhighly_corr['groupId'] = highly_corr['groupId'].astype('category')\nhighly_corr['matchId'] = highly_corr['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\nhighly_corr['groupId_cat'] = highly_corr['groupId'].cat.codes\nhighly_corr['matchId_cat'] = highly_corr['matchId'].cat.codes\n\n# Get rid of old columns\nhighly_corr.drop(columns=['groupId', 'matchId'], inplace=True)\n\n# Lets take a look at our newly created features\nhighly_corr[['groupId_cat', 'matchId_cat']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Id column, because it probably won't be useful for our Machine Learning algorithm,\n# because the test set contains different Id's\nhighly_corr.drop(columns = ['Id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take sample for debugging and exploration\nsample = 500000\ndf_sample = highly_corr.sample(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split sample into training data and target variable\nX = df_sample.drop(columns = ['winPlacePerc']) #all columns except target\ny = df_sample['winPlacePerc'] # Only target variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Defining function for calculating Mean Absolute Error (MAE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metric used for the PUBG competition (Mean Absolute Error (MAE))\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Function to print the MAE (Mean Absolute Error) score\n\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n           'mae val: ', mean_absolute_error(m.predict(X_test), y_test)]\n    #Score of the training dataset obtained using an out-of-bag estimate.\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Basic Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train basic model\nm1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nm1.fit(X_train, y_train)\nprint_score(m1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finding Feature Importance using Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}).sort_values('imp', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What are the most predictive features according to our basic random forest model\nfi = rf_feat_importance(m1, X); fi[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a feature importance graph for the 20 most important features\nplot1 = fi[:15].plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep only significant features\nto_keep = fi[fi.imp>0.005].cols\nprint('Significant features: ', len(to_keep))\nto_keep\n\n# Make a DataFrame with only significant features\ndf_keep = X[to_keep].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Building a Random Forest Model with top features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model on top features\nm2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nm2.fit(X_train, y_train)\nprint_score(m2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get feature importances of our top features\nfi_to_keep = rf_feat_importance(m2, X)\n\nfor i in list(fi_to_keep['cols']):\n    if i not in list(to_keep):\n        fi_to_keep = fi_to_keep[fi_to_keep.cols != i]\n        \nplot2 = fi_to_keep.plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy\nfrom scipy.cluster import hierarchy as hc\n# Create a Dendrogram to view highly correlated features\ncorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(14,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = highly_corr.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(columns = ['winPlacePerc']) # all columns except target\nX = X[to_keep] # Keep only relevant features\ny = train['winPlacePerc'] # target variable\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train final model\n# You should get better results by increasing n_estimators\n# and by playing around with the parameters\nm3 = RandomForestRegressor(n_estimators=50, min_samples_leaf=3, max_features=0.5,\n                          n_jobs=-1)\nm3.fit(X_train, y_train)\nprint_score(m3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modifying the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding same features to test data\nagg = test.groupby(['groupId']).size().to_frame('players_in_team')\ntest = test.merge(agg, how='left', on=['groupId'])\ntest['_headshot_rate'] = test['headshotKills'] / test['kills']\ntest['_headshot_rate'] = test['_headshot_rate'].fillna(0)\ntest['_totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\ntest['_playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\ntest['_killsNorm'] = test['kills']*((100-test['_playersJoined'])/100 + 1)\ntest['_damageDealtNorm'] = test['damageDealt']*((100-test['_playersJoined'])/100 + 1)\ntest['_damageDealtPerc'] = test['damageDealt'].rank(pct=True).values\ntest['_healthItems'] = test['heals'] + test['boosts']\ntest['killsWithoutMoving'] = ((test['kills'] > 0) & (test['_totalDistance'] == 0))\ntest['_killPlacePerc'] = test['killPlace'].rank(pct=True).values\ntest['_killsPerc'] = test['kills'].rank(pct=True).values\ntest['_walkDistancePerc'] = test['walkDistance'].rank(pct=True).values\ntest['_walkPerc_killsPerc'] = test['_walkDistancePerc'] / test['_killsPerc']\ntest['_killPlaceOverMaxPlace'] = test['killPlace'] / test['maxPlace']\ntest['_killsPerc'] = test['kills'].rank(pct=True).values\ntest['_walkDistancePerc'] = test['walkDistance'].rank(pct=True).values\ntest['_walkDistancePerSec'] = test['walkDistance'] / test['matchDuration']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn groupId and match Id into categorical types\ntest['groupId'] = test['groupId'].astype('category')\ntest['matchId'] = test['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntest['groupId_cat'] = test['groupId'].cat.codes\ntest['matchId_cat'] = test['matchId'].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_keep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Remove irrelevant features from the test set\ntest_pred = test[to_keep].copy()\n\n# Fill NaN with 0 (temporary)\ntest_pred.fillna(0, inplace=True)\ntest_pred.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 4: Final Predition"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.clip(a = m3.predict(test_pred), a_min = 0.0, a_max = 1.0)\npred_df = pd.DataFrame({'Id' : test['Id'], 'winPlacePerc' : predictions})\npred_df\n# Create submission file\npred_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}