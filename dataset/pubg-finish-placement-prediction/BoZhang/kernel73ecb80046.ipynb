{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport gc\nimport os\nimport sys\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import minmax_scale\nimport lightgbm as lgb\n\nsns.set_style('darkgrid')\nsns.set_palette('bone')\n\npd.options.display.float_format = '{:,.3f}'.format\n\n\ndef toTapleList(list1,list2):\n    return list(itertools.product(list1,list2))\n\n#save memory function\n#https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n                #else:\n                    #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n                                                                                               start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n\n#load data\ntrain = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')\ntrain = reduce_mem_usage(train)\n\ntest = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\ntest = reduce_mem_usage(test)\nprint(train.shape, test.shape)\n\nprint()\n#print the train info\ntrain.info()\n\nprint()\nnull_cnt = train.isnull().sum().sort_values()\nprint('null count:', null_cnt[null_cnt>0])\n#delet null use dropna\ntrain.dropna(inplace=True)\n\nprint()\nprint(train.describe(include=np.number).drop('count').T)\n\n\nprint()\n#Data Analysis\n\n#Match id, groupid, matchid\nfor c in ['Id','groupId','matchId']:\n    print(f'unique [{c}] count:',train[c].nunique())\n\nprint()\n#For pubg there are three module, solo, duo and squad in the game\n#matchType\nfig, ax=plt.subplots(1,2,figsize=(12,4))\n#solo: solo, solo-fpp, normal-solo, normal-solo-fpp\n#duo: duo, duo-fpp, normal-duo, normal-duo-fpp, crashfpp, crashtpp\n#squad: squad, squad-fpp, normal-squad, normal-squad-fpp, flarefpp, flaretpp\ntrain.groupby('matchId')['matchType'].first().value_counts().plot.bar(ax=ax[0])\nmapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\ntrain['matchType'] = train['matchType'].apply(mapper)\ntrain.groupby('matchId')['matchType'].first().value_counts().plot.bar(ax=ax[1])\nplt.pause(15)\n\n\nprint()\n#print the number of the maxplace groups\nfor q in ['numGroups == maxPlace', 'numGroups != maxPlace']:\n    print(q, ':', len(train.query(q)))\n\nprint()\n#numGroups, maxPlace, group_in_match\ncols = ['numGroups','maxPlace']\ndesc1 = train.groupby('matchType')[cols].describe()[toTapleList(cols,['min','mean','max'])]\ngroup = train.groupby(['matchType', 'matchId', 'groupId']).count().groupby(['matchType','matchId']).size().to_frame('groups_in_match')\ndesc2 = group.groupby('matchType').describe()[toTapleList(['groups_in_match'],['min','mean','max'])]\ngroup_res = pd.concat([desc1,desc2],axis=1)\nprint(group_res)\n\n\nprint()\n#number players in match\n#each server have 100 player\n#solo have max 100 players as 100 group\n#duo have max 100 players as 50 group\n#squad have max 100 player each group have 4 people as 25 groups\nmatch = train.groupby(['matchType','matchId']).size().to_frame('players_in_match')\ngroup = train.groupby(['matchType','matchId','groupId']).size().to_frame('players_in_group')\nplayer_res = pd.concat([match.groupby('matchType').describe()[toTapleList(['players_in_match'],['min','mean','max'])],\n                        group.groupby('matchType').describe()[toTapleList(['players_in_group'],['min','mean','max'])]],axis=1)\nprint(player_res)\n\n\nprint()\n#for group more than maxsize\nprint(group['players_in_group'].nlargest(5))\ndel match,group\n\n\nprint()\n#example matchId=='41a634f62f86b7', groupId=='128b07271aa012'\nsubset = train[train['matchId']=='41a634f62f86b7']\nsub_group = subset[subset['groupId'] == '128b07271aa012']\n\nprint('matchId==\\'41a634f62f86b7\\' & groupId==\\'128b07271aa012\\'')\nprint('-'*50)\nprint('players:',len(subset))\nprint('groups:',subset['groupId'].nunique())\nprint('maxPlace:',subset['maxPlace'].nunique())\nprint('-'*50)\nprint('max-group players:', len(sub_group))\nprint('max-group winPlacePerc:', sub_group['winPlacePerc'].unique())\nprint('-'*50)\nprint('winPlacePerc:', subset['winPlacePerc'].sort_values().unique())\n\n\n\nprint()\n#plot player\ngroup = train.groupby(['matchId','groupId','matchType'])['Id'].count().to_frame('players').reset_index()\ngroup.loc[group['players']>4, 'players'] = 'default' #more than 4 people\ngroup['players'] = group['players'].astype(str)\n\nfig, ax = plt.subplots(1,3,figsize=(16,4))\nfor mt,ax in zip(['solo','duo','squad'], ax.ravel()):\n    ax.set_xlabel(mt)\n    group[group['matchType'] == mt]['players'].value_counts().sort_index().plot.bar(ax=ax)\nplt.pause(15)\n\n\nprint()\n#matchDuration\nfig, ax = plt.subplots(1,2,figsize=(12,4))\ntrain['matchDuration'].hist(bins=50,ax=ax[0])\ntrain.query('matchDuration >= 1400 & matchDuration <= 1800')['matchDuration'].hist(bins=50,ax=ax[1])\nplt.pause(15)\n\nprint()\n#min matchDuration\nprint(train[train['matchDuration'] == train['matchDuration'].min()].head())\n\nprint()\n#max matchDuration\nprint(train[train['matchDuration'] == train['matchDuration'].max()].head())\n\nprint()\n#each match duration always same\nduartion_res = (train.groupby('matchId')['matchDuration'].nunique()>1).any()\nprint(duartion_res)\n\n\nprint()\n#boosts and heals\nfig, ax = plt.subplots(2,2,figsize=(16,8))\ncols = ['boosts','heals']\nfor cols, ax in zip(cols, ax):\n    sub = train[['winPlacePerc', cols]].copy()\n    mv = (sub[cols].max() // 5)+1\n    sub[cols] = pd.cut(sub[cols], [5*x for x in range(0, mv)], right=False)\n    sub.groupby(cols).mean()['winPlacePerc'].plot.bar(ax=ax[0])\n    train[cols].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\n\nprint()\n#revives\nprint('solo player no revives:', 'solo' in train.query('revives > 0')['matchType'].unique())\n\n\nprint()\n#revives hist\nfig, ax = plt.subplots(1,2,figsize=(16,4))\ncol = 'revives'\nsub = train.loc[~train['matchType'].str.contains('solo'),['winPlacePerc',col]].copy()\nsub[col] = pd.cut(sub[col], [5*x for x in range(0,8)], right=False)\nsub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\ntrain[col].hist(bins=20,ax=ax[1])\nplt.pause(15)\n\n\nprint()\n#killPlace\nprint(train.groupby(['matchType'])['killPlace'].describe()[['min','mean','max']])\n\nprint()\n#killPlace hist\nplt.figure(figsize=(8,4))\ncol = 'killPlace'\nsub = train[['winPlacePerc', col]].copy()\nsub[col] = pd.cut(sub[col], [10*x for x in range(0,11)],right=False)\nsub.groupby(col).mean()['winPlacePerc'].plot.bar()\nplt.pause(15)\n\n\nprint()\n#killPlace is sorted ranking of kills and winPlacePerc in each match\nsubMatch = train[train['matchId'] == train['matchId'].min()].sort_values(['winPlacePerc','killPlace'])\ncols = ['groupId', 'kills', 'winPlacePerc', 'killPlace']\nkillPlace_res = subMatch[cols]\nprint(killPlace_res)\n\n\nprint()\n#kills\nfig, ax = plt.subplots(1,2, figsize=(16,4))\ncol = 'kills'\nsub = train[['winPlacePerc',col]].copy()\nsub[col] = pd.cut(sub[col], [5*x for x in range(0,20)],right=False)\nsub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\ntrain[train['kills'] <20][col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\nprint()\n#kill summary of match\nsub = train['matchType'].str.contains('solo')\nkill_summary_res = pd.concat([train.loc[sub].groupby('matchId')['kills'].sum().describe(), train.loc[~sub].groupby('matchId')['kills'].sum().describe()],\n          keys=['solo', 'group'], axis=1).T\nprint(kill_summary_res)\n\n\n\nprint()\n#killStreaks, DBNOs\nfig, ax = plt.subplots(2, 2, figsize=(16,8))\ncols = ['killStreaks', 'DBNOs']\nfor col, ax in zip(cols, ax):\n    sub = train[['winPlacePerc', col]].copy()\n    sub[col]=pd.cut(sub[col], 6)\n    sub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\n    train[col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\nprint()\n#headshotKills, roadKills, teamKills\nfig,ax = plt.subplots(3,2,figsize=(16,12))\ncols = ['headshotKills', 'roadKills', 'teamKills']\nfor col, ax in zip(cols, ax):\n    sub = train[['winPlacePerc',col]].copy()\n    sub.loc[sub[col] >= 5, col] = '5+'\n    sub[col] = sub[col].astype(str)\n    sub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\n    train[col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\n\nprint()\n#assists\nfig, ax = plt.subplots(1,2, figsize=(16,4))\ncol='assists'\nsub = train[['winPlacePerc', col]].copy()\nsub.loc[sub[col] >= 5, col] = '5+'\nsub[col] = sub[col].astype(str)\nsub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\ntrain[col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\nprint()\n#number of assists\nassists_res = pd.concat([train[train['matchType'] == 'solo'].describe()['assists'], train[train['matchType'] != 'solo'].describe()['assists']], keys=['solo', 'group'], axis=1).T\nprint(assists_res)\n\n\n\nprint()\n#longestKill\nfig, ax = plt.subplots(1,2, figsize=(16, 4))\ncol = 'longestKill'\nsub = train[['winPlacePerc', col]].copy()\nsub[col] = pd.cut(sub[col], 6)\nsub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\ntrain[col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\n\nprint()\nfig, ax = plt.subplots(1,2, figsize=(16,4))\ncol = 'damageDealt'\nsub = train[['winPlacePerc', col]].copy()\nsub[col] = pd.cut(sub[col], 6)\nsub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\ntrain[col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\nprint()\n#summary of damageDealt\ndamageDealt_res = train.query('damageDealt == 0 & (kills >0 | DBNOs >0)')[['damageDealt', 'kills', 'DBNOs', 'headshotKills', 'roadKills', 'teamKills']].head(20)\n\n\n\nprint()\n#walkDistance, rideDistance, swimDistance\nfig, ax = plt.subplots(3,2, figsize=(16,12))\ncols = ['walkDistance', 'rideDistance', 'swimDistance']\nfor col, ax in zip(cols, ax):\n    sub = train[['winPlacePerc', col]].copy()\n    sub[col] = pd.cut(sub[col], 6)\n    sub.groupby(col).mean()['winPlacePerc'].plot.bar(ax=ax[0])\n    train[col].hist(bins=20, ax=ax[1])\nplt.pause(15)\n\n\n\nprint()\n#number of walkDistance, rideDistance, swimDistance\nsub = train[['walkDistance', 'rideDistance', 'swimDistance', 'winPlacePerc']].copy()\nwalk = train['walkDistance']\nsub['walkDistanceBin'] = pd.cut(walk, [0, 0.001, walk.quantile(.25), walk.quantile(.5), walk.quantile(.75), 99999])\nsub['rideDistanceBin'] = (train['rideDistance'] > 0).astype(int)\nsub['swimDistanceBin'] = (train['swimDistance'] > 0).astype(int)\n\nfig,ax = plt.subplots(1, 3, figsize=(16,3), sharey=True)\nsub.groupby('walkDistanceBin').mean()['winPlacePerc'].plot.bar(ax=ax[0])\nsub.groupby('rideDistanceBin').mean()['winPlacePerc'].plot.bar(ax=ax[1])\nsub.groupby('swimDistanceBin').mean()['winPlacePerc'].plot.bar(ax=ax[2])\ndel sub, walk\nplt.pause(15)\n\n\nprint()\n#zombie\nsub = train.query('walkDistance == 0 & kills == 0 & weaponsAcquired == 0 & \\'solo\\' in matchType')\nprint('count:', len(sub), 'winPlacePerc:', round(sub['winPlacePerc'].mean(),3))\n\n\nprint()\n#kills summary\nkills_res = train.query('kills >3 & (headshotKills/kills) >= 0.8')\nprint('kills >3 & (headshotKills/kills) >= 0.8')\nprint('count: ', len(kills_res))\nprint('winPlacePerc: ', round(kills_res['winPlacePerc'].mean(),3))\n\n\n\nprint()\n#killPoints, rankPoints, winPoints\nfig, ax = plt.subplots(1,3, figsize=(16,4))\ncols = ['killPoints', 'rankPoints', 'winPoints']\nfor col, ax in zip(cols, ax.ravel()):\n    train.plot.scatter(x=col, y='winPlacePerc', ax=ax)\nplt.pause(15)\n\n\nprint()\n#winPlacePerc\nwinPlacePerc_summary = train['winPlacePerc'].describe()\nprint(winPlacePerc_summary)\n\n\nprint()\n#unique match count\nprint('unique match count: ', train['matchId'].nunique())\nmaxPlacePerc = train.groupby('matchId')['winPlacePerc'].max() #not contain 1st place\nprint('match [not contain 1st place]: ', len(maxPlacePerc[maxPlacePerc != 1]))\ndel maxPlacePerc\n#edge case\nsub = train[(train['maxPlace'] > 1) & (train['numGroups'] == 1)]\nprint('match [maxPlace >1 & numGroup == 1] : ', len(sub.groupby('matchId')))\nprint(' - unique winPlacePerc: ', sub['winPlacePerc'].unique())\n\n\n\nprint()\nwinPlace_res = pd.concat([train[train['winPlacePerc'] == 1].head(10), train[train['winPlacePerc'] == 0].head(10)], keys=['winPlacePerc_1', 'winPlacePerc+0'])\nprint(winPlace_res)\n\n\n\nprint()\ncols = ['kills', 'teamKills', 'DBNOs', 'revives', 'assists', 'boosts', 'heals', 'damageDealt', 'walkDistance', 'rideDistance', 'swimDistance', 'weaponsAcquired']\n\naggs = ['count', 'min', 'mean', 'max']\n#summary of solo match\ngrp = train.loc[train['matchType'].str.contains('solo')].groupby('matchId')\ngrpSolo = grp[cols].sum()\n#summary of team match\ngrp = train.loc[~train['matchType'].str.contains('solo')].groupby('matchId')\ngrpTeam = grp[cols].sum()\nwinPlacePerc_res = pd.concat([grpSolo.describe().T[aggs], grpTeam.describe().T[aggs]],keys=['solo','team'],axis=1)\nprint(winPlacePerc_res)\n\n\nprint()\nprint(grpSolo.nlargest(5,'kills'))\n\nprint()\nprint(grpTeam.nlargest(5,'kills'))\n\ndel grpSolo, grpTeam\n\n\nprint()\n#group summary\ncols = ['kills', 'teamKills', 'DBNOs', 'revives', 'assists', 'boosts', 'heals', 'damageDealt', 'walkDistance', 'rideDistance', 'swimDistance', 'weaponsAcquired']\ncols.extend(['killPlace', 'winPlacePerc'])\ngroup = train.groupby(['matchId', 'groupId'])[cols]\nfig, ax = plt.subplots(3, 1, figsize=(12,18), sharey=True)\nfor df, ax in zip([group.mean(), group.min(), group.max()], ax.ravel()):\n    sns.heatmap(df.corr(), annot=True, linewidths=.6, fmt='.2f', vmax=1, vmin=-1, center=0, cmap='Blues', ax=ax)\nplt.pause(150)\n\n\n\nprint()\n#print match stats\ndef printMatchStats(matchIds):\n    for mid in matchIds:\n        subMatch = train[train['matchId'] == mid]\n        print('matchType:', subMatch['matchType'].values[0])\n\n        grp1st = subMatch[subMatch['winPlacePerc'] == 1]\n        grpOther = subMatch[subMatch['winPlacePerc'] != 1]\n        print('players'.ljust(10), ' total:{:>3} 1st:{:>3} other:{:>3}'.format(len(subMatch), len(grp1st), len(grpOther)))\n        for c in ['kills', 'teamKills', 'roadKills', 'DBNOs', 'revives', 'assists']:\n              print(c.ljust(10), ' total:{:>3} 1st:{:>3} other:{:>3}'.format(subMatch[c].sum(), grp1st[c].sum(), grpOther[c].sum()))\n              print('-'*50)\n\nprint()\n\n\nmatch = train.groupby(['matchId'])['Id'].count()\nfullplayer = match[match==100].reset_index()\nsampleMid = fullplayer['matchId'][0:5]\nprintMatchStats(sampleMid)\n\n\nprint()\nall_data = train.append(test, sort=False).reset_index(drop=True)\ndel train, test\n#gc.collect()\nprint(gc.collect())\n\nprint()\n#reconstruct data\nmatch = all_data.groupby('matchId')\nall_data['killsPerc'] = match['kills'].rank(pct=True).values\nall_data['killPlacePerc'] = match['killPlace'].rank(pct=True).values\nall_data['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values\nall_data['walkPerc_killPerc'] = all_data['walkDistancePerc']/all_data['killsPerc']\n\n\nprint()\nall_data['_totalDistance'] = all_data['rideDistance'] + all_data['walkDistance'] + all_data['swimDistance']\n\nprint()\n#fill new feature\ndef fillInfo(df, val):\n    numcols = df.select_dtypes(include='number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols:\n        df[c].fillna(val,inplace=True)\n\n\nprint()\n#create new feature\nall_data['_healthItems'] = all_data['heals'] + all_data['boosts']\nall_data['_headshotKillRate'] = all_data['headshotKills']/all_data['kills']\nall_data['_killPlaceOverMaxPlace'] = all_data['killPlace'] / all_data['maxPlace']\nall_data['_killsOverWalkDistance'] = all_data['kills'] / all_data['walkDistance']\nall_data['_killsOverDistance'] = all_data['kills'] / all_data['_totalDistance']\nall_data['_walkDistancePerSec'] = all_data['walkDistance'] / all_data['matchDuration']\nfillInfo(all_data,0)\n\n\nprint()\n#drop feature\nall_data.drop(['boosts', 'heals', 'killStreaks', 'DBNOs'], axis=1, inplace=True)\nall_data.drop(['headshotKills','roadKills', 'vehicleDestroys'], axis=1, inplace=True)\nall_data.drop(['rideDistance','swimDistance', 'matchDuration'], axis=1, inplace=True)\nall_data.drop(['rankPoints','killPoints', 'winPoints'], axis=1, inplace=True)\n\n\nprint()\n#group the data\nmatch = all_data.groupby(['matchId'])\ngroup = all_data.groupby(['matchId', 'groupId', 'matchType'])\nagg_col = list(all_data.columns)\nexclude_agg_col = ['Id','matchId','groupId','matchType','maxPlace','numGroups','winPlacePerc']\nfor c in exclude_agg_col:\n    agg_col.remove(c)\nprint(agg_col)\nsum_col = ['kills','killPlace','damageDealt','walkDistance','_healthItems']\n\n\nprint()\nmatch_data = pd.concat([match.size().to_frame('m.players'),\n                        match[sum_col].sum().rename(columns=lambda s: 'm.sum.' + s),\n                        match[sum_col].max().rename(columns=lambda s: 'm.max.' + s),\n                        match[sum_col].mean().rename(columns=lambda s: 'm.mean.' + s)], axis=1).reset_index()\nmatch_data = pd.merge(match_data,group[sum_col].sum().rename(columns=lambda s: 'sum.' + s).reset_index())\nmatch_data = reduce_mem_usage(match_data)\n\nprint(match_data.shape)\n\n\nprint()\n#ranking kill and killPlace\nminKills= all_data.sort_values(['matchId','groupId','kills','killPlace']).groupby(['matchId','groupId','kills']).first().reset_index().copy()\nfor n in np.arange(4):\n    c = 'kills_' + str(n) +'_Place'\n    nKills = (minKills['kills'] == n)\n    minKills.loc[nKills, c] = minKills[nKills].groupby(['matchId'])['killPlace'].rank().values\n    match_data = pd.merge(match_data, minKills[nKills][['matchId','groupId',c]],how='left')\n\nmatch_data = reduce_mem_usage(match_data)\ndel minKills,nKills\nprint()\nprint(match_data.shape)\n\nprint()\nprint(match_data.head())\n\n\nprint()\n#mean, max, min\nall_data = pd.concat([group.size().to_frame('players'),\n                      group.mean(),\n                      group[agg_col].max().rename(columns=lambda s: 'max.' +s),\n                      group[agg_col].min().rename(columns=lambda s: 'min.' +s)], axis=1).reset_index()\nall_data = reduce_mem_usage(all_data)\nprint(all_data)\n\n\nprint()\n#aggregate feature\nnumcols = all_data.select_dtypes(include='number').columns.values\nnumcols = numcols[numcols != 'winPlacePerc']\n\nall_data = pd.merge(all_data,match_data)\ndel match_data\ngc.collect()\n\nall_data['enemy.players'] = all_data['m.players'] - all_data['players']\nfor c in sum_col:\n    all_data['enemy.players'+c] = (all_data['m.sum.'+c]- all_data['sum.'+c])/all_data['enemy.players']\n    all_data['p.sum_msum.'+c] = all_data['m.sum.'+c] / all_data['m.sum.'+c]\n    all_data['p.max_mmean.'+c] = all_data['max.'+c] / all_data['m.mean.'+c]\n    all_data['p.max_msum.'+c] = all_data['max.'+c] / all_data['m.sum.'+c]\n    all_data['p.max_mmax.'+c] = all_data['max.'+c] / all_data['m.max.'+c]\n    all_data.drop(['m.sum.'+c, 'm.max.'+c], axis=1, inplace=True)\nfillInfo(all_data,0)\nprint(all_data.shape)\n\n\nprint()\nmatch = all_data.groupby('matchId')\nmatchRank = match[numcols].rank(pct=True).rename(columns=lambda s:'rank.'+s)\nall_data = reduce_mem_usage(pd.concat([all_data,matchRank],axis=1))\nrank_col = matchRank.columns\ndel matchRank\ngc.collect()\n\nmatch = all_data.groupby('matchId')\nmatchRank = match[rank_col].max().rename(columns=lambda s:'max.'+s).reset_index()\nall_data = pd.merge(all_data,matchRank)\nfor c in numcols:\n    all_data['rank.'+c] = all_data['rank.'+c] / all_data['max.rank.'+c]\n    all_data.drop(['max.rank.'+c], axis=1,inplace=True)\ndel matchRank\ngc.collect()\nprint(all_data.shape)\n\n\nprint()\n#encode\n#all_data['matchType'] = all_data['matchType'].apply(mapper)\n\nall_data = pd.concat([all_data,pd.get_dummies(all_data['matchType'])], axis=1)\nall_data.drop(['matchType'], axis=1, inplace=True)\nall_data['matchId'] = all_data['matchId'].apply(lambda x: int(x,16))\nall_data['groupId'] = all_data['groupId'].apply(lambda x: int(x,16))\n\nnull_count = all_data.isnull().sum().sort_values()\nprint(null_count[null_count>0])\n\ncols = [col for col in all_data.columns if col not in ['Id','matchId','groupId']]\nfor i,t in all_data.loc[:,cols].dtypes.iteritems():\n    if t == object:\n        all_data[i] = pd.factorize(all_data[i])[0]\n\nall_data = reduce_mem_usage(all_data)\nall_data.head()\n\nprint()\n#predict\nX_train = all_data[all_data['winPlacePerc'].notnull()].reset_index(drop=True)\nX_test = all_data[all_data['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis=1).reset_index(drop=True)\ndel all_data\ngc.collect()\n\nY_train = X_train.pop('winPlacePerc')\nX_test_group = X_test[['matchId','groupId']].copy()\ntrain_matchId = X_train['matchId']\n\nX_train.drop(['matchId','groupId'], axis=1, inplace=True)\nX_test.drop(['matchId','groupId'], axis=1, inplace=True)\nprint(X_train.shape, X_test.shape)\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])\n              \n\n\nprint()\nparams = {'learning_rate': 0.05, 'objective': 'mae', 'metric':'mae', 'num_leaves': 128,\n    'verbose': 1, 'verbose': 1, 'bagging_fraction': 0.7, 'feature_fraction': 0.7\n}\n\nreg = lgb.LGBMRegressor(**params, n_estimators=10000)\nreg.fit(X_train, Y_train)\npred = reg.predict(X_test, num_iteration=reg.best_iteration_)\n\n# Plot feature importance\nfeature_importance = reg.feature_importances_\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\nsorted_idx = sorted_idx[len(feature_importance) - 30:]\npos = np.arange(sorted_idx.shape[0]) + .5\n\nplt.figure(figsize=(12,8))\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X_train.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()\n\nprint()\nprint(X_train.columns[np.argsort(-feature_importance)].values)\n\nX_test_group['_nofit.winPlacePerc'] = pred\ngroup = X_test_group.groupby(['matchId'])\nX_test_group['winPlacePerc'] = pred\nX_test_group['_rank.winPlacePerc'] = group['winPlacePerc'].rank(method='min')\nX_test = pd.concat([X_test, X_test_group], axis=1)\n\nfullgroup = (X_test['numGroups'] == X_test['maxPlace'])\nsubset = X_test.loc[fullgroup]\nX_test.loc[fullgroup, 'winPlacePerc'] = (subset['_rank.winPlacePerc'].values - 1) / (subset['maxPlace'].values - 1)\n\nsubset = X_test.loc[~fullgroup]\ngap = 1.0 / (subset['maxPlace'].values - 1)\nnew_perc = np.around(subset['winPlacePerc'].values / gap) * gap\nX_test.loc[~fullgroup, 'winPlacePerc'] = new_perc\n\nX_test['winPlacePerc'] = X_test['winPlacePerc'].clip(lower=0,upper=1)\n\n# edge cases\nX_test.loc[X_test['maxPlace'] == 0, 'winPlacePerc'] = 0\nX_test.loc[X_test['maxPlace'] == 1, 'winPlacePerc'] = 1\nX_test.loc[(X_test['maxPlace'] > 1) & (X_test['numGroups'] == 1), 'winPlacePerc'] = 0\nprint(X_test['winPlacePerc'].describe())\n\n\n#submittion\ntest = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\ntest['matchId'] = test['matchId'].apply(lambda x: int(x,16))\ntest['groupId'] = test['groupId'].apply(lambda x: int(x,16))\n\nsubmission = pd.merge(test, X_test[['matchId','groupId','winPlacePerc']])\nsubmission = submission[['Id','winPlacePerc']]\nsubmission.to_csv(\"submission.csv\", index=False)\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}