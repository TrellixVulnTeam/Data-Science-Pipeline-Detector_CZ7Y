{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\nrandom.seed(42)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n# !chmod 600 '/content/drive/My Drive/pubg/train/train_V2.csv'\n# !chmod 600 '/content/drive/My Drive/pubg/test/test_V2.csv'\nINPUT_DIR = \"../input\"\n\n# Specific imports\nfrom sklearn.metrics import mean_absolute_error\n\n# Helper Functions\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    #start_mem = df.memory_usage().sum() / 1024**2\n    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    return df\n\ndef reload():\n    print(\"Building dataframe...\")\n    gc.collect()\n    df = reduce_mem_usage(pd.read_csv(INPUT_DIR + '/pubg-finish-placement-prediction/train_V2.csv')) # <=========== Just a function to reduce memory usage\n\n    # Only take the samples with matches that have more than 1 player \n    # there are matches with no players or just one player ( those samples could affect our model badly) \n    df = df[df['maxPlace'] > 1]\n    invalid_match_ids = df[df['winPlacePerc'].isna()]['matchId'].values\n    df = df[-df['matchId'].isin(invalid_match_ids)]\n    print(\"Done loading train to dataframe...\")\n    return df\n\ndef train_test_split(df, test_size=0.1):\n    match_ids = df['matchId'].unique().tolist()\n    train_size = int(len(match_ids) * (1 - test_size))\n    train_match_ids = random.sample(match_ids, train_size)\n\n    train = df[df['matchId'].isin(train_match_ids)]\n    test = df[-df['matchId'].isin(train_match_ids)]\n\n    return train, test\n  \n# Split train to train and eval set\ndef generate_train_test_set(df, split):\n    print(\"Generating train and test set...\")\n    # df.drop(columns=['matchType'], inplace=True)\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    train, val = train_test_split(df, split)\n    return train[cols_to_fit], val[cols_to_fit]\n\ndef generate_train_set(df):\n    print(\"Generating train and test set...\")\n    # df.drop(columns=['matchType'], inplace=True)\n\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    train = df\n    return train[cols_to_fit]\n\ndef load_test():\n    print(\"Loading test...\")\n    df = reduce_mem_usage(pd.read_csv(INPUT_DIR + '/pubg-finish-placement-prediction/test_V2.csv')) # <=========== Just a function to reduce memory usage\n    return df\n\ndef generate_test_set(df):\n    print(\"Generating train and test set...\")\n    # df.drop(columns=['matchType'], inplace=True)\n\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    train = df\n    return train[cols_to_fit]\n\ndef save_for_submission(df, path):\n    submission = df[['Id', 'winPlacePerc']]\n    submission.to_csv(path + '/' + 'submission.csv', index=False)\n\ndef transform_preds(df_test, pred):\n    df_test['orig_preds'] = pred\n    for i in range(len(df_test)):\n        winPlacePerc_m = pred[i]\n        maxPlace = int(df_test.iloc[i]['maxPlace'])\n        if maxPlace == 0:\n            winPlacePerc_m = 0.0\n        elif maxPlace == 1:\n            winPlacePerc_m = 1.0\n        else:\n            gap = 1.0 / (maxPlace - 1)\n            winPlacePerc_m = np.round(winPlacePerc_m / gap) * gap\n\n        if winPlacePerc_m < 0: winPlacePerc_m = 0.0\n        if winPlacePerc_m > 1: winPlacePerc_m = 1.0    \n        pred[i] = winPlacePerc_m\n\n        if (i + 1) % 100000 == 0:\n            print(i, flush=True, end=\" \")\n\n    df_test['winPlacePerc'] = pred\n    return df_test\n    \n# Feature Engineering\n# Helper Functions\n\ndef get_playersJoined(df):\n    df['playersJoined'] = df.groupby('matchId')['matchId'].transform('count')\n    return df\n\ndef get_killsNorm(df):\n    if 'playersJoined' not in df.columns:\n        df = get_playersJoined(df)\n    df['killsNorm'] = df['kills']*((100-df['playersJoined'])/100 + 1)\n    return df\n\ndef get_damageDealtNorm(df):\n    if 'playersJoined' not in df.columns:\n        df = get_playersJoined(df)\n    df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])/100 + 1)\n    return df\n\ndef get_healsAndBoosts(df):\n    df['healsAndBoosts'] = df['heals'] + df['boosts']\n    return df\n\ndef get_totalDistance(df):\n    df['totalDistance'] = df['walkDistance']+ df['rideDistance']+ df['swimDistance']\n    return df\n\ndef get_team(df):\n    df['team'] = [1 if i>50 else 2 if (i>25 & i<=50) else 4 for i in df['numGroups']]\n    return df\n\ndef get_players_in_team(df):\n    agg = df.groupby(['groupId']).size().to_frame('players_in_team')\n    return df.merge(agg, how='left', on=['groupId'])\n\ndef get_headshotKills_over_kills(df):\n    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n    df['headshotKills_over_kills'].fillna(0, inplace=True)\n    return df\n\ndef get_killPlace_over_maxPlace(df):\n    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n    df['killPlace_over_maxPlace'].fillna(0, inplace=True)\n    df['killPlace_over_maxPlace'].replace(np.inf, 0, inplace=True)\n    return df\n\ndef get_walkDistance_over_heals(df):\n    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n    df['walkDistance_over_heals'].fillna(0, inplace=True)\n    df['walkDistance_over_heals'].replace(np.inf, 0, inplace=True)\n    return df\n  \ndef get_walkDistance_over_boosts(df):\n    df['walkDistance_over_boosts'] = df['walkDistance'] / df['boosts']\n    df['walkDistance_over_boosts'].fillna(0, inplace=True)\n    df['walkDistance_over_boosts'].replace(np.inf, 0, inplace=True)\n    return df\n\ndef get_walkDistance_over_kills(df):\n    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n    df['walkDistance_over_kills'].fillna(0, inplace=True)\n    df['walkDistance_over_kills'].replace(np.inf, 0, inplace=True)\n    return df\n\ndef get_teamwork(df):\n    df['teamwork'] = df['assists'] + df['revives']\n    return df\n\n# BY AGGREGATES, meaning, they calculate mean/max/min, etc of each columns then add it into the left of the existing one\ndef add_min_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId','groupId'])[features].min()\n    return df.merge(agg, suffixes=['', '_min'], how='left', on=['matchId', 'groupId'])\n\ndef add_max_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].max()\n    return df.merge(agg, suffixes=['', '_max'], how='left', on=['matchId', 'groupId'])\n\ndef add_sum_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].sum()\n    return df.merge(agg, suffixes=['', '_sum'], how='left', on=['matchId', 'groupId'])\n\ndef add_median_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].median()\n    return df.merge(agg, suffixes=['', '_median'], how='left', on=['matchId', 'groupId'])\n\ndef add_mean_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n    return df.merge(agg, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n\ndef add_rank_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n    agg = agg.groupby('matchId')[features].rank(pct=True)\n    return df.merge(agg, suffixes=['', '_mean_rank'], how='left', on=['matchId', 'groupId'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moving\n# sub_df = reduce_mem_usage(pd.read_csv(INPUT_DIR + '/samplesubmissioncsv/submission.csv')) # <=========== Just a function to reduce memory usage\n# sub_df.to_csv(INPUT_DIR + '/' + 'samplesubmission.csv', index=False)\n# Build the NEURAL NET\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers import LeakyReLU\nfrom keras.regularizers import l2\nfrom keras.callbacks import *\nfrom keras.models import load_model\n\n# adjusted because im still testing so i reduced hidden units from 64 to 32, epoch reduced\nclass NNModel():\n    # network parameters\n    batch_size = 32\n    hidden_units = 64\n    dropout = 0.2\n    kernel_regularizer = l2(0.0001)\n    leaky_relu = (5 ** 0.5 - 3) / 2\n  \n    def __init__(self, input_size, reload=False, path=None):\n        if reload:\n            self.model = load_model(path)\n        else:\n            # Regression has 1 output layer\n            output_shape = 1\n\n            self.model = model = Sequential()\n            self.model.add(Dense(self.hidden_units, input_dim=input_size, init=\"glorot_uniform\", bias_initializer='zeros'))\n            # self.model.add(LeakyReLU(alpha=self.leaky_relu))\n            self.model.add(Activation('sigmoid'))\n            self.model.add(Dropout(self.dropout))\n            self.model.add(Dense(self.hidden_units, init=\"glorot_uniform\", bias_initializer='zeros'))\n            self.model.add(Activation('sigmoid'))\n            # self.model.add(LeakyReLU(alpha=self.leaky_relu))\n            self.model.add(Dropout(self.dropout))\n            self.model.add(Dense(output_shape))\n            # this is the output for one-hot vector\n            self.model.add(Activation('linear'))\n \n    def _summarize(self):\n        self.model.summary()\n\n    def _compile(self):\n        self.model.compile(loss='mse',\n                  optimizer='adam',\n                  metrics=['mse', 'mae'])\n\n    def _train(self, x_train, y_train, epochs):\n        filepath=\"../input/epochs:{epoch:03d}-mse:{loss:.3f}.hdf5\"\n        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, \n                                     save_best_only=True, mode='min', period=2)\n        callbacks_list = [checkpoint]\n\n        self.history = self.model.fit(x_train, y_train, \n                  epochs=epochs, batch_size=self.batch_size, callbacks=callbacks_list)\n\n    def _evaluate(self, x_test, y_test):\n        return self.model.evaluate(x_test, y_test, batch_size=self.batch_size)\n\n    def _predict(self, x_test):\n        return self.model.predict(x_test)\n  \n  # For Plotting Purposes\n    def _history(self):\n        return self.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def original(df):\n    return df\n\ndef get_these_cols(df, remain):\n    return df[remain]\n\ndef remove_these_cols(df, remove_cols):\n    cols_to_remain = [col for col in df.columns if col not in remove_cols]\n    return df[cols_to_remain]\n\ndef put_everything_and_rank(df):\n    df.drop(columns=['matchType'], inplace=True)\n    df = get_playersJoined(df)\n    df = get_killsNorm(df)\n    df = get_damageDealtNorm(df)\n    df = get_healsAndBoosts(df)\n    df = get_totalDistance(df)\n    df = get_team(df)\n    df = get_players_in_team(df)\n    df = get_headshotKills_over_kills(df)\n    df = get_killPlace_over_maxPlace(df)\n    df = get_walkDistance_over_heals(df)\n    df = get_walkDistance_over_boosts(df)\n    df = get_walkDistance_over_kills(df)\n    df = get_teamwork(df)\n    df = add_rank_by_team(df)\n    return df\n\ndef new_combination_2(df):\n    df.drop(columns=['matchType'], inplace=True)\n    # Just combination 1 with ranking\n    '''\n        Value                             Feature\n    0     506                           killPlace\n    1     421             totalDistance_mean_rank\n    2     378                 killPlace_mean_rank\n    3     377              walkDistance_mean_rank\n    4     293   killPlace_over_maxPlace_mean_rank\n    5     257                     kills_mean_rank\n    6     254             killPlace_over_maxPlace\n    7     224                        walkDistance\n    8     197               killStreaks_mean_rank\n    9     188   walkDistance_over_kills_mean_rank\n    10    161                    boosts_mean_rank\n    11    146                 killsNorm_mean_rank\n    12    142           players_in_team_mean_rank\n    13    136                       playersJoined\n    14    135                           killsNorm\n    15    132                     players_in_team\n    16    114                       totalDistance\n    17    108           weaponsAcquired_mean_rank\n    18    107                       matchDuration\n    19     90                            maxPlace\n    20     84                           numGroups\n    '''\n    df = get_killPlace_over_maxPlace(df)\n    df = get_totalDistance(df)\n    df = get_playersJoined(df)\n    df = get_players_in_team(df)\n    df = get_walkDistance_over_kills(df)\n    df = get_killsNorm(df)\n    df = get_walkDistance_over_boosts(df)\n    df = get_healsAndBoosts(df)\n    df = get_damageDealtNorm(df)\n    df = add_rank_by_team(df)\n  \n    to_remove = ['assists', 'heals', 'walkDistance_over_heals', 'swimDistance', 'teamwork', 'teamKills', 'revives', 'headshotKills_over_kills', 'headshotKills', 'roadKills', 'team', 'vehicleDestroys']\n    df = remove_these_cols(df, to_remove)\n    return df\n\ndef new_combination_4(df):\n    df.drop(columns=['matchType'], inplace=True)\n    df = put_everything_and_rank(df)\n    remaining_cols = ['Id', 'groupId', 'matchId', 'winPlacePerc', 'killPlace', 'killPlace_mean_rank', \n                    'walkDistance_mean_rank', 'totalDistance_mean_rank',\n                    'killPlace_over_maxPlace', 'killPlace_over_maxPlace_mean_rank', 'kills_mean_rank',\n                    'killStreaks_mean_rank', 'walkDistance_over_kills_mean_rank', 'killsNorm_mean_rank',\n                    'walkDistance_over_boosts_mean_rank', 'weaponsAcquired_mean_rank', 'walkDistance',\n                    'playersJoined', 'players_in_team_mean_rank', 'boosts_mean_rank', 'players_in_team',\n                    'killsNorm', 'walkDistance_over_kills', 'matchDuration', 'DBNOs_mean_rank', 'numGroups',\n                    'longestKill_mean_rank', 'maxPlace']\n                    \n    df = get_these_cols(df, remaining_cols)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training & Evaluate Phase\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain_evaluate = False\nreload_model = True\nmodel_path = INPUT_DIR + '/models/epochs_020-mse_0.004.hdf5'\n\nif train_evaluate:\n    df = reload()\n    df = new_combination_2(df)\n    target = 'winPlacePerc'\n\n    train, val = generate_train_test_set(df, 0.1)\n\n    del df\n    gc.collect()\n\n    x_train, y_train = train.drop(target, axis=1).to_numpy(), train[target].to_numpy()\n    x_eval, y_eval = val.drop(target, axis=1).to_numpy(), val[target].to_numpy()\n\n    scaler = MinMaxScaler().fit(x_train)\n    rescaled_x_train = scaler.transform(x_train)\n\n    del x_train\n    del train\n    del val\n    gc.collect()\n\n    num_labels = len(x_eval[0])\n    model1 = NNModel(num_labels)\n    model1._summarize()\n    model1._compile()\n    model1._train(rescaled_x_train, y_train, 2)\n    # Evalute\n    rescaled_x_test = scaler.transform(x_eval)\n    score = model1._evaluate(rescaled_x_test, y_eval)\n    print(\"\\nMean Squared Error [smaller the better]: %f\" % (score[1]))\nelse:\n    df = reload()\n    df = new_combination_2(df)\n    target = 'winPlacePerc'\n    train = generate_train_set(df)\n    x_train, y_train = train.drop(target, axis=1).to_numpy(), train[target].to_numpy()\n\n    # Garbage collection\n    del train\n    del df\n    gc.collect()\n\n    scaler = MinMaxScaler().fit(x_train)\n    x_train = scaler.transform(x_train)\n    \n    num_labels = len(x_train[0])\n    if reload_model:\n        model1 = NNModel(num_labels, reload_model, model_path)\n        # model1._train(x_train, y_train, 3)\n    else:\n        model1 = NNModel(num_labels)\n        model1._summarize()\n        model1._compile()\n        model1._train(x_train, y_train, 20)\n    \n    df_test = load_test() # load test data from csv\n    df_test = new_combination_2(df_test)\n    pred_df = df_test[['Id', 'maxPlace']].copy()\n    df_test = generate_test_set(df_test)\n\n    x_test = df_test.to_numpy() # df to numpy array\n    print('Scaling test set...')\n    scaled_x_test = scaler.transform(x_test) # scaling\n\n    del x_test\n    gc.collect()\n    print('Start prediction...')\n    pred = model1._predict(scaled_x_test)\n    df_to_submit = transform_preds(pred_df, pred)\n    print('Saving...')\n    # print(df_to_submit[:5])\n\n    save_for_submission(df_to_submit, INPUT_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}