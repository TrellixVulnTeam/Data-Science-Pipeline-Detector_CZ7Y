{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def reduce_mem_usage(df):\n#     '''\n#     iterate through all the columns of a dataframe and modify the data type\n#     to reduce memory usage.        \n#     '''\n#     start_mem = df.memory_usage().sum() / 1024**2\n#     print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n#     for col in df.columns:\n#         col_type = df[col].dtype\n#         if col_type != object:\n#             c_min = df[col].min()\n#             c_max = df[col].max()\n#             if str(col_type)[:3] == 'int':\n#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n#                     df[col] = df[col].astype(np.int8)\n#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n#                     df[col] = df[col].astype(np.int16)\n#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n#                     df[col] = df[col].astype(np.int32)\n#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n#                     df[col] = df[col].astype(np.int64)  \n#             else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n#                     df[col] = df[col].astype(np.float32)\n#                 else:\n#                     df[col] = df[col].astype(np.float64)\n#     end_mem = df.memory_usage().sum() / 1024**2\n#     print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n#     print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n#     return df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# develop_mode = False\n# if develop_mode:\n#     df_train = reduce_mem_usage(pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv', nrows=5000))\n#     df_test = reduce_mem_usage(pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv'))\n# else:\n#     df_train = reduce_mem_usage(pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv'))\n#     df_test = reduce_mem_usage(pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import warnings\n# warnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# import gc, sys\n\n# def BuildFeature(is_train=True):\n#     '''\n#     Function for feature engineering\n#     is_train incicates whether the train set or the test set is processed\n#     '''\n#     y = None\n#     test_idx = None\n    \n#     if is_train: \n#         print(\"Reading train.csv\")\n#         df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')           \n#         df = df[df['maxPlace'] > 1]\n#     else:\n#         print(\"Reading test.csv\")\n#         df = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n#         test_idx = df.Id\n    \n#     # Reduce the memory usage\n#     df = reduce_mem_usage(df)\n    \n#     print(\"Delete Unuseful Columns\")\n#     target = 'winPlacePerc'\n#     features = list(df.columns)\n#     features.remove(\"Id\")\n#     features.remove(\"matchId\")\n#     features.remove(\"groupId\")\n#     features.remove(\"matchType\")  \n    \n#     if is_train: \n#         print(\"Read Labels\")\n#         y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n#         features.remove(target)\n\n#     print(\"Read Group mean features\")\n#     agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n#     agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n#     if is_train:\n#         df_out = agg.reset_index()[['matchId','groupId']]\n#     else:\n#         df_out = df[['matchId','groupId']]\n#     df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n#     df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n\n#     print(\"Read Group max features\")\n#     agg = df.groupby(['matchId','groupId'])[features].agg('max')\n#     agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n#     df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n#     df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n#     print(\"Read Group min features\")\n#     agg = df.groupby(['matchId','groupId'])[features].agg('min')\n#     agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n#     df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n#     df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n#     print(\"Read Group size features\")\n#     agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n#     df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n#     print(\"Read Match mean features\")\n#     agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n#     df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n#     print(\"Read Match size features\")\n#     agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n#     df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n#     df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n#     X = df_out\n#     feature_names = list(df_out.columns)\n#     del df, df_out, agg, agg_rank\n#     gc.collect()\n\n#     return X, y, feature_names, test_idx\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, y_train, train_columns, _ = BuildFeature(is_train=True)\n# X_test, _, _ , test_idx = BuildFeature(is_train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train =reduce_mem_usage(X_train)\n# X_test = reduce_mem_usage(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model building"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import GradientBoostingRegressor\n# GBR = GradientBoostingRegressor(loss='ls',learning_rate=0.1,\n#                                 n_estimators=100,max_depth=3)\n# GBR.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GBR.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred_train = GBR.predict(X_train)\n# y_pred_test = GBR.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport gc, sys\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(is_train=True,debug=True):\n    test_idx = None\n    if is_train: \n        print(\"processing train.csv\")\n        if debug == True:\n            df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv', nrows=10000)\n        else:\n            df = pd.read_csv('../input/pubg-finish-placement-prediction/train_V2.csv')           \n\n        df = df[df['maxPlace'] > 1]\n    else:\n        print(\"processing test.csv\")\n        df = pd.read_csv('../input/pubg-finish-placement-prediction/test_V2.csv')\n        test_idx = df.Id\n    \n    # df = reduce_mem_usage(df)\n    #df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    \n    # df = df[:100]\n    \n    print(\"remove some columns\")\n    target = 'winPlacePerc'\n\n    print(\"Adding Features\")\n \n    df['headshotrate'] = df['kills']/df['headshotKills']\n    df['killStreakrate'] = df['killStreaks']/df['kills']\n    df['healthitems'] = df['heals'] + df['boosts']\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n    df[\"skill\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    \n    print(\"Removing Na's From DF\")\n    df.fillna(0, inplace=True)\n\n    \n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchType\")\n    \n    # matchType = pd.get_dummies(df['matchType'])\n    # df = df.join(matchType)    \n    \n    y = None\n    \n    \n    if is_train: \n        print(\"get target\")\n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        features.remove(target)\n\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    else: df_out = df[['matchId','groupId']]\n\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # print(\"get group sum feature\")\n    # agg = df.groupby(['matchId','groupId'])[features].agg('sum')\n    # agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    # df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    # df_out = df_out.merge(agg_rank, suffixes=[\"_sum\", \"_sum_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # print(\"get group sum feature\")\n    # agg = df.groupby(['matchId','groupId'])[features].agg('sum')\n    # agg_rank = agg.groupby('matchId')[features].agg('sum')\n    # df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    # df_out = df_out.merge(agg_rank.reset_index(), suffixes=[\"_sum\", \"_sum_pct\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    # print(\"get match type feature\")\n    # agg = df.groupby(['matchId'])[matchType.columns].agg('mean').reset_index()\n    # df_out = df_out.merge(agg, suffixes=[\"\", \"_match_type\"], how='left', on=['matchId'])\n    \n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n\n    X = df_out\n    \n    feature_names = list(df_out.columns)\n\n    del df, df_out, agg, agg_rank\n    gc.collect()\n\n    return X, y, feature_names, test_idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train, train_columns, _ = feature_engineering(True,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test, _, _ , test_idx = feature_engineering(False,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\nx_train = reduce_mem_usage(x_train)\nx_test = reduce_mem_usage(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# data manipulation\n\nimport numpy as np\nimport pandas as pd\n# plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n# model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#use_cols = [col for col in df_train.columns if col not in excluded_features]\n\ntrain_index = round(int(x_train.shape[0]*0.8))\ndev_X = x_train[:train_index] \nval_X = x_train[train_index:]\ndev_y = y_train[:train_index] \nval_y = y_train[train_index:] \ngc.collect();\n\n# custom function to run light gbm model\ndef run_lgb(train_X, train_y, val_X, val_y, x_test):\n    params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators':20000, 'early_stopping_rounds':200,\n              \"num_leaves\" : 31, \"learning_rate\" : 0.05, \"bagging_fraction\" : 0.7,\n               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n             }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgval], early_stopping_rounds=200, verbose_eval=1000)\n    \n    pred_test_y = model.predict(x_test, num_iteration=model.best_iteration)\n    return pred_test_y, model\n\n# Training the model #\npred_test, model = run_lgb(dev_X, dev_y, val_X, val_y, x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('111')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.read_csv(\"../input/pubg-finish-placement-prediction/sample_submission_V2.csv\")\ndf_test = pd.read_csv(\"../input/pubg-finish-placement-prediction/test_V2.csv\")\ndf_sub['winPlacePerc'] = pred_test\n# Restore some columns\ndf_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\n\n# Sort, rank, and assign adjusted ratio\ndf_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\ndf_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\ndf_sub_group = df_sub_group.merge(\n    df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n    on=\"matchId\", how=\"left\")\ndf_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n\ndf_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\ndf_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]\n\n# Deal with edge cases\ndf_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\ndf_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n\n# Align with maxPlace\n# Credit: https://www.kaggle.com/anycode/simple-nn-baseline-4\nsubset = df_sub.loc[df_sub.maxPlace > 1]\ngap = 1.0 / (subset.maxPlace.values - 1)\nnew_perc = np.around(subset.winPlacePerc.values / gap) * gap\ndf_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n\n# Edge case\ndf_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\nassert df_sub[\"winPlacePerc\"].isnull().sum() == 0\n\ndf_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}