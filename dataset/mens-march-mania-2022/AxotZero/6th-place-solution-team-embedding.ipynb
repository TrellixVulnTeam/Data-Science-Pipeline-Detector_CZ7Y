{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train Team Embedding for one epoch\n\n## Warning\n1. This method only got 472th/659 in [March Machine Learning Mania 2022 - Women's](https://www.kaggle.com/competitions/womens-march-mania-2022).\n2. The config of the following code isn't the config of my final submission.\n\n\n## Method\n\n### Model\n\n<img src=\"https://i.imgur.com/pY1b0mu.png\" alt=\"drawing\" width=\"350\" height=\"400\"/>\n\n- The goal of model:\n    - Given 2 team_id, predict the competition result\n- Input:\n    - **team_emb**: trained embedding, represent the embedding of given team_id, initialized with torch.nn.Embedding().\n- Output:\n    - **team1_win**: whether team1 win the game\n    - **team_info**: abbreviation of the competition detail result, contains ['Score','FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR','Ast','TO','Stl','Blk','PF'] \n\n\n### Data\n- **Training data**: \n    - RegularSeasonDetailedResults.csv\n- **Validation data**: \n    - NCAATourneyDetailedResults.csv\n\n### Preprocess\n1. Duplicate the data and make it symetrical to get rid of winner and loser.\n2. **Add feature** \"**is_win**\" which represent whether team1 win the game.\n2.  Apply **quantile transformation** to transform the **team_info** to normal distribution.\n\n### Training\n1. Train for one epoch along the timeline\n2. A minibatch is the data that has the same 'Season' and 'DayNum'.\n3. The team embeddings will be updated everyday.\n\n\n## Future work\n- Apply GNN to let a single game result of two teams affect other teams and enhance the ability of the model to apply the relationships between the teams.\n\n","metadata":{}},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom easydict import EasyDict as edict\nfrom sklearn.preprocessing import QuantileTransformer\nimport torch\nimport torch.nn as nn\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:27.987673Z","iopub.execute_input":"2022-04-05T12:49:27.988099Z","iopub.status.idle":"2022-04-05T12:49:27.992745Z","shell.execute_reply.started":"2022-04-05T12:49:27.988069Z","shell.execute_reply":"2022-04-05T12:49:27.991958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CONFIG","metadata":{}},{"cell_type":"code","source":"# Random Seed\nSEED = 2626\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# device\nDEVICE_IDS = \"\"\nos.environ['CUDA_VISIBLE_DEVICES'] = DEVICE_IDS\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'device: {device}')\n\n# model\nTEAM_EMB_SIZE = 16\nMODEL_HIDDEN_SIZE = 32\nBATCH_SIZE = 2000\n\n# model training\nLEARNING_RATE = 1e-2\n## Loss weight of team1_win and detail_result predictions \nTEAM1_WIN_LOSS_WEIGHT = 0.7\nINFO_LOSS_WEIGHT = 1 - TEAM1_WIN_LOSS_WEIGHT\n## Loss weight of each columns of detail_result \nINFO_COLS_LOSS_WEIGHT = [5] + [0.1] * 13\nINFO_COLS_LOSS_WEIGHT = np.array(INFO_COLS_LOSS_WEIGHT) / np.sum(INFO_COLS_LOSS_WEIGHT)\nINFO_COLS_LOSS_WEIGHT = torch.tensor(INFO_COLS_LOSS_WEIGHT).to(device)\nINFO_COLS = ['Score','FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR','Ast','TO','Stl','Blk','PF']\nWIN_INFO_COLS = ['W'+col for col in INFO_COLS]\nLOSE_INFO_COLS = ['L'+col for col in INFO_COLS]\n\n# file\nGENDER = 'M'\nif GENDER == 'M':\n    DATA_DIR = f'../input/mens-march-mania-2022/MDataFiles_Stage2'\nelse:\n    DATA_DIR = f'../input/womens-march-mania-2022/WDataFiles_Stage2'\n\nREGULAR_FILE = f'{GENDER}RegularSeasonDetailedResults.csv'\nNCAA_FILE = f'{GENDER}NCAATourneyDetailedResults.csv'\nSAMPLE_SUBMISSION_FILE = f'{GENDER}SampleSubmissionStage2.csv'\n\n# Season\nif GENDER == 'M':\n    SEASONS = list(range(2003, 2020)) + [2021, 2022]\nelse:\n    SEASONS = list(range(2010, 2020)) + [2021, 2022]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:28.340747Z","iopub.execute_input":"2022-04-05T12:49:28.341211Z","iopub.status.idle":"2022-04-05T12:49:28.35518Z","shell.execute_reply.started":"2022-04-05T12:49:28.341178Z","shell.execute_reply":"2022-04-05T12:49:28.354168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df(file_name):\n    return pd.read_csv(f'{DATA_DIR}/{file_name}')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:28.574493Z","iopub.execute_input":"2022-04-05T12:49:28.574941Z","iopub.status.idle":"2022-04-05T12:49:28.579276Z","shell.execute_reply.started":"2022-04-05T12:49:28.57491Z","shell.execute_reply":"2022-04-05T12:49:28.57864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Manager","metadata":{}},{"cell_type":"code","source":"class DataManager:\n    def __init__(self, reg_df, nca_df, sub_df, device):\n        self.reg_df = reg_df.copy()\n        self.nca_df = nca_df.copy()\n        self.sub_df = sub_df.copy()\n        self.device = device\n        self.team_id_map = self.get_team_id_map()\n        self.num_team = len(self.team_id_map)\n        self.normalizer = self.get_normalizer()\n    \n    def get_test_data(self, season):\n        df = self.sub_df.copy()\n        df['Season'] = df['ID'].apply(lambda x: int(x.split('_')[0]))\n        df = df[df.Season == season]\n        team1_ids = df['ID'].apply(lambda x: int(x.split('_')[1])).astype(int).map(self.team_id_map)\n        team2_ids = df['ID'].apply(lambda x: int(x.split('_')[2])).astype(int).map(self.team_id_map)\n        team1_ids = torch.tensor(team1_ids.values).long().to(self.device)\n        team2_ids = torch.tensor(team2_ids.values).long().to(self.device)\n        return team1_ids, team2_ids\n    \n    def get_team_id_map(self):\n        df = self.reg_df\n        team_ids = set(list(df.WTeamID.unique()) + list(df.LTeamID.unique()))\n        return {team_id: i for i, team_id in enumerate(team_ids)}\n\n    def get_normalizer(self):\n        df = self.reg_df.copy()\n        qt = QuantileTransformer(random_state=SEED)\n        info_data = np.concatenate((df[WIN_INFO_COLS].values, df[LOSE_INFO_COLS].values), axis=0)\n        qt.fit(info_data)\n        return qt\n    \n    def process_df(self, _df, is_train=True):\n        df = _df.copy()\n        df.drop(columns=['WLoc','NumOT'], inplace=True)\n\n        # normalize\n        df[WIN_INFO_COLS] = self.normalizer.transform(df[WIN_INFO_COLS])\n        df[LOSE_INFO_COLS] = self.normalizer.transform(df[LOSE_INFO_COLS])\n\n        # map indices\n        df['WTeamID'] = df['WTeamID'].astype(int).map(self.team_id_map)\n        df['LTeamID'] = df['LTeamID'].astype(int).map(self.team_id_map)\n\n        ret = []\n        for _, group in df.groupby(['Season', 'DayNum']):\n            data1 = group[['WTeamID'] + WIN_INFO_COLS].values\n            data2 = group[['LTeamID'] + LOSE_INFO_COLS].values\n\n            if is_train:\n                # Duplicate the data and make it symetrical to get rid of winner and loser\n                _data1 = np.zeros((len(data1)*2, *data1.shape[1:]))\n                _data1[::2] = data1.copy()\n                _data1[1::2] = data2.copy()\n\n                _data2 = np.zeros((len(data2)*2, *data2.shape[1:]))\n                _data2[::2] = data2.copy()\n                _data2[1::2] = data1.copy()\n\n                data1 = _data1\n                data2 = _data2\n\n            tmp = {\n                'team1_ids': torch.tensor(data1[:, 0]).long().to(self.device),\n                'team2_ids': torch.tensor(data2[:, 0]).long().to(self.device),\n                'team1_data': torch.tensor(data1[:, 1:]).float().to(self.device),\n                'team2_data': torch.tensor(data2[:, 1:]).float().to(self.device),\n                'team1_win': torch.tensor(data1[:, 1] > data2[:, 1]).float().to(self.device)\n            }\n            ret.append(edict(tmp))\n        return ret\n    \n    def get_train_data(self, season=2016):\n        train_df = self.reg_df[self.reg_df.Season == season]\n        train_df = self.process_df(train_df)\n        if season < 2022:\n            valid_df = self.nca_df[self.nca_df.Season == season]\n            valid_df = self.process_df(valid_df, is_train=False)\n            test_data = None\n        else:\n            valid_df = None\n            test_data = self.get_test_data(season)\n        return train_df, valid_df, test_data\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:28.812561Z","iopub.execute_input":"2022-04-05T12:49:28.812991Z","iopub.status.idle":"2022-04-05T12:49:28.83976Z","shell.execute_reply.started":"2022-04-05T12:49:28.812961Z","shell.execute_reply":"2022-04-05T12:49:28.838672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MetricTracker","metadata":{}},{"cell_type":"code","source":"class MetricTracker:\n    def __init__(self):\n        self.bce = 0\n        self.mse = 0\n        self.count = 0\n\n    def update(self, count, bce, mse):\n        self.count += count\n        self.bce += bce * count\n        self.mse += mse * count\n    \n    def __str__(self):\n        return f\"bce: {self.bce/self.count:.04f}, mse: {self.mse / self.count:.04f}\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:29.140619Z","iopub.execute_input":"2022-04-05T12:49:29.141006Z","iopub.status.idle":"2022-04-05T12:49:29.14702Z","shell.execute_reply.started":"2022-04-05T12:49:29.14096Z","shell.execute_reply":"2022-04-05T12:49:29.145991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IterativeModel(nn.Module):\n    def __init__(self, num_team, num_info=14, team_emb_size=32, model_emb_size=64):\n        super().__init__()\n        \n        self.team_embs = nn.Embedding(num_team, team_emb_size)\n\n        self.mlp = nn.Sequential(\n            nn.utils.weight_norm(nn.Linear(team_emb_size*2, model_emb_size*6)),\n            nn.LeakyReLU(),\n\n            nn.BatchNorm1d(model_emb_size*6),\n            nn.utils.weight_norm(nn.Linear(model_emb_size*6, model_emb_size*4)),\n            nn.LeakyReLU(),\n\n            nn.BatchNorm1d(model_emb_size*4),\n            nn.utils.weight_norm(nn.Linear(model_emb_size*4, model_emb_size*2)),\n            nn.LeakyReLU(),\n\n        )\n        self.output_win = nn.Sequential(\n            nn.Linear(model_emb_size*2, 1),\n            nn.Sigmoid()\n        )\n        self.output_team1_info = nn.Linear(model_emb_size*2, num_info)\n        self.output_team2_info = nn.Linear(model_emb_size*2, num_info)\n    \n    def forward(self, team1_ids, team2_ids):\n        team1_embs = self.team_embs(team1_ids)\n        team2_embs = self.team_embs(team2_ids)\n\n        embs = torch.cat((team1_embs, team2_embs), dim=1)\n        embs = self.mlp(embs)\n\n        team1_win = self.output_win(embs).view(-1)\n        team1_info = self.output_team1_info(embs)\n        team2_info = self.output_team2_info(embs)\n        return team1_win, team1_info, team2_info","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:29.472753Z","iopub.execute_input":"2022-04-05T12:49:29.473404Z","iopub.status.idle":"2022-04-05T12:49:29.485958Z","shell.execute_reply.started":"2022-04-05T12:49:29.473357Z","shell.execute_reply":"2022-04-05T12:49:29.485145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read file, Define DataManager and model","metadata":{}},{"cell_type":"code","source":"sub_df = get_df(SAMPLE_SUBMISSION_FILE)\nreg_df = get_df(REGULAR_FILE)\nnca_df = get_df(NCAA_FILE)\n\ndm = DataManager(reg_df, nca_df, sub_df, device)\n\nmodel = IterativeModel(\n    num_team = dm.num_team,\n    num_info = len(INFO_COLS),\n    team_emb_size = TEAM_EMB_SIZE,\n    model_emb_size = MODEL_HIDDEN_SIZE\n).to(device)\n\nbce = nn.BCELoss()\nmse = nn.MSELoss(reduction='none')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:29.797725Z","iopub.execute_input":"2022-04-05T12:49:29.798136Z","iopub.status.idle":"2022-04-05T12:49:30.325855Z","shell.execute_reply.started":"2022-04-05T12:49:29.798108Z","shell.execute_reply":"2022-04-05T12:49:30.325085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train, Valid and Test","metadata":{}},{"cell_type":"code","source":"test_pred = []\nvalid_bce = []\nvalid_mse = []\n\nfor season in SEASONS:\n    print(f' ======== Season {season} ======== ')\n\n    # get data of given season\n    train_data, valid_data, test_data = dm.get_train_data(season=season)\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    \n    # train\n    model.train()\n    mt = MetricTracker()\n    for data in train_data:\n        # pred\n        team1_win_pred, team1_pred, team2_pred = model(data.team1_ids, data.team2_ids)\n\n        # compute loss\n        bce_loss = bce(team1_win_pred, data.team1_win)\n        team1_info_loss = mse(team1_pred, data.team1_data)\n        team2_info_loss = mse(team2_pred, data.team2_data)\n        mse_loss = torch.mean((team1_info_loss + team2_info_loss) / 2 * INFO_COLS_LOSS_WEIGHT)\n        loss = TEAM1_WIN_LOSS_WEIGHT * bce_loss + INFO_LOSS_WEIGHT * mse_loss\n        \n        # backward\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # update metric\n        mt.update(\n            count=len(team1_pred),\n            bce=bce_loss.item(), \n            mse=mse_loss.item()\n        )\n    print(f\"Train Season: {season}, {mt}\")\n\n    # valid\n    if valid_data: \n        model.eval()\n        mt = MetricTracker()\n        for data in valid_data:\n            # pred\n            team1_win_pred, team1_pred, team2_pred = model(data.team1_ids, data.team2_ids)\n\n            # compute loss\n            bce_loss = bce(team1_win_pred, data.team1_win)\n            team1_info_loss = mse(team1_pred, data.team1_data)\n            team2_info_loss = mse(team2_pred, data.team2_data)\n            mse_loss = torch.mean((team1_info_loss + team2_info_loss) / 2 * INFO_COLS_LOSS_WEIGHT)\n\n            # update metric\n            mt.update(\n                count=len(team1_pred),\n                bce=bce_loss.item(), \n                mse=mse_loss.item()\n            )\n\n            valid_bce.append(mt.bce / mt.count)\n            valid_mse.append(mt.mse / mt.count)\n            \n        print(f\"Valid Season: {season}, {mt}\")\n\n    if test_data:\n        # test\n        model.eval()\n        team1_ids, team2_ids = test_data\n        team1_win_pred, _, _ = model(team1_ids, team2_ids)\n        test_pred += team1_win_pred.tolist()\n        print(\"Run Testing\")\n\nprint(f\"\\nmean bce: {np.mean(valid_bce):4f}\")\nprint(f\"mean mse: {np.mean(valid_mse):4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:30.32733Z","iopub.execute_input":"2022-04-05T12:49:30.327567Z","iopub.status.idle":"2022-04-05T12:49:48.6682Z","shell.execute_reply.started":"2022-04-05T12:49:30.327538Z","shell.execute_reply":"2022-04-05T12:49:48.666988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['Pred'] = test_pred\nsub_df.to_csv(f'sub_{GENDER}.csv', index=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:49:48.670063Z","iopub.execute_input":"2022-04-05T12:49:48.670643Z","iopub.status.idle":"2022-04-05T12:49:48.688706Z","shell.execute_reply.started":"2022-04-05T12:49:48.670578Z","shell.execute_reply":"2022-04-05T12:49:48.687593Z"},"trusted":true},"execution_count":null,"outputs":[]}]}