{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **March Madness 2022** - Prediction using most recent games\nHere we will explore some potentially useful features for our model.\n\nDevelop features based on $n$ previous games\n- this is the idea that recent performance is most important in determining who wins the current matchup\n- for each game, features are computed for both teams based on previous $n$ games (the first games for each team in each season are dropped)\n- this might be bad for a tournament since you won't know how a team plays throughout the tournament, only the last games of the season are available\n- game data is available in `MRegularSeasonDetailedResults.csv`\n- For the game to be predicted, we will average the results of the previous $n$ games.\n- We can double the amount of training data since there is symmetry to exploit. More on this later.\n- Build a random forest model!","metadata":{"id":"nLTjDNNr0FIG"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nSTAGE_1_DIR = './MDataFiles_Stage1/'\nteams_df = pd.read_csv(STAGE_1_DIR + 'MTeams.csv')\nteams_df.head()","metadata":{"execution":{"iopub.execute_input":"2022-03-13T03:32:40.381161Z","iopub.status.busy":"2022-03-13T03:32:40.379025Z","iopub.status.idle":"2022-03-13T03:32:40.416261Z","shell.execute_reply":"2022-03-13T03:32:40.415181Z","shell.execute_reply.started":"2022-03-13T03:32:40.381116Z"},"id":"vZ_Lr8SS0FIK","outputId":"564da944-a065-4466-eaa2-bbdeef84fdda"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stage 1** - Data Preparation\n\nLet's get into cleaning and transforming the data! First we will define some functions that will allow us to transform the game data into something we can use to train a ML model. Notice that we can get double the amount of data by switching the lower ID team with the higher ID team and using the opposite label. That is, there is some degree of symmetry we can exploit.\n","metadata":{"id":"evjwRZUy0FIM"}},{"cell_type":"code","source":"from sklearn.base import TransformerMixin\nfrom tqdm import tqdm\n\nclass Preprocessor(TransformerMixin):\n    def __init__(self, games_df, n=10, weighting='avg', verbose=False):\n        super().__init__()\n        self.n = n\n        self.games_df = games_df\n        self.verbose = verbose\n        self.weighting = weighting # 'avg' or 'exp'\n        self.cached = {}\n    \n    def get_features(self, team_id, season, day_num):\n        '''\n        Computes the feature vector of the team over the past n games\n\n        Parameters\n        ----------\n        team_id : str\n            The unique identifier for the team\n        season : int\n            Current season\n        day_num : int\n            The day from the start of the season in which the game was played\n\n        Returns\n        -------\n        features : pd.Series\n            The team's features averaged over the previous n games\n        '''\n        # column names for winning or losing\n        if (team_id, season, day_num) not in self.cached:\n            won_columns = [c for c in self.games_df.columns if c[0] == 'W']\n            lost_columns = [c for c in self.games_df.columns if c[0] == 'L']\n            # mapping from old column names to new column names\n            won_renamed_columns = {c: c[1:] for c in won_columns}\n            lost_renamed_columns = {c: c[1:] for c in lost_columns}\n            # select all previous games for this team in the current season\n            lost_games = self.games_df[(self.games_df.LTeamID == team_id) &\n                                       (self.games_df.Season == season) &\n                                       (self.games_df.DayNum < day_num)]\n            won_games = self.games_df[(self.games_df.WTeamID == team_id) &\n                                      (self.games_df.Season == season) &\n                                      (self.games_df.DayNum < day_num)]\n            # drop the other teams statistics\n            lost_games = lost_games.drop(won_columns, axis=1)\n            won_games = won_games.drop(lost_columns, axis=1)\n            # rename the columns so they match and can be joined\n            lost_games = lost_games.rename(columns=lost_renamed_columns)\n            won_games = won_games.rename(columns=won_renamed_columns)\n            # join previous lost and won games\n            previous_games = pd.concat([lost_games, won_games], axis=0)\n            # sort by DayNum\n            sorted_games = previous_games.sort_values('DayNum', ascending=False)\n            self.cached[(team_id, season, day_num)] = sorted_games\n        else:\n            sorted_games = self.cached[(team_id, season, day_num)]\n        # remove unused columns\n        columns_to_remove = ['Season', 'DayNum', 'TeamID', 'NumOT']\n        n = self.n\n        if len(sorted_games) < self.n:\n            n = len(sorted_games)\n        last_n_games = sorted_games.iloc[:n, :]\n        last_n_games_features = last_n_games[last_n_games.columns.difference(columns_to_remove)]\n        if self.weighting == 'exp':\n            if n != 0:\n                exp_weights = [((1 - 0.9) / (1 - (0.9 ** n))) * ((0.9) ** (t - 1)) for t in range(1, n + 1)] \n                return last_n_games_features.multiply(exp_weights, axis='rows').sum(axis=0)\n        return last_n_games_features.mean(axis=0)\n\n    def fit(self, x, y):\n        return self\n    \n    def transform(self, x, testing=False):\n        new_rows = []\n        for i, row in tqdm(x.iterrows(), total=len(x), disable=not self.verbose):\n            if row.WTeamID < row.LTeamID:\n                lower = row.WTeamID\n                higher = row.LTeamID\n            else:\n                lower = row.LTeamID\n                higher = row.WTeamID\n            lower_id_features = self.get_features(lower, row.Season, row.DayNum)\n            higher_id_features = self.get_features(higher, row.Season, row.DayNum)\n            new_row_1 = lower_id_features - higher_id_features\n            new_rows.append(new_row_1)\n            # Doubles the amount of training data!\n            # Note that the target values are doubled during creation\n            # See `create_targets()` below\n            if not testing:\n                new_row_2 = higher_id_features - lower_id_features\n                new_rows.append(new_row_2)\n        ret = pd.DataFrame(new_rows)\n        return ret\n    \n    def set_params(self, **parameters):\n        for parameter, value in parameters.items():\n            setattr(self, parameter, value)\n        return self\n        \n        \ndef create_targets(full_data, testing=False):\n    targets = []\n    for i, row in full_data.iterrows():\n        if row.WTeamID < row.LTeamID:\n            targets.append(1)\n            if not testing:\n                targets.append(0)\n        else:\n            targets.append(0)\n            if not testing:\n                targets.append(1)\n    return pd.Series(targets)\n    \n    \ndef create_new_features(full_data):\n    to_remove = ['WScore', 'LScore', 'WFTM', 'WFTA', 'LFTM', 'LFTA',\n                 'WFGM3', 'WFGA3', 'LFGM3', 'LFGA3', 'WFGM', 'WFGA',\n                 'LFGM', 'LFGA', 'WLoc']\n    full_data['ScoreDiff'] = full_data.WScore - full_data.LScore\n    full_data['WFTrR'] = full_data.WFTM / full_data.WFTA\n    full_data['LFTrR'] = full_data.LFTM / full_data.LFTA\n    full_data['WFGR3'] = full_data.WFGM3 / full_data.WFGA3\n    full_data['LFGR3'] = full_data.LFGM3 / full_data.LFGA3\n    full_data['WFGR2'] = (full_data.WFGM - full_data.WFGM3) / (full_data.WFGA - full_data.WFGA3)\n    full_data['LFGR2'] = (full_data.LFGM - full_data.LFGM3) / (full_data.LFGA - full_data.LFGA3)\n    return full_data[full_data.columns.difference(to_remove)]","metadata":{"execution":{"iopub.execute_input":"2022-03-13T03:34:26.81936Z","iopub.status.busy":"2022-03-13T03:34:26.81907Z","iopub.status.idle":"2022-03-13T03:34:26.842768Z","shell.execute_reply":"2022-03-13T03:34:26.841502Z","shell.execute_reply.started":"2022-03-13T03:34:26.819334Z"},"id":"Dd40lwJE0FIN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to read in the data and construct our new features! These are:\n- `ScoreDiff`: Difference in score (WScore - LScore)\n- `FTrR`: Free throw rate\n- `FGR3`: 3-point field goal rate\n- `FGR2`: 2-point field goal rate\n- `OR`: Offensive rebounds\n- `DR`: Defensive rebounds\n- `Ast`: Assists\n- `Blk`: Blocks\n- `TO`: Turnovers\n- `Stl`: Steals\n- `PF`: Personal fouls\n","metadata":{"id":"0FHzhY680FIO"}},{"cell_type":"code","source":"tournament_games = pd.read_csv(STAGE_1_DIR + 'MNCAATourneyDetailedResults.csv')\nseason_games = pd.read_csv(STAGE_1_DIR + 'MRegularSeasonDetailedResults.csv')\n\n# Use 2016 and above for testing in stage 1\nfull_train_tournament = tournament_games[tournament_games.Season < 2016]\nfull_test_tournament = tournament_games[tournament_games.Season >= 2016]\n\nfull_train_season = season_games[season_games.Season < 2016]\nfull_test_season = season_games[season_games.Season >= 2016]\n\nfull_train = pd.concat([full_train_season, full_train_tournament])\nfull_test = pd.DataFrame(full_test_tournament)\n\ntarget_train = create_targets(full_train)\ntarget_test = create_targets(full_test, testing=True)\n\nfeatures_train = full_train\nfeatures_test = full_test\n\nseason_games = create_new_features(season_games)\n\nfull_train.head()","metadata":{"execution":{"iopub.execute_input":"2022-03-13T03:32:41.600012Z","iopub.status.busy":"2022-03-13T03:32:41.599786Z","iopub.status.idle":"2022-03-13T03:32:48.29623Z","shell.execute_reply":"2022-03-13T03:32:48.295419Z","shell.execute_reply.started":"2022-03-13T03:32:41.599984Z"},"id":"bOQm7uwB0FIP","outputId":"1c527fc8-939c-4217-eade-a974c76dc559"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see now that each matchup has a winning team, losing team, a day in which in took place, and the  season. This is what we will use to construct the features for both teams.\n\nHere the preprocessor expands a given matchup into the features to use for that matchup. Each matchup produces two training samples for the model. The first is the `lowerID - higherID` with a target corresponding to the lower ID team winning. The second is `higherID - lowerID` with the opposite target. Note that the preprocessor only transforms the features, the targets were determined in the previous section when they were created.","metadata":{"id":"TULouz_XOoCk"}},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef hyperparameter_search(n_list, estimator_list,\n                          train_features, train_targets,\n                          test_features, test_targets,\n                          season_games):\n    '''\n    This performs a search over a parameter space specified by the different options available for\n    both feature selection and model training.\n    It will return all of the scores and the best parameter combination.\n    '''\n    print(f'Starting search over\\nn: {n_list}\\nn_estimators: {estimator_list}')\n    accuracy_scores = {}\n    log_loss_scores = {}\n    best_score = float('inf')\n    best_params = None\n    preprocessor = Preprocessor(season_games, n=1, weighting='mean', verbose=False)\n    for method in ['exp', 'mean']:\n        accuracy_scores[method] = []\n        log_loss_scores[method] = []\n        preprocessor.method = method\n        print(f'Calculating scores for {method} method...')\n        for i, n in tqdm(enumerate(n_list), total=len(n_list)):\n            preprocessor.n = n\n            accuracy_scores[method].append([])\n            log_loss_scores[method].append([])\n            X_train = preprocessor.transform(train_features)\n            X_test = preprocessor.transform(test_features, testing=True)\n            X_train['Target'] = target_train\n            X_train = X_train.dropna()\n            X_train = X_train.sample(frac=1, random_state=1)\n            y_train = X_train.loc[:, 'Target']\n            X_train = X_train.loc[:, X_train.columns != 'Target']\n            for n_estimators in estimator_list:\n                model = RandomForestClassifier(n_estimators=n_estimators, criterion='entropy', random_state=2)\n                model.fit(X_train, y_train)\n                accuracy_score = model.score(X_test, test_targets)\n                log_loss_score = log_loss(test_targets, model.predict_proba(X_test))\n                accuracy_scores[method][i].append(accuracy_score)\n                log_loss_scores[method][i].append(log_loss_score)\n                if log_loss_score < best_score:\n                    best_score = log_loss_score\n                    best_params = (method, n, n_estimators)\n    return (accuracy_scores, log_loss_scores), best_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PERFORM_SEARCH = False\nif PERFORM_SEARCH:\n    n_list = list(range(1, 45, 6))\n    estimator_list = list(range(50, 600, 50))\n    (accuracy_scores, log_loss_scores), (method, n, n_estimators) = hyperparameter_search(n_list, estimator_list,\n                                                                                          features_train[:20000], target_train[:40000],\n                                                                                          features_test, target_test,\n                                                                                          season_games)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nif PERFORM_SEARCH:\n    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 20))\n    ax1.imshow(accuracy_scores['mean'])\n    ax1.set_title('Accuracy for the mean method')\n    ax1.set_ylabel('n')\n    ax1.set_xlabel('n_estimators')\n    ax1.set_yticks(range(len(n_list)), labels=n_list)\n    ax1.set_xticks(range(len(estimator_list)), labels=estimator_list)\n    ax2.imshow(accuracy_scores['exp'])\n    ax2.set_title('Accuracy for the exp method')\n    ax2.set_ylabel('n')\n    ax2.set_xlabel('n_estimators')\n    ax2.set_yticks(range(len(n_list)), labels=n_list)\n    ax2.set_xticks(range(len(estimator_list)), labels=estimator_list)\n    ax3.imshow(log_loss_scores['mean'])\n    ax3.set_title('Log loss for the mean method')\n    ax3.set_ylabel('n')\n    ax3.set_xlabel('n_estimators')\n    ax3.set_yticks(range(len(n_list)), labels=n_list)\n    ax3.set_xticks(range(len(estimator_list)), labels=estimator_list)\n    ax4.imshow(log_loss_scores['exp'])\n    ax4.set_title('Log loss for the exp method')\n    ax4.set_ylabel('n')\n    ax4.set_xlabel('n_estimators')\n    ax4.set_yticks(range(len(n_list)), labels=n_list)\n    ax4.set_xticks(range(len(estimator_list)), labels=estimator_list)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I forgot to check how many games are in a regular season schedule. It turns out that there are only 35-40 games. This is why past $n =37$ there is no improvement. A lot of wasted time and computation :(\n\nEither way, it looks like the best method was to use the entire season weighting by exponential decay.","metadata":{}},{"cell_type":"code","source":"n = 37\nmethod = 'exp'\nn_estimators = 450\nprint(f'Best Parameters: method = {method}, n = {n}, n_estimators = {n_estimators}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = Preprocessor(season_games, n=n, weighting=method, verbose=True)\n\nX_train = preprocessor.fit_transform(features_train, target_train)\nX_test = preprocessor.transform(features_test, testing=True)","metadata":{"execution":{"iopub.execute_input":"2022-03-13T03:32:48.306186Z","iopub.status.busy":"2022-03-13T03:32:48.30591Z","iopub.status.idle":"2022-03-13T03:32:48.329715Z","shell.execute_reply":"2022-03-13T03:32:48.328565Z","shell.execute_reply.started":"2022-03-13T03:32:48.306157Z"},"id":"dGQW1fmd0FIQ","outputId":"5652fb69-8c42-4ee7-afbb-95b32fd1b711"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['Target'] = target_train\nX_train = X_train.dropna()\nX_train = X_train.sample(frac=1, random_state=1)\ny_train = X_train.loc[:, 'Target']\nX_train = X_train.loc[:, X_train.columns != 'Target']\n\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"id":"8_FT9e0iOoCk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stage 1** - Model Training \nHere we build a simple random forest classifier. The best number of estimators was determined by the table below in the Model Testing section.","metadata":{"id":"TKU9vpxg0FIS"}},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=n_estimators, criterion='entropy', random_state=2)","metadata":{"id":"uWERsEUJOoCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{"id":"DOe8buJc0FIT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stage 1** - Model Testing\nHere we can get the accuracy score for tournament games.","metadata":{"id":"geDx8Mwq0FIU"}},{"cell_type":"code","source":"print(f'Performance of {n} previous games using a model with {n_estimators} estimators:')\nprint(f'Accuracy: {model.score(X_test, target_test)}')\nprint(f'Log Loss: {log_loss(target_test, model.predict_proba(X_test))}')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T03:34:55.388126Z","iopub.status.idle":"2022-03-13T03:34:55.388419Z","shell.execute_reply":"2022-03-13T03:34:55.388279Z","shell.execute_reply.started":"2022-03-13T03:34:55.388256Z"},"id":"uXPy0EeW0FIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stage 1** - Model Submission\nThis is the submission for Stage 1 of the Kaggle competition. It gives the probability that the lower ID team wins a given matchup. All games are tournament games from 2016 to 2021.","metadata":{"id":"4u-bcJ_d0FIW"}},{"cell_type":"code","source":"stage_1_submission = pd.read_csv(STAGE_1_DIR + 'MSampleSubmissionStage1.csv')\n\nstage_1_submission['Season'] = stage_1_submission.ID.str.split('_', expand=True).iloc[:, 0].astype('int')\nstage_1_submission['WTeamID'] = stage_1_submission.ID.str.split('_', expand=True).iloc[:, 1].astype('int')\nstage_1_submission['LTeamID'] = stage_1_submission.ID.str.split('_', expand=True).iloc[:, 2].astype('int')\nstage_1_submission['DayNum'] = [134 for _ in range(len(stage_1_submission))]\n\nX = preprocessor.transform(stage_1_submission, testing=True)\n\nnew_preds = model.predict_proba(X)[:, 1]\nstage_1_submission.Pred = new_preds\nstage_1_submission = stage_1_submission[\n    stage_1_submission.columns.difference(['Season', 'WTeamID', 'LTeamID', 'DayNum'])]","metadata":{"execution":{"iopub.status.busy":"2022-03-13T03:32:48.686391Z","iopub.status.idle":"2022-03-13T03:32:48.686827Z","shell.execute_reply":"2022-03-13T03:32:48.686681Z","shell.execute_reply.started":"2022-03-13T03:32:48.686664Z"},"id":"qu2F9L0x0FIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stage_1_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T03:32:48.687771Z","iopub.status.idle":"2022-03-13T03:32:48.688218Z","shell.execute_reply":"2022-03-13T03:32:48.688058Z","shell.execute_reply.started":"2022-03-13T03:32:48.688037Z"},"id":"jW9qxLmz0FIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stage_1_submission.to_csv(f'submission_{n}_{n_estimators}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T03:32:48.689554Z","iopub.status.idle":"2022-03-13T03:32:48.689989Z","shell.execute_reply":"2022-03-13T03:32:48.689843Z","shell.execute_reply.started":"2022-03-13T03:32:48.689826Z"},"id":"ubKjvt2Z0FIX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stage 2** - Model Training, Testing, & Submission\nNow we can train using all of the data! The procedure is exactly the same as before.","metadata":{}},{"cell_type":"code","source":"STAGE_2_DIR = './MDataFiles_Stage2/'\ntournament_games = pd.read_csv(STAGE_2_DIR + 'MNCAATourneyDetailedResults.csv')\nseason_games = pd.read_csv(STAGE_2_DIR + 'MRegularSeasonDetailedResults.csv')\n\n# Use 2016 and above for testing in stage 1\nfull_train_tournament = tournament_games\n\nfull_train_season = season_games\n\nfull_train = pd.concat([full_train_season, full_train_tournament])\n\ntarget_train = create_targets(full_train)\n\nfeatures_train = full_train\nseason_games = create_new_features(season_games)\n\nfull_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = Preprocessor(season_games, n=n, weighting=method, verbose=True)\n\nX_train = preprocessor.fit_transform(features_train, target_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['Target'] = target_train\nX_train = X_train.dropna()\nX_train = X_train.sample(frac=1, random_state=1)\ny_train = X_train.loc[:, 'Target']\nX_train = X_train.loc[:, X_train.columns != 'Target']\n\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=n_estimators, criterion='entropy', random_state=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stage_2_submission = pd.read_csv(STAGE_2_DIR + 'MSampleSubmissionStage2.csv')\n\nstage_2_submission['Season'] = stage_2_submission.ID.str.split('_', expand=True).iloc[:, 0].astype('int')\nstage_2_submission['WTeamID'] = stage_2_submission.ID.str.split('_', expand=True).iloc[:, 1].astype('int')\nstage_2_submission['LTeamID'] = stage_2_submission.ID.str.split('_', expand=True).iloc[:, 2].astype('int')\nstage_2_submission['DayNum'] = [134 for _ in range(len(stage_2_submission))]\n\nX = preprocessor.transform(stage_2_submission, testing=True)\n\nnew_preds = model.predict_proba(X)[:, 1]\nstage_2_submission.Pred = new_preds\nstage2 = stage_2_submission[\n    stage_2_submission.columns.difference(['Season', 'WTeamID', 'LTeamID', 'DayNum'])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stage2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stage2.to_csv(f'submission_{n}_{n_estimators}_stage2.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stage 2** - Model Predictions\nHere we will show all of the predictions that our model makes for each possible matchup.","metadata":{}},{"cell_type":"code","source":"id_df = pd.read_csv(STAGE_2_DIR + 'MTeams.csv')\nprint('If these two teams are playing each other, the one on the left has this chance of winning the matchup...')\nfor i, row in stage_2_submission.iterrows():\n    if row.WTeamID < row.LTeamID:\n        lower = row.WTeamID\n        higher = row.LTeamID\n    else:\n        lower = row.LTeamID\n        higher = row.WTeamID\n    lower_team_name = id_df[id_df.TeamID == lower].TeamName.iloc[0]\n    higher_team_name = id_df[id_df.TeamID == higher].TeamName.iloc[0]\n    print(f'{lower_team_name} vs. {higher_team_name}: {row.Pred}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}