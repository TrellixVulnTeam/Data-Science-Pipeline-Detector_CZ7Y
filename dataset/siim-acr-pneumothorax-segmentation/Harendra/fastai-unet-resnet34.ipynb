{"cells":[{"metadata":{},"cell_type":"markdown","source":"## References\nhttps://www.kaggle.com/mnpinto/pneumothorax-fastai-u-net\n\nNormalize with imagenet caused weird loss values so removed it\nadded TTA \n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n\nimport fastai\nfrom fastai.vision import *\nfrom mask_functions import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.callbacks import *\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SZ = 128\npath = Path(f'../input/pneumotorax{SZ}/data{SZ}/data{SZ}')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# copy pretrained weights for resnet34 to the folder fastai will search by default\nPath('/tmp/.cache/torch/checkpoints/').mkdir(exist_ok=True, parents=True)\n!cp '../input/resnet34/resnet34.pth' '/tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Setting div=True in open_mask\nclass SegmentationLabelList(SegmentationLabelList):\n    def open(self, fn): return open_mask(fn, div=True)\n    \nclass SegmentationItemList(SegmentationItemList):\n    _label_cls = SegmentationLabelList\n\n# Setting transformations on masks to False on test set\ndef transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n    if not tfms: tfms=(None,None)\n    assert is_listy(tfms) and len(tfms) == 2\n    self.train.transform(tfms[0], **kwargs)\n    self.valid.transform(tfms[1], **kwargs)\n    kwargs['tfm_y'] = False # Test data has no labels\n    if self.test: self.test.transform(tfms[1], **kwargs)\n    return self\n\nfastai.data_block.ItemLists.transform = transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef dice(input:Tensor, targs:Tensor, eps:float=1e-8)->Rank0Tensor:\n    input = input.clone()\n    targs = targs.clone()\n    n = targs.shape[0]\n    input = torch.softmax(input, dim=1).argmax(dim=1)\n    input = input.view(n, -1)\n    targs = targs.view(n, -1)\n    input[input == 0] = -999\n    intersect = (input == targs).sum().float()\n    union = input[input > 0].sum().float() + targs[targs > 0].sum().float()\n    del input, targs\n    gc.collect()\n    return ((2.0 * intersect + eps) / (union + eps)).mean()\n\ndef visualize_one(a, b, c, title):\n    fig, ax = plt.subplots(3, 1, figsize=(15, 7))\n    ax[0].set_title(title)\n    ax[0].imshow(a.permute(1, 2, 0))\n    ax[1].imshow(b.squeeze(), vmin=0, vmax=4)\n    ax[2].imshow(c.squeeze(), vmin=0, vmax=4)\n    ax[0].set_axis_off()\n    ax[1].set_axis_off()\n    ax[2].set_axis_off()\n    plt.show()\n    \ndef visualize_some():\n    n_batch = 0\n    for batch in learn.data.train_dl:\n        x, y = batch\n        n_batch += 1\n        if n_batch > 8:\n            break\n        for idx in range(bs):\n            predimg, pred, _ = learn.predict(Image(x[idx].cpu()))\n            visualize_one(x[idx], y[idx], pred, f\"Index: {idx}\")\n    plt.tight_layout()\n    \ndef print_stats(learn):\n    print(\"Plotting Losses\")\n    learn.recorder.plot_losses()\n    print(\"Plotting metrics\")\n    learn.recorder.plot_metrics()\n    print(\"Plotting LR\")\n    learn.recorder.plot_lr()\n    print(\"Validation losses\")\n    print(learn.recorder.val_losses)\n    print(\"Metrics\")\n    print(learn.recorder.metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create databunch\ndata = (SegmentationItemList.from_folder(path=path/'train')\n        .split_by_rand_pct(0.2)\n        .label_from_func(lambda x : str(x).replace('train', 'masks'), classes=[0, 1])\n        .add_test((path/'test').ls(), label=None)\n        .transform(get_transforms(), size=SZ, tfm_y=True)\n        .databunch(path=Path('.'), bs=32)\n       #        .normalize(imagenet_stats)\n       )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display some images with masks\ndata.show_batch(rows=3, figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create U-Net with a pretrained resnet34 as encoder\nlearn = unet_learner(data, models.resnet34, metrics=[dice],model_dir=\"/kaggle/working\",\n                    callback_fns=[partial(EarlyStoppingCallback, monitor='dice',\n                                          min_delta=0.01, patience=3)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit one cycle of 6 epochs with max lr of 1e-3\nlearn.fit_one_cycle(4,max_lr=1e3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unfreeze the encoder (resnet34)\nlearn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit one cycle of 12 epochs\n#lr = 1e-3\nlearn.fit_one_cycle(12, max_lr=slice(1e-5,1e-3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TTA and Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.core import *\nfrom fastai.basic_data import *\nfrom fastai.basic_train import *\nfrom fastai.torch_core import *\ndef _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset\n    old = ds.tfms\n    aug_tfms = [o for o in learn.data.train_ds.tfms]\n    try:\n        pbar = master_bar(range(num_pred))\n        for i in pbar:\n            ds.tfms = aug_tfms\n            yield get_preds(learn.model, dl, pbar=pbar)[0]\n    finally: ds.tfms = old\n\nLearner.tta_only = _tta_only\n\ndef _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10, with_loss:bool=False) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"\n    preds,y = learn.get_preds(ds_type)\n    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n    avg_preds = torch.stack(all_preds).mean(0)\n    if beta is None: return preds,avg_preds,y\n    else:            \n        final_preds = preds*beta + avg_preds*(1-beta)\n        if with_loss: \n            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n            return final_preds, y, loss\n        return final_preds, y\n\nLearner.TTA = _TTA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions for the validation set\npreds, ys = learn.get_preds()\npreds = preds[:,1,...]\nys = ys.squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_overall(preds, targs):\n    n = preds.shape[0]\n    preds = preds.view(n, -1)\n    targs = targs.view(n, -1)\n    intersect = (preds * targs).sum(-1).float()\n    union = (preds+targs).sum(-1).float()\n    u0 = union==0\n    intersect[u0] = 1\n    union[u0] = 2\n    return (2. * intersect / union)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find optimal threshold\ndices = []\nthrs = np.arange(0.01, 1, 0.01)\nfor i in progress_bar(thrs):\n    preds_m = (preds>i).long()\n    dices.append(dice_overall(preds_m, ys).mean())\ndices = np.array(dices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_dice = dices.max()\nbest_thr = thrs[dices.argmax()]\n\nplt.figure(figsize=(8,4))\nplt.plot(thrs, dices)\nplt.vlines(x=best_thr, ymin=dices.min(), ymax=dices.max())\nplt.text(best_thr+0.03, best_dice-0.01, f'DICE = {best_dice:.3f}', fontsize=14);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot some samples\nrows = 10\nplot_idx = ys.sum((1,2)).sort(descending=True).indices[:rows]\nfor idx in plot_idx:\n    fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n    ax0.imshow(data.valid_ds[idx][0].data.numpy().transpose(1,2,0))\n    ax1.imshow(ys[idx], vmin=0, vmax=1)\n    ax2.imshow(preds[idx], vmin=0, vmax=1)\n    ax1.set_title('Targets')\n    ax2.set_title('Predictions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions for test set\npreds, _ = learn.TTA(ds_type=DatasetType.Test)\npreds = (preds[:,1,...]>best_thr).long().numpy()\nprint(preds.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate rle encodings (images are first converted to the original size)\nrles = []\nfor p in progress_bar(preds):\n    im = PIL.Image.fromarray((p.T*255).astype(np.uint8)).resize((1024,1024))\n    im = np.asarray(im)\n    rles.append(mask2rle(im, 1024, 1024))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = [o.stem for o in data.test_ds.items]\nsub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\nsub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}