{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Phân đoạn Pneumothorax (tràn khí màng phổi)\n\n## Tổng quan bài toán\n\nTrong dự án này, sẽ phải phân đoạn được đâu là phần tràn khí màng phổi từ hình ảnh X-quang đã được gán nhãn trước.\n\nDữ liệu bao gồm có 12955 hình X-quang từ 12047 bệnh nhân và nhãn tương ứng (có những hình ảnh có nhãn, có những hình ảnh không có nhãn tức là không bị chứng tràn khí màng phổi)."},{"metadata":{},"cell_type":"markdown","source":"## Mục tiêu\n\n* Đào tạo mô hình segment dựa trên Unet với các backbone:\n    * Resnet50\n    * Efficientnet\n    * Xceptionnet\n* Thử nghiệm các phương pháp augumentation trên hình ảnh X-Quang\n* Đánh giá mô hình:\n    * Trên metrics dice score\n    * Đánh giá cho từng mô hình với các backbone khác nhau"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import libraries\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as image\nfrom tqdm.notebook import tqdm\nimport glob\nimport pydicom\nimport sys\nimport os\n\nprint(os.listdir(\"../input/siim-acr-pneumothorax-segmentation\"))\nprint()\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n\nfrom mask_functions import rle2mask\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install libraries for augumentation image and\n# visualize architecture model Unet\n!pip install albumentations\n!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn \nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchsummary import summary\nimport torchvision.models as models\nimport torchvision.transforms as T\nimport albumentations as A\n\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load information for dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load information for dataset\ntrain_df = pd.read_csv(\"../input/segment-data/train_info_split.csv\")\nval_df = pd.read_csv(\"../input/segment-data/val_info_split.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load all path for file .dcm\nfile_path = \"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/*/*/*.dcm\"\nfile_paths = glob.glob(file_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize image origin and mask with file .dcm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize image mask for file .dcm\nimage_id_arr = train_df[\"ImageId\"].unique()\n\nfor index, image_id in enumerate(image_id_arr):\n    index_ = list(filter(lambda x: image_id in file_paths[x], range(len(file_paths))))\n    dataset = pydicom.dcmread(file_paths[index_[0]])\n    image_data = dataset.pixel_array\n    \n    record_arr = train_df[train_df[\"ImageId\"]==image_id]\n    # Visualize patient has multi segment\n    if len(record_arr) >= 2:\n        fig, (ax1, ax2) = plt.subplots(1, 2)\n        fig.set_figheight(15)\n        fig.set_figwidth(15)\n        ax1.imshow(image_data, cmap=plt.cm.bone)\n        ax2.imshow(image_data, cmap=plt.cm.bone)\n        mask = np.zeros((1024, 1024))\n        for _, row in record_arr.iterrows():\n            if row[\"EncodedPixels\"] != ' -1':\n                mask_ = rle2mask(row[\"EncodedPixels\"], 1024, 1024).T\n                mask[mask_==255] = 255\n        \n        ax2.imshow(mask, alpha=0.3, cmap=\"Blues\")    \n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Khởi tạo kiến trúc mô hình"},{"metadata":{},"cell_type":"markdown","source":"### Các hàm trợ giúp"},{"metadata":{"trusted":true},"cell_type":"code","source":"def toTensor(np_array, axis=(2,0,1)):\n    return torch.tensor(np_array).permute(axis)\n\ndef toNumpy(tensor, axis=(1,2,0)):\n    return tensor.detach().cpu().permute(axis).numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tạo Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize image mask for file .dcm\nimage_id_arr = train_df[\"ImageId\"].unique()\n\nfor index, image_id in enumerate(image_id_arr):\n    index_ = list(filter(lambda x: image_id in file_paths[x], range(len(file_paths))))\n    dataset = pydicom.dcmread(file_paths[index_[0]])\n    image_data = dataset.pixel_array\n    \n    record_arr = train_df[train_df[\"ImageId\"]==image_id]\n    # Visualize patient has multi segment\n    if len(record_arr) >= 2:\n        fig, (ax1, ax2) = plt.subplots(1, 2)\n        fig.set_figheight(15)\n        fig.set_figwidth(15)\n        ax1.imshow(image_data, cmap=plt.cm.bone)\n        ax2.imshow(image_data, cmap=plt.cm.bone)\n        mask = np.zeros((1024, 1024))\n        for _, row in record_arr.iterrows():\n            if row[\"EncodedPixels\"] != ' -1':\n                mask_ = rle2mask(row[\"EncodedPixels\"], 1024, 1024).T\n                mask[mask_==255] = 255\n        \n        ax2.imshow(mask, alpha=0.3, cmap=\"Blues\")    \n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_infor(df):\n    infor = []\n    image_id_arr = df[\"ImageId\"].unique()\n    for index, image_id in tqdm(enumerate(image_id_arr)):\n        index_ = list(filter(lambda x: image_id in file_paths[x], range(len(file_paths))))\n        full_image_path = file_paths[index_[0]]\n\n        # Get all segment encode\n        record_arr = train_df[train_df[\"ImageId\"]==image_id]\n        encode_pixels = []\n        for _, row in record_arr.iterrows():\n            encode_pixels.append(row[\"EncodedPixels\"])\n\n        infor.append({\n            \"key\": image_id,\n            \"file_path\": full_image_path,\n            \"mask\": encode_pixels\n        })\n    return infor\n\nprint(\"Loading information for training set \\n\")\ntrain_infor = get_infor(train_df)\nprint(\"Loading information for validation set \\n\")\nval_infor = get_infor(val_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nclass MaskDataset(Dataset):\n    def __init__(self, df, img_info, transforms=None):\n        self.df = df\n        self.img_info = img_info\n        self.transforms = transforms\n        \n    def __getitem__(self, idx):\n        img_path = self.img_info[idx][\"file_path\"]\n        key = self.img_info[idx][\"key\"]\n        \n        # load image data\n        dataset = pydicom.dcmread(img_path)\n        img = dataset.pixel_array\n        img = cv2.resize(img, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n        \n        mask_arr = self.img_info[idx][\"mask\"]\n        \n        mask = np.zeros((512, 512))\n        \n        for item in mask_arr:\n            if item != \" -1\":\n                mask_ = rle2mask(item, 1024, 1024).T\n                mask_ = cv2.resize(mask_, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n                mask[mask_==255] = 255\n\n        # to Tensor\n        mask = np.expand_dims(mask, axis=-1)/255.0\n        mask = toTensor(mask).float()\n        \n        img = np.expand_dims(img, axis=-1)/255.0\n        img = toTensor(img).float()\n        \n        return img, mask\n            \n    def __len__(self):\n        return len(self.img_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = MaskDataset(train_df, train_infor)\ntrain_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, drop_last=True)\n\nval_dataset = MaskDataset(val_df, val_infor)\nval_loader = DataLoader(val_dataset, batch_size=10, shuffle=True, drop_last=True)\n\nnumber_visualize = 1\nfor img, mask in train_dataset:\n    if number_visualize > 5:\n        break\n    img = toNumpy(img)[:,:,0]\n    mask = toNumpy(mask)[:,:,0]\n\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    ax1.imshow(img, cmap=plt.cm.bone)\n    ax2.imshow(img, cmap=plt.cm.bone)\n    ax2.imshow(mask, alpha=0.3, cmap=\"Blues\")\n    number_visualize += 1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Định nghĩa hàm đo dice score và tính toán dice loss"},{"metadata":{},"cell_type":"markdown","source":"Đọc trong: [jeremyjordan semantic-segmentation](https://www.jeremyjordan.me/semantic-segmentation/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary\nimport os\nimport cv2\nimport pandas\nimport numpy as np\nfrom tqdm import tqdm\nfrom glob import glob\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom random import choice, choices, shuffle\n\nimport torch\nimport torchvision\nimport torch.nn as nn \nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchsummary import summary\nimport torchvision.models as models\nimport torchvision.transforms as T\nfrom sklearn.model_selection import train_test_split\nfrom random import randint\nimport albumentations as A\nfrom PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Deconv(n_input, n_output, k_size=4, stride=2, padding=1):\n    Tconv = nn.ConvTranspose2d(\n        n_input, n_output,\n        kernel_size=k_size,\n        stride=stride, padding=padding,\n        bias=False)\n    block = [\n        Tconv,\n        nn.BatchNorm2d(n_output),\n        nn.LeakyReLU(inplace=True),\n    ]\n    return nn.Sequential(*block)\n        \n\ndef Conv(n_input, n_output, k_size=4, stride=2, padding=0, bn=False, dropout=0):\n    conv = nn.Conv2d(\n        n_input, n_output,\n        kernel_size=k_size,\n        stride=stride,\n        padding=padding, bias=False)\n    block = [\n        conv,\n        nn.BatchNorm2d(n_output),\n        nn.LeakyReLU(0.2, inplace=True),\n        nn.Dropout(dropout)\n    ]\n    return nn.Sequential(*block)\n\nclass Unet(nn.Module):\n    def __init__(self, resnet):\n        super().__init__()\n        \n        self.conv1 = resnet.conv1\n        self.bn1 = resnet.bn1\n        self.relu = resnet.relu\n        self.maxpool = resnet.maxpool\n        self.tanh = nn.Tanh()\n        self.sigmoid = nn.Sigmoid()\n        \n        # get some layer from resnet to make skip connection\n        self.layer1 = resnet.layer1\n        self.layer2 = resnet.layer2\n        self.layer3 = resnet.layer3\n        self.layer4 = resnet.layer4\n        \n        # convolution layer, use to reduce the number of channel => reduce weight number\n        self.conv_5 = Conv(2048, 512, 1, 1, 0)\n        self.conv_4 = Conv(2048, 1024, 1, 1, 0)\n        self.conv_3 = Conv(1024, 512, 1, 1, 0)\n        self.conv_2 = Conv(512, 128, 1, 1, 0)\n        self.conv_1 = Conv(128, 64, 1, 1, 0)\n        self.conv_0 = Conv(32, 1, 1, 1, 0)\n        \n        # deconvolution layer\n        self.deconv4 = Deconv(512, 1024, 3, 2, 1)\n        self.deconv3 = Deconv(1024, 512, 3, 2, 1)\n        self.deconv2 = Deconv(512, 256, 3, 2, 1)\n        self.deconv1 = Deconv(128, 64, 4, 2, 1)\n        self.deconv0 = Deconv(64, 32, 2, 2, 2)\n        \n        \n    def forward(self, x):\n        # down sample\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        skip_1 = x\n        \n        x = self.maxpool(x)\n        x = self.layer1(x)\n        skip_2 = x\n\n        x = self.layer2(x)\n        skip_3 = x\n        x = self.layer3(x)\n        skip_4 = x\n        \n        x5 = self.layer4(x)\n        x5 = self.conv_5(x5)\n        \n        # up sample\n        x4 = self.deconv4(x5)\n        x4 = torch.cat([x4, skip_4], dim=1)\n        x4 = self.conv_4(x4)\n        \n        x3 = self.deconv3(x4)\n        x3 = torch.cat([x3, skip_3], dim=1)\n        x3 = self.conv_3(x3)\n        x2 = self.deconv2(x3)\n        \n        x2 = torch.cat([x2, skip_2], dim=1)\n        x2 = self.conv_2(x2)\n        \n        x1 = self.deconv1(x2)\n        x1 = torch.cat([x1, skip_1], dim=1)\n        x1 = self.conv_1(x1)\n        \n        x0 = self.deconv0(x1)\n        x0 = self.conv_0(x0)\n        x0 = self.sigmoid(x0)\n        return x0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel_ft = models.resnet50(pretrained=True)\nmodel_ft.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3), bias=False)\n\nmodel = Unet(model_ft)\nmodel.to(device)\n\nfor i, child in enumerate(model.children()):\n    if i <= 7:\n        for param in child.parameters():\n            param.requires_grad = False\n\nprint(summary(model,input_size=(1,512,512)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nimport torch.nn as nn\n\ndef get_dice_score(inputs, targets, smooth=1):\n    intersection = (inputs * targets).sum((3,2,1))                            \n    dice_scores = (2.*intersection + smooth)/(inputs.sum((3,2,1)) + targets.sum((3,2,1)) + smooth)   \n    dice_score = dice_scores.mean()\n    \n    return dice_score, dice_scores\n\ndef loss_function(inputs, targets, smooth=1):\n    # soft dice loss\n    intersection = (inputs * targets).sum((3,2,1))                            \n    dice = (2.*intersection + smooth)/((inputs**2).sum((3,2,1)) + (targets**2).sum((3,2,1)) + smooth)   \n    dice_loss = 1 - dice.mean()\n    # binary cross entropy\n    BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n    # overall loss\n    loss = dice_loss + BCE\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\n# free_gpu_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\ntrain_params = [param for param in model.parameters() if param.requires_grad]\noptimizer = torch.optim.Adam(train_params, lr=0.001, betas=(0.9, 0.99))\n\nepochs = 100\nmodel.train()\nsaved_dir = \"model\"\nos.makedirs(saved_dir, exist_ok=True)\npath_csv_history = \"./model/history.csv\"\n\nwith open(path_csv_history, mode='w') as csv_file:\n    fieldnames = ['train_dice_score', 'val_dice_score']\n    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n\n    writer.writeheader()\n    for epoch in range(epochs):\n        number_iter = 0\n        train_dice_score = []\n        for imgs, masks in tqdm(train_loader):\n            optimizer.zero_grad()\n            imgs_gpu = imgs.to(device)\n            outputs = model(imgs_gpu)\n            # outputs = F.sigmoid(outputs) \n            masks = masks.to(device)\n            \n            _, dice_scores = get_dice_score(outputs, masks)\n            \n            loss = loss_function(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            \n            train_dice_score.extend(dice_scores)\n        train_dice_score = torch.mean(torch.stack(train_dice_score))\n        print(f\"Epoch {epoch}, Dice score in training set: {train_dice_score:0.4f}\")\n            \n        # free_gpu_cache()\n        val_dice_score = []\n        with torch.no_grad():\n            for imgs, masks in tqdm(val_loader):\n                imgs_gpu = imgs.to(device)\n                outputs = model(imgs_gpu)\n                outputs = F.sigmoid(outputs) \n                masks = masks.to(device)\n\n                _, dice_scores = get_dice_score(outputs, masks)\n                val_dice_score.extend(dice_scores)\n            val_dice_score = torch.mean(torch.stack(val_dice_score))\n            print(f\"Epoch {epoch}, Dice score in validation set: {val_dice_score:0.4f}\")\n            path = \"./model/model_unet_epoch_{:.1f}_dice_score_{:0.4f}\".format(epoch, val_dice_score.mean())\n            torch.save(model.state_dict(), path)\n        \n        writer.writerow({\n            \"train_dice_score\": train_dice_score,\n            \"val_dice_score\": val_dice_score\n        })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}