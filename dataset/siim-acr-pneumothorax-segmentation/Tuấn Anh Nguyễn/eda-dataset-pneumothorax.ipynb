{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Phân đoạn Pneumothorax (tràn khí màng phổi)"},{"metadata":{},"cell_type":"markdown","source":"## Tổng quan bài toán"},{"metadata":{},"cell_type":"markdown","source":"Trong dự án này, sẽ phải phân đoạn được đâu là phần tràn khí màng phổi từ hình ảnh X-quang đã được gán nhãn trước.\n\nDữ liệu bao gồm có 12955 hình X-quang từ 12047 bệnh nhân và nhãn tương ứng (có những hình ảnh có nhãn, có những hình ảnh không có nhãn tức là không bị chứng tràn khí màng phổi)."},{"metadata":{},"cell_type":"markdown","source":"## Các bước thực hiện dự án\n\n### 1. Phân tích và khám phá dữ liệu (EDA)\n\nPhần đầu tập trung vào việc phân tích và khám phá dữ liệu để có thể hiểu và mô tả được nội dung và bản chất của dữ liệu.\n\nEDA rất quan trọng khi nó có thể giúp tăng độ chính xác mô hình nếu phân tích dữ liệu tốt và có thể làm báo cáo về sau. Một số thông tin mà lúc làm EDA có thể làm đó là:\n* Dữ liệu nhân khẩu học của bệnh nhân:\n        * Giới tính\n        * Tuổi\n        * ... các thông tin này là có sẵn\n* X-ray view (góc chụp của hình ảnh X-quang)\n* Các thông tin:\n        * Số lượng các ca bệnh mắc tràn khí phổi\n        * Số lượng các ca bệnh không bị mắc tràn khí phổi\n* Sự phân bố các ca bệnh theo:\n        * Độ tuổi\n        * Giới tính\n        * ...\n* Đánh giá mức pixel giữa trạng thái khỏe mạnh và trạng thái bị bệnh trong bộ dữ liệu (ví dụ: biểu đồ các giá trị cường độ) và so sánh phân bố giữa các loại này\n\n### 2. Xây dựng và đào tạo mô hình\n\n**Training and Validation Datasets**\n\nTừ các phát hiện trong phần EDA, hãy sắp xếp các tập train và validation sao cho phù hợp để có thể phân đoạn được bệnh. Hãy chắc chắn xem xét các điều kiện sau:\n* Thông tin nhân khẩu học, vị trí chụp hình ảnh, và số lượng hình ảnh theo độ tuổi và giới tính, ...\n* Phân bố giữa các trường hợp dương tính và âm tính trong mỗi tập dữ liệu\n\n**Kiến trúc mô hình**:\n\nTrong dự án này, có thể sử dụng việc tinh chỉnh kiến trúc Unet3D để có thể phân đoạn được vị trí tràn khí màng phổi. Việc tinh chỉnh có thể đến từ việc đóng băng một số lớp đầu và đào tạo các lớp phía sau.\n\n**Xử lý trước và tăng cường dữ liệu**:\n\nTiền xử lý trước dữ liệu trước khi đưa vào mạng để đào tạo và xác thực. Điều này có tác dụng giúp phù hợp với kiến trúc mô hình hơn, dễ đào tạo hơn để có thể tăng được hiệu suất của mô hình. Ngoài ra, có thể tăng cường dữ liệu và phải chú ý đến các thông số phản ánh được sự khác biệt có thể đến từ thế giới thực có thể nhận được khi chụp hình ảnh X-Quang.\n\n**Đào tạo**:\n\nTrong quá trình đào tạo, có nhiều tham số cần tinh chỉnh bao gồm:\n* Các tham số trong quá trình tăng cường dữ liệu\n* Batch_size\n* Learning rate\n* Các tham số của từng lớp cụ thể trong mạng\n\nCần phải mô tả được các phương pháp và tham số đã sử dụng sau khi đánh giá hiệu suất của mô hình.\n\n### 3. Tích hợp quy trình làm việc lâm sàng\n\nDữ liệu hình ảnh được cung cấp để thực hiện đào tạo mô hình đang trong dạng DICOM. Trong dự án này, hãy tạo một DICOM wrapper có thể nhận các tệp DICOM chuẩn, và xuất dữ liệu ở định dạng mà mô hình có thể chấp nhận được."},{"metadata":{},"cell_type":"markdown","source":"# Thực hiện dự án"},{"metadata":{},"cell_type":"markdown","source":"## Khám phá và phân tích dữ liệu (EDA)\n\nEDA là một bước rất quan trọng giúp hiểu được bản chất của dữ liệu từ đó có thể giúp quá trình tiếp cận vấn đề và đưa ra hướng giải quyết được đúng và chính xác. Ví dụ, EDA trong dự án này có thể giúp phát hiện ra được các biểu hiện của tràn khí màng phổi trong tự nhiên. Ví dụ như: tần suất xuất hiện là bao nhiêu, độ tuổi chịu ảnh hưởng của loại bệnh này, ... \n\nCác việc cần EDA trên tập dữ liệu này bao gồm có:\n* Dữ liệu về nhân khẩu học như giới tính, tuổi, vị trí đặt bệnh nhân, ...\n* Các chế độ khi chụp ảnh X-Quang (vị trí chụp, ... )\n* Số trường hợp:\n    * Số lượng trường hợp bị tràn khí màng phổi\n    * Số lượng trường hợp không bị tràn khí màng phổi\n* Sự phân bố của các trường hợp tràn khí màng phổi đối với độ tuổi\n* Sự phân bố của các trường hợp tràn khí màng phổi đối với giới tính\n* Đánh giá mức pixel của dữ liệu hình ảnh cho các trạng thái khỏe mạnh và bệnh tật cần quan tâm (ví dụ như biểu đồ về các giá trị cường độ và so sánh sự phân bố này).\n\nNgoài ra, sau khi đã thực hiện EDA, hãy mô tả cách thiết lập tập training và testing cho bộ dữ liệu."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n##Import any other packages you may need here\nimport matplotlib.image as image\nimport os\nimport glob\n\nimport pydicom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_dcm_info(dataset):\n    storage_type = dataset.SOPClassUID\n    \n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    \n    pat_id = dataset.PatientID\n    pat_age = dataset.PatientAge\n    pat_sex = dataset.PatientSex\n    modality = dataset.Modality\n    body_part_examined = dataset.BodyPartExamined\n    view_position = dataset.ViewPosition\n    rows = None\n    cols = None\n    pixel_spacing = None\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        if 'PixelSpacing' in dataset:\n            pixel_spacing = dataset.PixelSpacing\n    \n    meta_data = {\n        \"storage_type\": storage_type,\n        \"display_name\": display_name,\n        \"pat_age\": pat_age,\n        \"pat_sex\": pat_sex,\n        \"modality\": modality,\n        \"body_part_examined\": body_part_examined,\n        \"view_position\": view_position,\n        \"rows\": rows,\n        \"cols\": cols,\n        \"pixel_spacing_x\": pixel_spacing[0],\n        \"pixel_spacing_y\": pixel_spacing[1]\n    }\n    \n    return meta_data \n\ndef plot_pixel_array(dataset, figsize=(10,10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_csv = \"../input/siim-acr-pneumothorax-segmentation-data/train-rle.csv\"\ndf = pd.read_csv(path_csv)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = \"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-test/1.2.276.0.7230010.3.1.2.8323329.5797.1517875190.762693/1.2.276.0.7230010.3.1.3.8323329.5797.1517875190.762692/1.2.276.0.7230010.3.1.4.8323329.5797.1517875190.762694.dcm\"\ndataset = pydicom.dcmread(file_path)\nmeta_data = show_dcm_info(dataset)\nmeta_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tqdm.notebook import tqdm\n\n# new_df = pd.DataFrame({\n#     \"ImageId\": [],\n#     \"EncodedPixels\": [],\n#     \"storage_type\": [],\n#     \"display_name\": [],\n#     \"pat_age\": [],\n#     \"pat_sex\": [],\n#     \"modality\": [],\n#     \"body_part_examined\": [],\n#     \"view_position\": [],\n#     \"rows\": [],\n#     \"cols\": [],\n#     \"pixel_spacing_x\": [],\n#     \"pixel_spacing_y\": []\n# })\n\n# file_path = \"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/*/*/*.dcm\"\n\n# file_paths = glob.glob(file_path)\n\n# for index, row in tqdm(df.iterrows()):\n    \n#     index_ = list(filter(lambda x: row[0] in file_paths[x], range(len(file_paths))))\n#     dataset = pydicom.dcmread(file_paths[index_[0]])\n#     meta_data = show_dcm_info(dataset)\n\n#     data = {\n#         \"ImageId\": file_paths[index_[0]].split(\"/\")[4],\n#         \"EncodedPixels\": row[1],\n#         \"storage_type\": meta_data[\"storage_type\"],\n#         \"display_name\": meta_data[\"display_name\"],\n#         \"pat_age\": meta_data[\"pat_age\"],\n#         \"pat_sex\": meta_data[\"pat_sex\"],\n#         \"modality\": meta_data[\"modality\"],\n#         \"body_part_examined\": meta_data[\"body_part_examined\"],\n#         \"view_position\": meta_data[\"view_position\"],\n#         \"rows\": meta_data[\"rows\"],\n#         \"cols\": meta_data[\"cols\"],\n#         \"pixel_spacing_x\": meta_data[\"pixel_spacing_x\"],\n#         \"pixel_spacing_y\": meta_data[\"pixel_spacing_y\"]\n#     }\n    \n#     new_df = new_df.append(data, ignore_index=True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_df.to_csv('train_info.csv', header=True, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_xray_df = pd.read_csv('../input/segment-data/train_info.csv')\nall_xray_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_xray_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Phân tích phân phối của các trường thuộc tính"},{"metadata":{},"cell_type":"markdown","source":"#### Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"h = all_xray_df['pat_age'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"over100 = all_xray_df[all_xray_df['pat_age'] > 100]\nprint(len(over100))\nover100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Có 2 records chứa giá trị tuổi trên 100. Đây rõ ràng là nhầm lẫn, cách đơn giản là đặt nó về giá trị 100, vì điều này ít nhất cũng cho hai bản ghi này nằm về cùng một giá trị có thể."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_xray_df['pat_age'] = all_xray_df.apply(lambda x: 101 if x['pat_age'] > 100 else x['pat_age'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"over100 = all_xray_df[all_xray_df['pat_age'] > 100]\nprint(len(over100))\nover100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = all_xray_df['pat_age'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Phân phối tuổi của bệnh nhân gần giống phân phối chuẩn với việc hơi lệch phải một chút, đỉnh của phân phối cao nhất là tầm 58 tuổi."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_xray_df[all_xray_df['pat_age'] <= 100][['pat_age']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Khoảng dao động của tuổi bệnh nhân nằm trong khoảng từ 1 cho đến 94."},{"metadata":{},"cell_type":"markdown","source":"#### Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_m = all_xray_df[all_xray_df['pat_sex'] == 'M']\ngender_f = all_xray_df[all_xray_df['pat_sex'] == 'F']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(['Male','Female'], [len(gender_m), len(gender_f)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Patien Gender distribution\\nMale: {len(gender_m)} ({100.0*len(gender_m)/len(all_xray_df):.2f}%), Female: {len(gender_f)} ({100.0*len(gender_f)/len(all_xray_df):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Số lượng về giới tính của bệnh nhân cũng không bị bias quá nhiều về lớp nào cả, cả hai lớp này khá đồng đều (tương đối)."},{"metadata":{},"cell_type":"markdown","source":"#### View Position"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_xray_df['view_position'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npos_pa = all_xray_df[all_xray_df['view_position'] == 'PA']\npos_ap = all_xray_df[all_xray_df['view_position'] == 'AP']\nplt.bar(['PA','AP'], [len(pos_pa), len(pos_ap)])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'View position value distribution\\nPA: {len(pos_pa)} ({100.0*len(pos_pa)/len(all_xray_df):.2f}%), AP: {len(pos_ap)} ({100.0*len(pos_ap)/len(all_xray_df):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cảm giác hai lớp này có sự bias nhẹ! Thiên về lớp PA"},{"metadata":{},"cell_type":"markdown","source":"#### Số lượng bệnh/không bị bệnh"},{"metadata":{"trusted":true},"cell_type":"code","source":"finding = all_xray_df[all_xray_df['EncodedPixels'] != ' -1']\nno_finding = all_xray_df[all_xray_df['EncodedPixels'] == ' -1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of sick value distribution\\nfinding: {len(finding)} ({100.0*len(finding)/len(all_xray_df):.2f}%), no finding: {len(no_finding)} ({100.0*len(no_finding)/len(all_xray_df):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(['finding','no finding'], [len(finding), len(no_finding)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Có thể thấy đã xuất hiện hiện tượng bị bias. Số lượng no finding nhiều hơn rất nhiều so với số lượng finding. Cần phải giải quyết vấn đề mất cân bằng này. Một trong nhưng cách đó là:\n* Giảm bớt số lượng no-finding về gần với finding\n* Áp dụng các kĩ thuật tăng cường dữ liệu đối với lớp finding"},{"metadata":{},"cell_type":"markdown","source":"#### Patient ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_patients_num = all_xray_df['display_name'].nunique()\nprint(f'Total unique patients: {unique_patients_num}, average number records per patient: {len(all_xray_df)/unique_patients_num :.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"records_per_patient = []\nfor pid in all_xray_df['display_name'].unique():\n    records_per_patient.append(len(all_xray_df[all_xray_df['display_name'] == pid]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(np.array(records_per_patient), return_counts=True)\nplt.bar(unique, counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def num_patients_with_records(num):\n    return (np.array(records_per_patient) == num*np.ones(len(records_per_patient))).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,11):\n    print(f'Number of patients with {i} records in the dataset: {num_patients_with_records(i)} ({100.0*num_patients_with_records(i)/unique_patients_num :.2f})')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Số lượng 1 bệnh nhân chỉ có một records tương ứng với việc một bệnh nhân chỉ có 1 phát hiện segment là nhiều nhất. Còn lại, số lượng 2, 3, ...  phân đoạn segment thì ít hơn và có trường hợp outline là có 10 phân đoạn segment cho một bệnh  Tuy nhiên tập trung nhiều vào trường hợp 1 nên cũng không cần quá quan tâm đến hiện tượng bias ở đây, hoặc nếu muốn xử lý thì chỉ nên xử lý phần có 2 segment."},{"metadata":{},"cell_type":"markdown","source":"#### Image width & Height, pixel spacing"},{"metadata":{"trusted":true},"cell_type":"code","source":"desc = all_xray_df.describe()\ndesc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_min_max_values(col, name):\n    print(f'{name} range: [{desc[col][\"min\"]}, {desc[col][\"max\"]}]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_min_max_values('rows', 'Image Width')\nshow_min_max_values('cols', 'Image Height')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_min_max_values('pixel_spacing_x', 'Pixel Spacing over X')\nshow_min_max_values('pixel_spacing_y', 'Pixel Spacing over Y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kích thước hình ảnh cũng như pixel spacing đối với các hình ảnh khác nhau không khác biệt, nên phần này không cần xử lý trước."},{"metadata":{},"cell_type":"markdown","source":"#### Kiểm tra rage age nằm trong khoảng nào đối với bệnh nhân bị bệnh"},{"metadata":{"trusted":true},"cell_type":"code","source":"finding = all_xray_df[all_xray_df['EncodedPixels'] != ' -1']\nno_finding = all_xray_df[all_xray_df['EncodedPixels'] == ' -1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding[finding['pat_age'] <= 100][['pat_age']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_finding[no_finding['pat_age'] <= 100][['pat_age']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2)\nfig.set_figheight(5)\nfig.set_figwidth(10)\nax1.title.set_text(\"Range Age For Finding\")\nax1.hist(finding['pat_age'], bins = 100)\nax2.title.set_text(\"Range Age For No Finding\")\nax2.hist(no_finding['pat_age'], bins = 100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Có thể thấy khoảng độ tuổi mắc tràn khí phổi trải gần đều từ 19 cho đến 63 tuổi, trong khi đối với những trường hợp không bị mắc thì lại tập trung vào khoảng 58 tuổi."},{"metadata":{},"cell_type":"markdown","source":"#### Kiểm tra phân bố giới tính với bị bệnh/ko bị bệnh"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_m = finding[finding['pat_sex'] == 'M']\ngender_f = finding[finding['pat_sex'] == 'F']\nplt.bar(['M','F'], [len(gender_m), len(gender_f)])\nprint(f'Patien Gender distribution\\nMale: {len(gender_m)} ({100.0*len(gender_m)/len(all_xray_df):.2f}%), Female: {len(gender_f)} ({100.0*len(gender_f)/len(all_xray_df):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_m = no_finding[no_finding['pat_sex'] == 'M']\ngender_f = no_finding[no_finding['pat_sex'] == 'F']\nplt.bar(['M','F'], [len(gender_m), len(gender_f)])\nprint(f'Patien Gender distribution\\nMale: {len(gender_m)} ({100.0*len(gender_m)/len(all_xray_df):.2f}%), Female: {len(gender_f)} ({100.0*len(gender_f)/len(all_xray_df):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Phân bố theo giới tính có vẻ khá đồng đều, không bị bias quá về lớp nào cả."},{"metadata":{},"cell_type":"markdown","source":"#### Kiểm tra phân bố theo view position với bị bệnh/ko bị bệnh"},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_pa = finding[finding['view_position'] == 'PA']\npos_ap = finding[finding['view_position'] == 'AP']\nplt.bar(['PA','AP'], [len(pos_pa), len(pos_ap)])\nprint(f'View position value distribution\\nPA: {len(pos_pa)} ({100.0*len(pos_pa)/len(finding):.2f}%), AP: {len(pos_ap)} ({100.0*len(pos_ap)/len(finding):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npos_pa = no_finding[no_finding['view_position'] == 'PA']\npos_ap = no_finding[no_finding['view_position'] == 'AP']\nplt.bar(['PA','AP'], [len(pos_pa), len(pos_ap)])\nprint(f'View position value distribution\\nPA: {len(pos_pa)} ({100.0*len(pos_pa)/len(no_finding):.2f}%), AP: {len(pos_ap)} ({100.0*len(pos_ap)/len(no_finding):.2f}%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Đối với trường hợp có bệnh, view position có vẻ hơi bị bias một chút về lớp PA, trong khi đó, những trường hợp không bị bệnh, việc bias này không đáng kể."},{"metadata":{},"cell_type":"markdown","source":"#### Phân tích theo mức pixel"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = all_xray_df.sample(1000)\nsample_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding_sample = sample_df[sample_df['EncodedPixels'] != ' -1']\nno_finding_sample = sample_df[sample_df['EncodedPixels'] == ' -1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding_sample_1 = finding_sample.iloc[0]\nfinding_sample_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fordel_path = \"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\nfile_path = os.path.join(fordel_path, finding_sample_1.ImageId) + \"/*/*.dcm\"\nimage_path = glob.glob(file_path)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image_distr(data):\n    data = data/255.\n    f = plt.figure()\n    f.set_figwidth(10)\n\n    s1 = f.add_subplot(1, 2, 1)\n    s1.set_title('Image')\n    plt.imshow(data, cmap='gray')\n\n\n    s2 = f.add_subplot(1, 2, 2)\n    s2.set_title('Intensity Distribution')\n    plt.hist(data.ravel(), bins = 256)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pydicom.dcmread(image_path)\nimg_data = dataset.pixel_array\nshow_image_distr(img_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image_data(row):\n    fordel_path = \"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\n    file_path = os.path.join(fordel_path, row[\"ImageId\"]) + \"/*/*.dcm\"\n    image_path = glob.glob(file_path)[0]\n    if image_path is not None:\n        dataset = pydicom.dcmread(image_path)\n        img_data = dataset.pixel_array\n        img_data = img_data/255.\n        return img_data\n    else:\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding_sample['image_data'] = finding_sample.apply(get_image_data, axis=1)\nfinding_sample.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding_data = finding_sample[finding_sample['image_data'].notna()]['image_data'].values\nfinding_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding_intensities = []\nfor data in finding_data:\n    finding_intensities.extend(data.flatten().tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(finding_intensities[:1000000],bins=256)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sample finding distribution with background"},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in finding_data[:10]:\n    show_image_distr(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hình ảnh gốc đang bị ảnh hưởng bởi 2 yếu tố:\n* Quá nhiều nền\n* Quá nhiều phần hình ảnh bị chặn bởi các vật thể khác (xương, nhựa, ... ) dẫn đến cường độ màu rất sáng"},{"metadata":{},"cell_type":"markdown","source":"#### Remove Background"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image_mask(img_data, th):\n    img_data = img_data/255.\n    f = plt.figure()\n    f.set_figwidth(15)\n\n    s1 = f.add_subplot(1, 3, 1)\n    s1.set_title('Image')\n    plt.imshow(img_data, cmap='gray')\n\n    mask = data > th\n\n    s2 = f.add_subplot(1, 3, 2)\n    s2.set_title('Mask')\n    plt.imshow(mask.astype(int)*255, cmap='gray')\n    \n    s3 = f.add_subplot(1, 3, 3)\n    s3.set_title('Intensity Distribution')\n    plt.hist(img_data[mask], bins = 256)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"background_threshold = 0.1\n\nfor data in finding_data[:10]:\n    show_image_mask(data, background_threshold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cần loại bỏ các vùng trắng quá mức"},{"metadata":{"trusted":true},"cell_type":"code","source":"foreground_threshold = 0.9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_intensities(option=\"finding\"):\n    fordel_path = \"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\n    \n    intensities = []\n    if option == \"finding\":\n        image_ids = sample_df[sample_df['EncodedPixels'] != ' -1'][:100].ImageId\n    else:\n        image_ids = sample_df[sample_df['EncodedPixels'] == ' -1'][:100].ImageId\n    for image_id in image_ids:\n        file_path = os.path.join(fordel_path, image_id) + \"/*/*.dcm\"\n        image_path = glob.glob(file_path)[0]\n        dataset = pydicom.dcmread(image_path)\n        data = dataset.pixel_array / 255.\n        mask = (data > background_threshold) & (data < foreground_threshold)\n        intensities.extend(data[mask].flatten().tolist())\n    return intensities\n    \nplt.hist(get_intensities(\"finding\"), bins = 256)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So sánh phân phối hình ảnh bị tràn khí phổi vs hình ảnh không bị tràn khí phổi"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure()\nf.set_figwidth(20)\nf.set_figheight(20)\n\ns1 = f.add_subplot(1, 2, 1)\ns1.set_title('Image Finding')\nplt.hist(get_intensities(\"finding\"), bins = 256)\nplt.show()\n\ns2 = f.add_subplot(1, 2, 2)\ns2.set_title('Image No Finding')\nplt.hist(get_intensities(\"no_finding\"), bins = 256)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Kết luận\n\n* Hình ảnh trong tập dữ liệu cần phải chuẩn hóa về đoạn từ 0 đến 1\n* Background cần phải được loại bỏ với ngưỡng là > 0.1\n* Foreground mà có giá trị quá sáng cũng cần phải loại bỏ, ngưỡng gợi ý là < 0.9. Đây có thể là những thực thể bên ngoài, hấp thụ tia X tốt, ví dụ như mảnh nhựa, ... )\n* Phân bố hình ảnh liên quan đến độ tuổi và giới tính tương đối đồng đều, không quá bị bias về lớp đối tượng nào cả.\n* Bias về số lượng hình ảnh finding và non-finding, với trường hợp non-finding có rất nhiều hình ảnh:\n    * Loại bỏ các hình ảnh non-finding sao cho gần bằng với số lượng hình ảnh finding:\n        * finding: 3286 (28.37%), no finding: 8296 (71.63%)\n    * Tăng cường dữ liệu đối với hình ảnh finding\n* View position đối với finding cũng bị bias nhẹ (có thể xử lý sau):\n    * PA: 2131 (64.85%), AP: 1155 (35.15%)\n* Ngoài ra còn có một số nhiễu trong hình ảnh cũng cần phải xử lý trước (xử lý sau - sau khi có base model)"},{"metadata":{},"cell_type":"markdown","source":"# Chia dữ liệu thành tập train và tập test"},{"metadata":{},"cell_type":"markdown","source":"Tiêu chí chia tập dữ liệu:\n* Chia theo số lượng finding:\n    * Lấy khoảng 3286 finding và chọn random 3286 non-finding\n    * Áp dụng các kĩ thuật tăng cường dữ liệu cho finding và non-finding\n* Đối với việc bị thiên lệch về view-position có thể tính sau"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read Origin Image\nall_xray_df = pd.read_csv('../input/segment-data/train_info.csv')\nall_xray_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finding = all_xray_df[all_xray_df['EncodedPixels'] != ' -1']\nno_finding = all_xray_df[all_xray_df['EncodedPixels'] == ' -1'].sample(len(finding))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_train = int(0.9 * len(finding))\ntraining_df = finding.sample(number_train)\nvalidation_df = finding.drop(training_df.index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_df.to_csv('train_info_split.csv', header=True, index=False)\nvalidation_df.to_csv('val_info_split.csv', header=True, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}