{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nJust to understand the images better, and see the capabilities of CNNs on these type of images, and of course playing with the data, I made this simple gender predictor. Taking the images and giving them to 2 layers of convolutions, it is able to predict the gender of above 80% of the images correctly. Here we go:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pylab as pl\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.layers import Input, InputLayer, Dropout, Conv2D, AveragePooling2D, MaxPooling2D, ReLU, Dense, Flatten, BatchNormalization\nfrom keras.models import Model, Sequential, save_model, load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras import backend\nfrom sklearn.model_selection import train_test_split\n\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset\n\nI have stored the useful part of metadata features in this dataset:\n\n[https://www.kaggle.com/safavieh/siim-acr-pneumothorax-segmentation-metadata](https://www.kaggle.com/safavieh/siim-acr-pneumothorax-segmentation-metadata)\n\nIt includes 'ViewPosition', 'PAtientAge', 'PatientSex' for each ImageId."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"trainDF = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-metadata/train.csv')\ntestDF = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-metadata/test.csv')\ntrainDF['FileNames'] = trainDF.ImageId.apply(lambda ID: '../input/siim-png-images/input/train_png/' + ID + '.png')\ntestDF['FileNames'] = testDF.ImageId.apply(lambda ID: '../input/siim-png-images/input/test_png/' + ID + '.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN model\n\nHere is the model:\n\nIt has two convolutional layer of relatively big size of 16x16 feeding to two layers of dense connections."},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session();\n\ndef getModel():\n    model = Sequential()\n    model.add(InputLayer(input_shape=(128,128,1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=64, kernel_size=16, activation='relu', strides=1))\n    model.add(Conv2D(filters=8, kernel_size=16, activation='relu', strides=1))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dropout(.1))\n    model.add(BatchNormalization())\n    model.add(Dense(20, activation='relu'))\n    model.add(Dense(2, activation='softmax'))\n    model.compile(optimizer=Adam(lr=0.001, decay=.01),\n                  loss='binary_crossentropy',\n                  metrics=['binary_accuracy'])\n    return model\n\nmodel = getModel()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training for 20 epochs:"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainSet, valSet = train_test_split(trainDF)\nparams = {'color_mode':'grayscale', 'directory':None, 'x_col':\"FileNames\", 'y_col':\"PatientSex\", 'class_mode':\"categorical\", 'target_size':(128,128)}\ntrDataGen = ImageDataGenerator().flow_from_dataframe(dataframe=trainSet, batch_size=16, **params)\nvlDataGen = ImageDataGenerator().flow_from_dataframe(dataframe=valSet, batch_size=64, shuffle=False, **params)\ntsDataGen = ImageDataGenerator().flow_from_dataframe(dataframe=testDF, batch_size=64, shuffle=False, **params)\n\nmodel.fit_generator(\n        trDataGen,\n        steps_per_epoch=len(trDataGen)/2,\n        epochs=20,\n        validation_data=vlDataGen,\n        validation_steps=len(vlDataGen))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results on test set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LogLoss: %g, binary accuracy: %g' % tuple(model.evaluate_generator(tsDataGen, steps=len(tsDataGen))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Output\n\nSample Output:"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = tsDataGen[0][0]\nTarget = tsDataGen[0][1]\nOutput = model.predict_on_batch(batch)\nLabels = ['F','M']\npl.figure(figsize=(15,15))\nfor i in range(9):\n    ax=pl.subplot(3,3,i+1)\n    ax.imshow(pl.imread(testDF.FileNames.iloc[i]), cmap='bone')\n    ax.set_title('true: '+ testDF.PatientSex.iloc[i] + \\\n                 ', pred: %.2g%% %s' % (Output[i,:].max()*100, \n                                        Labels[pl.argmax(Output[i,:])]))\n    ax.set_axis_off()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visulaization of Convolutional Layers\n\nLet's take a look at the trained Convolutional layer weights:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pl.figure(figsize=(10,10))\nw=model.get_layer('conv2d_1').get_weights()[0]\nfor i in range(w.shape[3]):\n    ax=pl.subplot(8,8,i+1)\n    ax.imshow(w[:,:,:,i].squeeze())\n    ax.set_axis_off()\npl.suptitle('Conv Layer 1')\n    \npl.figure(figsize=(10,10))\nw=model.get_layer('conv2d_2').get_weights()[0]\nfor i in range(w.shape[3]):\n    ax=pl.subplot(3,3,i+1)\n    ax.imshow(w[:,:,:,i].sum(2).squeeze())\n    ax.set_axis_off()\npl.suptitle('Conv Layer 2');\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}