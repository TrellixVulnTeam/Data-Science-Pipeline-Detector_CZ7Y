{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is forked from [mask-rcnn with augmentation and multiple masks](https://www.kaggle.com/abhishek/mask-rcnn-with-augmentation-and-multiple-masks)\n\n# Import Cool Stuff"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from __future__ import print_function\n\nfrom collections import defaultdict, deque\nimport datetime\nimport pickle\nimport time\nimport torch.distributed as dist\nimport errno\nfrom fastai import metrics\n\nimport cv2\nimport collections\nimport os\nimport numpy as np\nimport torch\nimport torch.utils.data\nfrom PIL import Image, ImageFile\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torchvision import transforms\nimport torchvision\nimport random\n\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import platform\nprint(f'Python version: {platform.python_version()}')\nprint(f'PyTorch version: {torch.__version__}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=73):\n    '''\n      Make PyTorch deterministic.\n    '''    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IS_DEBUG = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utility Functions (hidden)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n\n    def f(x):\n        if x >= warmup_iters:\n            return 1\n        alpha = float(x) / warmup_iters\n        return warmup_factor * (1 - alpha) + alpha\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dice Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DiceLoss(torch.nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n \n    def forward(self, logits, targets):\n        ''' fastai.metrics.dice uses argmax() which is not differentiable, so it \n          can NOT be used in training, however it can be used in prediction.\n          see https://github.com/fastai/fastai/blob/master/fastai/metrics.py#L53\n        '''\n        N = targets.size(0)\n        preds = torch.sigmoid(logits)\n        #preds = logits.argmax(dim=1) # do NOT use argmax in training, because it is NOT differentiable\n        # https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/keras/backend.py#L96\n        EPSILON = 1e-7\n \n        preds_flat = preds.view(N, -1)\n        targets_flat = targets.view(N, -1)\n \n        intersection = (preds_flat * targets_flat).sum()#.float()\n        union = (preds_flat + targets_flat).sum()#.float()\n        \n        loss = (2.0 * intersection + EPSILON) / (union + EPSILON)\n        loss = 1 - loss / N\n        return loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\n\ndef train_one_epoch(model, optimizer, data_loader, device, epoch):\n    model.train()\n    loss_func = DiceLoss()\n\n    lr_scheduler = None\n    if epoch == 0:\n        warmup_factor = 1. / 1000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    lossf=None\n    inner_tq = tqdm(data_loader, total=len(data_loader), leave=False, desc= f'Iteration {epoch}')\n    for images, masks in inner_tq:\n        y_preds = model(images.to(device))\n        y_preds = y_preds['out'][:, 1, :, :] #\n\n        loss = loss_func(y_preds, masks.to(device))\n\n        if torch.cuda.device_count() > 1:\n            loss = loss.mean() # mean() to average on multi-gpu.\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()\n        else:\n            lossf = loss.item()\n        inner_tq.set_postfix(loss = lossf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RLE to Mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, width, height):\n    mask= np.zeros(width * height, dtype=np.uint8)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 1\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIIM Dataset Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SIIMDataset(torch.utils.data.Dataset):\n    def __init__(self, df_path, img_dir):\n        self.df = pd.read_csv(df_path)\n        self.df = self.df[self.df[' EncodedPixels'] != ' -1']\n        if IS_DEBUG:\n            self.df = self.df.sample(frac=0.01, random_state=73)\n        self.height = 1024\n        self.width = 1024\n        self.image_dir = img_dir\n        self.image_info = collections.defaultdict(dict)\n\n        counter = 0\n        for index, row in tqdm(self.df.iterrows(), total=len(self.df)):\n            image_id = row['ImageId']\n            image_path = os.path.join(self.image_dir, image_id)\n            if os.path.exists(image_path + '.png') and row[\" EncodedPixels\"].strip() != \"-1\":\n                self.image_info[counter][\"image_id\"] = image_id\n                self.image_info[counter][\"image_path\"] = image_path\n                self.image_info[counter][\"annotations\"] = row[\" EncodedPixels\"].strip()\n                counter += 1\n\n    def __getitem__(self, idx):\n        img_path = self.image_info[idx][\"image_path\"]\n        img = Image.open(img_path + '.png').convert(\"RGB\")\n        width, height = img.size\n        info = self.image_info[idx]\n\n        mask = rle2mask(info['annotations'], width, height)\n        mask = mask.T\n#         mask = np.expand_dims(mask, axis=0)\n        mask = torch.as_tensor(mask, dtype=torch.float)\n\n        img = transforms.ToTensor()(img)\n        \n        return img, mask\n\n    def __len__(self):\n        return len(self.image_info)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_train = SIIMDataset(\"../input/siim-dicom-images/train-rle.csv\", \"../input/siim-png-images/input/train_png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dataset_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create DeepLabV3 Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False, num_classes=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft.to(device)\nNUM_GPUS = torch.cuda.device_count()\nif NUM_GPUS > 1:\n    model_ft = torch.nn.DataParallel(model_ft)\n_ = model_ft.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loader = torch.utils.data.DataLoader(\n    dataset_train, batch_size=2*NUM_GPUS, shuffle=True, num_workers=NUM_GPUS,drop_last=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Training Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct an optimizer\nparams = [p for p in model_ft.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# and a learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                               step_size=5,\n                                               gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 5\nfor epoch in range(num_epochs):\n    train_one_epoch(model_ft, optimizer, data_loader, device, epoch)\n    lr_scheduler.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mask to RLE helper"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_to_rle(img, width, height):\n    rle = []\n    lastColor = 0\n    currentPixel = 0\n    runStart = -1\n    runLength = 0\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 1:\n                    runStart = currentPixel\n                    runLength = 1\n                else:\n                    rle.append(str(runStart))\n                    rle.append(str(runLength))\n                    runStart = -1\n                    runLength = 0\n                    currentPixel = 0\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor\n            currentPixel+=1\n    # https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/98317\n    if lastColor == 255:\n        rle.append(runStart)\n        rle.append(runLength)\n    return \" \" + \" \".join(rle)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert Model to Evaluation Mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft.eval()\nfor param in model_ft.parameters():\n    param.requires_grad = False\nmodel_ft.to(torch.device('cuda'))\nassert model_ft.training == False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model_ft.state_dict(), 'deeplabv3.pth')\ntorch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv(\"../input/siim-acr-pneumothorax-segmentation/sample_submission.csv\")\n\n# this part was taken from @raddar's kernel: https://www.kaggle.com/raddar/better-sample-submission\nmasks_ = sample_df.groupby('ImageId')['ImageId'].count().reset_index(name='N')\nmasks_ = masks_.loc[masks_.N > 1].ImageId.values\n###\nsample_df = sample_df.drop_duplicates('ImageId', keep='last').reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt = transforms.ToTensor()\nsublist = []\ncounter = 0\nthreshold = 0.5\nfor index, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n    image_id = row['ImageId']\n    if image_id in masks_:\n        img_path = os.path.join('../input/siim-png-images/input/test_png', image_id + '.png')\n\n        img = Image.open(img_path).convert(\"RGB\")\n        width, height = img.size\n        img = img.resize((1024, 1024), resample=Image.BILINEAR)\n        img = tt(img)\n        img = img.reshape((1, *img.numpy().shape))\n        logits = model_ft(img.to(device))['out'][:, 1, :, :]\n        preds = torch.sigmoid(logits)[0].cpu().numpy()\n        mask = (preds > 0.5).astype(np.uint8).T\n        if np.count_nonzero(mask) == 0:\n            rle = \" -1\"\n        else:\n            rle = mask_to_rle(mask, width, height)\n    else:\n        rle = \" -1\"\n    sublist.append([image_id, rle])\n\nsubmission_df = pd.DataFrame(sublist, columns=sample_df.columns.values)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(counter)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}