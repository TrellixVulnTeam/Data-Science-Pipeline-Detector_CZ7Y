{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\n\nIn this kernel, I am interested to understand more about the Pneumothorax diagnosis masks. I want to identify natural categories / clusters of pneumothorax diagnosis that exist. I'll use different unsupervised learning approach. Starting with PCA + KMeans, and then use different autoencoders.\n\nThe result might be useful to have better understanding about the illness itseslf. It would also be useful if we want to do hierarchical step for our prediction\n\nI am using this kernel for references on data extraction: https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data#data"},{"metadata":{},"cell_type":"markdown","source":"# Sections\n\n* A: All the data pre-processing\n* B-1: Use simple PCA & K-Means\n* C: All the autoencoders\n* C1: Shallow network AE - learned nothing\n* C2: Deep (fully-connected) AE - still not useful\n* C3: Deep Convolutional AE - finally worked well"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import pydicom\nimport os\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nfrom matplotlib import pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom tqdm import tqdm\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\n\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nimport plotly.offline as pyo\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly_express as px\ninit_notebook_mode(connected=True)\n\nimport tensorflow as tf\n\nfrom tqdm import tqdm_notebook\n\n# ['siim-acr-pneumothorax-segmentation-data', 'siim-acr-pneumothorax-segmentation']\n\nimport sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation/')\n\nfrom mask_functions import rle2mask\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def show_dcm_info(dataset):\n    print(\"Filename.........:\", file_path)\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    print()\n\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    print(\"View Position.......:\", dataset.ViewPosition)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)\n            \ndef plot_pixel_array(dataset, figsize=(10,10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A-1 Load training data"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"samplesize = 5000\ntrain_glob = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/dicom-images-train/*/*/*.dcm'\ntest_glob = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/dicom-images-test/*/*/*.dcm'\ntrain_fns = sorted(glob.glob(train_glob))[:samplesize]\ntest_fns = sorted(glob.glob(test_glob))[:samplesize]\ndf_full = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-data/pneumothorax/train-rle.csv', index_col='ImageId')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A-2 Generate diagnostic masking data in image format"},{"metadata":{},"cell_type":"markdown","source":"### Convert DCM into numpy array\nIn this step, I will be constructing Y_train from DCM format into numpy array. The starter code was taken from [this](http://https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data#data) kernel, with some adjustments: (1) I skipped loading X_train to save memory, since I'm only interested in the shape of the mask, (2) I changed the implementation from the original additive function into taking the maximum (since some points are overlapping.\n> Y_train[n] =  np.maximum(Y_train[n], np.expand_dims(rle2mask(x, 1024, 1024), axis=2))"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"im_height = 1024\nim_width = 1024\nim_chan = 1\n# Get train images and masks\n# X_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.int16)\nprint('Getting train images and masks ... ')\nsys.stdout.flush()\nfor n, _id in tqdm_notebook(enumerate(train_fns), total=len(train_fns)):\n    dataset = pydicom.read_file(_id)\n#     X_train[n] = np.expand_dims(dataset.pixel_array, axis=2)\n    try:\n        if '-1' in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n            Y_train[n] = np.zeros((1024, 1024, 1))\n        else:\n            if type(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']) == str:\n                x = np.expand_dims(rle2mask(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n                Y_train[n] = x\n            else:\n                Y_train[n] = np.zeros((1024, 1024, 1))\n                for x in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n                    Y_train[n] =  np.maximum(Y_train[n], np.expand_dims(rle2mask(x, 1024, 1024), axis=2))\n    except KeyError:\n        print(f\"Key {_id.split('/')[-1][:-4]} without mask, assuming healthy patient.\")\n        Y_train[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rescale the image down to save memory"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"from skimage.transform import rescale\n\nimage_setori = []\nfor i in range(samplesize):\n    count = Y_train[i].sum()\n    if count > 0:\n        image_setori.append(rescale(Y_train[i],1.0/4.0)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove the last dimension and flatten the image"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_set = np.asarray(image_setori)\nsamplesize = len(image_set)\nimage_set = np.squeeze(image_set)\nimage_set = np.reshape(image_set, ((samplesize, image_set.shape[1] * image_set.shape[2])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalize the value to be [0 to 1]"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"image_set = image_set * 128\n# for i in range(len(image_set)):\n#     print(image_set[i].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Util to check memory size"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import sys\n\n# These are the usual ipython objects, including this one you are creating\nipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# Get a sorted list of the objects and their sizes\nsorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We delete Y_train to save memory"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"del Y_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B-1 Start with PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Review explained variance plot to determine number of PCA components (capped at 50):"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pca = PCA(n_components=50).fit(image_set)\n#Plotting the Cumulative Summation of the Explained Variance\ny=np.cumsum(pca.explained_variance_ratio_)\ndata = [go.Scatter(y=y)]\nlayout = {'title': 'PCA Explained Variance'}\niplot({'data':data,'layout':layout})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even at n=20 components, we still can only explain 50% of variance. Oh well. \n\nLet's still zoom in with n=20 components:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=20)\nimage_PCA = pca.fit_transform(image_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trace1 = go.Scatter(y=pca.explained_variance_ratio_)\ntrace2 = go.Scatter(y=np.cumsum(pca.explained_variance_ratio_))\nfig = tools.make_subplots(rows=1,cols=2,subplot_titles=('Explained Variance','Cumulative Explained Variance'))\nfig.append_trace(trace1,1,1)\nfig.append_trace(trace2,1,2)\nfig['layout'].update(height=600, width=1200, title=\"Explained Variance Ratios\",showlegend=False)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll also check elbow curve for number of clusters for kmeans"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"Nc = range(1,20)\nkmeans = [KMeans(i) for i in Nc]\nscore = [kmeans[i].fit(image_PCA).score(image_PCA) for i in range(len(kmeans))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = [go.Scatter(y=score,x=list(Nc))]\nlayout = {'title':'Elbow Curve for KMeans'}\niplot({'data':data,'layout':layout})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"n_clusters=12\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nimage_kmeans = kmeans.fit_predict(image_PCA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_kmeans.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_clusters = np.zeros((n_clusters, image_set.shape[1]), dtype=np.float64)\nclustercounts = np.zeros(n_clusters,dtype=np.int)\nfor i in range(samplesize):\n    for j in range(n_clusters):\n        if image_kmeans[i] == j:\n            image_clusters[j] += image_set[i]\n            clustercounts[j] += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check shape of image_clusters (number of clusters, height x width). Each row is individual clusters and the columns are the flattened pixels.\nCheck the number of images in each clusters and total images in our training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(image_clusters.shape)\nprint(clustercounts)\nprint(clustercounts.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll transform the image_clusters into height x width format "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for j in range(n_clusters):\n    image_clusters[j] = image_clusters[j] / clustercounts[j]\nimage_clusters = np.reshape(image_clusters, ((n_clusters, 256, 256)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_clusters.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We then do a simple step to sort the clustering output based on location. Simply sum the masks on the top left. Print "},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"image_clusters_sortingval = [np.sum(image_clusters[i,:80,:80]) for i in range(n_clusters)]\ncluster_ordered = range(n_clusters)\ncluster_ordered = [x for _,x in sorted(zip(image_clusters_sortingval,cluster_ordered))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finally now we display the clusters of Pneumothorax masks\n\nIn general, we can see that the clusters are based on location (left, right) and also the size of the masks"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(hspace=0.05, wspace=0.05)\nj = 1\nfor i in cluster_ordered:\n    plt.subplot(2,6,j)\n    plt.imshow(image_clusters[i].T, cmap=plt.cm.bone)\n    plt.title('Cluster '+str(i)+'. Num Samples: '+str(clustercounts[i]))\n    j += 1\nplt.tight_layout()\nplt.suptitle(\"Clusters of Pneumothorax Diagnosis based on simple PCA & K-Means\",fontsize=16,y=1.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\nimageTSNE = TSNE(n_components=2).fit_transform(image_PCA)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"imageTSNEdf = pd.concat([pd.DataFrame(imageTSNE),pd.DataFrame(image_kmeans)],axis=1)\nimageTSNEdf.columns = ['x1','x2','cluster']\npx.scatter(imageTSNEdf,x='x1',y='x2',color='cluster',color_continuous_scale=px.colors.qualitative.Plotly,title=\"TSNE visualization of Image Clusters\",width=800,height=500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's also do a simplified version with just 6 clusters\n\nInterestingly, there are 4 variations of left-side masks but only 1 variation of right-side marks. The majority is still scattered. Most likely this reflect small spots that is not big enough to belong in the other clusters"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"n_clusters=6\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nimage_kmeans = kmeans.fit_predict(image_PCA)\nimage_clusters = np.zeros((n_clusters, image_set.shape[1]), dtype=np.float64)\nclustercounts = np.zeros(n_clusters,dtype=np.int)\nfor i in range(samplesize):\n    for j in range(n_clusters):\n        if image_kmeans[i] == j:\n            image_clusters[j] += image_set[i]\n            clustercounts[j] += 1\nfor j in range(n_clusters):\n    image_clusters[j] = image_clusters[j] / clustercounts[j]\nimage_clusters = np.reshape(image_clusters, ((n_clusters, 256, 256)))\nimage_clusters_sortingval = [np.sum(image_clusters[i,:80,:80]) for i in range(n_clusters)]\ncluster_ordered = range(n_clusters)\ncluster_ordered = [x for _,x in sorted(zip(image_clusters_sortingval,cluster_ordered))]\nfig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(hspace=0.05, wspace=0.05)\nj = 1\nfor i in cluster_ordered:\n    plt.subplot(1,6,j)\n    plt.imshow(image_clusters[i].T, cmap=plt.cm.bone)\n    plt.title('Cluster '+str(i)+'. Num Samples: '+str(clustercounts[i]))\n    j += 1\nplt.tight_layout()\nplt.suptitle(\"Clusters of Pneumothorax Diagnosis based on simple PCA & K-Means\",)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"imageTSNEdf = pd.concat([pd.DataFrame(imageTSNE),pd.DataFrame(image_kmeans)],axis=1)\nimageTSNEdf.columns = ['x1','x2','cluster']\npx.scatter(imageTSNEdf,x='x1',y='x2',color='cluster',color_continuous_scale=px.colors.qualitative.Plotly,title=\"TSNE visualization of Image Clusters\",width=800,height=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Clean-up\ndel image_PCA\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import sys\n\n# # These are the usual ipython objects, including this one you are creating\n# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# # Get a sorted list of the objects and their sizes\n# sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"del df_full\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C-1 AutoEncoder: Simple AE with fully-connected layer"},{"metadata":{},"cell_type":"markdown","source":"## One hidden layer"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nencoding_dim = 128\nimgsize_flat = 256 * 256\ninput_img = Input(shape=(imgsize_flat,))\nencoded = Dense(encoding_dim,activation='relu')(input_img)\ndecoded = Dense(imgsize_flat,activation='sigmoid')(encoded)\nautoencoder = Model(input_img, decoded)\n\n# Encoder\nencoder = Model(input_img,encoded)\n\n# Decoder\nencoded_input = Input(shape=(encoding_dim,))\ndecoder_layer = autoencoder.layers[-1]\ndecoder = Model(encoded_input, decoder_layer(encoded_input))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nxtrain = image_set\nautoencoder.fit(xtrain,xtrain,epochs=20,batch_size=256,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check how the original compare with the reconstructed\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nfor i in range(5):\n    plt.subplot(2,5,i+1)\n    plt.imshow(xtrain[i].reshape(256,256).T, cmap=plt.cm.bone)\n    autoencoded = autoencoder.predict(xtrain[i:i+1])\n    plt.subplot(2,5,i+6)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\nplt.tight_layout()\nplt.suptitle('Comparing original vs AE reconstruction images',fontsize=16,y=1)        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still random noise. As visible for large loss value, the network hasn't learned anything meaningful"},{"metadata":{},"cell_type":"markdown","source":"# C-2 Deep autoencoder - fully connected\n\ntl;dr Fully-connected deep autoencoder still failed to produce meaningful encoding."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nencoding_dim = 64\nimgsize_flat = 256 * 256\nlayer1_multiplier = 32\nlayer2_multiplier = 16\n\ninput_img = Input(shape=(imgsize_flat,))\nencoded = Dense(encoding_dim*layer1_multiplier ,activation='relu')(input_img)\nencoded = Dense(encoding_dim*layer2_multiplier,activation='relu')(encoded)\nencodedFinal = Dense(encoding_dim,activation='relu')(encoded)\ndecoded = Dense(encoding_dim*layer2_multiplier,activation='relu')(encodedFinal)\ndecoded = Dense(encoding_dim*layer1_multiplier ,activation='relu')(decoded)\ndecodedFinal = Dense(imgsize_flat,activation='sigmoid')(decoded)\n\nautoencoder = Model(input_img, decodedFinal)\n\n# Encoder\nencoder = Model(input_img,encodedFinal)\n\n# Decoder\n# encoded_input = Input(shape=(encoding_dim,))\n# decoder_layer = autoencoder.layers[-1]\n# decoder = Model(encoded_input, decoder_layer(encoded_input))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"xtrain = image_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"autoencoder.compile(optimizer='adam', loss='mean_squared_error')\nautoencoder.fit(xtrain,xtrain,epochs=20,batch_size=64,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check how the original compare with the reconstructed\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nfor i in range(10):\n    plt.subplot(2,10,i+1)\n    plt.imshow(xtrain[i].reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('Image ' + str(i))\n    \n    autoencoded = autoencoder.predict(xtrain[i:i+1])\n    plt.subplot(2,10,i+11)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('AE ' + str(i))\nplt.tight_layout()\nplt.suptitle('Comparing original vs AE reconstruction images',fontsize=16,y=1)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The reconstruction pretty much generated black images"},{"metadata":{},"cell_type":"markdown","source":"## Running some diagnostics to check the encoded features\n"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"image = []\nfor i in range(10):\n    image.append(encoder.predict(xtrain[i:i+1]))\nimage = np.array(image)\nimage = np.squeeze(image)\nimagedf = pd.DataFrame(image)\nimagedf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(24,8))\nfor i in range(8):\n    series = imagedf.iloc[:,i]\n    plt.subplot(4,8,i+1)\n    series.hist()\n    plt.title('Dim ' + str(i))\nplt.suptitle('Histogram for each encoding dimension')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The encoding pretty much failed. Many encoding dimensions are perfectly correlated. The correlation dataframe below further confirms that"},{"metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"imagedf.corr().iloc[:5,:5] #just a sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C-3 Convolutional Autoencoder"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import backend as K\n\ninput_img=Input(shape=(256,256,1))\nx = Conv2D(16,(3,3),activation='relu',padding='same')(input_img)\nx = MaxPooling2D((4,4), padding='same')(x)\nx = Conv2D(4,(3,3), activation='relu',padding='same')(x)\nencoded = MaxPooling2D((4,4), padding='same')(x)\n\nx = Conv2D(4,(3,3),activation='relu',padding='same')(encoded)\nx = UpSampling2D((4,4))(x)\nx = Conv2D(16,(3,3),activation='relu',padding='same')(x)\nx = UpSampling2D((4,4))(x)\ndecoded = Conv2D(1,(3,3),activation='sigmoid',padding='same')(x)\n\nautoencoderCNN=Model(input_img,decoded)\nautoencoderCNN.compile(optimizer='adam',loss='binary_crossentropy')\n\n# Encoder\nencoderCNN = Model(input_img,encoded)\n\n# Decoder\nencoded_inputCNN = Input(shape=(16,16,4,))\ndecoder1 = autoencoderCNN.layers[-1]\ndecoder2 = autoencoderCNN.layers[-2]\ndecoder3 = autoencoderCNN.layers[-3]\ndecoder4 = autoencoderCNN.layers[-4]\ndecoder5 = autoencoderCNN.layers[-5]\n\ndecoderCNN = Model(encoded_inputCNN,decoder1(decoder2(decoder3(decoder4(decoder5(encoded_inputCNN))))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoderCNN.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoderCNN.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"xtrain = np.reshape(xtrain, (len(xtrain),256,256,1))\nautoencoderCNN.fit(xtrain,xtrain,epochs=20,batch_size=64,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nfor i in range(5):\n    plt.subplot(2,5,i+1)\n    plt.imshow(xtrain[i:i+1].reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('Image ' + str(i))\n    autoencoded = autoencoderCNN.predict(xtrain[i:i+1])\n    plt.subplot(2,5,i+6)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('AE ' + str(i))\nplt.suptitle('Comparing original vs AE reconstruction images (5 images)',fontsize=16,y=1)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nfor i in range(11,20):\n    plt.subplot(2,10,i-10)\n    plt.imshow(xtrain[i].reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('Image ' + str(i))    \n    autoencoded = autoencoderCNN.predict(xtrain[i:i+1])\n    plt.subplot(2,10,i-0)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('AE ' + str(i))\nplt.suptitle('Comparing original vs AE reconstruction images (10 images)',fontsize=16,y=1.03)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The reconstructions above looks pretty good!\nFinally."},{"metadata":{},"cell_type":"markdown","source":"### Quickly check what the encoded features look like (hidden)"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"encoderCNN = Model(input_img,encoded)\nencodedX = []\nfor i in range(len(xtrain)):\n    encodedX.append(encoderCNN.predict(xtrain[i:i+1]))\nencodedX = np.array(encodedX)\nprint(encodedX.shape)\nencodedX = np.squeeze(encodedX)\nprint(encodedX.shape)\nencodeddf = pd.DataFrame(encodedX.reshape(encodedX.shape[0],np.prod(encodedX.shape[1:])))\nencodeddf.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clustering the encoded representations"},{"metadata":{},"cell_type":"markdown","source":"Lets use explained variance ratio to figure out a good PCA n_components"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pca = PCA(n_components=50)\nimage_PCA = pca.fit_transform(encodeddf)\nfig, ax = plt.subplots(1,2,figsize=(10,5))\nax[0].plot(pca.explained_variance_ratio_)\nax[0].title.set_text(\"Explained variance ratio\")\nax[1].plot(np.cumsum(pca.explained_variance_ratio_))\nax[1].title.set_text(\"Cumulative Explained variance ratio\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll use 30 components for now. Now check the numer of clusters"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pca = PCA(n_components=30)\nimage_PCA = pca.fit_transform(encodeddf)\nNc = range(1,30)\nkmeans = [KMeans(i) for i in Nc]\nscore = [kmeans[i].fit(image_PCA).score(image_PCA) for i in range(len(kmeans))]\nplt.plot(Nc,score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve to evaluate number of clusters')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll use 12 clusters again"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"n_clusters=12\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nencoding_kmeans = kmeans.fit_predict(image_PCA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"encoding_clusters = np.zeros((n_clusters, encodeddf.iloc[0,:].shape[0]), dtype=np.float64)\nclustercounts = np.zeros(n_clusters,dtype=np.int)\nfor i in range(len(encoding_kmeans)):\n    for j in range(n_clusters):\n        if encoding_kmeans[i] == j:\n            encoding_clusters[j] += encodeddf.iloc[i,:]\n            clustercounts[j] += 1\nencoding_clustersdf = pd.DataFrame(encoding_clusters)\nfor j in range(n_clusters):\n    encoding_clustersdf[j] = encoding_clustersdf[j] / clustercounts[j]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Printing out what the centroid of clusters of encoded features look like (hidden)"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"encoding_clustersdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from skimage.filters import gaussian\nfig = plt.figure(figsize=(15,10))\nfor i in range(len(encoding_clustersdf)):\n    decoded = decoderCNN.predict(encoding_clustersdf.iloc[i,:].values.reshape((1,16, 16, 4)))\n    plt.subplot(4,5,i+1)\n    imgtoshow = gaussian(decoded.reshape(256,256).T, sigma=2)\n    plt.imshow(imgtoshow, cmap=plt.cm.bone)\n    plt.title('Cluster '+str(i)+' Size: '+str(clustercounts[i]))\nplt.tight_layout()\nplt.suptitle('Images of Final Clustering Result using Encoded Features as basis of clustering',fontsize=16,y=1.08)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stop here for now.\n\nA couple of next steps from here. \n\nFurther EDA: I still want to visualize the clustering onto tsne to understand the spread of the clusters. I also want to show images from each of the clusters to compare the clustered encodings vs. actual examples\n\nImproving Prediction: The clustering can be used to make a hierarchical prediction exercise. \n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}