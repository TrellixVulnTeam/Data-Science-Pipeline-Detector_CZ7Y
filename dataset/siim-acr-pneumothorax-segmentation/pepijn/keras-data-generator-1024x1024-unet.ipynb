{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Our own imports\nimport json\nfrom glob import glob\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization\nfrom keras import optimizers\nfrom keras.models import Model\nimport pydicom\nimport pandas as pd\nfrom collections import defaultdict\nimport keras\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# via https://www.kaggle.com/seesee/full-dataset\ntrain_fns = sorted(glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm'))\ntest_fns = sorted(glob('../input/siim-train-test/siim/dicom-images-test/*/*/*.dcm'))\nrles = pd.read_csv('../input/siim-train-test/siim/train-rle.csv')\n\nrles_ = defaultdict(list)\nfor image_id, rle in zip(rles['ImageId'], rles[' EncodedPixels']):\n    rles_[image_id].append(rle)\nrles = rles_\nannotated = {k: v for k, v in rles.items() if v[0] != ' -1'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(1024,1024), n_channels=1,\n                 shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            X[i,] = np.expand_dims(pydicom.read_file(ID).pixel_array, axis=2)\n            \n            stripped_id = ID.split('/')[-1][:-4]\n            rle = self.labels.get(stripped_id)\n            \n            if rle is None:\n                y[i,] = np.zeros((1024, 1024, 1))\n            else:\n                if len(rle) == 1:\n                    y[i,] = np.expand_dims(rle2mask(rle[0], self.dim[0], self.dim[1]).T, axis=2)\n                else: \n                    y[i,] = np.zeros((1024, 1024, 1))\n                    for x in rle:\n                        y[i,] =  y[i,] + np.expand_dims(rle2mask(x, 1024, 1024).T, axis=2)\n\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2D blocks\ndef conv2D_block(inputs, filters, activation, padding, batchnorm=False):\n    conv = Conv2D(filters, 3, activation=activation, padding=padding)(inputs)\n    if batchnorm:\n        conv = BatchNormalization()(conv)\n    conv = Conv2D(filters, 3, activation=activation, padding=padding)(conv) \n    if batchnorm:\n        conv = BatchNormalization()(conv)\n    return conv\n\ndef conv2D_maxpool_block(inputs, filters, activation, padding, batchnorm=False):\n    conv = conv2D_block(inputs, filters, activation, padding)\n    pool = MaxPooling2D()(conv)\n    return pool, conv\n\ndef upsamp_conv2D_block(conv_prev, conv_direct, filters, activation, padding, batchnorm=False):\n    up = UpSampling2D()(conv_prev)\n    conc = concatenate([up, conv_direct])\n    cm = conv2D_block(conc, filters, activation, padding, batchnorm)\n    return cm\n\ndef build_unet2D(inp_shape=(None, None, 1)):\n    inputs = Input(shape=inp_shape)\n\n    # Three conv pool blocks\n    p1, c1 = conv2D_maxpool_block(inputs, 16, 'relu', 'same', False)\n    p2, c2 = conv2D_maxpool_block(p1, 32, 'relu', 'same', False)\n    p3, c3 = conv2D_maxpool_block(p2, 64, 'relu', 'same', False)\n    p4, c4 = conv2D_maxpool_block(p3, 128, 'relu', 'same', False)\n\n    # Fourth conv -- lowest point\n    c5 = conv2D_block(p4, 256, 'relu', 'same', False)\n\n    # Three upsampling conv blocks\n    cm2 = upsamp_conv2D_block(c5, c4, 128, 'relu', 'same', False)\n    cm3 = upsamp_conv2D_block(cm2, c3, 64, 'relu', 'same', False)\n    cm4 = upsamp_conv2D_block(cm3, c2, 32, 'relu', 'same', False)\n    cm5 = upsamp_conv2D_block(cm4, c1, 16, 'relu', 'same', False)\n\n    # Output\n    predictions = Conv2D(1, 1, activation='sigmoid')(cm5)\n    model = Model(inputs, predictions)\n\n    return model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build model\nmodel2D = build_unet2D(inp_shape=(None, None, 1))\n\nparams = {'dim': (1024, 1024),\n          'batch_size': 8,\n          'n_channels': 1,\n          'shuffle': True}\n\n# Generators\ntraining_generator = DataGenerator(train_fns[0:8000], annotated, **params)\nvalidation_generator = DataGenerator(train_fns[8000:10712], annotated, **params) \n\n# Compile model\noptimizer = optimizers.Adam(lr = 0.001, epsilon = 0.1)\nloss = dice_coef_loss\nmetrics= [dice_coef]\nmodel2D.compile(optimizer=optimizer, loss=loss, metrics= metrics)\n\n# Fit model\nmodel2D.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}