{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/siim-acr-pneumothorax-segmentation/stage_2_images')\nfrom mask_functions import *\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n!pip install torch-summary\nimport numpy as np\nimport pandas as pd\nimport random\nimport cv2 as cv\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchsummary import summary\nimport torchvision\nimport torchvision.datasets as datasets\nfrom torch.optim.swa_utils import AveragedModel, SWALR\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pydicom\nfrom glob import glob\nimport os\ntorch.autograd.set_detect_anomaly(True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T17:55:12.132418Z","iopub.execute_input":"2021-07-28T17:55:12.132849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def squash(x, dim = -1):\n    square_norm = torch.sum(x ** 2, dim = dim, keepdim = True)\n    return square_norm / (0.5 + square_norm) * x / (torch.sqrt(square_norm + 1e-6) + 1e-6)\ndef power_squash(x, dim = -1, n = 3):\n    x = squash(x, dim = dim)\n    square_norm = torch.sum(x ** 2, dim = dim, keepdim = True) + 1e-6\n    return square_norm ** (n / 2) * x / (torch.sqrt(square_norm) + 1e-6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class XrayDataset(Dataset):\n    def __init__(self, paths, df, target_shape = (512, 512), mode = 'train', has_upsample = True, props = (3, 2), transforms = None):\n        super().__init__()\n        self.paths = paths\n        self.df = df\n        self.target_shape = target_shape\n        self.mode = mode\n        self.transforms = transforms\n        self.data = self.prepare_data()\n        if mode == \"train\" and has_upsample:\n            self.upsample_positive_data(props)            \n    \n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        info = self.data[idx]\n        path = info['path']\n        dcmdata = pydicom.dcmread(path)\n        image = dcmdata.pixel_array\n        if self.target_shape is not None:\n            image = cv.resize(image, self.target_shape[::-1], interpolation = cv.INTER_CUBIC)\n        if self.mode == \"test\":\n            image = np.expand_dims(image, 0) / 255.\n            image = image.astype(np.float32)\n            return torch.from_numpy(image)\n        encoded_masks = info['masks']\n        mask = np.zeros(self.target_shape)\n        is_mask = False\n        for encoded_mask in encoded_masks:\n            if encoded_mask != \"-1\":\n                _mask = rle2mask(encoded_mask, 1024, 1024).T\n                _mask = cv.resize(_mask, self.target_shape[::-1], interpolation = cv.INTER_CUBIC)\n                mask[_mask > 127] = 255\n                is_mask = True\n        if self.transforms:\n            aug = self.transforms(image = image, mask = mask)\n            image = aug['image']\n            mask = aug['mask']        \n        image = np.expand_dims(image, 0) / 255.\n        mask = np.expand_dims(mask, 0) / 255.\n        image = image.astype(np.float32)\n        mask = mask.astype(np.float32)\n        \n        image = torch.Tensor(image).float()\n        mask = torch.Tensor(mask).float()\n        return image, mask, image * mask, torch.Tensor([int(is_mask)])\n\n    def prepare_data(self):\n        data = []\n        image_ids = self.df['ImageId'].unique()\n        for image_id in tqdm(image_ids):\n            index = list(filter(lambda x: image_id in self.paths[x], range(len(self.paths))))\n            if len(index) == 0:\n                continue\n            index = index[0]\n            path = self.paths[index]\n            all_chests = self.df[self.df[\"ImageId\"] == image_id]\n            encode_rois = []\n            for _, row in all_chests.iterrows():\n                encode_rois.append(row[\" EncodedPixels\"])\n            data.append({\n                'image_id': image_id,\n                'path': path,\n                'masks': encode_rois\n            })\n        return data\n    def upsample_positive_data(self, props = (1, 1)):\n        positive_data = list(filter(lambda x: x[\"masks\"] != [\"-1\"], self.data))\n        n_positive = len(positive_data)\n        n_negative = len(self.data) - n_positive\n        n_new_samples = props[0] * n_negative // props[1] - n_positive\n        if n_new_samples <= 0: return\n        self.data.extend(random.choices(positive_data, k = n_new_samples))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SpatialCapsuleAttn(nn.Module):\n    def __init__(self, in_capsules):\n        super().__init__()\n        self.in_capsules = in_capsules\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.weight = nn.Parameter(torch.zeros(1, in_capsules, 1, 1, 1))\n        self.bias = nn.Parameter(torch.ones(1, in_capsules, 1, 1, 1))\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        b, c, d, h, w = x.shape\n        x = x.view(b * c, d, h , w)\n        avg = x * self.avg_pool(x)\n        avg = torch.sum(avg, dim = 1, keepdim = True)\n        t = avg.view(b * c, h * w)\n        mean = t.mean(dim = 1, keepdim = True)\n        std = t.std(dim = 1, keepdim = True) + 1e-6\n        t = (t - mean) / std\n        t = t.view(b, c, 1, h, w)\n        t = t * self.weight + self.bias\n        x = x.view(b, c, d, h, w) * self.sigmoid(t)\n        return x\nclass CapXLayer(nn.Module):\n    def __init__(self, in_capsules, in_cap_dim, middle_cap_dim, out_capsules, out_cap_dim, iterations = 3):\n        super().__init__()\n        self.blocks = nn.ModuleList()\n        self.in_capsules = in_capsules\n        self.in_cap_dim = in_cap_dim\n        self.middle_cap_dim = middle_cap_dim\n        self.out_capsules = out_capsules\n        self.out_cap_dim = out_cap_dim\n        self.iterations = iterations\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.has_residual = (self.in_capsules * self.in_cap_dim) == (self.out_capsules * self.out_cap_dim)\n        self.spatial_attn = SpatialCapsuleAttn(out_capsules)\n        for _ in range(in_capsules):\n            self.blocks.append(\n                nn.Sequential(\n                    nn.ReLU(),\n                    nn.Conv2d(in_cap_dim, middle_cap_dim, kernel_size = 1),\n                    nn.ReLU(inplace = True),\n                    nn.Conv2d(middle_cap_dim, middle_cap_dim, kernel_size = 3, padding = 1),\n                    nn.ReLU(inplace = True),\n                    nn.Conv2d(middle_cap_dim, out_capsules * out_cap_dim, kernel_size = 1)\n                )\n            )\n\n    def forward(self, x):\n        assert x.shape[1] == self.in_capsules * self.in_cap_dim\n        x_temp = x.view(x.shape[0], self.in_capsules, self.in_cap_dim, x.shape[-2], x.shape[-1])\n        outputs = []\n        for i, block in enumerate(self.blocks):\n            inp = x_temp[:, i]\n            out = block(inp)\n            out = out.reshape(out.shape[0], self.out_capsules, self.out_cap_dim, out.shape[-2], out.shape[-1])\n            outputs.append(out)\n        u_hat = torch.stack(outputs, dim = 1)\n        if self.iterations > 1:\n            u_hat_squash = squash(u_hat, dim = 3)\n        b = torch.zeros(out.shape[0], self.in_capsules, self.out_capsules, u_hat.shape[-2], u_hat.shape[-1]).to(self.device)\n        for _ in range(self.iterations - 1):\n            c = torch.sigmoid(b)\n            s = torch.sum(u_hat_squash * c.unsqueeze(3), dim = 1)\n            v = squash(s, dim = 2)\n            b = b + torch.sum(u_hat_squash * v.unsqueeze(1), dim = 3)\n        c = torch.sigmoid(b)\n        s = torch.sum(u_hat * c.unsqueeze(3), dim = 1)\n        s = self.spatial_attn(s)\n        out = s.reshape(s.shape[0], -1, *s.shape[-2:])\n        out = out + x\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBn(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1)\n        self.bn = nn.BatchNorm2d(out_channels)\n    def forward(self, x):\n        return self.bn(self.conv(x))\nclass ConvRelu(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1)\n        self.act = nn.ReLU(inplace = True)\n    def forward(self, x):\n        return self.act(self.conv(x))\nclass ConvBnRelu(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.act = nn.ReLU(inplace = True)\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\nclass DeConv(nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels, is_deconv = False):\n        super().__init__()\n        self.up_sample = nn.Upsample(scale_factor = 2, mode = 'bilinear')\n        self.block = nn.Sequential(\n                ConvBnRelu(in_channels, middle_channels),\n                nn.Conv2d(middle_channels, out_channels, kernel_size = 3, padding = 1)\n            )\n    def forward(self, x1, x2):\n        out_x1 = self.up_sample(x1)\n        out = torch.cat((out_x1, x2), dim = 1)\n        out = self.block(out)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class XNet(nn.Module):\n    def __init__(self, iterations = 3):\n        super().__init__()\n        self.conv1 = ConvRelu(1, 64)\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size = 3, stride = 2, padding = 1),\n            CapXLayer(8, 8, 4, 8, 8, iterations = iterations),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace = True)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1),\n            CapXLayer(16, 8, 4, 16, 8, iterations = iterations),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True)\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1),\n            CapXLayer(16, 16, 8, 16, 16, iterations = iterations),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace = True)\n        )\n\n        self.upconv3 = DeConv(256 + 128, 256, 128)\n        self.upconv3_residual = nn.Sequential(\n            CapXLayer(16, 8, 4, 16, 8, iterations = iterations),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True)\n        )\n        self.upconv2 = DeConv(128 + 64, 128, 64)\n        self.upconv2_residual = nn.Sequential(\n            CapXLayer(8, 8, 4, 8, 8, iterations = iterations),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace = True)\n        )\n        self.upconv1 = DeConv(128, 96, 64)\n        self.upconv1_residual = nn.Sequential(\n            CapXLayer(8, 8, 4, 8, 8, iterations = iterations),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace = True)\n        )\n        self.re_conv = nn.Sequential(\n            ConvRelu(64, 32),\n            ConvRelu(32, 32),\n            nn.Conv2d(32, 1, kernel_size = 3, padding = 1),\n            nn.Sigmoid()\n        )\n        self.decoder = nn.Sequential(\n            ConvRelu(64, 32),\n            ConvRelu(32, 32),\n            nn.Conv2d(32, 1, kernel_size = 3, padding = 1),\n            nn.Sigmoid()\n        )\n        self.relu = nn.ReLU(inplace = True)\n        self.prob_head = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n        \n        \n    def forward(self, input, mask = None):\n        out_conv1 = self.conv1(input)\n        out_conv2 = self.conv2(out_conv1)\n        out_conv3 = self.conv3(out_conv2)\n        out_conv4 = self.conv4(out_conv3)\n        out_up3   = self.upconv3(out_conv4, out_conv3)\n        out_up3_r = self.upconv3_residual(out_up3)\n        out_up2   = self.upconv2(out_up3_r, out_conv2)\n        out_up2_r = self.upconv2_residual(out_up2)\n        out_up1   = self.upconv1(out_up2_r, out_conv1)\n        out_up1_r = self.upconv1_residual(out_up1)\n        out_prob = self.prob_head(out_conv4)\n        out = self.decoder(out_up1_r)\n        if mask is not None:\n            out_re = self.re_conv(out_up1_r * mask)\n        else:\n            out_re = None\n        return out_prob, out, out_re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary(XNet(), (1, 128, 128))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_margin_loss(m_pos, m_neg, scale = .5):\n    def margin_loss(inputs, targets):\n        diff = torch.where(targets == 1, m_pos - inputs, inputs - m_neg)\n        diff = F.relu(diff)\n        diff = diff ** 2\n        diff = torch.where(targets == 1, diff, scale * diff)\n        return diff.mean()\n    return margin_loss\ndef get_acc_score(input, target):\n    pred = (input > 0.5).to(torch.float32)\n    return torch.mean((pred == target).to(torch.float32))\ndef dice_score(inputs, targets, smooth = 1e-6):\n    num = (2 * (inputs * targets).sum(dim = [1, 2, 3]) + smooth) \n    de = (inputs.sum(dim = [1, 2, 3]) + targets.sum(dim = [1, 2, 3]) + smooth)\n    return torch.mean(num / de)\ndef val_dice_score(inputs, targets, threshold = 0.5, smooth = 1e-6):\n    inputs = torch.where(inputs > threshold, 1., 0.)\n    num = (2 * (inputs * targets).sum(dim = [1, 2, 3]) + smooth) \n    de = (inputs.sum(dim = [1, 2, 3]) + targets.sum(dim = [1, 2, 3]) + smooth)\n    return torch.mean(num / de)\ndef dice_loss(inputs, targets, smooth = 1e-6):\n    return 1 - dice_score(inputs, targets, smooth)\ndef focal_loss(inputs, targets, alpha = 0.8, gamma = 2, reduction = 'mean'):\n    assert reduction in ['none', 'mean', 'sum']\n    loss = F.binary_cross_entropy(inputs, targets, reduction = 'none')\n    coeff = (1 - inputs) ** gamma\n    loss = coeff * loss\n    focal_loss = torch.where(targets == 1, loss, loss * alpha)\n    if reduction == \"none\": return focal_loss\n    elif reduction == \"mean\": return focal_loss.mean()\n    elif reduction == \"sum\": return focal_loss.sum()\n    else:\n        raise Exception()\nclass IoULoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, inputs, targets, smooth = 1e-6):\n        \n        intersection = (inputs * targets).sum(dim = [1, 2, 3])\n        total = (inputs + targets).sum(dim = [1, 2, 3])\n        union = total - intersection \n        \n        IoU = (intersection + smooth)/(union + smooth)\n                \n        return 1 - IoU.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ComboLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bce = nn.BCELoss()\n        self.iou = IoULoss()\n        self.mse = nn.MSELoss()\n    def forward(self, input1, target1, input2, target2, input3 = None, target3 = None, weight_factors = [2, 1, 2, 2]):\n        return self.bce(input1, target1) * weight_factors[0] + \\\n                self.iou(input1, target1) * weight_factors[1] + \\\n                focal_loss(input1, target1) * weight_factors[2] + \\\n                self.bce(input2, target2) * weight_factors[3] + (self.mse(input3, target3) * 0.005 if input3 is not None else 0)\n                    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = glob(os.path.join('..', 'input', 'siim-train-test', 'dicom-images-train', '*', '*', '*.dcm'))\ndf = pd.read_csv(\"../input/siim-train-test/train-rle.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nINIT_LR = 1e-5\nBATCH_SIZE = 12\nTRAIN_RATE = 0.7\nEPOCHS = 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths, test_paths = train_test_split(paths, train_size = TRAIN_RATE, random_state = 22)\nnp.random.seed(22)\nnp.random.shuffle(test_paths)\ntest_size = len(test_paths) // 2\nval_paths = test_paths[:test_size]\ntest_paths = test_paths[test_size:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = A.Compose([\n    A.HorizontalFlip(),\n    A.OneOf([\n        A.RandomContrast(),\n        A.RandomGamma(),\n        A.RandomBrightness(),\n        ], p = 0.4),\n    A.OneOf([\n        A.Blur(blur_limit = 5), \n        A.MedianBlur(blur_limit = 5)\n    ], p = 0.4),\n    A.ShiftScaleRotate(shift_limit = 0.01, rotate_limit = 15, border_mode = cv.BORDER_CONSTANT)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = XrayDataset(train_paths, df, target_shape = (256, 256), props = (11, 9), transforms = transforms)\nval_dataset = XrayDataset(val_paths, df, target_shape = (256, 256), mode = 'val')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\nval_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XNet(1).to(DEVICE)\n# swa_model = AveragedModel(model)\noptimizer = torch.optim.Adam(model.parameters(), lr = INIT_LR)\n# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, get_lr_scheduler, verbose = True)\n# swa_scheduler = SWALR(optimizer, anneal_epochs = 5, swa_lr = 1e-3)\n# criterion = ComboLoss().to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = ComboLoss().to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/newcaps2107/checkpoint_epoch_r1_29_07.tar', map_location = DEVICE)['model'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ITERS_PER_EPOCH = len(train_dataset) // BATCH_SIZE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_weight_prob_decay = lambda x: max(0.4, -1.6 * x / (10 * ITERS_PER_EPOCH) + 2)\n# iter_count = 0\nfor epoch in range(EPOCHS):\n    model.train()\n    bar = tqdm(enumerate(train_loader), total = ITERS_PER_EPOCH)\n    for i, (images, masks, rois, lbs) in bar:\n        images = images.to(DEVICE)\n        masks = masks.to(DEVICE)\n        rois = rois.to(DEVICE)\n        lbs = lbs.to(DEVICE)\n        optimizer.zero_grad()\n        pred_probs, pred_masks, pred_rois = model(images)\n        loss = criterion(pred_masks, masks, pred_probs, lbs, pred_rois, rois, weight_factors = [3, 2, 3, 1])\n        loss.backward()\n        optimizer.step()\n        with torch.no_grad():\n            val_dice = val_dice_score(pred_masks, masks).cpu().item()\n            acc = get_acc_score(pred_probs, lbs).cpu().item()\n            dice = dice_score(pred_masks, masks).cpu().item()\n#         iter_count += 1\n        bar.set_description(f'epoch {epoch + 1} iter {i + 1} loss {loss.cpu().detach().item(): .6f} dice {dice:.4f} acc {acc: .4f} val_dice {val_dice :.4f}')\n    torch.save({\n        'epoch': epoch,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'iter': i\n        }, f'checkpoint_epoch_{epoch + 1}.tar')\n    model.eval()\n    with torch.no_grad():\n        acc_loss = 0\n        acc_dice = 0\n        count = 0\n        acc_acc = 0\n        for images, masks, rois, lbs in tqdm(val_loader):\n            images = images.to(DEVICE)\n            masks  = masks.to(DEVICE)\n#             rois = rois.to(DEVICE)\n            lbs = lbs.to(DEVICE)\n            pred_probs, pred_masks, _ = model(images)\n            loss = criterion(pred_masks, masks, pred_probs, lbs)\n            acc_loss += loss.cpu().item()         \n            acc_dice += val_dice_score(pred_masks, masks).cpu().item()\n            acc_acc  += get_acc_score(pred_probs, lbs).cpu().item()\n            count += 1\n        acc_loss /= count\n        acc_dice /= count\n        acc_acc  /= count\n        with open('log.txt', 'a') as f:\n            f.write(f'[VAL] epoch {epoch + 1} loss {acc_loss: .4f} dice {acc_dice: .4f} acc {acc_acc: .4f}\\n')\n        print(f'[VAL] epoch {epoch + 1} loss {acc_loss: .4f} dice {acc_dice: .4f} acc {acc_acc: .4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lbs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idx = 1\n# plt.imshow(pred_masks.detach().cpu().numpy()[idx, 0], 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_masks.detach().cpu().numpy()[idx, 0].max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(masks.cpu().numpy()[idx, 0], 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save({\n#         'epoch': epoch,\n#         'model': model.state_dict(),\n#         'optimizer': optimizer.state_dict(),\n#         'iter': i\n#         }, f'checkpoint_epoch_r1_29_07.tar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with torch.no_grad():\n#         acc_loss = 0\n#         acc_dice = 0\n#         count = 0\n#         acc_acc = 0\n#         for images, masks, rois, lbs in tqdm(val_loader):\n#             images = images.to(DEVICE)\n#             masks  = masks.to(DEVICE)\n# #             rois = rois.to(DEVICE)\n#             lbs = lbs.to(DEVICE)\n#             pred_probs, pred_masks, _ = model(images)\n#             loss = criterion(pred_masks, masks, pred_probs, lbs)\n#             acc_loss += loss.cpu().item()         \n#             acc_dice += val_dice_score(pred_masks, masks).cpu().item()\n#             acc_acc  += get_acc_score(pred_probs, lbs).cpu().item()\n#             count += 1\n#         acc_loss /= count\n#         acc_dice /= count\n#         acc_acc  /= count\n#         with open('log.txt', 'a') as f:\n#             f.write(f'[VAL] epoch {epoch + 1} loss {acc_loss: .4f} dice {acc_dice: .4f} acc {acc_acc: .4f}\\n')\n#         print(f'[VAL] epoch {epoch + 1} loss {acc_loss: .4f} dice {acc_dice: .4f} acc {acc_acc: .4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}