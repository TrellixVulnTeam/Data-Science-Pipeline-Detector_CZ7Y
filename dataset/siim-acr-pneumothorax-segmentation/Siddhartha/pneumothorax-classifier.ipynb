{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel i train a classifier using fastai. The classifieer data used for training is genereated [here](https://www.kaggle.com/meaninglesslives/make-pneumothorax-classifer-data). I use pretrained imagenet weights for seresnext50.\n\nI use the trained classifier to modify the submission in [my efficientnet kernel](https://www.kaggle.com/meaninglesslives/unet-plus-plus-with-efficientnet-encoder). The idea is that the trained unet may predict masks even when there is no pneumothorax. Zeroing out wrongly predicted masks will help us get a better performance."},{"metadata":{},"cell_type":"markdown","source":"# Loading Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai import *\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\nimport fastai","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import fastprogress\nfastprogress.fastprogress.NO_BAR = True\nmaster_bar, progress_bar = fastprogress.force_console_behavior()\nfastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar\nfastai.basic_data.master_bar, fastai.basic_data.progress_bar = master_bar, progress_bar\ndataclass.master_bar, dataclass.progress_bar = master_bar, progress_bar\n\nfastai.core.master_bar, fastai.core.progress_bar = master_bar, progress_bar\nseed = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making the training set and dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input')\n!tar -xf /kaggle/input/make-pneumothorax-classifer-data/classifier_data.tar.gz -C .\n!tar -xf /kaggle/input/make-pneumothorax-classifer-data/test_data.tar.gz -C .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n                      max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2))])\n\n\npath = '/kaggle/working/classifier_data'\npath_test = '/kaggle/working/test'\n\ndata = (ImageList.from_folder(path)\n        .split_by_rand_pct(seed=seed)\n        .label_from_folder()\n        .transform(tfms, size=224)\n        .databunch().normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(12,9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class names and number of classes\n# print(data.classes)\nlen(data.classes),data.c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels\nimport pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1., gamma=2.):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets, **kwargs):\n        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-CE_loss)\n        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n        return F_loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnext50_32x4d(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n    return nn.Sequential(*list(model.children()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, resnext50_32x4d, pretrained=True, cut=-2,\n                    split_on=lambda m: (m[0][3], m[1]), \n                    metrics=[accuracy])\nlearn.loss_fn = FocalLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stage 1 training with size 128"},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.fit_one_cycle(32, max_lr=slice(2e-2), wd=1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('resnext50_32x4d_1');\nlearn.unfreeze();\nlearn = learn.clip_grad();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.load('resnext50_32x4d_1');\nlearn.unfreeze();\nlearn = learn.clip_grad();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lr = [3e-3/100, 3e-3/20, 3e-3/10]\nlearn.fit_one_cycle(36, lr, wd=1e-7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('resnext50_32x4d_2');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Size 224"},{"metadata":{"trusted":true},"cell_type":"code","source":"SZ = 224\ncutout_frac = 0.20\np_cutout = 0.75\ncutout_sz = round(SZ*cutout_frac)\ncutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)\n\ntfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n                      max_zoom=1.05, max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_folder(path)\n        .split_by_rand_pct(seed=seed)\n        .label_from_folder()\n        .transform(tfms, size=224)\n        .databunch().normalize(imagenet_stats))\n\nlearn.data = data\nlearn.bs = 32\ndata.train_ds[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.load('resnext50_32x4d_2');\nlearn.freeze();\nlearn = learn.clip_grad();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.loss_func = FocalLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.fit_one_cycle(24, slice(3e-3), wd=5e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('resnext50_32x4d_3');\nlearn.load('resnext50_32x4d_3');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.unfreeze();\nlearn = learn.clip_grad();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lr = [1e-3/200, 1e-3/20, 1e-3/10]\nlearn.fit_one_cycle(32, lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('resnext50_32x4d_4');\nlearn.load('resnext50_32x4d_4');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export('/kaggle/working/fastai_resnet.pkl');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = load_learner('/kaggle/working/','fastai_resnet.pkl', ImageList.from_folder(path_test))\npreds,_ = learn.get_preds(ds_type=DatasetType.Test)\ncls_pred = F.softmax(preds,1).argmax(1).cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = list(map(str,list(learn.data.test_ds.x.items)))\nall_test_paths = [p.split('/')[-1][:-4] for p in paths]\n\ndf_preds = pd.DataFrame()\ndf_preds['test_paths'] = all_test_paths\ndf_preds['class_pred'] = cls_pred\n\ndf_preds.set_index('test_paths',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_dis_idx = df_preds[df_preds.class_pred==1].index\nprint(len(no_dis_idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/unet-plus-plus-with-efficientnet-encoder/submission.csv'\n                  ,index_col='ImageId')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[no_dis_idx] = ' -1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('sub_classifier_correction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r */","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}