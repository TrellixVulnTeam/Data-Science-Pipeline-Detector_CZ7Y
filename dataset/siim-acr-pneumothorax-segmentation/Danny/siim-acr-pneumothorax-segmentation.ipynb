{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Overview\n\nCheck the competition: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation","metadata":{}},{"cell_type":"markdown","source":"## Dependencies","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pydicom\nfrom glob import glob\nimport sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"# Load rles\ntrain_csv_dir = '../input/siim-acr-pneumothorax-segmentation/stage_2_train.csv'\nrles_df = pd.read_csv(train_csv_dir)\n# Create a dic for images with masks\nrles_df = rles_df[rles_df['EncodedPixels']!='-1'].groupby('ImageId')['EncodedPixels']\\\n            .apply(list).reset_index()\nmasks = {}\nfor index, row in rles_df.iterrows():\n    masks[row['ImageId']] = row['EncodedPixels']\n\n# Create a list of image files\ntrain_stage1_fns = sorted(glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm'))\ntest_stage1_fns = sorted(glob('../input/siim-train-test/siim/dicom-images-test/*/*/*.dcm'))\ntrain_file_path = train_stage1_fns+test_stage1_fns","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model\n\nWe are implementing a UNet model","metadata":{}},{"cell_type":"code","source":"# Parameters\nimg_size = 128\nbatch_size = 32\nk_size = 3\ntrain_size = 0.2\ntest_size = 0.05\nshuffle = True\nchannels = 1\nepoch = 2\nsmooth = 1 \nverbose = 2  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a data generator\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, file_path_list, labels, batch_size=32, img_size=256, channels=1, shuffle=True):\n        self.file_path_list = file_path_list\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.channels = channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.file_path_list)) / self.batch_size)\n\n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        file_path_list_temp = [self.file_path_list[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(file_path_list_temp)\n        # return data \n        return X, y\n\n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.file_path_list))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, file_path_list_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        y = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n\n        for idx, file_path in enumerate(file_path_list_temp):\n\n            id = file_path.split('/')[-1][:-4]\n            rle = self.labels.get(id)\n            image = pydicom.read_file(file_path).pixel_array\n            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n            image_resized = np.array(image_resized, dtype=np.float64)\n\n            X[idx,] = np.expand_dims(image_resized, axis=2)\n\n            # if there is no mask create empty mask\n            # notice we are starting of with 1024 because we need to use the rle2mask function\n            \n            mask = np.zeros((1024, 1024))\n            if rle is not None:\n                for r in rle:\n                    mask =  mask + rle2mask(r, 1024, 1024).T\n\n            mask_resized = cv2.resize(mask, (self.img_size, self.img_size))\n            y[idx,] = np.expand_dims(mask_resized, axis=2)\n\n        # normalize \n        X = X / 255\n        y = y / 255\n\n        return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create generators for training and validating\nparams = {'img_size': img_size,\n          'batch_size': batch_size,\n          'channels': channels,\n          'shuffle': shuffle}\n\nX_train,X_val = train_test_split(train_file_path,train_size=train_size ,test_size=test_size)\n\ntrain_gen = DataGenerator(X_train,masks,**params)\nval_gen = DataGenerator(X_val,masks,**params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample batch\nx, y = train_gen.__getitem__(1)\nprint(x.shape, y.shape)\nn=8\nfig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(20,10))\nax[0].imshow(x[n,:,:,0],cmap='bone')\nax[1].imshow(y[n,:,:,0],cmap='Reds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper functions\ndef down_block(x, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'down sampling block of our UNet'\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    pool = MaxPool2D((2,2), (2,2))(conv)\n    return conv, pool\n\ndef up_block(x, skip, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'up sampling block of our UNet'\n    up_sample = UpSampling2D((2,2))(x)\n    concat = Concatenate()([up_sample, skip])\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(concat)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    return conv\n\ndef bottleneck(x, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'bottle neck that sits inbetween the down sampling side and the up sampling side'\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    return conv\n\ndef UNet(img_size):\n    'constructing UNet using the blocks defined above'\n    \n    # number of filters per block\n    f = [16, 32, 64, 128, 256]\n    inputs = Input((img_size, img_size, 1))\n    \n    p0 = inputs\n    c1, p1 = down_block(p0, f[0])\n    c2, p2 = down_block(p1, f[1])\n    c3, p3 = down_block(p2, f[2])\n    c4, p4 = down_block(p3, f[3])\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3])\n    u2 = up_block(u1, c3, f[2])\n    u3 = up_block(u2, c2, f[1])\n    u4 = up_block(u3, c1, f[0])\n    \n    outputs = Conv2D(1, (1,1), padding='same', activation='sigmoid')(u4)\n    model = Model(inputs, outputs)\n    return model\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = tf.keras.layers.Flatten()(y_true)\n    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet(img_size)\nadam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\nmodel.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_gen, validation_data=val_gen, epochs=epoch, verbose=verbose)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}