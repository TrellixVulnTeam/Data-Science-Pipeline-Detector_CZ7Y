{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport glob\nimport os, sys\nimport json\nimport pprint\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm_notebook as tqdm\nfrom PIL import Image\nfrom skimage.transform import resize\n\nsns.set_style('darkgrid')\nsns.set_palette('bone')\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sys.path.insert(0, '/kaggle/input/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/siim-acr-pneumothorax-segmentation-data/pneumothorax'\n\nrle = pd.read_csv(f'{path}/train-rle.csv')\nrle.columns = ['ImageId','EncodedPixels']\nprint(rle.shape)\nrle.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rle['ImageId'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = rle['EncodedPixels'].map(lambda x: 'none' if x != ' -1' else 'pneumothorax').value_counts()\ncounts.plot.barh(figsize=(10,3))\ncounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fns = sorted(glob.glob(f'{path}/dicom-images-train/*/*/*.dcm'))\ntest_fns = sorted(glob.glob(f'{path}/dicom-images-test/*/*/*.dcm'))\n\nprint('The training set contains {} files.'.format(len(train_fns)))\nprint('The test set contains {} files.'.format(len(test_fns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_id = rle['ImageId'].unique()\nfile_id = list(map(lambda x: x.split('/')[-1][:-4], train_fns))\nprint('only ImageId data:',len([f for f in unique_id if f not in file_id]))\nprint('only image files:', len([f for f in file_id if f not in unique_id]))\ndel unique_id, file_id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## dicom image"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom as dicom\n\nd = dicom.read_file(train_fns[0])\nprint(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(d.pixel_array.shape)\nprint(d.pixel_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axis = plt.subplots(2, 3, figsize=(14,9))\naxis = np.ravel(axis)\n\nfor ax, n in zip(axis, [2,3,4,5,6,7]):\n    d = dicom.read_file(train_fns[n])\n    ax.axis('off')\n    ax.imshow(d.pixel_array, cmap='bone')\n    ax.imshow(rle2mask(rle.iloc[n, 1], d.Columns, d.Rows), alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## compress image"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axis = plt.subplots(1, 2, figsize=(10,4))\n\npa128 = resize(d.pixel_array, (128,128), mode='constant', preserve_range=True)\naxis[0].imshow(d.pixel_array, cmap='bone')\naxis[1].imshow(pa128, cmap='bone')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## load images"},{"metadata":{"trusted":true},"cell_type":"code","source":"_='''\ndim = 1024\n\ntrain_img = {}\ntargetId = rle['ImageId'].values\nfor n in tqdm(range(len(train_fns))):\n    d = dicom.read_file(train_fns[n])\n    imageId = train_fns[n].split('/')[-1][:-4]\n    if imageId in targetId:\n        train_img[imageId] = [d.pixel_array / 256]\n        #train_img[imageId] = [resize(d.pixel_array, (dim, dim), mode='constant', preserve_range=True).tolist()]\n        train_img[imageId] = np.resize(train_img[imageId], (dim, dim, 1))\n\nX_train = [train_img[i] for i in rle['ImageId']]\nY_train = [np.expand_dims(rle2mask(px, 1024, 1024).T, axis=2) if px != ' -1' else np.zeros((1024, 1024, 1)) for px in rle['EncodedPixels']]\n#Y_train = [np.ravel(rle2mask(px, 1024, 1024)) if px != ' -1' else np.zeros(dim * dim) for px in rle['EncodedPixels']][:1000]\n#Y_train = (rle.iloc[:,1] != ' -1').astype(int)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del train_fns\n#del rle, train_img\ngc.collect()\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import optimizers\nfrom keras import backend as K\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, Flatten, Conv2D, UpSampling2D, MaxPooling2D, BatchNormalization, Permute, concatenate\nfrom keras.utils import np_utils\n\n# 2D blocks\ndef conv2D_block(inputs, filters, activation, padding, batchnorm=False):\n    conv = Conv2D(filters, 3, activation=activation, padding=padding)(inputs)\n    if batchnorm:\n        conv = BatchNormalization()(conv)\n    conv = Conv2D(filters, 3, activation=activation, padding=padding)(conv) \n    if batchnorm:\n        conv = BatchNormalization()(conv)\n    return conv\n\ndef conv2D_maxpool_block(inputs, filters, activation, padding, batchnorm=False):\n    conv = conv2D_block(inputs, filters, activation, padding)\n    pool = MaxPooling2D()(conv)\n    return pool, conv\n\ndef upsamp_conv2D_block(conv_prev, conv_direct, filters, activation, padding, batchnorm=False):\n    up = UpSampling2D()(conv_prev)\n    conc = concatenate([up, conv_direct])\n    cm = conv2D_block(conc, filters, activation, padding, batchnorm)\n    return cm\n\ndef build_unet2D(inp_shape=(None, None, 1)):\n    inputs = Input(shape=inp_shape)\n    \n    # Three conv pool blocks\n    p1, c1 = conv2D_maxpool_block(inputs, 16, 'relu', 'same', False)\n    p2, c2 = conv2D_maxpool_block(p1, 32, 'relu', 'same', False)\n    p3, c3 = conv2D_maxpool_block(p2, 64, 'relu', 'same', False)\n    p4, c4 = conv2D_maxpool_block(p3, 128, 'relu', 'same', False)\n\n    # Fourth conv -- lowest point\n    c5 = conv2D_block(p4, 256, 'relu', 'same', False)\n\n    # Three upsampling conv blocks\n    cm2 = upsamp_conv2D_block(c5, c4, 128, 'relu', 'same', False)\n    cm3 = upsamp_conv2D_block(cm2, c3, 64, 'relu', 'same', False)\n    cm4 = upsamp_conv2D_block(cm3, c2, 32, 'relu', 'same', False)\n    cm5 = upsamp_conv2D_block(cm4, c1, 16, 'relu', 'same', False)\n\n    # Output\n    predictions = Conv2D(1, 1, activation='sigmoid')(cm5)\n    model = Model(inputs, predictions)\n\n    return model\n\nmodel = build_unet2D(inp_shape=(1024, 1024, 1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(1024,1024), n_channels=1,\n                 shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            X[i,] = np.expand_dims(dicom.read_file(ID).pixel_array, axis=2)\n            \n            stripped_id = ID.split('/')[-1][:-4]\n            if self.labels is not None:\n                rle = self.labels.get(stripped_id)\n\n                if rle is None:\n                    y[i,] = np.zeros((1024, 1024, 1))\n                else:\n                    if len(rle) == 1:\n                        y[i,] = np.expand_dims(rle2mask(rle[0], self.dim[0], self.dim[1]).T, axis=2)\n                    else: \n                        y[i,] = np.zeros((1024, 1024, 1))\n                        for x in rle:\n                            y[i,] =  y[i,] + np.expand_dims(rle2mask(x, 1024, 1024).T, axis=2)\n\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\n\nd = defaultdict(list)\nfor image_id, r in zip(rle['ImageId'], rle['EncodedPixels']):\n    d[image_id].append(r)\nannotated = {k: v for k, v in d.items() if v[0] != ' -1'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'dim': (1024, 1024),\n          'batch_size': 8,\n          'n_channels': 1,\n          'shuffle': True}\n\n# Generators\ntraining_generator = DataGenerator(train_fns[0:8000], annotated, **params)\nvalidation_generator = DataGenerator(train_fns[8000:10712], annotated, **params) \n\n# Compile model\noptimizer = optimizers.Adam(lr = 0.001, epsilon = 0.1)\nloss = dice_coef_loss\nmetrics= [dice_coef]\nmodel.compile(optimizer=optimizer, loss=loss, metrics= metrics)\n\n# Fit model\nmodel.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss_and_metrics = model.evaluate(np.array(X_train), np.array(Y_train), batch_size=128)\n#print(loss_and_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del X_train, Y_train \ngc.collect()\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = DataGenerator(test_fns, None, **params)\npred = model.predict_generator(test_generator, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rles = []\nfor p in tqdm(pred):\n    im = np.asarray(p)\n    rles.append(mask2rle(im, 1024, 1024))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_id = list(map(lambda x: x.split('/')[-1][:-4], test_fns))\nsubmission = pd.DataFrame({\n    \"ImageId\": file_id,\n    \"EncodedPixels\": rles})\nsubmission.loc[submission.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsubmission.to_csv(\"submission.csv\", index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}