{"cells":[{"metadata":{},"cell_type":"markdown","source":"I found this model in Kaggle and had good results using it to align lung images. It may be usefull for focusing on ROI region."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom einops import rearrange, reduce  # pip install einops (amazing lib!)\nimport cv2\nfrom itertools import starmap\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configure a few matplotlib parameters\nplt.rcParams['figure.figsize'] = [20, 10]\nplt.rcParams['image.interpolation'] = 'bilinear'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load images"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def extract_image(fname):\n    ds = pydicom.read_file(str(fname))\n    return ds.pixel_array\n\nfnames = list(Path('../input/siim-acr-pneumothorax-segmentation/sample images/').glob('*.dcm'))\nimgs = np.array(list(map(extract_image, fnames)))\nimgs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Input images')\nplt.imshow(rearrange(imgs, '(b1 b2) h w -> (b1 h) (b2 w)', b1=2));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load pre-trained UNet for lung segmentation\n\nWe will use the model trained here: https://www.kaggle.com/eduardomineo/u-net-lung-segmentation-montgomery-shenzhen/"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet = load_model('../input/u-net-lung-segmentation-montgomery-shenzhen/unet_lung_seg.hdf5', compile=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_input(img, width=512, height=512):\n    '''\n    Prepare image to be feed into model, according to definitions made by trained model\n    '''\n    # Resize\n    x = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n    \n    # Normalize\n    x = np.float32(x) / 255.\n    \n    # Add channel axis\n    x = x[..., np.newaxis]\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(list(map(prepare_input, imgs)))\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = unet.predict(X)\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Input images with lung segmentation')\nplt.imshow(rearrange(X, '(b1 b2) h w () -> (b1 h) (b2 w)', b1=2))\nplt.contour(rearrange(y_pred, '(b1 b2) h w () -> (b1 h) (b2 w)', b1=2), levels=[0.5], colors='r');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define function to crop using segmentation results\nThis function uses the output from unet to crop lungs. It has a few heuristics that I have to develop in order to better find the ROI."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import ndimage\n\n# Declare structure used in morphotology opening\nmorph_structure = np.ones((11, 11))\n\ndef crop_segmentation(mask, *others, width=512, height=512, extra_space=0.1):\n    '''\n    Crop using `mask` as input. `others` are optional arguments that will be croped using `mask`\n    as reference.\n    '''\n    # Binarize mask\n    mask_bin = np.squeeze(mask) > 0.5\n    \n    # Use morphology opening to reduce small structures detected.\n    mask_bin = ndimage.morphology.binary_opening(mask_bin, morph_structure)\n    \n    # This is one of the trickest part: will label each structure and keep only the 3 biggest ones.\n    # We assume that these three ones will include the background and two lungs\n    mask_bin_label, n_labels = ndimage.label(mask_bin, np.ones((3, 3), dtype=np.uint8))\n    used_labels = np.argsort(-np.bincount(mask_bin_label.ravel()))[:3]\n\n    # Remove from mask other objects that are not top-3\n    mask_bin &= np.in1d(mask_bin_label.reshape(-1), used_labels).reshape(mask_bin.shape)\n    \n    # Squeeze horizontal and vertical dimention to find where mask begins and ends\n    mask_bin_hor = mask_bin.any(axis=0)\n    mask_bin_ver = mask_bin.any(axis=1)\n\n    # Find index of first and last positive pixel\n    xmin, xmax = np.argmax(mask_bin_hor), len(mask_bin_hor)-np.argmax(mask_bin_hor[::-1])\n    ymin, ymax = np.argmax(mask_bin_ver), len(mask_bin_ver)-np.argmax(mask_bin_ver[::-1])\n    \n    # Add extra space\n    xextra = int((xmax-xmin) * extra_space)\n    yextra = int((ymax-ymin) * extra_space)\n    xmin -= xextra\n    xmax += xextra\n    ymin -= yextra\n    ymax += yextra\n    \n    # We will use affine transform to crop image. It will deal with padding image if necessary\n    # Note: `pts` will follow a L shape: top left, bottom left and bottom right\n    # For details see: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#affine-transformation\n    pts1 = np.float32([[xmin, ymin], [xmin, ymax], [xmax, ymax]])\n    pts2 = np.float32([[0, 0], [0, height], [width, height]])\n    M = cv2.getAffineTransform(pts1, pts2)\n\n    # Crop mask\n    mask_crop = cv2.warpAffine(mask, M, (height, width), flags=cv2.INTER_AREA, borderValue=0)\n    \n    if len(others) > 0:\n        # Crop others\n        others_crop = tuple(cv2.warpAffine(np.squeeze(other), M, (height, width), flags=cv2.INTER_AREA, borderValue=0) for other in others)\n        \n        return (mask_crop, ) + others_crop\n    else:\n        return mask_crop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_crop, X_crop = map(np.array, zip(*starmap(crop_segmentation, zip(y_pred, X))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Final results')\nplt.imshow(rearrange(X_crop, '(b1 b2) h w -> (b1 h) (b2 w)', b1=2))\nplt.contour(rearrange(y_crop, '(b1 b2) h w -> (b1 h) (b2 w)', b1=2), levels=[0.5], colors='r');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}