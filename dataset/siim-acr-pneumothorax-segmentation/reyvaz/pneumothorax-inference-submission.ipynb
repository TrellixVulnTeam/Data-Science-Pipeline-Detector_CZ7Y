{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Identify Pneumothorax Disease in Chest X-Rays, Inference Notebook\n\nMore information about training the networks can be found [here]( https://github.com/reyvaz/pneumothorax_detection)\n\n#### Uses a 2-step approach for the identification of pneumothorax disease on the test dataset images. \n\nThe 1st step attempts to classify x-rays as presenting pneumothorax disease or not. To do so, it uses an ensemble of EfficientNet based image classifiers. The ensemble predictions are the simple average across all classifiers in the ensemble. \n\nIn the 2nd step, if the image was classified as likely having the disease in step 1, it tries to identify the location of the disease within the x-ray image. To do this, it uses an ensemble of Unet and Unet++ segmentation CNNs, all with EfficientNet encoders. The mask predictions are the simple average predictions across all CNNs in the the ensemble.\n\n**Credits**:\n\nThis notebook was inspired by Siddharthaâ€™s [Unet Plus Plus with EfficientNet Encoder](https://www.kaggle.com/meaninglesslives/nested-unet-with-efficientnet-encoder) notebook.\n\n**References**:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, & Jian Sun. (2015). Deep Residual Learning for Image Recognition.\n\nMingxing Tan, & Quoc V. Le. (2020). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n\nOlaf Ronneberger, Philipp Fischer, & Thomas Brox. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation.\n\nZhou, Z., Siddiquee, M., Tajbakhsh, N., & Liang, J. (2019). UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation IEEE - Transactions on Medical Imaging.","metadata":{"papermill":{"duration":0.02629,"end_time":"2021-04-08T18:02:30.733841","exception":false,"start_time":"2021-04-08T18:02:30.707551","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Required Packages","metadata":{"papermill":{"duration":0.026345,"end_time":"2021-04-08T18:02:30.785168","exception":false,"start_time":"2021-04-08T18:02:30.758823","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, sys, re\nfrom time import time, strftime, gmtime\nstart_notebook = time()\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\n!git clone -q https://github.com/reyvaz/tpu_segmentation.git\n!pip config set global.disable-pip-version-check true >/dev/null\n!pip install -qr tpu_segmentation/requirements.txt >/dev/null\nfrom tpu_segmentation import *\n\nimport mask_functions as mf\n\nprint('Tensorflow version: ', tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":19.337264,"end_time":"2021-04-08T18:02:50.14821","exception":false,"start_time":"2021-04-08T18:02:30.810946","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution Strategy","metadata":{"papermill":{"duration":0.025584,"end_time":"2021-04-08T18:02:50.20187","exception":false,"start_time":"2021-04-08T18:02:50.176286","status":"completed"},"tags":[]}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n    print('TPU not found')\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu) \nelse:\n    strategy = tf.distribute.get_strategy()","metadata":{"papermill":{"duration":5.773996,"end_time":"2021-04-08T18:02:56.001669","exception":false,"start_time":"2021-04-08T18:02:50.227673","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Constants and TFRecs File Paths","metadata":{"papermill":{"duration":0.02833,"end_time":"2021-04-08T18:02:56.056248","exception":false,"start_time":"2021-04-08T18:02:56.027918","status":"completed"},"tags":[]}},{"cell_type":"code","source":"IMAGE_SIZE = [1024, 1024] # Original size of the images\nN_CLASSES = 1\nN_CHANNELS = 1\nN_REPLICAS = strategy.num_replicas_in_sync\n\ngcs_path = KaggleDatasets().get_gcs_path('siimacr-pneumothorax-segmentation-tfrecs')\nTFRECS_TEST = tf.io.gfile.glob(gcs_path + '/tfrecs/*test*.tfrec')\nn_test_examples = count_data_items(TFRECS_TEST)\nprint('Number of TEST TFRecs: ', len(TFRECS_TEST))\nprint('Number of TEST examples: ', n_test_examples)","metadata":{"papermill":{"duration":0.539095,"end_time":"2021-04-08T18:02:56.621504","exception":false,"start_time":"2021-04-08T18:02:56.082409","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Pipeline","metadata":{"papermill":{"duration":0.026721,"end_time":"2021-04-08T18:02:56.674876","exception":false,"start_time":"2021-04-08T18:02:56.648155","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def read_test_tfrecord(example, str_feat):\n    features = {\n        str_feat: tf.io.FixedLenFeature([], tf.string)\n        }\n    example = tf.io.parse_single_example(example, features)\n    return example[str_feat]\n        \ndef load_test_dataset(filenames, str_feat = 'image'):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.map(lambda x: read_test_tfrecord(x, str_feat), \n                          num_parallel_calls=AUTO)\n    return dataset\n\ndef decode_resize_image(image_data, target_size, image_size = IMAGE_SIZE,\n                        make_rgb = True, n_channels = N_CHANNELS):\n\n    image = tf.image.decode_jpeg(image_data, channels=n_channels)\n    image = tf.cast(image, tf.float32) / 255.0  \n    if target_size != image_size: image = tf.image.resize(image, target_size)\n    if make_rgb:\n        image = tf.image.grayscale_to_rgb(image)\n        n_channels = 3\n    return tf.reshape(image, [*target_size, n_channels]) \n\ndescribe_ds = lambda x: print(re.sub('[<>]', '', str(x)))\n\ndef get_test_dataset(filenames, target_size, imgs_per_replica, make_rgb = True):\n    \n    batch_size = imgs_per_replica * N_REPLICAS\n    n_test = count_data_items(filenames)\n    min_steps = np.ceil(n_test/batch_size).astype(int)\n\n    dataset = load_test_dataset(filenames)\n    dataset = dataset.map(lambda image: decode_resize_image(\n        image, target_size, make_rgb=make_rgb), AUTO)\n    \n    dataset = dataset.batch(batch_size).prefetch(AUTO) \n    describe_ds(dataset)\n    return dataset, n_test, min_steps","metadata":{"papermill":{"duration":0.042537,"end_time":"2021-04-08T18:02:56.743748","exception":false,"start_time":"2021-04-08T18:02:56.701211","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize Test Examples","metadata":{"papermill":{"duration":0.026151,"end_time":"2021-04-08T18:02:56.79627","exception":false,"start_time":"2021-04-08T18:02:56.770119","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n_rows, n_cols = 2, 5\n\ntemp_dataset = get_test_dataset(TFRECS_TEST[:1], (256, 256), 1, make_rgb = False)[0]\ntemp_dataset = temp_dataset.unbatch().take(n_rows*n_cols)\n\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(25, 4*n_rows))\nfor c, item in enumerate(temp_dataset):\n    ax = fig.axes[c]\n    ax.imshow(item, cmap=plt.cm.bone)\n    ax.axis('off')","metadata":{"papermill":{"duration":2.592072,"end_time":"2021-04-08T18:02:59.41497","exception":false,"start_time":"2021-04-08T18:02:56.822898","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pretrained Weights Metadata","metadata":{"papermill":{"duration":0.049758,"end_time":"2021-04-08T18:02:59.510923","exception":false,"start_time":"2021-04-08T18:02:59.461165","status":"completed"},"tags":[]}},{"cell_type":"code","source":"base_dir = '../input/pneumothorax-segmentation-base/'\nbin_meta = pd.read_csv(base_dir + 'bin_weights_meta.csv')\nseg_meta = pd.read_csv(base_dir + 'seg_weights_meta.csv')\nweigths_meta = bin_meta.append(seg_meta, ignore_index = True)\nweights_names = dict(zip(weigths_meta.key, weigths_meta.filename))","metadata":{"papermill":{"duration":0.09256,"end_time":"2021-04-08T18:02:59.65991","exception":false,"start_time":"2021-04-08T18:02:59.56735","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions to Build Ensembles","metadata":{"papermill":{"duration":0.045773,"end_time":"2021-04-08T18:02:59.751698","exception":false,"start_time":"2021-04-08T18:02:59.705925","status":"completed"},"tags":[]}},{"cell_type":"code","source":"weights_dir = base_dir + 'weights/'\n\ndef load_pretrained_model(weights_id, compile_model = True, opt = [], loss = [], \n                          metrics = 'default', details = []):\n\n    prefix, size = weights_id.split('_')\n    size = eval(size.replace('x', ', '))\n    base, base_ver, model_type, _  = prefix.split('-')\n    wname = weights_names[weights_id]\n    weights_path = weights_dir + wname\n\n    base_name = base + base_ver\n\n    if 'bin' in model_type: \n        builder = build_classifier\n        if metrics == 'default': metrics = ['accuracy', 'AUC']\n            \n    elif 'unetpp' in model_type: builder = xnet\n    elif 'unet' in model_type and not 'unetpp' in model_type: builder = unet\n    \n    if 'unet' in model_type and metrics == 'default': \n        metrics = [dice_coef, dice_avg]\n    \n    with strategy.scope():\n        model = builder(base_name, 1, input_shape=(*size, 3), weights = None)\n        model.load_weights(weights_path)\n        if compile_model: model.compile(optimizer=opt, loss=loss, metrics=metrics)\n            \n    if len(details) > 0: \n        scope = locals()\n        return (model, *[eval(d, scope) for d in details])\n    else: return model\n\ndef assemble_ensemble(weights_ids, outter_size = (1024, 1024), \n                      ensemble_type = 'binary', metrics = 'default'):\n    \n    ensemble_outputs = []\n    resized_inputs = {}\n    with strategy.scope():\n        x = L.Input(shape=(*outter_size, 3))\n        for i, w in enumerate(weights_ids):\n            model, size = load_pretrained_model(w, compile_model = False, details = ['size'])\n            model._name = '{}-M{}'.format(model.name, i)\n            if size == outter_size:\n                model_output = model(x)\n            else:\n                if not str(size) in resized_inputs: \n                    resized_inputs[str(size)] = tf.image.resize(x, size)\n                model_output = model(resized_inputs[str(size)])\n                if ensemble_type == 'segmentation':\n                    model_output = tf.image.resize(model_output, outter_size)\n\n            ensemble_outputs.append(model_output)\n\n        y = L.Average(name = 'Simple_Average')(ensemble_outputs)\n\n        if metrics == 'default':\n            if ensemble_type == 'segmentation': metrics = [dice_coef, dice_avg] \n            else: metrics = ['accuracy', 'AUC']\n\n        name = '{}_Ensemble'.format(ensemble_type.title())\n        ensemble = tf.keras.Model(inputs=x, outputs=y, name=name)\n        ensemble.compile(optimizer=[], loss=[], metrics=metrics)\n    return ensemble","metadata":{"papermill":{"duration":0.068013,"end_time":"2021-04-08T18:02:59.865614","exception":false,"start_time":"2021-04-08T18:02:59.797601","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Retrieving Ordered Image IDs from TFRecs","metadata":{"papermill":{"duration":0.044866,"end_time":"2021-04-08T18:02:59.955502","exception":false,"start_time":"2021-04-08T18:02:59.910636","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ids_ds = load_test_dataset(TFRECS_TEST, str_feat = 'img_id').batch(512)\ntest_ids_bytes = []\nfor item in ids_ds:\n    test_ids_bytes += list(item.numpy())\nassert len(test_ids_bytes) == 3205\n\ntest_ids = [i.decode() for i in test_ids_bytes]\nprint('Num Test Examples: ', len(test_ids))","metadata":{"papermill":{"duration":1.935694,"end_time":"2021-04-08T18:03:01.936505","exception":false,"start_time":"2021-04-08T18:03:00.000811","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Binary Predictions","metadata":{"papermill":{"duration":0.047799,"end_time":"2021-04-08T18:03:02.030105","exception":false,"start_time":"2021-04-08T18:03:01.982306","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Dataset for Binary Predictions","metadata":{"papermill":{"duration":0.046056,"end_time":"2021-04-08T18:03:02.123165","exception":false,"start_time":"2021-04-08T18:03:02.077109","status":"completed"},"tags":[]}},{"cell_type":"code","source":"filenames = TFRECS_TEST\ntarget_size = (1024, 1024)\nimgs_per_replica = 8\n\ntest_ds, n_test, min_steps = get_test_dataset(filenames, target_size, imgs_per_replica)","metadata":{"papermill":{"duration":0.114876,"end_time":"2021-04-08T18:03:02.283887","exception":false,"start_time":"2021-04-08T18:03:02.169011","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build Ensemble for Binary Predictions\n\nCNNs were trained across 5 cross-validation folds. The ensemble for binary predictions will include the top 2 best performing classifiers corresponding to each of the k-folds used during training. ","metadata":{"papermill":{"duration":0.046534,"end_time":"2021-04-08T18:03:02.376843","exception":false,"start_time":"2021-04-08T18:03:02.330309","status":"completed"},"tags":[]}},{"cell_type":"code","source":"temp = bin_meta.groupby('fold')['metric'].nlargest(2)\nidxs = [i[1] for i in temp.index]\nbinary_members = bin_meta.loc[idxs].reset_index(drop=True)\n\nbinary_ensemble_members = binary_members.key.values\nprint('Number of Binary Ensemble Members: {}'.format(len(binary_ensemble_members)))\n\nbinary_ensemble = assemble_ensemble(binary_ensemble_members)\nbinary_ensemble.summary()","metadata":{"papermill":{"duration":197.416568,"end_time":"2021-04-08T18:06:19.839706","exception":false,"start_time":"2021-04-08T18:03:02.423138","status":"completed"},"tags":[],"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Perform Binary Predictions","metadata":{"papermill":{"duration":0.04843,"end_time":"2021-04-08T18:06:19.93664","exception":false,"start_time":"2021-04-08T18:06:19.88821","status":"completed"},"tags":[]}},{"cell_type":"code","source":"start_binary_preds = time()\nbin_preds = binary_ensemble.predict(test_ds, verbose=1)\n\ntime_binary_preds = time() - start_binary_preds\nmin_secs = lambda secs: strftime(\"%M:%S\", gmtime(secs))\nprint('Time to make {} binary predictions: {} (MM:SS)'.format(n_test, min_secs(time_binary_preds)))","metadata":{"papermill":{"duration":237.351176,"end_time":"2021-04-08T18:10:17.336245","exception":false,"start_time":"2021-04-08T18:06:19.985069","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bin_preds = bin_preds.squeeze()\nbinary_probs = dict(zip(test_ids, bin_preds))\nbinary_preds_df = pd.DataFrame(binary_probs.items(), columns = ['ImageId', 'pred_prob'])\n\ndisplay(binary_preds_df.head())","metadata":{"papermill":{"duration":0.092024,"end_time":"2021-04-08T18:10:17.491994","exception":false,"start_time":"2021-04-08T18:10:17.39997","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del binary_ensemble","metadata":{"papermill":{"duration":0.073556,"end_time":"2021-04-08T18:10:17.630278","exception":false,"start_time":"2021-04-08T18:10:17.556722","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mask Predictions","metadata":{"papermill":{"duration":0.064107,"end_time":"2021-04-08T18:10:17.759568","exception":false,"start_time":"2021-04-08T18:10:17.695461","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Build Segmentation Ensemble","metadata":{"papermill":{"duration":0.063928,"end_time":"2021-04-08T18:10:17.887806","exception":false,"start_time":"2021-04-08T18:10:17.823878","status":"completed"},"tags":[]}},{"cell_type":"code","source":"size = (544, 544)\nsegmentation_ensemble_members = seg_meta.key.values\nprint('Number of Segmentation Ensemble Members: {}'.format(len(segmentation_ensemble_members)))\n\nsegmentation_ensemble = assemble_ensemble(segmentation_ensemble_members,\n                                          outter_size = size, ensemble_type = 'segmentation' )\nsegmentation_ensemble.summary()","metadata":{"papermill":{"duration":265.374826,"end_time":"2021-04-08T18:14:43.328299","exception":false,"start_time":"2021-04-08T18:10:17.953473","status":"completed"},"tags":[],"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mask Prediction Dataset(s)\n\nUnlike for the binary predictions, there's not sufficient memory to store the predicted masks for the entire test dataset. These mask predicitions are required for post-processing before encoding into RLE. \n\nAlthough mask predictions are not required for the entire test dataset (i.e. mask predictions for images predicited negative for pneumothorax are not needed), in order to take advantage of the TPU during inference, mask predictions will be done for all test images. \n\nFor this, the test dataset will be divided into several parts. Predictions will sequentially be made for each part, post-processed, and rle-encoded.","metadata":{"papermill":{"duration":0.066443,"end_time":"2021-04-08T18:14:43.460225","exception":false,"start_time":"2021-04-08T18:14:43.393782","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_ds, n_test, total_steps = get_test_dataset(filenames, size, imgs_per_replica)\nprint('Total prediction steps: ', total_steps)\n\nn_parts = 3\nlen_part = np.ceil(min_steps/n_parts).astype(int)\nprint('Max steps per part:', len_part)\n\nds_remain = test_ds\ntest_ds_parts = []\nfor d in range(n_parts):\n    dset = ds_remain.take(len_part)\n    test_ds_parts.append(dset)\n    ds_remain = ds_remain.skip(len_part)","metadata":{"papermill":{"duration":0.122164,"end_time":"2021-04-08T18:14:43.647749","exception":false,"start_time":"2021-04-08T18:14:43.525585","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict Mask, Post-Process, Encode and Record RLE","metadata":{"papermill":{"duration":0.065502,"end_time":"2021-04-08T18:14:43.77915","exception":false,"start_time":"2021-04-08T18:14:43.713648","status":"completed"},"tags":[]}},{"cell_type":"code","source":"binary_treshhold = 0.60\nthresh_max = 0.75\nthresh_min = 0.40\nmin_area = 200\n\npred_rles = dict([[id, -1] for id in test_ids])\nprelim_masked = binary_preds_df.ImageId[binary_preds_df.pred_prob > binary_treshhold].values\nstart_mask_preds = time()\n\ni = 0\nmasked_ids = []\nfor p, test_ds_part in enumerate(test_ds_parts): \n    print('\\nPredicting and processing part {} of {}'.format(p+1, n_parts))\n    preds = segmentation_ensemble.predict(test_ds_part, verbose = 1)\n    preds = np.squeeze(preds)\n    print('Shape of predictions matrix {}: {}\\n'.format(p+1, preds.shape))\n\n    for pred in preds:\n        test_id = test_ids[i]\n        if binary_probs[test_id] > binary_treshhold:\n            pred_ = pred.copy()\n            pred  = (pred > thresh_max).astype(int)\n            if pred.sum() > min_area: \n                pred = (pred_ > thresh_min).astype(int)\n                pred = np.expand_dims(pred, axis = 2)\n                pred_mask = tf.image.resize(pred, IMAGE_SIZE)\n                pred_mask = np.squeeze(pred_mask)\n                pred_mask = (np.round(pred_mask)*255).astype(int)\n                mask_rle = mf.mask2rle(pred_mask.T, *IMAGE_SIZE)\n                pred_rles[test_id] = mask_rle\n                masked_ids.append(test_id)\n        i += 1\n    del preds, pred, pred_, pred_mask\n\ntime_mask_preds = time() - start_mask_preds\ndel segmentation_ensemble\nprint('Time to predict and post-process {} images: {} (MM:SS)'.format(n_test, min_secs(time_mask_preds)))","metadata":{"papermill":{"duration":1043.814514,"end_time":"2021-04-08T18:32:07.659558","exception":false,"start_time":"2021-04-08T18:14:43.845044","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Predicted Examples","metadata":{"papermill":{"duration":0.083898,"end_time":"2021-04-08T18:32:07.827778","exception":false,"start_time":"2021-04-08T18:32:07.74388","status":"completed"},"tags":[]}},{"cell_type":"code","source":"skip = 100\ndemo_ds = test_ds_parts[0].unbatch().skip(skip)\n\nn_rows = 2\nn_cols = 5\n\nmasked_examples = {}\nunmasked_examples = {}\nmax_examples = n_rows*n_cols\n\nfor i, image in enumerate(demo_ds):\n    test_id = test_ids[i+skip]\n    if test_id in masked_ids and len(masked_examples) < max_examples:\n        masked_examples[test_id] = image\n    elif not test_id in masked_ids and len(unmasked_examples) < max_examples: \n        unmasked_examples[test_id] = image\n    if len(masked_examples) == len(unmasked_examples) == max_examples: break\n","metadata":{"papermill":{"duration":0.680845,"end_time":"2021-04-08T18:32:08.592938","exception":false,"start_time":"2021-04-08T18:32:07.912093","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predictions with Pneumothorax Disease","metadata":{"papermill":{"duration":0.084138,"end_time":"2021-04-08T18:32:08.762152","exception":false,"start_time":"2021-04-08T18:32:08.678014","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, axs = plt.subplots(n_rows, n_cols, figsize=(25, 4*n_rows))\nfor c, (img_id, image) in enumerate(masked_examples.items()):\n    image = tf.image.resize(image, IMAGE_SIZE)\n    \n    mask = mf.rle2mask(pred_rles[img_id], *IMAGE_SIZE)/255\n    mask = contoured_mask(mask.T, rgb_color = (200, 0, 150), alpha = 0.35)\n\n    ax = fig.axes[c]\n    ax.imshow(image, cmap=plt.cm.bone)\n    ax.imshow(mask)\n    ax.axis('off')\n    ax.set_title('Image ID: {}'.format(img_id), fontdict={'fontsize': 13})","metadata":{"papermill":{"duration":16.197341,"end_time":"2021-04-08T18:32:25.04371","exception":false,"start_time":"2021-04-08T18:32:08.846369","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predictions with no Pneumothorax Disease","metadata":{"papermill":{"duration":0.098222,"end_time":"2021-04-08T18:32:25.24033","exception":false,"start_time":"2021-04-08T18:32:25.142108","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, axs = plt.subplots(n_rows, n_cols, figsize=(25, 4*n_rows))\nfor c, (img_id, image) in enumerate(unmasked_examples.items()):\n    ax = fig.axes[c]\n    ax.imshow(image, cmap=plt.cm.bone)\n    ax.axis('off')\n    ax.set_title('Image ID: {}'.format(img_id), fontdict={'fontsize': 13})","metadata":{"papermill":{"duration":1.414116,"end_time":"2021-04-08T18:32:26.751097","exception":false,"start_time":"2021-04-08T18:32:25.336981","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission File","metadata":{"papermill":{"duration":0.109299,"end_time":"2021-04-08T18:32:26.970442","exception":false,"start_time":"2021-04-08T18:32:26.861143","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sub_df = pd.DataFrame(pred_rles.items(), columns=['ImageId', 'EncodedPixels'])\nsub_df.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.982331,"end_time":"2021-04-08T18:32:28.061244","exception":false,"start_time":"2021-04-08T18:32:27.078913","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf tpu_segmentation mask_functions.py __pycache__","metadata":{"papermill":{"duration":0.913122,"end_time":"2021-04-08T18:32:29.08484","exception":false,"start_time":"2021-04-08T18:32:28.171718","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_notebook = time() - start_notebook\nprint('Time to run notebook {} (MM:SS)'.format(min_secs(time_notebook)))","metadata":{"papermill":{"duration":0.119176,"end_time":"2021-04-08T18:32:29.313773","exception":false,"start_time":"2021-04-08T18:32:29.194597","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}