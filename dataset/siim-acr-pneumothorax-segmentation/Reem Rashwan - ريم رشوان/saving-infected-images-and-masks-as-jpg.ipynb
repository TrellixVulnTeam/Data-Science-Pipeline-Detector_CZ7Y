{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[:5]:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport tqdm\nimport sys\nimport pydicom\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sys.path.append(\"/kaggle/input/siim-acr-pneumothorax-segmentation/\")\nfrom mask_functions import mask2rle, rle2mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_path = \"/kaggle/input/siim-train-test/dicom-images-train\"\ntest_images_path = \"/kaggle/input/siim-train-test/dicom-images-test/_/_/\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"masks_data_path = \"/kaggle/input/siim-train-test/train-rle.csv\"\n\nmasks_data = pd.read_csv(masks_data_path)\nmasks_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masks_data.rename(columns={' EncodedPixels': 'EncodedPixels'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masks_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Length of masks data-frame: {len(masks_data)}\")\nprint(f\"Length of images in training dir: {len(os.listdir(train_images_path))}\")\nprint(f\"Length of images in testing dir: {len(os.listdir(test_images_path))}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The length of the masks and the images doesn't match, maybe this is becuase that each image has multiple entries. Lets check."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique images in masks dataframe: {masks_data.ImageId.nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only positive cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"masks_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = masks_data[masks_data.EncodedPixels != '-1'].reset_index(drop=True)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.ImageId[0])\n# print(dataset.ImagePath[0].split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{},"cell_type":"markdown","source":"### Visualize a sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_mask = rle2mask(dataset.iloc[dataset.index[0]]['EncodedPixels'], 1024, 1024)\nsample_image = pydicom.dcmread(dataset.iloc[dataset.index[0]]['ImagePath']).pixel_array\nplt.imshow(sample_mask, cmap='gray')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(sample_mask.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(sample_image, cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(sample_image + sample_mask.T * 0.4, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_mask.T.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_mask.T.dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize a bunch of samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(images, cols = 1, titles = None):\n    \"\"\"Display a list of images in a single figure with matplotlib.\n    \n    Parameters\n    ---------\n    images: List of np.arrays compatible with plt.imshow.\n    \n    cols (Default = 1): Number of columns in figure (number of rows is \n                        set to np.ceil(n_images/float(cols))).\n    \n    titles: List of titles corresponding to each image. Must have\n            the same length as titles.\n    \"\"\"\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(np.ceil(n_images/float(cols)), cols, n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.axis('off')\n        plt.imshow(image)\n        a.set_title(title)\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sample_images_and_masks(samples):\n    images = []\n    titles = []\n    for i in range(len(samples)):\n        image = pydicom.dcmread(samples.iloc[i].ImagePath).pixel_array\n        mask = rle2mask(samples.iloc[i].EncodedPixels, 1024, 1024).T\n        masked_image = image + mask * 0.4\n        \n        images.extend([image, mask, masked_image])\n        titles.extend([f\"{i} image\", f\"{i} mask\", f\"{i} masked_image\"])\n        \n    show_images(images=images, titles=titles, cols=3)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = dataset[dataset.EncodedPixels != '-1'].sample(3).reset_index(drop=True)\nsamples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sample_images_and_masks(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Width and Height"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_WIDTH = 254\nIMG_HEIGHT = 254","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combine Masks for The Same Image"},{"metadata":{},"cell_type":"markdown","source":"1. Extract masks\n2. Get images with more than one mask\n3. Combine masks\n4. Merge with full data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test on a sample\n# m1 = dataset.Mask.values[0]\n# m2 = dataset.Mask.values[22]\n# m3 = np.sum(m1, m2)\n# plt.imshow(m3)\n# plt.imshow(np.clip(m3, 0, 255))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract Masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting masks\n# dataset['Mask'] = dataset.EncodedPixels.apply(lambda cell_value: cv2.resize(rle2mask(cell_value, 1024, 1024).T, (IMG_WIDTH, IMG_HEIGHT)))\ndataset['Mask'] = dataset.EncodedPixels.apply(lambda cell_value: rle2mask(cell_value, 1024, 1024).T)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get images with more than one mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_ids_count = dataset[['ImageId', 'Mask']].groupby(['ImageId']).Mask.count()  # don't use small c in count\nids_with_one_mask = unique_ids_count[unique_ids_count == 1].reset_index()\nids_with_more_than_one_mask = unique_ids_count[unique_ids_count > 1].reset_index()\n# ids_with_more_than_one_mask\n# ids_with_one_mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combine "},{"metadata":{"trusted":true},"cell_type":"code","source":"one_mask_data = pd.merge(dataset[['ImageId', 'Mask']], ids_with_one_mask.ImageId, on='ImageId', how='right')\nmore_than_one_mask_data = pd.merge(dataset[['ImageId', 'Mask']], ids_with_more_than_one_mask.ImageId, on='ImageId', how='right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_than_one_mask_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combine masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_masks =  more_than_one_mask_data[['ImageId', 'Mask']].groupby('ImageId').Mask.apply(np.sum)\ncombined_masks = combined_masks.apply(np.clip, a_min=0, a_max=1).reset_index()  # maybe some masks are overlapped, so when sum it will exceed 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(combined_masks.Mask.sample(1).values[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Putting It All Together (Combining Single and Multi Mask Images)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# combined_masks.head()\n# one_mask_data.head()\n\nfinal_dataset = pd.concat([combined_masks, one_mask_data], ignore_index=True)\nfinal_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Save Images and Masks on Disk \nConvert dcm into jpg."},{"metadata":{},"cell_type":"markdown","source":"### Get Each Image Path"},{"metadata":{},"cell_type":"markdown","source":"We need to match each entry with its corresponding image to insure that each image has a mask and vice versa."},{"metadata":{"trusted":true},"cell_type":"code","source":"images_paths = glob.glob(f\"{train_images_path}/*/*/*.dcm\")\nprint(len(images_paths))\n# print(images_paths[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image_id(image_path):\n    image_name = image_path.rsplit(\"/\", maxsplit=1)[-1]\n    return image_name[:-4]  # id without extension\n\ndef get_images_path_and_id(images_paths):\n    images_data = pd.DataFrame(columns=['ImageId', 'ImagePath'])\n#     for image_path in tqdm.notebook.tqdm(images_paths):\n    for image_path in tqdm.tqdm_notebook(images_paths):\n        image_id = get_image_id(image_path)\n        images_data = images_data.append({'ImageId': image_id, 'ImagePath': image_path}, ignore_index=True)\n        \n    return images_data\n\ndef get_images_path_and_id(images_paths):\n    images_data = pd.DataFrame(columns=['ImageId', 'ImagePath'])\n    images_data = {\"ImageId\": [], \"ImagePath\": []}\n#     for image_path in tqdm.notebook.tqdm(images_paths):\n    for image_path in tqdm.tqdm_notebook(images_paths):\n        image_id = get_image_id(image_path)\n        images_data['ImageId'].append(image_id)\n        images_data['ImagePath'].append(image_path)\n        \n    images_data = pd.DataFrame(images_data)\n    \n    return images_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_paths_and_ids = get_images_path_and_id(images_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_paths_and_ids.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset = pd.merge(images_paths_and_ids, final_dataset, on='ImageId', how='inner')\nfinal_dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save Images to Disk As JPG"},{"metadata":{"trusted":true},"cell_type":"code","source":"# arrange dataset \nfinal_dataset = final_dataset.sort_values('ImageId', ascending=True).reset_index(drop=True)\nfinal_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dir(dirname):\n    try:\n        os.makedirs(dirname)\n        print(f\"Directory '{dirname}' created.\") \n    except FileExistsError:\n        print(f\"Directory '{dirname}' already exists.\") \n\n\n# create a train directory\ntrain_images_dir = '/kaggle/working/train/images'\ntrain_masks_dir = '/kaggle/working/train/masks'\n\ncreate_dir(train_images_dir)\ncreate_dir(train_masks_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_dcm_to_folder_as_jpg(dcm_id, dcm_path, destination_path):\n    # read image\n    dcm_file = pydicom.dcmread(dcm_path)\n    # to np array\n    image_array = dcm_file.pixel_array\n    save_np_array_as_image(dcm_id, image_array, destination_path)\n\n    \ndef save_np_array_as_image(image_id, image_array, destination_path):\n    image = convert_image_array_to_pil_image(image_array).convert('L')\n     # save to disk\n    image.save(os.path.join(destination_path, f\"{image_id}.jpg\"))\n    \n    \ndef convert_image_array_to_pil_image(image_array):\n    image = Image.fromarray(image_array)  # to gray\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save dcm as jpg\nfinal_dataset.apply(lambda row: extract_dcm_to_folder_as_jpg(row['ImageId'], row['ImagePath'], train_images_dir), axis=1)\nprint(f\"Done saving {len(os.listdir(train_images_dir))} images.\")\n# tqdm.tqdm_notebook.pandas()\n# dataset.progress_apply(lambda row: extract_dcm_to_folder_as_jpg(row['ImageId'], row['ImagePath'], train_images_dir), axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save Masks to Disk"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.apply(lambda row: save_np_array_as_image(row['ImageId'], row['Mask'], train_masks_dir), axis=1)\nprint(f\"Done saving {len(os.listdir(train_masks_dir))} masks.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensure that we saved masks correctly."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = final_dataset.sample(1)\nsample_path = os.path.join(train_masks_dir, sample.ImageId.values[0]) + '.jpg'\nsample_mask_image = Image.open(sample_path)\nsample_mask_array = sample.Mask.values[0]\n\nprint(\"Array\")\nplt.imshow(sample_mask_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Saved image\")\nplt.imshow(sample_mask_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}