{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI_For_Healthcare_Ex2_Image_Segmentation\n\nIn this excersice, we tried to build a U-net learning model for Image segmentation of X-Ray images.","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nfrom glob import glob\n\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as image\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nimport pydicom\nfrom pydicom.data import get_testdata_files\n\n# libraries For building the model\nimport torch\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate\nimport cv2\n\nprint(os.listdir(\"../input/siim-acr-pneumothorax-segmentation\"))\nprint()\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n\nfrom mask_functions import mask2rle, rle2mask\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-15T19:10:00.843479Z","iopub.execute_input":"2022-05-15T19:10:00.844036Z","iopub.status.idle":"2022-05-15T19:10:01.95518Z","shell.execute_reply.started":"2022-05-15T19:10:00.843986Z","shell.execute_reply":"2022-05-15T19:10:01.952697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\n\nprint(device_lib.list_local_devices())\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.957103Z","iopub.status.idle":"2022-05-15T19:10:01.957698Z","shell.execute_reply.started":"2022-05-15T19:10:01.957464Z","shell.execute_reply":"2022-05-15T19:10:01.957487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load information of the dataset\n\nWe actually used another data set that was stored in this notebook: https://www.kaggle.com/datasets/seesee/siim-train-test (Doesn't exists anymore). It has the same files but with minor changes in the meatadata and mybe also in the number of files.","metadata":{}},{"cell_type":"code","source":"# Create a list of image files\ntrain_imgs_paths = sorted(glob('../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/*/*/*.dcm'))\nprint(\"Train images -\", len(train_imgs_paths))\n\ntest_imgs_paths = sorted(glob('../input/siim-acr-pneumothorax-segmentation-data/dicom-images-test/*/*/*.dcm'))\nprint(\"Test images -\", len(test_imgs_paths))\nfile_paths = train_imgs_paths + test_imgs_paths","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.958878Z","iopub.status.idle":"2022-05-15T19:10:01.959265Z","shell.execute_reply.started":"2022-05-15T19:10:01.959077Z","shell.execute_reply":"2022-05-15T19:10:01.959102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load information for dataset\ndata_df = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-data/train-rle.csv')\ndata_df.rename(columns={\" EncodedPixels\" : \"EncodedPixels\"}, inplace=True) # a typo in the csv\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.961092Z","iopub.status.idle":"2022-05-15T19:10:01.96147Z","shell.execute_reply.started":"2022-05-15T19:10:01.961286Z","shell.execute_reply":"2022-05-15T19:10:01.961306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The Images & metadata","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\n# Showing 10 sample images\nfor q, file_path in enumerate(file_paths):\n    if q == 8:\n        # See the metadata included in the image file\n        print(ds)\n        print()\n        break\n    ds = pydicom.dcmread(file_path)\n    plt.subplot(1,8,q+1)\n    plt.title('Input Images')\n    plt.imshow(ds.pixel_array, cmap='gray') \n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.963045Z","iopub.status.idle":"2022-05-15T19:10:01.963808Z","shell.execute_reply.started":"2022-05-15T19:10:01.963593Z","shell.execute_reply":"2022-05-15T19:10:01.963617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get information from images","metadata":{}},{"cell_type":"code","source":"def get_metadata(dicom, df):\n    \"\"\"\n    Maps the metadata from the dcm file to an image Id that we actually have in the labeled data (df)\n    \"\"\"\n    metadata = {}\n\n    matching_image = df['ImageId'] == dicom.SOPInstanceUID\n    # meaning we didn't find any matching image to df image id \n    if matching_image.eq(False).all():\n        return {}\n\n    encoded_pixels = df[matching_image]['EncodedPixels'].values\n\n    metadata['patient sex'] = dicom.PatientSex\n    metadata['patient age'] = dicom.PatientAge\n    metadata['view position'] = dicom.ViewPosition\n    metadata['has pneumothorax'] = encoded_pixels[0] != ' -1'\n    metadata['encoded pixels'] = encoded_pixels\n\n    return metadata","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.965092Z","iopub.status.idle":"2022-05-15T19:10:01.965608Z","shell.execute_reply.started":"2022-05-15T19:10:01.965425Z","shell.execute_reply":"2022-05-15T19:10:01.965448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_metadata = []\n    \nfor file_path in file_paths:\n    ds = pydicom.dcmread(file_path)\n    metadata = get_metadata(ds, data_df)\n    if metadata != {}:\n        all_metadata.append(metadata)\n\nmetadata_df = pd.DataFrame(all_metadata)\nmetadata_df.head()\nprint(metadata_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.966932Z","iopub.status.idle":"2022-05-15T19:10:01.967305Z","shell.execute_reply.started":"2022-05-15T19:10:01.967129Z","shell.execute_reply":"2022-05-15T19:10:01.967151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of the data\n\nWe wanted to see the distribution of the data from the dcm files - # of men/women, Age distribution, How much people are with pneumothorax. We used the metadata data frame that we created earlier.","metadata":{}},{"cell_type":"code","source":"precent_pneumothorax = ((metadata_df['has pneumothorax'] == True).sum())/len(metadata_df)\nprecent_no_pneumothorax = 1-precent_pneumothorax\nlabels = ['Pneumothorax', 'No Pneumothorax']\ncolors = sns.color_palette('pastel')\nplt.pie([precent_pneumothorax, precent_no_pneumothorax], labels = labels, colors = colors, autopct='%.2f%%')\nplt.title(\"Precentage of Pneumothorax vs. No Pneumothorax\")\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.968839Z","iopub.status.idle":"2022-05-15T19:10:01.969368Z","shell.execute_reply.started":"2022-05-15T19:10:01.969163Z","shell.execute_reply":"2022-05-15T19:10:01.969185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(metadata_df, x='patient sex', hue='has pneumothorax', palette='flare').set(title='Distribution of Female and Male with and without Pneumothorax');","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.970548Z","iopub.status.idle":"2022-05-15T19:10:01.970881Z","shell.execute_reply.started":"2022-05-15T19:10:01.970709Z","shell.execute_reply":"2022-05-15T19:10:01.970731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_genders = metadata_df['patient sex'].value_counts()\nmen_with_pneumothorax = metadata_df.loc[(metadata_df['patient sex'] == 'M') & (metadata_df['has pneumothorax'] == True)].count()[0]\nwomen_with_pneumothorax = metadata_df.loc[(metadata_df['patient sex'] == 'F') & (metadata_df['has pneumothorax'] == True)].count()[0]\n\nprint(\"% of men with pneumothorax\", round(men_with_pneumothorax/count_genders['M']*100, 2), '%')\nprint(\"% of women with pneumothorax\", round(women_with_pneumothorax/count_genders['F']*100, 2), '%')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.972286Z","iopub.status.idle":"2022-05-15T19:10:01.972874Z","shell.execute_reply.started":"2022-05-15T19:10:01.972666Z","shell.execute_reply":"2022-05-15T19:10:01.97269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that \n1. More men patients than women\n2. More men have been diagnosed with pneumothorax. \n\nThe precentage of men which have pneumothorax from the tested group is: ~ 22.5% and of the women is: ~ 21.7%","metadata":{}},{"cell_type":"markdown","source":"Preparing the data for feading the model:","metadata":{}},{"cell_type":"code","source":"# Load rles\nrles_df = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-data/train-rle.csv')\nrles_df = rles_df.rename(columns={' EncodedPixels':'EncodedPixels'})\nrles_df['EncodedPixels'] = rles_df['EncodedPixels'].apply(lambda x: x.strip())\n\n# Create a dictionary for images with masks\nrles_df = rles_df[rles_df['EncodedPixels'] !='-1'].groupby('ImageId')['EncodedPixels'].apply(list).reset_index()\nprint(len(rles_df))\n\nmasks = {}\nfor index, row in rles_df.iterrows():\n    masks[row['ImageId']] = row['EncodedPixels']\nprint(len(masks))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.974216Z","iopub.status.idle":"2022-05-15T19:10:01.974564Z","shell.execute_reply.started":"2022-05-15T19:10:01.97438Z","shell.execute_reply":"2022-05-15T19:10:01.974402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Learning Model\nWe played with the different parameters and changed a little the architecture","metadata":{}},{"cell_type":"code","source":"# Parameters\nimg_size = 128\nbatch_size = 8\nk_size = 3\ntrain_size = 0.7\ntest_size = 0.05\nshuffle = True\nchannels = 1\nepoch = 10\nsmooth = 1 \nverbose = 2","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.975807Z","iopub.status.idle":"2022-05-15T19:10:01.976168Z","shell.execute_reply.started":"2022-05-15T19:10:01.975992Z","shell.execute_reply":"2022-05-15T19:10:01.976014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a data generator\n# The data generator will help us hold the images and the masks\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, file_path_list, labels, batch_size=32, img_size=256, channels=1, shuffle=True):\n        self.file_path_list = file_path_list\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.channels = channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.file_path_list)) / self.batch_size)\n\n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        file_path_list_temp = [self.file_path_list[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(file_path_list_temp)\n        # return data \n        return X, y\n\n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.file_path_list))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, file_path_list_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        y = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n\n        for idx, file_path in enumerate(file_path_list_temp):\n\n            id = file_path.split('/')[-1][:-4]\n            rle = self.labels.get(id)\n            image = pydicom.read_file(file_path).pixel_array\n            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n            image_resized = np.array(image_resized, dtype=np.float64)\n\n            X[idx,] = np.expand_dims(image_resized, axis=2)\n\n            # if there is no mask create empty mask\n            # notice we are starting of with 1024 because we need to use the rle2mask function\n            \n            mask = np.zeros((1024, 1024))\n            if rle is not None:\n                for r in rle:\n                    mask =  mask + rle2mask(r, 1024, 1024).T\n\n            mask_resized = cv2.resize(mask, (self.img_size, self.img_size))\n            y[idx,] = np.expand_dims(mask_resized, axis=2)\n\n        # normalize \n        X = X / 255\n        y = y / 255\n\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.977663Z","iopub.status.idle":"2022-05-15T19:10:01.978321Z","shell.execute_reply.started":"2022-05-15T19:10:01.978114Z","shell.execute_reply":"2022-05-15T19:10:01.978137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create generators for training and validating\nparams = {'img_size': img_size,\n          'batch_size': batch_size,\n          'channels': channels,\n          'shuffle': shuffle}\n\nX_train, X_val = train_test_split(train_imgs_paths, test_size=test_size, train_size=train_size)\nprint(len(X_train))\nprint(len(X_val))\n\ntrain_gen = DataGenerator(X_train, masks, **params)\nval_gen = DataGenerator(X_val, masks, **params)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.979305Z","iopub.status.idle":"2022-05-15T19:10:01.979972Z","shell.execute_reply.started":"2022-05-15T19:10:01.97968Z","shell.execute_reply":"2022-05-15T19:10:01.979705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample batch\nfor i in range(8):    \n    x, y = train_gen.__getitem__(i)\n    print(x.shape, y.shape)\n    n=1\n    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(10,7))\n    ax[0].imshow(x[n,:,:,0],cmap='bone')\n    ax[1].imshow(y[n,:,:,0],cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.981286Z","iopub.status.idle":"2022-05-15T19:10:01.981858Z","shell.execute_reply.started":"2022-05-15T19:10:01.981604Z","shell.execute_reply":"2022-05-15T19:10:01.98163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper functions\ndef down_block(x, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'down sampling block of our UNet'\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    pool = MaxPool2D((2,2), (2,2))(conv)\n    return conv, pool\n\ndef up_block(x, skip, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'up sampling block of our UNet'\n    up_sample = UpSampling2D((2,2))(x)\n    concat = Concatenate()([up_sample, skip])\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(concat)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    return conv\n\ndef bottleneck(x, filters, kernel_size=3, padding='same', strides=1, activation='relu'):\n    'bottle neck that sits inbetween the down sampling side and the up sampling side'\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=activation)(conv)\n    return conv\n\ndef UNet(img_size):\n    'constructing UNet using the blocks defined above'\n    \n    # number of filters per block\n    f = [16, 32, 64, 128, 256]\n    inputs = Input((img_size, img_size, 1))\n    p0 = inputs\n    c1, p1 = down_block(p0, f[0])\n    c2, p2 = down_block(p1, f[1])\n    c3, p3 = down_block(p2, f[2])\n    c4, p4 = down_block(p3, f[3])\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3])\n    u2 = up_block(u1, c3, f[2])\n    u3 = up_block(u2, c2, f[1])\n    u4 = up_block(u3, c1, f[0])\n    \n    outputs = Conv2D(1, (1,1), padding='same', activation='sigmoid')(u4)\n    model = Model(inputs, outputs)\n    return model\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = tf.keras.layers.Flatten()(y_true)\n    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.983183Z","iopub.status.idle":"2022-05-15T19:10:01.98352Z","shell.execute_reply.started":"2022-05-15T19:10:01.983338Z","shell.execute_reply":"2022-05-15T19:10:01.983364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet(img_size)\n\nadam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\nmodel.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.984944Z","iopub.status.idle":"2022-05-15T19:10:01.985359Z","shell.execute_reply.started":"2022-05-15T19:10:01.985204Z","shell.execute_reply":"2022-05-15T19:10:01.985219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_gen, validation_data=val_gen, epochs=epoch, verbose=verbose)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.986078Z","iopub.status.idle":"2022-05-15T19:10:01.986815Z","shell.execute_reply.started":"2022-05-15T19:10:01.986599Z","shell.execute_reply":"2022-05-15T19:10:01.986625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Model did not really learn or improve after running more than 10 epochs.","metadata":{}},{"cell_type":"code","source":"test_gen = DataGenerator(test_imgs_paths, masks, **params)\n\n\nresults = model.evaluate(test_gen, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.987929Z","iopub.status.idle":"2022-05-15T19:10:01.988234Z","shell.execute_reply.started":"2022-05-15T19:10:01.988077Z","shell.execute_reply":"2022-05-15T19:10:01.988092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"test loss, test acc:\", results)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.989558Z","iopub.status.idle":"2022-05-15T19:10:01.990179Z","shell.execute_reply.started":"2022-05-15T19:10:01.989975Z","shell.execute_reply":"2022-05-15T19:10:01.989995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = model.predict(test_gen)\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.991093Z","iopub.status.idle":"2022-05-15T19:10:01.991715Z","shell.execute_reply.started":"2022-05-15T19:10:01.991547Z","shell.execute_reply":"2022-05-15T19:10:01.991564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the 20 first predictions (3rd column is the actual masks)\nfor i in range(20):    \n    x, y2 = test_gen.__getitem__(i)\n    n=1\n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(10,7))\n    ax[0].imshow(x[n,:,:,0],cmap='bone')\n    ax[1].imshow(y[i][:,:,0],cmap='Blues')\n    ax[1].imshow(y2[n,:,:,0],cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:10:01.992547Z","iopub.status.idle":"2022-05-15T19:10:01.993218Z","shell.execute_reply.started":"2022-05-15T19:10:01.992989Z","shell.execute_reply":"2022-05-15T19:10:01.993026Z"},"trusted":true},"execution_count":null,"outputs":[]}]}