{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport glob\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data\nCheck the competition page for the details of the data: https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles","metadata":{}},{"cell_type":"code","source":"# Read all txt files into a panda dataframe\ndef importData():\n   \n    path='../input/data-science-for-good-city-of-los-angeles/cityofla/CityofLA/Job Bulletins/*.txt'\n    files=glob.glob(path)\n    jobs_list=[]\n    file_names=[]\n    for file in files:\n        with open(file,'r',errors='replace') as f:\n            jobs_list.append(f.read())\n        match = re.search('Bulletins/(.*\\.txt)',file)\n        file_names.append(match.group(1))\n    jobs_df = pd.DataFrame({\"File_Name\":file_names,\"job_info\":jobs_list})\n    \n    return jobs_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract data using regex","metadata":{}},{"cell_type":"code","source":"# Define functions for pandas dataframe apply\n\n# Get job title (JOB_CLASS_TITLE)\ndef get_job_title(text):\n    title = text.split('\\n',1)[0]\n    return title.strip()\n\n# Get class code (JOB_CLASS_NO)\ndef get_class_code(text):\n    match = re.search(r'Class\\s*Code:\\s*(\\d+)',text)\n    if match:\n        return match.group(1)\n    else:\n        return None\n\n    \n# Get open date (OPEN_DATE)\ndef get_open_date(text):\n    match = re.search(r'Open\\s*Date:\\s*(\\d+-\\d+-\\d+)',text)\n    if match:\n        return match.group(1)\n    else:\n        return None\n\n# Get exam type\ndef get_exam_type(text):\n    match = re.search(r'(?s)Open\\s*Date(.*?)ANNUAL\\s*SALARY',text)\n    if match:\n        result = match.group(1)\n        op=re.search(r'open',result,flags=re.IGNORECASE)\n        open_int_prom=re.search(r'(open.*comp.*?tive)|(comp.*?tive.*open)',result,flags=re.IGNORECASE)\n        int_dept_prom=re.search(r'inter.*?mental',result,flags=re.IGNORECASE)\n        dept_prom=re.search(r'dep.*?mental',result,flags=re.IGNORECASE)\n        if int_dept_prom:\n            return 'INT_DEPT_PROM'\n        elif dept_prom:\n            return 'DEPT_PROM'\n        elif open_int_prom:\n            return 'OPEN_INT_PROM'\n        elif op:\n            return 'OPEN'\n        else:\n            return None\n    else:\n        return None\n    \n# Get general salary (ENTRY_SALARY_GEN)\ndef get_salary_gen(text):\n    match = re.search(r'(?s)ANNUAL\\s*SALARY(.*?)DUTIES.*',text)\n    if match:\n        result = match.group(1)\n        sal=re.search(r'(\\d+,\\d+.*?to.*?\\d+,\\d+|\\d+,\\d+).*?Water.*Power',text,flags=re.IGNORECASE)\\\n                if get_salary_dwp(text) else re.search(r'(\\d+,\\d+.*?to.*?\\d+,\\d+|\\d+,\\d+)',text,flags=re.IGNORECASE)\n        if sal:\n            return sal.group(1).replace('to','-').replace('$','')\n        else:\n            return None\n    else:\n        return None\n\n\n# Get DWP salary (ENTRY_SALARY_DWP)\ndef get_salary_dwp(text):\n    match = re.search(r'(?s)ANNUAL\\s*SALARY(.*?)DUTIES.*',text)\n    if match:\n        result = match.group(1)\n        sal=re.search(r'Water.*Power.*?(\\d+,\\d+.*?to.*?\\d+,\\d+|\\d+,\\d+)',text)\n        if sal:\n            return sal.group(1).replace('$','').replace('to','-')\n        else:\n            return None \n    else:\n        return None\n    \n# Get driver license req (DRIVERS_LICENSE_REQ)\ndef get_dl_req(text):\n    match= re.search(r\"(.*?)driver\\'s license\",text)    \n    if match:\n        result = match.group(1).lower().split()\n        if 'may' in result:\n            return 'P'\n        else:\n            return 'R'\n    else:\n        return None\n    \n# Get driver license type (DRIV_LIC_TYPE)\ndef get_dl_type(text):\n    dl_types=[]\n    match= re.search(r\"(?s)(valid California Class|valid Class|valid California Commercial Class)(.*?)(California driver\\'s license|driver\\'s license)\",text)\n    if match:\n        dl=match.group(2)\n        if 'A' in dl:\n            dl_types.append('A')\n        if 'B' in dl:\n            dl_types.append('B') \n        if 'C' in dl:\n            dl_types.append('C')  \n        if 'I' in dl:\n            dl_types.append('I')   \n        return ','.join(dl_types)\n    else:\n        return None\n\n# Get duties (JOB_DUTIES)\ndef get_duties(text):\n    match= re.search(r\"(?s)DUTIES(.*?)(REQ.*?MENT|MINI.*?REQ)\", text)\n    if match:\n        return match.group(1).strip()\n    else:\n        return None\n\n# Get requirements section\ndef get_req_section(text):  \n    match= re.search(r\"(?s)(QUAL.*?TIONS*|REQ.*?MENTS*).*?\\n(.*?)(PROCESS NOTES|NOTES|WHERE TO APPLY|HOW TO APPLY)\", text)\n    if match:\n        return match.group(2).strip()\n    else:\n        return None\n\n# Split requirements to rows\ndef split_req(df):\n    req_list = df['Req_section'].apply(lambda x: re.split(r'or\\s*\\n+(?=\\d\\.)', x))\n    df = pd.DataFrame({col:np.repeat(df[col].values, req_list.str.len()) \\\n                  for col in df.columns})\n    df['req_list'] = np.concatenate(req_list.values)\n\n    return df\n    \n    \n# Extract all by regex\ndef extract_df(df):    \n    # JOB_CLASS_TITLE\n    df['JOB_CLASS_TITLE'] = df['job_info'].apply(lambda x: get_job_title(x))\n    # JOB_CLASS_NO\n    df['JOB_CLASS_NO'] = df['job_info'].apply(lambda x: get_class_code(x))\n    # OPEN_DATE\n    df['OPEN_DATE'] = df['job_info'].apply(lambda x: get_open_date(x))\n    # EXAM_TYPE\n    df['EXAM_TYPE'] = df['job_info'].apply(lambda x: get_exam_type(x))\n    # ENTRY_SALARY_GEN\n    df['ENTRY_SALARY_GEN'] = df['job_info'].apply(lambda x: get_salary_gen(x))\n    # ENTRY_SALARY_DWP\n    df['ENTRY_SALARY_DWP'] = df['job_info'].apply(lambda x: get_salary_dwp(x))\n    # JOB_DUTIES\n    df['JOB_DUTIES'] = df['job_info'].apply(lambda x: get_duties(x))\n    # DRIVERS_LICENSE_REQ\n    df['DRIVERS_LICENSE_REQ'] = df['job_info'].apply(lambda x: get_dl_req(x))\n    # DRIV_LIC_TYPE\n    df['DRIV_LIC_TYPE'] = df['job_info'].apply(lambda x: get_dl_type(x))\n    # Requirements section\n    df['Req_section'] = df['job_info'].apply(lambda x: get_req_section(x))\n    # Split reqs\n    df = split_req(df)\n    # Add req_set_id\n    df['REQUIREMENT_SET_ID'] = df.groupby('JOB_CLASS_NO').cumcount() + 1\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform the extraction\ndf = importData()\ndf = extract_df(df)\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract data using NER in spaCy","metadata":{}},{"cell_type":"markdown","source":"## Generate spacy training data","metadata":{}},{"cell_type":"code","source":"import logging\nimport json\n# Convert json to spacy training data structure\ndef json_to_spacy(filePath):\n    try:\n        training_data = []\n        lines=[]\n        with open(filePath, 'r') as f:\n            lines = f.readlines()\n\n        for line in lines:\n            data = json.loads(line)\n            text = data['content']\n            entities = []\n            for annotation in data['annotation']:\n                #only a single point in text annotation.\n                point = annotation['points'][0]\n                labels = annotation['label']\n                # handle both list of labels or a single label.\n                if not isinstance(labels, list):\n                    labels = [labels]\n\n                for label in labels:\n                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n                    entities.append((point['start'], point['end'] + 1 ,label))\n\n\n            training_data.append((text, {\"entities\" : entities}))\n\n        return training_data\n    except Exception as e:\n        logging.exception(\"Unable to process \" + filePath + \"\\n\" + \"error = \" + str(e))\n        return None\n    \n# Create spacy training data\ntrain_data = json_to_spacy('../input/ner-annotation-of-city-of-la-jobs/city_la_jobs_ner_labeling.json')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train NER model","metadata":{}},{"cell_type":"code","source":"import random\nimport spacy\n\n# Model training function\ndef ner_model(train_data, n_iter=50):\n    \n    # Create Ner model and add labels\n    nlp = spacy.blank(\"en\")\n    ner = nlp.create_pipe(\"ner\")\n    nlp.add_pipe(ner, last=True)\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n    \n    # Begin training\n    nlp.begin_training()\n    \n    for itn in range(n_iter):\n        random.shuffle(train_data)\n        losses = {}\n        batches = spacy.util.minibatch(train_data, size=spacy.util.compounding(4.0, 32.0, 1.001))\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            nlp.update(texts,annotations,drop=0.5,losses=losses)\n        if itn%10==0:\n            print(losses)\n    return nlp\n\nnlp = ner_model(train_data)\nnlp.to_disk('./')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the model with predictions\nfor text, _ in train_data:\n    doc = nlp(text)\n    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract using NER model","metadata":{}},{"cell_type":"code","source":"# Extract data by ner model\ndef ner_extract(nlp,text):\n    doc = nlp(text)\n    return [(ent.text, ent.label_) for ent in doc.ents]\n\n# Extract requirements \ndf['temp_req'] = df['req_list'].apply(lambda x: ner_extract(nlp,x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create CSV","metadata":{}},{"cell_type":"markdown","source":"##  Flatten the temp_req column","metadata":{}},{"cell_type":"code","source":"# Extract one column from list\ndef extract_col(l,col):\n    result = [x[0] for x in l if x[1]==col]\n    return None if result==[] else result[0]\n\n# Extract colums from temp_req column\ndef extract_col_df(df,col):\n    df[col]=df['temp_req'].apply(lambda x: extract_col(x,col))\n    return df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract coulums in df\ncols_to_extract = ['EDUCATION_YEARS', 'SCHOOL_TYPE' ,'EDUCATION_MAJOR', 'EXPERIENCE_LENGTH' ,\\\n                   'FULL_TIME_PART_TIME','EXP_JOB_CLASS_TITLE', 'EXP_JOB_CLASS_ALT_RESP',\\\n                   'EXP_JOB_CLASS_FUNCTION', 'EXP_JOB_CLASS_ADDITIONAL_FUNCTION','COURSE_COUNT',\\\n                   'COURSE_LENGTH', 'COURSE_SUBJECT', 'MISC_COURSE_DETAILS', 'EXP_JOB_COMPANY',\\\n                   'DEGREE NAME', 'EXP_JOB_CLASS_ALT_JOB_TITLE', 'REQUIRED_CERTIFICATE',\\\n                   'CERTIFICATE_ISSUED_BY','COURSE_TITLE', 'REQUIRED_EXAM_PASS', 'EXPERIENCE_EXTRA_DETAILS']\n\nfor col in cols_to_extract:\n    df = extract_col_df(df,col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_orders = ['File_Name','JOB_CLASS_TITLE', 'JOB_CLASS_NO', \n                 'REQUIREMENT_SET_ID',\n                 'JOB_DUTIES','EDUCATION_YEARS', 'SCHOOL_TYPE',\n                 'EDUCATION_MAJOR', 'DEGREE NAME','EXPERIENCE_LENGTH',\n                 'FULL_TIME_PART_TIME',\n                 'EXP_JOB_CLASS_TITLE', 'EXP_JOB_CLASS_FUNCTION',\n                 'EXP_JOB_COMPANY','EXP_JOB_CLASS_ALT_JOB_TITLE',\n                 'EXP_JOB_CLASS_ALT_RESP', 'COURSE_COUNT',\n                 'COURSE_LENGTH', 'COURSE_SUBJECT',\n                 'REQUIRED_CERTIFICATE','CERTIFICATE_ISSUED_BY',\n                 'DRIVERS_LICENSE_REQ', 'DRIV_LIC_TYPE',\n                 'EXAM_TYPE','ENTRY_SALARY_GEN','ENTRY_SALARY_DWP','OPEN_DATE']\n\ndf[col_orders].to_csv('./jobs.csv', index=None)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}