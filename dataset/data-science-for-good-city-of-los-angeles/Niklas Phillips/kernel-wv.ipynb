{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Objective**\n<br>Parse job bulletin text files and create output dataframe with the structure mentioned in \"Sample job class export template.csv\"\n\n<br>**Columns Added** \n>        'FILE_NAME', 'JOB_CLASS_TITLE', 'JOB_CLASS_NO', 'REQUIREMENT_SET_ID', \n       'REQUIREMENT_SUBSET_ID', 'ENTRY_SALARY_GEN', 'ENTRY_SALARY_DWP', 'OPEN_DATE',\n       'SCHOOL_TYPE','EDUCATION_MAJOR', 'JOB_DUTIES_1', 'JOB_DUTIES_2', 'EXAM_TYPE'\n\n<br><br>**Columns Left**\n>      'EDUCATION_YEARS', 'EXPERIENCE_LENGTH', 'FULL_TIME_PART_TIME',\n       'EXP_JOB_CLASS_TITLE', 'EXP_JOB_CLASS_ALT_RESP',\n       'EXP_JOB_CLASS_FUNCTION', 'COURSE_COUNT', 'COURSE_LENGTH',\n       'COURSE_SUBJECT', 'MISC_COURSE_DETAILS', 'DRIVERS_LICENSE_REQ',\n       'DRIV_LIC_TYPE', 'ADDTL_LIC','Benefits'"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import os\nimport pandas as pd,numpy as np\nimport re\nimport spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nfrom collections import Counter\nimport pprint\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"bulletin_dir = '../input/cityofla/CityofLA/Job Bulletins/'\nadditional_data_dir = '../input/cityofla/CityofLA/Additional data/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assumption after looking at the data in text files: Headings are written in upper case letters.\n<br>I've used this assumption to parse the text"},{"metadata":{"trusted":false},"cell_type":"code","source":"headings = {}\nm=0\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        for line in f.readlines():\n            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\":\",\"\").strip()\n#             m+=1\n#             if m==8:\n#                 break\n            if line.isupper():\n                if line not in headings.keys():\n                    headings[line] = 1\n                else:\n                    count = int(headings[line])\n                    headings[line] = count+1\n#     break","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del headings['$103,606 TO $151,484'] #This is not a heading, it's an Annual Salary component\nheadingsFrame = []\nfor i,j in (sorted(headings.items(), key = lambda kv:(kv[1], kv[0]), reverse = True)):\n    headingsFrame.append([i,j])\nheadingsFrame = pd.DataFrame(headingsFrame)\nheadingsFrame.columns = [\"Heading\",\"Count\"]\n#headingsFrame.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Add 'FILE_NAME', 'JOB_CLASS_TITLE', 'JOB_CLASS_NO' ,'OPEN_DATE'\ndata_list = []\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        job_class_title = ''\n        for line in f.readlines():\n            #Insert code to parse job bulletins\n            if \"Open Date:\" in line:\n                job_bulletin_date = line.split(\"Open Date:\")[1].split(\"(\")[0].strip()\n            if \"Class Code:\" in line:\n                job_class_no = line.split(\"Class Code:\")[1].strip()\n            if len(job_class_title)<2 and len(line.strip())>1:\n                job_class_title = line.strip()\n        data_list.append([filename, job_bulletin_date, job_class_title, job_class_no])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.DataFrame(data_list)\ndf.columns = [\"FILE_NAME\", \"OPEN_DATE\", \"JOB_CLASS_TITLE\", \"JOB_CLASS_NO\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Add 'REQUIREMENT_SET_ID','REQUIREMENT_SUBSET_ID'\nrequirements = []\nrequirementHeadings = [k for k in headingsFrame['Heading'].values if 'requirement' in k.lower()]\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        readNext = 0\n        isNumber=0\n        prevNumber=0\n        prevLine=''\n        \n        for line in f.readlines():\n            clean_line = line.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\":\",\"\").strip()   \n            if readNext == 0:                         \n                if clean_line in requirementHeadings:\n                    readNext = 1\n            elif readNext == 1:\n                if clean_line in headingsFrame['Heading'].values:\n                    if isNumber>0:\n                        requirements.append([filename,prevNumber,'',prevLine])\n                    break\n                elif len(clean_line)<2:\n                    continue\n                else:\n                    rqrmntText = clean_line.split('.')\n                    if len(rqrmntText)<2:\n                        requirements.append([filename,'','',clean_line])\n                    else:                        \n                        if rqrmntText[0].isdigit():\n                            if isNumber>0:\n                                requirements.append([filename,prevNumber,'',prevLine])\n                            isNumber=1\n                            prevNumber=rqrmntText[0]\n                            prevLine=clean_line\n                        elif re.match('^[a-z]$',rqrmntText[0]):\n                            requirements.append([filename,prevNumber,rqrmntText[0],prevLine+'-'+clean_line])\n                            isNumber=0\n                        else:\n                            requirements.append([filename,'','',clean_line])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_requirements = pd.DataFrame(requirements)\ndf_requirements.columns = ['FILE_NAME','REQUIREMENT_SET_ID','REQUIREMENT_SUBSET_ID','REQUIREMENT_TEXT']\ndf_requirements.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Check for one sample file \ndf_requirements.loc[df_requirements['FILE_NAME']=='SYSTEMS ANALYST 1596 102717.txt']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Check for salary components\nsalHeadings = [k for k in headingsFrame['Heading'].values if 'salary' in k.lower()]\nsal_list = []\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        readNext = 0\n        for line in f.readlines():\n            clean_line = line.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\":\",\"\").strip()  \n            if clean_line in salHeadings:\n                readNext = 1\n            elif readNext == 1:\n                if clean_line in headingsFrame['Heading'].values:\n                    break\n                elif len(clean_line)<2:\n                    continue\n                else:\n                    sal_list.append([filename, clean_line])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_salary = pd.DataFrame(sal_list)\ndf_salary.columns = ['FILE_NAME','SALARY_TEXT']\ndf_salary['SALARY_TEXT'][6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"files = []\nfor filename in os.listdir(bulletin_dir):\n    files.append(filename)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ENTRY_SALARY_GEN ENTRY_SALARY_DWP"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Add 'ENTRY_SALARY_GEN','ENTRY_SALARY_DWP'\npattern = r'\\$?([0-9]{1,3},([0-9]{3},)*[0-9]{3}|[0-9]+)(.[0-9][0-9])?'\ndwp_salary_list = {}\ngen_salary_list = {}\nfor filename in files:\n    for sal_text in df_salary.loc[df_salary['FILE_NAME']==filename]['SALARY_TEXT']:\n        if 'department of water' in sal_text.lower():\n            if filename in dwp_salary_list.keys():\n                continue\n            matches = re.findall(pattern+' to '+pattern, sal_text) \n            if len(matches)>0:\n                salary_dwp = ' - '.join([x for x in matches[0] if x and not x.endswith(',')])\n            else:\n                matches = re.findall(pattern, sal_text)\n                if len(matches)>0:\n                    salary_dwp = matches[0][0]\n                else:\n                    salary_dwp = ''\n            dwp_salary_list[filename]= salary_dwp\n        else:\n            if filename in gen_salary_list.keys():\n                continue\n            matches = re.findall(pattern+' to '+pattern, sal_text)\n            if len(matches)>0:\n                salary_gen = ' - '.join([x for x in matches[0] if x and not x.endswith(',')])\n            else:\n                matches = re.findall(pattern, sal_text)\n                if len(matches)>0:\n                    salary_gen = matches[0][0]\n                else:\n                    salary_gen = ''\n            if len(salary_gen)>1:\n                gen_salary_list[filename]= salary_gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_salary_dwp = pd.DataFrame(list(dwp_salary_list.items()), columns=['FILE_NAME','ENTRY_SALARY_DWP'])\ndf_salary_gen = pd.DataFrame(list(gen_salary_list.items()), columns=['FILE_NAME','ENTRY_SALARY_GEN'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result = pd.merge(df, df_requirements, how='inner', left_on='FILE_NAME', right_on='FILE_NAME', sort=True)\n\nresult = pd.merge(result, df_salary_dwp, how='left', left_on='FILE_NAME', right_on='FILE_NAME', sort=True)\n\nresult = pd.merge(result, df_salary_gen, how='left', left_on='FILE_NAME', right_on='FILE_NAME', sort=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ADD JOB_DUTIES_1 AND JOB_DUTIES_2"},{"metadata":{"trusted":false},"cell_type":"code","source":"#ADD JOB_DUTIES_1 AND JOB_DUTIES_2\nduties = {}\nname2=[]\nd1=[]\nd2=[]\nm=0\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        for line in f.readlines():\n            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\":\",\"\").strip()\n            if 'DUTIES' in line:\n                m=1\n    #             print(line)\n            if line.isupper() and line!='DUTIES':\n                m=0\n    #             print(line)\n            if m==1 and line!='DUTIES' and line!='':\n                \n                if filename not in duties:\n                    duties[filename]=line\n                else:\n                    d3=[duties[filename],line]\n                    duties[filename]=d3\n                    \nfor i in duties:\n    name2.append(i)\n    if len(duties[i])==2:\n        d1.append(duties[i][0])\n        d2.append(duties[i][1])\n    else:\n        d1.append(duties[i])\n        d2.append(None)\n\ndf_duties = pd.DataFrame({'FILE_NAME': name2,'JOB_DUTIES_1': d1,'JOB_DUTIES_2': d2})\nresult = pd.merge(result, df_duties, how='left', left_on='FILE_NAME', right_on='FILE_NAME', sort=True)\n\n\n#WITHOUT DUTIES\n\n# APPARATUS OPERATOR 2121 071417 (1).txt\n# ENGINEER OF FIRE DEPARTMENT 2131 111116.txt\n# FIRE ASSISTANT CHIEF 2166 011218.txt\n# FIRE BATTALION CHIEF 2152 030918.txt\n# FIRE HELICOPTER PILOT 3563 081415 REV. 081815.txt\n# FIRE INSPECTOR 2128 031717.txt\n# Vocational Worker  DEPARTMENT OF PUBLIC WORKS.txt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ADD the EXAM_type"},{"metadata":{"trusted":false},"cell_type":"code","source":"### ADD the EXAM_type\nexam_type = []\nname1=[]\nm=0\nEXAM_TYPE=[]\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        for line in f.readlines():\n            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\":\",\"\").strip()\n            if 'THIS EXAM' in line:\n                m=1\n    #             print(line)\n            if 'discriminate' in line:\n                m=0\n    #             print(line)\n            if m==1 and line!='' and not('THIS' in line):\n                name1.append(filename)\n                exam_type.append(line)\n#                 print(filename,line)\n\nfor i in exam_type:\n    if ('OPEN' in i) and ('INTER' in i):\n        EXAM_TYPE.append('OPEN_INT_PROM')\n    elif ('OPEN' in i) and ('PROMO' in i):\n        EXAM_TYPE.append('OPEN_DEPT_PROM')\n    elif 'OPEN' in i:\n        EXAM_TYPE.append('OPEN')\n    elif 'INTER' in i:\n        EXAM_TYPE.append('INT_DEPT_PROM')\n    else:\n        EXAM_TYPE.append('DEPT_PROM')\n            \ndf_exam_type = pd.DataFrame({'FILE_NAME': name1,'EXAM_TYPE': EXAM_TYPE})\nresult = pd.merge(result, df_exam_type, how='left', left_on='FILE_NAME', right_on='FILE_NAME', sort=True)\n\n\n#WITHOUT EXAMINATION\n\n# PILE DRIVER WORKER 3553 041417.txt\n# Vocational Worker  DEPARTMENT OF PUBLIC WORKS.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#result.drop(columns=['REQUIREMENT_TEXT'], inplace=True)\nresult\n# result.to_csv('result_table.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# School Type"},{"metadata":{"trusted":false},"cell_type":"code","source":"def getSchoolType(txt):\n    txt1=''\n    line = txt.lower().find('college or university')\n    if line==-1: \n#         return ''\n        txt1+=''\n    else:\n        txt1+= 'college or university '\n    line1 = txt.lower().find('high school')\n    if line1==-1:\n        txt1+= ''\n    else:\n        txt1+='HIGH SCHOOL'\n    \n    line2 = txt.lower().find('apprenticeship')\n    if line2==-1:\n        txt1+= ''\n    else:\n        txt1+='apprenticeship'\n\n    return txt1\n\nresult['SCHOOL_TYPE'] = result['REQUIREMENT_TEXT'].apply(lambda x: getSchoolType(x))\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df1=result[result['SCHOOL_TYPE']=='apprenticeship'].drop(columns=['OPEN_DATE', 'JOB_CLASS_TITLE', 'JOB_CLASS_NO','ENTRY_SALARY_DWP', 'ENTRY_SALARY_GEN', 'JOB_DUTIES_1', 'JOB_DUTIES_2','EXAM_TYPE','SCHOOL_TYPE'])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in df1['REQUIREMENT_TEXT']:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"displacy.render(doc[175],style='dep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Education major"},{"metadata":{"trusted":false},"cell_type":"code","source":"import string\nfrom spacy import displacy\nfrom spacy.matcher import Matcher\n\ntagger=nltk.pos_tag\ntokenizer = word_tokenize\nstop = stopwords.words('english')\n\n\ndf1['REQUIREMENT_TEXT']= df1['REQUIREMENT_TEXT'].apply(lambda x: x.lower())\n# df1['REQUIREMENT_TEXT']= df1['REQUIREMENT_TEXT'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\ndf1['REQUIREMENT_TEXT']= df1['REQUIREMENT_TEXT'].apply(lambda x: x.translate(str.maketrans('', '', string.digits)))\n\n\n\n# ####################################################################################################################\n# text= result['REQUIREMENT_TEXT'].apply(tokenizer)\n# text= text.apply(tagger)\n#text=text.apply(lambda x: [item for item in x if item not in stop])\ndoc= df1['REQUIREMENT_TEXT'].apply(nlp)\n\n# displacy.render(doc[19],style='dep')\n\nmatcher = Matcher(nlp.vocab)\npattern = [{'POS': 'NOUN'},\n           {'POS': 'ADP'},\n           {'POS': 'DET'},\n           {'POS': 'NOUN'},\n           {'POS': 'CCONJ', 'OP': '?'},\n           {'POS': 'NOUN', 'OP': '?'},\n           {'POS': 'NOUN', 'OP': '?'},\n           {'POS': 'Noun', 'OP': '?'}]\n\n\n# text= result['REQUIREMENT_TEXT'].apply(tokenizer)\n# # text= text.apply(lambda x: [item for item in x if item not in stop])\n# # text = [word for word in text if word.isalpha()]\n# # text\n\n                                                    \n# # def preprocess(txt):\n# #     txt = nltk.word_tokenize(txt)\n# #     txt = nltk.pos_tag(txt)\n# #     return txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matcher.add(\"apprenticeship\",None, pattern)\nmatches = matcher(doc[219])\nmatches\nfor match_id, start, end in matches:\n# Get the matched span by slicing the Doc\n    span = doc[219][start:end]\n    print(span.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matcher.add(\"apprenticeship\",None, pattern)\n# matches =[]\nfor i in doc:\n    matches =[]\n    matches.append(matcher(i))\n    if matches[0]:\n        print(i[matches[0][-1][1]:matches[0][-1][2]])\n# matches\n# for match_id, start, end in matches:\n# # Get the matched span by slicing the Doc\n#     span = doc[19][start:end]\n#     print(span.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matches","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"displacy.render(doc[19],style='dep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"doc[0],doc[1],doc[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"text= result['REQUIREMENT_TEXT'].apply(tokenizer)\ntext= text.apply(lambda x: [item for item in x if item not in stop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in text:\n    for t in i:\n        if len(t)==1:\n            i.remove(t)\ntext","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}