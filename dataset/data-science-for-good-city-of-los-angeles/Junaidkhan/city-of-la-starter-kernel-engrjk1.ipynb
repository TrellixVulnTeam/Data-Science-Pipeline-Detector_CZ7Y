{"cells":[{"metadata":{},"cell_type":"markdown","source":"## City of LA - Converting the job bulletins to a pd dataframe "},{"metadata":{},"cell_type":"markdown","source":"The goal of this kernel is to extract the usefull information from the txt files:\n* Job Positions\n* Starting Salary\n* Duties\n* Minimum Requirements"},{"metadata":{},"cell_type":"markdown","source":"#### Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport re #search in strings.\n\nimport plotly.plotly as py\nimport cufflinks as cf\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load file titles"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_dir = '../input/cityofla/CityofLA/Job Bulletins/'\n\ndef getListOfFiles(dirName):\n# create a list of file and sub directories \n# names in the given directory \n    listOfFile = os.listdir(dirName)\n    allFiles = list()\n    # Iterate over all the entries\n    for entry in listOfFile:\n    # Create full path\n        fullPath = os.path.join(dirName, entry)\n        # If entry is a directory then get the list of files in this directory \n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\nlistOfFiles = getListOfFiles(input_dir)\ndf_bulletins = pd.DataFrame(listOfFiles, columns = ['job_position'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean up the file names"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean up of the job_position name\ndf_positions = pd.DataFrame()\ndf_positions['job_position'] = (df_bulletins['job_position']\n                                .str.replace(input_dir, '', regex=False)\n                                .str.replace('.txt', '', regex=False)\n                                .str.replace('\\d+', '')\n                                .str.replace(r\"\\s+\\(.*\\)\",\"\")\n                                .str.replace(r\"REV\",\"\"))\n\n#Remove the numbers\ndf_positions['class_code'] = (df_bulletins['job_position']\n                              .str.replace(input_dir, '', regex=False)\n                              .str.replace('.txt', '', regex=False)\n                              .str.extract('(\\d+)'))\n\ndisplay(df_positions.head())\n# Add the Text fields of Salary, Duties and Minimum REQ\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert the information in the txt files in a table\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert the txt files to a table:\nimport glob\npath = input_dir # use your path\nall_files = glob.glob(path + \"/*.txt\")\nli = []\n\nfor filename in all_files:\n    with open (filename, \"r\",errors='replace') as myfile:\n        data=pd.DataFrame(myfile.readlines())\n        #df = pd.read_csv(filename, header=0,error_bad_lines=False, encoding='latin-1')\n    li.append(data)\nframe = pd.concat(li, axis=1, ignore_index=True)\n#pd.read_csv(listOfFiles,header = None)\nframe = frame.replace('\\n','', regex=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look for keywords, and append the following strings to the final dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here the loop should start, for each text file do:\ndef getString(col_i, frame):\n    try:\n        filter = frame[col_i] != \"\"\n        bulletin = frame[col_i][filter]\n        #display(salary)\n        isal = min(bulletin[bulletin.str.contains('SALARY',na=False)].index.values) #take the sum to convert the array to an int...TO CHANGE\n        inot = min(bulletin[bulletin.str.contains('NOTES',na=False)].index.values) # NOTES\n        idut = min(bulletin[bulletin.str.contains('DUTIES',na=False)].index.values) # DUTIES\n        ireq = min(bulletin[bulletin.str.contains('REQUIREMENT',na=False)].index.values) #REQUIREMENTS\n        ipro = min(bulletin[bulletin.str.contains('PROCESS',na=False)].index.values) # PROCESS NOTES\n\n        #isal = sum(bulletin.loc[bulletin == 'ANNUAL SALARY'].index.values) #take the sum to convert the array to an int...TO CHANGE\n        #inot = sum(bulletin.loc[bulletin == 'NOTES:'].index.values) # NOTES\n        #idut = sum(bulletin.loc[bulletin == 'DUTIES'].index.values) # DUTIES\n        #ireq = sum(bulletin.loc[bulletin == '(.*)REQUIREMENTS(.*)'].index.values) #REQUIREMENTS\n        #ipro = sum(bulletin.loc[bulletin == '(.*)PROCESS(.*)'].index.values) # PROCESS NOTES\n\n        icode = min(bulletin[bulletin.str.contains('Class Code',na=False)].index.values)\n        class_code = sum(bulletin.str.extract('(\\d+)').iloc[icode].dropna().astype('int'))\n        salary = (bulletin.loc[isal+1:inot-1]).to_string()\n        duties = (bulletin.loc[idut+1:ireq-1]).to_string()\n        requirements = (bulletin.loc[ireq+1:ipro-1]).to_string()\n        return (class_code, salary, duties, requirements)\n    except:\n        return (np.nan,np.nan,np.nan,np.nan)\n    \njobsections = pd.DataFrame()\n#getString(0,bulletin)\nfor col_i in range(frame.shape[1]):\n    #print(col_i)\n    #print(list(getString(col_i,frame)))\n    prop = getString(col_i,frame)\n    prop = pd.DataFrame(list(prop)).T\n    jobsections = jobsections.append(prop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jobsections.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jobsections.columns = ['class_code','salary','duties','requirements']\njobsections['class_code'] = pd.to_numeric(jobsections['class_code'],downcast='integer')\ndf_positions['class_code'] = pd.to_numeric(df_positions['class_code'], downcast='integer')\n#df_positions['class_code']\ndf_jobs = df_positions.merge(jobsections, left_on='class_code',right_on='class_code', how='outer')\ndisplay(df_jobs.dropna())\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}