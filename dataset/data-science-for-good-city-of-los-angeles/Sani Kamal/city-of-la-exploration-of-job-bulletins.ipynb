{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Science for Good: City of Los Angeles"},{"metadata":{},"cell_type":"markdown","source":"## Problem Objective:\nHelp the City of Los Angeles to structure and analyze its job descriptions\n\nThe City of Los Angeles faces a big hiring challenge: 1/3 of its 50,000 workers are eligible to retire by July of 2020. The city has partnered with Kaggle to create a competition to improve the job bulletins that will fill all those open positions.\n\nThe content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor’s Office wants to reimagine the city’s job bulletins by using text analysis to identify needed improvements.\n\nThe goal is to convert a folder full of plain-text job postings into a structured CSV file and then to use this data to:\n\n(1) identify language that can negatively bias the pool of applicants;\n\n(2) improve the diversity and quality of the applicant pool; and/or\n\n(3) make it easier to determine which promotions are available to employees in each job class.\n"},{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport xml.etree.ElementTree as ET\nimport zipfile\nimport os\nfrom os import walk\nimport shutil\nfrom shutil import copytree, ignore_patterns\nfrom PIL import Image\nfrom wand.image import Image as Img\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bulletin_dir = \"../input/cityofla/CityofLA/Job Bulletins\"\naddl_data_dir=\"../input/cityofla/CityofLA/Additional data\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Introduction\nLet us first start by looking at some of the job postings to get an idea of how they look like.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pdf = '../input/cityofla/CityofLA/Additional data/PDFs/2014/September 2014/09262014/PRINCIPAL INSPECTOR 4226.pdf'\nImg(filename=pdf, resolution=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdf = '../input/cityofla/CityofLA/Additional data/PDFs/2018/December/Dec 7/COMMERCIAL FIELD REPRESENTATIVE 1600 120718.pdf'\nImg(filename=pdf, resolution=200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check sample job class export template.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_job_template = pd.read_csv(os.path.join(addl_data_dir, 'sample job class export template.csv'))\nsample_job_template","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check kaggle_data_dictionary.csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dictionary = pd.read_csv(os.path.join(addl_data_dir, 'kaggle_data_dictionary.csv'))\ndata_dictionary.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Job titles listing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\njob_titles = pd.read_csv(os.path.join(addl_data_dir, 'job_titles.csv'), names=['JOB TITLES'])\njob_titles.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Iterate over Job Bulletins directory\nWe are also given the job descriptions in plain text files. Let us get the total number of files and have a look at top few lines of one of the files."},{"metadata":{"trusted":true},"cell_type":"code","source":"job_files = os.listdir(bulletin_dir)\nprint(\"No of files in Job Bulletins Folder:\",len(job_files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(bulletin_dir+\"/\"+job_files[0]) as file:\n    print(\"File name: \",file.name)\n    print(\"=====================================\")\n    print(file.read(1000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Extraction\n\nIn this section, let us extract the data and create a structured table out of it.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Code from the starter kernel to iterate over Job Bulletins directory\ndata_list = []\nfor filename in os.listdir(bulletin_dir):\n    with open(bulletin_dir + \"/\" + filename, 'r', errors='ignore') as f:\n        for line in f.readlines():\n            #Insert code to parse job bulletins\n            if \"Class Code:\" in line:\n                class_code=line.split(\"Class Code:\")[1].split(\"Open Date\")[0].strip()\n            if \"Open Date:\" in line:\n                job_bulletin_date = line.split(\"Open Date:\")[1].split(\"(\")[0].strip()\n        data_list.append([filename,class_code,job_bulletin_date])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Form a DataFrame \ndf = pd.DataFrame(data_list)\ndf.columns = [\"FILE_NAME\",\"CLASS_CODE\",\"OPEN_DATE\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Let's convert `OPEN_DATE` to `DATETIME`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.OPEN_DATE = pd.to_datetime(df.OPEN_DATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert to CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"job_bulletins.csv\",index= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"job_df = pd.read_csv(\"job_bulletins.csv\")\njob_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## More to come. Stay tuned!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}