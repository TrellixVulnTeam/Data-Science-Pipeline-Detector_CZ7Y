{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:26.039159Z","start_time":"2019-06-21T06:36:25.461209Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup libraries"},{"metadata":{},"cell_type":"markdown","source":"Turn on Internet connection in the settings section of this notebook to download libraries"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:26.044782Z","start_time":"2019-06-21T06:36:26.041933Z"},"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install lajobsparser\n!pip install pdfminer-six","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:26.526676Z","start_time":"2019-06-21T06:36:26.048746Z"},"trusted":true},"cell_type":"code","source":"import pathlib\nimport pandas as pd\nimport seaborn as sns\nimport itertools\n\n%matplotlib inline\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:26.610554Z","start_time":"2019-06-21T06:36:26.528852Z"},"trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import a custom Python library on PyPI to process job bulletins"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.319998Z","start_time":"2019-06-21T06:36:26.61279Z"},"trusted":true},"cell_type":"code","source":"import lajobsparser as ljp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get jobs data"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.367926Z","start_time":"2019-06-21T06:36:27.323358Z"},"trusted":true},"cell_type":"code","source":"SCRIPT_DIR = pathlib.Path().resolve()\nDATA_ROOT = SCRIPT_DIR / '..' / 'input' / 'cityofla' / \\\n    'CityofLA' / 'Job Bulletins'\npaths = list(DATA_ROOT.glob('*'))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.404037Z","start_time":"2019-06-21T06:36:27.37142Z"},"trusted":true},"cell_type":"code","source":"print('There are {} job bulletins'.format(len(paths)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get headers for job bulletins"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.719033Z","start_time":"2019-06-21T06:36:27.408611Z"},"trusted":true},"cell_type":"code","source":"headers = ljp.get_bulletin_headers(paths)\nselected_headers = set(header for header in headers\n                       if not header.startswith('REVISED'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display some words in the job bulletins showing spelling errors"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.754454Z","start_time":"2019-06-21T06:36:27.721609Z"},"trusted":true},"cell_type":"code","source":"header_words = itertools.chain(*list(header.split()\n                                     for header in selected_headers))\nunique_header_words = sorted(set(header_words))\nsample_header_words = [\n    word for word in unique_header_words if word.startswith('QUAL')\n]\nprint(sample_header_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 1: Use a spell checker\n\nUse a spell checker for the job bulletins. This will look more professional and\nwill also help if any machine learning algorithms are used on the job\ndescriptions.\n\nGet selected headers"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.798626Z","start_time":"2019-06-21T06:36:27.756992Z"},"trusted":true},"cell_type":"code","source":"# get headers that do not start with revised\nselected_headers = set(header for header in headers\n                       if not header.startswith('REVISED'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display some of the headers showing different wording"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:27.839219Z","start_time":"2019-06-21T06:36:27.804633Z"},"trusted":true},"cell_type":"code","source":"requirement_headers = sorted(\n    set([\n        header for header in selected_headers if header.startswith('REQUIREM')\n    ]))\nprint('\\n'.join(requirement_headers))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 2: Standardize headers in job bulletins\n\nUse the same headers in all job bulletins. This will make it easier to work\nwith the bulletins using automated tools."},{"metadata":{},"cell_type":"markdown","source":"Get job bulletin contents as a data frame"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:28.529815Z","start_time":"2019-06-21T06:36:27.842225Z"},"trusted":true},"cell_type":"code","source":"bulletin_df = ljp.get_job_bulletins(paths)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display the first few rows of the data"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:28.669021Z","start_time":"2019-06-21T06:36:28.532141Z"},"trusted":true},"cell_type":"code","source":"bulletin_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the job titles data"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:28.717316Z","start_time":"2019-06-21T06:36:28.672171Z"},"trusted":true},"cell_type":"code","source":"ADDITIONAL_DATA_PATH = SCRIPT_DIR / '..' / 'input' / 'cityofla' / \\\n    'CityofLA' / 'Additional data'\nJOB_TITLES_PATH = ADDITIONAL_DATA_PATH / 'job_titles.csv'\ntitle_df = pd.read_csv(JOB_TITLES_PATH, header=None, names=['job_class_title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combine job titles from bulletins and additional data"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:28.761629Z","start_time":"2019-06-21T06:36:28.720722Z"},"trusted":true},"cell_type":"code","source":"bulletin_job = set(bulletin_df.job_class_title.str.lower())\ntitle_job = set(title_df.job_class_title.str.lower())\n\njobs_in_either = bulletin_job | title_job\n\njobs_in_both = bulletin_job & title_job\n\ntitle_list_only = title_job - bulletin_job\n\nbulletin_list_only = bulletin_job - title_job","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display jobs titles in bulletins and/or job title list"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-21T06:36:28.818783Z","start_time":"2019-06-21T06:36:28.764004Z"},"trusted":true},"cell_type":"code","source":"title_compare_df = pd.DataFrame(\n    {\n        'jobs_in_either': len(jobs_in_either),\n        'jobs_in_both': len(jobs_in_both),\n        'jobs_in_title_list_only': len(title_list_only),\n        'jobs_in_bulletin_list_only': len(bulletin_list_only)\n    },\n    index=[0])\ntitle_compare_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 3: Standardize the job titles\n\nMost of the job titles used job bulletins match the jobs in the job title list\nbut a few do not. Using standard job titles will make it easier to make\nrecommendations."},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 4. Improve the readability of the job description\n\nThere are other Kaggle kernels that explain this.\n\nhttps://www.kaggle.com/silverfoxdss/city-of-la-readability-and-promotion-nudges"},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 5. Improve the language of the job bulleting using proselint\n\nProselint is an automated tool that will help improve the use of language.\nAccording to the description they consider\n\n    redundancy, jargon, illogic, clich√©s, sexism, misspelling, inconsistency,\n    misuse of symbols, malapropisms, oxymorons, security gaffes, hedging,\n    apologizing, pretension, and more.\n\nhttps://github.com/amperser/proselint\n\nWhen running it on text it claims to detect\n\n* sexism.misc - Avoiding sexist language\n* lgbtq.offensive_terms - Avoiding offensive LGBTQ terms\n* lgbtq.terms - Misused LGBTQ terms\n\nHowever when running it on the job bulletins it does not detect any offensive\nlanguage. Based on the source code it looks for explicitly offensive language.\n\nIt does however detect jargon and corporate-speak."},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 6. Send LA county employees job paths annually\n\nThe entry level employees of LA are likely to be more diverse than the senior\nlevels. Keep track of the employees anniversaries at their job. As most jobs\nrequire a whole number of years of experience send LA employees the relevant\njob path document for their job title on their anniversary and let them know\nthat they may be eligible to apply for a higher position."},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 7. Reduce unconscious bias about candidate names\n\nOne of the best known and most cited American Economic Review papers found\nresumes with typical black names received fewer callbacks than those with\ntypical white names. The paper was titled:\n\n    Are Emily and Greg More Employable than Lakisha and Jamal?\n\nTo reduce unconscious bias reviewers in LA county should evaluate resumes with\nthe candidates names obscured.\n\nhttps://www.nber.org/papers/w9873"},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 8. Gather data to help use machine learning in the future\n\nThe most successful machine learning examples use supervised learning.\n\nhttps://www.youtube.com/watch?v=21EiKfQYZXc\n\nSupervised learning needs inputs and outcomes. For LA jobs descriptions, the\ninputs would be job bulletins that appeal to diverse candidates and job\nbulletins that do not do so. The outcomes would be the numbers and diversity of\nthe candidates that apply to the jobs.\n\nAs of 2019, there does not appear to be data set of labelled job descriptions\nthat can be used to train a machine learning algorithm. LA county can help make\nsuch a data set available by doing the following.\n\n1. Get experts to modify job descriptions to appeal to diverse candidates\n2. Save the older job description\n3. Keep statistics on the candidates that saw each kind of job bulletin and\n   those that applied\n4. Make the data set available to researchers"},{"metadata":{},"cell_type":"markdown","source":"## Recommendation 9. Create a code library to process job descriptions\n\nTo create clean code to process job descriptions it is best to write it as\na separate Python library.\n\nThe PyPI repository of Python library hosts the [lajobsparser][lajobsparser] library created\nspecially to work with LA county job descriptions.\n\n[lajobsparser]: https://pypi.org/project/lajobsparser\n\nAdditionally, the code is open source and hosted on [Github][github_code]\n\n[github_code]: https://github.com/gavinln/lajobsparser\n\nIt uses the [flake8][flake8] tool to validate that the code follows the [pep8][pep8] coding\nconventions.\n\n[flake8]: https://pypi.org/project/flake8/\n\n[pep8]: https://www.python.org/dev/peps/pep-0008/\n\nIt also uses the [mypy][mypy] tool for static type checking\n\n[mypy]: http://mypy-lang.org/"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}