{"cells":[{"metadata":{},"cell_type":"markdown","source":"## The goal of this project was to first extract all the \"real\" words from all the job decriptions in the Kaggle Challenge (link below) and then to look up the level of difficulty of the words to determine if language could be a barrier to diversity in hiring.\n### https://www.kaggle.com/c/data-science-for-good-city-of-los-angeles/overview?utm_medium=email&utm_source=intercom&utm_campaign=data-science-for-good-2019.  "},{"metadata":{},"cell_type":"markdown","source":"Note:  While this code worked successfully in my environment it required updates to run in Kaggle from not using the Kaggle API to replacing Unirest with requests (which would not install) to finding a way to not leverage Textract (which also would not install)."},{"metadata":{},"cell_type":"markdown","source":"## Part 1: Get the data from Kaggle and tokenize"},{"metadata":{},"cell_type":"markdown","source":"Set up libaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard imports and imports for creating a .csv\nimport numpy as np\nimport os\nimport csv\nimport urllib\nimport json \nimport zipfile\nimport pandas as pd\n\n# Import libraries for parsing\nimport PyPDF2 \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport fnmatch\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read files and write to .csv and extract word parts"},{"metadata":{},"cell_type":"markdown","source":"### Read the files and extract all the words \n##### Reference article: https://medium.com/@rqaiserr/how-to-convert-pdfs-into-searchable-key-words-with-python-85aab86c544f"},{"metadata":{},"cell_type":"markdown","source":"Removed function to see if that would help with output issues"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/data-science-for-good-city-of-los-angeles/cityofla/CityofLA/Additional data/PDFs'\nfilesread = 0\n\n\nfiles = [os.path.join(dirpath, filename)\nfor dirpath, dirnames, files in os.walk(path)\nfor filename in files if filename.endswith('.pdf')]\n\nfilecount=len(files)\njoblist = []\n\nwhile filesread <  filecount:\n    for file in files:\n            fileerror = 0\n            filegood = 0\n            namesonly = file.split(\"/\")\n            arraylen=len(namesonly)\n            try:\n                fileyear = namesonly[8]\n                fileonly = namesonly[arraylen-1]\n                jobdata = (fileonly, fileyear)\n                joblist.append(jobdata)\n                filegood +=1\n            except:\n                fileerror +=1\n\n    filesread +=1\n\njoblist_df = pd.DataFrame(joblist, columns =['Job Description', 'Year']) \njoblist_df.to_csv('job_descriptions.csv' , index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdfFileObj = open(file,'rb')               ## open the file\npdfReader = PyPDF2.PdfFileReader(pdfFileObj)   ## read the data in the file\nnum_pages = pdfReader.numPages                 ## figure out the number of pages\ncount = 0\ntext = \"\"\n\nwhile count < num_pages:                       ## get a page\n    pageObj = pdfReader.getPage(count)          \n    count +=1\n    text += pageObj.extractText()              ## extract the data from the page\n    if text != \"\":\n            text = text\n                                    \n    else:\n            text = textract.process(fileurl, method='tesseract', language='eng')\n                            \n    global tokens\n    tokens = word_tokenize(text)\n    textlen = len(text) \n                    \nprint (filesread, \"files read\")\nprint (\"words in file: \",textlen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Specify words to exclude from level of difficulty tagging"},{"metadata":{"trusted":true},"cell_type":"code","source":"punctuations = ['(',')',';',':','[',']',',', \"$\", \"%\", \"/\"]\nweb_characters =[ \"http//\", \"http\", \".\", ['.'], \"-\", \"www\", \"//\" \"https\"]\nstop_words = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a process to extract keywords by exclusion and ensure the words are unique"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_key_words():  \n    \n    keywords = [word for word in tokens if not word in stop_words \\\n                and not word in punctuations and not word in web_characters]\n\n    keywordct = len(keywords)\n    print(\"keyword count\", keywordct)\n\n\n    unique_keywords = set(keywords) \n    uniquect = len(unique_keywords)\n    print(\"unique count\", uniquect)\n\n\n    wordread = 0\n    global goodwords\n    goodwords=[]\n\n    while wordread < keywordct:\n            wordread +=1\n            \n    goodwords = [word.lower() for word in unique_keywords if word.isalpha()]\n\n    global goodwordct\n    goodwordct = len(goodwords)\n    print(\"good words\", goodwordct) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the keyword extraction process"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_key_words()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 2: Detemine level of difficulty "},{"metadata":{},"cell_type":"markdown","source":"Look up each word for level of difficulty (Twinword API) and write words and difficulty levels to a file"},{"metadata":{},"cell_type":"markdown","source":"Iterate through words looking up the level of difficulty and write to list.   Code replaced as Unirest could not be installed n Kaggle."},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\n\nindex = 0\nwordcode = 0 \n# goodwordct=\ndictlist = []\ndropword = 0\ntwinword_key = \"null\"\n\nwhile wordcode < goodwordct:\n    myword = goodwords[index]\n    wordcode +=1\n    index +=1    \n\n    response = requests.get(\"https://twinword-language-scoring.p.rapidapi.com/word/\",\n            headers={\n                \"X-RapidAPI-Host\": \"twinword-language-scoring.p.rapidapi.com\",\n                \"X-RapidAPI-Key\": twinword_key,\n                \"Content-Type\": \"application/x-www-form-urlencoded\"\n                       },\n                params={\n                  \"entry\": myword\n                }\n        )\n    \n    if response.status_code == 200:\n        try:\n            data =response.json()\n            worddiff = data.get(\"ten_degree\")\n            if type(worddiff) == int:\n                listdata = (worddiff, myword)\n                dictlist.append(listdata)\n            else:\n                print (\"Word Difficulty not found for: \", myword)\n        except:\n            dropword +=1\n        \nprint (\"words dropped\", dropword)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a process to sort and output the data to a .csv file with the most difficult words at the top."},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_to_csv():\n    dict_list_sorted = sorted(dictlist, key=None, reverse=True)\n    output_dataframe = pd.DataFrame(dict_list_sorted,columns=[\"Word Difficulty\",'Word']) \n    csv_outfile_name = 'word_difficulty.csv'\n    output_dataframe.to_csv(csv_outfile_name , index=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the process to create the .csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"write_to_csv()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 3: Gender Bias\nReferencing this research article and acknowledging this tool: http://gender-decoder.katmatfield.com/about#masculine, \nlook up words for contains male or femal bias words in the job description."},{"metadata":{},"cell_type":"markdown","source":"Import gender bias words from .csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"Male_Bias_csv = \"../input/bais-word-lists/Female-Bias-wordparts.csv\"\nwith open(Male_Bias_csv, 'r') as my_file:\n    reader = csv.reader(my_file, delimiter='\\t')\n    male_bias_words = list(reader)\nFemale_Bias_csv = \"../input/bais-word-lists/Female-Bias-wordparts.csv\"\nwith open(Female_Bias_csv, 'r') as my_file:\n    reader = csv.reader(my_file, delimiter='\\t')\n    female_bias_words = list(reader)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Compare words to list of known gender bias words and write output to files. "},{"metadata":{},"cell_type":"markdown","source":"Transform to lists for matching"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_list_sorted = sorted(dictlist, key=None, reverse=True)\ngender_clean_dataframe = pd.DataFrame(dict_list_sorted)\ngender_clean_dataframe.columns = [\"Difficulty\",\"Word\"]\ngender_df =  gender_clean_dataframe[\"Word\"]\ngender_list = gender_df.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Process for Male bias words and write matches to file"},{"metadata":{"trusted":true},"cell_type":"code","source":"male_matchbias = []\ntry:\n    male_matchbias = [s for s in gender_list if any(xs in s for xs in male_bias_words)]\nexcept:\n    pass\n\nif (len(male_matchbias)) == 0:\n    print (\"No male bias words were found\")\nelse:\n    print(\"Male bias words were found and exported\")\n    male_bias_out= pd.DataFrame(male_matchbias)\n    male_bias_out.columns = [\"Male Bias Words\"]\n    csv_outfile_name = 'Male Bias Words.csv'\n    male_bias_out.to_csv(csv_outfile_name , index=False, header =False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Process for Female bias words and write matches to file"},{"metadata":{"trusted":true},"cell_type":"code","source":"female_matchbias = []\ntry:\n    female_matchbias = [s for s in gender_list if any(xs in s for xs in female_bias_words)]\nexcept:\n    pass\n\n\nif (len(female_matchbias)) == 0:\n    print (\"No female bias words were found\")\nelse:\n    print(\"female bias words were found and exported\")\n    female_bias_out= pd.DataFrame(female_matchbias)\n    female_bias_out.columns = [\"female Bias Words\"]\n    csv_outfile_name = 'female Bias Words.csv'\n    female_bias_out.to_csv(csv_outfile_name , index=False, header =False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 4: Age Bias"},{"metadata":{},"cell_type":"markdown","source":"Finally as this article points out you need to look for age bias.  \nhttps://www.linkedin.com/in/alison-doucette-5b40374/"},{"metadata":{},"cell_type":"markdown","source":"Read list of age bias words from .csv (list compiles from articles)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Age_Bias_csv = \"../input/bais-word-lists/age-bias-wordparts.csv\"\nwith open(Age_Bias_csv, 'r') as my_file:\n    reader = csv.reader(my_file, delimiter='\\t')\n    age_bias_words = list(reader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compare words for age bias and write age bias words detected to .csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_matchbias = []\ntry:\n    age_matchbias = [s for s in gender_list if any(xs in s for xs in age_bias_words)]\nexcept:\n    pass\n\n\nif (len(age_matchbias)) == 0:\n    print (\"No age bias words were found\")\nelse:\n    print(\"Age bias words were found and exported\")\n    age_bias_out= pd.DataFrame(age_matchbias)\n    age_bias_out.columns = [\"Age Bias Words\"]\n    csv_outfile_name = 'Age Bias Words.csv'\n    female_bias_out.to_csv(csv_outfile_name , index=False, header =False)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check output.  Note:  no bias output .csv files produced if no bias is found."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"In conclusion, the City of Los Angeles Job descriptions showed no gender or age bias.\nHowever some words which may not be essential could limit accessibklity for those for whom English is not a first language."}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.16"}},"nbformat":4,"nbformat_minor":1}