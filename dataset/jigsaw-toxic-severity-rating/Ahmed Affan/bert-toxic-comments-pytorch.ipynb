{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport random\nimport gc\nimport glob\npd.set_option('display.max_columns', None)\nnp.seterr(divide='ignore', invalid='ignore')\ngc.enable()\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import OneCycleLR\n# NLP\nfrom transformers import AutoTokenizer, AutoModel\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-08T04:55:40.865851Z","iopub.execute_input":"2021-12-08T04:55:40.866533Z","iopub.status.idle":"2021-12-08T04:55:47.740561Z","shell.execute_reply.started":"2021-12-08T04:55:40.866422Z","shell.execute_reply":"2021-12-08T04:55:47.739766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/jigsaw-toxic-severity-rating'\nmodels_dir = '../input/jrstc-models'\ntest_file_path = os.path.join(data_dir, 'comments_to_score.csv')\nprint(f'Train file: {test_file_path}')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:47.742287Z","iopub.execute_input":"2021-12-08T04:55:47.742549Z","iopub.status.idle":"2021-12-08T04:55:47.747105Z","shell.execute_reply.started":"2021-12-08T04:55:47.742514Z","shell.execute_reply":"2021-12-08T04:55:47.746388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(test_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:47.74833Z","iopub.execute_input":"2021-12-08T04:55:47.748746Z","iopub.status.idle":"2021-12-08T04:55:47.847817Z","shell.execute_reply.started":"2021-12-08T04:55:47.748704Z","shell.execute_reply":"2021-12-08T04:55:47.847107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:47.850717Z","iopub.execute_input":"2021-12-08T04:55:47.851386Z","iopub.status.idle":"2021-12-08T04:55:47.858757Z","shell.execute_reply.started":"2021-12-08T04:55:47.851345Z","shell.execute_reply":"2021-12-08T04:55:47.858104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\ntest_df['text'] = test_df['text'].progress_apply(text_cleaning)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:47.859944Z","iopub.execute_input":"2021-12-08T04:55:47.860676Z","iopub.status.idle":"2021-12-08T04:55:50.337589Z","shell.execute_reply.started":"2021-12-08T04:55:47.860618Z","shell.execute_reply":"2021-12-08T04:55:50.336902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.33889Z","iopub.execute_input":"2021-12-08T04:55:50.339555Z","iopub.status.idle":"2021-12-08T04:55:50.356738Z","shell.execute_reply.started":"2021-12-08T04:55:50.339515Z","shell.execute_reply":"2021-12-08T04:55:50.356015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CFG","metadata":{}},{"cell_type":"code","source":"params = {\n    'device': device,\n    'debug': False,\n    'checkpoint': '../input/roberta-base',\n    'output_logits': 768,\n    'max_len': 256,\n    'batch_size': 32,\n    'dropout': 0.2,\n    'num_workers': 2\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.357821Z","iopub.execute_input":"2021-12-08T04:55:50.358458Z","iopub.status.idle":"2021-12-08T04:55:50.362694Z","shell.execute_reply.started":"2021-12-08T04:55:50.358412Z","shell.execute_reply":"2021-12-08T04:55:50.362054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if params['debug']:\n    train_df = train_df.sample(frac=0.01)\n    print('Reduced training Data Size for Debugging purposes')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.363913Z","iopub.execute_input":"2021-12-08T04:55:50.364323Z","iopub.status.idle":"2021-12-08T04:55:50.372078Z","shell.execute_reply.started":"2021-12-08T04:55:50.364283Z","shell.execute_reply":"2021-12-08T04:55:50.371336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset \n","metadata":{}},{"cell_type":"code","source":"class BERTDataset:\n    def __init__(self, text, max_len=params['max_len'], checkpoint=params['checkpoint']):\n        self.text = text\n        self.max_len = max_len\n        self.checkpoint = checkpoint\n        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n        self.num_examples = len(self.text)\n\n    def __len__(self):\n        return self.num_examples\n\n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n\n        tokenized_text = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n        )\n\n        ids = tokenized_text['input_ids']\n        mask = tokenized_text['attention_mask']\n        token_type_ids = tokenized_text['token_type_ids']\n\n        return {'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)}\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.37332Z","iopub.execute_input":"2021-12-08T04:55:50.374048Z","iopub.status.idle":"2021-12-08T04:55:50.384007Z","shell.execute_reply.started":"2021-12-08T04:55:50.37399Z","shell.execute_reply":"2021-12-08T04:55:50.383328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NLP Model\n","metadata":{}},{"cell_type":"code","source":"class ToxicityModel(nn.Module):\n    def __init__(self, checkpoint=params['checkpoint'], params=params):\n        super(ToxicityModel, self).__init__()\n        self.checkpoint = checkpoint\n        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n        self.layer_norm = nn.LayerNorm(params['output_logits'])\n        self.dropout = nn.Dropout(params['dropout'])\n        self.dense = nn.Sequential(\n            nn.Linear(params['output_logits'], 256),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Dropout(params['dropout']),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, input_ids, token_type_ids, attention_mask):\n        _, pooled_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n        pooled_output = self.layer_norm(pooled_output)\n        pooled_output = self.dropout(pooled_output)\n        preds = self.dense(pooled_output)\n        return preds\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.387291Z","iopub.execute_input":"2021-12-08T04:55:50.387633Z","iopub.status.idle":"2021-12-08T04:55:50.397561Z","shell.execute_reply.started":"2021-12-08T04:55:50.387598Z","shell.execute_reply":"2021-12-08T04:55:50.396861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predication \n","metadata":{}},{"cell_type":"code","source":"predictions_nn = None\nfor model_name in glob.glob(models_dir + '/*.pth'):\n    model = ToxicityModel()\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(params['device'])\n    model.eval()\n\n    test_dataset = BERTDataset(\n        text = test_df['text'].values\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=params['batch_size'],\n        shuffle=False, num_workers=params['num_workers'],\n        pin_memory=True\n    )\n\n    temp_preds = None\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f'Predicting. '):\n            ids= batch['ids'].to(device)\n            mask = batch['mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            predictions = model(ids, token_type_ids, mask).to('cpu').numpy()\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n\n    if predictions_nn is None:\n        predictions_nn = temp_preds\n    else:\n        predictions_nn += temp_preds\n        \npredictions_nn = (len(glob.glob(models_dir + '/*.pth')))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.398779Z","iopub.execute_input":"2021-12-08T04:55:50.399439Z","iopub.status.idle":"2021-12-08T04:55:50.411036Z","shell.execute_reply.started":"2021-12-08T04:55:50.399398Z","shell.execute_reply":"2021-12-08T04:55:50.410353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['comment_id'] = test_df['comment_id']\nsub_df['score'] = predictions_nn\nsub_df['score'] = sub_df['score'].rank(method='first')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.412241Z","iopub.execute_input":"2021-12-08T04:55:50.412657Z","iopub.status.idle":"2021-12-08T04:55:50.430259Z","shell.execute_reply.started":"2021-12-08T04:55:50.41262Z","shell.execute_reply":"2021-12-08T04:55:50.429577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.431444Z","iopub.execute_input":"2021-12-08T04:55:50.432387Z","iopub.status.idle":"2021-12-08T04:55:50.444868Z","shell.execute_reply.started":"2021-12-08T04:55:50.432341Z","shell.execute_reply":"2021-12-08T04:55:50.443974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.446455Z","iopub.execute_input":"2021-12-08T04:55:50.446728Z","iopub.status.idle":"2021-12-08T04:55:50.473516Z","shell.execute_reply.started":"2021-12-08T04:55:50.446694Z","shell.execute_reply":"2021-12-08T04:55:50.472933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('My heart is beating like Thunder')\nprint('By Elvis Presley')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:55:50.474667Z","iopub.execute_input":"2021-12-08T04:55:50.475117Z","iopub.status.idle":"2021-12-08T04:55:50.479788Z","shell.execute_reply.started":"2021-12-08T04:55:50.475081Z","shell.execute_reply":"2021-12-08T04:55:50.478962Z"},"trusted":true},"execution_count":null,"outputs":[]}]}