{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RAPIDS Forest Inference Library! INFERENCE NOTEBOOK\n# Kaggle Toxic Comp 2022 Solution - Silver 52nd Place\nSince [RAPIDS Forest Inference Library][1] can infer Tree Based Models blazing fast at 100 million rows per second!!, we can approach this problem in a way that no other team did. During inference, we need to predict 14,000 toxic scores for each of the test data comments. Instead of predicting 14,000 numbers, we will predict 196,000,000 million numbers! We create every pair of comments `14,000 x 14,000 = 196,000,000`, and then for each of these 196 million pairs, we feed `1792 x 2 = 3584` columns of features and use [RAPIDS Forest Inference Library][1] to predict whether the second comment is more toxic than the first comment. After inferring all 196,000,000 pair probabilities, we convert these into 14,000 toxic scores.\n\n[1]: https://medium.com/rapids-ai/rapids-forest-inference-library-prediction-at-100-million-rows-per-second-19558890bc35","metadata":{}},{"cell_type":"markdown","source":"# Extract Features for Test Comments\nFirst we will extract `roBERTa-base` and `roBERTa-large` features for each test comment by running the two Python scripts below. The two scripts will save the features as two NumPy arrays named `embed.npy` and `embed_large.npy` ","metadata":{}},{"cell_type":"code","source":"%%time\n# ROBERTA-BASE EMBEDDINGS\n! python -W ignore ../input/toxiccompscripts/roberta-extract-7.py","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-02-08T03:10:40.463775Z","iopub.execute_input":"2022-02-08T03:10:40.464027Z","iopub.status.idle":"2022-02-08T03:14:00.173749Z","shell.execute_reply.started":"2022-02-08T03:10:40.463999Z","shell.execute_reply":"2022-02-08T03:14:00.172913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# ROBERTA-LARGE EMBEDDINGS\n! python -W ignore ../input/toxiccompscripts/roberta-extract-8.py","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-02-08T03:14:00.176112Z","iopub.execute_input":"2022-02-08T03:14:00.176386Z","iopub.status.idle":"2022-02-08T03:22:56.083503Z","shell.execute_reply.started":"2022-02-08T03:14:00.176345Z","shell.execute_reply":"2022-02-08T03:22:56.082649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test with RAPIDS Forest Inference Library\nAfter reading the 14,000 unique test comments, we will create each of the `196,000,000 = 14,000 x 14,000` pairs. Then we will put these pairs into a RAPIDS cuDF dataframe. Next we will merge the `roBERTa` features extracted above onto the RAPIDS cuDF dataframe and use [RAPIDS Forest Inference Library (FIL)][1] to infer a probability score for each of the 196 million pairs! Finally we will convert these probabilities into 14,000 toxic scores for `submission.csv`.\n\n[1]: https://medium.com/rapids-ai/rapids-forest-inference-library-prediction-at-100-million-rows-per-second-19558890bc35","metadata":{}},{"cell_type":"code","source":"VER = 100\nFOLDS = 11\n\nimport pandas as pd, numpy as np, cudf, cupy, os\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom scipy.stats import rankdata\nprint('RAPIDS version',cudf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:22:56.085353Z","iopub.execute_input":"2022-02-08T03:22:56.085635Z","iopub.status.idle":"2022-02-08T03:22:56.092934Z","shell.execute_reply.started":"2022-02-08T03:22:56.085596Z","shell.execute_reply":"2022-02-08T03:22:56.092061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD COMMENTS TO SCORE\nsub = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:22:56.094367Z","iopub.execute_input":"2022-02-08T03:22:56.094621Z","iopub.status.idle":"2022-02-08T03:22:56.154533Z","shell.execute_reply.started":"2022-02-08T03:22:56.094587Z","shell.execute_reply":"2022-02-08T03:22:56.153898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MERGE EMBEDDINGS ONTO COMMENTS TO SCORE\nWORDS = 768 + 1024\nembed = np.concatenate( [np.load('embed.npy'), np.load('embed_large.npy')], axis=1 )\ndf_e = pd.DataFrame(embed,columns=[f'f_{x}' for x in range(WORDS)])\nsub = pd.concat([sub,df_e],axis=1)\ndel sub['text']","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:22:56.156786Z","iopub.execute_input":"2022-02-08T03:22:56.157043Z","iopub.status.idle":"2022-02-08T03:22:56.268571Z","shell.execute_reply.started":"2022-02-08T03:22:56.157011Z","shell.execute_reply":"2022-02-08T03:22:56.267825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.iloc[:,:1] = sub.iloc[:,:1].astype('int32')\nsub.iloc[:,1:] = sub.iloc[:,1:].astype('float32')\nIDS = sub.comment_id.values\nprint('Test has',len(IDS),'unique comments')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:22:56.270008Z","iopub.execute_input":"2022-02-08T03:22:56.270295Z","iopub.status.idle":"2022-02-08T03:22:56.511333Z","shell.execute_reply.started":"2022-02-08T03:22:56.27026Z","shell.execute_reply":"2022-02-08T03:22:56.510552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE RAPIDS CUDF DATAFRAME FOR ALL 196,000,000 PAIRS!\ntest2 = cudf.DataFrame({'id1':np.repeat(IDS,len(IDS)),\n                        'id2':np.tile(IDS,len(IDS))})\nfeatures = cudf.DataFrame(sub)\nprint('We will infer every row of dataframe with shape', test2.shape )\ntest2.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:22:56.512472Z","iopub.execute_input":"2022-02-08T03:22:56.513165Z","iopub.status.idle":"2022-02-08T03:23:00.154664Z","shell.execute_reply.started":"2022-02-08T03:22:56.513127Z","shell.execute_reply":"2022-02-08T03:23:00.153966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ONLY INFER DURING SUBMIT AND NOT COMMIT\nif len(IDS)==7537:\n    print('SKipping Infer During Commit...')\n    test2 = test2.iloc[:1_000_000]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:23:00.155963Z","iopub.execute_input":"2022-02-08T03:23:00.156713Z","iopub.status.idle":"2022-02-08T03:23:00.164351Z","shell.execute_reply.started":"2022-02-08T03:23:00.156674Z","shell.execute_reply":"2022-02-08T03:23:00.163487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURES = []\nWORDS = 768 + 1024\nFEATURES = FEATURES + [f'f_{x}' for x in range(WORDS)]\nFEATURES = FEATURES + [f'g_{x}' for x in range(WORDS)]\nprint('Each comment has',len(FEATURES),'feature columns')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:23:00.165651Z","iopub.execute_input":"2022-02-08T03:23:00.165967Z","iopub.status.idle":"2022-02-08T03:23:00.173943Z","shell.execute_reply.started":"2022-02-08T03:23:00.165929Z","shell.execute_reply":"2022-02-08T03:23:00.173229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom cuml import ForestInference\n\n# INFER TEST ITEM PAIRS IN BATCHES\nBATCH_SIZE = 100_000\nBATCHES = int( np.ceil( len(test2)/BATCH_SIZE ) )\ntest_preds = cupy.zeros((len(test2)),dtype='float32')\n\n#LOAD FOLD MODELS\nmodels = []\nfor fold in range(FOLDS):\n    model_path = f'../input/xgbtoxic100/XGB_v{VER}_f{fold}.xgb'\n    model = ForestInference.load(model_path, output_class=True, threads_per_tree=16,\n                                 storage_type='dense', algo='BATCH_TREE_REORG',\n                                 n_items=2, blocks_per_sm=5)\n    models.append(model)\n\n# INFER BATCHES, INFER FOLD MODELS\nprint(f'Inferring {BATCHES} batches...')\nfor k in range(BATCHES):\n    \n    start = BATCH_SIZE*k\n    end = min(BATCH_SIZE*(k+1),len(test2))\n    print(k,', ',end='')\n    \n    test3 = test2.iloc[start:end].copy()\n    test3['order'] = cupy.arange(len(test3)) #maintain order after merge\n    features.columns = ['id1'] + [f'g_{x}' for x in range(WORDS)]\n    test3 = test3.merge(features,on='id1',how='left')\n    features.columns = ['id2'] + [f'f_{x}' for x in range(WORDS)]\n    test3 = test3.merge(features,on='id2',how='left')\n    test3 = test3.fillna(-1)\n    test3 = test3.sort_values('order').drop(['order'],axis=1)\n    dtest = cupy.array( test3[FEATURES].values.astype('float32'), order='C' )\n\n    for fold in range(FOLDS):\n        test_preds[start:end] += models[fold].predict_proba(dtest)[:,1] / FOLDS\n    \nprint()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:23:00.175134Z","iopub.execute_input":"2022-02-08T03:23:00.175533Z","iopub.status.idle":"2022-02-08T03:23:38.53928Z","shell.execute_reply.started":"2022-02-08T03:23:00.175498Z","shell.execute_reply":"2022-02-08T03:23:38.538501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Pair Probabilities into Toxic Scores\nWe convert all the pair probabilities into toxic scores by simply adding up all the scores. If we use something more sophisted like ELO score or Bradley-Terry, we could probably boost our CV LB.","metadata":{}},{"cell_type":"code","source":"print('We inferred',len(test_preds),'numbers!')\nprint('During submit, we will infer 196,000,000 million numbers!')\ntest2['score'] = test_preds","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:23:38.543597Z","iopub.execute_input":"2022-02-08T03:23:38.545807Z","iopub.status.idle":"2022-02-08T03:23:38.553725Z","shell.execute_reply.started":"2022-02-08T03:23:38.545761Z","shell.execute_reply":"2022-02-08T03:23:38.553017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT PAIR PROBABILITIES INTO TOXIC SCORES\ntmp1 = test2.groupby('id1').score.sum().reset_index()\ntmp1.columns = ['comment_id','score1']\ntmp2 = test2.groupby('id2').score.sum().reset_index()\ntmp2.columns = ['comment_id','score2']\ntmp3 = tmp1.merge(tmp2,on='comment_id',how='left')\ntmp3['score'] = tmp3.score2 - tmp3.score1\ntmp3.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:23:38.5557Z","iopub.execute_input":"2022-02-08T03:23:38.556346Z","iopub.status.idle":"2022-02-08T03:23:38.656621Z","shell.execute_reply.started":"2022-02-08T03:23:38.556308Z","shell.execute_reply":"2022-02-08T03:23:38.652214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission.csv\nNow we merge toxic scores onto `submission.csv`","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:28:13.96887Z","iopub.execute_input":"2022-02-08T03:28:13.969156Z","iopub.status.idle":"2022-02-08T03:28:14.015121Z","shell.execute_reply.started":"2022-02-08T03:28:13.969126Z","shell.execute_reply":"2022-02-08T03:28:14.014319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MERGE TOXIC SCORES ONTO COMMENT TO SCORE\nsub = sub.merge(tmp3[['comment_id','score']].to_pandas(),on='comment_id',how='left')\nsub = sub.fillna(tmp3.score.mean())\nsub['score']=rankdata( sub['score'], method='ordinal')\nsub.sort_values('score')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:28:16.24687Z","iopub.execute_input":"2022-02-08T03:28:16.247528Z","iopub.status.idle":"2022-02-08T03:28:16.273377Z","shell.execute_reply.started":"2022-02-08T03:28:16.247487Z","shell.execute_reply":"2022-02-08T03:28:16.272718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WRITE SUBMISSION TO DISK\ndel sub['text']\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T03:23:38.789228Z","iopub.execute_input":"2022-02-08T03:23:38.791478Z","iopub.status.idle":"2022-02-08T03:23:38.824645Z","shell.execute_reply.started":"2022-02-08T03:23:38.79144Z","shell.execute_reply":"2022-02-08T03:23:38.823961Z"},"trusted":true},"execution_count":null,"outputs":[]}]}