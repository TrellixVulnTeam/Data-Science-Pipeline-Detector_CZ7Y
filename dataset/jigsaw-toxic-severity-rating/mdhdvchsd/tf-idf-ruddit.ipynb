{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T17:51:25.888434Z","iopub.execute_input":"2021-12-11T17:51:25.888787Z","iopub.status.idle":"2021-12-11T17:51:25.953529Z","shell.execute_reply.started":"2021-12-11T17:51:25.888692Z","shell.execute_reply":"2021-12-11T17:51:25.952829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import RidgeCV,Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline\nimport scipy\nfrom tqdm import tqdm_notebook\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:25.955073Z","iopub.execute_input":"2021-12-11T17:51:25.955486Z","iopub.status.idle":"2021-12-11T17:51:27.165033Z","shell.execute_reply.started":"2021-12-11T17:51:25.955452Z","shell.execute_reply":"2021-12-11T17:51:27.164111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\ndf_total.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.166481Z","iopub.execute_input":"2021-12-11T17:51:27.16674Z","iopub.status.idle":"2021-12-11T17:51:27.386188Z","shell.execute_reply.started":"2021-12-11T17:51:27.166709Z","shell.execute_reply":"2021-12-11T17:51:27.385177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef convert_reddit(dataframe):\n    list_label=[]\n    for index,row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n        list_label.append((row['offensiveness_score']+1)/(1+1))\n    return list_label\n\nlist_labels=convert_reddit(df_total)\ndf_total['label']=list_labels\ndf_total = df_total.rename(columns={\"txt\": \"text\"})\n\n# df_total = df_total.head(1000)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.388483Z","iopub.execute_input":"2021-12-11T17:51:27.389345Z","iopub.status.idle":"2021-12-11T17:51:27.725591Z","shell.execute_reply.started":"2021-12-11T17:51:27.389308Z","shell.execute_reply":"2021-12-11T17:51:27.723954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total.head(50)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.726936Z","iopub.execute_input":"2021-12-11T17:51:27.727166Z","iopub.status.idle":"2021-12-11T17:51:27.75638Z","shell.execute_reply.started":"2021-12-11T17:51:27.727138Z","shell.execute_reply":"2021-12-11T17:51:27.755168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom collections import defaultdict\n\nspecial_character_removal=re.compile(r'[^?!.,:a-z\\d ]',re.IGNORECASE)\n# regex to replace all numerics\nreplace_numbers=re.compile(r'\\d+',re.IGNORECASE)\nword_count_dict = defaultdict(int)\ntoxic_dict = {}\n\ndef clean_text(text, remove_stopwords=False, stem_words=False, count_null_words=True, clean_wiki_tokens=True):\n    # Clean the text, with the option to remove stopwords and to stem words.\n    # dirty words\n    #text = text.lower()\n    text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", text)\n    text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", text)\n    \n    if clean_wiki_tokens:\n        # Drop the image\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.jpg\", \" \", text)\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.png\", \" \", text)\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.gif\", \" \", text)\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.bmp\", \" \", text)\n\n        # Drop css\n        text = re.sub(r\"#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})\", \" \",text)\n        text = re.sub(r\"\\{\\|[^\\}]*\\|\\}\", \" \", text)\n        \n        # Clean templates\n        text = re.sub(r\"\\[?\\[user:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[user:.*\\|\", \" \", text)        \n        text = re.sub(r\"\\[?\\[wikipedia:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[wikipedia:.*\\|\", \" \", text)\n        text = re.sub(r\"\\[?\\[special:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[special:.*\\|\", \" \", text)\n        text = re.sub(r\"\\[?\\[category:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[category:.*\\|\", \" \", text)\n    \n   \n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" \", text)\n    text = re.sub(r\"!\", \" ! \", text)\n    text = re.sub(r\"\\/\", \" \", text)\n    text = re.sub(r\"\\?\", \" ? \", text)\n    text = re.sub(r\"\\!\", \" ! \", text)\n    text = re.sub(r\"\\\"\", \" \", text)\n    text = re.sub(r\"\\^\", \" ^ \", text)\n    text = re.sub(r\"\\+\", \" + \", text)\n    text = re.sub(r\"\\-\", \" - \", text)\n    text = re.sub(r\"\\=\", \" = \", text)\n    text = re.sub(r\"'\", \" \", text)\n    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    text = re.sub(r\":\", \" : \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\" u s \", \" american \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e - mail\", \"email\", text)\n    text = re.sub(r\"j k\", \"jk\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = replace_numbers.sub(' ', text)\n    #text = special_character_removal.sub('',text)\n\n    if count_null_words:\n        text = text.split()\n        for t in text:\n            word_count_dict[t] += 1\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n\n    return (text)\n\n# df_total['text'] = [clean_text(text) for text in df_total['text']]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.759949Z","iopub.execute_input":"2021-12-11T17:51:27.760728Z","iopub.status.idle":"2021-12-11T17:51:27.786966Z","shell.execute_reply.started":"2021-12-11T17:51:27.760675Z","shell.execute_reply":"2021-12-11T17:51:27.786009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.788389Z","iopub.execute_input":"2021-12-11T17:51:27.788919Z","iopub.status.idle":"2021-12-11T17:51:27.819078Z","shell.execute_reply.started":"2021-12-11T17:51:27.788879Z","shell.execute_reply":"2021-12-11T17:51:27.818068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline(\n    [\n        (\"vect\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n        #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n        (\"clf\", Ridge()),\n        #(\"clf\",LinearRegression())\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.820392Z","iopub.execute_input":"2021-12-11T17:51:27.820691Z","iopub.status.idle":"2021-12-11T17:51:27.826238Z","shell.execute_reply.started":"2021-12-11T17:51:27.820657Z","shell.execute_reply":"2021-12-11T17:51:27.825534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the pipeline\npipeline.fit(df_total['text'], df_total['label'])","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:51:27.82742Z","iopub.execute_input":"2021-12-11T17:51:27.828228Z","iopub.status.idle":"2021-12-11T17:52:18.355814Z","shell.execute_reply.started":"2021-12-11T17:51:27.82813Z","shell.execute_reply":"2021-12-11T17:52:18.354574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_val.drop_duplicates(subset=['less_toxic', 'more_toxic'], keep='first', inplace=True)\ndf_val.reset_index(inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:18.359175Z","iopub.execute_input":"2021-12-11T17:52:18.360248Z","iopub.status.idle":"2021-12-11T17:52:19.012061Z","shell.execute_reply.started":"2021-12-11T17:52:18.360186Z","shell.execute_reply":"2021-12-11T17:52:19.010981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_val['less_toxic'] = [clean_text(text) for text in df_val['less_toxic']]\n# df_val['more_toxic'] = [clean_text(text) for text in df_val['more_toxic']]\np1 = pipeline.predict(df_val['less_toxic'])\np2 = pipeline.predict(df_val['more_toxic'])","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:19.013912Z","iopub.execute_input":"2021-12-11T17:52:19.014453Z","iopub.status.idle":"2021-12-11T17:52:47.308271Z","shell.execute_reply.started":"2021-12-11T17:52:19.014414Z","shell.execute_reply":"2021-12-11T17:52:47.307083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}'","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:47.310336Z","iopub.execute_input":"2021-12-11T17:52:47.311602Z","iopub.status.idle":"2021-12-11T17:52:47.318705Z","shell.execute_reply.started":"2021-12-11T17:52:47.311551Z","shell.execute_reply":"2021-12-11T17:52:47.31777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:47.319931Z","iopub.execute_input":"2021-12-11T17:52:47.320341Z","iopub.status.idle":"2021-12-11T17:52:47.33187Z","shell.execute_reply.started":"2021-12-11T17:52:47.320292Z","shell.execute_reply":"2021-12-11T17:52:47.330955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'finalized_model.sav'\npickle.dump(pipeline, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:47.335177Z","iopub.execute_input":"2021-12-11T17:52:47.335698Z","iopub.status.idle":"2021-12-11T17:52:47.379353Z","shell.execute_reply.started":"2021-12-11T17:52:47.335655Z","shell.execute_reply":"2021-12-11T17:52:47.378305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n# test_df = test_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:47.380965Z","iopub.execute_input":"2021-12-11T17:52:47.381343Z","iopub.status.idle":"2021-12-11T17:52:47.478748Z","shell.execute_reply.started":"2021-12-11T17:52:47.381298Z","shell.execute_reply":"2021-12-11T17:52:47.477743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:52:47.480091Z","iopub.execute_input":"2021-12-11T17:52:47.480803Z","iopub.status.idle":"2021-12-11T17:52:47.48432Z","shell.execute_reply.started":"2021-12-11T17:52:47.480752Z","shell.execute_reply":"2021-12-11T17:52:47.483623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df['text'] = [clean_text(text) for text in test_df['text']]\n\nout = pipeline.predict(test_df['text'])\nout","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:54:08.146345Z","iopub.execute_input":"2021-12-11T17:54:08.146729Z","iopub.status.idle":"2021-12-11T17:54:15.154106Z","shell.execute_reply.started":"2021-12-11T17:54:08.146689Z","shell.execute_reply":"2021-12-11T17:54:15.153477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import rankdata\n\n\nsubmission = pd.DataFrame({'comment_id': test_df['comment_id'], 'score':out})\nsubmission['score'] = rankdata(submission['score'], method='ordinal')\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:54:15.15554Z","iopub.execute_input":"2021-12-11T17:54:15.155979Z","iopub.status.idle":"2021-12-11T17:54:15.186092Z","shell.execute_reply.started":"2021-12-11T17:54:15.155943Z","shell.execute_reply":"2021-12-11T17:54:15.185384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-12-11T17:54:15.187697Z","iopub.execute_input":"2021-12-11T17:54:15.188152Z","iopub.status.idle":"2021-12-11T17:54:15.201536Z","shell.execute_reply.started":"2021-12-11T17:54:15.188118Z","shell.execute_reply":"2021-12-11T17:54:15.200499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}