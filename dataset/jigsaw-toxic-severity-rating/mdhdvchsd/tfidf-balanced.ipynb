{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T19:01:34.551123Z","iopub.execute_input":"2021-12-22T19:01:34.551529Z","iopub.status.idle":"2021-12-22T19:01:34.589609Z","shell.execute_reply.started":"2021-12-22T19:01:34.551423Z","shell.execute_reply":"2021-12-22T19:01:34.588984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import RidgeCV, Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline\nimport scipy\nfrom tqdm import tqdm_notebook","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:34.591708Z","iopub.execute_input":"2021-12-22T19:01:34.592081Z","iopub.status.idle":"2021-12-22T19:01:35.895053Z","shell.execute_reply.started":"2021-12-22T19:01:34.592008Z","shell.execute_reply":"2021-12-22T19:01:35.894201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ndf_test = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")\ndf_test_labels = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv\")\ndf_test=df_test.merge(df_test_labels, how='inner', on='id')\n\ndf_total=pd.concat([df_train,df_test]).reset_index(drop=True)\ndf_total=df_total[df_total['toxic']!=-1]\n\ndf_total","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:35.896308Z","iopub.execute_input":"2021-12-22T19:01:35.896635Z","iopub.status.idle":"2021-12-22T19:01:40.225894Z","shell.execute_reply.started":"2021-12-22T19:01:35.8966Z","shell.execute_reply":"2021-12-22T19:01:40.224981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_mapping_kaggle={\n    'severe_toxic':5,\n    'obscene':1,\n    'threat':4,\n    'insult':2,\n    'identity_hate':3\n}\n\n\ndef convert_kaggle(dataframe):\n    list_label=[]\n    for index,row in tqdm_notebook(dataframe.iterrows(), total=len(dataframe)):\n        if(row['toxic']==0):\n            list_label.append(0)\n        else:\n            final_label=0\n            count=0\n            for col in list(dataframe.columns)[3:]:\n                if(row[col]==1):\n                    final_label+=dict_mapping_kaggle[col]\n                    count+=1\n            if(final_label==0):\n                final_label=(1+2+3+4+5)/5\n            else:\n                final_label=final_label/count\n            list_label.append(final_label/5)\n    return list_label    \n            \nlist_labels=convert_kaggle(df_total)\ndf_total['label']=list_labels\ndf_total = df_total.rename(columns={\"comment_text\": \"text\"})\n\n# # df_total = df_total.head(1000)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:40.22777Z","iopub.execute_input":"2021-12-22T19:01:40.227988Z","iopub.status.idle":"2021-12-22T19:01:52.845433Z","shell.execute_reply.started":"2021-12-22T19:01:40.22796Z","shell.execute_reply":"2021-12-22T19:01:52.844232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# df_total['severe_toxic'] = df_total.severe_toxic * 2\n# # df['sum'] = df['toxic'] + df['severe_toxic'] + df['obscene'] + df['insult'] + df['threat'] + df['identity_hate']\n# df_total['label'] = df_total.iloc[:, 2:9].sum(axis = 1)\n# print(df_total['label'].max())\n# df_total['label']  = df_total['label']/df_total['label'].max()\n\n# df_total = df_total.rename(columns={\"comment_text\": \"text\"})","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:52.846722Z","iopub.execute_input":"2021-12-22T19:01:52.846966Z","iopub.status.idle":"2021-12-22T19:01:52.851245Z","shell.execute_reply.started":"2021-12-22T19:01:52.846935Z","shell.execute_reply":"2021-12-22T19:01:52.850378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:52.852313Z","iopub.execute_input":"2021-12-22T19:01:52.852522Z","iopub.status.idle":"2021-12-22T19:01:52.875745Z","shell.execute_reply.started":"2021-12-22T19:01:52.852496Z","shell.execute_reply":"2021-12-22T19:01:52.874502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(df_total))\n# len(df_total[df_total['label'] != 0])\n# np.random.seed(10)\n\n# remove_n = len(df_total[df_total['label'] == 0]) - len(df_total[df_total['label'] != 0])\n# drop_indices = np.random.choice(df_total.index, remove_n, replace=False)\n# df_total.drop(drop_indices, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:52.877148Z","iopub.execute_input":"2021-12-22T19:01:52.878728Z","iopub.status.idle":"2021-12-22T19:01:52.885253Z","shell.execute_reply.started":"2021-12-22T19:01:52.878684Z","shell.execute_reply":"2021-12-22T19:01:52.884575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:52.886485Z","iopub.execute_input":"2021-12-22T19:01:52.88756Z","iopub.status.idle":"2021-12-22T19:01:52.909616Z","shell.execute_reply.started":"2021-12-22T19:01:52.887483Z","shell.execute_reply":"2021-12-22T19:01:52.90877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom collections import defaultdict\n\nspecial_character_removal=re.compile(r'[^?!.,:a-z\\d ]',re.IGNORECASE)\n# regex to replace all numerics\nreplace_numbers=re.compile(r'\\d+',re.IGNORECASE)\nword_count_dict = defaultdict(int)\ntoxic_dict = {}\n\ndef clean_text(text, remove_stopwords=False, stem_words=False, count_null_words=True, clean_wiki_tokens=True):\n    # Clean the text, with the option to remove stopwords and to stem words.\n    # dirty words\n    #text = text.lower()\n    text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", text)\n    text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", text)\n    \n    if clean_wiki_tokens:\n        # Drop the image\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.jpg\", \" \", text)\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.png\", \" \", text)\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.gif\", \" \", text)\n        text = re.sub(r\"image:[a-zA-Z0-9]*\\.bmp\", \" \", text)\n\n        # Drop css\n        text = re.sub(r\"#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})\", \" \",text)\n        text = re.sub(r\"\\{\\|[^\\}]*\\|\\}\", \" \", text)\n        \n        # Clean templates\n        text = re.sub(r\"\\[?\\[user:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[user:.*\\|\", \" \", text)        \n        text = re.sub(r\"\\[?\\[wikipedia:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[wikipedia:.*\\|\", \" \", text)\n        text = re.sub(r\"\\[?\\[special:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[special:.*\\|\", \" \", text)\n        text = re.sub(r\"\\[?\\[category:.*\\]\", \" \", text)\n        text = re.sub(r\"\\[?\\[category:.*\\|\", \" \", text)\n    \n   \n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" \", text)\n    text = re.sub(r\"!\", \" ! \", text)\n    text = re.sub(r\"\\/\", \" \", text)\n    text = re.sub(r\"\\?\", \" ? \", text)\n    text = re.sub(r\"\\!\", \" ! \", text)\n    text = re.sub(r\"\\\"\", \" \", text)\n    text = re.sub(r\"\\^\", \" ^ \", text)\n    text = re.sub(r\"\\+\", \" + \", text)\n    text = re.sub(r\"\\-\", \" - \", text)\n    text = re.sub(r\"\\=\", \" = \", text)\n    text = re.sub(r\"'\", \" \", text)\n    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    text = re.sub(r\":\", \" : \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\" u s \", \" american \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e - mail\", \"email\", text)\n    text = re.sub(r\"j k\", \"jk\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = replace_numbers.sub(' ', text)\n    #text = special_character_removal.sub('',text)\n\n    if count_null_words:\n        text = text.split()\n        for t in text:\n            word_count_dict[t] += 1\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n\n    return (text)\n\ndf_total['text'] = [clean_text(text) for text in df_total['text']]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:01:52.911056Z","iopub.execute_input":"2021-12-22T19:01:52.911404Z","iopub.status.idle":"2021-12-22T19:02:55.522143Z","shell.execute_reply.started":"2021-12-22T19:01:52.911359Z","shell.execute_reply":"2021-12-22T19:02:55.521287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline(\n    [\n#         (\"vect\", TfidfVectorizer(analyzer = 'char_wb',  max_features = 5000)),\n        (\"vect\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5),  max_features = 10000)),\n        \n        #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n        (\"clf\", Ridge()),\n        #(\"clf\",LinearRegression())\n    ],verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:02:55.524804Z","iopub.execute_input":"2021-12-22T19:02:55.525145Z","iopub.status.idle":"2021-12-22T19:02:55.530636Z","shell.execute_reply.started":"2021-12-22T19:02:55.525111Z","shell.execute_reply":"2021-12-22T19:02:55.529663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the pipeline\npipeline.fit(df_total['text'], df_total['label'])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:02:55.531729Z","iopub.execute_input":"2021-12-22T19:02:55.531943Z","iopub.status.idle":"2021-12-22T19:06:32.690517Z","shell.execute_reply.started":"2021-12-22T19:02:55.531916Z","shell.execute_reply":"2021-12-22T19:06:32.689435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_val.drop_duplicates(subset=['less_toxic', 'more_toxic'], keep='first', inplace=True)\ndf_val.reset_index(inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:06:32.692365Z","iopub.execute_input":"2021-12-22T19:06:32.692678Z","iopub.status.idle":"2021-12-22T19:06:33.323227Z","shell.execute_reply.started":"2021-12-22T19:06:32.692645Z","shell.execute_reply":"2021-12-22T19:06:33.322328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['less_toxic'] = [clean_text(text) for text in df_val['less_toxic']]\ndf_val['more_toxic'] = [clean_text(text) for text in df_val['more_toxic']]\np1 = pipeline.predict(df_val['less_toxic'])\np2 = pipeline.predict(df_val['more_toxic'])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:06:33.324794Z","iopub.execute_input":"2021-12-22T19:06:33.325327Z","iopub.status.idle":"2021-12-22T19:07:11.02097Z","shell.execute_reply.started":"2021-12-22T19:06:33.325277Z","shell.execute_reply":"2021-12-22T19:07:11.020031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}'","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:07:11.022356Z","iopub.execute_input":"2021-12-22T19:07:11.02261Z","iopub.status.idle":"2021-12-22T19:07:11.030967Z","shell.execute_reply.started":"2021-12-22T19:07:11.022575Z","shell.execute_reply":"2021-12-22T19:07:11.030062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfilename = 'finalized_model.sav'\npickle.dump(pipeline, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:07:11.032676Z","iopub.execute_input":"2021-12-22T19:07:11.033168Z","iopub.status.idle":"2021-12-22T19:07:11.745103Z","shell.execute_reply.started":"2021-12-22T19:07:11.033123Z","shell.execute_reply":"2021-12-22T19:07:11.744284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n# # test_df = test_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:07:11.746294Z","iopub.execute_input":"2021-12-22T19:07:11.746945Z","iopub.status.idle":"2021-12-22T19:07:11.874664Z","shell.execute_reply.started":"2021-12-22T19:07:11.746905Z","shell.execute_reply":"2021-12-22T19:07:11.873931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['text'] = [clean_text(text) for text in test_df['text']]\n\nout = pipeline.predict(test_df['text'])\nout","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:07:11.876265Z","iopub.execute_input":"2021-12-22T19:07:11.876634Z","iopub.status.idle":"2021-12-22T19:07:21.223185Z","shell.execute_reply.started":"2021-12-22T19:07:11.876587Z","shell.execute_reply":"2021-12-22T19:07:21.22209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import rankdata\n\n\nsubmission = pd.DataFrame({'comment_id': test_df['comment_id'], 'score':out})\nsubmission['score'] = rankdata(submission['score'], method='ordinal')\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:07:21.224691Z","iopub.execute_input":"2021-12-22T19:07:21.225168Z","iopub.status.idle":"2021-12-22T19:07:21.255374Z","shell.execute_reply.started":"2021-12-22T19:07:21.225126Z","shell.execute_reply":"2021-12-22T19:07:21.254455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-12-22T19:07:21.256773Z","iopub.execute_input":"2021-12-22T19:07:21.257018Z","iopub.status.idle":"2021-12-22T19:07:21.269281Z","shell.execute_reply.started":"2021-12-22T19:07:21.256978Z","shell.execute_reply":"2021-12-22T19:07:21.268412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}