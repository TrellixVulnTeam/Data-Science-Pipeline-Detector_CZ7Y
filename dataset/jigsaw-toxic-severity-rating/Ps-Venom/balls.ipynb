{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\nfrom zipfile import ZipFile\nimport seaborn as sns\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-20T13:31:47.603702Z","iopub.execute_input":"2021-12-20T13:31:47.6041Z","iopub.status.idle":"2021-12-20T13:31:53.814468Z","shell.execute_reply.started":"2021-12-20T13:31:47.603994Z","shell.execute_reply":"2021-12-20T13:31:53.813376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsample_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:53.816706Z","iopub.execute_input":"2021-12-20T13:31:53.817134Z","iopub.status.idle":"2021-12-20T13:31:53.964284Z","shell.execute_reply.started":"2021-12-20T13:31:53.817087Z","shell.execute_reply":"2021-12-20T13:31:53.963231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = sample_data['text']\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:53.965969Z","iopub.execute_input":"2021-12-20T13:31:53.966214Z","iopub.status.idle":"2021-12-20T13:31:53.976232Z","shell.execute_reply.started":"2021-12-20T13:31:53.966157Z","shell.execute_reply":"2021-12-20T13:31:53.975197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\nlis2 = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv')\nlis.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:53.979117Z","iopub.execute_input":"2021-12-20T13:31:53.979487Z","iopub.status.idle":"2021-12-20T13:31:56.536906Z","shell.execute_reply.started":"2021-12-20T13:31:53.979441Z","shell.execute_reply":"2021-12-20T13:31:56.536137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis['compound'] = lis.sum(axis = 1)\ndef a(x) :\n    if x> 0:\n        return 1\n    else:\n        return 0\nlis['y'] = lis['compound'].apply(lambda x: a(x))\nlis.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:56.538532Z","iopub.execute_input":"2021-12-20T13:31:56.539072Z","iopub.status.idle":"2021-12-20T13:31:56.989497Z","shell.execute_reply.started":"2021-12-20T13:31:56.539024Z","shell.execute_reply":"2021-12-20T13:31:56.988589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlis = lis[['comment_text', 'y']]\nlis.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:56.990542Z","iopub.execute_input":"2021-12-20T13:31:56.990748Z","iopub.status.idle":"2021-12-20T13:31:57.018864Z","shell.execute_reply.started":"2021-12-20T13:31:56.990721Z","shell.execute_reply":"2021-12-20T13:31:57.017883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"less_arr = pd.DataFrame(lis2['less_toxic']).rename(columns = {'less_toxic':'comment_text'}, inplace = False)\nmore_arr = pd.DataFrame(lis2['more_toxic']).rename(columns = {'more_toxic':'comment_text'}, inplace = False)\nmore_arr['y'] = 1\nless_arr['y'] =  0  \nlis  = pd.concat([less_arr, more_arr, lis])\nlis.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:57.019975Z","iopub.execute_input":"2021-12-20T13:31:57.020292Z","iopub.status.idle":"2021-12-20T13:31:57.045363Z","shell.execute_reply.started":"2021-12-20T13:31:57.020259Z","shell.execute_reply":"2021-12-20T13:31:57.044571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:57.046566Z","iopub.execute_input":"2021-12-20T13:31:57.046797Z","iopub.status.idle":"2021-12-20T13:31:57.052957Z","shell.execute_reply.started":"2021-12-20T13:31:57.046768Z","shell.execute_reply":"2021-12-20T13:31:57.052253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"contractions_dict = { \n\"ain't\": \"am not / are not / is not / has not / have not\",\n\"aren't\": \"are not / am not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had / he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he shall / he will\",\n\"he'll've\": \"he shall have / he will have\",\n\"he's\": \"he has / he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how has / how is / how does\",\n\"I'd\": \"I had / I would\",\n\"I'd've\": \"I would have\",\n\"I'll\": \"I shall / I will\",\n\"I'll've\": \"I shall have / I will have\",\n\"I'm\": \"I am\",\n\"I've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it had / it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it shall / it will\",\n\"it'll've\": \"it shall have / it will have\",\n\"it's\": \"it has / it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she had / she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she shall / she will\",\n\"she'll've\": \"she shall have / she will have\",\n\"she's\": \"she has / she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as / so is\",\n\"that'd\": \"that would / that had\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that has / that is\",\n\"there'd\": \"there had / there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there has / there is\",\n\"they'd\": \"they had / they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they shall / they will\",\n\"they'll've\": \"they shall have / they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had / we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what shall / what will\",\n\"what'll've\": \"what shall have / what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what has / what is\",\n\"what've\": \"what have\",\n\"when's\": \"when has / when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where has / where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who shall / who will\",\n\"who'll've\": \"who shall have / who will have\",\n\"who's\": \"who has / who is\",\n\"who've\": \"who have\",\n\"why's\": \"why has / why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you had / you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you shall / you will\",\n\"you'll've\": \"you shall have / you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}\ncontractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\ndef expand_contractions(text,contractions_dict=contractions_dict):\n    def replace(match):\n        return contractions_dict[match.group(0)]\n    return contractions_re.sub(replace, text)\n# Expanding Contractions in the reviews\nlis['comment_text']= lis['comment_text'].apply(lambda x:expand_contractions(x))\n\nlis.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:31:57.054815Z","iopub.execute_input":"2021-12-20T13:31:57.055263Z","iopub.status.idle":"2021-12-20T13:32:22.494135Z","shell.execute_reply.started":"2021-12-20T13:31:57.05523Z","shell.execute_reply":"2021-12-20T13:32:22.493145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test= test.apply(lambda x:expand_contractions(x))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:22.49834Z","iopub.execute_input":"2021-12-20T13:32:22.498578Z","iopub.status.idle":"2021-12-20T13:32:23.366154Z","shell.execute_reply.started":"2021-12-20T13:32:22.498549Z","shell.execute_reply":"2021-12-20T13:32:23.365137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis['comment_text'] = lis['comment_text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:23.367362Z","iopub.execute_input":"2021-12-20T13:32:23.367625Z","iopub.status.idle":"2021-12-20T13:32:23.725819Z","shell.execute_reply.started":"2021-12-20T13:32:23.367593Z","shell.execute_reply":"2021-12-20T13:32:23.724909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:23.727056Z","iopub.execute_input":"2021-12-20T13:32:23.727713Z","iopub.status.idle":"2021-12-20T13:32:23.742063Z","shell.execute_reply.started":"2021-12-20T13:32:23.727664Z","shell.execute_reply":"2021-12-20T13:32:23.741328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nlis['comment_text'] = lis['comment_text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\nlis.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:23.743481Z","iopub.execute_input":"2021-12-20T13:32:23.74404Z","iopub.status.idle":"2021-12-20T13:32:27.490578Z","shell.execute_reply.started":"2021-12-20T13:32:23.744005Z","shell.execute_reply":"2021-12-20T13:32:27.489506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:27.491863Z","iopub.execute_input":"2021-12-20T13:32:27.492117Z","iopub.status.idle":"2021-12-20T13:32:27.628961Z","shell.execute_reply.started":"2021-12-20T13:32:27.492084Z","shell.execute_reply":"2021-12-20T13:32:27.627847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis['comment_text'] = lis['comment_text'].apply(lambda x: re.sub('\\W+',' ', x))\nlis.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:27.6303Z","iopub.execute_input":"2021-12-20T13:32:27.630644Z","iopub.status.idle":"2021-12-20T13:32:35.94552Z","shell.execute_reply.started":"2021-12-20T13:32:27.630595Z","shell.execute_reply":"2021-12-20T13:32:35.944265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.apply(lambda x: re.sub('\\W+',' ', x))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:35.947434Z","iopub.execute_input":"2021-12-20T13:32:35.947857Z","iopub.status.idle":"2021-12-20T13:32:36.264349Z","shell.execute_reply.started":"2021-12-20T13:32:35.947806Z","shell.execute_reply":"2021-12-20T13:32:36.263361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis[lis['y']>=0].hist()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:36.265564Z","iopub.execute_input":"2021-12-20T13:32:36.265812Z","iopub.status.idle":"2021-12-20T13:32:36.610775Z","shell.execute_reply.started":"2021-12-20T13:32:36.265783Z","shell.execute_reply":"2021-12-20T13:32:36.60977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis = pd.concat([lis[lis['y'] > 0], lis[lis['y'] == 0].sample(int(len(lis[lis['y'] > 0])*1.5))], axis = 0).sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:36.612246Z","iopub.execute_input":"2021-12-20T13:32:36.612573Z","iopub.status.idle":"2021-12-20T13:32:36.670922Z","shell.execute_reply.started":"2021-12-20T13:32:36.612526Z","shell.execute_reply":"2021-12-20T13:32:36.669983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis[lis['y']>=0].hist()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:36.673293Z","iopub.execute_input":"2021-12-20T13:32:36.67367Z","iopub.status.idle":"2021-12-20T13:32:36.960592Z","shell.execute_reply.started":"2021-12-20T13:32:36.673621Z","shell.execute_reply":"2021-12-20T13:32:36.959772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:36.962002Z","iopub.execute_input":"2021-12-20T13:32:36.962394Z","iopub.status.idle":"2021-12-20T13:32:36.967456Z","shell.execute_reply.started":"2021-12-20T13:32:36.962359Z","shell.execute_reply":"2021-12-20T13:32:36.966621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import unidecode\nlis['comment_text'] = lis['comment_text'].apply(lambda x: unidecode.unidecode(x))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:36.968381Z","iopub.execute_input":"2021-12-20T13:32:36.968874Z","iopub.status.idle":"2021-12-20T13:32:38.258855Z","shell.execute_reply.started":"2021-12-20T13:32:36.968837Z","shell.execute_reply":"2021-12-20T13:32:38.257819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.apply(lambda x: unidecode.unidecode(x))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:38.260202Z","iopub.execute_input":"2021-12-20T13:32:38.260625Z","iopub.status.idle":"2021-12-20T13:32:38.340412Z","shell.execute_reply.started":"2021-12-20T13:32:38.260591Z","shell.execute_reply":"2021-12-20T13:32:38.339591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textblob as tb\nfrom textblob import TextBlob\ndef sentiment(text):\n    tb = TextBlob(text)\n    tb = (tb.sentiment.polarity-1)/(-2)\n    return tb\nlis['senti'] = lis['comment_text'].apply(lambda x: sentiment(x))\nsns.heatmap(lis.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:32:38.341697Z","iopub.execute_input":"2021-12-20T13:32:38.341949Z","iopub.status.idle":"2021-12-20T13:33:50.484073Z","shell.execute_reply.started":"2021-12-20T13:32:38.341918Z","shell.execute_reply":"2021-12-20T13:33:50.483422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsample_data['senti'] = sample_data['text'].apply(lambda x: sentiment(x))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:33:50.485366Z","iopub.execute_input":"2021-12-20T13:33:50.485767Z","iopub.status.idle":"2021-12-20T13:33:56.342184Z","shell.execute_reply.started":"2021-12-20T13:33:50.485716Z","shell.execute_reply":"2021-12-20T13:33:56.341341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis = lis.sample(frac = 1)\ntext = list(lis['comment_text'])\nsubmit = list(sample_data['text'])\noutputs = list(lis['y'])\nsentimentX = list(lis['senti'])\nsentimentY = list(sample_data['senti'])\nfor i in test:\n    submit.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:33:56.343565Z","iopub.execute_input":"2021-12-20T13:33:56.343804Z","iopub.status.idle":"2021-12-20T13:33:56.435188Z","shell.execute_reply.started":"2021-12-20T13:33:56.343775Z","shell.execute_reply":"2021-12-20T13:33:56.434419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\ntokenizer = Tokenizer(num_words = 250000)\nt_samples = 100000\nv_samples = 15832\ntokenizer.fit_on_texts(text)\nsequences = tokenizer.texts_to_sequences(text)\nsubmit_sequences = tokenizer.texts_to_sequences(submit)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens' % len(word_index))\ndata = pad_sequences(sequences, maxlen = 1000)\ndata_submit = pad_sequences(submit_sequences, maxlen = 1000)\noutputs = np.asarray(outputs)\nprint('shape of data tensor', (data.shape, data_submit.shape))\nprint('shape of output', outputs.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T13:33:56.436571Z","iopub.execute_input":"2021-12-20T13:33:56.436997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = np.arange(data.shape[0])\ndata = data[indices]\nlabels = outputs[indices]\nXt, Xv = data[:t_samples], data[t_samples: t_samples+v_samples]\nyt, yv = outputs[:t_samples], outputs[t_samples: t_samples+v_samples]\nSt, Sv = sentimentX[:t_samples], sentimentX[t_samples: t_samples+v_samples]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(os.path.join('/kaggle/input/glove-global-vectors-for-word-representation', 'glove.twitter.27B.100d.txt'))\nembeddings_index = {}\nfor line in f:\n    value = line.split()\n    word = value[0]\n    coefs = np.asarray(value[1:], dtype = 'float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors'%len(embeddings_index))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 100\nembedding_matrix = np.zeros((1193514, embedding_dim))\nfor word, i in word_index.items():\n    if i<200:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\nembedding_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Input, Embedding, Flatten, Dense, Dropout, GRU, concatenate, Conv1D, MaxPooling1D\ntext_input = Input(shape = (1000, ))\ntext_input_layer = Embedding(1193514, 100, input_length = 1000, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable = True)(text_input)\nmodel = Conv1D(32, 7, activation = 'relu')(text_input_layer)\nmodel = LSTM(64)(model)\nlrelu = lambda x: tf.keras.layers.LeakyReLU( alpha = 0.01)(x)\nsenti_input = Input(shape = (1, ))\nsenti_input_layer = Dense(32, activation = lrelu)(senti_input)\nmodel = concatenate([model, senti_input_layer])\nmodel = Dense(128, activation= lrelu)(model)\nmodel = Dropout(0.08)(model)\noutput = Dense(1, activation = 'sigmoid')(model)\n\nmodel = keras.Model(inputs=[text_input, senti_input], outputs= output)\nmodel.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([Xt, np.asarray(St)], yt, epochs = 4, batch_size = 32, validation_data = ([Xv, np.asarray(Sv)], yv))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(data_submit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data['score'] = predictions\nsample_data.head()\ndel sample_data['text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data.to_csv('submission.csv', index = False, float_format='%.20f' )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}