{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Context\n\nThis notebook uses the \"detoxify\" model\n\nhttps://github.com/unitaryai/detoxify\n\nA discussion of this model is available here\n\nhttps://www.kaggle.com/c/jigsaw-toxic-severity-rating/discussion/300058\n\nOne way to run\n\n*Using Detoxify in offline mode*  \nhttps://www.kaggle.com/atamazian/using-detoxify-in-offline-mode\n\n@atamazian thanks!\n\n## Clarification\n\nThis configuration has a limitation - the maximum length of a string is no more than 512 characters, otherwise an error like\n\n> RuntimeError: The size of tensor a (___) must match the size of tensor b (512)\n\nso I had to shorten it\n\n```\ndef get_predict_data(model: Callable, data: pd.Series) -> pd.Series:\n    \"\"\" Create toxic data by detoxify model. \"\"\"\n    # The BERT's limitation with the word count\n    max_str_len = 500\n    data = data.apply(tc.shorten_text, max_len=max_str_len)\n    \n    [...]\n```\n\nI tried the length of 300 (**V5**) and 500 (**V6**) characters, the more - the more score.\n\nAlso, I didn't use all the predictions\n\n```\n    \n    labels_list = ['toxicity', 'severe_toxicity',\n                   'obscene', 'threat', 'insult',\n                   'identity_attack'],\n    \n    weigths_list = [None, 1, 1, 1, 1, 1]\n\n    [...]    \n\n    return (predict_df * weigths_list).median(axis=1)\n```","metadata":{}},{"cell_type":"markdown","source":"# 1. Import & Def & Load data","metadata":{}},{"cell_type":"code","source":"%%capture\n\n!cp -r ../input/detoxify/detoxify-master detoxify\n!pip install -q ./detoxify\n!rm -rf ./detoxify","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-06T01:27:34.491223Z","iopub.execute_input":"2022-02-06T01:27:34.491604Z","iopub.status.idle":"2022-02-06T01:28:06.159529Z","shell.execute_reply.started":"2022-02-06T01:27:34.491518Z","shell.execute_reply":"2022-02-06T01:28:06.158597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nfrom typing import Callable\n\nfrom detoxify import Detoxify\n\nimport toxic_comments_utilities as tc","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-06T01:28:06.162258Z","iopub.execute_input":"2022-02-06T01:28:06.162801Z","iopub.status.idle":"2022-02-06T01:28:09.343589Z","shell.execute_reply.started":"2022-02-06T01:28:06.16276Z","shell.execute_reply":"2022-02-06T01:28:09.342886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predict_data(model: Callable, data: pd.Series) -> pd.Series:\n    \"\"\" Create toxic data by detoxify model. \"\"\"\n    # The BERT's limitation with the word count\n    max_str_len = 500\n    data = data.apply(tc.shorten_text, max_len=max_str_len)\n    \n    labels_list = ['toxicity', 'severe_toxicity',\n                   'obscene', 'threat', 'insult',\n                   'identity_attack'],\n    \n    weigths_list = [None, 1, 1, 1, 1, 1]\n\n    result = []\n\n    predict_labels = model.class_names\n        \n    for text in data.values:\n        result.append(list(model.predict(text).values()))\n        \n    predict_df = pd.DataFrame.from_records(\n                                    result,\n                                    index=data.index,\n                                    columns=predict_labels)\n\n    return (predict_df * weigths_list).median(axis=1)\n\n\ndef get_score(model: Callable, data: pd.DataFrame) -> float:\n    \"\"\" Score a model on the validation data. \"\"\"\n    data = data.copy()\n    \n    data['less_toxic'] = get_predict_data(model, data['less_toxic'])\n    data['more_toxic'] = get_predict_data(model, data['more_toxic'])\n    \n    score = data.eval('less_toxic < more_toxic').mean()\n    \n    return round(score, 4)\n\n\ndef get_submission(model: Callable, data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\" Get predicted toxicity scores to submit results. \"\"\"\n    data = data.copy()\n    \n    data['text'] = get_predict_data(model, data['text'])\n    \n    return data.rename(columns={'text':'score'})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-06T01:32:49.115556Z","iopub.execute_input":"2022-02-06T01:32:49.115811Z","iopub.status.idle":"2022-02-06T01:32:49.125661Z","shell.execute_reply.started":"2022-02-06T01:32:49.115783Z","shell.execute_reply":"2022-02-06T01:32:49.124902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments_to_score_path = \"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\nvalidation_data_path = \"../input/jigsaw-toxic-severity-rating/validation_data.csv\"\nscore_data = pd.read_csv(comments_to_score_path)\nvalid_data = pd.read_csv(validation_data_path)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-06T01:28:09.359138Z","iopub.execute_input":"2022-02-06T01:28:09.359541Z","iopub.status.idle":"2022-02-06T01:28:09.958824Z","shell.execute_reply.started":"2022-02-06T01:28:09.359505Z","shell.execute_reply":"2022-02-06T01:28:09.958084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%whos DataFrame","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:28:09.960066Z","iopub.execute_input":"2022-02-06T01:28:09.960312Z","iopub.status.idle":"2022-02-06T01:28:09.979026Z","shell.execute_reply.started":"2022-02-06T01:28:09.960281Z","shell.execute_reply":"2022-02-06T01:28:09.978274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Get & Check detoxify model","metadata":{}},{"cell_type":"code","source":"detoxify_model = Detoxify(\n    model_type='original',  \n    checkpoint='../input/detoxify-models/toxic_original-c1212f89.ckpt',\n    huggingface_config_path='../input/bert-base-uncased',\n    device='cuda'\n) \n# device='cuda' / 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:28:09.980111Z","iopub.execute_input":"2022-02-06T01:28:09.980421Z","iopub.status.idle":"2022-02-06T01:28:26.35956Z","shell.execute_reply.started":"2022-02-06T01:28:09.980386Z","shell.execute_reply":"2022-02-06T01:28:26.358784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicts_dict = detoxify_model.predict(\"I'll tell you about toxicity labels.\")\n\npd.DataFrame.from_dict(predicts_dict, orient='index', columns=['predict'])","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:28:26.361088Z","iopub.execute_input":"2022-02-06T01:28:26.361339Z","iopub.status.idle":"2022-02-06T01:28:27.253389Z","shell.execute_reply.started":"2022-02-06T01:28:26.361305Z","shell.execute_reply":"2022-02-06T01:28:27.252707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nget_score(detoxify_model, valid_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:33:22.660509Z","iopub.execute_input":"2022-02-06T01:33:22.660784Z","iopub.status.idle":"2022-02-06T01:33:25.703007Z","shell.execute_reply.started":"2022-02-06T01:33:22.660753Z","shell.execute_reply":"2022-02-06T01:33:25.702178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nCPU times: user 10min 36s, sys: 812 ms, total: 10min 37s\nWall time: 10min 38s\n\n0.6946\n```","metadata":{}},{"cell_type":"markdown","source":"# 3. Create & Save submission","metadata":{}},{"cell_type":"code","source":"%%time\nsubmission = get_submission(detoxify_model, score_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:33:36.512827Z","iopub.execute_input":"2022-02-06T01:33:36.513607Z","iopub.status.idle":"2022-02-06T01:34:59.104898Z","shell.execute_reply.started":"2022-02-06T01:33:36.513555Z","shell.execute_reply":"2022-02-06T01:34:59.104188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:29:48.908516Z","iopub.execute_input":"2022-02-06T01:29:48.910004Z","iopub.status.idle":"2022-02-06T01:29:48.943001Z","shell.execute_reply.started":"2022-02-06T01:29:48.909961Z","shell.execute_reply":"2022-02-06T01:29:48.942194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-02-06T01:34:59.108969Z","iopub.execute_input":"2022-02-06T01:34:59.110861Z","iopub.status.idle":"2022-02-06T01:34:59.127187Z","shell.execute_reply.started":"2022-02-06T01:34:59.110806Z","shell.execute_reply":"2022-02-06T01:34:59.126543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}