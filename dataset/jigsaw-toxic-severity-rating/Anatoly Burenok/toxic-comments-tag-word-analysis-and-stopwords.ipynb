{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\nI use data from two competitions:\n* [Jigsaw Rate Severity of Toxic Comments (2021-2022)](http://https://www.kaggle.com/c/jigsaw-toxic-severity-rating)\n* [Toxic Comment Classification Challenge (2018)](http://https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n\nI use data:\n* comments_to_score.csv\n* validation_data.csv\n* train.csv\n\nTo extract tags from words I use\n\n#### nltk.tag.pos_tag(tokens, tagset=None, lang='eng')\n\n```\n>>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"))\n[('John', 'NNP'), (\"'s\", 'POS'), ('big', 'JJ'), ('idea', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('all', 'PDT'), ('that', 'DT'), ('bad', 'JJ'), ('.', '.')]\n\n>>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"), tagset='universal')\n[('John', 'NOUN'), (\"'s\", 'PRT'), ('big', 'ADJ'), ('idea', 'NOUN'), ('is', 'VERB'), (\"n't\", 'ADV'), ('all', 'DET'), ('that', 'DET'), ('bad', 'ADJ'), ('.', '.')]\n```\n\nhttps://www.nltk.org/api/nltk.tag.html\n\n> This package contains classes and interfaces for part-of-speech tagging, or simply \"tagging\".  \n> A \"tag\" is a case-sensitive string that specifies some property of a token, such as its part of speech.","metadata":{}},{"cell_type":"markdown","source":"# 1. Import & Set & Load","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport calendar\nimport textwrap\nimport re\nfrom string import punctuation\nfrom bs4 import BeautifulSoup\n\nfrom nltk import word_tokenize, pos_tag\nfrom nltk.corpus import stopwords\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-25T15:33:19.736106Z","iopub.execute_input":"2022-01-25T15:33:19.736943Z","iopub.status.idle":"2022-01-25T15:33:22.343663Z","shell.execute_reply.started":"2022-01-25T15:33:19.73681Z","shell.execute_reply":"2022-01-25T15:33:22.342974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_valid_data(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\" Create valid_data. \"\"\"\n    data = data.copy()\n    \n    data['id'] = data.index.astype(str) + '_' + data['worker'].astype(str)\n  \n    less_toxic = data[['id', 'less_toxic']].rename(\n                    columns={'less_toxic': 'text'})\n\n    more_toxic = data[['id', 'more_toxic']].rename(\n                    columns={'more_toxic': 'text'})\n\n    return pd.concat([less_toxic,more_toxic], ignore_index=True)\n\n\ndef get_short_data(data: pd.DataFrame, frac_n: \"float or int\", rs: int = None) -> pd.DataFrame:\n    \"\"\" Get the selected piece of data. \"\"\"\n    result = data.copy()\n\n    if not rs:\n        rs = 1234\n\n    if frac_n > 0 and frac_n < 1:\n        result = result.sample(frac=frac_n, random_state=rs)\n    elif frac_n > 1 and frac_n < 100:\n        frac_n = frac_n / 100\n        result = result.sample(frac=frac_n, random_state=rs)\n    elif frac_n >= 100:\n        result = result.sample(n=frac_n, random_state=rs)\n    else:\n        # 0 or 1\n        raise ValueError(\"Invalid '{}' value!\".format(frac_n))\n\n    return result.sort_index()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-25T15:33:22.34509Z","iopub.execute_input":"2022-01-25T15:33:22.345429Z","iopub.status.idle":"2022-01-25T15:33:22.357581Z","shell.execute_reply.started":"2022-01-25T15:33:22.345397Z","shell.execute_reply":"2022-01-25T15:33:22.356615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"option_random = 1234567\noption_color = \"green\"\ncm = sns.light_palette(option_color, as_cmap=True)\npd.set_option(\"max_colwidth\", 90)\n\nDEBUG_MODE = False # Cut raw data to speed up debugging\n\nCUT_DATA = None\n# None   :  all data without cutting\n# < 100  :  0.1 or 10 equal 10% samples\n# >= 100 :  100|1000  equal 100|1000 samples\n\nSAVE_RESULT = True  # Saving results to csv format\nREMOVE_DOUBLE = True # Removing doubles in raw text data\nSKIP_STOP_WORDS = False  # stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:22.361141Z","iopub.execute_input":"2022-01-25T15:33:22.36149Z","iopub.status.idle":"2022-01-25T15:33:22.37945Z","shell.execute_reply.started":"2022-01-25T15:33:22.361449Z","shell.execute_reply":"2022-01-25T15:33:22.378798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_comments_to_score = \"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\npath_validation_data = \"../input/jigsaw-toxic-severity-rating/validation_data.csv\"\npath_train_data = \"./train.csv\"  # *.zip Toxic Comment Classification Challenge\n\nif not os.path.isfile(path_train_data):\n    !unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:22.38184Z","iopub.execute_input":"2022-01-25T15:33:22.382307Z","iopub.status.idle":"2022-01-25T15:33:23.406246Z","shell.execute_reply.started":"2022-01-25T15:33:22.382249Z","shell.execute_reply":"2022-01-25T15:33:23.405302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading data and bringing them to a single format\nraw_score_data = pd.read_csv(path_comments_to_score).rename(\n                                columns={'comment_id': 'id'})\nraw_train_data = pd.read_csv(path_train_data).rename(\n                                columns={'comment_text': 'text'})\n\nvalidation_data = pd.read_csv(path_validation_data)\nraw_valid_data = create_valid_data(validation_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:23.407608Z","iopub.execute_input":"2022-01-25T15:33:23.407826Z","iopub.status.idle":"2022-01-25T15:33:25.71583Z","shell.execute_reply.started":"2022-01-25T15:33:23.407799Z","shell.execute_reply":"2022-01-25T15:33:25.714662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:25.720219Z","iopub.execute_input":"2022-01-25T15:33:25.720498Z","iopub.status.idle":"2022-01-25T15:33:25.745845Z","shell.execute_reply.started":"2022-01-25T15:33:25.720463Z","shell.execute_reply":"2022-01-25T15:33:25.744546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_valid_data","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:25.74741Z","iopub.execute_input":"2022-01-25T15:33:25.74774Z","iopub.status.idle":"2022-01-25T15:33:25.76386Z","shell.execute_reply.started":"2022-01-25T15:33:25.747702Z","shell.execute_reply":"2022-01-25T15:33:25.762482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(raw_score_data.shape)\nprint(raw_valid_data.shape)\nprint(raw_train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:25.76509Z","iopub.execute_input":"2022-01-25T15:33:25.765619Z","iopub.status.idle":"2022-01-25T15:33:25.778524Z","shell.execute_reply.started":"2022-01-25T15:33:25.765559Z","shell.execute_reply":"2022-01-25T15:33:25.77751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data & Text preprocessing","metadata":{}},{"cell_type":"code","source":"custom_stop_words = ['utc', 'wikipedia', 'wiki']\n\ncustom_stop_words = custom_stop_words \\\n                + [w.lower() for w in calendar.month_name[1:]] \\\n                + [w.lower() for w in calendar.month_abbr[1:]]\n\n\ndef text_preprocessor(text: str, max_str_len: int = None) -> str:\n    \"\"\" Cutting and cleaning the text. \"\"\"\n    text = text.lower()\n    text = text.replace('\\n', ' ')\n    text = text.strip()\n\n    text = re.sub(' +', ' ', text)\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub(r'image|file|jpg|jpeg', '', text)\n    # Cut IP-address\n    text = re.sub(r'\\d{1,4}\\.\\d{1,4}\\.\\d{1,4}\\.\\d{1,4}', '', text)\n    # Cut time, period or year\n    text = re.sub(r'\\d{2,}[:|-]\\d{2,}|\\d{4}', '', text)\n    # Cut 20th or 1st\n    text = re.sub(r'\\d{1,}[th|st]', '', text)\n    # Cut money\n    text = re.sub(r'\\d{1,}[,|\\.]\\d{2,}', '', text)\n    # Cut address (9/169)\n    text = re.sub(r'\\d{1,}/\\d{1,}', '', text)\n    \n    soup = BeautifulSoup(text, 'lxml')\n    text = soup.get_text()\n      \n    words_cleaned = [w.strip(punctuation) for w in text.split() if not w.isdigit()]\n\n    temp_list = []\n    for word in words_cleaned:\n        if word.isdigit():\n            continue\n        \n        # \"word!!!!!!word!!?!?!!\"\n        word_splitted = re.split('\\?|!|:|;|\\||\\)|\\(|\\+|\"|\\.|,|#|&|_', word)\n        \n        if len(word_splitted) > 1:\n            for w in word_splitted:\n                w = w.strip(punctuation)\n                if not w.isdigit():\n                    temp_list.append(w)\n        else:\n            temp_list.append(word)\n\n    # skip word \"uhbsirtubgyihihlkjngkjbnkgjnbkf\"\n    max_word_len = 30\n    words_cleaned = [w for w in temp_list if len(w) < max_word_len]\n\n    # skip words with numbers\n    words_cleaned = [w for w in words_cleaned if not bool(re.search(r'\\d', w))]\n    words_cleaned = [w for w in words_cleaned if bool(re.search(r\"[a-zA-Z'\\-]\", w))]\n\n    # skip one letter\n    words_cleaned = [w for w in words_cleaned if len(w) > 1 or w == 'i']\n\n    text = \" \".join(words_cleaned)\n\n    if max_str_len:\n        text = textwrap.shorten(text, width=max_len, placeholder='')\n        \n    words_skipped = [w for w in text.split()\n                         if w.lower() not in custom_stop_words]\n    text = \" \".join(words_skipped)\n    \n    return text","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-25T15:33:25.779845Z","iopub.execute_input":"2022-01-25T15:33:25.780094Z","iopub.status.idle":"2022-01-25T15:33:25.803252Z","shell.execute_reply.started":"2022-01-25T15:33:25.780058Z","shell.execute_reply":"2022-01-25T15:33:25.801354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_data = raw_score_data.copy()\nvalid_data = raw_valid_data.copy()\ntrain_data = raw_train_data.copy()\n\nif DEBUG_MODE:\n    score_data = get_short_data(score_data, 300, option_random)\n    valid_data = get_short_data(valid_data, 150, option_random)\n    train_data = get_short_data(train_data, 300, option_random)\n    \nif REMOVE_DOUBLE:\n    score_data = score_data.drop_duplicates(subset=['text'])\n    valid_data = valid_data.drop_duplicates(subset=['text'])\n    train_data = train_data.drop_duplicates(subset=['text'])\n    \nprint(score_data.shape)\nprint(valid_data.shape)\nprint(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:25.807671Z","iopub.execute_input":"2022-01-25T15:33:25.807955Z","iopub.status.idle":"2022-01-25T15:33:26.174324Z","shell.execute_reply.started":"2022-01-25T15:33:25.807917Z","shell.execute_reply":"2022-01-25T15:33:26.173087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using text_preprocessor\nraw_text = \"\"\"\n28 July 2008 (UTC) 12:50 20.215.60.232 I w WHAT!!?!!!Oleg's bags name F-25 Duke1V 1,000 :-)\n'\"\\n \\n\\nGjalexei, You asked about whether there is an \"\"anti-editorializing\"\" policy here.\nThere is, and it\\'s called wikipedia:neutral point of view.  It discusses at some length...\nthe case of what we should do when writing about a subject which most of us find repugnant.\nTheeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\"'\n\"\"\"\n\ntext_preprocessor(raw_text)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:26.175679Z","iopub.execute_input":"2022-01-25T15:33:26.175924Z","iopub.status.idle":"2022-01-25T15:33:26.185979Z","shell.execute_reply.started":"2022-01-25T15:33:26.175891Z","shell.execute_reply":"2022-01-25T15:33:26.184851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nclean_score_data = score_data.copy()\nclean_valid_data = valid_data.copy()\nclean_train_data = train_data.copy()\n\nclean_score_data['text'] = clean_score_data['text'].apply(text_preprocessor)\nclean_valid_data['text'] = clean_valid_data['text'].apply(text_preprocessor)\nclean_train_data['text'] = clean_train_data['text'].apply(text_preprocessor)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:33:26.187468Z","iopub.execute_input":"2022-01-25T15:33:26.187758Z","iopub.status.idle":"2022-01-25T15:36:20.433991Z","shell.execute_reply.started":"2022-01-25T15:33:26.187721Z","shell.execute_reply":"2022-01-25T15:36:20.432821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentiles = [.05, .25, .5, .75, .85, .95]\npd.DataFrame({'score': clean_score_data['text'].str.len().describe(percentiles),\n              'valid': clean_valid_data['text'].str.len().describe(percentiles),\n              'train': clean_train_data['text'].str.len().describe(percentiles)}\n).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.435461Z","iopub.execute_input":"2022-01-25T15:36:20.435727Z","iopub.status.idle":"2022-01-25T15:36:20.604869Z","shell.execute_reply.started":"2022-01-25T15:36:20.435696Z","shell.execute_reply":"2022-01-25T15:36:20.60427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_mask = clean_score_data['text'].str.len() < 20\n\nprint(\"\\n=== SCORE DATA: Text columns before/after text preprocessing ===\")\npd.DataFrame({'id': clean_score_data.loc[check_mask, 'id'],\n              'raw_text': score_data.loc[check_mask, 'text'],\n              'clean_text': clean_score_data.loc[check_mask, 'text']}\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.605954Z","iopub.execute_input":"2022-01-25T15:36:20.606837Z","iopub.status.idle":"2022-01-25T15:36:20.635095Z","shell.execute_reply.started":"2022-01-25T15:36:20.606804Z","shell.execute_reply":"2022-01-25T15:36:20.633914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_mask = clean_valid_data['text'].str.len() < 20\n\nprint(\"\\n=== VALID DATA: Text columns before/after text preprocessing ===\")\npd.DataFrame({'id': clean_valid_data.loc[check_mask, 'id'],\n              'raw_text': valid_data.loc[check_mask, 'text'],\n              'clean_text': clean_valid_data.loc[check_mask, 'text']}\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.636667Z","iopub.execute_input":"2022-01-25T15:36:20.636966Z","iopub.status.idle":"2022-01-25T15:36:20.679659Z","shell.execute_reply.started":"2022-01-25T15:36:20.636929Z","shell.execute_reply":"2022-01-25T15:36:20.678084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_mask = clean_train_data['text'].str.len() < 20\n\nprint(\"\\n=== TRAIN DATA: Text columns before/after text preprocessing ===\")\npd.DataFrame({'id': clean_train_data.loc[check_mask, 'id'],\n              'raw_text': train_data.loc[check_mask, 'text'],\n              'clean_text': clean_train_data.loc[check_mask, 'text']}\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.681927Z","iopub.execute_input":"2022-01-25T15:36:20.682266Z","iopub.status.idle":"2022-01-25T15:36:20.856491Z","shell.execute_reply.started":"2022-01-25T15:36:20.682228Z","shell.execute_reply":"2022-01-25T15:36:20.85542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SAVE_RESULT:\n    clean_score_data.to_csv('clean_score_data.csv', index_label='index')\n    clean_valid_data.to_csv('clean_valid_data.csv', index_label='index')\n    clean_train_data.to_csv('clean_train_data.csv', index_label='index')\n    \nprint(SAVE_RESULT)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.859536Z","iopub.execute_input":"2022-01-25T15:36:20.859836Z","iopub.status.idle":"2022-01-25T15:36:20.867637Z","shell.execute_reply.started":"2022-01-25T15:36:20.859801Z","shell.execute_reply":"2022-01-25T15:36:20.866433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Word & Tag extraction","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english') \\\n                + [\"can't\", \"i'm\"]\n\n\ndef word_extractor(data: pd.Series, max_str_len: int = None, is_stopwords: bool = False) -> pd.DataFrame:\n    \"\"\" Cut, clean and extract information from text. \"\"\"\n    words_and_tags = []\n    \n    for string in data.values:\n        if max_str_len:\n            string = textwrap.shorten(string, width=max_str_len, placeholder='')\n            \n        splitted_text = string.split()\n\n        if is_stopwords:\n            splitted_text = [w for w in splitted_text if w not in stop_words]\n          \n        words_and_tags.extend(pos_tag(splitted_text, tagset='universal'))\n        \n    result = pd.DataFrame.from_records(words_and_tags, columns=['word', 'tag'])\n\n    result['tag'] = result['tag'].astype(\"category\")\n    \n    return result","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-25T15:36:20.869392Z","iopub.execute_input":"2022-01-25T15:36:20.869684Z","iopub.status.idle":"2022-01-25T15:36:20.887686Z","shell.execute_reply.started":"2022-01-25T15:36:20.869648Z","shell.execute_reply":"2022-01-25T15:36:20.886606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not DEBUG_MODE and CUT_DATA:\n    clean_score_data = get_short_data(clean_score_data, CUT_DATA, option_random)\n    clean_valid_data = get_short_data(clean_valid_data, CUT_DATA, option_random)\n    clean_train_data = get_short_data(clean_train_data, CUT_DATA, option_random)\n    \n    print(clean_score_data.shape)\n    print(clean_valid_data.shape)\n    print(clean_train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.889255Z","iopub.execute_input":"2022-01-25T15:36:20.889803Z","iopub.status.idle":"2022-01-25T15:36:20.937433Z","shell.execute_reply.started":"2022-01-25T15:36:20.889757Z","shell.execute_reply":"2022-01-25T15:36:20.936643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_text = \"I'm busy You asked about whether there is an anti-editorializing policy\"\n\n# Using nltk.tag.pos_tag(tokens, tagset=None, lang='eng')\n# tagset='universal'  < None, universal, wsj, brown\ntext_tagged = pos_tag(\n    word_tokenize(\n        textwrap.shorten(\n            clean_text, width=70, placeholder=''\n        )\n    ),\n    tagset='universal'\n)\n\nprint(*text_tagged, \" ...\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:20.938955Z","iopub.execute_input":"2022-01-25T15:36:20.939408Z","iopub.status.idle":"2022-01-25T15:36:21.141665Z","shell.execute_reply.started":"2022-01-25T15:36:20.939364Z","shell.execute_reply":"2022-01-25T15:36:21.140258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmax_str_len = 500\nwords_and_tags = pd.concat(\n    [word_extractor(clean_score_data['text'], max_str_len, SKIP_STOP_WORDS),\n     word_extractor(clean_valid_data['text'], max_str_len, SKIP_STOP_WORDS),\n     word_extractor(clean_train_data['text'], max_str_len, SKIP_STOP_WORDS)\n    ], keys=['score', 'valid', 'train'],\n       names=['data', 'index']\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:36:21.143889Z","iopub.execute_input":"2022-01-25T15:36:21.144244Z","iopub.status.idle":"2022-01-25T15:37:16.958132Z","shell.execute_reply.started":"2022-01-25T15:36:21.144194Z","shell.execute_reply":"2022-01-25T15:37:16.956928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_and_tags['tag'] = words_and_tags['tag'].astype(\"category\")\nwords_and_tags = words_and_tags.reset_index(level='data').reset_index(drop=True)\nwords_and_tags['data'] = words_and_tags['data'].astype(\"category\")\n\nwords_and_tags.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:16.959581Z","iopub.execute_input":"2022-01-25T15:37:16.960496Z","iopub.status.idle":"2022-01-25T15:37:17.54292Z","shell.execute_reply.started":"2022-01-25T15:37:16.960454Z","shell.execute_reply":"2022-01-25T15:37:17.5413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_and_tags","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:17.544561Z","iopub.execute_input":"2022-01-25T15:37:17.544845Z","iopub.status.idle":"2022-01-25T15:37:17.559765Z","shell.execute_reply.started":"2022-01-25T15:37:17.544814Z","shell.execute_reply":"2022-01-25T15:37:17.558943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SAVE_RESULT:\n    words_and_tags.to_csv('words_and_tags.csv', index=False)\n    \nprint(SAVE_RESULT)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:17.560875Z","iopub.execute_input":"2022-01-25T15:37:17.561079Z","iopub.status.idle":"2022-01-25T15:37:17.572414Z","shell.execute_reply.started":"2022-01-25T15:37:17.561053Z","shell.execute_reply":"2022-01-25T15:37:17.571914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Tag & Word analysis","metadata":{}},{"cell_type":"code","source":"def tags_info(data: pd.DataFrame, is_norm: bool = False, is_all: bool = False, is_style: bool = True) -> pd.DataFrame:\n    \"\"\" Tabular information about tags. \"\"\"\n    data_col = \"data\"\n    tags_col = \"tag\"\n    \n    if is_norm:\n        is_norm = 'columns'\n    \n    result = pd.crosstab(data[tags_col], data[data_col],\n                         normalize=is_norm, margins=is_all)\n\n    if is_norm:\n        result = result.mul(100).round(2)\n    \n    if is_all and 'All' in result.index:\n        result = result.drop(['All'], axis=0)\n    \n    if 'All' in result.columns:\n        result = result.sort_values(by='All', ascending=False)\n    \n    if is_style and not is_norm and 'All' in result.columns:\n        result = result.style.bar(subset=['All'], color=option_color)\n\n    if is_style and not is_norm and 'All' not in result.columns:\n        result = result.style.background_gradient(cmap=cm)\n\n    return result\n\n\ndef tags_plot(data: pd.DataFrame, figsize: tuple = (12, 6)) -> plt.figure:\n    \"\"\" Visualization of information about tags. \"\"\"\n    plot_data = data\n    col_name = \"data\"\n    hue_name = \"tag\"\n    \n    hue_order = plot_data[hue_name].value_counts(ascending=False) \\\n                               .index.to_list()\n    \n    plt.figure(figsize=figsize)\n    sns.histplot(y=col_name, hue=hue_name, data=plot_data,\n                 hue_order=hue_order,\n                 multiple='fill', shrink=.75)\n    plt.title(\"Frequency of using tags in datasets\")\n    plt.ylabel(\"\")\n    plt.xlabel(\"\")\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-25T15:37:17.573695Z","iopub.execute_input":"2022-01-25T15:37:17.574027Z","iopub.status.idle":"2022-01-25T15:37:17.588817Z","shell.execute_reply.started":"2022-01-25T15:37:17.574Z","shell.execute_reply":"2022-01-25T15:37:17.588004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1. Tags info","metadata":{}},{"cell_type":"code","source":"tags_info(words_and_tags)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:17.590132Z","iopub.execute_input":"2022-01-25T15:37:17.590483Z","iopub.status.idle":"2022-01-25T15:37:17.775635Z","shell.execute_reply.started":"2022-01-25T15:37:17.590455Z","shell.execute_reply":"2022-01-25T15:37:17.774463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag_types = tags_info(words_and_tags).index.to_list()\nmax_num_words = 20\n\nfor x_tag in tag_types:\n    x_data = words_and_tags.loc[words_and_tags.tag == x_tag, 'word']\n    print()\n    print(\"Tag:\", x_tag)\n    print(\"Nunique:\", x_data.nunique())\n    print(\"Sample words:\", *x_data.values[:max_num_words])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:17.777882Z","iopub.execute_input":"2022-01-25T15:37:17.77881Z","iopub.status.idle":"2022-01-25T15:37:18.429102Z","shell.execute_reply.started":"2022-01-25T15:37:17.778756Z","shell.execute_reply":"2022-01-25T15:37:18.426984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The number of mentions of the tag\ntags_info(words_and_tags, is_all=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:38:30.584935Z","iopub.execute_input":"2022-01-25T15:38:30.585222Z","iopub.status.idle":"2022-01-25T15:38:30.754297Z","shell.execute_reply.started":"2022-01-25T15:38:30.58519Z","shell.execute_reply":"2022-01-25T15:38:30.753096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Relative (each data) number of mentions of the tag\ntags_info(words_and_tags, is_norm=True, is_all=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:18.631238Z","iopub.execute_input":"2022-01-25T15:37:18.631474Z","iopub.status.idle":"2022-01-25T15:37:18.833859Z","shell.execute_reply.started":"2022-01-25T15:37:18.631443Z","shell.execute_reply":"2022-01-25T15:37:18.83265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags_plot(words_and_tags)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:18.838687Z","iopub.execute_input":"2022-01-25T15:37:18.839874Z","iopub.status.idle":"2022-01-25T15:37:19.873909Z","shell.execute_reply.started":"2022-01-25T15:37:18.839715Z","shell.execute_reply":"2022-01-25T15:37:19.872521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Words info","metadata":{}},{"cell_type":"code","source":"def popular_words(data: pd.DataFrame, n: int = 10, is_norm: bool = False) -> pd.DataFrame:\n    \"\"\" Tabular information about words. \"\"\"\n    data_col = \"data\"\n    word_col = \"word\"\n    \n    if is_norm:\n        is_norm = 'columns'\n    \n    result = pd.crosstab(data[word_col], data[data_col],\n                         normalize=is_norm, margins=True)\n\n    if is_norm:\n        result = result.mul(100).round(2)\n    \n    if 'All' in result.index:\n        result = result.drop(['All'], axis=0)\n    \n    return result.nlargest(n, 'All')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-25T15:37:19.875343Z","iopub.execute_input":"2022-01-25T15:37:19.875648Z","iopub.status.idle":"2022-01-25T15:37:19.885776Z","shell.execute_reply.started":"2022-01-25T15:37:19.875612Z","shell.execute_reply":"2022-01-25T15:37:19.884486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"popular_words(words_and_tags, 15)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:38:37.904556Z","iopub.execute_input":"2022-01-25T15:38:37.90488Z","iopub.status.idle":"2022-01-25T15:38:40.473187Z","shell.execute_reply.started":"2022-01-25T15:38:37.904843Z","shell.execute_reply":"2022-01-25T15:38:40.472252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"popular_words(words_and_tags, 10, is_norm=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:22.690879Z","iopub.execute_input":"2022-01-25T15:37:22.691099Z","iopub.status.idle":"2022-01-25T15:37:25.27328Z","shell.execute_reply.started":"2022-01-25T15:37:22.691069Z","shell.execute_reply":"2022-01-25T15:37:25.27258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x_tag in tag_types:\n    if x_tag in [\".\", \"X\"]:\n        continue\n    \n    x_data = words_and_tags.loc[words_and_tags.tag == x_tag]\n    print(f\"Tag: {x_tag}\")\n    print(\"Frequency of mentioning the words (TOP-10) in percent\")\n    display(popular_words(x_data, is_norm=True))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:25.275158Z","iopub.execute_input":"2022-01-25T15:37:25.275533Z","iopub.status.idle":"2022-01-25T15:37:29.627791Z","shell.execute_reply.started":"2022-01-25T15:37:25.275496Z","shell.execute_reply":"2022-01-25T15:37:29.626593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Stop words","metadata":{}},{"cell_type":"code","source":"# text_preprocessor()\nprint(len(custom_stop_words))\nprint(*custom_stop_words)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:29.629877Z","iopub.execute_input":"2022-01-25T15:37:29.630216Z","iopub.status.idle":"2022-01-25T15:37:29.639997Z","shell.execute_reply.started":"2022-01-25T15:37:29.630167Z","shell.execute_reply":"2022-01-25T15:37:29.638842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word_extractor()\nprint(len(stop_words))\nprint(*stop_words)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T15:37:29.641311Z","iopub.execute_input":"2022-01-25T15:37:29.641545Z","iopub.status.idle":"2022-01-25T15:37:29.675833Z","shell.execute_reply.started":"2022-01-25T15:37:29.641513Z","shell.execute_reply":"2022-01-25T15:37:29.674437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}