{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Begin","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\n\nall_lines = []\n\nVERSION = 0\ntry:\n    with open('../input/jigsaw-toxic-severity-lightgbm-training/version.info', 'r') as f:\n        all_lines = f.readlines()\n    print(\"Version file read successfully.\")\nexcept:\n    pass\n\nfinally:\n    print(\"Updating version file...\")\n    with open('version.info', 'w') as f:\n        if len(all_lines) != 0:\n            VERSION = int(re.sub(r'\\D', '', '\\n'.join(all_lines))) + 1\n            \n        f.writelines(f\"Version: {VERSION}\")\n        print(\"current version:\", VERSION)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T06:34:46.412762Z","iopub.execute_input":"2021-11-20T06:34:46.413607Z","iopub.status.idle":"2021-11-20T06:34:46.430644Z","shell.execute_reply.started":"2021-11-20T06:34:46.413536Z","shell.execute_reply":"2021-11-20T06:34:46.429669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will be using multiple dataset from previous Jigsaw competitions as complementary train data.","metadata":{}},{"cell_type":"code","source":"train_1 = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntrain_1","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:34:46.432795Z","iopub.execute_input":"2021-11-20T06:34:46.433457Z","iopub.status.idle":"2021-11-20T06:34:46.689666Z","shell.execute_reply.started":"2021-11-20T06:34:46.433418Z","shell.execute_reply":"2021-11-20T06:34:46.688856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the main train data, we will simple associate the column `less_toxic` with the score of `0` and the column `more_toxic` with the score of `1`. There are some text that are duplicates so we will filter out the uniques for each level of toxicity.","metadata":{}},{"cell_type":"code","source":"train_1_cleaned = pd.concat(\n    [pd.DataFrame({\"text\":train_1.less_toxic.unique(), \"score\":np.zeros(train_1.less_toxic.nunique())}),\n     pd.DataFrame({\"text\":train_1.more_toxic.unique(), \"score\":np.ones(train_1.more_toxic.nunique())})],\n    axis=0).reset_index(drop=True)\ntrain_1_cleaned","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:34:46.690755Z","iopub.execute_input":"2021-11-20T06:34:46.690969Z","iopub.status.idle":"2021-11-20T06:34:46.818125Z","shell.execute_reply.started":"2021-11-20T06:34:46.690943Z","shell.execute_reply":"2021-11-20T06:34:46.817271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2 = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")\ntrain_2","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:34:46.81979Z","iopub.execute_input":"2021-11-20T06:34:46.820036Z","iopub.status.idle":"2021-11-20T06:35:03.109588Z","shell.execute_reply.started":"2021-11-20T06:34:46.820001Z","shell.execute_reply":"2021-11-20T06:35:03.10894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the data from `jigsaw-unintended-bias-in-toxicity-classification` we will only be using the `comment_text` and the `target` columns. We will adjust the score on a 50% base if, and only if, the score is not near zero.","metadata":{}},{"cell_type":"code","source":"train_2_cleaned = pd.DataFrame({'text':train_2.comment_text, 'score':train_2.target})\ntrain_2_cleaned['score'] = train_2_cleaned['score'].apply(lambda x: 0 if x <= 0.05 else 0.5+(x/2))\ntrain_2_cleaned","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:03.110648Z","iopub.execute_input":"2021-11-20T06:35:03.110975Z","iopub.status.idle":"2021-11-20T06:35:03.834943Z","shell.execute_reply.started":"2021-11-20T06:35:03.110947Z","shell.execute_reply":"2021-11-20T06:35:03.834284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_3 = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\ntrain_3","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:03.835968Z","iopub.execute_input":"2021-11-20T06:35:03.836312Z","iopub.status.idle":"2021-11-20T06:35:05.354979Z","shell.execute_reply.started":"2021-11-20T06:35:03.836284Z","shell.execute_reply":"2021-11-20T06:35:05.354098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the data from `jigsaw-toxic-comment-classification-challenge`, we will be scoring them based on the average of the five columns present as targets. Similar to `train_2` we will be using base 50% once more.","metadata":{}},{"cell_type":"code","source":"score = np.mean(train_3[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']], axis=1)\ntrain_3_cleaned = pd.DataFrame({'text':train_3.comment_text, 'score':score})\ntrain_3_cleaned['score'] = train_3_cleaned['score'].apply(lambda x: 0 if x <= 0.05 else 0.5+(x/2))\ntrain_3_cleaned","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:05.356435Z","iopub.execute_input":"2021-11-20T06:35:05.356775Z","iopub.status.idle":"2021-11-20T06:35:05.438657Z","shell.execute_reply.started":"2021-11-20T06:35:05.356731Z","shell.execute_reply":"2021-11-20T06:35:05.437749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will merge all train data as one.","metadata":{}},{"cell_type":"code","source":"train_df = pd.concat(\n    [train_1_cleaned, train_2_cleaned, train_3_cleaned],\n    axis=0\n).reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:05.439754Z","iopub.execute_input":"2021-11-20T06:35:05.440049Z","iopub.status.idle":"2021-11-20T06:35:05.59194Z","shell.execute_reply.started":"2021-11-20T06:35:05.440019Z","shell.execute_reply":"2021-11-20T06:35:05.591206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check one random comment for each unique score (based from a rounded cutoff or 2 decimal places) printing the first 100 raw chars of the corresponding text.","metadata":{}},{"cell_type":"code","source":"printed = []\nfor i in sorted(train_df.score.unique()):\n    n = np.round(i, 2) \n    if n in printed:\n        continue\n    printed.append(n)\n    print(f\"{len(printed):<3}: {i:.5f}\\t{repr(np.random.choice(train_df[train_df.score==i]['text']))[:100]}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:05.593871Z","iopub.execute_input":"2021-11-20T06:35:05.594083Z","iopub.status.idle":"2021-11-20T06:35:05.874002Z","shell.execute_reply.started":"2021-11-20T06:35:05.594057Z","shell.execute_reply":"2021-11-20T06:35:05.873075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\nNow that we have a train data, let's focus on preparing the data for our training. The first step is to clean the text input string.","metadata":{}},{"cell_type":"code","source":"train_df[train_df.score == 0.].shape[0]/train_df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:05.874973Z","iopub.execute_input":"2021-11-20T06:35:05.875214Z","iopub.status.idle":"2021-11-20T06:35:05.980296Z","shell.execute_reply.started":"2021-11-20T06:35:05.875184Z","shell.execute_reply":"2021-11-20T06:35:05.979285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's over 70% of the data that is not toxic (`score` is `0.0`) so we need to reduce their numbers.","metadata":{}},{"cell_type":"code","source":"train_df_sel = train_df[train_df.score != 0.]\ntrain_df_zer = train_df[train_df.score == 0.].reset_index(drop=True)\ntrain_df_zer = train_df_zer[:train_df_zer.shape[0]//4]\ntrain_df = pd.concat([train_df_zer, train_df_sel], axis=0).reset_index(drop=True)\nprint(train_df[train_df.score == 0.].shape[0]/train_df.shape[0])\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:05.981788Z","iopub.execute_input":"2021-11-20T06:35:05.982233Z","iopub.status.idle":"2021-11-20T06:35:06.333073Z","shell.execute_reply.started":"2021-11-20T06:35:05.982185Z","shell.execute_reply":"2021-11-20T06:35:06.33217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will vectorize our train data.","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas()\n\nimport re\n\nW_to_I = {'':0}\nadd_space_before_punc = lambda x: re.sub(r'(\\W|_)', r' \\1 ', x)\nremove_whitespaces = lambda x: re.sub(r'\\s+', ' ', x)\nremove_multiples = lambda x: re.sub(r'(.)\\1{2,}', r'\\1\\1', x) #Remove repeated char multiple times\n\ntrain_df['clean_text'] = train_df.text.progress_apply(\n    lambda x: remove_whitespaces(remove_multiples(add_space_before_punc(x)))\n)\n\n# Average len is 44 with min of 1 word and max of 4948.\ntrain_df['len'] = train_df.clean_text.progress_apply(lambda x: len(x.split()))\n\ndef convert_to_int(word):\n    c = W_to_I.get(word, -1)\n    if c==-1:\n        c = len(W_to_I)\n        W_to_I[word] = c\n    return c\n\ndef convert_text_to_arr(text, max_len=60):\n    words = text.split()[:max_len]\n    n = len(words)\n    if n < max_len:\n        words += ['' for _ in range(max_len - n)]\n    words = [convert_to_int(word) for word in words]\n    return np.array(words)\n\nX = train_df.clean_text.progress_apply(lambda x: convert_text_to_arr(x))\nX = np.concatenate([i.reshape((1, -1)) for i in X.values], axis=0)\ny = train_df['score']\nstratify = ['toxic' if y_v>=0.5 else 'not' for y_v in y]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:35:06.334469Z","iopub.execute_input":"2021-11-20T06:35:06.334723Z","iopub.status.idle":"2021-11-20T06:38:43.579601Z","shell.execute_reply.started":"2021-11-20T06:35:06.334694Z","shell.execute_reply":"2021-11-20T06:38:43.578648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor as method\nfrom sklearn.model_selection import train_test_split as tts\n\ncurrent_seed = np.random.randint(7, 1e6)\nprint(\"Using seed:\", current_seed)\n\nprint(\"Splitting train and validation set...\")\ntrain_x, valid_x, train_y, valid_y = tts(X, y, test_size=0.1,\n                                         shuffle=True, random_state=current_seed,\n                                        stratify=stratify)\nprint(\"Train shapes:\", train_x.shape, train_y.shape,\n      \"\\nTest shapes:\", valid_x.shape, valid_y.shape)\n\ndepth = 1000\nmodel = method(\n    device='cpu',\n    #gpu_platform_id=0,\n    #gpu_device_id=0,\n    boosting_type='goss',\n    objective='mse',\n    is_unbalance=True,\n    n_estimators=depth**2,\n    learning_rate=0.05/(VERSION+1),\n    max_bin=64,\n    #subsample_freq=10,\n    #subsample=0.75,\n    #max_depth=2,\n    #num_leaves=5,\n    reg_alpha=1.5,\n    reg_lambda=5.75,\n    random_state=current_seed,\n    #force_col_wise=True,\n    silent=True,\n    n_jobs=64,\n)\nprint(\"Model fitting...\")\nmodel.fit(train_x, train_y,\n          eval_set=[[train_x, train_y], [valid_x, valid_y]],\n          early_stopping_rounds=depth//5,\n          verbose=depth//50,\n          init_model=\"../input/jigsaw-toxic-severity-lightgbm-training/model_booster_weights.txt\",\n         )\nmodel.booster_.save_model(\"model_booster_weights.txt\", num_iteration=model.best_iteration_)\nprint(\"Training end.\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:38:43.612253Z","iopub.execute_input":"2021-11-20T06:38:43.612548Z","iopub.status.idle":"2021-11-20T06:41:59.767458Z","shell.execute_reply.started":"2021-11-20T06:38:43.612521Z","shell.execute_reply":"2021-11-20T06:41:59.766758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\npreds =model.predict(valid_x, num_iteration=model.best_iteration_)\n\nplt.title(\"Prediction and True value difference with abs(y - pred):\")\nplt.ylim([0, 1])\nplt.plot(range(len(preds)), np.abs(np.where(valid_y=='toxic', 1, 0) - preds), c='#ff0000', alpha=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:41:59.769876Z","iopub.execute_input":"2021-11-20T06:41:59.770212Z","iopub.status.idle":"2021-11-20T06:42:06.402205Z","shell.execute_reply.started":"2021-11-20T06:41:59.770168Z","shell.execute_reply":"2021-11-20T06:42:06.40134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"from scipy.stats import rankdata\n\ntest = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntest['clean_text'] = test.text.progress_apply(\n    lambda x: remove_whitespaces(remove_multiples(add_space_before_punc(x)))\n)\ntest_X = test.clean_text.progress_apply(lambda x: convert_text_to_arr(x))\ntest_X = np.concatenate([i.reshape((1, -1)) for i in test_X.values], axis=0)\n\npreds = model.predict(test_X, num_iteration=model.best_iteration_)\ndisplay(preds, preds.min(), preds.max())\nsub = pd.DataFrame({'comment_id':test.comment_id.values, 'score':rankdata(preds, method='ordinal')})\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:42:06.403513Z","iopub.execute_input":"2021-11-20T06:42:06.40383Z","iopub.status.idle":"2021-11-20T06:42:09.299435Z","shell.execute_reply.started":"2021-11-20T06:42:06.40379Z","shell.execute_reply":"2021-11-20T06:42:09.298467Z"},"trusted":true},"execution_count":null,"outputs":[]}]}