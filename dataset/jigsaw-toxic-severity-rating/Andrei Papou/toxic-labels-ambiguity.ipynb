{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport typing as t\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T16:15:08.264786Z","iopub.execute_input":"2022-01-10T16:15:08.265407Z","iopub.status.idle":"2022-01-10T16:15:08.347959Z","shell.execute_reply.started":"2022-01-10T16:15:08.265351Z","shell.execute_reply":"2022-01-10T16:15:08.347019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:15:08.68672Z","iopub.execute_input":"2022-01-10T16:15:08.68708Z","iopub.status.idle":"2022-01-10T16:15:08.692795Z","shell.execute_reply.started":"2022-01-10T16:15:08.687044Z","shell.execute_reply":"2022-01-10T16:15:08.691498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2017_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv')\nvalid_df = pd.read_csv('/kaggle/input/jt-combined/valid.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:17:50.21026Z","iopub.execute_input":"2022-01-10T16:17:50.211288Z","iopub.status.idle":"2022-01-10T16:17:51.90789Z","shell.execute_reply.started":"2022-01-10T16:17:50.211195Z","shell.execute_reply":"2022-01-10T16:17:51.906699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLS_LIST = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:18:13.220052Z","iopub.execute_input":"2022-01-10T16:18:13.220475Z","iopub.status.idle":"2022-01-10T16:18:13.225786Z","shell.execute_reply.started":"2022-01-10T16:18:13.220431Z","shell.execute_reply":"2022-01-10T16:18:13.224839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _build_readable_label(row: t.Dict[str, int]) -> str:\n    return ' '.join([cls for cls in CLS_LIST if row[cls]])\n\n\ndef _build_bitmap_label(row: t.Dict[str, int]) -> str:\n    return ' '.join([str(row[cls]) for cls in CLS_LIST])\n\n\ndef assign_label_to_comment(df: pd.DataFrame, labels_df: pd.DataFrame) -> pd.DataFrame:\n    result_row_list = []\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        less_toxic_comment_text = str(row['less_toxic'])\n        more_toxic_comment_text = str(row['more_toxic'])\n        less_toxic_label_row_candidate_df = labels_df[labels_df['comment_text'] == less_toxic_comment_text]\n        if len(less_toxic_label_row_candidate_df):\n            less_toxic_readable_label = _build_readable_label(less_toxic_label_row_candidate_df.iloc[0])\n            less_toxic_bitmap_label = _build_bitmap_label(less_toxic_label_row_candidate_df.iloc[0])\n        else:\n            less_toxic_readable_label = ''\n            less_toxic_bitmap_label = ''\n        more_toxic_label_row_candidate_df = labels_df[labels_df['comment_text'] == more_toxic_comment_text]\n        if len(more_toxic_label_row_candidate_df):\n            more_toxic_readable_label = _build_readable_label(more_toxic_label_row_candidate_df.iloc[0])\n            more_toxic_bitmap_label = _build_bitmap_label(more_toxic_label_row_candidate_df.iloc[0])\n        else:\n            more_toxic_readable_label = ''\n            more_toxic_bitmap_label = ''\n        result_row_list.append({\n            'less_toxic': less_toxic_comment_text,\n            'less_toxic_readable_label': less_toxic_readable_label,\n            'less_toxic_bitmap_label': less_toxic_bitmap_label,\n            'more_toxic': more_toxic_comment_text,\n            'more_toxic_readable_label': more_toxic_readable_label,\n            'more_toxic_bitmap_label': more_toxic_bitmap_label,\n        })\n    return pd.DataFrame(result_row_list)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:18:38.057959Z","iopub.execute_input":"2022-01-10T16:18:38.058389Z","iopub.status.idle":"2022-01-10T16:18:38.07124Z","shell.execute_reply.started":"2022-01-10T16:18:38.058346Z","shell.execute_reply":"2022-01-10T16:18:38.070502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_with_labels_df = assign_label_to_comment(df=valid_df, labels_df=train_2017_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:19:19.435474Z","iopub.execute_input":"2022-01-10T16:19:19.435817Z","iopub.status.idle":"2022-01-10T16:29:56.464165Z","shell.execute_reply.started":"2022-01-10T16:19:19.435785Z","shell.execute_reply":"2022-01-10T16:29:56.463171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"analyze_cls_label_df = valid_with_labels_df[(valid_with_labels_df['less_toxic_readable_label'] != '') & (valid_with_labels_df['more_toxic_readable_label'] != '')]","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:29:56.4664Z","iopub.execute_input":"2022-01-10T16:29:56.466663Z","iopub.status.idle":"2022-01-10T16:29:56.4773Z","shell.execute_reply.started":"2022-01-10T16:29:56.466632Z","shell.execute_reply":"2022-01-10T16:29:56.476496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Are there any samples where `less_toxic` and `more_toxic` comments have the same labels?","metadata":{}},{"cell_type":"code","source":"len(analyze_cls_label_df[analyze_cls_label_df['less_toxic_bitmap_label'] == analyze_cls_label_df['more_toxic_bitmap_label']]) / len(analyze_cls_label_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:29:56.478389Z","iopub.execute_input":"2022-01-10T16:29:56.47859Z","iopub.status.idle":"2022-01-10T16:29:56.49234Z","shell.execute_reply.started":"2022-01-10T16:29:56.478559Z","shell.execute_reply":"2022-01-10T16:29:56.491445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's consider a pair of `(less_toxic_bitmap_label, more_toxic_bitmap_label)` ambiguous if there is at least 1 pair of comments in the validation set where a comment with `less_toxic_bitmap_label` is ranked as more toxic than a comment with `more_toxic_bitmap_label`. How many ambigous samples do we have?","metadata":{}},{"cell_type":"code","source":"def get_amb_label_pair_set(df: pd.DataFrame) -> t.Set[t.Tuple[str, str]]:\n    amb_label_pair_set = set()\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        less_toxic_bitmap_label, more_toxic_bitmap_label = str(row['less_toxic_bitmap_label']), str(row['more_toxic_bitmap_label'])\n        if less_toxic_bitmap_label == more_toxic_bitmap_label:\n            continue\n        if len(df[(df['less_toxic_bitmap_label'] == more_toxic_bitmap_label) & (df['more_toxic_bitmap_label'] == less_toxic_bitmap_label)]):\n            amb_label_pair_set.add((\n                min(less_toxic_bitmap_label, more_toxic_bitmap_label),\n                max(less_toxic_bitmap_label, more_toxic_bitmap_label),\n            ))\n    return amb_label_pair_set\n\n\ndef count_rows_with_bitmap_labels(df: pd.DataFrame, bitmap_label_set: t.Set[t.Tuple[str, str]]) -> int:\n    n = 0\n    for bitmap_left, bitmap_right in tqdm(bitmap_label_set):\n        n += len(df[\n            ((df['less_toxic_bitmap_label'] == bitmap_left) & (df['more_toxic_bitmap_label'] == bitmap_right)) |\n            ((df['less_toxic_bitmap_label'] == bitmap_right) & (df['more_toxic_bitmap_label'] == bitmap_left))\n        ])\n    return n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:34:17.860903Z","iopub.execute_input":"2022-01-10T16:34:17.861309Z","iopub.status.idle":"2022-01-10T16:34:17.872177Z","shell.execute_reply.started":"2022-01-10T16:34:17.861247Z","shell.execute_reply":"2022-01-10T16:34:17.87132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amb_label_pair_set = get_amb_label_pair_set(analyze_cls_label_df)\ncount_rows_with_bitmap_labels(analyze_cls_label_df, amb_label_pair_set) / len(analyze_cls_label_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:34:20.492347Z","iopub.execute_input":"2022-01-10T16:34:20.492685Z","iopub.status.idle":"2022-01-10T16:34:21.039294Z","shell.execute_reply.started":"2022-01-10T16:34:20.492635Z","shell.execute_reply":"2022-01-10T16:34:21.038681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just to sum up, for the 19.78% of validation samples the toxicity labels from the https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge are identical. Moreover, for the 63% of the validation samples the labels are ambigous. So there is a question of how useful those toxicity labels are for the ranking task.","metadata":{}}]}