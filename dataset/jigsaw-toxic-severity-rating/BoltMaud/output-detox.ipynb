{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget \"https://github.com/unitaryai/detoxify/releases/download/v0.1-alpha/toxic_original-c1212f89.ckpt?raw=true\"\nimport os\nos.rename(\"toxic_original-c1212f89.ckpt?raw=true\",\"toxic_original-c1212f89.ckpt\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T10:03:47.327059Z","iopub.execute_input":"2021-11-26T10:03:47.328016Z","iopub.status.idle":"2021-11-26T10:03:55.258372Z","shell.execute_reply.started":"2021-11-26T10:03:47.32796Z","shell.execute_reply":"2021-11-26T10:03:55.257543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport transformers\n\nMODEL_URLS = {\n    \"original\": \"./toxic_original-c1212f89.ckpt\"\n}\n\nPRETRAINED_MODEL = None\n\n\ndef get_model_and_tokenizer(\n    model_type, model_name, tokenizer_name, num_classes, state_dict\n):\n    model_class = getattr(transformers, model_name)\n    model = model_class.from_pretrained(\n        pretrained_model_name_or_path=None,\n        config=model_type,\n        num_labels=num_classes,\n        state_dict=state_dict,\n    )\n    tokenizer = getattr(transformers, tokenizer_name).from_pretrained(model_type)\n    \n    return model, tokenizer\n\n\ndef load_checkpoint(model_type=\"original\", checkpoint=None, device='cpu'):\n    if checkpoint is None:\n        checkpoint_path = MODEL_URLS[model_type]\n        loaded = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=device)\n    else:\n        loaded = torch.load(checkpoint)\n        if \"config\" not in loaded or \"state_dict\" not in loaded:\n            raise ValueError(\n                \"Checkpoint needs to contain the config it was trained \\\n                    with as well as the state dict\"\n            )\n    class_names = loaded[\"config\"][\"dataset\"][\"args\"][\"classes\"]\n    # standardise class names between models\n    change_names = {\n        \"toxic\": \"toxicity\",\n        \"identity_hate\": \"identity_attack\",\n        \"severe_toxic\": \"severe_toxicity\",\n    }\n    class_names = [change_names.get(cl, cl) for cl in class_names]\n    model, tokenizer = get_model_and_tokenizer(\n        **loaded[\"config\"][\"arch\"][\"args\"], state_dict=loaded[\"state_dict\"]\n    )\n\n    return model, tokenizer, class_names\n\n\ndef load_model(model_type, checkpoint=None, device='cpu'):\n    if checkpoint is None:\n        model, _, _ = load_checkpoint(model_type=model_type, device=device)\n    else:\n        model, _, _ = load_checkpoint(checkpoint=checkpoint,device=device)\n    return model\n\n\nclass Detoxify:\n    def __init__(self, model_type=\"original\", checkpoint=PRETRAINED_MODEL, device=\"cpu\"):\n        super(Detoxify, self).__init__()\n        self.model, self.tokenizer, self.class_names = load_checkpoint(\n            model_type=model_type, checkpoint=checkpoint, device=device\n        )\n        self.device = device\n        self.model.to(self.device)\n\n\n    @torch.no_grad()\n    def predict(self, text):\n        self.model.eval()\n        inputs = self.tokenizer(\n            text, return_tensors=\"pt\", truncation=True, padding=True\n        ).to(self.model.device)\n        out = self.model(**inputs)[0]\n        scores = torch.sigmoid(out).cpu().detach().numpy()\n        results = {}\n        for i, cla in enumerate(self.class_names):\n            results[cla] = (\n                scores[0][i]\n                if isinstance(text, str)\n                else [scores[ex_i][i].tolist() for ex_i in range(len(scores))]\n            )\n        return results","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:08:08.903339Z","iopub.execute_input":"2021-11-26T10:08:08.904468Z","iopub.status.idle":"2021-11-26T10:08:10.640778Z","shell.execute_reply.started":"2021-11-26T10:08:08.904393Z","shell.execute_reply":"2021-11-26T10:08:10.639787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, tokenizer, classes = load_checkpoint(checkpoint = \"./toxic_original-c1212f89.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:08:12.372378Z","iopub.execute_input":"2021-11-26T10:08:12.373361Z","iopub.status.idle":"2021-11-26T10:08:20.790282Z","shell.execute_reply.started":"2021-11-26T10:08:12.373321Z","shell.execute_reply":"2021-11-26T10:08:20.789357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"./tokenizer/\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:08:22.402716Z","iopub.execute_input":"2021-11-26T10:08:22.403043Z","iopub.status.idle":"2021-11-26T10:08:22.43722Z","shell.execute_reply.started":"2021-11-26T10:08:22.403008Z","shell.execute_reply":"2021-11-26T10:08:22.436591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"./model/\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:08:26.098341Z","iopub.execute_input":"2021-11-26T10:08:26.098993Z","iopub.status.idle":"2021-11-26T10:08:26.907499Z","shell.execute_reply.started":"2021-11-26T10:08:26.098954Z","shell.execute_reply":"2021-11-26T10:08:26.906585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:08:50.56482Z","iopub.execute_input":"2021-11-26T10:08:50.565124Z","iopub.status.idle":"2021-11-26T10:08:50.572587Z","shell.execute_reply.started":"2021-11-26T10:08:50.565095Z","shell.execute_reply":"2021-11-26T10:08:50.571595Z"},"trusted":true},"execution_count":null,"outputs":[]}]}