{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Get  Libraries\n","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport transformers\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoModel, BertTokenizer","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:18:48.055002Z","iopub.execute_input":"2021-12-20T15:18:48.055479Z","iopub.status.idle":"2021-12-20T15:18:55.138425Z","shell.execute_reply.started":"2021-12-20T15:18:48.055392Z","shell.execute_reply":"2021-12-20T15:18:55.137719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:18:59.585814Z","iopub.execute_input":"2021-12-20T15:18:59.586362Z","iopub.status.idle":"2021-12-20T15:18:59.645364Z","shell.execute_reply.started":"2021-12-20T15:18:59.586322Z","shell.execute_reply":"2021-12-20T15:18:59.644631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.__version__, pd.__version__, sklearn.__version__, transformers.__version__","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:04.379626Z","iopub.execute_input":"2021-12-20T15:19:04.380105Z","iopub.status.idle":"2021-12-20T15:19:04.386873Z","shell.execute_reply.started":"2021-12-20T15:19:04.380068Z","shell.execute_reply":"2021-12-20T15:19:04.386177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:05.970359Z","iopub.execute_input":"2021-12-20T15:19:05.970916Z","iopub.status.idle":"2021-12-20T15:19:05.977312Z","shell.execute_reply.started":"2021-12-20T15:19:05.970879Z","shell.execute_reply":"2021-12-20T15:19:05.976637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Configs","metadata":{}},{"cell_type":"code","source":"MODEL =  '../input/output-detox/model/'\nTOKENIZER = '../input/output-detox/tokenizer/'","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:10.461743Z","iopub.execute_input":"2021-12-20T15:19:10.462295Z","iopub.status.idle":"2021-12-20T15:19:10.46634Z","shell.execute_reply.started":"2021-12-20T15:19:10.462257Z","shell.execute_reply":"2021-12-20T15:19:10.465269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"code","source":"df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:13.465024Z","iopub.execute_input":"2021-12-20T15:19:13.465281Z","iopub.status.idle":"2021-12-20T15:19:14.02948Z","shell.execute_reply.started":"2021-12-20T15:19:13.465253Z","shell.execute_reply":"2021-12-20T15:19:14.028736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ruddit = pd.read_csv(\"../input/ruddit-jigsaw-dataset-combined-cleaned/toxic_train.csv\")\ndf_ruddit = df_ruddit[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n                                                                'offensiveness_score':'y'})\ndf_ruddit['y'] = (df_ruddit['y'] - df_ruddit.y.min()) / (df_ruddit.y.max() - df_ruddit.y.min())","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:35.715566Z","iopub.execute_input":"2021-12-20T15:19:35.716107Z","iopub.status.idle":"2021-12-20T15:19:36.999026Z","shell.execute_reply.started":"2021-12-20T15:19:35.716068Z","shell.execute_reply":"2021-12-20T15:19:36.991731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n\ndf_train['severe_toxic'] = df_train.severe_toxic * 1.2\ndf_train['obscene'] = df_train.obscene * 1.3\ndf_train['threat'] = df_train.threat * 1.4\ndf_train['insult'] = df_train.insult * 1.5\ndf_train['identity_hate'] = df_train.identity_hate * 1.6 \n\ndf_train['y'] = (df_train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf_train['y'] = df_train['y']/df_train['y'].max()\n\ndf_train = df_train[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:44:03.13578Z","iopub.execute_input":"2021-12-10T17:44:03.13643Z","iopub.status.idle":"2021-12-10T17:44:04.758122Z","shell.execute_reply.started":"2021-12-10T17:44:03.136382Z","shell.execute_reply":"2021-12-10T17:44:04.757147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total_train = pd.concat([df_ruddit, df_train])\ndel df_ruddit\ndf_total_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:46.736955Z","iopub.execute_input":"2021-12-20T15:19:46.737213Z","iopub.status.idle":"2021-12-20T15:19:46.763143Z","shell.execute_reply.started":"2021-12-20T15:19:46.737184Z","shell.execute_reply":"2021-12-20T15:19:46.762314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total_train = df_total_train.sample(200000,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:44:04.790436Z","iopub.execute_input":"2021-12-10T17:44:04.790767Z","iopub.status.idle":"2021-12-10T17:44:04.841401Z","shell.execute_reply.started":"2021-12-10T17:44:04.79072Z","shell.execute_reply":"2021-12-10T17:44:04.840446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Detofixy Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"model = AutoModel.from_pretrained(MODEL)\ntokenizer = BertTokenizer.from_pretrained(TOKENIZER)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:19:51.857389Z","iopub.execute_input":"2021-12-20T15:19:51.857649Z","iopub.status.idle":"2021-12-20T15:19:59.521945Z","shell.execute_reply.started":"2021-12-20T15:19:51.857619Z","shell.execute_reply":"2021-12-20T15:19:59.521251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"# get length of all the messages in the train set\nseq_len = [len(i.split()) for i in df_total_train[\"text\"]]\npd.Series(seq_len).hist(bins = 30)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:20:03.807469Z","iopub.execute_input":"2021-12-20T15:20:03.808318Z","iopub.status.idle":"2021-12-20T15:20:04.792426Z","shell.execute_reply.started":"2021-12-20T15:20:03.808266Z","shell.execute_reply":"2021-12-20T15:20:04.791779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_len = 150","metadata":{"execution":{"iopub.status.busy":"2021-12-20T15:20:13.731186Z","iopub.execute_input":"2021-12-20T15:20:13.731731Z","iopub.status.idle":"2021-12-20T15:20:13.735048Z","shell.execute_reply.started":"2021-12-20T15:20:13.731693Z","shell.execute_reply":"2021-12-20T15:20:13.734358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenize and encode sequences in the training and val set\ntokens_train = tokenizer.batch_encode_plus(\n    df_total_train[\"text\"].tolist(),\n    padding = 'max_length',\n    max_length = max_seq_len,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the real validation set\nval_less_toxic_tokens = tokenizer.batch_encode_plus(\n    df_val[\"less_toxic\"].tolist(),\n    padding = 'max_length',\n    max_length = max_seq_len,\n    truncation=True,\n    return_token_type_ids=False\n)\nval_more_toxic_tokens = tokenizer.batch_encode_plus(\n    df_val[\"more_toxic\"].tolist(),\n    padding = 'max_length',\n    max_length = max_seq_len,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the test set\nsub_tokens = tokenizer.batch_encode_plus(\n    df_sub[\"text\"].tolist(),\n    padding = 'max_length',\n    max_length = max_seq_len,\n    truncation=True,\n    return_token_type_ids=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:44:12.524826Z","iopub.execute_input":"2021-12-10T17:44:12.52528Z","iopub.status.idle":"2021-12-10T17:57:04.621406Z","shell.execute_reply.started":"2021-12-10T17:44:12.525209Z","shell.execute_reply":"2021-12-10T17:57:04.620425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Integer Sequences to Tensors","metadata":{}},{"cell_type":"code","source":"# for train set\ntrain_seq = torch.tensor(tokens_train['input_ids'])\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\ntrain_y = torch.tensor(df_total_train[\"y\"].tolist())\n\n# for validation set\nval_more_toxic_seq = torch.tensor(val_more_toxic_tokens['input_ids'])\nval_more_toxic_mask = torch.tensor(val_more_toxic_tokens['attention_mask'])\nval_less_toxic_seq = torch.tensor(val_less_toxic_tokens['input_ids'])\nval_less_toxic_mask = torch.tensor(val_less_toxic_tokens['attention_mask'])\ntarget = torch.tensor(1, dtype=torch.long)\n\n# for test set\nsub_seq = torch.tensor(sub_tokens['input_ids'])\nsub_mask = torch.tensor(sub_tokens['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:04.623356Z","iopub.execute_input":"2021-12-10T17:57:04.623682Z","iopub.status.idle":"2021-12-10T17:57:14.182158Z","shell.execute_reply.started":"2021-12-10T17:57:04.623636Z","shell.execute_reply":"2021-12-10T17:57:14.181179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create DataLoaders\n","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#define a batch size\nbatch_size = 32\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# same \nval_data = TensorDataset(val_more_toxic_seq, val_more_toxic_mask,val_less_toxic_seq, val_less_toxic_mask)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n\n# test\nsub_data = TensorDataset(sub_seq,sub_mask)\nsub_sampler = SequentialSampler(sub_data)\nsub_dataloader = DataLoader(sub_data,sampler = sub_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:14.183956Z","iopub.execute_input":"2021-12-10T17:57:14.184286Z","iopub.status.idle":"2021-12-10T17:57:14.192891Z","shell.execute_reply.started":"2021-12-10T17:57:14.184241Z","shell.execute_reply":"2021-12-10T17:57:14.191767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Freeze model Parameters\n","metadata":{}},{"cell_type":"code","source":"# freeze all the parameters\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:14.194761Z","iopub.execute_input":"2021-12-10T17:57:14.195096Z","iopub.status.idle":"2021-12-10T17:57:14.208833Z","shell.execute_reply.started":"2021-12-10T17:57:14.195053Z","shell.execute_reply":"2021-12-10T17:57:14.207876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model Architecture\n","metadata":{}},{"cell_type":"code","source":"class myDetox(nn.Module):\n\n    def __init__(self, model):\n        super(myDetox, self).__init__()\n        self.model = model \n        \n        # dropout layer\n        self.dropout = nn.Dropout(0.2)\n\n        # dense layer 1\n        self.fc1 = nn.Linear(768,512)\n\n        # dense layer 2 (Output layer)\n        self.fc2 = nn.Linear(512,1)\n\n    #define the forward pass\n    def forward(self, sent_id, mask):\n        #pass the inputs to the model  \n        _, cls_hs = self.model(sent_id, attention_mask=mask, return_dict=False)\n\n        x = self.fc1(cls_hs)\n\n        x = self.dropout(x)\n\n        # output layer\n        x = self.fc2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:14.210728Z","iopub.execute_input":"2021-12-10T17:57:14.211803Z","iopub.status.idle":"2021-12-10T17:57:14.222772Z","shell.execute_reply.started":"2021-12-10T17:57:14.211767Z","shell.execute_reply":"2021-12-10T17:57:14.221861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pass the pre-trained BERT to our define architecture\nfinedmodel = myDetox(model)\n\n# push the model to GPU\nfinedmodel = finedmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:14.22595Z","iopub.execute_input":"2021-12-10T17:57:14.226515Z","iopub.status.idle":"2021-12-10T17:57:19.701997Z","shell.execute_reply.started":"2021-12-10T17:57:14.226469Z","shell.execute_reply":"2021-12-10T17:57:19.700909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer from hugging face transformers\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(finedmodel.parameters(), lr = 1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.703467Z","iopub.execute_input":"2021-12-10T17:57:19.703776Z","iopub.status.idle":"2021-12-10T17:57:19.724509Z","shell.execute_reply.started":"2021-12-10T17:57:19.703732Z","shell.execute_reply":"2021-12-10T17:57:19.723337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" MSE_loss = nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.726182Z","iopub.execute_input":"2021-12-10T17:57:19.726821Z","iopub.status.idle":"2021-12-10T17:57:19.731646Z","shell.execute_reply.started":"2021-12-10T17:57:19.726772Z","shell.execute_reply":"2021-12-10T17:57:19.730409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valCrossLoss(outputs1, outputs2, targets):\n    return nn.MarginRankingLoss(margin=0)(outputs1, outputs2, targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.733491Z","iopub.execute_input":"2021-12-10T17:57:19.734148Z","iopub.status.idle":"2021-12-10T17:57:19.742243Z","shell.execute_reply.started":"2021-12-10T17:57:19.734102Z","shell.execute_reply":"2021-12-10T17:57:19.741031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define training step and evaluation step","metadata":{}},{"cell_type":"code","source":"# function to train the model\ndef train():\n\n    finedmodel.train()\n\n    total_loss = 0\n\n    # iterate over batches\n    for step,batch in enumerate(train_dataloader):\n\n        # progress update after every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n\n        # push the batch to gpu\n        batch = [r.to(device) for r in batch]\n\n        sent_id, mask, labels = batch\n\n        # clear previously calculated gradients \n        finedmodel.zero_grad()        \n\n        # get model predictions for the current batch\n        preds = finedmodel(sent_id, mask)\n\n        # compute the loss between actual and predicted values\n        loss = MSE_loss(preds, labels)\n\n        # add on to the total loss\n        total_loss = total_loss + loss.item()\n\n        # backward pass to calculate the gradients\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        torch.nn.utils.clip_grad_norm_(finedmodel.parameters(), 1.0)\n\n        # update parameters\n        optimizer.step()\n        \n        for r in batch:\n            del r\n    # compute the training loss of the epoch\n    avg_loss = total_loss / len(train_dataloader)\n\n    #returns the loss and predictions\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.743888Z","iopub.execute_input":"2021-12-10T17:57:19.744377Z","iopub.status.idle":"2021-12-10T17:57:19.757858Z","shell.execute_reply.started":"2021-12-10T17:57:19.744332Z","shell.execute_reply":"2021-12-10T17:57:19.756985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for evaluating the model\ndef retrain():\n  \n    print(\"\\nEvaluating... well retrain...\")\n\n    # deactivate dropout layers\n    finedmodel.eval()\n\n    total_loss = 0\n\n    # empty list to save the model predictions\n    total_acc = 0\n\n    # iterate over batches\n    for step,batch in enumerate(val_dataloader):\n\n        # Progress update every 50 batches.\n        if step % 1000 == 0 and not step == 0:\n\n          # Calculate elapsed time in minutes.\n          #elapsed = format_time(time.time() - t0)\n\n          # Report progress.\n          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        more_toxic_ids, more_toxic_mask, less_toxic_ids, less_toxic_mask = batch\n\n        # deactivate autograd\n        #with torch.no_grad():\n\n        # model predictions\n        more_toxic_outputs = finedmodel(more_toxic_ids, more_toxic_mask)\n        less_toxic_outputs = finedmodel(less_toxic_ids, less_toxic_mask)\n\n        batch_size = more_toxic_ids.size(0)\n        targets = torch.ones(batch_size,device = device, dtype = torch.long)\n\n        loss = valCrossLoss(more_toxic_outputs, less_toxic_outputs, targets)\n        \n        # backward pass to calculate the gradients\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        torch.nn.utils.clip_grad_norm_(finedmodel.parameters(), 1.0)\n\n        # update parameters\n        optimizer.step()\n        \n        total_loss = total_loss + (loss.item() * batch_size)\n\n        more_toxic_outputs = more_toxic_outputs.detach().cpu().numpy()\n        less_toxic_outputs = less_toxic_outputs.detach().cpu().numpy()\n        \n        total_acc += np.round((less_toxic_outputs < more_toxic_outputs).mean(),3)\n        del more_toxic_outputs, less_toxic_outputs\n        for r in batch:\n            del r\n            \n    # compute the validation loss of the epoch\n    avg_loss = total_loss / len(val_dataloader) \n    total_acc = total_acc / len(val_dataloader) \n    return avg_loss, total_acc","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.760497Z","iopub.execute_input":"2021-12-10T17:57:19.76116Z","iopub.status.idle":"2021-12-10T17:57:19.775303Z","shell.execute_reply.started":"2021-12-10T17:57:19.761112Z","shell.execute_reply":"2021-12-10T17:57:19.774375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for evaluating the model\ndef evaluate():\n  \n    print(\"\\nEvaluating...\")\n\n    # deactivate dropout layers\n    finedmodel.eval()\n\n    total_loss = 0\n\n    # empty list to save the model predictions\n    total_acc = 0\n\n    # iterate over batches\n    for step,batch in enumerate(val_dataloader):\n\n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n\n          # Calculate elapsed time in minutes.\n          #elapsed = format_time(time.time() - t0)\n\n          # Report progress.\n          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        more_toxic_ids, more_toxic_mask, less_toxic_ids, less_toxic_mask = batch\n\n        # deactivate autograd\n        with torch.no_grad():\n\n            # model predictions\n            more_toxic_outputs = finedmodel(more_toxic_ids, more_toxic_mask)\n            less_toxic_outputs = finedmodel(less_toxic_ids, less_toxic_mask)\n\n            #batch_size = more_toxic_ids.size(0)\n            #targets = torch.ones(batch_size,device = device, dtype = torch.long)\n\n            #loss = valCrossLoss(more_toxic_outputs, less_toxic_outputs, targets)\n            #total_loss = total_loss + (loss.item() * batch_size)\n\n            more_toxic_outputs = more_toxic_outputs.detach().cpu().numpy()\n            less_toxic_outputs = less_toxic_outputs.detach().cpu().numpy()\n        \n        total_acc += np.round((less_toxic_outputs < more_toxic_outputs).mean(),3)\n        del more_toxic_outputs, less_toxic_outputs\n        for r in batch:\n            del r\n            \n    # compute the validation loss of the epoch\n    #avg_loss = total_loss / len(val_dataloader) \n    total_acc = total_acc / len(val_dataloader) \n    return  total_acc","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.776992Z","iopub.execute_input":"2021-12-10T17:57:19.777569Z","iopub.status.idle":"2021-12-10T17:57:19.792079Z","shell.execute_reply.started":"2021-12-10T17:57:19.777521Z","shell.execute_reply":"2021-12-10T17:57:19.791024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start Model Training\n","metadata":{}},{"cell_type":"code","source":"epochs = 3\n# set initial loss to infinite\nbest_valid_loss = float('inf')\n\n# empty lists to store training and validation loss of each epoch\ntrain_losses=[]\nvalid_losses=[]\nbest_acc = 0\n#for each epoch\nfor epoch in range(epochs):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    \n    #train model\n    train_loss, acc = retrain()\n    \n    #evaluate model\n    #acc = evaluate()\n    \n    #save the best model\n    if acc > best_acc:\n        best_acc = acc\n        torch.save(finedmodel.state_dict(), 'saved_weights'+str(epoch)+'.pt')\n        torch.save(finedmodel.state_dict(), 'saved_weights.pt')\n    \n    # append training and validation loss\n    #train_losses.append(train_loss)\n    #valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    #print(f'Validation Loss: {valid_loss:.3f}')\n    print(f'Validation ACC: {acc:.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T17:57:19.795073Z","iopub.execute_input":"2021-12-10T17:57:19.796369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load weights of best model\npath = 'saved_weights.pt'\nfinedmodel.load_state_dict(torch.load(path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Predictions for Real Validation Data and Submission Data","metadata":{}},{"cell_type":"code","source":"# get predictions for test data\n#with torch.no_grad():\n#    preds_more = finedmodel(val_more_toxic_seq.to(device), val_more_toxic_mask.to(device))\n#    preds_more = preds_more.detach().cpu().numpy()\n    \n#    preds_less = finedmodel(val_less_toxic_seq.to(device), val_less_toxic_mask.to(device))\n#    preds_less = preds_less.detach().cpu().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(l,m):\n    print(f'Validation Accuracy is { np.round((l < m).mean() * 100,2)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = []\nwith torch.no_grad():\n    for step,batch in enumerate(sub_dataloader):\n        # Progress update every 50 batches.\n        if step % 1000 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(sub_dataloader)))\n        sub_seq, sub_mask = batch\n        preds_sub = finedmodel(sub_seq.to(device), sub_mask.to(device))\n        preds_sub_ = preds_sub.detach().cpu().numpy()\n        next_results = [a[0] for a in preds_sub_.tolist()]\n        all_preds += next_results\n        del sub_seq, sub_mask, preds_sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scores = pd.DataFrame({\"score\":all_preds, \"comment_id\":df_sub[\"comment_id\"]},)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scores.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}