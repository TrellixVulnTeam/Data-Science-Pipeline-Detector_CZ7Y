{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:13.411028Z","iopub.execute_input":"2022-02-23T08:22:13.411951Z","iopub.status.idle":"2022-02-23T08:22:13.42164Z","shell.execute_reply.started":"2022-02-23T08:22:13.411908Z","shell.execute_reply":"2022-02-23T08:22:13.420586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Functions\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:17.502649Z","iopub.execute_input":"2022-02-23T08:22:17.503632Z","iopub.status.idle":"2022-02-23T08:22:17.507169Z","shell.execute_reply.started":"2022-02-23T08:22:17.503582Z","shell.execute_reply":"2022-02-23T08:22:17.506579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Dice(d1,d2):\n    #print(set(d1).intersection(d2))\n    #print(set(d1).union(set(d2)))\n    d=len(set(d1).union(set(d2)))\n    if d==0:\n        d=1\n    return len(set(d1).intersection(d2))/d","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:20.011407Z","iopub.execute_input":"2022-02-23T08:22:20.011868Z","iopub.status.idle":"2022-02-23T08:22:20.017055Z","shell.execute_reply.started":"2022-02-23T08:22:20.011816Z","shell.execute_reply":"2022-02-23T08:22:20.016136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pairbased\ndef TestScoreProb(q1,doc1,doc2,i):\n    s1 = Dice(q1,doc1)\n    #print(s1)\n    s2 = Dice(q1,doc2)\n    #print(s2)\n    p1=0.0\n    p2=0.0\n    if s1 > s2:\n        p1=s1*Prob['less_toxic_prob'][i]\n        p2=s2*Prob['more_toxic_prob'][i]\n    else:\n        p1=s1*Prob['less_toxic_prob'][i]\n        p2=s2*Prob['more_toxic_prob'][i]\n    s= p1-p2\n    d=(1-math.exp(-(s)))\n    if d==0:\n        return (s1,s2,p1,p2,-0.1,0)\n    p = 1/d #(1-math.exp(-(s)))\n    if s1 > s2:\n        return (s1,s2,p1,p2,p,1)\n    return (s1,s2,p1,p2,p,0)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:23.213135Z","iopub.execute_input":"2022-02-23T08:22:23.213441Z","iopub.status.idle":"2022-02-23T08:22:23.222654Z","shell.execute_reply.started":"2022-02-23T08:22:23.213407Z","shell.execute_reply":"2022-02-23T08:22:23.221624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pairbased\ndef TestScoreProb2(s1,s2,n,m):\n    p1=0.0\n    p2=0.0\n    if s1 > s2:\n        p1=Prob['less_toxic_prob'][n]\n        p2=Prob['more_toxic_prob'][m]\n    else:\n        p1=Prob['less_toxic_prob'][n]\n        p2=Prob['more_toxic_prob'][m]\n    s= p1-p2\n    d=(1-math.exp(-(s)))\n    if d==0:\n        return (s1,s2,p1,p2,0)\n    p = 1/d #(1-math.exp(-(s)))\n    if s1 > s2:\n        return (s1,s2,p1,p2,p)\n    return (s1,s2,p1,p2,p)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:27.939877Z","iopub.execute_input":"2022-02-23T08:22:27.94013Z","iopub.status.idle":"2022-02-23T08:22:27.947406Z","shell.execute_reply.started":"2022-02-23T08:22:27.9401Z","shell.execute_reply":"2022-02-23T08:22:27.946475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import dependencies\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nimport gensim\nfrom gensim.models import LdaModel\nfrom gensim import models, corpora, similarities\nimport re\nfrom nltk.stem.porter import PorterStemmer\nimport time\nfrom nltk import FreqDist\nfrom scipy.stats import entropy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:32.3749Z","iopub.execute_input":"2022-02-23T08:22:32.375182Z","iopub.status.idle":"2022-02-23T08:22:34.606504Z","shell.execute_reply.started":"2022-02-23T08:22:32.375144Z","shell.execute_reply":"2022-02-23T08:22:34.605506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initial_clean(text):\n    \"\"\"\n    Function to clean text of websites, email addresess and any punctuation\n    We also lower case the text\n    \"\"\"\n    text = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", text)\n    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n    text = text.lower() # lower case the text\n    text = nltk.word_tokenize(text)\n    return text\n\nstop_words = stopwords.words('english')\ndef remove_stop_words(text):\n    \"\"\"\n    Function that removes all stopwords from text\n    \"\"\"\n    return [word for word in text if word not in stop_words]\n\nstemmer = PorterStemmer()\ndef stem_words(text):\n    \"\"\"\n    Function to stem words, so plural and singular are treated the same\n    \"\"\"\n    try:\n        text = [stemmer.stem(word) for word in text]\n        text = [word for word in text if len(word) > 1] # make sure we have no 1 letter words\n    except IndexError: # the word \"oed\" broke this, so needed try except\n        pass\n    return text\n\ndef apply_all(text):\n    \"\"\"\n    This function applies all the functions above into one\n    \"\"\"\n    return stem_words(remove_stop_words(initial_clean(text)))","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:39.744055Z","iopub.execute_input":"2022-02-23T08:22:39.744705Z","iopub.status.idle":"2022-02-23T08:22:39.760835Z","shell.execute_reply.started":"2022-02-23T08:22:39.744657Z","shell.execute_reply":"2022-02-23T08:22:39.759949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train data ../input/jigsaw-toxic-severity-rating/validation_data.csv\n\n#cleaning process\ndfTrain = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv' ,encoding='utf-8')\ndfTrain['Rank'] = [0] * len(dfTrain['less_toxic'])\ndfTrain['Label'] = [-1] * len(dfTrain['less_toxic'])\ndfTrain.head(20)\n\ndfLexx = dfTrain[[\"worker\", \"less_toxic\",\"Rank\",\"Label\"]]\ndfMore = dfTrain[[\"worker\", \"more_toxic\",\"Rank\",\"Label\"]]\n\ndfLexx['Label']=[0] * len(dfLexx['less_toxic'])\ndfMore['Label']=[1] * len(dfMore['more_toxic'])\n\ndfLexx.rename(columns = {'less_toxic':'text'}, inplace = True)\n\nRankedData = dfLexx\ndfMore.rename(columns = {'more_toxic':'text'}, inplace = True)\nRankedData3 =RankedData.append(dfMore,ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:45.932205Z","iopub.execute_input":"2022-02-23T08:22:45.933114Z","iopub.status.idle":"2022-02-23T08:22:46.7363Z","shell.execute_reply.started":"2022-02-23T08:22:45.933068Z","shell.execute_reply":"2022-02-23T08:22:46.735317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dfTrain['up'] = dfTrain['less_toxic'] +\"\"+ dfTrain['more_toxic']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:57:08.55614Z","iopub.execute_input":"2022-02-16T18:57:08.556446Z","iopub.status.idle":"2022-02-16T18:57:08.615865Z","shell.execute_reply.started":"2022-02-16T18:57:08.556412Z","shell.execute_reply":"2022-02-16T18:57:08.614899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:57:16.642848Z","iopub.execute_input":"2022-02-16T18:57:16.643424Z","iopub.status.idle":"2022-02-16T18:57:16.649869Z","shell.execute_reply.started":"2022-02-16T18:57:16.643379Z","shell.execute_reply":"2022-02-16T18:57:16.648909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:56:49.849071Z","iopub.execute_input":"2022-02-16T18:56:49.849998Z","iopub.status.idle":"2022-02-16T18:56:49.922417Z","shell.execute_reply.started":"2022-02-16T18:56:49.849939Z","shell.execute_reply":"2022-02-16T18:56:49.921535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uniqItems = pd.DataFrame(RankedData3['text'].unique(),columns=['text'])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:52.620605Z","iopub.execute_input":"2022-02-23T08:22:52.620888Z","iopub.status.idle":"2022-02-23T08:22:52.680778Z","shell.execute_reply.started":"2022-02-23T08:22:52.620859Z","shell.execute_reply":"2022-02-23T08:22:52.679749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UniqItemIndx = uniqItems.text.index.values\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:22:55.752607Z","iopub.execute_input":"2022-02-23T08:22:55.752873Z","iopub.status.idle":"2022-02-23T08:22:55.757439Z","shell.execute_reply.started":"2022-02-23T08:22:55.752844Z","shell.execute_reply":"2022-02-23T08:22:55.756464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates a list containing 5 lists, each of 8 items, all set to 0\nw, h = len(UniqItemIndx), len(UniqItemIndx)\n#Matrix = [[0 for x in range(w)] for y in range(h)] ","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:49:41.880045Z","iopub.execute_input":"2022-02-22T17:49:41.880963Z","iopub.status.idle":"2022-02-22T17:49:41.885378Z","shell.execute_reply.started":"2022-02-22T17:49:41.880903Z","shell.execute_reply":"2022-02-22T17:49:41.884417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unikPairs =[]\nfor p in dfTrain.less_toxic.index.values:\n    n =uniqItems[uniqItems.text ==dfTrain.less_toxic[p]].index.values[0]\n    m=uniqItems[uniqItems.text ==dfTrain.more_toxic[p]].index.values[0]\n    unikPairs.append((n,m))\n    #print(uniqItems[uniqItems.text ==dfTrain.less_toxic[p]].index.values[0],uniqItems[uniqItems.text ==dfTrain.more_toxic[p]].index.values[0])\n    #Matrix[n][m]=Matrix[n][m]+1\n    #break","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:23:06.224231Z","iopub.execute_input":"2022-02-23T08:23:06.22474Z","iopub.status.idle":"2022-02-23T08:25:45.567067Z","shell.execute_reply.started":"2022-02-23T08:23:06.224698Z","shell.execute_reply":"2022-02-23T08:25:45.565829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#unikPairs = list(set(unikPairs))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T20:55:12.632768Z","iopub.execute_input":"2022-02-16T20:55:12.633417Z","iopub.status.idle":"2022-02-16T20:55:12.650674Z","shell.execute_reply.started":"2022-02-16T20:55:12.63337Z","shell.execute_reply":"2022-02-16T20:55:12.6499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(unikPairs)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T20:44:16.354342Z","iopub.execute_input":"2022-02-17T20:44:16.354715Z","iopub.status.idle":"2022-02-17T20:44:16.364004Z","shell.execute_reply.started":"2022-02-17T20:44:16.354684Z","shell.execute_reply":"2022-02-17T20:44:16.363054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean text and title and create new column \"tokenized\"\nt1 = time.time()\nuniqItems['tokenized'] = uniqItems['text'].apply(apply_all)\nt2 = time.time()\nprint(\"Time to clean and tokenize\", len(dfMore), \"articles:\", (t2-t1)/60, \"min\")","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:50:44.320025Z","iopub.execute_input":"2022-02-23T08:50:44.320649Z","iopub.status.idle":"2022-02-23T08:50:44.420491Z","shell.execute_reply.started":"2022-02-23T08:50:44.3205Z","shell.execute_reply":"2022-02-23T08:50:44.419244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:55:15.2502Z","iopub.execute_input":"2022-02-22T17:55:15.250503Z","iopub.status.idle":"2022-02-22T17:55:15.255254Z","shell.execute_reply.started":"2022-02-22T17:55:15.250472Z","shell.execute_reply":"2022-02-22T17:55:15.254354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\n#A = csr_matrix(Matrix)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:55:17.828457Z","iopub.execute_input":"2022-02-22T17:55:17.829045Z","iopub.status.idle":"2022-02-22T17:55:17.83275Z","shell.execute_reply.started":"2022-02-22T17:55:17.829004Z","shell.execute_reply":"2022-02-22T17:55:17.831972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Prob={}\ndone=[]\na=[]\n\nfor i in dfTrain.index.values:\n    if i in done:\n        continue\n    done.append(i)\n    nl = dfTrain[dfTrain.less_toxic==dfTrain.less_toxic[i]]\n    nm = dfTrain[dfTrain.more_toxic==dfTrain.less_toxic[i]]\n    #Prob['less_toxic']=dfTrain.less_toxic[i]\n    a.append(len(nl)/(len(nl)+len(nm)))\n    \n    #break\n    \nProb['less_toxic_prob']=a\nProb['less_toxic']=done","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:55:21.123646Z","iopub.execute_input":"2022-02-22T17:55:21.123968Z","iopub.status.idle":"2022-02-22T18:01:08.650188Z","shell.execute_reply.started":"2022-02-22T17:55:21.123921Z","shell.execute_reply":"2022-02-22T18:01:08.649442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"done=[]\na=[]\nfor i in dfTrain.index.values:\n    if i in done:\n        continue\n    done.append(i)\n    nl = dfTrain[dfTrain.less_toxic==dfTrain.more_toxic[i]]\n    nm = dfTrain[dfTrain.more_toxic==dfTrain.more_toxic[i]]\n    #Prob['less_toxic']=dfTrain.less_toxic[i]\n    a.append(len(nm)/(len(nl)+len(nm)))\n    #break\n    \nProb['more_toxic_prob']=a\nProb['more_toxic']=done","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:04:23.637835Z","iopub.execute_input":"2022-02-22T18:04:23.638735Z","iopub.status.idle":"2022-02-22T18:10:10.658643Z","shell.execute_reply.started":"2022-02-22T18:04:23.638692Z","shell.execute_reply":"2022-02-22T18:10:10.657743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-16T12:11:55.044548Z","iopub.execute_input":"2022-02-16T12:11:55.045108Z","iopub.status.idle":"2022-02-16T12:11:55.049642Z","shell.execute_reply.started":"2022-02-16T12:11:55.045063Z","shell.execute_reply":"2022-02-16T12:11:55.048824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cleaning process\ndfTest = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv' ,encoding='utf-8')\ndfTest['cleaned_'] = ''\ndfTest.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:10:10.659975Z","iopub.execute_input":"2022-02-22T18:10:10.660172Z","iopub.status.idle":"2022-02-22T18:10:10.798288Z","shell.execute_reply.started":"2022-02-22T18:10:10.660146Z","shell.execute_reply":"2022-02-22T18:10:10.797379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean text and title and create new column \"tokenized\"\nt1 = time.time()\ndfTest['tokenized'] = dfTest['text'].apply(apply_all)\nt2 = time.time()\nprint(\"Time to clean and tokenize\", len(dfLexx), \"articles:\", (t2-t1)/60, \"min\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:21:07.782409Z","iopub.execute_input":"2022-02-22T18:21:07.783004Z","iopub.status.idle":"2022-02-22T18:21:33.522303Z","shell.execute_reply.started":"2022-02-22T18:21:07.782958Z","shell.execute_reply":"2022-02-22T18:21:33.521383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(uniqItems['tokenized'].index.values)\nuniqItems['text'][14250]","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:21:40.362771Z","iopub.execute_input":"2022-02-22T18:21:40.363068Z","iopub.status.idle":"2022-02-22T18:21:40.369569Z","shell.execute_reply.started":"2022-02-22T18:21:40.363034Z","shell.execute_reply":"2022-02-22T18:21:40.368574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# query to doc sim dice\nimport random\nSim=[]\nSimL=[]\nT=[]\nLabel=[]\nModels=[]\n#SelectedPairs=[]\nj=0\nDrawSample=2770 #minimum statistical sampling\nfor x in dfTest['tokenized']:\n    i=0\n    a=[]\n    for pair in random.sample(unikPairs, DrawSample): # y in uniqItems['tokenized']:\n        n = pair[0]\n        m = pair[1]\n        #SelectedPairs.append(pair)\n        s1 = Dice(x,uniqItems['tokenized'][pair[0]])\n        s2 = Dice(x,uniqItems['tokenized'][pair[1]])\n        if s1>s2:\n            #print(TestScoreProb2(s1,s2,n,m))\n            #break\n            T.append(TestScoreProb2(s1,s2,n,m))#(len(x),len(uniqItems['tokenized'][n]),s1,len(uniqItems['tokenized'][m]),s2))\n            Label.append(0)\n        else:\n            T.append(TestScoreProb2(s1,s2,n,m))#(len(x),len(uniqItems['tokenized'][m]),s2,len(uniqItems['tokenized'][n]),s1))\n            Label.append(1)\n    #Sim.append(T)\n    #SimL.append(Label)\n    j=j+1\n    #if j%3000==0:\n        #regLess = LinearRegression().fit(T, Label)\n        #Models.append(regLess)\n        #T=[]\n        #Label=[]\n    #break\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-22T19:32:42.040777Z","iopub.execute_input":"2022-02-22T19:32:42.041107Z","iopub.status.idle":"2022-02-22T19:41:36.114046Z","shell.execute_reply.started":"2022-02-22T19:32:42.041072Z","shell.execute_reply":"2022-02-22T19:41:36.113109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-17T21:56:53.778714Z","iopub.execute_input":"2022-02-17T21:56:53.779084Z","iopub.status.idle":"2022-02-17T21:56:54.779578Z","shell.execute_reply.started":"2022-02-17T21:56:53.779049Z","shell.execute_reply":"2022-02-17T21:56:54.778411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-17T21:57:03.540818Z","iopub.execute_input":"2022-02-17T21:57:03.541143Z","iopub.status.idle":"2022-02-17T21:57:03.547422Z","shell.execute_reply.started":"2022-02-17T21:57:03.541111Z","shell.execute_reply":"2022-02-17T21:57:03.546849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-17T21:57:11.077251Z","iopub.execute_input":"2022-02-17T21:57:11.077798Z","iopub.status.idle":"2022-02-17T21:57:11.084385Z","shell.execute_reply.started":"2022-02-17T21:57:11.07776Z","shell.execute_reply":"2022-02-17T21:57:11.083225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregLess = LinearRegression().fit(T, Label)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T19:52:50.355491Z","iopub.execute_input":"2022-02-22T19:52:50.355854Z","iopub.status.idle":"2022-02-22T19:53:22.581515Z","shell.execute_reply.started":"2022-02-22T19:52:50.355816Z","shell.execute_reply":"2022-02-22T19:53:22.580617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = regLess.predict(T)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T19:53:52.35504Z","iopub.execute_input":"2022-02-22T19:53:52.3558Z","iopub.status.idle":"2022-02-22T19:54:19.143969Z","shell.execute_reply.started":"2022-02-22T19:53:52.355741Z","shell.execute_reply":"2022-02-22T19:54:19.142988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions[0:370])","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:26:12.192541Z","iopub.execute_input":"2022-02-22T18:26:12.192848Z","iopub.status.idle":"2022-02-22T18:26:12.198841Z","shell.execute_reply.started":"2022-02-22T18:26:12.192813Z","shell.execute_reply":"2022-02-22T18:26:12.198019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre=[]\nfor i in range(0,len(dfTest['tokenized'])):\n    s=i*DrawSample\n    e= s+DrawSample\n    print(i,s,e)\n    t =predictions[s:e]\n    #print(dfTest['text'][i])\n    print(\"--------------\\n\")\n    #minpos = t.index(min(t))\n    #maxpos = t.index(max(t))\n    print(min(t),max(t))\n    #print(sum([d for d in t if d>0.0])/len([d for d in t if d>0.0]),sum([d for d in t if d<0.5 and d>0.0])/len([d for d in t if d<0.5 and d>0.0]))\n    #print(sum([d for d in t])/len([d for d in t if d<0.5 and d>0.0]))\n    pre.append(sum([d for d in t if d>0.0])/len([d for d in t if d>0.0]))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-22T19:56:35.4951Z","iopub.execute_input":"2022-02-22T19:56:35.495402Z","iopub.status.idle":"2022-02-22T19:56:36.009774Z","shell.execute_reply.started":"2022-02-22T19:56:35.495372Z","shell.execute_reply":"2022-02-22T19:56:36.008627Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(T)/len(dfTest['tokenized'])","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:26:30.929179Z","iopub.execute_input":"2022-02-22T18:26:30.929879Z","iopub.status.idle":"2022-02-22T18:26:30.93624Z","shell.execute_reply.started":"2022-02-22T18:26:30.929842Z","shell.execute_reply":"2022-02-22T18:26:30.935332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#validation\nfor p in dfTrain.less_toxic.index.values:\n    ls = uniqItems[uniqItems.text ==dfTrain.less_toxic[p]].tokenized.iloc[0]\n    mr = uniqItems[uniqItems.text ==dfTrain.more_toxic[p]].tokenized.iloc[0]\n    q=ls\n    s1 = Dice(q,ls)\n    s2 = Dice(q,mr)\n    validate = TestScoreProb2(s1,s2,n,m)\n    tl =regLess.predict([validate])\n    #print(t)\n    q=mr\n    s1 = Dice(q,ls)\n    s2 = Dice(q,mr)\n    validate = TestScoreProb2(s1,s2,n,m)\n    tm = regLess.predict([validate])\n    print(tl[0]<tm[0])\n    #break\n    print(\"--------------\\n\")\n    #minpos = t.index(min(t))\n    #maxpos = t.index(max(t))\n    #print(minpos,maxpos)\n    #print(sum([d for d in t if d>0.5]),sum([d for d in t if d<0.5]))\n    #print(dfTest['tokenized'][i],))\n    #break","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:37:25.191294Z","iopub.execute_input":"2022-02-18T13:37:25.191826Z","iopub.status.idle":"2022-02-18T13:37:49.956142Z","shell.execute_reply.started":"2022-02-18T13:37:25.19178Z","shell.execute_reply":"2022-02-18T13:37:49.954862Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"for i in range(0,len(dfTest['tokenized'])):\n    s=i*DrawSample\n    e= s+DrawSample\n    print(s,e)\n    t =regLess.predict(T[s:e])\n    print(dfTest['text'][i])\n    print(\"--------------\\n\")\n    #minpos = t.index(min(t))\n    #maxpos = t.index(max(t))\n    #print(minpos,maxpos)\n    print(sum([d for d in t if d>0.5])/len([d for d in t if d>0.5]),sum([d for d in t if d<0.5])/len([d for d in t if d<0.5]))\n    #print(dfTest['tokenized'][i],))\n    #break","metadata":{"execution":{"iopub.status.busy":"2022-02-18T13:40:19.377926Z","iopub.execute_input":"2022-02-18T13:40:19.378749Z","iopub.status.idle":"2022-02-18T13:40:19.588322Z","shell.execute_reply.started":"2022-02-18T13:40:19.378695Z","shell.execute_reply":"2022-02-18T13:40:19.587158Z"}}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:08:49.550787Z","iopub.execute_input":"2022-02-18T09:08:49.551069Z","iopub.status.idle":"2022-02-18T09:08:49.557822Z","shell.execute_reply.started":"2022-02-18T09:08:49.551039Z","shell.execute_reply":"2022-02-18T09:08:49.557158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataSubmission={}\n#dataSubmission['comment_id']=labelsTest\n#dataSubmission['score'] = y_pred\ndataSubmission['comment_id']=dfTest.comment_id\ndataSubmission['score'] = pre","metadata":{"execution":{"iopub.status.busy":"2022-02-01T06:01:18.470849Z","iopub.execute_input":"2022-02-01T06:01:18.471127Z","iopub.status.idle":"2022-02-01T06:01:18.477125Z","shell.execute_reply.started":"2022-02-01T06:01:18.471096Z","shell.execute_reply":"2022-02-01T06:01:18.476243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-01T06:01:38.637535Z","iopub.execute_input":"2022-02-01T06:01:38.638058Z","iopub.status.idle":"2022-02-01T06:01:38.648Z","shell.execute_reply.started":"2022-02-01T06:01:38.638022Z","shell.execute_reply":"2022-02-01T06:01:38.647121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Train done above\n\n#Train\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidfTrain = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', encoding='latin-1', ngram_range=(1, 1),max_features=7000) #stop_words='english' #7000 max features max_features=7000\n\nfeatures = tfidfTrain.fit_transform(RankedData3.text).toarray() \nlabels = RankedData3.Rank                           # represents the category of each of the 1490 articles\n#ids = df.comment_id\n\nselectedFeatures = tfidfTrain.get_feature_names()\n\n\n#test\n\n#get common features from train n test\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidfTest = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', encoding='latin-1', ngram_range=(1, 1),max_features=12000) #max_features=15000 stop_words='english' ,max_features=12000\n\nfeaturesTest = tfidfTest.fit_transform(dfTest.text).toarray() \n#featuresTest = tfidfTrain.fit_transform(dfTest.text).toarray() \nlabelsTest = dfTest.index.values \n\nprint('d')\nintersection = set(tfidfTest.get_feature_names()).intersection(tfidfTrain.get_feature_names())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:18:03.361622Z","iopub.execute_input":"2022-01-27T16:18:03.362721Z","iopub.status.idle":"2022-01-27T16:18:16.142665Z","shell.execute_reply.started":"2022-01-27T16:18:03.362666Z","shell.execute_reply":"2022-01-27T16:18:16.141736Z"}}},{"cell_type":"markdown","source":"len(intersection)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:18:39.332129Z","iopub.execute_input":"2022-01-27T16:18:39.333293Z","iopub.status.idle":"2022-01-27T16:18:39.341585Z","shell.execute_reply.started":"2022-01-27T16:18:39.333229Z","shell.execute_reply":"2022-01-27T16:18:39.34084Z"}}},{"cell_type":"markdown","source":"filtered=[]\nfor f in features[0:3000,:]:\n    i=0\n    for s in f:\n        if s>0.1:\n            print(selectedFeatures[i],s)\n            if selectedFeatures[i] not in filtered:\n                filtered.append(selectedFeatures[i])\n        i=i+1\nlen(filtered)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T09:36:53.906848Z","iopub.execute_input":"2022-01-27T09:36:53.907202Z","iopub.status.idle":"2022-01-27T09:38:30.524416Z","shell.execute_reply.started":"2022-01-27T09:36:53.90715Z","shell.execute_reply":"2022-01-27T09:38:30.523193Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"#list(intersection).index('shut')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.metrics.pairwise import linear_kernel\n#cosine_similarities = linear_kernel(featuresTest[0:1,:7000], features[0:60000,0:7000]) #.flatten()\n#t=[for x in cosine_similarities[0] (cosine_similarities[0].index(x),x) if x>0] \n#t=[(idx,val) for idx, val in enumerate(cosine_similarities[0]) if val > 0.1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#t","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(RankedData3.text[56200],' >> ',RankedData3.Rank[56200])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dfTest.text[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filtered=[]\n#for f in features[0:3000,:]:\n#    i=0\n#    for s in f:\n#        if s>0.1:\n#            print(selectedFeatures[i],s)\n#            if selectedFeatures[i] not in filtered:\n#                filtered.append(selectedFeatures[i])\n#        i=i+1\n#len(filtered)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(intersection)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#min max rescaling\n\n#max = np.max(labels)\n#min = np.min(labels)\n#rank_scaled = np.array([(x - min) / (max - min) for x in labels])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rank_scaled=100*rank_scaled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rank_scaled[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.preprocessing import Normalizer\ntransformer = Normalizer().fit([labels])  # fit does nothing.\nrank_scaled = transformer.transform([labels])","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:18:58.696424Z","iopub.execute_input":"2022-01-27T16:18:58.696975Z","iopub.status.idle":"2022-01-27T16:18:58.704142Z","shell.execute_reply.started":"2022-01-27T16:18:58.696939Z","shell.execute_reply":"2022-01-27T16:18:58.70333Z"}}},{"cell_type":"markdown","source":"rank_scaled=[labels]\nfNames=tfidfTrain.get_feature_names()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:19:05.057975Z","iopub.execute_input":"2022-01-27T16:19:05.058303Z","iopub.status.idle":"2022-01-27T16:19:05.07301Z","shell.execute_reply.started":"2022-01-27T16:19:05.058271Z","shell.execute_reply":"2022-01-27T16:19:05.072057Z"}}},{"cell_type":"markdown","source":"sindexTrain = [fNames.index(x) for x in intersection]","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:19:10.719454Z","iopub.execute_input":"2022-01-27T16:19:10.71977Z","iopub.status.idle":"2022-01-27T16:19:11.034548Z","shell.execute_reply.started":"2022-01-27T16:19:10.719732Z","shell.execute_reply":"2022-01-27T16:19:11.033573Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sample = features[: , sindexTrain]\nsample.shape\nsamLab = rank_scaled[0]\nsamLab.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:19:16.526845Z","iopub.execute_input":"2022-01-27T16:19:16.527191Z","iopub.status.idle":"2022-01-27T16:19:24.084425Z","shell.execute_reply.started":"2022-01-27T16:19:16.527159Z","shell.execute_reply":"2022-01-27T16:19:24.08361Z"}}},{"cell_type":"markdown","source":"del features","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:19:28.800288Z","iopub.execute_input":"2022-01-27T16:19:28.800782Z","iopub.status.idle":"2022-01-27T16:19:28.89876Z","shell.execute_reply.started":"2022-01-27T16:19:28.800748Z","shell.execute_reply":"2022-01-27T16:19:28.897908Z"}}},{"cell_type":"markdown","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(sample, samLab, test_size=0.05, random_state=21)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:19:50.369392Z","iopub.execute_input":"2022-01-27T16:19:50.370039Z","iopub.status.idle":"2022-01-27T16:19:54.494902Z","shell.execute_reply.started":"2022-01-27T16:19:50.369992Z","shell.execute_reply":"2022-01-27T16:19:54.494255Z"}}},{"cell_type":"markdown","source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_squared_error\n\nscaler = StandardScaler().fit(sample)\nrescaled_X_train = scaler.transform(sample)\nmodel = GradientBoostingRegressor(random_state=21, n_estimators=400,learning_rate=0.09) #subsample=0.5\nmodel.fit(rescaled_X_train, samLab) #normalized y\n\n# transform the validation dataset\nrescaled_X_test = scaler.transform(x_test)\npredictions = model.predict(rescaled_X_test)\nprint (mean_squared_error(y_test, predictions))","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:23:43.263167Z","iopub.execute_input":"2022-01-27T16:23:43.263504Z","iopub.status.idle":"2022-01-27T16:26:33.291745Z","shell.execute_reply.started":"2022-01-27T16:23:43.263466Z","shell.execute_reply":"2022-01-27T16:26:33.290841Z"}}},{"cell_type":"code","source":"#import gc\n\n#del scaler,model\n\n#gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"for x in model.train_score_:\n    print(x)","metadata":{}},{"cell_type":"markdown","source":"fNames=tfidfTest.get_feature_names()\nsindex = [fNames.index(x) for x in intersection]","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:27:42.21947Z","iopub.execute_input":"2022-01-27T16:27:42.220621Z","iopub.status.idle":"2022-01-27T16:27:42.808638Z","shell.execute_reply.started":"2022-01-27T16:27:42.220558Z","shell.execute_reply":"2022-01-27T16:27:42.807655Z"}}},{"cell_type":"markdown","source":"#predict\n#print(tfidfTrain.get_feature_names())\nsampleTest = featuresTest[: , sindex]\nsampleTest.shape\nsamLabTest = labelsTest\nsamLab.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T16:27:48.481915Z","iopub.execute_input":"2022-01-27T16:27:48.482387Z","iopub.status.idle":"2022-01-27T16:27:50.142095Z","shell.execute_reply.started":"2022-01-27T16:27:48.482342Z","shell.execute_reply":"2022-01-27T16:27:50.141254Z"}}},{"cell_type":"markdown","source":"#middle toxic tier ranking\nsampleTest=[ftmodel.get_sentence_vector(x) for x in dfTest.text]","metadata":{}},{"cell_type":"markdown","source":"#booster\nrescaled_X_test = scaler.transform(sampleTest)\npredictions = model.predict(rescaled_X_test)","metadata":{}},{"cell_type":"markdown","source":"indx = dfTest.text.index.values\nfor i in range(predictions.shape[0]):\n    #print(dfTest.text[indx[i]],predictions[i])\n    dfTest.at[indx[i],'Rank']=predictions[i]\n    #break","metadata":{}},{"cell_type":"markdown","source":"RankedData3 = RankedData3.append(dfTest,ignore_index=True)\n#samLab = sample.Rank","metadata":{}},{"cell_type":"markdown","source":"#clean\nimport re\na=[]\nfor txt in dfTest.text:\n    tmp=''\n    tmp = txt.replace(\"_\", \" \")\n    tmp = tmp.replace('\"', \"\")\n    tmp = tmp.replace('.', \"\")\n    tmp = tmp.replace(\"'\", \"\")\n    tmp = tmp.replace(\":\", \"\")\n    tmp = tmp.replace(\"?\", \"\")\n    tmp = tmp.replace(\",\", \"\")\n    tmp = tmp.replace(\"!\", \"\")\n    tmp = tmp.replace(\"-\", \" \")\n    tmp = tmp.replace(\"(\", \"\")\n    tmp = tmp.replace(\")\", \"\")\n    tmp = tmp.replace(\"[\", \"\")\n    tmp = tmp.replace(\"]\", \"\")\n    tmp = tmp.replace(\"’\", \"\")\n    tmp = tmp.replace(\"}\", \"\")\n    tmp = tmp.replace(\"{\", \"\")\n    tmp = tmp.replace(\"/\", \"\")\n    tmp = tmp.replace(\"=\", \"\")\n    tmp = tmp.replace(\";\", \"\")\n    tmp = tmp.replace(\"~\", \"\")\n    tmp = tmp.replace(\"^\", \"\")\n    tmp = tmp.replace(\"#\", \"\")\n    tmp = tmp.replace(\".\", \"\")\n    tmp = tmp.replace(\"=\", \"\")\n    tmp = tmp.replace(\"\\n\", \" \")\n    tmp = tmp.replace(\"http\", \" weblink \")\n    pattern = r'[0-9]'\n    tmp = re.sub(pattern, '', tmp)\n    \n    #print(tmp)\n    #print(\">>>\")\n    a.append(tmp)\n    #if len(a)==1000:\n        #break\n\ndfTest.text=a","metadata":{}},{"cell_type":"markdown","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidfTrain = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', encoding='latin-1', ngram_range=(1, 1),max_features=7000) #stop_words='english' #7000 max features max_features=7000\n\nfeatures = tfidfTrain.fit_transform(RankedData3.text).toarray() \nlabels = RankedData3.Rank                           # represents the category of each of the 1490 articles\n#ids = df.comment_id\n\nselectedFeatures = tfidfTrain.get_feature_names()\n\n\n#test\n\n#get common features from train n test\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidfTest = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', encoding='latin-1', ngram_range=(1, 1),max_features=12000) #max_features=15000 stop_words='english' ,max_features=12000\n\nfeaturesTest = tfidfTest.fit_transform(dfTest.text).toarray() \n#featuresTest = tfidfTrain.fit_transform(dfTest.text).toarray() \nlabelsTest = dfTest.comment_id \n\nprint('d')\nintersection = set(tfidfTest.get_feature_names()).intersection(tfidfTrain.get_feature_names())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:30:36.221294Z","iopub.execute_input":"2022-01-27T17:30:36.22158Z","iopub.status.idle":"2022-01-27T17:30:47.387311Z","shell.execute_reply.started":"2022-01-27T17:30:36.221552Z","shell.execute_reply":"2022-01-27T17:30:47.386168Z"}}},{"cell_type":"markdown","source":"labelsTest = dfTest.comment_id ","metadata":{}},{"cell_type":"markdown","source":"print(dfTest.comment_id)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:50:37.934519Z","iopub.execute_input":"2022-01-27T17:50:37.934897Z","iopub.status.idle":"2022-01-27T17:50:37.948885Z","shell.execute_reply.started":"2022-01-27T17:50:37.934845Z","shell.execute_reply":"2022-01-27T17:50:37.948136Z"}}},{"cell_type":"markdown","source":"rank_scaled=[labels]\nfNames=tfidfTrain.get_feature_names()\n\nsindexTrain = [fNames.index(x) for x in intersection]\n\nsample = features[: , sindexTrain]\nsample.shape\nsamLab = rank_scaled[0]\nsamLab.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:30:52.834914Z","iopub.execute_input":"2022-01-27T17:30:52.835705Z","iopub.status.idle":"2022-01-27T17:31:10.188021Z","shell.execute_reply.started":"2022-01-27T17:30:52.835667Z","shell.execute_reply":"2022-01-27T17:31:10.187411Z"}}},{"cell_type":"markdown","source":"del features","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:31:15.434879Z","iopub.execute_input":"2022-01-27T17:31:15.435419Z","iopub.status.idle":"2022-01-27T17:31:15.556789Z","shell.execute_reply.started":"2022-01-27T17:31:15.435384Z","shell.execute_reply":"2022-01-27T17:31:15.556014Z"}}},{"cell_type":"markdown","source":"[](http://)fNames=tfidfTest.get_feature_names()\nsindex = [fNames.index(x) for x in intersection]\n\n#predict\n#print(tfidfTrain.get_feature_names())\nsampleTest = featuresTest[: , sindex]\nsampleTest.shape\nsamLabTest = labelsTest\nsamLab.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-27T17:31:21.627587Z","iopub.execute_input":"2022-01-27T17:31:21.627945Z","iopub.status.idle":"2022-01-27T17:31:24.252007Z","shell.execute_reply.started":"2022-01-27T17:31:21.62791Z","shell.execute_reply":"2022-01-27T17:31:24.251339Z"}}},{"cell_type":"markdown","source":"sampleTrain=[ftmodel.get_sentence_vector(x) for x in RankedData3.text]\nsampleTest=[ftmodel.get_sentence_vector(x) for x in dfTest.text]","metadata":{}},{"cell_type":"markdown","source":"scaler = StandardScaler().fit(sampleTrain)\nrescaled_X_train = scaler.transform(sampleTrain)\nmodel = GradientBoostingRegressor(random_state=21, n_estimators=150,learning_rate=0.09) #subsample=0.5\nmodel.fit(rescaled_X_train, RankedData3.Rank) #normalized y\n\n# transform the validation dataset\n#rescaled_X_test = scaler.transform(x_test)\n#predictions = model.predict(rescaled_X_test)\n#print (mean_squared_error(y_test, predictions))","metadata":{}},{"cell_type":"markdown","source":"rescaled_X_test = scaler.transform(sampleTest)\npredictions = model.predict(rescaled_X_test)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test = [\" This article sucks woo woo wooooooo\"]\n#tfidfTest = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', encoding='latin-1', ngram_range=(1, 1),max_features=12000) #max_features=15000 stop_words='english' ,max_features=12000\n\n#featuresTest = tfidfTest.fit_transform(test[0]).toarray() \n#featuresTest = tfidfTrain.fit_transform(dfTest.text).toarray() \n#labelsTest = dfTest.comment_id \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"dataSubmission={}\n#dataSubmission['comment_id']=labelsTest\n#dataSubmission['score'] = y_pred\ndataSubmission['comment_id']=labelsTest\ndataSubmission['score'] = predictions","metadata":{}},{"cell_type":"code","source":"ds= pd.DataFrame.from_dict(dataSubmission)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T20:25:14.537979Z","iopub.execute_input":"2022-01-29T20:25:14.538378Z","iopub.status.idle":"2022-01-29T20:25:14.547157Z","shell.execute_reply.started":"2022-01-29T20:25:14.538349Z","shell.execute_reply":"2022-01-29T20:25:14.546151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T20:25:17.768813Z","iopub.execute_input":"2022-01-29T20:25:17.769119Z","iopub.status.idle":"2022-01-29T20:25:17.804393Z","shell.execute_reply.started":"2022-01-29T20:25:17.769085Z","shell.execute_reply":"2022-01-29T20:25:17.80343Z"},"trusted":true},"execution_count":null,"outputs":[]}]}