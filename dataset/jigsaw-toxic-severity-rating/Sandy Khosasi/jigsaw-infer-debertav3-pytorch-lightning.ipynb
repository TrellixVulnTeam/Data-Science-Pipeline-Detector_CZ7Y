{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Config","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/jigsaw-train-debertav3/model_cp","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:38:19.69412Z","iopub.execute_input":"2022-02-07T05:38:19.69461Z","iopub.status.idle":"2022-02-07T05:38:20.538161Z","shell.execute_reply.started":"2022-02-07T05:38:19.69452Z","shell.execute_reply":"2022-02-07T05:38:20.537377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/jigsaw-get-zsc-models/DeBERTa-v3-base-mnli-fever-anli'\nWEIGHT_PATH = '/kaggle/input/jigsaw-train-debertav3/model_cp/jigsaw-debertav3-epoch=01-val_loss=0.3983.ckpt'\nSEED = 42\n\nBATCH_SIZE = 16","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-05T19:14:17.196429Z","iopub.execute_input":"2022-02-05T19:14:17.197112Z","iopub.status.idle":"2022-02-05T19:14:17.228426Z","shell.execute_reply.started":"2022-02-05T19:14:17.197019Z","shell.execute_reply":"2022-02-05T19:14:17.227521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport pytorch_lightning as pl\nimport transformers\nimport itertools\n\nprint(torch.__version__)\nprint(pd.__version__)\nprint(transformers.__version__)\nprint(pl.__version__)\n\npl.seed_everything(SEED, workers=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T19:14:17.230311Z","iopub.execute_input":"2022-02-05T19:14:17.230891Z","iopub.status.idle":"2022-02-05T19:14:27.171546Z","shell.execute_reply.started":"2022-02-05T19:14:17.230845Z","shell.execute_reply":"2022-02-05T19:14:27.170496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer, AutoConfig\n\nm = AutoModel.from_pretrained(MODEL_PATH)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nconfig = AutoConfig.from_pretrained(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T19:14:27.173395Z","iopub.execute_input":"2022-02-05T19:14:27.174111Z","iopub.status.idle":"2022-02-05T19:14:35.380725Z","shell.execute_reply.started":"2022-02-05T19:14:27.174048Z","shell.execute_reply":"2022-02-05T19:14:35.379814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout, ContextPooler\n\nclass JigsawModel(pl.LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.deberta = model\n        self.dense = torch.nn.Sequential(\n            torch.nn.Linear(768, 768),\n            StableDropout(drop_prob=0.1), # original 0.0 ??\n            torch.nn.Linear(768, 1)\n        )\n        self.loss = torch.nn.BCEWithLogitsLoss()\n    \n    def forward(self, ids, mask, token_type_ids):\n        out = self.deberta(ids, attention_mask = mask, token_type_ids = token_type_ids)\n        out = out.last_hidden_state[:, 0]\n        out = self.dense(out)\n        out = torch.reshape(out, (-1, ))\n\n        return out\n\n    def configure_optimizers(self):\n        optimizer = transformers.AdamW(self.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n        scheduler = transformers.get_linear_schedule_with_warmup(\n            optimizer,\n            int(EPOCH * STEPS * WARMUP_RATIO),\n            int(EPOCH * STEPS * (1 - WARMUP_RATIO))\n        )\n    \n        return [optimizer], [scheduler]\n    \n    def training_step(self, batch, batch_idx):\n        ids = batch['ids']\n        mask = batch['mask']\n        token_type_ids = batch['token_type_ids']\n        label = batch['label']\n\n        out = self(ids, mask, token_type_ids)\n        loss = self.loss(out, label)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        ids = batch['ids']\n        mask = batch['mask']\n        token_type_ids = batch['token_type_ids']\n        label = batch['label']\n\n        out = self(ids, mask, token_type_ids)\n        loss = self.loss(out, label)\n        self.log(\"val_loss\", loss, prog_bar=True)\n        \n        return loss\n\n    def training_epoch_end(self, outputs):\n        # manually print loss on each epoch\n        losses = [d['loss'] for d in outputs]\n        avg_loss = torch.stack(losses).mean()\n        print(f'Epoch #{self.current_epoch} | loss: {avg_loss}')\n\n    def validation_epoch_end(self, outputs):\n        # manually print loss on each epoch\n        avg_loss = torch.stack(outputs).mean()\n        print(f'Epoch #{self.current_epoch} | val_loss: {avg_loss}')\n\n        \n    def predict_step(self, batch, batch_idx):\n        ids = batch['ids']\n        mask = batch['mask']\n        token_type_ids = batch['token_type_ids']\n\n        out = self(ids, mask, token_type_ids)\n        out = torch.sigmoid(out)\n\n        return out\n\n    \nmodel = JigsawModel(m)\nmodel.load_from_checkpoint(WEIGHT_PATH, model=m)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T19:14:35.38331Z","iopub.execute_input":"2022-02-05T19:14:35.383629Z","iopub.status.idle":"2022-02-05T19:14:51.065619Z","shell.execute_reply.started":"2022-02-05T19:14:35.383599Z","shell.execute_reply":"2022-02-05T19:14:51.064678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(torch.utils.data.Dataset):\n    def __init__(self, tokenizer, text, label=None):\n        self.tokenizer = tokenizer\n        self.text = text\n        self.label = label\n    \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        inputs = self.tokenizer(\n            self.text[idx],\n            truncation=True,\n            padding='max_length',\n            max_length=512\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        if self.label is None:\n            return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n            }            \n        else:\n            return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n                'label': torch.tensor(self.label[idx], dtype=torch.float)\n            }","metadata":{"execution":{"iopub.status.busy":"2022-02-05T19:14:51.067028Z","iopub.execute_input":"2022-02-05T19:14:51.068747Z","iopub.status.idle":"2022-02-05T19:14:51.079718Z","shell.execute_reply.started":"2022-02-05T19:14:51.068702Z","shell.execute_reply":"2022-02-05T19:14:51.078793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Predict","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ntest_ds = TextDataset(tokenizer, df_test['text'].tolist())\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T19:14:51.080939Z","iopub.execute_input":"2022-02-05T19:14:51.08188Z","iopub.status.idle":"2022-02-05T19:14:51.183663Z","shell.execute_reply.started":"2022-02-05T19:14:51.081831Z","shell.execute_reply":"2022-02-05T19:14:51.182676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n    gpus=1,\n    precision=16\n)\n\ny_pred = trainer.predict(model, test_dl)\ny_pred = [t.numpy() for t in y_pred]\ny_pred = list(itertools.chain(*y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T19:14:51.185415Z","iopub.execute_input":"2022-02-05T19:14:51.18606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission = df_test.copy()\ndel df_submission['text']\ndf_submission['score'] = y_pred\ndf_submission.to_csv('submission.csv', index=False)\ndf_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}