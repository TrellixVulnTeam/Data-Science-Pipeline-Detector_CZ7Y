{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-15T15:14:28.464471Z","iopub.execute_input":"2022-01-15T15:14:28.46505Z","iopub.status.idle":"2022-01-15T15:14:28.49585Z","shell.execute_reply.started":"2022-01-15T15:14:28.464904Z","shell.execute_reply":"2022-01-15T15:14:28.494269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/classification-data/train.csv')\nprint(df.shape)\n\n#sum toxicity\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T17:06:29.440588Z","iopub.execute_input":"2022-01-15T17:06:29.441012Z","iopub.status.idle":"2022-01-15T17:06:29.533513Z","shell.execute_reply.started":"2022-01-15T17:06:29.440913Z","shell.execute_reply":"2022-01-15T17:06:29.532542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic = []\nfor l in df.y:\n    if l == 0:\n        toxic.append(0)\n    else:\n        toxic.append(1)\n\nprint(len(df))\ndf['toxic']= toxic","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:14:31.023432Z","iopub.execute_input":"2022-01-15T15:14:31.023851Z","iopub.status.idle":"2022-01-15T15:14:31.181529Z","shell.execute_reply.started":"2022-01-15T15:14:31.023802Z","shell.execute_reply":"2022-01-15T15:14:31.180318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:14:31.184943Z","iopub.execute_input":"2022-01-15T15:14:31.185247Z","iopub.status.idle":"2022-01-15T15:14:31.199412Z","shell.execute_reply.started":"2022-01-15T15:14:31.185204Z","shell.execute_reply":"2022-01-15T15:14:31.197983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get rid of punctuation\nimport re\ndf['text'] = df['text'].str.lower()\ndf['text']  = df['text'].astype(str)\ndf['text'] = df['text'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\ndf['text'] = df['text'].str.replace('nan','')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:14:31.201257Z","iopub.execute_input":"2022-01-15T15:14:31.201611Z","iopub.status.idle":"2022-01-15T15:14:38.532871Z","shell.execute_reply.started":"2022-01-15T15:14:31.201564Z","shell.execute_reply":"2022-01-15T15:14:38.532062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import word_tokenize\n#tokenize\ntokens = [word_tokenize(sentence) for sentence in df.text]\ndf['tokens'] = tokens ","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:14:38.534156Z","iopub.execute_input":"2022-01-15T15:14:38.534381Z","iopub.status.idle":"2022-01-15T15:16:33.82365Z","shell.execute_reply.started":"2022-01-15T15:14:38.534355Z","shell.execute_reply":"2022-01-15T15:16:33.822456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim\nfrom gensim.models import KeyedVectors\nfrom gensim.models import Word2Vec\n#train a word2vec model on all of the data\ndef word2vec(sentences):\n    model = Word2Vec(sentences=sentences,  window=5, min_count=1)\n    model.init_sims(replace=True)\n    return(model)\nmodel = word2vec(df['tokens'])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:16:33.825028Z","iopub.execute_input":"2022-01-15T15:16:33.825294Z","iopub.status.idle":"2022-01-15T15:17:44.829646Z","shell.execute_reply.started":"2022-01-15T15:16:33.825261Z","shell.execute_reply":"2022-01-15T15:17:44.828645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#similarity?\nmodel.wv.most_similar(positive=[\"fuck\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:44.831231Z","iopub.execute_input":"2022-01-15T15:17:44.83155Z","iopub.status.idle":"2022-01-15T15:17:44.855816Z","shell.execute_reply.started":"2022-01-15T15:17:44.831507Z","shell.execute_reply":"2022-01-15T15:17:44.854828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.wv.most_similar(positive=[\"nazi\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:44.857969Z","iopub.execute_input":"2022-01-15T15:17:44.858781Z","iopub.status.idle":"2022-01-15T15:17:44.882862Z","shell.execute_reply.started":"2022-01-15T15:17:44.858722Z","shell.execute_reply":"2022-01-15T15:17:44.881843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.wv.most_similar(positive=[\"comment\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:44.890307Z","iopub.execute_input":"2022-01-15T15:17:44.891208Z","iopub.status.idle":"2022-01-15T15:17:44.911978Z","shell.execute_reply.started":"2022-01-15T15:17:44.891133Z","shell.execute_reply":"2022-01-15T15:17:44.909677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[df['y'] != 0])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:44.914466Z","iopub.execute_input":"2022-01-15T15:17:44.915328Z","iopub.status.idle":"2022-01-15T15:17:44.965182Z","shell.execute_reply.started":"2022-01-15T15:17:44.915263Z","shell.execute_reply":"2022-01-15T15:17:44.964115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[df['y'] == 0])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:44.967704Z","iopub.execute_input":"2022-01-15T15:17:44.968489Z","iopub.status.idle":"2022-01-15T15:17:45.010506Z","shell.execute_reply.started":"2022-01-15T15:17:44.968429Z","shell.execute_reply":"2022-01-15T15:17:45.009137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_zero = df[df['y'] == 0].sample(16000)\ndf = df[df['y']!=0].reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:45.016924Z","iopub.execute_input":"2022-01-15T15:17:45.017653Z","iopub.status.idle":"2022-01-15T15:17:45.055532Z","shell.execute_reply.started":"2022-01-15T15:17:45.017595Z","shell.execute_reply":"2022-01-15T15:17:45.054662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df,df_zero])\ndf['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:45.057056Z","iopub.execute_input":"2022-01-15T15:17:45.057958Z","iopub.status.idle":"2022-01-15T15:17:45.07581Z","shell.execute_reply.started":"2022-01-15T15:17:45.05791Z","shell.execute_reply":"2022-01-15T15:17:45.07465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\ndf = shuffle(df).reset_index()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:45.077019Z","iopub.execute_input":"2022-01-15T15:17:45.077255Z","iopub.status.idle":"2022-01-15T15:17:45.12092Z","shell.execute_reply.started":"2022-01-15T15:17:45.077227Z","shell.execute_reply":"2022-01-15T15:17:45.120245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nall_training_words = [word for tokens in df[\"tokens\"] for word in tokens]\ntraining_sentence_lengths = [len(tokens) for tokens in df[\"tokens\"]]\nvocab = sorted(list(set(all_training_words)))\n\ntokenizer = Tokenizer(num_words=len(vocab), lower=True, char_level=False)\ntokenizer.fit_on_texts(df[\"tokens\"].tolist())\ntraining_sequences = tokenizer.texts_to_sequences(df[\"tokens\"].tolist())\nimport pickle\nwith open('tokenizer.pk', 'wb') as fout:\n        pickle.dump(tokenizer, fout)\n\ntrain_word_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(train_word_index))\nprint(\"Max sentence length is %s\" % max(training_sentence_lengths))","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:45.122232Z","iopub.execute_input":"2022-01-15T15:17:45.122942Z","iopub.status.idle":"2022-01-15T15:17:55.224914Z","shell.execute_reply.started":"2022-01-15T15:17:45.122899Z","shell.execute_reply":"2022-01-15T15:17:55.223722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.hist(training_sentence_lengths,bins = 50)\nplt.yscale('log')\nplt.xlabel('Length of comment in words')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:55.226399Z","iopub.execute_input":"2022-01-15T15:17:55.226743Z","iopub.status.idle":"2022-01-15T15:17:56.827047Z","shell.execute_reply.started":"2022-01-15T15:17:55.226709Z","shell.execute_reply":"2022-01-15T15:17:56.825898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\ntrain_rnn_data = pad_sequences(training_sequences, maxlen=50)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:56.828798Z","iopub.execute_input":"2022-01-15T15:17:56.829144Z","iopub.status.idle":"2022-01-15T15:17:57.260814Z","shell.execute_reply.started":"2022-01-15T15:17:56.829098Z","shell.execute_reply":"2022-01-15T15:17:57.259688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embedding_weights = np.zeros((len(train_word_index)+1, 100))\nfor word,index in train_word_index.items():\n    try:\n        train_embedding_weights[index,:] = model.wv[word]\n    except:\n        train_embedding_weights[index,:] = np.random.rand(100)\nprint(train_embedding_weights.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:57.262154Z","iopub.execute_input":"2022-01-15T15:17:57.262394Z","iopub.status.idle":"2022-01-15T15:17:57.573305Z","shell.execute_reply.started":"2022-01-15T15:17:57.262368Z","shell.execute_reply":"2022-01-15T15:17:57.572247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recurrent_nn(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n    \n    embedding_layer = Embedding(num_words,\n                            embedding_dim,\n                            weights=[embeddings],\n                            input_length=max_sequence_length,\n                            trainable=False)\n    \n    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n    embedded_sequences = embedding_layer(sequence_input)\n\n\n    lstm = LSTM(128)(embedded_sequences)\n    x = Dense(128, activation='relu')(lstm)\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.1)(x)\n\n    preds = Dense(labels_index, activation='sigmoid')(x)\n    model = Model(sequence_input, preds)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['acc'])\n    model.summary()\n    return model\nprint('done')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:17:57.574619Z","iopub.execute_input":"2022-01-15T15:17:57.574913Z","iopub.status.idle":"2022-01-15T15:17:57.585331Z","shell.execute_reply.started":"2022-01-15T15:17:57.574827Z","shell.execute_reply":"2022-01-15T15:17:57.584033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Embedding\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Model\n\n#let's classify as toxic or not\ny_train = df['toxic'].values\nx_train = train_rnn_data\n\nmodel = recurrent_nn(train_embedding_weights, 50, len(train_word_index)+1, 100, \n                    1)\nprint('training model....')\n\nnum_epochs = 8\nbatch_size = 64\nhist = model.fit(x_train, y_train, epochs=num_epochs, validation_split=0.1, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:48:46.755134Z","iopub.execute_input":"2022-01-15T15:48:46.755695Z","iopub.status.idle":"2022-01-15T16:02:14.877969Z","shell.execute_reply.started":"2022-01-15T15:48:46.755653Z","shell.execute_reply":"2022-01-15T16:02:14.877211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_val","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:20:24.438319Z","iopub.execute_input":"2022-01-15T15:20:24.438566Z","iopub.status.idle":"2022-01-15T15:20:25.02916Z","shell.execute_reply.started":"2022-01-15T15:20:24.438535Z","shell.execute_reply":"2022-01-15T15:20:25.028239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef correct(col):\n    df_val[col] = df_val[col].str.lower()\n    df_val[col]  =df_val[col].astype(str)\n    df_val[col] = df_val[col].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n    df_val[col] = df_val[col].str.replace('nan','')\n    return(list(df_val[col]))","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:20:25.030722Z","iopub.execute_input":"2022-01-15T15:20:25.031058Z","iopub.status.idle":"2022-01-15T15:20:25.038084Z","shell.execute_reply.started":"2022-01-15T15:20:25.031013Z","shell.execute_reply":"2022-01-15T15:20:25.037129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['less_toxic'] = correct('less_toxic')\ndf_val['more_toxic'] = correct('more_toxic')\ndf_val['less_tokens'] = [word_tokenize(sentence) for sentence in df_val.less_toxic]\ndf_val['more_tokens'] = [word_tokenize(sentence) for sentence in df_val.more_toxic]\ndf_val","metadata":{"execution":{"iopub.status.busy":"2022-01-15T15:20:25.039622Z","iopub.execute_input":"2022-01-15T15:20:25.039949Z","iopub.status.idle":"2022-01-15T15:21:13.457127Z","shell.execute_reply.started":"2022-01-15T15:20:25.039905Z","shell.execute_reply":"2022-01-15T15:21:13.456266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_word_index = tokenizer.word_index\ntraining_sequences = tokenizer.texts_to_sequences(df_val[\"less_tokens\"].tolist())\ntest_less = pad_sequences(training_sequences, maxlen=50)\nless_pred = model.predict(test_less, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:02:23.61267Z","iopub.execute_input":"2022-01-15T16:02:23.613488Z","iopub.status.idle":"2022-01-15T16:02:53.046528Z","shell.execute_reply.started":"2022-01-15T16:02:23.613441Z","shell.execute_reply":"2022-01-15T16:02:53.045762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_word_index = tokenizer.word_index\ntraining_sequences = tokenizer.texts_to_sequences(df_val[\"more_tokens\"].tolist())\ntest_more = pad_sequences(training_sequences, maxlen=50)\nmore_pred = model.predict(test_more, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:02:54.788123Z","iopub.execute_input":"2022-01-15T16:02:54.789029Z","iopub.status.idle":"2022-01-15T16:03:25.167053Z","shell.execute_reply.started":"2022-01-15T16:02:54.788984Z","shell.execute_reply":"2022-01-15T16:03:25.166093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['less_pred'] = less_pred\ndf_val['more_pred'] = more_pred\ndf_val","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:03:26.924717Z","iopub.execute_input":"2022-01-15T16:03:26.924997Z","iopub.status.idle":"2022-01-15T16:03:26.960332Z","shell.execute_reply.started":"2022-01-15T16:03:26.924964Z","shell.execute_reply":"2022-01-15T16:03:26.959237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_val[df_val['more_pred']>df_val['less_pred']])/(len(df_val[df_val['more_pred']<df_val['less_pred']])+len(df_val[df_val['more_pred']>df_val['less_pred']]))","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:03:31.438131Z","iopub.execute_input":"2022-01-15T16:03:31.439156Z","iopub.status.idle":"2022-01-15T16:03:31.460019Z","shell.execute_reply.started":"2022-01-15T16:03:31.439105Z","shell.execute_reply":"2022-01-15T16:03:31.458872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_score = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nto_score","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:03:39.284035Z","iopub.execute_input":"2022-01-15T16:03:39.284388Z","iopub.status.idle":"2022-01-15T16:03:39.358655Z","shell.execute_reply.started":"2022-01-15T16:03:39.284344Z","shell.execute_reply":"2022-01-15T16:03:39.35796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_score['text'] = to_score['text'].str.lower()\nto_score['text']  =to_score['text'].astype(str)\nto_score['text'] = to_score['text'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\nto_score['text'] = to_score['text'].str.replace('nan','')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:03:41.913689Z","iopub.execute_input":"2022-01-15T16:03:41.914413Z","iopub.status.idle":"2022-01-15T16:03:42.332297Z","shell.execute_reply.started":"2022-01-15T16:03:41.914358Z","shell.execute_reply":"2022-01-15T16:03:42.33108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_score['tokens'] = [word_tokenize(sentence) for sentence in to_score.text]\ntrain_word_index = tokenizer.word_index\ntraining_sequences = tokenizer.texts_to_sequences(to_score[\"tokens\"].tolist())\ntest_seq = pad_sequences(training_sequences, maxlen=50)\npred = model.predict(test_seq, batch_size=512, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:03:48.594499Z","iopub.execute_input":"2022-01-15T16:03:48.59503Z","iopub.status.idle":"2022-01-15T16:03:56.602608Z","shell.execute_reply.started":"2022-01-15T16:03:48.594994Z","shell.execute_reply":"2022-01-15T16:03:56.60186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_score['score'] = pred\nto_score","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:03:58.494161Z","iopub.execute_input":"2022-01-15T16:03:58.494672Z","iopub.status.idle":"2022-01-15T16:03:58.516961Z","shell.execute_reply.started":"2022-01-15T16:03:58.494617Z","shell.execute_reply":"2022-01-15T16:03:58.515817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_score[['comment_id','score']].to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T16:04:04.607823Z","iopub.execute_input":"2022-01-15T16:04:04.608104Z","iopub.status.idle":"2022-01-15T16:04:04.644473Z","shell.execute_reply.started":"2022-01-15T16:04:04.608073Z","shell.execute_reply":"2022-01-15T16:04:04.643749Z"},"trusted":true},"execution_count":null,"outputs":[]}]}