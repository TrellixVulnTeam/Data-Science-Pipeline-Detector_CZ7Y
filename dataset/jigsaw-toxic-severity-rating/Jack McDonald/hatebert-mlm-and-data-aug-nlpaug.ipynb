{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nlpaug","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-22T15:24:10.244189Z","iopub.execute_input":"2021-11-22T15:24:10.244529Z","iopub.status.idle":"2021-11-22T15:24:21.414486Z","shell.execute_reply.started":"2021-11-22T15:24:10.244482Z","shell.execute_reply":"2021-11-22T15:24:21.413578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nimport nlpaug.augmenter.sentence as nas\nimport nlpaug.flow as nafc\nfrom nlpaug.util import Action\n\nfrom transformers import (AutoModel, \n                          AutoModelForMaskedLM,\n                          AutoTokenizer,\n                          AutoConfig,\n                          AdamW,\n                          LineByLineTextDataset,\n                          DataCollatorForLanguageModeling,\n                          Trainer,\n                          TrainingArguments)\n\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nimport warnings, os, gc, random, re \nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:21.417161Z","iopub.execute_input":"2021-11-22T15:24:21.417841Z","iopub.status.idle":"2021-11-22T15:24:32.685954Z","shell.execute_reply.started":"2021-11-22T15:24:21.417801Z","shell.execute_reply":"2021-11-22T15:24:32.684851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:32.691638Z","iopub.execute_input":"2021-11-22T15:24:32.691945Z","iopub.status.idle":"2021-11-22T15:24:32.701952Z","shell.execute_reply.started":"2021-11-22T15:24:32.691904Z","shell.execute_reply":"2021-11-22T15:24:32.701348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntest_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:32.702935Z","iopub.execute_input":"2021-11-22T15:24:32.70367Z","iopub.status.idle":"2021-11-22T15:24:33.369302Z","shell.execute_reply.started":"2021-11-22T15:24:32.703635Z","shell.execute_reply":"2021-11-22T15:24:33.368503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:33.371176Z","iopub.execute_input":"2021-11-22T15:24:33.371488Z","iopub.status.idle":"2021-11-22T15:24:33.391597Z","shell.execute_reply.started":"2021-11-22T15:24:33.371447Z","shell.execute_reply":"2021-11-22T15:24:33.390669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing and Cleaning\nHere we concatenate all the text data and remove any duplicate rows.  \nWe also clean some noise and punctuation from the input data  \n`\\n` characters are removed when cleaning, which is important when using `LineByLineTextDataset`","metadata":{}},{"cell_type":"code","source":"pretrain_text = pd.concat([df.less_toxic, df.more_toxic, test_df.text])\npretrain_text.drop_duplicates(inplace = True)\npretrain_text.reset_index(drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:33.392952Z","iopub.execute_input":"2021-11-22T15:24:33.39327Z","iopub.status.idle":"2021-11-22T15:24:33.427375Z","shell.execute_reply.started":"2021-11-22T15:24:33.393229Z","shell.execute_reply":"2021-11-22T15:24:33.426438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(data):\n    # Clean some punctutations\n    data = data.str.replace('\\n', ' ')\n    data = data.str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters\n    data = data.str.replace(r'(\")\\1+',r'\\1')    \n    data = data.str.replace(r'([*!?\\'])\\1\\1+\\B',r'\\1\\1')    \n    data = data.str.replace(r'(\\w)\\1\\1+\\B',r'\\1\\1')    \n    data = data.str.replace(r'(\\w)\\1+\\b',r'\\1').str.strip()\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:33.921465Z","iopub.execute_input":"2021-11-22T15:24:33.921749Z","iopub.status.idle":"2021-11-22T15:24:33.927894Z","shell.execute_reply.started":"2021-11-22T15:24:33.921721Z","shell.execute_reply":"2021-11-22T15:24:33.927273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrain_text = clean(pretrain_text)\n\nwith open('text.txt','w') as f:\n    text  = '\\n'.join(pretrain_text.tolist())\n    f.write(text)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:24:38.053407Z","iopub.execute_input":"2021-11-22T15:24:38.053813Z","iopub.status.idle":"2021-11-22T15:24:44.56071Z","shell.execute_reply.started":"2021-11-22T15:24:38.053784Z","shell.execute_reply":"2021-11-22T15:24:44.560085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MLM Pretraining\nWe'll perform MLM pretraining on our transformer model.  \nThis usually improves downstream performance when fine-tuning/ensembling.  \nWe'll also explore using the pretrained model for contextual data augmentation  \n\nThis code was based on maunish's excellent CommonLit MLM notebook:    \nhttps://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain","metadata":{}},{"cell_type":"code","source":"class cfg:\n    model_name = 'GroNLP/hateBERT'\n    epochs = 3 # adjust\n    learning_rate = 5e-05\n    train_batch_size = 32\n    eval_batch_size = 32\n    eval_steps = 200\n    block_size = 256\n    gradient_accum_steps = 1\n    mlm_prob = 0.15\n    fp16 = True\n    output_dir = './hatebert_mlm'","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:26:01.332433Z","iopub.execute_input":"2021-11-22T15:26:01.332735Z","iopub.status.idle":"2021-11-22T15:26:01.337922Z","shell.execute_reply.started":"2021-11-22T15:26:01.332703Z","shell.execute_reply":"2021-11-22T15:26:01.337318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMaskedLM.from_pretrained(cfg.model_name)\ntokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\ntokenizer.save_pretrained(cfg.output_dir);","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:26:07.677301Z","iopub.execute_input":"2021-11-22T15:26:07.677735Z","iopub.status.idle":"2021-11-22T15:26:34.797125Z","shell.execute_reply.started":"2021-11-22T15:26:07.677703Z","shell.execute_reply":"2021-11-22T15:26:34.796258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sequences are truncated to block size\ntrain_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"text.txt\",\n    block_size=cfg.block_size)\n\nvalid_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"text.txt\",\n    block_size=cfg.block_size)\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, \n    mlm=True, \n    mlm_probability=cfg.mlm_prob)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:26:34.799055Z","iopub.execute_input":"2021-11-22T15:26:34.799288Z","iopub.status.idle":"2021-11-22T15:26:40.160133Z","shell.execute_reply.started":"2021-11-22T15:26:34.799259Z","shell.execute_reply":"2021-11-22T15:26:40.159337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=cfg.output_dir+'_chk',\n    overwrite_output_dir=True,\n    num_train_epochs=cfg.epochs,\n    per_device_train_batch_size=cfg.train_batch_size,\n    per_device_eval_batch_size=cfg.eval_batch_size,\n    learning_rate=cfg.learning_rate,\n    gradient_accumulation_steps=cfg.gradient_accum_steps,\n    fp16=cfg.fp16,\n    eval_steps=cfg.eval_steps,\n    evaluation_strategy='steps',\n    save_total_limit=2,\n    metric_for_best_model='eval_loss',\n    greater_is_better=False,\n    load_best_model_at_end=True,\n    prediction_loss_only=True,\n    report_to='none')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:26:40.161618Z","iopub.execute_input":"2021-11-22T15:26:40.161833Z","iopub.status.idle":"2021-11-22T15:26:40.618038Z","shell.execute_reply.started":"2021-11-22T15:26:40.161807Z","shell.execute_reply":"2021-11-22T15:26:40.616893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(cfg.output_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n`nlpaug` helps with generating synthetic data for augmentating NLP pipelines.  \nThe library also makes it simple to use context-aware augmentations such as MLM for sentence augmentation  \nWe'll go through some augmentation methods, before testing out our pretrained `HateBert` model  \n\nA list of supported augmentation strategies can be found in the documentation:  \nhttps://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb","metadata":{}},{"cell_type":"markdown","source":"## Synonym Replacement","metadata":{}},{"cell_type":"code","source":"example_text = pretrain_text[7500]\naug = naw.SynonymAug(aug_src='wordnet')\naugmented_text = aug.augment(example_text)\n\nprint(\"Original:\")\nprint(example_text)\nprint('\\n')\nprint(\"Augmented Text:\")\nprint(augmented_text)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:30:43.735527Z","iopub.execute_input":"2021-11-22T15:30:43.735802Z","iopub.status.idle":"2021-11-22T15:30:43.758872Z","shell.execute_reply.started":"2021-11-22T15:30:43.735771Z","shell.execute_reply":"2021-11-22T15:30:43.75817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Back Translation","metadata":{}},{"cell_type":"code","source":"back_translation_aug = naw.BackTranslationAug(\n    from_model_name='facebook/wmt19-en-de', \n    to_model_name='facebook/wmt19-de-en')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:27:39.39666Z","iopub.execute_input":"2021-11-22T15:27:39.397322Z","iopub.status.idle":"2021-11-22T15:29:35.781696Z","shell.execute_reply.started":"2021-11-22T15:27:39.397277Z","shell.execute_reply":"2021-11-22T15:29:35.780861Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_text = pretrain_text[200]\naugmented_text = back_translation_aug.augment(example_text)\n\nprint(\"Original:\")\nprint(example_text)\nprint('\\n')\nprint(\"Augmented Text:\")\nprint(augmented_text)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:29:35.783558Z","iopub.execute_input":"2021-11-22T15:29:35.784092Z","iopub.status.idle":"2021-11-22T15:30:43.73324Z","shell.execute_reply.started":"2021-11-22T15:29:35.78405Z","shell.execute_reply":"2021-11-22T15:30:43.732043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Contextual (Word Embeddings) Augmentation","metadata":{}},{"cell_type":"code","source":"# substitute is peforming MLM augmentation\naug = naw.ContextualWordEmbsAug(model_path=cfg.output_dir,\n                                action='substitute',\n                                aug_p=0.15,\n                                device='cuda')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:33:19.063713Z","iopub.execute_input":"2021-11-22T15:33:19.064175Z","iopub.status.idle":"2021-11-22T15:33:19.188338Z","shell.execute_reply.started":"2021-11-22T15:33:19.064135Z","shell.execute_reply":"2021-11-22T15:33:19.186753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_text = pretrain_text[7]\naugmented_text = aug.augment(example_text)\n\nprint(\"Original:\")\nprint(example_text)\nprint('\\n')\nprint(\"Augmented Text:\")\nprint(augmented_text)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:33:26.085449Z","iopub.execute_input":"2021-11-22T15:33:26.085741Z","iopub.status.idle":"2021-11-22T15:33:26.100777Z","shell.execute_reply.started":"2021-11-22T15:33:26.08571Z","shell.execute_reply":"2021-11-22T15:33:26.099784Z"},"trusted":true},"execution_count":null,"outputs":[]}]}