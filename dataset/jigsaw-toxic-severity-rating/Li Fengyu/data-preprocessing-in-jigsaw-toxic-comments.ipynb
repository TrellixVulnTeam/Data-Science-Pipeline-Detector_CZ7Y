{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rate Severity of Toxic Comments: Preprocessing","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-07T15:24:37.901433Z","iopub.execute_input":"2022-02-07T15:24:37.902066Z","iopub.status.idle":"2022-02-07T15:24:37.915575Z","shell.execute_reply.started":"2022-02-07T15:24:37.902031Z","shell.execute_reply":"2022-02-07T15:24:37.914769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:38.138701Z","iopub.execute_input":"2022-02-07T15:24:38.139479Z","iopub.status.idle":"2022-02-07T15:24:39.414888Z","shell.execute_reply.started":"2022-02-07T15:24:38.139422Z","shell.execute_reply":"2022-02-07T15:24:39.41399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nprint(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:39.417035Z","iopub.execute_input":"2022-02-07T15:24:39.417304Z","iopub.status.idle":"2022-02-07T15:24:39.478294Z","shell.execute_reply.started":"2022-02-07T15:24:39.417272Z","shell.execute_reply":"2022-02-07T15:24:39.477484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_score = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in label_score:\n    train[category] = train[category] * label_score[category]\n\ntrain['severity'] = train.loc[:, 'toxic':'identity_hate'].sum(axis=1)\ncount = train.query('severity > 0').shape[0]\nnon_toxic = train[train['severity'] == 0].sample(n=count)\ntrain = pd.concat([train[train['severity'] > 0], non_toxic])\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:39.480265Z","iopub.execute_input":"2022-02-07T15:24:39.480607Z","iopub.status.idle":"2022-02-07T15:24:39.567816Z","shell.execute_reply.started":"2022-02-07T15:24:39.480563Z","shell.execute_reply":"2022-02-07T15:24:39.566892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n, bins, patches = plt.hist(train['severity'])\nplt.xlabel('severity')\nplt.ylabel('count')\nplt.title('Histogram of Severity')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:39.569289Z","iopub.execute_input":"2022-02-07T15:24:39.569575Z","iopub.status.idle":"2022-02-07T15:24:39.775797Z","shell.execute_reply.started":"2022-02-07T15:24:39.569539Z","shell.execute_reply":"2022-02-07T15:24:39.774741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis & Lemmatization - NLTK","metadata":{}},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nlemmatizer = WordNetLemmatizer()\nstop = stopwords.words('english')\ncopy = train['comment_text']\ncopy = copy.str.lower().str.replace(\"\\n\", \" \")\n# TODO: remove emojis / special characters\n\nfor i in range(len(copy)):\n    tempArr = []\n    for word in copy.iloc[i].split(' '):\n        if word.find(\"fuck\") != -1:\n            tempArr.append(\"fuck\")\n        elif word.find(\"shit\") != -1:\n            tempArr.append(\"shit\")\n        elif word.find(\"dick\") != -1:\n            tempArr.append(\"dick\")\n        elif word.find(\"bitch\") != -1:\n            tempArr.append(\"bitch\")\n        else:\n            tempArr.append(lemmatizer.lemmatize(word))\n    copy.iloc[i] = ' '.join(tempArr)\n    # del stopwords\n    copy.iloc[i] = ' '.join([word for word in copy.iloc[i].split(' ') if word not in stop])\n    \n    # punctuation are not deleted as they might represent emotions","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:39.778215Z","iopub.execute_input":"2022-02-07T15:24:39.778589Z","iopub.status.idle":"2022-02-07T15:24:56.568063Z","shell.execute_reply.started":"2022-02-07T15:24:39.778547Z","shell.execute_reply":"2022-02-07T15:24:56.567022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare = pd.DataFrame([copy,train['comment_text']])\ncompare = compare.transpose()\ncompare = compare.reset_index(drop=True)\ncompare.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:56.569435Z","iopub.execute_input":"2022-02-07T15:24:56.569738Z","iopub.status.idle":"2022-02-07T15:24:57.727516Z","shell.execute_reply.started":"2022-02-07T15:24:56.569705Z","shell.execute_reply":"2022-02-07T15:24:57.726461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vectorization","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\nvectorized = vectorizer.fit_transform(copy)\n# copy = 0 # clear space\n# compare = 0 # clear space\nvectorized = vectorized.toarray()\nvectorized = pd.DataFrame(vectorized)\nvectorized = vectorized.loc[:,vectorized.sum(axis=0)>50]\nvectorized.columns = range(len(vectorized.columns))\nvectorized","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:24:57.7287Z","iopub.execute_input":"2022-02-07T15:24:57.728953Z","iopub.status.idle":"2022-02-07T15:25:07.340815Z","shell.execute_reply.started":"2022-02-07T15:24:57.728923Z","shell.execute_reply":"2022-02-07T15:25:07.340174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = train.loc[:,'toxic':'identity_hate']\nscores = scores.reset_index(drop=True)\nscores.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:07.341891Z","iopub.execute_input":"2022-02-07T15:25:07.342239Z","iopub.status.idle":"2022-02-07T15:25:07.356424Z","shell.execute_reply.started":"2022-02-07T15:25:07.342209Z","shell.execute_reply":"2022-02-07T15:25:07.355827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorized = pd.concat([vectorized,train.loc[:,'toxic':'identity_hate'].reset_index(drop=True)], axis = 1)\nvectorized","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:07.357947Z","iopub.execute_input":"2022-02-07T15:25:07.358176Z","iopub.status.idle":"2022-02-07T15:25:08.174481Z","shell.execute_reply.started":"2022-02-07T15:25:07.358149Z","shell.execute_reply":"2022-02-07T15:25:08.173562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# TODO: make a for loop with all score categories\nX = vectorized\ny = vectorized['toxic'] \nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:08.175917Z","iopub.execute_input":"2022-02-07T15:25:08.176142Z","iopub.status.idle":"2022-02-07T15:25:09.002382Z","shell.execute_reply.started":"2022-02-07T15:25:08.176115Z","shell.execute_reply":"2022-02-07T15:25:09.001214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:09.00388Z","iopub.execute_input":"2022-02-07T15:25:09.004196Z","iopub.status.idle":"2022-02-07T15:25:09.010165Z","shell.execute_reply.started":"2022-02-07T15:25:09.004153Z","shell.execute_reply":"2022-02-07T15:25:09.008994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unusually high score\nmodel = Ridge()\nmodel.fit(x_train, y_train)\nscore = [model, model.score(x_train, y_train), model.score(\n        x_test, y_test), abs(model.score(x_test, y_test) - model.score(x_train, y_train))]\nprint(pd.DataFrame(data=np.array([score]), columns=[\n          'Model', 'Train Set Score', 'Test Set Score', 'Generalization Error']))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:09.011503Z","iopub.execute_input":"2022-02-07T15:25:09.011884Z","iopub.status.idle":"2022-02-07T15:25:14.694498Z","shell.execute_reply.started":"2022-02-07T15:25:09.011847Z","shell.execute_reply":"2022-02-07T15:25:14.69359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cannot run because taking too much RAM \n# from sklearn.neighbors import KNeighborsRegressor\n# models = [KNeighborsRegressor(n_neighbors=10, weights='distance')]\n# result = []\n# for model in models:\n#     model.fit(x_train, y_train)\n#     score = [model, model.score(x_train, y_train), model.score(\n#         x_test, y_test), abs(model.score(x_test, y_test) - model.score(x_train, y_train))]\n#     result.append(score)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:14.695991Z","iopub.execute_input":"2022-02-07T15:25:14.6969Z","iopub.status.idle":"2022-02-07T15:25:14.702734Z","shell.execute_reply.started":"2022-02-07T15:25:14.696847Z","shell.execute_reply":"2022-02-07T15:25:14.701457Z"},"trusted":true},"execution_count":null,"outputs":[]}]}