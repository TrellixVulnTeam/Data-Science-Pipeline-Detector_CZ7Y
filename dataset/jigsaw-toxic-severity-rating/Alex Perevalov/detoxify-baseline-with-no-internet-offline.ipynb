{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Because notebook is not allowed to have intertet, I had to add this (copied from detoxify library):","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\n\nMODEL_URLS = {\n    \"original\": \"https://github.com/unitaryai/detoxify/releases/download/v0.1-alpha/toxic_original-c1212f89.ckpt\"\n}\n\nPRETRAINED_MODEL = None\n\n\ndef get_model_and_tokenizer(\n    model_type, model_name, tokenizer_name, num_classes, state_dict\n):\n    model_class = getattr(transformers, model_name)\n    model = model_class.from_pretrained(\n        pretrained_model_name_or_path=\"../input/get-huggingface-models/bert-base-uncased/\", # clone huggingface model via another online notebook\n        num_labels=num_classes,\n        state_dict=state_dict,\n        local_files_only=True\n    )\n    tokenizer = getattr(transformers, tokenizer_name).from_pretrained(\n        \"../input/get-huggingface-models/bert-base-uncased/\", # clone huggingface model via another online notebook\n        local_files_only=True,\n        model_max_length=512\n    )\n\n    return model, tokenizer\n\n\ndef load_checkpoint(model_type=\"original\", checkpoint=None, device='cpu'):\n    if checkpoint is None:\n        checkpoint_path = MODEL_URLS[model_type]\n        loaded = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=device)\n    else:\n        loaded = torch.load(checkpoint)\n        if \"config\" not in loaded or \"state_dict\" not in loaded:\n            raise ValueError(\n                \"Checkpoint needs to contain the config it was trained \\\n                    with as well as the state dict\"\n            )\n    class_names = loaded[\"config\"][\"dataset\"][\"args\"][\"classes\"]\n    # standardise class names between models\n    change_names = {\n        \"toxic\": \"toxicity\",\n        \"identity_hate\": \"identity_attack\",\n        \"severe_toxic\": \"severe_toxicity\",\n    }\n    class_names = [change_names.get(cl, cl) for cl in class_names]\n    model, tokenizer = get_model_and_tokenizer(\n        **loaded[\"config\"][\"arch\"][\"args\"], state_dict=loaded[\"state_dict\"]\n    )\n\n    return model, tokenizer, class_names\n\n\ndef load_model(model_type, checkpoint=None):\n    if checkpoint is None:\n        model, _, _ = load_checkpoint(model_type=model_type)\n    else:\n        model, _, _ = load_checkpoint(checkpoint=checkpoint)\n    return model\n\n\nclass Detoxify:\n    def __init__(self, model_type=\"original\", checkpoint=PRETRAINED_MODEL, device=\"cpu\"):\n        super(Detoxify, self).__init__()\n        self.model, self.tokenizer, self.class_names = load_checkpoint(\n            model_type=model_type, checkpoint=checkpoint, device=device\n        )\n        self.device = device\n        self.model.to(self.device)\n\n\n    @torch.no_grad()\n    def predict(self, text):\n        self.model.eval()\n        inputs = self.tokenizer(\n            text, return_tensors=\"pt\", truncation=True, padding=True\n        ).to(self.model.device)\n        out = self.model(**inputs)[0]\n        scores = torch.sigmoid(out).cpu().detach().numpy()\n        results = {}\n        for i, cla in enumerate(self.class_names):\n            results[cla] = (\n                scores[0][i]\n                if isinstance(text, str)\n                else [scores[ex_i][i].tolist() for ex_i in range(len(scores))]\n            )\n        return results","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:24:56.309936Z","iopub.execute_input":"2021-11-19T20:24:56.310313Z","iopub.status.idle":"2021-11-19T20:24:57.703722Z","shell.execute_reply.started":"2021-11-19T20:24:56.310206Z","shell.execute_reply":"2021-11-19T20:24:57.702952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make sure that all the dependencies match to what detoxify is requiring\n!pip install ../input/detoxifygithub18112021/ > /dev/null # include github repo of detoxify into the data","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:24:57.705529Z","iopub.execute_input":"2021-11-19T20:24:57.705766Z","iopub.status.idle":"2021-11-19T20:25:27.591508Z","shell.execute_reply.started":"2021-11-19T20:24:57.705733Z","shell.execute_reply":"2021-11-19T20:25:27.59067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load checkpoint of a required model\n!mkdir /root/.cache/torch\n!mkdir /root/.cache/torch/hub\n!mkdir /root/.cache/torch/hub/checkpoints\n!cp ../input/detoxifyoriginal/toxic_original-c1212f89.ckpt /root/.cache/torch/hub/checkpoints/toxic_original-c1212f89.ckpt","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:25:27.593109Z","iopub.execute_input":"2021-11-19T20:25:27.593388Z","iopub.status.idle":"2021-11-19T20:25:36.29799Z","shell.execute_reply.started":"2021-11-19T20:25:27.593349Z","shell.execute_reply":"2021-11-19T20:25:36.297081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now, actual code begins","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:25:36.30016Z","iopub.execute_input":"2021-11-19T20:25:36.300384Z","iopub.status.idle":"2021-11-19T20:25:36.966597Z","shell.execute_reply.started":"2021-11-19T20:25:36.300358Z","shell.execute_reply":"2021-11-19T20:25:36.965859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\nmodel = Detoxify('original', device='cuda')\nmodel.predict('I hate you')['severe_toxicity']","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:25:36.981641Z","iopub.execute_input":"2021-11-19T20:25:36.982183Z","iopub.status.idle":"2021-11-19T20:25:43.820076Z","shell.execute_reply.started":"2021-11-19T20:25:36.982145Z","shell.execute_reply":"2021-11-19T20:25:43.819361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments_to_score = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nsample_submission = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/sample_submission.csv\")\nvalidation_data = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:25:43.821418Z","iopub.execute_input":"2021-11-19T20:25:43.822011Z","iopub.status.idle":"2021-11-19T20:25:44.458978Z","shell.execute_reply.started":"2021-11-19T20:25:43.821972Z","shell.execute_reply":"2021-11-19T20:25:44.45818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new column \"score\" with the scores from the pre-trained model\ncomments_to_score['score'] = comments_to_score.text.apply(lambda x: model.predict(x)['severe_toxicity']).values","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:25:45.257636Z","iopub.execute_input":"2021-11-19T20:25:45.258171Z","iopub.status.idle":"2021-11-19T20:28:51.826877Z","shell.execute_reply.started":"2021-11-19T20:25:45.258059Z","shell.execute_reply":"2021-11-19T20:28:51.826136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.distplot(comments_to_score['score'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:28:51.828556Z","iopub.execute_input":"2021-11-19T20:28:51.828798Z","iopub.status.idle":"2021-11-19T20:28:52.173994Z","shell.execute_reply.started":"2021-11-19T20:28:51.828764Z","shell.execute_reply":"2021-11-19T20:28:52.173328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments_to_score[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T10:52:25.968605Z","iopub.execute_input":"2021-11-18T10:52:25.969373Z","iopub.status.idle":"2021-11-18T10:52:26.000314Z","shell.execute_reply.started":"2021-11-18T10:52:25.969337Z","shell.execute_reply":"2021-11-18T10:52:25.999709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"validation_data['score_less'] = validation_data.less_toxic.apply(lambda x: model.predict(x)['severe_toxicity']).values\nvalidation_data['score_more'] = validation_data.more_toxic.apply(lambda x: model.predict(x)['severe_toxicity']).values","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:57:00.344219Z","iopub.execute_input":"2021-11-19T19:57:00.344822Z","iopub.status.idle":"2021-11-19T20:09:23.572861Z","shell.execute_reply.started":"2021-11-19T19:57:00.344785Z","shell.execute_reply":"2021-11-19T20:09:23.572066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average Agreement with Annotators -- score by organizers\nranking_results = (np.array(validation_data.score_less.values) < np.array(validation_data.score_more.values))\nranking_results.mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:09:23.574613Z","iopub.execute_input":"2021-11-19T20:09:23.574866Z","iopub.status.idle":"2021-11-19T20:09:23.581544Z","shell.execute_reply.started":"2021-11-19T20:09:23.574833Z","shell.execute_reply":"2021-11-19T20:09:23.580837Z"},"trusted":true},"execution_count":null,"outputs":[]}]}