{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 0.85+ score by ensemble of simple TF-Idf and Ridge regression\n\n### Ensemble of TfIdf - Ridge models using data from \n- Toxic competition\n- Toxic CLEANED competition\n- Ruddit toxic data\n- Toxic multilingual competition\n\n### Analysis of bad predictions\n","metadata":{}},{"cell_type":"markdown","source":"#### Some cool starters notebooks : \n- https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768\n- https://www.kaggle.com/steubk/jrsotc-ridgeregression-ensemble-of-3","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nimport re \nimport scipy\nfrom scipy import sparse\nimport gc \n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:46.739299Z","iopub.execute_input":"2021-11-24T17:13:46.740088Z","iopub.status.idle":"2021-11-24T17:13:47.95768Z","shell.execute_reply.started":"2021-11-24T17:13:46.739977Z","shell.execute_reply":"2021-11-24T17:13:47.956793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def timer(func):\n    def wrapper(*args, **kws):\n        st = time.time()\n        res = func(*args, **kws)\n        et = time.time()\n        tt = (et-st)/60\n        print(f'Time taken is {tt:.2f} mins')\n        return res\n    return wrapper\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:47.959211Z","iopub.execute_input":"2021-11-24T17:13:47.959458Z","iopub.status.idle":"2021-11-24T17:13:47.965663Z","shell.execute_reply.started":"2021-11-24T17:13:47.959427Z","shell.execute_reply":"2021-11-24T17:13:47.964692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training data \n\n## Convert the label to SUM of all toxic labels (This might help with maintaining toxicity order of comments)","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")\ndf_test_l = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv\").replace(-1,0)\nprint(df_test.shape)\ndf_test = pd.merge(df_test, df_test_l, how=\"left\", on = \"id\")\ndf_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:48.842088Z","iopub.execute_input":"2021-11-24T17:13:48.842374Z","iopub.status.idle":"2021-11-24T17:13:51.147761Z","shell.execute_reply.started":"2021-11-24T17:13:48.842344Z","shell.execute_reply":"2021-11-24T17:13:51.14691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\nprint(df.shape)\ndf = pd.concat([df, df_test])\nprint(df.shape)\ndel df_test\n\nfor col in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n    print(f'****** {col} *******')\n    display(df.loc[df[col]==1,['comment_text',col]].sample(5))","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:51.62331Z","iopub.execute_input":"2021-11-24T17:13:51.623575Z","iopub.status.idle":"2021-11-24T17:13:53.469013Z","shell.execute_reply.started":"2021-11-24T17:13:51.623546Z","shell.execute_reply":"2021-11-24T17:13:53.468164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Give more weight to severe toxic \ndf['severe_toxic'] = df.severe_toxic * 2\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf['y'] = df['y']/df['y'].max()\n\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:53.969881Z","iopub.execute_input":"2021-11-24T17:13:53.970231Z","iopub.status.idle":"2021-11-24T17:13:54.045639Z","shell.execute_reply.started":"2021-11-24T17:13:53.970192Z","shell.execute_reply":"2021-11-24T17:13:54.044775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:54.393989Z","iopub.execute_input":"2021-11-24T17:13:54.394575Z","iopub.status.idle":"2021-11-24T17:13:54.409621Z","shell.execute_reply.started":"2021-11-24T17:13:54.394523Z","shell.execute_reply":"2021-11-24T17:13:54.408591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load validation data & filter for overlapping sentences","metadata":{}},{"cell_type":"code","source":"# Validation data \n\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\nprint(df_val.shape)\n\n\n# Find cases already present in toxic data\n\ndf_val = pd.merge(df_val, df.loc[:,['text']], \n                  left_on = 'less_toxic', \n                  right_on = 'text', how='left')\n\ndf_val = pd.merge(df_val, df.loc[:,['text']], \n                  left_on = 'more_toxic', \n                  right_on = 'text', how='left')\n\n# Removing those cases\ndf_val = df_val[(~df_val.text_x.isna()) | (~df_val.text_y.isna())][['worker', 'less_toxic', 'more_toxic']]\ndf_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:54.974693Z","iopub.execute_input":"2021-11-24T17:13:54.974996Z","iopub.status.idle":"2021-11-24T17:13:55.892069Z","shell.execute_reply.started":"2021-11-24T17:13:54.974967Z","shell.execute_reply":"2021-11-24T17:13:55.891124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create 3 versions of the TOXIC data","metadata":{}},{"cell_type":"code","source":"n_folds = 2\n\nfrac_1 = 0.7\nfrac_1_factor = 1.3\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:55.894154Z","iopub.execute_input":"2021-11-24T17:13:55.894518Z","iopub.status.idle":"2021-11-24T17:13:55.898999Z","shell.execute_reply.started":"2021-11-24T17:13:55.894475Z","shell.execute_reply":"2021-11-24T17:13:55.897971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@timer\ndef create_folds():\n    for fld in range(n_folds):\n        print(f'Fold: {fld}')\n        tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                            df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n                                                random_state = 10*(fld+1))], axis=0).sample(frac=1, random_state = 10*(fld+1))\n\n        tmp_df.to_csv(f'/kaggle/working/df_fld{fld}.csv', index=False)\n        print(tmp_df.shape)\n        print(tmp_df['y'].value_counts())\n\n\ncreate_folds()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:13:55.900596Z","iopub.execute_input":"2021-11-24T17:13:55.900923Z","iopub.status.idle":"2021-11-24T17:13:57.279554Z","shell.execute_reply.started":"2021-11-24T17:13:55.900878Z","shell.execute_reply":"2021-11-24T17:13:57.277752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 3 versions of __clean__ TOXIC data","metadata":{}},{"cell_type":"code","source":"@timer\ndef clean(data, col):\n\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    # Remove ip address\n    data[col] = data[col].str.replace(r'(([0-9]+\\.){2,}[0-9]+)',' ')\n    \n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')\n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([!?\\']+)',r' \\1 ')    \n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:14:26.015151Z","iopub.execute_input":"2021-11-24T17:14:26.01547Z","iopub.status.idle":"2021-11-24T17:14:26.024019Z","shell.execute_reply.started":"2021-11-24T17:14:26.015433Z","shell.execute_reply":"2021-11-24T17:14:26.023157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test clean function\ntest_clean_df = pd.DataFrame({\"text\":\n                              [\"heyy\\n\\nkkdsfj\",\n                               \"hi   how/are/you ???\",\n                               \"hey?????\",\n                               \"hey????? 18.98.333.20 18.98.\",\n                               \"noooo!!!!!!!!!   comeone !! \",\n                              \"cooooooooool     brooooooooooo  coool brooo\",\n                              \"naaaahhhhhhh\"]})\ndisplay(test_clean_df)\nclean(test_clean_df,'text')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:14:29.010966Z","iopub.execute_input":"2021-11-24T17:14:29.011357Z","iopub.status.idle":"2021-11-24T17:14:29.036923Z","shell.execute_reply.started":"2021-11-24T17:14:29.01131Z","shell.execute_reply":"2021-11-24T17:14:29.036238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = clean(df,'text')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:14:30.706861Z","iopub.execute_input":"2021-11-24T17:14:30.70714Z","iopub.status.idle":"2021-11-24T17:16:25.923139Z","shell.execute_reply.started":"2021-11-24T17:14:30.707111Z","shell.execute_reply":"2021-11-24T17:16:25.922342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n                                            random_state = 10*(fld+1))], axis=0).sample(frac=1, random_state = 10*(fld+1))\n\n    tmp_df.to_csv(f'/kaggle/working/df_clean_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:16:25.924468Z","iopub.execute_input":"2021-11-24T17:16:25.925033Z","iopub.status.idle":"2021-11-24T17:16:27.363749Z","shell.execute_reply.started":"2021-11-24T17:16:25.924989Z","shell.execute_reply":"2021-11-24T17:16:27.362796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df,tmp_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:16:27.365221Z","iopub.execute_input":"2021-11-24T17:16:27.365748Z","iopub.status.idle":"2021-11-24T17:16:27.535363Z","shell.execute_reply.started":"2021-11-24T17:16:27.365698Z","shell.execute_reply":"2021-11-24T17:16:27.534365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read toxic Ruddit data","metadata":{}},{"cell_type":"code","source":"df_ = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(df_.shape)\n\ndf_ = df_[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n                                                                'offensiveness_score':'y'})\n\ndf_['y'] = (df_['y'] - df_.y.min()) / (df_.y.max() - df_.y.min()) \ndf_.y.hist()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:16:27.537961Z","iopub.execute_input":"2021-11-24T17:16:27.53822Z","iopub.status.idle":"2021-11-24T17:16:27.853087Z","shell.execute_reply.started":"2021-11-24T17:16:27.538189Z","shell.execute_reply":"2021-11-24T17:16:27.852269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 3 versions of RUDDIT data","metadata":{}},{"cell_type":"code","source":"\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = df_.sample(frac=frac_1, random_state = 10*(fld+1))\n    tmp_df.to_csv(f'/kaggle/working/df2_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:16:27.854396Z","iopub.execute_input":"2021-11-24T17:16:27.854628Z","iopub.status.idle":"2021-11-24T17:16:27.968471Z","shell.execute_reply.started":"2021-11-24T17:16:27.854598Z","shell.execute_reply":"2021-11-24T17:16:27.967433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del tmp_df, df_; \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:16:27.970963Z","iopub.execute_input":"2021-11-24T17:16:27.971494Z","iopub.status.idle":"2021-11-24T17:16:28.090927Z","shell.execute_reply.started":"2021-11-24T17:16:27.971446Z","shell.execute_reply":"2021-11-24T17:16:28.090076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Jigsaw multilingual data CLEANED","metadata":{}},{"cell_type":"code","source":"dfm = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\nprint(dfm.shape)\n\ndfm = clean(dfm,'comment_text')\n\nfor col in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n    print(f'****** {col} *******')\n    display(dfm.loc[dfm[col]==1,['comment_text',col]].sample(5))\n    \n\n# Give more weight to severe toxic \ndfm['severe_toxic'] = dfm.severe_toxic * 2\ndfm['y'] = (dfm[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndfm['y'] = dfm['y']/dfm['y'].max()\n\ndfm = dfm[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\ndfm.y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:16:28.092296Z","iopub.execute_input":"2021-11-24T17:16:28.093223Z","iopub.status.idle":"2021-11-24T17:17:56.317973Z","shell.execute_reply.started":"2021-11-24T17:16:28.09317Z","shell.execute_reply":"2021-11-24T17:17:56.31696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 3 versions of Multilingual data","metadata":{}},{"cell_type":"code","source":"\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = pd.concat([dfm[dfm.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                        dfm[dfm.y==0].sample(n=int(len(dfm[dfm.y>0])*frac_1*frac_1_factor) , \n                                            random_state = 10*(fld+1))], axis=0).sample(frac=1, \n                                                                                        random_state = 10*(fld+1))\n\n    tmp_df.to_csv(f'/kaggle/working/dfm_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:17:56.320468Z","iopub.execute_input":"2021-11-24T17:17:56.32084Z","iopub.status.idle":"2021-11-24T17:17:57.734382Z","shell.execute_reply.started":"2021-11-24T17:17:56.320791Z","shell.execute_reply":"2021-11-24T17:17:57.733306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Test data  \n","metadata":{}},{"cell_type":"code","source":"# Validation data \n\n# df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n# df_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-20T07:56:45.678906Z","iopub.execute_input":"2021-11-20T07:56:45.679158Z","iopub.status.idle":"2021-11-20T07:56:46.238798Z","shell.execute_reply.started":"2021-11-20T07:56:45.679132Z","shell.execute_reply":"2021-11-20T07:56:46.237903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove contradicting cases from validation data\n- cases where contradictory evaluation is in minority (< 50%)","metadata":{}},{"cell_type":"code","source":"# gp1=df_val.copy()\n# gp1['pair'] = gp1.apply(lambda x:\" \".join(sorted((x['less_toxic'],\n#                                                   x['more_toxic']))),axis=1)\n# gp1['pair_hash'] = gp1.pair.apply(lambda x: str(abs(hash(x)) % (10 ** 8)))\n# del gp1['pair']\n# print(len(gp1), len(gp1.pair_hash.drop_duplicates()))\n\n# gp1['cnt']=gp1.groupby(['pair_hash', \n#                         'less_toxic',\n#                         'more_toxic']).transform(lambda x: x.count())\n# print(gp1[['pair_hash', 'less_toxic', 'more_toxic','cnt']].drop_duplicates().cnt.value_counts())\n\n# #gp1.head(10)\n# majority_cases = gp1.groupby('pair_hash')\\\n#                     .agg({'cnt':['count','max']})\\\n#                     .reset_index()\\\n#                     .set_axis(['pair_hash','count','max'], \n#                               axis='columns')\\\n#                     .assign(pct=lambda x: x['max']/x['count'])\\\n#                     .query('pct>=0.5')\\\n#                     .rename(columns={'max':'cnt'})\\\n#                     [['pair_hash','cnt']]\n\n# df_val = pd.merge(gp1,majority_cases,\n#                  how=\"inner\",\n#                  on = ['pair_hash','cnt'])\n# #gp1.groupby('pair_hash').apply(lambda x: x[['less_toxic','more_toxic','cnt']].sort_values('cnt', ascending=False))\n# df_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-20T02:29:24.674687Z","iopub.execute_input":"2021-11-20T02:29:24.675269Z","iopub.status.idle":"2021-11-20T02:29:47.320157Z","shell.execute_reply.started":"2021-11-20T02:29:24.675232Z","shell.execute_reply":"2021-11-20T02:29:47.31934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf_sub.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:17:57.735731Z","iopub.execute_input":"2021-11-24T17:17:57.736018Z","iopub.status.idle":"2021-11-24T17:17:57.840515Z","shell.execute_reply.started":"2021-11-24T17:17:57.735987Z","shell.execute_reply":"2021-11-24T17:17:57.839247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Sklearn Pipeline with \n-  TFIDF - Take 'char_wb' as analyzer to capture subwords well\n-  Ridge - Ridge is a simple regression algorithm that will reduce overfitting ","metadata":{}},{"cell_type":"code","source":"\nclass LengthTransformer(BaseEstimator, TransformerMixin):\n\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return sparse.csr_matrix([[(len(x)-360)/550] for x in X])\n    def get_feature_names(self):\n        return [\"lngth\"]\n\nclass LengthUpperTransformer(BaseEstimator, TransformerMixin):\n\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return sparse.csr_matrix([[int(sum([1 for y in x if y.isupper()])/len(x) > 0.75) ] for x in X])\n    def get_feature_names(self):\n        return [\"lngth_uppercase\"]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:17:57.842817Z","iopub.execute_input":"2021-11-24T17:17:57.843479Z","iopub.status.idle":"2021-11-24T17:17:57.853843Z","shell.execute_reply.started":"2021-11-24T17:17:57.843429Z","shell.execute_reply":"2021-11-24T17:17:57.852878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Does % of uppercase characters have effect on toxicity\n","metadata":{}},{"cell_type":"code","source":"\n# df_val['upper_1'] = np.array(LengthUpperTransformer().transform(df_val['less_toxic']).todense()).reshape(-1,1)\n# df_val['upper_2'] = np.array(LengthUpperTransformer().transform(df_val['more_toxic']).todense()).reshape(-1,1)\n\n# print(df_val['upper_1'].mean(), df_val['upper_1'].std())\n# print(df_val['upper_2'].mean(), df_val['upper_2'].std())\n\n# df_val['upper_1'].hist(bins=100)\n# df_val['upper_2'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:00:59.086833Z","iopub.execute_input":"2021-11-18T17:00:59.087117Z","iopub.status.idle":"2021-11-18T17:01:01.13661Z","shell.execute_reply.started":"2021-11-18T17:00:59.087089Z","shell.execute_reply":"2021-11-18T17:01:01.13564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train pipeline\n\n- Load folds data\n- train pipeline\n- Predict on validation data\n- Predict on test data","metadata":{}},{"cell_type":"markdown","source":"# Training function","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@timer\ndef train_pipeline(pipeline, data_path_name, n_folds, pipeline_, clean_prm = False):\n    val_preds_arr1_tmp = np.zeros((df_val.shape[0], n_folds))\n    val_preds_arr2_tmp = np.zeros((df_val.shape[0], n_folds))\n    test_preds_arr_tmp = np.zeros((df_sub.shape[0], n_folds))\n\n    for fld in range(n_folds):\n        print(\"\\n\\n\")\n        print(f' ****************************** FOLD: {fld} ******************************')\n        df = pd.read_csv(f'/kaggle/working/{data_path_name}_fld{fld}.csv')\n        print(df.shape)\n\n        print(\"\\nTrain:\")\n        # Train the pipeline\n        pipeline_.fit(df['text'], df['y'])\n\n        # What are the important features for toxicity\n\n        print('\\nTotal number of features:', len(pipeline_['features'].get_feature_names()) )\n\n        if pipeline_['clf'].__class__.__name__ == 'Ridge':\n            feature_wts = sorted(list(zip(pipeline_['features'].get_feature_names(), \n                                          np.round(pipeline_['clf'].coef_,2) )), \n                                 key = lambda x:x[1], \n                                 reverse=True)\n        else:\n            feature_wts = sorted(list(zip(pipeline_['features'].get_feature_names(), \n                                          np.round(pipeline_['clf'].feature_importances_,2) )), \n                                 key = lambda x:x[1], \n                                 reverse=True)\n            \n\n        display(pd.DataFrame(feature_wts[:50], columns = ['feat','val']).T)\n        display(pd.DataFrame(feature_wts[-50:], columns = ['feat','val']).T)\n        #.plot('feat','val',kind='barh',figsize = (8,8) )\n        #plt.show()\n\n        if clean_prm:\n            print(\"\\npredict validation data \")\n            val_preds_arr1_tmp[:,fld] = pipeline_.predict(clean(df_val,'less_toxic')['less_toxic'])\n            val_preds_arr2_tmp[:,fld] = pipeline_.predict(clean(df_val,'more_toxic')['more_toxic'])\n\n            print(\"\\npredict test data \")\n            test_preds_arr_tmp[:,fld] = pipeline_.predict(clean(df_sub,'text')['text'])\n        else:\n            print(\"\\npredict validation data \")\n            val_preds_arr1_tmp[:,fld] = pipeline_.predict(df_val['less_toxic'])\n            val_preds_arr2_tmp[:,fld] = pipeline_.predict(df_val['more_toxic'])\n\n            print(\"\\npredict test data \")\n            test_preds_arr_tmp[:,fld] = pipeline_.predict(df_sub['text'])\n    return val_preds_arr1_tmp, val_preds_arr2_tmp, test_preds_arr_tmp","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:22:11.286191Z","iopub.execute_input":"2021-11-24T17:22:11.287286Z","iopub.status.idle":"2021-11-24T17:22:11.311841Z","shell.execute_reply.started":"2021-11-24T17:22:11.287224Z","shell.execute_reply":"2021-11-24T17:22:11.310827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Toxic Training","metadata":{}},{"cell_type":"code","source":"features = FeatureUnion([\n    #('vect1', LengthTransformer()),\n    #('vect2', LengthUpperTransformer()),\n    (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, \n                              analyzer = 'char_wb', ngram_range = (3,5))),\n    #(\"vect4\", TfidfVectorizer(min_df= 5, max_df=0.5, analyzer = 'word', token_pattern=r'(?u)\\b\\w{8,}\\b')),\n\n])\npipeline = Pipeline(\n    [\n        (\"features\", features),\n        #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n        (\"clf\", Ridge()),\n        #(\"clf\",LinearRegression())\n    ]\n)\n\nval_preds_arr1, val_preds_arr2, test_preds_arr = train_pipeline(pipeline, \n                                                                \"df\", \n                                                                n_folds,\n                                                                pipeline,\n                                                                clean_prm=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:18:33.401318Z","iopub.execute_input":"2021-11-24T17:18:33.401626Z","iopub.status.idle":"2021-11-24T17:18:33.407607Z","shell.execute_reply.started":"2021-11-24T17:18:33.40159Z","shell.execute_reply":"2021-11-24T17:18:33.406657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Toxic __clean__ Training","metadata":{}},{"cell_type":"code","source":"features = FeatureUnion([\n    #('vect2', LengthUpperTransformer()),\n    (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, \n                              analyzer = 'char_wb', ngram_range = (3,5))),\n\n])\npipeline = Pipeline(\n    [\n        (\"features\", features),\n        #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n        (\"clf\", Ridge()),\n    ]\n)\n\nval_preds_arr1c, val_preds_arr2c, test_preds_arrc = train_pipeline(pipeline, \n                                                                   \"df_clean\", \n                                                                   n_folds,\n                                                                   pipeline,\n                                                                   clean_prm=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:54:21.355523Z","iopub.execute_input":"2021-11-23T17:54:21.355859Z","iopub.status.idle":"2021-11-23T17:57:56.866927Z","shell.execute_reply.started":"2021-11-23T17:54:21.355825Z","shell.execute_reply":"2021-11-23T17:57:56.865923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Toxic clean RF","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:53:14.714271Z","iopub.execute_input":"2021-11-25T05:53:14.714583Z","iopub.status.idle":"2021-11-25T05:53:14.719825Z","shell.execute_reply.started":"2021-11-25T05:53:14.714549Z","shell.execute_reply":"2021-11-25T05:53:14.719308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = FeatureUnion([\n    #('vect2', LengthUpperTransformer()),\n    (\"vect3\", TfidfVectorizer(min_df= 4, max_df=0.4, max_features = 10000,\n                              analyzer = 'word', ngram_range = (1,2))),\n\n])\npipeline = Pipeline(\n    [\n        (\"features\", features),\n        (\"clf\", RandomForestRegressor(n_estimators = 50, \n                                      min_samples_leaf=3, \n                                      max_features = 'sqrt')),\n        #(\"clf\", Ridge()),\n    ]\n)\n\nval_preds_arr1c_r, val_preds_arr2c_r, test_preds_arrc_r = train_pipeline(pipeline, \n                                                                   \"df_clean\", \n                                                                   n_folds,\n                                                                   pipeline,\n                                                                   clean_prm=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:29:46.054999Z","iopub.execute_input":"2021-11-24T17:29:46.055852Z","iopub.status.idle":"2021-11-24T17:35:53.496453Z","shell.execute_reply.started":"2021-11-24T17:29:46.055801Z","shell.execute_reply":"2021-11-24T17:35:53.49555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ruddit data Training","metadata":{}},{"cell_type":"code","source":"features = FeatureUnion([\n    #('vect2', LengthUpperTransformer()),\n    (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, \n                              analyzer = 'char_wb', ngram_range = (3,5))),\n\n])\npipeline = Pipeline(\n    [\n        (\"features\", features),\n        #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n        (\"clf\", Ridge()),\n    ]\n)\n\nval_preds_arr1_, val_preds_arr2_, test_preds_arr_ = train_pipeline(pipeline, \n                                                                   \"df2\", \n                                                                   n_folds,\n                                                                   pipeline,\n                                                                   clean_prm=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:57:56.868808Z","iopub.execute_input":"2021-11-23T17:57:56.869006Z","iopub.status.idle":"2021-11-23T18:00:20.293877Z","shell.execute_reply.started":"2021-11-23T17:57:56.868982Z","shell.execute_reply":"2021-11-23T18:00:20.292942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mulitlingual data Training","metadata":{}},{"cell_type":"code","source":"features = FeatureUnion([\n    #('vect1', LengthTransformer()),\n    #('vect2', LengthUpperTransformer()),\n    (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, \n                              analyzer = 'char_wb', ngram_range = (3,5))),\n    #(\"vect4\", CountVectorizer(min_df= 5, max_df=0.3, analyzer = 'word', ngram_range = (2,3), token_pattern=r'(?u)\\b\\w{3,}\\b', binary=True))\n])\npipeline = Pipeline(\n    [\n        (\"features\", features),\n        #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n        (\"clf\", Ridge()),\n        #(\"clf\",LinearRegression())\n    ]\n)\n\nval_preds_arr1m, val_preds_arr2m, test_preds_arrm = train_pipeline(pipeline, \n                                                                    \"dfm\", \n                                                                    n_folds,\n                                                                   pipeline,\n                                                                   clean_prm=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:00:20.295205Z","iopub.execute_input":"2021-11-23T18:00:20.295428Z","iopub.status.idle":"2021-11-23T18:03:53.411693Z","shell.execute_reply.started":"2021-11-23T18:00:20.295402Z","shell.execute_reply":"2021-11-23T18:03:53.410761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del df, pipeline, feature_wts\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:03:53.413572Z","iopub.execute_input":"2021-11-23T18:03:53.414488Z","iopub.status.idle":"2021-11-23T18:03:53.418576Z","shell.execute_reply.started":"2021-11-23T18:03:53.414443Z","shell.execute_reply":"2021-11-23T18:03:53.417576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate the pipeline ","metadata":{}},{"cell_type":"code","source":"print(\"\\n Toxic data \")\np1 = val_preds_arr1.mean(axis=1)\np2 = val_preds_arr2.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')\n\nprint(\"\\n Ruddit data \")\np3 = val_preds_arr1_.mean(axis=1)\np4 = val_preds_arr2_.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p3 < p4).mean() * 100,2)}')\n\nprint(\"\\n Toxic CLEAN data \")\np5 = val_preds_arr1c.mean(axis=1)\np6 = val_preds_arr2c.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p5 < p6).mean() * 100,2)}')\n\nprint(\"\\n Toxic Mulitlingual data \")\np7 = val_preds_arr1m.mean(axis=1)\np8 = val_preds_arr2m.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p7 < p8).mean() * 100,2)}')\n\nprint(\"\\n Toxic CLEAN data - RF\")\np9 = val_preds_arr1c_r.mean(axis=1)\np10 = val_preds_arr2c_r.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p9 < p10).mean() * 100,2)}')\n\n#val_preds_arr1c_r, val_preds_arr2c_r, test_preds_arrc_r\n\nprint(\"\\n Simple avg of ALL \")\nprint(f'Validation Accuracy is { np.round(((p1+p3+p5+p7+p9) < (p2+p4+p6+p8+p10)).mean() * 100,2)}')\n\n#print(\"\\n Simple product of ALL \")\n#print(f'Validation Accuracy is { np.round(((p1*p3*p5*p7) < (p2*p4*p6*p8)).mean() * 100,2)}')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:13:01.98689Z","iopub.execute_input":"2021-11-23T18:13:01.987082Z","iopub.status.idle":"2021-11-23T18:13:02.007445Z","shell.execute_reply.started":"2021-11-23T18:13:01.98706Z","shell.execute_reply":"2021-11-23T18:13:02.00691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation between predictions","metadata":{}},{"cell_type":"code","source":"corr = np.corrcoef(np.vstack([p1,p3,p5,p7,p9]))\nprint(corr)\n\nplt.matshow(corr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:06:59.422401Z","iopub.execute_input":"2021-11-23T18:06:59.422746Z","iopub.status.idle":"2021-11-23T18:06:59.630599Z","shell.execute_reply.started":"2021-11-23T18:06:59.422675Z","shell.execute_reply":"2021-11-23T18:06:59.629765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimize the model weights for ensemble","metadata":{}},{"cell_type":"code","source":"\n@timer\ndef optimize_wts():\n    func = lambda x: -1*(((x[0]*p1 + x[1]*p3 + x[2]*p5 + x[3]*p9) < \\\n                          (x[0]*p2 + x[1]*p4 + x[2]*p6  + x[3]*p10)).mean())\n\n    rranges = (slice(0.20, 0.6, 0.01), \n               slice(0.05, 0.5, 0.01),\n               slice(0.05, 0.5, 0.015),\n               slice(0.05, 0.5, 0.01),\n              )\n\n    resbrute = optimize.brute(func, \n                              rranges, \n                              #args=params, \n                              full_output=True,\n                              finish=None)\n    return resbrute\nresbrute = optimize_wts()\n\nprint(resbrute[0])  # global minimum\nprint(resbrute[1]*-1)  # function value at global minimum\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:09:53.786756Z","iopub.execute_input":"2021-11-23T18:09:53.787016Z","iopub.status.idle":"2021-11-23T18:13:01.978054Z","shell.execute_reply.started":"2021-11-23T18:09:53.78699Z","shell.execute_reply":"2021-11-23T18:13:01.976967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w1,w2,w3,w4 = resbrute[0]\n#print(best_wts)\n\np1_wt = w1*p1 + w2*p3 + w3*p5 + w4*p9\np2_wt = w1*p2 + w2*p4 + w3*p6 + w4*p10\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:13:01.97973Z","iopub.execute_input":"2021-11-23T18:13:01.980078Z","iopub.status.idle":"2021-11-23T18:13:01.985765Z","shell.execute_reply.started":"2021-11-23T18:13:01.980043Z","shell.execute_reply":"2021-11-23T18:13:01.984943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyze bad predictions \n### Incorrect predictions with similar scores\n### Incorrect predictions with different scores","metadata":{}},{"cell_type":"code","source":"df_val['p1'] = p1_wt\ndf_val['p2'] = p2_wt\ndf_val['diff'] = np.abs(p2_wt - p1_wt)\n\ndf_val['correct'] = (p1_wt < p2_wt).astype('int')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T15:04:44.008901Z","iopub.execute_input":"2021-11-19T15:04:44.009203Z","iopub.status.idle":"2021-11-19T15:04:44.017792Z","shell.execute_reply.started":"2021-11-19T15:04:44.009173Z","shell.execute_reply":"2021-11-19T15:04:44.017102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n### Incorrect predictions with similar scores\n\ndf_val[(df_val.correct == 0) & (df_val.p1 < 0.5*df_val.p1.max())].sort_values('diff', ascending=True).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:25:58.138899Z","iopub.execute_input":"2021-11-18T17:25:58.139517Z","iopub.status.idle":"2021-11-18T17:25:58.165802Z","shell.execute_reply.started":"2021-11-18T17:25:58.139465Z","shell.execute_reply":"2021-11-18T17:25:58.164756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val[(df_val.correct == 0) & (df_val.p1 > 0.5*df_val.p1.max())].sort_values('diff', ascending=True).head(20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Some of these just look incorrectly tagged \n","metadata":{}},{"cell_type":"code","source":"### Incorrect predictions with dis-similar scores\n\ndf_val[df_val.correct == 0].sort_values('diff', ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:26:02.870889Z","iopub.execute_input":"2021-11-18T17:26:02.871184Z","iopub.status.idle":"2021-11-18T17:26:02.892047Z","shell.execute_reply.started":"2021-11-18T17:26:02.871148Z","shell.execute_reply":"2021-11-18T17:26:02.891101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val[(df_val.correct == 0) & (df_val['diff'] < 0.4*df_val['diff'].max())].sort_values('diff', ascending=False).head(20)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on test data ","metadata":{}},{"cell_type":"code","source":"# Predict using pipeline\n\ndf_sub['score'] = w1*test_preds_arr.mean(axis=1) + \\\n                  w2*test_preds_arr_.mean(axis=1) + \\\n                  w3*test_preds_arrc.mean(axis=1) + \\\n                  w4*test_preds_arrc_r.mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:27:08.378049Z","iopub.execute_input":"2021-11-18T17:27:08.37834Z","iopub.status.idle":"2021-11-18T17:27:08.38374Z","shell.execute_reply.started":"2021-11-18T17:27:08.37831Z","shell.execute_reply":"2021-11-18T17:27:08.383073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_preds_arr","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:06:11.374494Z","iopub.execute_input":"2021-11-18T14:06:11.374853Z","iopub.status.idle":"2021-11-18T14:06:11.387837Z","shell.execute_reply.started":"2021-11-18T14:06:11.374806Z","shell.execute_reply":"2021-11-18T14:06:11.386874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correct the rank ordering","metadata":{}},{"cell_type":"code","source":"# Cases with duplicates scores\n\ndf_sub['score'].count() - df_sub['score'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:27:13.966573Z","iopub.execute_input":"2021-11-18T17:27:13.96751Z","iopub.status.idle":"2021-11-18T17:27:13.976928Z","shell.execute_reply.started":"2021-11-18T17:27:13.96745Z","shell.execute_reply":"2021-11-18T17:27:13.976294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"same_score = df_sub['score'].value_counts().reset_index()[:10]\nsame_score","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:27:15.139345Z","iopub.execute_input":"2021-11-18T17:27:15.139613Z","iopub.status.idle":"2021-11-18T17:27:15.155436Z","shell.execute_reply.started":"2021-11-18T17:27:15.139584Z","shell.execute_reply":"2021-11-18T17:27:15.154455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[df_sub['score'].isin(same_score['index'].tolist())]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:27:25.256581Z","iopub.execute_input":"2021-11-18T17:27:25.257391Z","iopub.status.idle":"2021-11-18T17:27:25.272575Z","shell.execute_reply.started":"2021-11-18T17:27:25.257354Z","shell.execute_reply":"2021-11-18T17:27:25.271921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Same comments have same score - which is ok ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:27:29.327817Z","iopub.execute_input":"2021-11-18T17:27:29.328366Z","iopub.status.idle":"2021-11-18T17:27:29.331633Z","shell.execute_reply.started":"2021-11-18T17:27:29.328327Z","shell.execute_reply":"2021-11-18T17:27:29.331016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Rank the predictions \n\n# df_sub['score']  = scipy.stats.rankdata(df_sub['score'], method='ordinal')\n\n# print(df_sub['score'].rank().nunique())","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:06:11.47096Z","iopub.execute_input":"2021-11-18T14:06:11.471643Z","iopub.status.idle":"2021-11-18T14:06:11.482114Z","shell.execute_reply.started":"2021-11-18T14:06:11.471594Z","shell.execute_reply":"2021-11-18T14:06:11.481373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T17:27:30.915528Z","iopub.execute_input":"2021-11-18T17:27:30.916055Z","iopub.status.idle":"2021-11-18T17:27:30.944486Z","shell.execute_reply.started":"2021-11-18T17:27:30.915994Z","shell.execute_reply":"2021-11-18T17:27:30.943441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}