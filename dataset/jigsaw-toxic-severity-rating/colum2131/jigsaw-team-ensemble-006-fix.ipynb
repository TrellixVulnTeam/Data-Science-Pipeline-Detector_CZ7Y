{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MST8823","metadata":{}},{"cell_type":"markdown","source":"## EXP029","metadata":{}},{"cell_type":"code","source":"\"\"\"\npseudo_label\ntoxic-xlm-roberta\nRMSE\nDropout=0.0\n\"\"\"\nclass Config:\n    author = \"mst8823\"\n    wandb_entity = \"mst8823\"\n    \n    competition = \"jigsaw-toxic-severity-rating\"\n    name = \"Exp-029-toxic-xlm-roberta-Pseudo-Ruddit\"\n    debug = False\n    inference_only = True\n    use_pretrain_model = False\n    target_cols = [\"pseudo_label\"]\n    \n    model_name = \"unitary/multilingual-toxic-xlm-roberta\"\n    hidden_size = 768\n    head = 256\n    tail = 0\n    max_length = head + tail\n\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    seed = 2022\n\n    max_epochs = 4\n    gradient_clip_val = 100\n    accumulate_grad_batches = 1\n    early_stopping = False\n    optimizer = dict(\n        optimizer=\"AdamW\", \n        lr=1e-5, \n        weight_decay=2e-5\n        )\n    scheduler = dict(\n        interval = \"step\",\n        scheduler=\"CosineAnnealingWarmupRestarts\",\n        max_lr=1e-5,\n        min_lr=1e-6,\n        T_mult=1,\n        warmup_steps=10,\n        gamma=1)\n    \n    train_batch_size = 8\n    valid_batch_size = 32\n    num_workers = 4\n    resume_from_checkpoint = None\n\n    colab_dir = \"/content/drive/Shareddrives/Jigsaw-Rate-Severity-of-Toxic-Comments\"\n    drive_path = colab_dir + f\"/{author}\"\n    api_path = drive_path + \"/kaggle.json\"\n\n    upload_from_colab = False\n    kaggle_dataset_path = \"../input/exp-029-toxic-xlm-roberta-pseudo-ruddit\"\n\n    \"\"\"\n    - step scheduler example\n    scheduler = dict(\n        interval = \"step\",\n        scheduler=\"get_cosine_schedule_with_warmup\",\n        num_warmup_steps=256, \n        num_cycles=0.5)\n\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:16.079291Z","iopub.execute_input":"2022-02-07T07:46:16.079631Z","iopub.status.idle":"2022-02-07T07:46:16.113009Z","shell.execute_reply.started":"2022-02-07T07:46:16.079543Z","shell.execute_reply":"2022-02-07T07:46:16.112092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport logging\nimport shutil\nimport json\nimport datetime\nimport requests\nimport itertools\nimport functools\nimport warnings\nimport joblib\nimport gc\nimport random\nimport string\nimport re\nimport collections\n\nimport pandas as pd\nimport numpy as np\nimport nltk\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom scipy.special import softmax\nfrom bs4 import BeautifulSoup\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, AdamW\nfrom torch.optim.lr_scheduler import (\n    CosineAnnealingWarmRestarts,\n    CosineAnnealingLR,\n    MultiStepLR, \n    ReduceLROnPlateau\n    )\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:16.114819Z","iopub.execute_input":"2022-02-07T07:46:16.115124Z","iopub.status.idle":"2022-02-07T07:46:18.970088Z","shell.execute_reply.started":"2022-02-07T07:46:16.115085Z","shell.execute_reply":"2022-02-07T07:46:18.969368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =========================\n# Utils\n# =========================\nclass Logger:\n    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n    def __init__(self, path):\n        self.general_logger = logging.getLogger(path)\n        stream_handler = logging.StreamHandler()\n        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n        if len(self.general_logger.handlers) == 0:\n            self.general_logger.addHandler(stream_handler)\n            self.general_logger.addHandler(file_general_handler)\n            self.general_logger.setLevel(logging.INFO)\n\n    def info(self, message):\n        # display time\n        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n\n    @staticmethod\n    def now_string():\n        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\n\ndef seed_everything(seed=2022):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef setup(cfg):\n    cfg.COLAB = \"google.colab\" in sys.modules\n    if cfg.COLAB:\n        print(\"This environment is Google Colab\")\n        \n        # mount\n        from google.colab import drive\n        if not os.path.isdir(\"/content/drive\"):\n            drive.mount('/content/drive') \n        \n        # import library\n        ! pip install --quiet pytorch_lightning\n        ! pip install --quiet transformers\n        ! pip install --quiet wandb\n        ! pip install --quiet sentencepiece\n        ! pip install --quiet 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n\n        # use kaggle api (need kaggle token)\n        f = open(cfg.api_path, 'r')\n        json_data = json.load(f) \n        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n        os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n        \n        # set dirs\n        cfg.DRIVE = cfg.drive_path\n        cfg.EXP = (cfg.name if cfg.name is not None \n            else requests.get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6])\n        cfg.INPUT = os.path.join(cfg.DRIVE, \"Input\")\n        cfg.OUTPUT = os.path.join(cfg.DRIVE, \"Output\")\n        cfg.SUBMISSION = os.path.join(cfg.DRIVE, \"Submission\")\n        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, \"model\")\n        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, \"fig\")\n        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, \"preds\")\n\n        # input data\n        cfg.INPUT_JIGSAW_01 = os.path.join(cfg.INPUT, \"jigsaw-toxic-comment-classification-challenge\")\n        cfg.INPUT_JIGSAW_02 = os.path.join(cfg.INPUT, \"jigsaw-unintended-bias-in-toxicity-classification\")\n        cfg.INPUT_JIGSAW_03 = os.path.join(cfg.INPUT, \"jigsaw-multilingual-toxic-comment-classification\")\n        cfg.INPUT_JIGSAW_04 = os.path.join(cfg.INPUT, \"jigsaw-toxic-severity-rating\")\n        cfg.INPUT_RUDDIT = os.path.join(cfg.INPUT, \"ruddit-jigsaw-dataset\")\n        cfg.jigsaw_inputs = [cfg.INPUT_JIGSAW_01, cfg.INPUT_JIGSAW_02, cfg.INPUT_JIGSAW_03, cfg.INPUT_JIGSAW_04, \n                             cfg.INPUT_RUDDIT]\n\n        # make dirs\n        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS] + cfg.jigsaw_inputs:\n            os.makedirs(d, exist_ok=True)\n\n        if not os.path.isfile(os.path.join(cfg.INPUT_JIGSAW_04, \"comments_to_score.csv\")):\n            print(\"load dataset\")\n            ! pip install --upgrade --force-reinstall --no-deps kaggle\n            ! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p $cfg.INPUT_JIGSAW_01 \n            ! kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification -p $cfg.INPUT_JIGSAW_02 \n            ! kaggle competitions download -c jigsaw-multilingual-toxic-comment-classification -p $cfg.INPUT_JIGSAW_03 \n            ! kaggle competitions download -c jigsaw-toxic-severity-rating -p $cfg.INPUT_JIGSAW_04 \n            ! kaggle datasets download -d rajkumarl/ruddit-jigsaw-dataset -p $cfg.INPUT_RUDDIT\n\n            for input_path in cfg.jigsaw_inputs:\n                filepath = f'{input_path}/{input_path.split(\"/\")[-1]}'\n                ! unzip -d $input_path $filepath\n\n    else:\n        print(\"This environment is Kaggle Kernel\")\n        if not cfg.inference_only:\n            ! pip install --quiet pytorch_lightning==1.5.8 \n\n        # set dirs\n        cfg.INPUT = f\"../input\"\n\n        # input data\n        cfg.INPUT_JIGSAW_01 = os.path.join(cfg.INPUT, \"jigsaw-toxic-comment-classification-challenge\")\n        cfg.INPUT_JIGSAW_02 = os.path.join(cfg.INPUT, \"jigsaw-unintended-bias-in-toxicity-classification\")\n        cfg.INPUT_JIGSAW_03 = os.path.join(cfg.INPUT, \"jigsaw-multilingual-toxic-comment-classification\")\n        cfg.INPUT_JIGSAW_04 = os.path.join(cfg.INPUT, \"jigsaw-toxic-severity-rating\")\n        cfg.INPUT_RUDDIT = os.path.join(cfg.INPUT, \"ruddit-jigsaw-dataset\")\n        cfg.jigsaw_inputs = [cfg.INPUT_JIGSAW_01, cfg.INPUT_JIGSAW_02, cfg.INPUT_JIGSAW_03, cfg.INPUT_JIGSAW_04, \n                             cfg.INPUT_RUDDIT]\n\n        cfg.EXP = cfg.OUTPUT_EXP = \"./\"\n        if cfg.kaggle_dataset_path is not None:\n            cfg.EXP_MODEL = os.path.join(cfg.kaggle_dataset_path, \"model\")\n        else:\n            cfg.EXP_MODEL = os.path.join(cfg.EXP, \"model\")\n\n        cfg.SUBMISSION = \"./\"\n        cfg.EXP_FIG = os.path.join(cfg.EXP, \"fig\")\n        cfg.EXP_PREDS = os.path.join(cfg.EXP, \"preds\")\n\n        # make dirs\n        make_dirs = [cfg.EXP_FIG, cfg.EXP_PREDS]\n        if not cfg.inference_only:\n            make_dirs.append(cfg.EXP_MODEL)\n        for d in make_dirs:\n            os.makedirs(d, exist_ok=True)\n\n    # set device    \n    cfg.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    warnings.filterwarnings(\"ignore\")\n    seed_everything(cfg.seed)\n\n    cfg.logger = Logger(cfg.OUTPUT_EXP)\n\n    return cfg\n\n\n# =========================\n# SetUp\n# =========================\nConfig = setup(Config)\n\n# 2nd import\nimport pytorch_lightning as pl\nimport wandb\n\nfrom transformers import (AutoConfig, AutoModel, AutoTokenizer)\nfrom transformers import (get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup)\n\nif not Config.inference_only:\n    from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n\n# wandb setting\nif not Config.COLAB:\n    if  not Config.inference_only:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"WANDB_API\")\n        wandb.login(key=api_key)\nelse:\n    wandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:18.972491Z","iopub.execute_input":"2022-02-07T07:46:18.972682Z","iopub.status.idle":"2022-02-07T07:46:25.857431Z","shell.execute_reply.started":"2022-02-07T07:46:18.972657Z","shell.execute_reply":"2022-02-07T07:46:25.856563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Dataset\n# =============================\nclass JigsawTrainDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer, text_col):\n        self.cfg = cfg\n        self.comment_text = df[text_col].values\n        self.targets = df[cfg.target_cols].values\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.comment_text)\n    \n    def __getitem__(self, idx):\n\n        text = str(self.comment_text[idx])\n        inputs = prepare_input(self.cfg, text, self.tokenizer)\n        targets = torch.tensor(self.targets[idx]).float()\n\n        return inputs, targets\n\n\nclass JigsawTestDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer, text_col):\n        self.cfg = cfg\n        self.comment_text = df[text_col].fillna(\"none\").values\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.comment_text)\n    \n    def __getitem__(self, idx):\n        text = str(self.comment_text[idx])\n        inputs = prepare_input(self.cfg, text, self.tokenizer)\n        return inputs\n\n\ndef prepare_input(cfg, text, tokenizer):\n    if cfg.tail == 0:\n        inputs = tokenizer.encode_plus(\n            text, \n            return_tensors=None, \n            add_special_tokens=True, \n            max_length=cfg.max_length,\n            pad_to_max_length=True,\n            truncation=True)\n        \n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n\n    else:\n        inputs = tokenizer.encode_plus(\n            text,\n            return_tensors=None, \n            add_special_tokens=True, \n            truncation=True)\n        \n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > cfg.max_length:\n                v = np.hstack([v[:cfg.head], v[-cfg.tail:]])\n\n            if k == 'input_ids':\n                new_v = np.ones(cfg.max_length) * tokenizer.pad_token_id\n\n            else:\n                new_v = np.zeros(cfg.max_length)\n\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n\n    return inputs\n\n\nclass JigsawDataModule(pl.LightningDataModule):\n    def __init__(self, cfg, tokenizer, train_df, valid_df, text_col):\n        super(JigsawDataModule).__init__()\n\n        self.cfg = cfg\n        self.text_col = text_col\n        self.tokenizer = tokenizer\n        self.train_df = train_df\n        self.valid_df = valid_df\n\n        self.train_dataset = None\n        self.val_dataset = None\n\n    def setup(self, stage=None):\n        self.train_dataset = JigsawTrainDataset(\n            cfg=self.cfg, df=self.train_df, tokenizer=self.tokenizer, text_col=self.text_col)\n        self.val_dataset = JigsawTrainDataset(\n            cfg=self.cfg, df=self.valid_df, tokenizer=self.tokenizer, text_col=self.text_col)\n        \n    def train_dataloader(self):\n        train_dataloader = DataLoader(\n            self.train_dataset, \n            batch_size=self.cfg.train_batch_size, \n            shuffle=True, \n            num_workers=self.cfg.num_workers, \n            pin_memory=True, \n            drop_last=True)\n        \n        return train_dataloader\n\n    def val_dataloader(self):\n        val_dataloader = DataLoader(\n            self.val_dataset,\n            batch_size=self.cfg.valid_batch_size,\n            shuffle=False,\n            num_workers=self.cfg.num_workers, \n            pin_memory=True, \n            drop_last=False)\n\n        return val_dataloader","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:25.860472Z","iopub.execute_input":"2022-02-07T07:46:25.861073Z","iopub.status.idle":"2022-02-07T07:46:25.897172Z","shell.execute_reply.started":"2022-02-07T07:46:25.86103Z","shell.execute_reply":"2022-02-07T07:46:25.896569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Model\n# =============================\ndef get_optimizer(cfg, parameters):\n    opt = cfg.optimizer\n    if opt[\"optimizer\"] == \"AdamW\":\n        optimizer = AdamW(\n            parameters,\n            lr=opt[\"lr\"],\n            weight_decay=opt[\"weight_decay\"]\n            )\n    \n    elif opt[\"optimizer\"] == \"Adam\":\n        optimizer = Adam(\n            parameters,\n            lr=opt[\"lr\"],\n            weight_decay=opt[\"weight_decay\"]\n            )\n    \n    else:\n        raise NotImplementedError\n    \n    return optimizer\n\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    sch = cfg.scheduler\n    if sch[\"scheduler\"] == \"get_linear_schedule_with_warmup\":\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, \n            num_warmup_steps=sch[\"num_warmup_steps\"],\n            num_training_steps=num_train_steps)\n    \n    elif sch[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=sch[\"num_warmup_steps\"],\n            num_training_steps=num_train_steps,\n            num_cycles=sch[\"num_cycles\"]\n            )\n\n    elif sch[\"scheduler\"] == \"MultiStepLR\":\n        scheduler = MultiStepLR(\n            optimizer, \n            milestones=sch[\"milestones\"], \n            gamma=sch[\"gamma\"]\n        )\n\n    elif sch[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n        \n        first_cycle_steps = (num_train_steps // cfg.max_epochs) * cfg.train_batch_size\n        print(first_cycle_steps)\n        scheduler = CosineAnnealingWarmupRestarts(\n            optimizer,\n            first_cycle_steps=int(first_cycle_steps),\n            cycle_mult=sch['T_mult'],\n            max_lr=sch[\"max_lr\"],\n            min_lr=sch['min_lr'],\n            warmup_steps=sch['warmup_steps'],\n            gamma=sch['gamma']\n        )\n    else:\n        raise NotImplementedError\n    \n    return scheduler\n\n\nclass JigsawModel(pl.LightningModule):\n    def __init__(self, cfg):\n        super(JigsawModel, self).__init__()\n        self.cfg = cfg\n        self.total_steps = None\n        self.dataset_size = None\n\n        self.backborn = get_backborn(cfg)   \n        self.out = nn.Linear(cfg.hidden_size, len(cfg.target_cols))\n\n    def forward(self, inputs):\n        x = self.backborn(**inputs)\n        x = x[0]\n        x = x[:, 0, :]\n\n        x_out = self.out(x)\n\n        return x_out\n\n    def training_step(self, batch, batch_idx):\n        inputs, targets = batch\n        outputs = self.forward(inputs)\n        loss = self.loss(outputs, targets)\n        self.log(\"train_loss\", loss, on_step=True, logger=True, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        inputs, targets = batch\n        outputs = self.forward(inputs)\n        loss = self.loss(outputs, targets)\n        self.log(\"val_loss\", loss, on_step=True, logger=True, prog_bar=True)\n        return loss\n\n    def loss(self, outputs, targets):\n        loss_fn = nn.MSELoss()\n        loss = loss_fn(outputs, targets)\n        # loss = torch.sqrt(loss)\n        return loss\n\n    def setup(self, stage=None):\n        if stage != \"fit\":\n            return\n\n        # calculate total steps\n        if self.dataset_size is None:\n            dataset = self.trainer._data_connector._train_dataloader_source.dataloader()\n            self.dataset_size = len(dataset)\n        num_devices = max(1, self.trainer.num_gpus, self.trainer.num_processes)  # gpus=-1だとそれが反映されちゃう\n        effective_batch_size = self.cfg.train_batch_size * self.trainer.accumulate_grad_batches * num_devices\n        print(self.dataset_size, effective_batch_size)\n        self.total_steps = (self.dataset_size // effective_batch_size) * self.cfg.max_epochs\n\n    def configure_optimizers(self):\n        optimizer = get_optimizer(self.cfg, parameters=self.parameters())\n\n        if self.cfg.scheduler is None:\n            return [optimizer]\n        else:\n            scheduler = get_scheduler(self.cfg, optimizer, num_train_steps=self.total_steps)\n            return [optimizer], [{\"scheduler\": scheduler, \"interval\": self.cfg.scheduler[\"interval\"]}]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:25.90224Z","iopub.execute_input":"2022-02-07T07:46:25.903152Z","iopub.status.idle":"2022-02-07T07:46:25.936718Z","shell.execute_reply.started":"2022-02-07T07:46:25.903115Z","shell.execute_reply":"2022-02-07T07:46:25.935738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Metrics\n# ============================= \ndef get_validation_data_hat(cfg, tokenizer, filename, validation_data):\n    validation_data_ = validation_data.copy()\n    df = pd.DataFrame({\"text\":sorted(set(validation_data_[\"less_toxic\"].unique()) |\n                                     set(validation_data_[\"more_toxic\"].unique()))})\n    \n    if filename is None:\n        preds = predict_cv(cfg, df, tokenizer, text_col=\"text\")\n    else:\n        preds = predict(cfg, df, tokenizer, filename, text_col=\"text\")\n\n    if np.ndim(preds) > 1:\n        df[\"preds\"] = np.mean(preds, axis=1)  # mean of targets\n    else:\n        df[\"preds\"] = preds.reshape(-1)\n\n    validation_data_ = (pd.merge(\n        validation_data_, df, left_on=\"less_toxic\", right_on=\"text\", how=\"left\").\n        rename(columns={\"preds\":\"less_toxic_preds\"}).\n        drop(\"text\", axis=1))\n    \n    validation_data_ = (pd.merge(\n        validation_data_, df, left_on=\"more_toxic\", right_on=\"text\", how=\"left\").\n        rename(columns={\"preds\":\"more_toxic_preds\"}).\n        drop(\"text\", axis=1))\n    \n    return validation_data_\n\n\ndef get_score(validation_data_hat):\n    less_toxic, more_toxic = validation_data_hat[\"less_toxic_preds\"], validation_data_hat[\"more_toxic_preds\"]\n    return np.mean(more_toxic > less_toxic)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:25.938616Z","iopub.execute_input":"2022-02-07T07:46:25.939205Z","iopub.status.idle":"2022-02-07T07:46:25.952001Z","shell.execute_reply.started":"2022-02-07T07:46:25.939167Z","shell.execute_reply":"2022-02-07T07:46:25.951336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Train & Predict\n# =============================\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\n\ndef train_fold(cfg, train_df, valid_df, tokenizer, filename, text_col):\n\n    wandblogger = pl.loggers.WandbLogger(\n        project=cfg.competition, \n        config=class2dict(cfg),\n        group=f\"{cfg.author}_{cfg.name}\",  \n        name=\"_\".join(filename.split(\"-\")[-2:]),\n        job_type=\"train\",\n        reinit=True,\n        anonymous=None,\n        entity=cfg.wandb_entity\n        )\n\n    lightning_datamodule = JigsawDataModule(\n        cfg=cfg, \n        tokenizer=tokenizer,\n        train_df=train_df, \n        valid_df=valid_df, \n        text_col=text_col\n        )\n    \n    lightning_model = JigsawModel(cfg=cfg)\n    lightning_model.dataset_size = len(train_df)  # cuz setup donot work?\n\n    checkpoint = pl.callbacks.ModelCheckpoint(\n        dirpath=cfg.EXP_MODEL,\n        filename=filename,\n        save_top_k=1,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\",\n    )\n    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n    callbacks = [checkpoint, lr_monitor]\n\n    if cfg.early_stopping:\n        early_stopping = pl.callbacks.EarlyStopping(\n            monitor=\"val_loss\", \n            min_delta=0.0, \n            patience=8, \n            mode='min', \n        )\n        callbacks += [early_stopping]\n    \n    trainer = pl.Trainer(\n        max_epochs=cfg.max_epochs,\n        callbacks=callbacks,\n        logger=[wandblogger],\n        gradient_clip_val=cfg.gradient_clip_val,\n        accumulate_grad_batches=cfg.accumulate_grad_batches,\n        resume_from_checkpoint=cfg.resume_from_checkpoint,\n        deterministic=False,\n        gpus=-1,\n        precision=16,\n    )\n\n    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n    wandb.finish(quiet=True)\n    torch.cuda.empty_cache()\n\n\ndef get_filname_listdir(dirctory):\n    listdir = os.listdir(dirctory)\n    out_lst = [os.path.splitext(d)[0] for d in listdir]\n    return out_lst\n\n\ndef train_cv(cfg, df, tokenizer, text_col=None, validation_data=None, get_oof=True):\n    \"\"\"cross validation & get oof\"\"\"\n    oof_df = pd.DataFrame(np.zeros((len(df), len(cfg.target_cols))), columns=cfg.target_cols)\n\n    for i_fold in range(cfg.n_fold):\n\n        if i_fold in cfg.trn_fold:\n            filename = f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}\"\n            filelist = get_filname_listdir(cfg.EXP_MODEL)\n\n            val_mask = (df[\"fold\"] == i_fold).astype(bool)\n            train_df = df[~val_mask].reset_index(drop=True)\n            valid_df = df[val_mask].reset_index(drop=True)\n\n            if not filename in filelist:\n                print(f\"# --------- # Start Training Fold={i_fold} # --------- #\")\n                # training\n                train_fold(\n                    cfg=cfg, \n                    train_df=train_df, \n                    valid_df=valid_df, \n                    tokenizer=tokenizer, \n                    filename=filename, \n                    text_col=text_col\n                    )\n\n            # get validation data score\n            if validation_data is not None:\n                validation_data_hat = get_validation_data_hat(cfg, tokenizer, filename, validation_data)\n                val_score = get_score(validation_data_hat)\n                log = f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}: validation data score={val_score:.4f}\"\n                cfg.logger.info(log)\n\n            # get validation prediction\n            if get_oof:\n                preds = predict(\n                    cfg=cfg,\n                    df=valid_df, \n                    tokenizer=tokenizer, \n                    filename=filename, \n                    text_col=text_col)\n                \n                oof_df.loc[val_mask] = preds\n                return oof_df\n\n\ndef predict(cfg, df, tokenizer, filename, text_col):\n    test_dataset = JigsawTestDataset(\n        cfg=cfg, tokenizer=tokenizer, df=df, text_col=text_col)\n    \n    test_dataloader = DataLoader(\n        test_dataset,\n        batch_size=cfg.valid_batch_size,\n        shuffle=False,\n        num_workers=cfg.num_workers, \n        pin_memory=True, \n        drop_last=False\n        ) \n    \n    lightning_model = JigsawModel(cfg=cfg).to(cfg.DEVICE).eval()\n    checkpoint_path = os.path.join(cfg.EXP_MODEL, filename + \".ckpt\") \n    lightning_model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n\n    num_targets = len(cfg.target_cols)\n    preds = np.zeros((len(df), num_targets))  # N * num targets\n    fill_start_idx = 0\n\n    for inputs in tqdm(test_dataloader,total=len(test_dataloader)):\n        # get predicted labels by batch\n        for k, v in inputs.items():\n            inputs[k] = v.to(cfg.DEVICE)\n\n        with torch.no_grad():\n            pred = lightning_model(inputs)\n            pred = pred.cpu().numpy()  # bs * num targets\n        \n        fill_end_idx = pred.shape[0] + fill_start_idx  # bs + idx\n        preds[fill_start_idx:fill_end_idx] = pred\n        fill_start_idx = fill_end_idx\n        \n    \n    del test_dataset, test_dataloader, lightning_model\n    gc.collect()\n\n    return preds\n\n\ndef predict_cv(cfg, df, tokenizer, text_col):\n    num_targets = len(cfg.target_cols)\n    preds = []\n    \n    for i_fold in range(cfg.n_fold):\n        if i_fold in cfg.trn_fold:\n            filename =f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}\"\n            preds_fold = predict(cfg, df, tokenizer, filename, text_col)\n            preds.append(preds_fold)\n    \n    preds = np.mean(preds, axis=0)  # fold mean\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:25.953686Z","iopub.execute_input":"2022-02-07T07:46:25.954336Z","iopub.status.idle":"2022-02-07T07:46:25.996962Z","shell.execute_reply.started":"2022-02-07T07:46:25.954298Z","shell.execute_reply":"2022-02-07T07:46:25.995958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Load Model\n# =============================\ndef get_tokenizer(cfg):\n\n    pretrained_dir = os.path.join(cfg.EXP_MODEL, \"Pretrain\")\n    tokenizer_path = os.path.join(pretrained_dir, \"tokenizer_config.json\")  # tokenizer.json??\n    if not os.path.isfile(tokenizer_path):\n        tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n        tokenizer.save_pretrained(pretrained_dir)\n    \n    else:\n        tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n\n    return tokenizer\n\n\ndef get_backborn(cfg):\n    pretrained_dir = os.path.join(cfg.EXP_MODEL, \"Pretrain\")\n    backborn_path = os.path.join(pretrained_dir, \"pytorch_model.bin\")\n    if not os.path.isfile(backborn_path):\n        model_config = AutoConfig.from_pretrained(cfg.model_name)\n\n        # No dropout\n        model_config.attention_probs_dropout_prob = 0.0\n        model_config.hidden_dropout_prob = 0.0\n\n        backborn = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n\n        backborn.save_pretrained(pretrained_dir)\n    \n    else:\n        model_config = AutoConfig.from_pretrained(pretrained_dir)\n\n        # No dropout\n        model_config.attention_probs_dropout_prob = 0.0\n        model_config.hidden_dropout_prob = 0.0\n        \n        if cfg.use_pretrain_model:\n            backborn = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n        else:\n            backborn = AutoModel.from_config(model_config)  # inference 時は pretrain weight いらない：cfg.use_pretrain_model=False\n\n    return backborn","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:25.998791Z","iopub.execute_input":"2022-02-07T07:46:25.99934Z","iopub.status.idle":"2022-02-07T07:46:26.011671Z","shell.execute_reply.started":"2022-02-07T07:46:25.999304Z","shell.execute_reply":"2022-02-07T07:46:26.010656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Create Data\n# =============================\ndef read_csv(filepath, **kwargs):\n    if os.path.isdir(filepath):\n        filename = filepath.split(\"/\")[-1]\n        filepath = os.path.join(filepath, filename)\n        \n    try:\n        csv_data = pd.read_csv(filepath,  **kwargs)\n    except:\n        csv_data = pd.read_csv(filepath + \".zip\",  **kwargs)\n\n    return csv_data\n\n\ndef text_cleaning(text):\n    '''\n    ref) # https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train\n\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n    text = ipPattern.sub(r'', text)\n    bikkuri = re.compile('!') # Removes bikkuri\n    text = bikkuri.sub(r' ', text)\n    text = text.replace('\\n','')\n    text = text.replace(\"\\'\",\"\")\n    text = text.replace(\"|\",\"\")\n    text = text.replace(\"=\",\"\")\n    text = text.replace(\"F**K\", \"FUCK\")\n    text = text.replace(\"F__K\", \"FUCK\")\n    text = text.replace(\"f**k\", \"fuck\")\n    text = text.replace(\"f__k\", \"fuck\")\n    text = text.replace(\"f*ck\", \"fuck\")    \n    text = text.replace(\"S$X\", \"SEX\")\n    text = text.replace(\"s$x\", \"sex\")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\"YOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUUUUUUUUUU\", \"YOU\")\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    return text\n\n\ndef text_normalization(s:pd.Series):\n    x = s.apply(text_cleaning)\n    return x\n\n\ndef get_jigsaw_01_dataset(cfg):\n    \"\"\"\n    jigsaw-toxic-comment-classification-challenge\n    - text_col : \"comment_text2\n    - target_cols : [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\n    \"\"\"\n    jigsaw1_train = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"train.csv\"))\n    jigsaw1_test = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"test.csv\"))\n    jigsaw1_test_label = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"test_labels.csv\"))\n    scoring_mask = jigsaw1_test_label[\"toxic\"] != -1\n    jigsaw1_test = pd.merge(jigsaw1_test[scoring_mask], jigsaw1_test_label[scoring_mask], on=\"id\", how=\"left\")\n    jigsaw1_train = pd.concat([jigsaw1_train, jigsaw1_test], axis=0).reset_index(drop=True)\n\n    return jigsaw1_train\n\n\ndef get_jigsaw_02_dataset(cfg, cat_threshold=0.5):\n    \"\"\"\n    jigsaw-unintended-bias-in-toxicity-classification\n    - text_col : \"comment_text\"\n    - target_cols : [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    \"\"\"\n    jigsaw2_data = read_csv(os.path.join(cfg.INPUT_JIGSAW_02 , \"all_data.csv\"), usecols=[\"id\", \"comment_text\"])\n    jigsaw2_labels = read_csv(os.path.join(cfg.INPUT_JIGSAW_02 , \"toxicity_individual_annotations.csv\"))\n    jigsaw2_agg_labels = jigsaw2_labels.groupby([\"id\"]).agg(\"mean\")\n\n    if cat_threshold is not None:\n        jigsaw2_agg_labels = pd.DataFrame(\n            np.where(jigsaw2_agg_labels >= cat_threshold, 1, 0), \n            index=jigsaw2_agg_labels.index,\n            columns=jigsaw2_agg_labels.columns)\n    \n    jigsaw2_train = pd.merge(jigsaw2_data, jigsaw2_agg_labels, on=\"id\", how=\"left\")\n    jigsaw2_train = jigsaw2_train.dropna(axis=0).reset_index(drop=True)\n    jigsaw2_train = (jigsaw2_train.\n                        rename(columns={\"identity_attack\":\"identity_hate\"}).\n                        drop([\"sexual_explicit\", \"worker\"], axis=1))\n    \n    return jigsaw2_train\n\n\ndef get_ruddit_dataset(cfg):\n    \"\"\"\n    Ruddit Dataset\n    - text_col : \"comment_text\"\n    - target_cols : \"offensiveness_score\"\n    \"\"\"\n    ruddit_df = read_csv(os.path.join(cfg.INPUT_RUDDIT, \"Dataset\", \"ruddit_with_text.csv\"))\n    ruddit_df = ruddit_df[~ruddit_df[\"txt\"].isin([\"[deleted]\", \"[removed]\"])].reset_index(drop=True)\n    # ruddit_df[\"comment_text\"] = text_normalization(ruddit_df[\"txt\"])\n    ruddit_df[\"comment_text\"] = ruddit_df[\"txt\"].fillna(\"none\")\n    return ruddit_df.drop(\"txt\", axis=1)\n\n\ndef get_fold_idx(cfg, df):\n    df[\"fold\"] = -1\n    y = df[cfg.target_cols].sum(axis=1)\n    cv_strategy = KFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n    for i_fold, (tr_idx, va_idx) in enumerate(cv_strategy.split(X=df, y=y)):\n        df.loc[va_idx, \"fold\"] = i_fold\n    \n    return df\n\n\ndef get_custom_jigsaw_dataset(cfg, train_data, validation_data):\n    \"\"\"\n    ref) https://www.kaggle.com/toru59er/0-866-tfidf-ridge-simple-baseline\n    target_cols : [\"toxic_score\"]\n    weighted sum of targets:[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    undersampling\n    \"\"\"\n\n    train_data[\"toxic_score\"] = train_data[cfg.target_cols].sum(axis=1)\n    \n    # undersample\n    toxic_mask = (train_data[\"toxic_score\"] > 0).astype(bool)\n    min_len = np.sum(toxic_mask)\n\n    sampled_data = train_data[train_data[\"toxic_score\"] == 0].sample(n=min_len, random_state=cfg.seed)\n    train_data = pd.concat([train_data[toxic_mask], sampled_data]).reset_index(drop=True).drop(\"toxic_score\", axis=1)\n\n    val_comment_unq = np.unique(validation_data['less_toxic'].tolist() + validation_data['more_toxic'].tolist())\n    duplicate_idx = np.isin(train_data['comment_text'], val_comment_unq)\n    train_data = train_data.iloc[~duplicate_idx].reset_index(drop=True)\n\n    return train_data","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:26.015768Z","iopub.execute_input":"2022-02-07T07:46:26.016347Z","iopub.status.idle":"2022-02-07T07:46:26.058366Z","shell.execute_reply.started":"2022-02-07T07:46:26.01631Z","shell.execute_reply":"2022-02-07T07:46:26.05772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"# ------------------ # Load Data # ------------------ #\")\n\n# load tokenizer\ntokenizer = get_tokenizer(Config)\n\ncomments_to_score = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"comments_to_score.csv\"))\n\nif len(comments_to_score) == 7537:\n    comments_to_score = comments_to_score.iloc[:100]\n\n# comments_to_score[\"text\"] = text_normalization(comments_to_score[\"text\"])\nsample_submission = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"sample_submission.csv\"))\n\nif not Config.inference_only:\n\n    # load validation data\n    validation_data = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"validation_data.csv\"))\n\n    # load train data\n    train_data = read_csv(\"/content/drive/Shareddrives/Jigsaw-Rate-Severity-of-Toxic-Comments/mst8823/Input/PseudoLabelDataset-Ruddit.csv\")\n    train_data = train_data[~train_data[\"txt\"].isin([\"[deleted]\", \"[removed]\"])].reset_index(drop=True)\n    train_data = get_fold_idx(cfg=Config, df=train_data)\n\n    # train_data[\"comment_text\"] = text_normalization(train_data[\"comment_text\"])\n    # validation_data[\"less_toxic\"] = text_normalization(validation_data[\"less_toxic\"])\n    # validation_data[\"more_toxic\"] = text_normalization(validation_data[\"more_toxic\"])\n\n    print(\"# ------------------ # Training # ------------------ #\")\n    # training\n    train_cv(\n        cfg=Config, \n        df=train_data, \n        tokenizer=tokenizer, \n        text_col=\"txt\",  #comment_text\n        validation_data=validation_data, \n        get_oof=False)\n\n    print(\"# ------------------ # Validation # ------------------ #\")\n    # validation\n    validation_data_hat = get_validation_data_hat(\n        cfg=Config, \n        tokenizer=tokenizer, \n        filename=None, \n        validation_data=validation_data\n        )\n    filepath = os.path.join(Config.EXP_PREDS, \"validation_data.csv\")\n    validation_data_hat.to_csv(filepath, index=False)\n    score = get_score(validation_data_hat)\n    Config.logger.info(f\"validation score = {score:.4f}\")\n\nprint(\"# ------------------ # Inference # ------------------ #\")\npreds = predict_cv(\n    cfg=Config, \n    df=comments_to_score, \n    tokenizer=tokenizer, \n    text_col=\"text\")\n\nprint(preds.shape)\nif np.ndim(preds) > 1:\n    mst029 = np.mean(preds, axis=1)  # mean of target\nelse:\n    mst029 = preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:26.059977Z","iopub.execute_input":"2022-02-07T07:46:26.0604Z","iopub.status.idle":"2022-02-07T07:50:33.450555Z","shell.execute_reply.started":"2022-02-07T07:46:26.060367Z","shell.execute_reply":"2022-02-07T07:50:33.44974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MST030","metadata":{}},{"cell_type":"code","source":"\"\"\"\npseudo_label\ntoxic-xlm-roberta\nRMSE\nDropout=0.0\n\"\"\"\nclass Config:\n    author = \"mst8823\"\n    wandb_entity = \"mst8823\"\n    \n    competition = \"jigsaw-toxic-severity-rating\"\n    name = \"Exp-030-toxic-xlm-roberta-Pseudo-Jigsaw1\"\n    debug = False\n    inference_only = True\n    use_pretrain_model = False\n    target_cols = [\"pseudo_label\"]\n    \n    model_name = \"unitary/multilingual-toxic-xlm-roberta\"\n    hidden_size = 768\n    head = 256\n    tail = 0\n    max_length = head + tail\n\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    seed = 2022\n\n    max_epochs = 5\n    gradient_clip_val = 100\n    accumulate_grad_batches = 1\n    early_stopping = False\n    optimizer = dict(\n        optimizer=\"AdamW\", \n        lr=1e-5, \n        weight_decay=2e-5\n        )\n    scheduler = dict(\n        interval = \"step\",\n        scheduler=\"CosineAnnealingWarmupRestarts\",\n        max_lr=1e-5,\n        min_lr=1e-6,\n        T_mult=1,\n        warmup_steps=10,\n        gamma=1)\n    \n    train_batch_size = 8\n    valid_batch_size = 32\n    num_workers = 2\n    resume_from_checkpoint = None\n\n    colab_dir = \"/content/drive/Shareddrives/Jigsaw-Rate-Severity-of-Toxic-Comments\"\n    drive_path = colab_dir + f\"/{author}\"\n    api_path = drive_path + \"/kaggle.json\"\n\n    upload_from_colab = False\n    kaggle_dataset_path = \"../input/exp-030-toxic-xlm-roberta-pseudo-jigsaw1\"\n\n    \"\"\"\n    - step scheduler example\n    scheduler = dict(\n        interval = \"step\",\n        scheduler=\"get_cosine_schedule_with_warmup\",\n        num_warmup_steps=256, \n        num_cycles=0.5)\n\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.451941Z","iopub.execute_input":"2022-02-07T07:50:33.452203Z","iopub.status.idle":"2022-02-07T07:50:33.476549Z","shell.execute_reply.started":"2022-02-07T07:50:33.452166Z","shell.execute_reply":"2022-02-07T07:50:33.475639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport logging\nimport shutil\nimport json\nimport datetime\nimport requests\nimport itertools\nimport functools\nimport warnings\nimport joblib\nimport gc\nimport random\nimport string\nimport re\nimport collections\n\nimport pandas as pd\nimport numpy as np\nimport nltk\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom scipy.special import softmax\nfrom bs4 import BeautifulSoup\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, AdamW\nfrom torch.optim.lr_scheduler import (\n    CosineAnnealingWarmRestarts,\n    CosineAnnealingLR,\n    MultiStepLR, \n    ReduceLROnPlateau\n    )\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.477836Z","iopub.execute_input":"2022-02-07T07:50:33.478102Z","iopub.status.idle":"2022-02-07T07:50:33.497334Z","shell.execute_reply.started":"2022-02-07T07:50:33.478067Z","shell.execute_reply":"2022-02-07T07:50:33.496398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =========================\n# Utils\n# =========================\nclass Logger:\n    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n    def __init__(self, path):\n        self.general_logger = logging.getLogger(path)\n        stream_handler = logging.StreamHandler()\n        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n        if len(self.general_logger.handlers) == 0:\n            self.general_logger.addHandler(stream_handler)\n            self.general_logger.addHandler(file_general_handler)\n            self.general_logger.setLevel(logging.INFO)\n\n    def info(self, message):\n        # display time\n        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n\n    @staticmethod\n    def now_string():\n        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\n\ndef seed_everything(seed=2022):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef setup(cfg):\n    cfg.COLAB = \"google.colab\" in sys.modules\n    if cfg.COLAB:\n        print(\"This environment is Google Colab\")\n        \n        # mount\n        from google.colab import drive\n        if not os.path.isdir(\"/content/drive\"):\n            drive.mount('/content/drive') \n        \n        # import library\n        ! pip install --quiet pytorch_lightning\n        ! pip install --quiet transformers\n        ! pip install --quiet wandb\n        ! pip install --quiet sentencepiece\n        ! pip install --quiet 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n\n        # use kaggle api (need kaggle token)\n        f = open(cfg.api_path, 'r')\n        json_data = json.load(f) \n        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n        os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n        \n        # set dirs\n        cfg.DRIVE = cfg.drive_path\n        cfg.EXP = (cfg.name if cfg.name is not None \n            else requests.get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6])\n        cfg.INPUT = os.path.join(cfg.DRIVE, \"Input\")\n        cfg.OUTPUT = os.path.join(cfg.DRIVE, \"Output\")\n        cfg.SUBMISSION = os.path.join(cfg.DRIVE, \"Submission\")\n        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, \"model\")\n        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, \"fig\")\n        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, \"preds\")\n\n        # input data\n        cfg.INPUT_JIGSAW_01 = os.path.join(cfg.INPUT, \"jigsaw-toxic-comment-classification-challenge\")\n        cfg.INPUT_JIGSAW_02 = os.path.join(cfg.INPUT, \"jigsaw-unintended-bias-in-toxicity-classification\")\n        cfg.INPUT_JIGSAW_03 = os.path.join(cfg.INPUT, \"jigsaw-multilingual-toxic-comment-classification\")\n        cfg.INPUT_JIGSAW_04 = os.path.join(cfg.INPUT, \"jigsaw-toxic-severity-rating\")\n        cfg.INPUT_RUDDIT = os.path.join(cfg.INPUT, \"ruddit-jigsaw-dataset\")\n        cfg.jigsaw_inputs = [cfg.INPUT_JIGSAW_01, cfg.INPUT_JIGSAW_02, cfg.INPUT_JIGSAW_03, cfg.INPUT_JIGSAW_04, \n                             cfg.INPUT_RUDDIT]\n\n        # make dirs\n        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS] + cfg.jigsaw_inputs:\n            os.makedirs(d, exist_ok=True)\n\n        if not os.path.isfile(os.path.join(cfg.INPUT_JIGSAW_04, \"comments_to_score.csv\")):\n            print(\"load dataset\")\n            ! pip install --upgrade --force-reinstall --no-deps kaggle\n            ! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p $cfg.INPUT_JIGSAW_01 \n            ! kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification -p $cfg.INPUT_JIGSAW_02 \n            ! kaggle competitions download -c jigsaw-multilingual-toxic-comment-classification -p $cfg.INPUT_JIGSAW_03 \n            ! kaggle competitions download -c jigsaw-toxic-severity-rating -p $cfg.INPUT_JIGSAW_04 \n            ! kaggle datasets download -d rajkumarl/ruddit-jigsaw-dataset -p $cfg.INPUT_RUDDIT\n\n            for input_path in cfg.jigsaw_inputs:\n                filepath = f'{input_path}/{input_path.split(\"/\")[-1]}'\n                ! unzip -d $input_path $filepath\n\n    else:\n        print(\"This environment is Kaggle Kernel\")\n        if not cfg.inference_only:\n            ! pip install --quiet pytorch_lightning==1.5.8 \n\n        # set dirs\n        cfg.INPUT = f\"../input\"\n\n        # input data\n        cfg.INPUT_JIGSAW_01 = os.path.join(cfg.INPUT, \"jigsaw-toxic-comment-classification-challenge\")\n        cfg.INPUT_JIGSAW_02 = os.path.join(cfg.INPUT, \"jigsaw-unintended-bias-in-toxicity-classification\")\n        cfg.INPUT_JIGSAW_03 = os.path.join(cfg.INPUT, \"jigsaw-multilingual-toxic-comment-classification\")\n        cfg.INPUT_JIGSAW_04 = os.path.join(cfg.INPUT, \"jigsaw-toxic-severity-rating\")\n        cfg.INPUT_RUDDIT = os.path.join(cfg.INPUT, \"ruddit-jigsaw-dataset\")\n        cfg.jigsaw_inputs = [cfg.INPUT_JIGSAW_01, cfg.INPUT_JIGSAW_02, cfg.INPUT_JIGSAW_03, cfg.INPUT_JIGSAW_04, \n                             cfg.INPUT_RUDDIT]\n\n        cfg.EXP = cfg.OUTPUT_EXP = \"./\"\n        if cfg.kaggle_dataset_path is not None:\n            cfg.EXP_MODEL = os.path.join(cfg.kaggle_dataset_path, \"model\")\n        else:\n            cfg.EXP_MODEL = os.path.join(cfg.EXP, \"model\")\n\n        cfg.SUBMISSION = \"./\"\n        cfg.EXP_FIG = os.path.join(cfg.EXP, \"fig\")\n        cfg.EXP_PREDS = os.path.join(cfg.EXP, \"preds\")\n\n        # make dirs\n        make_dirs = [cfg.EXP_FIG, cfg.EXP_PREDS]\n        if not cfg.inference_only:\n            make_dirs.append(cfg.EXP_MODEL)\n        for d in make_dirs:\n            os.makedirs(d, exist_ok=True)\n\n    # set device    \n    cfg.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    warnings.filterwarnings(\"ignore\")\n    seed_everything(cfg.seed)\n\n    cfg.logger = Logger(cfg.OUTPUT_EXP)\n\n    return cfg\n\n\n# =========================\n# SetUp\n# =========================\nConfig = setup(Config)\n\n# 2nd import\nimport pytorch_lightning as pl\nimport wandb\n\nfrom transformers import (AutoConfig, AutoModel, AutoTokenizer)\nfrom transformers import (get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup)\n\nif not Config.inference_only:\n    from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n\n# wandb setting\nif not Config.COLAB:\n    if  not Config.inference_only:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"WANDB_API\")\n        wandb.login(key=api_key)\nelse:\n    wandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.498723Z","iopub.execute_input":"2022-02-07T07:50:33.499068Z","iopub.status.idle":"2022-02-07T07:50:33.830145Z","shell.execute_reply.started":"2022-02-07T07:50:33.499032Z","shell.execute_reply":"2022-02-07T07:50:33.829205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Dataset\n# =============================\nclass JigsawTrainDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer, text_col):\n        self.cfg = cfg\n        self.comment_text = df[text_col].values\n        self.targets = df[cfg.target_cols].values\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.comment_text)\n    \n    def __getitem__(self, idx):\n\n        text = str(self.comment_text[idx])\n        inputs = prepare_input(self.cfg, text, self.tokenizer)\n        targets = torch.tensor(self.targets[idx]).float()\n\n        return inputs, targets\n\n\nclass JigsawTestDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer, text_col):\n        self.cfg = cfg\n        self.comment_text = df[text_col].fillna(\"none\").values\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.comment_text)\n    \n    def __getitem__(self, idx):\n        text = str(self.comment_text[idx])\n        inputs = prepare_input(self.cfg, text, self.tokenizer)\n        return inputs\n\n\ndef prepare_input(cfg, text, tokenizer):\n    if cfg.tail == 0:\n        inputs = tokenizer.encode_plus(\n            text, \n            return_tensors=None, \n            add_special_tokens=True, \n            max_length=cfg.max_length,\n            pad_to_max_length=True,\n            truncation=True)\n        \n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n\n    else:\n        inputs = tokenizer.encode_plus(\n            text,\n            return_tensors=None, \n            add_special_tokens=True, \n            truncation=True)\n        \n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > cfg.max_length:\n                v = np.hstack([v[:cfg.head], v[-cfg.tail:]])\n\n            if k == 'input_ids':\n                new_v = np.ones(cfg.max_length) * tokenizer.pad_token_id\n\n            else:\n                new_v = np.zeros(cfg.max_length)\n\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n\n    return inputs\n\n\nclass JigsawDataModule(pl.LightningDataModule):\n    def __init__(self, cfg, tokenizer, train_df, valid_df, text_col):\n        super(JigsawDataModule).__init__()\n\n        self.cfg = cfg\n        self.text_col = text_col\n        self.tokenizer = tokenizer\n        self.train_df = train_df\n        self.valid_df = valid_df\n\n        self.train_dataset = None\n        self.val_dataset = None\n\n    def setup(self, stage=None):\n        self.train_dataset = JigsawTrainDataset(\n            cfg=self.cfg, df=self.train_df, tokenizer=self.tokenizer, text_col=self.text_col)\n        self.val_dataset = JigsawTrainDataset(\n            cfg=self.cfg, df=self.valid_df, tokenizer=self.tokenizer, text_col=self.text_col)\n        \n    def train_dataloader(self):\n        train_dataloader = DataLoader(\n            self.train_dataset, \n            batch_size=self.cfg.train_batch_size, \n            shuffle=True, \n            num_workers=self.cfg.num_workers, \n            pin_memory=True, \n            drop_last=True)\n        \n        return train_dataloader\n\n    def val_dataloader(self):\n        val_dataloader = DataLoader(\n            self.val_dataset,\n            batch_size=self.cfg.valid_batch_size,\n            shuffle=False,\n            num_workers=self.cfg.num_workers, \n            pin_memory=True, \n            drop_last=False)\n\n        return val_dataloader","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.831501Z","iopub.execute_input":"2022-02-07T07:50:33.831784Z","iopub.status.idle":"2022-02-07T07:50:33.853972Z","shell.execute_reply.started":"2022-02-07T07:50:33.831745Z","shell.execute_reply":"2022-02-07T07:50:33.852795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Model\n# =============================\ndef get_optimizer(cfg, parameters):\n    opt = cfg.optimizer\n    if opt[\"optimizer\"] == \"AdamW\":\n        optimizer = AdamW(\n            parameters,\n            lr=opt[\"lr\"],\n            weight_decay=opt[\"weight_decay\"]\n            )\n    \n    elif opt[\"optimizer\"] == \"Adam\":\n        optimizer = Adam(\n            parameters,\n            lr=opt[\"lr\"],\n            weight_decay=opt[\"weight_decay\"]\n            )\n    \n    else:\n        raise NotImplementedError\n    \n    return optimizer\n\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    sch = cfg.scheduler\n    if sch[\"scheduler\"] == \"get_linear_schedule_with_warmup\":\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, \n            num_warmup_steps=sch[\"num_warmup_steps\"],\n            num_training_steps=num_train_steps)\n    \n    elif sch[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=sch[\"num_warmup_steps\"],\n            num_training_steps=num_train_steps,\n            num_cycles=sch[\"num_cycles\"]\n            )\n\n    elif sch[\"scheduler\"] == \"MultiStepLR\":\n        scheduler = MultiStepLR(\n            optimizer, \n            milestones=sch[\"milestones\"], \n            gamma=sch[\"gamma\"]\n        )\n\n    elif sch[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n        \n        first_cycle_steps = (num_train_steps // cfg.max_epochs) * cfg.train_batch_size\n        print(first_cycle_steps)\n        scheduler = CosineAnnealingWarmupRestarts(\n            optimizer,\n            first_cycle_steps=int(first_cycle_steps),\n            cycle_mult=sch['T_mult'],\n            max_lr=sch[\"max_lr\"],\n            min_lr=sch['min_lr'],\n            warmup_steps=sch['warmup_steps'],\n            gamma=sch['gamma']\n        )\n    else:\n        raise NotImplementedError\n    \n    return scheduler\n\n\nclass JigsawModel(pl.LightningModule):\n    def __init__(self, cfg):\n        super(JigsawModel, self).__init__()\n        self.cfg = cfg\n        self.total_steps = None\n        self.dataset_size = None\n\n        self.backborn = get_backborn(cfg)   \n        self.out = nn.Linear(cfg.hidden_size, len(cfg.target_cols))\n\n    def forward(self, inputs):\n        x = self.backborn(**inputs)\n        x = x[0]\n        x = x[:, 0, :]\n\n        x_out = self.out(x)\n\n        return x_out\n\n    def training_step(self, batch, batch_idx):\n        inputs, targets = batch\n        outputs = self.forward(inputs)\n        loss = self.loss(outputs, targets)\n        self.log(\"train_loss\", loss, on_step=True, logger=True, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        inputs, targets = batch\n        outputs = self.forward(inputs)\n        loss = self.loss(outputs, targets)\n        self.log(\"val_loss\", loss, on_step=True, logger=True, prog_bar=True)\n        return loss\n\n    def loss(self, outputs, targets):\n        loss_fn = nn.MSELoss()\n        loss = loss_fn(outputs, targets)\n        # loss = torch.sqrt(loss)\n        return loss\n\n    def setup(self, stage=None):\n        if stage != \"fit\":\n            return\n\n        # calculate total steps\n        if self.dataset_size is None:\n            dataset = self.trainer._data_connector._train_dataloader_source.dataloader()\n            self.dataset_size = len(dataset)\n        num_devices = max(1, self.trainer.num_gpus, self.trainer.num_processes)  # gpus=-1だとそれが反映されちゃう\n        effective_batch_size = self.cfg.train_batch_size * self.trainer.accumulate_grad_batches * num_devices\n        print(self.dataset_size, effective_batch_size)\n        self.total_steps = (self.dataset_size // effective_batch_size) * self.cfg.max_epochs\n\n    def configure_optimizers(self):\n        optimizer = get_optimizer(self.cfg, parameters=self.parameters())\n\n        if self.cfg.scheduler is None:\n            return [optimizer]\n        else:\n            scheduler = get_scheduler(self.cfg, optimizer, num_train_steps=self.total_steps)\n            return [optimizer], [{\"scheduler\": scheduler, \"interval\": self.cfg.scheduler[\"interval\"]}]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.856215Z","iopub.execute_input":"2022-02-07T07:50:33.856775Z","iopub.status.idle":"2022-02-07T07:50:33.879107Z","shell.execute_reply.started":"2022-02-07T07:50:33.856738Z","shell.execute_reply":"2022-02-07T07:50:33.87835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Metrics\n# ============================= \ndef get_validation_data_hat(cfg, tokenizer, filename, validation_data):\n    validation_data_ = validation_data.copy()\n    df = pd.DataFrame({\"text\":sorted(set(validation_data_[\"less_toxic\"].unique()) |\n                                     set(validation_data_[\"more_toxic\"].unique()))})\n    \n    if filename is None:\n        preds = predict_cv(cfg, df, tokenizer, text_col=\"text\")\n    else:\n        preds = predict(cfg, df, tokenizer, filename, text_col=\"text\")\n\n    if np.ndim(preds) > 1:\n        df[\"preds\"] = np.mean(preds, axis=1)  # mean of targets\n    else:\n        df[\"preds\"] = preds.reshape(-1)\n\n    validation_data_ = (pd.merge(\n        validation_data_, df, left_on=\"less_toxic\", right_on=\"text\", how=\"left\").\n        rename(columns={\"preds\":\"less_toxic_preds\"}).\n        drop(\"text\", axis=1))\n    \n    validation_data_ = (pd.merge(\n        validation_data_, df, left_on=\"more_toxic\", right_on=\"text\", how=\"left\").\n        rename(columns={\"preds\":\"more_toxic_preds\"}).\n        drop(\"text\", axis=1))\n    \n    return validation_data_\n\n\ndef get_score(validation_data_hat):\n    less_toxic, more_toxic = validation_data_hat[\"less_toxic_preds\"], validation_data_hat[\"more_toxic_preds\"]\n    return np.mean(more_toxic > less_toxic)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.880592Z","iopub.execute_input":"2022-02-07T07:50:33.880991Z","iopub.status.idle":"2022-02-07T07:50:33.894038Z","shell.execute_reply.started":"2022-02-07T07:50:33.880878Z","shell.execute_reply":"2022-02-07T07:50:33.893101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Train & Predict\n# =============================\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\n\ndef train_fold(cfg, train_df, valid_df, tokenizer, filename, text_col):\n\n    wandblogger = pl.loggers.WandbLogger(\n        project=cfg.competition, \n        config=class2dict(cfg),\n        group=f\"{cfg.author}_{cfg.name}\",  \n        name=\"_\".join(filename.split(\"-\")[-2:]),\n        job_type=\"train\",\n        reinit=True,\n        anonymous=None,\n        entity=cfg.wandb_entity\n        )\n\n    lightning_datamodule = JigsawDataModule(\n        cfg=cfg, \n        tokenizer=tokenizer,\n        train_df=train_df, \n        valid_df=valid_df, \n        text_col=text_col\n        )\n    \n    lightning_model = JigsawModel(cfg=cfg)\n    lightning_model.dataset_size = len(train_df)  # cuz setup donot work?\n\n    checkpoint = pl.callbacks.ModelCheckpoint(\n        dirpath=cfg.EXP_MODEL,\n        filename=filename,\n        save_top_k=1,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\",\n    )\n    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n    callbacks = [checkpoint, lr_monitor]\n\n    if cfg.early_stopping:\n        early_stopping = pl.callbacks.EarlyStopping(\n            monitor=\"val_loss\", \n            min_delta=0.0, \n            patience=8, \n            mode='min', \n        )\n        callbacks += [early_stopping]\n    \n    trainer = pl.Trainer(\n        max_epochs=cfg.max_epochs,\n        callbacks=callbacks,\n        logger=[wandblogger],\n        gradient_clip_val=cfg.gradient_clip_val,\n        accumulate_grad_batches=cfg.accumulate_grad_batches,\n        resume_from_checkpoint=cfg.resume_from_checkpoint,\n        deterministic=False,\n        gpus=-1,\n        precision=16,\n    )\n\n    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n    wandb.finish(quiet=True)\n    torch.cuda.empty_cache()\n\n\ndef get_filname_listdir(dirctory):\n    listdir = os.listdir(dirctory)\n    out_lst = [os.path.splitext(d)[0] for d in listdir]\n    return out_lst\n\n\ndef train_cv(cfg, df, tokenizer, text_col=None, validation_data=None, get_oof=True):\n    \"\"\"cross validation & get oof\"\"\"\n    oof_df = pd.DataFrame(np.zeros((len(df), len(cfg.target_cols))), columns=cfg.target_cols)\n\n    for i_fold in range(cfg.n_fold):\n\n        if i_fold in cfg.trn_fold:\n            filename = f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}\"\n            filelist = get_filname_listdir(cfg.EXP_MODEL)\n\n            val_mask = (df[\"fold\"] == i_fold).astype(bool)\n            train_df = df[~val_mask].reset_index(drop=True)\n            valid_df = df[val_mask].reset_index(drop=True)\n\n            if not filename in filelist:\n                print(f\"# --------- # Start Training Fold={i_fold} # --------- #\")\n                # training\n                train_fold(\n                    cfg=cfg, \n                    train_df=train_df, \n                    valid_df=valid_df, \n                    tokenizer=tokenizer, \n                    filename=filename, \n                    text_col=text_col\n                    )\n\n            # get validation data score\n            if validation_data is not None:\n                validation_data_hat = get_validation_data_hat(cfg, tokenizer, filename, validation_data)\n                val_score = get_score(validation_data_hat)\n                log = f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}: validation data score={val_score:.4f}\"\n                cfg.logger.info(log)\n\n            # get validation prediction\n            if get_oof:\n                preds = predict(\n                    cfg=cfg,\n                    df=valid_df, \n                    tokenizer=tokenizer, \n                    filename=filename, \n                    text_col=text_col)\n                \n                oof_df.loc[val_mask] = preds\n                return oof_df\n\n\ndef predict(cfg, df, tokenizer, filename, text_col):\n    test_dataset = JigsawTestDataset(\n        cfg=cfg, tokenizer=tokenizer, df=df, text_col=text_col)\n    \n    test_dataloader = DataLoader(\n        test_dataset,\n        batch_size=cfg.valid_batch_size,\n        shuffle=False,\n        num_workers=cfg.num_workers, \n        pin_memory=True, \n        drop_last=False\n        ) \n    \n    lightning_model = JigsawModel(cfg=cfg).to(cfg.DEVICE).eval()\n    checkpoint_path = os.path.join(cfg.EXP_MODEL, filename + \".ckpt\") \n    lightning_model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n\n    num_targets = len(cfg.target_cols)\n    preds = np.zeros((len(df), num_targets))  # N * num targets\n    fill_start_idx = 0\n\n    for inputs in tqdm(test_dataloader,total=len(test_dataloader)):\n        # get predicted labels by batch\n        for k, v in inputs.items():\n            inputs[k] = v.to(cfg.DEVICE)\n\n        with torch.no_grad():\n            pred = lightning_model(inputs)\n            pred = pred.cpu().numpy()  # bs * num targets\n        \n        fill_end_idx = pred.shape[0] + fill_start_idx  # bs + idx\n        preds[fill_start_idx:fill_end_idx] = pred\n        fill_start_idx = fill_end_idx\n        \n    \n    del test_dataset, test_dataloader, lightning_model\n    gc.collect()\n\n    return preds\n\n\ndef predict_cv(cfg, df, tokenizer, text_col):\n    num_targets = len(cfg.target_cols)\n    preds = []\n    \n    for i_fold in range(cfg.n_fold):\n        if i_fold in cfg.trn_fold:\n            filename =f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}\"\n            preds_fold = predict(cfg, df, tokenizer, filename, text_col)\n            preds.append(preds_fold)\n    \n    preds = np.mean(preds, axis=0)  # fold mean\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.895112Z","iopub.execute_input":"2022-02-07T07:50:33.895325Z","iopub.status.idle":"2022-02-07T07:50:33.925445Z","shell.execute_reply.started":"2022-02-07T07:50:33.895292Z","shell.execute_reply":"2022-02-07T07:50:33.924477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Load Model\n# =============================\ndef get_tokenizer(cfg):\n\n    pretrained_dir = os.path.join(cfg.EXP_MODEL, \"Pretrain\")\n    tokenizer_path = os.path.join(pretrained_dir, \"tokenizer_config.json\")  # tokenizer.json??\n    if not os.path.isfile(tokenizer_path):\n        tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n        tokenizer.save_pretrained(pretrained_dir)\n    \n    else:\n        tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n\n    return tokenizer\n\n\ndef get_backborn(cfg):\n    pretrained_dir = os.path.join(cfg.EXP_MODEL, \"Pretrain\")\n    backborn_path = os.path.join(pretrained_dir, \"pytorch_model.bin\")\n    if not os.path.isfile(backborn_path):\n        model_config = AutoConfig.from_pretrained(cfg.model_name)\n\n        # No dropout\n        model_config.attention_probs_dropout_prob = 0.0\n        model_config.hidden_dropout_prob = 0.0\n\n        backborn = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n\n        backborn.save_pretrained(pretrained_dir)\n    \n    else:\n        model_config = AutoConfig.from_pretrained(pretrained_dir)\n\n        # No dropout\n        model_config.attention_probs_dropout_prob = 0.0\n        model_config.hidden_dropout_prob = 0.0\n        \n        if cfg.use_pretrain_model:\n            backborn = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n        else:\n            backborn = AutoModel.from_config(model_config)  # inference 時は pretrain weight いらない：cfg.use_pretrain_model=False\n\n    return backborn","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.92706Z","iopub.execute_input":"2022-02-07T07:50:33.927334Z","iopub.status.idle":"2022-02-07T07:50:33.940782Z","shell.execute_reply.started":"2022-02-07T07:50:33.927284Z","shell.execute_reply":"2022-02-07T07:50:33.940061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Create Data\n# =============================\ndef read_csv(filepath, **kwargs):\n    if os.path.isdir(filepath):\n        filename = filepath.split(\"/\")[-1]\n        filepath = os.path.join(filepath, filename)\n        \n    try:\n        csv_data = pd.read_csv(filepath,  **kwargs)\n    except:\n        csv_data = pd.read_csv(filepath + \".zip\",  **kwargs)\n\n    return csv_data\n\n\ndef text_cleaning(text):\n    '''\n    ref) # https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train\n\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n    text = ipPattern.sub(r'', text)\n    bikkuri = re.compile('!') # Removes bikkuri\n    text = bikkuri.sub(r' ', text)\n    text = text.replace('\\n','')\n    text = text.replace(\"\\'\",\"\")\n    text = text.replace(\"|\",\"\")\n    text = text.replace(\"=\",\"\")\n    text = text.replace(\"F**K\", \"FUCK\")\n    text = text.replace(\"F__K\", \"FUCK\")\n    text = text.replace(\"f**k\", \"fuck\")\n    text = text.replace(\"f__k\", \"fuck\")\n    text = text.replace(\"f*ck\", \"fuck\")    \n    text = text.replace(\"S$X\", \"SEX\")\n    text = text.replace(\"s$x\", \"sex\")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\"YOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUUUUUUUUUU\", \"YOU\")\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    return text\n\n\ndef text_normalization(s:pd.Series):\n    x = s.apply(text_cleaning)\n    return x\n\n\ndef get_jigsaw_01_dataset(cfg):\n    \"\"\"\n    jigsaw-toxic-comment-classification-challenge\n    - text_col : \"comment_text2\n    - target_cols : [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\n    \"\"\"\n    jigsaw1_train = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"train.csv\"))\n    jigsaw1_test = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"test.csv\"))\n    jigsaw1_test_label = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"test_labels.csv\"))\n    scoring_mask = jigsaw1_test_label[\"toxic\"] != -1\n    jigsaw1_test = pd.merge(jigsaw1_test[scoring_mask], jigsaw1_test_label[scoring_mask], on=\"id\", how=\"left\")\n    jigsaw1_train = pd.concat([jigsaw1_train, jigsaw1_test], axis=0).reset_index(drop=True)\n\n    return jigsaw1_train\n\n\ndef get_jigsaw_02_dataset(cfg, cat_threshold=0.5):\n    \"\"\"\n    jigsaw-unintended-bias-in-toxicity-classification\n    - text_col : \"comment_text\"\n    - target_cols : [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    \"\"\"\n    jigsaw2_data = read_csv(os.path.join(cfg.INPUT_JIGSAW_02 , \"all_data.csv\"), usecols=[\"id\", \"comment_text\"])\n    jigsaw2_labels = read_csv(os.path.join(cfg.INPUT_JIGSAW_02 , \"toxicity_individual_annotations.csv\"))\n    jigsaw2_agg_labels = jigsaw2_labels.groupby([\"id\"]).agg(\"mean\")\n\n    if cat_threshold is not None:\n        jigsaw2_agg_labels = pd.DataFrame(\n            np.where(jigsaw2_agg_labels >= cat_threshold, 1, 0), \n            index=jigsaw2_agg_labels.index,\n            columns=jigsaw2_agg_labels.columns)\n    \n    jigsaw2_train = pd.merge(jigsaw2_data, jigsaw2_agg_labels, on=\"id\", how=\"left\")\n    jigsaw2_train = jigsaw2_train.dropna(axis=0).reset_index(drop=True)\n    jigsaw2_train = (jigsaw2_train.\n                        rename(columns={\"identity_attack\":\"identity_hate\"}).\n                        drop([\"sexual_explicit\", \"worker\"], axis=1))\n    \n    return jigsaw2_train\n\n\ndef get_ruddit_dataset(cfg):\n    \"\"\"\n    Ruddit Dataset\n    - text_col : \"comment_text\"\n    - target_cols : \"offensiveness_score\"\n    \"\"\"\n    ruddit_df = read_csv(os.path.join(cfg.INPUT_RUDDIT, \"Dataset\", \"ruddit_with_text.csv\"))\n    ruddit_df = ruddit_df[~ruddit_df[\"txt\"].isin([\"[deleted]\", \"[removed]\"])].reset_index(drop=True)\n    # ruddit_df[\"comment_text\"] = text_normalization(ruddit_df[\"txt\"])\n    ruddit_df[\"comment_text\"] = ruddit_df[\"txt\"].fillna(\"none\")\n    return ruddit_df.drop(\"txt\", axis=1)\n\n\ndef get_fold_idx(cfg, df):\n    df[\"fold\"] = -1\n    y = df[cfg.target_cols].sum(axis=1)\n    cv_strategy = KFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n    for i_fold, (tr_idx, va_idx) in enumerate(cv_strategy.split(X=df, y=y)):\n        df.loc[va_idx, \"fold\"] = i_fold\n    \n    return df\n\n\ndef get_custom_jigsaw_dataset(cfg, train_data, validation_data):\n    \"\"\"\n    ref) https://www.kaggle.com/toru59er/0-866-tfidf-ridge-simple-baseline\n    target_cols : [\"toxic_score\"]\n    weighted sum of targets:[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    undersampling\n    \"\"\"\n\n    train_data[\"toxic_score\"] = train_data[cfg.target_cols].sum(axis=1)\n    \n    # undersample\n    toxic_mask = (train_data[\"toxic_score\"] > 0).astype(bool)\n    min_len = np.sum(toxic_mask)\n\n    sampled_data = train_data[train_data[\"toxic_score\"] == 0].sample(n=min_len, random_state=cfg.seed)\n    train_data = pd.concat([train_data[toxic_mask], sampled_data]).reset_index(drop=True).drop(\"toxic_score\", axis=1)\n\n    val_comment_unq = np.unique(validation_data['less_toxic'].tolist() + validation_data['more_toxic'].tolist())\n    duplicate_idx = np.isin(train_data['comment_text'], val_comment_unq)\n    train_data = train_data.iloc[~duplicate_idx].reset_index(drop=True)\n\n    return train_data","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.942298Z","iopub.execute_input":"2022-02-07T07:50:33.942742Z","iopub.status.idle":"2022-02-07T07:50:33.974012Z","shell.execute_reply.started":"2022-02-07T07:50:33.942704Z","shell.execute_reply":"2022-02-07T07:50:33.973229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"# ------------------ # Load Data # ------------------ #\")\n\n# load tokenizer\ntokenizer = get_tokenizer(Config)\n\ncomments_to_score = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"comments_to_score.csv\"))\n\nif len(comments_to_score) == 7537:\n    comments_to_score = comments_to_score.iloc[:100]\n    \n# comments_to_score[\"text\"] = text_normalization(comments_to_score[\"text\"])\nsample_submission = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"sample_submission.csv\"))\n\nif not Config.inference_only:\n\n    # load validation data\n    validation_data = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"validation_data.csv\"))\n\n    # load train data\n    train_data = read_csv(\"/content/drive/Shareddrives/Jigsaw-Rate-Severity-of-Toxic-Comments/mst8823/Input/PseudoLabelDataset-Jigsaw1.csv\")\n    train_data = get_custom_jigsaw_dataset(Config, train_data, validation_data)\n    train_data = get_fold_idx(cfg=Config, df=train_data)\n\n    # train_data[\"comment_text\"] = text_normalization(train_data[\"comment_text\"])\n    # validation_data[\"less_toxic\"] = text_normalization(validation_data[\"less_toxic\"])\n    # validation_data[\"more_toxic\"] = text_normalization(validation_data[\"more_toxic\"])\n\n    print(\"# ------------------ # Training # ------------------ #\")\n    # training\n    train_cv(\n        cfg=Config, \n        df=train_data, \n        tokenizer=tokenizer, \n        text_col=\"comment_text\",  #comment_text\n        validation_data=validation_data, \n        get_oof=False)\n\n    print(\"# ------------------ # Validation # ------------------ #\")\n    # validation\n    validation_data_hat = get_validation_data_hat(\n        cfg=Config, \n        tokenizer=tokenizer, \n        filename=None, \n        validation_data=validation_data\n        )\n    filepath = os.path.join(Config.EXP_PREDS, \"validation_data.csv\")\n    validation_data_hat.to_csv(filepath, index=False)\n    score = get_score(validation_data_hat)\n    Config.logger.info(f\"validation score = {score:.4f}\")\n\nprint(\"# ------------------ # Inference # ------------------ #\")\npreds = predict_cv(\n    cfg=Config, \n    df=comments_to_score, \n    tokenizer=tokenizer, \n    text_col=\"text\")\n\nprint(preds.shape)\nif np.ndim(preds) > 1:\n    mst030 = np.mean(preds, axis=1)  # mean of target\nelse:\n    mst030 = preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:50:33.975789Z","iopub.execute_input":"2022-02-07T07:50:33.976449Z","iopub.status.idle":"2022-02-07T07:54:18.203715Z","shell.execute_reply.started":"2022-02-07T07:50:33.976415Z","shell.execute_reply":"2022-02-07T07:54:18.202871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MSTtweet","metadata":{}},{"cell_type":"code","source":"\"\"\"\npseudo labeling\ntweet dataset\n\"\"\"\nclass Config:\n    author = \"mst8823\"\n    wandb_entity = \"mst8823\"\n    \n    competition = \"jigsaw-toxic-severity-rating\"\n    name = \"Pseudo-Labeling-001\"\n    debug = False\n    inference_only = True\n    use_pretrain_model = False\n    target_cols = [\"pseudo_label\"]\n    \n    model_name = \"unitary/multilingual-toxic-xlm-roberta\"\n    hidden_size = 768\n    head = 256\n    tail = 0\n    max_length = head + tail\n\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    seed = 2022\n\n    max_epochs = 4\n    gradient_clip_val = 100\n    accumulate_grad_batches = 1\n    early_stopping = False\n    optimizer = dict(\n        optimizer=\"AdamW\", \n        lr=1e-5, \n        weight_decay=2e-5\n        )\n    scheduler = dict(\n        interval = \"step\",\n        scheduler=\"CosineAnnealingWarmupRestarts\",\n        max_lr=1e-5,\n        min_lr=1e-6,\n        T_mult=1,\n        warmup_steps=10,\n        gamma=1)\n    \n    train_batch_size = 8\n    valid_batch_size = 32\n    num_workers = 4\n    resume_from_checkpoint = None\n\n    colab_dir = \"/content/drive/Shareddrives/Jigsaw-Rate-Severity-of-Toxic-Comments\"\n    drive_path = colab_dir + f\"/{author}\"\n    api_path = drive_path + \"/kaggle.json\"\n\n    upload_from_colab = False\n    kaggle_dataset_path = \"../input/pseudo-labeling-001-code-fit\"\n\n    \"\"\"\n    - step scheduler example\n    scheduler = dict(\n        interval = \"step\",\n        scheduler=\"get_cosine_schedule_with_warmup\",\n        num_warmup_steps=256, \n        num_cycles=0.5)\n\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.205385Z","iopub.execute_input":"2022-02-07T07:54:18.205668Z","iopub.status.idle":"2022-02-07T07:54:18.225447Z","shell.execute_reply.started":"2022-02-07T07:54:18.205631Z","shell.execute_reply":"2022-02-07T07:54:18.224577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport logging\nimport shutil\nimport json\nimport datetime\nimport requests\nimport itertools\nimport functools\nimport warnings\nimport joblib\nimport gc\nimport random\nimport string\nimport re\nimport collections\n\nimport pandas as pd\nimport numpy as np\nimport nltk\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom scipy.special import softmax\nfrom bs4 import BeautifulSoup\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, AdamW\nfrom torch.optim.lr_scheduler import (\n    CosineAnnealingWarmRestarts,\n    CosineAnnealingLR,\n    MultiStepLR, \n    ReduceLROnPlateau\n    )\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.229552Z","iopub.execute_input":"2022-02-07T07:54:18.230226Z","iopub.status.idle":"2022-02-07T07:54:18.24867Z","shell.execute_reply.started":"2022-02-07T07:54:18.230186Z","shell.execute_reply":"2022-02-07T07:54:18.247984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =========================\n# Utils\n# =========================\nclass Logger:\n    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n    def __init__(self, path):\n        self.general_logger = logging.getLogger(path)\n        stream_handler = logging.StreamHandler()\n        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n        if len(self.general_logger.handlers) == 0:\n            self.general_logger.addHandler(stream_handler)\n            self.general_logger.addHandler(file_general_handler)\n            self.general_logger.setLevel(logging.INFO)\n\n    def info(self, message):\n        # display time\n        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n\n    @staticmethod\n    def now_string():\n        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\n\ndef seed_everything(seed=2022):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef setup(cfg):\n    cfg.COLAB = \"google.colab\" in sys.modules\n    if cfg.COLAB:\n        print(\"This environment is Google Colab\")\n        \n        # mount\n        from google.colab import drive\n        if not os.path.isdir(\"/content/drive\"):\n            drive.mount('/content/drive') \n        \n        # import library\n        ! pip install --quiet pytorch_lightning\n        ! pip install --quiet transformers\n        ! pip install --quiet wandb\n        ! pip install --quiet sentencepiece\n        ! pip install --quiet 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n\n        # use kaggle api (need kaggle token)\n        f = open(cfg.api_path, 'r')\n        json_data = json.load(f) \n        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n        os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n        \n        # set dirs\n        cfg.DRIVE = cfg.drive_path\n        cfg.EXP = (cfg.name if cfg.name is not None \n            else requests.get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6])\n        cfg.INPUT = os.path.join(cfg.DRIVE, \"Input\")\n        cfg.OUTPUT = os.path.join(cfg.DRIVE, \"Output\")\n        cfg.SUBMISSION = os.path.join(cfg.DRIVE, \"Submission\")\n        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, \"model\")\n        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, \"fig\")\n        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, \"preds\")\n\n        # input data\n        cfg.INPUT_JIGSAW_01 = os.path.join(cfg.INPUT, \"jigsaw-toxic-comment-classification-challenge\")\n        cfg.INPUT_JIGSAW_02 = os.path.join(cfg.INPUT, \"jigsaw-unintended-bias-in-toxicity-classification\")\n        cfg.INPUT_JIGSAW_03 = os.path.join(cfg.INPUT, \"jigsaw-multilingual-toxic-comment-classification\")\n        cfg.INPUT_JIGSAW_04 = os.path.join(cfg.INPUT, \"jigsaw-toxic-severity-rating\")\n        cfg.INPUT_RUDDIT = os.path.join(cfg.INPUT, \"ruddit-jigsaw-dataset\")\n        cfg.jigsaw_inputs = [cfg.INPUT_JIGSAW_01, cfg.INPUT_JIGSAW_02, cfg.INPUT_JIGSAW_03, cfg.INPUT_JIGSAW_04, \n                             cfg.INPUT_RUDDIT]\n\n        # make dirs\n        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS] + cfg.jigsaw_inputs:\n            os.makedirs(d, exist_ok=True)\n\n        if not os.path.isfile(os.path.join(cfg.INPUT_JIGSAW_04, \"comments_to_score.csv\")):\n            print(\"load dataset\")\n            ! pip install --upgrade --force-reinstall --no-deps kaggle\n            ! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p $cfg.INPUT_JIGSAW_01 \n            ! kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification -p $cfg.INPUT_JIGSAW_02 \n            ! kaggle competitions download -c jigsaw-multilingual-toxic-comment-classification -p $cfg.INPUT_JIGSAW_03 \n            ! kaggle competitions download -c jigsaw-toxic-severity-rating -p $cfg.INPUT_JIGSAW_04 \n            ! kaggle datasets download -d rajkumarl/ruddit-jigsaw-dataset -p $cfg.INPUT_RUDDIT\n\n            for input_path in cfg.jigsaw_inputs:\n                filepath = f'{input_path}/{input_path.split(\"/\")[-1]}'\n                ! unzip -d $input_path $filepath\n\n    else:\n        print(\"This environment is Kaggle Kernel\")\n        if not cfg.inference_only:\n            ! pip install --quiet pytorch_lightning==1.5.8 \n            ! pip install --quiet 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n\n        # set dirs\n        cfg.INPUT = f\"../input\"\n\n        # input data\n        cfg.INPUT_JIGSAW_01 = os.path.join(cfg.INPUT, \"jigsaw-toxic-comment-classification-challenge\")\n        cfg.INPUT_JIGSAW_02 = os.path.join(cfg.INPUT, \"jigsaw-unintended-bias-in-toxicity-classification\")\n        cfg.INPUT_JIGSAW_03 = os.path.join(cfg.INPUT, \"jigsaw-multilingual-toxic-comment-classification\")\n        cfg.INPUT_JIGSAW_04 = os.path.join(cfg.INPUT, \"jigsaw-toxic-severity-rating\")\n        cfg.INPUT_RUDDIT = os.path.join(cfg.INPUT, \"ruddit-jigsaw-dataset\")\n        cfg.jigsaw_inputs = [cfg.INPUT_JIGSAW_01, cfg.INPUT_JIGSAW_02, cfg.INPUT_JIGSAW_03, cfg.INPUT_JIGSAW_04, \n                             cfg.INPUT_RUDDIT]\n\n        cfg.EXP = cfg.OUTPUT_EXP = \"./\"\n        if cfg.kaggle_dataset_path is not None:\n            cfg.EXP_MODEL = os.path.join(cfg.kaggle_dataset_path, \"model\")\n        else:\n            cfg.EXP_MODEL = os.path.join(cfg.EXP, \"model\")\n\n        cfg.SUBMISSION = \"./\"\n        cfg.EXP_FIG = os.path.join(cfg.EXP, \"fig\")\n        cfg.EXP_PREDS = os.path.join(cfg.EXP, \"preds\")\n\n        # make dirs\n        make_dirs = [cfg.EXP_FIG, cfg.EXP_PREDS]\n        if not cfg.inference_only:\n            make_dirs.append(cfg.EXP_MODEL)\n        for d in make_dirs:\n            os.makedirs(d, exist_ok=True)\n\n    # set device    \n    cfg.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    warnings.filterwarnings(\"ignore\")\n    seed_everything(cfg.seed)\n\n    cfg.logger = Logger(cfg.OUTPUT_EXP)\n\n    return cfg\n\n\n# =========================\n# SetUp\n# =========================\nConfig = setup(Config)\n\n# 2nd import\nimport pytorch_lightning as pl\nimport wandb\n\nfrom transformers import (AutoConfig, AutoModel, AutoTokenizer)\nfrom transformers import (get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup)\n\nif not Config.inference_only:\n    from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n\n# wandb setting\nif not Config.COLAB:\n    if  not Config.inference_only:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        api_key = user_secrets.get_secret(\"WANDB_API\")\n        wandb.login(key=api_key)\nelse:\n    wandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.250188Z","iopub.execute_input":"2022-02-07T07:54:18.250524Z","iopub.status.idle":"2022-02-07T07:54:18.59237Z","shell.execute_reply.started":"2022-02-07T07:54:18.250486Z","shell.execute_reply":"2022-02-07T07:54:18.591414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Dataset\n# =============================\nclass JigsawTrainDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer, text_col):\n        self.cfg = cfg\n        self.comment_text = df[text_col].values\n        self.targets = df[cfg.target_cols].values\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.comment_text)\n    \n    def __getitem__(self, idx):\n\n        text = str(self.comment_text[idx])\n        inputs = prepare_input(self.cfg, text, self.tokenizer)\n        targets = torch.tensor(self.targets[idx]).float()\n\n        return inputs, targets\n\n\nclass JigsawTestDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer, text_col):\n        self.cfg = cfg\n        self.comment_text = df[text_col].fillna(\"none\").values\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.comment_text)\n    \n    def __getitem__(self, idx):\n        text = str(self.comment_text[idx])\n        inputs = prepare_input(self.cfg, text, self.tokenizer)\n        return inputs\n\n\ndef prepare_input(cfg, text, tokenizer):\n    if cfg.tail == 0:\n        inputs = tokenizer.encode_plus(\n            text, \n            return_tensors=None, \n            add_special_tokens=True, \n            max_length=cfg.max_length,\n            pad_to_max_length=True,\n            truncation=True)\n        \n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n\n    else:\n        inputs = tokenizer.encode_plus(\n            text,\n            return_tensors=None, \n            add_special_tokens=True, \n            truncation=True)\n        \n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > cfg.max_length:\n                v = np.hstack([v[:cfg.head], v[-cfg.tail:]])\n\n            if k == 'input_ids':\n                new_v = np.ones(cfg.max_length) * tokenizer.pad_token_id\n\n            else:\n                new_v = np.zeros(cfg.max_length)\n\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n\n    return inputs\n\n\nclass JigsawDataModule(pl.LightningDataModule):\n    def __init__(self, cfg, tokenizer, train_df, valid_df, text_col):\n        super(JigsawDataModule).__init__()\n\n        self.cfg = cfg\n        self.text_col = text_col\n        self.tokenizer = tokenizer\n        self.train_df = train_df\n        self.valid_df = valid_df\n\n        self.train_dataset = None\n        self.val_dataset = None\n\n    def setup(self, stage=None):\n        self.train_dataset = JigsawTrainDataset(\n            cfg=self.cfg, df=self.train_df, tokenizer=self.tokenizer, text_col=self.text_col)\n        self.val_dataset = JigsawTrainDataset(\n            cfg=self.cfg, df=self.valid_df, tokenizer=self.tokenizer, text_col=self.text_col)\n        \n    def train_dataloader(self):\n        train_dataloader = DataLoader(\n            self.train_dataset, \n            batch_size=self.cfg.train_batch_size, \n            shuffle=True, \n            num_workers=self.cfg.num_workers, \n            pin_memory=True, \n            drop_last=True)\n        \n        return train_dataloader\n\n    def val_dataloader(self):\n        val_dataloader = DataLoader(\n            self.val_dataset,\n            batch_size=self.cfg.valid_batch_size,\n            shuffle=False,\n            num_workers=self.cfg.num_workers, \n            pin_memory=True, \n            drop_last=False)\n\n        return val_dataloader","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.598093Z","iopub.execute_input":"2022-02-07T07:54:18.598506Z","iopub.status.idle":"2022-02-07T07:54:18.632039Z","shell.execute_reply.started":"2022-02-07T07:54:18.598467Z","shell.execute_reply":"2022-02-07T07:54:18.631261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Model\n# =============================\ndef get_optimizer(cfg, parameters):\n    opt = cfg.optimizer\n    if opt[\"optimizer\"] == \"AdamW\":\n        optimizer = AdamW(\n            parameters,\n            lr=opt[\"lr\"],\n            weight_decay=opt[\"weight_decay\"]\n            )\n    \n    elif opt[\"optimizer\"] == \"Adam\":\n        optimizer = Adam(\n            parameters,\n            lr=opt[\"lr\"],\n            weight_decay=opt[\"weight_decay\"]\n            )\n    \n    else:\n        raise NotImplementedError\n    \n    return optimizer\n\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    sch = cfg.scheduler\n    if sch[\"scheduler\"] == \"get_linear_schedule_with_warmup\":\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, \n            num_warmup_steps=sch[\"num_warmup_steps\"],\n            num_training_steps=num_train_steps)\n    \n    elif sch[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=sch[\"num_warmup_steps\"],\n            num_training_steps=num_train_steps,\n            num_cycles=sch[\"num_cycles\"]\n            )\n\n    elif sch[\"scheduler\"] == \"MultiStepLR\":\n        scheduler = MultiStepLR(\n            optimizer, \n            milestones=sch[\"milestones\"], \n            gamma=sch[\"gamma\"]\n        )\n\n    elif sch[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n        \n        first_cycle_steps = (num_train_steps // cfg.max_epochs) * cfg.train_batch_size\n        print(first_cycle_steps)\n        scheduler = CosineAnnealingWarmupRestarts(\n            optimizer,\n            first_cycle_steps=int(first_cycle_steps),\n            cycle_mult=sch['T_mult'],\n            max_lr=sch[\"max_lr\"],\n            min_lr=sch['min_lr'],\n            warmup_steps=sch['warmup_steps'],\n            gamma=sch['gamma']\n        )\n    else:\n        raise NotImplementedError\n    \n    return scheduler\n\n\nclass JigsawModel(pl.LightningModule):\n    def __init__(self, cfg):\n        super(JigsawModel, self).__init__()\n        self.cfg = cfg\n        self.total_steps = None\n        self.dataset_size = None\n\n        self.backborn = get_backborn(cfg)   \n        self.out = nn.Linear(cfg.hidden_size, len(cfg.target_cols))\n\n    def forward(self, inputs):\n        x = self.backborn(**inputs)\n        x = x[0]\n        x = x[:, 0, :]\n\n        x_out = self.out(x)\n\n        return x_out\n\n    def training_step(self, batch, batch_idx):\n        inputs, targets = batch\n        outputs = self.forward(inputs)\n        loss = self.loss(outputs, targets)\n        self.log(\"train_loss\", loss, on_step=True, logger=True, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        inputs, targets = batch\n        outputs = self.forward(inputs)\n        loss = self.loss(outputs, targets)\n        self.log(\"val_loss\", loss, on_step=True, logger=True, prog_bar=True)\n        return loss\n\n    def loss(self, outputs, targets):\n        loss_fn = nn.MSELoss()\n        loss = loss_fn(outputs, targets)\n        # loss = torch.sqrt(loss)\n        return loss\n\n    def setup(self, stage=None):\n        if stage != \"fit\":\n            return\n\n        # calculate total steps\n        if self.dataset_size is None:\n            dataset = self.trainer._data_connector._train_dataloader_source.dataloader()\n            self.dataset_size = len(dataset)\n        num_devices = max(1, self.trainer.num_gpus, self.trainer.num_processes)  # gpus=-1だとそれが反映されちゃう\n        effective_batch_size = self.cfg.train_batch_size * self.trainer.accumulate_grad_batches * num_devices\n        print(self.dataset_size, effective_batch_size)\n        self.total_steps = (self.dataset_size // effective_batch_size) * self.cfg.max_epochs\n\n    def configure_optimizers(self):\n        optimizer = get_optimizer(self.cfg, parameters=self.parameters())\n\n        if self.cfg.scheduler is None:\n            return [optimizer]\n        else:\n            scheduler = get_scheduler(self.cfg, optimizer, num_train_steps=self.total_steps)\n            return [optimizer], [{\"scheduler\": scheduler, \"interval\": self.cfg.scheduler[\"interval\"]}]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.634349Z","iopub.execute_input":"2022-02-07T07:54:18.63488Z","iopub.status.idle":"2022-02-07T07:54:18.667555Z","shell.execute_reply.started":"2022-02-07T07:54:18.634809Z","shell.execute_reply":"2022-02-07T07:54:18.665742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Metrics\n# ============================= \ndef get_validation_data_hat(cfg, tokenizer, filename, validation_data):\n    validation_data_ = validation_data.copy()\n    df = pd.DataFrame({\"text\":sorted(set(validation_data_[\"less_toxic\"].unique()) |\n                                     set(validation_data_[\"more_toxic\"].unique()))})\n    \n    if filename is None:\n        preds = predict_cv(cfg, df, tokenizer, text_col=\"text\")\n    else:\n        preds = predict(cfg, df, tokenizer, filename, text_col=\"text\")\n\n    if np.ndim(preds) > 1:\n        df[\"preds\"] = np.mean(preds, axis=1)  # mean of targets\n    else:\n        df[\"preds\"] = preds.reshape(-1)\n\n    validation_data_ = (pd.merge(\n        validation_data_, df, left_on=\"less_toxic\", right_on=\"text\", how=\"left\").\n        rename(columns={\"preds\":\"less_toxic_preds\"}).\n        drop(\"text\", axis=1))\n    \n    validation_data_ = (pd.merge(\n        validation_data_, df, left_on=\"more_toxic\", right_on=\"text\", how=\"left\").\n        rename(columns={\"preds\":\"more_toxic_preds\"}).\n        drop(\"text\", axis=1))\n    \n    return validation_data_\n\n\ndef get_score(validation_data_hat):\n    less_toxic, more_toxic = validation_data_hat[\"less_toxic_preds\"], validation_data_hat[\"more_toxic_preds\"]\n    return np.mean(more_toxic > less_toxic)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.671042Z","iopub.execute_input":"2022-02-07T07:54:18.671385Z","iopub.status.idle":"2022-02-07T07:54:18.687834Z","shell.execute_reply.started":"2022-02-07T07:54:18.671344Z","shell.execute_reply":"2022-02-07T07:54:18.686823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Train & Predict\n# =============================\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\n\ndef train_fold(cfg, train_df, valid_df, tokenizer, filename, text_col):\n\n    wandblogger = pl.loggers.WandbLogger(\n        project=cfg.competition, \n        config=class2dict(cfg),\n        group=f\"{cfg.author}_{cfg.name}\",  \n        name=\"_\".join(filename.split(\"-\")[-2:]),\n        job_type=\"train\",\n        reinit=True,\n        anonymous=None,\n        entity=cfg.wandb_entity\n        )\n\n    lightning_datamodule = JigsawDataModule(\n        cfg=cfg, \n        tokenizer=tokenizer,\n        train_df=train_df, \n        valid_df=valid_df, \n        text_col=text_col\n        )\n    \n    lightning_model = JigsawModel(cfg=cfg)\n    lightning_model.dataset_size = len(train_df)  # cuz setup donot work?\n\n    checkpoint = pl.callbacks.ModelCheckpoint(\n        dirpath=cfg.EXP_MODEL,\n        filename=filename,\n        save_top_k=1,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\",\n    )\n    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n    callbacks = [checkpoint, lr_monitor]\n\n    if cfg.early_stopping:\n        early_stopping = pl.callbacks.EarlyStopping(\n            monitor=\"val_loss\", \n            min_delta=0.0, \n            patience=8, \n            mode='min', \n        )\n        callbacks += [early_stopping]\n    \n    trainer = pl.Trainer(\n        max_epochs=cfg.max_epochs,\n        callbacks=callbacks,\n        logger=[wandblogger],\n        gradient_clip_val=cfg.gradient_clip_val,\n        accumulate_grad_batches=cfg.accumulate_grad_batches,\n        resume_from_checkpoint=cfg.resume_from_checkpoint,\n        deterministic=False,\n        gpus=-1,\n        precision=16,\n    )\n\n    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n    wandb.finish(quiet=True)\n    torch.cuda.empty_cache()\n\n\ndef get_filname_listdir(dirctory):\n    listdir = os.listdir(dirctory)\n    out_lst = [os.path.splitext(d)[0] for d in listdir]\n    return out_lst\n\n\ndef train_cv(cfg, df, tokenizer, text_col=None, validation_data=None, get_oof=True):\n    \"\"\"cross validation & get oof\"\"\"\n    oof_df = pd.DataFrame(np.zeros((len(df), len(cfg.target_cols))), columns=cfg.target_cols)\n\n    for i_fold in range(cfg.n_fold):\n\n        if i_fold in cfg.trn_fold:\n            filename = f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}\"\n            filelist = get_filname_listdir(cfg.EXP_MODEL)\n\n            val_mask = (df[\"fold\"] == i_fold).astype(bool)\n            train_df = df[~val_mask].reset_index(drop=True)\n            valid_df = df[val_mask].reset_index(drop=True)\n\n            if not filename in filelist:\n                print(f\"# --------- # Start Training Fold={i_fold} # --------- #\")\n                # training\n                train_fold(\n                    cfg=cfg, \n                    train_df=train_df, \n                    valid_df=valid_df, \n                    tokenizer=tokenizer, \n                    filename=filename, \n                    text_col=text_col\n                    )\n\n            # get validation data score\n            if validation_data is not None:\n                validation_data_hat = get_validation_data_hat(cfg, tokenizer, filename, validation_data)\n                val_score = get_score(validation_data_hat)\n                log = f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}: validation data score={val_score:.4f}\"\n                cfg.logger.info(log)\n\n            # get validation prediction\n            if get_oof:\n                preds = predict(\n                    cfg=cfg,\n                    df=valid_df, \n                    tokenizer=tokenizer, \n                    filename=filename, \n                    text_col=text_col)\n                \n                oof_df.loc[val_mask] = preds\n                return oof_df\n\n\ndef predict(cfg, df, tokenizer, filename, text_col):\n    test_dataset = JigsawTestDataset(\n        cfg=cfg, tokenizer=tokenizer, df=df, text_col=text_col)\n    \n    test_dataloader = DataLoader(\n        test_dataset,\n        batch_size=cfg.valid_batch_size,\n        shuffle=False,\n        num_workers=cfg.num_workers, \n        pin_memory=True, \n        drop_last=False\n        ) \n    \n    lightning_model = JigsawModel(cfg=cfg).to(cfg.DEVICE).eval()\n    checkpoint_path = os.path.join(cfg.EXP_MODEL, filename + \".ckpt\") \n    lightning_model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n\n    num_targets = len(cfg.target_cols)\n    preds = np.zeros((len(df), num_targets))  # N * num targets\n    fill_start_idx = 0\n\n    for inputs in tqdm(test_dataloader,total=len(test_dataloader)):\n        # get predicted labels by batch\n        for k, v in inputs.items():\n            inputs[k] = v.to(cfg.DEVICE)\n\n        with torch.no_grad():\n            pred = lightning_model(inputs)\n            pred = pred.cpu().numpy()  # bs * num targets\n        \n        fill_end_idx = pred.shape[0] + fill_start_idx  # bs + idx\n        preds[fill_start_idx:fill_end_idx] = pred\n        fill_start_idx = fill_end_idx\n        \n    \n    del test_dataset, test_dataloader, lightning_model\n    gc.collect()\n\n    return preds\n\n\ndef predict_cv(cfg, df, tokenizer, text_col):\n    num_targets = len(cfg.target_cols)\n    preds = []\n    \n    for i_fold in range(cfg.n_fold):\n        if i_fold in cfg.trn_fold:\n            filename =f\"{cfg.name}-seed{cfg.seed}-fold{i_fold}\"\n            preds_fold = predict(cfg, df, tokenizer, filename, text_col)\n            preds.append(preds_fold)\n    \n    preds = np.mean(preds, axis=0)  # fold mean\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.689896Z","iopub.execute_input":"2022-02-07T07:54:18.690254Z","iopub.status.idle":"2022-02-07T07:54:18.746858Z","shell.execute_reply.started":"2022-02-07T07:54:18.690208Z","shell.execute_reply":"2022-02-07T07:54:18.744994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Load Model\n# =============================\ndef get_tokenizer(cfg):\n\n    pretrained_dir = os.path.join(cfg.EXP_MODEL, \"Pretrain\")\n    tokenizer_path = os.path.join(pretrained_dir, \"tokenizer_config.json\")  # tokenizer.json??\n    if not os.path.isfile(tokenizer_path):\n        tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n        tokenizer.save_pretrained(pretrained_dir)\n    \n    else:\n        tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n\n    return tokenizer\n\n\ndef get_backborn(cfg):\n    pretrained_dir = os.path.join(cfg.EXP_MODEL, \"Pretrain\")\n    backborn_path = os.path.join(pretrained_dir, \"pytorch_model.bin\")\n    if not os.path.isfile(backborn_path):\n        model_config = AutoConfig.from_pretrained(cfg.model_name)\n\n        # No dropout\n        model_config.attention_probs_dropout_prob = 0.0\n        model_config.hidden_dropout_prob = 0.0\n\n        backborn = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n\n        backborn.save_pretrained(pretrained_dir)\n    \n    else:\n        model_config = AutoConfig.from_pretrained(pretrained_dir)\n\n        # No dropout\n        model_config.attention_probs_dropout_prob = 0.0\n        model_config.hidden_dropout_prob = 0.0\n        \n        if cfg.use_pretrain_model:\n            backborn = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n        else:\n            backborn = AutoModel.from_config(model_config)  # inference 時は pretrain weight いらない：cfg.use_pretrain_model=False\n\n    return backborn","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.748203Z","iopub.execute_input":"2022-02-07T07:54:18.74853Z","iopub.status.idle":"2022-02-07T07:54:18.759697Z","shell.execute_reply.started":"2022-02-07T07:54:18.748491Z","shell.execute_reply":"2022-02-07T07:54:18.758912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================\n# Create Data\n# =============================\ndef read_csv(filepath, **kwargs):\n    if os.path.isdir(filepath):\n        filename = filepath.split(\"/\")[-1]\n        filepath = os.path.join(filepath, filename)\n        \n    try:\n        csv_data = pd.read_csv(filepath,  **kwargs)\n    except:\n        csv_data = pd.read_csv(filepath + \".zip\",  **kwargs)\n\n    return csv_data\n\n\ndef text_cleaning(text):\n    '''\n    ref) # https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train\n\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n    text = ipPattern.sub(r'', text)\n    bikkuri = re.compile('!') # Removes bikkuri\n    text = bikkuri.sub(r' ', text)\n    text = text.replace('\\n','')\n    text = text.replace(\"\\'\",\"\")\n    text = text.replace(\"|\",\"\")\n    text = text.replace(\"=\",\"\")\n    text = text.replace(\"F**K\", \"FUCK\")\n    text = text.replace(\"F__K\", \"FUCK\")\n    text = text.replace(\"f**k\", \"fuck\")\n    text = text.replace(\"f__k\", \"fuck\")\n    text = text.replace(\"f*ck\", \"fuck\")    \n    text = text.replace(\"S$X\", \"SEX\")\n    text = text.replace(\"s$x\", \"sex\")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\"YOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUUUUUUUUUU\", \"YOU\")\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    return text\n\n\ndef text_normalization(s:pd.Series):\n    x = s.apply(text_cleaning)\n    return x\n\n\ndef get_jigsaw_01_dataset(cfg):\n    \"\"\"\n    jigsaw-toxic-comment-classification-challenge\n    - text_col : \"comment_text2\n    - target_cols : [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\n    \"\"\"\n    jigsaw1_train = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"train.csv\"))\n    jigsaw1_test = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"test.csv\"))\n    jigsaw1_test_label = read_csv(os.path.join(cfg.INPUT_JIGSAW_01 , \"test_labels.csv\"))\n    scoring_mask = jigsaw1_test_label[\"toxic\"] != -1\n    jigsaw1_test = pd.merge(jigsaw1_test[scoring_mask], jigsaw1_test_label[scoring_mask], on=\"id\", how=\"left\")\n    jigsaw1_train = pd.concat([jigsaw1_train, jigsaw1_test], axis=0).reset_index(drop=True)\n\n    return jigsaw1_train\n\n\ndef get_jigsaw_02_dataset(cfg, cat_threshold=0.5):\n    \"\"\"\n    jigsaw-unintended-bias-in-toxicity-classification\n    - text_col : \"comment_text\"\n    - target_cols : [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    \"\"\"\n    jigsaw2_data = read_csv(os.path.join(cfg.INPUT_JIGSAW_02 , \"all_data.csv\"), usecols=[\"id\", \"comment_text\"])\n    jigsaw2_labels = read_csv(os.path.join(cfg.INPUT_JIGSAW_02 , \"toxicity_individual_annotations.csv\"))\n    jigsaw2_agg_labels = jigsaw2_labels.groupby([\"id\"]).agg(\"mean\")\n\n    if cat_threshold is not None:\n        jigsaw2_agg_labels = pd.DataFrame(\n            np.where(jigsaw2_agg_labels >= cat_threshold, 1, 0), \n            index=jigsaw2_agg_labels.index,\n            columns=jigsaw2_agg_labels.columns)\n    \n    jigsaw2_train = pd.merge(jigsaw2_data, jigsaw2_agg_labels, on=\"id\", how=\"left\")\n    jigsaw2_train = jigsaw2_train.dropna(axis=0).reset_index(drop=True)\n    jigsaw2_train = (jigsaw2_train.\n                        rename(columns={\"identity_attack\":\"identity_hate\"}).\n                        drop([\"sexual_explicit\", \"worker\"], axis=1))\n    \n    return jigsaw2_train\n\n\ndef get_ruddit_dataset(cfg):\n    \"\"\"\n    Ruddit Dataset\n    - text_col : \"comment_text\"\n    - target_cols : \"offensiveness_score\"\n    \"\"\"\n    ruddit_df = read_csv(os.path.join(cfg.INPUT_RUDDIT, \"Dataset\", \"ruddit_with_text.csv\"))\n    ruddit_df = ruddit_df[~ruddit_df[\"txt\"].isin([\"[deleted]\", \"[removed]\"])].reset_index(drop=True)\n    # ruddit_df[\"comment_text\"] = text_normalization(ruddit_df[\"txt\"])\n    ruddit_df[\"comment_text\"] = ruddit_df[\"txt\"].fillna(\"none\")\n    return ruddit_df.drop(\"txt\", axis=1)\n\n\ndef get_fold_idx(cfg, df):\n    df[\"fold\"] = -1\n    y = df[cfg.target_cols].sum(axis=1)\n    cv_strategy = KFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n    for i_fold, (tr_idx, va_idx) in enumerate(cv_strategy.split(X=df, y=y)):\n        df.loc[va_idx, \"fold\"] = i_fold\n    \n    return df\n\n\ndef get_custom_jigsaw_dataset(cfg, train_data, validation_data):\n    \"\"\"\n    ref) https://www.kaggle.com/toru59er/0-866-tfidf-ridge-simple-baseline\n    target_cols : [\"toxic_score\"]\n    weighted sum of targets:[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    undersampling\n    \"\"\"\n\n    train_data[\"toxic_score\"] = train_data[cfg.target_cols].sum(axis=1)\n    \n    # undersample\n    toxic_mask = (train_data[\"toxic_score\"] > 0).astype(bool)\n    min_len = np.sum(toxic_mask)\n\n    sampled_data = train_data[train_data[\"toxic_score\"] == 0].sample(n=min_len, random_state=cfg.seed)\n    train_data = pd.concat([train_data[toxic_mask], sampled_data]).reset_index(drop=True).drop(\"toxic_score\", axis=1)\n\n    val_comment_unq = np.unique(validation_data['less_toxic'].tolist() + validation_data['more_toxic'].tolist())\n    duplicate_idx = np.isin(train_data['comment_text'], val_comment_unq)\n    train_data = train_data.iloc[~duplicate_idx].reset_index(drop=True)\n\n    return train_data","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.761339Z","iopub.execute_input":"2022-02-07T07:54:18.761793Z","iopub.status.idle":"2022-02-07T07:54:18.80277Z","shell.execute_reply.started":"2022-02-07T07:54:18.761733Z","shell.execute_reply":"2022-02-07T07:54:18.801832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"# ------------------ # Load Data # ------------------ #\")\n\n# load tokenizer\ntokenizer = get_tokenizer(Config)\n\ncomments_to_score = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"comments_to_score.csv\"))\n\nif len(comments_to_score) == 7537:\n    comments_to_score = comments_to_score.iloc[:100]\n\n# comments_to_score[\"text\"] = text_normalization(comments_to_score[\"text\"])\nsample_submission = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"sample_submission.csv\"))\n\nif not Config.inference_only:\n\n    # load validation data\n    validation_data = read_csv(os.path.join(Config.INPUT_JIGSAW_04 , \"validation_data.csv\"))\n\n    # load train data\n    train_data = read_csv(\"../input/jigsaw-pseudo-toxictweetsdataset/PseudoLabelDataset.csv\")\n    train_data = get_fold_idx(cfg=Config, df=train_data)\n\n#     train_data[\"comment_text\"] = text_normalization(train_data[\"comment_text\"])\n#     validation_data[\"less_toxic\"] = text_normalization(validation_data[\"less_toxic\"])\n#     validation_data[\"more_toxic\"] = text_normalization(validation_data[\"more_toxic\"])\n\n    print(\"# ------------------ # Training # ------------------ #\")\n    # training\n    train_cv(\n        cfg=Config, \n        df=train_data, \n        tokenizer=tokenizer, \n        text_col=\"tweet\",  # comment_text\n        validation_data=validation_data, \n        get_oof=False)\n\n    print(\"# ------------------ # Validation # ------------------ #\")\n    # validation\n    validation_data_hat = get_validation_data_hat(\n        cfg=Config, \n        tokenizer=tokenizer, \n        filename=None, \n        validation_data=validation_data\n        )\n    filepath = os.path.join(Config.EXP_PREDS, \"validation_data.csv\")\n    validation_data_hat.to_csv(filepath, index=False)\n    score = get_score(validation_data_hat)\n    Config.logger.info(f\"validation score = {score:.4f}\")\n\nprint(\"# ------------------ # Inference # ------------------ #\")\npreds = predict_cv(\n    cfg=Config, \n    df=comments_to_score, \n    tokenizer=tokenizer, \n    text_col=\"text\")\n\nprint(preds.shape)\nif np.ndim(preds) > 1:\n    msttweet = np.mean(preds, axis=1)  # mean of target\nelse:\n    msttweet = preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:54:18.804159Z","iopub.execute_input":"2022-02-07T07:54:18.804647Z","iopub.status.idle":"2022-02-07T07:58:25.008656Z","shell.execute_reply.started":"2022-02-07T07:54:18.804609Z","shell.execute_reply":"2022-02-07T07:58:25.007908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# COLUM2131","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport time\nimport random\nimport string\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n\nfrom collections import defaultdict\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:58:25.012927Z","iopub.execute_input":"2022-02-07T07:58:25.018093Z","iopub.status.idle":"2022-02-07T07:58:25.202741Z","shell.execute_reply.started":"2022-02-07T07:58:25.018048Z","shell.execute_reply":"2022-02-07T07:58:25.20202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length'\n        )\n\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }\n\n\n@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS\n\n\ndef inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    del model\n    gc.collect()\n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:58:25.204739Z","iopub.execute_input":"2022-02-07T07:58:25.205185Z","iopub.status.idle":"2022-02-07T07:58:25.22012Z","shell.execute_reply.started":"2022-02-07T07:58:25.205147Z","shell.execute_reply":"2022-02-07T07:58:25.219382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COLUM014","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:59:51.023001Z","iopub.execute_input":"2022-02-06T15:59:51.02331Z","iopub.status.idle":"2022-02-06T15:59:51.043092Z","shell.execute_reply.started":"2022-02-06T15:59:51.023232Z","shell.execute_reply":"2022-02-06T15:59:51.042444Z"}}},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-roberta-base/model',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\n\nMAIN_PATH = '../input/jigsaw-exp014-roberta-base'\n\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n\n###############\n# INFERENCE\n###############\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nif len(comments) == 7537:\n    comments = comments.iloc[:100]\n\ntest_dataset = JigsawDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\ncolum014 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:58:25.221239Z","iopub.execute_input":"2022-02-07T07:58:25.222128Z","iopub.status.idle":"2022-02-07T07:59:15.188386Z","shell.execute_reply.started":"2022-02-07T07:58:25.222089Z","shell.execute_reply":"2022-02-07T07:59:15.18767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COLUM015","metadata":{}},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-roberta-large/model',\n    test_batch_size = 32,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\n\nMAIN_PATH = '../input/jigsaw-exp015-roberta-large'\n\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(1024, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n    \n###############\n# INFERENCE\n###############\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nif len(comments) == 7537:\n    comments = comments.iloc[:100]\n\ntest_dataset = JigsawDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\ncolum015 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:59:15.190061Z","iopub.execute_input":"2022-02-07T07:59:15.190532Z","iopub.status.idle":"2022-02-07T08:01:32.623143Z","shell.execute_reply.started":"2022-02-07T07:59:15.190494Z","shell.execute_reply":"2022-02-07T08:01:32.622357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COLUM016","metadata":{}},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-deberta-v3-base/model',\n    test_batch_size = 32,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\n\nMAIN_PATH = '../input/jigsaw-exp016-deberta-v3-base'\n\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n\n###############\n# INFERENCE\n###############\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nif len(comments) == 7537:\n    comments = comments.iloc[:100]\n\ntest_dataset = JigsawDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\ncolum016 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:01:32.625535Z","iopub.execute_input":"2022-02-07T08:01:32.625818Z","iopub.status.idle":"2022-02-07T08:02:47.862453Z","shell.execute_reply.started":"2022-02-07T08:01:32.625782Z","shell.execute_reply":"2022-02-07T08:02:47.861759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COLUM018","metadata":{}},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-unbiased-toxic-roberta/model',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\n\nMAIN_PATH = '../input/jigsaw-exp018-unbiased-toxic-roberta'\n\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n\n###############\n# INFERENCE\n###############\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nif len(comments) == 7537:\n    comments = comments.iloc[:100]\n\ntest_dataset = JigsawDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\ncolum018 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:02:47.864118Z","iopub.execute_input":"2022-02-07T08:02:47.864413Z","iopub.status.idle":"2022-02-07T08:03:35.509073Z","shell.execute_reply.started":"2022-02-07T08:02:47.864376Z","shell.execute_reply":"2022-02-07T08:03:35.507549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COLUM019","metadata":{}},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-multilingual-toxic-xlm-roberta/model',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\nMAIN_PATH = '../input/jigsaw-exp019-toxic-xlm-roberta'\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n\n###############\n# INFERENCE\n###############\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nif len(comments) == 7537:\n    comments = comments.iloc[:100]\n\ntest_dataset = JigsawDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\ncolum019 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:03:35.510587Z","iopub.execute_input":"2022-02-07T08:03:35.511028Z","iopub.status.idle":"2022-02-07T08:05:25.017358Z","shell.execute_reply.started":"2022-02-07T08:03:35.51099Z","shell.execute_reply":"2022-02-07T08:05:25.016343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COLUM020","metadata":{}},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-toxic-bert/model',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\nMAIN_PATH = '../input/jigsaw-exp020-toxic-bert'\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n\n###############\n# INFERENCE\n###############\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nif len(comments) == 7537:\n    comments = comments.iloc[:100]\n    \ntest_dataset = JigsawDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\ncolum020 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:05:25.019084Z","iopub.execute_input":"2022-02-07T08:05:25.0196Z","iopub.status.idle":"2022-02-07T08:06:11.758699Z","shell.execute_reply.started":"2022-02-07T08:05:25.019558Z","shell.execute_reply":"2022-02-07T08:06:11.757727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CALPIS10000","metadata":{}},{"cell_type":"markdown","source":"## CALPIS001","metadata":{}},{"cell_type":"code","source":"# ----------------------------------------------\n# Load Libraries\n# ----------------------------------------------\nimport os\nimport math\nimport random\nimport time\nimport pathlib\nfrom pathlib import Path\nimport sys\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import BertForSequenceClassification, BertConfig, BertModel\nfrom transformers import get_cosine_schedule_with_warmup\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport gc\ngc.enable()\n\n\n# ----------------------------------------------\n# Set Config\n# ----------------------------------------------\nclass Config:\n    INPUT_DIR_0 = Path('../input/jigsaw-toxic-severity-rating/')\n    INPUT_DIR_1 = Path('../input/jigsaw-toxic-comment-classification-challenge/')\n    INPUT_DIR_2 = Path('../input/jigsaw-unintended-bias-in-toxicity-classification/')\n    SEED = 2021\n    FOLDS = 5\n    BATCH_SIZE = 32\n    BATCH_SIZE_PRED = 512\n    NUM_EPOCHS = 3\n    MAX_LEN = 128\n    LEANING_RATE = 1e-5\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない\n    DEBUG = False\n    TRAIN = False\n    RUN_VALID = False\n    PRETRAINED = '../input/roberta-transformers-pytorch/roberta-large'\n    TOKENIZER = PRETRAINED\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n\n# ----------------------------------------------\n# Load Data\n# ----------------------------------------------\n# INPUT_0: This Competition\nsubmission = pd.read_csv(Config.INPUT_DIR_0/'sample_submission.csv')\nval_data = pd.read_csv(Config.INPUT_DIR_0/'validation_data.csv')\ntest = pd.read_csv(Config.INPUT_DIR_0/'comments_to_score.csv')\n\nif len(test) == 7537:\n    test = test.iloc[:100]\n\nprint('load data: this competition')\n\n# INPUT_1: 1st Competition\n#train_1st = pd.read_csv(INPUT_DIR_1/'train.csv')\n#test_1st = pd.read_csv(INPUT_DIR_1/'test.csv')\n#test_labels_1st = pd.read_csv(INPUT_DIR_1/'test_labels.csv')\n#print('load data: 1st competition')\n\n# INPUT_2: 2nd Competition\n#train_2nd = pd.read_csv(INPUT_DIR_2/'train.csv')\n#test_2nd = pd.read_csv(INPUT_DIR_2/'test.csv')\n#idt_indiv_anno = pd.read_csv(INPUT_DIR_2/'identity_individual_annotations.csv')\n#tox_indiv_anno = pd.read_csv(INPUT_DIR_2/'toxicity_individual_annotations.csv')\n#print('load data: 2nd competition')\n\n\n# ----------------------------------------------\n# Set SEED\n# ----------------------------------------------\n# seed\ndef set_seed(SEED):\n    random.seed(Config.SEED)\n    np.random.seed(Config.SEED)\n    os.environ['PYTHONHASHSEED'] = str(Config.SEED)\n    \n    torch.manual_seed(Config.SEED)\n    torch.cuda.manual_seed(Config.SEED)\n    torch.cuda.manual_seed_all(Config.SEED)\n    torch.backends.cudnn.deterministic = True\n    \nset_seed(Config.SEED)\n\n\n# ----------------------------------------------\n# Create Tokenizer\n# ----------------------------------------------\ntokenizer = AutoTokenizer.from_pretrained(Config.TOKENIZER)\nprint('create: tokenizer')\n\n\n# ----------------------------------------------\n# Preprocess func\n# ----------------------------------------------\n# Preprocess\nimport string\nimport re\nimport collections\n\nimport nltk\nfrom bs4 import BeautifulSoup\n\n# https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\n\ndef text_normalization(s:pd.Series):\n    x = s.apply(text_cleaning)\n    return x\n\n\n# ----------------------------------------------\n# Dataset Class\n# ----------------------------------------------\nclass Jigsaw1stDataset(Dataset):\n    def __init__(self, df, inference_only=False):\n        super().__init__\n        \n        self.df = df\n        self.inference_only = inference_only\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df[toxic_cols].values, dtype=torch.float32)\n        \n        self.encoded = tokenizer.batch_encode_plus(\n            text_normalization(df['comment_text']).tolist(),\n            padding='max_length',\n            max_length=Config.MAX_LEN,\n            truncation=True,\n            return_attention_mask=True\n        )\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return {'input_ids': input_ids,\n                    'attention_mask': attention_mask\n                    }\n        else:\n            target = self.target[index]\n            return {'input_ids': input_ids,\n                    'attention_mask': attention_mask, \n                    'target': target}\n\n\n# ----------------------------------------------\n# Model Class\n# ----------------------------------------------\nclass AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\nclass Jigsaw1stModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        config = AutoConfig.from_pretrained(Config.PRETRAINED)\n        self.pre_model = AutoModel.from_pretrained(Config.PRETRAINED)\n        self.head = AttentionHead(config.hidden_size, config.hidden_size,1)\n        self.dropout = nn.Dropout(0.3)\n        self.regressor = nn.Linear(config.hidden_size, 6)\n    \n    def forward(self, input_ids, attention_mask):\n        pre_out = self.pre_model(input_ids=input_ids, attention_mask=attention_mask)\n        x0 = pre_out['last_hidden_state']\n        x1 = self.head(x0)\n        x2 = self.dropout(x1)\n        x3 = self.regressor(x2)\n        return x3\n    \n\n# ----------------------------------------------\n# predict func\n# ----------------------------------------------\ndef predict(model, dataloader):\n    model.eval()\n    result = np.zeros((len(dataloader.dataset), 6))\n    idx = 0\n    \n    with torch.no_grad():\n        for batch_idx, data in enumerate(dataloader):\n            input_ids = data['input_ids'].to(Config.DEVICE)\n            attention_mask = data['attention_mask'].to(Config.DEVICE)\n            \n            output = model(input_ids, attention_mask)\n            result[idx:idx + output.shape[0], :] = output.to('cpu')\n            \n            idx += output.shape[0]\n            \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:06:11.760522Z","iopub.execute_input":"2022-02-07T08:06:11.762042Z","iopub.status.idle":"2022-02-07T08:06:12.8069Z","shell.execute_reply.started":"2022-02-07T08:06:11.761993Z","shell.execute_reply":"2022-02-07T08:06:12.806113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nmodel_path = Path('../input/jigsaw-calpis-001')\nmodels = sorted([str(i) for i in list(model_path.iterdir())])\nprint(models)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:06:12.808287Z","iopub.execute_input":"2022-02-07T08:06:12.808704Z","iopub.status.idle":"2022-02-07T08:06:12.821991Z","shell.execute_reply.started":"2022-02-07T08:06:12.808666Z","shell.execute_reply":"2022-02-07T08:06:12.820842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.zeros((Config.FOLDS, len(test), 6))\n\ntest_dataset = Jigsaw1stDataset(test.rename(columns={'text':'comment_text'}),\n                                inference_only=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE_PRED,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor i, model_ in enumerate(models):\n    print(i)\n    \n    model = Jigsaw1stModel()\n    model.to(Config.DEVICE)\n    model.load_state_dict(torch.load(model_))    # 対応するモデルから、重みを読み込む\n    test_preds[i, :] = predict(model, test_loader)\n\ndel test_dataset, test_loader, model\ngc.collect()\n\ncalpis001 = test_preds.mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:06:12.823588Z","iopub.execute_input":"2022-02-07T08:06:12.823875Z","iopub.status.idle":"2022-02-07T08:08:12.08164Z","shell.execute_reply.started":"2022-02-07T08:06:12.823817Z","shell.execute_reply":"2022-02-07T08:08:12.080811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_calpis001 = np.zeros(len(calpis001))\nopt_calpis001 += calpis001[:, 0] * 0.9002713914265349\nopt_calpis001 += calpis001[:, 1] * 0.6604849251407883\nopt_calpis001 += calpis001[:, 2] * 0.37099326391227044\nopt_calpis001 += calpis001[:, 3] * 0.12224998906148228\nopt_calpis001 += calpis001[:, 4] * 0.2487358556500514\nopt_calpis001 += calpis001[:, 5] * 0.3088187717206416\nprint(opt_calpis001.mean(), opt_calpis001.std())","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:08:12.08442Z","iopub.execute_input":"2022-02-07T08:08:12.085692Z","iopub.status.idle":"2022-02-07T08:08:12.095981Z","shell.execute_reply.started":"2022-02-07T08:08:12.085648Z","shell.execute_reply":"2022-02-07T08:08:12.095244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CALPIS011","metadata":{}},{"cell_type":"code","source":"# ----------------------------------------------\n# Load Libraries\n# ----------------------------------------------\nimport os\nimport math\nimport random\nimport time\nimport pathlib\nfrom pathlib import Path\nimport sys\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import BertForSequenceClassification, BertConfig, BertModel\nfrom transformers import get_cosine_schedule_with_warmup\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport gc\ngc.enable()\n\n\n# ----------------------------------------------\n# Set Config\n# ----------------------------------------------\nclass Config:\n    INPUT_DIR_0 = Path('../input/jigsaw-toxic-severity-rating/')\n    INPUT_DIR_1 = Path('../input/jigsaw-toxic-comment-classification-challenge/')\n    INPUT_DIR_2 = Path('../input/jigsaw-unintended-bias-in-toxicity-classification/')\n    SEED = 2021\n    FOLDS = 5\n    BATCH_SIZE = 32\n    BATCH_SIZE_PRED = 512\n    NUM_EPOCHS = 6\n    NUM_CLASSES = 1\n    MAX_LEN = 128\n    LEANING_RATE = 2e-5\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない\n    DEBUG = False\n    TRAIN = False\n    RUN_VALID = False\n    PRETRAINED = '../input/jigsaw-multilingual-toxic-xlm-roberta/model'\n    TOKENIZER = PRETRAINED\n    TRAINED_MODELS = Path('../input/jigsaw-calpis-011')\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n\n\n# ----------------------------------------------\n# Load Data\n# ----------------------------------------------\n# INPUT_0: This Competition\nsubmission = pd.read_csv(Config.INPUT_DIR_0/'sample_submission.csv')\nval_data = pd.read_csv(Config.INPUT_DIR_0/'validation_data.csv')\ntest = pd.read_csv(Config.INPUT_DIR_0/'comments_to_score.csv')\n\nif len(test) == 7537:\n    test = test.iloc[:100]\n\nprint('load data: this competition')\n\n# INPUT_1: 1st Competition\n#train_1st = pd.read_csv(INPUT_DIR_1/'train.csv')\n#test_1st = pd.read_csv(INPUT_DIR_1/'test.csv')\n#test_labels_1st = pd.read_csv(INPUT_DIR_1/'test_labels.csv')\n#print('load data: 1st competition')\n\n# INPUT_2: 2nd Competition\n#train_2nd = pd.read_csv(INPUT_DIR_2/'train.csv')\n#test_2nd = pd.read_csv(INPUT_DIR_2/'test.csv')\n#idt_indiv_anno = pd.read_csv(INPUT_DIR_2/'identity_individual_annotations.csv')\n#tox_indiv_anno = pd.read_csv(INPUT_DIR_2/'toxicity_individual_annotations.csv')\n#print('load data: 2nd competition')\n\n\n# ----------------------------------------------\n# Set SEED\n# ----------------------------------------------\n# seed\ndef set_seed(SEED):\n    random.seed(Config.SEED)\n    np.random.seed(Config.SEED)\n    os.environ['PYTHONHASHSEED'] = str(Config.SEED)\n    \n    torch.manual_seed(Config.SEED)\n    torch.cuda.manual_seed(Config.SEED)\n    torch.cuda.manual_seed_all(Config.SEED)\n    torch.backends.cudnn.deterministic = True\n    \nset_seed(Config.SEED)\n\n\n# ----------------------------------------------\n# Create Tokenizer\n# ----------------------------------------------\ntokenizer = AutoTokenizer.from_pretrained(Config.TOKENIZER)\nprint('create: tokenizer')\n\n\n# ----------------------------------------------\n# Dataset Class\n# ----------------------------------------------\nclass JigsawDataset(Dataset):\n    def __init__(self, df, inference_only=False):\n        super().__init__\n        \n        self.df = df\n        self.inference_only = inference_only\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df['target'].values, dtype=torch.float32)\n        \n        self.encoded = tokenizer.batch_encode_plus(\n            #text_normalization(df['comment_text']).tolist(),\n            df['comment_text'].tolist(),\n            padding='max_length',\n            max_length=Config.MAX_LEN,\n            truncation=True,\n            return_attention_mask=True\n        )\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return {'input_ids': input_ids,\n                    'attention_mask': attention_mask\n                    }\n        else:\n            target = self.target[index]\n            return {'input_ids': input_ids,\n                    'attention_mask': attention_mask, \n                    'target': target}\n\n\n# ----------------------------------------------\n# Model Class\n# ----------------------------------------------\nclass AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\nclass JigsawModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(Config.PRETRAINED)\n        self.config.attention_probs_dropout_prob = 0.0\n        self.config.hidden_dropout_prob = 0.0\n        self.pre_model = AutoModel.from_pretrained(Config.PRETRAINED, config=self.config)\n        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size,1)\n        self.dropout = nn.Dropout(0.3)\n        self.regressor = nn.Linear(self.config.hidden_size, Config.NUM_CLASSES)\n    \n    def forward(self, input_ids, attention_mask):\n        pre_out = self.pre_model(input_ids=input_ids, attention_mask=attention_mask)\n        x0 = pre_out['last_hidden_state']\n        x1 = self.head(x0)\n        #x2 = self.dropout(x1)\n        x3 = self.regressor(x1)\n        return x3\n    \n\n# ----------------------------------------------\n# predict func\n# ----------------------------------------------\ndef predict(model, dataloader):\n    model.eval()\n    result = np.zeros((len(dataloader.dataset), Config.NUM_CLASSES))\n    idx = 0\n    \n    with torch.no_grad():\n        for batch_idx, data in enumerate(dataloader):\n            input_ids = data['input_ids'].to(Config.DEVICE)\n            attention_mask = data['attention_mask'].to(Config.DEVICE)\n            \n            output = model(input_ids, attention_mask)\n            result[idx:idx + output.shape[0], :] = output.to('cpu')\n            \n            idx += output.shape[0]\n            \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:08:12.097195Z","iopub.execute_input":"2022-02-07T08:08:12.097783Z","iopub.status.idle":"2022-02-07T08:08:13.329737Z","shell.execute_reply.started":"2022-02-07T08:08:12.097641Z","shell.execute_reply":"2022-02-07T08:08:13.328994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = Config.TRAINED_MODELS\nmodels = sorted([str(i) for i in list(model_path.iterdir())])\nprint(models)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:08:13.330934Z","iopub.execute_input":"2022-02-07T08:08:13.331642Z","iopub.status.idle":"2022-02-07T08:08:13.343518Z","shell.execute_reply.started":"2022-02-07T08:08:13.331601Z","shell.execute_reply":"2022-02-07T08:08:13.342816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.zeros((Config.FOLDS, len(test), Config.NUM_CLASSES))\n\ntest_dataset = JigsawDataset(test.rename(columns={'text':'comment_text'}),\n                                inference_only=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE_PRED,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor i, model_ in enumerate(models):\n    print(i)\n    \n    model = JigsawModel()\n    model.to(Config.DEVICE)\n    model.load_state_dict(torch.load(model_))    # 対応するモデルから、重みを読み込む\n    test_preds[i, :] = predict(model, test_loader)\n    \ndel test_dataset, test_loader, model\ngc.collect()\n\ncalpis011 = test_preds.mean(axis=0)\ncalpis011 = calpis011.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:08:13.34636Z","iopub.execute_input":"2022-02-07T08:08:13.346548Z","iopub.status.idle":"2022-02-07T08:09:32.346247Z","shell.execute_reply.started":"2022-02-07T08:08:13.346524Z","shell.execute_reply":"2022-02-07T08:09:32.345431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CALPIS012","metadata":{}},{"cell_type":"code","source":"# ----------------------------------------------\n# Load Libraries\n# ----------------------------------------------\nimport os\nimport math\nimport random\nimport time\nimport pathlib\nfrom pathlib import Path\nimport sys\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import BertForSequenceClassification, BertConfig, BertModel\nfrom transformers import get_cosine_schedule_with_warmup\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport gc\ngc.enable()\n\n\n# ----------------------------------------------\n# Set Config\n# ----------------------------------------------\nclass Config:\n    INPUT_DIR_0 = Path('../input/jigsaw-toxic-severity-rating/')\n    INPUT_DIR_1 = Path('../input/jigsaw-toxic-comment-classification-challenge/')\n    INPUT_DIR_2 = Path('../input/jigsaw-unintended-bias-in-toxicity-classification/')\n    SEED = 2021\n    FOLDS = 5\n    BATCH_SIZE = 32\n    BATCH_SIZE_PRED = 512\n    NUM_EPOCHS = 6\n    NUM_CLASSES = 1\n    MAX_LEN = 128\n    LEANING_RATE = 2e-5\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない\n    DEBUG = False\n    TRAIN = False\n    RUN_VALID = False\n    PRETRAINED = '../input/jigsaw-multilingual-toxic-xlm-roberta/model'\n    TOKENIZER = PRETRAINED\n    TRAINED_MODELS = Path('../input/jigsaw-calpis-012')\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n\n\n# ----------------------------------------------\n# Load Data\n# ----------------------------------------------\n# INPUT_0: This Competition\nsubmission = pd.read_csv(Config.INPUT_DIR_0/'sample_submission.csv')\nval_data = pd.read_csv(Config.INPUT_DIR_0/'validation_data.csv')\ntest = pd.read_csv(Config.INPUT_DIR_0/'comments_to_score.csv')\n\nif len(test) == 7537:\n    test = test.iloc[:100]\n\nprint('load data: this competition')\n\n# INPUT_1: 1st Competition\n#train_1st = pd.read_csv(INPUT_DIR_1/'train.csv')\n#test_1st = pd.read_csv(INPUT_DIR_1/'test.csv')\n#test_labels_1st = pd.read_csv(INPUT_DIR_1/'test_labels.csv')\n#print('load data: 1st competition')\n\n# INPUT_2: 2nd Competition\n#train_2nd = pd.read_csv(INPUT_DIR_2/'train.csv')\n#test_2nd = pd.read_csv(INPUT_DIR_2/'test.csv')\n#idt_indiv_anno = pd.read_csv(INPUT_DIR_2/'identity_individual_annotations.csv')\n#tox_indiv_anno = pd.read_csv(INPUT_DIR_2/'toxicity_individual_annotations.csv')\n#print('load data: 2nd competition')\n\n\n# ----------------------------------------------\n# Set SEED\n# ----------------------------------------------\n# seed\ndef set_seed(SEED):\n    random.seed(Config.SEED)\n    np.random.seed(Config.SEED)\n    os.environ['PYTHONHASHSEED'] = str(Config.SEED)\n    \n    torch.manual_seed(Config.SEED)\n    torch.cuda.manual_seed(Config.SEED)\n    torch.cuda.manual_seed_all(Config.SEED)\n    torch.backends.cudnn.deterministic = True\n    \nset_seed(Config.SEED)\n\n\n# ----------------------------------------------\n# Create Tokenizer\n# ----------------------------------------------\ntokenizer = AutoTokenizer.from_pretrained(Config.TOKENIZER)\nprint('create: tokenizer')\n\n\n# ----------------------------------------------\n# Dataset Class\n# ----------------------------------------------\nclass JigsawDataset(Dataset):\n    def __init__(self, df, inference_only=False):\n        super().__init__\n        \n        self.df = df\n        self.inference_only = inference_only\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df['target'].values, dtype=torch.float32)\n        \n        self.encoded = tokenizer.batch_encode_plus(\n            #text_normalization(df['comment_text']).tolist(),\n            df['comment_text'].tolist(),\n            padding='max_length',\n            max_length=Config.MAX_LEN,\n            truncation=True,\n            return_attention_mask=True\n        )\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return {'input_ids': input_ids,\n                    'attention_mask': attention_mask\n                    }\n        else:\n            target = self.target[index]\n            return {'input_ids': input_ids,\n                    'attention_mask': attention_mask, \n                    'target': target}\n\n\n# ----------------------------------------------\n# Model Class\n# ----------------------------------------------\nclass AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\nclass JigsawModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(Config.PRETRAINED)\n        self.config.attention_probs_dropout_prob = 0.0\n        self.config.hidden_dropout_prob = 0.0\n        self.pre_model = AutoModel.from_pretrained(Config.PRETRAINED, config=self.config)\n        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size,1)\n        self.dropout = nn.Dropout(0.3)\n        self.regressor = nn.Linear(self.config.hidden_size, Config.NUM_CLASSES)\n    \n    def forward(self, input_ids, attention_mask):\n        pre_out = self.pre_model(input_ids=input_ids, attention_mask=attention_mask)\n        x0 = pre_out['last_hidden_state']\n        x1 = self.head(x0)\n        #x2 = self.dropout(x1)\n        x3 = self.regressor(x1)\n        return x3\n    \n\n# ----------------------------------------------\n# predict func\n# ----------------------------------------------\ndef predict(model, dataloader):\n    model.eval()\n    result = np.zeros((len(dataloader.dataset), Config.NUM_CLASSES))\n    idx = 0\n    \n    with torch.no_grad():\n        for batch_idx, data in enumerate(dataloader):\n            input_ids = data['input_ids'].to(Config.DEVICE)\n            attention_mask = data['attention_mask'].to(Config.DEVICE)\n            \n            output = model(input_ids, attention_mask)\n            result[idx:idx + output.shape[0], :] = output.to('cpu')\n            \n            idx += output.shape[0]\n            \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:09:32.348302Z","iopub.execute_input":"2022-02-07T08:09:32.348526Z","iopub.status.idle":"2022-02-07T08:09:33.804928Z","shell.execute_reply.started":"2022-02-07T08:09:32.3485Z","shell.execute_reply":"2022-02-07T08:09:33.803453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = Config.TRAINED_MODELS\nmodels = sorted([str(i) for i in list(model_path.iterdir())])\nprint(models)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:09:33.806365Z","iopub.execute_input":"2022-02-07T08:09:33.806629Z","iopub.status.idle":"2022-02-07T08:09:33.823173Z","shell.execute_reply.started":"2022-02-07T08:09:33.806592Z","shell.execute_reply":"2022-02-07T08:09:33.822497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.zeros((Config.FOLDS, len(test), Config.NUM_CLASSES))\n\ntest_dataset = JigsawDataset(test.rename(columns={'text':'comment_text'}),\n                                inference_only=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE_PRED,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor i, model_ in enumerate(models):\n    print(i)\n    \n    model = JigsawModel()\n    model.to(Config.DEVICE)\n    model.load_state_dict(torch.load(model_))    # 対応するモデルから、重みを読み込む\n    test_preds[i, :] = predict(model, test_loader)\n    \ndel test_dataset, test_loader, model\ngc.collect()\n\ncalpis012 = test_preds.mean(axis=0)\ncalpis012 = calpis012.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:09:33.824372Z","iopub.execute_input":"2022-02-07T08:09:33.8247Z","iopub.status.idle":"2022-02-07T08:10:40.860228Z","shell.execute_reply.started":"2022-02-07T08:09:33.824662Z","shell.execute_reply":"2022-02-07T08:10:40.859383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NAOISM","metadata":{}},{"cell_type":"markdown","source":"## NAOISM1004","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport math\nimport time\nimport random\nimport shutil\nimport copy\nimport glob\nimport collections\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom tqdm.auto import tqdm\nfrom functools import partial\nimport torch\nimport torch.nn as nn\nfrom torch.nn import MarginRankingLoss\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport transformers\nfrom transformers import (AutoModel, AutoTokenizer)\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom torch.cuda.amp import autocast, GradScaler\nimport re\nfrom bs4 import BeautifulSoup\nimport gc\ntqdm.pandas()\n\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nINPUT_PATH = \"../input/jigsaw-toxic-severity-rating/\"\nMODEL_PATH = \"../input/jigsaw2021-models-naoism/\"\nMODEL_PATHS = glob.glob(MODEL_PATH + \"*/*.pth\")\nOUTPUT_DIR = '/' \nprint(MODEL_PATHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:10:40.861954Z","iopub.execute_input":"2022-02-07T08:10:40.862225Z","iopub.status.idle":"2022-02-07T08:10:40.941265Z","shell.execute_reply.started":"2022-02-07T08:10:40.862191Z","shell.execute_reply":"2022-02-07T08:10:40.940535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 0\n    n_model_seed = 3\n    exp_name = \"exp1004\"\n    print_freq = 100\n    toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n    ######################\n    # Dataset #\n    ######################\n    head = 64\n    tail = 64\n    max_length = head+tail\n    ######################\n    # Augmentation #\n    ######################\n\n    ######################\n    # Loaders #\n    ######################\n    batch_size = 64\n    num_workers = 8\n    ######################\n    # Model #\n    ######################\n    pretrained = False\n    num_classes = len(toxic_cols)  # Binary \n    hidden_node = 1024  # large: 1024, base: 768\n\nmodel_path_list = [mp for mp in MODEL_PATHS if CFG.exp_name in mp]\nmodel_path_list = sorted(model_path_list)\nprint(\"Model PATHs:\", model_path_list)\nCFG.model_path = model_path_list[0]\nCFG.base_model_name = CFG.model_path[len(f\"../input/jigsaw2021-models-naoism/{CFG.exp_name}/\"):-len(\"_best_score.pth'\")+1]\nprint(\"Base_Model_Name:\", CFG.base_model_name)\nif CFG.base_model_name == \"bertweet-large\":\n    CFG.base_model_path = \"../input/hugging-face-bertweet-large/model\"\nelif CFG.base_model_name == \"roberta-large-squad2\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large-squad2/model\"\nelif CFG.base_model_name == \"roberta-large\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large/model\"\nelif CFG.base_model_name == \"albert-large-v2\":\n    CFG.base_model_path = \"../input/hugging-face-albert-large-v2/model\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:10:40.942713Z","iopub.execute_input":"2022-02-07T08:10:40.943003Z","iopub.status.idle":"2022-02-07T08:10:40.953256Z","shell.execute_reply.started":"2022-02-07T08:10:40.942966Z","shell.execute_reply":"2022-02-07T08:10:40.952538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef init_logger(log_file=OUTPUT_DIR+\"train.log\"):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n    \nLOGGER = init_logger()\n\ndef get_score(more_toxic_preds, less_toxic_preds):\n    score = np.mean(more_toxic_preds > less_toxic_preds)\n    return score\n\n\n\ndef get_result(df):\n    more_toxic_preds = df[\"more_toxic_preds\"].values\n    less_toxic_preds = df[\"less_toxic_preds\"].values\n    score = get_score(more_toxic_preds, less_toxic_preds)\n    LOGGER.info(f\"Score: {score:<.4f}\")\n    return score\n\n\ndef read_data():\n    validation_data = pd.read_csv(INPUT_PATH + \"validation_data.csv\")\n    test = pd.read_csv(INPUT_PATH + \"comments_to_score.csv\")\n    sub = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\n    return validation_data, test, sub\n\n\n\ndef text_cleaning(text):\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    template = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\") #Removes e-mail address\n    text = template.sub(r'.', text)\n    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n    text = ipPattern.sub(r'', text)\n    bikkuri = re.compile('!') # Removes bikkuri\n    text = bikkuri.sub(r' ', text)\n    text = text.replace('\\n','')\n    text = text.replace(\"\\'\",\"\")\n    text = text.replace(\"|\",\"\")\n    text = text.replace(\"=\",\"\")\n    text = text.replace(\"F**K\", \"FUCK\")\n    text = text.replace(\"F__K\", \"FUCK\")\n    text = text.replace(\"f**k\", \"fuck\")\n    text = text.replace(\"f__k\", \"fuck\")\n    text = text.replace(\"f*ck\", \"fuck\")    \n    text = text.replace(\"S$X\", \"SEX\")\n    text = text.replace(\"s$x\", \"sex\")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" u \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\" U \", \" you \")\n    text = text.replace(\"YOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUUUUUUUUUU\", \"YOU\")\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    return text\n\n\ndef prepare_input(text, tokenizer):\n    if CFG.tail == 0:\n        inputs = tokenizer.encode_plus(\n            text, \n            return_tensors=None, \n            add_special_tokens=True, \n            max_length=CFG.max_length,\n            pad_to_max_length=True,\n            truncation=True\n            )\n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n    else:\n        inputs = tokenizer.encode_plus(\n            text,\n            return_tensors=None, \n            add_special_tokens=True, \n            truncation=True\n            )\n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > CFG.max_length:\n                v = np.hstack([v[:CFG.head], v[-CFG.tail:]])\n            if k == 'input_ids':\n                new_v = np.ones(CFG.max_length) * tokenizer.pad_token_id\n            else:\n                new_v = np.zeros(CFG.max_length)\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.text = df[\"text\"].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):   \n        text = self.text[idx]\n        inputs = prepare_input(str(text), self.tokenizer)\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n        }\n\n\nclass Model(nn.Module):\n    def __init__(self, modelname_or_path):\n        super(Model, self).__init__()\n        self.base_model = AutoModel.from_pretrained(modelname_or_path)\n        self.fc = nn.Linear(CFG.hidden_node, CFG.num_classes)\n        self.dropout = nn.Dropout(p=0.5)\n        # self.ln = nn.LayerNorm(CFG.hidden_node)\n        \n    def feature(self, input_ids, attention_mask):\n        outputs = self.base_model(\n            input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=False\n        )\n        last_hidden_states = outputs[0]\n        feature = torch.mean(last_hidden_states, 1)\n        return feature\n\n    def forward(self, input_ids, attention_mask=None):\n        feature = self.feature(input_ids, attention_mask)\n        output = self.fc(self.dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:10:40.954957Z","iopub.execute_input":"2022-02-07T08:10:40.955702Z","iopub.status.idle":"2022-02-07T08:10:40.98716Z","shell.execute_reply.started":"2022-02-07T08:10:40.955663Z","shell.execute_reply":"2022-02-07T08:10:40.986386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for batch_data in tk0:\n        ids = batch_data['ids'].to(device)\n        mask = batch_data['mask'].to(device)\n        with torch.no_grad():\n            y_preds = model(ids, mask)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\n\ndef main():\n    seed_torch(seed=CFG.seed)\n    \n    validation_data, test, submission = read_data()\n    if len(test) == 7537:\n        test = test.iloc[:100]\n    \n    print(\"Text cleaning...\")\n    test['text'] = test['text'].progress_apply(text_cleaning)\n    \n    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model_path)\n    print(\"tokenizer:\", tokenizer)\n    \n    test_dataset = TestDataset(test, tokenizer, CFG.max_length)\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    predictions = []\n    for ms in range(CFG.n_model_seed):\n        model = Model(CFG.base_model_path)\n        # print(\"Loaded model:\", model.base_model)\n        state = torch.load(model_path_list[ms], map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        predictions.append(prediction)\n        del model, state; gc.collect()\n        torch.cuda.empty_cache()\n    \n    # submission['score'] = np.mean(predictions, axis=0)\n    # submission[['comment_id', 'score']].to_csv('submission.csv', index=False)\n    predictions = np.array(np.mean(predictions, axis=0))\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:10:40.9886Z","iopub.execute_input":"2022-02-07T08:10:40.989394Z","iopub.status.idle":"2022-02-07T08:10:41.002569Z","shell.execute_reply.started":"2022-02-07T08:10:40.989356Z","shell.execute_reply":"2022-02-07T08:10:41.001816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naoism1004 = main()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:10:41.005453Z","iopub.execute_input":"2022-02-07T08:10:41.005702Z","iopub.status.idle":"2022-02-07T08:12:39.644263Z","shell.execute_reply.started":"2022-02-07T08:10:41.005676Z","shell.execute_reply":"2022-02-07T08:12:39.643483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_naoism1004 = np.zeros(len(naoism1004))\nopt_naoism1004 += naoism1004[:, 0] * 0.23555360425248387\nopt_naoism1004 += naoism1004[:, 1] * 0.935995774834193\nopt_naoism1004 += naoism1004[:, 2] * 0.3951396313555483\nopt_naoism1004 += naoism1004[:, 3] * 0.10302749719202853\nopt_naoism1004 += naoism1004[:, 4] * 0.3105753465044702\nopt_naoism1004 += naoism1004[:, 5] * 0.4543676174582658\nprint(opt_naoism1004.mean(), opt_naoism1004.std())","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:12:39.645797Z","iopub.execute_input":"2022-02-07T08:12:39.646089Z","iopub.status.idle":"2022-02-07T08:12:39.654444Z","shell.execute_reply.started":"2022-02-07T08:12:39.646052Z","shell.execute_reply":"2022-02-07T08:12:39.65369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NAOISM4001","metadata":{"execution":{"iopub.status.busy":"2022-02-06T16:17:06.368657Z","iopub.execute_input":"2022-02-06T16:17:06.368937Z","iopub.status.idle":"2022-02-06T16:17:06.373026Z","shell.execute_reply.started":"2022-02-06T16:17:06.368905Z","shell.execute_reply":"2022-02-06T16:17:06.371999Z"}}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport math\nimport time\nimport random\nimport shutil\nimport copy\nimport glob\nimport collections\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom tqdm.auto import tqdm\nfrom functools import partial\nimport torch\nimport torch.nn as nn\nfrom torch.nn import MarginRankingLoss\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport transformers\nfrom transformers import (AutoModel, AutoTokenizer)\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom torch.cuda.amp import autocast, GradScaler\nimport re\nfrom bs4 import BeautifulSoup\nimport gc\ntqdm.pandas()\n\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nINPUT_PATH = \"../input/jigsaw-toxic-severity-rating/\"\nMODEL_PATH = \"../input/jigsaw2021-models-naoism/\"\nMODEL_PATHS = glob.glob(MODEL_PATH + \"*/*.pth\")\nOUTPUT_DIR = '/' \nprint(MODEL_PATHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:12:39.655869Z","iopub.execute_input":"2022-02-07T08:12:39.656418Z","iopub.status.idle":"2022-02-07T08:12:39.689441Z","shell.execute_reply.started":"2022-02-07T08:12:39.656378Z","shell.execute_reply":"2022-02-07T08:12:39.688624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 0\n    n_model_seed = 1\n    exp_name = \"exp4001\"\n    print_freq = 100\n    target_col = \"target\"\n    base_model_name = \"multilingual-toxic-xlm-roberta\"\n    ######################\n    # Dataset #\n    ######################\n    head = 64\n    tail = 64\n    max_length = head+tail\n    ######################\n    # Augmentation #\n    ######################\n\n    ######################\n    # Loaders #\n    ######################\n    batch_size = 64\n    num_workers = 8\n    ######################\n    # Model #\n    ######################\n    pretrained = False\n    num_classes = 1  # Binary \n    hidden_node = 768  # large: 1024, base: 768\n\nmodel_path_list = [mp for mp in MODEL_PATHS if CFG.exp_name in mp]\nmodel_path_list = sorted(model_path_list)\nprint(\"Model PATHs:\", model_path_list)\nprint(\"Base_Model_Name:\", CFG.base_model_name)\nif CFG.base_model_name == \"bertweet-large\":\n    CFG.base_model_path = \"../input/hugging-face-bertweet-large/model\"\nelif CFG.base_model_name == \"roberta-large-squad2\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large-squad2/model\"\nelif CFG.base_model_name == \"roberta-large\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large/model\"\nelif CFG.base_model_name == \"albert-large-v2\":\n    CFG.base_model_path = \"../input/hugging-face-albert-large-v2/model\"\nelif CFG.base_model_name == \"multilingual-toxic-xlm-roberta\":\n    CFG.base_model_path = \"../input/jigsaw-multilingual-toxic-xlm-roberta/model\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:12:39.690693Z","iopub.execute_input":"2022-02-07T08:12:39.691031Z","iopub.status.idle":"2022-02-07T08:12:39.701023Z","shell.execute_reply.started":"2022-02-07T08:12:39.690995Z","shell.execute_reply":"2022-02-07T08:12:39.700143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef init_logger(log_file=OUTPUT_DIR+\"train.log\"):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n    \nLOGGER = init_logger()\n\ndef get_score(more_toxic_preds, less_toxic_preds):\n    score = np.mean(more_toxic_preds > less_toxic_preds)\n    return score\n\n\n\ndef get_result(df):\n    more_toxic_preds = df[\"more_toxic_preds\"].values\n    less_toxic_preds = df[\"less_toxic_preds\"].values\n    score = get_score(more_toxic_preds, less_toxic_preds)\n    LOGGER.info(f\"Score: {score:<.4f}\")\n    return score\n\n\ndef read_data():\n    validation_data = pd.read_csv(INPUT_PATH + \"validation_data.csv\")\n    test = pd.read_csv(INPUT_PATH + \"comments_to_score.csv\")\n    sub = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\n    return validation_data, test, sub\n\n\n\ndef text_cleaning(text):\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    template = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\") #Removes e-mail address\n    text = template.sub(r'.', text)\n    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n    text = ipPattern.sub(r'', text)\n    text = text.replace('\\n','')\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    return text\n\n\ndef prepare_input(text, tokenizer):\n    if CFG.tail == 0:\n        inputs = tokenizer.encode_plus(\n            text, \n            return_tensors=None, \n            add_special_tokens=True, \n            max_length=CFG.max_length,\n            pad_to_max_length=True,\n            truncation=True\n            )\n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n    else:\n        inputs = tokenizer.encode_plus(\n            text,\n            return_tensors=None, \n            add_special_tokens=True, \n            truncation=True\n            )\n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > CFG.max_length:\n                v = np.hstack([v[:CFG.head], v[-CFG.tail:]])\n            if k == 'input_ids':\n                new_v = np.ones(CFG.max_length) * tokenizer.pad_token_id\n            else:\n                new_v = np.zeros(CFG.max_length)\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.text = df[\"text\"].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):   \n        text = self.text[idx]\n        inputs = prepare_input(str(text), self.tokenizer)\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n        }\n\n\nclass Model_reg(nn.Module):\n    def __init__(self, modelname_or_path):\n        super(Model_reg, self).__init__()\n        self.base_model = AutoModel.from_pretrained(modelname_or_path)\n        self.fc = nn.Linear(CFG.hidden_node, CFG.num_classes)\n        self.dropout = nn.Dropout(p=0.)\n        # self.ln = nn.LayerNorm(CFG.hidden_node)\n        \n    def feature(self, input_ids, attention_mask):\n        outputs = self.base_model(\n            input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=False\n        )\n        last_hidden_states = outputs[0]\n        feature = torch.mean(last_hidden_states, 1)\n        return feature\n\n    def forward(self, input_ids, attention_mask=None):\n        feature = self.feature(input_ids, attention_mask)\n        output = self.fc(self.dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:12:39.702666Z","iopub.execute_input":"2022-02-07T08:12:39.702983Z","iopub.status.idle":"2022-02-07T08:12:39.730787Z","shell.execute_reply.started":"2022-02-07T08:12:39.702946Z","shell.execute_reply":"2022-02-07T08:12:39.73006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for batch_data in tk0:\n        ids = batch_data['ids'].to(device)\n        mask = batch_data['mask'].to(device)\n        with torch.no_grad():\n            y_preds = model(ids, mask)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\n\ndef main():\n    seed_torch(seed=CFG.seed)\n    \n    validation_data, test, submission = read_data()\n    if len(test) == 7537:\n        test = test.iloc[:100]\n    \n    print(\"Text cleaning...\")\n    test['text'] = test['text'].progress_apply(text_cleaning)\n    \n    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model_path)\n    print(\"tokenizer:\", tokenizer)\n    \n    test_dataset = TestDataset(test, tokenizer, CFG.max_length)\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    predictions = []\n    for ms in range(CFG.n_model_seed):\n        model = Model_reg(CFG.base_model_path)\n        # print(\"Loaded model:\", model.base_model)\n        state = torch.load(model_path_list[ms], map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        predictions.append(prediction)\n        del model, state; gc.collect()\n        torch.cuda.empty_cache()\n    \n    # submission['score'] = np.mean(predictions, axis=0)\n    # submission[['comment_id', 'score']].to_csv('submission.csv', index=False)\n    predictions = np.array(np.mean(predictions, axis=0))\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:12:39.732123Z","iopub.execute_input":"2022-02-07T08:12:39.732379Z","iopub.status.idle":"2022-02-07T08:12:39.745649Z","shell.execute_reply.started":"2022-02-07T08:12:39.732344Z","shell.execute_reply":"2022-02-07T08:12:39.744813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NAOISM4001 SEED0","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 0\n    n_model_seed = 1\n    exp_name = \"exp4001_pseudo_jigsaw1st_seed0\"\n    print_freq = 100\n    target_col = \"target\"\n    base_model_name = \"multilingual-toxic-xlm-roberta\"\n    ######################\n    # Dataset #\n    ######################\n    head = 64\n    tail = 64\n    max_length = head+tail\n    ######################\n    # Augmentation #\n    ######################\n\n    ######################\n    # Loaders #\n    ######################\n    batch_size = 64\n    num_workers = 8\n    ######################\n    # Model #\n    ######################\n    pretrained = False\n    num_classes = 1  # Binary \n    hidden_node = 768  # large: 1024, base: 768\n\nmodel_path_list = [mp for mp in MODEL_PATHS if CFG.exp_name in mp]\nmodel_path_list = sorted(model_path_list)\nprint(\"Model PATHs:\", model_path_list)\nprint(\"Base_Model_Name:\", CFG.base_model_name)\nif CFG.base_model_name == \"bertweet-large\":\n    CFG.base_model_path = \"../input/hugging-face-bertweet-large/model\"\nelif CFG.base_model_name == \"roberta-large-squad2\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large-squad2/model\"\nelif CFG.base_model_name == \"roberta-large\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large/model\"\nelif CFG.base_model_name == \"albert-large-v2\":\n    CFG.base_model_path = \"../input/hugging-face-albert-large-v2/model\"\nelif CFG.base_model_name == \"multilingual-toxic-xlm-roberta\":\n    CFG.base_model_path = \"../input/jigsaw-multilingual-toxic-xlm-roberta/model\"\n\n\nnaoism4001_seed0 = main()\nnaoism4001_seed0 = naoism4001_seed0.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:12:39.746978Z","iopub.execute_input":"2022-02-07T08:12:39.747237Z","iopub.status.idle":"2022-02-07T08:13:09.063381Z","shell.execute_reply.started":"2022-02-07T08:12:39.747201Z","shell.execute_reply":"2022-02-07T08:13:09.062602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NAOISM4001 SEED1","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 0\n    n_model_seed = 1\n    exp_name = \"exp4001_pseudo_jigsaw1st_seed1\"\n    print_freq = 100\n    target_col = \"target\"\n    base_model_name = \"multilingual-toxic-xlm-roberta\"\n    ######################\n    # Dataset #\n    ######################\n    head = 64\n    tail = 64\n    max_length = head+tail\n    ######################\n    # Augmentation #\n    ######################\n\n    ######################\n    # Loaders #\n    ######################\n    batch_size = 64\n    num_workers = 8\n    ######################\n    # Model #\n    ######################\n    pretrained = False\n    num_classes = 1  # Binary \n    hidden_node = 768  # large: 1024, base: 768\n\nmodel_path_list = [mp for mp in MODEL_PATHS if CFG.exp_name in mp]\nmodel_path_list = sorted(model_path_list)\nprint(\"Model PATHs:\", model_path_list)\nprint(\"Base_Model_Name:\", CFG.base_model_name)\nif CFG.base_model_name == \"bertweet-large\":\n    CFG.base_model_path = \"../input/hugging-face-bertweet-large/model\"\nelif CFG.base_model_name == \"roberta-large-squad2\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large-squad2/model\"\nelif CFG.base_model_name == \"roberta-large\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large/model\"\nelif CFG.base_model_name == \"albert-large-v2\":\n    CFG.base_model_path = \"../input/hugging-face-albert-large-v2/model\"\nelif CFG.base_model_name == \"multilingual-toxic-xlm-roberta\":\n    CFG.base_model_path = \"../input/jigsaw-multilingual-toxic-xlm-roberta/model\"\n\n\nnaoism4001_seed1 = main()\nnaoism4001_seed1 = naoism4001_seed1.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:09.06488Z","iopub.execute_input":"2022-02-07T08:13:09.065135Z","iopub.status.idle":"2022-02-07T08:13:36.766004Z","shell.execute_reply.started":"2022-02-07T08:13:09.065099Z","shell.execute_reply":"2022-02-07T08:13:36.765145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NAOISM4001 SEED2","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 0\n    n_model_seed = 1\n    exp_name = \"exp4001_pseudo_jigsaw1st_seed2\"\n    print_freq = 100\n    target_col = \"target\"\n    base_model_name = \"multilingual-toxic-xlm-roberta\"\n    ######################\n    # Dataset #\n    ######################\n    head = 64\n    tail = 64\n    max_length = head+tail\n    ######################\n    # Augmentation #\n    ######################\n\n    ######################\n    # Loaders #\n    ######################\n    batch_size = 64\n    num_workers = 8\n    ######################\n    # Model #\n    ######################\n    pretrained = False\n    num_classes = 1  # Binary \n    hidden_node = 768  # large: 1024, base: 768\n\nmodel_path_list = [mp for mp in MODEL_PATHS if CFG.exp_name in mp]\nmodel_path_list = sorted(model_path_list)\nprint(\"Model PATHs:\", model_path_list)\nprint(\"Base_Model_Name:\", CFG.base_model_name)\nif CFG.base_model_name == \"bertweet-large\":\n    CFG.base_model_path = \"../input/hugging-face-bertweet-large/model\"\nelif CFG.base_model_name == \"roberta-large-squad2\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large-squad2/model\"\nelif CFG.base_model_name == \"roberta-large\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large/model\"\nelif CFG.base_model_name == \"albert-large-v2\":\n    CFG.base_model_path = \"../input/hugging-face-albert-large-v2/model\"\nelif CFG.base_model_name == \"multilingual-toxic-xlm-roberta\":\n    CFG.base_model_path = \"../input/jigsaw-multilingual-toxic-xlm-roberta/model\"\n\n\nnaoism4001_seed2 = main()\nnaoism4001_seed2 = naoism4001_seed2.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:36.770365Z","iopub.execute_input":"2022-02-07T08:13:36.772246Z","iopub.status.idle":"2022-02-07T08:13:55.785931Z","shell.execute_reply.started":"2022-02-07T08:13:36.772206Z","shell.execute_reply":"2022-02-07T08:13:55.784907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naoism4001 = np.array([\n    naoism4001_seed0,\n    naoism4001_seed1,\n    naoism4001_seed2\n])\n\nnaoism4001 = naoism4001.mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:55.7878Z","iopub.execute_input":"2022-02-07T08:13:55.789426Z","iopub.status.idle":"2022-02-07T08:13:55.796867Z","shell.execute_reply.started":"2022-02-07T08:13:55.789381Z","shell.execute_reply":"2022-02-07T08:13:55.795614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NAOISM4003","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport math\nimport time\nimport random\nimport shutil\nimport copy\nimport glob\nimport collections\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom tqdm.auto import tqdm\nfrom functools import partial\nimport torch\nimport torch.nn as nn\nfrom torch.nn import MarginRankingLoss\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport transformers\nfrom transformers import (AutoModel, AutoTokenizer)\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom torch.cuda.amp import autocast, GradScaler\nimport re\nfrom bs4 import BeautifulSoup\nimport gc\ntqdm.pandas()\n\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nINPUT_PATH = \"../input/jigsaw-toxic-severity-rating/\"\nMODEL_PATH = \"../input/jigsaw2021-models-naoism/\"\nMODEL_PATHS = glob.glob(MODEL_PATH + \"*/*.pth\")\nOUTPUT_DIR = '/' \nprint(MODEL_PATHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:55.798741Z","iopub.execute_input":"2022-02-07T08:13:55.799075Z","iopub.status.idle":"2022-02-07T08:13:55.847665Z","shell.execute_reply.started":"2022-02-07T08:13:55.799039Z","shell.execute_reply":"2022-02-07T08:13:55.847017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 0\n    n_model_seed = 3\n    exp_name = \"exp4003\"\n    print_freq = 100\n    target_col = \"target\"\n    base_model_name = \"multilingual-toxic-xlm-roberta\"\n    ######################\n    # Dataset #\n    ######################\n    head = 64\n    tail = 64\n    max_length = head+tail\n    ######################\n    # Augmentation #\n    ######################\n\n    ######################\n    # Loaders #\n    ######################\n    batch_size = 64\n    num_workers = 8\n    ######################\n    # Model #\n    ######################\n    pretrained = False\n    num_classes = 1  # Binary \n    hidden_node = 768  # large: 1024, base: 768\n\nmodel_path_list = [mp for mp in MODEL_PATHS if CFG.exp_name in mp]\nmodel_path_list = sorted(model_path_list)\nprint(\"Model PATHs:\", model_path_list)\nprint(\"Base_Model_Name:\", CFG.base_model_name)\nif CFG.base_model_name == \"bertweet-large\":\n    CFG.base_model_path = \"../input/hugging-face-bertweet-large/model\"\nelif CFG.base_model_name == \"roberta-large-squad2\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large-squad2/model\"\nelif CFG.base_model_name == \"roberta-large\":\n    CFG.base_model_path = \"../input/hugging-face-roberta-large/model\"\nelif CFG.base_model_name == \"albert-large-v2\":\n    CFG.base_model_path = \"../input/hugging-face-albert-large-v2/model\"\nelif CFG.base_model_name == \"multilingual-toxic-xlm-roberta\":\n    CFG.base_model_path = \"../input/jigsaw-multilingual-toxic-xlm-roberta/model\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:55.851124Z","iopub.execute_input":"2022-02-07T08:13:55.851598Z","iopub.status.idle":"2022-02-07T08:13:55.878858Z","shell.execute_reply.started":"2022-02-07T08:13:55.851562Z","shell.execute_reply":"2022-02-07T08:13:55.877944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef init_logger(log_file=OUTPUT_DIR+\"train.log\"):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n    \nLOGGER = init_logger()\n\ndef get_score(more_toxic_preds, less_toxic_preds):\n    score = np.mean(more_toxic_preds > less_toxic_preds)\n    return score\n\n\n\ndef get_result(df):\n    more_toxic_preds = df[\"more_toxic_preds\"].values\n    less_toxic_preds = df[\"less_toxic_preds\"].values\n    score = get_score(more_toxic_preds, less_toxic_preds)\n    LOGGER.info(f\"Score: {score:<.4f}\")\n    return score\n\n\ndef read_data():\n    validation_data = pd.read_csv(INPUT_PATH + \"validation_data.csv\")\n    test = pd.read_csv(INPUT_PATH + \"comments_to_score.csv\")\n    sub = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\n    return validation_data, test, sub\n\n\n\ndef text_cleaning(text):\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    template = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\") #Removes e-mail address\n    text = template.sub(r'.', text)\n    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n    text = ipPattern.sub(r'', text)\n    text = text.replace('\\n','')\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    return text\n\n\ndef prepare_input(text, tokenizer):\n    if CFG.tail == 0:\n        inputs = tokenizer.encode_plus(\n            text, \n            return_tensors=None, \n            add_special_tokens=True, \n            max_length=CFG.max_length,\n            pad_to_max_length=True,\n            truncation=True\n            )\n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n    else:\n        inputs = tokenizer.encode_plus(\n            text,\n            return_tensors=None, \n            add_special_tokens=True, \n            truncation=True\n            )\n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > CFG.max_length:\n                v = np.hstack([v[:CFG.head], v[-CFG.tail:]])\n            if k == 'input_ids':\n                new_v = np.ones(CFG.max_length) * tokenizer.pad_token_id\n            else:\n                new_v = np.zeros(CFG.max_length)\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.text = df[\"text\"].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):   \n        text = self.text[idx]\n        inputs = prepare_input(str(text), self.tokenizer)\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n        }\n\n\nclass Model_reg(nn.Module):\n    def __init__(self, modelname_or_path):\n        super(Model_reg, self).__init__()\n        self.base_model = AutoModel.from_pretrained(modelname_or_path)\n        self.fc = nn.Linear(CFG.hidden_node, CFG.num_classes)\n        self.dropout = nn.Dropout(p=0.)\n        # self.ln = nn.LayerNorm(CFG.hidden_node)\n        \n    def feature(self, input_ids, attention_mask):\n        outputs = self.base_model(\n            input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=False\n        )\n        last_hidden_states = outputs[0]\n        feature = torch.mean(last_hidden_states, 1)\n        return feature\n\n    def forward(self, input_ids, attention_mask=None):\n        feature = self.feature(input_ids, attention_mask)\n        output = self.fc(self.dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:55.880434Z","iopub.execute_input":"2022-02-07T08:13:55.880669Z","iopub.status.idle":"2022-02-07T08:13:55.928748Z","shell.execute_reply.started":"2022-02-07T08:13:55.880637Z","shell.execute_reply":"2022-02-07T08:13:55.927722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for batch_data in tk0:\n        ids = batch_data['ids'].to(device)\n        mask = batch_data['mask'].to(device)\n        with torch.no_grad():\n            y_preds = model(ids, mask)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\n\ndef main():\n    seed_torch(seed=CFG.seed)\n    \n    validation_data, test, submission = read_data()\n    if len(test) == 7537:\n        test = test.iloc[:100]\n    \n    print(\"Text cleaning...\")\n    test['text'] = test['text'].progress_apply(text_cleaning)\n    \n    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model_path)\n    print(\"tokenizer:\", tokenizer)\n    \n    test_dataset = TestDataset(test, tokenizer, CFG.max_length)\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    predictions = []\n    for ms in range(CFG.n_model_seed):\n        model = Model_reg(CFG.base_model_path)\n    #     print(\"Loaded model:\", model.base_model)\n        state = torch.load(model_path_list[ms], map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        predictions.append(prediction)\n        del model, state; gc.collect()\n        torch.cuda.empty_cache()\n    \n    # submission['score'] = np.mean(predictions, axis=0)\n    # submission[['comment_id', 'score']].to_csv('submission.csv', index=False)\n    predictions = np.array(np.mean(predictions, axis=0))\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:55.930202Z","iopub.execute_input":"2022-02-07T08:13:55.930727Z","iopub.status.idle":"2022-02-07T08:13:55.951762Z","shell.execute_reply.started":"2022-02-07T08:13:55.930693Z","shell.execute_reply":"2022-02-07T08:13:55.950878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naoism4003 = main()\nnaoism4003 = naoism4003.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:13:55.953877Z","iopub.execute_input":"2022-02-07T08:13:55.954283Z","iopub.status.idle":"2022-02-07T08:15:19.886899Z","shell.execute_reply.started":"2022-02-07T08:13:55.954242Z","shell.execute_reply":"2022-02-07T08:15:19.884436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"opt_calpis001 = (opt_calpis001 - (-6.704694566371928)) / 6.580703873327574\ncalpis011 = (calpis011 - 0.8956230733023224) / 2.425622948718177\ncalpis012 = (calpis012 - 0.6895453671041332) / 2.5203015957033124\nmst029 = (mst029 - 0.1526331402436699) / 0.3893276159801335\nmst030 = (mst030 - 0.14825907568890248) / 0.3999030418536887\nmsttweet = (msttweet - 0.12312389583278482) / 0.4091648306519364\ncolum014 = (colum014 - 0.24127438913680962) / 0.44425866838169137\ncolum015 = (colum015 - (-0.2577407630301099)) / 0.5301155853075479\ncolum016 = (colum016 - 0.5858787377958661) / 0.8508980633132797\ncolum018 = (colum018 - 0.22228450849477926) / 0.42716001301281553\ncolum019 = (colum019 - 0.14911354891415332) / 0.4663198934837049\ncolum020 = (colum020 - (-0.14148513577689115)) / 0.4680944916684828\nnaoism4001 = (naoism4001 - 0.17912335923882833) / 0.4534633684561525\nnaoism4003 = (naoism4003 - 0.1490397266759139) /  0.406784531557102\nopt_naoism1004 = (opt_naoism1004 - (-10.102940974843643)) / 6.497813296296825\n\npred_df = pd.DataFrame({\n    'opt_calpis001': opt_calpis001,\n    'calpis011': calpis011,\n    'calpis012': calpis012,\n    'mst029': mst029,\n    'mst030': mst030,\n    'msttweet': msttweet,\n    'colum014': colum014,\n    'colum015': colum015,\n    'colum016': colum016,\n    'colum018': colum018,\n    'colum019': colum019,\n    'colum020': colum020,\n    'naoism4001': naoism4001,\n    'naoism4003': naoism4003,\n    'opt_naoism1004': opt_naoism1004\n})\n\ndisplay(pred_df.describe())\npred_df.to_csv('pred_df.csv', index=False)\n\nsub = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\nif len(sub) == 7537:\n    sub = sub.iloc[:100]\n    \nsub['score'] = (\n    opt_calpis001 * 0.8907374041352457 +\n    calpis011 * 0.46794326158461463 +\n    calpis012 * 0.0613928819716386 +\n    mst029 * 0.14599159334648742 +\n    mst030 * 0.9400258577765264 +\n    msttweet * 0.2296755364508963 +\n    colum014 * 0.46435656956718 +\n    colum015 * 0.8156998001053446 +\n    colum016 * 0.6003326557886719 +\n    colum018 * 0.08731982956387017 +\n    colum019 * 0.02050220970508744 +\n    colum020 * 0.8002815649764881 +\n    naoism4001 * 0.9085892865154106 +\n    naoism4003 * 0.0312185722129308 +\n    opt_naoism1004 * 0.9998908148400331\n)\nsub['score'] = sub['score'].rank(method='first')\nsub.to_csv(\"submission.csv\", index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:15:32.387344Z","iopub.execute_input":"2022-02-07T08:15:32.387626Z","iopub.status.idle":"2022-02-07T08:15:32.523691Z","shell.execute_reply.started":"2022-02-07T08:15:32.387597Z","shell.execute_reply":"2022-02-07T08:15:32.522928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}