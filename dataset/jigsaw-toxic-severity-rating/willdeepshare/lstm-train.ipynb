{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport string\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport json\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, LSTM, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom wordcloud import STOPWORDS\n\nfrom sklearn.model_selection import train_test_split,KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:56:58.824855Z","iopub.execute_input":"2021-12-11T14:56:58.82548Z","iopub.status.idle":"2021-12-11T14:57:04.391137Z","shell.execute_reply.started":"2021-12-11T14:56:58.82539Z","shell.execute_reply":"2021-12-11T14:57:04.390325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/toxic-comments-train/train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\nsample = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\ntarget = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:04.395053Z","iopub.execute_input":"2021-12-11T14:57:04.395289Z","iopub.status.idle":"2021-12-11T14:57:06.825915Z","shell.execute_reply.started":"2021-12-11T14:57:04.395261Z","shell.execute_reply":"2021-12-11T14:57:06.825172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['y'] = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].sum(axis=1) > 0\ntrain.drop(['toxic','severe_toxic','obscene','threat','insult','identity_hate'], inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:06.828752Z","iopub.execute_input":"2021-12-11T14:57:06.829313Z","iopub.status.idle":"2021-12-11T14:57:06.858963Z","shell.execute_reply.started":"2021-12-11T14:57:06.829283Z","shell.execute_reply":"2021-12-11T14:57:06.858234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_of_toxic_comments =  train[train.y != 0].shape[0]\ncount_of_toxic_comments","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:06.861754Z","iopub.execute_input":"2021-12-11T14:57:06.862103Z","iopub.status.idle":"2021-12-11T14:57:06.876578Z","shell.execute_reply.started":"2021-12-11T14:57:06.862073Z","shell.execute_reply":"2021-12-11T14:57:06.875905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_toxic = train[train.y != 0]\ntrain_non_toxic = train[train.y == 0].sample(count_of_toxic_comments)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:06.877927Z","iopub.execute_input":"2021-12-11T14:57:06.878194Z","iopub.status.idle":"2021-12-11T14:57:06.902203Z","shell.execute_reply.started":"2021-12-11T14:57:06.878161Z","shell.execute_reply":"2021-12-11T14:57:06.901452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_toxic, train_non_toxic])\ndf","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:06.903957Z","iopub.execute_input":"2021-12-11T14:57:06.904446Z","iopub.status.idle":"2021-12-11T14:57:06.92493Z","shell.execute_reply.started":"2021-12-11T14:57:06.904409Z","shell.execute_reply":"2021-12-11T14:57:06.924257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.y.value_counts().plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:06.927895Z","iopub.execute_input":"2021-12-11T14:57:06.928177Z","iopub.status.idle":"2021-12-11T14:57:07.327972Z","shell.execute_reply.started":"2021-12-11T14:57:06.92815Z","shell.execute_reply":"2021-12-11T14:57:07.327229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Imbalanced dataset issue sorted","metadata":{}},{"cell_type":"code","source":"# word_count\ndf['word_count'] = df['comment_text'].apply(lambda x: len(str(x).split()))\n\n# unique_word_count\ndf['unique_word_count'] = df['comment_text'].apply(lambda x: len(set(str(x).split())))\n\n# stop_word_count\ndf['stop_word_count'] = df['comment_text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n\n# mean_word_length\ndf['mean_word_length'] = df['comment_text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n\n# char_count\ndf['char_count'] = df['comment_text'].apply(lambda x: len(str(x)))\n\n# punctuation_count\ndf['punctuation_count'] = df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:07.329339Z","iopub.execute_input":"2021-12-11T14:57:07.329624Z","iopub.status.idle":"2021-12-11T14:57:10.157685Z","shell.execute_reply.started":"2021-12-11T14:57:07.329585Z","shell.execute_reply":"2021-12-11T14:57:10.156959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:10.160892Z","iopub.execute_input":"2021-12-11T14:57:10.161103Z","iopub.status.idle":"2021-12-11T14:57:10.177758Z","shell.execute_reply.started":"2021-12-11T14:57:10.161079Z","shell.execute_reply":"2021-12-11T14:57:10.176969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:10.180787Z","iopub.execute_input":"2021-12-11T14:57:10.181193Z","iopub.status.idle":"2021-12-11T14:57:10.219196Z","shell.execute_reply.started":"2021-12-11T14:57:10.18115Z","shell.execute_reply":"2021-12-11T14:57:10.218075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Remove stopwords, Punctuations","metadata":{}},{"cell_type":"code","source":"# Remove stopwords & convert to lower case\ndf['comment_text'] = df['comment_text'].apply(lambda x: ' '.join([w for w in str(x).lower().split() if w not in STOPWORDS]))\n\n# Remove Punctuations\ndf[\"comment_text\"] = df['comment_text'].str.replace('[^\\w\\s]','')\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:10.220938Z","iopub.execute_input":"2021-12-11T14:57:10.221273Z","iopub.status.idle":"2021-12-11T14:57:11.048633Z","shell.execute_reply.started":"2021-12-11T14:57:10.221234Z","shell.execute_reply":"2021-12-11T14:57:11.047898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.reset_index(drop=True)\nkflod = KFold(n_splits=5, shuffle=True, random_state=22)\nfor fold, ( _, val_) in enumerate(kflod.split(X=df)):\n    df.loc[val_ , \"kfold\"] = int(fold)\n\ndf[\"kfold\"] = df[\"kfold\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:11.049925Z","iopub.execute_input":"2021-12-11T14:57:11.050318Z","iopub.status.idle":"2021-12-11T14:57:11.069749Z","shell.execute_reply.started":"2021-12-11T14:57:11.050279Z","shell.execute_reply":"2021-12-11T14:57:11.06905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n    model_save_path = './lstm_{}'.format(fold)\n    if not os.path.exists(model_save_path):\n        os.makedirs(model_save_path)\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_test = df[df.kfold == fold].reset_index(drop=True)\n    X_train, X_test, y_train, y_test = df_train.drop(['y', 'kfold'], axis=1),\\\n                                        df_test.drop(['y', 'kfold'], axis=1),\\\n                                        df_train['y'],\\\n                                        df_test['y']\n    X_train = X_train.comment_text.values\n    X_test = X_test.comment_text.values\n    OOV_TOKEN = '<OOV>'\n    VOCAB_SIZE = 10000\n    MAX_LEN = 100\n    EMBEDDING_DIM = 100\n    tokenizer = Tokenizer(\n    num_words=VOCAB_SIZE,\n    oov_token=OOV_TOKEN)\n    tokenizer.fit_on_texts(X_train)\n    tokenizer_json = tokenizer.to_json()\n    with open(model_save_path+'/tokenizer.json'.format(fold), 'w', encoding='utf-8') as f:\n        f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n    train_seq = tokenizer.texts_to_sequences(X_train)\n    train_padded = pad_sequences(\n    train_seq, maxlen=MAX_LEN, dtype='int32', padding='post',\n    truncating='post')\n\n    test_seq = tokenizer.texts_to_sequences(X_test)\n    test_padded = pad_sequences(\n        test_seq, maxlen=MAX_LEN, dtype='int32', padding='post',\n        truncating='post')\n    \n    model = tf.keras.Sequential([\n        Embedding(VOCAB_SIZE, EMBEDDING_DIM, name=\"embedding\"),\n        LSTM(64),\n        Dropout(0.2),\n        Dense(16, activation='relu'),\n        Dropout(0.2),\n        Dense(1,activation='sigmoid')\n    ])\n    model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n    es = EarlyStopping(patience=3, \n                   monitor='loss', \n                   restore_best_weights=True, \n                   mode='min', \n                   verbose=1)\n    \n    hist = model.fit(\n    train_padded,\n    y = y_train,\n    validation_data=(test_padded, y_test),\n    epochs=15,\n    callbacks=es)\n    model.save(model_save_path)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:11.071203Z","iopub.execute_input":"2021-12-11T14:57:11.071985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare test data","metadata":{}},{"cell_type":"code","source":"target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_target = target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove stopwords & convert to lower case\ndf_target['text'] = df_target['text'].apply(lambda x: ' '.join([w for w in str(x).lower().split() if w not in STOPWORDS]))\n\n# Remove Punctuations\ndf_target[\"text\"] = df_target['text'].str.replace('[^\\w\\s]','')\ndf_target.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_seq = tokenizer.texts_to_sequences(df_target.text.values)\ntarget_padded = pad_sequences(\n    target_seq, maxlen=MAX_LEN, dtype='int32', padding='post',\n    truncating='post'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}