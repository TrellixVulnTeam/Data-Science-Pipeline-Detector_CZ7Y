{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction import text\nimport re\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 150)\nimport os\nimport gc\ngc.enable()\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\nfrom scipy import stats\n%matplotlib inline\nfrom datetime import timedelta\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import MiniBatchKMeans\nimport warnings\nwarnings.filterwarnings('ignore')\nimport urllib        #for url stuff\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import text\nfrom IPython.display import display\nfrom tqdm import tqdm\nfrom collections import Counter\nimport ast\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom textblob import TextBlob\nimport scipy.stats as stats\n\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\nimport seaborn as sns #for making plots\nimport matplotlib.pyplot as plt # for plotting\nimport os  # for os commands\n\nimport gensim\nfrom gensim import corpora, models, similarities\nimport logging\nimport tempfile\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom collections import OrderedDict\n\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.manifold import TSNE\n\n\nfrom bokeh.plotting import figure, output_file, show\nfrom bokeh.models import Label\nfrom bokeh.io import output_notebook\noutput_notebook()\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-08T19:20:58.111734Z","iopub.execute_input":"2021-11-08T19:20:58.112378Z","iopub.status.idle":"2021-11-08T19:20:58.160921Z","shell.execute_reply.started":"2021-11-08T19:20:58.112336Z","shell.execute_reply":"2021-11-08T19:20:58.160061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsubm = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:20:58.163247Z","iopub.execute_input":"2021-11-08T19:20:58.163563Z","iopub.status.idle":"2021-11-08T19:20:58.46515Z","shell.execute_reply.started":"2021-11-08T19:20:58.16352Z","shell.execute_reply":"2021-11-08T19:20:58.464283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train))\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:20:58.466664Z","iopub.execute_input":"2021-11-08T19:20:58.467216Z","iopub.status.idle":"2021-11-08T19:20:58.47962Z","shell.execute_reply.started":"2021-11-08T19:20:58.467174Z","shell.execute_reply":"2021-11-08T19:20:58.479011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words=list(text.ENGLISH_STOP_WORDS.union([\"book\"]))\nhtml_tags = ['<P>', '</P>', '<Table>', '</Table>', '<Tr>', '</Tr>', '<Ul>', '<Ol>', '<Dl>', '</Ul>', '</Ol>', \\\n             '</Dl>', '<Li>', '<Dd>', '<Dt>', '</Li>', '</Dd>', '</Dt>', '/n', '\\n']\nr_buf = ['It', 'is', 'are', 'do', 'does', 'did', 'was', 'were', 'will', 'can', 'the', 'a', 'of', 'in', 'and', 'on', \\\n         'what', 'where', 'when', 'which'] + html_tags\nto_remove=list(set(stop_words+html_tags+r_buf))\n\ndef clean(x):\n    x = x.lower()\n    for r in to_remove:\n        x = x.replace(r, '')\n    x = re.sub(' +', ' ', x)\n    return x\n\n\ncomments=[str(clean(x)) for x in train['less_toxic'].tolist()+train['more_toxic'].tolist()]\nlabels=[0]*30108 + [1]*30108\ntrain = pd.DataFrame({'comments':comments, 'labels':labels})\n\ncomments=[str(clean(x)) for x in test['text'].tolist()]\ntest['comments']=comments","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:20:58.481066Z","iopub.execute_input":"2021-11-08T19:20:58.481866Z","iopub.status.idle":"2021-11-08T19:21:11.614751Z","shell.execute_reply.started":"2021-11-08T19:20:58.48183Z","shell.execute_reply":"2021-11-08T19:21:11.614137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:21:11.616112Z","iopub.execute_input":"2021-11-08T19:21:11.616608Z","iopub.status.idle":"2021-11-08T19:21:11.631833Z","shell.execute_reply.started":"2021-11-08T19:21:11.616567Z","shell.execute_reply":"2021-11-08T19:21:11.631199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:21:11.63301Z","iopub.execute_input":"2021-11-08T19:21:11.633818Z","iopub.status.idle":"2021-11-08T19:21:11.648387Z","shell.execute_reply.started":"2021-11-08T19:21:11.633781Z","shell.execute_reply":"2021-11-08T19:21:11.647678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n\nn = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(2,4), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train['comments'])\ntest_term_doc = vec.transform(test['comments'])","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:21:11.649469Z","iopub.execute_input":"2021-11-08T19:21:11.649793Z","iopub.status.idle":"2021-11-08T19:21:40.00934Z","shell.execute_reply.started":"2021-11-08T19:21:11.649766Z","shell.execute_reply":"2021-11-08T19:21:40.008573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn_term_doc, test_term_doc\n\ndef pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)\n\n\nx = trn_term_doc\ntest_x = test_term_doc\n\n\ndef get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4, solver='liblinear', dual=False)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r\n\npreds = np.zeros((len(test), 1))\n\nfor i, j in enumerate(['labels']):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n    \npreds=[int(p >= 0.6) for p in preds]","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:24:28.198835Z","iopub.execute_input":"2021-11-08T19:24:28.199133Z","iopub.status.idle":"2021-11-08T19:24:41.295161Z","shell.execute_reply.started":"2021-11-08T19:24:28.199091Z","shell.execute_reply":"2021-11-08T19:24:41.294211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'comment_id': subm[\"comment_id\"], 'score': preds})","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:24:41.296776Z","iopub.execute_input":"2021-11-08T19:24:41.297077Z","iopub.status.idle":"2021-11-08T19:24:41.305258Z","shell.execute_reply.started":"2021-11-08T19:24:41.297043Z","shell.execute_reply":"2021-11-08T19:24:41.304173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:24:41.306605Z","iopub.execute_input":"2021-11-08T19:24:41.306882Z","iopub.status.idle":"2021-11-08T19:24:41.326436Z","shell.execute_reply.started":"2021-11-08T19:24:41.306852Z","shell.execute_reply":"2021-11-08T19:24:41.325746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T19:24:41.328695Z","iopub.execute_input":"2021-11-08T19:24:41.329314Z","iopub.status.idle":"2021-11-08T19:24:41.354006Z","shell.execute_reply.started":"2021-11-08T19:24:41.329264Z","shell.execute_reply":"2021-11-08T19:24:41.353069Z"},"trusted":true},"execution_count":null,"outputs":[]}]}