{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this competition we have tried different approaches in order to properly rank from the validation comparisons.\n\nThe idea is to create some features from text using a model such as Detoxify and then use them to develop a ranking model. Since in validation we have two texts in comparison, we just make the difference between the features of the two texts (t1 - t2) and then train a model to figure out if the more toxic has been subtractred from the less toxic or viceversa.\n\nWe use a linear support vector machine because we can later use the decision boundary with the expectation that it has maximized the distance from the boundary based on the intensity of the difference.\n\nIn the testing phase we subtract our text example with different examples from the validation texts in order. Our expectation is that by averaging the resulting decision boundaries we can obtain an average ranking comparable to other tested tests.","metadata":{}},{"cell_type":"code","source":"## install detoxify from dataset\n!cp -r ../input/detoxify-sourcemodels/detoxify .\n!pip install -q ./detoxify\n!rm -r ./detoxify\n\n\n## copy detoxify pretrained models and transformers configuration files from dataset to local caches\n!mkdir -p  /root/.cache/torch/hub/checkpoints\n!mkdir -p  /root/.cache/huggingface/transformers\n!cp -r ../input/detoxify-sourcemodels/torch/hub/checkpoints /root/.cache/torch/hub\n!cp -r ../input/detoxify-sourcemodels/huggingface/transformers /root/.cache/huggingface","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:30:11.718711Z","iopub.execute_input":"2022-02-09T05:30:11.719375Z","iopub.status.idle":"2022-02-09T05:31:05.055567Z","shell.execute_reply.started":"2022-02-09T05:30:11.719259Z","shell.execute_reply":"2022-02-09T05:31:05.054534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting environment variable TRANSFORMERS_OFFLINE=1 will tell Transformers to use local files only and will not try to look things up.\n# Itâ€™s possible to run Transformers in a firewalled or a no-network environment or in a Kaggle inference kernel !\nimport os\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:31:05.057948Z","iopub.execute_input":"2022-02-09T05:31:05.058503Z","iopub.status.idle":"2022-02-09T05:31:05.063081Z","shell.execute_reply.started":"2022-02-09T05:31:05.058457Z","shell.execute_reply":"2022-02-09T05:31:05.062291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detoxify import Detoxify","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:31:05.065705Z","iopub.execute_input":"2022-02-09T05:31:05.065984Z","iopub.status.idle":"2022-02-09T05:31:06.961782Z","shell.execute_reply.started":"2022-02-09T05:31:05.065952Z","shell.execute_reply":"2022-02-09T05:31:06.96107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, GroupKFold, RepeatedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import LinearSVC\n\nimport pickle\nfrom tqdm import tqdm\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:31:06.965601Z","iopub.execute_input":"2022-02-09T05:31:06.965815Z","iopub.status.idle":"2022-02-09T05:31:07.944469Z","shell.execute_reply.started":"2022-02-09T05:31:06.965777Z","shell.execute_reply":"2022-02-09T05:31:07.943698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:31:07.948275Z","iopub.execute_input":"2022-02-09T05:31:07.950196Z","iopub.status.idle":"2022-02-09T05:31:07.955417Z","shell.execute_reply.started":"2022-02-09T05:31:07.950157Z","shell.execute_reply":"2022-02-09T05:31:07.95467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\nsample = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\ntoscore = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-09T05:31:07.958457Z","iopub.execute_input":"2022-02-09T05:31:07.958661Z","iopub.status.idle":"2022-02-09T05:31:08.532546Z","shell.execute_reply.started":"2022-02-09T05:31:07.958635Z","shell.execute_reply":"2022-02-09T05:31:08.531764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frames\nless_df = validation[['worker']].copy()\nmore_df = validation[['worker']].copy()\ntoscore_df = toscore[['comment_id']].copy()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:31:08.533859Z","iopub.execute_input":"2022-02-09T05:31:08.534147Z","iopub.status.idle":"2022-02-09T05:31:08.549886Z","shell.execute_reply.started":"2022-02-09T05:31:08.534106Z","shell.execute_reply":"2022-02-09T05:31:08.549136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(df, comment_text, batch_size=256):\n    types = ['original','unbiased', 'multilingual']\n    for t in types:\n        print(f\"Detoxify {t}\")\n        detox = Detoxify(t, device='cuda')\n        comment_t_pred =[]\n        comment_text_iter = []\n        for i in tqdm(range(0, len(comment_text), batch_size)):\n            comment_text_batch = comment_text[i:i+batch_size]\n            comment_t_pred.append(detox.predict(comment_text_batch))\n        # Stacking batches togeter\n        for i in range(len(comment_t_pred)):\n            if i==0:\n                dx_df = comment_t_pred[i].copy()\n            else:\n                for key in dx_df.keys():\n                    dx_df[key] = dx_df[key] + comment_t_pred[i][key]\n        # Saving results\n        for key in dx_df.keys():\n            df[t+'_'+key] = dx_df[key]\n\npredict(toscore_df, toscore.text.to_list())","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:31:08.55308Z","iopub.execute_input":"2022-02-09T05:31:08.554603Z","iopub.status.idle":"2022-02-09T05:38:27.767031Z","shell.execute_reply.started":"2022-02-09T05:31:08.554549Z","shell.execute_reply":"2022-02-09T05:38:27.766293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we recover the Detoxify estimates on the validation from a pickle in order to save time\n\nwith open('../input/detoxify-validation-prepared/less_df.pkl', 'rb') as f:\n    less_df = pickle.load(f)\n    \nwith open('../input/detoxify-validation-prepared/more_df.pkl', 'rb') as f:\n    more_df = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:38:27.768529Z","iopub.execute_input":"2022-02-09T05:38:27.768964Z","iopub.status.idle":"2022-02-09T05:38:27.854223Z","shell.execute_reply.started":"2022-02-09T05:38:27.768921Z","shell.execute_reply":"2022-02-09T05:38:27.853482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:38:27.85806Z","iopub.execute_input":"2022-02-09T05:38:27.858269Z","iopub.status.idle":"2022-02-09T05:38:27.925707Z","shell.execute_reply.started":"2022-02-09T05:38:27.858243Z","shell.execute_reply":"2022-02-09T05:38:27.924918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we are using a LinearSVC we need to strandardize the features for a better result.","metadata":{}},{"cell_type":"code","source":"ss = StandardScaler()\nss.fit(less_df.append(more_df).iloc[:,1:])\n\nless_df.iloc[:,1:] = ss.transform(less_df.iloc[:,1:])\nmore_df.iloc[:,1:] = ss.transform(more_df.iloc[:,1:])\ntoscore_df.iloc[:,1:] = ss.transform(toscore_df.iloc[:,1:])","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:38:27.927373Z","iopub.execute_input":"2022-02-09T05:38:27.927949Z","iopub.status.idle":"2022-02-09T05:38:28.219876Z","shell.execute_reply.started":"2022-02-09T05:38:27.927899Z","shell.execute_reply":"2022-02-09T05:38:28.21912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We make 500 comparisons in order to extract enough rankings to average","metadata":{}},{"cell_type":"code","source":"cv_score = []\ncv_ranks = []\nresult_x_list =[]\nscores = []\nkf = RepeatedKFold(n_splits=5, n_repeats=120)\n\nfor k, (train_index, test_index) in enumerate(kf.split(validation)):\n    print(f\"\\nCV FOLD {k}\")\n    best_accuracy = 0.0\n    best_c = 1.0\n    \n    # Creating factual and counter-factual comparisons\n    X =  np.vstack([(more_df.iloc[train_index, 1:] - less_df.iloc[train_index, 1:]),\n    (less_df.iloc[train_index, 1:] - less_df.iloc[train_index, 1:])])\n    y = [1] * len(train_index) + [0] * len(train_index)\n    \n    # Tuning a LinearSVC to correctly classify comparisons\n    for c_value in [1000, 100, 10, 1, 0.1, 0.01, 0.001]:\n        svc = LinearSVC(penalty='l2', loss='squared_hinge', dual=False, C=c_value, fit_intercept=False)\n        cv_scores = cross_val_score(svc, X, y, scoring='accuracy', cv=3, n_jobs=-1)\n        accuracy = np.mean(cv_scores)\n        print(f\"With C={c_value} ranking achieves {accuracy:0.3f} accuracy\")\n\n        if accuracy > best_accuracy:\n            best_c = c_value\n            best_accuracy = accuracy\n    \n    # Retraining on all the data with the best C\n    svc = LinearSVC(penalty='l2', loss='squared_hinge', dual=False, C=best_c, fit_intercept=False)\n    svc.fit(X, y)\n    \n    # For CV purposes we compare with a random example from the validation\n    ms_c = less_df.iloc[np.random.choice(range(len(less_df))), 1:]\n    ls_c = more_df.iloc[np.random.choice(range(len(less_df))), 1:]\n    ms = svc.decision_function(more_df.iloc[test_index, 1:] - ms_c)\n    ls = svc.decision_function(less_df.iloc[test_index, 1:] - ls_c)\n\n    score = np.sum(ms > ls) / len(ms)\n    scores.append(score)\n    print(f\"FOLD {k}: validation accuracy = {score:0.5f}\")\n    \n    # In testing phase we compare with a random example from validation\n    if np.random.random() > 0.5:\n        cv_ranks.append(svc.decision_function(toscore_df.iloc[:, 1:] - ms_c))\n    else:\n        cv_ranks.append(svc.decision_function(toscore_df.iloc[:, 1:] - ls_c)) \n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:38:28.221188Z","iopub.execute_input":"2022-02-09T05:38:28.221475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our reference for checking the CV score is the mean accuracy on the validation comparison between two tests","metadata":{}},{"cell_type":"code","source":"print(f\"Average cv score: {np.mean(scores):0.5f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We average the random example rankings in order to obtain a general ranking\nranks = np.vstack(cv_ranks).mean(axis=0)\nranks = (ranks - np.min(ranks)) / (np.max(ranks) - np.min(ranks))\nsub = pd.DataFrame({'comment_id': toscore.comment_id, 'score': ranks})\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}