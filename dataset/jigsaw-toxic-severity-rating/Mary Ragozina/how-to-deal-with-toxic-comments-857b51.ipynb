{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1 style=\"font-size:300%; font-family:cursive; background:Blue; padding:10px; color:white; border-radius: 30px 30px;\"> How to deal with Toxic words?</h1></center>\n<br>\n<center><h1 style=\"font-size:200%; font-family:cursive;color:Blue; \">Jigsaw Rate Severity of Toxic Comments</h1></center>","metadata":{}},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Libraries Import</b></h1></center>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn import metrics\nfrom tqdm.auto import tqdm\nfrom sklearn.naive_bayes import MultinomialNB\nfrom bs4 import BeautifulSoup\nfrom tokenizers import (decoders,models,normalizers,pre_tokenizers,processors,trainers,Tokenizer)\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import Ridge\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:28.898463Z","iopub.execute_input":"2022-01-19T19:54:28.8992Z","iopub.status.idle":"2022-01-19T19:54:28.907679Z","shell.execute_reply.started":"2022-01-19T19:54:28.899161Z","shell.execute_reply":"2022-01-19T19:54:28.906923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Data Preparations </b></h1></center>","metadata":{}},{"cell_type":"code","source":"TRAIN_DATA_PATH = \"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\"\nVALID_DATA_PATH = \"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\"\nTEST_DATA_PATH = \"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\ndf_train = pd.read_csv(TRAIN_DATA_PATH)\ndf_valid = pd.read_csv(VALID_DATA_PATH)\ndf_test = pd.read_csv(TEST_DATA_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:30.658584Z","iopub.execute_input":"2022-01-19T19:54:30.658975Z","iopub.status.idle":"2022-01-19T19:54:31.723381Z","shell.execute_reply.started":"2022-01-19T19:54:30.658943Z","shell.execute_reply":"2022-01-19T19:54:31.722672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:32.662373Z","iopub.execute_input":"2022-01-19T19:54:32.662663Z","iopub.status.idle":"2022-01-19T19:54:32.675218Z","shell.execute_reply.started":"2022-01-19T19:54:32.662632Z","shell.execute_reply":"2022-01-19T19:54:32.674449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_valid.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:34.909984Z","iopub.execute_input":"2022-01-19T19:54:34.910619Z","iopub.status.idle":"2022-01-19T19:54:34.92009Z","shell.execute_reply.started":"2022-01-19T19:54:34.910554Z","shell.execute_reply":"2022-01-19T19:54:34.919441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:36.575355Z","iopub.execute_input":"2022-01-19T19:54:36.575625Z","iopub.status.idle":"2022-01-19T19:54:36.583258Z","shell.execute_reply.started":"2022-01-19T19:54:36.575594Z","shell.execute_reply":"2022-01-19T19:54:36.58263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape,df_valid.shape,df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:38.737257Z","iopub.execute_input":"2022-01-19T19:54:38.737718Z","iopub.status.idle":"2022-01-19T19:54:38.743281Z","shell.execute_reply.started":"2022-01-19T19:54:38.737679Z","shell.execute_reply":"2022-01-19T19:54:38.742626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['toxic','severe_toxic','obscene','threat','insult','identity_hate']:\n    print(f'------------------------{col}-----------------------')\n    display(df_train.loc[df_train[col]==1,['comment_text',col]].sample(2))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:04.833559Z","iopub.execute_input":"2022-01-19T19:55:04.834449Z","iopub.status.idle":"2022-01-19T19:55:04.886694Z","shell.execute_reply.started":"2022-01-19T19:55:04.834412Z","shell.execute_reply":"2022-01-19T19:55:04.885913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Feature Weights </b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"\nIn the previous competition the task was to perform multi-class classification. Text sample could be labeled with one or several categories or not labeled with any. Non-toxic comments represent the majority of text samples, while toxic comments are a minority class and extremely toxic comments are more rare than plain toxic.In this competition we have to score texts based on the level of toxicity. To get a toxicity score from the previous data we can use two approaches:\n\n* Simply sum up all values in each row of the DataFrame. The toxicity score will vary between 0 and 6. However some unequally toxic samples could have the same score.\n    \n* Adjust the values in the DataFrame according to extremety of the category (for example, \"toxic\" and \"severe toxic\" should have different score) and then sum up per row values.\n","metadata":{}},{"cell_type":"code","source":"cat_mtpl ={'obscene':0.16,'toxic':0.32,'threat':1.5,\n          'insult':0.64,'severe_toxic':1.5,'identity_hate':1.5}\n\n\nfor category in cat_mtpl:\n    df_train[category] = df_train[category]*cat_mtpl[category]\n    \ndf_train['score'] = df_train.loc[:,'toxic':'identity_hate'].mean(axis = 1)\ndf_train['y'] = df_train['score']\n\n\nmin_len = (df_train['y']>0).sum()\n\ndf_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=41)  # take non toxic comments\n\ndf_train_new = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\n\ndf_train_new.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T18:56:52.433545Z","iopub.execute_input":"2022-01-19T18:56:52.434192Z","iopub.status.idle":"2022-01-19T18:56:52.509157Z","shell.execute_reply.started":"2022-01-19T18:56:52.434153Z","shell.execute_reply":"2022-01-19T18:56:52.508476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Text Cleaning</b></h1></center>","metadata":{}},{"cell_type":"code","source":"'''def text_cleaning(text):\n    template = re.compile(r'https?://\\S+|www\\.\\S+')\n    text = template.sub(r'',text)\n    \n    soup = BeautifulSoup(text,'lxml')\n    only_text = soup.get_text()\n    text = only_text\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    text = re.sub(r\"[^a-zA-Z\\d]\",\" \",text)\n    text = re.sub(' +',' ',text)\n    text = text.strip().lower()\n    \n    lemmatizer = WordNetLemmatizer()\n    stop = stopwords.words('english')\n    \n    text  = ''.join([lemmatizer.lemmatize(word) for word in text.split( ' ')])\n    \n    text = ' '.join([word for word in text.split(' ') if word not in stop])\n    \n    return text '''\n\n'''tqdm.pandas()\ndf_train_new['clean_text'] = df_train_new['comment_text'].progress_apply(text_cleaning)'''\n\n'''df_test['text'] = df_test['text'].progress_apply(text_cleaning)'''","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:08:02.276595Z","iopub.execute_input":"2022-01-19T12:08:02.2769Z","iopub.status.idle":"2022-01-19T12:08:02.284761Z","shell.execute_reply.started":"2022-01-19T12:08:02.276858Z","shell.execute_reply":"2022-01-19T12:08:02.28387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:cursive; color:Red; border:solid; border-radius:10px 10px; padding:13px;\"><b>For Now I have not used this text cleaning</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Tokenizer Train</b></h1></center>","metadata":{}},{"cell_type":"code","source":"raw_t = Tokenizer(models.WordPiece(unk_token = \"[UNK]\"))\nraw_t.normalizer = normalizers.BertNormalizer(lowercase = True)\nraw_t.pre_tokenizer  = pre_tokenizers.BertPreTokenizer()\n\nspecial_tokens = [\"[UNK]\",\"[PAD]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n\ntrainer = trainers.WordPieceTrainer(vocab_size = 50000,\n                                  special_tokens = special_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:01:53.56037Z","iopub.execute_input":"2022-01-19T19:01:53.560657Z","iopub.status.idle":"2022-01-19T19:01:53.578763Z","shell.execute_reply.started":"2022-01-19T19:01:53.560626Z","shell.execute_reply":"2022-01-19T19:01:53.578036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\ndataset = Dataset.from_pandas(df_train_new[['comment_text']])\n\ndef get_training_corpus():\n    for i in range(0,len(dataset),1000):\n        yield dataset[i:i+1000][\"comment_text\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:02:14.393476Z","iopub.execute_input":"2022-01-19T19:02:14.393926Z","iopub.status.idle":"2022-01-19T19:02:16.13614Z","shell.execute_reply.started":"2022-01-19T19:02:14.393886Z","shell.execute_reply":"2022-01-19T19:02:16.135269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_t.train_from_iterator(get_training_corpus(),trainer =trainer)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:02:18.477025Z","iopub.execute_input":"2022-01-19T19:02:18.477267Z","iopub.status.idle":"2022-01-19T19:02:25.626117Z","shell.execute_reply.started":"2022-01-19T19:02:18.47724Z","shell.execute_reply":"2022-01-19T19:02:25.625231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Model Training</b></h1></center>","metadata":{}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\n\ntokenizer =PreTrainedTokenizerFast(\ntokenizer_object = raw_t,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:02:25.63016Z","iopub.execute_input":"2022-01-19T19:02:25.630411Z","iopub.status.idle":"2022-01-19T19:02:25.740055Z","shell.execute_reply.started":"2022-01-19T19:02:25.630377Z","shell.execute_reply":"2022-01-19T19:02:25.739411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy_fun(doc):\n    return doc\nlabels = df_train_new['y']\ncomment = df_train_new['comment_text']\ntokenized_comments = tokenizer(comment.to_list())['input_ids']\n\nvectorizer = TfidfVectorizer(\nanalyzer = 'word',\ntokenizer = dummy_fun,\npreprocessor = dummy_fun,\ntoken_pattern =None)\n\ncom_tr = vectorizer.fit_transform(tokenized_comments)\ncom_tr","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:02:29.249663Z","iopub.execute_input":"2022-01-19T19:02:29.24992Z","iopub.status.idle":"2022-01-19T19:02:37.966529Z","shell.execute_reply.started":"2022-01-19T19:02:29.24989Z","shell.execute_reply":"2022-01-19T19:02:37.965835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Simple Ridge </b></h1></center>","metadata":{}},{"cell_type":"code","source":"%%time\nregressor =Ridge(random_state = 42,alpha = 0.8)\nregressor.fit(com_tr,labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:08:20.57662Z","iopub.execute_input":"2022-01-19T12:08:20.576853Z","iopub.status.idle":"2022-01-19T12:08:20.952571Z","shell.execute_reply.started":"2022-01-19T12:08:20.57682Z","shell.execute_reply":"2022-01-19T12:08:20.951828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''%%time\nmodel = Ridge(alpha=0.5)\nmodel.fit(com_tr,labels)'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''%%time\nl_model = Ridge(alpha=1.)\nl_model.fit(com_tr,labels)'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''%%time\ns_model = Ridge(alpha=2.)\ns_model.fit(com_tr,labels)'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Processing Validation Data</b></h1></center>","metadata":{}},{"cell_type":"code","source":"# preprocess val data\nless_toxic_comments = df_valid['less_toxic']\nmore_toxic_comments = df_valid['more_toxic']\n\nless_toxic_comments = tokenizer(less_toxic_comments.to_list())['input_ids']\nmore_toxic_comments = tokenizer(more_toxic_comments.to_list())['input_ids']\n\n\nless_toxic = vectorizer.transform(less_toxic_comments)\nmore_toxic = vectorizer.transform(less_toxic_comments)\n\ny_pred_less = regressor.predict(less_toxic)\ny_pred_more = regressor.predict(more_toxic)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:03:17.040579Z","iopub.execute_input":"2022-01-19T19:03:17.041235Z","iopub.status.idle":"2022-01-19T19:03:35.093836Z","shell.execute_reply.started":"2022-01-19T19:03:17.041198Z","shell.execute_reply":"2022-01-19T19:03:35.093093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(y_pred_less<y_pred_more).mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:03:35.095389Z","iopub.execute_input":"2022-01-19T19:03:35.095662Z","iopub.status.idle":"2022-01-19T19:03:35.102904Z","shell.execute_reply.started":"2022-01-19T19:03:35.095628Z","shell.execute_reply":"2022-01-19T19:03:35.102269Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Final Prediction on Test Data</b></h1></center>","metadata":{}},{"cell_type":"code","source":"texts = df_test['text']\ntexts = tokenizer(texts.to_list())['input_ids']\ntexts = vectorizer.transform(texts)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:03:43.605636Z","iopub.execute_input":"2022-01-19T19:03:43.60606Z","iopub.status.idle":"2022-01-19T19:03:45.70975Z","shell.execute_reply.started":"2022-01-19T19:03:43.606023Z","shell.execute_reply":"2022-01-19T19:03:45.709022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['prediction'] = regressor.predict(texts)\ndf_test = df_test[['comment_id','prediction']]\n\ndf_test['score'] = df_test['prediction']\ndf_test = df_test[['comment_id','score']]","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:03:45.711933Z","iopub.execute_input":"2022-01-19T19:03:45.712156Z","iopub.status.idle":"2022-01-19T19:03:45.721303Z","shell.execute_reply.started":"2022-01-19T19:03:45.712128Z","shell.execute_reply":"2022-01-19T19:03:45.720474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Submission File</b></h1></center>","metadata":{}},{"cell_type":"code","source":"df_test.to_csv('./submission.csv', index=False)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:03:46.975507Z","iopub.execute_input":"2022-01-19T19:03:46.976094Z","iopub.status.idle":"2022-01-19T19:03:47.016477Z","shell.execute_reply.started":"2022-01-19T19:03:46.976057Z","shell.execute_reply":"2022-01-19T19:03:47.015708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <center><h1 style=\"font-size:150%; font-family:solid; color:DarkOrange; border:solid; border-radius:10px 10px; padding:13px;\"><b> Updating...</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}