{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TF-IDF Vectorization with Keras\n\n\nThanks for the notebook from \n- https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768 \n- https://www.kaggle.com/steubk/jrsotc-ridgeregression\n\n[julian3833](https://www.kaggle.com/julian3833) and [steubk](https://www.kaggle.com/steubk) both show a good way of TF-IDF Vectorization with SKLearn Models such as Ridge Regression and Naive Bayes. Recently I was thinking of a way to use TF-IDF vectorization with Keras, so that we can work with different kinds of Neural Network,  luckily I find a way to do it with keras `TextVectorization` layer.\n\nI will also build a multi-label classification Model and train with all labels from [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). After training, I will use the Model to predict probability of all labels and multiply them with weights to generate a final result for calcuate ranking of toxicity.\n\nI am also keeping several models and use their final results to calcuate final score.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import rankdata\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nimport numpy as np\nimport sklearn \nimport os\nfrom sklearn import model_selection\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:46:30.543605Z","iopub.execute_input":"2021-11-18T16:46:30.543895Z","iopub.status.idle":"2021-11-18T16:46:30.54916Z","shell.execute_reply.started":"2021-11-18T16:46:30.543855Z","shell.execute_reply":"2021-11-18T16:46:30.548311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    vocab_size = 20000\n    batch_size = 256\n    epochs = 50\n    labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n       'identity_hate']\n    label_weights = [1, 2, 2, 5, 1, 2]\n    ouput_dataset_path = \"../input/tfidf-vectorization-with-keras-output\"\n    best_acc_path = \"model_best_acc.tf\"\n    best_auc_path = \"model_best_auc.tf\"\n    best_loss_path = \"model_best_loss.tf\"\n    latest_path = \"model_latest.tf\"\n    model_paths = [best_acc_path, best_auc_path, latest_path, best_loss_path]\n    modes = [\"training\", \"inference\"]\n    mode = modes[0]\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:52:30.827751Z","iopub.execute_input":"2021-11-18T16:52:30.828454Z","iopub.status.idle":"2021-11-18T16:52:30.835124Z","shell.execute_reply.started":"2021-11-18T16:52:30.82841Z","shell.execute_reply":"2021-11-18T16:52:30.834071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the data\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ndf = df.rename(columns={'comment_text': 'text'})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:24:59.568237Z","iopub.execute_input":"2021-11-18T16:24:59.56852Z","iopub.status.idle":"2021-11-18T16:25:01.418846Z","shell.execute_reply.started":"2021-11-18T16:24:59.568488Z","shell.execute_reply":"2021-11-18T16:25:01.418104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF vectorization","metadata":{}},{"cell_type":"code","source":"X = df[\"text\"]\ntext_vectorizer = layers.TextVectorization(max_tokens=config.vocab_size, output_mode=\"tf-idf\", ngrams=2)\n# Index the bigrams and learn the TF-IDF weights via `adapt()`\nwith tf.device(\"CPU\"):\n    # A bug that prevents this from running on GPU for now.\n    text_vectorizer.adapt(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:25:06.814544Z","iopub.execute_input":"2021-11-18T16:25:06.815267Z","iopub.status.idle":"2021-11-18T16:25:47.588456Z","shell.execute_reply.started":"2021-11-18T16:25:06.81523Z","shell.execute_reply":"2021-11-18T16:25:47.587588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df[config.labels]\ny.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:25:47.590061Z","iopub.execute_input":"2021-11-18T16:25:47.590325Z","iopub.status.idle":"2021-11-18T16:25:47.646607Z","shell.execute_reply.started":"2021-11-18T16:25:47.590288Z","shell.execute_reply":"2021-11-18T16:25:47.645659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output of the vectorizer:","metadata":{}},{"cell_type":"code","source":"sample = text_vectorizer(X[0:config.batch_size])\nsample.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:25:47.648236Z","iopub.execute_input":"2021-11-18T16:25:47.648527Z","iopub.status.idle":"2021-11-18T16:25:47.724788Z","shell.execute_reply.started":"2021-11-18T16:25:47.648487Z","shell.execute_reply":"2021-11-18T16:25:47.724014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n        keras.Input(shape=(None, ), dtype=\"string\"),\n        text_vectorizer,\n        layers.Dense(256, activation=\"relu\", kernel_regularizer=\"l2\"),\n        layers.Dense(32, activation=\"relu\", kernel_regularizer=\"l2\"),\n        layers.Dense(len(config.labels), activation=\"sigmoid\")\n    ])\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"categorical_accuracy\", keras.metrics.AUC()])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:25:55.132915Z","iopub.execute_input":"2021-11-18T16:25:55.13321Z","iopub.status.idle":"2021-11-18T16:25:55.23936Z","shell.execute_reply.started":"2021-11-18T16:25:55.133177Z","shell.execute_reply":"2021-11-18T16:25:55.238547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Validation Split","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:54:30.312069Z","iopub.execute_input":"2021-11-18T16:54:30.312534Z","iopub.status.idle":"2021-11-18T16:54:30.384098Z","shell.execute_reply.started":"2021-11-18T16:54:30.312491Z","shell.execute_reply":"2021-11-18T16:54:30.383264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"if config.mode == config.modes[0]:\n    model_best_acc_checkpoint = keras.callbacks.ModelCheckpoint(config.best_acc_path, save_best_only=True, save_weights_only=True, monitor=\"val_categorical_accuracy\")\n    model_best_auc_checkpoint = keras.callbacks.ModelCheckpoint(config.best_auc_path, save_best_only=True, save_weights_only=True, monitor=\"val_auc\")\n    model_best_loss_checkpoint = keras.callbacks.ModelCheckpoint(config.best_loss_path, save_best_only=True, save_weights_only=True, monitor=\"val_loss\")\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n    model.fit(X_train, y_train, epochs=config.epochs, batch_size=config.batch_size, validation_data=(X_val, y_val), callbacks=[model_best_acc_checkpoint, model_best_auc_checkpoint, model_best_loss_checkpoint, reduce_lr])\n    model.save_weights(config.latest_path)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:54:34.026948Z","iopub.execute_input":"2021-11-18T16:54:34.027629Z","iopub.status.idle":"2021-11-18T16:54:34.035287Z","shell.execute_reply.started":"2021-11-18T16:54:34.027587Z","shell.execute_reply":"2021-11-18T16:54:34.034137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evluation\n","metadata":{}},{"cell_type":"code","source":"def evaluate(model, model_path, X_val, y_val):\n    print(\"Evaluation of %s\"%(model_path))\n    path = model_path\n    if config.mode == config.modes[1]:\n        path = os.path.join(config.ouput_dataset_path, path)\n    model.load_weights(path)\n    result = np.array(model.predict(X_val) > 0.5, dtype=int)\n    for i in range(len(config.labels)):\n        cls_report = metrics.classification_report(y_val[config.labels[i]], result[:, i])\n        print(\"Classification Report of %s\"%config.labels[i])\n        print(cls_report)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:54:37.243871Z","iopub.execute_input":"2021-11-18T16:54:37.244164Z","iopub.status.idle":"2021-11-18T16:54:37.251423Z","shell.execute_reply.started":"2021-11-18T16:54:37.244128Z","shell.execute_reply":"2021-11-18T16:54:37.2506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in config.model_paths:\n    evaluate(model, path, X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:53:16.505271Z","iopub.execute_input":"2021-11-18T16:53:16.505544Z","iopub.status.idle":"2021-11-18T16:53:50.107083Z","shell.execute_reply.started":"2021-11-18T16:53:16.505515Z","shell.execute_reply":"2021-11-18T16:53:50.106202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"scores = []\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nfor path in [config.best_acc_path, config.best_auc_path, config.latest_path, config.best_loss_path]:\n    if config.mode == config.modes[1]:\n        path = os.path.join(config.ouput_dataset_path, path)\n    model.load_weights(path)\n    score = model.predict(df_sub[\"text\"], batch_size=config.batch_size)\n    score = np.sum(score * np.array(config.label_weights), axis=1)\n    scores.append(score)\nscore = np.mean(scores, axis=0)\ndf_sub['score'] = rankdata(score, method='ordinal')\ndf_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\ndf_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T16:55:17.878769Z","iopub.execute_input":"2021-11-18T16:55:17.879054Z","iopub.status.idle":"2021-11-18T16:55:20.507747Z","shell.execute_reply.started":"2021-11-18T16:55:17.879023Z","shell.execute_reply":"2021-11-18T16:55:20.506995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<font color=\"red\" size=\"5\">If you found it useful and would like to back me up, just upvote.</font>\n\n","metadata":{}}]}