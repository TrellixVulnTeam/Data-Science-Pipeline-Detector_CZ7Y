{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-21T10:44:34.069845Z","iopub.execute_input":"2021-11-21T10:44:34.070165Z","iopub.status.idle":"2021-11-21T10:44:34.093441Z","shell.execute_reply.started":"2021-11-21T10:44:34.07007Z","shell.execute_reply":"2021-11-21T10:44:34.092179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n## Train set\ntr = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv')\ntr.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.095755Z","iopub.execute_input":"2021-11-21T10:44:34.096042Z","iopub.status.idle":"2021-11-21T10:44:34.201135Z","shell.execute_reply.started":"2021-11-21T10:44:34.096007Z","shell.execute_reply":"2021-11-21T10:44:34.200335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Validation data set\nval = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv')\nval.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.203172Z","iopub.execute_input":"2021-11-21T10:44:34.203822Z","iopub.status.idle":"2021-11-21T10:44:34.672881Z","shell.execute_reply.started":"2021-11-21T10:44:34.203774Z","shell.execute_reply":"2021-11-21T10:44:34.672212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Sample submission data set\nsub = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/sample_submission.csv')\nsub.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.674148Z","iopub.execute_input":"2021-11-21T10:44:34.674538Z","iopub.status.idle":"2021-11-21T10:44:34.694215Z","shell.execute_reply.started":"2021-11-21T10:44:34.674504Z","shell.execute_reply":"2021-11-21T10:44:34.693503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA on Comments to score dataset","metadata":{}},{"cell_type":"code","source":"## Top 5 less toxic comments\n\nval['less_toxic'].value_counts().head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.696549Z","iopub.execute_input":"2021-11-21T10:44:34.696864Z","iopub.status.idle":"2021-11-21T10:44:34.720012Z","shell.execute_reply.started":"2021-11-21T10:44:34.696829Z","shell.execute_reply":"2021-11-21T10:44:34.719285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr['text'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.721517Z","iopub.execute_input":"2021-11-21T10:44:34.721797Z","iopub.status.idle":"2021-11-21T10:44:34.741235Z","shell.execute_reply.started":"2021-11-21T10:44:34.721758Z","shell.execute_reply":"2021-11-21T10:44:34.740571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## There are several unwanted punctuation marks in the text.\n# ## Some comments have repeated dots and words. We have to clean them\n\n# tr['text'] = tr['text'].apply(lambda x:x.split('...')[0])\n# tr['text']","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.742607Z","iopub.execute_input":"2021-11-21T10:44:34.742911Z","iopub.status.idle":"2021-11-21T10:44:34.746502Z","shell.execute_reply.started":"2021-11-21T10:44:34.742873Z","shell.execute_reply":"2021-11-21T10:44:34.745782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data cleaning","metadata":{}},{"cell_type":"code","source":"import re\nimport string\ndef clean(d):\n    ## lowercase the reviews\n    d = d.apply(lambda x:x.lower())\n    ## remove punctuation marks\n    d = d.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n    # Removing extra spaces\n    d = d.apply(lambda x: re.sub(' +',' ',x))\n    ## Remove line breaks\n    d = d.replace('\\n',' ').replace('\\r',' ').replace('...',' ')\n    # Remove special characters\n    d = d.apply(lambda x:re.sub('[^a-zA-z0-9\\s]','',x))\n\n    ## Look at the text after cleaning \n    d.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.748062Z","iopub.execute_input":"2021-11-21T10:44:34.748772Z","iopub.status.idle":"2021-11-21T10:44:34.75765Z","shell.execute_reply.started":"2021-11-21T10:44:34.748735Z","shell.execute_reply":"2021-11-21T10:44:34.756853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean(tr['text'])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:34.759077Z","iopub.execute_input":"2021-11-21T10:44:34.759344Z","iopub.status.idle":"2021-11-21T10:44:35.178879Z","shell.execute_reply.started":"2021-11-21T10:44:34.759309Z","shell.execute_reply":"2021-11-21T10:44:35.178179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stopwords removal & Lemmatization\n\nStopwords are the most commonly occuring words in the text carrying no meaning. Ex: 'I', 'This','on','there','here','is','in'.\n\nWe will use spacy , a nltk library to remove stopwords from the cleaned train set.\n\nLemmatization removes inflectional endings only and returns the base or dictionary form of a word, which is known as the lemma .\nEx: rained, rainning, has rained, going to rain will be reduced to 'rain'","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n\n# Lemmatization with stopwords removal\ntr['text']=tr['text'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:44:35.180027Z","iopub.execute_input":"2021-11-21T10:44:35.180695Z","iopub.status.idle":"2021-11-21T10:45:49.204627Z","shell.execute_reply.started":"2021-11-21T10:44:35.180659Z","shell.execute_reply":"2021-11-21T10:45:49.203784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr['text'].head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:49.206058Z","iopub.execute_input":"2021-11-21T10:45:49.206347Z","iopub.status.idle":"2021-11-21T10:45:49.216486Z","shell.execute_reply.started":"2021-11-21T10:45:49.206313Z","shell.execute_reply":"2021-11-21T10:45:49.215412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"markdown","source":"Introducing the feature Polarity to score toxicity of comments.\n\nSentiment analysis is the analysis of how much a piece of text is positive and opinionated.\n","metadata":{}},{"cell_type":"code","source":"from textblob import TextBlob\ntr['polarity'] = tr['text'].apply(lambda x: round(TextBlob(x).sentiment.polarity),2)\nprint(\" 3 Comments which are positive (highest polarity)\")\nfor index, t in enumerate(tr.iloc[tr['polarity'].sort_values(ascending = True)[:3].index]['text']):\n    print(index+1,t,'\\n')\n# tr[['polarity','text']].head(3)\ntr['polarity_category'] = ['positive' if score > 0\n                           else 'negative' if score < 0 \n                              else 'neutral' \n                                  for score in tr['polarity']]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:49.218202Z","iopub.execute_input":"2021-11-21T10:45:49.218651Z","iopub.status.idle":"2021-11-21T10:45:53.784802Z","shell.execute_reply.started":"2021-11-21T10:45:49.218595Z","shell.execute_reply":"2021-11-21T10:45:53.784062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr.groupby(by=['polarity_category']).describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:53.786106Z","iopub.execute_input":"2021-11-21T10:45:53.786343Z","iopub.status.idle":"2021-11-21T10:45:53.84494Z","shell.execute_reply.started":"2021-11-21T10:45:53.78631Z","shell.execute_reply":"2021-11-21T10:45:53.843981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.barplot(x = 'polarity_category', y ='polarity',data = tr)\nplt.title('Sentiment analysis of comments')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:53.848684Z","iopub.execute_input":"2021-11-21T10:45:53.848894Z","iopub.status.idle":"2021-11-21T10:45:54.259938Z","shell.execute_reply.started":"2021-11-21T10:45:53.848867Z","shell.execute_reply":"2021-11-21T10:45:54.259242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:54.261489Z","iopub.execute_input":"2021-11-21T10:45:54.261776Z","iopub.status.idle":"2021-11-21T10:45:54.271628Z","shell.execute_reply.started":"2021-11-21T10:45:54.26174Z","shell.execute_reply":"2021-11-21T10:45:54.270764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Tokenization\n\nTokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nt = Tokenizer()\ninput_text = tr['text'].values\nt.fit_on_texts(input_text)\ntxt_sequences = t.texts_to_sequences(input_text)\ntxt_vectors = pad_sequences(txt_sequences, maxlen = 512)\ntxt_vectors.shape\n\nprint('Text tokens count ',len(t.word_index))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:54.273396Z","iopub.execute_input":"2021-11-21T10:45:54.273951Z","iopub.status.idle":"2021-11-21T10:45:55.914253Z","shell.execute_reply.started":"2021-11-21T10:45:54.273892Z","shell.execute_reply":"2021-11-21T10:45:55.912586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the deep learning model\n\nAn lstm model can remember, learn and memorise sequences of padded vectors.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\nfrom tensorflow.keras.losses import BinaryCrossentropy\nvocab_size = 60000\nembedding_dim = 100\nmodel = Sequential([\n    Embedding(vocab_size, embedding_dim,name='embedding'),\n    LSTM(64),\n    Dropout(0.2),\n    Dense(16,activation = 'relu'),\n    Dropout(0.2),\n    Dense(1,activation = 'sigmoid')\n])\nmodel.compile(optimizer='adam',loss=BinaryCrossentropy(from_logits = True),\n             metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:45:55.915661Z","iopub.execute_input":"2021-11-21T10:45:55.915982Z","iopub.status.idle":"2021-11-21T10:46:03.206172Z","shell.execute_reply.started":"2021-11-21T10:45:55.915945Z","shell.execute_reply":"2021-11-21T10:46:03.205477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\nplot_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:46:03.207427Z","iopub.execute_input":"2021-11-21T10:46:03.207709Z","iopub.status.idle":"2021-11-21T10:46:04.239179Z","shell.execute_reply.started":"2021-11-21T10:46:03.207671Z","shell.execute_reply":"2021-11-21T10:46:04.238394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model\n\n","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\nimport datetime\n\ncp_file = './lstm_model.h5'\ncp = ModelCheckpoint(cp_file, \n                     monitor='loss', \n                     verbose=0, \n                     save_best_only=True, mode='min')\n\nes = EarlyStopping(patience=3, \n                   monitor='loss', \n                   #restore_best_weights=True, \n                   mode='min', \n                   verbose=1)\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")\n\n# model train\nhistory = model.fit(txt_vectors,tr['polarity'].values,\n                    batch_size= 500, \n                    epochs= 10,\n                    validation_split=0.1,\n                    callbacks=[es, cp, tensorboard_callback],\n                    shuffle=True,\n                    )\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:46:04.240877Z","iopub.execute_input":"2021-11-21T10:46:04.241502Z","iopub.status.idle":"2021-11-21T10:46:27.582841Z","shell.execute_reply.started":"2021-11-21T10:46:04.241463Z","shell.execute_reply":"2021-11-21T10:46:27.581765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# %reload_ext tensorboard\n# !kill 302\n# %tensorboard --logdir logs","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:46:27.585571Z","iopub.execute_input":"2021-11-21T10:46:27.586006Z","iopub.status.idle":"2021-11-21T10:46:27.589488Z","shell.execute_reply.started":"2021-11-21T10:46:27.585966Z","shell.execute_reply":"2021-11-21T10:46:27.588724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"preds = model.predict(txt_vectors)\nplt.hist(preds,label='Model Prediction')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:47:14.31805Z","iopub.execute_input":"2021-11-21T10:47:14.318605Z","iopub.status.idle":"2021-11-21T10:47:17.438569Z","shell.execute_reply.started":"2021-11-21T10:47:14.318468Z","shell.execute_reply":"2021-11-21T10:47:17.437793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"from scipy.stats import rankdata\nu = pd.DataFrame()\nu['comment_id'] = tr['comment_id']\nu['score'] = rankdata(preds)\nu.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:48:26.961798Z","iopub.execute_input":"2021-11-21T10:48:26.962073Z","iopub.status.idle":"2021-11-21T10:48:26.994532Z","shell.execute_reply.started":"2021-11-21T10:48:26.962043Z","shell.execute_reply":"2021-11-21T10:48:26.993727Z"},"trusted":true},"execution_count":null,"outputs":[]}]}