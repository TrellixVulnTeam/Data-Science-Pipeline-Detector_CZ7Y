{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras\nfrom sklearn.model_selection import train_test_split\nimport json\nimport io\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-07T13:09:33.869749Z","iopub.execute_input":"2022-02-07T13:09:33.870352Z","iopub.status.idle":"2022-02-07T13:09:40.394362Z","shell.execute_reply.started":"2022-02-07T13:09:33.870262Z","shell.execute_reply":"2022-02-07T13:09:40.393734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data = pd.read_csv(\"../input/jigsaw-regression-based-data/train_data_version2.csv\")\n\n# input_text_train = input_txt[:int(0.8*(len(input_txt)))]\n# labels_train = input_labels[:int(0.8*(len(input_txt)))]\n# input_text_test = input_txt[int(0.8*(len(input_txt))):]\n# labels_test = input_labels[int(0.8*(len(input_txt))):]\n\n# sample_submission = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/sample_submission.csv\")\n# comments_to_score = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n# merged = pd.merge(sample_submission, comments_to_score)\n# input_text_test = merged['text']\n# labels_test = merged['score']","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:34:32.353526Z","iopub.status.idle":"2022-02-01T18:34:32.354671Z","shell.execute_reply.started":"2022-02-01T18:34:32.354416Z","shell.execute_reply":"2022-02-01T18:34:32.354443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\", usecols=['id','comment_text', 'toxic'])\n# id_of_no_toxic = (data[data['toxic']==0]['id']).map(int)\n# exclude = list(np.random.choice(id_of_no_toxic,int(.8 * len(id_of_no_toxic))))\n# data = data[~data['id'].isin(exclude)]\n# data = data.rename(columns={\"comment_text\": \"text\", \"toxic\": \"y\"})","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:40:28.351292Z","iopub.execute_input":"2022-02-01T18:40:28.351562Z","iopub.status.idle":"2022-02-01T18:40:49.322862Z","shell.execute_reply.started":"2022-02-01T18:40:28.351522Z","shell.execute_reply":"2022-02-01T18:40:49.322068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_txt = data['text']\n# input_labels = data['y'].map(float)\n\n# x_train, x_test, y_train, y_test = train_test_split(input_txt, input_labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:40:49.326371Z","iopub.execute_input":"2022-02-01T18:40:49.326657Z","iopub.status.idle":"2022-02-01T18:40:49.956444Z","shell.execute_reply.started":"2022-02-01T18:40:49.326618Z","shell.execute_reply":"2022-02-01T18:40:49.955452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:45:30.005491Z","iopub.execute_input":"2022-02-01T18:45:30.0062Z","iopub.status.idle":"2022-02-01T18:45:30.01293Z","shell.execute_reply.started":"2022-02-01T18:45:30.006156Z","shell.execute_reply":"2022-02-01T18:45:30.012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyse exploratoire\n\n# def exp(input_text, labels):\n#     print(\"Moyenne de toxicité :\", sum(labels)/len(labels))\n#     print(\"Toxicité médiane :\", np.percentile(labels, 50))\n#     print('Min/Max de toxicité : {:.2} | {:.2}'.format(min(labels), max(labels)))\n#     print('Variance :', np.var(labels))\n#     print('Ecart-type :', np.std(labels))\n\n#     print(max(len(i) for i in input_text))\n#     print(min(len(i) for i in input_text))\n#     print(np.percentile([len(i) for i in input_text], 50))\n\n# exp(x_train, y_train)\n# exp(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:35:12.327484Z","iopub.execute_input":"2022-02-01T18:35:12.327751Z","iopub.status.idle":"2022-02-01T18:35:14.286843Z","shell.execute_reply.started":"2022-02-01T18:35:12.327717Z","shell.execute_reply":"2022-02-01T18:35:14.285982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def tokenisation(input_text):\n#     tokenizer = tf.keras.preprocessing.text.Tokenizer(1024, \"\", False, \"\", True, \"OOV\")\n#     tokenizer.fit_on_texts(input_text)\n#     unique_token_count = len(tokenizer.word_counts) + 2\n#     token_sequences = tokenizer.texts_to_sequences(input_text)\n#     padded_token_sequences = tf.keras.preprocessing.sequence.pad_sequences(token_sequences, 180)\n#     return padded_token_sequences, unique_token_count","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:49:36.513535Z","iopub.execute_input":"2022-02-01T18:49:36.513763Z","iopub.status.idle":"2022-02-01T18:49:36.521675Z","shell.execute_reply.started":"2022-02-01T18:49:36.513735Z","shell.execute_reply":"2022-02-01T18:49:36.52096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# padded_token_sequences, unique_token_count = tokenisation(x_train)\n# padded_token_sequences_test, unique_token_count_test = tokenisation(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:46:07.470824Z","iopub.execute_input":"2022-02-01T18:46:07.471583Z","iopub.status.idle":"2022-02-01T18:49:36.496595Z","shell.execute_reply.started":"2022-02-01T18:46:07.471543Z","shell.execute_reply":"2022-02-01T18:49:36.49574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = tf.keras.models.Sequential()\n# model.add(tf.keras.layers.Input(shape=(180,)))\n# model.add(tf.keras.layers.Embedding(max(unique_token_count,unique_token_count_test), 16))\n\n# model.add(tf.keras.layers.Flatten())\n# model.add(tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid))\n\n# model.compile(loss=tf.keras.losses.binary_crossentropy, metrics=[tf.keras.metrics.binary_accuracy])\n# model.fit(padded_token_sequences, y_train, validation_data=(padded_token_sequences_test,y_test), \n#           callbacks=[keras.callbacks.TensorBoard(\"logs\"),\n#                     keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=20)], epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:51:37.405858Z","iopub.execute_input":"2022-02-01T18:51:37.406712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = tf.keras.models.load_model(\"../input/linear-16-neurons/linear_16_neurons_sigmoid_bs_1024_model_seed_42_2022-02-02_14_58_07.429031.keras\")\n# model = tf.keras.models.load_model(\"../input/linear-20-neurons-input-200-bs-1024-lr-0-1-m-0-9/0.574.keras\")\n# model = tf.keras.models.load_model(\"../input/linear-20-neurons-input-200-bs-1024-lr-0-1/model_seed_42_2022-02-03_14_52_43.069535.keras\")\n# model = tf.keras.models.load_model(\"../input/linear1/model_seed_51_2022-02-03_18_55_31.531602.keras\")\n# model = tf.keras.models.load_model(\"../input/linear2/model_seed_12_2022-02-02_20_46_40.543932.keras\")\n# model = tf.keras.models.load_model(\"../input/cnn-32-32-64-128/model_seed_420_2022-02-05_21_49_27.549577.keras\")\n# model = tf.keras.models.load_model(\"../input/mlp-3-hidden-layer-64-neurons-lr-0-1/model_seed_12_2022-02-06_22_21_41.711378.keras\")\n# model = tf.keras.models.load_model(\"../input/lstm-cnn-3-hidden-layers-64-neurons-lr0-1/model_seed_51_2022-02-06_23_28_14.678118.keras\")\n\n# model = tf.keras.models.load_model(\"../input/cnn-resnet-5-hidden-layers-32neurons-dropout-lr0-1/model_seed_13_2022-02-06_18_32_02.345551.keras\")\nmodel = tf.keras.models.load_model(\"../input/lstm-cnn-3hidden-layers-64-96-128-neurons-lr0-1/model_seed_13_2022-02-07_11_07_55.717032.keras\")\n\nwith open('../input/tokenizeer/tokenizer.json') as f:\n        data = json.load(f)\n        tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)\n\nsub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nnew_text = tokenizer.texts_to_sequences(sub.text)\nnew_text = tf.keras.preprocessing.sequence.pad_sequences(new_text, 300)\nsub['score'] = model.predict(new_text) * 1000\nsub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n\nval = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\nless_toxic = tokenizer.texts_to_sequences(val.less_toxic)\nmore_toxic = tokenizer.texts_to_sequences(val.more_toxic)\nless_toxic = tf.keras.preprocessing.sequence.pad_sequences(less_toxic, 300)\nmore_toxic = tf.keras.preprocessing.sequence.pad_sequences(more_toxic, 300)\np1 = model.predict(less_toxic) * 1000\np2 = model.predict(more_toxic) * 1000\nprint((p1 < p2).mean())","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:09:50.848716Z","iopub.execute_input":"2022-02-07T13:09:50.848985Z","iopub.status.idle":"2022-02-07T13:11:02.372675Z","shell.execute_reply.started":"2022-02-07T13:09:50.848957Z","shell.execute_reply":"2022-02-07T13:11:02.371679Z"},"trusted":true},"execution_count":null,"outputs":[]}]}