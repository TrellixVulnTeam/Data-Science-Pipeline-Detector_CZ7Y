{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor \nimport optuna\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport sys\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import PreTrainedTokenizerFast\nfrom tokenizers import (\n    models,\n    normalizers,\n    pre_tokenizers,\n    trainers,\n    Tokenizer,\n)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 41\nCLASSIFY_DATA = \"/kaggle/input/comment-classify/train.csv\"\nRUDDIT_DATA = \"/kaggle/input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\"\n\nn_trials = 20\nDATA = 'ruddit'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data extraction from file ","metadata":{}},{"cell_type":"code","source":"def get_ruddit_data():\n    df_ruddit = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n    df_ruddit = df_ruddit[['txt', 'offensiveness_score']].rename(columns = {'txt': 'text', 'offensiveness_score': 'y'})\n    df_ruddit['y'] = (df_ruddit['y'] - df_ruddit.y.min()) / (df_ruddit.y.max() - df_ruddit.y.min())\n    df_ruddit = df_ruddit[df_ruddit['text']!='[deleted]'] \n    df_ruddit = df_ruddit.drop_duplicates()\n    df_ruddit = df_ruddit.dropna()    \n\n    raw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n    raw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n    raw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\n    special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n    trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\n\n    dataset = Dataset.from_pandas(df_ruddit[['text']])\n\n    def get_training_corpus():\n        for i in range(0, len(dataset), 1000):\n            yield dataset[i : i + 1000][\"text\"]\n\n    raw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n\n    tokenizer = PreTrainedTokenizerFast(\n        tokenizer_object=raw_tokenizer,\n        unk_token=\"[UNK]\",\n        pad_token=\"[PAD]\",\n        cls_token=\"[CLS]\",\n        sep_token=\"[SEP]\",\n        mask_token=\"[MASK]\",\n    )\n\n    labels = df_ruddit['y']\n    comments = df_ruddit['text']\n\n    return comments, labels, tokenizer\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_data_classify():\n    df_train = pd.read_csv(TRAIN_DATA_PATH)\n    cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n                'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n    for category in cat_mtpl:\n        df_train[category] = df_train[category] * cat_mtpl[category]\n    df_train['score'] = df_train.loc[:, 'toxic':'identity_hate'].mean(axis=1)\n    df_train['y'] = df_train['score']\n    min_len = (df_train['y'] > 0).sum()  # len of toxic comments\n    df_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=SEED)  # take non toxic comments\n    df_train_final = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\n    raw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n    raw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n    raw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\n    special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n    trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\n\n    dataset = Dataset.from_pandas(df_train_final[['comment_text']])\n\n    def get_training_corpus():\n        for i in range(0, len(dataset), 1000):\n            yield dataset[i : i + 1000][\"comment_text\"]\n\n    raw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n\n    tokenizer = PreTrainedTokenizerFast(\n        tokenizer_object=raw_tokenizer,\n        unk_token=\"[UNK]\",\n        pad_token=\"[PAD]\",\n        cls_token=\"[CLS]\",\n        sep_token=\"[SEP]\",\n        mask_token=\"[MASK]\",\n    )\n\n    labels = df_train_final['y']\n    comments = df_train_final['comment_text']\n\n    return comments, labels, tokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Choose which data evaluation to be done","metadata":{}},{"cell_type":"code","source":"if DATA  == 'classify':\n    comments, labels, tokenizer = get_data_classify()\n    tokenized_comments = tokenizer(comments.to_list(), padding=True)['input_ids']\nelif DATA  == 'ruddit':\n    comments, labels, tokenizer = get_ruddit_data()\n    tokenized_comments = tokenizer(comments.to_list(), padding=True)['input_ids']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef objective_xgb(trial):    \n    params = {\n            'n_estimators':trial.suggest_int(\"n_estimators\", 1000, 20000),\n            'learning_rate' : trial.suggest_uniform('learning_rate', 0.001, 1),\n            'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n            'colsample_bytree':trial.suggest_uniform('colsample_bytree', 0.1, 1),\n            'max_depth': trial.suggest_categorical('max_depth', [1,3,5,7,9,11,13,15,17,20]),\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n            'tree_method': 'gpu_hist'\n        }\n    model = XGBRegressor(**params)\n    x_train, x_valid, y_train, y_valid =  train_test_split(tokenized_comments , labels, test_size=0.1, shuffle=True, random_state=1)\n    model.fit(\n        x_train , y_train,\n        eval_set=[(x_valid, y_valid)],\n        early_stopping_rounds=100,\n        verbose=0\n    )\n    return mean_squared_error(y_valid, model.predict(x_valid))\n\ndef objective_ridge(trial):    \n    params = {\n            'max_iter':trial.suggest_int(\"max_iter\", 1000, 20000),\n            'tol': trial.suggest_loguniform('tol', 1e-4, 0.1),\n            'alpha': trial.suggest_uniform('alpha', 0.1, 1),\n            'solver': trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n        }\n\n    x_train, x_valid, y_train, y_valid =  train_test_split(tokenized_comments , labels, test_size=0.1, shuffle=True, random_state=1)\n    model = Ridge(**params)\n    model.fit(\n        x_train , y_train\n    )\n    return mean_squared_error(y_valid, model.predict(x_valid)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(\n    direction='minimize',\n    study_name='XG_boost'\n)\n\nstudy.optimize(\n    objective_xgb,\n    n_trials=n_trials\n)\n\nbest_classify_trial = study.best_trial.value\nbest_classify_params = study.best_trial.params\n\nstudy = optuna.create_study(\n    direction='minimize',\n    study_name='Ridge'\n)\n\nstudy.optimize(\n    objective_ridge,\n    n_trials=n_trials\n)\n\nprint(f\"Best Trial Ridge: {study.best_trial.value}\")\nprint(f\"Best Params Ridge: {study.best_trial.params}\")\n\nprint(f\"Best Trial XGB: {best_classify_trial}\")\nprint(f\"Best Params XGB: {best_classify_params}\")\n","metadata":{},"execution_count":null,"outputs":[]}]}