{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport time\nimport random\nimport string\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n\nfrom collections import defaultdict\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-06T13:45:55.274885Z","iopub.execute_input":"2022-02-06T13:45:55.275512Z","iopub.status.idle":"2022-02-06T13:45:55.284814Z","shell.execute_reply.started":"2022-02-06T13:45:55.275471Z","shell.execute_reply":"2022-02-06T13:45:55.284028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_CCC = pd.read_csv(\"../input/context-toxicitymaster/CCC.csv\")\ndf_gc = pd.read_csv(\"../input/context-toxicitymaster/gc.csv\")\ndf_gn = pd.read_csv(\"../input/context-toxicitymaster/gn.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:45:55.754746Z","iopub.execute_input":"2022-02-06T13:45:55.755458Z","iopub.status.idle":"2022-02-06T13:45:55.942738Z","shell.execute_reply.started":"2022-02-06T13:45:55.755414Z","shell.execute_reply":"2022-02-06T13:45:55.942022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_CCC.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:46:06.802108Z","iopub.execute_input":"2022-02-06T13:46:06.802657Z","iopub.status.idle":"2022-02-06T13:46:06.8149Z","shell.execute_reply.started":"2022-02-06T13:46:06.802614Z","shell.execute_reply":"2022-02-06T13:46:06.81404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_gc.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:46:15.495525Z","iopub.execute_input":"2022-02-06T13:46:15.495795Z","iopub.status.idle":"2022-02-06T13:46:15.510843Z","shell.execute_reply.started":"2022-02-06T13:46:15.495765Z","shell.execute_reply":"2022-02-06T13:46:15.509926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_gn.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:46:22.349326Z","iopub.execute_input":"2022-02-06T13:46:22.349858Z","iopub.status.idle":"2022-02-06T13:46:22.35989Z","shell.execute_reply.started":"2022-02-06T13:46:22.34982Z","shell.execute_reply":"2022-02-06T13:46:22.35927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_list = list(df_CCC[\"text\"].values) + list(df_gc[\"text\"].values) + list(df_gn[\"text\"].values)\nprint(len(text_list))\ntext_list = list(np.unique(text_list))\nprint(len(text_list))\ntarget_dataset = pd.DataFrame([])\ntarget_dataset[\"comment_text\"] = text_list","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:50:58.574099Z","iopub.execute_input":"2022-02-06T13:50:58.574636Z","iopub.status.idle":"2022-02-06T13:50:59.003314Z","shell.execute_reply.started":"2022-02-06T13:50:58.574597Z","shell.execute_reply":"2022-02-06T13:50:59.002554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:50:59.450162Z","iopub.execute_input":"2022-02-06T13:50:59.4506Z","iopub.status.idle":"2022-02-06T13:50:59.458696Z","shell.execute_reply.started":"2022-02-06T13:50:59.450564Z","shell.execute_reply":"2022-02-06T13:50:59.457871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CCDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['comment_text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length'\n        )\n\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }\n\n\n@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS\n\n\ndef inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    del model\n    gc.collect()\n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:51:01.947934Z","iopub.execute_input":"2022-02-06T13:51:01.948476Z","iopub.status.idle":"2022-02-06T13:51:01.961712Z","shell.execute_reply.started":"2022-02-06T13:51:01.948437Z","shell.execute_reply":"2022-02-06T13:51:01.961036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############\n# CONFIG\n###############\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/jigsaw-multilingual-toxic-xlm-roberta/model',\n    test_batch_size = 128,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\nset_seed(CONFIG['seed'])\n\n\nMAIN_PATH = '../input/jigsaw-exp019-toxic-xlm-roberta'\n\nMODEL_PATHS = [\n    f'../input/{MAIN_PATH}/Loss-Fold-0.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-1.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-2.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-3.bin',\n    f'../input/{MAIN_PATH}/Loss-Fold-4.bin',\n]\n\n\n###############\n# MODEL\n###############\n\nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"attention_probs_dropout_prob\": 0.0,\n        })\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(\n            input_ids=ids,\n            attention_mask=mask,\n        )\n        outputs = self.linear(out.last_hidden_state[:, 0, :])\n        return outputs\n\n###############\n# INFERENCE\n###############\n\nvalidation_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\nvalid_comments = pd.concat([validation_df['less_toxic'], validation_df['more_toxic']]).unique()\ncomments = target_dataset[~target_dataset['comment_text'].isin(valid_comments)].reset_index(drop=True)\ndisplay(comments)\n\ntest_dataset = CCDataset(\n    comments,\n    CONFIG['tokenizer'],\n    max_length=CONFIG['max_length']\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG['test_batch_size'],\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True\n)\n\npreds = inference(MODEL_PATHS, test_loader, CONFIG['device'])\ncomments['pseudo_label'] = preds\ncomments.to_csv('PseudoLabelDataset.csv', index=False)\n\ndel comments, test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T13:51:29.373544Z","iopub.execute_input":"2022-02-06T13:51:29.3742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}