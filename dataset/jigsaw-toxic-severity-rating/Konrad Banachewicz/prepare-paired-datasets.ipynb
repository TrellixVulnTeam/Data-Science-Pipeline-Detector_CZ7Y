{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\n\nimport pandas as pd\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import KFold\nfrom itertools import combinations\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-13T13:06:02.52402Z","iopub.execute_input":"2021-12-13T13:06:02.524642Z","iopub.status.idle":"2021-12-13T13:06:03.85707Z","shell.execute_reply.started":"2021-12-13T13:06:02.524525Z","shell.execute_reply":"2021-12-13T13:06:03.856009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    data_folder = '../input/jigsaw-toxic-severity-rating/'\n    nfolds = 10","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:06:03.858664Z","iopub.execute_input":"2021-12-13T13:06:03.858905Z","iopub.status.idle":"2021-12-13T13:06:03.864597Z","shell.execute_reply.started":"2021-12-13T13:06:03.858874Z","shell.execute_reply":"2021-12-13T13:06:03.863119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data\n\nCreate all pairs for the Ruddit dataset - we preserve the original scores, so that a difference (pointing which one is more toxic) can be adjusted at modeling time. ","metadata":{}},{"cell_type":"code","source":"# ruddit\ndf = pd.read_csv('../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv')[['comment_id', 'txt', 'offensiveness_score']]\ndf = df.loc[(df.txt != '[deleted]') & (df.txt != '[removed]')]\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:22:02.634522Z","iopub.execute_input":"2021-12-13T13:22:02.634888Z","iopub.status.idle":"2021-12-13T13:22:02.689172Z","shell.execute_reply.started":"2021-12-13T13:22:02.634847Z","shell.execute_reply":"2021-12-13T13:22:02.688178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a vector of combinations\nid1 = []\nid2 = []\n\nfor f in combinations(range(df.shape[0]),2):\n\n    id1.append(f[0])\n    id2.append(f[1])\n    \nindices_df = pd.DataFrame(id1, columns=['id1'])\nindices_df['id2'] = id2\n\n# shuffle\nindices_df = indices_df.sample(frac=1).reset_index(drop=True)\n\n# map to texts and scores\nx1 = df.iloc[indices_df.id1][['txt', 'offensiveness_score']].rename(columns={\"txt\": \"txt1\", \"offensiveness_score\": \"sc1\"}).reset_index(drop=True)\nx2 = df.iloc[indices_df.id2][['txt', 'offensiveness_score']].rename(columns={\"txt\": \"txt2\", \"offensiveness_score\": \"sc2\"}).reset_index(drop=True)\n\n# combine\nx3 = pd.concat([x1,x2], axis = 1, ignore_index = True)\nx3.columns = ['txt1', 'sc1', 'txt2', 'sc2']\n\n# dump to file\nx3.to_csv('ruddit_pairs.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:22:03.826508Z","iopub.execute_input":"2021-12-13T13:22:03.826842Z","iopub.status.idle":"2021-12-13T13:22:24.964029Z","shell.execute_reply.started":"2021-12-13T13:22:03.826806Z","shell.execute_reply":"2021-12-13T13:22:24.963082Z"},"trusted":true},"execution_count":null,"outputs":[]}]}