{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Special Thanks to Z by HP & NVIDIA for sponsoring me a Z4 Workstation with dual A6000 GPU!\n\nTraining large transformer models with 48GB VRAM is awesome!","metadata":{}},{"cell_type":"code","source":"from argparse import ArgumentParser\nfrom lightgbm import train\nimport numpy as np\nimport pandas as pd\nimport random\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\n\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig\n\nimport wandb\n\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\nfrom pytorch_lightning import LightningDataModule, LightningModule\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\nfrom argparse import Namespace\nfrom scipy.stats import rankdata\n\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T14:17:43.41453Z","iopub.execute_input":"2022-02-03T14:17:43.415166Z","iopub.status.idle":"2022-02-03T14:17:54.680162Z","shell.execute_reply.started":"2022-02-03T14:17:43.415064Z","shell.execute_reply":"2022-02-03T14:17:54.679383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_pickle('../input/jigsaw-data/valid_text.pkl')\ntest_mapping = pd.read_csv('../input/jigsaw-data/valid_set.csv')\npairs = pd.read_pickle('../input/jigsaw-data/pairs_v2_v4.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:54.682237Z","iopub.execute_input":"2022-02-03T14:17:54.682505Z","iopub.status.idle":"2022-02-03T14:17:57.296423Z","shell.execute_reply.started":"2022-02-03T14:17:54.682469Z","shell.execute_reply":"2022-02-03T14:17:57.295567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.297659Z","iopub.execute_input":"2022-02-03T14:17:57.297933Z","iopub.status.idle":"2022-02-03T14:17:57.323116Z","shell.execute_reply.started":"2022-02-03T14:17:57.297896Z","shell.execute_reply":"2022-02-03T14:17:57.322294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(1991)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.324451Z","iopub.execute_input":"2022-02-03T14:17:57.324775Z","iopub.status.idle":"2022-02-03T14:17:57.335076Z","shell.execute_reply.started":"2022-02-03T14:17:57.324736Z","shell.execute_reply":"2022-02-03T14:17:57.334416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_anchor(anchor_per_group=50, fold=0):\n    anchors, score_weights = [], []\n    for group in pairs['group'].unique():\n        temp = pairs[pairs['group']==group]\n        divider = int(len(temp)/anchor_per_group)\n        a_text = temp[temp['uni_rank']%divider==fold]['text'].tolist()\n        anchors.extend(a_text)\n        score_divider = int(len(temp)/10)\n        a_weight = (temp[temp['uni_rank']%divider==fold]['uni_rank']//score_divider+1).tolist()\n        score_weights.extend(a_weight)\n    return anchors, score_weights","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.337317Z","iopub.execute_input":"2022-02-03T14:17:57.337576Z","iopub.status.idle":"2022-02-03T14:17:57.344429Z","shell.execute_reply.started":"2022-02-03T14:17:57.337541Z","shell.execute_reply":"2022-02-03T14:17:57.343564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawPairValidDataset(Dataset):\n    def __init__(self, df):\n        self._X = df[\"text\"].values\n        self._id = df.index.tolist()\n        self._y = None\n        if \"toxic\" in df.keys():\n            self._y = df[\"toxic\"].values\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        text = self._X[idx]\n        \n        return text, torch.FloatTensor([idx])\n    \nclass ValidCollator:\n\n    def __init__(self, config, anchors):\n        super().__init__()        \n        self.max_length = config.max_length\n        self.tokenizer = AutoTokenizer.from_pretrained(config.backbone_name)\n        self.token_pad_value = self.tokenizer.pad_token_id\n        self.type_pad_value = self.tokenizer.pad_token_type_id\n        self.anchors = anchors\n        self.n_anchors = len(anchors)\n        \n    def __call__(self, batch):\n        text, label = zip(*batch)\n\n        features_a = self.tokenizer.batch_encode_plus(list(text), \n                                                    return_tensors='pt',\n                                                    padding='max_length',\n                                                    max_length=self.max_length, truncation=True)\n        features_b = self.tokenizer.batch_encode_plus(list(self.anchors), \n                                                    return_tensors='pt',\n                                                    padding='max_length',\n                                                    max_length=self.max_length, truncation=True)\n        label = torch.stack(label)\n        return features_a, features_b, label","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.346299Z","iopub.execute_input":"2022-02-03T14:17:57.346824Z","iopub.status.idle":"2022-02-03T14:17:57.358734Z","shell.execute_reply.started":"2022-02-03T14:17:57.346785Z","shell.execute_reply":"2022-02-03T14:17:57.35796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawPairModel(pl.LightningModule):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        if config.predict:\n            bert_config = AutoConfig.from_pretrained(config.backbone_name)\n            self.bert = AutoModel.from_config(bert_config)\n        else:\n            self.bert = AutoModel.from_pretrained(config.backbone_name)\n        \n        self.head = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(self.bert.config.hidden_size*3, 1)\n        )\n\n        self.save_hyperparameters(config)\n        self.anchor_outputs = None\n\n    def masked_mean_pooling(self, emb, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(emb.size()).float()\n        sum_embeddings = torch.sum(emb * input_mask_expanded, 1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n        out = sum_embeddings / sum_mask\n        return out\n    \n    def inference(self, seq1, seq2, mask1=None, mask2=None):\n        # seq1: B*l1*D\n        # seq2: B*l2*D\n        # mask1: B*l1\n        # mask2: B*l2\n        score = torch.bmm(seq1, seq2.permute(0, 2, 1))\n        new_seq1 = torch.bmm(torch.softmax(score, dim=-1), seq2*mask2.unsqueeze(-1)) #\n        new_seq1 = torch.sum(new_seq1*mask1.unsqueeze(-1),dim=1)/torch.sum(mask1, dim=1).unsqueeze(-1)\n        # del score1\n\n        new_seq2 = torch.bmm(torch.softmax(score, dim=1).permute(0, 2, 1), seq1*mask1.unsqueeze(-1)) #\n        new_seq2 = torch.sum(new_seq2*mask2.unsqueeze(-1), dim=1)/torch.sum(mask2, dim=1).unsqueeze(-1)\n        return new_seq1, new_seq2\n    \n    def forward(self, x, anchors, score_weights):\n        out1 = self.bert(**x)\n        if self.anchor_outputs is None:\n            self.anchor_outputs = self.bert(**anchors)\n            if not hasattr(self.anchor_outputs, 'pooler_output'):\n                self.anchor_outputs.pooler_output = self.masked_mean_pooling(self.anchor_outputs.last_hidden_state, anchors['attention_mask'])\n            \n        if not hasattr(out1, 'pooler_output'):\n            out1.pooler_output = self.masked_mean_pooling(out1.last_hidden_state, x['attention_mask'])\n              \n        scores = []\n        for i in range(len(out1.pooler_output)):\n            sample_out = out1.pooler_output[i,:] \n            if self.config.inference:\n                sample_hidden_out = out1.last_hidden_state[i,:,:].unsqueeze(0).expand_as(self.anchor_outputs.last_hidden_state)\n\n                new_anchor_emb, new_sample_emb = self.inference(self.anchor_outputs.last_hidden_state, sample_hidden_out, \n                                                anchors['attention_mask'], x['attention_mask'][i].unsqueeze(0))\n                pred = torch.sigmoid(self.head(torch.cat([\n                                            new_sample_emb,\n                                            new_anchor_emb,\n                                            self.anchor_outputs.pooler_output-sample_out], axis=1))).flatten().cpu().numpy()\n            else:\n                pred = torch.sigmoid(self.head(torch.cat([\n                                            self.anchor_outputs.pooler_output,\n                                            sample_out.expand_as(self.anchor_outputs.pooler_output),\n                                            self.anchor_outputs.pooler_output-sample_out], axis=1))).flatten().cpu().numpy()\n            score = np.dot(pred, score_weights)\n            scores.append(score)\n        return np.array(scores)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.360203Z","iopub.execute_input":"2022-02-03T14:17:57.360823Z","iopub.status.idle":"2022-02-03T14:17:57.384128Z","shell.execute_reply.started":"2022-02-03T14:17:57.360784Z","shell.execute_reply":"2022-02-03T14:17:57.383016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(all_pred):\n    test_mapping['score1'] = test_mapping['text1'].apply(lambda x: all_pred[x])\n    test_mapping['score2'] = test_mapping['text2'].apply(lambda x: all_pred[x])\n    \n    match, real_match = 0, 0\n    for idx1, idx2, real_label in zip(test_mapping['text1'].tolist(), test_mapping['text2'].tolist(), test_mapping['real_label'].tolist()):\n        if idx1>=len(all_pred) or idx2>=len(all_pred):\n            continue\n        if all_pred[idx1]<all_pred[idx2]:\n            match+=1\n        if int(all_pred[idx1]<all_pred[idx2])==real_label:\n            real_match +=1\n    print(f'score: {match/len(test_mapping)}, real score: {real_match/len(test_mapping)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.385851Z","iopub.execute_input":"2022-02-03T14:17:57.386975Z","iopub.status.idle":"2022-02-03T14:17:57.397324Z","shell.execute_reply.started":"2022-02-03T14:17:57.386929Z","shell.execute_reply":"2022-02-03T14:17:57.396347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(config, to_pred):\n    anchors, score_weights = make_anchor(fold=config.fold)\n    \n    dataset = JigsawPairValidDataset(to_pred)\n    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=False, \n            num_workers=2,\n            collate_fn=ValidCollator(config, anchors))\n    model = JigsawPairModel.load_from_checkpoint(config.path, config=config, strict=False)\n    model.eval()\n    model.cuda()\n    \n    preds = []\n    with torch.no_grad():\n        for x, a, _ in tqdm(dataloader):\n            pred = model(x.to('cuda'), a.to('cuda'), score_weights)\n            preds.append(pred)\n    preds = np.concatenate(preds)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.398972Z","iopub.execute_input":"2022-02-03T14:17:57.399197Z","iopub.status.idle":"2022-02-03T14:17:57.410059Z","shell.execute_reply.started":"2022-02-03T14:17:57.399171Z","shell.execute_reply":"2022-02-03T14:17:57.409358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rbase_config = Namespace(\n    backbone_name='../input/rbase-inf/',\n    max_length=128,\n    batch_size=128,\n    predict=True,\n    focal=False,\n    inference=True,\n    fold=0,\n    path='../input/rbase-inf/roberta-base_0-v1.ckpt'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.411545Z","iopub.execute_input":"2022-02-03T14:17:57.411928Z","iopub.status.idle":"2022-02-03T14:17:57.417523Z","shell.execute_reply.started":"2022-02-03T14:17:57.411827Z","shell.execute_reply":"2022-02-03T14:17:57.416681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbase_config = Namespace(\n    backbone_name='../input/dbase-late/',\n    max_length=128,\n    batch_size=128,\n    predict=True,\n    focal=False,\n    inference=True,\n    fold=1,\n    path='../input/dbase-late/deberta-v3_0.ckpt'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.418658Z","iopub.execute_input":"2022-02-03T14:17:57.419398Z","iopub.status.idle":"2022-02-03T14:17:57.425164Z","shell.execute_reply.started":"2022-02-03T14:17:57.419197Z","shell.execute_reply":"2022-02-03T14:17:57.424223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ebase_config = Namespace(\n    backbone_name='../input/ebase-inf/',\n    max_length=128,\n    batch_size=128,\n    predict=True,\n    focal=False,\n    inference=True,\n    fold=2,\n    path='../input/ebase-inf/electra-base_0.ckpt'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.426902Z","iopub.execute_input":"2022-02-03T14:17:57.427401Z","iopub.status.idle":"2022-02-03T14:17:57.433413Z","shell.execute_reply.started":"2022-02-03T14:17:57.427364Z","shell.execute_reply":"2022-02-03T14:17:57.432618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finter_config = Namespace(\n    backbone_name='../input/finter-inf/',\n    max_length=128,\n    batch_size=128,\n    predict=True,\n    focal=False,\n    inference=True,\n    fold=3,\n    path='../input/finter-inf/funnel-intermediate_0.ckpt'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.434997Z","iopub.execute_input":"2022-02-03T14:17:57.435326Z","iopub.status.idle":"2022-02-03T14:17:57.442716Z","shell.execute_reply.started":"2022-02-03T14:17:57.435293Z","shell.execute_reply":"2022-02-03T14:17:57.441958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xbase_config = Namespace(\n    backbone_name='../input/xbase-inf/',\n    max_length=128,\n    batch_size=128,\n    predict=True,\n    focal=False,\n    inference=True,\n    fold=4,\n    path='../input/xbase-inf/xlnet-base_0.ckpt'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.446591Z","iopub.execute_input":"2022-02-03T14:17:57.446886Z","iopub.status.idle":"2022-02-03T14:17:57.451653Z","shell.execute_reply.started":"2022-02-03T14:17:57.446858Z","shell.execute_reply":"2022-02-03T14:17:57.450929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## validation","metadata":{}},{"cell_type":"code","source":"# finter_config = predict(finter_config, test_df)\n# ebase_score = predict(ebase_config, test_df)\n# dbase_score = predict(dbase_config, test_df)\n# rbase_score = predict(rbase_config, test_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.453166Z","iopub.execute_input":"2022-02-03T14:17:57.453669Z","iopub.status.idle":"2022-02-03T14:17:57.459395Z","shell.execute_reply.started":"2022-02-03T14:17:57.453576Z","shell.execute_reply":"2022-02-03T14:17:57.458634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.corrcoef([finter_config,ebase_score,dbase_score,rbase_score])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.460559Z","iopub.execute_input":"2022-02-03T14:17:57.461237Z","iopub.status.idle":"2022-02-03T14:17:57.466689Z","shell.execute_reply.started":"2022-02-03T14:17:57.461196Z","shell.execute_reply":"2022-02-03T14:17:57.465471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_score(np.mean([finter_config,ebase_score,dbase_score,rbase_score], axis=0))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.468511Z","iopub.execute_input":"2022-02-03T14:17:57.468736Z","iopub.status.idle":"2022-02-03T14:17:57.473383Z","shell.execute_reply.started":"2022-02-03T14:17:57.468712Z","shell.execute_reply":"2022-02-03T14:17:57.472531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_score(rbase_score)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.474932Z","iopub.execute_input":"2022-02-03T14:17:57.475398Z","iopub.status.idle":"2022-02-03T14:17:57.480923Z","shell.execute_reply.started":"2022-02-03T14:17:57.475361Z","shell.execute_reply":"2022-02-03T14:17:57.480073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## test","metadata":{}},{"cell_type":"code","source":"comment_to_score = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.482542Z","iopub.execute_input":"2022-02-03T14:17:57.483008Z","iopub.status.idle":"2022-02-03T14:17:57.563975Z","shell.execute_reply.started":"2022-02-03T14:17:57.482972Z","shell.execute_reply":"2022-02-03T14:17:57.563231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_to_score.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:17:57.565399Z","iopub.execute_input":"2022-02-03T14:17:57.565657Z","iopub.status.idle":"2022-02-03T14:17:57.574302Z","shell.execute_reply.started":"2022-02-03T14:17:57.565623Z","shell.execute_reply":"2022-02-03T14:17:57.573603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finter_score = predict(finter_config, comment_to_score)\n# ebase_score = predict(ebase_config, comment_to_score)\ndbase_score = predict(dbase_config, comment_to_score)\n# rbase_score = predict(rbase_config, comment_to_score)\n# xbase_score = predict(xbase_config, comment_to_score)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:18:43.477733Z","iopub.execute_input":"2022-02-03T14:18:43.477982Z","iopub.status.idle":"2022-02-03T14:26:57.896286Z","shell.execute_reply.started":"2022-02-03T14:18:43.477954Z","shell.execute_reply":"2022-02-03T14:26:57.895447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rank = np.mean([\n#     rankdata(rbase_score), rankdata(dbase_score), rankdata(ebase_score),\n#     rankdata(xbase_score), rankdata(xbase_score),rankdata(xbase_score),\n#     rankdata(finter_score),rankdata(finter_score)], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:29:46.613383Z","iopub.execute_input":"2022-02-03T14:29:46.613643Z","iopub.status.idle":"2022-02-03T14:29:46.62669Z","shell.execute_reply.started":"2022-02-03T14:29:46.613613Z","shell.execute_reply":"2022-02-03T14:29:46.626015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.corrcoef([rbase_score, dbase_score, ebase_score, xbase_score, finter_score])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:30:16.887544Z","iopub.execute_input":"2022-02-03T14:30:16.887805Z","iopub.status.idle":"2022-02-03T14:30:16.899918Z","shell.execute_reply.started":"2022-02-03T14:30:16.887776Z","shell.execute_reply":"2022-02-03T14:30:16.899067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_to_score['score'] = rankdata(dbase_score)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:30:31.202558Z","iopub.execute_input":"2022-02-03T14:30:31.202914Z","iopub.status.idle":"2022-02-03T14:30:31.209299Z","shell.execute_reply.started":"2022-02-03T14:30:31.202874Z","shell.execute_reply":"2022-02-03T14:30:31.208374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_to_score.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:30:36.127952Z","iopub.execute_input":"2022-02-03T14:30:36.128655Z","iopub.status.idle":"2022-02-03T14:30:36.138355Z","shell.execute_reply.started":"2022-02-03T14:30:36.128617Z","shell.execute_reply":"2022-02-03T14:30:36.137665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_to_score[['comment_id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T14:31:34.046662Z","iopub.execute_input":"2022-02-03T14:31:34.046917Z","iopub.status.idle":"2022-02-03T14:31:34.073499Z","shell.execute_reply.started":"2022-02-03T14:31:34.04689Z","shell.execute_reply":"2022-02-03T14:31:34.072881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}