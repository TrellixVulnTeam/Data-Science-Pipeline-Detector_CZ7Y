{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport sys\nimport numpy as np\nimport pandas as pd\nimport pickle\n\n!cp -r ../input/detoxify-master detoxify\n!pip install -q ./detoxify\n!rm -rf ./detoxify\nfrom detoxify import Detoxify\n\nimport datasets\nimport pytorch_lightning as pl\nimport torch\nimport transformers\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Dataset\n\nNUM_WORKERS = 2\nGPUS = 1\nBATCH_SIZE = 4\n\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\nclass JigsawDataOriginal(Dataset):\n    def __init__(self, df, train=True):\n        self.data = datasets.Dataset.from_pandas(df)\n        self.train = train\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        meta = {}\n        entry = self.data[index]\n        text = entry[\"comment_text\"]\n        if 'score' in entry:\n            meta[\"target\"] = torch.tensor([entry[\"score\"]], dtype=torch.float)\n        return text, meta\n\nclass ToxicClassifier(pl.LightningModule):\n    def __init__(self, model_type):\n        super().__init__()\n        if model_type == 'bert-base-uncased':\n            self.model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\", num_labels=1)\n            self.tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n        elif model_type == 'roberta-base':\n            self.model = transformers.RobertaForSequenceClassification.from_pretrained(\"../input/roberta-base\", num_labels=1)\n            self.tokenizer = transformers.RobertaTokenizer.from_pretrained(\"../input/roberta-base\")\n        elif model_type == 'xlnet-base-cased':\n            self.model = transformers.XLNetForSequenceClassification.from_pretrained(\"../input/xlnet-base-cased\", num_labels=1)\n            self.tokenizer = transformers.XLNetTokenizer.from_pretrained(\"../input/xlnet-base-cased\", model_max_length=512)\n        else:\n            print('Unsupported model requested')\n            sys.exit(1)\n        self.preds = []\n\n    def forward(self, x):\n        inputs = self.tokenizer(x, return_tensors=\"pt\", truncation=True, padding=True).to(self.model.device)\n        outputs = self.model(**inputs)[0]\n        return outputs\n\n    def training_step(self, batch, batch_idx):\n        x, meta = batch\n        output = self.forward(x)\n        loss = F.binary_cross_entropy_with_logits(output, meta[\"target\"].to(output.device).float())\n        self.log(\"train_loss\", loss)\n        return {\"loss\": loss}\n\n    def validation_step(self, batch, batch_idx):\n        x, meta = batch\n        output = self.forward(x)\n        loss = F.binary_cross_entropy_with_logits(output, meta[\"target\"].to(output.device).float())\n        self.log(\"val_loss\", loss)\n        return {\"loss\": loss}\n\n    def test_step(self, batch, batch_idx):\n        x, meta = batch\n        output = self.forward(x)\n        preds = torch.sigmoid(output).cpu().detach().numpy().reshape(-1)\n        self.preds += preds.tolist()\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=3e-5, weight_decay=3e-6, amsgrad=True)\n\ndef load_and_predict(path, texts):\n    if 'linear' in path:\n        pipeline = pickle.load(open(path, 'rb'))\n        return pipeline.predict(texts)\n    elif 'detoxify-models' in path:\n        if path == '../input/detoxify-models/toxic_original-c1212f89.ckpt':\n            model_type = 'original'\n            model = Detoxify(model_type, checkpoint=path, device='cuda',\n                huggingface_config_path='../input/bert-base-uncased')\n            model.tokenizer = transformers.AutoTokenizer.from_pretrained('../input/bert-base-uncased',\n                local_files_only=True, use_fast=False)\n        elif path == '../input/detoxify-models/toxic_debiased-c7548aa0.ckpt':\n            model_type = 'unbiased'\n            model = Detoxify(model_type, checkpoint=path, device='cuda',\n                huggingface_config_path='../input/roberta-base')\n            model.tokenizer = transformers.AutoTokenizer.from_pretrained('../input/roberta-base',\n                local_files_only=True, use_fast=False)\n        elif path == '../input/detoxify-models/multilingual_debiased-0b549669.ckpt':\n            model_type = 'multilingual'\n            model = Detoxify(model_type, checkpoint=path, device='cuda',\n                huggingface_config_path='../input/xlm-roberta-base')\n            model.tokenizer = transformers.AutoTokenizer.from_pretrained('../input/xlm-roberta-base',\n                local_files_only=True)\n        else:\n            print('Invalid detoxify model type requested')\n            sys.exit(1)\n        preds = []\n        for text in texts:\n            res = model.predict(text)\n            if model_type == 'original' or model_type == 'multilingual':\n                score = res['toxicity'] + res['severe_toxicity']\n                preds.append(score)\n            else:\n                score = res['severe_toxicity'] + res['obscene'] + res['identity_attack'] + res['insult'] + res['threat'] + res['sexual_explicit']\n                preds.append(score)\n        return np.array(preds)\n    elif 'torch' in path:\n        df = pd.DataFrame({'comment_text': texts})\n        dataset = JigsawDataOriginal(df, train=False)\n        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n\n        if 'bert-base-uncased' in path:\n            model = ToxicClassifier('bert-base-uncased')\n        elif 'roberta-base' in path:\n            model = ToxicClassifier('roberta-base')\n        elif 'xlnet-base-cased' in path:\n            model = ToxicClassifier('xlnet-base-cased')\n        else:\n            print('Unsupported torch model requested')\n            sys.exit(1)\n\n        model.load_state_dict(torch.load(path))\n        trainer = pl.Trainer(gpus=GPUS)\n\n        trainer.test(model, dataloaders=dataloader)\n        return np.array(model.preds)\n    else:\n        print(\"invalid model format in arguments\")\n        sys.exit(1)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:41:52.362985Z","iopub.execute_input":"2022-02-09T04:41:52.363389Z","iopub.status.idle":"2022-02-09T04:42:33.845342Z","shell.execute_reply.started":"2022-02-09T04:41:52.363306Z","shell.execute_reply":"2022-02-09T04:42:33.844456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0.7117709578849475 = (1) [0.24 0.27 0.15 0.26 0.08] model_linear_ruddit.csv model_linear_unintended.csv\n# model_detoxify_unbiased.csv model_detoxify_multilingual.csv model_torch_xlnet_unbiased.csv\n\ndef get_all(path, check_val):\n    print(f'getting predictions from {path}')\n    val_lt = load_and_predict(path, df_val['less_toxic']) if check_val else None\n    val_mt = load_and_predict(path, df_val['more_toxic']) if check_val else None\n    sub = load_and_predict(path, df_sub['text'])\n    return val_lt, val_mt, sub\n\nweights = np.array([0.24, 0.27, 0.15, 0.26, 0.08])\n\ncheck_val = False\n\np1_lt, p1_mt, p1_sub = get_all('../input/jigsaw-models-20220202/model_linear_ruddit.pkl', check_val)\nprint(p1_lt)\nprint(p1_mt)\nprint(p1_sub)\np2_lt, p2_mt, p2_sub = get_all('../input/jigsaw-models-20220202/model_linear_unintended.pkl', check_val)\nprint(p2_lt)\nprint(p2_mt)\nprint(p2_sub)\np3_lt, p3_mt, p3_sub = get_all('../input/detoxify-models/toxic_debiased-c7548aa0.ckpt', check_val)\nprint(p3_lt)\nprint(p3_mt)\nprint(p3_sub)\np4_lt, p4_mt, p4_sub = get_all('../input/detoxify-models/multilingual_debiased-0b549669.ckpt', check_val)\nprint(p4_lt)\nprint(p4_mt)\nprint(p4_sub)\np5_lt, p5_mt, p5_sub = get_all('../input/jigsaw-models-20220202/xlnet-base-cased/model_torch_xlnet_unbiased.ckpt', check_val)\nprint(p5_lt)\nprint(p5_mt)\nprint(p5_sub)\n\nif check_val:\n    lt = np.dot(weights, np.stack([p1_lt, p2_lt, p3_lt, p4_lt, p5_lt]))\n    mt = np.dot(weights, np.stack([p1_mt, p2_mt, p3_mt, p4_mt, p5_mt]))\n    print(f'Validation Accuracy is {(lt < mt).mean()}')\n\ndf_sub['score'] = np.dot(weights, np.stack([p1_sub, p2_sub, p3_sub, p4_sub, p5_sub]))\nprint(df_sub['score'])\ndf_sub['score'] = df_sub['score'].rank(method='first')\ndf_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\nprint(df_sub)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:33.847611Z","iopub.execute_input":"2022-02-09T04:42:33.848055Z","iopub.status.idle":"2022-02-09T04:48:20.660899Z","shell.execute_reply.started":"2022-02-09T04:42:33.848013Z","shell.execute_reply":"2022-02-09T04:48:20.658437Z"},"trusted":true},"execution_count":null,"outputs":[]}]}