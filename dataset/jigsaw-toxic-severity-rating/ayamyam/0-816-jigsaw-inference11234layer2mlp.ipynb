{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">üéØ Training Kernel: <strong><a href=\"https://www.kaggle.com/debarshichanda/pytorch-w-b-jigsaw-starter\">[Pytorch + W&B] Jigsaw Starter</a></strong>.</span>","metadata":{}},{"cell_type":"markdown","source":"# ver45\ndistilroberta\n\n# ver44\nver36facebook/bart-base\n\n# ver43\nver38pseudopair0508\n\n# ver41\nweight initialization\nrobert-base\n\n# ver40\nmargin0.4\n\n# ver39\nruddit\nver31_pretrain2\n\n# ver38\nver26\nMLM ver2\n\n# ver37\ninner merge√ó2\nver30\n\n# ver36\nroberta-base\nmlm TCC„Ç≥„É≥„Éö„ÅÆ„Éá„Éº„Çø„Çí‰ΩøÁî® ver24\n5model\n\n# ver35\nroberta-base\nmlm\n5model\n\n# ver34\nroberta-large\ninner merge 1Âõû\n5fold\n\n# ver28-32\nroberta-large\ninner merge 1Âõû\n1fold„Å†„Åë\n\n# ver27\nroberta-large‰ªÆ\ninner merge1Âõû\n\nto do \nÂ≠¶ÁøíÊ∏à„Åø„ÅÆ„É¢„Éá„É´„Åå„Åß„Åç„Åü„ÇâÁßªÊ§ç„Åô„Çã\n\n# ver15\nABC„ÅÆÈñ¢‰øÇ„Çí‰Ωø„Å£„Å¶„Éá„Éº„ÇøÊ∞¥Â¢ó„Åó\n\n# ver14\nË©ï‰æ°„ÅåÂàÜ„Åã„Çå„Çã„ÇÇ„ÅÆ„ÅØmajority„ÇíÊé°Áî®\n\n# ver13\n6‰ª•‰∏ä\nÈÅéÂéª„ÅÆ„Ç≥„É≥„Éö„ÅÆ„Éá„Éº„Çø„Çí„Å§„Åã„Å£„Å¶„Çà„ÇäÁµû„Å£„ÅüÂΩ¢„Åß„Éá„Éº„Çø„Çí„Åµ„ÇÑ„Åó„Åü\n\n# ver12\nÈÅéÂéª„ÅÆ„Ç≥„É≥„Éö„ÅÆ„Éá„Éº„Çø„Çí„Å§„Åã„Å£„Å¶„Çà„ÇäÁµû„Å£„ÅüÂΩ¢„Åß„Éá„Éº„Çø„Çí„Åµ„ÇÑ„Åó„Åü\n4‰ª•‰∏ä\n\n\n# ver11\nÈÅéÂéª„ÅÆ„Ç≥„É≥„Éö„ÅÆ„Éá„Éº„Çø„Çí„Å§„Åã„Å£„Å¶„Éá„Éº„Çø„Çí„Åµ„ÇÑ„Åó„Åü\n\n# ver3\n4layer„ÅÆmaxmeax","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig,AdamW,AutoModelForMaskedLM,get_linear_schedule_with_warmup\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:17:55.129201Z","iopub.execute_input":"2022-01-04T07:17:55.129798Z","iopub.status.idle":"2022-01-04T07:18:03.226461Z","shell.execute_reply.started":"2022-01-04T07:17:55.129662Z","shell.execute_reply":"2022-01-04T07:18:03.22541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42,\n    model_name = '../input/distilroberta-base',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.229154Z","iopub.execute_input":"2022-01-04T07:18:03.229718Z","iopub.status.idle":"2022-01-04T07:18:03.463885Z","shell.execute_reply.started":"2022-01-04T07:18:03.229674Z","shell.execute_reply":"2022-01-04T07:18:03.462868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATHS = [\n    '../input/ver40distil/version40_Loss-Fold-0.bin',\n    '../input/ver40distil/version40_Loss-Fold-1.bin',\n    '../input/ver40distil/version40_Loss-Fold-2.bin',\n    '../input/ver40distil/version40_Loss-Fold-3.bin',\n    '../input/ver40distil/version40_Loss-Fold-4.bin',\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.465693Z","iopub.execute_input":"2022-01-04T07:18:03.466023Z","iopub.status.idle":"2022-01-04T07:18:03.471583Z","shell.execute_reply.started":"2022-01-04T07:18:03.465979Z","shell.execute_reply":"2022-01-04T07:18:03.470536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.474539Z","iopub.execute_input":"2022-01-04T07:18:03.475286Z","iopub.status.idle":"2022-01-04T07:18:03.486847Z","shell.execute_reply.started":"2022-01-04T07:18:03.47519Z","shell.execute_reply":"2022-01-04T07:18:03.485836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.488638Z","iopub.execute_input":"2022-01-04T07:18:03.489293Z","iopub.status.idle":"2022-01-04T07:18:03.61731Z","shell.execute_reply.started":"2022-01-04T07:18:03.489245Z","shell.execute_reply":"2022-01-04T07:18:03.616254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.619244Z","iopub.execute_input":"2022-01-04T07:18:03.619627Z","iopub.status.idle":"2022-01-04T07:18:03.630383Z","shell.execute_reply.started":"2022-01-04T07:18:03.619583Z","shell.execute_reply":"2022-01-04T07:18:03.629091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.632557Z","iopub.execute_input":"2022-01-04T07:18:03.632955Z","iopub.status.idle":"2022-01-04T07:18:03.647635Z","shell.execute_reply.started":"2022-01-04T07:18:03.632887Z","shell.execute_reply":"2022-01-04T07:18:03.646553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.n_use_layer = 4\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.5)\n        self.fc = nn.Linear(768*2, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=True)\n#         out = self.drop(out[1])\n#         outputs = self.fc(out)\n\n        #ÊúÄÂæå„ÅÆ4Â±§„ÅÆÊΩúÂú®Áä∂ÊÖã„Çí‰Ωø„ÅÜ\n#         out = torch.cat([out[2][-1*i][:,0] for i in range(self.n_use_layer)],dim=1)        \n        out = torch.stack(tuple(out[2][-1*i][:,0] for i in range(self.n_use_layer)), dim=0)\n\n        #4Â±§„ÅÆÊΩúÂú®Áä∂ÊÖã„ÅÆÂπ≥Âùá„Å®max„Çí„Åè„Å£„Å§„Åë„Çã\n        out_mean = torch.mean(out, dim=0)\n        out_max, _ = torch.max(out, dim=0)\n        out = torch.cat((out_mean, out_max), dim=-1)\n\n        # Multisample Dropout: https://arxiv.org/abs/1905.09788\n        outputs = torch.mean(torch.stack([self.fc(self.drop(out)) for _ in range(5)], dim=0), dim=0)\n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.651139Z","iopub.execute_input":"2022-01-04T07:18:03.652117Z","iopub.status.idle":"2022-01-04T07:18:03.664203Z","shell.execute_reply.started":"2022-01-04T07:18:03.652071Z","shell.execute_reply":"2022-01-04T07:18:03.662992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.667839Z","iopub.execute_input":"2022-01-04T07:18:03.668129Z","iopub.status.idle":"2022-01-04T07:18:03.67999Z","shell.execute_reply.started":"2022-01-04T07:18:03.668098Z","shell.execute_reply":"2022-01-04T07:18:03.678855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.683969Z","iopub.execute_input":"2022-01-04T07:18:03.684862Z","iopub.status.idle":"2022-01-04T07:18:03.693603Z","shell.execute_reply.started":"2022-01-04T07:18:03.684778Z","shell.execute_reply":"2022-01-04T07:18:03.692257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:03.695164Z","iopub.execute_input":"2022-01-04T07:18:03.696458Z","iopub.status.idle":"2022-01-04T07:18:36.883128Z","shell.execute_reply.started":"2022-01-04T07:18:03.69641Z","shell.execute_reply":"2022-01-04T07:18:36.881329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total Predictiions: {preds.shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:36.885101Z","iopub.status.idle":"2022-01-04T07:18:36.885958Z","shell.execute_reply.started":"2022-01-04T07:18:36.885612Z","shell.execute_reply":"2022-01-04T07:18:36.885643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['score'] = preds\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:36.887571Z","iopub.status.idle":"2022-01-04T07:18:36.888512Z","shell.execute_reply.started":"2022-01-04T07:18:36.888156Z","shell.execute_reply":"2022-01-04T07:18:36.888189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['score'] = df['score'].rank(method='first')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:18:36.890209Z","iopub.status.idle":"2022-01-04T07:18:36.891195Z","shell.execute_reply.started":"2022-01-04T07:18:36.890777Z","shell.execute_reply":"2022-01-04T07:18:36.890828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('text', axis=1, inplace=True)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:12:23.504704Z","iopub.status.idle":"2021-12-30T12:12:23.506785Z","shell.execute_reply.started":"2021-12-30T12:12:23.506537Z","shell.execute_reply":"2021-12-30T12:12:23.506563Z"},"trusted":true},"execution_count":null,"outputs":[]}]}