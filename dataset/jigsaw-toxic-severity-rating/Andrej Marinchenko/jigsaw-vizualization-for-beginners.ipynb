{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Jigsaw data vizualization for beginners\n\nThis notebook is to visualise the text data to see and identify some patterns in the text data which might help us in differentiating between less_toxic and more_toxic comments.\n\n# Problem Statement\n<ul style='font-family: Segoe UI; font-size: 1.5em; font-weight: 400; font-size: 15px'>\n<li>Build a model that produces scores that rank each pair of comments the same way as the professional raters in the training dataset.</li>\n</ul>\n\n<h2 style='font-family: Segoe UI; font-weight: 400;'>Why this competition?</h2>\n<p style='font-family: Segoe UI; font-size: 1.5em; font-weight: 400; font-size: 15px'>As evident from the problem statement, this competition presents an unique challenge for a greater purpose. Online bullying has become a epidemic with the boom in connectivity.<br>Hopefully the solutions contribute towards controlling this behaviour so that the internet remains a safe place for everyone.</p>\n\n<h2 style='font-family: Segoe UI; font-weight: 400;'>Expected Outcome</h2>\n<p style='font-family: Segoe UI; font-size: 1.5em; font-weight: 400; font-size: 15px'>In this competition we will be ranking comments in order of severity of toxicity.<br>We are given a list of comments, and each comment should be scored according to their relative toxicity. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity.</p>\n\n<h2 style='font-family: Segoe UI; font-weight: 400;'>Data Description</h2>\n<p style='font-family: Segoe UI; font-size: 1.5em; font-weight: 400; font-size: 15px'>There is no training data for this competition. We can refer to previous Jigsaw competitions for data that might be useful to train models.<br>However, we are provided a set of paired toxicity rankings(as per expert raters) that can be used to validate models.</p>\n\n<h2 style='font-family: Segoe UI; font-weight: 400;'>Grading Metric</h2>\n<p style='font-family: Segoe UI; font-size: 1.5em; font-weight: 400; font-size: 15px'>Submissions are evaluated on <b>Average Agreement</b> with Annotators.<br>\nFor the ground truth, annotators were shown two comments and asked to identify which of the two was more toxic. Pairs of comments can be, and often are, rated by more than one annotator, and may have been ordered differently by different annotators.</p>\n\n<p style='background:MediumSeaGreen; border:0; color: white; text-align: center; font-family: Segoe UI; font-size: 1.5em; font-weight: 400; font-size: 24px'>If you found this notebook useful or use parts of it in your work, please don't forget to show your appreciation by upvoting this kernel. That keeps me motivated and inspires me to write and share such public kernels.<br>Thanks! ðŸ˜Š</p>","metadata":{}},{"cell_type":"markdown","source":"# Get GPU Info","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:39.108922Z","iopub.execute_input":"2021-12-17T14:55:39.109802Z","iopub.status.idle":"2021-12-17T14:55:39.892582Z","shell.execute_reply.started":"2021-12-17T14:55:39.109675Z","shell.execute_reply":"2021-12-17T14:55:39.891461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd  # data analysis library\nimport numpy as np  # comprehensive mathematical functions, random number generators, linear algebra routines, Fourier transforms, and more\nimport matplotlib.pyplot as plt  # provides an implicit way of plotting\nimport seaborn as sns  # for visualization\nfrom tqdm import tqdm  # progressbar decorator for iterators\nimport os  # for operating system\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator  # word cloud building library\n\nimport warnings  # error processing\nwarnings.filterwarnings(\"ignore\")\n\nfrom collections import defaultdict  # if the key is not found in the method, then a new entry is created instead of KeyError. The type of this new entry is specified by the defaultdict argument.\n\nfrom itertools import cycle  # contains some inbuilt functions for generating sequences using iterators\nplt.style.use('ggplot')\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:39.894984Z","iopub.execute_input":"2021-12-17T14:55:39.895304Z","iopub.status.idle":"2021-12-17T14:55:41.05546Z","shell.execute_reply.started":"2021-12-17T14:55:39.895274Z","shell.execute_reply":"2021-12-17T14:55:41.054538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- validation_data.csv - This contains pairs of rankings not from comments_to_score. It gives us an idea of how the rankings were applied. We also can learn about the annotators from this dataset.\n- comments_to_score.csv (aka test set)- for each comment text in this file, we need to rank these in order of toxicity.\n- sample_submission.csv - a sample submission file.","metadata":{}},{"cell_type":"code","source":"# Look at the data names and size\n!ls -Flash --color ../input/jigsaw-toxic-severity-rating/","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:41.057091Z","iopub.execute_input":"2021-12-17T14:55:41.057347Z","iopub.status.idle":"2021-12-17T14:55:41.822032Z","shell.execute_reply.started":"2021-12-17T14:55:41.057317Z","shell.execute_reply":"2021-12-17T14:55:41.820993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nss = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\nprint(f'Validation Data csv is of shape: {val.shape}')\nprint(f'Comments csv is of shape: {comments.shape}')\nprint(f'Sample submission csv is of shape: {ss.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:41.824798Z","iopub.execute_input":"2021-12-17T14:55:41.825077Z","iopub.status.idle":"2021-12-17T14:55:42.547975Z","shell.execute_reply.started":"2021-12-17T14:55:41.825044Z","shell.execute_reply":"2021-12-17T14:55:42.546996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total workers involved in validation are => {len(val.worker.unique())}')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:42.550237Z","iopub.execute_input":"2021-12-17T14:55:42.550582Z","iopub.status.idle":"2021-12-17T14:55:42.564251Z","shell.execute_reply.started":"2021-12-17T14:55:42.550535Z","shell.execute_reply":"2021-12-17T14:55:42.563263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Less toxic unique comments => {len(val.less_toxic.unique())}')\nprint(f'More toxic unique comments => {len(val.more_toxic.unique())}')\nprint(f'Toal unique comments in both columns => {len(val.more_toxic.append(val.less_toxic).unique())}')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:42.565988Z","iopub.execute_input":"2021-12-17T14:55:42.566479Z","iopub.status.idle":"2021-12-17T14:55:42.683914Z","shell.execute_reply.started":"2021-12-17T14:55:42.566436Z","shell.execute_reply":"2021-12-17T14:55:42.68305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total:\n- there are more than 30,000 lines in the dataset (to be precise 30108), thus the total number of comments for analysis is 30 108 * 2 = 60 216\n- less toxic unique comments - 11,532 out of 60,216\n- more toxic unique comments - 11678 out of 60 216\n- unique Toal comments in both columns -14251 out of 60216\n- in total, 753 employees were involved in the validation - and divided 60,216 comments into more or less toxic\n","metadata":{}},{"cell_type":"code","source":"lens=comments.text.str.len()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:42.685432Z","iopub.execute_input":"2021-12-17T14:55:42.685876Z","iopub.status.idle":"2021-12-17T14:55:42.698969Z","shell.execute_reply.started":"2021-12-17T14:55:42.685822Z","shell.execute_reply":"2021-12-17T14:55:42.698062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lens.hist(color='orange', figsize=(30, 10))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:42.7008Z","iopub.execute_input":"2021-12-17T14:55:42.701114Z","iopub.status.idle":"2021-12-17T14:55:43.042429Z","shell.execute_reply.started":"2021-12-17T14:55:42.701071Z","shell.execute_reply":"2021-12-17T14:55:43.041524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation Data\nIn this dataset we have three columns. The worker identifier - which is unique for the person ordering the pair of comments. Two columns less_toxic and more_toxic show the comments as the worker has ordered them.","metadata":{}},{"cell_type":"markdown","source":"### Comments most and lest commonly ranked less_toxic and more_toxic","metadata":{}},{"cell_type":"code","source":"# Top 25 \"Less Toxic\" Comments.\nval['less_toxic'].value_counts() \\\n    .to_frame().head(25)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:43.043983Z","iopub.execute_input":"2021-12-17T14:55:43.046297Z","iopub.status.idle":"2021-12-17T14:55:43.081064Z","shell.execute_reply.started":"2021-12-17T14:55:43.046243Z","shell.execute_reply":"2021-12-17T14:55:43.079969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 25 \"More Toxic\" Comments.\nval['more_toxic'].value_counts() \\\n    .to_frame().head(25)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:43.084999Z","iopub.execute_input":"2021-12-17T14:55:43.085722Z","iopub.status.idle":"2021-12-17T14:55:43.11267Z","shell.execute_reply.started":"2021-12-17T14:55:43.085675Z","shell.execute_reply":"2021-12-17T14:55:43.111856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### consider the most common words of the most taxing and less toxic reviews\nUnigrams are single words in a sentence. It's the smallest unit of word measurement.","metadata":{}},{"cell_type":"code","source":"# In the fields of computational linguistics and probability, an n-gram (sometimes also called Q-gram) is \n# a contiguous sequence of n items from a given sample of text or speech. The items can be phonemes, syllables, \n# letters, words or base pairs according to the application.\n\ndef generate_ngrams(text, n_gram=1):\n    token = [token for token in text.lower().split(' ') if token != '' if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [' '.join(ngram) for ngram in ngrams]\n\ndf =  val\nN = 50  # N number of n-grams to visualize\n\n\n\nless_toxic_unigrams = defaultdict(int)\nfor tweet in df['less_toxic']:\n    for word in generate_ngrams(tweet, 1):\n        less_toxic_unigrams[word] += 1\n        \ndf_less_toxic_unigrams = pd.DataFrame(sorted(less_toxic_unigrams.items(), key=lambda x: x[1])[::-1])\n\nunigrams_less_100 = df_less_toxic_unigrams[:N]\n\nmore_toxic_unigrams = defaultdict(int)\nfor tweet in df['more_toxic']:\n    for word in generate_ngrams(tweet, 1):\n        more_toxic_unigrams[word] += 1\n        \ndf_more_toxic_unigrams = pd.DataFrame(sorted(more_toxic_unigrams.items(), key=lambda x: x[1])[::-1])\n\nunigrams_more_100 = df_more_toxic_unigrams[:N]","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:43.114219Z","iopub.execute_input":"2021-12-17T14:55:43.114646Z","iopub.status.idle":"2021-12-17T14:55:45.243105Z","shell.execute_reply.started":"2021-12-17T14:55:43.114606Z","shell.execute_reply":"2021-12-17T14:55:45.242341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(18, N//2), dpi=100)\nplt.tight_layout()\n\nsns.barplot(y=unigrams_less_100[0], x=unigrams_less_100[1], ax=axes[0], color='green')\nsns.barplot(y=unigrams_more_100[0], x=unigrams_more_100[1], ax=axes[1], color='red')\n\nfor i in range(2):\n    axes[i].spines['right'].set_visible(False)\n    axes[i].set_xlabel('')\n    axes[i].set_ylabel('')\n    axes[i].tick_params(axis='x', labelsize=13)\n    axes[i].tick_params(axis='y', labelsize=13)\n\naxes[0].set_title(f'Top {N} most common unigrams in less_toxic comments', fontsize=15)\naxes[1].set_title(f'Top {N} most common unigrams in more_toxic comments', fontsize=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:45.244702Z","iopub.execute_input":"2021-12-17T14:55:45.245215Z","iopub.status.idle":"2021-12-17T14:55:47.090413Z","shell.execute_reply.started":"2021-12-17T14:55:45.245173Z","shell.execute_reply":"2021-12-17T14:55:47.089693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"in addition to words, we see that there are often symbols that do not carry a semantic meaning","metadata":{}},{"cell_type":"markdown","source":"### bi-grams\nBi-grams are two words zipped together. If we iterate through each word in a sentence, then the pair of that word and the next word is called a bi-gram.","metadata":{}},{"cell_type":"code","source":"less_toxic_bigrams = defaultdict(int)\nfor tweet in df['less_toxic']:\n    for word in generate_ngrams(tweet, 2):\n        less_toxic_bigrams[word] += 1\n        \ndf_less_toxic_bigrams = pd.DataFrame(sorted(less_toxic_bigrams.items(), key=lambda x: x[1])[::-1])\n\nbigrams_less_100 = df_less_toxic_bigrams[:N]\n\nmore_toxic_bigrams = defaultdict(int)\nfor tweet in df['more_toxic']:\n    for word in generate_ngrams(tweet, 2):\n        more_toxic_bigrams[word] += 1\n        \ndf_more_toxic_bigrams = pd.DataFrame(sorted(more_toxic_bigrams.items(), key=lambda x: x[1])[::-1])\n\nbigrams_more_100 = df_more_toxic_bigrams[:N]","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:47.091759Z","iopub.execute_input":"2021-12-17T14:55:47.092138Z","iopub.status.idle":"2021-12-17T14:55:50.250474Z","shell.execute_reply.started":"2021-12-17T14:55:47.092102Z","shell.execute_reply":"2021-12-17T14:55:50.249677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(18, N//2), dpi=100)\nplt.tight_layout()\n\nsns.barplot(y=bigrams_less_100[0], x=bigrams_less_100[1], ax=axes[0], color='green')\nsns.barplot(y=bigrams_more_100[0], x=bigrams_more_100[1], ax=axes[1], color='red')\n\nfor i in range(2):\n    axes[i].spines['right'].set_visible(False)\n    axes[i].set_xlabel('')\n    axes[i].set_ylabel('')\n    axes[i].tick_params(axis='x', labelsize=13)\n    axes[i].tick_params(axis='y', labelsize=13)\n\naxes[0].set_title(f'Top {N} most common bigrams in less_toxic comments', fontsize=15)\naxes[1].set_title(f'Top {N} most common bigrams in more_toxic comments', fontsize=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:50.251786Z","iopub.execute_input":"2021-12-17T14:55:50.252082Z","iopub.status.idle":"2021-12-17T14:55:52.564885Z","shell.execute_reply.started":"2021-12-17T14:55:50.252012Z","shell.execute_reply":"2021-12-17T14:55:52.564096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### tri-grams\nSimilarly, the tri-grams would be 3 consecutive words in a sentence","metadata":{}},{"cell_type":"code","source":"less_toxic_trigrams = defaultdict(int)\nfor tweet in df['less_toxic']:\n    for word in generate_ngrams(tweet, 3):\n        less_toxic_trigrams[word] += 1\n        \ndf_less_toxic_trigrams = pd.DataFrame(sorted(less_toxic_trigrams.items(), key=lambda x: x[1])[::-1])\n\ntrigrams_less_100 = df_less_toxic_trigrams[:N]\n\nmore_toxic_trigrams = defaultdict(int)\nfor tweet in df['more_toxic']:\n    for word in generate_ngrams(tweet, 3):\n        more_toxic_trigrams[word] += 1\n        \ndf_more_toxic_trigrams = pd.DataFrame(sorted(more_toxic_trigrams.items(), key=lambda x: x[1])[::-1])\n\ntrigrams_more_100 = df_more_toxic_trigrams[:N]","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:52.566494Z","iopub.execute_input":"2021-12-17T14:55:52.56683Z","iopub.status.idle":"2021-12-17T14:55:55.894092Z","shell.execute_reply.started":"2021-12-17T14:55:52.566796Z","shell.execute_reply":"2021-12-17T14:55:55.893115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(30, N//2), dpi=100)\nplt.tight_layout()\n\nsns.barplot(y=trigrams_less_100[0], x=trigrams_less_100[1], ax=axes[0], color='green')\nsns.barplot(y=trigrams_more_100[0], x=trigrams_more_100[1], ax=axes[1], color='red')\n\nfor i in range(2):\n    axes[i].spines['right'].set_visible(False)\n    axes[i].set_xlabel('')\n    axes[i].set_ylabel('')\n    axes[i].tick_params(axis='x', labelsize=13)\n    axes[i].tick_params(axis='y', labelsize=13)\n\naxes[0].set_title(f'Top {N} most common trigrams in less_toxic comments', fontsize=35)\naxes[1].set_title(f'Top {N} most common trigrams in more_toxic comments', fontsize=35)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:55.895548Z","iopub.execute_input":"2021-12-17T14:55:55.895844Z","iopub.status.idle":"2021-12-17T14:55:58.688136Z","shell.execute_reply.started":"2021-12-17T14:55:55.895811Z","shell.execute_reply":"2021-12-17T14:55:58.687121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comment occurance in the validation set.\nHow often to comments even appear in the validation set? What is the distribution, and what are the top/least occuring comments?\n\nSome thing to note:\n\nComments tend to occur in multiples of 3 (3, 6, 9, etc.)\nMost workers only score a small ammount of comments. However there are workers who score much more than the rest of the population (200+ pairs)","metadata":{}},{"cell_type":"code","source":"all_comments = pd.concat([val['less_toxic'],\n                          val['more_toxic']]) \\\n    .reset_index(drop=True)\n\nax = pd.DataFrame(index=range(1,19)) \\\n    .merge(all_comments.value_counts() \\\n           .value_counts().to_frame(),\n           left_index=True, right_index=True, how='outer').fillna(0) \\\n    .astype('int').rename(columns={0:'Comment Frequency'}) \\\n    .plot(kind='bar',\n          figsize=(12, 5))\nplt.xticks(rotation=0)\nax.set_title('Comment Frequency in Val Dataset', fontsize=20)\nax.set_xlabel('Comment Occurance')\nax.set_ylabel('Number of Comments')\nax.legend().remove()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:58.689305Z","iopub.execute_input":"2021-12-17T14:55:58.689531Z","iopub.status.idle":"2021-12-17T14:55:59.009369Z","shell.execute_reply.started":"2021-12-17T14:55:58.689502Z","shell.execute_reply":"2021-12-17T14:55:59.00849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = val['worker'].value_counts() \\\n    .plot(kind='hist', bins=50,\n          color=color_pal[1], figsize=(30, 20))\nax.set_title('Frequeny of Worker in Val Set', fontsize=20)\nax.set_xlabel('Rows in Validation set for a Worker')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:59.010594Z","iopub.execute_input":"2021-12-17T14:55:59.010801Z","iopub.status.idle":"2021-12-17T14:55:59.451862Z","shell.execute_reply.started":"2021-12-17T14:55:59.010775Z","shell.execute_reply":"2021-12-17T14:55:59.450886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, the distribution tells us that most workers scored some 1-20 comment pairs but there were also some workers who did upwards of 200 pairs!","metadata":{}},{"cell_type":"code","source":"# The most commonly occuring comment.\nall_comments.value_counts() \\\n    .to_frame().rename(columns={0:'Total Comment Count'}) \\\n    .head()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:59.453534Z","iopub.execute_input":"2021-12-17T14:55:59.453858Z","iopub.status.idle":"2021-12-17T14:55:59.48998Z","shell.execute_reply.started":"2021-12-17T14:55:59.453814Z","shell.execute_reply":"2021-12-17T14:55:59.489108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The least common comment.\nall_comments.value_counts() \\\n    .to_frame().rename(columns={0:'Total Comment Count'}) \\\n    .tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:59.4914Z","iopub.execute_input":"2021-12-17T14:55:59.49166Z","iopub.status.idle":"2021-12-17T14:55:59.521963Z","shell.execute_reply.started":"2021-12-17T14:55:59.49163Z","shell.execute_reply":"2021-12-17T14:55:59.521122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Repeated Pairs in Validation SetÂ¶\nHow much workers agree and/or disagree.\n\nComment pairs occur in the same order 1, 2 or 3 times - but never more.\nWhen we take the comments and undo the ordering (sort them alphabetically - we find that the pairs almost always occur 3 times)","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 10), sharey=True)\nval['comment_pair_ordered'] = val['less_toxic'] + ' : ' + val['more_toxic']\n# The most common pair\nval['comment_pair_ordered'] \\\n    .value_counts().value_counts() \\\n    .plot(kind='bar', title='Ordered Comment Pairs',\n          color=color_pal[4], ax=ax1)\nax1.tick_params(axis='x', rotation=0)\nax1.set_ylabel('Occurance')\nax1.set_xlabel('Number of times Pair is Found in Dataset')\n\n\n# Comment Pairs in a standard alphabetical order\nval['comment_pair_not_ordered'] = val[['less_toxic','more_toxic']] \\\n    .apply(lambda x: ':'.join(np.sort(list(x))), axis=1)\nval['comment_pair_not_ordered'].value_counts().value_counts() \\\n    .sort_index() \\\n    .plot(kind='bar', title='Unordered Comment Pairs', ax=ax2,\n          color=color_pal[5])\nax2.tick_params(axis='x', rotation=0)\nax2.set_xlabel('Number of times Unordered Pair is Found in Dataset')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:55:59.523803Z","iopub.execute_input":"2021-12-17T14:55:59.524355Z","iopub.status.idle":"2021-12-17T14:56:01.041987Z","shell.execute_reply.started":"2021-12-17T14:55:59.524314Z","shell.execute_reply":"2021-12-17T14:56:01.040892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comments to GradeÂ¶\nDo they appear in the validation data? Yes 100% of the public all_comments also appear in the validation data. Thus, each pair of comments occurs in the dataset three times and a smaller part of the sample once.","metadata":{}},{"cell_type":"code","source":"comments['text'].isin(all_comments).mean()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:01.043443Z","iopub.execute_input":"2021-12-17T14:56:01.043713Z","iopub.status.idle":"2021-12-17T14:56:01.067671Z","shell.execute_reply.started":"2021-12-17T14:56:01.04367Z","shell.execute_reply":"2021-12-17T14:56:01.06676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Where do labelers disagree the most?\nWe now know that pairs occur three times in the validation dataset. This leads us to ask the question... are there any \"workers\" who disagree more than others?\n\nWe can create a new columns n_agreements to see for each row how many times the three workers had the same order for the given pair.","metadata":{}},{"cell_type":"code","source":"val_order_dict = val['comment_pair_ordered'].value_counts().to_dict()\nval['n_agreements'] = val['comment_pair_ordered'].map(val_order_dict)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:01.068964Z","iopub.execute_input":"2021-12-17T14:56:01.069687Z","iopub.status.idle":"2021-12-17T14:56:01.13311Z","shell.execute_reply.started":"2021-12-17T14:56:01.069651Z","shell.execute_reply":"2021-12-17T14:56:01.132144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val['agreement'] = val['n_agreements'].map({1: 'Reviewer Disagreed',\n                         2: 'Agreed with One Reviwer',\n                         3: 'All Three Reviewers Agreed'})\nax = val['agreement'].value_counts().plot(kind='bar', color=color_pal[5],\n                                         figsize=(30, 10))\nax.tick_params(axis='x', rotation=0)\nax.set_title('Worker Agreement', fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:01.134721Z","iopub.execute_input":"2021-12-17T14:56:01.134974Z","iopub.status.idle":"2021-12-17T14:56:01.618627Z","shell.execute_reply.started":"2021-12-17T14:56:01.134946Z","shell.execute_reply":"2021-12-17T14:56:01.617752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 20))\n# Reviewers with the most disagreements\nval.query('n_agreements == 1')['worker'].value_counts(ascending=True) \\\n    .tail(20) \\\n    .plot(kind='barh', title='Reviewers with the Most Disagreements', ax=ax1)\n\n# Reviewers with the most disagreements\nval.query('n_agreements == 3')['worker'].value_counts(ascending=True) \\\n    .tail(60) \\\n    .plot(kind='barh', title='Reviewers with the Most Agreements', ax=ax2,\n         color=color_pal[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:01.619893Z","iopub.execute_input":"2021-12-17T14:56:01.620133Z","iopub.status.idle":"2021-12-17T14:56:02.792885Z","shell.execute_reply.started":"2021-12-17T14:56:01.620103Z","shell.execute_reply":"2021-12-17T14:56:02.792051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets look at disagreement count vs. total label reviews","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n\nval['worker'].value_counts().to_frame().merge(\n    val.query('n_agreements == 1')['worker'].value_counts().to_frame(),\n    left_index=True, right_index=True\n).rename(columns={'worker_x':'Number of Reviews',\n                  'worker_y':'Number of Disagreements'}) \\\n    .plot(x='Number of Reviews', y='Number of Disagreements',\n          kind='scatter', title='Worker Reviews vs Disagreements', ax=ax1)\n\nval['worker'].value_counts().to_frame().merge(\n    val.query('n_agreements == 3')['worker'].value_counts().to_frame(),\n    left_index=True, right_index=True\n).rename(columns={'worker_x':'Number of Reviews',\n                  'worker_y':'Number of Disagreements'}) \\\n    .plot(x='Number of Reviews', y='Number of Disagreements',\n          kind='scatter', title='Worker Reviews vs Agreements', ax=ax2, color=color_pal[2])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:02.794383Z","iopub.execute_input":"2021-12-17T14:56:02.79463Z","iopub.status.idle":"2021-12-17T14:56:03.262019Z","shell.execute_reply.started":"2021-12-17T14:56:02.794599Z","shell.execute_reply":"2021-12-17T14:56:03.261119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Wordclouds of Toxic and Non-Toxic Comments.","metadata":{}},{"cell_type":"code","source":"non_toxic_comments = val['less_toxic'].value_counts() \\\n    .to_frame().head(1000)\nnon_toxic_text = ' '.join(non_toxic_comments.index.tolist())\n\ntoxic_comments = val['more_toxic'].value_counts() \\\n    .to_frame().head(1000)\ntoxic_text = ' '.join(toxic_comments.index.tolist())\n\n\nwordcloud = WordCloud(max_font_size=50, max_words=100,width=500, height=500,\n                      background_color=\"white\") \\\n    .generate(non_toxic_text)\n\n\nwordcloud2 = WordCloud(max_font_size=50, max_words=100,width=500, height=500,\n                      background_color=\"black\") \\\n    .generate(toxic_text)\n\n\nfig, (ax1,ax2) = plt.subplots(1, 2, figsize=(30,20))\n\nax1.imshow(wordcloud, interpolation=\"bilinear\")\nax1.axis(\"off\")\nax2.imshow(wordcloud2, interpolation=\"bilinear\")\nax2.axis(\"off\")\nax1.set_title('Non Toxic Comments', fontsize=25)\nax2.set_title('Toxic Comments', fontsize=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:03.263426Z","iopub.execute_input":"2021-12-17T14:56:03.264168Z","iopub.status.idle":"2021-12-17T14:56:05.159186Z","shell.execute_reply.started":"2021-12-17T14:56:03.26411Z","shell.execute_reply":"2021-12-17T14:56:05.158217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom io import BytesIO\nfrom PIL import Image\ntry:\n    url=\"https://user-images.githubusercontent.com/74188336/142692890-641ebc21-2e47-4556-9d37-1c0b9e1a0587.jpeg\"\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n\n    text = ' '.join(df['less_toxic'].values)\n    mask = np.array(img)\n    wordcloud = WordCloud(max_font_size=50, max_words=1000, background_color=\"white\", mask=mask, colormap='BuGn').generate(text.lower())\n    plt.figure(figsize=(15,15))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\nexcept Exception as e:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:05.163644Z","iopub.execute_input":"2021-12-17T14:56:05.164659Z","iopub.status.idle":"2021-12-17T14:56:14.568703Z","shell.execute_reply.started":"2021-12-17T14:56:05.164595Z","shell.execute_reply":"2021-12-17T14:56:14.567811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    text = ' '.join(df['more_toxic'].values)\n    url=\"https://user-images.githubusercontent.com/74188336/142692894-c17240e4-1101-4591-9d10-71793e460816.jpeg\"\n    \n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n\n    mask = np.array(img)\n    wordcloud = WordCloud(max_font_size=50, max_words=2000, background_color=\"white\", mask=mask, contour_width=0, contour_color='grey', colormap='Reds').generate(text.lower())\n    plt.figure(figsize=(15,15))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\nexcept Exception as e:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:56:14.569976Z","iopub.execute_input":"2021-12-17T14:56:14.570217Z","iopub.status.idle":"2021-12-17T14:56:22.995097Z","shell.execute_reply.started":"2021-12-17T14:56:14.570188Z","shell.execute_reply":"2021-12-17T14:56:22.99369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total:\n- there are more than 30,000 lines in the dataset (to be precise 30108), thus the total number of comments for analysis is 30 108 * 2 = 60 216\n- less toxic unique comments - 11,532 out of 60,216\n- more toxic unique comments - 11678 out of 60 216\n- unique Toal comments in both columns -14251 out of 60216\n- in total, 753 employees were involved in the validation - and divided 60,216 comments into more or less toxic\n- a large number of unnecessary symbols that do not play a role in determining taxation, such as quotes or the symbol equal\n- pairs occur three times in the validation dataset. Moreover, these comments are found both in the same pairs and in the composition of others\n- at the same time, new employees who rated pairs of comments did not always give the same rating, subjectivity of employees' assessment of the degree of toxicity of comments\n- the distribution tells us that most workers scored some 1-20 comment pairs but there were also some workers who did upwards of 200 pairs\n\nAll this says that before training our model, it is necessary to conduct a good pre-processing of the text.","metadata":{}},{"cell_type":"markdown","source":"Thanks a lot for sticking along and taking your time to read this. Do let know if something needs to be corrected and also feel free to drop a comment.","metadata":{}}]}