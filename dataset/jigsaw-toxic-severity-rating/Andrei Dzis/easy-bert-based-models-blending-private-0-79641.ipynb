{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is the simplest bronze solution, using 9 stacked models for toxic classification. Unlucky we haven't submitted this solution.","metadata":{}},{"cell_type":"code","source":"import gc\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport transformers\nimport optuna\nfrom transformers import AdamW, AutoTokenizer, AutoModel\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport time\nfrom tqdm import tqdm\n\nimport pickle\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Для подготовки данных\nimport nltk\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-07T23:27:53.7374Z","iopub.execute_input":"2022-02-07T23:27:53.737848Z","iopub.status.idle":"2022-02-07T23:27:53.751919Z","shell.execute_reply.started":"2022-02-07T23:27:53.737798Z","shell.execute_reply":"2022-02-07T23:27:53.750671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --no-deps ../input/swifter/swifter-1.1.2.tar","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:53.754748Z","iopub.execute_input":"2022-02-07T23:27:53.755833Z","iopub.status.idle":"2022-02-07T23:27:57.886853Z","shell.execute_reply.started":"2022-02-07T23:27:53.755789Z","shell.execute_reply":"2022-02-07T23:27:57.885735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import swifter","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.889152Z","iopub.execute_input":"2022-02-07T23:27:57.889588Z","iopub.status.idle":"2022-02-07T23:27:57.897411Z","shell.execute_reply.started":"2022-02-07T23:27:57.889536Z","shell.execute_reply":"2022-02-07T23:27:57.893931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.901152Z","iopub.execute_input":"2022-02-07T23:27:57.901599Z","iopub.status.idle":"2022-02-07T23:27:57.908205Z","shell.execute_reply.started":"2022-02-07T23:27:57.901553Z","shell.execute_reply":"2022-02-07T23:27:57.907048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = False","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.910227Z","iopub.execute_input":"2022-02-07T23:27:57.911443Z","iopub.status.idle":"2022-02-07T23:27:57.919212Z","shell.execute_reply.started":"2022-02-07T23:27:57.911365Z","shell.execute_reply":"2022-02-07T23:27:57.918016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def washing_machine(comments): # Чистка текста от мусора\n    corpus=[]\n    for i in tqdm(range(len(comments))):\n        comment = re.sub('[^a-zA-Z]', ' ', comments[i])\n        comment = comment.lower()\n        comment = comment.split()\n        stemmer = SnowballStemmer('english')\n        lemmatizer = WordNetLemmatizer()\n        all_stopwords = stopwords.words('english')\n        comment = [stemmer.stem(word) for word in comment if not word in set(all_stopwords)]\n        comment = [lemmatizer.lemmatize(word) for word in comment]\n        comment = ' '.join(comment)\n        corpus.append(comment)\n\n    return corpus","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.921317Z","iopub.execute_input":"2022-02-07T23:27:57.922742Z","iopub.status.idle":"2022-02-07T23:27:57.934191Z","shell.execute_reply.started":"2022-02-07T23:27:57.922583Z","shell.execute_reply":"2022-02-07T23:27:57.932961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Data cleaning","metadata":{}},{"cell_type":"code","source":"def clean(data, col):\n    # чистка для tfidf\n\n        # Remove ip address\n    data[col] = data[col].str.replace(r'(([0-9]+\\.){2,}[0-9]+)',' ')\n    # Remove website\n    data[col] = data[col].str.replace(r'https?://\\S+|www\\.\\S+', ' ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')\n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\'\"]+)',r' \\1 ')    \n    # Remove multiple white spaces\n    data[col] = data[col].str.replace(r' +', ' ')\n    # Remove html tags\n    data[col] = data[col].str.replace(r'<[^<]+?>', ' ')\n    \n    #Code for removing slang words\n    \n    d = {'luv':'love','wud':'would','lyk':'like','wateva':'whatever','ttyl':'talk to you later',\n         'kul':'cool','fyn':'fine','omg':'oh my god!','fam':'family','bruh':'brother',\n         'cud':'could', 'fud':'food'} ## Need a huge dictionary\n        \n    data[col] = data[col].swifter.apply(lambda x : ' '.join(d[word] if word in d else word for word in x.split()))\n    data[col] = data[col].str.replace(r\"j k\", \"jk\")\n    data[col] = data[col].str.replace(r\"e - mail\", \"email\")\n    data[col] = data[col].str.replace(r\"\\0s\", \"0\")\n    data[col] = data[col].str.replace(r\" 9 11 \", \" 911 \")\n    data[col] = data[col].str.replace(r\" e g \", \" eg \")\n    data[col] = data[col].str.replace(r\" b g \", \" bg \")\n    data[col] = data[col].str.replace(r\" u s \", \" american \")\n#         data[col] = data[col].str.replace(r\"https?://[A-Za-z0-9./]+\", \"url\")\n    data[col] = data[col].str.replace(r\"what's\", \"what is \")\n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \")\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n    data[col] = data[col].str.replace(r\"n't\", \" not \")\n#     data[col] = data[col].str.replace(r\"n ' t\", \" not \")\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \")\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \")\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \")\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \")\n    data[col] = data[col].str.replace(r\"\\'s\", \" \")\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)', r'\\1 \\2 \\3')\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}', r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'([*!?\\']+)', r' \\1 ')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b', r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B', r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}', ' ').str.strip()\n    data[col] = data[col].str.replace(r'[ ]{2,}', ' ').str.strip()\n\n    return data\n\n# df = clean(df, 'text')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.936966Z","iopub.execute_input":"2022-02-07T23:27:57.937842Z","iopub.status.idle":"2022-02-07T23:27:57.977056Z","shell.execute_reply.started":"2022-02-07T23:27:57.937775Z","shell.execute_reply":"2022-02-07T23:27:57.975468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 1 - Roberta Base","metadata":{}},{"cell_type":"code","source":"def get_predictions(args, dataloader, model):\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = args.batch_size\n\n            input_ids = data['input_ids'].to(device) # .cuda()\n            attention_mask = data['attention_mask'].to(device) #.cuda()\n            outputs = model(input_ids, attention_mask)\n            outputs = outputs.cpu().detach().numpy()\n            outputs = [sum(output) for output in outputs]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.981399Z","iopub.execute_input":"2022-02-07T23:27:57.982063Z","iopub.status.idle":"2022-02-07T23:27:57.994484Z","shell.execute_reply.started":"2022-02-07T23:27:57.982008Z","shell.execute_reply":"2022-02-07T23:27:57.991944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    model_name = '../input/roberta-base'\n    batch_size = 96\n    lr = 1e-4\n    weight_decay = 0.01\n    scheduler = 'CosineAnnealingLR'\n    early_stopping_epochs = 1\n    epochs = 20\n#     max_length = 128    \n    max_length = 196\n    num_folds = 2\n    \n    \n\nclass ToxicDataset:\n    def __init__(self, comments, tokenizer, max_len=196):\n        self.comments = comments\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.comments)\n    \n    def __getitem__(self, idx):\n        \n        tokenized = self.tokenizer.encode_plus(\n            self.comments[idx],\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length'\n        )\n        \n        input_ids = tokenized['input_ids']\n        attention_mask = tokenized['attention_mask']\n        \n\n        return {\n            'input_ids' : torch.tensor(input_ids, dtype=torch.long),\n            'attention_mask' : torch.tensor(attention_mask, dtype=torch.long)\n        }    \n    \nclass ToxicModel(nn.Module):\n    def __init__(self, args):\n        super(ToxicModel, self).__init__()\n        self.args = args\n        self.model = AutoModel.from_pretrained(self.args.model_name)\n        self.dropout = nn.Dropout(p=0.2)\n        self.toxic = nn.Linear(768, 1)\n        self.stoxic = nn.Linear(768, 1)\n        self.obs = nn.Linear(768, 1)\n        self.threat = nn.Linear(768, 1)\n        self.insult = nn.Linear(768, 1)\n        self.id_hate = nn.Linear(768, 1)\n    \n        \n    def forward(self, input_ids, attention_mask):\n        \n        out = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=False\n        )\n        \n        out = self.dropout(out[1])\n        \n        toxic = self.toxic(out)\n        stoxic = self.stoxic(out)\n        obs = self.obs(out)\n        threat = self.threat(out)\n        insult = self.insult(out)\n        id_hate = self.id_hate(out)\n\n        return torch.cat([toxic, stoxic, obs, threat, insult, id_hate], dim=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:57.999133Z","iopub.execute_input":"2022-02-07T23:27:58.001424Z","iopub.status.idle":"2022-02-07T23:27:58.061412Z","shell.execute_reply.started":"2022-02-07T23:27:58.001356Z","shell.execute_reply":"2022-02-07T23:27:58.05928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(data):\n    args=Config()\n    print('Пытаюсь найти модель тут:',args.model_name)\n    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n    base_path='../input/roberta-base-multi-label/'\n    \n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=16*args.batch_size)\n    \n     \n    \n    final_preds = []\n    \n    num_folds = args.num_folds \n    \n    for fold in range(num_folds):\n        model = ToxicModel(args)\n#         model = model.cuda()\n\n        model.to(device)\n        path = base_path + f'model_fold_{fold}.bin'\n        model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n        \n        print(f\"Getting predictions for model {fold+1}\")\n        preds = get_predictions(args, dataloader, model)\n        final_preds.append(np.vstack(preds))\n        del model\n        gc.collect()\n    return np.hstack(sum(final_preds)/num_folds)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:58.072611Z","iopub.execute_input":"2022-02-07T23:27:58.074548Z","iopub.status.idle":"2022-02-07T23:27:58.100388Z","shell.execute_reply.started":"2022-02-07T23:27:58.074496Z","shell.execute_reply":"2022-02-07T23:27:58.098562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Prediction","metadata":{}},{"cell_type":"code","source":"if train:\n    df_train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n    print(df_train.shape) \n    df_train.head()\n    df_train['severe_toxic'] = df_train.severe_toxic * 3\n    df_train['threat'] = df_train.threat * 2\n\n    df_train['y'] = (df_train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\n    df_train['y'] = np.around (df_train[\"y\"].values , decimals = 2)\n\n    df_train = df_train[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n\n    # Reduce rows with 0 toxicity\n    df_train = pd.concat([df_train[df_train.y>0] , \n                    df_train[df_train.y==0].sample(int(len(df_train[df_train.y>0])*1.5)) ], axis=0).sample(frac=1)\n\n    print(df_train.shape)\n    data_train = washing_machine(df_train['text'].values)\nelse:\n    df = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n    data = washing_machine(df['text'].values)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:27:58.10226Z","iopub.execute_input":"2022-02-07T23:27:58.103509Z","iopub.status.idle":"2022-02-07T23:28:09.553801Z","shell.execute_reply.started":"2022-02-07T23:27:58.103464Z","shell.execute_reply":"2022-02-07T23:28:09.552887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train==True:\n    df_train['score_M1'] = inference(data_train)\nelse:\n    df['score_M1'] = inference(data)\n\n# # df[['comment_id', 'score_M1']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:28:09.555751Z","iopub.execute_input":"2022-02-07T23:28:09.556794Z","iopub.status.idle":"2022-02-07T23:29:46.87506Z","shell.execute_reply.started":"2022-02-07T23:28:09.556749Z","shell.execute_reply":"2022-02-07T23:29:46.874036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 2 - autonlp-toxic-new","metadata":{}},{"cell_type":"code","source":"class ToxicDataset:\n    def __init__(self, comments, tokenizer, max_len=196):\n        self.comments = comments\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.comments)\n    \n    def __getitem__(self, idx):\n        \n        tokenized = self.tokenizer.encode_plus(\n            self.comments[idx],\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length'\n        )\n        \n        input_ids = tokenized['input_ids']\n        attention_mask = tokenized['attention_mask']\n        \n\n        return {\n            'input_ids' : torch.tensor(input_ids, dtype=torch.long),\n            'attention_mask' : torch.tensor(attention_mask, dtype=torch.long)\n        }    \n    \n    \ndef get_predictions(dataloader, model):\n    \n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()[:,1]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:29:46.876821Z","iopub.execute_input":"2022-02-07T23:29:46.877086Z","iopub.status.idle":"2022-02-07T23:29:46.890306Z","shell.execute_reply.started":"2022-02-07T23:29:46.877054Z","shell.execute_reply":"2022-02-07T23:29:46.88927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/autonlp-toxic-1'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M2'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M2'] = get_predictions(dataloader, model)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-07T23:29:46.89182Z","iopub.execute_input":"2022-02-07T23:29:46.89256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 3 - distilbert-base-uncased-finetuned-sst-2-english","metadata":{"execution":{"iopub.status.busy":"2022-01-29T14:29:28.237786Z","iopub.execute_input":"2022-01-29T14:29:28.238192Z","iopub.status.idle":"2022-01-29T14:29:28.261095Z","shell.execute_reply.started":"2022-01-29T14:29:28.238083Z","shell.execute_reply":"2022-01-29T14:29:28.260262Z"}}},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()[:,0]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/distilbertbaseuncasedfinetunedsst2english/distilbert-base-uncased-finetuned-sst-2-english'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M3'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M3'] = get_predictions(dataloader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 4 - dehatebert-mono-english","metadata":{"execution":{"iopub.status.busy":"2022-01-29T14:29:42.483272Z","iopub.execute_input":"2022-01-29T14:29:42.483568Z","iopub.status.idle":"2022-01-29T14:29:42.48739Z","shell.execute_reply.started":"2022-01-29T14:29:42.483532Z","shell.execute_reply":"2022-01-29T14:29:42.486464Z"}}},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()[:,1]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/hatespeechcnergdehatebertmonoenglish/dehatebert-mono-english'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M4'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M4'] = get_predictions(dataloader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 5 - twitter-roberta-base-hate","metadata":{}},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()[:,1]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/twitterrobertabasehate/twitter-roberta-base-hate'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M5'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M5'] = get_predictions(dataloader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 6 - twitter-roberta-base-offensive","metadata":{"execution":{"iopub.status.busy":"2022-01-29T14:57:23.129154Z","iopub.execute_input":"2022-01-29T14:57:23.12943Z","iopub.status.idle":"2022-01-29T14:57:23.133354Z","shell.execute_reply.started":"2022-01-29T14:57:23.129402Z","shell.execute_reply":"2022-01-29T14:57:23.132204Z"}}},{"cell_type":"code","source":"model_path = '../input/twitterrobertabaseoffensive/twitter-roberta-base-offensive'\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M6'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M6'] = get_predictions(dataloader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 7 - twitter-roberta-base-sentiment","metadata":{}},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()[:,0]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/twitterrobertabasesentiment/twitter-roberta-base-sentiment'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M7'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M7'] = get_predictions(dataloader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 8 - BERT-SBIC-offensive","metadata":{}},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()[:,2]\n            all_outputs.append(outputs)\n\n            bar.set_postfix(Stage='Inference') \n    return np.hstack(all_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/bertsbicoffensive/BERT-SBIC-offensive'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M8'] = get_predictions(dataloader_train, model)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M8'] = get_predictions(dataloader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 9 - beep-KcELECTRA-base-hate (3 classes)","metadata":{}},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    model.to(device)\n    model.eval()\n    all_outputs=[]\n    all_outputs_features = {'none':[], \n                            'offensive': [],\n                            'hate': []\n                           }\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    with torch.no_grad():\n        for step, data in bar:\n            batch_size = 100\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()#[:,[1,2]].sum(axis=1)\n            all_outputs.append(outputs[:,[1,2]].sum(axis=1))\n            all_outputs_features['none'].append(outputs[:,0])\n            all_outputs_features['offensive'].append(outputs[:,1])\n            all_outputs_features['hate'].append(outputs[:,2])\n            bar.set_postfix(Stage='Inference') \n            \n    all_outputs_features['none'] = np.hstack(all_outputs_features['none'])\n    all_outputs_features['offensive'] = np.hstack(all_outputs_features['offensive'])\n    all_outputs_features['hate'] = np.hstack(all_outputs_features['hate'])\n            \n    return np.hstack(all_outputs), pd.DataFrame(all_outputs_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/beepkcelectrabasehate/beep-KcELECTRA-base-hate'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\nif train==True:\n    dataset_train = ToxicDataset(data_train, tokenizer)\n    dataloader_train = DataLoader(dataset_train, batch_size=100)\n    df_train['score_M9'], df_feat_train = get_predictions(dataloader_train, model)\n    df_feat_train.sample(3)\nelse:\n    dataset = ToxicDataset(data, tokenizer)\n    dataloader = DataLoader(dataset, batch_size=100)\n    df['score_M9'], df_feat = get_predictions(dataloader, model)\n    df_feat.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅ Model 10 - bertweet-hate-speech(3 classes)","metadata":{}},{"cell_type":"code","source":"# def get_predictions(dataloader, model):\n#     model.to(device)\n#     model.eval()\n#     all_outputs=[]\n#     all_outputs_features = {'hateful':[], \n#                             'targeted': [],\n#                             'aggresive': []\n#                            }\n#     bar = tqdm(enumerate(dataloader), total=len(dataloader))\n#     with torch.no_grad():\n#         for step, data in bar:\n#             batch_size = 100\n#             input_ids = data['input_ids'].to(device)\n#             attention_mask = data['attention_mask'].to(device)\n#             outputs = model(input_ids, attention_mask)\n#             outputs = F.softmax(outputs.logits, dim = 1).cpu().detach().numpy()#[:,[0,2]].sum(axis=1)\n#             all_outputs.append(outputs)#[:,[0,2]].sum(axis=1))\n#             all_outputs_features['hateful'].append(outputs[:,0])\n#             all_outputs_features['targeted'].append(outputs[:,1])\n#             all_outputs_features['aggresive'].append(outputs[:,2])\n#             bar.set_postfix(Stage='Inference') \n            \n#     all_outputs_features['hateful'] = np.hstack(all_outputs_features['hateful'])\n#     all_outputs_features['targeted'] = np.hstack(all_outputs_features['targeted'])\n#     all_outputs_features['aggresive'] = np.hstack(all_outputs_features['aggresive'])\n            \n#     return np.hstack(all_outputs), pd.DataFrame(all_outputs_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_path = '../input/bertweethatespeech/bertweet-hate-speech'\n\n\n# tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n# model = AutoModelForSequenceClassification.from_pretrained(model_path)\n\n# dataset = ToxicDataset(data, tokenizer, max_len=130)\n# dataloader = DataLoader(dataset, batch_size=100)\n\n\n# df['score_M10'],df_feat1 = get_predictions(dataloader, model)\n\n# dataset_train = ToxicDataset(data_train, tokenizer)\n# dataloader_train = DataLoader(dataset_train, batch_size=100)\n# df_train['score_M10'], df_feat_train1 = get_predictions(dataloader_train, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train==True:\n    df_train_full = pd.concat([df_train.reset_index(drop=True),df_feat_train],axis = 1)\n    print(df_train_full.columns)\n    df_train_full.sample(5)\nif train==False:\n    df_full = pd.concat([df.reset_index(drop=True),df_feat],axis = 1)\n    print(df_full.columns)\n    df_full.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ❎ Ridge regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy import sparse\n\nfrom sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer, make_column_selector\n\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif\nfrom mlxtend.feature_selection import ColumnSelector\n\nimport sklearn\nsklearn.set_config(display='diagram') # Визуализация пайплайна\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train==True:\n    df_train_full['text'] = clean(df_train,'text')['text'].values\nelse:\n    df_full['text'] = clean(df,'text')['text'].values\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_features = ['text']\nbert_features = ['score_M1', 'score_M2', 'score_M3', 'score_M4',\n                 'score_M5', 'score_M6', 'score_M7', 'score_M8',\n                 'score_M9', 'none', 'offensive', 'hate']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_transformer = Pipeline(steps=[\n    ('col_selector', ColumnSelector(cols=('text'),drop_axis=True)),\n    (\"tfidf\", TfidfVectorizer(\n        min_df = 5, max_df = 0.7, \n        norm = 'l2', analyzer = 'char_wb', ngram_range = (3, 5))),\n])\n\n#   Для численных/бертовых - применяем SimpleImputer,\nbert_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer()),    \n    \n])\n\n# Собираем воедино трансформеры для текстовых и бертовых признаков\ndata_transformer = ColumnTransformer(transformers=[\n    (\"text_fs\", text_transformer, text_features),\n    (\"bert_fs\", bert_transformer, bert_features),\n])\n\n# Создание конвейера препроцессора, который сначала преобразует данные\npreprocessor = Pipeline(steps=[(\"data_transformer\", data_transformer)])\n\nridge_pipline = Pipeline(\n    steps=[(\"preprocessor\", preprocessor), \n           (\"regressor\", Ridge(alpha=1.0))])\n\nridge_pipline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Для сериализации моделей\nimport pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train==True:\n    ridge_pipline.fit(df_train_full.drop('y', axis=1), df_train_full['y'])\n\n    with open(\"owesome_pipeline.pkl\", \"wb\") as f:\n        pickle.dump(ridge_pipline, f)\nelse:\n    with open(\"../input/d/dzisandy/jigsaw-ridge-reg-v1/owesome_pipeline.pkl\", 'rb') as f:\n        ridge_pipline = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridge_pipline['regressor'].coef_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train==False:\n    df['score_rd_big_2'] = ridge_pipline.predict(df_full)\n#     df[['comment_id','score']].to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✅✅✅ 3 Alerons Piplines with Ridge","metadata":{}},{"cell_type":"code","source":"def clean(data, col):\n    \n    def remove_urls (vTEXT):\n        vTEXT = re.sub(r'http\\S+|www\\S+', 'URL', vTEXT)\n        return(vTEXT)\n\n    data[col] = data[col].swifter.swifter.apply(remove_urls)\n    \n    data[col] = data[col].str.replace(r\"-\", \" - \", regex=True)\n    \n    #Removing numbers\n    data[col] = data[col].swifter.swifter.apply(lambda x : ' '.join([tweet for tweet in x.split() if not tweet == '\\d*']))\n    \n        # Remove ip address\n    data[col] = data[col].str.replace(r'(([0-9]+\\.){2,}[0-9]+)',' ', regex=True)\n    # Remove website\n    data[col] = data[col].str.replace(r'https?://\\S+|www\\.\\S+', ' ', regex=True)\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3', regex=True)\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1', regex=True)\n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\'\"]+)',r' \\1 ', regex=True)    \n    # Remove multiple white spaces\n    data[col] = data[col].str.replace(r' +', ' ', regex=True)\n    # Remove html tags\n    data[col] = data[col].str.replace(r'<[^<]+?>', ' ', regex=True)\n    \n    #Code for removing slang words\n    \n    d = {'luv':'love','wud':'would','lyk':'like','wateva':'whatever','ttyl':'talk to you later',\n         'kul':'cool','fyn':'fine','omg':'oh my god!','fam':'family','bruh':'brother',\n         'cud':'could', 'fud':'food'} ## Need a huge dictionary\n        \n    data[col] = data[col].swifter.swifter.apply(lambda x : ' '.join(d[word] if word in d else word for word in x.split()))\n    data[col] = data[col].str.replace(r\"j k\", \"jk\", regex=True)\n    data[col] = data[col].str.replace(r\"e - mail\", \"email\", regex=True)\n    data[col] = data[col].str.replace(r\"\\0s\", \"0\", regex=True)\n    data[col] = data[col].str.replace(r\" 9 11 \", \" 911 \", regex=True)\n    data[col] = data[col].str.replace(r\" e g \", \" eg \", regex=True)\n    data[col] = data[col].str.replace(r\" b g \", \" bg \", regex=True)\n    data[col] = data[col].str.replace(r\" u s \", \" american \", regex=True)\n    data[col] = data[col].str.replace(r\"what's\", \"what is \", regex=True)\n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=True)\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \", regex=True)\n    data[col] = data[col].str.replace(r\"n't\", \" not \", regex=True)\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \", regex=True)\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=True)\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=True)\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=True)\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=True)\n    data[col] = data[col].str.replace(r\"\\'s\", \" \", regex=True)\n    data[col] = data[col].str.replace('\\n', ' \\n ', regex=True)\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)', r'\\1 \\2 \\3', regex=True)\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}', r'\\1\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'([*!?\\']+)', r' \\1 ', regex=True)\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b', r'\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B', r'\\1\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'[ ]{2,}', ' ', regex=True).str.strip()\n    data[col] = data[col].str.replace(r'[ ]{2,}', ' ', regex=True).str.strip()\n\n    def count_urls(text):\n        return text.count('URL')\n    \n    data['URL_count'] = data[col].swifter.swifter.apply(count_urls)\n\n#     data[col] = data[col].swifter.swifter.apply(lambda x: ' '.join([word for word in x.split() if word not in (filtered_stop_word)]))\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from string import punctuation\n\ndef up_low(s):\n    u, l  = sum(1 for i in s if i.isupper()), sum(1 for i in s if i.islower())\n    if l == 0 : l = 1\n    return u/l\n\ndef up_low_word(s):\n    u, l  = sum(1 for i in s.split() if i.isupper()), sum(1 for i in s.split() if i.islower())\n    if l == 0 : l = 1\n    return u/l\n\n\n\n# расстояние левинштейна\n\n\ndef get_toxic_index(text, words = ['fuck', 'bitch', None]):\n    sen_list = sent_tokenize(text)\n    sen_list = [sen.lower() for sen in sen_list]\n    one_word_sum = 0\n    sent_words = len(text.split())\n    text = text.lower()\n    for word in words:\n        one_word_sum += text.count(word)/sent_words*np.log(1 + (len(sen_list)+1)/(sum(1 for sen in sen_list if sen.count(word))+1))\n#         one_word_sum += sum(sen.lower().count(word)/len(sen.split()) for sen in sen_list)*np.log(1 + (len(sen_list)+1)/(sum(1 for sen in sen_list if sen.lower().count(word))+1))\n    return one_word_sum\n\n\ndef make_features(df, target = 'text', show_fs=False):\n    \n    col_before = df.columns\n    \n    df['sentence_count'] = df[target].swifter.apply(lambda x : len(sent_tokenize(x)))\n    df['upper_on_lower'] = df[target].swifter.apply(up_low)\n    df['upper_on_lower_word'] = df[target].swifter.apply(up_low_word)\n    df['len_text'] = df[target].swifter.apply(lambda x : len(x)//30)\n    df['size_punct'] = df[target].swifter.apply(lambda x : sum(1 for i in x if i in punctuation)) # Надо сколько именно слов, не символов\n    df['size_letter'] = df[target].swifter.apply(lambda x : sum(1 for i in x if i not in punctuation))\n    df['punct_on_letter'] = df['size_punct'].values/df['size_letter'].values\n    df.drop(['size_letter', 'size_punct'], axis=1, inplace=True)\n#     df['mean_word_len'] = df[target].swifter.apply(lambda x : sum(len(i)//3 for i in x.split())/len(x.split()))\n    df['words'] = df[target].swifter.apply(lambda x : sum(1 for i in x.split())/len(x))\n    df['ques_punct_on_word'] = df[target].swifter.apply(lambda x : 100*sum(1 for i in x if i in '?')/len(x))\n    df['state_punct_on_word'] = df[target].swifter.apply(lambda x : 100*sum(1 for i in x if i in '!')/len(x))\n    df['duble_state_punct_on_word'] = df[target].swifter.apply(lambda x : 100*sum(1 for i in x if i in '!!')/len(x))\n    df['snow_punct_on_word'] = df[target].swifter.apply(lambda x : 100*sum(1 for i in x if i in '*')/len(x))\n    df['uniq_word_on_sentence'] = df[target].swifter.apply(lambda x : len(set(x.split()))/len(x.split()))*df['sentence_count'].values\n    df['haha_pattern'] = df[target].swifter.apply(lambda x : x.lower().count('hah')/len(x.split()))*df['sentence_count'].values\n    df['fuck_pattern'] = df[target].swifter.apply(lambda x : x.lower().count('fuck')/len(x.split()))*df['sentence_count'].values\n    df['off_pattern'] = df[target].swifter.apply(lambda x : x.lower().count('off')/len(x.split()))*df['sentence_count'].values\n    df['ques_pattern'] = df[target].swifter.apply(lambda x : x.count('???')/len(x.split()))*df['sentence_count'].values\n    df['you_pattern'] = df[target].swifter.apply(lambda x : x.lower().count(' you')/len(x.split()))*df['sentence_count'].values\n    ################################\n    \n    # Правильная нормировка \n#     df['sentence_count']\n\n#     df[target] = df[target].swifter.apply(get_toxic_index, words = words)\n    ###############################\n    # TODO ur\n    df['u_pattern'] = df[target].swifter.apply(lambda x : len(x.lower().split(' u '))/len(x.split()))\n    \n    you_are_patterns = ['you are', 'you ar ', 'you re ', 'u are ', ' u r ', ' are you', ' ur ', \"you ' re\", \"you're\", 'youre',\n                        'you will', \"you'll\", \"you ' ll\", 'u will'] \n    \n#     df['you_are_patterns'] = df[target].swifter.apply(lambda x : sum(len(x.split(i)) for i in you_are_patterns )/len(x.split()))*df['sentence_count'].values\n    df['you_are_patterns'] = df[target].swifter.apply(get_toxic_index, words = you_are_patterns)\n    \n    \n    hide_punct_pattern = '*&%$#@'\n#     df['hide_punct_pattern'] = df[target].swifter.apply(lambda x : sum(x.count(i) for i in hide_punct_pattern )/len(x.split()))*df['sentence_count'].values\n    df['hide_punct_pattern'] = df[target].swifter.apply(get_toxic_index, words = hide_punct_pattern)\n\n    penis_pattern = ['dick','diick', 'penis', 'sock','suck', 'cock', 'balls', ' ball', 'bell', 'phallus','condone',\n                     'sucker', 'suker', 'penes', 'prick', 'pecker', 'dildo']\n#     df['penis_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in penis_pattern)/len(x.split()))*df['sentence_count'].values\n    df['penis_pattern'] = df[target].swifter.apply(get_toxic_index, words = penis_pattern)\n    \n    fucking_pattern = ['fuck', '*uck', 'f*ck', 'fu*k', 'fuc*','f**k','f ** k', 'fucck','fcuken','fcken','ruck', 'f *** ing', 'sh * t', 'sh*t','s**t', 'fukk', 'fricki',\n                       'f***', 'f ** ck', 'f * ck', 'b ** ch','b * ch']\n#     df['fucking_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in fucking_pattern)/len(x.split()))*df['sentence_count'].values  \n    df['fucking_pattern'] = df[target].swifter.apply(get_toxic_index, words = fucking_pattern)\n    \n    virgin_pattern = ['virgin', 'slut', 'whore', 'prostitut', 'bitch', 'biatch', 'hooker','pussy', 'beetch', 'bithc', 'butch']\n#     df['virgin_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in virgin_pattern)/len(x.split()))*df['sentence_count'].values \n    df['virgin_pattern'] = df[target].swifter.apply(get_toxic_index, words = virgin_pattern)\n    \n    dubble_word_pattern = ['buttseck', 'dumbass', 'asshole', 'arsehole', 'cocksucker', 'asscake', 'jackass']\n#     df['dubble_word_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in dubble_word_pattern)/len(x.split()))*df['sentence_count'].values\n    df['dubble_word_pattern'] = df[target].swifter.apply(get_toxic_index, words = dubble_word_pattern)\n    \n    funny_pattern = ['glad', 'happy', 'hilarious', 'fanny', 'humor']\n#     df['funny_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in funny_pattern)/len(x.split()))*df['sentence_count'].values\n    df['funny_pattern'] = df[target].swifter.apply(get_toxic_index, words = funny_pattern)\n    \n   # ДОбавить поправку растояния левенштена                                                                       \n    toxic_words = ['ass', 'a$$', 'hole', 'drool', 'anal', 'pedo', 'poopie', 'hose', 'berk', 'duffer', 'pillock', 'plonker', 'wally',\n                   'knobend', 'rotter', 'swine', 'blighter', ' cad', 'idiot', 'faggot', 'clown', 'tosser', 'cunt', 'arrogant', 'freak', 'dude',  \n                   'ugly', 'little', 'fat', 'liar', 'heck', 'vandal', 'nerd','stubborn']\n#     df['toxic_word_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in toxic_words)/len(x.split()))*df['sentence_count'].values \n    df['toxic_word_pattern'] = df[target].swifter.apply(get_toxic_index, words = toxic_words)    \n        \n    yeald_pattern = ['ggg','uuu','aaa', 'hhh', 'eee','ooo','!!!','???', '!?!', '!??']\n#     df['yeald_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in yeald_pattern)/len(x.split()))*df['sentence_count'].values    \n    df['yeald_pattern'] = df[target].swifter.apply(get_toxic_index, words = yeald_pattern)    \n        \n    noncence_toxic = ['poo', 'poop', 'poopy', 'butt','piss','shit','shut', 'testicles', 'bollocks', 'heresy', 'absurd', 'nonsense', 'crud','crap']\n#     df['noncence_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in noncence_toxic)/len(x.split()))*df['sentence_count'].values\n    df['noncence_toxic'] = df[target].swifter.apply(get_toxic_index, words = noncence_toxic)\n    \n    long_phase_pattern = ['fuck all', 'piss off', 'fuck off', 'get off', 'stay off', 'shut up', 'god damn', 'damn it', 'who care', 'kiss off', 'fuck–up', 'fuck up', 'bang up']\n#     df['long_phase_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in long_phase_pattern)/len(x.split()))*df['sentence_count'].values\n    df['long_phase_pattern'] = df[target].swifter.apply(get_toxic_index, words = long_phase_pattern)\n\n    child_toxic = ['holy', 'moly', 'jeepers', 'good', 'heavens', 'gosh', 'fiddlesticks', 'poppycock']\n#     df['child_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in child_toxic)/len(x.split()))*df['sentence_count'].values\n    df['child_toxic'] = df[target].swifter.apply(get_toxic_index, words = child_toxic)\n\n    more_toxic_word = ['damn', 'whore', 'hoe', 'jade', 'jerk', 'moron', \n                       'douchebag', 'dork', 'faggot', 'fag', 'queer', 'pirate', 'candyass',\n                       'finook', 'capon', 'butter', 'boy', 'banana', 'crammer', 'nancy', 'pansy', 'scumbag', 'scum', 'prat', 'brat', 'loser',\n                       'sack', 'goof', 'wanker', 'noob', 'retard', 'numbnuts', 'shitbox']\n#     df['more_toxic_word'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in more_toxic_word)/len(x.split()))*df['sentence_count'].values\n    df['more_toxic_word'] = df[target].swifter.apply(get_toxic_index, words = more_toxic_word)\n    \n    light_level_toxic  = ['arse', 'bloody', 'hell', 'bugger', 'damn', 'minger', 'sod-off']\n#     df['light_level_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in light_level_toxic)/len(x.split()))*df['sentence_count'].values\n    df['light_level_toxic'] = df[target].swifter.apply(get_toxic_index, words = light_level_toxic)\n    \n    middle_level_toxic = ['shit', 'son of a bitch', 'arsehole', 'balls', 'bint', 'bollocks', 'bullshit', 'feck', 'munter', 'pissed', 'pissed off']\n#     df['middle_level_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in middle_level_toxic)/len(x.split()))*df['sentence_count'].values\n    df['middle_level_toxic'] = df[target].swifter.apply(get_toxic_index, words = middle_level_toxic)\n    \n    hard_level_toxic  = ['bastard', 'dickhead', 'bloodclaat', 'jamaican', 'knob', 'prick', 'bellend',\n                        'minge', 'twat', 'twunt', 'beaver', 'curtains', 'beef', 'clunge', 'snatch', 'punani', 'gash']\n#     df['hard_level_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in hard_level_toxic)/len(x.split()))*df['sentence_count'].values\n    df['hard_level_toxic'] = df[target].swifter.apply(get_toxic_index, words = hard_level_toxic)\n    \n    very_hard_level_toxic  = ['cunt', 'fuck', 'motherfucker', 'motherfudger', 'mother fudger']\n#     df['very_hard_level_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in very_hard_level_toxic)/len(x.split()))*df['sentence_count'].values\n    df['very_hard_level_toxic'] = df[target].swifter.apply(get_toxic_index, words = very_hard_level_toxic)\n    \n    very_very_hard_level_toxic  = ['felch' ,'skullfuck', 'fuck puppet', 'bisnotch', 'rusty trombone']\n#     df['very_very_hard_level_toxic'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in very_very_hard_level_toxic)/len(x.split()))*df['sentence_count'].values\n    df['very_very_hard_level_toxic'] = df[target].swifter.apply(get_toxic_index, words = very_very_hard_level_toxic)\n    \n    away_patterns  = [' out ', 'away ', ' off ' ,' up ', ' down ', 'm done']\n#     df['away_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in away_patterns)/len(x.split()))*df['sentence_count'].values\n    df['away_patterns'] = df[target].swifter.apply(get_toxic_index, words = away_patterns) \n        \n    synon_toxic_words = ['jerk', 'stinker', 'heck', 'crud', 'schmuck', 'riffraff']    \n#     df['synon_toxic_words'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in synon_toxic_words)/len(x.split()))*df['sentence_count'].values\n    df['synon_toxic_words'] = df[target].swifter.apply(get_toxic_index, words = synon_toxic_words)\n    \n    lgbt_pattern = [ 'gay', 'homosexual', 'hetero', ' lgbt', 'bisexual', 'lesbian', 'queer']\n#     df['lgbt_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in lgbt_pattern)/len(x.split()))*df['sentence_count'].values\n    df['lgbt_pattern'] = df[target].swifter.apply(get_toxic_index, words = lgbt_pattern)\n    \n    descrimination_pattern = ['racist', 'nazi', 'antic', 'commie',  'discriminat', 'female', 'troll', 'abusing', 'nigger', 'nigga', 'jew',\n                            'fascist', 'haras', 'racism', 'bigot', 'gosh', 'kike', 'slave', 'victim', ]\n#     df['descrimination_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in descrimination_pattern)/len(x.split()))*df['sentence_count'].values\n    df['descrimination_pattern'] = df[target].swifter.apply(get_toxic_index, words = descrimination_pattern)\n    \n    god_pattern = ['catholic', 'god','religi', 'islam', 'bibl', 'muslim', 'atheist']\n#     df['god_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in god_pattern)/len(x.split()))*df['sentence_count'].values\n    df['god_pattern'] = df[target].swifter.apply(get_toxic_index, words = god_pattern)\n    \n    animal_pattern = ['monkey', 'horse', 'pig', 'animal', 'dog', 'bull', ' swine', ' pork', 'llama','skunk','racooon', 'raccoon', 'racoon', ' coon',\n                    'bat', 'bird', 'chicken', 'duck', 'goose', 'weasel', ' swan', 'dog', 'donkey', 'goat', ' rat', 'sheep']\n#     df['animal_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in animal_pattern)/len(x.split()))*df['sentence_count'].values\n    df['animal_pattern'] = df[target].swifter.apply(get_toxic_index, words = animal_pattern)\n    \n    slang_pattern = [' u ', ' ur ', 'cuz']\n#     df['slang_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in slang_pattern)/len(x.split()))*df['sentence_count'].values\n    df['slang_pattern'] = df[target].swifter.apply(get_toxic_index, words = slang_pattern)\n    \n    body_pattern = ['tits', 'mouth', 'body', 'face',  'head', ' boob', 'oral']  \n#     df['body_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in body_pattern)/len(x.split()))*df['sentence_count'].values\n    df['body_pattern'] = df[target].swifter.apply(get_toxic_index, words = body_pattern)\n    \n    not_good_words = ['rude', 'stuck', 'porn', 'mug', 'sex', 'shame', 'gang', 'bang', 'wanker']  \n#     df['not_good_words'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in not_good_words)/len(x.split()))*df['sentence_count'].values\n    df['not_good_words'] = df[target].swifter.apply(get_toxic_index, words = not_good_words)\n    \n    threat_pattern = ['going', 'wanna', 'will', 'threat', 'barbarian', 'savage', 'insult', 'rape',]\n#     df['threat_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in threat_pattern)/len(x.split()))*df['sentence_count'].values\n    df['threat_pattern'] = df[target].swifter.apply(get_toxic_index, words = threat_pattern)\n    \n    hard_threat_words = ['xenocidic', 'terrorist', 'akbar', 'dangerous', 'genocide', 'holocaust']\n#     df['hard_threat_words'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in hard_threat_words)/len(x.split()))*df['sentence_count'].values\n    df['hard_threat_words'] = df[target].swifter.apply(get_toxic_index, words = hard_threat_words)\n    \n    stop_pattern = ['delet', 'destroy', ' bann', 'block',  'stop', 'quit', 'unblock', 'attack', 'remove']\n#     df['stop_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in stop_pattern)/len(x.split()))*df['sentence_count'].values\n    df['stop_pattern'] = df[target].swifter.apply(get_toxic_index, words = stop_pattern)\n    \n    mom_pattern = [' mom ', 'mother', ' moth ', ' mum ', 'mothefucker', ' milf', ]  \n#     df['mom_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in mom_pattern)/len(x.split()))*df['sentence_count'].values\n    df['mom_pattern'] = df[target].swifter.apply(get_toxic_index, words = mom_pattern)\n    \n    brother_pattern = [' son ', 'son of', 'children', 'cousin', 'kids', 'baby', 'brother', 'father','family', 'daugher', 'sister']  \n#     df['brother_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in brother_pattern)/len(x.split()))*df['sentence_count'].values\n    df['brother_pattern'] = df[target].swifter.apply(get_toxic_index, words = brother_pattern)\n    \n    mental_pattern = ['retard', 'mind', 'mental', 'brain', 'stupid', 'silly', 'fool', 'dumb', 'meatball', 'numnut',\n                      'paranoid', 'mad', 'crazy', 'insane', 'frantic', 'reckless', 'lunatic', 'sick']  \n#     df['mental_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in mental_pattern)/len(x.split()))*df['sentence_count'].values\n    df['mental_pattern'] = df[target].swifter.apply(get_toxic_index, words = mental_pattern)\n    \n    negative_pattern = ['horrible', 'coward', 'crack','less','dart','hate', 'annoy', 'hurt', 'demon',\n                        'pain', 'dead', ' die',' death', 'satan', 'terrible', 'awful', 'spam', 'avil']\n#     df['negative_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in negative_pattern)/len(x.split()))*df['sentence_count'].values   \n    df['negative_pattern'] = df[target].swifter.apply(get_toxic_index, words = negative_pattern)\n    \n    negative_verb_pattern = ['smell', 'stink', ' reek', ' hum']\n#     df['negative_verb_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in negative_verb_pattern)/len(x.split()))*df['sentence_count'].values    \n    df['negative_verb_pattern'] = df[target].swifter.apply(get_toxic_index, words = negative_verb_pattern)\n    \n    ill_pattern = [ 'canser', 'coward', 'disease', 'slave', 'bizarre', 'anorexic', ' cry', 'obese', 'fart','garbage']\n#     df['ill_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in ill_pattern)/len(x.split()))*df['sentence_count'].values\n    df['ill_pattern'] = df[target].swifter.apply(get_toxic_index, words = ill_pattern)\n    \n    crime_pattern = ['warmonger', 'pedophile', 'kill', 'murder', 'vandal', 'crime', 'fraud', 'scam', 'gulty', 'speculat']\n#     df['crime_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in crime_pattern)/len(x.split()))*df['sentence_count'].values\n    df['crime_pattern'] = df[target].swifter.apply(get_toxic_index, words = crime_pattern)\n    \n    nasty_pattern = ['nasty', 'bad ', 'black', 'filth', 'horrible','horror','suicid', 'masturb', 'disgust', 'slime', 'slur']\n#     df['nasty_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in nasty_pattern)/len(x.split()))*df['sentence_count'].values\n    df['nasty_pattern'] = df[target].swifter.apply(get_toxic_index, words = nasty_pattern)\n    \n    talkative_pattern = ['talker', 'chatterbox', 'windbag', 'babbler', 'gossip', 'jay'] \n#     df['talkative_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in talkative_pattern)/len(x.split()))*df['sentence_count'].values\n    df['talkative_pattern'] = df[target].swifter.apply(get_toxic_index, words = talkative_pattern)\n    \n    target_pattern = ['self', 'selves'] \n#     df['target_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in target_pattern)/len(x.split()))*df['sentence_count'].values\n    df['target_pattern'] = df[target].swifter.apply(get_toxic_index, words = target_pattern)\n    \n    WTF_pattern = ['what the', 'wtf', 'omfg', 'why the'] \n#     df['WTF_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in WTF_pattern)/len(x.split()))*df['sentence_count'].values\n    df['WTF_pattern'] = df[target].swifter.apply(get_toxic_index, words = WTF_pattern)\n    \n    country_pattern = ['moldavian', 'iraq', 'egypt','romanian','countr', 'israel', 'russia', 'europa', 'america', 'livin',  'arab','chinese','czech',\n                       'china', 'spain', 'germanic', 'germany', 'poland','texas', 'russkie', 'france', 'armenia', 'rebublic', 'macedonia', 'bulgar',\n                       'albania',' turk', 'london','greek', 'natioa', 'population', 'india', 'hindu', 'turk', 'saudi', 'pakistan'] \n#     df['country_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in country_pattern)/len(x.split()))*df['sentence_count'].values\n    df['country_pattern'] = df[target].swifter.apply(get_toxic_index, words = country_pattern)\n    \n    politics_pattern = ['putin', 'bush', 'abama', 'trump', 'stalin', 'kgb', 'saddam', 'hussein', 'politic', 'president', 'cult',\n                        'anarchist', 'osama bin', 'hitler', ' war', ' fbi', 'lenin', 'biden', 'liberal', 'propagand']  \n#     df['politics_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in politics_pattern)/len(x.split()))*df['sentence_count'].values\n    df['politics_pattern'] = df[target].swifter.apply(get_toxic_index, words = politics_pattern)\n    \n    NO_pattern = [' no', 'nooo', 'not','nor', 'none', 'no one', 'nobody', 'nothing', 'neither', 'nowhere', 'never', 'negative', ' un-', 'anti', 'pseudo'] \n#     df['NO_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in NO_pattern)/len(x.split()))*df['sentence_count'].values\n    df['NO_pattern'] = df[target].swifter.apply(get_toxic_index, words = NO_pattern)\n    \n    NO_verb_pattern = [\"do't\", \"do ' t\", 'doesn’t', 'isn’t', 'wasn’t', 'shouldn’t', 'wouldn’t', \"couldn’t\", \"can't\", \"can ' t\", \"cant\"] \n#     df['NO_verb_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in NO_verb_pattern)/len(x.split()))*df['sentence_count'].values\n    df['NO_verb_pattern'] = df[target].swifter.apply(get_toxic_index, words = NO_verb_pattern)\n    \n    max_pattern = [\"all!\", 'every', 'any', 'too ', 'such', 'very'] \n#     df['max_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in max_pattern)/len(x.split()))*df['sentence_count'].values\n    df['max_pattern'] = df[target].swifter.apply(get_toxic_index, words = max_pattern)\n    \n    thanks_pattern = [\"sorry\", \" thank\", 'thx', 'hello', 'hey']  \n#     df['thanks_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in thanks_pattern)/len(x.split()))*df['sentence_count'].values\n    df['thanks_pattern'] = df[target].swifter.apply(get_toxic_index, words = thanks_pattern)\n    \n    positive_pattern = [\"well\", \"nice\", 'good', 'cool'] \n#     df['positive_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in positive_pattern)/len(x.split()))*df['sentence_count'].values\n    df['positive_pattern'] = df[target].swifter.apply(get_toxic_index, words = positive_pattern)\n    \n    weapon_pattern = [\"gun\", \"weapon\", 'rocket', 'shoot', 'bomb'] \n#     df['weapon_pattern'] = df[target].swifter.apply(lambda x : sum(x.lower().count(word) for word in weapon_pattern)/len(x.split()))*df['sentence_count'].values\n    df['weapon_pattern'] = df[target].swifter.apply(get_toxic_index, words = weapon_pattern)\n\n    new_features = [i for i in df.columns if i not in col_before]\n    \n    if show_fs: print('new_features', len(new_features), new_features)\n    \n    return df, new_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/big-ridge-piplines/pipeline.pkl\", 'rb') as f:\n    ridge_pipline_1 = pickle.load(f)\n    \nwith open(\"../input/big-ridge-piplines/ridge_pipeline_1.pkl\", 'rb') as f:\n    ridge_pipline_2 = pickle.load(f)\n    \nwith open(\"../input/big-ridge-piplines/ridge_pipeline_2.pkl\", 'rb') as f:\n    ridge_pipline_3 = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\n\ndf_test, _ = make_features(df_test, target = 'text')\ndf_test = clean(df_test, 'text')\ncoms_id = df_test.comment_id.values\ndf_test.drop('comment_id', axis=1, inplace=True)\n\nm1_preds = ridge_pipline_1.predict(df_test)\n\ndf['score_M11'] = rankdata(m1_preds, method='ordinal') # m1_preds\n# df_test['comment_id'] = coms_id\n\n\n# with open(\"pipeline.pkl\", \"wb\") as f:\n#     pickle.dump(pipeline, f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jr_preds=ridge_pipeline_2.predict(df_test)\ndf['score_M12']=rankdata(jr_preds, method='ordinal') \n\nwith open(\"ridge_pipeline_1.pkl\", \"wb\") as f:\n    pickle.dump(ridge_pipeline_1, f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jr_preds=ridge_pipeline_3.predict(df_test)\ndf['score_M13']=rankdata(jr_preds, method='ordinal') \n\nwith open(\"ridge_pipeline_1.pkl\", \"wb\") as f:\n    pickle.dump(ridge_pipeline_1, f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Final blend two big Ridges\n","metadata":{}},{"cell_type":"code","source":"if train==False:\n    df['score_rd_big_2'] = ridge_pipline.predict(df_full)\n#     df[['comment_id','score']].to_csv('submission.csv', index=False)\n\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if train==False:\ndf['score'] = df['score_rd_big_2'].values + df['score_M11'].values + df['score_M12'].values + df['score_M13'].values\ndf[['comment_id','score']].to_csv('submission.csv', index=False)\n\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ❎ Блендинг","metadata":{}},{"cell_type":"code","source":"# weights = {#'score_M1': 1,\n#           'score_M2': 1,\n#           'score_M3': 1,\n#           'score_M4': 1,\n#           'score_M5': 1,\n#           'score_M6': 1,\n#           'score_M7': 1,\n#           'score_M8': 1,\n# #           'score_M9': 1\n#           }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Подозрительно, что среденее по score_M1 не ноль. =>  Убрал пока из прогноза \n# df[['score_M1','score_M2','score_M3','score_M4','score_M5','score_M6','score_M7', 'score_M8', 'score_M9']].mean(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for mod, weight in weights.items():\n#     df[mod] = df[mod].rank()*weight\n    \n# df['score'] = df[weights.keys()].sum(axis=1).rank(method='max')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[['comment_id','score']].to_csv('submission.csv', index=False)\n# df[['comment_id','score']].sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}