{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ☣️ Jigsaw - HuggingFace Hub Baselines\n\nIn this notebook I will explore, without fine-tuning, various models from the huggingface hub.\nI am bringing them to kaggle as datasets in the process.\n\nThere are various that were already trained for other Jigsaw competitions. \n\n\n\n|Version | Model | Validation (first 5000 samples) | LB |\n|---| ---   | ---: | --- |\n|V1 | [toxic-bert](https://www.kaggle.com/julian3833/toxic-bert) | `0.71` | __ |\n","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = \"../input/toxic-bert\"\nMAX_LENGTH = 192\n\nDO_VALIDATE = False\nVALIDATION_SIZE = 5000","metadata":{"execution":{"iopub.status.busy":"2021-11-13T04:12:42.979347Z","iopub.execute_input":"2021-11-13T04:12:42.979632Z","iopub.status.idle":"2021-11-13T04:12:42.983289Z","shell.execute_reply.started":"2021-11-13T04:12:42.979594Z","shell.execute_reply":"2021-11-13T04:12:42.982652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test and Validation Dataset","metadata":{}},{"cell_type":"code","source":"class Dataset:\n    \"\"\"\n    For comments_to_score.csv (the submission), get only one comment per row\n    \"\"\"\n    def __init__(self, text, tokenizer, max_len):\n        self.text = text\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        text = str(self.text[item])\n        inputs = self.tokenizer(\n            text, \n            max_length=self.max_len, \n            padding=\"max_length\", \n            truncation=True\n        )\n\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"attention_mask\": torch.tensor(mask, dtype=torch.long)\n        }\n    \n    \nclass ValidationDataset:\n    \"\"\"\n    Goes through validation_data.csv, Loading and tokenizing both less_toxic and more_toxic\n    \n    Inspired by: https://www.kaggle.com/debarshichanda/pytorch-w-b-jigsaw-starter\n    \"\"\"\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.df)\n\n    def tokenize(self, text):\n        return self.tokenizer(text, max_length=self.max_len, \n                              padding=\"max_length\", truncation=True)\n    \n    def __getitem__(self, i):\n        more_toxic = self.df['more_toxic'].iloc[i]\n        less_toxic = self.df['less_toxic'].iloc[i]\n        \n        less_inputs = self.tokenize(less_toxic)\n        more_inputs = self.tokenize(more_toxic)\n\n        return {\n            \"less_input_ids\": torch.tensor(less_inputs[\"input_ids\"], dtype=torch.long),\n            \"less_attention_mask\": torch.tensor(less_inputs[\"attention_mask\"], dtype=torch.long),\n            \"more_input_ids\": torch.tensor(more_inputs[\"input_ids\"], dtype=torch.long),\n            \"more_attention_mask\": torch.tensor(more_inputs[\"attention_mask\"], dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-13T04:16:00.168948Z","iopub.execute_input":"2021-11-13T04:16:00.169271Z","iopub.status.idle":"2021-11-13T04:16:00.184475Z","shell.execute_reply.started":"2021-11-13T04:16:00.16923Z","shell.execute_reply":"2021-11-13T04:16:00.183674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation\n","metadata":{}},{"cell_type":"code","source":"def validate(model_path, max_len):\n    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    model.to(\"cuda\")\n    model.eval()\n    \n    df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\", nrows=VALIDATION_SIZE)\n    \n    dataset = ValidationDataset(df=df, tokenizer=tokenizer, max_len=max_len)\n    data_loader = torch.utils.data.DataLoader(\n        dataset, batch_size=16, num_workers=4, pin_memory=True, shuffle=False\n    )\n\n    n_samples = len(dataset)\n    hits = 0\n    \n    for data in data_loader:\n        with torch.no_grad():\n            for key, value in data.items():\n                data[key] = value.to(\"cuda\")\n            less_output = model(input_ids=data['less_input_ids'], \n                                attention_mask=data['less_attention_mask'])\n            \n            more_output = model(input_ids=data['more_input_ids'], \n                                attention_mask=data['more_attention_mask'])\n            \n            # Sum the logits of the 6 toxic labels\n            less_score = less_output.logits.sum(dim=1)\n            more_score = more_output.logits.sum(dim=1)\n            \n            hits += (less_score < more_score).sum().item()\n    \n    \n    accuracy = hits / n_samples\n    print(f\"Validation Accuracy: {accuracy:4.2f}\")\n    \n    torch.cuda.empty_cache()\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2021-11-13T04:12:43.002476Z","iopub.execute_input":"2021-11-13T04:12:43.003053Z","iopub.status.idle":"2021-11-13T04:12:43.01479Z","shell.execute_reply.started":"2021-11-13T04:12:43.003013Z","shell.execute_reply":"2021-11-13T04:12:43.014108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DO_VALIDATE:\n    validate(MODEL_PATH, max_len=MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T04:12:43.016262Z","iopub.execute_input":"2021-11-13T04:12:43.016794Z","iopub.status.idle":"2021-11-13T04:12:43.02677Z","shell.execute_reply.started":"2021-11-13T04:12:43.016756Z","shell.execute_reply":"2021-11-13T04:12:43.026115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction\n\nAdapted from [AutoNLP for toxic ratings ;)](https://www.kaggle.com/abhishek/autonlp-for-toxic-ratings) by Abhishek.","metadata":{}},{"cell_type":"code","source":"def generate_predictions(model_path, max_len):\n    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    model.to(\"cuda\")\n    model.eval()\n    \n    df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n    \n    dataset = Dataset(text=df.text.values, tokenizer=tokenizer, max_len=max_len)\n    data_loader = torch.utils.data.DataLoader(\n        dataset, batch_size=16, num_workers=4, pin_memory=True, shuffle=False\n    )\n\n    final_output = []\n\n    for data in data_loader:\n        with torch.no_grad():\n            for key, value in data.items():\n                data[key] = value.to(\"cuda\")\n            output = model(**data)\n            output = output.logits.sum(dim=1).detach().cpu().numpy().tolist()\n            final_output.extend(output)\n    \n    torch.cuda.empty_cache()\n    return np.array(final_output)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T04:12:43.028005Z","iopub.execute_input":"2021-11-13T04:12:43.028548Z","iopub.status.idle":"2021-11-13T04:12:43.037678Z","shell.execute_reply.started":"2021-11-13T04:12:43.028513Z","shell.execute_reply":"2021-11-13T04:12:43.036938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"preds = generate_predictions(MODEL_PATH, max_len=MAX_LENGTH)\n\nsub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nsub[\"score\"] = preds\nsub = sub[[\"comment_id\", \"score\"]]\nsub.to_csv(\"submission.csv\", index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T04:12:43.039011Z","iopub.execute_input":"2021-11-13T04:12:43.039742Z","iopub.status.idle":"2021-11-13T04:13:41.106626Z","shell.execute_reply.started":"2021-11-13T04:12:43.039655Z","shell.execute_reply":"2021-11-13T04:13:41.105749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}}]}