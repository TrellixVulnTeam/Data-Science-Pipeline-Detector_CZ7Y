{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport re\nfrom bs4 import BeautifulSoup\nimport os\nimport random\nimport joblib\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import KFold, cross_val_score\n\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\n\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-06T12:09:50.282812Z","iopub.execute_input":"2021-12-06T12:09:50.283396Z","iopub.status.idle":"2021-12-06T12:09:50.763749Z","shell.execute_reply.started":"2021-12-06T12:09:50.283349Z","shell.execute_reply":"2021-12-06T12:09:50.762758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DATA_PATH = '../input/jigsaw-toxic-severity-rating/comments_to_score.csv'\nVALID_DATA_PATH = '../input/jigsaw-toxic-severity-rating/validation_data.csv'\nTRAIN_DATA_PATH = '../input/jigsaw-toxic-comment-classification-challenge/train.csv'","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:12:27.803823Z","iopub.execute_input":"2021-12-06T12:12:27.804145Z","iopub.status.idle":"2021-12-06T12:12:27.808964Z","shell.execute_reply.started":"2021-12-06T12:12:27.804114Z","shell.execute_reply":"2021-12-06T12:12:27.808103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 10\nMAX_FEATURES = 10_000","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:10:03.496318Z","iopub.execute_input":"2021-12-06T12:10:03.496611Z","iopub.status.idle":"2021-12-06T12:10:03.501044Z","shell.execute_reply.started":"2021-12-06T12:10:03.49658Z","shell.execute_reply":"2021-12-06T12:10:03.500043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n    \n    \ndef text_cleaning(text: str) -> str:\n    \"\"\"Function cleans text removing special characters,\n    extra spaces, embedded URL links, HTML tags and emojis.\n    Code source: https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-infer\n    :param text: Original text\n    :return: Preprocessed text\n    \"\"\"\n    template = re.compile(r'https?://\\S+|www\\.\\S+')  # website links\n    text = template.sub(r'', text)\n\n    soup = BeautifulSoup(text, 'lxml')  # HTML tags\n    only_text = soup.get_text()\n    text = only_text\n\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n\n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text)  # special characters\n    text = re.sub(' +', ' ', text)  # extra spaces\n    text = text.strip()  # spaces at the beginning and at the end of string\n\n    return text","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-06T12:10:22.003006Z","iopub.execute_input":"2021-12-06T12:10:22.003469Z","iopub.status.idle":"2021-12-06T12:10:22.013149Z","shell.execute_reply.started":"2021-12-06T12:10:22.003418Z","shell.execute_reply":"2021-12-06T12:10:22.012393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(SEED)\nset_display()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:10:36.306537Z","iopub.execute_input":"2021-12-06T12:10:36.308649Z","iopub.status.idle":"2021-12-06T12:10:36.313043Z","shell.execute_reply.started":"2021-12-06T12:10:36.308604Z","shell.execute_reply":"2021-12-06T12:10:36.311973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract classified text samples and clean the texts.\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\ndata_train['comment_text'] = data_train['comment_text'].apply(text_cleaning)\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:12:32.320762Z","iopub.execute_input":"2021-12-06T12:12:32.321039Z","iopub.status.idle":"2021-12-06T12:13:23.393461Z","shell.execute_reply.started":"2021-12-06T12:12:32.321009Z","shell.execute_reply":"2021-12-06T12:13:23.392699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = data_train.loc[:, 'toxic':'identity_hate'].sum()\nplt.title('Category Frequency')\nplt.bar(categories.index, categories.values)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:14:28.671052Z","iopub.execute_input":"2021-12-06T12:14:28.67139Z","iopub.status.idle":"2021-12-06T12:14:28.935339Z","shell.execute_reply.started":"2021-12-06T12:14:28.67136Z","shell.execute_reply":"2021-12-06T12:14:28.934559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = data_train.loc[:, 'toxic':'identity_hate'].sum(axis=1).value_counts()\nplt.bar(scores.index, scores.values)\nplt.title('Scores Distribution: Simple Sum')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:14:43.225979Z","iopub.execute_input":"2021-12-06T12:14:43.22803Z","iopub.status.idle":"2021-12-06T12:14:43.465555Z","shell.execute_reply.started":"2021-12-06T12:14:43.227989Z","shell.execute_reply":"2021-12-06T12:14:43.464863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiplication factors for categories.\ncat_mtpl = {'toxic': 1, 'severe_toxic': 1.75, 'obscene': 0.95,\n            'threat': 2, 'insult': 1.6, 'identity_hate': 1.95}\n\nfor category in cat_mtpl:\n    data_train[category] = data_train[category] * cat_mtpl[category]\n\ndata_train['score'] = data_train.loc[:, 'toxic':'identity_hate'].sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:15:44.465838Z","iopub.execute_input":"2021-12-06T12:15:44.466495Z","iopub.status.idle":"2021-12-06T12:15:44.507688Z","shell.execute_reply.started":"2021-12-06T12:15:44.466454Z","shell.execute_reply":"2021-12-06T12:15:44.506971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(data_train['score'])\nplt.title('Scores Distribution: Adjusted Sum')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:15:55.019366Z","iopub.execute_input":"2021-12-06T12:15:55.019646Z","iopub.status.idle":"2021-12-06T12:15:55.243951Z","shell.execute_reply.started":"2021-12-06T12:15:55.019617Z","shell.execute_reply":"2021-12-06T12:15:55.24328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples_toxic = len(data_train[data_train['score'] != 0])\nn_samples_normal = len(data_train) - n_samples_toxic\n\nidx_to_drop = data_train[data_train['score'] == 0].index[n_samples_toxic//5:]\ndata_train = data_train.drop(idx_to_drop)\n\nprint(f'Reduced number of neutral text samples from {n_samples_normal} to {n_samples_toxic//5}.')\nprint(f'Total number of training samples: {len(data_train)}')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:16:15.373613Z","iopub.execute_input":"2021-12-06T12:16:15.37414Z","iopub.status.idle":"2021-12-06T12:16:15.460238Z","shell.execute_reply.started":"2021-12-06T12:16:15.374099Z","shell.execute_reply":"2021-12-06T12:16:15.459358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Mean toxicity score: {data_train[\"score\"].mean()}\\n'\n      f'Standard deviation: {data_train[\"score\"].std()}')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:16:27.895166Z","iopub.execute_input":"2021-12-06T12:16:27.895988Z","iopub.status.idle":"2021-12-06T12:16:27.901209Z","shell.execute_reply.started":"2021-12-06T12:16:27.895947Z","shell.execute_reply":"2021-12-06T12:16:27.90038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"# Candidate models\nkridge = make_pipeline(\n    TfidfVectorizer(decode_error='ignore', stop_words='english', max_features=MAX_FEATURES),\n    KernelRidge()\n)\n\nrandforest = make_pipeline(\n    TfidfVectorizer(decode_error='ignore', stop_words='english', max_features=MAX_FEATURES),\n    RandomForestRegressor(n_jobs=-1)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:16:41.873487Z","iopub.execute_input":"2021-12-06T12:16:41.874498Z","iopub.status.idle":"2021-12-06T12:16:41.879883Z","shell.execute_reply.started":"2021-12-06T12:16:41.874454Z","shell.execute_reply":"2021-12-06T12:16:41.879287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [\n    ('KernelRidge', kridge),\n    ('RandomForest', randforest)\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:17:41.903635Z","iopub.execute_input":"2021-12-06T12:17:41.90442Z","iopub.status.idle":"2021-12-06T12:17:41.908561Z","shell.execute_reply.started":"2021-12-06T12:17:41.904377Z","shell.execute_reply":"2021-12-06T12:17:41.907727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New data for validation: text pairs.\ndata_valid = pd.read_csv(VALID_DATA_PATH)\n\n# Clean the texts\ndata_valid['less_toxic'] = data_valid['less_toxic'].apply(text_cleaning)\ndata_valid['more_toxic'] = data_valid['more_toxic'].apply(text_cleaning)\n\ndata_valid.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:17:50.658471Z","iopub.execute_input":"2021-12-06T12:17:50.658869Z","iopub.status.idle":"2021-12-06T12:18:10.448656Z","shell.execute_reply.started":"2021-12-06T12:17:50.658839Z","shell.execute_reply":"2021-12-06T12:18:10.44767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train each model on all available samples from previous competition.\nfor name, model in models:\n    print('-' * 50)\n    model.fit(data_train['comment_text'], data_train['score'])\n    print(f'{name} model completed training.')\n\n    # Estimate toxicity score for text pairs.\n    data_valid[f'less_toxic_score_{name}'] = model.predict(data_valid['less_toxic'])\n    data_valid[f'more_toxic_score_{name}'] = model.predict(data_valid['more_toxic'])\n    print(f'{name} model completed prediction.')\n\n    # Compare scores for all text pairs.\n    data_valid[f'result_{name}'] = \\\n        data_valid[f'more_toxic_score_{name}'] > data_valid[f'less_toxic_score_{name}']\n\n    # Ratio of correctly scored text pairs.\n    print('Correct predictions:', data_valid[f'result_{name}'].sum() / len(data_valid))\n    \n    joblib.dump(model, f'{name}.joblib')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:18:14.356741Z","iopub.execute_input":"2021-12-06T12:18:14.357016Z","iopub.status.idle":"2021-12-06T12:24:50.372279Z","shell.execute_reply.started":"2021-12-06T12:18:14.356988Z","shell.execute_reply":"2021-12-06T12:24:50.371351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the accuracy of averaged scores from the best models.\ndata_valid['less_toxic_score'] = data_valid[['less_toxic_score_KernelRidge', 'less_toxic_score_RandomForest']].mean(axis=1)\n\ndata_valid['more_toxic_score'] = data_valid[['more_toxic_score_KernelRidge', 'more_toxic_score_RandomForest']].mean(axis=1)\n\ndata_valid[f'result'] = data_valid[f'more_toxic_score'] > data_valid[f'less_toxic_score']\nprint('Correct averaged predictions:', data_valid[f'result'].sum() / len(data_valid))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:29:16.706768Z","iopub.execute_input":"2021-12-06T12:29:16.707068Z","iopub.status.idle":"2021-12-06T12:29:16.723976Z","shell.execute_reply.started":"2021-12-06T12:29:16.707037Z","shell.execute_reply":"2021-12-06T12:29:16.722861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New data for text scoring.\ndata_test = pd.read_csv(TEST_DATA_PATH)\ndata_test['text'] = data_test['text'].apply(text_cleaning)\ndata_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:29:25.84198Z","iopub.execute_input":"2021-12-06T12:29:25.842237Z","iopub.status.idle":"2021-12-06T12:29:28.393905Z","shell.execute_reply.started":"2021-12-06T12:29:25.842211Z","shell.execute_reply":"2021-12-06T12:29:28.393152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"# Get prediction from the best models.\nfor name, model in models[0:]:\n    data_test[f'score_{name}'] = model.predict(data_test['text'])\n    print(f'{name} model completed prediction.')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:30:17.278485Z","iopub.execute_input":"2021-12-06T12:30:17.279225Z","iopub.status.idle":"2021-12-06T12:30:21.50009Z","shell.execute_reply.started":"2021-12-06T12:30:17.279177Z","shell.execute_reply":"2021-12-06T12:30:21.499088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average the result.\ndata_test['score'] = data_test[['score_KernelRidge', 'score_RandomForest']].mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:30:26.289332Z","iopub.execute_input":"2021-12-06T12:30:26.28963Z","iopub.status.idle":"2021-12-06T12:30:26.297591Z","shell.execute_reply.started":"2021-12-06T12:30:26.289601Z","shell.execute_reply":"2021-12-06T12:30:26.296637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test[['comment_id', 'score']].to_csv('submission.csv', index=False)\ndata_test[['comment_id', 'score']].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T12:30:36.639668Z","iopub.execute_input":"2021-12-06T12:30:36.640667Z","iopub.status.idle":"2021-12-06T12:30:36.676272Z","shell.execute_reply.started":"2021-12-06T12:30:36.640623Z","shell.execute_reply":"2021-12-06T12:30:36.675406Z"},"trusted":true},"execution_count":null,"outputs":[]}]}