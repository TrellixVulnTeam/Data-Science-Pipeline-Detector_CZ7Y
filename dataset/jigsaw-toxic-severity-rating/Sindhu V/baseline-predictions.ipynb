{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n1. V1: Baseline single model (Fully uses HF Framework)\n2. V2: Baseline ranker model (HF models integrated to FastAI)\n3. V3: Same approach as V1. More reliable training data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport wt_text_processing_utils as wtp_utils\nimport torch\ntorch.set_grad_enabled(False)\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import TrainingArguments, Trainer, default_data_collator\ndata_collator = default_data_collator\n\nmname = \"../input/hatebert-regression-single-model/hatebert_reg_baseline/checkpoint-1000\"\n#They are all in the same range. MSELoss wise, 250 performed better\ntokenizer = AutoTokenizer.from_pretrained(mname)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T09:58:52.490261Z","iopub.execute_input":"2021-11-19T09:58:52.491007Z","iopub.status.idle":"2021-11-19T09:58:59.446414Z","shell.execute_reply.started":"2021-11-19T09:58:52.490901Z","shell.execute_reply":"2021-11-19T09:58:59.44566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nkey1, key2 = \"tclean\", None\n\n#Allows truncation. So encoded ds and actual ds should share the same size. \ndef preprocess_function(examples):\n    if key2 is None:\n        return tokenizer(examples[key1], padding=True, truncation=True, max_length=512) \n    return tokenizer(examples[key1], examples[key2], padding=True, truncation=True, max_length=512) \n\ndf = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf[\"tclean\"] = wtp_utils.preprocess_text(df[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T09:58:59.448347Z","iopub.execute_input":"2021-11-19T09:58:59.448593Z","iopub.status.idle":"2021-11-19T10:00:23.198984Z","shell.execute_reply.started":"2021-11-19T09:58:59.448559Z","shell.execute_reply":"2021-11-19T10:00:23.198252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import rankdata\n\nmodel = AutoModelForSequenceClassification.from_pretrained(mname)\n\nargs = TrainingArguments(\"dummy\", report_to=[\"tensorboard\"], per_device_eval_batch_size=256)\ntrainer = Trainer(model, args, data_collator=data_collator, tokenizer=tokenizer)\n\ntest_ds = Dataset.from_pandas(df)\ntest_ds = test_ds.map(preprocess_function, batched=True)\npreds = trainer.predict(test_ds)\nranks = preds.predictions[:, 0]\n\ndf[\"score\"] = rankdata(ranks, method='ordinal')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T10:03:12.680256Z","iopub.execute_input":"2021-11-19T10:03:12.680826Z","iopub.status.idle":"2021-11-19T10:10:20.629307Z","shell.execute_reply.started":"2021-11-19T10:03:12.68079Z","shell.execute_reply":"2021-11-19T10:10:20.628511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[[\"comment_id\", \"score\"]].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T10:10:20.634532Z","iopub.execute_input":"2021-11-19T10:10:20.636262Z","iopub.status.idle":"2021-11-19T10:10:20.666131Z","shell.execute_reply.started":"2021-11-19T10:10:20.636229Z","shell.execute_reply":"2021-11-19T10:10:20.664943Z"},"trusted":true},"execution_count":null,"outputs":[]}]}