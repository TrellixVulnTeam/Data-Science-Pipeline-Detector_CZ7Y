{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center>How to train a Huggingface Tokenizer + TFIDF + RIDGE</center></h1>     \n\n<center><img src = \"https://i.imgur.com/iRX7hwu.png\" width = \"1000\" height = \"400\"/></center>           \n\nThis notebook was inspided on the following other two notebooks:\n* https://www.kaggle.com/vitaleey/tfidf-ridge\n* https://www.kaggle.com/pablorosa01/naive-bayes-modeling-base-line\n\n<h3 style='background:orange; color:black'><center>Consider upvoting this notebook if you found it helpful.</center></h3>","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nimport re\nfrom bs4 import BeautifulSoup\n\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Datasets","metadata":{}},{"cell_type":"code","source":"TRAIN_DATA_PATH = \"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\"\nVALID_DATA_PATH = \"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\"\nTEST_DATA_PATH = \"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_DATA_PATH)\ndf_valid = pd.read_csv(VALID_DATA_PATH)\ndf_test = pd.read_csv(TEST_DATA_PATH)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scoring training data","metadata":{}},{"cell_type":"code","source":"cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    df_train[category] = df_train[category] * cat_mtpl[category]\n\ndf_train['score'] = df_train.loc[:, 'toxic':'identity_hate'].mean(axis=1)\n\ndf_train['y'] = df_train['score']\n\nmin_len = (df_train['y'] > 0).sum()  # len of toxic comments\ndf_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=41)  # take non toxic comments\ndf_train_new = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\ndf_train_new","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the tokenizer","metadata":{}},{"cell_type":"code","source":"from tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nraw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\nraw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\ndataset = Dataset.from_pandas(df_train_new[['comment_text']])\n\ndef get_training_corpus():\n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"comment_text\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\n\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy_fun(doc):\n    return doc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = df_train_new['y']\ncomments = df_train_new['comment_text']\ntokenized_comments = tokenizer(comments.to_list())['input_ids']\n\nvectorizer = TfidfVectorizer(\n    analyzer = 'word',\n    tokenizer = dummy_fun,\n    preprocessor = dummy_fun,\n    token_pattern = None)\n\ncomments_tr = vectorizer.fit_transform(tokenized_comments)\ncomments_tr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor = Ridge(random_state=42, alpha=0.8)\nregressor.fit(comments_tr, labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"# preprocess val data\nless_toxic_comments = df_valid['less_toxic']\nmore_toxic_comments = df_valid['more_toxic']\n\nless_toxic_comments = tokenizer(less_toxic_comments.to_list())['input_ids']\nmore_toxic_comments = tokenizer(more_toxic_comments.to_list())['input_ids']\n\nless_toxic = vectorizer.transform(less_toxic_comments)\nmore_toxic = vectorizer.transform(more_toxic_comments)\n\n# make predictions\ny_pred_less = regressor.predict(less_toxic)\ny_pred_more = regressor.predict(more_toxic)\n\n(y_pred_less < y_pred_more).mean()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Tokenizer (deberta-v3): 0.6699880430450379\n* Tokenizer (trained): 0.6674970107612594\n* Tokenizer (trained + dirty): 0.6716819449980072\n\n** Be careful, this results suggest that the 0.86 LB score is not reliable!!! Use at your own risk!","metadata":{}},{"cell_type":"markdown","source":"# Predictions and load submission.csv","metadata":{}},{"cell_type":"code","source":"texts = df_test['text']\ntexts = tokenizer(texts.to_list())['input_ids']\ntexts = vectorizer.transform(texts)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['prediction'] = regressor.predict(texts)\ndf_test = df_test[['comment_id','prediction']]\n\ndf_test['score'] = df_test['prediction']\ndf_test = df_test[['comment_id','score']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.to_csv('./submission.csv', index=False)\ndf_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}