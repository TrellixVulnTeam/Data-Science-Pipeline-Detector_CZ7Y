{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-25T14:40:10.414816Z","iopub.execute_input":"2021-12-25T14:40:10.415396Z","iopub.status.idle":"2021-12-25T14:40:10.426402Z","shell.execute_reply.started":"2021-12-25T14:40:10.415355Z","shell.execute_reply":"2021-12-25T14:40:10.425493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just a quick demo to test torchtext lib and my first experience with NLP.","metadata":{}},{"cell_type":"code","source":"text = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nlabels = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:40:10.777278Z","iopub.execute_input":"2021-12-25T14:40:10.777829Z","iopub.status.idle":"2021-12-25T14:40:11.032935Z","shell.execute_reply.started":"2021-12-25T14:40:10.777792Z","shell.execute_reply":"2021-12-25T14:40:11.032193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_labels = np.concatenate((np.zeros(len(labels['less_toxic'])), \n                             np.ones(len(labels['more_toxic']))))\nnew_comments = np.concatenate((labels['less_toxic'].values, \n                               labels['more_toxic'].values))\n\ndataset = np.stack((new_comments, new_labels), axis=1)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:40:11.034537Z","iopub.execute_input":"2021-12-25T14:40:11.034829Z","iopub.status.idle":"2021-12-25T14:40:11.048253Z","shell.execute_reply.started":"2021-12-25T14:40:11.034789Z","shell.execute_reply":"2021-12-25T14:40:11.047559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\ntokenizer = get_tokenizer('basic_english')\n\ndef yield_tokens(data_iter):\n    for text, _ in data_iter:\n        yield tokenizer(text)\n        \nvocab = build_vocab_from_iterator(yield_tokens(dataset))\nvocab.set_default_index(1)\nprint(vocab.get_default_index())","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:40:11.049871Z","iopub.execute_input":"2021-12-25T14:40:11.050337Z","iopub.status.idle":"2021-12-25T14:40:15.096847Z","shell.execute_reply.started":"2021-12-25T14:40:11.050301Z","shell.execute_reply":"2021-12-25T14:40:15.096021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_pipeline = lambda x: vocab(tokenizer(x))\nlabel_pipeline = lambda x: float(x)\n\ntext_pipeline('Hello world')","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:40:15.098279Z","iopub.execute_input":"2021-12-25T14:40:15.098725Z","iopub.status.idle":"2021-12-25T14:40:15.104868Z","shell.execute_reply.started":"2021-12-25T14:40:15.098686Z","shell.execute_reply":"2021-12-25T14:40:15.104103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef collate_batch(batch):\n    label_list, text_list, offsets = [], [], [0]\n    for (_text, _label) in batch:\n        label_list.append(_label)\n        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n        text_list.append(processed_text)\n        offsets.append(processed_text.size(0))\n    label_list = torch.tensor(label_list, dtype=torch.float)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text_list = torch.cat(text_list)\n    return label_list.unsqueeze(1).to(device), text_list.to(device), offsets.to(device)\n\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_batch)\n\nnext(iter(dataloader))","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:40:15.107094Z","iopub.execute_input":"2021-12-25T14:40:15.107518Z","iopub.status.idle":"2021-12-25T14:40:15.128358Z","shell.execute_reply.started":"2021-12-25T14:40:15.10748Z","shell.execute_reply":"2021-12-25T14:40:15.127638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef train(dataloader):\n    model.train()\n    total_acc, total_count = 0, 0\n    log_interval = 500\n    start_time = time.time()\n\n    for idx, (label, text, offsets) in enumerate(dataloader):\n        optimizer.zero_grad()\n        predicted_label = model(text, offsets)\n        loss = criterion(predicted_label, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n        total_acc += ((predicted_label > 0.5).float() == label).sum().item()\n        total_count += label.size(0)\n        if idx % log_interval == 0 and idx > 0:\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches '\n                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n                                              total_acc/total_count))\n            total_acc, total_count = 0, 0\n            start_time = time.time()\n\ndef evaluate(dataloader):\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    with torch.no_grad():\n        for idx, (label, text, offsets) in enumerate(dataloader):\n            predicted_label = model(text, offsets)\n            loss = criterion(predicted_label, label)\n            total_acc += ((predicted_label > 0.5).float() == label).sum().item()\n            total_count += label.size(0)\n    return total_acc/total_count","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:40:15.129714Z","iopub.execute_input":"2021-12-25T14:40:15.130178Z","iopub.status.idle":"2021-12-25T14:40:15.141096Z","shell.execute_reply.started":"2021-12-25T14:40:15.130142Z","shell.execute_reply":"2021-12-25T14:40:15.140338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\nclass CustomModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim):\n        super(CustomModel, self).__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n        self.fc_1 = nn.Linear(embed_dim, 32)\n        self.relu = nn.ReLU()\n        self.fc_2 = nn.Linear(32, 1)\n        self.init_weights()\n        \n    def init_weights(self):\n        initrange = 0.5\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.fc_1.weight.data.uniform_(-initrange,initrange)\n        self.fc_1.bias.data.zero_()\n        self.fc_2.weight.data.uniform_(-initrange,initrange)\n        self.fc_2.bias.data.zero_()\n        \n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        embedded = self.fc_1(embedded)\n        embedded = self.relu(embedded)\n        return torch.sigmoid(self.fc_2(embedded))\n    \nvocab_size = len(vocab)\nemsize = 128\nmodel = CustomModel(vocab_size, emsize).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:43:25.852561Z","iopub.execute_input":"2021-12-25T14:43:25.853252Z","iopub.status.idle":"2021-12-25T14:43:25.989237Z","shell.execute_reply.started":"2021-12-25T14:43:25.853218Z","shell.execute_reply":"2021-12-25T14:43:25.987869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import random_split\nfrom torchtext.data.functional import to_map_style_dataset\nfrom sklearn.model_selection import train_test_split\n\nEPOCHS = 10 \nLR = 1.\nBATCH_SIZE = 64 \n  \ncriterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, .01, gamma=0.1)\ntotal_accu = None\ntrain_iter, test_iter = train_test_split(dataset, test_size=0.1, train_size=0.9, random_state=42)\ntrain_dataset = to_map_style_dataset(train_iter)\ntest_dataset = to_map_style_dataset(test_iter)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\nvalid_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    train(train_dataloader)\n    accu_val = evaluate(valid_dataloader)\n    if total_accu is not None and total_accu > accu_val:\n        scheduler.step()\n    else:\n        total_accu = accu_val\n    \n    print('| end of epoch {:3d} | time: {:5.2f}s | valid accuracy {:8.3f} '\n          .format(epoch, time.time() - epoch_start_time, accu_val))","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:43:30.217769Z","iopub.execute_input":"2021-12-25T14:43:30.21806Z","iopub.status.idle":"2021-12-25T14:44:36.167131Z","shell.execute_reply.started":"2021-12-25T14:43:30.218028Z","shell.execute_reply":"2021-12-25T14:44:36.166284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(text, text_pipeline):\n    with torch.no_grad():\n        text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n        offsets = [0]\n        offsets.append(text.size(0))\n        offsets = torch.tensor(offsets[:-1]).cumsum(dim=0).to(device)\n        \n        output = model(text, offsets)\n        return output\n\ntext.text=text.text.astype(str)\n    \nfor index, i in enumerate(text['text']):\n    item = predict(i, text_pipeline).item()\n    text.at[index, 'score'] = item\n    \ntext.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:44:38.997528Z","iopub.execute_input":"2021-12-25T14:44:38.997782Z","iopub.status.idle":"2021-12-25T14:44:41.822389Z","shell.execute_reply.started":"2021-12-25T14:44:38.997748Z","shell.execute_reply":"2021-12-25T14:44:41.821461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_cv = text.drop('text', axis=1)\nsub_cv.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T14:44:41.824356Z","iopub.execute_input":"2021-12-25T14:44:41.824636Z","iopub.status.idle":"2021-12-25T14:44:41.857154Z","shell.execute_reply.started":"2021-12-25T14:44:41.824586Z","shell.execute_reply":"2021-12-25T14:44:41.856442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you liked it or found useful - plz UV ;) \n\nPS: I would like to learn more about NLP, so please share some wisdom or guidance.","metadata":{}}]}