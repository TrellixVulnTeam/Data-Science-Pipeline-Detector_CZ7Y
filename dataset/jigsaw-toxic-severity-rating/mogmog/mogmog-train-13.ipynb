{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class CFG:\n    debug=False\n    seed=42\n    n_fold = 4\n    model_name = \"../input/roberta-base-edited\"\n    max_len = 256\n    text=\"text_clean2\"\n    target=\"target\"\n    target_size = 1\n    hidden_size = 768\n    fc_dropout = 0.\n    batch_size = 32\n    num_workers = 4\n    model_dir = \"../input/roberta-001-train-jigsaw2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport gc\nimport time\nimport math\nimport random\nimport string\nimport pickle\nfrom collections import Counter\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\nfrom gensim import models\nfrom gensim.models import KeyedVectors,FastText\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_selection import SelectKBest, mutual_info_regression,chi2, f_regression\nfrom bs4 import BeautifulSoup\n\nfrom sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\nfrom scipy import sparse\nimport scipy\nimport seaborn as sns\n\nfrom nltk.stem import PorterStemmer, SnowballStemmer\nfrom unicodedata import category, name, normalize\nfrom nltk.stem.lancaster import LancasterStemmer\n\nimport lightgbm as lgb\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import OneCycleLR\n# NLP\nfrom transformers import AutoTokenizer, AutoModel,get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option(\"max_columns\",100)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:23.229538Z","iopub.execute_input":"2022-02-19T08:28:23.236096Z","iopub.status.idle":"2022-02-19T08:28:35.314428Z","shell.execute_reply.started":"2022-02-19T08:28:23.236045Z","shell.execute_reply":"2022-02-19T08:28:35.313347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything()\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:35.316629Z","iopub.execute_input":"2022-02-19T08:28:35.31697Z","iopub.status.idle":"2022-02-19T08:28:35.387493Z","shell.execute_reply.started":"2022-02-19T08:28:35.316909Z","shell.execute_reply":"2022-02-19T08:28:35.385255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"train_ruddit_df = pd.read_csv('../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv')\ntrain_1st_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntrain_1st_test_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\ntrain_1st_test_lb_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\nvalidation_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n\n# merge jigsaw 1st test_label\ntrain_1st_test_df = train_1st_test_df.merge(train_1st_test_lb_df, on='id')\n\n# drop \"-1\"label\ndrop_idx = (train_1st_test_df.loc[:,\"toxic\":]==-1).sum(axis = 1) >=1\ntrain_1st_test_df = train_1st_test_df[~drop_idx].reset_index(drop=True)\n\n# concat train and test\ntrain_1st_df = pd.concat([train_1st_df,train_1st_test_df]).reset_index(drop = True)\n\nif CFG.debug:\n    train_ruddit_df = train_ruddit_df.sample(n=2000, random_state=CFG.seed).reset_index(drop=True)\n    train_1st_df =  train_1st_df.sample(n=2000, random_state=CFG.seed).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:35.39076Z","iopub.execute_input":"2022-02-19T08:28:35.391113Z","iopub.status.idle":"2022-02-19T08:28:39.45667Z","shell.execute_reply.started":"2022-02-19T08:28:35.391055Z","shell.execute_reply":"2022-02-19T08:28:39.455607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename columns\ntrain_ruddit_df = train_ruddit_df.rename(columns = {\"txt\":\"text\"})\ntrain_1st_df = train_1st_df.rename(columns = {\"comment_text\":\"text\"})\ntrain_ruddit_df = train_ruddit_df.rename(columns = {\"offensiveness_score\":\"target\"})\n\n# delete\nidx = train_ruddit_df[\"text\"].isin([\"[deleted]\",\"[removed]\"])\ntrain_ruddit_df = train_ruddit_df[~idx].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:39.458617Z","iopub.execute_input":"2022-02-19T08:28:39.458992Z","iopub.status.idle":"2022-02-19T08:28:39.49481Z","shell.execute_reply.started":"2022-02-19T08:28:39.458946Z","shell.execute_reply":"2022-02-19T08:28:39.493713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_jigsaw1_data(train_1st_df):   \n    txt_validation_df = pd.concat([validation_df[\"less_toxic\"],validation_df[\"more_toxic\"]]) \n    txt_1st =train_1st_df[\"text\"] \n    print(f\"Before:{len(train_1st_df)}\")\n    \n    val_text_list = list(set(txt_validation_df))\n    dup_idx = train_1st_df[\"text\"].isin(val_text_list)\n    print(f\"Num_duplicate_text_{sum(dup_idx)}\")\n    \n    train_1st_df = train_1st_df[~dup_idx].reset_index(drop=True)\n    print(f\"After:{len(train_1st_df)}\")\n\n    cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n                'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\n    for category in cat_mtpl:\n        train_1st_df[category] = train_1st_df[category] * cat_mtpl[category]  \n    train_1st_df[\"target\"] = train_1st_df.loc[:,\"toxic\":\"identity_hate\"].sum(axis=1)\n    return train_1st_df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:39.496528Z","iopub.execute_input":"2022-02-19T08:28:39.49684Z","iopub.status.idle":"2022-02-19T08:28:39.507292Z","shell.execute_reply.started":"2022-02-19T08:28:39.496795Z","shell.execute_reply":"2022-02-19T08:28:39.506224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def under_sample(input_df, frac = 0.1):\n    '''\n        undersampling target == 0 rows\n    '''\n    print(f\"before_shape:{len(input_df)}\")\n    \n    zero_sample_df = input_df[input_df[\"target\"]==0].sample(frac = frac,random_state = 1)\n    non_zero_df = input_df[input_df[\"target\"]!=0]\n    out_df = pd.concat([zero_sample_df,non_zero_df]).sort_index().reset_index(drop=True)\n\n    print(f\"After_shape:{len(out_df)}\")\n    print(f\"Ratio :{len(out_df)/len(input_df)}\")\n    return out_df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:39.508928Z","iopub.execute_input":"2022-02-19T08:28:39.510112Z","iopub.status.idle":"2022-02-19T08:28:39.523915Z","shell.execute_reply.started":"2022-02-19T08:28:39.510057Z","shell.execute_reply":"2022-02-19T08:28:39.522834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1st_df = make_jigsaw1_data(train_1st_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:39.525744Z","iopub.execute_input":"2022-02-19T08:28:39.526098Z","iopub.status.idle":"2022-02-19T08:28:39.787031Z","shell.execute_reply.started":"2022-02-19T08:28:39.526048Z","shell.execute_reply":"2022-02-19T08:28:39.785943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1st_df = under_sample(train_1st_df, frac = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:39.789992Z","iopub.execute_input":"2022-02-19T08:28:39.790603Z","iopub.status.idle":"2022-02-19T08:28:39.87816Z","shell.execute_reply.started":"2022-02-19T08:28:39.790555Z","shell.execute_reply":"2022-02-19T08:28:39.876874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1st_df[\"target\"].hist(bins = 40)\ntrain_1st_df[\"target\"].describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:39.886689Z","iopub.execute_input":"2022-02-19T08:28:39.887006Z","iopub.status.idle":"2022-02-19T08:28:40.291997Z","shell.execute_reply.started":"2022-02-19T08:28:39.886972Z","shell.execute_reply":"2022-02-19T08:28:40.291003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocess \n- reference\n    - https://www.kaggle.com/sunnymarkliu/more-text-cleaning-to-increase-word-coverage","metadata":{}},{"cell_type":"code","source":"spaces = ['\\u200b', '\\u200e', '\\u202a', '\\u202c', '\\ufeff', '\\uf0d8', '\\u2061', '\\x10', '\\x7f', '\\x9d', '\\xad', '\\xa0']\ndef remove_space(text):\n    \"\"\"\n    remove extra spaces and ending space if any\n    \"\"\"\n    for space in spaces:\n        text = text.replace(space, ' ')\n    text = text.strip()\n    text = re.sub('\\s+', ' ', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.293779Z","iopub.execute_input":"2022-02-19T08:28:40.295317Z","iopub.status.idle":"2022-02-19T08:28:40.303908Z","shell.execute_reply.started":"2022-02-19T08:28:40.295264Z","shell.execute_reply":"2022-02-19T08:28:40.302483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"special_punc_mappings = {\"—\": \"-\", \"–\": \"-\", \"_\": \"-\", '”': '\"', \"″\": '\"', '“': '\"', '•': '.', '−': '-',\n                         \"’\": \"'\", \"‘\": \"'\", \"´\": \"'\", \"`\": \"'\", '\\u200b': ' ', '\\xa0': ' ','،':'','„':'',\n                         '…': ' ... ', '\\ufeff': ''}\ndef clean_special_punctuations(text):\n    for punc in special_punc_mappings:\n        if punc in text:\n            text = text.replace(punc, special_punc_mappings[punc])\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.305846Z","iopub.execute_input":"2022-02-19T08:28:40.306265Z","iopub.status.idle":"2022-02-19T08:28:40.318104Z","shell.execute_reply.started":"2022-02-19T08:28:40.306216Z","shell.execute_reply":"2022-02-19T08:28:40.316899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number\ndef clean_number(text):\n    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text)\n    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text)\n    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.320001Z","iopub.execute_input":"2022-02-19T08:28:40.32104Z","iopub.status.idle":"2022-02-19T08:28:40.333012Z","shell.execute_reply.started":"2022-02-19T08:28:40.32099Z","shell.execute_reply":"2022-02-19T08:28:40.332054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rare_words_mapping = {' s.p ': ' ', ' S.P ': ' ', 'U.s.p': '', 'U.S.A.': 'USA', 'u.s.a.': 'USA', 'U.S.A': 'USA',\n                      'u.s.a': 'USA', 'U.S.': 'USA', 'u.s.': 'USA', ' U.S ': ' USA ', ' u.s ': ' USA ', 'U.s.': 'USA',\n                      ' U.s ': 'USA', ' u.S ': ' USA ', 'fu.k': 'fuck', 'U.K.': 'UK', ' u.k ': ' UK ',\n                      ' don t ': ' do not ', 'bacteries': 'batteries', ' yr old ': ' years old ', 'Ph.D': 'PhD',\n                      'cau.sing': 'causing', 'Kim Jong-Un': 'The president of North Korea', 'savegely': 'savagely',\n                      'Ra apist': 'Rapist', '2fifth': 'twenty fifth', '2third': 'twenty third',\n                      '2nineth': 'twenty nineth', '2fourth': 'twenty fourth', '#metoo': 'MeToo',\n                      'Trumpcare': 'Trump health care system', '4fifth': 'forty fifth', 'Remainers': 'remainder',\n                      'Terroristan': 'terrorist', 'antibrahmin': 'anti brahmin',\n                      'fuckboys': 'fuckboy', 'Fuckboys': 'fuckboy', 'Fuckboy': 'fuckboy', 'fuckgirls': 'fuck girls',\n                      'fuckgirl': 'fuck girl', 'Trumpsters': 'Trump supporters', '4sixth': 'forty sixth',\n                      'culturr': 'culture',\n                      'weatern': 'western', '4fourth': 'forty fourth', 'emiratis': 'emirates', 'trumpers': 'Trumpster',\n                      'indans': 'indians', 'mastuburate': 'masturbate', 'f**k': 'fuck', 'F**k': 'fuck', 'F**K': 'fuck',\n                      ' u r ': ' you are ', ' u ': ' you ', '操你妈': 'fuck your mother', 'e.g.': 'for example',\n                      'i.e.': 'in other words', '...': '.', 'et.al': 'elsewhere', 'anti-Semitic': 'anti-semitic',\n                      'f***': 'fuck', 'f**': 'fuc', 'F***': 'fuck', 'F**': 'fuc','f*ck':'fuck',\n                      'a****': 'assho', 'a**': 'ass', 'h***': 'hole', 'A****': 'assho', 'A**': 'ass', 'H***': 'hole',\n                      's***': 'shit', 's**': 'shi', 'S***': 'shit', 'S**': 'shi', 'Sh**': 'shit','sh*t':'shit',\n                      'p****': 'pussy', 'p*ssy': 'pussy', 'P****': 'pussy',\n                      'p***': 'porn', 'p*rn': 'porn', 'P***': 'porn',\n                      'st*up*id': 'stupid',\n                      'd***': 'dick', 'di**': 'dick', 'h*ck': 'hack',\n                      'b*tch': 'bitch', 'bi*ch': 'bitch', 'bit*h': 'bitch', 'bitc*': 'bitch', 'b****': 'bitch',\n                      'b***': 'bitc', 'b**': 'bit', 'b*ll': 'bull'\n                      }\n\n\ndef pre_clean_rare_words(text):\n    for rare_word in rare_words_mapping:\n        if rare_word in text:\n            text = text.replace(rare_word, rare_words_mapping[rare_word])\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.335809Z","iopub.execute_input":"2022-02-19T08:28:40.336248Z","iopub.status.idle":"2022-02-19T08:28:40.354338Z","shell.execute_reply.started":"2022-02-19T08:28:40.336168Z","shell.execute_reply":"2022-02-19T08:28:40.353036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# de-contract the contraction\ndef decontracted(text):\n    # specific\n    text = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", text)\n    text = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", text)\n    text = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", text)\n    text = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", text)\n\n    # general\n    text = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", text)\n    text = re.sub(r\"(A|a)in(\\'|\\’)t \", \"is not \", text)\n    text = re.sub(r\"n(\\'|\\’)t \", \" not \", text)\n    text = re.sub(r\"(\\'|\\’)re \", \" are \", text)\n    text = re.sub(r\"(\\'|\\’)s \", \" is \", text)\n    text = re.sub(r\"(\\'|\\’)d \", \" would \", text)\n    text = re.sub(r\"(\\'|\\’)ll \", \" will \", text)\n    text = re.sub(r\"(\\'|\\’)t \", \" not \", text)\n    text = re.sub(r\"(\\'|\\’)ve \", \" have \", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.356223Z","iopub.execute_input":"2022-02-19T08:28:40.356699Z","iopub.status.idle":"2022-02-19T08:28:40.371359Z","shell.execute_reply.started":"2022-02-19T08:28:40.356634Z","shell.execute_reply":"2022-02-19T08:28:40.369984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regular_punct = list(string.punctuation)\nextra_punct = [\n    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n    '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n    '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n    '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n    'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n    '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\nall_punct = list(set(regular_punct + extra_punct))\nall_punct.remove('-')\nall_punct.remove('.')\n\ndef spacing_punctuation(text):\n    \"\"\"\n    add space before and after punctuation and symbols\n    \"\"\"\n    for punc in all_punct:\n        if punc in text:\n            text = text.replace(punc, f' {punc} ')\n    return text\ndef remove_punctuation(text):\n    for punc in all_punct:\n        if punc in text:\n            text = text.replace(punc, ' ')\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.37396Z","iopub.execute_input":"2022-02-19T08:28:40.37475Z","iopub.status.idle":"2022-02-19T08:28:40.391478Z","shell.execute_reply.started":"2022-02-19T08:28:40.374689Z","shell.execute_reply":"2022-02-19T08:28:40.390432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mis_connect_list = ['(W|w)hat', '(W|w)hy', '(H|h)ow', '(W|w)hich', '(W|w)here', '(W|w)ill']\nmis_connect_re = re.compile('(%s)' % '|'.join(mis_connect_list))\n\nmis_spell_mapping = {'whattsup': 'WhatsApp', 'whatasapp':'WhatsApp', 'whatsupp':'WhatsApp', \n                      'whatcus':'what cause', 'arewhatsapp': 'are WhatsApp', 'Hwhat':'what',\n                      'Whwhat': 'What', 'whatshapp':'WhatsApp', 'howhat':'how that',\n                      # why\n                      'Whybis':'Why is', \n                      # How\n                      \"Howddo\":\"How do\", 'Howeber':'However'}\ndef spacing_some_connect_words(text):\n    \"\"\"\n    'Whyare' -> 'Why are'\n    \"\"\"\n    ori = text\n    for error in mis_spell_mapping:\n        if error in text:\n            text = text.replace(error, mis_spell_mapping[error])\n            \n    # what\n    text = re.sub(r\" (W|w)hat+(s)*[A|a]*(p)+ \", \" WhatsApp \", text)\n    text = re.sub(r\" (W|w)hat\\S \", \" What \", text)\n    text = re.sub(r\" \\S(W|w)hat \", \" What \", text)\n    # why\n    text = re.sub(r\" (W|w)hy\\S \", \" Why \", text)\n    text = re.sub(r\" \\S(W|w)hy \", \" Why \", text)\n    # How\n    text = re.sub(r\" (H|h)ow\\S \", \" How \", text)\n    text = re.sub(r\" \\S(H|h)ow \", \" How \", text)\n    # which\n    text = re.sub(r\" (W|w)hich\\S \", \" Which \", text)\n    text = re.sub(r\" \\S(W|w)hich \", \" Which \", text)\n    # where\n    text = re.sub(r\" (W|w)here\\S \", \" Where \", text)\n    text = re.sub(r\" \\S(W|w)here \", \" Where \", text)\n    # \n    text = mis_connect_re.sub(r\" \\1 \", text)\n    text = text.replace(\"What sApp\", 'WhatsApp')\n    \n    text = remove_space(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.39362Z","iopub.execute_input":"2022-02-19T08:28:40.394035Z","iopub.status.idle":"2022-02-19T08:28:40.410381Z","shell.execute_reply.started":"2022-02-19T08:28:40.393987Z","shell.execute_reply":"2022-02-19T08:28:40.409371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_number(text):\n    text = re.sub(r'[0-9]+', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.41396Z","iopub.execute_input":"2022-02-19T08:28:40.414992Z","iopub.status.idle":"2022-02-19T08:28:40.426331Z","shell.execute_reply.started":"2022-02-19T08:28:40.414935Z","shell.execute_reply":"2022-02-19T08:28:40.424979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lower(text):\n    text = text.lower()\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.429795Z","iopub.execute_input":"2022-02-19T08:28:40.430502Z","iopub.status.idle":"2022-02-19T08:28:40.438352Z","shell.execute_reply.started":"2022-02-19T08:28:40.430463Z","shell.execute_reply":"2022-02-19T08:28:40.437093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train/notebook\ndef text_cleaning_1(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = remove_space(text)\n    text = clean_special_punctuations(text)\n    text = clean_number(text)\n    text = pre_clean_rare_words(text)\n    text = decontracted(text)\n    text = spacing_punctuation(text)\n    text = spacing_some_connect_words(text)\n    text = remove_space(text)\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.442491Z","iopub.execute_input":"2022-02-19T08:28:40.442758Z","iopub.status.idle":"2022-02-19T08:28:40.452904Z","shell.execute_reply.started":"2022-02-19T08:28:40.442726Z","shell.execute_reply":"2022-02-19T08:28:40.451717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning_2(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.45531Z","iopub.execute_input":"2022-02-19T08:28:40.455737Z","iopub.status.idle":"2022-02-19T08:28:40.467846Z","shell.execute_reply.started":"2022-02-19T08:28:40.455683Z","shell.execute_reply":"2022-02-19T08:28:40.466708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning_3(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = remove_number(text) \n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    text = get_lower(text)\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.470194Z","iopub.execute_input":"2022-02-19T08:28:40.470759Z","iopub.status.idle":"2022-02-19T08:28:40.482533Z","shell.execute_reply.started":"2022-02-19T08:28:40.470706Z","shell.execute_reply":"2022-02-19T08:28:40.481331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## basic_feat","metadata":{}},{"cell_type":"code","source":"def make_basic_feat(input_df):\n    out_df = pd.DataFrame()\n    out_df[\"Num_character\"] = input_df[\"text\"].apply(lambda x:len(x))\n    out_df[\"Num_word\"] = input_df[\"text\"].apply(lambda x:len(x.split()))\n    \n    return out_df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.48499Z","iopub.execute_input":"2022-02-19T08:28:40.485605Z","iopub.status.idle":"2022-02-19T08:28:40.496107Z","shell.execute_reply.started":"2022-02-19T08:28:40.485551Z","shell.execute_reply":"2022-02-19T08:28:40.494865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basic_feat_df = make_basic_feat(train_1st_df)\nbasic_feat_df_ruddit = make_basic_feat(train_ruddit_df)\n\ndisplay(basic_feat_df.head())\ndisplay(basic_feat_df_ruddit.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.497871Z","iopub.execute_input":"2022-02-19T08:28:40.498697Z","iopub.status.idle":"2022-02-19T08:28:40.863812Z","shell.execute_reply.started":"2022-02-19T08:28:40.498538Z","shell.execute_reply":"2022-02-19T08:28:40.862568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tfidf / Countvec","metadata":{}},{"cell_type":"code","source":"def get_tfidf(input_df, col_name, mode = \"char_wb\"):\n    input_series = input_df[col_name].copy()\n    if mode == \"char_wb\":\n        vectorizer = TfidfVectorizer(min_df=3,\n                                     max_df=0.5,\n                                     analyzer='char_wb',\n                                     ngram_range=(3,5)\n                                    )\n    elif mode == \"n_gram\":\n        vectorizer = TfidfVectorizer(ngram_range=(1,2),\n                                     min_df=3,\n                                     max_df=0.5\n                                    )\n    else:\n        raise Exception(\"SelectMode char_wb or n_gram\")\n    tfidf_mat = vectorizer.fit_transform(input_series)\n    return tfidf_mat, vectorizer","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.865965Z","iopub.execute_input":"2022-02-19T08:28:40.866348Z","iopub.status.idle":"2022-02-19T08:28:40.874966Z","shell.execute_reply.started":"2022-02-19T08:28:40.866303Z","shell.execute_reply":"2022-02-19T08:28:40.873322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_countvec(input_df, col_name, mode = \"char_wb\"):\n    input_series = input_df[col_name].copy()\n    if mode == \"char_wb\":\n        vectorizer = CountVectorizer(min_df=3, \n                                     max_df=0.5, \n                                     analyzer='char_wb', \n                                     ngram_range=(3,5)\n                                    )\n    elif mode == \"n_gram\":\n        vectorizer = CountVectorizer(ngram_range=(1,2),\n                                     min_df=3,\n                                     max_df=0.5\n                                    )\n    else:\n        raise Exception(\"SelectMode char_wb or n_gram\")\n    tfidf_mat = vectorizer.fit_transform(input_series)\n    return tfidf_mat, vectorizer","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.877407Z","iopub.execute_input":"2022-02-19T08:28:40.877811Z","iopub.status.idle":"2022-02-19T08:28:40.890354Z","shell.execute_reply.started":"2022-02-19T08:28:40.877765Z","shell.execute_reply":"2022-02-19T08:28:40.889357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## gensim_w2v_embedding","metadata":{}},{"cell_type":"code","source":"def get_gensim_embed(texts,ndim):\n    swem_embedding = np.zeros((len(texts), ndim))\n    \n    for i, text in enumerate(tqdm(texts)):\n        embeddings = [w2v_model.get_vector(word)\n                      if w2v_model.key_to_index.get(word) is not None\n                      else np.zeros(ndim, dtype=np.float32)\n                      for word in text.split()\n                     ]\n        if len(embeddings) > 0:\n            mean_vector = np.mean(np.stack(embeddings), axis=0)\n            swem_embedding[i] = mean_vector\n    return swem_embedding","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.892513Z","iopub.execute_input":"2022-02-19T08:28:40.892977Z","iopub.status.idle":"2022-02-19T08:28:40.904063Z","shell.execute_reply.started":"2022-02-19T08:28:40.892933Z","shell.execute_reply":"2022-02-19T08:28:40.90297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## fasttext_embedding","metadata":{}},{"cell_type":"code","source":"def get_fasttext_embed(texts,ndim):\n    swem_embedding = np.zeros((len(texts), ndim))\n    \n    for i, text in enumerate(tqdm(texts)):\n        tokens = [word for word in text.split()]\n        if len(tokens)>0:\n            mean_vector = np.mean(fmodel.wv[tokens], axis = 0)\n            swem_embedding[i] = mean_vector\n    return swem_embedding","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.914037Z","iopub.execute_input":"2022-02-19T08:28:40.914303Z","iopub.status.idle":"2022-02-19T08:28:40.923955Z","shell.execute_reply.started":"2022-02-19T08:28:40.914274Z","shell.execute_reply":"2022-02-19T08:28:40.922919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## decompositon","metadata":{}},{"cell_type":"code","source":"def make_decompositon_mat(matrix, n_components = 300,mode = \"svd\",random_state = 0):\n    if mode == \"svd\":\n        transfomer = TruncatedSVD(n_components = n_components, random_state=random_state)\n    elif mode == \"nmf\":\n        transfomer = NMF(n_components = n_components, random_state=random_state)\n    elif mode == \"lda\":\n        transfomer = LatentDirichletAllocation(n_components = n_components, random_state=random_state)\n    else:\n        raise Exception(\"check mode\")\n    out_feature = transfomer.fit_transform(matrix)\n    return out_feature, transfomer","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.928403Z","iopub.execute_input":"2022-02-19T08:28:40.929341Z","iopub.status.idle":"2022-02-19T08:28:40.93769Z","shell.execute_reply.started":"2022-02-19T08:28:40.929243Z","shell.execute_reply":"2022-02-19T08:28:40.936465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_chi2_feature(matrix,y, k=1000):\n    ch2_selector = SelectKBest(chi2, k=k)\n    matrix_filtered = ch2_selector.fit_transform(matrix, y)\n    return matrix_filtered, ch2_selector","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.939973Z","iopub.execute_input":"2022-02-19T08:28:40.94078Z","iopub.status.idle":"2022-02-19T08:28:40.950546Z","shell.execute_reply.started":"2022-02-19T08:28:40.940728Z","shell.execute_reply":"2022-02-19T08:28:40.949098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_f_reg_feature(matrix,y, k=1000):\n    f_selector = SelectKBest(f_regression, k=k)\n    matrix_filtered = f_selector.fit_transform(matrix, y)\n    return matrix_filtered, f_selector","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.954577Z","iopub.execute_input":"2022-02-19T08:28:40.954985Z","iopub.status.idle":"2022-02-19T08:28:40.963488Z","shell.execute_reply.started":"2022-02-19T08:28:40.954931Z","shell.execute_reply":"2022-02-19T08:28:40.962338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Regression_model","metadata":{}},{"cell_type":"code","source":"def train(X, y, cv, model):\n    oof_pred = np.zeros(len(y))\n    val_rmse_list = []\n    model_list = []\n\n    for fold, (train_idx, val_idx) in enumerate(cv):\n        print(\"*\" * 100)\n        print(f\"FOLD : {fold + 1} / {len(cv)}\")\n        tra_x, tra_y = X[train_idx], y[train_idx]\n        val_x, val_y = X[val_idx], y[val_idx]\n        \n        model.fit(tra_x,tra_y)\n        \n        val_pred = model.predict(val_x)\n        oof_pred[val_idx] = val_pred\n        \n        valid_score = np.sqrt(mean_squared_error(val_y, val_pred))\n        val_rmse_list.append(valid_score)\n        print(f\"RMSE : {valid_score:.5f}\")\n  \n        model_list.append(model)\n       \n    print(\"**\"*10,\"FINISH\",\"**\"*10)\n    oof_score = np.sqrt(mean_squared_error(y, oof_pred))\n    print(f\"oof_score:{oof_score}\")\n    val_score_df = pd.DataFrame({\"fold\" : np.arange(len(cv)), \"RMSE\" : val_rmse_list})\n    \n    return oof_pred, val_score_df, model_list","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.965268Z","iopub.execute_input":"2022-02-19T08:28:40.965699Z","iopub.status.idle":"2022-02-19T08:28:40.979542Z","shell.execute_reply.started":"2022-02-19T08:28:40.96565Z","shell.execute_reply":"2022-02-19T08:28:40.978208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lgb","metadata":{}},{"cell_type":"code","source":"def fit_lgbm(X, y, cv, params: dict=None, verbose=False):\n    if params is None:\n        params = {}\n\n    oof_pred = np.zeros(len(y))\n    feature_importances_list = []\n    val_rmse_list = []\n    model_list = []\n\n    for fold, (train_idx, val_idx) in enumerate(cv):\n        print(\"*\" * 100)\n        print(f\"FOLD : {fold + 1} / {len(cv)}\")\n        tra_x, tra_y = X[train_idx], y[train_idx]\n        val_x, val_y = X[val_idx], y[val_idx]\n        \n        dtrain = lgb.Dataset(tra_x, tra_y)\n        dvalid = lgb.Dataset(val_x, val_y)\n        \n        model = lgb.train(\n            params, dtrain,\n            valid_sets=[dtrain, dvalid],\n            valid_names=['train', 'valid'],\n            early_stopping_rounds=50,\n            verbose_eval=verbose\n        ) \n        \n        val_pred = model.predict(val_x)\n        oof_pred[val_idx] = val_pred\n        \n        valid_score = np.sqrt(mean_squared_error(val_y, val_pred))\n        val_rmse_list.append(valid_score)\n        print(f\"RMSE : {valid_score:.5f}\")\n  \n        model_list.append(model)\n        \n    print(\"**\"*10,\"FINISH\",\"**\"*10)\n    oof_score = np.sqrt(mean_squared_error(y, oof_pred))\n    print(f\"oof_score:{oof_score}\")\n    val_score_df = pd.DataFrame({\"fold\" : np.arange(len(cv)), \"RMSE\" : val_rmse_list})\n    \n    return oof_pred, val_score_df, model_list","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.981305Z","iopub.execute_input":"2022-02-19T08:28:40.982215Z","iopub.status.idle":"2022-02-19T08:28:40.997692Z","shell.execute_reply.started":"2022-02-19T08:28:40.982134Z","shell.execute_reply":"2022-02-19T08:28:40.996536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# cleanning 3 pattern \ntqdm.pandas()\ntrain_1st_df[\"text_clean1\"] = train_1st_df['text'].progress_apply(text_cleaning_1)\ntrain_1st_df[\"text_clean2\"] = train_1st_df['text'].progress_apply(text_cleaning_2)\ntrain_1st_df[\"text_clean3\"] = train_1st_df['text'].progress_apply(text_cleaning_3)\n\ntrain_ruddit_df[\"text_clean1\"] = train_ruddit_df['text'].progress_apply(text_cleaning_1)\ntrain_ruddit_df[\"text_clean2\"] = train_ruddit_df['text'].progress_apply(text_cleaning_2)\ntrain_ruddit_df[\"text_clean3\"] = train_ruddit_df['text'].progress_apply(text_cleaning_3)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:28:40.99986Z","iopub.execute_input":"2022-02-19T08:28:41.000412Z","iopub.status.idle":"2022-02-19T08:30:44.268185Z","shell.execute_reply.started":"2022-02-19T08:28:41.000286Z","shell.execute_reply":"2022-02-19T08:30:44.2669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tf-idf / CountVec","metadata":{}},{"cell_type":"code","source":"# use_cols for tfidf\nuse_cols = [\n    \"text_clean1\",\n    \"text_clean2\",\n    \"text_clean3\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:30:44.269905Z","iopub.execute_input":"2022-02-19T08:30:44.271107Z","iopub.status.idle":"2022-02-19T08:30:44.276998Z","shell.execute_reply.started":"2022-02-19T08:30:44.271027Z","shell.execute_reply":"2022-02-19T08:30:44.275091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tfidf_dict(input_df, use_cols = use_cols):\n    '''\n       TF-IDF(char_wb & n_gram) dict for each preprocessed text  \n    '''\n    \n    tfidf_df_dict = {}\n    tfidf_vec_dict = {}\n    for _col in tqdm(use_cols):\n        tfidf_char,tfidf_char_vec = get_tfidf(input_df,_col,mode = \"char_wb\")\n        tfidf_ngram,tfidf_ngram_vec = get_tfidf(input_df,_col,mode = \"n_gram\")\n\n        print(tfidf_char.shape)\n        print(tfidf_ngram.shape)\n\n        tfidf_df_dict[f\"tfidf_char_{_col}\"] = tfidf_char\n        tfidf_df_dict[f\"tfidf_ngram_{_col}\"]= tfidf_ngram\n\n        tfidf_vec_dict[f\"tfidf_char_{_col}\"] = tfidf_char_vec\n        tfidf_vec_dict[f\"tfidf_ngram_{_col}\"] = tfidf_ngram_vec\n    \n    return tfidf_df_dict,tfidf_vec_dict","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:30:44.278775Z","iopub.execute_input":"2022-02-19T08:30:44.279779Z","iopub.status.idle":"2022-02-19T08:30:44.291882Z","shell.execute_reply.started":"2022-02-19T08:30:44.279729Z","shell.execute_reply":"2022-02-19T08:30:44.290515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_df_dict,tfidf_vec_dict = get_tfidf_dict(train_1st_df, use_cols = use_cols)\ntfidf_df_dict_ruddit,tfidf_vec_dict_ruddit = get_tfidf_dict(train_ruddit_df, use_cols = use_cols)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:30:44.293861Z","iopub.execute_input":"2022-02-19T08:30:44.295074Z","iopub.status.idle":"2022-02-19T08:33:37.584829Z","shell.execute_reply.started":"2022-02-19T08:30:44.295024Z","shell.execute_reply":"2022-02-19T08:33:37.583552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_pkl(file_name, processor):\n    OUTPUT_DIR = './'\n    file_name = os.path.join(OUTPUT_DIR,file_name)\n    pickle.dump(processor,open(file_name, 'wb'))\n    \n    print(\"FINISH\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:33:37.586778Z","iopub.execute_input":"2022-02-19T08:33:37.589336Z","iopub.status.idle":"2022-02-19T08:33:37.59618Z","shell.execute_reply.started":"2022-02-19T08:33:37.589281Z","shell.execute_reply":"2022-02-19T08:33:37.594824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_pkl(file_path):\n    out_object = pickle.load(open(file_path, 'rb'))   \n    return out_object","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:33:37.598163Z","iopub.execute_input":"2022-02-19T08:33:37.598931Z","iopub.status.idle":"2022-02-19T08:33:37.611275Z","shell.execute_reply.started":"2022-02-19T08:33:37.598881Z","shell.execute_reply":"2022-02-19T08:33:37.610005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"tfidf_vec_dict.pkl\",tfidf_vec_dict)\nsave_pkl(\"tfidf_vec_dict_ruddit.pkl\",tfidf_vec_dict_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:33:37.61285Z","iopub.execute_input":"2022-02-19T08:33:37.614038Z","iopub.status.idle":"2022-02-19T08:33:40.580228Z","shell.execute_reply.started":"2022-02-19T08:33:37.613902Z","shell.execute_reply":"2022-02-19T08:33:40.578945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SWEM\n### Gensim(GoogleNews)","metadata":{}},{"cell_type":"code","source":"%%time\nw2v_model = KeyedVectors.load(\"../input/gensim-googlenewsvectorsnegative300/GoogleNews-vectors-negative300.gensim\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:33:40.58573Z","iopub.execute_input":"2022-02-19T08:33:40.585978Z","iopub.status.idle":"2022-02-19T08:35:04.702056Z","shell.execute_reply.started":"2022-02-19T08:33:40.585944Z","shell.execute_reply":"2022-02-19T08:35:04.700856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get embeddings for each each preprocessed text\ngensim_df_dict = {}\ngensim_df_dict_ruddit = {}\nfor _col in tqdm(use_cols):\n    gensim_df_dict[f\"gensim_{_col}\"] = get_gensim_embed(train_1st_df[_col],ndim=300)\n    gensim_df_dict_ruddit[f\"gensim_{_col}\"] = get_gensim_embed(train_ruddit_df[_col],ndim=300)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:35:04.703851Z","iopub.execute_input":"2022-02-19T08:35:04.706388Z","iopub.status.idle":"2022-02-19T08:36:12.295744Z","shell.execute_reply.started":"2022-02-19T08:35:04.706329Z","shell.execute_reply":"2022-02-19T08:36:12.294448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fasttext","metadata":{}},{"cell_type":"code","source":"%%time\nfmodel = FastText.load('../input/jigsaw-regression-based-data/FastText-jigsaw-256D/Jigsaw-Fasttext-Word-Embeddings-256D.bin')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:36:12.297611Z","iopub.execute_input":"2022-02-19T08:36:12.298119Z","iopub.status.idle":"2022-02-19T08:36:42.291654Z","shell.execute_reply.started":"2022-02-19T08:36:12.298073Z","shell.execute_reply":"2022-02-19T08:36:42.290301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get embeddings for each each preprocessed text\nfasttext_df_dict = {}\nfasttext_df_dict_ruddit = {}\nfor _col in tqdm(use_cols):\n    fasttext_df_dict[f\"fasttext_{_col}\"] = get_fasttext_embed(train_1st_df[_col],ndim=256)\n    fasttext_df_dict_ruddit[f\"fasttext_{_col}\"] = get_fasttext_embed(train_ruddit_df[_col],ndim=256)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:36:42.293658Z","iopub.execute_input":"2022-02-19T08:36:42.29554Z","iopub.status.idle":"2022-02-19T08:38:42.490181Z","shell.execute_reply.started":"2022-02-19T08:36:42.295484Z","shell.execute_reply":"2022-02-19T08:38:42.488787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decomposition","metadata":{}},{"cell_type":"code","source":"def select_topfeat_and_svd(input_df_dict, y_for_select, classif = True):\n    '''\n        select top features for regression and SVD\n    '''\n    tfidf_filtered_SVD_dict = {}\n    tfidf_feat_selector = {}\n    tfidf_svd_transfomer = {}\n\n    for k,v in tqdm(input_df_dict.items()):\n        # select 5000 feats\n        if classif:\n            matrix_filtered, feat_selector = select_chi2_feature(v,y_for_select, k=5000)\n        else:\n            matrix_filtered, feat_selector = select_f_reg_feature(v,y_for_select, k=5000)\n        # SVD\n        out_feature, transfomer = make_decompositon_mat(matrix_filtered,\n                                                        n_components = 100,\n                                                        mode = \"svd\",\n                                                        random_state = 0 )\n\n        tfidf_filtered_SVD_dict[f\"{k}\"] = out_feature\n        tfidf_feat_selector[f\"{k}\"] = feat_selector\n        tfidf_svd_transfomer[f\"{k}\"] = transfomer\n\n    return tfidf_filtered_SVD_dict, tfidf_feat_selector, tfidf_svd_transfomer","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:38:42.49232Z","iopub.execute_input":"2022-02-19T08:38:42.492967Z","iopub.status.idle":"2022-02-19T08:38:42.50548Z","shell.execute_reply.started":"2022-02-19T08:38:42.492906Z","shell.execute_reply":"2022-02-19T08:38:42.503946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_for_chi2 = train_1st_df[\"target\"].values\ntfidf_filtered_SVD_dict, tfidf_feat_selector, tfidf_svd_transfomer = select_topfeat_and_svd(tfidf_df_dict, y_for_chi2, classif = False)\nprint(tfidf_filtered_SVD_dict.keys())\nprint(tfidf_feat_selector.keys())\nprint(tfidf_svd_transfomer.keys())","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:38:42.507594Z","iopub.execute_input":"2022-02-19T08:38:42.508432Z","iopub.status.idle":"2022-02-19T08:40:03.04869Z","shell.execute_reply.started":"2022-02-19T08:38:42.508365Z","shell.execute_reply":"2022-02-19T08:40:03.04722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"tfidf_feat_selector.pkl\",tfidf_feat_selector)\nsave_pkl(\"tfidf_svd_transfomer.pkl\",tfidf_svd_transfomer)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:40:03.050819Z","iopub.execute_input":"2022-02-19T08:40:03.05197Z","iopub.status.idle":"2022-02-19T08:40:03.180429Z","shell.execute_reply.started":"2022-02-19T08:40:03.051902Z","shell.execute_reply":"2022-02-19T08:40:03.179342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ruddit\ny_for_reg = train_ruddit_df[\"target\"].values\ntfidf_filtered_SVD_dict_ruddit, tfidf_feat_selector_ruddit, tfidf_svd_transfomer_ruddit = select_topfeat_and_svd(tfidf_df_dict_ruddit, y_for_reg, classif = False)\nprint(tfidf_filtered_SVD_dict_ruddit.keys())\nprint(tfidf_feat_selector_ruddit.keys())\nprint(tfidf_svd_transfomer_ruddit.keys())","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:40:03.182867Z","iopub.execute_input":"2022-02-19T08:40:03.183488Z","iopub.status.idle":"2022-02-19T08:40:10.059723Z","shell.execute_reply.started":"2022-02-19T08:40:03.183431Z","shell.execute_reply":"2022-02-19T08:40:10.058588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"tfidf_feat_selector_ruddit.pkl\",tfidf_feat_selector_ruddit)\nsave_pkl(\"tfidf_svd_transfomer_ruddit.pkl\",tfidf_svd_transfomer_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:40:10.06195Z","iopub.execute_input":"2022-02-19T08:40:10.062712Z","iopub.status.idle":"2022-02-19T08:40:10.204635Z","shell.execute_reply.started":"2022-02-19T08:40:10.06266Z","shell.execute_reply":"2022-02-19T08:40:10.203507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start traingings(jigsaw 1st)","metadata":{}},{"cell_type":"code","source":"fold = KFold(n_splits=5,shuffle=True,random_state=0)\n\ncv = list(fold.split(train_1st_df)) \ncv_ruddit = list(fold.split(train_ruddit_df)) \n\ny = train_1st_df[\"target\"]\ny_ruddit = train_ruddit_df[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:40:10.206617Z","iopub.execute_input":"2022-02-19T08:40:10.207024Z","iopub.status.idle":"2022-02-19T08:40:10.223518Z","shell.execute_reply.started":"2022-02-19T08:40:10.206976Z","shell.execute_reply":"2022-02-19T08:40:10.222263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge(TF-IDF)","metadata":{}},{"cell_type":"code","source":"alpha = 2\nridge_model_dict_1 = {}\nfor k,v in tfidf_df_dict.items():\n    print(\"=====\"*20)\n    print(\"Get Started.\")\n    print(f\"use_data : {k}\")\n    print(\"=====\"*20)\n    model = Ridge(alpha=alpha)\n    oof_pred, val_score_df, model_list = train(v, y, cv, model)\n    display(val_score_df)\n    ridge_model_dict_1[k] = model_list\n    \nprint(\"=====\"*20)\nprint(\"FINISHED.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:40:10.225757Z","iopub.execute_input":"2022-02-19T08:40:10.22612Z","iopub.status.idle":"2022-02-19T08:42:50.020223Z","shell.execute_reply.started":"2022-02-19T08:40:10.226061Z","shell.execute_reply":"2022-02-19T08:42:50.019204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"ridge_model_dict_1.pkl\",ridge_model_dict_1)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:42:50.024471Z","iopub.execute_input":"2022-02-19T08:42:50.028002Z","iopub.status.idle":"2022-02-19T08:42:50.062178Z","shell.execute_reply.started":"2022-02-19T08:42:50.027947Z","shell.execute_reply":"2022-02-19T08:42:50.061268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lgb","metadata":{}},{"cell_type":"code","source":"params ={\n    \"boosting_type\" : \"gbdt\",\n    \"objective\" : \"rmse\", \n    \"num_boost_round\": 10000,\n    \"max_depth\" : 5, \n    \"num_leaves\" : 28,  \n    \"learning_rate\": 0.05, \n    \"feature_fraction\" : 0.5, \n    'bagging_fraction': 0.8,\n    \"bagging_freq\" : 5, \n    \"seed\" : 42, \n    \"reg_alpha\":1, \n    \"reg_lambda\":1, \n    'min_child_samples': 20,\n    'verbose':-1\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:42:50.06366Z","iopub.execute_input":"2022-02-19T08:42:50.064257Z","iopub.status.idle":"2022-02-19T08:42:50.074054Z","shell.execute_reply.started":"2022-02-19T08:42:50.064207Z","shell.execute_reply":"2022-02-19T08:42:50.072545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lgb(gensim & Fasttext & basic_feat)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T17:35:35.654951Z","iopub.status.idle":"2022-01-22T17:35:35.655475Z","shell.execute_reply.started":"2022-01-22T17:35:35.655257Z","shell.execute_reply":"2022-01-22T17:35:35.655291Z"}}},{"cell_type":"code","source":"lgb_model_dict_2 = {}\nuse_basic_feat = [\"Num_character\", \"Num_word\"]\nfor _gen, _fast in zip(gensim_df_dict.items(),fasttext_df_dict.items()):\n    \n    mat = np.hstack([_gen[1], \n                     _fast[1],\n                     basic_feat_df[use_basic_feat].values\n                    ])\n    \n    name = f\"{_gen[0]}&{_fast[0]}&basic_feat\"\n    print(\"=====\"*20)\n    print(\"Get Started.\")\n    print(f\"use_data : {name}\")\n    print(\"=====\"*20)\n    oof_pred, val_score_df, model_list = fit_lgbm(mat, y,  cv=cv,params=params)\n    display(val_score_df)\n    lgb_model_dict_2[name] = model_list\n    \nprint(\"=====\"*20)\nprint(\"FINISHED.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T08:42:50.079053Z","iopub.execute_input":"2022-02-19T08:42:50.081322Z","iopub.status.idle":"2022-02-19T09:12:04.118768Z","shell.execute_reply.started":"2022-02-19T08:42:50.081264Z","shell.execute_reply":"2022-02-19T09:12:04.117557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"lgb_model_dict_2.pkl\",lgb_model_dict_2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:12:04.122374Z","iopub.execute_input":"2022-02-19T09:12:04.122594Z","iopub.status.idle":"2022-02-19T09:12:07.770716Z","shell.execute_reply.started":"2022-02-19T09:12:04.122566Z","shell.execute_reply":"2022-02-19T09:12:07.769631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lgb(TF-IDF(SVD))","metadata":{}},{"cell_type":"code","source":"concat_mat = []\nlgb_model_dict_3 = {}\nfor k,v in tfidf_filtered_SVD_dict.items():\n    concat_mat.append(v)\n    \nconcat_mat =  np.hstack(concat_mat)\noof_pred, val_score_df, model_list = fit_lgbm(concat_mat, y,  cv=cv,params=params)\nlgb_model_dict_3[\"TF-IDF(SVD)_600dim\"] = model_list\nprint(\"=====\"*20)\nprint(\"FINISHED.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:12:07.772553Z","iopub.execute_input":"2022-02-19T09:12:07.772902Z","iopub.status.idle":"2022-02-19T09:17:56.26911Z","shell.execute_reply.started":"2022-02-19T09:12:07.772854Z","shell.execute_reply":"2022-02-19T09:17:56.267875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"lgb_model_dict_3.pkl\",lgb_model_dict_3)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:17:56.270952Z","iopub.execute_input":"2022-02-19T09:17:56.271334Z","iopub.status.idle":"2022-02-19T09:17:56.918163Z","shell.execute_reply.started":"2022-02-19T09:17:56.27128Z","shell.execute_reply":"2022-02-19T09:17:56.917058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start training(ruddit)","metadata":{}},{"cell_type":"markdown","source":"### Ridge(TF-IDF)","metadata":{}},{"cell_type":"code","source":"alpha = 1\nridge_model_dict_1_ruddit = {}\nfor k,v in tfidf_df_dict_ruddit.items():\n    print(\"=====\"*20)\n    print(\"Get Started.\")\n    print(f\"use_data : {k}\")\n    print(\"=====\"*20)\n    model = Ridge(alpha=alpha)\n    oof_pred, val_score_df, model_list = train(v, y_ruddit, cv_ruddit, model)\n    display(val_score_df)\n    ridge_model_dict_1_ruddit[k] = model_list\n    \nprint(\"=====\"*20)\nprint(\"FINISHED.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:17:56.919881Z","iopub.execute_input":"2022-02-19T09:17:56.920243Z","iopub.status.idle":"2022-02-19T09:18:01.170349Z","shell.execute_reply.started":"2022-02-19T09:17:56.920196Z","shell.execute_reply":"2022-02-19T09:18:01.169248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"ridge_model_dict_1_ruddit.pkl\",ridge_model_dict_1_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:18:01.17242Z","iopub.execute_input":"2022-02-19T09:18:01.178967Z","iopub.status.idle":"2022-02-19T09:18:01.190959Z","shell.execute_reply.started":"2022-02-19T09:18:01.178911Z","shell.execute_reply":"2022-02-19T09:18:01.189584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lgb(gensim & Fasttext & basic_feat)","metadata":{}},{"cell_type":"code","source":"lgb_model_dict_1_ruddit = {}\nuse_basic_feat = [\"Num_character\", \"Num_word\"]\nfor _gen, _fast in zip(gensim_df_dict_ruddit.items(),fasttext_df_dict_ruddit.items()):\n    \n    mat = np.hstack([_gen[1], \n                     _fast[1],\n                     basic_feat_df_ruddit[use_basic_feat].values\n                    ])\n    \n    name = f\"{_gen[0]}&{_fast[0]}&basic_feat\"\n    print(\"=====\"*20)\n    print(\"Get Started.\")\n    print(f\"use_data : {name}\")\n    print(\"=====\"*20)\n    oof_pred, val_score_df, model_list = fit_lgbm(mat, y_ruddit,  cv=cv_ruddit,params=params)\n    display(val_score_df)\n    lgb_model_dict_1_ruddit[name] = model_list\n    \nprint(\"=====\"*20)\nprint(\"FINISHED.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:18:01.19378Z","iopub.execute_input":"2022-02-19T09:18:01.19636Z","iopub.status.idle":"2022-02-19T09:24:50.500964Z","shell.execute_reply.started":"2022-02-19T09:18:01.196299Z","shell.execute_reply":"2022-02-19T09:24:50.499818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"lgb_model_dict_1_ruddit.pkl\",lgb_model_dict_1_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:24:50.502855Z","iopub.execute_input":"2022-02-19T09:24:50.503459Z","iopub.status.idle":"2022-02-19T09:24:53.474113Z","shell.execute_reply.started":"2022-02-19T09:24:50.503415Z","shell.execute_reply":"2022-02-19T09:24:53.473202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lgb(TF-IDF(SVD))","metadata":{}},{"cell_type":"code","source":"concat_mat = []\nlgb_model_dict_2_ruddit = {}\nfor k,v in tfidf_filtered_SVD_dict_ruddit.items():\n    concat_mat.append(v)\n    \nconcat_mat =  np.hstack(concat_mat)\noof_pred, val_score_df, model_list = fit_lgbm(concat_mat, y_ruddit,  cv=cv_ruddit,params=params)\nlgb_model_dict_2_ruddit[\"TF-IDF(SVD)_600dim\"] = model_list\nprint(\"=====\"*20)\nprint(\"FINISHED.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:24:53.479033Z","iopub.execute_input":"2022-02-19T09:24:53.481766Z","iopub.status.idle":"2022-02-19T09:26:36.050879Z","shell.execute_reply.started":"2022-02-19T09:24:53.481705Z","shell.execute_reply":"2022-02-19T09:26:36.049875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pkl(\"lgb_model_dict_2_ruddit.pkl\",lgb_model_dict_2_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:26:36.052921Z","iopub.execute_input":"2022-02-19T09:26:36.053338Z","iopub.status.idle":"2022-02-19T09:26:36.460689Z","shell.execute_reply.started":"2022-02-19T09:26:36.053269Z","shell.execute_reply":"2022-02-19T09:26:36.45964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del (train_1st_df, \n     train_ruddit_df,\n     tfidf_df_dict,\n     tfidf_df_dict_ruddit,\n     gensim_df_dict,\n     gensim_df_dict_ruddit,\n     fasttext_df_dict, \n     fasttext_df_dict_ruddit, \n     tfidf_filtered_SVD_dict, \n     tfidf_filtered_SVD_dict_ruddit)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:26:36.462364Z","iopub.execute_input":"2022-02-19T09:26:36.463396Z","iopub.status.idle":"2022-02-19T09:26:37.430212Z","shell.execute_reply.started":"2022-02-19T09:26:36.463345Z","shell.execute_reply":"2022-02-19T09:26:37.429169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"# get unique text id of validation_data\nwhole_unique_sentence = validation_df[\"less_toxic\"].append(validation_df[\"more_toxic\"]).unique()\nsentence_master_dict = {_:i for i, _ in enumerate(whole_unique_sentence)}\nvalidation_df[\"less_toxic_id\"] = validation_df[\"less_toxic\"].map(sentence_master_dict)\nvalidation_df[\"more_toxic_id\"] = validation_df[\"more_toxic\"].map(sentence_master_dict)\ndel whole_unique_sentence\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:26:37.434941Z","iopub.execute_input":"2022-02-19T09:26:37.435221Z","iopub.status.idle":"2022-02-19T09:26:38.270127Z","shell.execute_reply.started":"2022-02-19T09:26:37.435188Z","shell.execute_reply":"2022-02-19T09:26:38.269062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df_for_pred = pd.DataFrame(data = {\"id\":sentence_master_dict.values(),\n                                       \"text\":sentence_master_dict.keys()\n                                      })\ndel sentence_master_dict\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:26:38.272097Z","iopub.execute_input":"2022-02-19T09:26:38.272489Z","iopub.status.idle":"2022-02-19T09:26:39.038667Z","shell.execute_reply.started":"2022-02-19T09:26:38.27244Z","shell.execute_reply":"2022-02-19T09:26:39.037106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### preprocess","metadata":{}},{"cell_type":"code","source":"%%time\ntqdm.pandas()\nval_df_for_pred[\"text_clean1\"] = val_df_for_pred['text'].progress_apply(text_cleaning_1)\nval_df_for_pred[\"text_clean2\"] = val_df_for_pred['text'].progress_apply(text_cleaning_2)\nval_df_for_pred[\"text_clean3\"] = val_df_for_pred['text'].progress_apply(text_cleaning_3)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:26:39.041048Z","iopub.execute_input":"2022-02-19T09:26:39.041773Z","iopub.status.idle":"2022-02-19T09:27:09.630447Z","shell.execute_reply.started":"2022-02-19T09:26:39.041714Z","shell.execute_reply":"2022-02-19T09:27:09.629186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### get tfidf","metadata":{}},{"cell_type":"code","source":"def get_val_tfidf_dict(vec_dict, val_df_for_pred):\n    out_dict = {}\n    for _name,_vec in tqdm(vec_dict.items()):\n        _col = \"_\".join(_name.split(\"_\")[-2:]) \n        out_dict[_name] = _vec.transform(val_df_for_pred[_col])\n    return out_dict","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:27:09.632221Z","iopub.execute_input":"2022-02-19T09:27:09.632799Z","iopub.status.idle":"2022-02-19T09:27:09.640476Z","shell.execute_reply.started":"2022-02-19T09:27:09.632749Z","shell.execute_reply":"2022-02-19T09:27:09.639381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_df_val_dict = get_val_tfidf_dict(tfidf_vec_dict, val_df_for_pred)\ntfidf_df_val_dict_ruddit = get_val_tfidf_dict(tfidf_vec_dict_ruddit, val_df_for_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:27:09.642334Z","iopub.execute_input":"2022-02-19T09:27:09.642977Z","iopub.status.idle":"2022-02-19T09:28:30.920514Z","shell.execute_reply.started":"2022-02-19T09:27:09.642918Z","shell.execute_reply":"2022-02-19T09:28:30.918968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SWEM(gensim /　fasttext)","metadata":{}},{"cell_type":"code","source":"gensim_df_val_dict = {}\nfor _col in tqdm(use_cols):\n    gensim_df_val_dict[f\"gensim_{_col}\"] = get_gensim_embed(val_df_for_pred[_col],ndim=300)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:28:30.922725Z","iopub.execute_input":"2022-02-19T09:28:30.925592Z","iopub.status.idle":"2022-02-19T09:28:48.849288Z","shell.execute_reply.started":"2022-02-19T09:28:30.925531Z","shell.execute_reply":"2022-02-19T09:28:48.847977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fasttext_df_val_dict = {}\nfor _col in tqdm(use_cols):\n    fasttext_df_val_dict[f\"fasttext_{_col}\"] = get_fasttext_embed(val_df_for_pred[_col],ndim=256)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:28:48.851297Z","iopub.execute_input":"2022-02-19T09:28:48.851895Z","iopub.status.idle":"2022-02-19T09:29:20.115927Z","shell.execute_reply.started":"2022-02-19T09:28:48.851846Z","shell.execute_reply":"2022-02-19T09:29:20.114896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### basic_feat","metadata":{}},{"cell_type":"code","source":"basic_feat_val_df = make_basic_feat(val_df_for_pred)\nbasic_feat_val_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:20.117567Z","iopub.execute_input":"2022-02-19T09:29:20.118387Z","iopub.status.idle":"2022-02-19T09:29:20.218639Z","shell.execute_reply.started":"2022-02-19T09:29:20.11834Z","shell.execute_reply":"2022-02-19T09:29:20.217417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### select feat and SVD","metadata":{}},{"cell_type":"code","source":"def get_val_select_topfeat_and_svd(tfidf_df_val_dict,selector_dict,svd_transfomer_dict):\n    svd_matrix_list = []\n    for i in tqdm(range(6)):\n        _mat = list(tfidf_df_val_dict.values())[i]\n        _selector = list(selector_dict.values())[i]\n        _svd_transformer = list(svd_transfomer_dict.values())[i]\n\n        _matrix_filtered = _selector.transform(_mat)\n        _svd_matrix = _svd_transformer.transform(_matrix_filtered)\n        svd_matrix_list.append(_svd_matrix)\n\n    val_svd_matrix =  np.hstack(svd_matrix_list)\n    return val_svd_matrix","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:20.221593Z","iopub.execute_input":"2022-02-19T09:29:20.222279Z","iopub.status.idle":"2022-02-19T09:29:20.230596Z","shell.execute_reply.started":"2022-02-19T09:29:20.222232Z","shell.execute_reply":"2022-02-19T09:29:20.22918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_svd_matrix = get_val_select_topfeat_and_svd(tfidf_df_val_dict,\n                                                tfidf_feat_selector,\n                                                tfidf_svd_transfomer)\nval_svd_matrix_ruddit = get_val_select_topfeat_and_svd(tfidf_df_val_dict_ruddit,\n                                                       tfidf_feat_selector_ruddit,\n                                                       tfidf_svd_transfomer_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:20.232503Z","iopub.execute_input":"2022-02-19T09:29:20.232994Z","iopub.status.idle":"2022-02-19T09:29:22.27168Z","shell.execute_reply.started":"2022-02-19T09:29:20.232912Z","shell.execute_reply":"2022-02-19T09:29:22.270566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(val_svd_matrix.shape)\nprint(val_svd_matrix_ruddit.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:22.273342Z","iopub.execute_input":"2022-02-19T09:29:22.274405Z","iopub.status.idle":"2022-02-19T09:29:22.282737Z","shell.execute_reply.started":"2022-02-19T09:29:22.274353Z","shell.execute_reply":"2022-02-19T09:29:22.281643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model_dict, df_val_dict):\n    preds_list = []\n    for _name,_model_list in model_dict.items():\n        _preds =[]\n        for i in range(len(cv)):\n            pred = _model_list[i].predict(df_val_dict[_name])\n            _preds.append(pred)\n        preds_list.append(np.mean(_preds, axis=0))\n    return preds_list","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:22.284443Z","iopub.execute_input":"2022-02-19T09:29:22.285628Z","iopub.status.idle":"2022-02-19T09:29:22.294872Z","shell.execute_reply.started":"2022-02-19T09:29:22.285574Z","shell.execute_reply":"2022-02-19T09:29:22.293611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scoring(pred):\n    val_df_for_pred[\"pred\"] = pred\n    scoring_dict = val_df_for_pred.set_index(\"id\")[\"pred\"].to_dict()\n    \n    validation_df[\"less_toxic_pred\"] = validation_df[\"less_toxic_id\"].map(scoring_dict)\n    validation_df[\"more_toxic_pred\"] = validation_df[\"more_toxic_id\"].map(scoring_dict)\n    validation_df[\"correct\"] = (validation_df[\"less_toxic_pred\"]  < validation_df[\"more_toxic_pred\"]).astype(int)\n    # スコア\n    print(validation_df[\"correct\"].mean())","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:22.296581Z","iopub.execute_input":"2022-02-19T09:29:22.297038Z","iopub.status.idle":"2022-02-19T09:29:22.307856Z","shell.execute_reply.started":"2022-02-19T09:29:22.296973Z","shell.execute_reply":"2022-02-19T09:29:22.305976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge_TFIDF_1st","metadata":{}},{"cell_type":"code","source":"_preds_list1 = valid(ridge_model_dict_1, tfidf_df_val_dict)\nfor _pred in _preds_list1:\n    scoring(_pred)\n    \nprint(\"ensemble\")\nscoring(np.mean(_preds_list1,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:22.309395Z","iopub.execute_input":"2022-02-19T09:29:22.311305Z","iopub.status.idle":"2022-02-19T09:29:23.026201Z","shell.execute_reply.started":"2022-02-19T09:29:22.311255Z","shell.execute_reply":"2022-02-19T09:29:23.025148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge_TFIDF_ruddit","metadata":{"execution":{"iopub.status.busy":"2022-01-23T10:21:41.943823Z","iopub.execute_input":"2022-01-23T10:21:41.944184Z","iopub.status.idle":"2022-01-23T10:21:41.948412Z","shell.execute_reply.started":"2022-01-23T10:21:41.944149Z","shell.execute_reply":"2022-01-23T10:21:41.947442Z"}}},{"cell_type":"code","source":"_preds_list2 = valid(ridge_model_dict_1_ruddit, tfidf_df_val_dict_ruddit)\nfor _pred in _preds_list2:\n    scoring(_pred)\n    \nprint(\"ensemble\")\nscoring(np.mean(_preds_list2,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:23.028612Z","iopub.execute_input":"2022-02-19T09:29:23.028935Z","iopub.status.idle":"2022-02-19T09:29:23.562031Z","shell.execute_reply.started":"2022-02-19T09:29:23.028893Z","shell.execute_reply":"2022-02-19T09:29:23.560644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lgb(gensim & Fasttext & basic_feat )","metadata":{}},{"cell_type":"code","source":"def valid2(lgb_model_dict):\n    preds_list = []\n    for i in tqdm(range(3)):\n        _gen = list(gensim_df_val_dict.values())[i]\n        _fast = list(fasttext_df_val_dict.values())[i]\n\n        mat = np.hstack([_gen,\n                         _fast,\n                         basic_feat_val_df[use_basic_feat].values\n                        ])\n\n        _preds =[]\n        _model_list = list(lgb_model_dict.values())[i]\n\n        for j in range(len(cv)):\n            pred = _model_list[j].predict(mat)\n            _preds.append(pred)\n        preds_list.append(np.mean(_preds, axis=0))\n    return preds_list","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:23.564691Z","iopub.execute_input":"2022-02-19T09:29:23.565151Z","iopub.status.idle":"2022-02-19T09:29:23.575835Z","shell.execute_reply.started":"2022-02-19T09:29:23.565089Z","shell.execute_reply":"2022-02-19T09:29:23.574313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#jigsaw 1st\npreds_list3 = valid2(lgb_model_dict_2)\n    \nfor _pred in preds_list3:\n    scoring(_pred)\n    \nprint(\"ensemble\")\nscoring(np.mean(preds_list3,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:23.577689Z","iopub.execute_input":"2022-02-19T09:29:23.57825Z","iopub.status.idle":"2022-02-19T09:29:51.563042Z","shell.execute_reply.started":"2022-02-19T09:29:23.578184Z","shell.execute_reply":"2022-02-19T09:29:51.561737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rudit\npreds_list4= valid2(lgb_model_dict_1_ruddit)\n    \nfor _pred in preds_list4:\n    scoring(_pred)\n    \nprint(\"ensemble\")\nscoring(np.mean(preds_list4,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:29:51.57411Z","iopub.execute_input":"2022-02-19T09:29:51.574416Z","iopub.status.idle":"2022-02-19T09:30:08.475866Z","shell.execute_reply.started":"2022-02-19T09:29:51.574387Z","shell.execute_reply":"2022-02-19T09:30:08.47463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lgb TF-IDF(SVD) only","metadata":{}},{"cell_type":"code","source":"# jigsaw 1st\npreds5 = []\nfor _model in lgb_model_dict_3['TF-IDF(SVD)_600dim']:\n    pred = _model.predict(val_svd_matrix)\n    preds5.append(pred)\nscoring(np.mean(preds5,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:30:08.477966Z","iopub.execute_input":"2022-02-19T09:30:08.478325Z","iopub.status.idle":"2022-02-19T09:30:13.550635Z","shell.execute_reply.started":"2022-02-19T09:30:08.478277Z","shell.execute_reply":"2022-02-19T09:30:13.549529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ruddit\npreds6 = []\nfor _model in lgb_model_dict_2_ruddit['TF-IDF(SVD)_600dim']:\n    pred = _model.predict(val_svd_matrix_ruddit)\n    preds6.append(pred)\nscoring(np.mean(preds6,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:30:13.552174Z","iopub.execute_input":"2022-02-19T09:30:13.553314Z","iopub.status.idle":"2022-02-19T09:30:17.586006Z","shell.execute_reply.started":"2022-02-19T09:30:13.553246Z","shell.execute_reply":"2022-02-19T09:30:17.584849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del w2v_model,fmodel\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:30:17.587799Z","iopub.execute_input":"2022-02-19T09:30:17.58803Z","iopub.status.idle":"2022-02-19T09:30:18.794724Z","shell.execute_reply.started":"2022-02-19T09:30:17.588001Z","shell.execute_reply":"2022-02-19T09:30:18.793325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RoBERTa(validation)","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\nclass JigsawDataset(Dataset):\n    def __init__(self, CFG, input_df, is_train=True):\n        self.CFG = CFG\n        self.is_train = is_train \n        self.text = input_df[self.CFG.text].values\n        self.tokenizer = AutoTokenizer.from_pretrained(self.CFG.model_name)\n        if self.is_train:\n            self.labels = input_df[self.CFG.target].values       \n             \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        text =  self.text[idx]\n        encoded = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.CFG.max_len,\n            padding='max_length'\n        )\n        input_ids = torch.tensor(encoded['input_ids'])\n        attention_mask = torch.tensor(encoded['attention_mask'])\n        \n        if self.is_train:\n            label = torch.tensor(self.labels[idx])\n            return input_ids, attention_mask, label\n        return input_ids, attention_mask\n    \nclass JigsawModel(nn.Module):\n    def __init__(self, CFG):\n        super().__init__()\n        self.CFG = CFG\n        self.model = AutoModel.from_pretrained(self.CFG.model_name)\n        self.fc_dropout = nn.Dropout(self.CFG.fc_dropout)\n        self.fc = nn.Linear(self.CFG.hidden_size, self.CFG.target_size)\n    \n    def forward(self, input_ids, attention_mask):\n        out = self.model(input_ids = input_ids, \n                         attention_mask = attention_mask)       \n        out = self.fc_dropout(out[1])\n        outputs = self.fc(out)\n        return outputs\n\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    \n    for step, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total = len(test_loader)):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        \n        with torch.no_grad():\n            y_preds = model(input_ids, attention_mask)\n        preds.append(y_preds.to(\"cpu\").numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:30:18.797232Z","iopub.execute_input":"2022-02-19T09:30:18.797843Z","iopub.status.idle":"2022-02-19T09:30:18.820613Z","shell.execute_reply.started":"2022-02-19T09:30:18.797791Z","shell.execute_reply":"2022-02-19T09:30:18.819347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = JigsawDataset(CFG, val_df_for_pred, is_train = False)\nval_loader = DataLoader(val_dataset, \n                        batch_size=CFG.batch_size,\n                        shuffle=False,\n                        num_workers=CFG.num_workers, \n                        pin_memory=True, \n                        drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:30:18.822368Z","iopub.execute_input":"2022-02-19T09:30:18.822855Z","iopub.status.idle":"2022-02-19T09:30:19.197847Z","shell.execute_reply.started":"2022-02-19T09:30:18.82278Z","shell.execute_reply":"2022-02-19T09:30:19.196639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_preds = []\nfor fold in range(CFG.n_fold):\n    model = JigsawModel(CFG)\n    state = torch.load(CFG.model_dir+f\"/{CFG.model_name.split('/')[-1]}_fold{fold}_best.pth\", map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(val_loader, model, device)\n    bert_preds.append(prediction)\n    del model, state; gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:30:19.200301Z","iopub.execute_input":"2022-02-19T09:30:19.200886Z","iopub.status.idle":"2022-02-19T09:38:43.779695Z","shell.execute_reply.started":"2022-02-19T09:30:19.200842Z","shell.execute_reply":"2022-02-19T09:38:43.778611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scoring(np.mean(bert_preds,axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:43.781848Z","iopub.execute_input":"2022-02-19T09:38:43.782168Z","iopub.status.idle":"2022-02-19T09:38:43.853434Z","shell.execute_reply.started":"2022-02-19T09:38:43.782124Z","shell.execute_reply":"2022-02-19T09:38:43.852194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del val_dataset, val_loader; gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:43.855328Z","iopub.execute_input":"2022-02-19T09:38:43.855703Z","iopub.status.idle":"2022-02-19T09:38:44.556227Z","shell.execute_reply.started":"2022-02-19T09:38:43.855656Z","shell.execute_reply":"2022-02-19T09:38:44.555002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr1 = np.mean(_preds_list1,axis = 0) # 1st-ridge\npr2 = np.mean(_preds_list2,axis = 0) # ruddit-ridge\npr3 = np.mean(preds_list3,axis = 0) # 1st-lgb\npr4 = np.mean(preds_list4,axis = 0) # ruddit-lgb\npr5 = np.mean(preds5,axis = 0) # 1st-lgb-svd\npr6 = np.mean(preds6,axis = 0) # ruddit-lgb-svd\npr7 = np.mean(bert_preds,axis = 0) # bert \n\nscaler = MinMaxScaler() \npr1_scaled = scaler.fit_transform(pr1.reshape(-1,1))\npr2_scaled = scaler.fit_transform(pr2.reshape(-1,1))\npr3_scaled = scaler.fit_transform(pr3.reshape(-1,1))\npr4_scaled = scaler.fit_transform(pr4.reshape(-1,1))\npr5_scaled = scaler.fit_transform(pr5.reshape(-1,1))\npr6_scaled = scaler.fit_transform(pr6.reshape(-1,1))\npr7_scaled = scaler.fit_transform(pr7.reshape(-1,1))\n\npred_scaled_mat = np.hstack([pr1_scaled,\n                             pr2_scaled,\n                             pr3_scaled,\n                             pr4_scaled,\n                             pr5_scaled,\n                             pr6_scaled,\n                             pr7_scaled\n                            ])","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:44.557887Z","iopub.execute_input":"2022-02-19T09:38:44.55905Z","iopub.status.idle":"2022-02-19T09:38:44.58071Z","shell.execute_reply.started":"2022-02-19T09:38:44.558988Z","shell.execute_reply":"2022-02-19T09:38:44.579579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### save pred for validation","metadata":{}},{"cell_type":"code","source":"def make_valid_pred(pred_scaled_mat):\n    for i in range(pred_scaled_mat.shape[1]):\n        val_df_for_pred[\"pred\"] = pred_scaled_mat[:,i]\n        scoring_dict = val_df_for_pred.set_index(\"id\")[\"pred\"].to_dict()  \n        validation_df[f\"Morita_less_toxic_pred_{i}\"] = validation_df[\"less_toxic_id\"].map(scoring_dict)\n        validation_df[f\"Morita_more_toxic_pred_{i}\"] = validation_df[\"more_toxic_id\"].map(scoring_dict)\n    return validation_df","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:44.582778Z","iopub.execute_input":"2022-02-19T09:38:44.58345Z","iopub.status.idle":"2022-02-19T09:38:44.590837Z","shell.execute_reply.started":"2022-02-19T09:38:44.583403Z","shell.execute_reply":"2022-02-19T09:38:44.589901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df_add_pred = make_valid_pred(pred_scaled_mat)\ndrop_cols_for_valid = [\"less_toxic_id\",\"more_toxic_id\",\"correct\",\"less_toxic_pred\",\"more_toxic_pred\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:44.593159Z","iopub.execute_input":"2022-02-19T09:38:44.594047Z","iopub.status.idle":"2022-02-19T09:38:44.860733Z","shell.execute_reply.started":"2022-02-19T09:38:44.593974Z","shell.execute_reply":"2022-02-19T09:38:44.859654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df_add_pred = validation_df_add_pred.drop(drop_cols_for_valid,axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:44.862535Z","iopub.execute_input":"2022-02-19T09:38:44.862993Z","iopub.status.idle":"2022-02-19T09:38:44.878892Z","shell.execute_reply.started":"2022-02-19T09:38:44.862951Z","shell.execute_reply":"2022-02-19T09:38:44.877682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df_add_pred.to_csv(\"./validation_df_add_pred.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:44.880648Z","iopub.execute_input":"2022-02-19T09:38:44.881042Z","iopub.status.idle":"2022-02-19T09:38:46.555571Z","shell.execute_reply.started":"2022-02-19T09:38:44.880999Z","shell.execute_reply":"2022-02-19T09:38:46.554468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df_add_pred.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:38:51.54818Z","iopub.execute_input":"2022-02-19T09:38:51.549028Z","iopub.status.idle":"2022-02-19T09:38:51.576534Z","shell.execute_reply.started":"2022-02-19T09:38:51.548969Z","shell.execute_reply":"2022-02-19T09:38:51.575475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}