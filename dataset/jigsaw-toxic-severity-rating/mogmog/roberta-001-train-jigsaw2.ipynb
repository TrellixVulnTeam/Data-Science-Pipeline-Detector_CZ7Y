{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class CFG:\n    debug=False\n    seed=42\n    n_fold = 4\n    model_name = \"../input/roberta-base-edited\"\n    max_len = 256\n    text=\"text\"\n    target=\"target\"\n    target_size = 1\n    hidden_size = 768\n    fc_dropout = 0.\n    print_freq=50\n    n_accumulate = 1\n    batch_size = 32\n    num_workers = 4\n    no_decay = True \n    weight_decay = 0.\n    lr = 1e-5\n    scheduler = \"cosine\"\n    num_cycles = 1\n    num_warmup_steps = 80\n    epochs = 4","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:33:46.30493Z","iopub.execute_input":"2022-02-04T16:33:46.305195Z","iopub.status.idle":"2022-02-04T16:33:46.31226Z","shell.execute_reply.started":"2022-02-04T16:33:46.305166Z","shell.execute_reply":"2022-02-04T16:33:46.311488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport gc\nimport time\nimport math\nimport random\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import OneCycleLR\n# NLP\nfrom transformers import AutoTokenizer, AutoModel,get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\nfrom bs4 import BeautifulSoup\n\npd.set_option(\"max_columns\",100)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:33:19.371785Z","iopub.execute_input":"2022-02-04T16:33:19.372055Z","iopub.status.idle":"2022-02-04T16:33:26.963017Z","shell.execute_reply.started":"2022-02-04T16:33:19.372028Z","shell.execute_reply":"2022-02-04T16:33:26.962305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything()\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:33:26.964534Z","iopub.execute_input":"2022-02-04T16:33:26.964777Z","iopub.status.idle":"2022-02-04T16:33:27.017846Z","shell.execute_reply.started":"2022-02-04T16:33:26.964745Z","shell.execute_reply":"2022-02-04T16:33:27.017097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"train_1st_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntrain_1st_test_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\ntrain_1st_test_lb_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n\nvalidation_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntrain_1st_test_df = train_1st_test_df.merge(train_1st_test_lb_df, on='id')\n\ndrop_idx = (train_1st_test_df.loc[:,\"toxic\":]==-1).sum(axis = 1) >=1\ntrain_1st_test_df = train_1st_test_df[~drop_idx].reset_index(drop=True)\n\ntrain_1st_df = pd.concat([train_1st_df,train_1st_test_df]).reset_index(drop = True)\n\nif CFG.debug:\n    train_1st_df =  train_1st_df.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:34:06.430482Z","iopub.execute_input":"2022-02-04T16:34:06.431194Z","iopub.status.idle":"2022-02-04T16:34:09.837059Z","shell.execute_reply.started":"2022-02-04T16:34:06.431154Z","shell.execute_reply":"2022-02-04T16:34:09.836257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.780828Z","iopub.execute_input":"2022-01-25T00:20:37.781134Z","iopub.status.idle":"2022-01-25T00:20:37.78734Z","shell.execute_reply.started":"2022-01-25T00:20:37.781098Z","shell.execute_reply":"2022-01-25T00:20:37.784726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.788822Z","iopub.execute_input":"2022-01-25T00:20:37.789096Z","iopub.status.idle":"2022-01-25T00:20:37.797081Z","shell.execute_reply.started":"2022-01-25T00:20:37.789055Z","shell.execute_reply":"2022-01-25T00:20:37.796182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train/notebook\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.798757Z","iopub.execute_input":"2022-01-25T00:20:37.799261Z","iopub.status.idle":"2022-01-25T00:20:37.807981Z","shell.execute_reply.started":"2022-01-25T00:20:37.799224Z","shell.execute_reply":"2022-01-25T00:20:37.807286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_fold(input_df):\n    Fold = KFold(n_splits=CFG.n_fold,random_state=CFG.seed,shuffle=True)\n    outdf = input_df.copy()\n    for n, (trn_index, val_index) in enumerate(Fold.split(outdf)):\n        outdf.loc[val_index, 'fold'] = int(n)\n    outdf['fold'] = outdf['fold'].astype(int)\n    display(outdf.groupby('fold').size())\n    return outdf","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.812006Z","iopub.execute_input":"2022-01-25T00:20:37.812328Z","iopub.status.idle":"2022-01-25T00:20:37.819982Z","shell.execute_reply.started":"2022-01-25T00:20:37.812266Z","shell.execute_reply":"2022-01-25T00:20:37.819196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset(Dataset):\n    def __init__(self, CFG, input_df, is_train=True):\n        self.CFG = CFG\n        self.is_train = is_train \n        self.text = input_df[self.CFG.text].values\n        self.tokenizer = AutoTokenizer.from_pretrained(self.CFG.model_name)\n        if self.is_train:\n            self.labels = input_df[self.CFG.target].values       \n             \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        text =  self.text[idx]\n        encoded = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.CFG.max_len,\n            padding='max_length'\n        )\n        input_ids = torch.tensor(encoded['input_ids'])\n        attention_mask = torch.tensor(encoded['attention_mask'])\n        \n        if self.is_train:\n            label = torch.tensor(self.labels[idx])\n            return input_ids, attention_mask, label\n        return input_ids, attention_mask","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.821467Z","iopub.execute_input":"2022-01-25T00:20:37.821807Z","iopub.status.idle":"2022-01-25T00:20:37.833105Z","shell.execute_reply.started":"2022-01-25T00:20:37.821763Z","shell.execute_reply":"2022-01-25T00:20:37.832212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawModel(nn.Module):\n    def __init__(self, CFG):\n        super().__init__()\n        self.CFG = CFG\n        self.model = AutoModel.from_pretrained(self.CFG.model_name)\n        self.fc_dropout = nn.Dropout(self.CFG.fc_dropout)\n        self.fc = nn.Linear(self.CFG.hidden_size, self.CFG.target_size)\n    \n    def forward(self, input_ids, attention_mask):\n        out = self.model(input_ids = input_ids, \n                         attention_mask = attention_mask)\n        \n        out = self.fc_dropout(out[1])\n        outputs = self.fc(out)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.83626Z","iopub.execute_input":"2022-01-25T00:20:37.836474Z","iopub.status.idle":"2022-01-25T00:20:37.845731Z","shell.execute_reply.started":"2022-01-25T00:20:37.836449Z","shell.execute_reply":"2022-01-25T00:20:37.844845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):   \n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.846897Z","iopub.execute_input":"2022-01-25T00:20:37.847352Z","iopub.status.idle":"2022-01-25T00:20:37.857832Z","shell.execute_reply.started":"2022-01-25T00:20:37.847305Z","shell.execute_reply":"2022-01-25T00:20:37.85699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utils\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return \"%dm %ds\" % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.85942Z","iopub.execute_input":"2022-01-25T00:20:37.859719Z","iopub.status.idle":"2022-01-25T00:20:37.867247Z","shell.execute_reply.started":"2022-01-25T00:20:37.85968Z","shell.execute_reply":"2022-01-25T00:20:37.866543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scheduler(CFG, optimizer, num_train_steps):\n    # https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_cosine_schedule_with_warmup\n    if CFG.scheduler=='linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, \n            num_warmup_steps=CFG.num_warmup_steps, \n            num_training_steps=num_train_steps\n        )\n    elif CFG.scheduler=='cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=CFG.num_warmup_steps,\n            num_training_steps=num_train_steps, \n            num_cycles=CFG.num_cycles\n        )\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.868838Z","iopub.execute_input":"2022-01-25T00:20:37.869105Z","iopub.status.idle":"2022-01-25T00:20:37.876162Z","shell.execute_reply.started":"2022-01-25T00:20:37.869068Z","shell.execute_reply":"2022-01-25T00:20:37.875356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    start = end = time.time()\n    losses = AverageMeter()\n    \n    model.train()\n    \n    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device).reshape(-1, 1).float()\n        batch_size = labels.size(0)\n        y_preds = model(input_ids, attention_mask)\n\n        \n        loss = criterion(y_preds, labels)\n        \n        losses.update(loss.item(), batch_size)\n        loss.backward()\n        \n        if (step + 1) % CFG.n_accumulate == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            if scheduler is not None:\n                scheduler.step()\n        \n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print(\n                f\"Epoch:[{epoch + 1}][{step}/{len(train_loader)}] \"\n                f\"Elapsed:{timeSince(start, float(step + 1) / len(train_loader))} \"\n                f\"Loss:{losses.avg:.4f} \"\n                f\"LR:{scheduler.get_lr()[0]:.8f}\"\n            )\n    return losses.avg","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.877602Z","iopub.execute_input":"2022-01-25T00:20:37.878073Z","iopub.status.idle":"2022-01-25T00:20:37.888847Z","shell.execute_reply.started":"2022-01-25T00:20:37.878036Z","shell.execute_reply":"2022-01-25T00:20:37.887912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, criterion, epoch, device):\n    start = end = time.time()\n    losses = AverageMeter()\n    \n    model.eval()\n    preds = []\n    \n    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device).reshape(-1, 1).float()\n        batch_size = labels.size(0)\n        \n        with torch.no_grad():\n            y_preds = model(input_ids, attention_mask)\n        \n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        \n        preds.append(y_preds.to(\"cpu\").numpy())\n        \n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print(\n                f\"Epoch:[{epoch + 1}][{step}/{len(valid_loader)}] \"\n                f\"Elapsed:{timeSince(start, float(step + 1) / len(valid_loader))} \"\n                f\"Loss:{losses.avg:.4f} \"\n            )\n            \n    predictions = np.concatenate(preds)\n    \n    return losses.avg, predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.891532Z","iopub.execute_input":"2022-01-25T00:20:37.892077Z","iopub.status.idle":"2022-01-25T00:20:37.902458Z","shell.execute_reply.started":"2022-01-25T00:20:37.892037Z","shell.execute_reply":"2022-01-25T00:20:37.901757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    \n    for step, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total = len(test_loader)):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        \n        with torch.no_grad():\n            y_preds = model(input_ids, attention_mask)\n        preds.append(y_preds.to(\"cpu\").numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.905287Z","iopub.execute_input":"2022-01-25T00:20:37.905535Z","iopub.status.idle":"2022-01-25T00:20:37.914447Z","shell.execute_reply.started":"2022-01-25T00:20:37.905509Z","shell.execute_reply":"2022-01-25T00:20:37.913764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(train_df, fold):\n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n    # ====================================================\n    # Data Loader\n    # ====================================================\n    trn_idx = train_df[train_df[\"fold\"] != fold].index\n    val_idx = train_df[train_df[\"fold\"] == fold].index\n    \n    train_folds = train_df.loc[trn_idx].reset_index(drop=True)\n    valid_folds = train_df.loc[val_idx].reset_index(drop=True)\n    \n    train_dataset = JigsawDataset(CFG, train_folds, is_train=True)\n    valid_dataset = JigsawDataset(CFG, valid_folds, is_train=True)\n    \n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, \n                              pin_memory=True, \n                              drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, \n                              pin_memory=True, \n                              drop_last=False)\n    \n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = JigsawModel(CFG)\n    model = model.to(device)\n    \n    if CFG.no_decay:\n        param_optimizer = list(model.named_parameters())\n        no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': CFG.weight_decay},\n            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters, lr=CFG.lr)\n    else:\n        optimizer = AdamW(model.parameters(), lr=CFG.lr)\n    \n    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n    \n    criterion = nn.MSELoss() \n    \n    # ====================================================\n    # Loop\n    # ====================================================\n    \n    best_score = np.inf \n    best_loss = np.inf \n    \n    for epoch in range(CFG.epochs):\n        start_time = time.time()\n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n        # eval\n        print(\"eval start\")\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, epoch, device)\n        \n        elapsed = time.time() - start_time\n        LOGGER.info(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n        \n        if avg_val_loss<= best_loss:\n            best_loss = avg_val_loss\n            \n            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_loss:.4f} Model\")\n            torch.save(\n                {\"model\": model.state_dict(),\n                 \"preds\": preds\n                }, \n                os.path.join(OUTPUT_DIR+f\"{CFG.model_name.split('/')[-1]}_fold{fold}_best.pth\")\n            )\n    preds = torch.load(OUTPUT_DIR+f\"{CFG.model_name.split('/')[-1]}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))['preds']\n    valid_folds[\"preds\"] = preds\n    \n    del model,train_loader,valid_loader\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.917719Z","iopub.execute_input":"2022-01-25T00:20:37.917949Z","iopub.status.idle":"2022-01-25T00:20:37.937621Z","shell.execute_reply.started":"2022-01-25T00:20:37.917924Z","shell.execute_reply":"2022-01-25T00:20:37.936694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    # Training\n    oof_df = pd.DataFrame()\n    for fold in range(CFG.n_fold):\n    #for fold in range(1):\n        _oof_df = train_loop(train_df, fold)\n        oof_df = pd.concat([oof_df, _oof_df])\n        LOGGER.info(f\"========== fold: {fold} result ==========\")\n    # CV result\n    LOGGER.info(f\"========== CV ==========\")\n    return oof_df","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.938918Z","iopub.execute_input":"2022-01-25T00:20:37.939783Z","iopub.status.idle":"2022-01-25T00:20:37.956009Z","shell.execute_reply.started":"2022-01-25T00:20:37.939738Z","shell.execute_reply":"2022-01-25T00:20:37.955267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt_validation_df = pd.concat([validation_df[\"less_toxic\"],validation_df[\"more_toxic\"]]) \ntxt_1st =train_1st_df[\"comment_text\"] \n\nvenn2(subsets=(set(txt_validation_df), set(txt_1st)),set_labels=(\"validation_df\", \"1st\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:37.976762Z","iopub.execute_input":"2022-01-25T00:20:37.977053Z","iopub.status.idle":"2022-01-25T00:20:38.23776Z","shell.execute_reply.started":"2022-01-25T00:20:37.977015Z","shell.execute_reply":"2022-01-25T00:20:38.236972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Before:{len(train_1st_df)}\")\nval_text_list = list(set(txt_validation_df))\ndup_idx = train_1st_df[\"comment_text\"].isin(val_text_list)\nprint(f\"Num_duplicate_text_{sum(dup_idx)}\")\ntrain_1st_df = train_1st_df[~dup_idx].reset_index(drop=True)\nprint(f\"After:{len(train_1st_df)}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:38.238948Z","iopub.execute_input":"2022-01-25T00:20:38.239225Z","iopub.status.idle":"2022-01-25T00:20:38.331149Z","shell.execute_reply.started":"2022-01-25T00:20:38.239186Z","shell.execute_reply":"2022-01-25T00:20:38.330364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt_validation_df = pd.concat([validation_df[\"less_toxic\"],validation_df[\"more_toxic\"]]) \ntxt_1st =train_1st_df[\"comment_text\"] \nvenn2(subsets=(set(txt_validation_df), set(txt_1st)),set_labels=(\"validation_df\", \"1st\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:38.332587Z","iopub.execute_input":"2022-01-25T00:20:38.333056Z","iopub.status.idle":"2022-01-25T00:20:38.483879Z","shell.execute_reply.started":"2022-01-25T00:20:38.333012Z","shell.execute_reply":"2022-01-25T00:20:38.483135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del txt_validation_df,txt_1st, val_text_list\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:38.485354Z","iopub.execute_input":"2022-01-25T00:20:38.485616Z","iopub.status.idle":"2022-01-25T00:20:38.674642Z","shell.execute_reply.started":"2022-01-25T00:20:38.485582Z","shell.execute_reply":"2022-01-25T00:20:38.673747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    train_1st_df[category] = train_1st_df[category] * cat_mtpl[category]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:38.676132Z","iopub.execute_input":"2022-01-25T00:20:38.67694Z","iopub.status.idle":"2022-01-25T00:20:38.693993Z","shell.execute_reply.started":"2022-01-25T00:20:38.676899Z","shell.execute_reply":"2022-01-25T00:20:38.693312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1st_df[\"target\"] = train_1st_df.loc[:, \"toxic\":\"identity_hate\"].sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:38.725246Z","iopub.execute_input":"2022-01-25T00:20:38.725711Z","iopub.status.idle":"2022-01-25T00:20:38.74872Z","shell.execute_reply.started":"2022-01-25T00:20:38.725679Z","shell.execute_reply":"2022-01-25T00:20:38.747962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1st_df[\"target\"].hist(bins = 10)\ntrain_1st_df[\"target\"].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:38.750109Z","iopub.execute_input":"2022-01-25T00:20:38.750529Z","iopub.status.idle":"2022-01-25T00:20:39.003254Z","shell.execute_reply.started":"2022-01-25T00:20:38.75048Z","shell.execute_reply":"2022-01-25T00:20:39.002596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_1st_df[train_1st_df[\"target\"]==0])/len(train_1st_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:39.004556Z","iopub.execute_input":"2022-01-25T00:20:39.004978Z","iopub.status.idle":"2022-01-25T00:20:39.03282Z","shell.execute_reply.started":"2022-01-25T00:20:39.00494Z","shell.execute_reply":"2022-01-25T00:20:39.031873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frac = 0.05\nzero_sample_df = train_1st_df[train_1st_df[\"target\"]==0].sample(frac = frac,random_state = 1)\nnon_zero_df = train_1st_df[train_1st_df[\"target\"]!=0]\ntrain_df = pd.concat([zero_sample_df,non_zero_df]).sort_index().reset_index(drop=True)\n\n# sampling_result\nprint(f\"before_len:{len(train_1st_df)}\")\nprint(f\"after_len:{len(train_df)}\")\nprint(f\"Ratio :{len(train_df)/len(train_1st_df)}\")\n\ndel train_1st_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:39.034355Z","iopub.execute_input":"2022-01-25T00:20:39.034607Z","iopub.status.idle":"2022-01-25T00:20:39.253446Z","shell.execute_reply.started":"2022-01-25T00:20:39.034573Z","shell.execute_reply":"2022-01-25T00:20:39.252633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"].hist(bins = 40)\ntrain_df[\"target\"].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:39.254874Z","iopub.execute_input":"2022-01-25T00:20:39.255465Z","iopub.status.idle":"2022-01-25T00:20:39.541849Z","shell.execute_reply.started":"2022-01-25T00:20:39.255423Z","shell.execute_reply":"2022-01-25T00:20:39.541156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.rename(columns = {\"comment_text\":\"text\"})\ntrain_df[\"text\"] = train_df[\"text\"].apply(lambda x:text_cleaning(x))\ntrain_df = create_fold(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:39.544177Z","iopub.execute_input":"2022-01-25T00:20:39.544452Z","iopub.status.idle":"2022-01-25T00:20:46.010996Z","shell.execute_reply.started":"2022-01-25T00:20:39.544422Z","shell.execute_reply":"2022-01-25T00:20:46.010173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    oof_df = main()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T00:20:46.012554Z","iopub.execute_input":"2022-01-25T00:20:46.012819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.debug:\n    validation_df = validation_df.sample(n=100, random_state=CFG.seed).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole_unique_sentence = validation_df[\"less_toxic\"].append(validation_df[\"more_toxic\"]).unique()\nsentence_master_dict = {_:i for i, _ in enumerate(whole_unique_sentence)}\nvalidation_df[\"less_toxic_id\"] = validation_df[\"less_toxic\"].map(sentence_master_dict)\nvalidation_df[\"more_toxic_id\"] = validation_df[\"more_toxic\"].map(sentence_master_dict)\ndel whole_unique_sentence\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df_for_pred = pd.DataFrame(data = {\"id\":sentence_master_dict.values(),\n                                       \"text\":sentence_master_dict.keys()\n                                      })\ndel sentence_master_dict\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df_for_pred[\"text\"] = val_df_for_pred[\"text\"].apply(lambda x:text_cleaning(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = JigsawDataset(CFG, val_df_for_pred, is_train = False)\nval_loader = DataLoader(val_dataset, \n                        batch_size=CFG.batch_size,\n                        shuffle=False,\n                        num_workers=CFG.num_workers, \n                        pin_memory=True, \n                        drop_last=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor fold in range(CFG.n_fold):\n    model = JigsawModel(CFG)\n    state = torch.load(\"./\"+f\"{CFG.model_name.split('/')[-1]}_fold{fold}_best.pth\", map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(val_loader, model, device)\n    predictions.append(prediction)\n    del model, state; gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df_for_pred[\"pred\"] = np.mean(predictions, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scoring_dict = val_df_for_pred.set_index(\"id\")[\"pred\"].to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df[\"less_toxic_pred\"] = validation_df[\"less_toxic_id\"].map(scoring_dict)\nvalidation_df[\"more_toxic_pred\"] = validation_df[\"more_toxic_id\"].map(scoring_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df[\"correct\"] = (validation_df[\"less_toxic_pred\"]  < validation_df[\"more_toxic_pred\"]).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df[\"correct\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}