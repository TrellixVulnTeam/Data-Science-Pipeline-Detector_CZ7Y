{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This simple notebook shows how *detoxify* package can be used in an offline mode.\n\n**Changelog:**\n* V3 - specified a device to use\n* V2 - max_len can be now set to a desired  value","metadata":{}},{"cell_type":"code","source":"!cp -r ../input/detoxify/detoxify-master detoxify\n!pip install -q ./detoxify\n!rm -rf ./detoxify","metadata":{"execution":{"iopub.status.busy":"2022-02-05T16:25:22.886763Z","iopub.execute_input":"2022-02-05T16:25:22.887226Z","iopub.status.idle":"2022-02-05T16:25:52.446631Z","shell.execute_reply.started":"2022-02-05T16:25:22.887132Z","shell.execute_reply":"2022-02-05T16:25:52.445809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom detoxify import Detoxify\nimport pandas as pd\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-05T16:25:52.447842Z","iopub.execute_input":"2022-02-05T16:25:52.448025Z","iopub.status.idle":"2022-02-05T16:25:58.598054Z","shell.execute_reply.started":"2022-02-05T16:25:52.448001Z","shell.execute_reply":"2022-02-05T16:25:58.59713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 300\nhuggingface_config_path = '../input/bert-base-uncased'\ndetox = Detoxify(model_type='original',  \n                 checkpoint='../input/detoxify-models/toxic_original-c1212f89.ckpt',\n                 device='cpu',\n                 huggingface_config_path=huggingface_config_path)\n\n# A little trick allowing us to set max_len\ndetox.tokenizer = AutoTokenizer.from_pretrained(huggingface_config_path,\n                    local_files_only=True,\n                    model_max_length=max_len)\n\nresults = detox.predict('I am not toxic, sorry!')\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T16:25:58.599025Z","iopub.execute_input":"2022-02-05T16:25:58.599193Z","iopub.status.idle":"2022-02-05T16:26:05.449255Z","shell.execute_reply.started":"2022-02-05T16:25:58.599172Z","shell.execute_reply":"2022-02-05T16:26:05.448561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv')\ncomments = pd.read_csv('/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-05T16:26:05.450557Z","iopub.execute_input":"2022-02-05T16:26:05.450729Z","iopub.status.idle":"2022-02-05T16:26:05.957001Z","shell.execute_reply.started":"2022-02-05T16:26:05.450706Z","shell.execute_reply":"2022-02-05T16:26:05.956205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\n\n# General\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport random\nimport gc\nimport glob\npd.set_option('display.max_columns', None)\nnp.seterr(divide='ignore', invalid='ignore')\ngc.enable()\n\n\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\ntqdm.pandas()\ncomments['text'] = comments['text'].progress_apply(text_cleaning)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a, b, c, d, e, f = [0.02680548, 0.96467853, 0.13336812, 0.35485912, 0.10866255, 0.31102502]\n\ndef make_pred(row):\n    pred = detox.predict(row)\n    return (\n        a*pred['toxicity']\n        + b*pred['severe_toxicity']\n        + c*pred['obscene']\n        + d*pred['threat']\n        + e*pred['insult']\n        + f*pred['identity_attack']\n    )\n\nsub = pd.DataFrame()\nsub[\"comment_id\"] = comments[\"comment_id\"]\nsub[\"score\"] = comments['text'].apply(lambda x: make_pred(x))\nsub.to_csv('submission.csv',index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-02-05T16:31:41.311434Z","iopub.execute_input":"2022-02-05T16:31:41.31213Z","iopub.status.idle":"2022-02-05T16:31:44.064349Z","shell.execute_reply.started":"2022-02-05T16:31:41.312085Z","shell.execute_reply":"2022-02-05T16:31:44.063543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}