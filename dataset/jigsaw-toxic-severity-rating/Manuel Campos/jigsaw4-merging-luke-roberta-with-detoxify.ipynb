{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## install detoxify from dataset\n!cp -r ../input/detoxify-sourcemodels/detoxify .\n!pip install -q ./detoxify\n!rm -r ./detoxify\n\n\n## copy detoxify pretrained models and transformers configuration files from dataset to local caches\n!mkdir -p  /root/.cache/torch/hub/checkpoints\n!mkdir -p  /root/.cache/huggingface/transformers\n!cp -r ../input/detoxify-sourcemodels/torch/hub/checkpoints /root/.cache/torch/hub\n!cp -r ../input/detoxify-sourcemodels/huggingface/transformers /root/.cache/huggingface\n\n\n# Setting environment variable TRANSFORMERS_OFFLINE=1 will tell Transformers to use local files only and will not try to look things up.\n# It’s possible to run Transformers in a firewalled or a no-network environment or in a Kaggle inference kernel !\nimport os\nimport random\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nclass CFG:\n    model_dir='../input/jigsaw4-luke-large-training-tito-cv-strategy/'\n    num_workers=4\n    model=\"studio-ousia/luke-large\"\n    batch_size=128\n    fc_dropout=0.\n    text=\"text\"\n    target=\"target\"\n    target_size=1\n    head=32\n    tail=32\n    seed=42\n    n_fold=5\n\n\nCFG.max_len = CFG.head + CFG.tail\n\nimport os\nimport gc\nimport re\nimport sys\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -q transformers -y')\nos.system('pip uninstall -q tokenizers -y')\nos.system('pip uninstall -q huggingface_hub -y')\n\nos.system('mkdir -p /tmp/pip/cache-tokenizers/')\nos.system('cp ../input/tokenizers-0103/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl /tmp/pip/cache-tokenizers/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-tokenizers/ tokenizers')\n\nos.system('mkdir -p /tmp/pip/cache-huggingface-hub/')\nos.system('cp ../input/huggingface-hub-008/huggingface_hub-0.0.8-py3-none-any.whl /tmp/pip/cache-huggingface-hub/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-huggingface-hub/ huggingface_hub')\n\nos.system('mkdir -p /tmp/pip/cache-transformers/')\nos.system('cp ../input/transformers-470/transformers-4.7.0-py3-none-any.whl /tmp/pip/cache-transformers/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-transformers/ transformers')\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import LukeTokenizer, LukeModel, LukeConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef get_score(df):\n    score = len(df[df['less_toxic_pred'] < df['more_toxic_pred']]) / len(df)\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)\n\ntest = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsubmission = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\nprint(test.shape, submission.shape)\ndisplay(test.head())\ndisplay(submission.head())\n\nCFG.tokenizer = LukeTokenizer.from_pretrained(CFG.model_dir+'tokenizer/')\n\ndef prepare_input(text, cfg):\n    if cfg.tail == 0:\n        inputs = cfg.tokenizer.encode_plus(text, \n                                           return_tensors=None, \n                                           add_special_tokens=True, \n                                           max_length=cfg.max_len,\n                                           pad_to_max_length=True,\n                                           truncation=True)\n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n    else:\n        inputs = cfg.tokenizer.encode_plus(text,\n                                           return_tensors=None, \n                                           add_special_tokens=True, \n                                           truncation=True)\n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > cfg.max_len:\n                v = np.hstack([v[:cfg.head], v[-cfg.tail:]])\n            if k == 'input_ids':\n                new_v = np.ones(cfg.max_len) * cfg.tokenizer.pad_token_id\n            else:\n                new_v = np.zeros(cfg.max_len)\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.text = df[cfg.text].fillna(\"none\").values\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        text = str(self.text[item])\n        inputs = prepare_input(text, self.cfg)\n        return inputs\n    \nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = LukeConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = LukeModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = LukeModel(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = torch.mean(last_hidden_states, 1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output\n    \ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\nconfig_path = CFG.model_dir+\"config.pth\"\npredictions = []\nfor fold in range(CFG.n_fold):\n    model = CustomModel(CFG, config_path=config_path, pretrained=False)\n    state = torch.load(CFG.model_dir+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state; gc.collect()\n    torch.cuda.empty_cache()\n    \nsubmission['score'] = np.mean(predictions, axis=0)\ncomments_luke = submission[['comment_id', 'score']].copy()\ncomments_luke","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.648806Z","iopub.status.idle":"2022-02-06T12:10:39.649115Z","shell.execute_reply.started":"2022-02-06T12:10:39.648967Z","shell.execute_reply":"2022-02-06T12:10:39.648984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detoxify import Detoxify\nimport pandas as pd\nimport numpy as np\n\n\n# each model takes in either a string or a list of strings\n#results = Detoxify('original').predict('example text 1')\n#results = Detoxify('unbiased').predict(['example text 1','example text 2'])\n#results = Detoxify('multilingual').predict(['example text','exemple de text','texto de ejemplo','testo di esempio','texto de exemplo','örnek metin','пример текста'])\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n#model = Detoxify('original', device='cuda')\n#results = model.predict(df.text.head(10).to_list())\n    \n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n#model = Detoxify('unbiased', device='cuda')\n#results = model.predict(df.text.head(10).to_list())\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n#model = Detoxify('multilingual', device='cuda')\n#results = model.predict(df.text.head(10).to_list())\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\nmodel = Detoxify('original', device='cuda')\nprint(model.predict('Hello World...'))\n\n\nmodel = Detoxify('unbiased', device='cuda')\nprint(model.predict('Hello World...'))\n\n\nmodel = Detoxify('multilingual', device='cuda')\nprint(model.predict('Hello World...'))\n\n\n\nauxi = pd.DataFrame(model.predict(['Hello World...','Hello World...']))\nauxi","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.654652Z","iopub.status.idle":"2022-02-06T12:10:39.655291Z","shell.execute_reply.started":"2022-02-06T12:10:39.655058Z","shell.execute_reply":"2022-02-06T12:10:39.655082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select = ['original','unbiased','multilingual']\n","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.656519Z","iopub.status.idle":"2022-02-06T12:10:39.657135Z","shell.execute_reply.started":"2022-02-06T12:10:39.65689Z","shell.execute_reply":"2022-02-06T12:10:39.656929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEL = 0\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nmodel = Detoxify(select[SEL], device='cuda')\nauxi = pd.DataFrame(model.predict(['Hello World...']))\nmy_list = list(auxi.columns)\n\nfor f in my_list:\n    comments[f]= 0.5\n    \n#comments = comments.head(100)    \nfor row in range(len(comments)):\n    comments.loc[row,my_list] = np.array(list(model.predict(comments['text'].iloc[row]).values())).reshape(1,-1)[0]\n    \ncomments","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.658359Z","iopub.status.idle":"2022-02-06T12:10:39.659009Z","shell.execute_reply.started":"2022-02-06T12:10:39.658754Z","shell.execute_reply":"2022-02-06T12:10:39.658778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRY = 600\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments1 = comments[['comment_id', 'score']].copy()\n\ncomments1[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.660244Z","iopub.status.idle":"2022-02-06T12:10:39.660861Z","shell.execute_reply.started":"2022-02-06T12:10:39.66063Z","shell.execute_reply":"2022-02-06T12:10:39.660654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEL = 1\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nmodel = Detoxify(select[SEL], device='cuda')\nauxi = pd.DataFrame(model.predict(['Hello World...']))\nmy_list = list(auxi.columns)\n\nfor f in my_list:\n    comments[f]= 0.5\n    \n#comments = comments.head(100)    \nfor row in range(len(comments)):\n    comments.loc[row,my_list] = np.array(list(model.predict(comments['text'].iloc[row]).values())).reshape(1,-1)[0]\n    \ncomments","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.662093Z","iopub.status.idle":"2022-02-06T12:10:39.662739Z","shell.execute_reply.started":"2022-02-06T12:10:39.662507Z","shell.execute_reply":"2022-02-06T12:10:39.662531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRY = 700\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments2 = comments[['comment_id', 'score']].copy()\n\ncomments2[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.663956Z","iopub.status.idle":"2022-02-06T12:10:39.664573Z","shell.execute_reply.started":"2022-02-06T12:10:39.664333Z","shell.execute_reply":"2022-02-06T12:10:39.664356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEL = 2\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nmodel = Detoxify(select[SEL], device='cuda')\nauxi = pd.DataFrame(model.predict(['Hello World...']))\nmy_list = list(auxi.columns)\n\nfor f in my_list:\n    comments[f]= 0.5\n    \n#comments = comments.head(100)    \nfor row in range(len(comments)):\n    comments.loc[row,my_list] = np.array(list(model.predict(comments['text'].iloc[row]).values())).reshape(1,-1)[0]\n    \ncomments","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.66576Z","iopub.status.idle":"2022-02-06T12:10:39.666397Z","shell.execute_reply.started":"2022-02-06T12:10:39.666161Z","shell.execute_reply":"2022-02-06T12:10:39.666185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRY = 700\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments3 = comments[['comment_id', 'score']].copy()\n\ncomments3[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.667636Z","iopub.status.idle":"2022-02-06T12:10:39.668272Z","shell.execute_reply.started":"2022-02-06T12:10:39.668039Z","shell.execute_reply":"2022-02-06T12:10:39.668063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nhspeech = pd.read_csv('../input/measuring-hate-speech/measuring_hate_speech.csv')\n\n# get mean scores for each comment_id\nscores_dict = hspeech.groupby('comment_id')['hate_speech_score'].apply(np.mean).to_dict()\n\n# drop duplicate comment_ids\nhspeech = hspeech.drop_duplicates(subset='comment_id')\nhspeech['hate_speech_score'] = hspeech['comment_id'].map(scores_dict)\nhspeech = hspeech[['comment_id','text','hate_speech_score']]\n\nprint(hspeech.text.nunique())\n\nhspeech.columns = ['comment_id','text','y']\n\ndel scores_dict\n\nimport gc\ngc.collect()\n\nhspeech = hspeech.sample(frac=1,random_state=0).reset_index(drop=True)\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge, SGDRegressor, LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.stats import rankdata\n\nfrom sklearn.svm import LinearSVR\n\n\njr = hspeech.copy()\njr.shape\ndf = jr[['text', 'y']]\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=1, ngram_range=(2, 5), use_idf=False)\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 2)\n\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\nprint(model1.score(X, y))\n\n#model11=LinearSVR(random_state=0,C=20.0,max_iter=10000)  \n#model11.fit(X, y)\n#print(model11.score(X, y))\n\ndf_test = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\ntest=vec.transform(df_test['text'])\njr_preds=model1.predict(test)\n\ndf_test['score1']=rankdata(jr_preds, method='ordinal') \n\n#auxi = model11.predict(test)\n#df_test['svr1']=rankdata(auxi, method='ordinal') \n\nrud_df = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(f\"rud_df:{rud_df.shape}\")\nrud_df['y'] = rud_df[\"offensiveness_score\"] \ndf = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=3, ngram_range=(3, 4), use_idf=False)\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 1)\ny\n\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\nprint(model1.score(X, y))\n\nmodel11=LinearSVR(random_state=0,C=20.0,max_iter=10000)  \nmodel11.fit(X, y)\nprint(model11.score(X, y))\n\ntest=vec.transform(df_test['text'])\nrud_preds=model1.predict(test)#+0.5*model11.predict(test)\n\ndf_test['score2']=rankdata(rud_preds, method='ordinal') \n\nauxi = model11.predict(test)\ndf_test['svr2']=rankdata(auxi, method='ordinal') \n\nN_TRY = 300\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = df_test['score1']\n#comments['score2'] = df_test['svr1']\ncomments['score3'] = df_test['score2']\ncomments['score4'] = df_test['svr2']\n\n\nmy_list = ['a','b','c']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ndf_test0b = comments[['comment_id', 'score']].copy()\ndf_test0b\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge, SGDRegressor, LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.stats import rankdata\n\nfrom sklearn.svm import LinearSVR\n\n\njr = hspeech.copy()\njr.shape\ndf = jr[['text', 'y']]\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=1, ngram_range=(2, 5))\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 2)\n\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\nprint(model1.score(X, y))\n\n#model11=LinearSVR(random_state=0,C=20.0,max_iter=10000)  \n#model11.fit(X, y)\n#print(model11.score(X, y))\n\ndf_test = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\ntest=vec.transform(df_test['text'])\njr_preds=model1.predict(test)\n\ndf_test['score1']=rankdata(jr_preds, method='ordinal') \n\n#auxi = model11.predict(test)\n#df_test['svr1']=rankdata(auxi, method='ordinal') \n\nrud_df = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(f\"rud_df:{rud_df.shape}\")\nrud_df['y'] = rud_df[\"offensiveness_score\"] \ndf = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=3, ngram_range=(3, 4))\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 1)\ny\n\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\nprint(model1.score(X, y))\n\nmodel11=LinearSVR(random_state=0,C=20.0,max_iter=10000)  \nmodel11.fit(X, y)\nprint(model11.score(X, y))\n\ntest=vec.transform(df_test['text'])\nrud_preds=model1.predict(test)#+0.5*model11.predict(test)\n\ndf_test['score2']=rankdata(rud_preds, method='ordinal') \n\nauxi = model11.predict(test)\ndf_test['svr2']=rankdata(auxi, method='ordinal') \n\nN_TRY = 300\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = df_test['score1']\n#comments['score2'] = df_test['svr1']\ncomments['score3'] = df_test['score2']\ncomments['score4'] = df_test['svr2']\n\n\nmy_list = ['a','b','c']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ndf_test0 = comments[['comment_id', 'score']].copy()\ndf_test0\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nimport re \nimport scipy\nfrom scipy import sparse\n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\ndf_train = hspeech.copy()\ndf_train = df_train.rename(columns={'txt':'text'})\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ndf_train['text'] = df_train['text'].progress_apply(text_cleaning)\ndf = df_train.copy()\n\nvec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))\nX = vec.fit_transform(df['text'])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])\nl_model = Ridge(alpha=1.)\nl_model.fit(X, df['y'])\ns_model = Ridge(alpha=2.)\ns_model.fit(X, df['y'])\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntqdm.pandas()\ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\nX_less_toxic = vec.transform(df_val['less_toxic'])\nX_more_toxic = vec.transform(df_val['more_toxic'])\np1 = model.predict(X_less_toxic)\np2 = model.predict(X_more_toxic)\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntqdm.pandas()\ndf_sub['text'] = df_sub['text'].progress_apply(text_cleaning)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) / 3.\ndf_sub['score'] = df_sub['score']\n\ndf_test0000 = df_sub.copy()\n\n\n#df_test0000['score'] = rankdata(df_test0000['score'], method='ordinal') \ndf_test0000\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nimport re \nimport scipy\nfrom scipy import sparse\n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\ndf_train = hspeech.copy()\ndf_train = df_train.rename(columns={'txt':'text'})\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ndf_train['text'] = df_train['text'].progress_apply(text_cleaning)\ndf = df_train.copy()\n\nvec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5),use_idf=False )\nX = vec.fit_transform(df['text'])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])\nl_model = Ridge(alpha=1.)\nl_model.fit(X, df['y'])\ns_model = Ridge(alpha=2.)\ns_model.fit(X, df['y'])\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntqdm.pandas()\ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\nX_less_toxic = vec.transform(df_val['less_toxic'])\nX_more_toxic = vec.transform(df_val['more_toxic'])\np1 = model.predict(X_less_toxic)\np2 = model.predict(X_more_toxic)\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntqdm.pandas()\ndf_sub['text'] = df_sub['text'].progress_apply(text_cleaning)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) / 3.\n\n\ndf_test0000b = df_sub.copy()\n\n#df_test0000b['score'] = rankdata(df_test0000b['score'], method='ordinal') \ndf_test0000b\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nimport re \nimport scipy\nfrom scipy import sparse\n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\n\ndf_train = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(f\"rud_df:{df_train.shape}\")\ndf_train['y'] = df_train[\"offensiveness_score\"] \ndf_train = df_train[['txt', 'y']].rename(columns={'txt': 'text'})\n\n\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ndf_train['text'] = df_train['text'].progress_apply(text_cleaning)\ndf = df_train.copy()\n\nvec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))\nX = vec.fit_transform(df['text'])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])\nl_model = Ridge(alpha=1.)\nl_model.fit(X, df['y'])\ns_model = Ridge(alpha=2.)\ns_model.fit(X, df['y'])\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntqdm.pandas()\ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\nX_less_toxic = vec.transform(df_val['less_toxic'])\nX_more_toxic = vec.transform(df_val['more_toxic'])\np1 = model.predict(X_less_toxic)\np2 = model.predict(X_more_toxic)\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntqdm.pandas()\ndf_sub['text'] = df_sub['text'].progress_apply(text_cleaning)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) / 3.\ndf_sub['score'] = df_sub['score']\n\ndf_test00 = df_sub.copy()\n\n\n#df_test0000['score'] = rankdata(df_test0000['score'], method='ordinal') \ndf_test00\n\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nimport re \nimport scipy\nfrom scipy import sparse\n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\ndf_train = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(f\"rud_df:{df_train.shape}\")\ndf_train['y'] = df_train[\"offensiveness_score\"] \ndf_train = df_train[['txt', 'y']].rename(columns={'txt': 'text'})\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ndf_train['text'] = df_train['text'].progress_apply(text_cleaning)\ndf = df_train.copy()\n\nvec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))\nX = vec.fit_transform(df['text'])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])\nl_model = Ridge(alpha=1.)\nl_model.fit(X, df['y'])\ns_model = Ridge(alpha=2.)\ns_model.fit(X, df['y'])\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntqdm.pandas()\ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\nX_less_toxic = vec.transform(df_val['less_toxic'])\nX_more_toxic = vec.transform(df_val['more_toxic'])\np1 = model.predict(X_less_toxic)\np2 = model.predict(X_more_toxic)\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntqdm.pandas()\ndf_sub['text'] = df_sub['text'].progress_apply(text_cleaning)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) / 3.\n\n\ndf_test00b = df_sub.copy()\n\n#df_test0000b['score'] = rankdata(df_test0000b['score'], method='ordinal') \ndf_test00b\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.stats import rankdata\nimport os\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import LinearSVR\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntest_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nvalid_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntrain_df=pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n\ntrain = train_df[[\"txt\", \"offensiveness_score\"]]\n\ntfvec = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (3,5))\ntfv = tfvec.fit_transform(train[\"txt\"])\n\nX=tfv\nY=train['offensiveness_score']\n\nreg = LinearRegression().fit(X,Y)\nprint(reg.score(X,Y))\n\nmodel11=LinearSVR(random_state=0,C=20.0,max_iter=10000) \nmodel11.fit(X, Y)\nprint(model11.score(X,Y))\n\ntfv_comments = tfvec.transform(test_df[\"text\"])\npred1 = reg.predict(tfv_comments)#+0.5*model11.predict(tfv_comments)\n\nauxi1 = model11.predict(tfv_comments)\n\n\ndata2 = hspeech.copy()\ndf2 = data2[['text', 'y']]\n\nvec = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 5))\nX = vec.fit_transform(df2['text'])\nw = df2[\"y\"].values\ny = np.around (w ,decimals = 2)\n\nfrom sklearn.linear_model import Ridge\nreg2=Ridge(alpha=0.3)\nreg2.fit(X, y)\nprint(reg2.score(X,y))\n\n#model11=LinearSVR(random_state=0,C=20.0,max_iter=10000)  \n#model11.fit(X, y)\n#print(model11.score(X,y))\n\ntest=vec.transform(test_df['text'])\npred2=reg2.predict(test)#+0.5*model11.predict(test)\n\n#auxi2 = model11.predict(test)\n\nsub = pd.DataFrame()\nsub[\"comment_id\"] = test_df[\"comment_id\"]\nsub[\"score\"] = pred1 + pred2\n\nsub[\"svr\"] = auxi1 #+ auxi2\n\ndf_test = sub.copy()\n\ndf_test['score1']=rankdata(pred1, method='ordinal') \ndf_test['svr1']=rankdata(auxi1, method='ordinal') \ndf_test['score2']=rankdata(pred2, method='ordinal') \n#df_test['svr2']=rankdata(auxi2, method='ordinal') \n\n\n#df_test['score']=rankdata(df_test['score'], method='ordinal') \n#df_test['svr']=rankdata(df_test['svr'], method='ordinal') \n\ndf_test000 = df_test.copy()\ndf_test000\n\nN_TRY = 300\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = df_test000['score1']\ncomments['score2'] = df_test000['svr1']\ncomments['score3'] = df_test000['score2']\n#comments['score4'] = df_test000['svr2']\n\n\nmy_list = ['a','b','c']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ndf_test000 = comments[['comment_id', 'score']].copy()\ndf_test000\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntest_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nvalid_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntrain_df=pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n\ntrain = train_df[[\"txt\", \"offensiveness_score\"]]\n\ntfvec = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (3,5), use_idf = False)\ntfv = tfvec.fit_transform(train[\"txt\"])\n\nX=tfv\nY=train['offensiveness_score']\n\nreg = LinearRegression().fit(X,Y)\nprint(reg.score(X,Y))\n\nmodel11=LinearSVR(random_state=0,C=20.0,max_iter=10000) \nmodel11.fit(X, Y)\nprint(model11.score(X,Y))\n\ntfv_comments = tfvec.transform(test_df[\"text\"])\npred1 = reg.predict(tfv_comments)#+0.5*model11.predict(tfv_comments)\n\nauxi1 = model11.predict(tfv_comments)\n\n\ndata2 = hspeech.copy()\ndf2 = data2[['text', 'y']]\n\nvec = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 5), use_idf = False)\nX = vec.fit_transform(df2['text'])\nw = df2[\"y\"].values\ny = np.around (w ,decimals = 2)\n\nfrom sklearn.linear_model import Ridge\nreg2=Ridge(alpha=0.3)\nreg2.fit(X, y)\nprint(reg2.score(X,y))\n\n#model11=LinearSVR(random_state=0,C=20.0,max_iter=10000)  \n#model11.fit(X, y)\n#print(model11.score(X,y))\n\ntest=vec.transform(test_df['text'])\npred2=reg2.predict(test)#+0.5*model11.predict(test)\n\n#auxi2 = model11.predict(test)\n\nsub = pd.DataFrame()\nsub[\"comment_id\"] = test_df[\"comment_id\"]\nsub[\"score\"] = pred1 + pred2\n\nsub[\"svr\"] = auxi1# + auxi2\n\ndf_test = sub.copy()\n\ndf_test['score1']=rankdata(pred1, method='ordinal') \ndf_test['svr1']=rankdata(auxi1, method='ordinal') \ndf_test['score2']=rankdata(pred2, method='ordinal') \n#df_test['svr2']=rankdata(auxi2, method='ordinal') \n\n\n#df_test['score']=rankdata(df_test['score'], method='ordinal') \n#df_test['svr']=rankdata(df_test['svr'], method='ordinal') \n\ndf_test000b = df_test.copy()\ndf_test000b\n\nN_TRY = 300\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = df_test000b['score1']\ncomments['score2'] = df_test000b['svr1']\ncomments['score3'] = df_test000b['score2']\n#comments['score4'] = df_test000b['svr2']\n\n\nmy_list = ['a','b','c']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ndf_test000b = comments[['comment_id', 'score']].copy()\ndf_test000b\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.base import TransformerMixin, BaseEstimator\nimport re \nimport scipy\nfrom scipy import sparse\nimport gc \nfrom IPython.display import display, HTML\nfrom pprint import pprint\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf = hspeech.copy()\n\nn_folds = 7\n\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = df.sample(frac=0.7,random_state=fld)\n\n    tmp_df.to_csv(f'/kaggle/working/df_fld{fld}.csv', index=False)\n    \nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return [lemmatizer.lemmatize(w) for w in text]\n\ndef clean(data, col):\n    \n    data[col] = data[col].str.replace(r\"what's\", \"what is \")    \n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \")\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n    data[col] = data[col].str.replace(r\"n't\", \" not \")\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \")\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \")\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \")\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \")\n    data[col] = data[col].str.replace(r\"\\'s\", \" \")\n\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n    \n    return data\n\n# Test clean function\ntest_clean_df = pd.DataFrame({\"text\":\n                              [\"heyy\\n\\nkkdsfj\",\n                               \"hi   how/are/you ???\",\n                               \"hey?????\",\n                               \"noooo!!!!!!!!!   comeone !! \",\n                              \"cooooooooool     brooooooooooo  coool brooo\",\n                              \"naaaahhhhhhh\"]})\ndisplay(test_clean_df)\nclean(test_clean_df,'text')\n\ndf = clean(df,'text')\n\nn_folds = 7\n\n\nfor fld in range(n_folds):\n    tmp_df = df.sample(frac=0.7,random_state=fld+55)\n\n    tmp_df.to_csv(f'/kaggle/working/df_clean_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())\n    \ndel df,tmp_df\ngc.collect()\n\ndf_ = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(df_.shape)\n\ndf_ = df_[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n                                                                'offensiveness_score':'y'})\n\ndf_['y'] = (df_['y'] - df_.y.min()) / (df_.y.max() - df_.y.min()) \n\nn_folds = 7\n\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = df_.sample(frac=0.7,random_state=fld+555)\n    tmp_df.to_csv(f'/kaggle/working/df2_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())\n    \ndel tmp_df, df_; \ngc.collect()\n\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\nclass LengthUpperTransformer(BaseEstimator, TransformerMixin):\n\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return sparse.csr_matrix([[sum([1 for y in x if y.isupper()])/len(x)] for x in X])\n    def get_feature_names(self):\n        return [\"lngth_uppercase\"]\n    \nval_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arr = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([\n        (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n\n    ])\n    \n    pipeline = Pipeline(\n        [\n            (\"features\", features),\n            (\"clf\", Ridge())\n        ]\n    )\n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    #print(\"\\npredict validation data \")\n    #val_preds_arr1[:,fld] = pipeline.predict(df_val['less_toxic'])\n    #val_preds_arr2[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arr[:,fld] = pipeline.predict(df_sub['text'])\n    \nval_preds_arr1c = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2c = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arrc = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df_clean_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([\n        (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n\n    ])\n    pipeline = Pipeline(\n        [\n            (\"features\", features),\n            (\"clf\", Ridge()),\n        ]\n    )\n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    #print(\"\\npredict validation data \")\n    #val_preds_arr1[:,fld] = pipeline.predict(df_val['less_toxic'])\n    #val_preds_arr2[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n\n    print(\"\\npredict test data \")\n    test_preds_arrc[:,fld] = pipeline.predict(df_sub['text'])\n    \nval_preds_arr1_ = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2_ = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arr_ = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df2_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([\n        (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n\n    ])\n    pipeline = Pipeline(\n        [\n            (\"features\", features),\n            (\"clf\", Ridge()),\n        ]\n    )\n    print(\"\\nTrain:\")\n    \n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    #print(\"\\npredict validation data \")\n    #val_preds_arr1[:,fld] = pipeline.predict(df_val['less_toxic'])\n    #val_preds_arr2[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n\n    print(\"\\npredict test data \")\n    test_preds_arr_[:,fld] = pipeline.predict(df_sub['text'])\n    \ndel df, pipeline, feature_wts\ngc.collect()\n\np1 = test_preds_arr.mean(axis=1)\np2 = test_preds_arr_.mean(axis=1)\np3 = test_preds_arrc.mean(axis=1)\n\nN_TRY = 300\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = rankdata(p1, method='ordinal') \ncomments['score2'] = rankdata(p2, method='ordinal') \ncomments['score3'] = rankdata(p3, method='ordinal') \n\n\nmy_list = ['a','b','c']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ndf_sub = comments[['comment_id', 'score']].copy()\ndf_sub\n\nN_TRY = 400\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = df_test0b['score']#.rank()\ncomments['score2'] = df_test00b['score']#.rank()\ncomments['score3'] = df_test000b['score']#.rank()\ncomments['score4'] = df_test0000b['score']#.rank()\n\n\nmy_list = ['a','b','c','d']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments_0b = comments[['comment_id', 'score']].copy()\ncomments_0b\n\nN_TRY = 500\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = df_test0['score']#.rank()\ncomments['score2'] = df_test00['score']#.rank()\ncomments['score3'] = df_test000['score']#.rank()\ncomments['score4'] = df_test0000['score']#.rank()\ncomments['score5'] = df_sub['score']#.rank()\n\nmy_list = ['a','b','c','d','d']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments_0 = comments[['comment_id', 'score']].copy()\ncomments_0\n\nN_TRY = 200\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = comments_0['score']#.rank()\ncomments['score2'] = comments_0b['score']#.rank()\n\n\nmy_list = ['a','b']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\nruddit_hate = comments[['comment_id', 'score']].copy()\nruddit_hate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRY = 400\n\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = comments1['score'].rank()\ncomments['score2'] = comments2['score'].rank()\ncomments['score3'] = comments3['score'].rank()\ncomments['score4'] = ruddit_hate['score'].rank()\n\n\n\nmy_list = ['original','unbiased','multilingual','ruddit']#,'comments_luke']#'luke_base','luke_large']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint(best_w)\nprint(best_score)\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.669498Z","iopub.status.idle":"2022-02-06T12:10:39.670132Z","shell.execute_reply.started":"2022-02-06T12:10:39.669884Z","shell.execute_reply":"2022-02-06T12:10:39.669908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments['score'] = (3/4)*comments['score'].rank() + (1/4)*comments_luke['score'].rank()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.671355Z","iopub.status.idle":"2022-02-06T12:10:39.671988Z","shell.execute_reply.started":"2022-02-06T12:10:39.671739Z","shell.execute_reply":"2022-02-06T12:10:39.671763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(comments) != comments['score'].nunique():\n    print(len(comments) == comments['score'].nunique())\n    comments = comments.sample(n=len(comments),random_state=0)\n    comments['score'] = comments['score'].rank(method='first')\n    \nprint(len(comments) == comments['score'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.673185Z","iopub.status.idle":"2022-02-06T12:10:39.673816Z","shell.execute_reply.started":"2022-02-06T12:10:39.673585Z","shell.execute_reply":"2022-02-06T12:10:39.673609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments[['comment_id', 'score']].to_csv('submission.csv', index=False)\ncomments[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T12:10:39.675243Z","iopub.status.idle":"2022-02-06T12:10:39.675861Z","shell.execute_reply.started":"2022-02-06T12:10:39.675628Z","shell.execute_reply":"2022-02-06T12:10:39.675652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}