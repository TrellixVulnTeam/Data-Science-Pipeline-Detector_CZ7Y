{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## install detoxify from dataset\n!cp -r ../input/detoxify-sourcemodels/detoxify .\n!pip install -q ./detoxify\n!rm -r ./detoxify\n\n\n## copy detoxify pretrained models and transformers configuration files from dataset to local caches\n!mkdir -p  /root/.cache/torch/hub/checkpoints\n!mkdir -p  /root/.cache/huggingface/transformers\n!cp -r ../input/detoxify-sourcemodels/torch/hub/checkpoints /root/.cache/torch/hub\n!cp -r ../input/detoxify-sourcemodels/huggingface/transformers /root/.cache/huggingface\n\n\n# Setting environment variable TRANSFORMERS_OFFLINE=1 will tell Transformers to use local files only and will not try to look things up.\n# It’s possible to run Transformers in a firewalled or a no-network environment or in a Kaggle inference kernel !\nimport os\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:10:27.573189Z","iopub.execute_input":"2022-02-05T20:10:27.57382Z","iopub.status.idle":"2022-02-05T20:11:22.866632Z","shell.execute_reply.started":"2022-02-05T20:10:27.57372Z","shell.execute_reply":"2022-02-05T20:11:22.865704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nclass CFG:\n    model_dir='../input/jigsaw4-luke-large-training-tito-cv-strategy/'\n    num_workers=4\n    model=\"studio-ousia/luke-large\"\n    batch_size=128\n    fc_dropout=0.\n    text=\"text\"\n    target=\"target\"\n    target_size=1\n    head=32\n    tail=32\n    seed=42\n    n_fold=5\n\n\nCFG.max_len = CFG.head + CFG.tail\n\nimport os\nimport gc\nimport re\nimport sys\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -q transformers -y')\nos.system('pip uninstall -q tokenizers -y')\nos.system('pip uninstall -q huggingface_hub -y')\n\nos.system('mkdir -p /tmp/pip/cache-tokenizers/')\nos.system('cp ../input/tokenizers-0103/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl /tmp/pip/cache-tokenizers/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-tokenizers/ tokenizers')\n\nos.system('mkdir -p /tmp/pip/cache-huggingface-hub/')\nos.system('cp ../input/huggingface-hub-008/huggingface_hub-0.0.8-py3-none-any.whl /tmp/pip/cache-huggingface-hub/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-huggingface-hub/ huggingface_hub')\n\nos.system('mkdir -p /tmp/pip/cache-transformers/')\nos.system('cp ../input/transformers-470/transformers-4.7.0-py3-none-any.whl /tmp/pip/cache-transformers/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-transformers/ transformers')\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import LukeTokenizer, LukeModel, LukeConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef get_score(df):\n    score = len(df[df['less_toxic_pred'] < df['more_toxic_pred']]) / len(df)\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)\n\ntest = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsubmission = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\nprint(test.shape, submission.shape)\ndisplay(test.head())\ndisplay(submission.head())\n\nCFG.tokenizer = LukeTokenizer.from_pretrained(CFG.model_dir+'tokenizer/')\n\ndef prepare_input(text, cfg):\n    if cfg.tail == 0:\n        inputs = cfg.tokenizer.encode_plus(text, \n                                           return_tensors=None, \n                                           add_special_tokens=True, \n                                           max_length=cfg.max_len,\n                                           pad_to_max_length=True,\n                                           truncation=True)\n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n    else:\n        inputs = cfg.tokenizer.encode_plus(text,\n                                           return_tensors=None, \n                                           add_special_tokens=True, \n                                           truncation=True)\n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > cfg.max_len:\n                v = np.hstack([v[:cfg.head], v[-cfg.tail:]])\n            if k == 'input_ids':\n                new_v = np.ones(cfg.max_len) * cfg.tokenizer.pad_token_id\n            else:\n                new_v = np.zeros(cfg.max_len)\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.text = df[cfg.text].fillna(\"none\").values\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        text = str(self.text[item])\n        inputs = prepare_input(text, self.cfg)\n        return inputs\n    \nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = LukeConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = LukeModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = LukeModel(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = torch.mean(last_hidden_states, 1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output\n    \ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\nconfig_path = CFG.model_dir+\"config.pth\"\npredictions = []\nfor fold in range(CFG.n_fold):\n    model = CustomModel(CFG, config_path=config_path, pretrained=False)\n    state = torch.load(CFG.model_dir+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state; gc.collect()\n    torch.cuda.empty_cache()\n    \nsubmission['score'] = np.mean(predictions, axis=0)\ncomments5 = submission[['comment_id', 'score']].copy()\ncomments5","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:11:22.868928Z","iopub.execute_input":"2022-02-05T20:11:22.869189Z","iopub.status.idle":"2022-02-05T20:20:09.425425Z","shell.execute_reply.started":"2022-02-05T20:11:22.869151Z","shell.execute_reply":"2022-02-05T20:20:09.424671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \n    \nclass CFG:\n    model_dir='../input/jigsaw4-luke-base-training-tito-cv-strategy/'\n    num_workers=4\n    model=\"studio-ousia/luke-base\"\n    batch_size=128\n    fc_dropout=0.\n    text=\"text\"\n    target=\"target\"\n    target_size=1\n    head=32\n    tail=32\n    seed=42\n    n_fold=5\n    \nCFG.max_len = CFG.head + CFG.tail\n\nimport os\nimport gc\nimport re\nimport sys\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -q transformers -y')\nos.system('pip uninstall -q tokenizers -y')\nos.system('pip uninstall -q huggingface_hub -y')\n\nos.system('mkdir -p /tmp/pip/cache-tokenizers/')\nos.system('cp ../input/tokenizers-0103/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl /tmp/pip/cache-tokenizers/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-tokenizers/ tokenizers')\n\nos.system('mkdir -p /tmp/pip/cache-huggingface-hub/')\nos.system('cp ../input/huggingface-hub-008/huggingface_hub-0.0.8-py3-none-any.whl /tmp/pip/cache-huggingface-hub/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-huggingface-hub/ huggingface_hub')\n\nos.system('mkdir -p /tmp/pip/cache-transformers/')\nos.system('cp ../input/transformers-470/transformers-4.7.0-py3-none-any.whl /tmp/pip/cache-transformers/')\nos.system('pip install -q --no-index --find-links /tmp/pip/cache-transformers/ transformers')\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import LukeTokenizer, LukeModel, LukeConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef get_score(df):\n    score = len(df[df['less_toxic_pred'] < df['more_toxic_pred']]) / len(df)\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)\n\ntest = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\nsubmission = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\nprint(test.shape, submission.shape)\ndisplay(test.head())\ndisplay(submission.head())\n\nCFG.tokenizer = LukeTokenizer.from_pretrained(CFG.model_dir+'tokenizer/')\n\ndef prepare_input(text, cfg):\n    if cfg.tail == 0:\n        inputs = cfg.tokenizer.encode_plus(text, \n                                           return_tensors=None, \n                                           add_special_tokens=True, \n                                           max_length=cfg.max_len,\n                                           pad_to_max_length=True,\n                                           truncation=True)\n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n    else:\n        inputs = cfg.tokenizer.encode_plus(text,\n                                           return_tensors=None, \n                                           add_special_tokens=True, \n                                           truncation=True)\n        for k, v in inputs.items():\n            v_length = len(v)\n            if v_length > cfg.max_len:\n                v = np.hstack([v[:cfg.head], v[-cfg.tail:]])\n            if k == 'input_ids':\n                new_v = np.ones(cfg.max_len) * cfg.tokenizer.pad_token_id\n            else:\n                new_v = np.zeros(cfg.max_len)\n            new_v[:v_length] = v \n            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.text = df[cfg.text].fillna(\"none\").values\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        text = str(self.text[item])\n        inputs = prepare_input(text, self.cfg)\n        return inputs\n    \nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = LukeConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = LukeModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = LukeModel(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = torch.mean(last_hidden_states, 1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output\n    \ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\nconfig_path = CFG.model_dir+\"config.pth\"\npredictions = []\nfor fold in range(CFG.n_fold):\n    model = CustomModel(CFG, config_path=config_path, pretrained=False)\n    state = torch.load(CFG.model_dir+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state; gc.collect()\n    torch.cuda.empty_cache()\n    \n\nsubmission['score'] = np.mean(predictions, axis=0)\ncomments4 = submission[['comment_id', 'score']].copy()\ncomments4","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:20:09.429951Z","iopub.execute_input":"2022-02-05T20:20:09.431997Z","iopub.status.idle":"2022-02-05T20:24:54.044292Z","shell.execute_reply.started":"2022-02-05T20:20:09.431956Z","shell.execute_reply":"2022-02-05T20:24:54.043494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_TRY = 100\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = comments4['score']\ncomments['score2'] = comments5['score']\n\n\nmy_list = ['luke_base','luke_large']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n#for w in np.arange(0,1.01,0.01):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    #w = np.array([w,1-w])\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\n\nprint('w_score',percent_correct)\nprint('best_score',best_score)\n\nprint('w',w)\nprint('w_norm',w/sum(w))\n\nprint('best_w',best_w)\nprint('best_w_norm',best_w/sum(best_w))\n\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments_luke = comments[['comment_id', 'score']].copy()\ncomments_luke","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:30:02.16803Z","iopub.execute_input":"2022-02-05T20:30:02.168335Z","iopub.status.idle":"2022-02-05T20:30:40.819307Z","shell.execute_reply.started":"2022-02-05T20:30:02.1683Z","shell.execute_reply":"2022-02-05T20:30:40.816596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detoxify import Detoxify\nimport pandas as pd\nimport numpy as np\n\n\n# each model takes in either a string or a list of strings\n#results = Detoxify('original').predict('example text 1')\n#results = Detoxify('unbiased').predict(['example text 1','example text 2'])\n#results = Detoxify('multilingual').predict(['example text','exemple de text','texto de ejemplo','testo di esempio','texto de exemplo','örnek metin','пример текста'])\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n#model = Detoxify('original', device='cuda')\n#results = model.predict(df.text.head(10).to_list())\n    \n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n#model = Detoxify('unbiased', device='cuda')\n#results = model.predict(df.text.head(10).to_list())\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n#model = Detoxify('multilingual', device='cuda')\n#results = model.predict(df.text.head(10).to_list())\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\nmodel = Detoxify('original', device='cuda')\nprint(model.predict('Hello World...'))\n\n\nmodel = Detoxify('unbiased', device='cuda')\nprint(model.predict('Hello World...'))\n\n\nmodel = Detoxify('multilingual', device='cuda')\nprint(model.predict('Hello World...'))\n\n\n\nauxi = pd.DataFrame(model.predict(['Hello World...','Hello World...']))\nauxi","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:23.362487Z","iopub.execute_input":"2022-02-05T20:27:23.362911Z","iopub.status.idle":"2022-02-05T20:27:28.721882Z","shell.execute_reply.started":"2022-02-05T20:27:23.362873Z","shell.execute_reply":"2022-02-05T20:27:28.720405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select = ['original','unbiased','multilingual']\nN_TRY = 100","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.72287Z","iopub.status.idle":"2022-02-05T20:27:28.723787Z","shell.execute_reply.started":"2022-02-05T20:27:28.723528Z","shell.execute_reply":"2022-02-05T20:27:28.723556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEL = 0\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nmodel = Detoxify(select[SEL], device='cuda')\nauxi = pd.DataFrame(model.predict(['Hello World...']))\nmy_list = list(auxi.columns)\n\nfor f in my_list:\n    comments[f]= 0.5\n    \n#comments = comments.head(100)    \nfor row in range(len(comments)):\n    comments.loc[row,my_list] = np.array(list(model.predict(comments['text'].iloc[row]).values())).reshape(1,-1)[0]\n    \ncomments","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.725067Z","iopub.status.idle":"2022-02-05T20:27:28.725707Z","shell.execute_reply.started":"2022-02-05T20:27:28.725454Z","shell.execute_reply":"2022-02-05T20:27:28.725495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint('w_score',percent_correct)\nprint('best_score',best_score)\n\nprint('w',w)\nprint('w_norm',w/sum(w))\n\nprint('best_w',best_w)\nprint('best_w_norm',best_w/sum(best_w))\n\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments1 = comments[['comment_id', 'score']].copy()\n\ncomments1[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.726926Z","iopub.status.idle":"2022-02-05T20:27:28.727568Z","shell.execute_reply.started":"2022-02-05T20:27:28.727312Z","shell.execute_reply":"2022-02-05T20:27:28.727337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEL = 1\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nmodel = Detoxify(select[SEL], device='cuda')\nauxi = pd.DataFrame(model.predict(['Hello World...']))\nmy_list = list(auxi.columns)\n\nfor f in my_list:\n    comments[f]= 0.5\n    \n#comments = comments.head(100)    \nfor row in range(len(comments)):\n    comments.loc[row,my_list] = np.array(list(model.predict(comments['text'].iloc[row]).values())).reshape(1,-1)[0]\n    \ncomments","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.728826Z","iopub.status.idle":"2022-02-05T20:27:28.729487Z","shell.execute_reply.started":"2022-02-05T20:27:28.729237Z","shell.execute_reply":"2022-02-05T20:27:28.729263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint('w_score',percent_correct)\nprint('best_score',best_score)\n\nprint('w',w)\nprint('w_norm',w/sum(w))\n\nprint('best_w',best_w)\nprint('best_w_norm',best_w/sum(best_w))\n\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments2 = comments[['comment_id', 'score']].copy()\n\ncomments2[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.730753Z","iopub.status.idle":"2022-02-05T20:27:28.731395Z","shell.execute_reply.started":"2022-02-05T20:27:28.73113Z","shell.execute_reply":"2022-02-05T20:27:28.731154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEL = 2\ncomments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nmodel = Detoxify(select[SEL], device='cuda')\nauxi = pd.DataFrame(model.predict(['Hello World...']))\nmy_list = list(auxi.columns)\n\nfor f in my_list:\n    comments[f]= 0.5\n    \n#comments = comments.head(100)    \nfor row in range(len(comments)):\n    comments.loc[row,my_list] = np.array(list(model.predict(comments['text'].iloc[row]).values())).reshape(1,-1)[0]\n    \ncomments","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.732656Z","iopub.status.idle":"2022-02-05T20:27:28.733276Z","shell.execute_reply.started":"2022-02-05T20:27:28.733029Z","shell.execute_reply":"2022-02-05T20:27:28.733054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint('w_score',percent_correct)\nprint('best_score',best_score)\n\nprint('w',w)\nprint('w_norm',w/sum(w))\n\nprint('best_w',best_w)\nprint('best_w_norm',best_w/sum(best_w))\n\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n\ncomments3 = comments[['comment_id', 'score']].copy()\n\ncomments3[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.734533Z","iopub.status.idle":"2022-02-05T20:27:28.735146Z","shell.execute_reply.started":"2022-02-05T20:27:28.734912Z","shell.execute_reply":"2022-02-05T20:27:28.734936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\ncomments['score1'] = comments1['score']\ncomments['score2'] = comments2['score']\ncomments['score3'] = comments3['score']\n#comments['score4'] = comments_luke['score']\n#comments['score5'] = comments5['score']\n\nmy_list = ['original','unbiased','multilingual']#,'comments_luke']#'luke_base','luke_large']\n\n\nvalidation = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n\nvalidation_annotations = validation.set_index('more_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'), how='inner').set_index('less_toxic').join(\n    comments[['comment_id', 'text']].set_index('text'),\n    lsuffix='_more', rsuffix='_less', how='inner').reset_index(drop=True)\n\nbest_score = 0\nbest_w = 0\nfor _ in range(N_TRY):\n    w = np.random.rand(len(my_list))\n    w = w / np.linalg.norm(w)\n    scores =  { c[1].comment_id: sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows() }\n    percent_correct = 100.0 * (\n        sum(validation_annotations['comment_id_more'].map(scores).gt(\n            validation_annotations['comment_id_less'].map(scores)))\n        / len(validation_annotations))\n    print(percent_correct)\n    if percent_correct > best_score:\n        best_score = percent_correct\n        best_w = w\n        \n        \nprint('----------')\nprint('----------')\nprint('----------')\n\nprint('w_score',percent_correct)\nprint('best_score',best_score)\n\nprint('w',w)\nprint('w_norm',w/sum(w))\n\nprint('best_w',best_w)\nprint('best_w_norm',best_w/sum(best_w))\n\n\ncomments['score'] = [sum(w * c[1][2:(2+len(my_list))]) for c in comments.iterrows()]\n","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.736413Z","iopub.status.idle":"2022-02-05T20:27:28.73705Z","shell.execute_reply.started":"2022-02-05T20:27:28.736816Z","shell.execute_reply":"2022-02-05T20:27:28.73684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments['score'] = (2/3)*comments['score'].rank() + (1/3)*comments_luke['score'].rank()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(comments) != comments['score'].nunique():\n    print(len(comments) == comments['score'].nunique())\n    comments = comments.sample(n=len(comments),random_state=0)\n    comments['score'] = comments['score'].rank(method='first')\n    \nprint(len(comments) == comments['score'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.738271Z","iopub.status.idle":"2022-02-05T20:27:28.738915Z","shell.execute_reply.started":"2022-02-05T20:27:28.738667Z","shell.execute_reply":"2022-02-05T20:27:28.738692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments[['comment_id', 'score']].to_csv('submission.csv', index=False)\ncomments[['comment_id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T20:27:28.740159Z","iopub.status.idle":"2022-02-05T20:27:28.740797Z","shell.execute_reply.started":"2022-02-05T20:27:28.74056Z","shell.execute_reply":"2022-02-05T20:27:28.740586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}