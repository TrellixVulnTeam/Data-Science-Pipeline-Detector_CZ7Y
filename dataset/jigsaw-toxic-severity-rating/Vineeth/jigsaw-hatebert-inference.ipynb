{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">ðŸŽ¯ Training Kernel: <strong><a href=\"https://www.kaggle.com/debarshichanda/pytorch-w-b-jigsaw-starter\">[Pytorch + W&B] Jigsaw Starter</a></strong>.</span>","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG_hatebert = dict(\n    seed = 42,\n    model_name = '../input/hatebert/dehatebert/model/',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG_distilbert = dict(\n    seed = 42,\n    model_name = '../input/distilbertbaseuncased/',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG_robertabase = dict(\n    seed = 42,\n    model_name = '../input/roberta-base/',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG_GroNLP = dict(\n    seed = 42,\n    model_name = '../input/hatebert/GroNLP/model/',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG_hatebert[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG_hatebert['model_name'])\nCONFIG_distilbert[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG_distilbert['model_name'])\nCONFIG_robertabase[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG_robertabase['model_name'])\nCONFIG_GroNLP[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG_GroNLP['model_name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATHS_hatebert = [\n    '../input/jigsaw-toxic-severity-hatebert-5f/Loss-Fold-0.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/Loss-Fold-1.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/Loss-Fold-2.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/Loss-Fold-3.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/Loss-Fold-4.bin'\n]\n\nMODEL_PATHS_distilbert = [\n    '../input/jigsaw-toxic-severity-hatebert-5f/DistilBERT_Loss-Fold-0.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/DistilBERT_Loss-Fold-1.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/DistilBERT_Loss-Fold-2.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/DistilBERT_Loss-Fold-3.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/DistilBERT_Loss-Fold-4.bin'\n]\n\nMODEL_PATHS_robertabase = [\n    '../input/jigsaw-toxic-severity-hatebert-5f/roberta_base_Loss-Fold-0.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/roberta_base_Loss-Fold-1.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/roberta_base_Loss-Fold-2.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/roberta_base_Loss-Fold-3.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/roberta_base_Loss-Fold-4.bin'\n]\n\nMODEL_PATHS_GroNLP = [\n    '../input/jigsaw-toxic-severity-hatebert-5f/GroNLP_CustomOpt-Fold-0.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/GroNLP_CustomOpt-Fold-1.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/GroNLP_CustomOpt-Fold-2.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/GroNLP_CustomOpt-Fold-3.bin',\n    '../input/jigsaw-toxic-severity-hatebert-5f/GroNLP_CustomOpt-Fold-4.bin'\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG_hatebert['seed'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n\n\ndf_test = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length, col_name):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df[col_name].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# less_toxic_test_dataset = JigsawDataset(df, CONFIG['tokenizer'], CONFIG['max_length'], 'less_toxic')\n# less_toxic_test_loader = DataLoader(less_toxic_test_dataset, batch_size=CONFIG['test_batch_size'],\n#                          num_workers=2, shuffle=False, pin_memory=True)\n\n# more_toxic_test_dataset = JigsawDataset(df, CONFIG['tokenizer'], CONFIG['max_length'], 'more_toxic')\n# more_toxic_test_loader = DataLoader(more_toxic_test_dataset, batch_size=CONFIG['test_batch_size'],\n#                          num_workers=2, shuffle=False, pin_memory=True)\n\ntest_dataset_distilbert = JigsawDataset(df_test, CONFIG_distilbert['tokenizer'], CONFIG_distilbert['max_length'], 'text')\ntest_loader_distilbert = DataLoader(test_dataset_distilbert, batch_size=CONFIG_distilbert['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)\n\ntest_dataset_hatebert = JigsawDataset(df_test, CONFIG_hatebert['tokenizer'], CONFIG_hatebert['max_length'], 'text')\ntest_loader_hatebert = DataLoader(test_dataset_hatebert, batch_size=CONFIG_hatebert['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)\n\ntest_dataset_robertabase = JigsawDataset(df_test, CONFIG_robertabase['tokenizer'], CONFIG_robertabase['max_length'], 'text')\ntest_loader_robertabase = DataLoader(test_dataset_robertabase, batch_size=CONFIG_robertabase['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)\n\ntest_dataset_GroNLP = JigsawDataset(df_test, CONFIG_GroNLP['tokenizer'], CONFIG_GroNLP['max_length'], 'text')\ntest_loader_GroNLP = DataLoader(test_dataset_GroNLP, batch_size=CONFIG_GroNLP['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)\n\n\n# more_toxic_test_dataset_distilbert = JigsawDataset(df, CONFIG_distilbert['tokenizer'], CONFIG_distilbert['max_length'], 'more_toxic')\n# more_toxic_test_loader_distilbert = DataLoader(more_toxic_test_dataset_distilbert, batch_size=CONFIG_distilbert['test_batch_size'],\n#                          num_workers=2, shuffle=False, pin_memory=True)\n\n# more_toxic_test_dataset_hatebert = JigsawDataset(df, CONFIG_hatebert['tokenizer'], CONFIG_hatebert['max_length'], 'more_toxic')\n# more_toxic_test_loader_hatebert = DataLoader(more_toxic_test_dataset_hatebert, batch_size=CONFIG_hatebert['test_batch_size'],\n#                          num_workers=2, shuffle=False, pin_memory=True)\n\n# more_toxic_test_dataset_robertabase = JigsawDataset(df, CONFIG_robertabase['tokenizer'], CONFIG_robertabase['max_length'], 'more_toxic')\n# more_toxic_test_loader_robertabase = DataLoader(more_toxic_test_dataset_robertabase, batch_size=CONFIG_robertabase['test_batch_size'],\n#                          num_workers=2, shuffle=False, pin_memory=True)\n\n# more_toxic_test_dataset_GroNLP = JigsawDataset(df, CONFIG_GroNLP['tokenizer'], CONFIG_GroNLP['max_length'], 'more_toxic')\n# more_toxic_test_loader_GroNLP = DataLoader(more_toxic_test_dataset_GroNLP, batch_size=CONFIG_GroNLP['test_batch_size'],\n#                          num_workers=2, shuffle=False, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawModel_distilbert(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel_distilbert, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(1024, CONFIG_distilbert['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs\n    \nclass JigsawModel_hatebert(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel_hatebert, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG_hatebert['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs\n    \nclass JigsawModel_robertabase(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel_robertabase, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG_hatebert['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs\n    \nclass JigsawModel_GroNLP(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel_GroNLP, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG_hatebert['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawModel_distilbert(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = DistilBertConfig.from_pretrained(CONFIG_distilbert['model_name'])\n        config.update({\"layer_norm_eps\": 1e-7,\n                       \"output_hidden_states\":True,\n                      \"hidden_dropout_prob\": 0.0})                       \n        \n        self.distilbert = DistilBertModel.from_pretrained(CONFIG_distilbert['model_name'], config=config)  \n            \n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )        \n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(768, 1)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        distilbert_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)        \n\n        last_layer_hidden_states = distilbert_output.last_hidden_state\n\n        weights = self.attention(last_layer_hidden_states)\n\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n\n        return self.regressor(context_vector)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_distilbert(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n#         model = JigsawModel_distilbert(CONFIG_distilbert['model_name'])\n        model = JigsawModel_distilbert()\n        model.to(CONFIG_distilbert['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds\n\ndef inference_hatebert(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel_hatebert(CONFIG_hatebert['model_name'])\n        model.to(CONFIG_hatebert['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds\n\ndef inference_GroNLP(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel_hatebert(CONFIG_GroNLP['model_name'])\n        model.to(CONFIG_GroNLP['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds\n\ndef inference_robertabase(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel_hatebert(CONFIG_robertabase['model_name'])\n        model.to(CONFIG_robertabase['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# less_toxic_preds_distilbert = inference_distilbert(MODEL_PATHS_distilbert, less_toxic_test_loader_distilbert, CONFIG_distilbert['device'])\n# less_toxic_preds_robertabase = inference_robertabase(MODEL_PATHS_robertabase, less_toxic_test_loader_robertabase, CONFIG_robertabase['device'])\n# less_toxic_preds_hatebert = inference_hatebert(MODEL_PATHS_hatebert, less_toxic_test_loader_hatebert, CONFIG_GroNLP['device'])\n# less_toxic_preds_GroNLP = inference_GroNLP(MODEL_PATHS_GroNLP, less_toxic_test_loader_GroNLP, CONFIG_GroNLP['device'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# more_toxic_preds = inference(MODEL_PATHS, more_toxic_test_loader, CONFIG['device'])\n\n# more_toxic_preds_distilbert = inference_distilbert(MODEL_PATHS_distilbert, more_toxic_test_loader_distilbert, CONFIG_distilbert['device'])\n# more_toxic_preds_robertabase = inference_robertabase(MODEL_PATHS_robertabase, more_toxic_test_loader_robertabase, CONFIG_robertabase['device'])\n# more_toxic_preds_hatebert = inference_hatebert(MODEL_PATHS_hatebert, more_toxic_test_loader_hatebert, CONFIG_GroNLP['device'])\n# more_toxic_preds_GroNLP = inference_GroNLP(MODEL_PATHS_GroNLP, more_toxic_test_loader_GroNLP, CONFIG_GroNLP['device'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# less_toxic_preds_ensemble =  less_toxic_preds_distilbert * 0.10 + less_toxic_preds_hatebert * 0.35 + less_toxic_preds_robertabase * 0.20 + less_toxic_preds_GroNLP * 0.35\n# more_toxic_preds_ensemble =  more_toxic_preds_distilbert * 0.10 + more_toxic_preds_hatebert * 0.35 + more_toxic_preds_robertabase * 0.20 + more_toxic_preds_GroNLP * 0.35","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# less_toxic_preds_ensemble =  less_toxic_preds_distilbert * 0.40 + less_toxic_preds_GroNLP * 0.60\n# more_toxic_preds_ensemble =  more_toxic_preds_distilbert * 0.40 + more_toxic_preds_GroNLP * 0.60","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (less_toxic_preds_ensemble < more_toxic_preds_ensemble).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_distilbert = inference_distilbert(MODEL_PATHS_distilbert, test_loader_distilbert, CONFIG_distilbert['device'])\npreds_robertabase = inference_robertabase(MODEL_PATHS_robertabase, test_loader_robertabase, CONFIG_robertabase['device'])\npreds_hatebert = inference_hatebert(MODEL_PATHS_hatebert, test_loader_hatebert, CONFIG_GroNLP['device'])\npreds_GroNLP = inference_GroNLP(MODEL_PATHS_GroNLP, test_loader_GroNLP, CONFIG_GroNLP['device'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f\"Total Predictiions: {preds.shape[0]}\")\n# print(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['score'] = preds_distilbert * 0.25 + preds_GroNLP * 0.50 + preds_robertabase * 0.125 + preds_hatebert * 0.125\n# df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['score'] = df_test['score'].rank(method='first')\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.drop('text', axis=1, inplace=True)\ndf_test.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}