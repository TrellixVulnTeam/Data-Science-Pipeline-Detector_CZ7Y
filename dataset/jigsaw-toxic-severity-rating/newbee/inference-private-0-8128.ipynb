{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport gc\nimport joblib\nimport warnings\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom functools import partial\nfrom scipy.stats import rankdata\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, logging\n\nimport sys \nsys.path.append(\"../input/jigsaw22models-infer/\")\n\nfrom train import *\nfrom inference import *\nfrom text import clean_text as text_preprocess_bert, clean_text_letters as text_preprocess_tfidf","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:41:51.287034Z","iopub.execute_input":"2022-02-07T08:41:51.287433Z","iopub.status.idle":"2022-02-07T08:41:59.041796Z","shell.execute_reply.started":"2022-02-07T08:41:51.287327Z","shell.execute_reply":"2022-02-07T08:41:59.041029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TTA\ndef predict_single_string(model, tokens):\n    tokens = np.array(tokens).reshape(1, -1)\n    return model(\n        torch.tensor(tokens, dtype=torch.long).to(DEVICE), \n        torch.tensor(np.ones_like(tokens), dtype=torch.long).to(DEVICE)\n    ).detach().cpu().numpy()[0][0]\n\ndef string_chunks_prediction(model, tokens, chunk_size, sos_id, eos_id):\n    out = []\n    chunk_size -= 2 # minus sos, eos\n    lb, rb = 0, chunk_size\n    while lb < len(tokens):\n        chunk = [sos_id] + tokens[lb:rb] + [eos_id]\n        p = predict_single_string(model, chunk)\n        out.append(p)\n        lb, rb = lb + chunk_size, rb + chunk_size\n    return out\n\ndef tta(model, loader, config):\n    print(str(config['weights_path']))\n    \n    net = make_model(config)\n    net.load_state_dict(torch.load(config['weights_path'], map_location=DEVICE))\n    net.eval()    \n    \n    s = config['seqlen']\n    tokenizer = config['tokenizer']\n    preds = []\n    for strings in tqdm(loader, total=len(loader), desc=\"tta\"):\n        batch_tokens = tokenizer(strings, padding=False, add_special_tokens=False)\n        for tokens in batch_tokens['input_ids']:\n            length = len(tokens)\n            if length <= s - 2:\n                tokens = [tokenizer.cls_token_id] + tokens + [tokenizer.eos_token_id]\n                p = [predict_single_string(net, tokens)]\n            else:\n                p = string_chunks_prediction(net, tokens, s, tokenizer.cls_token_id, tokenizer.eos_token_id)\n            preds.append(p)\n    \n    # weighting\n    weights = np.round(np.exp(-0.5*np.arange(0, 100)), 2)\n    preds_wgt = np.zeros(len(preds), dtype=float)\n    for i in range(len(preds)):\n        p = preds[i]\n        w = weights[:len(p)]\n        preds_wgt[i] = p @ (w/w.sum())\n    \n    del net\n    gc.collect()\n    return rankdata(preds_wgt)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:41:59.043481Z","iopub.execute_input":"2022-02-07T08:41:59.043733Z","iopub.status.idle":"2022-02-07T08:41:59.057654Z","shell.execute_reply.started":"2022-02-07T08:41:59.043699Z","shell.execute_reply":"2022-02-07T08:41:59.056921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logging.set_verbosity_error()\nwarnings.filterwarnings(\"ignore\")\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ['TOKENIZERS_PARALLELISM'] = \"false\"\npd.options.display.max_colwidth = 200","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:41:59.059089Z","iopub.execute_input":"2022-02-07T08:41:59.059926Z","iopub.status.idle":"2022-02-07T08:41:59.07181Z","shell.execute_reply.started":"2022-02-07T08:41:59.059895Z","shell.execute_reply":"2022-02-07T08:41:59.071101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nMODELS_DIR_RIDGE = Path(\"../input/jigsaw22models-infer/linear\")\nWEIGHT_DIR_BERT  = Path(\"../input/jigsaw22models-infer/roberta\")\nMODELS_DIR_BERT  = Path(\"../input/nlpmodels/\")","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:41:59.073425Z","iopub.execute_input":"2022-02-07T08:41:59.07365Z","iopub.status.idle":"2022-02-07T08:41:59.12532Z","shell.execute_reply.started":"2022-02-07T08:41:59.073615Z","shell.execute_reply":"2022-02-07T08:41:59.124488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf['text_tfidf'] = df['text'].copy()\ndf = text_preprocess_tfidf(df, 'text_tfidf')\ndf['text'] = [text_preprocess_bert(t) for t in df.text]\ninference_dataset = InferenceDataset(df) # takes \"text\" field\nloader = DataLoader(inference_dataset, batch_size=32, num_workers=1, shuffle=False, pin_memory=False, collate_fn=None)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:41:59.128962Z","iopub.execute_input":"2022-02-07T08:41:59.129172Z","iopub.status.idle":"2022-02-07T08:42:01.372855Z","shell.execute_reply.started":"2022-02-07T08:41:59.129147Z","shell.execute_reply":"2022-02-07T08:42:01.372113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roberta\n!ls {WEIGHT_DIR_BERT}\n\nfolds = 1\nmodel = \"roberta_toxicity_classifier\"\n\nseqlen = [128, 128, 256, 512, 128, 512]\nmodels = [\"clf-128-v2\", \"clf-128\", \"clf-256\", \"clf-512\", \"oe-128\", \"oe-512\"]\n\npreds_roberta = np.zeros((len(inference_dataset), len(models)), dtype=np.float64)\nfor i, (s, name) in enumerate(zip(seqlen, models)):\n    config = make_inference_config(model, MODELS_DIR_BERT, WEIGHT_DIR_BERT / name / \"model.bin\", s, folds, DEVICE)\n    config['tokenizer'] = AutoTokenizer.from_pretrained(MODELS_DIR_BERT / model)\n    preds_roberta[:, i] = tta(model, loader, config)\n    # preds_roberta[:, i] = prediction(inference_dataset, config).squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T08:42:01.374259Z","iopub.execute_input":"2022-02-07T08:42:01.374507Z","iopub.status.idle":"2022-02-07T09:00:35.83797Z","shell.execute_reply.started":"2022-02-07T08:42:01.374475Z","shell.execute_reply":"2022-02-07T09:00:35.837158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tfidf regression\n\n!ls {MODELS_DIR_RIDGE}\n\nmodels = [\"bias\", \"clf\", \"oe\", \"pub-ruddit\", \"td2\"]\npreds_ridge = np.zeros((len(inference_dataset), len(models)), dtype=np.float64)\n\nfor i, model in enumerate(models):\n    path = MODELS_DIR_RIDGE / f\"{model}.pkl\"\n    print(path)\n    ridge = joblib.load(path)\n    preds_ridge[:, i] = rankdata(ridge.predict(df.text_tfidf))\n    del ridge\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T09:00:35.839963Z","iopub.execute_input":"2022-02-07T09:00:35.840459Z","iopub.status.idle":"2022-02-07T09:01:30.078311Z","shell.execute_reply.started":"2022-02-07T09:00:35.840423Z","shell.execute_reply":"2022-02-07T09:01:30.077578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ensemble\n# w = np.array([0.544, 0.55 , 0.539, 0.455, 0.506, 0.929, 0.467, 0.384, 0.936, 0.257, 0.016])\nw = np.array([0.813, 0.512, 0.945, 0.05, 0.896, 0.574, 0.999, 0.928, 0.898, 0.062, 0.508])\n# w = np.array([0.509, 0.354, 0.699, 0.031, 0.927])\n\npreds = np.concatenate((preds_ridge, preds_roberta), axis=1)\n# preds = preds_ridge\ndf['score'] = rankdata(preds @ w, method=\"ordinal\")","metadata":{"execution":{"iopub.status.busy":"2022-02-07T09:01:30.079751Z","iopub.execute_input":"2022-02-07T09:01:30.080042Z","iopub.status.idle":"2022-02-07T09:01:30.093988Z","shell.execute_reply.started":"2022-02-07T09:01:30.080005Z","shell.execute_reply":"2022-02-07T09:01:30.092998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/sample_submission.csv\")\ndel submission['score']\nsubmission = pd.merge(submission, df[['comment_id', 'score']], on='comment_id')\n# assert np.all(submission.comment_id == df.comment_id)\n# submission['score'] = df['score'].values\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T09:01:30.095211Z","iopub.execute_input":"2022-02-07T09:01:30.095765Z","iopub.status.idle":"2022-02-07T09:01:30.163908Z","shell.execute_reply.started":"2022-02-07T09:01:30.09559Z","shell.execute_reply":"2022-02-07T09:01:30.163155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T09:01:30.166006Z","iopub.execute_input":"2022-02-07T09:01:30.166387Z","iopub.status.idle":"2022-02-07T09:01:30.182844Z","shell.execute_reply.started":"2022-02-07T09:01:30.166353Z","shell.execute_reply":"2022-02-07T09:01:30.182201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sort_values('score', ascending=False).iloc[[0,1,2,3,4,5,6,7,8,9,10,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1], [1,3]]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T09:01:30.18404Z","iopub.execute_input":"2022-02-07T09:01:30.18429Z","iopub.status.idle":"2022-02-07T09:01:30.202787Z","shell.execute_reply.started":"2022-02-07T09:01:30.184258Z","shell.execute_reply":"2022-02-07T09:01:30.202153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}