{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n# Python Libraries\nimport os\nimport gc\nimport pickle\nfrom bs4 import BeautifulSoup\nimport re \n\n# Third party\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import rankdata\nimport plotly.express as px\n%matplotlib inline\n\n# Pytorch \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import AutoTokenizer, AutoModel,AutoConfig\nfrom transformers import AlbertModel,AlbertTokenizer\nfrom transformers import BertModel,BertTokenizer\nfrom transformers import RobertaModel,RobertaTokenizer\nfrom transformers import DebertaModel, DebertaTokenizer\nfrom transformers import XLNetModel,XLNetTokenizer,XLNetConfig\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nall_preds = []","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-07T13:08:45.584047Z","iopub.execute_input":"2022-02-07T13:08:45.584488Z","iopub.status.idle":"2022-02-07T13:08:45.596338Z","shell.execute_reply.started":"2022-02-07T13:08:45.584451Z","shell.execute_reply":"2022-02-07T13:08:45.595692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nif _df.shape[0] == 7537:\n    _df = _df.head(320)\n    \ndef load_pickle(filename):\n    with open(filename, mode='rb') as f:\n        p = pickle.load(f)\n    return p \n# 1\n# =================================================================================\nvec = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/tfidf1.pkl')\nmodel1=load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/Ridge1.pkl')\ndf_test = _df.copy()\ntest=vec.transform(df_test['text'])\njr_preds=model1.predict(test)\ndf_test['score1']=rankdata( jr_preds, method='ordinal') \n\nvec = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/tfidf2.pkl')\nmodel1=load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/Ridge2.pkl')\n\ntest=vec.transform(df_test['text'])\nrud_preds=model1.predict(test)\ndf_test['score2']=rankdata( rud_preds, method='ordinal')\ndf_test['score']=df_test['score1']+df_test['score2']\ndf_test['score']=rankdata( df_test['score'], method='ordinal')\ndf_test[['comment_id', 'score']].to_csv(\"submission1.csv\", index=False)\n# 2\n# =================================================================================\ndef dummy_fun(doc):\n    return doc\ntokenizer = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/tokenizer1.pkl')\nvectorizer = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/tfidf3.pkl')\nregressor = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/Redge3.pkl')\n\ndf_test2 = _df.copy()\ntexts = df_test2['text']\ntexts = tokenizer(texts.to_list())['input_ids']\ntexts = vectorizer.transform(texts)\n\ndf_test2['prediction'] = regressor.predict(texts)\ndf_test2 = df_test2[['comment_id','prediction']]\n\ndf_test2['score'] = df_test2['prediction']\ndf_test2 = df_test2[['comment_id','score']]\n\ndf_test2.to_csv('./submission2.csv', index=False)\n# 3\n# =================================================================================\ndef text_cleaning2(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\nvec = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/tfidf4.pkl')\nmodel = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/Redge4.pkl')\nl_model = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/Redge5.pkl')\ns_model = load_pickle('../input/overfitting-lb-is-easier-than-solving-the-problem/Redge6.pkl')\n\ndf_sub = _df.copy()\ndf_sub['text'] = df_sub['text'].apply(text_cleaning2)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) / 3.\ndf_sub['score'] = df_sub['score']\ndf_sub[['comment_id', 'score']].to_csv(\"submission3.csv\", index=False)\n\n# アンサンブル\n# =================================================================================\ndata = pd.read_csv(\"./submission1.csv\",index_col=\"comment_id\")\ndata[\"score1\"] = data[\"score\"]\n\ndata[\"score2\"] = pd.read_csv(\"./submission2.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score2\"] = rankdata( data[\"score2\"], method='ordinal')\n\ndata[\"score3\"] = pd.read_csv(\"./submission3.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score3\"] = rankdata( data[\"score3\"], method='ordinal')\n\ndata[\"score\"] = 2*data[\"score1\"] + .66*data[\"score2\"] + data[\"score3\"]*.33\ndata[\"score\"] = rankdata( data[\"score\"], method='ordinal')\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del _df, vec, model1, df_test,test,jr_preds,rud_preds,tokenizer,vectorizer,regressor,df_test2,texts,l_model,s_model,X_test,p3,p4,p5,df_sub\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# text_cleaning\n# ====================================================\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:08:46.182881Z","iopub.execute_input":"2022-02-07T13:08:46.183667Z","iopub.status.idle":"2022-02-07T13:08:46.191263Z","shell.execute_reply.started":"2022-02-07T13:08:46.183615Z","shell.execute_reply":"2022-02-07T13:08:46.190082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass JigsawDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer):\n        self.df = df\n        self.max_len = cfg.max_len\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']  \n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }\n# ====================================================\n# model\n# ====================================================\nclass bert_model(nn.Module):\n    def __init__(self, cfg):\n        super(bert_model, self).__init__()\n        self.cfg = cfg\n        self.config = AutoConfig.from_pretrained(self.cfg.model_name)\n        self.bert = AutoModel.from_pretrained(self.cfg.model_name,\n                                              hidden_dropout_prob=0,\n                                              attention_probs_dropout_prob=0)\n        # self.bert = transformers.BertForSequenceClassification.from_pretrained(BERT_MODEL,num_labels=1)\n        self.ln = nn.LayerNorm(self.config.hidden_size)\n        self.out = nn.Linear(self.config.hidden_size, 1)\n\n    def forward(self, ids, mask):\n        # pooler\n        emb, _ = self.bert(ids, attention_mask=mask,return_dict=False)\n        emb = torch.mean(emb, axis=1)\n        output = self.ln(emb)\n        output = self.out(output)\n        return output\n\nclass distilbert_model(nn.Module):\n    def __init__(self, cfg):\n        super(distilbert_model, self).__init__()\n        self.cfg = cfg\n        self.config = AutoConfig.from_pretrained(self.cfg.model_name)\n        self.bert = AutoModel.from_pretrained(self.cfg.model_name,\n                                              attention_dropout=0,\n                                              dropout=0)\n        self.ln = nn.LayerNorm(self.config.hidden_size)\n        self.out = nn.Linear(self.config.hidden_size, 1)\n\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.bert(ids, attention_mask=mask)['last_hidden_state'][:, 0, :]\n#         emb = torch.mean(emb, axis=1)\n        output = self.ln(emb)\n        output = self.out(output)\n        return output\n\nclass roberta_model(nn.Module):\n    # https://github.com/TakoiHirokazu/kaggle_commonLit_readability_prize/blob/master/exp/ex072.py\n    def __init__(self, cfg):\n        super(roberta_model, self).__init__()\n        self.cfg = cfg\n        self.roberta = AutoModel.from_pretrained(self.cfg.model_name)\n        self.num_features = self.roberta.pooler.dense.out_features\n        \n        # self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(self.num_features)\n        self.out = nn.Linear(self.num_features, 1)\n        \n    def forward(self, ids, mask):\n        # pooler\n        emb= self.roberta(input_ids=ids, attention_mask=mask)[\n            \"last_hidden_state\"]\n        emb = torch.mean(emb, axis=1)\n        output = self.ln(emb)\n        # output = self.dropout(output)\n        output = self.out(output)\n        return output\n\nclass deberta_model(nn.Module):\n    # https://github.com/TakoiHirokazu/kaggle_commonLit_readability_prize/blob/master/exp/ex182.py\n    def __init__(self,cfg):\n        super(deberta_model, self).__init__()\n        self.cfg = cfg\n        self.deberta_model = AutoModel.from_pretrained(self.cfg.model_name,\n                                                          hidden_dropout_prob=0,\n                                                          attention_probs_dropout_prob=0,\n                                                          hidden_act=\"gelu_new\")\n        self.num_features = self.deberta_model.encoder.rel_embeddings.embedding_dim\n        # self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(self.num_features)\n        self.out = nn.Linear(self.num_features, 1)\n\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.deberta_model(ids, attention_mask=mask)[\n            'last_hidden_state'][:, 0, :]\n        output = self.ln(emb)\n        # output = self.dropout(output)\n        output = self.out(output)\n        return output\n    \nclass xlnet_model(nn.Module):\n    # https://github.com/TakoiHirokazu/kaggle_commonLit_readability_prize/blob/master/exp/ex182.py\n    def __init__(self,cfg):\n        super(xlnet_model, self).__init__()\n        self.cfg = cfg\n        self.config = AutoConfig.from_pretrained('../input/xlnet-pretrained-models-pytorch/xlnet-base-cased-config.json')\n        self.config.hidden_dropout_prob = 0\n        self.config.attention_probs_dropout_prob = 0\n        self.config.dropout = 0\n        self.xlnet_model = AutoModel.from_pretrained(self.cfg.model_name,\n                                                    config=self.config)\n        self.ln = nn.LayerNorm(self.config.hidden_size)\n        self.out = nn.Linear(self.config.hidden_size, 1)\n\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.xlnet_model(ids, attention_mask=mask)['last_hidden_state']\n        emb = torch.mean(emb,axis=1)\n        output = self.ln(emb)\n        # output = self.dropout(output)\n        output = self.out(output)\n        return output\n    \nclass gpt2_model(nn.Module):\n    # https://github.com/TakoiHirokazu/kaggle_commonLit_readability_prize/blob/master/exp/ex429.py\n    def __init__(self,cfg):\n        super(gpt2_model, self).__init__()\n        self.cfg = cfg\n        self.gpt2_model = AutoModel.from_pretrained(self.cfg.model_name,\n                                                    attn_pdrop=0,\n                                                    embd_pdrop=0,\n                                                    resid_pdrop=0,\n                                                    summary_first_dropout=0)\n        self.gpt2_model.resize_token_embeddings(len(cfg.tokenizer))\n\n        # self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(1024)\n        self.out = nn.Linear(1024, 1)\n\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.gpt2_model(ids, attention_mask=mask)[\"last_hidden_state\"]\n        emb = torch.mean(emb, axis=1)\n        output = self.ln(emb)\n        # output = self.dropout(output)\n        output = self.out(output)\n        return output\n    \nclass albert_model(nn.Module):\n    def __init__(self, cfg):\n        super(albert_model, self).__init__()\n        self.cfg = cfg\n        self.config = AutoConfig.from_pretrained(self.cfg.model_name)\n        self.albert = AlbertModel.from_pretrained(\n            self.cfg.model_name,\n            hidden_dropout_prob=0,\n            attention_probs_dropout_prob=0\n        )\n\n        # self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(self.config.hidden_size)\n        self.out = nn.Linear(self.config.hidden_size, 1)\n\n    def forward(self, ids, mask, token_type_ids):\n        # pooler\n        emb = self.albert(ids, attention_mask=mask, token_type_ids=token_type_ids)[\n            \"last_hidden_state\"]\n        emb = torch.mean(emb, axis=1)\n        output = self.ln(emb)\n        # output = self.dropout(output)\n        output = self.out(output)\n        return output#, emb\n    \nclass bart_model(nn.Module):\n    # https://github.com/TakoiHirokazu/kaggle_commonLit_readability_prize/blob/master/exp/ex107.py\n    def __init__(self, cfg):\n        super(bart_model, self).__init__()\n        self.cfg = cfg\n        self.config = AutoConfig.from_pretrained(self.cfg.model_name)\n        self.config.hidden_dropout_prob = 0\n        self.bart = AutoModel.from_pretrained(\n            self.cfg.model_name,\n            dropout=0.0, attention_dropout=0.0\n        )\n\n        # self.dropout = nn.Dropout(p=0.2)\n        self.ln = nn.LayerNorm(self.config.hidden_size)\n        self.out = nn.Linear(self.config.hidden_size, 1)\n\n    def forward(self, ids, mask):\n        # pooler\n        emb = self.bart(ids, attention_mask=mask)['last_hidden_state']\n        emb = torch.mean(emb, axis=1)\n        output = self.ln(emb)\n        # output = self.dropout(output)\n        output = self.out(output)\n        return output\n    \n# ====================================================\n# comon prediction func\n# ====================================================\ndef predict(model, loader):\n    model = model.to(device)\n    model = model.eval()\n    predicts = []\n    for data in tqdm(loader):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        with torch.no_grad():\n            predict = model(ids, mask).squeeze(1)\n        predict = predict.sigmoid().detach().cpu()\n        predicts.append(predict)\n    predicts = np.concatenate(predicts)\n    return predicts","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:08:47.325381Z","iopub.execute_input":"2022-02-07T13:08:47.325696Z","iopub.status.idle":"2022-02-07T13:08:47.374001Z","shell.execute_reply.started":"2022-02-07T13:08:47.325649Z","shell.execute_reply":"2022-02-07T13:08:47.373085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\nif df.shape[0] == 7537:\n    df = df.head(320)\ndf_cleaned = df.copy()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:08:48.663093Z","iopub.execute_input":"2022-02-07T13:08:48.66334Z","iopub.status.idle":"2022-02-07T13:08:48.763875Z","shell.execute_reply.started":"2022-02-07T13:08:48.663311Z","shell.execute_reply":"2022-02-07T13:08:48.763184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned['text'] = df_cleaned['text'].apply(text_cleaning)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:20:49.266222Z","iopub.execute_input":"2022-02-07T00:20:49.266704Z","iopub.status.idle":"2022-02-07T00:20:49.395902Z","shell.execute_reply.started":"2022-02-07T00:20:49.266668Z","shell.execute_reply":"2022-02-07T00:20:49.395269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trained Binaly Data Models","metadata":{}},{"cell_type":"code","source":"# %%time\n# \"\"\"====================================================\n# roberta_base binary exp001\n# ====================================================\"\"\"\n# roberta_base_MODEL_PATH = '../input/roberta-transformers-pytorch/roberta-base'\n# roberta_base_tokenizer = RobertaTokenizer.from_pretrained(roberta_base_MODEL_PATH)\n\n# class CFG_BI_001:\n#     CV = 0.6981\n#     model_name = roberta_base_MODEL_PATH\n#     max_len = 256\n#     # DataLoader\n#     loader = {\n#         \"batch_size\": 32,\n#         \"num_workers\": 2,\n#         \"shuffle\": False,\n#         \"pin_memory\": True,\n#         \"drop_last\": False,\n#     }\n# _CFG = CFG_BI_001 # edit\n# ds = JigsawDataset(_CFG, df_cleaned, roberta_base_tokenizer) # edit\n# loader = DataLoader(ds, **_CFG.loader)\n\n# predictions = []\n# for fold in tqdm(range(5)):\n#     model = roberta_model(_CFG) # edit\n#     model.load_state_dict(torch.load(f\"../input/jigsaw4-model2/bi001_roberta-base/Bi_exp001_fold{fold}_best.pth\")) # edit\n#     p = predict(model, loader)\n#     predictions.append(p)\n#     del model\n#     torch.cuda.empty_cache()\n#     gc.collect()\n\n    \n# pred = np.mean(predictions,axis=0)\n# all_preds.append(pred)\n# # plot\n# plt.hist(pred)\n# plt.show()\n\n# del ds, loader, pred\n# torch.cuda.empty_cache()\n# gc.collect()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:20:49.3972Z","iopub.execute_input":"2022-02-07T00:20:49.397461Z","iopub.status.idle":"2022-02-07T00:21:54.658615Z","shell.execute_reply.started":"2022-02-07T00:20:49.397426Z","shell.execute_reply":"2022-02-07T00:21:54.657894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# \"\"\"====================================================\n# # distilroberta-base binary exp002\n# ====================================================\"\"\"\n# distilroberta_base_MODEL_PATH = '../input/distilroberta-base'\n# distilroberta_base_tokenizer = RobertaTokenizer.from_pretrained(distilroberta_base_MODEL_PATH)\n\n# class CFG_BI_002:\n#     CV = 0.6955\n#     model_name = distilroberta_base_MODEL_PATH\n#     max_len = 256\n#     # DataLoader\n#     loader = {\n#         \"batch_size\": 64,\n#         \"num_workers\": 2,\n#         \"shuffle\": False,\n#         \"pin_memory\": True,\n#         \"drop_last\": False,\n#     }\n# _CFG = CFG_BI_002 # edit\n# ds = JigsawDataset(_CFG, df_cleaned, distilroberta_base_tokenizer) # edit\n# loader = DataLoader(ds, **_CFG.loader)\n\n# predictions = []\n# for fold in tqdm(range(5)):\n#     model = roberta_model(_CFG) # edit\n#     model.load_state_dict(torch.load(f\"../input/jigsaw4-binary-task/Bi_exp002_fold{fold}_best.pth\")) # edit\n#     p = predict(model, loader)\n#     predictions.append(p)\n#     del model\n#     torch.cuda.empty_cache()\n#     gc.collect()\n\n    \n# pred = np.mean(predictions,axis=0)\n# all_preds.append(pred)\n# # plot\n# plt.hist(pred)\n# plt.show()\n# del ds, loader, pred\n# torch.cuda.empty_cache()\n# gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:21:54.660245Z","iopub.execute_input":"2022-02-07T00:21:54.660747Z","iopub.status.idle":"2022-02-07T00:21:54.666086Z","shell.execute_reply.started":"2022-02-07T00:21:54.660708Z","shell.execute_reply":"2022-02-07T00:21:54.665347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# deberta_learge binary exp003\n====================================================\"\"\"\ndeberta_large_MODEL_PATH = '../input/deberta/large'\ndeberta_large_tokenizer = DebertaTokenizer.from_pretrained(deberta_large_MODEL_PATH)\n\nclass CFG_BI_003:\n    CV = 0.7032\n    model_name = deberta_large_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 4,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG_BI_003 # edit\nds = JigsawDataset(_CFG, df_cleaned, deberta_large_tokenizer) # edit\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = deberta_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model2/bi003_deberta-large/Bi_exp003_fold{fold}_best.pth\")) # edit\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:21:54.667545Z","iopub.execute_input":"2022-02-07T00:21:54.667833Z","iopub.status.idle":"2022-02-07T00:25:02.895917Z","shell.execute_reply.started":"2022-02-07T00:21:54.667798Z","shell.execute_reply":"2022-02-07T00:25:02.89509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# \"\"\"====================================================\n# # distilbert-base-uncased-distilled-squad binary exp004\n# ====================================================\"\"\"\n# distilbert_base_MODEL_PATH = '../input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad'\n# distilbert_base_tokenizer = AutoTokenizer.from_pretrained(distilbert_base_MODEL_PATH)\n\n# class CFG_BI_004:\n#     CV = 0.6967\n#     model_name = distilbert_base_MODEL_PATH\n#     max_len = 256\n#     # DataLoader\n#     loader = {\n#         \"batch_size\": 72,\n#         \"num_workers\": 2,\n#         \"shuffle\": False,\n#         \"pin_memory\": True,\n#         \"drop_last\": False,\n#     }\n# _CFG = CFG_BI_004 # edit\n# ds = JigsawDataset(_CFG, df_cleaned, distilbert_base_tokenizer) # edit\n# loader = DataLoader(ds, **_CFG.loader) # edit\n\n# predictions = []\n# for fold in tqdm(range(5)):\n#     model = distilbert_model(_CFG)\n#     model.load_state_dict(torch.load(f\"../input/jigsaw4-binary-task-exp004/Bi_exp004_fold{fold}_best.pth\")) # edit\n#     p = predict(model, loader)\n#     predictions.append(p)\n#     del model\n#     torch.cuda.empty_cache()\n#     gc.collect()\n\n    \n# pred = np.mean(predictions,axis=0)\n# all_preds.append(pred)\n# # plot\n# plt.hist(pred)\n# plt.show()\n# del ds, loader, pred\n# torch.cuda.empty_cache()\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:25:02.897583Z","iopub.execute_input":"2022-02-07T00:25:02.899037Z","iopub.status.idle":"2022-02-07T00:25:02.904562Z","shell.execute_reply.started":"2022-02-07T00:25:02.898995Z","shell.execute_reply":"2022-02-07T00:25:02.903746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# gpt2-medium binary exp006\n====================================================\"\"\"\nfrom transformers import GPT2Model, GPT2Tokenizer, GPT2Config\ngpt2_medium_MODEL_PATH = \"../input/jigsaw4-gpt-medium-save/gpt-medium/\"\ngpt2_medium_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_medium_MODEL_PATH)\n\nclass CFG_BI_006:\n    CV = 0.6993\n    model_name = gpt2_medium_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 16,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG_BI_006 # edit\n_CFG.tokenizer = gpt2_medium_tokenizer\nds = JigsawDataset(_CFG, df_cleaned, gpt2_medium_tokenizer) # edit\nloader = DataLoader(ds, **_CFG.loader) # edit\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = gpt2_model(_CFG) # edit\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model2/Bi_006_gpt2-medium/Bi_exp006_fold{fold}_best.pth\")) # edit\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:25:02.907017Z","iopub.execute_input":"2022-02-07T00:25:02.907714Z","iopub.status.idle":"2022-02-07T00:28:20.196105Z","shell.execute_reply.started":"2022-02-07T00:25:02.907674Z","shell.execute_reply":"2022-02-07T00:28:20.195223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# \"\"\"====================================================\n# # albert-xlarge-v2 binary exp007\n# ====================================================\"\"\"\n# albert_xlarge_MODEL_PATH = '../input/jigsaw4-albert-xlarge-v2-save/albert-xlarge-v2/'\n# albert_xlarge_tokenizer = AlbertTokenizer.from_pretrained(albert_xlarge_MODEL_PATH)\n\n# class CFG_BI_007:\n#     CV = 0.6962\n#     model_name = albert_xlarge_MODEL_PATH\n#     max_len = 256\n#     # DataLoader\n#     loader = {\n#         \"batch_size\": 4,\n#         \"num_workers\": 2,\n#         \"shuffle\": False,\n#         \"pin_memory\": True,\n#         \"drop_last\": False,\n#     }\n# _CFG = CFG_BI_007 # edit\n# ds = JigsawDataset(_CFG, df_cleaned, albert_xlarge_tokenizer) # edit\n# loader = DataLoader(ds, **_CFG.loader)\n\n# predictions = []\n# for fold in tqdm(range(5)):\n#     model = albert_model(_CFG)\n#     model.load_state_dict(torch.load(f\"../input/jigsaw4-model2/bi007_albert-xlarge-v2/Bi_exp007_fold{fold}_best.pth\")) # edit\n#     p = predict(model, loader)\n#     predictions.append(p)\n#     del model\n#     torch.cuda.empty_cache()\n#     gc.collect()\n\n    \n# pred = np.mean(predictions,axis=0)\n# all_preds.append(pred)\n# # plot\n# plt.hist(pred)\n# plt.show()\n# del ds, loader, pred\n# torch.cuda.empty_cache()\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:28:20.197579Z","iopub.execute_input":"2022-02-07T00:28:20.198022Z","iopub.status.idle":"2022-02-07T00:28:20.204297Z","shell.execute_reply.started":"2022-02-07T00:28:20.19798Z","shell.execute_reply":"2022-02-07T00:28:20.20333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trained Valid and extra valid data models","metadata":{}},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# roberta_base exp008\n====================================================\"\"\"\nroberta_base_MODEL_PATH = '../input/roberta-transformers-pytorch/roberta-base'\nroberta_base_tokenizer = RobertaTokenizer.from_pretrained(roberta_base_MODEL_PATH)\n\nclass CFG008:\n    CV = 0.7017\n    model_name = roberta_base_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 32,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG008\nds = JigsawDataset(_CFG, df, roberta_base_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = roberta_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model1/exp008_roberta-base/exp008_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:28:20.205647Z","iopub.execute_input":"2022-02-07T00:28:20.205924Z","iopub.status.idle":"2022-02-07T00:29:20.258976Z","shell.execute_reply.started":"2022-02-07T00:28:20.205886Z","shell.execute_reply":"2022-02-07T00:29:20.258234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# deberta_learge exp022\n====================================================\"\"\"\ndeberta_large_MODEL_PATH = '../input/deberta/large'\ndeberta_large_tokenizer = DebertaTokenizer.from_pretrained(deberta_large_MODEL_PATH)\n\nclass CFG022:\n    CV = 0.7003\n    model_name = deberta_large_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 4,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG022\nds = JigsawDataset(_CFG, df, deberta_large_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = deberta_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model1/022_deberta-large/exp022_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:29:20.260547Z","iopub.execute_input":"2022-02-07T00:29:20.261406Z","iopub.status.idle":"2022-02-07T00:32:20.153024Z","shell.execute_reply.started":"2022-02-07T00:29:20.261367Z","shell.execute_reply":"2022-02-07T00:32:20.152225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# # ====================================================\n# # Hate-speech-CNERG/dehatebert-mono-english exp023\n# # ====================================================\n# dehatebert_MODEL_PATH = '../input/hatespeechcnergdehatebertmonoenglish/dehatebert-mono-english'\n# dehatebert_tokenizer = BertTokenizer.from_pretrained(dehatebert_MODEL_PATH)\n\n# class CFG023:\n#     CV = 0.6743\n#     model_name = dehatebert_MODEL_PATH\n#     max_len = 256\n#     # DataLoader\n#     loader = {\n#         \"batch_size\": 32,\n#         \"num_workers\": 2,\n#         \"shuffle\": False,\n#         \"pin_memory\": True,\n#         \"drop_last\": False,\n#     }\n# _CFG = CFG023\n# ds = JigsawDataset(_CFG, df, dehatebert_tokenizer)\n# loader = DataLoader(ds, **_CFG.loader)\n\n# predictions = []\n# for fold in tqdm(range(5)):\n#     model = bert_model(_CFG)\n#     model.load_state_dict(torch.load(f\"../input/jigsaw4-model1/023_hatebert/exo023_fold{fold}_best.pth\"))\n#     p = predict(model, loader)\n#     predictions.append(p)\n#     del model\n#     torch.cuda.empty_cache()\n#     gc.collect()\n\n    \n# pred = np.mean(predictions,axis=0)\n# all_preds.append(pred)\n# # plot\n# plt.hist(pred)\n# plt.show()\n# del ds, loader, pred\n# torch.cuda.empty_cache()\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:32:20.154295Z","iopub.execute_input":"2022-02-07T00:32:20.15506Z","iopub.status.idle":"2022-02-07T00:33:31.634785Z","shell.execute_reply.started":"2022-02-07T00:32:20.155018Z","shell.execute_reply":"2022-02-07T00:33:31.634062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# distilroberta-base exp026\n====================================================\"\"\"\ndistilroberta_base_MODEL_PATH = '../input/distilroberta-base'\ndistilroberta_base_tokenizer = RobertaTokenizer.from_pretrained(distilroberta_base_MODEL_PATH)\n\nclass CFG026:\n    CV = 0.7012\n    model_name = distilroberta_base_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 64,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG026\nds = JigsawDataset(_CFG, df, distilroberta_base_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = roberta_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model1/026_distilroberta-base/exp026_fold{fold}_best.pth\"))\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:33:31.636205Z","iopub.execute_input":"2022-02-07T00:33:31.636612Z","iopub.status.idle":"2022-02-07T00:33:57.697908Z","shell.execute_reply.started":"2022-02-07T00:33:31.63657Z","shell.execute_reply":"2022-02-07T00:33:57.697205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# deberta_base exp032\n====================================================\"\"\"\ndeberta_base_MODEL_PATH = '../input/deberta/base'\ndeberta_base_tokenizer = DebertaTokenizer.from_pretrained(deberta_base_MODEL_PATH)\n\nclass CFG032:\n    CV = 0.7043\n    model_name = deberta_base_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 32,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG032\nds = JigsawDataset(_CFG, df, deberta_base_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = deberta_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model2/032_deberta-base/exp032_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:33:57.699211Z","iopub.execute_input":"2022-02-07T00:33:57.699731Z","iopub.status.idle":"2022-02-07T00:35:07.802802Z","shell.execute_reply.started":"2022-02-07T00:33:57.699691Z","shell.execute_reply":"2022-02-07T00:35:07.802005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# deberta_base exp033\n====================================================\"\"\"\nxlnet_base_MODEL_PATH  = '../input/xlnet-pretrained-models-pytorch/xlnet-base-cased-pytorch_model.bin'\nxlnet_base_tokenizer = XLNetTokenizer.from_pretrained(\"../input/xlnet-pretrained-models-pytorch/xlnet-base-cased-spiece.model\")\n\nclass CFG033:\n    CV = 0.6997\n    model_name = xlnet_base_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 32,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG033\nds = JigsawDataset(_CFG, df, xlnet_base_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = xlnet_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model2/033_xlnet-base-cased/exp033_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T12:48:30.366854Z","iopub.execute_input":"2022-02-07T12:48:30.367112Z","iopub.status.idle":"2022-02-07T12:50:01.060191Z","shell.execute_reply.started":"2022-02-07T12:48:30.367084Z","shell.execute_reply":"2022-02-07T12:50:01.059451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# robelta-large exp034\n====================================================\"\"\"\nrobeota_large_MODEL_PATH = '../input/roberta-transformers-pytorch/roberta-large'\nrobeota_large_tokenizer = RobertaTokenizer.from_pretrained(robeota_large_MODEL_PATH)\n\nclass CFG034:\n    CV = 0.702\n    model_name = robeota_large_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 8,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG034\nds = JigsawDataset(_CFG, df, robeota_large_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = roberta_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model3/034_robelta-large/exp034_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T12:56:47.729606Z","iopub.execute_input":"2022-02-07T12:56:47.730164Z","iopub.status.idle":"2022-02-07T12:56:57.679513Z","shell.execute_reply.started":"2022-02-07T12:56:47.730126Z","shell.execute_reply":"2022-02-07T12:56:57.678729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# facebook/bart-base exp035\n====================================================\"\"\"\nbart_base_MODEL_PATH  = '../input/bart-models-hugging-face-model-repository/bart-base'\nbart_base_tokenizer  = AutoTokenizer.from_pretrained('../input/bartbase/')\n\nclass CFG035:\n    CV = 0.7027\n    model_name = bart_base_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 16,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG035\nds = JigsawDataset(_CFG, df, bart_base_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = bart_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model3/exp035_bart-base/exp035_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:09:40.933896Z","iopub.execute_input":"2022-02-07T13:09:40.934163Z","iopub.status.idle":"2022-02-07T13:10:53.2455Z","shell.execute_reply.started":"2022-02-07T13:09:40.934134Z","shell.execute_reply":"2022-02-07T13:10:53.244806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\"\"\"====================================================\n# Hate-speech-CNERG/dehatebert-mono-english exp036\n====================================================\"\"\"\ndehatebert_MODEL_PATH = '../input/hatespeechcnergdehatebertmonoenglish/dehatebert-mono-english'\ndehatebert_tokenizer = BertTokenizer.from_pretrained(dehatebert_MODEL_PATH)\n\nclass CFG036:\n    CV = 0.6769\n    model_name = dehatebert_MODEL_PATH\n    max_len = 256\n    # DataLoader\n    loader = {\n        \"batch_size\": 32,\n        \"num_workers\": 2,\n        \"shuffle\": False,\n        \"pin_memory\": True,\n        \"drop_last\": False,\n    }\n_CFG = CFG036\nds = JigsawDataset(_CFG, df, dehatebert_tokenizer)\nloader = DataLoader(ds, **_CFG.loader)\n\npredictions = []\nfor fold in tqdm(range(5)):\n    model = bert_model(_CFG)\n    model.load_state_dict(torch.load(f\"../input/jigsaw4-model3/036_hatebert/exp036_fold{fold}_best.pth\"))\n    p = predict(model, loader)\n    predictions.append(p)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    \npred = np.mean(predictions,axis=0)\nall_preds.append(pred)\n# plot\nplt.hist(pred)\nplt.show()\ndel ds, loader, pred\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:00:00.897746Z","iopub.execute_input":"2022-02-07T13:00:00.898597Z","iopub.status.idle":"2022-02-07T13:01:29.140373Z","shell.execute_reply.started":"2022-02-07T13:00:00.898547Z","shell.execute_reply":"2022-02-07T13:01:29.139606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"best score: 0.7141623488773747  \nbest weight: [0.18375869 0.00485101 0.18612081 0.20428201 0.06021268 0.2105402\n 0.061306   0.02023979 0.05850578 0.01018304]  \n https://www.kaggle.com/teyosan1229/jigsaw4-optuna?scriptVersionId=87206038","metadata":{}},{"cell_type":"code","source":"weight = [0.18375869, 0.00485101, 0.18612081, 0.20428201, 0.06021268, 0.2105402, 0.061306, 0.02023979, 0.05850578, 0.01018304]\npred = np.zeros(all_preds[0].shape)\nfor p, w in zip(all_preds, weight):\n    pred += p*w","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:36:57.56856Z","iopub.execute_input":"2022-02-07T00:36:57.569144Z","iopub.status.idle":"2022-02-07T00:36:57.574463Z","shell.execute_reply.started":"2022-02-07T00:36:57.569106Z","shell.execute_reply":"2022-02-07T00:36:57.573557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:40:50.57264Z","iopub.execute_input":"2022-02-07T00:40:50.572936Z","iopub.status.idle":"2022-02-07T00:40:50.578847Z","shell.execute_reply.started":"2022-02-07T00:40:50.5729Z","shell.execute_reply":"2022-02-07T00:40:50.578164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## make submission","metadata":{}},{"cell_type":"code","source":"# df['score'] = np.mean(all_preds,axis=0)\ndf['score'] = pred\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:41:09.699688Z","iopub.execute_input":"2022-02-07T00:41:09.700402Z","iopub.status.idle":"2022-02-07T00:41:09.718433Z","shell.execute_reply.started":"2022-02-07T00:41:09.700362Z","shell.execute_reply":"2022-02-07T00:41:09.717665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['score'] = df['score'].rank(method='first')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:41:14.131735Z","iopub.execute_input":"2022-02-07T00:41:14.132498Z","iopub.status.idle":"2022-02-07T00:41:14.151615Z","shell.execute_reply.started":"2022-02-07T00:41:14.132457Z","shell.execute_reply":"2022-02-07T00:41:14.150929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 公開ノートアンサンブルとbertのアンサンブル\ndf[\"score\"] = 0.33*df[\"score\"].values + 0.66*data[\"score\"].values\ndf[\"score\"] = rankdata( df[\"score\"], method='ordinal')\ndf.head(20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('text', axis=1, inplace=True)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T00:41:15.531137Z","iopub.execute_input":"2022-02-07T00:41:15.531631Z","iopub.status.idle":"2022-02-07T00:41:15.548985Z","shell.execute_reply.started":"2022-02-07T00:41:15.531592Z","shell.execute_reply":"2022-02-07T00:41:15.54824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}