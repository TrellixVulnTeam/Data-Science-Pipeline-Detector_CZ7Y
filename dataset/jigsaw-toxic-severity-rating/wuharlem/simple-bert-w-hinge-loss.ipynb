{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Package","metadata":{}},{"cell_type":"code","source":"import tqdm\nimport ast\n\nimport pandas as pd\nimport numpy as np\n\n## BERT\nimport transformers\nfrom transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:17.697164Z","iopub.execute_input":"2021-12-18T05:44:17.697591Z","iopub.status.idle":"2021-12-18T05:44:25.195696Z","shell.execute_reply.started":"2021-12-18T05:44:17.697513Z","shell.execute_reply":"2021-12-18T05:44:25.194964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data","metadata":{}},{"cell_type":"code","source":"comments = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\npairs = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\nsubmission = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:50.248815Z","iopub.execute_input":"2021-12-18T05:44:50.24908Z","iopub.status.idle":"2021-12-18T05:44:50.806161Z","shell.execute_reply.started":"2021-12-18T05:44:50.24905Z","shell.execute_reply":"2021-12-18T05:44:50.805466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"pairs.less_toxic = pairs.less_toxic.apply(lambda x: ' '.join(x.replace('\\n', ' ').replace('\"', \" \").split()))\npairs.more_toxic = pairs.more_toxic.apply(lambda x: ' '.join(x.replace('\\n', ' ').replace('\"', \" \").split()))\ncomments.text = comments.text.apply(lambda x: ' '.join(x.replace('\\n', ' ').replace('\"', \" \").split()))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:50.807944Z","iopub.execute_input":"2021-12-18T05:44:50.808206Z","iopub.status.idle":"2021-12-18T05:44:51.308309Z","shell.execute_reply.started":"2021-12-18T05:44:50.808172Z","shell.execute_reply":"2021-12-18T05:44:51.307598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:51.309479Z","iopub.execute_input":"2021-12-18T05:44:51.309729Z","iopub.status.idle":"2021-12-18T05:44:51.324965Z","shell.execute_reply.started":"2021-12-18T05:44:51.309693Z","shell.execute_reply":"2021-12-18T05:44:51.324314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2comment = {i: c for i, c in enumerate(list(set(pairs.less_toxic.unique().tolist()+pairs.more_toxic.unique().tolist())))}\ncomment2id = {v:k for (k, v) in id2comment.items()}","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:51.326517Z","iopub.execute_input":"2021-12-18T05:44:51.326828Z","iopub.status.idle":"2021-12-18T05:44:51.40007Z","shell.execute_reply.started":"2021-12-18T05:44:51.326786Z","shell.execute_reply":"2021-12-18T05:44:51.399407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs['id_l'] = pairs.less_toxic.map(comment2id)\npairs['id_m'] = pairs.more_toxic.map(comment2id)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:51.401273Z","iopub.execute_input":"2021-12-18T05:44:51.40152Z","iopub.status.idle":"2021-12-18T05:44:51.448666Z","shell.execute_reply.started":"2021-12-18T05:44:51.401488Z","shell.execute_reply":"2021-12-18T05:44:51.44799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_count = pairs.groupby(['id_l', 'id_m']).count()['worker'].transpose().to_dict()\npairs_count_new = {}\nfor pair in pairs_count:\n    l, m = pair\n    if (m, l) in pairs_count:\n        if (l, m) not in pairs_count_new:\n            ratio = pairs_count[pair]/(pairs_count[pair]+pairs_count[(m, l)])\n            if ratio < 0.5:\n                pairs_count_new[(m, l)] = 1-ratio\n            else:\n                pairs_count_new[(l, m)] = ratio\n    else:\n        pairs_count_new[(l, m)] = 1","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:51.449842Z","iopub.execute_input":"2021-12-18T05:44:51.450085Z","iopub.status.idle":"2021-12-18T05:44:51.669602Z","shell.execute_reply.started":"2021-12-18T05:44:51.450052Z","shell.execute_reply":"2021-12-18T05:44:51.66887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_new = pd.DataFrame.from_dict({'confidence': pairs_count_new}).reset_index()\npairs_new.columns = ['id_l', 'id_m', 'confidence']\npairs_new['less_toxic'] = pairs_new.id_l.map(id2comment)\npairs_new['more_toxic'] = pairs_new.id_m.map(id2comment)\npairs_new.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:51.671476Z","iopub.execute_input":"2021-12-18T05:44:51.671731Z","iopub.status.idle":"2021-12-18T05:44:51.740528Z","shell.execute_reply.started":"2021-12-18T05:44:51.671697Z","shell.execute_reply":"2021-12-18T05:44:51.739859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_bert = \"../input/huggingface-bert/bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(pretrained_bert, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:51.827401Z","iopub.execute_input":"2021-12-18T05:44:51.827637Z","iopub.status.idle":"2021-12-18T05:44:51.882157Z","shell.execute_reply.started":"2021-12-18T05:44:51.827611Z","shell.execute_reply":"2021-12-18T05:44:51.881492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_new['pairs'] = pairs_new.less_toxic + '[SEP]' + pairs_new.more_toxic\npairs_new['pairs'] = pairs_new['pairs'].apply(lambda x: x.split('[SEP]'))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:52.086317Z","iopub.execute_input":"2021-12-18T05:44:52.0869Z","iopub.status.idle":"2021-12-18T05:44:52.123502Z","shell.execute_reply.started":"2021-12-18T05:44:52.086867Z","shell.execute_reply":"2021-12-18T05:44:52.122651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npairs_new['input_ids'] = pairs_new.pairs.apply(lambda x: tokenizer(x, truncation=True, max_length=512))\npairs_new['token_type_ids'] = pairs_new['input_ids'].apply(lambda x: x['token_type_ids'])\npairs_new['attention_mask'] = pairs_new['input_ids'].apply(lambda x: x['attention_mask'])\npairs_new['input_ids']      = pairs_new['input_ids'].apply(lambda x: x['input_ids'])\ncomments['input_ids'] = comments.text.apply(lambda x: tokenizer(x, truncation=True, max_length=512))\ncomments['token_type_ids'] = comments['input_ids'].apply(lambda x: x['token_type_ids'])\ncomments['attention_mask'] = comments['input_ids'].apply(lambda x: x['attention_mask'])\ncomments['input_ids']      = comments['input_ids'].apply(lambda x: x['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:44:52.460904Z","iopub.execute_input":"2021-12-18T05:44:52.461395Z","iopub.status.idle":"2021-12-18T05:46:03.145545Z","shell.execute_reply.started":"2021-12-18T05:44:52.461358Z","shell.execute_reply":"2021-12-18T05:46:03.144816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test = train_test_split(pairs_new, test_size=0.2, random_state=0)\nX_valid, X_test = train_test_split(X_test, test_size=0.5, random_state=0)\n\nSIZE_OF_TRAIN = len(X_train)\nSIZE_OF_VALID = len(X_valid)\nSIZE_OF_TEST  = len(X_test)\n\nprint(SIZE_OF_TRAIN, SIZE_OF_VALID, SIZE_OF_TEST)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:03.147206Z","iopub.execute_input":"2021-12-18T05:46:03.147772Z","iopub.status.idle":"2021-12-18T05:46:03.163475Z","shell.execute_reply.started":"2021-12-18T05:46:03.14773Z","shell.execute_reply":"2021-12-18T05:46:03.162621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.sample()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:03.16485Z","iopub.execute_input":"2021-12-18T05:46:03.165288Z","iopub.status.idle":"2021-12-18T05:46:03.185088Z","shell.execute_reply.started":"2021-12-18T05:46:03.16525Z","shell.execute_reply":"2021-12-18T05:46:03.184399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments.sample()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:03.187152Z","iopub.execute_input":"2021-12-18T05:46:03.187586Z","iopub.status.idle":"2021-12-18T05:46:03.201162Z","shell.execute_reply.started":"2021-12-18T05:46:03.187548Z","shell.execute_reply":"2021-12-18T05:46:03.200483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loader","metadata":{}},{"cell_type":"code","source":"def pad_to_len(seqs, to_len, padding=0):\n    paddeds = []\n    for seq in seqs:\n        paddeds.append(\n            seq[:to_len] + [padding] * max(0, to_len - len(seq))\n        )\n    return paddeds\n\ndef pad_to_len_pair(seqs, to_len, padding=0):\n    paddeds = []\n    for seq in seqs:\n        new_pair = []\n        for pair in seq:\n            new_pair.append(\n                pair[:to_len] + [padding] * max(0, to_len - len(pair))\n            )\n        paddeds.append(new_pair)\n    return paddeds","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:03.20299Z","iopub.execute_input":"2021-12-18T05:46:03.203456Z","iopub.status.idle":"2021-12-18T05:46:03.210294Z","shell.execute_reply.started":"2021-12-18T05:46:03.203408Z","shell.execute_reply":"2021-12-18T05:46:03.20967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class dataset(Dataset):\n    def __init__(self, data):\n        self.data  = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        sample = self.data[index]\n        return sample\n    \n    def collate_fn(self, samples, pair=True):\n\n        batch = {}\n        \n        for key in ['input_ids', 'token_type_ids', 'attention_mask']:\n            \n            if pair:\n            \n                to_len = max([\n                    max(len(sample[key][0]),len(sample[key][1])) \n                    for sample in samples])\n                padded = pad_to_len_pair(\n                    [sample[key] for sample in samples], to_len, 0\n                )\n                batch[key] = torch.tensor(padded)\n            \n            else:\n                to_len = max([len(sample[key]) for sample in samples])\n                padded = pad_to_len(\n                    [sample[key] for sample in samples], to_len, 0\n                )\n                batch[key] = torch.tensor(padded)\n            \n        return batch","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:03.21157Z","iopub.execute_input":"2021-12-18T05:46:03.212002Z","iopub.status.idle":"2021-12-18T05:46:03.221867Z","shell.execute_reply.started":"2021-12-18T05:46:03.211965Z","shell.execute_reply":"2021-12-18T05:46:03.221166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset  = dataset(X_train.reset_index(drop=True).transpose().to_dict())\nvalid_dataset   = dataset(X_valid.reset_index(drop=True).transpose().to_dict())\ntest_dataset   = dataset(X_test.reset_index(drop=True).transpose().to_dict())\nsubmission_dataset = dataset(comments.transpose().to_dict())","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:03.223128Z","iopub.execute_input":"2021-12-18T05:46:03.223562Z","iopub.status.idle":"2021-12-18T05:46:04.913103Z","shell.execute_reply.started":"2021-12-18T05:46:03.223526Z","shell.execute_reply":"2021-12-18T05:46:04.912117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:04.914405Z","iopub.execute_input":"2021-12-18T05:46:04.914675Z","iopub.status.idle":"2021-12-18T05:46:04.919754Z","shell.execute_reply.started":"2021-12-18T05:46:04.91464Z","shell.execute_reply":"2021-12-18T05:46:04.919105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n    dataset = train_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = True,\n    num_workers=8,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(train_dataset, x)\n)\n\nvalid_loader = DataLoader(\n    dataset = valid_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=8,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(train_dataset, x)\n)\n\ntest_loader = DataLoader(\n    dataset = test_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=8,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(train_dataset, x)\n)\n\n\ntest_loader = DataLoader(\n    dataset = test_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=8,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(test_dataset, x, pair=False)\n)\n\n\nsubmission_loader = DataLoader(\n    dataset = submission_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=8,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(submission_dataset, x, pair=False)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:46:04.920882Z","iopub.execute_input":"2021-12-18T05:46:04.922582Z","iopub.status.idle":"2021-12-18T05:46:04.934848Z","shell.execute_reply.started":"2021-12-18T05:46:04.922545Z","shell.execute_reply":"2021-12-18T05:46:04.933964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class BERT(torch.nn.Module):\n    def __init__(self):\n        super().__init__()        \n        self.model = BertModel.from_pretrained(\"../input/huggingface-bert/bert-base-uncased\")\n        self.extractor  = torch.nn.Linear(768, 768)\n        self.classifer  = torch.nn.Linear(768, 1)\n        self.input_drop = torch.nn.Dropout(0.7)\n        self.dropout    = torch.nn.Dropout(0.1)\n        self.relu = torch.nn.ReLU() \n        \n    def forward(self, ids, mask):\n        output = self.model(ids, mask)\n        CLS    = output.last_hidden_state[:,0,:]\n        CLS    = self.input_drop(CLS)\n        output = self.dropout(self.relu(self.extractor(CLS)))\n        output = self.classifer(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:19:38.867351Z","iopub.execute_input":"2021-12-18T06:19:38.868078Z","iopub.status.idle":"2021-12-18T06:19:38.87573Z","shell.execute_reply.started":"2021-12-18T06:19:38.868039Z","shell.execute_reply":"2021-12-18T06:19:38.874855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Estimator():\n    def __init__(self, hyperparameters, device, model, optim = 'AdamW'):        \n        self.params = hyperparameters\n        self.model  = model\n        self.device = device\n        \n        no_decay = ['bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], \n             'weight_decay': self.params['weight_decay']},\n            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], \n             'weight_decay': 0.0}\n        ]\n        \n        if optim == 'Adam':\n            self.optimizer = torch.optim.Adam(params=optimizer_grouped_parameters, \n                                              lr=self.params['learning_rate'])\n        if optim == 'AdamW':\n            self.optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, \n                                              lr=self.params['learning_rate'])\n        self.model.to(self.device)\n        \n    def load_weight(self, weight_path):\n        self.model.load_state_dict(torch.load(weight_path))\n        \n\n    def fit(self, data, save_name):\n\n        ## Meta\n        len_of_train = len(data['train'].dataset)\n        len_of_test  = len(data['test'].dataset)\n        best = 1000\n        \n        train_steps = int(len_of_train/self.params['batch_size']*self.params['epoch'])\n        num_steps   = int(train_steps*0.1)\n\n        scheduler = get_linear_schedule_with_warmup(self.optimizer, num_steps, train_steps)\n\n        for epoch in range(self.params['epoch']):\n            total_loss = 0\n            total_acc  = 0\n            total_val_acc  = 0\n            total_val_loss = 0\n            \n            self.model.train()\n            for step, batch in enumerate(tqdm.tqdm(data['train'])):\n                ## INPUT\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                \n                batch_size, _, max_length = input_ids.size()\n                \n                input_ids = input_ids.reshape(batch_size*2, max_length)\n                attention_mask = attention_mask.reshape(batch_size*2, max_length)\n\n                ## FOWARD\n                output = self.model(input_ids, attention_mask)\n                output = output.reshape(batch_size, 2)\n                pos_score = output[:, 1]\n                neg_score = output[:, 0]\n                acc  = pos_score > neg_score\n                loss = torch.mean(torch.max(torch.zeros_like(pos_score), torch.ones_like(pos_score)-pos_score+neg_score))\n                total_acc+=acc.sum().float().item()\n                total_loss+=loss.item()*len(input_ids)\n\n                ## OPTIMIZE\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                scheduler.step() # Update learning rate schedule\n\n            self.model.eval()\n            for batch in data['test']:\n                with torch.no_grad():\n                    ## INPUT\n                    input_ids = batch['input_ids'].to(self.device)\n                    attention_mask = batch['attention_mask'].to(self.device)\n                    \n                    batch_size, _, max_length = input_ids.size()\n\n                    input_ids = input_ids.reshape(batch_size*2, max_length)\n                    attention_mask = attention_mask.reshape(batch_size*2, max_length)\n\n                    ## FOWARD\n                    output = self.model(input_ids, attention_mask)\n                    output = output.reshape(batch_size, 2)\n                    pos_score = output[:, 1]\n                    neg_score = output[:, 0]\n                    acc  = pos_score > neg_score\n                    loss = torch.mean(torch.max(torch.zeros_like(pos_score), torch.ones_like(pos_score)-pos_score+neg_score))\n                    total_val_acc+=acc.sum().float().item()\n                    total_val_loss+=loss.item()*len(input_ids)\n                \n            print(f'Epoch: {epoch}, Train Loss: {(total_loss/len_of_train)}, Train Acc: {(total_acc/len_of_train)}, \\\n            Test Loss: {(total_val_loss/len_of_test)}, Test Acc: {(total_val_acc/len_of_test)}')\n\n            if total_val_loss/len_of_test < best:\n                best = total_val_loss\n                torch.save(self.model.state_dict(), f\"{save_name}.pth\")\n                    \n    def inference(self, data):\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:20:13.525698Z","iopub.execute_input":"2021-12-18T06:20:13.526059Z","iopub.status.idle":"2021-12-18T06:20:13.548079Z","shell.execute_reply.started":"2021-12-18T06:20:13.526023Z","shell.execute_reply":"2021-12-18T06:20:13.547403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:20:14.149322Z","iopub.execute_input":"2021-12-18T06:20:14.150006Z","iopub.status.idle":"2021-12-18T06:20:14.156303Z","shell.execute_reply.started":"2021-12-18T06:20:14.149967Z","shell.execute_reply":"2021-12-18T06:20:14.155432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator = Estimator(\n    hyperparameters = {\n        'learning_rate': 1e-5,\n        'epoch': 3,\n        'batch_size': BATCH_SIZE,\n        'weight_decay':1e-4,\n    }, \n    device = device,\n    model = BERT()\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:32:03.246679Z","iopub.execute_input":"2021-12-18T06:32:03.247297Z","iopub.status.idle":"2021-12-18T06:32:04.74393Z","shell.execute_reply.started":"2021-12-18T06:32:03.247255Z","shell.execute_reply":"2021-12-18T06:32:04.743162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator.fit({\n    'train': train_loader,\n    'test':valid_loader\n}, save_name='best_model')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:32:05.956354Z","iopub.execute_input":"2021-12-18T06:32:05.956859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator.model.load_state_dict(torch.load('./best_model.pth'))\nestimator.model.eval()\noutputs = []\nfor batch in tqdm.tqdm(submission_loader):\n    with torch.no_grad():\n        ## INPUT\n        input_ids = batch['input_ids'].to(estimator.device)\n        attention_mask = batch['attention_mask'].to(estimator.device)\n\n        ## FOWARD\n        output = estimator.model(input_ids, attention_mask)\n        outputs+=output.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments['score'] = outputs\ncomments['score'] = comments['score'].apply(lambda x: x[0])\nsubmission['score'] = comments['score']","metadata":{"execution":{"iopub.status.busy":"2021-12-17T04:28:34.244153Z","iopub.execute_input":"2021-12-17T04:28:34.244452Z","iopub.status.idle":"2021-12-17T04:28:34.259584Z","shell.execute_reply.started":"2021-12-17T04:28:34.244408Z","shell.execute_reply":"2021-12-17T04:28:34.258519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments[['text', 'score']].sort_values('score', ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T04:28:34.260961Z","iopub.execute_input":"2021-12-17T04:28:34.261234Z","iopub.status.idle":"2021-12-17T04:28:34.28405Z","shell.execute_reply.started":"2021-12-17T04:28:34.261197Z","shell.execute_reply":"2021-12-17T04:28:34.283261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments[['text', 'score']].sort_values('score', ascending=False).tail(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T04:28:34.285932Z","iopub.execute_input":"2021-12-17T04:28:34.2862Z","iopub.status.idle":"2021-12-17T04:28:34.302824Z","shell.execute_reply.started":"2021-12-17T04:28:34.286164Z","shell.execute_reply":"2021-12-17T04:28:34.302148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T04:28:34.304031Z","iopub.execute_input":"2021-12-17T04:28:34.304312Z","iopub.status.idle":"2021-12-17T04:28:34.340489Z","shell.execute_reply.started":"2021-12-17T04:28:34.304277Z","shell.execute_reply":"2021-12-17T04:28:34.339757Z"},"trusted":true},"execution_count":null,"outputs":[]}]}