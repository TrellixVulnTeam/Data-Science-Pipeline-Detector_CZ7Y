{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Environment setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n! pip install pytorch-pretrained-bert pytorch-nlp transformers\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom pytorch_pretrained_bert import BertTokenizer\nfrom pytorch_pretrained_bert.modeling import BertModel\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data._utils.collate import default_collate\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.linear_model import Ridge\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport time\n\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-12-11T03:25:52.497531Z","iopub.execute_input":"2021-12-11T03:25:52.49786Z","iopub.status.idle":"2021-12-11T03:26:04.158774Z","shell.execute_reply.started":"2021-12-11T03:25:52.497779Z","shell.execute_reply":"2021-12-11T03:26:04.158018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:29:14.113994Z","iopub.execute_input":"2021-12-11T03:29:14.114257Z","iopub.status.idle":"2021-12-11T03:29:14.182319Z","shell.execute_reply.started":"2021-12-11T03:29:14.114228Z","shell.execute_reply":"2021-12-11T03:29:14.181659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### get device","metadata":{}},{"cell_type":"code","source":"# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:26:04.160335Z","iopub.execute_input":"2021-12-11T03:26:04.160749Z","iopub.status.idle":"2021-12-11T03:26:04.207856Z","shell.execute_reply.started":"2021-12-11T03:26:04.16071Z","shell.execute_reply":"2021-12-11T03:26:04.205511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Load & analysis","metadata":{}},{"cell_type":"code","source":"comments_to_score = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nsample_submission = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/sample_submission.csv\")\nvalidation_data = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:26:23.465896Z","iopub.execute_input":"2021-12-11T03:26:23.466144Z","iopub.status.idle":"2021-12-11T03:26:24.032967Z","shell.execute_reply.started":"2021-12-11T03:26:23.466115Z","shell.execute_reply":"2021-12-11T03:26:24.032245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments_to_score","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:26:26.620699Z","iopub.execute_input":"2021-12-11T03:26:26.621361Z","iopub.status.idle":"2021-12-11T03:26:26.640362Z","shell.execute_reply.started":"2021-12-11T03:26:26.621325Z","shell.execute_reply":"2021-12-11T03:26:26.639583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:26:29.033649Z","iopub.execute_input":"2021-12-11T03:26:29.033919Z","iopub.status.idle":"2021-12-11T03:26:29.045236Z","shell.execute_reply.started":"2021-12-11T03:26:29.033889Z","shell.execute_reply":"2021-12-11T03:26:29.044528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:26:32.429008Z","iopub.execute_input":"2021-12-11T03:26:32.429442Z","iopub.status.idle":"2021-12-11T03:26:32.44391Z","shell.execute_reply.started":"2021-12-11T03:26:32.429404Z","shell.execute_reply":"2021-12-11T03:26:32.443212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic_data_path = \"../input/all-in-one-jigsaw/all_in_one_jigsaw.csv\"\ntoxic_data = pd.read_csv(toxic_data_path, low_memory=False)\ntoxic_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:26:35.658778Z","iopub.execute_input":"2021-12-11T03:26:35.659029Z","iopub.status.idle":"2021-12-11T03:27:09.944794Z","shell.execute_reply.started":"2021-12-11T03:26:35.659002Z","shell.execute_reply":"2021-12-11T03:27:09.944121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic_data['severe_toxic'] = toxic_data.severe_toxic * 2\ntoxic_data['y'] = (toxic_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)).astype(int)\ntoxic_data['y'] = toxic_data['y'] / toxic_data['y'].max()\ntoxic_data = toxic_data[['comment_text_processed', 'y']].rename(columns={'comment_text_processed': 'text'})\ntoxic_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:31:06.886082Z","iopub.execute_input":"2021-12-11T03:31:06.886362Z","iopub.status.idle":"2021-12-11T03:31:07.48308Z","shell.execute_reply.started":"2021-12-11T03:31:06.886331Z","shell.execute_reply":"2021-12-11T03:31:07.482153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic_data[\"text\"] = toxic_data[\"text\"].astype(\"str\")\ntoxic_data[\"y\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:41:12.536134Z","iopub.execute_input":"2021-12-11T03:41:12.536657Z","iopub.status.idle":"2021-12-11T03:41:12.87416Z","shell.execute_reply.started":"2021-12-11T03:41:12.536617Z","shell.execute_reply":"2021-12-11T03:41:12.87325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(data, col):  # Replace each occurrence of pattern/regex in the Series/Index\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')  \n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    return data ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:49:32.425179Z","iopub.execute_input":"2021-12-11T03:49:32.425887Z","iopub.status.idle":"2021-12-11T03:49:32.432836Z","shell.execute_reply.started":"2021-12-11T03:49:32.425847Z","shell.execute_reply":"2021-12-11T03:49:32.431742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toxic_data = clean(toxic_data, \"text\")\ntoxic_data","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:50:11.439181Z","iopub.execute_input":"2021-12-11T03:50:11.439916Z","iopub.status.idle":"2021-12-11T03:56:55.466793Z","shell.execute_reply.started":"2021-12-11T03:50:11.439879Z","shell.execute_reply":"2021-12-11T03:56:55.466093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# toxic_data[toxic_data[\"y\"] >=0.8]\n# temp_len_df = toxic_data[\"text\"].str.len()\n# temp_len_df[temp_len_df > 200]","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:15:34.703312Z","iopub.execute_input":"2021-12-10T08:15:34.703752Z","iopub.status.idle":"2021-12-10T08:15:34.708014Z","shell.execute_reply.started":"2021-12-10T08:15:34.703711Z","shell.execute_reply":"2021-12-10T08:15:34.707103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(\"seed_everything\")\n\nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:45:50.450155Z","iopub.execute_input":"2021-12-11T03:45:50.45082Z","iopub.status.idle":"2021-12-11T03:45:50.457074Z","shell.execute_reply.started":"2021-12-11T03:45:50.450783Z","shell.execute_reply":"2021-12-11T03:45:50.456157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Model ","metadata":{}},{"cell_type":"markdown","source":"### 1. model: bert + fc","metadata":{}},{"cell_type":"code","source":"from transformers import AlbertTokenizer, AlbertModel\n\nclass config:\n    bert_path = \"../input/torch-bert-weights/bert-base-uncased/bert-base-uncased\"\n#     bert_path = \"../input/pretrained-albert-pytorch/albert-base-v2\"\n    seed = 2021\n    max_len = 512\n    batch_size = 256\n    test_size = 0.2\n    \n    \nbert = BertModel.from_pretrained(config.bert_path)\ntokenizer = BertTokenizer.from_pretrained('../input/torch-bert-weights/bert-base-uncased-vocab.txt')\n\n# bert = AlbertModel.from_pretrained(config.bert_path, return_dict=False)\n# vocab_file = '../input/pretrained-albert-pytorch/albert-base-v2/spiece.model'\n# tokenizer = AlbertTokenizer(vocab_file)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T03:41:20.104737Z","iopub.execute_input":"2021-12-11T03:41:20.104986Z","iopub.status.idle":"2021-12-11T03:41:32.883892Z","shell.execute_reply.started":"2021-12-11T03:41:20.104957Z","shell.execute_reply":"2021-12-11T03:41:32.88309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class JigsawDataset(Dataset):\n#     def __init__(self, samples, max_seq_length, tokenizer):\n#         self.samples = samples\n#         self.max_seq_length = max_seq_length - 2\n#         self.tokenizer = tokenizer\n#         self.length = len(self.samples)\n\n#     def convert2ids(self, sample):\n#         sample_text = sample[\"text\"]\n#         tokens = self.tokenizer.tokenize(sample_text)\n#         if len(tokens) > self.max_seq_length:\n#             tokens = tokens[: self.max_seq_length]\n\n#         padding_num = self.max_seq_length - len(tokens)\n#         tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n\n#         one_token = self.tokenizer.convert_tokens_to_ids(tokens) + [0] * padding_num\n#         one_mask = [1] * len(tokens) + [0] * padding_num\n#         return torch.tensor(one_token, dtype=torch.int32), torch.tensor(one_mask, dtype=torch.int32)\n\n    \n#     def __getitem__(self, index):\n#         sample = self.samples.iloc[index]\n#         one_token, one_mask = self.convert2ids(sample)\n#         logit = self.samples.iloc[index][\"y\"]\n#         return one_token, one_mask, torch.tensor(logit, dtype=torch.float32)\n\n    \n#     def __len__(self):\n#         return self.length","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:21:12.47334Z","iopub.execute_input":"2021-12-10T08:21:12.473586Z","iopub.status.idle":"2021-12-10T08:21:12.483489Z","shell.execute_reply.started":"2021-12-10T08:21:12.473551Z","shell.execute_reply":"2021-12-10T08:21:12.482822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_dataset = JigsawDataset(samples=toxic_data, max_seq_length=config.max_len, tokenizer=tokenizer)\n# train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:21:12.484764Z","iopub.execute_input":"2021-12-10T08:21:12.48523Z","iopub.status.idle":"2021-12-10T08:21:12.492899Z","shell.execute_reply.started":"2021-12-10T08:21:12.485193Z","shell.execute_reply":"2021-12-10T08:21:12.492093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in test_dataloader:\n#     print(len(i))\n#     print(i[0].dtype, i[1].dtype, i[2].dtype)\n#     print(i[0].shape, i[1].shape, i[2].shape)\n#     break","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:15:41.681729Z","iopub.execute_input":"2021-12-10T08:15:41.682569Z","iopub.status.idle":"2021-12-10T08:15:41.688535Z","shell.execute_reply.started":"2021-12-10T08:15:41.682433Z","shell.execute_reply":"2021-12-10T08:15:41.687838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class ToxicModel(nn.Module):\n    \n#     def __init__(self, bert_encoder, n_hidden, device):\n#         super().__init__()\n#         # 加载并冻结bert模型参数\n#         self.bert = bert_encoder.to(device)\n#         for param in self.bert.parameters():\n#             param.requires_grad = False\n            \n#         self.output = nn.Sequential(\n#             nn.Dropout(0.2),\n#             nn.Linear(768, n_hidden),\n#             nn.ReLU(),\n#             nn.Linear(n_hidden, 1),\n#             nn.Sigmoid()\n#         ).to(device)\n\n#     def forward(self, seqs, attention_mask):\n#         _, pooled = self.bert(seqs, attention_mask=attention_mask, output_all_encoded_layers=False) #output_all_encoded_layers=False\n#         logits = self.output(pooled)\n#         return logits","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:21:54.355415Z","iopub.execute_input":"2021-12-10T08:21:54.356082Z","iopub.status.idle":"2021-12-10T08:21:54.362729Z","shell.execute_reply.started":"2021-12-10T08:21:54.356042Z","shell.execute_reply":"2021-12-10T08:21:54.361945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Trainner:\n#     def __init__(self, num_epochs, lr, device):\n#         self.device = device\n#         self.net = ToxicModel(bert, 768, device)\n#         self.num_epochs = num_epochs\n#         self.opt = optim.AdamW(self.net.parameters(), lr=lr)\n#         self.mseloss = nn.MSELoss(reduction=\"sum\").to(device)\n#         print(\"ToxicModel is on the\", next(self.net.parameters()).device)\n    \n#     def train(self, train_loader):\n#         self.net.train()\n#         total_acc, total_count = 0, 0\n#         log_interval = 500\n    \n#         for epoch in range(self.num_epochs):\n#             running_loss = 0.0\n#             total_count = 0\n#             start_time = time.time()\n#             for idx, data in enumerate(tqdm(train_loader)):\n#                 texts, masks, logits = [item.to(self.device) for item in data]\n\n#                 # zero the parameter gradients\n#                 self.opt.zero_grad()\n\n#                 # forward + backward + optimize\n#                 outputs = self.net(texts, masks)\n#                 loss = self.mseloss(outputs.squeeze(-1), logits)\n#                 loss.backward()\n#                 self.opt.step()\n\n#                 # print statistics\n#                 running_loss += loss.item()\n                \n#                 if idx % log_interval == 0 and idx > 0:\n#                     total_count += log_interval\n#                     elapsed = time.time() - start_time\n#                     print('| epoch {:3d} | {:5d}/{:5d} batches '\n#                           '| loss {:8.3f}'.format(epoch, idx, len(train_loader), running_loss / total_count))\n#                     start_time = time.time()\n\n#             print('| epoch {:3d} | {:5d} batches '\n#                   '| loss {:8.3f}'.format(epoch, len(train_loader), running_loss / len(train_loader)))\n#             print('Finished Training')\n            \n            \n#     def save_model(self, path):\n#         torch.save(self.net, path)\n    \n#     def load_model(self, path):\n#         self.net = torch.load(path)\n        \n#     def evaluate(self, test_loader):\n#         self.net.eval()\n#         test_loss = 0.\n#         with torch.no_grad():\n#             for idx, data in enumerate(tqdm(test_loader)):\n#                 texts, masks, logits = [item.to(self.device) for item in data]\n#                 pred = self.net(texts, masks)\n#                 loss = self.mseloss(pred, logits)\n#                 test_loss += loss.item()\n#         print(test_loss)\n    \n#     def infer(self, test_loader):\n#         self.net.eval()\n#         result = []\n#         with torch.no_grad():\n#             for idx, data in enumerate(tqdm(test_loader)):\n#                 texts, masks = [item.to(self.device) for item in data]\n#                 pred = self.net(texts, masks)\n#                 result.append(pred)\n#         return torch.cat(result, dim=0)\n    \n#     def evaluate_by_contrast(self, less_toxic_loader, more_toxic_loader):\n#         less_toxic_pred = trainer.infer(less_toxic_loader).cpu().numpy()\n#         more_toxic_pred = trainer.infer(more_toxic_loader).cpu().numpy()\n#         valid_result = np.array(less_toxic_pred < more_toxic_pred, dtype=np.int32)\n#         acc = valid_result.sum() / len(valid_result)\n#         return acc\n\n\n# trainer = Trainner(1, 1e-5, device)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:21:54.438549Z","iopub.execute_input":"2021-12-10T08:21:54.440041Z","iopub.status.idle":"2021-12-10T08:21:54.588843Z","shell.execute_reply.started":"2021-12-10T08:21:54.439997Z","shell.execute_reply":"2021-12-10T08:21:54.588107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mini_data = toxic_data.iloc[0: 2000]\n# mini_dataset = JigsawDataset(samples=mini_data, max_seq_length=config.max_len, tokenizer=tokenizer)\n# mini_dataloader = DataLoader(mini_dataset, batch_size=config.batch_size, shuffle=False)\n# trainer.train(train_dataloader)\n# trainer.train(mini_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:21:54.590426Z","iopub.execute_input":"2021-12-10T08:21:54.590841Z","iopub.status.idle":"2021-12-10T08:22:38.730644Z","shell.execute_reply.started":"2021-12-10T08:21:54.590803Z","shell.execute_reply":"2021-12-10T08:22:38.729938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class EvaluateDataset(Dataset):\n#     def __init__(self, samples, max_seq_length, tokenizer):\n#         self.samples = samples\n#         self.max_seq_length = max_seq_length - 2\n#         self.tokenizer = tokenizer\n#         self.length = len(self.samples)\n\n#     def convert2ids(self, sample_text):\n#         tokens = self.tokenizer.tokenize(sample_text)\n#         if len(tokens) > self.max_seq_length:\n#             tokens = tokens[: self.max_seq_length]\n\n#         padding_num = self.max_seq_length - len(tokens)\n#         tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n\n#         one_token = self.tokenizer.convert_tokens_to_ids(tokens) + [0] * padding_num\n#         one_mask = [1] * len(tokens) + [0] * padding_num\n#         return torch.tensor(one_token, dtype=torch.int32), torch.tensor(one_mask, dtype=torch.int32)\n\n    \n#     def __getitem__(self, index):\n#         sample = self.samples.iloc[index]\n#         return self.convert2ids(sample)\n\n    \n#     def __len__(self):\n#         return self.length","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:23:09.291501Z","iopub.execute_input":"2021-12-10T08:23:09.291752Z","iopub.status.idle":"2021-12-10T08:23:09.300105Z","shell.execute_reply.started":"2021-12-10T08:23:09.291723Z","shell.execute_reply":"2021-12-10T08:23:09.299117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp_dataset = EvaluateDataset(validation_data[\"less_toxic\"], max_seq_length=config.max_len, tokenizer=tokenizer)\n# less_toxic_loader = DataLoader(temp_dataset, batch_size=config.batch_size, shuffle=False)\n\n# temp_dataset = EvaluateDataset(validation_data[\"more_toxic\"], max_seq_length=config.max_len, tokenizer=tokenizer)\n# more_toxic_loader = DataLoader(temp_dataset, batch_size=config.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:23:29.613985Z","iopub.execute_input":"2021-12-10T08:23:29.614591Z","iopub.status.idle":"2021-12-10T08:23:29.620272Z","shell.execute_reply.started":"2021-12-10T08:23:29.614531Z","shell.execute_reply":"2021-12-10T08:23:29.619435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.evaluate_by_contrast(less_toxic_loader, more_toxic_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp_dataset = EvaluateDataset(comments_to_score[\"text\"], max_seq_length=config.max_len, tokenizer=tokenizer)\n# res_loader = DataLoader(temp_dataset, batch_size=config.batch_size, shuffle=False)\n# pred_res = trainer.infer(res_loader).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:15:46.443449Z","iopub.status.idle":"2021-12-10T08:15:46.44414Z","shell.execute_reply.started":"2021-12-10T08:15:46.443863Z","shell.execute_reply":"2021-12-10T08:15:46.443905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# comment_id = comments_to_score[\"comment_id\"].to_numpy().reshape(-1, 1)\n# result = np.hstack((comment_id, pred_res))\n# result = pd.DataFrame(result, columns=[\"comment_id\", \"score\"])\n# result.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:15:46.445475Z","iopub.status.idle":"2021-12-10T08:15:46.446157Z","shell.execute_reply.started":"2021-12-10T08:15:46.445905Z","shell.execute_reply":"2021-12-10T08:15:46.445931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Model: Bert + Ridge","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}