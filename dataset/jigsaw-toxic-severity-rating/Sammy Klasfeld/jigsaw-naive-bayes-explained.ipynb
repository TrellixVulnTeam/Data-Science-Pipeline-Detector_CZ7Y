{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Background\nThe following code was inspired by the following\n* notebook by JULIÁN PELLER: https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768\n* notebook by ANDREJ MARINCHENKO: https://www.kaggle.com/andrej0marinchenko/jigsaw-ensemble-0-86\n* notebook by MANAV: https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-infer\n\nSo far this notebook is split into three submissions:\n1. Using the current competition training datasets as validation data for running a Naive Bayes model\n2. Using the current competition training datasets as a seperate training data to generate two Naive Bayes models\n3. Using the current competition training datasets as additional training data to generate a single Naive Bayes models","metadata":{}},{"cell_type":"markdown","source":"# Imports\nImport the following libraries and data from \n* Jigsaw Toxic Comment Classification challenge - predicts whether a comment was 'toxic' 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate' (1,0)\n* Ruddit Jigsaw dataset - scores between -1 (maximally supportive) and 1 (maximally offensive)\n* Jigsaw Unintended Bias in Toxicity Classification - predicts whether a comment was 'toxic' 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate' (1,0)\n* Jigsaw Toxic Severity rating - predicts how toxic a comment is compared to other comments","metadata":{"execution":{"iopub.status.busy":"2021-12-29T17:14:50.291953Z","iopub.execute_input":"2021-12-29T17:14:50.292427Z","iopub.status.idle":"2021-12-29T17:14:50.299742Z","shell.execute_reply.started":"2021-12-29T17:14:50.292372Z","shell.execute_reply":"2021-12-29T17:14:50.298941Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer # converts sentences into vectors\nfrom sklearn.naive_bayes import MultinomialNB # Naive Bayes model for discrete scores\nimport re # regular expression libary\nfrom bs4 import BeautifulSoup # used to interpret websites\nfrom tqdm.auto import tqdm # progress bar\nfrom scipy.sparse import vstack # concat sparse matricies\n\n \n# imbalanced dataset methods\nfrom imblearn.under_sampling import RandomUnderSampler # used to randomly under-sample imbalanced dataset\nfrom imblearn.over_sampling import SMOTE # used to over-sample imbalanced dataset with SMOTE\nfrom imblearn.over_sampling import ADASYN # used to over-sample imbalanced dataset with ADASYN\n# ignore SettingWithCopyWarning\nimport warnings\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T18:41:55.765335Z","iopub.execute_input":"2022-01-10T18:41:55.765668Z","iopub.status.idle":"2022-01-10T18:41:55.798445Z","shell.execute_reply.started":"2022-01-10T18:41:55.765634Z","shell.execute_reply":"2022-01-10T18:41:55.797465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set seed for randomness\nrseed=201","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:32.362796Z","iopub.execute_input":"2022-01-10T18:05:32.363085Z","iopub.status.idle":"2022-01-10T18:05:32.368106Z","shell.execute_reply.started":"2022-01-10T18:05:32.363052Z","shell.execute_reply":"2022-01-10T18:05:32.367202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:32.370149Z","iopub.execute_input":"2022-01-10T18:05:32.370493Z","iopub.status.idle":"2022-01-10T18:05:32.380827Z","shell.execute_reply.started":"2022-01-10T18:05:32.370426Z","shell.execute_reply":"2022-01-10T18:05:32.380063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create training data from other jigsaw competitions\nTo train the data we need comments (X) as features and then a \"ground truth\" of the comment's toxicity (y). We use the Jigsaw Toxic Comment Classification challenge training data which labels each comment as either 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', or 'identity_hate' using 1's and 0's. Since in this competition these categories are all considered to be toxic, we transform this training data to list whether each comment is toxic or not.","metadata":{}},{"cell_type":"markdown","source":"## Import Jigsaw Toxic Comment Classification challenge data","metadata":{}},{"cell_type":"code","source":"pre_train_df1 = pd.read_csv(\n    \"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\")\npre_train_df1['y'] = (\n    pre_train_df1[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n    .sum(axis=1) > 0 ).astype(int)\npre_train_df1 = pre_train_df1[['comment_text', 'y']].rename(\n    columns={'comment_text': 'text'})\npre_train_df1.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:32.38238Z","iopub.execute_input":"2022-01-10T18:05:32.382665Z","iopub.status.idle":"2022-01-10T18:05:34.749276Z","shell.execute_reply.started":"2022-01-10T18:05:32.382632Z","shell.execute_reply":"2022-01-10T18:05:34.748223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Ruddit Jigsaw dataset","metadata":{}},{"cell_type":"code","source":"pre_train_df2 = pd.read_csv(\n    \"/kaggle/input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n\n# rename the columns containing the text data and score\npre_train_df2 = pre_train_df2[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n                                                          'offensiveness_score':'score'})\n\n\n# label all comments with an offensiveness score greater than 0 as 1's, otherwise 0's\npre_train_df2['y'] = (pre_train_df2['score'] > 0 ).astype(int)\n\n# uncomment below to transform the offensiveness score to range 0-1\n#pre_train_df2['score'] = ((pre_train_df2['score'] - pre_train_df2.score.min())\n#                      / (pre_train_df2.score.max() - pre_train_df2.score.min()))\n\npre_train_df2.drop(['score'], axis=1, inplace=True)\npre_train_df2.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:34.752511Z","iopub.execute_input":"2022-01-10T18:05:34.7528Z","iopub.status.idle":"2022-01-10T18:05:34.827891Z","shell.execute_reply.started":"2022-01-10T18:05:34.752767Z","shell.execute_reply":"2022-01-10T18:05:34.827293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Jigsaw Unintended Bias challenge data","metadata":{}},{"cell_type":"code","source":"if 1==0:\n    pre_train_df3 = pd.read_csv(\n        \"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\n    print(len(pre_train_df3))\n    pre_train_df3['y'] = (\n        pre_train_df3[['toxic', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']]\n        .sum(axis=1) > 0 ).astype(int)\n    pre_train_df3 = pre_train_df3[['comment_text', 'y']].rename(\n        columns={'comment_text': 'text'})\n    pre_train_df3.sample(3)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:34.828928Z","iopub.execute_input":"2022-01-10T18:05:34.829322Z","iopub.status.idle":"2022-01-10T18:05:34.835832Z","shell.execute_reply.started":"2022-01-10T18:05:34.829293Z","shell.execute_reply":"2022-01-10T18:05:34.834799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comments to vectors","metadata":{}},{"cell_type":"markdown","source":"below we generate a clean function from MANAV","metadata":{}},{"cell_type":"code","source":"def text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:34.837214Z","iopub.execute_input":"2022-01-10T18:05:34.837548Z","iopub.status.idle":"2022-01-10T18:05:34.85182Z","shell.execute_reply.started":"2022-01-10T18:05:34.837485Z","shell.execute_reply":"2022-01-10T18:05:34.850751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"below we generate a clean function from ANDREJ MARINCHENKO","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n\ndef clean(data, col):\n    \n    data[col] = data[col].str.replace('https?://\\S+|www\\.\\S+', ' social medium ', regex=True)      \n        \n    data[col] = data[col].str.lower()\n    data[col] = data[col].str.replace(\"4\", \"a\") \n    data[col] = data[col].str.replace(\"2\", \"l\")\n    data[col] = data[col].str.replace(\"5\", \"s\") \n    data[col] = data[col].str.replace(\"1\", \"i\") \n    data[col] = data[col].str.replace(\"!\", \"i\") \n    data[col] = data[col].str.replace(\"|\", \"i\", regex=False) \n    data[col] = data[col].str.replace(\"0\", \"o\") \n    data[col] = data[col].str.replace(\"l3\", \"b\") \n    data[col] = data[col].str.replace(\"7\", \"t\") \n    data[col] = data[col].str.replace(\"7\", \"+\") \n    data[col] = data[col].str.replace(\"8\", \"ate\") \n    data[col] = data[col].str.replace(\"3\", \"e\") \n    data[col] = data[col].str.replace(\"9\", \"g\")\n    data[col] = data[col].str.replace(\"6\", \"g\")\n    data[col] = data[col].str.replace(\"@\", \"a\")\n    data[col] = data[col].str.replace(\"$\", \"s\", regex=False)\n    data[col] = data[col].str.replace(\"#ofc\", \" of fuckin course \")\n    data[col] = data[col].str.replace(\"fggt\", \" faggot \")\n    data[col] = data[col].str.replace(\"your\", \" your \")\n    data[col] = data[col].str.replace(\"self\", \" self \")\n    data[col] = data[col].str.replace(\"cuntbag\", \" cunt bag \")\n    data[col] = data[col].str.replace(\"fartchina\", \" fart china \")    \n    data[col] = data[col].str.replace(\"youi\", \" you i \")\n    data[col] = data[col].str.replace(\"cunti\", \" cunt i \")\n    data[col] = data[col].str.replace(\"sucki\", \" suck i \")\n    data[col] = data[col].str.replace(\"pagedelete\", \" page delete \")\n    data[col] = data[col].str.replace(\"cuntsi\", \" cuntsi \")\n    data[col] = data[col].str.replace(\"i'm\", \" i am \")\n    data[col] = data[col].str.replace(\"offuck\", \" of fuck \")\n    data[col] = data[col].str.replace(\"centraliststupid\", \" central ist stupid \")\n    data[col] = data[col].str.replace(\"hitleri\", \" hitler i \")\n    data[col] = data[col].str.replace(\"i've\", \" i have \")\n    data[col] = data[col].str.replace(\"i'll\", \" sick \")\n    data[col] = data[col].str.replace(\"fuck\", \" fuck \")\n    data[col] = data[col].str.replace(\"f u c k\", \" fuck \")\n    data[col] = data[col].str.replace(\"shit\", \" shit \")\n    data[col] = data[col].str.replace(\"bunksteve\", \" bunk steve \")\n    data[col] = data[col].str.replace('wikipedia', ' social medium ')\n    data[col] = data[col].str.replace(\"faggot\", \" faggot \")\n    data[col] = data[col].str.replace(\"delanoy\", \" delanoy \")\n    data[col] = data[col].str.replace(\"jewish\", \" jewish \")\n    data[col] = data[col].str.replace(\"sexsex\", \" sex \")\n    data[col] = data[col].str.replace(\"allii\", \" all ii \")\n    data[col] = data[col].str.replace(\"i'd\", \" i had \")\n    data[col] = data[col].str.replace(\"'s\", \" is \")\n    data[col] = data[col].str.replace(\"youbollocks\", \" you bollocks \")\n    data[col] = data[col].str.replace(\"dick\", \" dick \")\n    data[col] = data[col].str.replace(\"cuntsi\", \" cuntsi \")\n    data[col] = data[col].str.replace(\"mothjer\", \" mother \")\n    data[col] = data[col].str.replace(\"cuntfranks\", \" cunt \")\n    data[col] = data[col].str.replace(\"ullmann\", \" jewish \")\n    data[col] = data[col].str.replace(\"mr.\", \" mister \", regex=False)\n    data[col] = data[col].str.replace(\"aidsaids\", \" aids \")\n    data[col] = data[col].str.replace(\"njgw\", \" nigger \")\n    data[col] = data[col].str.replace(\"wiki\", \" social medium \")\n    data[col] = data[col].str.replace(\"administrator\", \" admin \")\n    data[col] = data[col].str.replace(\"gamaliel\", \" jewish \")\n    data[col] = data[col].str.replace(\"rvv\", \" vanadalism \")\n    data[col] = data[col].str.replace(\"admins\", \" admin \")\n    data[col] = data[col].str.replace(\"pensnsnniensnsn\", \" penis \")\n    data[col] = data[col].str.replace(\"pneis\", \" penis \")\n    data[col] = data[col].str.replace(\"pennnis\", \" penis \")\n    data[col] = data[col].str.replace(\"pov.\", \" point of view \", regex=False)\n    data[col] = data[col].str.replace(\"vandalising\", \" vandalism \")\n    data[col] = data[col].str.replace(\"cock\", \" dick \")\n    data[col] = data[col].str.replace(\"asshole\", \" asshole \")\n    data[col] = data[col].str.replace(\"youi\", \" you \")\n    data[col] = data[col].str.replace(\"afd\", \" all fucking day \")\n    data[col] = data[col].str.replace(\"sockpuppets\", \" sockpuppetry \")\n    data[col] = data[col].str.replace(\"iiprick\", \" iprick \")\n    data[col] = data[col].str.replace(\"penisi\", \" penis \")\n    data[col] = data[col].str.replace(\"warrior\", \" warrior \")\n    data[col] = data[col].str.replace(\"loil\", \" laughing out insanely loud \")\n    data[col] = data[col].str.replace(\"vandalise\", \" vanadalism \")\n    data[col] = data[col].str.replace(\"helli\", \" helli \")\n    data[col] = data[col].str.replace(\"lunchablesi\", \" lunchablesi \")\n    data[col] = data[col].str.replace(\"special\", \" special \")\n    data[col] = data[col].str.replace(\"ilol\", \" i lol \")\n    data[col] = data[col].str.replace(r'\\b[uU]\\b', 'you', regex=True)\n    data[col] = data[col].str.replace(r\"what's\", \"what is \")\n    data[col] = data[col].str.replace(r\"\\'s\", \" is \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=False)\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n    data[col] = data[col].str.replace(r\"n't\", \" not \")\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=False)\n    data[col] = data[col].str.replace('\\s+', ' ', regex=True)  # will remove more than one whitespace character\n#     text = re.sub(r'\\b([^\\W\\d_]+)(\\s+\\1)+\\b', r'\\1', re.sub(r'\\W+', ' ', text).strip(), flags=re.I)  # remove repeating words coming immediately one after another\n    data[col] = data[col].str.replace(r'(.)\\1+', r'\\1\\1', regex=True) # 2 or more characters are replaced by 2 characters\n#     text = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', text, flags = re.I)\n    data[col] = data[col].str.replace(\"[:|♣|'|§|♠|*|/|?|=|%|&|-|#|•|~|^|>|<|►|_]\", '', regex=True)\n    \n    \n    data[col] = data[col].str.replace(r\"what's\", \"what is \")    \n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=False)\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n    data[col] = data[col].str.replace(r\"n't\", \" not \", regex=False)\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=False)\n    data[col] = data[col].str.replace(r\"\\'s\", \" \", regex=False)\n\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3', regex=True)\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1', regex=True)    \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ', regex=True)    \n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1', regex=True)\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n    tqdm.pandas()\n    data[col] = data[col].progress_apply(text_cleaning)\n    return data","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-10T18:05:34.853526Z","iopub.execute_input":"2022-01-10T18:05:34.853784Z","iopub.status.idle":"2022-01-10T18:05:35.586011Z","shell.execute_reply.started":"2022-01-10T18:05:34.853756Z","shell.execute_reply":"2022-01-10T18:05:35.585034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the code below simply tests the cleaning functions above","metadata":{}},{"cell_type":"code","source":"# Test clean function\ntest_clean_df = pd.DataFrame({\"text\":\n                              [\"heyy\\n\\nkkdsfj\",\n                               \"hi   how/are/U ???\",\n                               \"hey?????\",\n                               \"noooo!!!!!!!!!   comeone !! \",\n                              \"cooooooooool     brooooooooooo  coool brooo\",\n                              \"naaaahhhhhhh\",\"'re been cool\"]})\ndisplay(test_clean_df)\nclean(test_clean_df,'text')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:35.587422Z","iopub.execute_input":"2022-01-10T18:05:35.587665Z","iopub.status.idle":"2022-01-10T18:05:35.707178Z","shell.execute_reply.started":"2022-01-10T18:05:35.587634Z","shell.execute_reply":"2022-01-10T18:05:35.706325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now we can clean up the comments in the training data","metadata":{}},{"cell_type":"code","source":"# create TF-IDF object\npre_train_df1 = clean(pre_train_df1,'text')\npre_train_df2 = clean(pre_train_df2,'text')\n\n# fit the TF-IDF object to the CLEAN training comments\npre_train_df = pd.concat([pre_train_df1,pre_train_df2])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:05:35.70864Z","iopub.execute_input":"2022-01-10T18:05:35.708861Z","iopub.status.idle":"2022-01-10T18:08:33.350566Z","shell.execute_reply.started":"2022-01-10T18:05:35.708833Z","shell.execute_reply":"2022-01-10T18:08:33.34956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can embed the comments in each training dataset. Note that we must first fit the embedding on all the comments from both datasets. When building the vocabulary I chose to ignore terms that have a document frequency in less than .001% of the documents.","metadata":{}},{"cell_type":"code","source":"# generate a model for the words\nvec = TfidfVectorizer(min_df=1e-5)\nvec.fit(pre_train_df['text'])\n\n# print the vocabulary size\nprint(len(vec.vocabulary_))\n\n# transform the text into sparse matrix format\nX_1 = vec.transform(pre_train_df1['text'])\nX_2 = vec.transform(pre_train_df2['text'])\nX_2","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-10T18:18:40.522699Z","iopub.execute_input":"2022-01-10T18:18:40.523806Z","iopub.status.idle":"2022-01-10T18:18:58.961587Z","shell.execute_reply.started":"2022-01-10T18:18:40.523755Z","shell.execute_reply":"2022-01-10T18:18:58.96065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imbalanced dataset\nBelow we run code to see if the comments have a relatively equal amount of toxic and non-toxic comments.","metadata":{}},{"cell_type":"code","source":"print (\"The first training dataset has %i rows.\" % len(pre_train_df1))\nprint (\"The first training dataset has %i toxic comments.\" % (pre_train_df1['y'] == 1).sum())\nprint (\"The first training dataset has %i non-toxic comments.\" % (pre_train_df1['y'] == 0).sum())\n\nprint (\"The second training dataset has %i rows.\" % len(pre_train_df2))\nprint (\"The second training dataset has %i toxic comments.\" % (pre_train_df2['y'] == 1).sum())\nprint (\"The second training dataset has %i non-toxic comments.\" % (pre_train_df2['y'] == 0).sum())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:18:58.963311Z","iopub.execute_input":"2022-01-10T18:18:58.964101Z","iopub.status.idle":"2022-01-10T18:18:58.976145Z","shell.execute_reply.started":"2022-01-10T18:18:58.96406Z","shell.execute_reply":"2022-01-10T18:18:58.975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first dataset is very unbalanced and the second is a little imbalanced. Below is code to undersample the majority class. Undersampling decreases the chance of false positives. However, we loss a lot of training data this way.","metadata":{}},{"cell_type":"code","source":"if 1==0:\n    rus = RandomUnderSampler(random_state=rseed)\n    rus_pre_train_x1, rus_pretrain_y1 = (\n        rus.fit_resample(X_1, pre_train_df1[\"y\"]))\n    rus_pre_train_x2, rus_pretrain_y2 = (\n        rus.fit_resample(X_2, pre_train_df2[\"y\"]))\n    \n    X_train = vstack([rus_pre_train_x1,rus_pre_train_x2])\n    y_train = pd.concat([rus_pretrain_y1, rus_pretrain_y2])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:18:58.97807Z","iopub.execute_input":"2022-01-10T18:18:58.978902Z","iopub.status.idle":"2022-01-10T18:18:58.984599Z","shell.execute_reply.started":"2022-01-10T18:18:58.978863Z","shell.execute_reply":"2022-01-10T18:18:58.983977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To prevent tossing training data, I want to try over-sampling using SMOTE. ","metadata":{}},{"cell_type":"code","source":"if 1==1:\n    sm = SMOTE(random_state=rseed)\n    sm_pre_train_x1, sm_pretrain_y1 = (\n        sm.fit_resample(X_1, pre_train_df1[\"y\"]))\n    sm_pre_train_x2, sm_pretrain_y2 = (\n        sm.fit_resample(X_2, pre_train_df2[\"y\"]))\n    \n    X_train = vstack([sm_pre_train_x1,sm_pre_train_x2])\n    y_train = pd.concat([sm_pretrain_y1, sm_pretrain_y2])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:18:58.986664Z","iopub.execute_input":"2022-01-10T18:18:58.987153Z","iopub.status.idle":"2022-01-10T18:19:09.054351Z","shell.execute_reply.started":"2022-01-10T18:18:58.987094Z","shell.execute_reply":"2022-01-10T18:19:09.053531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"The first training dataset has %i rows.\" % len(y_train))\nprint (\"The first training dataset has %i toxic comments.\" % (y_train == 1).sum())\nprint (\"The first training dataset has %i non-toxic comments.\" % (y_train == 0).sum())","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:19:09.055991Z","iopub.execute_input":"2022-01-10T18:19:09.056537Z","iopub.status.idle":"2022-01-10T18:19:09.067427Z","shell.execute_reply.started":"2022-01-10T18:19:09.056493Z","shell.execute_reply":"2022-01-10T18:19:09.066596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit Naive Bayes\nWe fit the naive bayes model to the comments from the training data based on whether they are labeled as toxic or not.","metadata":{}},{"cell_type":"code","source":"model = MultinomialNB() \nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:19:09.068884Z","iopub.execute_input":"2022-01-10T18:19:09.069724Z","iopub.status.idle":"2022-01-10T18:19:09.19447Z","shell.execute_reply.started":"2022-01-10T18:19:09.069671Z","shell.execute_reply":"2022-01-10T18:19:09.193209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validate using the data from the current competition\nTo validate the Naive Bayes model we use the training data for this competition.","metadata":{}},{"cell_type":"code","source":"val_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\")\nval_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:19:09.196185Z","iopub.execute_input":"2022-01-10T18:19:09.196496Z","iopub.status.idle":"2022-01-10T18:19:09.452442Z","shell.execute_reply.started":"2022-01-10T18:19:09.196461Z","shell.execute_reply":"2022-01-10T18:19:09.451613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The naive bayes model is run on the the comments labeled as \"less_toxic\" and \"more_toxic\" seperately. If a comment is more toxic it should have a higher value.","metadata":{}},{"cell_type":"code","source":"val_df = clean(val_df,'less_toxic')\nval_df = clean(val_df,'more_toxic')\nX_less_toxic = vec.transform(val_df['less_toxic'])\nX_more_toxic = vec.transform(val_df['more_toxic'])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:19:09.454516Z","iopub.execute_input":"2022-01-10T18:19:09.454759Z","iopub.status.idle":"2022-01-10T18:20:22.628219Z","shell.execute_reply.started":"2022-01-10T18:19:09.45473Z","shell.execute_reply":"2022-01-10T18:20:22.627256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The \"predict_proba\" function generated a 2D array where the first dimension lists the probability the comment is not toxic and the second contains the probability that the comment is toxic.","metadata":{}},{"cell_type":"code","source":"p1 = model.predict_proba(X_less_toxic)\np2 = model.predict_proba(X_more_toxic)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:20:31.767988Z","iopub.execute_input":"2022-01-10T18:20:31.768305Z","iopub.status.idle":"2022-01-10T18:20:31.800431Z","shell.execute_reply.started":"2022-01-10T18:20:31.768271Z","shell.execute_reply":"2022-01-10T18:20:31.799227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To validate the model we measure whether the \"more_toxic\" comments got higher values than the \"less_toxic\" comments","metadata":{}},{"cell_type":"code","source":"# Validation Accuracy\n(p1[:, 1] < p2[:, 1]).mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:20:32.995526Z","iopub.execute_input":"2022-01-10T18:20:32.995864Z","iopub.status.idle":"2022-01-10T18:20:33.003893Z","shell.execute_reply.started":"2022-01-10T18:20:32.99583Z","shell.execute_reply":"2022-01-10T18:20:33.002905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nsub_df = clean(sub_df,'text')\nX_test = vec.transform(sub_df['text'])\np3 = model.predict_proba(X_test)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:10:17.192774Z","iopub.execute_input":"2022-01-10T18:10:17.193Z","iopub.status.idle":"2022-01-10T18:10:26.108364Z","shell.execute_reply.started":"2022-01-10T18:10:17.192973Z","shell.execute_reply":"2022-01-10T18:10:26.107455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"add the predictions to the submission data frame","metadata":{}},{"cell_type":"code","source":"sub_df['score'] = p3[:, 1]","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.11135Z","iopub.execute_input":"2022-01-10T18:10:26.112213Z","iopub.status.idle":"2022-01-10T18:10:26.118343Z","shell.execute_reply.started":"2022-01-10T18:10:26.112163Z","shell.execute_reply":"2022-01-10T18:10:26.11742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uncomment below to generate original submission file\n#sub_df[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.120203Z","iopub.execute_input":"2022-01-10T18:10:26.120933Z","iopub.status.idle":"2022-01-10T18:10:26.130544Z","shell.execute_reply.started":"2022-01-10T18:10:26.120883Z","shell.execute_reply":"2022-01-10T18:10:26.129859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add more training data using current competition\nWe can split the 30108 rows of training data from the current competition for both training and validation. Unlike the comments from the first competition which are binary (1=toxic, 0=not) we can label the comments from the current competition fractions based on whether they were more toxic than the comparing comment more often than not.","metadata":{}},{"cell_type":"markdown","source":"First we generate a table with two columns: 'text' and 'score'. The score will equal *0* if the comment was considered less toxic and *1* if the comment was considered more toxic in the pairwise comparisons.","metadata":{}},{"cell_type":"code","source":"less_toxic_score_df=pd.DataFrame()\nless_toxic_score_df[\"text\"] = val_df[\"less_toxic\"].copy()\nless_toxic_score_df[\"score\"] = 0\nmore_toxic_score_df=pd.DataFrame()\nmore_toxic_score_df[\"text\"] = val_df[\"more_toxic\"].copy()\nmore_toxic_score_df[\"score\"] = 1\ntoxic_score_df = pd.concat([less_toxic_score_df, more_toxic_score_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.131998Z","iopub.execute_input":"2022-01-10T18:10:26.132813Z","iopub.status.idle":"2022-01-10T18:10:26.16711Z","shell.execute_reply.started":"2022-01-10T18:10:26.13277Z","shell.execute_reply":"2022-01-10T18:10:26.166189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Group the scores given to each comment_text, get the average of each distinct comment_text, and then set `y` to \"0\" if the average is less than or equal to 0.5 and set `y` to \"1\" otherwise","metadata":{}},{"cell_type":"code","source":"# sort the comments (not necessary)\ntoxic_score_df = toxic_score_df.sort_values(by = 'text').copy()\n\n# use groupby function to group the comments\nval_score_df = toxic_score_df.groupby('text')['score'].mean().reset_index()\n\n# set `y` to \"0\" if the average is less than or equal to 0.5 and set `y` to \"1\" otherwise\nval_score_df['y'] = (val_score_df['score'] > .5).astype(int)\n\n# drop the `score` column\n#val_score_df.drop(['score'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.168893Z","iopub.execute_input":"2022-01-10T18:10:26.169161Z","iopub.status.idle":"2022-01-10T18:10:26.40854Z","shell.execute_reply.started":"2022-01-10T18:10:26.169107Z","shell.execute_reply":"2022-01-10T18:10:26.407623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"The training data has %i rows.\" % len(val_score_df))\nprint (\"The training data has %i toxic comments.\" % (val_score_df['y'] == 1).sum())\nprint (\"The training data has %i non-toxic comments.\" % (val_score_df['y'] == 0).sum())","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.409835Z","iopub.execute_input":"2022-01-10T18:10:26.41009Z","iopub.status.idle":"2022-01-10T18:10:26.420493Z","shell.execute_reply.started":"2022-01-10T18:10:26.410059Z","shell.execute_reply":"2022-01-10T18:10:26.419407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset does not look seriously imbalanced so we can continue by splitting the full validation set into a smaller training and validation set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# we chose a random test size, this number may be optimized for improved results\ntrain_df2, val_df2 = train_test_split(val_score_df, test_size=0.70, random_state = rseed)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.42202Z","iopub.execute_input":"2022-01-10T18:10:26.422291Z","iopub.status.idle":"2022-01-10T18:10:26.436635Z","shell.execute_reply.started":"2022-01-10T18:10:26.422262Z","shell.execute_reply":"2022-01-10T18:10:26.435712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"The training data has %i rows.\" % len(train_df2))\nprint (\"The training data has %i toxic comments.\" % (train_df2['y'] == 1).sum())\nprint (\"The training data has %i non-toxic comments.\" % (train_df2['y'] == 0).sum())","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:26.438017Z","iopub.execute_input":"2022-01-10T18:10:26.438936Z","iopub.status.idle":"2022-01-10T18:10:26.448464Z","shell.execute_reply.started":"2022-01-10T18:10:26.438895Z","shell.execute_reply":"2022-01-10T18:10:26.447547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comments to vectors","metadata":{}},{"cell_type":"code","source":"vec2 = TfidfVectorizer()\n\n# fit the TF-IDF object to the training comments\ntrain_df2 = clean(train_df2,'text')\nX2 = vec2.fit_transform(train_df2['text'])\nX2","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:10:26.449634Z","iopub.execute_input":"2022-01-10T18:10:26.450052Z","iopub.status.idle":"2022-01-10T18:10:30.640349Z","shell.execute_reply.started":"2022-01-10T18:10:26.450021Z","shell.execute_reply":"2022-01-10T18:10:30.639356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit Naive Bayes\nWe fit the naive bayes model to the comments from this new training data","metadata":{}},{"cell_type":"code","source":"# create TF-IDF object\n\n\nmodel2 = MultinomialNB()\nmodel2.fit(X2, train_df2['y'])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:30.642036Z","iopub.execute_input":"2022-01-10T18:10:30.642393Z","iopub.status.idle":"2022-01-10T18:10:30.655201Z","shell.execute_reply.started":"2022-01-10T18:10:30.642345Z","shell.execute_reply":"2022-01-10T18:10:30.65431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use validation data from current competition to create seperate model\nThen validate our results on the new validation data","metadata":{}},{"cell_type":"code","source":"val_df2 = clean(val_df2,'text')\nX_predict = vec2.transform(val_df2['text'])\npredictions = model2.predict_proba(X_predict)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:10:30.656329Z","iopub.execute_input":"2022-01-10T18:10:30.656591Z","iopub.status.idle":"2022-01-10T18:10:41.593309Z","shell.execute_reply.started":"2022-01-10T18:10:30.656561Z","shell.execute_reply":"2022-01-10T18:10:41.592322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df2.loc[:,'pred_score']=predictions[:, 1]\nval_df2.loc[:,'error'] = 1-abs(val_df2['score']-val_df2['pred_score'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:10:41.594828Z","iopub.execute_input":"2022-01-10T18:10:41.595188Z","iopub.status.idle":"2022-01-10T18:10:41.609081Z","shell.execute_reply.started":"2022-01-10T18:10:41.595141Z","shell.execute_reply":"2022-01-10T18:10:41.608049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df2['error'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:41.610498Z","iopub.execute_input":"2022-01-10T18:10:41.610722Z","iopub.status.idle":"2022-01-10T18:10:41.622843Z","shell.execute_reply.started":"2022-01-10T18:10:41.610695Z","shell.execute_reply":"2022-01-10T18:10:41.622091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission with new model","metadata":{}},{"cell_type":"code","source":"sub_df = sub_df.rename(\n    columns={'score': 'score1'})\nsub_df = clean(sub_df,'text')\nX_test2 = vec2.transform(sub_df['text'])\nsubmission_predictions2 = model2.predict_proba(X_test2)\nsub_df['score2'] = submission_predictions2[:, 1]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:10:41.623817Z","iopub.execute_input":"2022-01-10T18:10:41.624862Z","iopub.status.idle":"2022-01-10T18:10:48.922269Z","shell.execute_reply.started":"2022-01-10T18:10:41.624829Z","shell.execute_reply":"2022-01-10T18:10:48.921221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"get the average of the two models","metadata":{}},{"cell_type":"code","source":"sub_df.loc[:,'score'] = sub_df.loc[:,['score1','score2']].astype(float).mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:10:48.924015Z","iopub.execute_input":"2022-01-10T18:10:48.92438Z","iopub.status.idle":"2022-01-10T18:10:48.937082Z","shell.execute_reply.started":"2022-01-10T18:10:48.924338Z","shell.execute_reply":"2022-01-10T18:10:48.935972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"generate submission file","metadata":{}},{"cell_type":"code","source":"#sub_df[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use validation data from current competition to add to data from the original competition","metadata":{}},{"cell_type":"code","source":"pre_train_df = pd.concat([pre_train_df,train_df2.loc[:,[\"text\",\"y\"]]])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:24:04.689862Z","iopub.execute_input":"2022-01-10T18:24:04.690592Z","iopub.status.idle":"2022-01-10T18:24:04.717618Z","shell.execute_reply.started":"2022-01-10T18:24:04.690544Z","shell.execute_reply":"2022-01-10T18:24:04.71634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate sparse matrix using all the training data comments","metadata":{}},{"cell_type":"code","source":"# generate a model for the words\nvec3 = TfidfVectorizer(min_df=1e-5)\nvec3.fit(pre_train_df['text'])\n\n# print the vocabulary size\nprint(len(vec3.vocabulary_))\n\n# transform the text into sparse matrix format\nX_1 = vec3.transform(pre_train_df1['text'])\nX_2 = vec3.transform(pre_train_df2['text'])\nX_3 = vec3.transform(train_df2['text'])\nX_3","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:27:08.85746Z","iopub.execute_input":"2022-01-10T18:27:08.857743Z","iopub.status.idle":"2022-01-10T18:27:26.517502Z","shell.execute_reply.started":"2022-01-10T18:27:08.857714Z","shell.execute_reply":"2022-01-10T18:27:26.516459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Recall we have imbalanced data so we over-sample","metadata":{}},{"cell_type":"code","source":"print (\"The first training dataset has %i rows.\" % len(pre_train_df1))\nprint (\"The first training dataset has %i toxic comments.\" % (pre_train_df1['y'] == 1).sum())\nprint (\"The first training dataset has %i non-toxic comments.\" % (pre_train_df1['y'] == 0).sum())\n\nprint (\"The second training dataset has %i rows.\" % len(pre_train_df2))\nprint (\"The second training dataset has %i toxic comments.\" % (pre_train_df2['y'] == 1).sum())\nprint (\"The second training dataset has %i non-toxic comments.\" % (pre_train_df2['y'] == 0).sum())\n\nprint (\"The third training dataset has %i rows.\" % len(train_df2))\nprint (\"The third training dataset has %i toxic comments.\" % (train_df2['y'] == 1).sum())\nprint (\"The third training dataset has %i non-toxic comments.\" % (train_df2['y'] == 0).sum())","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:28:47.835866Z","iopub.execute_input":"2022-01-10T18:28:47.836206Z","iopub.status.idle":"2022-01-10T18:28:47.852003Z","shell.execute_reply.started":"2022-01-10T18:28:47.836175Z","shell.execute_reply":"2022-01-10T18:28:47.850767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 1==1:\n    sm = SMOTE(random_state=rseed)\n    sm_pre_train_x1, sm_pretrain_y1 = (\n        sm.fit_resample(X_1, pre_train_df1[\"y\"]))\n    sm_pre_train_x2, sm_pretrain_y2 = (\n        sm.fit_resample(X_2, pre_train_df2[\"y\"]))\n    sm_pre_train_x3, sm_pretrain_y3 = (\n        sm.fit_resample(X_3, train_df2[\"y\"]))\n    \n    X_train = vstack([sm_pre_train_x1, sm_pre_train_x2, sm_pre_train_x3])\n    y_train = pd.concat([sm_pretrain_y1, sm_pretrain_y2, sm_pretrain_y3])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:42:06.813294Z","iopub.execute_input":"2022-01-10T18:42:06.813605Z","iopub.status.idle":"2022-01-10T18:44:04.708463Z","shell.execute_reply.started":"2022-01-10T18:42:06.813574Z","shell.execute_reply":"2022-01-10T18:44:04.706641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit Naive Bayes\nWe fit the naive bayes model to the comments from this new training data","metadata":{}},{"cell_type":"code","source":"X_train = vstack([sm_pre_train_x1, sm_pre_train_x2, sm_pre_train_x3])\ny_train = pd.concat([sm_pretrain_y1, sm_pretrain_y2, sm_pretrain_y3])\n\nmodel3 = MultinomialNB()\nmodel3.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:44:04.709874Z","iopub.status.idle":"2022-01-10T18:44:04.710418Z","shell.execute_reply.started":"2022-01-10T18:44:04.710107Z","shell.execute_reply":"2022-01-10T18:44:04.710161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use validation data from current competition to create seperate model\nThen validate our results on the new validation data","metadata":{}},{"cell_type":"code","source":"val_df2 = clean(val_df2,'text')\nX_predict = vec3.transform(val_df2['text'])\npredictions = model3.predict_proba(X_predict)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:44:04.712364Z","iopub.status.idle":"2022-01-10T18:44:04.712849Z","shell.execute_reply.started":"2022-01-10T18:44:04.712594Z","shell.execute_reply":"2022-01-10T18:44:04.71262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df2.loc[:,'pred_score']=predictions[:, 1]\nval_df2.loc[:,'error'] = 1-abs(val_df2['score']-val_df2['pred_score'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-10T18:44:04.714579Z","iopub.status.idle":"2022-01-10T18:44:04.715047Z","shell.execute_reply.started":"2022-01-10T18:44:04.714792Z","shell.execute_reply":"2022-01-10T18:44:04.714818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df2['error'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:44:04.717721Z","iopub.status.idle":"2022-01-10T18:44:04.718889Z","shell.execute_reply.started":"2022-01-10T18:44:04.718585Z","shell.execute_reply":"2022-01-10T18:44:04.718617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission with new model","metadata":{}},{"cell_type":"code","source":"sub_df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-10T18:36:56.286319Z","iopub.execute_input":"2022-01-10T18:36:56.286927Z","iopub.status.idle":"2022-01-10T18:36:56.345678Z","shell.execute_reply.started":"2022-01-10T18:36:56.28688Z","shell.execute_reply":"2022-01-10T18:36:56.344701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = clean(sub_df,'text')\nX_test3 = vec3.transform(sub_df['text'])\nsubmission_predictions3 = model3.predict_proba(X_test3)\nsub_df['score'] = submission_predictions3[:, 1]","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-10T18:36:56.348101Z","iopub.execute_input":"2022-01-10T18:36:56.348476Z","iopub.status.idle":"2022-01-10T18:37:05.241769Z","shell.execute_reply.started":"2022-01-10T18:36:56.34843Z","shell.execute_reply":"2022-01-10T18:37:05.240718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"generate submission file","metadata":{}},{"cell_type":"code","source":"sub_df[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}