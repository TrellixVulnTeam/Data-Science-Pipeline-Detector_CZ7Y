{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn as sk\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.stats import rankdata\n\njr = pd.read_csv(\"../input/jigsaw-regression-based-data/train_data_version2.csv\")\njr.shape\ndf = jr[['text', 'y']]\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.8, min_df=1, ngram_range=(2, 5) )\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 2)\n\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\ndf_test = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntest=vec.transform(df_test['text'])\njr_preds=model1.predict(test)\ndf_test['score1']=rankdata( jr_preds, method='ordinal') \nrud_df = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n#print(f\"rud_df:{rud_df.shape}\")\nrud_df['y'] = rud_df[\"offensiveness_score\"] \ndf = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.8, min_df=3, ngram_range=(3, 4) )\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 1)\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\ntest=vec.transform(df_test['text'])\nrud_preds=model1.predict(test)\ndf_test['score2']=rankdata( rud_preds, method='ordinal')\ndf_test['score']=df_test['score1']+df_test['score2']\ndf_test['score']=rankdata( df_test['score'], method='ordinal')\ndf_test[['comment_id', 'score']].to_csv(\"submission1.csv\", index=False)","metadata":{"papermill":{"duration":56.508509,"end_time":"2022-01-26T02:51:06.548265","exception":false,"start_time":"2022-01-26T02:50:10.039756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T18:18:30.847698Z","iopub.execute_input":"2022-02-27T18:18:30.847997Z","iopub.status.idle":"2022-02-27T18:19:31.52913Z","shell.execute_reply.started":"2022-02-27T18:18:30.847924Z","shell.execute_reply":"2022-02-27T18:19:31.528049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nimport re\nfrom bs4 import BeautifulSoup\nfrom tqdm.auto import tqdm\n\nTRAIN_DATA_PATH = \"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\"\nVALID_DATA_PATH = \"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\"\nTEST_DATA_PATH = \"/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\n\ndf_train2 = pd.read_csv(TRAIN_DATA_PATH)\ndf_valid2 = pd.read_csv(VALID_DATA_PATH)\ndf_test2 = pd.read_csv(TEST_DATA_PATH)\ncat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    df_train2[category] = df_train2[category] * cat_mtpl[category]\n\ndf_train2['score'] = df_train2.loc[:, 'toxic':'identity_hate'].mean(axis=1)\n\ndf_train2['y'] = df_train2['score']\n\nmin_len = (df_train2['y'] > 0).sum()  # len of toxic comments\ndf_y0_undersample = df_train2[df_train2['y'] == 0].sample(n=min_len, random_state=41)  # take non toxic comments\ndf_train_new = pd.concat([df_train2[df_train2['y'] > 0], df_y0_undersample])  # make new df\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nraw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\nraw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\nfrom datasets import Dataset\n\ndataset = Dataset.from_pandas(df_train_new[['comment_text']])\n\ndef get_training_corpus():\n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"comment_text\"]\n\nraw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n\nfrom transformers import PreTrainedTokenizerFast\n\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge\n\ndef dummy_fun(doc):\n    return doc\n\nlabels = df_train_new['y']\ncomments = df_train_new['comment_text']\ntokenized_comments = tokenizer(comments.to_list())['input_ids']\n\nvectorizer = TfidfVectorizer(\n    analyzer = 'word',\n    tokenizer = dummy_fun,\n    preprocessor = dummy_fun,\n    token_pattern = None)\n\ncomments_tr = vectorizer.fit_transform(tokenized_comments)\n\nregressor = Ridge(random_state=42, alpha=0.8)\nregressor.fit(comments_tr, labels)\n\nless_toxic_comments = df_valid2['less_toxic']\nmore_toxic_comments = df_valid2['more_toxic']\n\nless_toxic_comments = tokenizer(less_toxic_comments.to_list())['input_ids']\nmore_toxic_comments = tokenizer(more_toxic_comments.to_list())['input_ids']\n\nless_toxic = vectorizer.transform(less_toxic_comments)\nmore_toxic = vectorizer.transform(more_toxic_comments)\n\n# make predictions\ny_pred_less = regressor.predict(less_toxic)\ny_pred_more = regressor.predict(more_toxic)\n\nprint(f'val : {(y_pred_less < y_pred_more).mean()}')\ntexts = df_test2['text']\ntexts = tokenizer(texts.to_list())['input_ids']\ntexts = vectorizer.transform(texts)\n\ndf_test2['prediction'] = regressor.predict(texts)\ndf_test2 = df_test2[['comment_id','prediction']]\n\ndf_test2['score'] = df_test2['prediction']\ndf_test2 = df_test2[['comment_id','score']]\n\ndf_test2.to_csv('./submission2.csv', index=False)","metadata":{"papermill":{"duration":28.9965,"end_time":"2022-01-26T02:51:35.600257","exception":false,"start_time":"2022-01-26T02:51:06.603757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T18:19:31.530642Z","iopub.execute_input":"2022-02-27T18:19:31.530837Z","iopub.status.idle":"2022-02-27T18:19:58.375537Z","shell.execute_reply.started":"2022-02-27T18:19:31.530789Z","shell.execute_reply":"2022-02-27T18:19:58.374995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train2.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:21:26.109361Z","iopub.execute_input":"2022-02-27T18:21:26.110323Z","iopub.status.idle":"2022-02-27T18:21:26.170288Z","shell.execute_reply.started":"2022-02-27T18:21:26.110278Z","shell.execute_reply":"2022-02-27T18:21:26.169355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n             'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf_train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T16:51:45.254939Z","iopub.execute_input":"2022-02-22T16:51:45.255492Z","iopub.status.idle":"2022-02-22T16:51:47.591227Z","shell.execute_reply.started":"2022-02-22T16:51:45.255348Z","shell.execute_reply":"2022-02-22T16:51:47.590081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-02-22T16:52:40.502556Z","iopub.execute_input":"2022-02-22T16:52:40.502877Z","iopub.status.idle":"2022-02-22T16:52:40.517472Z","shell.execute_reply.started":"2022-02-22T16:52:40.50283Z","shell.execute_reply":"2022-02-22T16:52:40.516614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nimport re \nimport scipy\nfrom scipy import sparse\n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\ndf_train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n\ncat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    df_train[category] = df_train[category] * cat_mtpl[category]\n\ndf_train['score'] = df_train.loc[:, 'toxic':'identity_hate'].sum(axis=1)\n\ndf_train['y'] = df_train['score']\n\nmin_len = (df_train['y'] > 0).sum()  # len of toxic comments\ndf_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=201)  # take non toxic comments\ndf_train_new = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\ndf_train = df_train.rename(columns={'comment_text':'text'})\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ndf_train['text'] = df_train['text'].progress_apply(text_cleaning)\ndf = df_train.copy()\ndf['y'].value_counts(normalize=True)\nmin_len = (df['y'] >= 0.1).sum()\ndf_y0_undersample = df[df['y'] == 0].sample(n=min_len * 2, random_state=402)\ndf = pd.concat([df[df['y'] >= 0.1], df_y0_undersample])\nvec = TfidfVectorizer(min_df= 3, max_df=0.8, analyzer = 'char_wb', ngram_range = (3,5))\nX = vec.fit_transform(df['text'])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])\nl_model = Ridge(alpha=1.)\nl_model.fit(X, df['y'])\ns_model = Ridge(alpha=2.)\ns_model.fit(X, df['y'])\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntqdm.pandas()\ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\nX_less_toxic = vec.transform(df_val['less_toxic'])\nX_more_toxic = vec.transform(df_val['more_toxic'])\np1 = model.predict(X_less_toxic)\np2 = model.predict(X_more_toxic)\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntqdm.pandas()\ndf_sub['text'] = df_sub['text'].progress_apply(text_cleaning)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) / 3.\ndf_sub['score'] = df_sub['score']\ndf_sub[['comment_id', 'score']].to_csv(\"submission3.csv\", index=False)","metadata":{"execution":{"iopub.execute_input":"2022-01-26T02:51:35.689916Z","iopub.status.busy":"2022-01-26T02:51:35.684613Z","iopub.status.idle":"2022-01-26T02:54:14.698402Z","shell.execute_reply":"2022-01-26T02:54:14.697834Z","shell.execute_reply.started":"2022-01-26T02:42:00.793541Z"},"papermill":{"duration":159.034884,"end_time":"2022-01-26T02:54:14.698567","exception":false,"start_time":"2022-01-26T02:51:35.663683","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"./submission1.csv\",index_col=\"comment_id\")\ndata[\"score1\"] = data[\"score\"]\n\ndata[\"score2\"] = pd.read_csv(\"./submission2.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score2\"] = rankdata( data[\"score2\"], method='ordinal')\n\ndata[\"score3\"] = pd.read_csv(\"./submission3.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score3\"] = rankdata( data[\"score3\"], method='ordinal')\n\ndata[\"score\"] = 2*data[\"score1\"] + .66*data[\"score2\"] + data[\"score3\"]*.33","metadata":{"execution":{"iopub.execute_input":"2022-01-26T02:54:14.782245Z","iopub.status.busy":"2022-01-26T02:54:14.781628Z","iopub.status.idle":"2022-01-26T02:54:14.810459Z","shell.execute_reply":"2022-01-26T02:54:14.809898Z","shell.execute_reply.started":"2022-01-26T02:44:47.970094Z"},"papermill":{"duration":0.049398,"end_time":"2022-01-26T02:54:14.810602","exception":false,"start_time":"2022-01-26T02:54:14.761204","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"score\"] = rankdata( data[\"score\"], method='ordinal')","metadata":{"execution":{"iopub.execute_input":"2022-01-26T02:54:14.843878Z","iopub.status.busy":"2022-01-26T02:54:14.843242Z","iopub.status.idle":"2022-01-26T02:54:14.846538Z","shell.execute_reply":"2022-01-26T02:54:14.846048Z","shell.execute_reply.started":"2022-01-26T02:44:48.007473Z"},"papermill":{"duration":0.021816,"end_time":"2022-01-26T02:54:14.846673","exception":false,"start_time":"2022-01-26T02:54:14.824857","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"for even more overfit :","metadata":{"papermill":{"duration":0.013907,"end_time":"2022-01-26T02:54:14.874702","exception":false,"start_time":"2022-01-26T02:54:14.860795","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Credit : [💥 Scaling for ✨Jigsaw Ensemble 💥](https://www.kaggle.com/chryzal/scaling-for-jigsaw-ensemble) by [Chryzal](https://www.kaggle.com/chryzal)\n\nI updated the weights, because I don't use them on a score but rather on a rank (from 0.892 to 0.896)","metadata":{"papermill":{"duration":0.013769,"end_time":"2022-01-26T02:54:14.902575","exception":false,"start_time":"2022-01-26T02:54:14.888806","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_test = data\n# for i in range(0, 500):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.35\n# for i in range(801, 1200):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.45\n# for i in range(1701, 2300):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.8\n# for i in range(2501, 2980):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.85    \n# for i in range(3001, 4000):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.4    \n# for i in range(4001, 4500):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.45   \n# for i in range(4501, 4940):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.86\n# for i in range(5501, 5980):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.83\n# for i in range(6001, 6500):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.45\n# for i in range(7001, 7536):\n#     df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.42 ","metadata":{"execution":{"iopub.execute_input":"2022-01-26T02:54:14.942463Z","iopub.status.busy":"2022-01-26T02:54:14.941783Z","iopub.status.idle":"2022-01-26T02:54:15.460107Z","shell.execute_reply":"2022-01-26T02:54:15.460578Z","shell.execute_reply.started":"2022-01-26T02:44:48.014742Z"},"papermill":{"duration":0.544114,"end_time":"2022-01-26T02:54:15.460761","exception":false,"start_time":"2022-01-26T02:54:14.916647","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[\"score\"] = rankdata( df_test[\"score\"], method='ordinal')\ndf_test[\"score\"].to_csv('./submission.csv')","metadata":{"execution":{"iopub.execute_input":"2022-01-26T02:54:16.370415Z","iopub.status.busy":"2022-01-26T02:54:16.369794Z","iopub.status.idle":"2022-01-26T02:54:16.395528Z","shell.execute_reply":"2022-01-26T02:54:16.395972Z","shell.execute_reply.started":"2022-01-26T02:44:49.402008Z"},"papermill":{"duration":0.043673,"end_time":"2022-01-26T02:54:16.396153","exception":false,"start_time":"2022-01-26T02:54:16.35248","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014081,"end_time":"2022-01-26T02:54:16.424906","exception":false,"start_time":"2022-01-26T02:54:16.410825","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}