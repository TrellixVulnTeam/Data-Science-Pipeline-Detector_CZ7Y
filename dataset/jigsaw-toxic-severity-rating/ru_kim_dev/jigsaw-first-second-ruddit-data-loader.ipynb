{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-23T04:40:33.174936Z","iopub.execute_input":"2021-11-23T04:40:33.175272Z","iopub.status.idle":"2021-11-23T04:40:33.200186Z","shell.execute_reply.started":"2021-11-23T04:40:33.175189Z","shell.execute_reply":"2021-11-23T04:40:33.19933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = '../input/'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:40:37.629449Z","iopub.execute_input":"2021-11-23T04:40:37.630096Z","iopub.status.idle":"2021-11-23T04:40:37.633732Z","shell.execute_reply.started":"2021-11-23T04:40:37.630064Z","shell.execute_reply":"2021-11-23T04:40:37.632876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Toxic Comment Classification Challenge","metadata":{}},{"cell_type":"code","source":"jf_train_df = pd.read_csv(base_path + 'jigsaw-toxic-comment-classification-challenge/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:40:43.642078Z","iopub.execute_input":"2021-11-23T04:40:43.642781Z","iopub.status.idle":"2021-11-23T04:40:45.678141Z","shell.execute_reply.started":"2021-11-23T04:40:43.642746Z","shell.execute_reply":"2021-11-23T04:40:45.677256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 가중치 부여 가공\ntoxic = 1.0\nsevere_toxic = 2.0\nobscene = 1.0\nthreat = 1.0\ninsult = 1.0\nidentity_hate = 2.0\n\ndef create_train_first(df):\n    df['y'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n    df['y'] = df['y'] + df['severe_toxic']*severe_toxic\n    df['y'] = df['y'] + df['obscene']*obscene\n    df['y'] = df['y'] + df['threat']*threat\n    df['y'] = df['y'] + df['insult']*insult\n    df['y'] = df['y'] + df['identity_hate']*identity_hate\n    \n    # renameing은 원하는대로 변경 가능\n#     df= df[['comment_text', 'y', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].rename(columns={'comment_text': 'text'})\n    \n    #undersample\n    min_len = (df['y'] >= 1).sum()\n    df_y0_undersample = df[df['y'] == 0].sample(n=int(min_len*1.5), random_state=201)\n    df = pd.concat([df[df['y'] >= 1], df_y0_undersample])\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:40:48.814653Z","iopub.execute_input":"2021-11-23T04:40:48.815357Z","iopub.status.idle":"2021-11-23T04:40:48.823131Z","shell.execute_reply.started":"2021-11-23T04:40:48.815319Z","shell.execute_reply":"2021-11-23T04:40:48.821962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jf_train_df = create_train_first(jf_train_df)\nprint(jf_train_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:41:22.663013Z","iopub.execute_input":"2021-11-23T04:41:22.663674Z","iopub.status.idle":"2021-11-23T04:41:22.675304Z","shell.execute_reply.started":"2021-11-23T04:41:22.663637Z","shell.execute_reply":"2021-11-23T04:41:22.67424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Unintended Bias in Toxicity Classification","metadata":{}},{"cell_type":"code","source":"js_train_df = pd.read_csv(base_path + 'jigsaw-unintended-bias-in-toxicity-classification/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:41:40.149578Z","iopub.execute_input":"2021-11-23T04:41:40.150012Z","iopub.status.idle":"2021-11-23T04:42:02.560523Z","shell.execute_reply.started":"2021-11-23T04:41:40.149974Z","shell.execute_reply":"2021-11-23T04:42:02.559762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_train_second(df):\n    # non-toxic data remove by annotator_count\n    df = df.query('toxicity_annotator_count > 5')\n    \n    df['y'] = df[['severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack', 'insult', 'threat']].sum(axis=1)\n    df['y'] = df.apply(lambda row: row['target'] if row['target'] <= 0.5 else row['y'], axis=1)\n    \n    # renameing은 원하는대로 변경 가능\n#     js_train_df = js_train_df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n\n    # undersampling\n    min_len = (df['y'] > 0.5).sum()\n    df_y0_undersample = df[df['y'] <= 0.5].sample(n=int(min_len*1.5), random_state=201)\n    df = pd.concat([df[df['y'] > 0.5], df_y0_undersample])\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:44:12.925687Z","iopub.execute_input":"2021-11-23T04:44:12.92623Z","iopub.status.idle":"2021-11-23T04:44:12.932309Z","shell.execute_reply.started":"2021-11-23T04:44:12.926195Z","shell.execute_reply":"2021-11-23T04:44:12.931424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js_train_df = create_train_second(js_train_df)\nprint(js_train_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:44:15.00815Z","iopub.execute_input":"2021-11-23T04:44:15.008713Z","iopub.status.idle":"2021-11-23T04:44:23.853072Z","shell.execute_reply.started":"2021-11-23T04:44:15.008678Z","shell.execute_reply":"2021-11-23T04:44:23.852091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Ruddit: Norms of Offensiveness for English Reddit Comments","metadata":{}},{"cell_type":"code","source":"rud_df = pd.read_csv(base_path + 'ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:44:31.074945Z","iopub.execute_input":"2021-11-23T04:44:31.075249Z","iopub.status.idle":"2021-11-23T04:44:31.137109Z","shell.execute_reply.started":"2021-11-23T04:44:31.075216Z","shell.execute_reply":"2021-11-23T04:44:31.136214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rud_df['y'] = rud_df['offensiveness_score'].map(lambda x: 0.0 if x <=0 else x)\n# rud_df = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\nprint(rud_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-23T04:44:32.184861Z","iopub.execute_input":"2021-11-23T04:44:32.18512Z","iopub.status.idle":"2021-11-23T04:44:32.194202Z","shell.execute_reply.started":"2021-11-23T04:44:32.185093Z","shell.execute_reply":"2021-11-23T04:44:32.193612Z"},"trusted":true},"execution_count":null,"outputs":[]}]}