{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Note:\nFor the most part, I used the following chamecall notebook as a reference https://www.kaggle.com/chamecall/clrp-pretrain\n\nThe dataset used was jigsaw-toxic-comment-classification-challenge created by dataista0ã€€https://www.kaggle.com/julian3833/jigsaw-toxic-comment-classification-challenge\n\nThank you very much!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom transformers import (AutoModel,AutoModelForMaskedLM, \n                          AutoTokenizer, LineByLineTextDataset,\n                          DataCollatorForLanguageModeling,\n                          Trainer, TrainingArguments)\nimport re","metadata":{"id":"DUGbFI45rL7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest_data = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\n\ntrain_data=train_data.loc[:,[\"id\",\"comment_text\"]]\ndata = pd.concat([train_data,test_data])\ndata[\"excerpt\"]=data[\"comment_text\"]\ndata['excerpt'] = data['comment_text'].apply(lambda x: x.replace('\\n',''))\ndef remove_url(sen):\n    ret = re.sub(r\"(http?|ftp)(:\\/\\/[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+$,%#]+)\", \"\" ,sen)\n    return ret\n\ndata.excerpt=data.excerpt.map(remove_url)\n\ntext  = '\\n'.join(data.excerpt.tolist())\n\nwith open('text.txt','w') as f:\n    f.write(text)","metadata":{"id":"EBOZE5WHrL7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"roberta-base\"\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.save_pretrained('./roberta-base');","metadata":{"id":"kTV_at3TrL7P","outputId":"bd87a49f-a401-41c1-8342-20c902e1e0fe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"text.txt\", #mention train text file here\n    block_size=256)\n\nvalid_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"text.txt\", #mention valid text file here\n    block_size=256)\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./roberta_base_chk\", #select model path for checkpoint\n    overwrite_output_dir=True,\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    evaluation_strategy= 'steps',\n    save_total_limit=2,\n    eval_steps=500,\n    gradient_accumulation_steps=16,\n    metric_for_best_model='eval_loss',\n    greater_is_better=False,\n    load_best_model_at_end =True,\n    prediction_loss_only=True,\n    report_to = \"none\")\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset)","metadata":{"id":"E6QCAyifrL7P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model('./roberta-base')","metadata":{"id":"kcerXfjDrL7R","outputId":"0d4fa8a1-17dc-48e3-a8d6-1cb1ac8c6dcc"},"execution_count":null,"outputs":[]}]}