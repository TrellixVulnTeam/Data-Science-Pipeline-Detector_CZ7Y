{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\n!cp -r ../input/nfl-health-and-safety-helmet-assignment ./\n\n\n!pip install adamp\n!pip install timm\n!pip install -q imutils","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-23T00:13:29.598565Z","iopub.execute_input":"2021-08-23T00:13:29.599195Z","iopub.status.idle":"2021-08-23T00:16:16.997283Z","shell.execute_reply.started":"2021-08-23T00:13:29.599093Z","shell.execute_reply":"2021-08-23T00:16:16.995582Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nCFG = {\n    'fold_num': 5,\n    'seed': 125,\n    'img_size': 224, \n    'train_bs': 128,\n    'valid_bs': 128,\n    'weight_decay':1e-6,\n    'model_arch': 'gluon_seresnext50_32x4d', \n    'epochs': 12,\n    'lr': 0.0003,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'accelerator': 'TPU', \n    'num_classes': 275,\n    'grad_clip': 0.001\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:16:27.001917Z","iopub.execute_input":"2021-08-23T00:16:27.002401Z","iopub.status.idle":"2021-08-23T00:16:27.01107Z","shell.execute_reply.started":"2021-08-23T00:16:27.002356Z","shell.execute_reply":"2021-08-23T00:16:27.009694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nif CFG['accelerator']=='TPU':\n    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n    import torch\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.debug.metrics as met\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp\n    import torch_xla.utils.utils as xu\n    import os\n    os.environ[\"XLA_USE_BF16\"] = \"1\"\n    os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"\n    device = xm.xla_device()\n    \nif CFG['accelerator']=='GPU':\n    import torch\n    device = torch.device('cuda:0')\n    torch.backends.cudnn.benchmark = True\n    print(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:16:32.599061Z","iopub.execute_input":"2021-08-23T00:16:32.599458Z","iopub.status.idle":"2021-08-23T00:17:53.670411Z","shell.execute_reply.started":"2021-08-23T00:16:32.599426Z","shell.execute_reply":"2021-08-23T00:17:53.669259Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport joblib\nimport sklearn\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage import io\n\nfrom datetime import datetime\n#import torchvision\n#from torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n#from torchvision.utils import make_grid \nfrom torch import nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport os\nfrom os.path import join\nfrom os import listdir, rmdir\nfrom shutil import move\nimport random\nfrom operator import itemgetter\nimport copy\nimport time\nimport timm\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport pydicom\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.cluster.vq import kmeans,whiten\nfrom scipy.stats import zscore\nfrom operator import itemgetter\n\nimport optuna\nfrom optuna.trial import TrialState\nimport shutil\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport imutils\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:17:57.743887Z","iopub.execute_input":"2021-08-23T00:17:57.744469Z","iopub.status.idle":"2021-08-23T00:18:04.687212Z","shell.execute_reply.started":"2021-08-23T00:17:57.744426Z","shell.execute_reply":"2021-08-23T00:18:04.686016Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nimport albumentations\n\n#Code by ilovescience https://www.kaggle.com/tanlikesmath/cassava-classification-eda-fastai-starter/notebook\n\nset_seed(999,reproducible=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:25:34.358773Z","iopub.execute_input":"2021-08-23T00:25:34.359214Z","iopub.status.idle":"2021-08-23T00:25:35.510148Z","shell.execute_reply.started":"2021-08-23T00:25:34.35917Z","shell.execute_reply":"2021-08-23T00:25:35.508911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path = Path('../input/nfl-health-and-safety-helmet-assignment')\nos.listdir(dataset_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:25:54.62588Z","iopub.execute_input":"2021-08-23T00:25:54.626709Z","iopub.status.idle":"2021-08-23T00:25:54.641601Z","shell.execute_reply.started":"2021-08-23T00:25:54.626654Z","shell.execute_reply":"2021-08-23T00:25:54.640506Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(dataset_path/'image_labels.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:27:03.597818Z","iopub.execute_input":"2021-08-23T00:27:03.598213Z","iopub.status.idle":"2021-08-23T00:27:03.796904Z","shell.execute_reply.started":"2021-08-23T00:27:03.598177Z","shell.execute_reply":"2021-08-23T00:27:03.795814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\n#le = LabelEncoder()\n\n#all_data = pd.read_csv('./nfl-health-and-safety-helmet-assignment/image_labels.csv')\n#all_data = all_data.rename(columns={'filepaths':'image', 'labels':'label'})\n\n#train = all_data[all_data['data set'] != 'test'].loc[:, ['image', 'label']]#, 'labels']]\n#train['image'] = train.image_id.apply(lambda x: '/'.join(x.split('\\\\')[-3:]))\n#train = train.reset_index(drop=True)\n\n#test = all_data[all_data['data set'] == 'test'].loc[:, ['image', 'label']]#, 'labels']]\n#test['image'] = test.image_id.apply(lambda x: '/'.join(x.split('\\\\')[-3:]))\n#test = test.reset_index(drop=True)\n\n#display(train)\n#display(test)\n\n#I don't know what is all data \"data set\", Hence I commented it.","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:18:22.22414Z","iopub.execute_input":"2021-08-23T00:18:22.224599Z","iopub.status.idle":"2021-08-23T00:18:22.833188Z","shell.execute_reply.started":"2021-08-23T00:18:22.224546Z","shell.execute_reply":"2021-08-23T00:18:22.831154Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nfig = go.Figure(\n    data=[ go.Bar(x=train['label'].value_counts().index, \n            y=train['label'].value_counts().values,\n            text=train['label'].value_counts().values,\n            textposition='auto',name='Count',\n           marker_color='indianred')],\n    layout_title_text=\"Class distribution\"\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T00:27:12.042196Z","iopub.execute_input":"2021-08-23T00:27:12.042597Z","iopub.status.idle":"2021-08-23T00:27:12.265385Z","shell.execute_reply.started":"2021-08-23T00:27:12.042545Z","shell.execute_reply":"2021-08-23T00:27:12.264295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nfor idx in tqdm(train.index):\n    img_name = train.loc[idx,'image']\n    #reading the image and converting BGR color space to RGB\n    img = cv2.cvtColor(cv2.imread('./nfl-health-and-safety-helmet-assignment/images/'+img_name), cv2.COLOR_BGR2RGB)\n    \n    #normalize the image in the range [0,1]\n    norm_image = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    \n    width,height,depth = img.shape\n    \n    #adding new column to the tabel with width height and aspect ratio for every image\n    train.loc[idx,'width'] = width\n    train.loc[idx,'height'] = height\n    train.loc[idx,'Aspect Ratio'] = width/height\n    \n    #calculate mean and standart deviation for each image\n    train.loc[idx,'Mean'] = img.mean()\n    train.loc[idx,'SD'] = img.std()\n    \n    #calculate mean and standart deviation for each normalized image\n    train.loc[idx,'Normalized_Mean'] = norm_image.mean()\n    train.loc[idx,'Normalized_SD'] = norm_image.std()\ntrain","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-23T00:27:21.806809Z","iopub.execute_input":"2021-08-23T00:27:21.807383Z","iopub.status.idle":"2021-08-23T02:53:11.745556Z","shell.execute_reply.started":"2021-08-23T00:27:21.807345Z","shell.execute_reply":"2021-08-23T02:53:11.744587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nfig =  make_subplots(rows=2,cols=1,subplot_titles=['Original Image', 'Normalized Image'])\ncolors = ['rgb({}, {}, {})'.format(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for iter in range(len(train['label'].unique()))]\nfor idx,class_name in enumerate(train['label'].unique()):\n    #scatter plot between mean and variance of the images for every disease\n    fig.add_trace(go.Scatter(x=train[train['label'] == class_name]['Mean'],\n                             y=train[train['label'] == class_name]['SD'],\n                            mode = 'markers',name=class_name, marker_color=colors[idx]),1,1)\n    \n    #scatter plot between mean and variance of the normalized images for every disease\n    fig.add_trace(go.Scatter(x=train[train['label'] == class_name]['Normalized_Mean'],\n                             y=train[train['label'] == class_name]['Normalized_SD'],\n                            mode = 'markers',name=class_name, marker_color=colors[idx], showlegend=False),2,1)\n#x-axis and y axis title\nfig.update_xaxes(title_text=\"Mean\", row=1, col=1)\nfig.update_yaxes(title_text=\"Standard Deviation\", row=1, col=1)\n\nfig.update_xaxes(title_text=\"Mean\", row=2, col=1)\nfig.update_yaxes(title_text=\"Standard Deviation\", row=2, col=1)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:53:21.363879Z","iopub.execute_input":"2021-08-23T02:53:21.364428Z","iopub.status.idle":"2021-08-23T02:53:23.479076Z","shell.execute_reply.started":"2021-08-23T02:53:21.364386Z","shell.execute_reply":"2021-08-23T02:53:23.477561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_path = './nfl-health-and-safety-helmet-assignment/images/'\nfrom scipy.cluster.vq import kmeans,whiten\nfrom scipy.stats import zscore","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:00:30.96142Z","iopub.execute_input":"2021-08-23T03:00:30.961884Z","iopub.status.idle":"2021-08-23T03:00:30.9679Z","shell.execute_reply.started":"2021-08-23T03:00:30.961828Z","shell.execute_reply":"2021-08-23T03:00:30.966685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nfig = make_subplots(rows=2,cols=1,\n                    subplot_titles=['Normalized Mean','Normalized Standard Deviation'],\n                    shared_xaxes=True)\ncolors = ['rgb({}, {}, {})'.format(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for iter in range(len(train['label'].unique()))]\nfor idx,class_name in enumerate(train['label'].unique()):\n    fig.add_trace(go.Box(y=train[train['label'] == class_name]['Normalized_Mean'],\n                        name=class_name,showlegend=False,\n                        marker_color=colors[idx]),1,1)\n    fig.add_trace(go.Box(y=train[train['label'] == class_name]['Normalized_SD'],\n                        name=class_name,showlegend=False,\n                        marker_color=colors[idx]),2,1)\nfig.update_layout(title='Outlier Detection - Box Plot')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:03:43.14342Z","iopub.execute_input":"2021-08-23T03:03:43.14388Z","iopub.status.idle":"2021-08-23T03:03:44.151557Z","shell.execute_reply.started":"2021-08-23T03:03:43.14383Z","shell.execute_reply":"2021-08-23T03:03:44.150054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\ndef calculate_fences_new(array):\n    upper_fence = array.describe()['75%']+1.5*(array.describe()['75%']-array.describe()['25%'])\n    lower_fence = array.describe()['25%']-1.5*(array.describe()['75%']-array.describe()['25%'])\n    return lower_fence, upper_fence","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:06:00.507048Z","iopub.execute_input":"2021-08-23T03:06:00.507567Z","iopub.status.idle":"2021-08-23T03:06:00.514269Z","shell.execute_reply.started":"2021-08-23T03:06:00.507502Z","shell.execute_reply":"2021-08-23T03:06:00.512914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\noutliers = set()\n\nfor species in train['label'].unique():\n    images  = train[train['label'] ==  label]\n    \n    data_for_fences_mean = train[train['label']==label].loc[:, 'Normalized_Mean']\n    data_for_fences_sd = train[train['label']==label].loc[:, 'Normalized_SD']\n    \n    outliers_mean = images[images['Normalized_Mean'].between(calculate_fences_new(data_for_fences_mean)[0],calculate_fences_new(data_for_fences_mean)[1],inclusive=True)]\n    outliers_mean = images[~images['image'].isin(outliers_mean['image'])]\n    \n    outliers_st = images[images['Normalized_SD'].between(calculate_fences_new(data_for_fences_sd)[0],calculate_fences_new(data_for_fences_sd)[1],inclusive=True)]\n    outliers_st = images[~images['image'].isin(outliers_st['image'])]\n    \n    delete_mean = set(input_path+outliers_mean['image'].astype(str).values)\n    delete_st= input_path+outliers_st['image'].astype(str).values\n    outliers = outliers.union(delete_mean)\n    outliers = outliers.union(delete_st)\n    \nprint(len(outliers))","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:06:42.050636Z","iopub.execute_input":"2021-08-23T03:06:42.051086Z","iopub.status.idle":"2021-08-23T03:06:42.224515Z","shell.execute_reply.started":"2021-08-23T03:06:42.051046Z","shell.execute_reply":"2021-08-23T03:06:42.222949Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\nimgs = list(outliers)\n\ngridimg = []        \nfor idx,img_name in enumerate(np.random.choice(imgs,25,replace=False)):\n    np_image = mpimg.imread(img_name)\n    gridimg.append(np_image)\n\nfig = plt.figure(figsize=(25, 25))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(5, 5),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 label_mode=\"1\")\n\nfor ax, im in zip(grid, gridimg):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    ax.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:09:01.031089Z","iopub.execute_input":"2021-08-23T03:09:01.031509Z","iopub.status.idle":"2021-08-23T03:09:01.086764Z","shell.execute_reply.started":"2021-08-23T03:09:01.031471Z","shell.execute_reply":"2021-08-23T03:09:01.085436Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images in outliers:\n    os.remove(images)\n    train = train.drop(train[train['image']=='/'.join(images.split('/')[-3:])].index)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:17:23.296488Z","iopub.execute_input":"2021-08-22T23:17:23.296891Z","iopub.status.idle":"2021-08-22T23:17:23.303183Z","shell.execute_reply.started":"2021-08-22T23:17:23.296857Z","shell.execute_reply":"2021-08-22T23:17:23.30181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:10:10.351584Z","iopub.execute_input":"2021-08-23T03:10:10.352072Z","iopub.status.idle":"2021-08-23T03:10:10.376672Z","shell.execute_reply.started":"2021-08-23T03:10:10.352029Z","shell.execute_reply":"2021-08-23T03:10:10.375522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by  Georgii Sirotenko  https://www.kaggle.com/georgiisirotenko/pytorch-fish-outliers-handling-test-100\n\ndef init_logger(log_file='./'+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-23T03:11:10.691931Z","iopub.execute_input":"2021-08-23T03:11:10.692344Z","iopub.status.idle":"2021-08-23T03:11:10.703638Z","shell.execute_reply.started":"2021-08-23T03:11:10.69231Z","shell.execute_reply":"2021-08-23T03:11:10.702273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:15:24.26604Z","iopub.execute_input":"2021-08-23T03:15:24.266415Z","iopub.status.idle":"2021-08-23T03:15:24.271624Z","shell.execute_reply.started":"2021-08-23T03:15:24.266381Z","shell.execute_reply":"2021-08-23T03:15:24.270451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rand_bbox(size, lam):\n    W = size[0]\n    H = size[1]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True, \n                 one_hot_label=False,\n                 do_fmix=False, \n                 fmix_params={\n                     'alpha': 1., \n                     'decay_power': 3., \n                     'shape': (CFG['img_size'], CFG['img_size']),\n                     'max_soft': True, \n                     'reformulate': False\n                 },\n                 do_cutmix=False,\n                 cutmix_params={\n                     'alpha': 1,\n                 }\n                ):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.do_fmix = do_fmix\n        self.fmix_params = fmix_params\n        self.do_cutmix = do_cutmix\n        self.cutmix_params = cutmix_params\n        \n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label == True:\n            self.species = self.df['label'].values\n            \n            if one_hot_label is True:\n                self.species = np.eye(self.df['label'].max()+1)[self.label]\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.species[index]\n          \n        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image']))\n\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                \n                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n                \n                # Make mask, get mean / std\n                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n    \n                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n                fmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image']))\n\n                if self.transforms:\n                    fmix_img = self.transforms(image=fmix_img)['image']\n\n                mask_torch = torch.from_numpy(mask)\n                \n                # mix image\n                img = mask_torch*img+(1.-mask_torch)*fmix_img\n\n                # mix target\n                rate = mask.sum()/CFG['img_size']/CFG['img_size']\n                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n        \n        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n                cmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image']))\n                if self.transforms:\n                    cmix_img = self.transforms(image=cmix_img)['image']\n                    \n                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n\n                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n\n                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (CFG['img_size'] * CFG['img_size']))\n                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:15:56.900441Z","iopub.execute_input":"2021-08-23T03:15:56.900845Z","iopub.status.idle":"2021-08-23T03:15:56.92862Z","shell.execute_reply.started":"2021-08-23T03:15:56.900811Z","shell.execute_reply":"2021-08-23T03:15:56.92742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,ImageCompression,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n    CenterCrop, Resize, RandomGamma, Posterize, GaussianBlur\n)\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_transforms(data):\n    \n    if data == 'train':\n        return Compose([\n            #RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            CLAHE(p=0.5),\n#             Posterize(p=0.5),\n#             GaussianBlur(p=0.5),\n#             ImageCompression(p=0.5),\n            #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\n    elif data == 'val':\n        return Compose([\n            #CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            #Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:21:40.376889Z","iopub.execute_input":"2021-08-23T03:21:40.3773Z","iopub.status.idle":"2021-08-23T03:21:40.390067Z","shell.execute_reply.started":"2021-08-23T03:21:40.377259Z","shell.execute_reply":"2021-08-23T03:21:40.388558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(15,12))\n    i = 0\n    for row in range(5):\n         for col in range(5):\n                img = mpimg.imread(input_path+samples[i][0][0])\n                ax[row][col].imshow(img)\n                ax[row][col].axis('off')\n                ax[row][col].set_title(samples[i][1], fontsize=15)\n                i+=1\n  \nexample = train\n\nrand_samples = [] \nfor _ in range(25): \n    sample = random.sample(list(train['image']), 1)\n    rand_samples.append([sample, train[train['image']==sample[0]]['label'].values[0]])\nrand_samples[0]\nplot_samples(rand_samples)\nplt.suptitle('Samples', fontsize=30)\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-23T03:23:28.813809Z","iopub.execute_input":"2021-08-23T03:23:28.814156Z","iopub.status.idle":"2021-08-23T03:23:34.672353Z","shell.execute_reply.started":"2021-08-23T03:23:28.814119Z","shell.execute_reply":"2021-08-23T03:23:34.671058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#le = LabelEncoder()\n#sets = {'train':train, 'test':test}\n#for x in ['train', 'test']:\n    #sets[x]['label'] = le.fit_transform(sets[x].label.values)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:24:49.956442Z","iopub.execute_input":"2021-08-23T03:24:49.957001Z","iopub.status.idle":"2021-08-23T03:24:49.99359Z","shell.execute_reply.started":"2021-08-23T03:24:49.956964Z","shell.execute_reply":"2021-08-23T03:24:49.992484Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(df, trn_idx, val_idx, data_root='./nfl-health-and-safety-helmet-assignment/images'):\n    \n    \n\n    train_ = df.reset_index().loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.reset_index().loc[val_idx,:].reset_index(drop=True)\n        \n    train_ds = CustomDataset(train_, data_root, transforms=get_transforms(data='train'), output_label=True, one_hot_label=False, do_fmix=False, do_cutmix=False)\n    valid_ds = CustomDataset(valid_, data_root, transforms=get_transforms(data='val'), output_label=True)\n    \n    if CFG['accelerator']=='TPU':\n        \n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n\n        valid_sampler = torch.utils.data.distributed.DistributedSampler(\n            valid_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n    \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=False,\n            sampler=train_sampler,\n            num_workers=CFG['num_workers'],\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            sampler=valid_sampler,\n            pin_memory=True,\n    )\n        \n    if CFG['accelerator']=='GPU':\n        \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=True,        \n            num_workers=CFG['num_workers']\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=True\n    )\n    \n    \n    return train_loader, val_loader, len(train_ds), len(valid_ds)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:26:12.020208Z","iopub.execute_input":"2021-08-23T03:26:12.021321Z","iopub.status.idle":"2021-08-23T03:26:12.037154Z","shell.execute_reply.started":"2021-08-23T03:26:12.021232Z","shell.execute_reply":"2021-08-23T03:26:12.036025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import autograd\n\ndef train_one_epoch(loader, epoch, model, optimizer, criterion, device, gradient_clipping=False):\n   \n   LOGGER.info('--------------------------------------------------------------')\n   LOGGER.info('Epoch: {}/{}'.format(epoch+1, CFG['epochs']))\n   model.train()\n  \n   running_loss = 0.\n   running_corrects = 0.\n\n   pbar = tqdm(enumerate(loader), total=len(loader))\n   for step, (imgs, targets) in pbar:\n      imgs, targets = imgs.to(device).float(), targets.to(device).long()\n      if CFG['accelerator']=='GPU':\n        with autocast():\n            output = model(imgs)\n            loss = criterion(output, targets)\n            loss = loss / CFG['accum_iter']\n        scaler.scale(loss).backward()\n            \n            \n      if CFG['accelerator']=='TPU':   \n        \n        output = model(imgs)\n        gc.collect()\n        loss = criterion(output, targets)\n        loss = loss / CFG['accum_iter']\n        loss.backward()\n      \n      if gradient_clipping:\n        timm.utils.agc.adaptive_clip_grad(model.parameters(), clip_factor=CFG['grad_clip'], eps=1e-3, norm_type=2.0)\n        \n      _, pred = output.max(dim=1)\n      running_corrects += torch.sum(pred == targets.data)\n      running_loss += loss.item()*imgs.size(0)\n            \n      pbar.set_description(f'train | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}')\n      if ((step + 1) % CFG['accum_iter'] == 0) or ((step + 1) == len(loader)):\n            \n            if CFG['accelerator']=='GPU':\n                scaler.step(optimizer)\n                scaler.update()\n                \n            if CFG['accelerator']=='TPU':\n                xm.optimizer_step(optimizer)\n                \n            optimizer.zero_grad()\n   return running_corrects, running_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:20:32.266167Z","iopub.execute_input":"2021-08-22T23:20:32.266753Z","iopub.status.idle":"2021-08-22T23:20:32.272055Z","shell.execute_reply.started":"2021-08-22T23:20:32.266702Z","shell.execute_reply":"2021-08-22T23:20:32.271103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_one_epoch(loader,epoch, model, device, criterion):\n    model.eval()\n    \n    running_loss = 0.\n    running_corrects = 0.\n    \n    pbar = tqdm(enumerate(loader), total=len(loader))\n    for step, (imgs, targets) in pbar:\n       imgs, targets = imgs.to(device).float(), targets.to(device).long()\n       with torch.no_grad():\n             output = model(imgs)\n             gc.collect()\n             _, pred = output.max(dim=1)\n             loss = criterion(output, targets)\n       running_corrects += torch.sum(pred == targets.data)\n       running_loss += loss.item()*imgs.size(0)\n       gc.collect()\n    \n       pbar.set_description(f'val | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}')\n                \n    return running_corrects, running_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:20:36.823816Z","iopub.execute_input":"2021-08-22T23:20:36.824193Z","iopub.status.idle":"2021-08-22T23:20:36.848733Z","shell.execute_reply.started":"2021-08-22T23:20:36.824161Z","shell.execute_reply":"2021-08-22T23:20:36.847718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True, \n                 one_hot_label=False):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        \n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label == True:\n            self.labels = self.df['label'].values\n            #print(self.labels)\n            \n            if one_hot_label is True:\n                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n                #print(self.labels)\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.labels[index]\n          \n        img  = get_img(\"{}\".format(self.df.loc[index]['image']))\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.output_label == True:\n            return img, target\n        else:\n            return img","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:20:52.421634Z","iopub.execute_input":"2021-08-22T23:20:52.422256Z","iopub.status.idle":"2021-08-22T23:20:52.432885Z","shell.execute_reply.started":"2021-08-22T23:20:52.42222Z","shell.execute_reply":"2021-08-22T23:20:52.431717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data):\n    \n    if data == 'train':\n        return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\n    elif data == 'val':\n        return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:20:59.657969Z","iopub.execute_input":"2021-08-22T23:20:59.658345Z","iopub.status.idle":"2021-08-22T23:20:59.670279Z","shell.execute_reply.started":"2021-08-22T23:20:59.658313Z","shell.execute_reply":"2021-08-22T23:20:59.669012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(15,12))\n    i = 0\n    for row in range(5):\n         for col in range(5):\n                img = mpimg.imread(samples[i][0][0])\n                ax[row][col].imshow(img)\n                ax[row][col].axis('off')\n                ax[row][col].set_title(samples[i][1], fontsize=15)\n                i+=1\n  \nexample = all_data\n\nrand_samples = [] \nfor _ in range(25): \n#     rand_samples.append([random.sample([os.path.join(input_path+'/'+str(classes), str(filename)) for filename in os.listdir(input_path)], 1), classes]) \n    sample = random.sample(list(train['image']), 1)\n    rand_samples.append([sample, train[train['image']==sample[0]]['label'].values[0]])\nrand_samples[0]\nplot_samples(rand_samples)\nplt.suptitle('Samples', fontsize=30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:21:06.386684Z","iopub.execute_input":"2021-08-22T23:21:06.387047Z","iopub.status.idle":"2021-08-22T23:21:10.340708Z","shell.execute_reply.started":"2021-08-22T23:21:06.387015Z","shell.execute_reply":"2021-08-22T23:21:10.339937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nsets = {'train':train, 'test':test}\nfor x in ['train', 'test']:\n    sets[x]['label'] = le.fit_transform(sets[x].label.values)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:21:30.559328Z","iopub.execute_input":"2021-08-22T23:21:30.559715Z","iopub.status.idle":"2021-08-22T23:21:30.570497Z","shell.execute_reply.started":"2021-08-22T23:21:30.559682Z","shell.execute_reply":"2021-08-22T23:21:30.569232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(df, trn_idx, val_idx, data_root='./nfl-health-and-safety-helmet-assignment'):\n\n    train_ = df.reset_index().loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.reset_index().loc[val_idx,:].reset_index(drop=True)\n        \n    train_ds = CustomDataset(train_, data_root, transforms=get_transforms(data='train'), output_label=True, one_hot_label=False)\n    valid_ds = CustomDataset(valid_, data_root, transforms=get_transforms(data='val'), output_label=True)\n    \n    if CFG['accelerator']=='TPU':\n        \n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n\n        valid_sampler = torch.utils.data.distributed.DistributedSampler(\n            valid_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n    \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            sampler=train_sampler,\n            num_workers=CFG['num_workers'],\n        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            sampler=valid_sampler,\n            pin_memory=True,\n    )\n        \n    if CFG['accelerator']=='GPU':\n        \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=True,        \n            num_workers=CFG['num_workers']\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=True\n    )\n    \n    \n    return train_loader, val_loader, len(train_ds), len(valid_ds)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:21:37.136679Z","iopub.execute_input":"2021-08-22T23:21:37.137071Z","iopub.status.idle":"2021-08-22T23:21:37.15138Z","shell.execute_reply.started":"2021-08-22T23:21:37.137031Z","shell.execute_reply":"2021-08-22T23:21:37.149892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import autograd\n\ndef train_one_epoch(loader, epoch, model, optimizer, criterion, gradient_clipping=False):\n   \n   LOGGER.info('--------------------------------------------------------------')\n   LOGGER.info('Epoch: {}/{}'.format(epoch+1, CFG['epochs']))\n    \n   model.train()\n\n   running_loss = 0.\n   running_corrects = 0.\n    \n   pbar = tqdm(enumerate(loader), total=len(loader))\n   for step, (imgs, targets) in pbar:\n        \n      imgs, targets = imgs.to(device).float(), targets.to(device).long()\n      if CFG['accelerator']=='GPU':\n        with autocast():\n            output = model(imgs)\n            loss = criterion(output, targets)\n            loss = loss / CFG['accum_iter']\n        scaler.scale(loss).backward()\n            \n            \n      if CFG['accelerator']=='TPU':\n        output = model(imgs)\n        gc.collect()\n        loss = criterion(output, targets)\n        loss = loss / CFG['accum_iter']\n        loss.backward()\n      \n      if gradient_clipping:\n        timm.utils.agc.adaptive_clip_grad(model.parameters(), clip_factor=CFG['grad_clip'], eps=1e-3, norm_type=2.0)\n        \n      _, pred = output.max(dim=1)\n      running_corrects += torch.sum(pred == targets.data)\n      running_loss += loss.item()*imgs.size(0)\n    \n      if loss.item()==float(\"NaN\"):\n            xm.master_print('0'*50)\n            break\n            \n      description = f'train | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}'\n      pbar.set_description(description)\n    \n      if ((step + 1) % CFG['accum_iter'] == 0) or ((step + 1) == len(loader)):\n            \n            if CFG['accelerator']=='GPU':\n                scaler.step(optimizer)\n                scaler.update()\n                \n            if CFG['accelerator']=='TPU':\n                xm.optimizer_step(optimizer)\n                \n            optimizer.zero_grad()\n   return running_corrects, running_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:21:44.09502Z","iopub.execute_input":"2021-08-22T23:21:44.095405Z","iopub.status.idle":"2021-08-22T23:21:44.1102Z","shell.execute_reply.started":"2021-08-22T23:21:44.095372Z","shell.execute_reply":"2021-08-22T23:21:44.10901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_one_epoch(loader,epoch, model, device, criterion):\n    model.eval()\n    \n    running_loss = 0.\n    running_corrects = 0.\n    \n    pbar = tqdm(enumerate(loader), total=len(loader))\n    for step, (imgs, targets) in pbar:\n       imgs, targets = imgs.to(device).float(), targets.to(device).long()\n       with torch.no_grad():\n             output = model(imgs)\n             gc.collect()\n             _, pred = output.max(dim=1)\n             loss = criterion(output, targets)\n       running_corrects += torch.sum(pred == targets.data)\n       running_loss += loss.item()*imgs.size(0)\n       gc.collect()\n    \n       description = f'val | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}'\n       pbar.set_description(description)\n                \n    return running_corrects, running_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:21:50.390265Z","iopub.execute_input":"2021-08-22T23:21:50.390673Z","iopub.status.idle":"2021-08-22T23:21:50.399809Z","shell.execute_reply.started":"2021-08-22T23:21:50.390623Z","shell.execute_reply":"2021-08-22T23:21:50.398991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(seed, epochs, model, freeze, device, fold, train_loader, val_loader, criterion, gradient_clipping=False):\n  \n  if CFG['accelerator']=='TPU':\n          LOGGER.info('Creating a model {}...'.format(seed))\n          #device = xm.xla_device()\n          WRAPPED_MODEL = xmp.MpModelWrapper(model)\n          model = WRAPPED_MODEL.to(device)\n          #model.to(device)\n          if freeze==True:\n            if seed==1:\n              optimizer = torch.optim.Adam(model.head.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n            if seed==2 or seed==3:\n              optimizer = torch.optim.Adam(model.fc.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n            if seed==4 or seed==0:\n              optimizer = torch.optim.Adam(model.classifier.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n          if freeze==False:\n            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        \n  if CFG['accelerator'] == 'GPU':\n    LOGGER.info('Creating a model...')\n    model.to(device)\n    if freeze==True:\n        if seed==1:\n            optimizer = torch.optim.Adam(model.head.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        if seed==2 or seed==3:\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        if seed==4 or seed==0:\n            optimizer = torch.optim.Adam(model.classifier.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])           \n    if freeze==False:\n       optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n    \n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  \n  if CFG['accelerator']=='TPU':\n     if freeze==True:\n                                         \n        for fase in ['CLASSIFIER TRAINING', 'ALL NET TRAINING']:\n                                         \n            if fase=='ALL NET TRAINING':             \n               model.load_state_dict(best_model)\n               for param in model.parameters():\n                   param.requires_grad=True\n               optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']* xm.xrt_world_size()/10, betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])  \n               scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)     \n                                         \n            for epoch in range(epochs):\n                                         \n                #train\n                para_loader = pl.ParallelLoader(train_loader, [device])\n                running_corrects, running_loss = train_one_epoch(para_loader.per_device_loader(device), epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss / train_len\n                epoch_acc = running_corrects/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                \n                #val\n                para_loader = pl.ParallelLoader(val_loader, [device])\n                running_corrects, running_loss = valid_one_epoch(para_loader.per_device_loader(device), epoch, model, device, criterion)\n                epoch_loss = running_loss / val_len\n                epoch_acc = running_corrects/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss)\n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                   \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n            time_elapsed = time.time() - since\n            LOGGER.info('{} TIME {}m {}s'.format(fase, time_elapsed//60, time_elapsed%60))\n            LOGGER.info('=='*31)\n                                         \n     if freeze==False:\n        for epoch in range(epochs):\n                                         \n                #train\n                para_loader = pl.ParallelLoader(train_loader, [device])\n                running_corrects, running_loss = train_one_epoch(para_loader.per_device_loader(device), epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss / train_len\n                epoch_acc = running_corrects/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                \n                \n                #val\n                para_loader = pl.ParallelLoader(val_loader, [device])\n                running_corrects, running_loss = valid_one_epoch(para_loader.per_device_loader(device), epoch, model, device, criterion)\n                epoch_loss = running_loss / val_len\n                epoch_acc = running_corrects/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n    \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n        time_elapsed = time.time() - since\n        LOGGER.info('FOLD_{} TRAINING TIME {}m {}s'.format(fold+1, time_elapsed//60, time_elapsed%60))\n        LOGGER.info('=='*31) \n                                         \n                                         \n  if CFG['accelerator']=='GPU':\n     if freeze==True:\n                                         \n        for fase in ['CLASSIFIER TRAINING', 'ALL NET TRAINING']:\n                                         \n            if fase=='ALL NET TRAINING':             \n               model.load_state_dict(best_model)\n               for param in model.parameters():\n                   param.requires_grad=True\n               optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']/10, betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])  \n               scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)     \n                                         \n            for epoch in range(CFG['epochs']):\n                                         \n                #train                           \n                running_corrects, running_loss = train_one_epoch(train_loader, epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss / train_len\n                epoch_acc = running_corrects/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                \n                #val\n                running_corrects, running_loss = valid_one_epoch(val_loader, epoch, model, device, criterion)\n                epoch_loss = running_loss / val_len\n                epoch_acc = running_corrects/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n            time_elapsed = time.time() - since\n            LOGGER.info('{} TIME {}m {}s'.format(fase, time_elapsed//60, time_elapsed%60))\n            LOGGER.info('=='*31)\n                                         \n     if freeze == False :\n        for epoch in range(epochs):\n                \n                #train                           \n                running_corrects, running_loss = train_one_epoch(train_loader, epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss / train_len\n                epoch_acc = running_corrects/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                \n                #val                             \n                running_corrects, running_loss = valid_one_epoch(val_loader, epoch, model, device, criterion)\n                epoch_loss = running_loss / val_len\n                epoch_acc = running_corrects/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n        time_elapsed = time.time() - since\n        LOGGER.info('FOLD_{} TRAINING TIME {}m {}s'.format(fold+1, time_elapsed//60, time_elapsed%60))\n        LOGGER.info('=='*31) \n                                         \n  if CFG['accelerator']=='TPU':\n     xm.save(best_model,'{}_fold_{}.pth'.format(CFG['model_arch'], fold+1))\n  if CFG['accelerator']=='GPU':\n     torch.save(best_model,'{}_fold_{}.pth'.format(CFG['model_arch'], fold+1))\n  \n  LOGGER.info('Prediction Saved! \\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:21:56.206522Z","iopub.execute_input":"2021-08-22T23:21:56.207105Z","iopub.status.idle":"2021-08-22T23:21:56.261416Z","shell.execute_reply.started":"2021-08-22T23:21:56.207068Z","shell.execute_reply":"2021-08-22T23:21:56.260603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n    \n    fold_best_acc = []\n    \n    all_losses = {f'fold_{x+1}':[[],[]] for x in range(CFG['fold_num'])}\n    all_accuracies = {f'fold_{x+1}':[[],[]] for x in range(CFG['fold_num'])}\n    \n    for fold, (trn_idx, val_idx) in enumerate(folds):\n        \n        #we'll train fold 0 first\n        if fold > 0:\n            break \n            \n        LOGGER.info('\\n\\n')\n        LOGGER.info(f'========== fold: {fold+1} training ==========')\n        LOGGER.info('Accelerator: {}'.format(CFG['accelerator']))\n        LOGGER.info(f'Device: {device}')\n            \n        train_loader, val_loader, train_len, val_len = prepare_dataloader(train, trn_idx, val_idx, data_root='./nfl-health-and-safety-helmet-assignment')\n        model = timm.create_model(CFG['model_arch'], pretrained=True, num_classes=CFG['num_classes'])\n        if CFG['accelerator']=='GPU':\n            model = nn.DataParallel(model).to(device)\n        scaler = GradScaler()\n        criterion = nn.CrossEntropyLoss().to(device)\n        #criterion = TaylorCrossEntropyLossV1().to(device)\n        fit(seed=1, epochs = CFG['epochs'], model=model, freeze=False, device=device, fold=fold, train_loader=train_loader, val_loader=val_loader, criterion=criterion, gradient_clipping=False)\n\n        LOGGER.info(f'========== fold: {fold+1} result ==========')\n        LOGGER.info('Score: {}'.format(max(all_accuracies['fold_{}'.format(fold+1)][1])))\n        fold_best_acc.append(max(all_accuracies['fold_{}'.format(fold+1)][1]))   \n        \n        del model, train_loader, val_loader#, scaler\n        torch.cuda.empty_cache()\n    # CV result\n    LOGGER.info(f\"========== CV ==========\")\n    LOGGER.info(f'Score: {max(fold_best_acc)}')","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:28:16.612398Z","iopub.status.idle":"2021-08-23T03:28:16.613095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = timm.create_model('gluon_resnet50_v1b', pretrained=False, num_classes=CFG['num_classes'])\nif CFG['accelerator']=='GPU':\n    model = nn.DataParallel(model).to(device)\nstate = torch.load('./gluon_resnet50_v1b_fold_1.pth')\nmodel.load_state_dict(state);\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2021-08-23T03:31:49.345707Z","iopub.execute_input":"2021-08-23T03:31:49.346344Z","iopub.status.idle":"2021-08-23T03:31:49.763278Z","shell.execute_reply.started":"2021-08-23T03:31:49.346287Z","shell.execute_reply":"2021-08-23T03:31:49.761773Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-08-22T23:24:40.153504Z","iopub.execute_input":"2021-08-22T23:24:40.154054Z","iopub.status.idle":"2021-08-22T23:24:40.168189Z","shell.execute_reply.started":"2021-08-22T23:24:40.154021Z","shell.execute_reply":"2021-08-22T23:24:40.166996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#After 3:30 hs, many cells deleted, eyes burning. I gave up my TPU project. ","metadata":{}}]}