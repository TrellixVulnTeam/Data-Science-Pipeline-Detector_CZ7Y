{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append('../input/pytorch-optimizers/')\nsys.path.append('../input/weightedboxfusion/')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:24.397227Z","iopub.execute_input":"2021-11-01T02:37:24.397839Z","iopub.status.idle":"2021-11-01T02:37:24.407122Z","shell.execute_reply.started":"2021-11-01T02:37:24.397748Z","shell.execute_reply":"2021-11-01T02:37:24.406234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport yaml\nimport random\nimport shutil\nimport warnings\nimport subprocess\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom tqdm import tqdm\nfrom PIL import Image, ImageDraw\nfrom shutil import copyfile\nfrom IPython.core.display import Video, display\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\nfrom ensemble_boxes import nms\n\nimport timm\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torchvision import models\nfrom torchvision import transforms\nfrom torch_optimizer.radam import RAdam\n\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n    ShiftScaleRotate, CenterCrop, Resize, Rotate, RandomRotate90, RGBShift, ChannelShuffle)\n\nwarnings.simplefilter('ignore')\npd.set_option(\"max_columns\", 150)\npd.set_option('display.max_rows', 150)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:24.704207Z","iopub.execute_input":"2021-11-01T02:37:24.704823Z","iopub.status.idle":"2021-11-01T02:37:30.804336Z","shell.execute_reply.started":"2021-11-01T02:37:24.704787Z","shell.execute_reply":"2021-11-01T02:37:30.803143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Configuration","metadata":{}},{"cell_type":"code","source":"CFG = {\n    \"seed\"        : 42,\n    \"make_dataset\": False,\n    \"save_zip\"    : True,\n    \"train_model\" : False,\n    'device'      : 'cuda:0',\n    \"input_img\"   : '../input/nfl-health-and-safety-helmet-assignment/images/',\n    \"label_img\"   : '../input/nfl-health-and-safety-helmet-assignment/image_labels.csv',\n    \"input_video\" : '../input/nfl-health-and-safety-helmet-assignment/train/',\n    \"label_video\" : '../input/nfl-health-and-safety-helmet-assignment/train_labels.csv',\n    \"output_path\" : './train/',\n    \"model\"       : \"tf_efficientnetv2_s_in21k\",\n    \"size\"        : 128,\n    \"height\"      : 4,\n    \"width\"       : 4,\n    \"batch_size\"  : 256,\n    \"epochs\"      : 5,\n    \"lr\"          : 0.001,\n    'weight_decay': 1e-4,\n    \"accum_iter\"  : 1,\n    'early_stopping': 10,\n    'verbose_step'  : 1,\n    \"num_workers\"   : 4\n}\n\nCFG","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:30.805763Z","iopub.execute_input":"2021-11-01T02:37:30.806055Z","iopub.status.idle":"2021-11-01T02:37:30.815698Z","shell.execute_reply.started":"2021-11-01T02:37:30.806025Z","shell.execute_reply":"2021-11-01T02:37:30.81491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed_everything(CFG[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:30.817009Z","iopub.execute_input":"2021-11-01T02:37:30.817521Z","iopub.status.idle":"2021-11-01T02:37:30.833249Z","shell.execute_reply.started":"2021-11-01T02:37:30.817492Z","shell.execute_reply":"2021-11-01T02:37:30.832427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:39:30.564416Z","iopub.execute_input":"2021-11-01T02:39:30.564818Z","iopub.status.idle":"2021-11-01T02:39:30.569316Z","shell.execute_reply.started":"2021-11-01T02:39:30.564778Z","shell.execute_reply":"2021-11-01T02:39:30.568401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data and make training data","metadata":{}},{"cell_type":"code","source":"# Load video label csv file\ndf_video_images = pd.read_csv(CFG['label_video'])\ndf_video_images[\"path\"] = CFG[\"output_path\"] + df_video_images.video.str.replace(\".mp4\",\"\") + \"/\" + df_video_images.video_frame + \".jpg\"\ndf_video_images = df_video_images[df_video_images.isSidelinePlayer==False].reset_index(drop=True)\n\nprint(df_video_images.shape, df_video_images.path.nunique())\ndf_video_images.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:30.834587Z","iopub.execute_input":"2021-11-01T02:37:30.835036Z","iopub.status.idle":"2021-11-01T02:37:35.197078Z","shell.execute_reply.started":"2021-11-01T02:37:30.834994Z","shell.execute_reply":"2021-11-01T02:37:35.196102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf {CFG[\"output_path\"]}\n\nfor f in tqdm(os.listdir(CFG['input_video'])):\n    in_path      = CFG[\"input_video\"] + f\n    out_img_path = CFG[\"output_path\"] + f[:-4]\n    image_name   = f[:-4]\n    extention    = \"jpg\"\n    # Make save directories\n    os.makedirs(out_img_path, exist_ok=True)\n    # Split into frames\n    cmd = 'ffmpeg -i \\\"{}\\\" -qscale:v 2 \\\"{}/{}_%d.{}\\\"'.format(in_path, out_img_path, image_name, extention)\n    subprocess.call(cmd, shell=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:35.198584Z","iopub.execute_input":"2021-11-01T02:37:35.19888Z","iopub.status.idle":"2021-11-01T02:37:40.032561Z","shell.execute_reply.started":"2021-11-01T02:37:35.198847Z","shell.execute_reply":"2021-11-01T02:37:40.031648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_imgs = glob(CFG[\"output_path\"] + \"/*/*.jpg\")\ndf_video_images = df_video_images[df_video_images.path.isin(target_imgs)]\ndf_video_images = df_video_images[df_video_images.frame % 4 == 0].reset_index(drop=True)\ndf_video_images = df_video_images[[\"path\",\"left\",\"width\",\"top\",\"height\"]]\n\nprint(df_video_images.shape, df_video_images.path.nunique())\ndf_video_images.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:41.110468Z","iopub.execute_input":"2021-11-01T02:37:41.110832Z","iopub.status.idle":"2021-11-01T02:37:41.25329Z","shell.execute_reply.started":"2021-11-01T02:37:41.110795Z","shell.execute_reply":"2021-11-01T02:37:41.252195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load image level csv file\ndf_images = pd.read_csv(CFG['label_img'])\ndf_images = df_images[df_images.label != \"Helmet-Sideline\"].reset_index(drop=True)\ndf_images[\"path\"] = CFG['input_img'] + df_images.image\n\npaths = df_images.path.unique()\nrandom.shuffle(paths)\ndf_images = df_images[df_images.path.isin(paths[:int(len(paths)/2)])]\ndf_images = df_images[[\"path\",\"left\",\"width\",\"top\",\"height\"]]\n\nprint(df_images.shape, df_images.path.nunique())\ndf_images.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:43.456669Z","iopub.execute_input":"2021-11-01T02:37:43.457188Z","iopub.status.idle":"2021-11-01T02:37:43.888567Z","shell.execute_reply.started":"2021-11-01T02:37:43.457154Z","shell.execute_reply":"2021-11-01T02:37:43.887435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_images = pd.concat([df_video_images, df_images]).reset_index(drop=True)\ndf_all_images[\"right\"]    = df_all_images.left + df_all_images.width\ndf_all_images[\"bottom\"]   = df_all_images.top  + df_all_images.height\ndf_all_images[\"x_center\"] = df_all_images.left + (df_all_images.width  / 2).astype(int)\ndf_all_images[\"y_center\"] = df_all_images.top  + (df_all_images.height / 2).astype(int)\ndf_all_images[\"label\"]    = \"Helmet\"\ndf_all_images[\"label_id\"] = 0\n\nprint(df_all_images.shape, df_all_images.path.nunique())\ndf_all_images.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:44.569367Z","iopub.execute_input":"2021-11-01T02:37:44.570049Z","iopub.status.idle":"2021-11-01T02:37:44.635881Z","shell.execute_reply.started":"2021-11-01T02:37:44.570007Z","shell.execute_reply":"2021-11-01T02:37:44.634937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check(l, r, t, b):\n    if l < 0 or 1280 < r:\n        return False\n    if t < 0 or 720 < b:\n        return False\n    return True\n\nif CFG[\"make_dataset\"]:\n    train_bboxes = []\n    for f in tqdm(df_all_images.path.unique()):\n        df  = df_all_images[df_all_images.path==f]\n        df  = df.sample(int(df.shape[0]/4)).reset_index(drop=True)\n        for i, (l, w, t, h) in df[[\"left\",\"width\",\"top\",\"height\"]].iterrows():\n            r = l + w\n            b = t + h\n            # positive data\n            if check(l, r, t, b):\n                train_bboxes.append([f, l, r, t, b, 1])\n            # negative data\n            t_down,  b_down  = t + h, b + h\n            #t_up,    b_up    = t - h, b - h\n            l_left,  r_left  = l - int(w/2), r - int(w/2)\n            l_right, r_right = l + int(w/2), r + int(w/2)\n            if check(l, r, t_down, b_down):\n                train_bboxes.append([f, l, r, t_down, b_down, 0])\n            #if check(l, r, t_up,   b_up):\n            #    train_bboxes.append([f, l, r, t_up,   b_up,   0])\n            if check(l_left,  r_left,  t, b):\n                train_bboxes.append([f, l_left,  r_left,  t, b, 0])\n            if check(l_right, r_right, t, b):\n                train_bboxes.append([f, l_right, r_right, t, b, 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:45.81634Z","iopub.execute_input":"2021-11-01T02:37:45.816688Z","iopub.status.idle":"2021-11-01T02:37:45.826948Z","shell.execute_reply.started":"2021-11-01T02:37:45.816656Z","shell.execute_reply":"2021-11-01T02:37:45.825748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG[\"make_dataset\"]:\n    df_train_bbox = pd.DataFrame(train_bboxes, columns=[\"path\",\"left\",\"right\",\"top\",\"bottom\",\"label\"])\n    df_train_bbox[\"conf\"] = 0.5\n    df_train_bbox.loc[df_train_bbox.label==1, \"conf\"] = 1\n    df_train_bbox[[\"left\",\"right\"]] /= 1280\n    df_train_bbox[[\"top\",\"bottom\"]] /= 720\n\n    print(df_train_bbox.shape)\n    df_train_bbox.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:46.719998Z","iopub.execute_input":"2021-11-01T02:37:46.720517Z","iopub.status.idle":"2021-11-01T02:37:46.725484Z","shell.execute_reply.started":"2021-11-01T02:37:46.720485Z","shell.execute_reply":"2021-11-01T02:37:46.724516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = None\niou_thr = 0.3\n\nif CFG[\"make_dataset\"]:\n    df_train_bbox_removed = pd.DataFrame()\n    for p in tqdm(df_train_bbox.path.unique()):\n        df = df_train_bbox[df_train_bbox.path==p].copy()\n        boxes  = [np.array(df[[\"left\",\"top\",\"right\",\"bottom\"]]).tolist()]\n        scores = [list(np.array(df.conf))]\n        labels = [list(np.ones(df.shape[0]))]\n        boxes, scores, labels = nms(boxes, scores, labels, weights=weights, iou_thr=iou_thr)\n        df_nms = pd.DataFrame(np.hstack([boxes, scores.reshape(-1,1)]))\n        df_nms[\"path\"] = p\n        df_train_bbox_removed = df_train_bbox_removed.append(df_nms)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:48.461171Z","iopub.execute_input":"2021-11-01T02:37:48.461698Z","iopub.status.idle":"2021-11-01T02:37:48.468994Z","shell.execute_reply.started":"2021-11-01T02:37:48.461652Z","shell.execute_reply":"2021-11-01T02:37:48.468015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG[\"make_dataset\"]:\n    df_train = df_train_bbox_removed.reset_index(drop=True)\n    df_train.columns = [\"left\",\"top\",\"right\",\"bottom\",\"conf\",\"path\"]\n    df_train[[\"left\",\"right\"]] = (df_train[[\"left\",\"right\"]] * 1280).astype(int)\n    df_train[[\"top\",\"bottom\"]] = (df_train[[\"top\",\"bottom\"]] *  720).astype(int)\n    df_train[\"width\"]  = df_train.right  - df_train.left\n    df_train[\"height\"] = df_train.bottom - df_train.top\n    df_train = df_train[[\"path\",\"left\",\"right\",\"width\",\"top\",\"bottom\",\"height\",\"conf\"]]\n    df_train[\"label\"]  = 1\n    df_train.loc[df_train.conf==0.5, \"label\"] = 0\n\n    df_train.right  = df_train.left + df_train.width  + (df_train.width /2*(CFG[\"width\"]  -1)).astype(int)\n    df_train.bottom = df_train.top  + df_train.height + (df_train.height/2*(CFG[\"height\"] -1)).astype(int)\n    df_train.left   = df_train.left - (df_train.width /2*(CFG[\"width\"]  -1)).astype(int)\n    df_train.top    = df_train.top  - (df_train.height/2*(CFG[\"height\"] -1)).astype(int)\n\n    df_train = df_train[(0<=df_train.left)&(df_train.right<=1280)&(0<=df_train.top)&(df_train.bottom<=720)]\n    df_train.to_csv(\"train.csv\", index=False)\nelse:\n    df_train = pd.read_csv(\"../input/nfl-helmet-assignment-cnn-models/train.csv\")\n    df_train.to_csv(\"train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:50.304674Z","iopub.execute_input":"2021-11-01T02:37:50.30524Z","iopub.status.idle":"2021-11-01T02:37:51.15378Z","shell.execute_reply.started":"2021-11-01T02:37:50.305189Z","shell.execute_reply":"2021-11-01T02:37:51.152774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train.shape)\ndf_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T02:37:51.155261Z","iopub.execute_input":"2021-11-01T02:37:51.155546Z","iopub.status.idle":"2021-11-01T02:37:51.169691Z","shell.execute_reply.started":"2021-11-01T02:37:51.155516Z","shell.execute_reply":"2021-11-01T02:37:51.168462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG[\"save_zip\"]:\n    \n    df_train = df_train.sort_values(\"path\").reset_index(drop=True)\n    \n    !rm -rf ./label0\n    !rm -rf ./label1    \n    os.makedirs(\"./label0\", exist_ok=True)\n    os.makedirs(\"./label1\", exist_ok=True)\n    \n    p_old = None\n    for (p, l, r, w, t, b, h, c, label) in tqdm(np.array(df_train)):\n        if os.path.isfile(p):\n            filename = os.path.basename(p)\n            if p_old != p:\n                img   = get_img(p)\n                p_old = p\n            cut_img = img[t:b, l:r]\n            cv2.imwrite(f\"./label{label}/{filename}\", cut_img)\n\n    shutil.make_archive(\"label0\", 'zip', root_dir=\"./label0\")\n    shutil.make_archive(\"label1\", 'zip', root_dir=\"./label1\")\n    !rm -rf ./label0\n    !rm -rf ./label1","metadata":{"execution":{"iopub.status.busy":"2021-11-01T03:00:32.0542Z","iopub.execute_input":"2021-11-01T03:00:32.054557Z","iopub.status.idle":"2021-11-01T03:00:35.700821Z","shell.execute_reply.started":"2021-11-01T03:00:32.054527Z","shell.execute_reply":"2021-11-01T03:00:35.699528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define model functions","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super(Model, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, 1)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:26:22.465992Z","iopub.execute_input":"2021-10-25T14:26:22.466501Z","iopub.status.idle":"2021-10-25T14:26:22.474054Z","shell.execute_reply.started":"2021-10-25T14:26:22.466464Z","shell.execute_reply":"2021-10-25T14:26:22.472477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NFLDataset(Dataset):\n    def __init__(self, df, transforms=None, output_label=True):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms   = transforms\n        self.output_label = output_label\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        left   = self.df.loc[index].left\n        right  = self.df.loc[index].right\n        top    = self.df.loc[index].top\n        bottom = self.df.loc[index].bottom\n        img    = get_img(self.df.loc[index].path)[top:bottom, left:right]\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        if self.output_label:\n            return img, torch.from_numpy(np.array(self.df.loc[index].label))\n        return img","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:26:23.590227Z","iopub.execute_input":"2021-10-25T14:26:23.590639Z","iopub.status.idle":"2021-10-25T14:26:23.601216Z","shell.execute_reply.started":"2021-10-25T14:26:23.590606Z","shell.execute_reply":"2021-10-25T14:26:23.599871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_transforms():\n    return Compose([\n            Resize(CFG['size'], CFG['size']),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            RandomRotate90(p=0.5),\n            MotionBlur(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RGBShift(p=0.5),\n            ChannelShuffle(p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)], p=1)\n  \ndef get_valid_transforms():\n    return Compose([\n            Resize(CFG['size'], CFG['size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)], p=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:26:24.614573Z","iopub.execute_input":"2021-10-25T14:26:24.614956Z","iopub.status.idle":"2021-10-25T14:26:24.625455Z","shell.execute_reply.started":"2021-10-25T14:26:24.614923Z","shell.execute_reply":"2021-10-25T14:26:24.623845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(train, valid):\n    train_ds = NFLDataset(train, transforms=get_train_transforms(), output_label=True)\n    valid_ds = NFLDataset(valid, transforms=get_valid_transforms(), output_label=True)\n    train_loader = torch.utils.data.DataLoader(train_ds,\n                                               batch_size=CFG['batch_size'],\n                                               drop_last=False,\n                                               pin_memory=False,\n                                               shuffle=True,\n                                               num_workers=CFG['num_workers'])\n    val_loader = torch.utils.data.DataLoader(valid_ds,\n                                             batch_size=CFG['batch_size'],\n                                             pin_memory=False,\n                                             shuffle=False,\n                                             num_workers=CFG['num_workers'])\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:26:25.740852Z","iopub.execute_input":"2021-10-25T14:26:25.741328Z","iopub.status.idle":"2021-10-25T14:26:25.748699Z","shell.execute_reply.started":"2021-10-25T14:26:25.741295Z","shell.execute_reply":"2021-10-25T14:26:25.747303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n    model.train()\n\n    t = time.time()\n    running_loss = None\n\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for step, (imgs, labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = labels.reshape(-1,1).to(device).float()\n\n        with autocast():\n            image_preds = model(imgs)\n            loss = loss_fn(image_preds, image_labels)\n            scaler.scale(loss).backward()\n\n            if running_loss is None:\n                running_loss = loss.item()\n            else:\n                running_loss = running_loss * .99 + loss.item() * .01\n\n            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad() \n                if scheduler is not None and schd_batch_update:\n                    scheduler.step()\n\n            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n                description = f'epoch {epoch} loss: {running_loss:.4f}'\n                pbar.set_description(description)\n                \n    if scheduler is not None and not schd_batch_update:\n        scheduler.step()\n        \ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n    model.eval()\n\n    t = time.time()\n    loss_sum   = 0\n    sample_num = 0\n    image_preds_all   = []\n    image_targets_all = []\n    \n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n    for step, (imgs, labels) in pbar:\n        imgs = imgs.to(device)\n        image_labels = labels.reshape(-1,1).to(device).float()\n        \n        image_preds = model(imgs)\n        image_preds_all   += [np.where(image_preds.detach().cpu().numpy()>0, 1, 0).reshape(1,-1)[0]]\n        image_targets_all += [np.array(labels)]\n        \n        loss = loss_fn(image_preds, image_labels)\n        loss_sum   += loss.item()*image_labels.shape[0]\n        sample_num += image_labels.shape[0]  \n\n        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n            pbar.set_description(description)\n            \n    image_preds_all   = np.concatenate(image_preds_all)\n    image_targets_all = np.concatenate(image_targets_all)\n    acc = (image_preds_all==image_targets_all).mean()\n    print('validation multi-class accuracy = {:.4f}'.format(acc))\n    \n    if scheduler is not None:\n        if schd_loss_update:\n            scheduler.step(loss_sum/sample_num)\n        else:\n            scheduler.step()\n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:26:26.765513Z","iopub.execute_input":"2021-10-25T14:26:26.76592Z","iopub.status.idle":"2021-10-25T14:26:26.785105Z","shell.execute_reply.started":"2021-10-25T14:26:26.765862Z","shell.execute_reply":"2021-10-25T14:26:26.783523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run training","metadata":{}},{"cell_type":"code","source":"print(df_train.shape)\nprint(df_train.label.value_counts())\n\ndf_train_label_0 = df_train[df_train.label==0].reset_index(drop=True)\ndf_train_label_1 = df_train[df_train.label==1].reset_index(drop=True)\ndf_train_label_0_sampled = df_train_label_0.sample(df_train_label_1.shape[0])\n\ndf_train = pd.concat([df_train_label_0_sampled, df_train_label_1]).reset_index(drop=True)\n\nprint(df_train.shape)\ndf_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:26:28.505456Z","iopub.execute_input":"2021-10-25T14:26:28.505836Z","iopub.status.idle":"2021-10-25T14:26:28.590149Z","shell.execute_reply.started":"2021-10-25T14:26:28.505805Z","shell.execute_reply":"2021-10-25T14:26:28.588663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG[\"train_model\"]:\n    train, valid = train_test_split(df_train, test_size=0.3, random_state=CFG[\"seed\"])\n    train = train.reset_index(drop=True)\n    valid = valid.reset_index(drop=True)\n    print(train.shape, valid.shape)\n    train_loader, val_loader = prepare_dataloader(train, valid)\n\n    not_improved_cnt = 0\n    best_acc = 0\n    device   = torch.device(CFG['device'])\n    model    = Model(CFG[\"model\"])\n    model.to(device)\n    scaler    = GradScaler()\n    optimizer = RAdam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n    scheduler = None\n    loss      = nn.BCEWithLogitsLoss().to(device)\n\n    for epoch in range(CFG['epochs']):\n        train_one_epoch(epoch, model, loss, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n\n        with torch.no_grad():\n            acc = valid_one_epoch(epoch, model, loss, val_loader, device, scheduler=None, schd_loss_update=False)\n\n        if best_acc < acc:\n            print('Best model will be saved to output path after completing this fold')\n            best_model = copy.deepcopy(model)\n            best_acc   = acc\n            not_improved_cnt = 0\n        elif CFG['early_stopping'] == not_improved_cnt:\n            print(\"Met early stopping.\")\n            break\n        else:\n            not_improved_cnt += 1  \n\n    torch.save(best_model.state_dict(), f'helmet_cnn.pt')\n\n    del model, optimizer, train_loader, val_loader, scaler\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T14:44:00.574573Z","iopub.execute_input":"2021-10-25T14:44:00.575054Z","iopub.status.idle":"2021-10-25T14:45:32.965203Z","shell.execute_reply.started":"2021-10-25T14:44:00.57502Z","shell.execute_reply":"2021-10-25T14:45:32.963028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./train","metadata":{"execution":{"iopub.status.busy":"2021-10-25T13:21:12.497218Z","iopub.execute_input":"2021-10-25T13:21:12.497648Z","iopub.status.idle":"2021-10-25T13:21:13.315702Z","shell.execute_reply.started":"2021-10-25T13:21:12.49755Z","shell.execute_reply":"2021-10-25T13:21:13.314298Z"},"trusted":true},"execution_count":null,"outputs":[]}]}