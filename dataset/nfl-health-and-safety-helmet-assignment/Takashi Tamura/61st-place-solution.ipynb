{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"First of all, congratulations to all winners and thanks to organizers. I have learned a lot from this competition, so I would like to share my solution here. I hope some pepole find new ideas from my solution.\n\nI joined this competition one month ago, and first I tried to implment YOLOv5 model to ensemble with baseline. However, my score had not been improved at all every time. I started focusing on postprocessing to remove over-detected BBoxes from baseline and add new BBoxes to baseline.\n\nThis solution consists of just adding postprocessing. The following is summary for it.\n- Use CNN helmet detector to remove over-detected BBoxes. (This does not work.)  \n  Training script: https://www.kaggle.com/ttkagglett/nfl-helmet-assignment-cnn-training/\n- Add new BBoxes to trace helmet.\n- Remove sideline helmets and some helmets that seemed wrong. Removing sideline helmets greatly improved my score.\n- Run my Re-ID module to re-assign labels. (I had no time to complete it correctly. But I believe idea is good.)\n\nThe detail is written in each section. If you have any questions, please let me know!","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/easydict-master/easydict-master/')\nsys.path.append('../input/weightedboxfusion/')\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\nsys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\n# Install helmet-assignment helper code\n!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport cv2\nimport yaml\nimport torch\nimport random\nimport shutil\nimport itertools\nimport subprocess\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom shutil import copyfile\nfrom multiprocessing import Pool\nfrom IPython.core.display import Video, display\nfrom scipy.spatial.distance import cdist\nfrom scipy.optimize import minimize, minimize_scalar\nfrom sklearn.neighbors import KDTree\nfrom sklearn.model_selection import train_test_split\nfrom ensemble_boxes import nms\n\nfrom helmet_assignment.score import NFLAssignmentScorer, check_submission\nfrom helmet_assignment.features import add_track_features\nfrom deep_sort.deep_sort import DeepSort\nfrom utils.parser import get_config\n\nimport timm\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torchvision import models\nfrom torchvision import transforms\n\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n    ShiftScaleRotate, CenterCrop, Resize)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:40:01.644177Z","iopub.execute_input":"2021-11-02T13:40:01.644563Z","iopub.status.idle":"2021-11-02T13:40:07.502847Z","shell.execute_reply.started":"2021-11-02T13:40:01.644524Z","shell.execute_reply":"2021-11-02T13:40:07.501905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"CFG = {\n    # If True, run fast submission.\n    \"nosave\"        : False, #True if len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/')) == 6 else False,\n    # Global setting\n    \"seed\"          : 42,\n    \"num_workers\"   : 4,\n    \"device\"        : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n    \"input_path\"    : '../input/nfl-health-and-safety-helmet-assignment/test/',\n    \"output_path\"   : \"./inference/\",\n    \"output_cnnpath\": \"./inference_cnn/\",\n    # Setting for own YOLOv5 model\n    \"use_own_models\": False,\n    \"save_zip\"      : False,\n    \"yolo_weight\"   : '../input/nfl-helmet-assignment-yolov5-models/result_0/best.pt ../input/nfl-helmet-assignment-yolov5-models/result_1/best.pt ../input/nfl-helmet-assignment-yolov5-models/result_2/best.pt',\n    \"yolo_size\"     : 800,\n    \"train_size\"    : (480, 800),\n    \"org_size\"      : (720, 1280),\n    \"thr_cut_area\"  : 0.2,\n    # Setting for postprocessing with cnn\n    \"model\"         : \"tf_efficientnetv2_s_in21k\",\n    \"batch_size\"    : 256,\n    \"cnn_weight\"    : '../input/nfl-helmet-assignment-cnn-models/helmet_cnn.pt',\n    \"cnn_size\"      : 128,\n    \"width\"         : 4,\n    \"height\"        : 4,\n    \"thr_do_cnn\"    : 0,\n    # Setting for ensembling baseline model and own model\n    \"thr_ens_iou\"   : 1,\n    \"thr_min_conf\"  : 0.4,\n    # Setting for postprocessing to trace helmet\n    \"add_helmet_num\": 10,\n    \"thr_strace_iou\": 0.2,\n    \"thr_etrace_iou\": 0.3,\n    \"thr_continuous\": 4,\n    \"thr_add_helmet\": 0.8,\n    \"thr_add_iou\"   : 0.5,\n    # Setting for postprocessing to delete FP helmet\n    \"thr_del_iou\"   : 0.3,\n    \"thr_del_trace\" : 10,\n    \"thr_del_conf\"  : 0.6,\n    # Setting for finding label with tracking data\n    \"dig_max\"       : 30,\n    \"dig_step\"      : 3,\n    \"max_iter\"      : 1000,\n    \"skip_reids\"    : True\n}\n\nCFG","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:46:33.801864Z","iopub.execute_input":"2021-11-02T13:46:33.802225Z","iopub.status.idle":"2021-11-02T13:46:33.814026Z","shell.execute_reply.started":"2021-11-02T13:46:33.802193Z","shell.execute_reply":"2021-11-02T13:46:33.813078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rescale(x, y, w, h, tr_h, tr_w, or_h, or_w):\n    # Rescale to training size\n    x_tr = x * tr_w\n    y_tr = y * tr_h\n    w_tr = w * tr_w\n    h_tr = h * tr_h\n    # Rescale to original size\n    x_or = int(or_w * x_tr / tr_w)\n    y_or = int(or_h * y_tr / tr_h)\n    w_or = int(or_w * w_tr / tr_w)\n    h_or = int(or_h * h_tr / tr_h)\n    # Minimum size should be 5.\n    # https://www.kaggle.com/c/nfl-health-and-safety-helmet-assignment/discussion/277388\n    w_or = 5 if w_or <= 5 else w_or\n    h_or = 5 if h_or <= 5 else h_or\n    # Calculate left and top by using center values\n    left = 0 if x_or - w_or/2 < 0 else x_or - int(w_or/2)\n    top  = 0 if y_or - h_or/2 < 0 else y_or - int(h_or/2)\n    return [left, w_or, top, h_or]\n\ndef read_label(target_file, train_shape, org_shape):\n    filename  = os.path.basename(target_file)[:-4]\n    frame_num = int(filename[filename.rfind(\"_\")+1:])\n    with open(target_file, 'r+') as file:\n        detect_result = file.read()\n    detect_result = list(map(float, re.split(r'[\\n ]', detect_result)[:-1]))\n    detect_result = np.array(detect_result).reshape(-1,6)\n    \n    detect_results = []\n    for i, v in enumerate(detect_result):\n        rescaled = rescale(*v[1:5], *train_shape, *org_shape)\n        detect_results.append([frame_num, filename,\n                               int(detect_result[i,0]), *rescaled, detect_result[i,5]])\n\n    return pd.DataFrame(detect_results, columns=[\"num\",\"video_frame\",\"label\",\"left\",\"width\",\"top\",\"height\",\"conf\"])\n\ndef get_range(df, org_size):\n    oh, ow = org_size[:2]\n    ratio  = ow/oh\n    x_min, x_max = df.left.min(),  df.right.max()\n    y_min, y_max = df.top.min(),   df.bottom.max()\n    w_max, h_max = df.width.max(), df.height.max()\n    x_min = 0  if x_min < w_max else x_min - w_max\n    x_max = ow if x_max > ow - w_max else x_max + w_max\n    y_min = 0  if y_min < h_max else y_min - h_max\n    y_max = oh if y_max > oh -h_max  else y_max + h_max\n    \n    cw = x_max - x_min\n    ch = y_max - y_min\n    rw = cw / ow\n    rh = ch / oh \n    if rw / rh > 0:\n        r = int((cw / ratio - ch) / 2)\n        y_min = 0  if y_min - r < 0  else y_min - r\n        y_max = oh if y_max + r > oh else y_max + r\n    else:\n        r = int((ch * ratio - cw) / 2)\n        x_min = 0  if x_min - r < 0  else x_min - r\n        x_max = ow if x_max + r > ow else x_max + r\n    \n    return x_min, x_max, y_min, y_max","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:52:00.153182Z","iopub.execute_input":"2021-11-02T13:52:00.15356Z","iopub.status.idle":"2021-11-02T13:52:00.169523Z","shell.execute_reply.started":"2021-11-02T13:52:00.153523Z","shell.execute_reply":"2021-11-02T13:52:00.168652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\nInference with own YOLOv5 model to detect helmet.","metadata":{}},{"cell_type":"code","source":"!mkdir /root/.config/Ultralytics\n!cp ../input/arial-font/arial.ttf /root/.config/Ultralytics/Arial.ttf\n!cp -r ../input/yolov5-11-march-2021/yolov5-master ./yolov5","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:52:00.868471Z","iopub.execute_input":"2021-11-02T13:52:00.868784Z","iopub.status.idle":"2021-11-02T13:52:03.485457Z","shell.execute_reply.started":"2021-11-02T13:52:00.868756Z","shell.execute_reply":"2021-11-02T13:52:03.484342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline = pd.read_csv(f'../input/nfl-health-and-safety-helmet-assignment/test_baseline_helmets.csv')\nbaseline[\"right\"]  = baseline.left + baseline.width\nbaseline[\"bottom\"] = baseline.top  + baseline.height\nbaseline.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:52:03.489244Z","iopub.execute_input":"2021-11-02T13:52:03.489536Z","iopub.status.idle":"2021-11-02T13:52:03.617022Z","shell.execute_reply.started":"2021-11-02T13:52:03.489506Z","shell.execute_reply":"2021-11-02T13:52:03.616264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndf_all_results = pd.DataFrame()\n\nif not CFG[\"nosave\"] and CFG[\"use_own_models\"]:\n    for f in os.listdir(CFG[\"input_path\"]):\n        !rm -rf ./inference/\n\n        in_path      = CFG[\"input_path\"]  + f\n        out_img_path = CFG[\"output_path\"] + \"frames/\"\n        out_cut_path = CFG[\"output_path\"] + \"cut_frames/\"\n        out_res_path = CFG[\"output_path\"] + f[:-4]\n        image_name   = f[:-4]\n        extention    = \"jpg\"\n        # Make save directories\n        os.makedirs(out_img_path, exist_ok=True)\n        os.makedirs(out_cut_path, exist_ok=True)\n        os.makedirs(out_res_path, exist_ok=True)\n        # Split into frames\n        cmd = 'ffmpeg -i \\\"{}\\\" -qscale:v 2 \\\"{}/{}_%d.{}\\\"'.format(in_path, out_img_path, image_name, extention)\n        subprocess.call(cmd, shell=True)\n\n        # Cut the area for expanding helmet size\n        df_baseline_cut = pd.DataFrame()\n        for f in tqdm(os.listdir(out_img_path)):\n            df = baseline[(baseline.video_frame==f[:-4])&(baseline.conf>CFG[\"thr_cut_area\"])].copy()\n            x_min, x_max, y_min, y_max = get_range(df, CFG[\"org_size\"])\n            img = cv2.imread(out_img_path + f)\n            img_cut = img[y_min:y_max, x_min:x_max]\n            df[\"x_min\"] = x_min\n            df[\"x_max\"] = x_max\n            df[\"y_min\"] = y_min\n            df[\"y_max\"] = y_max\n            cv2.imwrite(out_cut_path + f, img_cut)\n            df_baseline_cut = df_baseline_cut.append(df)\n        df_baseline_cut = df_baseline_cut[[\"video_frame\",\"x_min\",\"x_max\",\"y_min\",\"y_max\"]].drop_duplicates()\n        df_baseline_cut.reset_index(drop=True, inplace=True)\n\n        # Detect helmets with YOLOv5\n        if CFG[\"save_zip\"]:\n            !python ./yolov5/detect.py \\\n                          --weights {CFG[\"yolo_weight\"]} \\\n                          --source {out_img_path} \\\n                          --img {CFG[\"yolo_size\"]} \\\n                          --device 0 \\\n                          --save-txt \\\n                          --save-conf \\\n                          --project {out_res_path}\n            # Save for debugging results\n            shutil.make_archive(f\"{image_name}_{i}\", 'zip', root_dir=out_res_path)\n        else:\n            !python ./yolov5/detect.py \\\n                          --weights {CFG[\"yolo_weight\"]} \\\n                          --source {out_cut_path} \\\n                          --img {CFG[\"yolo_size\"]} \\\n                          --device 0 \\\n                          --nosave \\\n                          --save-txt \\\n                          --save-conf \\\n                          --project {out_res_path}\n\n        # Read all of results\n        label_path = out_res_path + \"/exp/labels/\"\n        df_results = pd.DataFrame()\n        for l in os.listdir(label_path):\n            df_resize2org = df_baseline_cut[df_baseline_cut.video_frame==l[:-4]]\n            or_h = df_resize2org.y_max - df_resize2org.y_min\n            or_w = df_resize2org.x_max - df_resize2org.x_min\n            df_res = read_label(label_path + l, CFG[\"train_size\"], (or_h,or_w))\n            df_results = df_results.append(df_res)\n        df_results = df_results.sort_values(\"num\").reset_index(drop=True)\n        # Adjust left and top with cropped area\n        df_results = df_results.merge(df_baseline_cut, on=\"video_frame\")\n        df_results[\"left\"] += df_results[\"x_min\"]\n        df_results[\"top\"]  += df_results[\"y_min\"]\n        df_all_results = df_all_results.append(df_results)\n\n    df_all_results.reset_index(drop=True, inplace=True)\nelse:\n    df_all_results = pd.DataFrame([], columns=[\"num\",\"label\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:52:03.619842Z","iopub.execute_input":"2021-11-02T13:52:03.620476Z","iopub.status.idle":"2021-11-02T13:52:03.651799Z","shell.execute_reply.started":"2021-11-02T13:52:03.620424Z","shell.execute_reply":"2021-11-02T13:52:03.651015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_all_results.shape)\ndf_all_results.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:52:03.653001Z","iopub.execute_input":"2021-11-02T13:52:03.653346Z","iopub.status.idle":"2021-11-02T13:52:03.663091Z","shell.execute_reply.started":"2021-11-02T13:52:03.653293Z","shell.execute_reply":"2021-11-02T13:52:03.662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_results.to_csv(\"yolo_results.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:52:03.664775Z","iopub.execute_input":"2021-11-02T13:52:03.665647Z","iopub.status.idle":"2021-11-02T13:52:03.673213Z","shell.execute_reply.started":"2021-11-02T13:52:03.665603Z","shell.execute_reply":"2021-11-02T13:52:03.672247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble with baseline\nIn this competition, baseline result has been provided by organizer, so ensemble baseline result with own model results generated above.","metadata":{}},{"cell_type":"code","source":"baseline      = pd.read_csv(f'../input/nfl-health-and-safety-helmet-assignment/test_baseline_helmets.csv')\nmodel_results = df_all_results.drop([\"num\",\"label\"], axis=1).copy()\ndf_with_baseline = pd.concat([model_results, baseline])\ndf_with_baseline = df_with_baseline[(df_with_baseline.width>0)&(df_with_baseline.height>0)]\ndf_with_baseline = df_with_baseline[df_with_baseline.conf>CFG[\"thr_min_conf\"]].reset_index(drop=True)\ndf_with_baseline[\"label\"]   = 0\ndf_with_baseline[\"right\"]   = df_with_baseline.left + df_with_baseline.width\ndf_with_baseline[\"bottom\"]  = df_with_baseline.top  + df_with_baseline.height\ndf_with_baseline[\"left\"]   /= 1280\ndf_with_baseline[\"right\"]  /= 1280\ndf_with_baseline[\"top\"]    /= 720\ndf_with_baseline[\"bottom\"] /= 720\n\nprint(baseline.shape, model_results.shape, df_with_baseline.shape)\ndf_with_baseline.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:15.009369Z","iopub.execute_input":"2021-11-02T13:53:15.009722Z","iopub.status.idle":"2021-11-02T13:53:15.110643Z","shell.execute_reply.started":"2021-11-02T13:53:15.009693Z","shell.execute_reply":"2021-11-02T13:53:15.109742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG[\"thr_ens_iou\"] < 1:\n    # Run NMS to delete duplicate BBoxes.\n    df_ensembled = pd.DataFrame()\n    for v in tqdm(df_with_baseline.video_frame.unique()):\n        df = df_with_baseline[df_with_baseline.video_frame==v].copy()\n        boxes  = [np.array(df[[\"left\",\"top\",\"right\",\"bottom\"]]).tolist()]\n        scores = [list(np.array(df.conf))]\n        labels = [list(np.array(df.label))]\n        boxes, scores, labels = nms(boxes, scores, labels, weights=None, iou_thr=CFG[\"thr_ens_iou\"])\n        df_nms = pd.DataFrame(np.hstack([boxes, scores.reshape(-1,1)]))\n        df_nms[\"video_frame\"] = v\n        df_ensembled = df_ensembled.append(df_nms)\nelse:\n    df_ensembled = df_with_baseline[[\"left\",\"top\",\"right\",\"bottom\",\"conf\",\"video_frame\"]].copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:15.527657Z","iopub.execute_input":"2021-11-02T13:53:15.527939Z","iopub.status.idle":"2021-11-02T13:53:15.542883Z","shell.execute_reply.started":"2021-11-02T13:53:15.527913Z","shell.execute_reply":"2021-11-02T13:53:15.541951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ensembled.columns   = [\"left\",\"top\",\"right\",\"bottom\",\"conf\",\"video_frame\"]\ndf_ensembled[\"left\"]   = (df_ensembled.left *1280).astype(int)\ndf_ensembled[\"right\"]  = (df_ensembled.right*1280).astype(int)\ndf_ensembled[\"top\"]    = (df_ensembled.top   *720).astype(int)\ndf_ensembled[\"bottom\"] = (df_ensembled.bottom*720).astype(int)\ndf_ensembled[\"width\"]  = df_ensembled.right  - df_ensembled.left\ndf_ensembled[\"height\"] = df_ensembled.bottom - df_ensembled.top\ndf_ensembled = df_ensembled[[\"video_frame\",\"left\",\"width\",\"top\",\"height\",\"conf\"]]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:16.030357Z","iopub.execute_input":"2021-11-02T13:53:16.03069Z","iopub.status.idle":"2021-11-02T13:53:16.053879Z","shell.execute_reply.started":"2021-11-02T13:53:16.030659Z","shell.execute_reply":"2021-11-02T13:53:16.053004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_ensembled.shape)\ndf_ensembled.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:16.439763Z","iopub.execute_input":"2021-11-02T13:53:16.440109Z","iopub.status.idle":"2021-11-02T13:53:16.451568Z","shell.execute_reply.started":"2021-11-02T13:53:16.440078Z","shell.execute_reply":"2021-11-02T13:53:16.450677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ensembled.to_csv(\"ensembled_results.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:16.951688Z","iopub.execute_input":"2021-11-02T13:53:16.951994Z","iopub.status.idle":"2021-11-02T13:53:17.179892Z","shell.execute_reply.started":"2021-11-02T13:53:16.951966Z","shell.execute_reply":"2021-11-02T13:53:17.179018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprosessing\nRemove over-detected helmet BBoxes by using CNN helmet detector.","metadata":{}},{"cell_type":"code","source":"def check(l, r, t, b):\n    if l < 0 or 1280 < r:\n        return False\n    if t < 0 or 720 < b:\n        return False\n    return True\n\ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:18.92355Z","iopub.execute_input":"2021-11-02T13:53:18.923875Z","iopub.status.idle":"2021-11-02T13:53:18.929185Z","shell.execute_reply.started":"2021-11-02T13:53:18.923845Z","shell.execute_reply":"2021-11-02T13:53:18.928156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super(Model, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, 1)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output\n\nclass NFLDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms   = transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        img = get_img(self.df.loc[index]['path'])\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        return img\n    \ndef get_inference_transforms():\n    return Compose([\n            Resize(CFG['cnn_size'], CFG['cnn_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)], p=1)\n\ndef inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        image_preds = model(imgs)\n        image_preds_all += [image_preds.detach().cpu().numpy()]\n        \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:53:19.52209Z","iopub.execute_input":"2021-11-02T13:53:19.522421Z","iopub.status.idle":"2021-11-02T13:53:19.534354Z","shell.execute_reply.started":"2021-11-02T13:53:19.522389Z","shell.execute_reply":"2021-11-02T13:53:19.533164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and 0 < CFG[\"thr_do_cnn\"]:\n    !rm -rf ./inference/\n    !rm -rf {CFG['output_cnnpath']}\n\n    cnn_results = []\n    for f in os.listdir(CFG[\"input_path\"]):\n        !rm -rf ./inference/\n\n        print(f)\n        in_path      = CFG[\"input_path\"]  + f\n        out_img_path = CFG[\"output_path\"] + \"frames/\"\n        out_res_path = f\"{CFG['output_cnnpath']}{f}/\"\n        image_name = f[:-4]\n        extention  = \"jpg\"\n        # Make save directories\n        os.makedirs(out_img_path, exist_ok=True)\n        os.makedirs(out_res_path, exist_ok=True)\n        # Split into frames\n        cmd = 'ffmpeg -i \\\"{}\\\" -qscale:v 2 \\\"{}/{}_%d.{}\\\"'.format(in_path, out_img_path, image_name, extention)\n        subprocess.call(cmd, shell=True)\n\n        for f2 in tqdm(os.listdir(out_img_path)):\n            img = cv2.imread(out_img_path + f2)\n            df  = df_ensembled[df_ensembled.video_frame==f2[:-4]].reset_index(drop=True)\n            for i, (l, w, t, h, c) in df[[\"left\",\"width\",\"top\",\"height\",\"conf\"]].iterrows():\n                # Expand the cut size. The helmet should be placed center of image.\n                l, w, t, h = int(l), int(w), int(t), int(h)\n                ad_r = l + w + int(w/2*(CFG[\"width\"] -1))\n                ad_b = t + h + int(h/2*(CFG[\"height\"]-1))\n                ad_l = l - int(w/2*(CFG[\"width\"] -1))\n                ad_t = t - int(h/2*(CFG[\"height\"]-1))\n                path = \"\"\n                do_inference = False\n                # If expanded size is over the original size, it will not be used in prediction.\n                if c < CFG[\"thr_do_cnn\"] and check(ad_l, ad_r, ad_t, ad_b):\n                    path = f\"{out_res_path}{f2.replace('.jpg',f'_{i}.jpg')}\"\n                    cv2.imwrite(path, img[ad_t:ad_b, ad_l:ad_r])\n                    do_inference = True\n                cnn_results.append([f2[:-4], path, l, w, t, h, do_inference])\n\n        !rm -rf {out_img_path}","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:51.697596Z","iopub.execute_input":"2021-11-02T13:57:51.697918Z","iopub.status.idle":"2021-11-02T13:57:51.7346Z","shell.execute_reply.started":"2021-11-02T13:57:51.697882Z","shell.execute_reply":"2021-11-02T13:57:51.733411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and 0 < CFG[\"thr_do_cnn\"]:\n    df_inference = pd.DataFrame(cnn_results, columns=[\"video_frame\",\"path\",\"left\",\"width\",\"top\",\"height\",\"do_inference\"])\n\n    print(df_inference.do_inference.value_counts())\n    print(df_inference.shape)\n    df_inference.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:51.736349Z","iopub.execute_input":"2021-11-02T13:57:51.736704Z","iopub.status.idle":"2021-11-02T13:57:51.748558Z","shell.execute_reply.started":"2021-11-02T13:57:51.73667Z","shell.execute_reply":"2021-11-02T13:57:51.747667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and 0 < CFG[\"thr_do_cnn\"]:\n    # Define a model (EfficientNetV2)\n    model = Model(CFG['model'], pretrained=False)\n    model.load_state_dict(torch.load(CFG['cnn_weight']))\n    model.to(CFG[\"device\"])\n\n    dataset = NFLDataset(df_inference[df_inference.do_inference],\n                         transforms=get_inference_transforms())\n    data_loader = torch.utils.data.DataLoader(dataset, \n                                              batch_size=CFG['batch_size'],\n                                              num_workers=CFG['num_workers'],\n                                              shuffle=False,\n                                              pin_memory=False)\n\n    with torch.no_grad():\n        preds = inference_one_epoch(model, data_loader, CFG[\"device\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:51.907639Z","iopub.execute_input":"2021-11-02T13:57:51.907994Z","iopub.status.idle":"2021-11-02T13:57:51.91398Z","shell.execute_reply.started":"2021-11-02T13:57:51.907958Z","shell.execute_reply":"2021-11-02T13:57:51.91311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and 0 < CFG[\"thr_do_cnn\"]:\n    df_inference_done = df_inference[df_inference.do_inference].copy()\n    df_inference_done[\"pred\"] = preds\n    # Concatenate results of CNN and the original data that is not used in CNN.\n    df_inference = pd.concat([df_inference_done,\n                              df_inference[df_inference.do_inference==False]]).reset_index(drop=True)\n    df_inference.loc[df_inference.pred.isnull(), \"pred\"] = 1\n\n    print(df_ensembled.shape)\n    merge_cols   = [\"video_frame\",\"left\",\"width\",\"top\",\"height\"]\n    df_ensembled = df_ensembled.merge(df_inference[(df_inference.pred > 0)][merge_cols], on=merge_cols)\n    df_ensembled.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:52.426677Z","iopub.execute_input":"2021-11-02T13:57:52.426971Z","iopub.status.idle":"2021-11-02T13:57:52.433125Z","shell.execute_reply.started":"2021-11-02T13:57:52.426943Z","shell.execute_reply":"2021-11-02T13:57:52.431922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_ensembled.shape)\ndf_ensembled.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:53.024742Z","iopub.execute_input":"2021-11-02T13:57:53.025088Z","iopub.status.idle":"2021-11-02T13:57:53.038886Z","shell.execute_reply.started":"2021-11-02T13:57:53.025056Z","shell.execute_reply":"2021-11-02T13:57:53.037787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ensembled.to_csv(\"ensembled_results_with_postprocessing.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:53.844075Z","iopub.execute_input":"2021-11-02T13:57:53.844417Z","iopub.status.idle":"2021-11-02T13:57:54.100789Z","shell.execute_reply.started":"2021-11-02T13:57:53.844384Z","shell.execute_reply":"2021-11-02T13:57:54.099844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprocessing to trace helmets\nIn this section, I implemented tracing module. This competition data is video and fps is around 60, so if the helmet can not be detected specific image, we can add BBoxes by using before and after BBoxes infomation.","metadata":{}},{"cell_type":"code","source":"def calc_iou(a, b):\n    # Calculate 1:N IoU\n    a_area = (a[2] - a[0] + 1)     * (a[3] - a[1] + 1)\n    b_area = (b[:,2] - b[:,0] + 1) * (b[:,3] - b[:,1] + 1)\n    \n    abx_mn = np.maximum(a[0], b[:,0]) # xmin\n    aby_mn = np.maximum(a[1], b[:,1]) # ymin\n    abx_mx = np.minimum(a[2], b[:,2]) # xmax\n    aby_mx = np.minimum(a[3], b[:,3]) # ymax\n    w = np.maximum(0, abx_mx - abx_mn + 1)\n    h = np.maximum(0, aby_mx - aby_mn + 1)\n    intersect = w*h\n    \n    iou = intersect / (a_area + b_area - intersect)\n    return iou\n\ndef get_sorted_idx(c, n):\n    # Get IoU ordered list. High IoU BBox is prioritized.\n    next_helmets = np.array([n.left, n.top, n.right, n.bottom]).T\n    idx_ious     = [[idx, calc_iou(np.array([cv[1], cv[3], cv[9], cv[10]]), next_helmets).max()] for idx, cv in enumerate(np.array(c))]\n    idx_ious     = np.array(idx_ious)\n    sorted_idx   = idx_ious[np.argsort(idx_ious[:, 1])][::-1]\n    sorted_idx   = (sorted_idx[:, 0]).astype(int)\n    return sorted_idx\n\ndef check_and_recalc(l, w, t, h):\n    if l < 0:\n        l = 0\n    if 1280 < l + w:\n        w = 1280 - l\n    if t < 0:\n        t = 0\n    if 720 < t + h:\n        h = 720 - t\n    return l, w, t, h\n\ndef check_add_data(df1, df2, helmet_id):\n    # Width and height should be over 5 for DeepSort.\n    if df1.width < 5 or df1.height < 5:\n        return False\n    if CFG[\"add_helmet_num\"] <= df1.added:\n        return False\n    if CFG[\"thr_add_helmet\"] <= df1.conf:\n        return True\n    if CFG[\"thr_continuous\"] <= df2[df2.helmet==helmet_id].shape[0]:\n        return True\n    return False\n\ndef trace(df):\n    df = df.copy()\n    \n    for v in tqdm(df.video.unique()):\n        df_video = df[df.video==v].copy()\n        thr_trace_iou = CFG['thr_strace_iou'] if -1 < v.find(\"Side\") else CFG[\"thr_etrace_iou\"]\n        max_helmet_no = 0\n        max_frame_no  = df_video.frame.max()\n        for idx, f in enumerate(sorted(df_video.frame.unique())):\n            df_curt_video   = df_video[df_video.frame==f].reset_index(drop=True)\n            df_next_video   = df_video[df_video.frame==f+1].reset_index(drop=True)\n            dict_next_video = df_next_video.T.to_dict()\n            if max_frame_no < f+1:\n                continue\n            # Sort with IoU\n            idxes = get_sorted_idx(df_curt_video, df_next_video)\n            for helmet in idxes:\n                l, r = df_curt_video.left[helmet], df_curt_video.right[helmet]\n                t, b = df_curt_video.top[helmet],  df_curt_video.bottom[helmet]\n                # Calcurate distance of target bbox and next frame bboxes. \n                curt_helmet  = np.array([[l, t, r, b]])\n                next_helmets = np.array(df_next_video[[\"left\",\"top\",\"right\",\"bottom\"]])\n                nearest_idx  = np.argmin(cdist(curt_helmet, next_helmets))\n                # Calculate IoU of target bbox and the nearest next frame bbox.\n                curt_helmet  = np.array([l, t, r, b])\n                next_helmet  = np.array([next_helmets[nearest_idx]])\n                iou = calc_iou(curt_helmet, next_helmet)\n                \n                # Tracing is successful\n                if thr_trace_iou <= iou and dict_next_video[nearest_idx][\"helmet\"] is None:\n                    h  = df_curt_video.helmet[helmet]\n                    a  = df_curt_video.added[helmet]\n                    cv = df_curt_video.video_frame[helmet]\n                    d  = dict_next_video[nearest_idx]\n                    nv, nl, nt, nr, nb = d[\"video_frame\"], d[\"left\"], d[\"top\"], d[\"right\"], d[\"bottom\"]\n                    if h is None:\n                        # New detected helmet\n                        helmet_id = max_helmet_no\n                        max_helmet_no += 1\n                    else:\n                        # Tracing helmet\n                        helmet_id = h\n                    if 0 < a:\n                        # Re-detected helmet successfully.\n                        # If failed to re-detect helmet, bboxes added will be removed after this module.\n                        df_video.loc[df_video.helmet==helmet_id, \"added\"] = 0\n                    if idx==0:\n                        df_video.loc[(df_video.video_frame==cv)&(df_video.left==l)&(df_video.top==t)&(df_video.right==r)&(df_video.bottom==b),\n                                     \"helmet\"] = helmet_id\n                    df_video.loc[(df_video.video_frame==nv)&(df_video.left==nl)&(df_video.top==nt)&(df_video.right==nr)&(df_video.bottom==nb),\n                                 [\"helmet\",\"x_move\",\"y_move\"]] = [helmet_id, nl-l, nt-t]\n                    dict_next_video[nearest_idx][\"helmet\"] = helmet_id\n                    \n                # Failed to trace because of no helmet at the nearest location.\n                else:\n                    # Add new bbox.\n                    if df_curt_video.helmet[helmet] is not None:\n                        df_add = df_curt_video.iloc[helmet,:].copy()\n                        # Add movement amount of previous image\n                        df_add[\"left\"] += df_add.x_move\n                        df_add[\"top\"]  += df_add.y_move\n                        df_add[[\"left\",\"width\",\"top\",\"height\"]] = check_and_recalc(df_add.left, df_add.width, df_add.top, df_add.height)\n                        if check_add_data(df_add, df_video, df_curt_video.helmet[helmet]):\n                            df_add[\"video_frame\"] = v + \"_\" + str(f+1)\n                            df_add[\"frame\"]  = f+1\n                            df_add[\"right\"]  = df_add.left + df_add.width\n                            df_add[\"bottom\"] = df_add.top  + df_add.height\n                            df_add[\"conf\"]   = CFG[\"thr_min_conf\"]+0.01\n                            df_add[\"added\"] += 1\n                            df_video = df_video.append(df_add)\n        df = df[df.video != v]\n        df = df.append(df_video).reset_index(drop=True)\n        \n    df.reset_index(drop=True, inplace=True)\n    return df\n\ndef delete_sideline_helmets(df, df_side):\n    # Detect and delete sideline helmet for Sideline video.\n    df = df.copy()\n    \n    df_sideline_deleted = pd.DataFrame()\n    for v in tqdm(df[df.video.str.contains(\"Side\")].video.unique()):\n        df_video  = df[df.video==v].reset_index(drop=True)\n        direction = df_side[df_side.video==v].y_move_total.values[0]\n\n        olds      = None\n        mean_move = 0\n        for f in sorted(df_video.frame.unique()):\n            df_this_frame = df_video[df_video.frame==f].copy()\n            l_min = df_this_frame.left.min()\n            r_max = df_this_frame.right.max()\n            t_min = df_this_frame.top.min()\n            b_max = df_this_frame.bottom.max()\n\n            if olds is None:\n                # Save previous max detected area.\n                olds = np.array([l_min, r_max, t_min, b_max])\n            else:\n                # Compare with previous area.\n                diff_move = np.array([l_min, r_max, t_min, b_max]) - olds\n                diff_move = np.sum(np.abs(diff_move))\n                if   10 <= f < 20:\n                    mean_move += diff_move\n                elif f == 20:\n                    # Calculate threthold for detecting sideline helmets.\n                    mean_move /= 10\n                elif 20 < f and mean_move*3 < diff_move:\n                    if 0 <= direction:\n                        # Players move to upper side. Sideline helmets appear in top of image.\n                        df_video.loc[(df_video.frame==f)&(df_video.bottom <= 120), \"width\"] = 0\n                    else:\n                        # Players move to under side. Sideline helmets appear in bottom of image.\n                        df_video.loc[(df_video.frame==f)&(630 <= df_video.top), \"width\"] = 0\n\n                    # Delete all of helmets that have the same ids\n                    df_delete_helmet_ids = df_video[(df_video.frame==f)&\n                                                    (df_video.width==0)&\n                                                    (df_video.helmet.notnull())].helmet.unique()\n                    if 0 < len(df_delete_helmet_ids):\n                        df_video = df_video[~df_video.helmet.isin(df_delete_helmet_ids)].copy()\n                    # Save new area without sideline helmets\n                    df_this_frame = df_video[(df_video.frame==f)&(df_video.width!=0)].copy()\n                    l_min = df_this_frame.left.min()\n                    r_max = df_this_frame.right.max()\n                    t_min = df_this_frame.top.min()\n                    b_max = df_this_frame.bottom.max()\n                # Save previous max detected area to use in next frame\n                olds = np.array([l_min, r_max, t_min, b_max])\n\n        df_sideline_deleted = df_sideline_deleted.append(df_video[df_video.width!=0])\n\n    df_sideline_deleted = pd.concat([df[df.video.str.contains(\"End\")], df_sideline_deleted])\n    return df_sideline_deleted.reset_index(drop=True)\n\ndef get_delete_bbox(df):\n    # Delete helmet if there is no helmets before and after target frame\n    df = df.copy()\n    df_delete_boxes = pd.DataFrame()\n    for v in tqdm(df.video.unique()):\n        df_video = df[(df.video==v)].copy()\n        n_max    = df_video.frame.max() - 1\n        for frame2 in range(2, n_max):\n            frame1 = frame2 - 1\n            frame3 = frame2 + 1\n            df_this_frame = df_video[(df_video.frame.isin([frame1, frame2, frame3]))].copy()\n            if df_this_frame.shape[0]==0:\n                continue\n            df_this_frame.loc[df_this_frame.frame==frame1, \"conf\"] = 0.7\n            df_this_frame.loc[df_this_frame.frame==frame2, \"conf\"] = 0.5  # Will be minimum\n            df_this_frame.loc[df_this_frame.frame==frame3, \"conf\"] = 1\n            boxes  = [np.array(df_this_frame[[\"left\",\"top\",\"right\",\"bottom\"]]).tolist()]\n            scores = [list(np.array(df_this_frame.conf))]\n            labels = [list(np.array(df_this_frame.label))]\n            boxes, scores, labels = nms(boxes, scores, labels, weights=None, iou_thr=CFG[\"thr_del_iou\"])\n            delete_boxes = boxes[np.where(scores==0.5)[0]]\n            delete_boxes = pd.DataFrame(delete_boxes)\n            delete_boxes[\"video_frame\"] = v + \"_\" + str(frame2)\n            df_delete_boxes = df_delete_boxes.append(delete_boxes)\n    df_delete_boxes.columns = [\"left\",\"top\",\"right\",\"bottom\",\"video_frame\"]\n    return df_delete_boxes.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:55.801166Z","iopub.execute_input":"2021-11-02T13:57:55.801515Z","iopub.status.idle":"2021-11-02T13:57:55.850193Z","shell.execute_reply.started":"2021-11-02T13:57:55.801482Z","shell.execute_reply":"2021-11-02T13:57:55.849247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add BBoxes to trace helmets","metadata":{}},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    df_ensembled[\"video\"]  = df_ensembled.video_frame.apply(lambda x: \"_\".join(x.split(\"_\")[:3]))\n    df_ensembled[\"frame\"]  = df_ensembled.video_frame.apply(lambda x: x.split(\"_\")[3]).astype(int)\n    df_ensembled[\"label\"]  = 1\n    df_ensembled[\"right\"]  = df_ensembled.left + df_ensembled.width\n    df_ensembled[\"bottom\"] = df_ensembled.top  + df_ensembled.height\n    df_ensembled[\"x_move\"] = 0\n    df_ensembled[\"y_move\"] = 0\n    df_ensembled[\"helmet\"] = None\n    df_ensembled[\"added\"]  = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:58.353145Z","iopub.execute_input":"2021-11-02T13:57:58.353511Z","iopub.status.idle":"2021-11-02T13:57:58.448878Z","shell.execute_reply.started":"2021-11-02T13:57:58.353475Z","shell.execute_reply":"2021-11-02T13:57:58.448073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    df_ensembled = trace(df_ensembled)\n    df_ensembled = df_ensembled[df_ensembled.added==0].reset_index(drop=True)\n    print(df_ensembled.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:57:59.88681Z","iopub.execute_input":"2021-11-02T13:57:59.887134Z","iopub.status.idle":"2021-11-02T14:03:12.022125Z","shell.execute_reply.started":"2021-11-02T13:57:59.887106Z","shell.execute_reply":"2021-11-02T14:03:12.021362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_ensembled.shape)\ndf_ensembled.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:29.453335Z","iopub.execute_input":"2021-11-02T14:09:29.453668Z","iopub.status.idle":"2021-11-02T14:09:29.47379Z","shell.execute_reply.started":"2021-11-02T14:09:29.453638Z","shell.execute_reply":"2021-11-02T14:09:29.472714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ensembled.to_csv(\"ensembled_results_with_post_trace.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:30.073528Z","iopub.execute_input":"2021-11-02T14:09:30.073849Z","iopub.status.idle":"2021-11-02T14:09:30.593165Z","shell.execute_reply.started":"2021-11-02T14:09:30.07382Z","shell.execute_reply":"2021-11-02T14:09:30.592274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Delete sideline helmets","metadata":{}},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    df_side = df_ensembled.copy()\n    df_side_frame = df_side.groupby(\"video\", as_index=False).frame.max()\n    df_side_frame.columns = [\"video\",\"frame_last\"]\n    df_side_frame[\"frame_half\"] = (df_side_frame.frame_last/2).astype(int)\n    df_side_frame[\"frame_4_3\"]  = (df_side_frame.frame_last - (df_side_frame.frame_half/2)).astype(int)\n    df_side = df_side.merge(df_side_frame, on=\"video\")\n\n    df_direction = df_side[df_side.frame_half <= df_side.frame].groupby(\"video\", as_index=False).agg({\"x_move\":\"mean\", \"y_move\":\"mean\"})\n    df_direction.columns = [\"video\",\"x_move_total\",\"y_move_total\"]\n    df_side = df_side_frame.merge(df_direction, on=\"video\")\n    \n    df_ensembled = delete_sideline_helmets(df_ensembled, df_side)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:35.004981Z","iopub.execute_input":"2021-11-02T14:09:35.005357Z","iopub.status.idle":"2021-11-02T14:09:38.972033Z","shell.execute_reply.started":"2021-11-02T14:09:35.005299Z","shell.execute_reply":"2021-11-02T14:09:38.970539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_ensembled.shape)\ndf_ensembled.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:40.102123Z","iopub.execute_input":"2021-11-02T14:09:40.102463Z","iopub.status.idle":"2021-11-02T14:09:40.121535Z","shell.execute_reply.started":"2021-11-02T14:09:40.10243Z","shell.execute_reply":"2021-11-02T14:09:40.120355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ensembled.to_csv(\"ensembled_results_with_post_trace_del.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:40.922935Z","iopub.execute_input":"2021-11-02T14:09:40.92327Z","iopub.status.idle":"2021-11-02T14:09:41.29227Z","shell.execute_reply.started":"2021-11-02T14:09:40.923238Z","shell.execute_reply":"2021-11-02T14:09:41.290753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Delete helmet if there is no helmets before and after target frame","metadata":{}},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    df_ensembled[\"left\"]   /= 1280\n    df_ensembled[\"right\"]  /= 1280\n    df_ensembled[\"top\"]    /=720\n    df_ensembled[\"bottom\"] /=720\n    \n    df_delete_boxes = get_delete_bbox(df_ensembled)\n    df_delete_boxes[\"delete\"] = 1\n    print(df_delete_boxes.shape)\n    \n    df_deleted = df_ensembled.merge(df_delete_boxes, on=[\"left\",\"top\",\"right\",\"bottom\",\"video_frame\"], how=\"left\")\n    df_deleted.loc[CFG['thr_del_conf'] <= df_deleted.conf, \"delete\"] = np.nan\n    df_deleted = df_deleted[df_deleted.delete.isnull()].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:42.481093Z","iopub.execute_input":"2021-11-02T14:09:42.48142Z","iopub.status.idle":"2021-11-02T14:09:57.166499Z","shell.execute_reply.started":"2021-11-02T14:09:42.481391Z","shell.execute_reply":"2021-11-02T14:09:57.165616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    # Do group by with helmet id and delete some BBoxes if the confidence is low.\n    df_traced_helmet_cnt = df_deleted.groupby([\"video\",\"helmet\"], as_index=False).video_frame.count()\n    df_traced_helmet_max = df_deleted.groupby([\"video\",\"helmet\"], as_index=False).conf.max()\n    df_traced_helmet_cnt.columns = [\"video\",\"helmet\",\"traced_cnt\"]\n    df_traced_helmet_max.columns = [\"video\",\"helmet\",\"traced_conf_max\"]\n    df_deleted = df_deleted.merge(df_traced_helmet_cnt, on=[\"video\",\"helmet\"])\n    df_deleted = df_deleted.merge(df_traced_helmet_max, on=[\"video\",\"helmet\"])\n    df_deleted = df_deleted[(df_deleted.traced_cnt >= CFG[\"thr_del_trace\"])|\n                            (df_deleted.traced_conf_max >= CFG[\"thr_del_conf\"])].reset_index(drop=True)\n    print(df_deleted.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:57.16807Z","iopub.execute_input":"2021-11-02T14:09:57.16843Z","iopub.status.idle":"2021-11-02T14:09:57.268678Z","shell.execute_reply.started":"2021-11-02T14:09:57.168393Z","shell.execute_reply":"2021-11-02T14:09:57.267766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    # Run NMS again because some helmets were added.\n    df_ensembled = pd.DataFrame()\n    for v in tqdm(df_deleted.video_frame.unique()):\n        df = df_deleted[df_deleted.video_frame==v].copy()\n        boxes  = [np.array(df[[\"left\",\"top\",\"right\",\"bottom\"]]).tolist()]\n        scores = [list(np.array(df.conf))]\n        labels = [list(np.array(df.label))]\n        boxes, scores, labels = nms(boxes, scores, labels, weights=None, iou_thr=CFG[\"thr_add_iou\"])\n        df_nms = pd.DataFrame(np.hstack([boxes, scores.reshape(-1,1)]))\n        df_nms[\"video_frame\"] = v\n        df_ensembled = df_ensembled.append(df_nms)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:09:57.270159Z","iopub.execute_input":"2021-11-02T14:09:57.270445Z","iopub.status.idle":"2021-11-02T14:10:22.314132Z","shell.execute_reply.started":"2021-11-02T14:09:57.270407Z","shell.execute_reply":"2021-11-02T14:10:22.313376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    df_ensembled.columns   = [\"left\",\"top\",\"right\",\"bottom\",\"conf\",\"video_frame\"]\n    df_ensembled = df_ensembled.merge(df_deleted, on=[\"left\",\"top\",\"right\",\"bottom\",\"conf\",\"video_frame\"])\n    df_ensembled = df_ensembled[[\"video_frame\",\"left\",\"width\",\"top\",\"height\",\"conf\",\"video\",\"frame\",\"x_move\",\"y_move\",\"helmet\"]]\n    df_ensembled[\"left\"]   = (df_ensembled.left *1280).astype(int)\n    df_ensembled[\"top\"]    = (df_ensembled.top   *720).astype(int)\n    df_ensembled[\"right\"]  = df_ensembled.left + df_ensembled.width\n    df_ensembled[\"bottom\"] = df_ensembled.top  + df_ensembled.height","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:10:41.545488Z","iopub.execute_input":"2021-11-02T14:10:41.545809Z","iopub.status.idle":"2021-11-02T14:10:42.042806Z","shell.execute_reply.started":"2021-11-02T14:10:41.545779Z","shell.execute_reply":"2021-11-02T14:10:42.041965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_ensembled.shape)\ndf_ensembled.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:10:43.818687Z","iopub.execute_input":"2021-11-02T14:10:43.819026Z","iopub.status.idle":"2021-11-02T14:10:43.834611Z","shell.execute_reply.started":"2021-11-02T14:10:43.818994Z","shell.execute_reply":"2021-11-02T14:10:43.833697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ensembled.to_csv(\"ensembled_results_with_post_trace_del2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:10:44.102908Z","iopub.execute_input":"2021-11-02T14:10:44.103206Z","iopub.status.idle":"2021-11-02T14:10:44.403919Z","shell.execute_reply.started":"2021-11-02T14:10:44.103178Z","shell.execute_reply":"2021-11-02T14:10:44.403099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find labels\n\nThis and next sections are based on the amaizing notebooks below. Thanks for sharing!\n- https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping\n- https://www.kaggle.com/robikscube/helper-code-helmet-mapping-deepsort\n\nNote: Each videos starts 10 frames before the snap. Tracking data is including events such as snap, so a snap event in tracking data equal frame 10 in video data. By starting from snap event, we can caluculate offsets from time of snap. For example, frame 10 in video data is offset 0, and frame 1 is minus offset time. Tracking data is 6 fps and video data is 59.94 fps (see next cell).\nThe function, find nearest, seeks the nearest tracking data by calculating the distance between video frame and point data in tracking data. ","metadata":{}},{"cell_type":"code","source":"#        ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||=1sec in video data\n#        ^        ^\n#      start     snap (offset 0)\n#  |        |         |         |         |         |         |      =1sec+a in tracking data","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:15:20.893054Z","iopub.execute_input":"2021-11-02T14:15:20.893394Z","iopub.status.idle":"2021-11-02T14:15:20.897753Z","shell.execute_reply.started":"2021-11-02T14:15:20.893361Z","shell.execute_reply":"2021-11-02T14:15:20.896636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_cols(df):\n    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\ndef find_nearest(array, value):\n    value = int(value)\n    array = np.asarray(array).astype(int)\n    idx   = (np.abs(array - value)).argmin()\n    return array[idx]\n\ndef norm_arr(a):\n    a = a-a.min()\n    a = a/a.max()\n    return a\n    \ndef dist(a1, a2):\n    return np.linalg.norm(a1-a2)\n\ndef dist_for_different_len(a1, a2):\n    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}'\n    len_diff = len(a1) - len(a2)\n    a2 = norm_arr(a2)\n    if len_diff == 0:\n        a1 = norm_arr(a1)\n        return dist(a1,a2), ()\n    else:\n        min_dist = 10000\n        min_detete_idx = None\n        cnt = 0\n        del_list = list(itertools.combinations(range(len(a1)),len_diff))\n        if len(del_list) > CFG[\"max_iter\"]:\n            del_list  = random.sample(del_list, CFG[\"max_iter\"])\n        for detete_idx in del_list:\n            this_a1   = np.delete(a1, detete_idx)\n            this_a1   = norm_arr(this_a1)\n            this_dist = dist(this_a1, a2)\n            if min_dist > this_dist:\n                min_dist = this_dist\n                min_detete_idx = detete_idx\n        return min_dist, min_detete_idx\n        \ndef rotate_arr(u, t, deg=True):\n    if deg == True:\n        t = np.deg2rad(t)\n    R = np.array([[np.cos(t), -np.sin(t)],\n                  [np.sin(t),  np.cos(t)]])\n    return np.dot(R, u)\n\ndef dist_rot(tracking_df, a2):\n    tracking_df = tracking_df.sort_values('x')\n    x = tracking_df['x']\n    y = tracking_df['y']\n    min_dist = 10000\n    min_idx  = None\n    min_x    = None\n    for dig in range(-CFG[\"dig_max\"], CFG[\"dig_max\"]+1, CFG[\"dig_step\"]):\n        arr = rotate_arr(np.array((x,y)), dig)\n        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2)\n        if min_dist > this_dist:\n            min_dist = this_dist\n            min_idx  = this_idx\n            min_x    = arr[0]\n    tracking_df['x_rot'] = min_x\n    player_arr = tracking_df.sort_values('x_rot')['player'].values\n    players    = np.delete(player_arr, min_idx)\n    return min_dist, players\n\ndef mapping_df(args):\n    video_frame, df = args\n    if df.shape[0] == 0:\n        return pd.DataFrame([], columns=['video_frame','left','width','top','height','label'])\n    gameKey, playID, view, frame = video_frame.split('_')\n    gameKey = int(gameKey)\n    playID  = int(playID)\n    frame   = int(frame)\n    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n    est_frame     = find_nearest(this_tracking.est_frame.values, frame)\n    this_tracking = this_tracking[this_tracking['est_frame']==est_frame]\n    len_this_tracking = len(this_tracking)\n    df['center_h_p']  = (df['left']+df['width']/2).astype(int)\n    df['center_h_m']  = (df['left']+df['width']/2).astype(int)*-1\n    if len(df) > len_this_tracking:\n        df = df.tail(len_this_tracking)\n    df_p = df.sort_values('center_h_p').copy()\n    df_m = df.sort_values('center_h_m').copy()\n    \n    if view == 'Endzone':\n        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n    a2_p = df_p['center_h_p'].values\n    a2_m = df_m['center_h_m'].values\n\n    min_dist_p, min_detete_idx_p = dist_rot(this_tracking ,a2_p)\n    min_dist_m, min_detete_idx_m = dist_rot(this_tracking ,a2_m)\n    if min_dist_p < min_dist_m:\n        min_dist = min_dist_p\n        min_detete_idx = min_detete_idx_p\n        tgt_df = df_p\n    else:\n        min_dist = min_dist_m\n        min_detete_idx = min_detete_idx_m\n        tgt_df = df_m\n        \n    tgt_df['label'] = min_detete_idx\n    return tgt_df[['video_frame','left','width','top','height','label']]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:15:21.412614Z","iopub.execute_input":"2021-11-02T14:15:21.412916Z","iopub.status.idle":"2021-11-02T14:15:21.435757Z","shell.execute_reply.started":"2021-11-02T14:15:21.412888Z","shell.execute_reply":"2021-11-02T14:15:21.434661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helmets  = df_ensembled.sort_values(\"video_frame\").reset_index(drop=True)\ntracking = pd.read_csv(f'../input/nfl-health-and-safety-helmet-assignment/test_player_tracking.csv')\ntracking = add_track_features(tracking)\nlabels   = pd.read_csv(f'../input/nfl-health-and-safety-helmet-assignment/train_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:15:22.940091Z","iopub.execute_input":"2021-11-02T14:15:22.940432Z","iopub.status.idle":"2021-11-02T14:15:25.623276Z","shell.execute_reply.started":"2021-11-02T14:15:22.9404Z","shell.execute_reply":"2021-11-02T14:15:25.622393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helmets = add_cols(helmets)\nlabels  = add_cols(labels)\ntracking.shape, helmets.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:15:25.624787Z","iopub.execute_input":"2021-11-02T14:15:25.625118Z","iopub.status.idle":"2021-11-02T14:15:29.547382Z","shell.execute_reply.started":"2021-11-02T14:15:25.625082Z","shell.execute_reply":"2021-11-02T14:15:29.546275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    p = Pool(processes=4)\n    submission_df_list = []\n    df_list = list(helmets.groupby('video_frame'))\n    with tqdm(total=len(df_list)) as pbar:\n        for this_df in p.imap(mapping_df, df_list):\n            submission_df_list.append(this_df)\n            pbar.update(1)\n    p.close()\n\n    submission_df = pd.concat(submission_df_list).reset_index(drop=True)\n    submission_df.to_csv('submission-baseline.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:15:29.548927Z","iopub.execute_input":"2021-11-02T14:15:29.549192Z","iopub.status.idle":"2021-11-02T14:25:00.911606Z","shell.execute_reply.started":"2021-11-02T14:15:29.549166Z","shell.execute_reply":"2021-11-02T14:25:00.910658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Apply DeepSort","metadata":{}},{"cell_type":"code","source":"%%writefile deepsort.yaml\n\nDEEPSORT:\n  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n  MAX_DIST: 0.2\n  MIN_CONFIDENCE: 0.3\n  NMS_MAX_OVERLAP: 0.5\n  MAX_IOU_DISTANCE: 0.9\n  MAX_AGE: 15\n  N_INIT: 1\n  NN_BUDGET: 30","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:25:25.671375Z","iopub.execute_input":"2021-11-02T14:25:25.671711Z","iopub.status.idle":"2021-11-02T14:25:25.678127Z","shell.execute_reply.started":"2021-11-02T14:25:25.671678Z","shell.execute_reply":"2021-11-02T14:25:25.677208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHelper functions from yolov5 to plot deepsort labels.\n\"\"\"\n\ndef compute_color_for_id(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the id\n    \"\"\"\n    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\n\ndef plot_one_box(x, im, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image 'im' using OpenCV\n    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n    tl     = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n    color  = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label: \n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n    return im","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:25:27.826266Z","iopub.execute_input":"2021-11-02T14:25:27.826684Z","iopub.status.idle":"2021-11-02T14:25:27.842201Z","shell.execute_reply.started":"2021-11-02T14:25:27.826641Z","shell.execute_reply":"2021-11-02T14:25:27.84114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deepsort_helmets(video_data,\n                     video_dir,\n                     deepsort_config='deepsort.yaml',\n                     plot=False,\n                     plot_frames=[]):\n    \n    # Setup Deepsort\n    cfg = get_config()\n    cfg.merge_from_file(deepsort_config)    \n    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n                        max_dist=cfg.DEEPSORT.MAX_DIST,\n                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n                        max_age=cfg.DEEPSORT.MAX_AGE,\n                        n_init=cfg.DEEPSORT.N_INIT,\n                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n                        use_cuda=True)\n    \n    # Run through frames.\n    video_data = video_data.sort_values('frame').reset_index(drop=True)\n    ds = []\n    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n        d['x'] = (d['left'] + round(d['width']  / 2))\n        d['y'] = (d['top']  + round(d['height'] / 2))\n\n        xywhs = d[['x','y','width','height']].values\n\n        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4')\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n        success, image = cap.read()\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        confs   = np.ones([len(d),])\n        clss    = np.zeros([len(d),])\n        outputs = deepsort.update(xywhs, confs, clss, image)\n\n        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n            for j, (output, conf) in enumerate(zip(outputs, confs)): \n\n                bboxes = output[0:4]\n                id  = output[4]\n                cls = output[5]\n\n                c = int(cls)  # integer class\n                label = f'{id}'\n                color = compute_color_for_id(id)\n                im  = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n            fig, ax = plt.subplots(figsize=(15, 10))\n            video_frame = d['video_frame'].values[0]\n            ax.set_title(f'Deepsort labels: {video_frame}')\n            plt.imshow(im)\n            plt.show()\n\n        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n        if len(preds_df) > 0:\n            # TODO Fix this messy merge\n            d = pd.merge_asof(d.sort_values(['left','top']),\n                              preds_df[['left','top','deepsort_cluster']] \\\n                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n                              direction='nearest')\n        ds.append(d)\n    dout = pd.concat(ds)\n    return dout\n\ndef add_deepsort_label_col(out):\n    # Find the top occuring label for each deepsort_cluster\n    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['label'].to_dict()\n    # Find the # of times that label appears for the deepsort_cluster.\n    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['label_count'].to_dict()\n    \n    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n\n    return out\n\ndef score_vs_deepsort(myvideo, out, labels):\n    # Score the base predictions compared to the deepsort postprocessed predictions.\n    myvideo_mp4  = myvideo + '.mp4'\n    labels_video = labels.query('video == @myvideo_mp4')\n    scorer       = NFLAssignmentScorer(labels_video)\n    out_deduped  = out.groupby(['video_frame','label']).first().reset_index()\n    base_video_score = scorer.score(out_deduped)\n    \n    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n    print(out_preds.shape)\n    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n    print(out_preds.shape)\n    deepsort_video_score = scorer.score(out_preds)\n    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:25:28.035651Z","iopub.execute_input":"2021-11-02T14:25:28.036342Z","iopub.status.idle":"2021-11-02T14:25:28.066876Z","shell.execute_reply.started":"2021-11-02T14:25:28.036282Z","shell.execute_reply":"2021-11-02T14:25:28.065889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"]:\n    # Add video and frame columns to submission.\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\n    submission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n\n    # Loop through test videos and apply. If in debug mode show the score change.\n    out_ds = []\n    outs   = []\n    for myvideo, video_data in submission_df.groupby('video'):\n        print(f'==== {myvideo} ====')\n        out = deepsort_helmets(video_data, CFG[\"input_path\"])\n        out_ds.append(out)\n        out = add_deepsort_label_col(out)\n        outs.append(out)\n    submission_deepsort = pd.concat(outs).copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:25:28.563506Z","iopub.execute_input":"2021-11-02T14:25:28.563817Z","iopub.status.idle":"2021-11-02T14:54:31.812132Z","shell.execute_reply.started":"2021-11-02T14:25:28.56379Z","shell.execute_reply":"2021-11-02T14:54:31.811352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check submission file","metadata":{}},{"cell_type":"code","source":"ss = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\nif not CFG[\"nosave\"]:\n    # Final Checks\n    submission_deepsort['label_deepsort'] = submission_deepsort['label_deepsort'].fillna(submission_deepsort['label'])\n    submission_deepsort = submission_deepsort.drop('label', axis=1).rename(columns={'label_deepsort':'label'})[ss.columns]\n    # Drop duplicate labels\n    submission_deepsort = submission_deepsort.loc[~submission_deepsort[['video_frame','label']].duplicated()]\n    check_submission(submission_deepsort)\n    submission_deepsort.to_csv('submission_deepsort.csv', index=False)\nelse:\n    submission_deepsort = ss.copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:54:39.90761Z","iopub.execute_input":"2021-11-02T14:54:39.907932Z","iopub.status.idle":"2021-11-02T14:54:40.111645Z","shell.execute_reply.started":"2021-11-02T14:54:39.907899Z","shell.execute_reply":"2021-11-02T14:54:40.11072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Re-ID\nIn Deepsort algorithm, unfortunately some of BBoxes have been removed even if the BBoxes detect helmet correctly. In this section, I implemented Re-ID module by using helmet-ids that generated postprocessing section.","metadata":{}},{"cell_type":"markdown","source":"***I had no time to complete implementation below correctly. I believe this will improve my score.***","metadata":{}},{"cell_type":"code","source":"def reid(traced, traced_max_num, traced_helmet_ids, dict_tracing):\n    reids = []\n    for v in tqdm(traced.video.unique()):\n        df_tracing    = traced[traced.video==v].reset_index(drop=True)\n        df_max_num    = traced_max_num[traced_max_num.video==v].reset_index(drop=True)\n        df_helmet_ids = traced_helmet_ids[traced_helmet_ids.video==v].reset_index(drop=True)\n        all_labels    = df_helmet_ids.label.unique()\n\n        this_video_reids = []\n        for f in sorted(df_tracing.frame.unique()):\n            dict_all_labels = {}\n            for l in all_labels:\n                if l==\"H0\": continue\n                dict_all_labels[l] = [0, [0]*4]\n            df_this_frame = df_tracing[df_tracing.frame==f].reset_index(drop=True)\n            # Target helmet-ids that appeared in current frame\n            this_helmets  = df_this_frame.helmet\n            this_helmets  = df_max_num[df_max_num.helmet.isin(this_helmets)].helmet\n            skipped_helmets = []\n            # Run two cycles.\n            for _ in range(2):\n                for h in this_helmets:\n                    # The \"cnts\" is ordered by descending.\n                    # Labels with the highest number of occurrences have priority.\n                    # After the first loop, the remainder should be assigned.\n                    labels, cnts = dict_tracing[v][h]\n                    for l, c in zip(labels, cnts):\n                        if l != \"H0\":\n                            if dict_all_labels[l][0] < c:\n                                if dict_all_labels[l][0] != 0:\n                                    skipped_helmets.append(dict_all_labels[l][1][2])\n                                dict_all_labels[l][0] = c\n                                dict_all_labels[l][1] = [v, f, h, l]\n                                break\n                            if dict_all_labels[l][0] == c:\n                                # Some of helmet-ids have the same number of different labels.\n                                # If that is happened, those will be processed on the next.\n                                skipped_helmets.append(h)\n                                if 0 < dict_all_labels[l][1][1]:\n                                    skipped_helmets.append(dict_all_labels[l][1][2])\n                                dict_all_labels[l][1] = [0]*4\n                                break\n                    else:\n                        skipped_helmets.append(h)\n\n                if len(this_helmets) != len(skipped_helmets):\n                    this_helmets    = skipped_helmets\n                    skipped_helmets = []\n\n            # Successful to do re-id\n            this_video_reids += [item for _, item in list(dict_all_labels.values()) if item[1] != 0]\n            # the other helmet that need to be assigned will go on next.\n            not_detected_helmets = [key for key, (cnt, _) in dict_all_labels.items() if cnt == 0]\n            if len(not_detected_helmets) == 0:\n                continue\n\n            if 0 < len(this_helmets):\n                # Calculate the nearest BBox\n                this_helmets   = list(set(this_helmets))\n                df_prev_traced = pd.DataFrame(this_video_reids, columns=[\"video\",\"frame\",\"helmet\",\"label\"])\n                df_curt_traced = df_tracing[(df_tracing.frame==f)&(df_tracing.helmet.isin(this_helmets))][[\"helmet\",\"left\",\"top\"]]\n\n                assigned_helmets = []\n                for l in not_detected_helmets:\n                    df_prev_frame  = df_prev_traced[(df_prev_traced.label==l)]\n                    if df_prev_frame.shape[0] == 0:\n                        continue\n                    prev_frame     = np.array(df_prev_frame.frame)[-1]\n                    prev_helmet    = np.array(df_prev_frame.helmet)[-1]\n                    prev_location  = np.array(df_tracing[(df_tracing.frame==prev_frame)&(df_tracing.helmet==prev_helmet)][[\"left\",\"top\"]])\n                    curt_location  = np.array(df_curt_traced[~df_curt_traced.helmet.isin(assigned_helmets)])\n                    nearest_helmet = curt_location[np.argmin(cdist(curt_location[:,1:], prev_location)), 0]\n                    this_video_reids += [[v, f, nearest_helmet, l]]\n                    assigned_helmets.append(nearest_helmet)\n                    if len(assigned_helmets) == len(this_helmets):\n                        break\n        reids += this_video_reids\n    \n    df_re_ids = pd.DataFrame(reids, columns=[\"video\",\"frame\",\"helmet\",\"label\"])\n    return df_re_ids","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:54:42.362713Z","iopub.execute_input":"2021-11-02T14:54:42.363026Z","iopub.status.idle":"2021-11-02T14:54:42.382817Z","shell.execute_reply.started":"2021-11-02T14:54:42.362998Z","shell.execute_reply":"2021-11-02T14:54:42.38182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and not CFG[\"skip_reids\"]:\n    traced = df_ensembled.merge(submission_deepsort, on=[\"video_frame\",\"left\",\"width\",\"top\",\"height\"], how=\"left\")\n    traced.loc[traced.label.isnull(), \"label\"] = \"H0\"\n    print(traced.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:54:42.462469Z","iopub.execute_input":"2021-11-02T14:54:42.462729Z","iopub.status.idle":"2021-11-02T14:54:42.510531Z","shell.execute_reply.started":"2021-11-02T14:54:42.462705Z","shell.execute_reply":"2021-11-02T14:54:42.509573Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and not CFG[\"skip_reids\"]:\n    traced_helmet_ids = traced.groupby([\"video\",\"helmet\",\"label\"], as_index=False).video_frame.count()\n    traced_helmet_ids.columns = [\"video\",\"helmet\",\"label\",\"cnt\"]\n    traced_helmet_ids = traced_helmet_ids.sort_values([\"video\",\"helmet\",\"cnt\"], ascending=[True,True,False])\n    traced_max_num = traced_helmet_ids.groupby([\"video\",\"helmet\"], as_index=False).cnt.max()\n    traced_max_num = traced_helmet_ids.merge(traced_max_num, on=[\"video\",\"helmet\",\"cnt\"])\n    traced_max_num = traced_max_num.sort_values(\"cnt\", ascending=False)\n\n    dict_tracing = {}\n    for v in traced_helmet_ids.video.unique():\n        df_video = traced_helmet_ids[traced_helmet_ids.video==v].reset_index(drop=True)\n        dict = {}\n        for h in df_video.helmet.unique():\n            this_helmet = df_video[df_video.helmet==h]\n            dict[h] = [list(this_helmet.label), list(this_helmet.cnt)]\n        dict_tracing[v] = dict    ","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:54:50.766759Z","iopub.execute_input":"2021-11-02T14:54:50.76707Z","iopub.status.idle":"2021-11-02T14:54:51.070008Z","shell.execute_reply.started":"2021-11-02T14:54:50.767042Z","shell.execute_reply":"2021-11-02T14:54:51.069228Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CFG[\"nosave\"] and not CFG[\"skip_reids\"]:\n    df_re_ids = reid(traced, traced_max_num, traced_helmet_ids, dict_tracing)\n    df_re_ids = df_re_ids.merge(traced[[\"video\",\"frame\",\"helmet\",\"left\",\"width\",\"top\",\"height\"]],\n                                on=[\"video\",\"frame\",\"helmet\"])\n    df_re_ids[\"video_frame\"] = df_re_ids[\"video\"] + \"_\" + df_re_ids[\"frame\"].astype(str)\n    df_re_ids = df_re_ids[[\"video_frame\",\"label\",\"left\",\"width\",\"top\",\"height\"]]\n\n    df_re_ids.to_csv('submission.csv', index=False)\nelse:\n    submission_deepsort.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:54:53.530006Z","iopub.execute_input":"2021-11-02T14:54:53.530346Z","iopub.status.idle":"2021-11-02T14:55:27.310644Z","shell.execute_reply.started":"2021-11-02T14:54:53.530297Z","shell.execute_reply":"2021-11-02T14:55:27.309823Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./inference_cnn\n!rm -rf ./inference\n!rm -rf ./yolov5","metadata":{"execution":{"iopub.status.busy":"2021-11-02T14:56:24.360281Z","iopub.execute_input":"2021-11-02T14:56:24.360756Z","iopub.status.idle":"2021-11-02T14:56:26.496755Z","shell.execute_reply.started":"2021-11-02T14:56:24.360719Z","shell.execute_reply":"2021-11-02T14:56:26.495536Z"},"trusted":true},"execution_count":null,"outputs":[]}]}