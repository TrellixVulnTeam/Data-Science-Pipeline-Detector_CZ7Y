{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\nfrom helmet_assignment.score import NFLAssignmentScorer, check_submission\nfrom helmet_assignment.features import add_track_features","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:54:09.767167Z","iopub.execute_input":"2021-10-27T22:54:09.76785Z","iopub.status.idle":"2021-10-27T22:54:40.238756Z","shell.execute_reply.started":"2021-10-27T22:54:09.767818Z","shell.execute_reply":"2021-10-27T22:54:40.237525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nimport glob\nimport os\nimport cv2\nimport csv\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.auto import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nimport random\nimport itertools\nimport cv2\nimport imageio\nimport numpy as np\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport matplotlib.pylab as plt\nfrom tqdm.auto import tqdm\n# !pip install imageio-ffmpeg\nimport csv\nimport math\nimport torch\nimport torch.utils.data\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport PIL\nfrom PIL import Image, ImageDraw\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nimport torchvision.transforms as transforms\nimport torch.optim as optim\n# !pip install utils\n# import utils \nimport os,sys\nimport IPython.display\nimport time\nimport glob\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom scipy.spatial import distance_matrix\nimport scipy.spatial.distance as scipy_distance\nimport scipy\nimport matplotlib","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:54:40.279052Z","iopub.execute_input":"2021-10-27T22:54:40.279756Z","iopub.status.idle":"2021-10-27T22:54:40.295733Z","shell.execute_reply.started":"2021-10-27T22:54:40.279698Z","shell.execute_reply":"2021-10-27T22:54:40.29473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gathering Data","metadata":{}},{"cell_type":"code","source":"n_test_videos = len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/'))\n# Run in debug mode unless during submission\nif n_test_videos == 6:\n    debug = True\nelse:\n    debug = False\n\n# debug = False\n\n# Configurables\nn_debug_samples = 1\nrandom_state = 50\nCONF_THRE = 0.3\n\n# Read in the data.\n\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nif debug:\n    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\nelse:\n    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n    \ntracking = add_track_features(tracking)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:54:40.297317Z","iopub.execute_input":"2021-10-27T22:54:40.298559Z","iopub.status.idle":"2021-10-27T22:54:44.72632Z","shell.execute_reply.started":"2021-10-27T22:54:40.298517Z","shell.execute_reply":"2021-10-27T22:54:44.725177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add new columns using the video_frame column\ndef add_cols(df):\n  if 'gameKey' not in df.columns:\n    df['gameKey'] = df['video_frame'].str.split('_').str[0:1].str.join('_').astype(int)\n  if 'playID' not in df.columns:\n    df['playID'] = df['video_frame'].str.split('_').str[1:2].str.join('_').astype(int)\n  if 'view' not in df.columns:\n    df['view'] = df['video_frame'].str.split('_').str[2:3].str.join('_')\n  if 'frame' not in df.columns:\n    df['frame'] = df['video_frame'].str.split('_').str[3:4].str.join('_').astype(int)\n  if 'video' not in df.columns:\n      df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n  return df\n\nhelmets = add_cols(helmets)\n#if debug:\nif True:\n  labels = add_cols(labels)\n  # Select `n_debug_samples` worth of videos to debug with\n  sample_videos = labels['video'].drop_duplicates()  #\\\n#      .sample(n_debug_samples, random_state=random_state).tolist() # Creates a list of n randomly selected videos\n#   sample_videos = ['58106_002918_Endzone.mp4', '57786_003085_Sideline.mp4', '57992_000301_Sideline.mp4']\n\n  sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos] # Creates a list of gameplay number in sample_videos\n\n  #Removes all other video_frames that aren't in sample_videos or sample_gameplays\n  tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n  helmets = helmets[helmets['video'].isin(sample_videos)]\n  labels = labels[labels['video'].isin(sample_videos)]\nlabels.shape, tracking.shape, helmets.shape\ndisplay(labels)\ndisplay(tracking)\ndisplay(helmets)\nprint(sample_videos)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:54:44.728003Z","iopub.execute_input":"2021-10-27T22:54:44.728302Z","iopub.status.idle":"2021-10-27T22:55:10.589258Z","shell.execute_reply.started":"2021-10-27T22:54:44.728265Z","shell.execute_reply":"2021-10-27T22:55:10.588252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove helmets below a certain confidence threshold\nhelmets = helmets[helmets['conf']>CONF_THRE].copy()\n\n# If there are still more than 22 helmets, keep only the best 22 helmets with highest confidence\nlow_conf_helms_removed = []\nfor vf in helmets['video_frame'].unique():\n  helm = helmets[helmets['video_frame'] == vf]\n  if len(helm) > 22:\n    helm = helm.sort_values('conf', ascending = False)\n    low_conf_helms_removed.append(helm.head(22))\n    continue\n  low_conf_helms_removed.append(helm)\n\nhelmets = pd.concat(low_conf_helms_removed)\nhelmets['x']=helmets['left']+helmets['width']/2\nhelmets['y']=helmets['top']+helmets['height']/2","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:19:07.820245Z","iopub.execute_input":"2021-10-27T22:19:07.820653Z","iopub.status.idle":"2021-10-27T22:21:36.1355Z","shell.execute_reply.started":"2021-10-27T22:19:07.820622Z","shell.execute_reply":"2021-10-27T22:21:36.134162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_nearest(array, value):\n    value = int(value)\n    array = np.asarray(array).astype(int)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx]\ndef dist(v1, v2):\n  # print(v1)\n  return np.sqrt(np.square(v1[0] - v2[0]) + np.square(v1[1] - v2[1]))\n\ndef get_NN_borders(list_points, amount=5):\n  results = np.zeros((4, amount)) #0xmin, 1ymin, 2xmax, 3ymax\n  lpmax = np.copy(list_points)\n  lpmin = np.copy(list_points)\n  for i in range(amount):\n    results[:2,i]=np.argmin(lpmin, 0)\n    #print(results[0,i])\n    lpmin[int(results[0,i])][0] = 1000000\n    lpmin[int(results[1,i]), 1] = 1000000\n    results[2:,i]=np.argmax(lpmax, 0)\n    lpmax[int(results[2,i]), 0],lpmax[int(results[3,i]), 1] = -np.inf, -np.inf \n  return results\n\ndef create_combinations(track):\n  mesh = np.array(np.meshgrid(track[0], track[1], track[2], track[3]))\n  combinations = mesh.T.reshape(-1, 4)\n  c = 0\n  for index, i in enumerate(combinations):\n    if i[0]==i[1] or i[0]==i[2] or i[0]==i[3] or i[1]==i[2] or i[1]==i[3] or i[2]==i[3]:\n      combinations = np.delete(combinations, int(index)-c, 0)\n      c+=1\n  return combinations\ndef convert_data_tonumpy(helm, track, view):\n  if 'Endzone'==view:\n    helm['x']=1280-helm['x']\n  helm['y']=720-helm['y']\n  tracking_points = track[['x','y']].to_numpy()\n  if 'Sideline'==view:\n    helmet_points = helm[['x','y']].to_numpy()\n  else:\n    helmet_points = np.c_[helm['y'].to_numpy(), helm['x'].to_numpy()]\n  return helmet_points, tracking_points","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:10.592218Z","iopub.execute_input":"2021-10-27T22:55:10.592543Z","iopub.status.idle":"2021-10-27T22:55:10.610334Z","shell.execute_reply.started":"2021-10-27T22:55:10.592505Z","shell.execute_reply":"2021-10-27T22:55:10.608767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get deepsort clusters","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/easydict-master/easydict-master/')\n# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\nsys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\nfrom deep_sort.deep_sort import DeepSort\nfrom utils.parser import get_config","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:10.612343Z","iopub.execute_input":"2021-10-27T22:55:10.612715Z","iopub.status.idle":"2021-10-27T22:55:10.627664Z","shell.execute_reply.started":"2021-10-27T22:55:10.612673Z","shell.execute_reply":"2021-10-27T22:55:10.62655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile deepsort.yaml\n\nDEEPSORT:\n  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n  MAX_DIST: 0.2\n  MIN_CONFIDENCE: 0.3\n  NMS_MAX_OVERLAP: 0.5\n  MAX_IOU_DISTANCE: 0.9\n  MAX_AGE: 15\n  N_INIT: 1\n  NN_BUDGET: 30","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:10.63062Z","iopub.execute_input":"2021-10-27T22:55:10.631304Z","iopub.status.idle":"2021-10-27T22:55:10.641694Z","shell.execute_reply.started":"2021-10-27T22:55:10.631261Z","shell.execute_reply":"2021-10-27T22:55:10.640452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHelper functions from yolov5 to plot deepsort labels.\n\"\"\"\n\ndef compute_color_for_id(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the id\n    \"\"\"\n    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\n\ndef plot_one_box(x, im, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image 'im' using OpenCV\n    #A contiguous array is just an array stored in an unbroken block of memory\n    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    #Generate corner points for making rectangle\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    #Put label on the bounding box if available\n    if label: \n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n    return im","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:10.643664Z","iopub.execute_input":"2021-10-27T22:55:10.644337Z","iopub.status.idle":"2021-10-27T22:55:10.660305Z","shell.execute_reply.started":"2021-10-27T22:55:10.644296Z","shell.execute_reply":"2021-10-27T22:55:10.659218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deepsort_helmets(video_data,\n                     video_dir,\n                     deepsort_config='deepsort.yaml',\n                     plot=False,\n                     plot_frames=[]):\n    \n    # Setup Deepsort\n    cfg = get_config()\n    cfg.merge_from_file(deepsort_config)    \n    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n                        max_dist=cfg.DEEPSORT.MAX_DIST,\n                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n                        max_age=cfg.DEEPSORT.MAX_AGE,\n                        n_init=cfg.DEEPSORT.N_INIT,\n                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n                        use_cuda=True)\n    \n    # Run through frames.\n    video_data = video_data.sort_values('frame').reset_index(drop=True)\n    ds = []\n    output_list = []\n    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n        #Calculate center points\n        d['x'] = (d['left'] + round(d['width'] / 2))\n        d['y'] = (d['top'] + round(d['height'] / 2))\n        \n\n        xywhs = d[['x','y','width','height']].values\n        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}')\n\n        video_frame = myvideo.replace(\".mp4\", \"\") + '_' + str(frame)\n#         print(video_frame)\n        #Retrieve correct frame from the video\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n        success, image = cap.read()\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        #Get the confidence and class for each player in the frame\n        confs = np.ones([len(d),])\n        clss =  np.zeros([len(d),])\n        outputs = deepsort.update(xywhs, confs, clss, image)\n        outputs_with_videoframe = []\n        for idx, op in enumerate(outputs.copy()):\n          op[2], op[1] = op[1], op[2]  # Switch top and right\n          op[1] = op[1] - op[0] # Width = right - left\n          op[3] = op[3] - op[2] #Height = bottom - top\n          row = [op[0], op[1], op[2], op[3], op[4], video_frame]\n          outputs_with_videoframe.append(row)\n        \n        header = ['left','width','top','height','deepsort_cluster', 'video_frame']\n#         print(outputs_with_videoframe)\n        if frame > 1:\n            preds_df_with_videoframe = pd.DataFrame(outputs_with_videoframe, columns = header)\n            output_list.append(preds_df_with_videoframe)\n\n        #Plot specified frames\n        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n            for j, (output, conf) in enumerate(zip(outputs, confs)): \n\n                bboxes = output[0:4]\n                id = output[4]\n                cls = output[5]\n\n                c = int(cls)  # integer class\n                label = f'{id}'\n                color = compute_color_for_id(id)\n                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n            fig, ax = plt.subplots(figsize=(15, 10))\n            video_frame = d['video_frame'].values[0]\n            ax.set_title(f'Deepsort labels: {video_frame}')\n            plt.imshow(im)\n            plt.show()\n\n        #Create a dataframe for predictions\n        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom', 'class','deepsort_cluster'])\n        if len(preds_df) > 0:\n            # TODO Fix this messy merge\n            d = pd.merge_asof(d.sort_values(['left','top']),\n                              preds_df[['left','top','deepsort_cluster']] \\\n                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n                              direction='nearest')\n        ds.append(d)\n        # display(d)\n    #Generate a final dataframe for class predictions over all frames    \n    dout = pd.concat(ds)\n    output_df = pd.concat(output_list)\n    return output_df\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:18:09.709835Z","iopub.status.idle":"2021-10-27T22:18:09.710461Z","shell.execute_reply.started":"2021-10-27T22:18:09.710127Z","shell.execute_reply":"2021-10-27T22:18:09.710156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\nelse:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n    \n# print(glob.glob(video_dir))\n\n# Uncomment this when trying a new video\n# Deletes the existing deepsort clusters file to create a new one.\n# if os.path.isfile('/content/drive/MyDrive/Team 3/NFL-Health-Safety/helmet-assignment/deepsort_clusters_submission.csv'):\n#   os.remove('/content/drive/MyDrive/Team 3/NFL-Health-Safety/helmet-assignment/deepsort_clusters_submission.csv')\noutput = []\nfor myvideo, video_data in tqdm(helmets.groupby('video'), total= helmets['video'].nunique()):\n    print(f'==== {myvideo} ====')\n    if debug:\n        # Plot deepsort labels when in debug mode.\n        out = deepsort_helmets(video_data, video_dir, plot_frames=[10, 50, 100, 150,200,250,300,350])\n    else:\n        out = deepsort_helmets(video_data, video_dir)\n    output.append(out)\n\noutput = pd.concat(output)\noutput.to_csv('deepsort_clusters.csv', index = False, mode='w')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:58:50.183047Z","iopub.execute_input":"2021-10-27T18:58:50.18331Z","iopub.status.idle":"2021-10-27T19:04:14.154083Z","shell.execute_reply.started":"2021-10-27T18:58:50.183283Z","shell.execute_reply":"2021-10-27T19:04:14.153426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.505377Z","iopub.execute_input":"2021-10-26T22:27:38.506051Z","iopub.status.idle":"2021-10-26T22:27:38.514432Z","shell.execute_reply.started":"2021-10-26T22:27:38.506014Z","shell.execute_reply":"2021-10-26T22:27:38.513739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting Homography","metadata":{}},{"cell_type":"code","source":"def flip_view(helmets, args = 2):\n  \n  if args == 2:\n    for ii, (x,y) in enumerate(helmets):\n      helmets[ii][0] = 1280 - x\n      helmets[ii][1] = 720  - y\n  return helmets","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:18.587282Z","iopub.execute_input":"2021-10-27T22:55:18.58758Z","iopub.status.idle":"2021-10-27T22:55:18.593923Z","shell.execute_reply.started":"2021-10-27T22:55:18.587537Z","shell.execute_reply":"2021-10-27T22:55:18.592735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flip_view_dataframe(deepsort_helms):\n  \n  deepsort_helms['x'] = 1280 - deepsort_helms['x']\n  deepsort_helms['y'] = 720 - deepsort_helms['y']\n\n  return deepsort_helms","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:17.123869Z","iopub.execute_input":"2021-10-27T22:55:17.12462Z","iopub.status.idle":"2021-10-27T22:55:17.130345Z","shell.execute_reply.started":"2021-10-27T22:55:17.124589Z","shell.execute_reply":"2021-10-27T22:55:17.128987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n@input : train_gt: detected helmet locations that you want to project\n         track_gt: tracking data of the helmets in the same frame\n         view    : Sideline or Endzone\n@return: h      : best estimated homography matrix\n'''\ndef getHomographyTryExact(train_gt, track_gt, view): #gameK, playid, videoname, train_gt, track_gt, frame_number, view):\n  time1 = time.time()\n  \n  #Check if the view is from one side of the field or another.\n  view_flip = False\n  #adapt the coordinates depending on the view  \n  if 'Endzone'==view:\n    train_gt['x']=1280-train_gt['x']\n  train_gt['y']=720-train_gt['y']\n  tracking_points = track_gt[['x','y']].to_numpy()\n  if 'Sideline'==view:\n    helmet_points = train_gt[['x','y']].to_numpy()\n  else:\n    helmet_points = np.c_[train_gt['y'].to_numpy(), train_gt['x'].to_numpy()]\n  amount_players_tracking, amount_players_helmets = len(tracking_points), len(helmet_points)\n  tracking_borders_index= get_NN_borders(tracking_points, max(amount_players_tracking-amount_players_helmets,5)) #0xmin, 1ymin, 2xmax, 3ymax\n  helmet_borders_index = get_NN_borders(helmet_points, 2)\n  #create combinations of the border points\n  list_combinations_tracking = create_combinations(tracking_borders_index)\n  list_combinations_helmet = create_combinations(helmet_borders_index)\n\n  print('Length combinations tracking', len(list_combinations_tracking))\n  print('Length combinations helmet', len(list_combinations_helmet))\n\n  current_combination = np.zeros((4,2))\n  helmet_borders = np.zeros((4,2))\n  bestH = None\n  bestPoints = None\n  bestHelm = None\n  min=np.inf\n  for ii in range(2):\n    if ii == 1:\n      helmet_points = flip_view(helmet_points.copy())\n      helmet_borders_index = get_NN_borders(helmet_points, 2)\n      list_combinations_helmet = create_combinations(helmet_borders_index)\n\n    for j, comb_helmets in enumerate(list_combinations_helmet):\n\n        for q in range(4):\n          helmet_borders[q]=helmet_points[int(comb_helmets[q])]\n\n        for i, comb in enumerate(list_combinations_tracking):\n          current_combination[0],current_combination[1],current_combination[2],current_combination[3] = tracking_points[int(comb[0])],tracking_points[int(comb[1])],tracking_points[int(comb[2])],tracking_points[int(comb[3])]\n          h, status = cv2.findHomography(helmet_borders,current_combination)\n          if h is not None:\n            helmet_points_transformed = cv2.perspectiveTransform(np.array([helmet_points]), h)\n            dist_matrix =scipy.spatial.distance.cdist(helmet_points_transformed[0], tracking_points)\n            row_ind, col_ind = scipy.optimize.linear_sum_assignment(dist_matrix)\n            count_min = dist_matrix[row_ind, col_ind].sum()\n            if count_min<min :\n              bestPoints = np.copy(helmet_points_transformed)\n              bestHelm = np.copy(helmet_points)\n              best_combination = np.copy(current_combination)\n              print('New min:', count_min, 'view flip:', view_flip)\n              min = count_min\n              bestH = np.copy(h)\n              if ii == 1:\n                view_flip = True\n          else:\n            print('h is none')\n    print('BEST MIN',min)\n\n  \n  ###########################\n  dist_matrix =scipy.spatial.distance.cdist(bestPoints[0], tracking_points)\n  row_ind, col_ind = scipy.optimize.linear_sum_assignment(dist_matrix)\n  count_min = dist_matrix[row_ind, col_ind].sum()\n  c = 0  \n  print(\"View Flip:\", view_flip)\n  print('Accuracy:',c,'/',len(row_ind))\n  print('time for one frame:', time.time()-time1)\n  print('rowind', row_ind, '//', len(row_ind))\n  print('col_ind', col_ind, '//',len(col_ind))\n  plt.figure(figsize=(10,10))\n  a = plt.plot(bestPoints[0,:,0] , bestPoints[0,:,1],'bo', markersize = 10) #.set_label(\"Estimation of helmets on map\") #bleu\n  b = plt.plot(tracking_points[:,0], tracking_points[:,1],'rs',  markersize = 7, label= \"Tracking GPS\") #red\n  plt.show()\n  return bestH, view_flip\n\n'''\n@input : helmets_data: detected helmet locations of the entire video\n         tracking_data: tracking data of the entire video\n         view    : Sideline or Endzone\n@return: list_homo: a list of all the estimated homography matrices\n'''\n\ndef findHomography_with_one_iteration(arranged_helm_points,arranged_track_points, Hprev):\n    #NewH1, status = cv2.findHomography(arranged_helm_points[:,:2],arranged_track_points[:,:2], method =0) # cv2.LMEDS)\n    # if view_flip:\n    #   arranged_helm_points = flip_view(arranged_helm_points)\n    helm_trans0 = cv2.perspectiveTransform(np.array([arranged_helm_points[:,:2]],dtype=np.float32), Hprev)\n    distances = np.zeros(len(arranged_helm_points))\n    thresh = int(len(arranged_helm_points)*0.5)\n    for r in range(len(helm_trans0[0])):\n      #print('lkjl', scipy.spatial.distance.euclidean(helm_trans0[0,r,:2], arranged_track_points[r,:2]))\n      distances[r]=scipy.spatial.distance.euclidean(helm_trans0[0,r,:2], arranged_track_points[r,:2])\n    dist_ind_ok = np.argwhere(distances<1)\n    if len(dist_ind_ok)<thresh or len(dist_ind_ok)<7:\n      # print('NEED MORE PAIRS ONE ITERATION')\n      c=1\n      while (len(dist_ind_ok)<thresh or len(dist_ind_ok)<7) and c<100:\n        c+=0.1\n        dist_ind_ok = np.argwhere(distances<c)\n      # print('C', c)\n    NewH2, status = cv2.findHomography(arranged_helm_points[dist_ind_ok,:2],arranged_track_points[dist_ind_ok,:2], method =0) \n    return NewH2\n\ndef find_index_array(arranged_track_points, dup1):\n  indexes= np.empty(0, np.int)\n  for i in range(len(dup1)):\n    indexes= np.append(indexes,np.where((arranged_track_points==dup1[i]).all(axis=1))[0])\n  return indexes","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:21.337053Z","iopub.execute_input":"2021-10-27T22:55:21.33759Z","iopub.status.idle":"2021-10-27T22:55:21.370814Z","shell.execute_reply.started":"2021-10-27T22:55:21.337556Z","shell.execute_reply":"2021-10-27T22:55:21.369608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def homography_for_all_frames(videoname, video_path, helmets_deepsort, tracking_data, show_plots = False):\n  #helmets_deepsort = preprocessing_with_occurences_deepsort_output(helmets_deepsort, 29)\n  vn = videoname.split('_')\n  gameK=int(vn[0])\n  playid = int(vn[1])\n  view = str(vn[2]).replace('.mp4', '')\n  video_filename = video_path+videoname\n  num_frames = helmets_deepsort['frame'].nunique() + 1\n  print(num_frames)\n  videoname = videoname.replace('.mp4','')\n  list_of_homography = np.zeros((num_frames, 3,3))\n  labels_clusters = np.zeros(max(helmets_deepsort['deepsort_cluster'])).astype('U256')\n  #HOMOGRAPHY FIRST IMAGE\n  helm_points = helmets_deepsort[(helmets_deepsort['video_frame']==videoname+'_'+str(2))]\n  track_points = tracking_data[(tracking_data['gameKey']==gameK) & (tracking_data['playID']==playid)]\n  est_frame = find_nearest(track_points.est_frame.values, 2)\n  track_points = track_points[track_points['est_frame']==est_frame].reset_index()\n  homography, view_flip = getHomographyTryExact(helm_points.copy(), track_points.copy(), view)\n  list_of_homography[1]=homography\n  list_of_homography[0]=homography\n\n  #CONVERT X Y OF IMAGE TO SATISFY VIEW\n  if 'Endzone'==view:\n    helmets_deepsort['x']=1280-helmets_deepsort['x']\n  helmets_deepsort['y']=720-helmets_deepsort['y']\n  if 'Endzone'==view:\n    X = helmets_deepsort['y'].copy()\n    Y = helmets_deepsort['x'].copy()\n    helmets_deepsort['x']=X\n    helmets_deepsort['y']=Y\n    \n  if view_flip:\n    helmets_deepsort = flip_view_dataframe(helmets_deepsort.copy())\n    \n  helm_points = helmets_deepsort[(helmets_deepsort['video_frame']==videoname+'_'+str(2))]\n#   track_points = track_points[(tracking_data['gameKey']==gameK) & (tracking_data['playID']==playid)]\n\n#   helm, track = convert_data_tonumpy(helm_points, track_points, view)\n  track = track_points[['x','y']].to_numpy()\n  helm = helm_points[['x','y']].to_numpy()\n  print(\"Helm and Track Lengths:\",len(helm), len(track))\n  \n  helmet_points_transformed = cv2.perspectiveTransform(np.array([helm]), homography)\n  dist_matrix =scipy.spatial.distance.cdist(helmet_points_transformed[0], track)\n#   print(dist_matrix)\n  row_ind, col_ind = scipy.optimize.linear_sum_assignment(dist_matrix)\n  count_min = dist_matrix[row_ind, col_ind].sum()\n  # print('row_ind', row_ind, 'col_ind', col_ind)\n  for i in range(len(row_ind)):\n    labels_clusters[i]=track_points['player'][col_ind[i]]\n  #print(labels_clusters)\n    \n    \n  #display(helmets_deepsort)\n  #print('numebrframes', num_frames)\n  for frame_number in range(1,num_frames-1):\n    helm_points = helmets_deepsort[(helmets_deepsort['video_frame']==videoname+'_'+str(frame_number + 2))].reset_index()\n    track_points = tracking_data[(tracking_data['gameKey']==gameK) & (tracking_data['playID']==playid)]\n    est_frame = find_nearest(track_points.est_frame.values, frame_number+2)\n    track_points = track_points[track_points['est_frame']==est_frame].reset_index()\n    t = track_points[['x','y']].to_numpy()\n    h = helm_points[['x','y']].to_numpy()\n    arranged_track_points = np.empty((0,2), np.float32)\n    arranged_helm_points = np.empty((0,3), np.float32)\n    assign_new_label = np.empty((0,3), np.float32) #x, y, cluster\n\n    for i in range(len(helm_points)):\n      if track_points[track_points['player']==labels_clusters[helm_points['deepsort_cluster'][i]-1]].empty:\n        assign_new_label = np.append(assign_new_label, np.array([[helm_points['x'][i],helm_points['y'][i],int(helm_points['deepsort_cluster'][i])]]), axis=0)\n      else:\n        arranged_helm_points = np.append(arranged_helm_points, np.array([[helm_points['x'][i],helm_points['y'][i],int(helm_points['deepsort_cluster'][i])]]), axis=0)\n        arranged_track_points = np.append(arranged_track_points, track_points[track_points['player']==labels_clusters[helm_points['deepsort_cluster'][i]-1]][['x','y']].to_numpy(), axis=0)\n\n    u1, c1 = np.unique(arranged_track_points, return_counts=True,axis=0)\n    dup1 = u1[c1 > 1]\n    # print('-----------------------------------------------------------------------------------------')\n    helmets_with_no_label = np.empty((0,3), np.float32)\n\n    #Look if there are duplicates in the tracking points\n    location = find_index_array(arranged_track_points, dup1)\n    if len(location)>0:\n      #print(arranged_track_points)\n      #print(location)\n      duplicate_helmets = arranged_helm_points[location]\n      duplicate_tracking = arranged_track_points[location]\n      helmets_with_no_label = np.append(helmets_with_no_label, duplicate_helmets,axis=0)\n      arranged_track_points = np.delete(arranged_track_points, location, 0)\n      arranged_helm_points = np.delete(arranged_helm_points, location, 0)\n      #print(arranged_track_points)\n      #print('aa',helmets_with_no_label)\n    \n    #Add assign new label to the list that need to be reconverted\n    helmets_with_no_label = np.append(helmets_with_no_label, assign_new_label[:,:],axis=0)\n    #NewH, status = cv2.findHomography(arranged_helm_points[:,:2],arranged_track_points[:,:2], method =0) # cv2.LMEDS)\n    # print(arranged_helm_points)\n#     if view_flip:\n#       arranged_helm_points = flip_view(arranged_helm_points, args = 3)\n    # print(arranged_helm_points)\n    NewH = findHomography_with_one_iteration(arranged_helm_points,arranged_track_points,list_of_homography[frame_number-1])\n    # print('bb',helmets_with_no_label)\n    \n    #Look if there are helmet-tracking pairs that have a big distance\n    locations_to_del=np.empty(0, np.int)\n#     print(arranged_helm_points)\n    helm_trans1 = cv2.perspectiveTransform(np.array([arranged_helm_points[:,:2]],dtype=np.float32), NewH)\n    for r in range(len(helm_trans1[0])):\n      if scipy.spatial.distance.euclidean(helm_trans1[0,r,:2], arranged_track_points[r,:2])>5:\n        locations_to_del=np.append(locations_to_del, r)\n        # print('arranged_helm_points[r,:2]',arranged_helm_points[r],arranged_helm_points[r].shape)\n        helmets_with_no_label = np.append(helmets_with_no_label,np.array([arranged_helm_points[r]]), axis=0)\n    if len(locations_to_del)>0:\n      # print('lllll', locations_to_del)\n      arranged_track_points = np.delete(arranged_track_points, locations_to_del, 0)\n      arranged_helm_points = np.delete(arranged_helm_points, locations_to_del, 0)\n    # print('cc',helmets_with_no_label)\n    \n    #NewH, status = cv2.findHomography(arranged_helm_points[:,:2],arranged_track_points[:,:2], method =0)\n    NewH = findHomography_with_one_iteration(arranged_helm_points,arranged_track_points,list_of_homography[frame_number-1])\n    if NewH is not None:\n      list_of_homography[frame_number+1] = NewH\n    if len(helmets_with_no_label)>0 and NewH is not None:\n        # print('helmets_with_no_label', np.array([helmets_with_no_label]).shape, np.array([helmets_with_no_label]))\n        h_no_label = cv2.perspectiveTransform(np.array([helmets_with_no_label[:,:2]],dtype=np.float32), NewH)\n        t_without_alreadyassigned = np.copy(t)\n        for q in range(len(t_without_alreadyassigned)):\n          for r in range(len(arranged_track_points)):\n            if t_without_alreadyassigned[q][0]== arranged_track_points[r,0] and t_without_alreadyassigned[q][1]== arranged_track_points[r,1]:\n              t_without_alreadyassigned[q]=np.array([100000,100000])\n        dist_matrix =scipy.spatial.distance.cdist(h_no_label[0], t_without_alreadyassigned)\n        row_ind, col_ind = scipy.optimize.linear_sum_assignment(dist_matrix)\n        #print('row_ind', row_ind)\n        #print('col_ind', col_ind)\n        for r in range(len(col_ind)):\n          labels_clusters[int(helmets_with_no_label[r,2]-1)]=track_points['player'][col_ind[r]]\n    \n    if frame_number%50==0 and show_plots:\n        #print(labels_clusters)\n        arr_helm_points_trans = cv2.perspectiveTransform(np.array([arranged_helm_points[:,:2]],dtype=np.float32), NewH)\n        h_trans = cv2.perspectiveTransform(np.array([arranged_helm_points[:,:2]],dtype=np.float32), NewH)\n#         img = vid.get_data(frame_number +1)\n#         plt.imshow(img)\n#         plt.show()\n\n        #print('arranged_track_points',arranged_track_points)\n        #print('arr_helm_points_trans',arr_helm_points_trans)\n        \"\"\"\n        plt.figure(figsize=(10,10))\n        a = plt.plot(arranged_helm_points[:,0], arranged_helm_points[:,1],'bo', markersize = 10) #.set_label(\"Estimation of helmets on map\") #bleu\n        b = plt.plot(h[:,0], h[:,1],'rs',  markersize = 7, label= \"Tracking GPS\") #red\n        plt.show()\n        \"\"\"\n        \n        plt.figure(figsize=(10,10))\n        if len(helmets_with_no_label)>0:\n          new_trans = cv2.perspectiveTransform(np.array([helmets_with_no_label[:,:2]],dtype=np.float32), NewH)\n          c = plt.plot(new_trans[0,:,0], new_trans[0,:,1],'gs',  markersize = 12, label= \"Tracking GPS\") #red\n\n        a = plt.plot(h_trans[0,:,0], h_trans[0,:,1],'bo', markersize = 10) #.set_label(\"Estimation of helmets on map\") #bleu\n        b = plt.plot(t[:,0], t[:,1],'rs',  markersize = 7, label= \"Tracking GPS\") #red\n#         for p in range(len(arranged_track_points)):\n#           plt.plot([arr_helm_points_trans[0,p,0], arranged_track_points[p,0]], [arr_helm_points_trans[0,p,1], arranged_track_points[p,1]], 'k')\n\n#         plt.axes().set_aspect('equal')\n        #plt.legend([a,b], [\"Estimation of helmets on map\",\"Tracking GPS\"])\n#         red_patch = matplotlib.patches.Patch(color='red', label='Tracking GPS')\n#         blue_patch = matplotlib.patches.Patch(color='blue', label='Estimation of helmets on map')\n        #green_patch = matplotlib.patches.Patch(color='green', label='Corner helmets used')\n#         plt.legend(handles=[red_patch,blue_patch])\n        plt.show()\n        \n        print(frame_number, '-------------------')\n  return labels_clusters, list_of_homography, view_flip","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:25.996191Z","iopub.execute_input":"2021-10-27T22:55:25.996493Z","iopub.status.idle":"2021-10-27T22:55:26.043503Z","shell.execute_reply.started":"2021-10-27T22:55:25.996464Z","shell.execute_reply":"2021-10-27T22:55:26.042167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Assigning labels to clusters","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.618478Z","iopub.execute_input":"2021-10-26T22:27:38.619102Z","iopub.status.idle":"2021-10-26T22:27:38.629715Z","shell.execute_reply.started":"2021-10-26T22:27:38.619064Z","shell.execute_reply":"2021-10-26T22:27:38.628797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_distmatrix(dist_matrix, comb_matrix_clustrack, track_ind, helm_clusters, type_clusters, type_players, final_results):\n  ii = np.empty((1,0), np.int)\n  jj = np.empty((1,0), np.int)\n  for i in range(len(dist_matrix)):\n    for j in range(len(dist_matrix[0])):\n      a = comb_matrix_clustrack[helm_clusters[i]==type_clusters, track_ind[j]==type_players]\n      b=dist_matrix[i][j]\n      dist_matrix[i][j]=dist_matrix[i][j]+comb_matrix_clustrack[helm_clusters[i]==type_clusters, track_ind[j]==type_players]*100000000\n      if final_results.at[helm_clusters[i], 'PlayerID' ] == track_ind[j]:\n        ii = np.append(ii, i)\n        jj = np.append(jj, j)\n  if len(ii)>0:\n    dist_matrix = np.delete(dist_matrix, jj, 1)\n    dist_matrix = np.delete(dist_matrix, ii, 0)\n  return dist_matrix, ii, jj","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:31.580271Z","iopub.execute_input":"2021-10-27T22:55:31.580613Z","iopub.status.idle":"2021-10-27T22:55:31.592719Z","shell.execute_reply.started":"2021-10-27T22:55:31.580574Z","shell.execute_reply":"2021-10-27T22:55:31.591675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_comb_matrix_clusclus(output_deepsort):\n  #display(output_deepsort)\n  type_clusters= output_deepsort['deepsort_cluster'].value_counts().index.to_numpy()\n  combMatrix = np.zeros((len(type_clusters), len(type_clusters)))\n  for i in range(len(type_clusters)):\n    for j in range(len(type_clusters)):\n      od1 = output_deepsort[(output_deepsort['deepsort_cluster']==type_clusters[i]) | (output_deepsort['deepsort_cluster']==type_clusters[j])]\n      has_duplicate_labels = od1[[\"frame\"]].duplicated().any()\n      if has_duplicate_labels:\n        combMatrix[i, j]=1 \n      if i==j:\n        combMatrix[i, j]=1 \n  #display(combMatrix)\n  return combMatrix\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:34.437823Z","iopub.execute_input":"2021-10-27T22:55:34.43816Z","iopub.status.idle":"2021-10-27T22:55:34.449649Z","shell.execute_reply.started":"2021-10-27T22:55:34.43813Z","shell.execute_reply":"2021-10-27T22:55:34.447934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#inp = final res: updated final results\n#       comb_matrix_clusclus,\n#       comb_matrix_clustrack to update\n#       index_type_player\n#       index_cluster\ndef update_comb_matrix_clustrack(final_results, comb_matrix_clusclus, comb_matrix_clustrack,index_type_player, index_cluster):\n  for i in range(len(comb_matrix_clustrack)):\n    if comb_matrix_clusclus[index_cluster][i]==1:\n      comb_matrix_clustrack[i][index_type_player]= 1\n  return comb_matrix_clustrack\ndef flip_view_dataframe(deepsort_helms):\n  deepsort_helms['x'] = 1280 - deepsort_helms['x']\n  deepsort_helms['y'] = 720 - deepsort_helms['y']\n  return deepsort_helms","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:37.208518Z","iopub.execute_input":"2021-10-27T22:55:37.209684Z","iopub.status.idle":"2021-10-27T22:55:37.217634Z","shell.execute_reply.started":"2021-10-27T22:55:37.209622Z","shell.execute_reply":"2021-10-27T22:55:37.216591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################################################\n\ndef Majority_votingV7(Homo_list, output_deepsort, tracking_data, videoname, view_flip,comb_matrix_clusclus, current_results):\n\n  out_deep = output_deepsort.copy()\n  vn = videoname.split('_')\n  gameK=int(vn[0])\n  playid = int(vn[1])\n  view = str(vn[2]).replace('.mp4', '')\n  video_filename = video_path+videoname\n  #vid = imageio.get_reader(video_filename, 'ffmpeg')\n  #num_frames=vid._meta['nframes']\n  videoname = videoname.replace('.mp4','')\n  if 'Endzone'==view:\n    output_deepsort['x']=1280-output_deepsort['x']\n  output_deepsort['y']=720-output_deepsort['y']\n  if 'Endzone'==view:\n    X = output_deepsort['y'].copy()\n    Y = output_deepsort['x'].copy()\n    output_deepsort['x']=X\n    output_deepsort['y']=Y\n  if view_flip:\n    output_deepsort = flip_view_dataframe(output_deepsort.copy())\n\n  track_points = tracking_data[(tracking_data['playID']==playid)]\n  count_clusters = output_deepsort['deepsort_cluster'].value_counts().to_numpy()\n  type_clusters= output_deepsort['deepsort_cluster'].value_counts().index.to_numpy()\n  type_players = track_points['player'].unique()\n  print('count_clusters',count_clusters)\n  print('type of clusters',type_clusters)\n  print(track_points['player'].unique())\n\n  final_results= current_results.copy()\n  colname=['gameKey', 'playID', 'player', 'time', 'x', 'y', 's', 'a', 'dis', 'o','dir', 'event', 'game_play', 'snap', 'isSnap', 'team', 'snap_offset','est_frame', 'frame_num']\n  all_track_points = pd.DataFrame(None, columns = colname) #.insert(len(track_points.columns),'Frame_num',\n  for q in range(2,len(Homo_list)+1):\n    est_frame = find_nearest(track_points.est_frame.values, q)\n    track = track_points[track_points['est_frame']==est_frame].reset_index()\n    track['frame_num']=q\n    all_track_points = all_track_points.append(track)\n  #output_deepsort['frame']=output_deepsort['video_frame'].map(lambda element: int(element.split('_')[-1]))\n  display(all_track_points)\n  all_track_points.drop('index', 1, inplace=True)\n  all_track_points.reset_index(inplace=True)\n  comb_matrix_clustrack = np.zeros((len(type_clusters), len(type_players)))\n  for i in range(len(final_results)):\n    if final_results.at[type_clusters[i],'PlayerID' ] != '0.0':\n      index_type_player = np.where(type_players==final_results.at[type_clusters[i],'PlayerID' ])\n      comb_matrix_clustrack = update_comb_matrix_clustrack(final_results, comb_matrix_clusclus, comb_matrix_clustrack,index_type_player, i)\n\n  for cluster in range(len(type_clusters)):\n    #for cluster in range(2):\n\n    if final_results.at[type_clusters[cluster],'PlayerID' ] =='0.0':\n      #print('in1')\n      results = pd.DataFrame( np.zeros((len(type_clusters),len(type_players))))\n      results.index=type_clusters\n      results.columns = type_players\n      cnone = 0\n      cnotnone=0\n      for frame_num in range(2,len(Homo_list)):\n        track = all_track_points[all_track_points['frame_num']==frame_num].copy()\n        helm = output_deepsort[(output_deepsort['frame']==frame_num)].copy() #need to finish the location of the first players on first frame\n        track_ind = track['player'].to_numpy()\n        helm_clusters = helm['deepsort_cluster'].to_numpy()\n        t = track[['x','y']].to_numpy()\n        h = helm[['x','y']].to_numpy()\n        if h is not None or t is not None:\n          h_trans = cv2.perspectiveTransform(np.array([h[:,:2]],dtype=np.float32), Homo_list[frame_num-1])\n          if (h_trans is None) or (t is None) or (h is None):\n            cnone+=1\n          else:\n            cnotnone+=1\n            dist_matrix =scipy.spatial.distance.cdist(h_trans[0], t)\n            dist_matrix_update, deleted_clus , deleted_track = update_distmatrix(dist_matrix, comb_matrix_clustrack, track_ind, helm_clusters, type_clusters, type_players, final_results)\n            if len(dist_matrix)>0:\n              row_ind, col_ind = scipy.optimize.linear_sum_assignment(dist_matrix_update) #row: indexes of helmets, col: indexes of tracking\n            #if cluster>70:\n            #  print(dist_matrix_update)\n              \n              helm_clusters = np.delete(helm_clusters, deleted_clus, 0)\n              track_ind = np.delete(track_ind, deleted_track,0)\n              for r in range(len(row_ind)):             \n                results.at[int(helm_clusters[row_ind[r]]),track_ind[col_ind[r]]]=results.at[int(helm_clusters[row_ind[r]]),track_ind[col_ind[r]]]+1\n      for i in range(len(final_results)):\n        if final_results.at[type_clusters[i], 'PlayerID' ] != '0.0':\n          a= len(results)\n          results = results.drop(type_clusters[i])\n          #print('remooooooooove',final_results.at[type_clusters[i], 'PlayerID' ] , 'before:', a, 'after', len(results))\n      maxxx = results.max()\n      col_max = maxxx.idxmax(axis=0, skipna=True) #player id\n      row_max = results[col_max].idxmax(skipna=True) #cluster \n      final_results.at[int(row_max),'PlayerID' ] = col_max\n      print(cluster,'New combination:',col_max, 'with', row_max)\n      ind_player = np.where(type_players==col_max)\n      ind_clus = np.where(type_clusters==row_max)\n      print('ind_palyer', int(ind_player[0]), 'ind_clus', int(ind_clus[0]))\n      comb_matrix_clustrack = update_comb_matrix_clustrack(final_results, comb_matrix_clusclus, comb_matrix_clustrack,int(np.where(type_players==col_max)[0]), int(np.where(type_clusters==row_max)[0]))\n      \n        \n        \n      #with np.printoptions(threshold=np.inf):\n      #  print('comb_matrix_clustrack')\n      #  print(comb_matrix_clustrack)\n      \n  display(final_results)\n  return final_results","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:55:39.28451Z","iopub.execute_input":"2021-10-27T22:55:39.284801Z","iopub.status.idle":"2021-10-27T22:55:39.316587Z","shell.execute_reply.started":"2021-10-27T22:55:39.284773Z","shell.execute_reply":"2021-10-27T22:55:39.315467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making a submission","metadata":{}},{"cell_type":"code","source":"# sample_videos","metadata":{"execution":{"iopub.status.busy":"2021-10-26T23:10:41.859511Z","iopub.execute_input":"2021-10-26T23:10:41.860209Z","iopub.status.idle":"2021-10-26T23:10:41.863593Z","shell.execute_reply.started":"2021-10-26T23:10:41.860172Z","shell.execute_reply":"2021-10-26T23:10:41.862543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if debug:\n#    video_path = '.../input/NFL-Health-Safety/nfl-health-and-safety-helmet-assignment/train/'\n#else:\n#    video_path = '.../input/NFL-Health-Safety/nfl-health-and-safety-helmet-assignment/test/'\nvideo_path = '.../input/NFL-Health-Safety/nfl-health-and-safety-helmet-assignment/train/'\n#helmets_deepsort = pd.read_csv('deepsort_clusters.csv')\nhelmets_deepsort = pd.read_csv(\"../input/deepsort-clusters5/deepsort_clusters.csv\")\n\n\n# helmets_deepsort = pd.read_csv('../input/ds-clusters/deepsort_clusters.csv')\n# print(helmets_deepsort['deepsort_cluster'].unique())\nhelmets_deepsort = add_cols(helmets_deepsort)\nhelmets_deepsort['deepsort_cluster'] = helmets_deepsort['deepsort_cluster'].astype('int')\nhelmets_deepsort['x']=helmets_deepsort['left']+helmets_deepsort['width']/2\nhelmets_deepsort['y']=helmets_deepsort['top']+helmets_deepsort['height']/2\n\nsubmission_df = []\nheader = ['video_frame', 'label', 'left', 'width', 'top', 'height']\nprint(helmets_deepsort['video'].unique())\nfor vvv in range(len(helmets_deepsort['video'].unique())):\n  if vvv>0:\n    continue\n  vid=helmets_deepsort['video'].unique()[vvv]\n  print(\"Video:\", vid)\n  \n#   if '57995_000109_Endzone.mp4' not in vid:\n#     continue\n\n  gameK  = int(vid.split('_')[0])\n  playID = int(vid.split('_')[1])\n  view   = (vid.split('_')[2]).split('.')[0]\n  #cluster_info = sort_by_span(find_cluster_span(vid,helmets_deepsort))\n  #if debug:\n  #    display(cluster_info)\n\n  tracking_one_vid = tracking[(tracking['gameKey'] == gameK) & (tracking['playID'] == playID)].reset_index()\n  helmets_deepsort_one_vid = helmets_deepsort[helmets_deepsort['video'] == vid].reset_index()\n    \n  labels_clusters, list_of_homography, view_flip = homography_for_all_frames(vid, video_path, helmets_deepsort_one_vid.copy(), tracking.copy())\n  display(helmets_deepsort_one_vid)\n  print('---------------------assigning cluster to player----------------------------')\n  comb_matrix_clusclus = create_comb_matrix_clusclus(helmets_deepsort_one_vid.copy())\n  print(comb_matrix_clusclus)\n  type_clusters= helmets_deepsort_one_vid['deepsort_cluster'].value_counts().index.to_numpy()\n  display(type_clusters)\n  display(helmets_deepsort_one_vid['deepsort_cluster'].value_counts().to_numpy())\n  final_results = pd.DataFrame( np.zeros((len(type_clusters),1)).astype(np.unicode_), index=type_clusters, columns=['PlayerID'])\n  \n  Majority_voting_result = Majority_votingV7(list_of_homography, helmets_deepsort_one_vid.copy(), tracking_one_vid.copy(), vid, view_flip,comb_matrix_clusclus.copy(), final_results)\n  print('-----------------adding cluster columns--------------------------')\n  Majority_voting_result['cluster']=Majority_voting_result.index\n  with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    display(Majority_voting_result)\n  print('-------------------associating helmets with players id--------------------------')\n  columns = ['video_frame', 'left', 'width', 'top', 'height', 'label']\n  sub_video = []\n  for cluster in helmets_deepsort_one_vid['deepsort_cluster'].unique():\n    deep_sort_cluster_data = helmets_deepsort_one_vid[helmets_deepsort_one_vid['deepsort_cluster'] == cluster].reset_index()\n    player_label = Majority_voting_result[Majority_voting_result['cluster'] == cluster].reset_index()['PlayerID'][0]\n    for idx, vf in enumerate(deep_sort_cluster_data['video_frame']):\n        left = deep_sort_cluster_data['left'][idx]\n        width= deep_sort_cluster_data['width'][idx]\n        top = deep_sort_cluster_data['top'][idx]\n        height = deep_sort_cluster_data['height'][idx]\n        row = [vf, left, width, top, height, str(player_label)]\n        sub_video.append(row)\n  sub_video = pd.DataFrame(sub_video, columns= columns)\n  print('-------------------rmoving duplicates--------------------------')\n  has_duplicate_labels = sub_video[[\"video_frame\", \"label\"]].duplicated().any()\n  #print(has_duplicate_labels)\n  if has_duplicate_labels:\n    a=sub_video[[\"video_frame\", \"label\"]].duplicated()\n    #print(sub_video[a])\n    sub_video=sub_video.drop_duplicates(subset=[\"video_frame\", \"label\"])\n  #print(sub_video)\n  has_duplicate_labels = sub_video[[\"video_frame\", \"label\"]].duplicated().any()\n  #print('a', has_duplicate_labels)\n  \n  print('--------------------removing frames with too much players-------------------------')\n  remove_extra_helmets = []\n  all_different_frames = sub_video['video_frame'].unique()\n  #print(all_different_frames)\n  for idx, vf in enumerate(all_different_frames):\n    num_helms = len(sub_video[sub_video['video_frame'] == vf])\n    if num_helms > 22:\n      remove_extra_helmets.append(sub_video[sub_video['video_frame'] == vf].head(22))\n      print(vf, num_helms)\n    else:\n      remove_extra_helmets.append(sub_video[sub_video['video_frame'] == vf])\n\n  sub_video = pd.concat(remove_extra_helmets)\n  sub_video = sub_video.reset_index()\n  submission_df.append(sub_video)\n\n\n\nsubmission_df = pd.DataFrame(submission_df, columns = header)\ndisplay(submission_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:56:14.30029Z","iopub.execute_input":"2021-10-27T22:56:14.300575Z","iopub.status.idle":"2021-10-27T23:04:45.699412Z","shell.execute_reply.started":"2021-10-27T22:56:14.300547Z","shell.execute_reply":"2021-10-27T23:04:45.698147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['video_frame', 'left', 'width', 'top', 'height', 'label']\nsub_video = []\nfor cluster in helmets_deepsort_one_vid['deepsort_cluster'].unique():\n    deep_sort_cluster_data = helmets_deepsort_one_vid[helmets_deepsort_one_vid['deepsort_cluster'] == cluster].reset_index()\n    player_label = Majority_voting_result[Majority_voting_result['cluster'] == cluster].reset_index()['PlayerID'][0]\n    for idx, vf in enumerate(deep_sort_cluster_data['video_frame']):\n        left = deep_sort_cluster_data['left'][idx]\n        width= deep_sort_cluster_data['width'][idx]\n        top = deep_sort_cluster_data['top'][idx]\n        height = deep_sort_cluster_data['height'][idx]\n        row = [vf, left, width, top, height, str(player_label)]\n        sub_video.append(row)\nsub_video = pd.DataFrame(sub_video, columns= columns)\nprint('-------------------rmoving duplicates--------------------------')\nhas_duplicate_labels = sub_video[[\"video_frame\", \"label\"]].duplicated().any()\n#print(has_duplicate_labels)\nif has_duplicate_labels:\n    a=sub_video[[\"video_frame\", \"label\"]].duplicated()\n    #print(sub_video[a])\n    sub_video=sub_video.drop_duplicates(subset=[\"video_frame\", \"label\"])\n    #print(sub_video)\nhas_duplicate_labels = sub_video[[\"video_frame\", \"label\"]].duplicated().any()\n#print('a', has_duplicate_labels)\n\nprint('--------------------removing frames with too much players-------------------------')\nremove_extra_helmets = []\nall_different_frames = sub_video['video_frame'].unique()\n#print(all_different_frames)\nfor idx, vf in enumerate(all_different_frames):\n    num_helms = len(sub_video[sub_video['video_frame'] == vf])\n    if num_helms > 22:\n      remove_extra_helmets.append(sub_video[sub_video['video_frame'] == vf].head(22))\n      print(vf, num_helms)\n    else:\n      remove_extra_helmets.append(sub_video[sub_video['video_frame'] == vf])\n\nsub_video = pd.concat(remove_extra_helmets)\nsub_video = sub_video.reset_index()\nsubmission_df.append(sub_video)\n\nsubmission_df = pd.DataFrame(submission_df, columns = header)\ndisplay(submission_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T23:09:50.06699Z","iopub.execute_input":"2021-10-27T23:09:50.067365Z","iopub.status.idle":"2021-10-27T23:09:51.831949Z","shell.execute_reply.started":"2021-10-27T23:09:50.067337Z","shell.execute_reply":"2021-10-27T23:09:51.830927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nlabels = add_cols(labels)\ndisplay(labels)\nsample_videos = submission_df['video'].unique())):\nlabels = labels[labels['video'].isin(sample_videos)]\nscorer = NFLAssignmentScorer(labels)\nbaseline_score = scorer.score(submission_df)\nprint(f\"validation score {baseline_score:0.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df = submission_df[np.invert(submission_df[[\"video_frame\", \"label\"]].duplicated())]\n# print(len(sub_df))\n# len(submission_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.74783Z","iopub.status.idle":"2021-10-26T22:27:38.7485Z","shell.execute_reply.started":"2021-10-26T22:27:38.748251Z","shell.execute_reply":"2021-10-26T22:27:38.748274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_submission(submission_df):\n\n  submission_df = submission_df[np.invert(submission_df[[\"video_frame\", \"label\"]].duplicated())]\n\n  submission_df_with_extra_helms_removed = []\n  for vf in submission_df['video_frame'].unique():\n    num_helms = submission_df[submission_df['video_frame'] == vf]\n\n    if len(num_helms) > 22:\n      print('Video frame',vf,'has', len(num_helms) ,'frames')\n      num_helms = num_helms.head(22)\n      submission_df_with_extra_helms_removed.append(num_helms)\n    else:\n      submission_df_with_extra_helms_removed.append(num_helms)\n\n  submission_df = pd.concat(submission_df_with_extra_helms_removed, ignore_index= True)\n\n  return submission_df","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.749658Z","iopub.status.idle":"2021-10-26T22:27:38.750387Z","shell.execute_reply.started":"2021-10-26T22:27:38.750152Z","shell.execute_reply":"2021-10-26T22:27:38.750174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Length before cleaning:\",len(submission_df))\nsubmission_df = clean_submission(submission_df)\nprint(\"Length after cleaning:\",len(submission_df))\n\nsubmission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.751532Z","iopub.status.idle":"2021-10-26T22:27:38.752148Z","shell.execute_reply.started":"2021-10-26T22:27:38.751923Z","shell.execute_reply":"2021-10-26T22:27:38.751945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission Accuracy","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nds = pd.read_csv(\"../input/deepsort-clusters5/deepsort_clusters.csv\")\nds","metadata":{"execution":{"iopub.status.busy":"2021-10-27T22:06:30.52778Z","iopub.execute_input":"2021-10-27T22:06:30.528125Z","iopub.status.idle":"2021-10-27T22:06:30.617629Z","shell.execute_reply.started":"2021-10-27T22:06:30.528087Z","shell.execute_reply":"2021-10-27T22:06:30.616747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nlabels = labels[labels['video'].isin(['57906_00718_Endzone.mp4'])]\ndisplay(labels)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T20:39:59.635208Z","iopub.execute_input":"2021-10-27T20:39:59.63572Z","iopub.status.idle":"2021-10-27T20:40:01.008878Z","shell.execute_reply.started":"2021-10-27T20:39:59.635682Z","shell.execute_reply":"2021-10-27T20:40:01.008231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = '57781_000252_Sideline.mp4'\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nlabels = add_cols(labels)\ndisplay(labels)\n\n\nif debug:\n  labels = labels[labels['video'].isin(sample_videos)]\n  scorer = NFLAssignmentScorer(labels)\n  baseline_score = scorer.score(submission_df)\n  print(f\"validation score {baseline_score:0.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T20:29:14.873776Z","iopub.execute_input":"2021-10-27T20:29:14.874055Z","iopub.status.idle":"2021-10-27T20:29:16.267179Z","shell.execute_reply.started":"2021-10-27T20:29:14.874027Z","shell.execute_reply":"2021-10-27T20:29:16.264919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(sample_videos)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T20:14:29.81476Z","iopub.execute_input":"2021-10-27T20:14:29.815432Z","iopub.status.idle":"2021-10-27T20:14:29.82258Z","shell.execute_reply.started":"2021-10-27T20:14:29.815387Z","shell.execute_reply":"2021-10-27T20:14:29.82185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.755263Z","iopub.status.idle":"2021-10-26T22:27:38.755947Z","shell.execute_reply.started":"2021-10-26T22:27:38.75568Z","shell.execute_reply":"2021-10-26T22:27:38.755705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@input: tracking_data: full_track_information modified, so each row has frame and each frame has 22 players ID\n# #       helmet_cluster: simple helmet cluster\n# #@return: dataframe which matches the clusters to the players\n# #         tracking_data: removed the player that have already been assigned and just removed on the frames where they have been assigned\n# #         helmet_cluster: remove clusters that have been assigned already\n# def big_cluste_assignement(track_data, helmet_cluster)\n\n\n# input:table with ID-cluster\n#     range clusters\n#     tracking_data\n#     helmet_cluster\n    \n#     return id_cluster updated","metadata":{"execution":{"iopub.status.busy":"2021-10-26T22:27:38.757133Z","iopub.status.idle":"2021-10-26T22:27:38.757757Z","shell.execute_reply.started":"2021-10-26T22:27:38.757496Z","shell.execute_reply":"2021-10-26T22:27:38.757519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}