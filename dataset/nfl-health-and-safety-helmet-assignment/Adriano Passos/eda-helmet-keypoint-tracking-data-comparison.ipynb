{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Helmet Keypoint annotation tool\n\nSimple and lightweight tool to extract a frame from a video file and annotate the helmet center coordinates.\nThis notebook is part of a more comprehensive processing pipeline that is still being developed. I will be updating this notebook quite often.\n\nIf you find this helpful, consider upvoting it! Thanks =)","metadata":{}},{"cell_type":"markdown","source":"## Importing the dependencies","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image, ImageDraw\nfrom pathlib import Path\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:52:41.213154Z","iopub.execute_input":"2021-08-23T12:52:41.213579Z","iopub.status.idle":"2021-08-23T12:52:41.388367Z","shell.execute_reply.started":"2021-08-23T12:52:41.213485Z","shell.execute_reply":"2021-08-23T12:52:41.387231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting a frame from a video\n\nThis function uses ffmeg to exctract a single frame from a video. It saves on the working dir, loads it as a PIL image object and then deletes the image from disk","metadata":{}},{"cell_type":"code","source":"def get_frame_from_video(frame, video):\n    frame = frame - 1\n    !ffmpeg \\\n        -hide_banner \\\n        -loglevel fatal \\\n        -nostats \\\n        -i $video -vf \"select=eq(n\\,$frame)\" -vframes 1 frame.png\n    img = Image.open('frame.png')\n    os.remove('frame.png')\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:52:41.392036Z","iopub.execute_input":"2021-08-23T12:52:41.39239Z","iopub.status.idle":"2021-08-23T12:52:41.398962Z","shell.execute_reply.started":"2021-08-23T12:52:41.392356Z","shell.execute_reply":"2021-08-23T12:52:41.397899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, an example","metadata":{}},{"cell_type":"code","source":"video = '../input/nfl-health-and-safety-helmet-assignment/train/57583_000082_Endzone.mp4'\nframe = 1\nimg = get_frame_from_video(frame, video)\nimg","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:52:41.400466Z","iopub.execute_input":"2021-08-23T12:52:41.400792Z","iopub.status.idle":"2021-08-23T12:52:42.965009Z","shell.execute_reply.started":"2021-08-23T12:52:41.400764Z","shell.execute_reply":"2021-08-23T12:52:42.959669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keypoint overlaying\n\nTo annotate the image with the key-point information, we first need to calculate the x-y coordinate of the helmet's center.\nFor now, I will use the baseline bounding boxes.","metadata":{}},{"cell_type":"code","source":"bboxes_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_baseline_helmets.csv')\nvideo_frame = Path(video).stem + '_' + str(frame)\ndf = bboxes_df[bboxes_df['video_frame'] == video_frame].copy()\nxc = (df['left'] + df['width']/2).astype(int).values\nyc = (df['top'] + df['height']/2).astype(int).values\nxc, yc","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:52:42.966784Z","iopub.execute_input":"2021-08-23T12:52:42.96708Z","iopub.status.idle":"2021-08-23T12:52:44.593395Z","shell.execute_reply.started":"2021-08-23T12:52:42.967049Z","shell.execute_reply":"2021-08-23T12:52:44.592667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can annotate the image passing the helmet centers and the radius of the circle. Originaly I only used a point, but the size of the pixel is too small to see.","metadata":{}},{"cell_type":"code","source":"def annotate_frame(img, xc, yc, r, col = (57, 255, 20)):\n    draw = ImageDraw.Draw(img)\n    for x, y in zip(xc, yc):\n#         draw.point((x, y), fill=col)\n        draw.ellipse((x-r, y-r, x+r, y+r), fill=col, outline = 'black')\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:52:44.596622Z","iopub.execute_input":"2021-08-23T12:52:44.597362Z","iopub.status.idle":"2021-08-23T12:52:44.603511Z","shell.execute_reply.started":"2021-08-23T12:52:44.597322Z","shell.execute_reply":"2021-08-23T12:52:44.602765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotate_frame(img, xc, yc, 5)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:52:44.604825Z","iopub.execute_input":"2021-08-23T12:52:44.605433Z","iopub.status.idle":"2021-08-23T12:52:45.000316Z","shell.execute_reply.started":"2021-08-23T12:52:44.605396Z","shell.execute_reply":"2021-08-23T12:52:44.999565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code from: https://www.kaggle.com/robikscube/nfl-helmet-assignment-getting-started-guide\ndef add_track_features(tracks, fps=59.94, snap_frame=10):\n    \"\"\"\n    Add column features helpful for syncing with video data.\n    \"\"\"\n    tracks = tracks.copy()\n    tracks[\"game_play\"] = (\n        tracks[\"gameKey\"].astype(\"str\")\n        + \"_\"\n        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n    )\n    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n    snap_dict = (\n        tracks.query('event == \"ball_snap\"')\n        .groupby(\"game_play\")[\"time\"]\n        .first()\n        .to_dict()\n    )\n    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n        \"timedelta64[ms]\"\n    ) / 1_000\n    # Estimated video frame\n    tracks[\"est_frame\"] = (\n        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n    )\n    return tracks\n\ndef add_video_features(videos):\n    videos['game_play'] = videos['video_frame'].apply(lambda x: '_'.join(x.split('_')[:2]))\n    videos['camera'] = videos['video_frame'].apply(lambda x: x.split('_')[2])\n    videos['frame'] = videos['video_frame'].apply(lambda x: x.split('_')[-1])\n    videos['xc'] = (videos['left'] + videos['width']/2).astype(int).values\n    videos['yc'] = (videos['top'] + videos['height']/2).astype(int).values\n    return videos","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-23T12:52:45.001485Z","iopub.execute_input":"2021-08-23T12:52:45.00191Z","iopub.status.idle":"2021-08-23T12:52:45.014742Z","shell.execute_reply.started":"2021-08-23T12:52:45.001881Z","shell.execute_reply":"2021-08-23T12:52:45.013929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the tracking data\n\nIt would be helpful to have visualize the tracking data as well, so here a code that can plot dots on a nice 2d drawing of the football field","metadata":{}},{"cell_type":"code","source":"def annotate_field(xc, yc, player, r = 10, width = 3, col = [(27, 3, 163), (255, 7, 58)], crop = None, box = True):\n    field = Image.open('../input/nflhelmet-helper-dataset/field.png')\n    w, h = field.size\n    zero = (68,68)\n    fs = (2424,1100)\n    draw = ImageDraw.Draw(field)\n    xc, yc = xc*fs[0]/120 + zero[0], (1 - yc/53.3)*fs[1] + zero[1]\n    for x, y, p in zip(xc, yc, player):\n        c = col[0] if p[0] == 'H' else col[1]\n        draw.ellipse((x-r, y-r, x+r, y+r), fill=c, width=width, outline = 'black')\n    if isinstance(crop, float):\n        if box:\n            cp = [xc.min() - crop*w, yc.min() - crop*h, xc.max() + crop*w, yc.max() + crop*h]\n        else:\n            cp = [xc.min() - crop*w, 0, xc.max() + crop*2*w, h]\n        field = field.crop(cp)\n        \n    return field","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:54:33.996363Z","iopub.execute_input":"2021-08-23T12:54:33.99685Z","iopub.status.idle":"2021-08-23T12:54:34.00608Z","shell.execute_reply.started":"2021-08-23T12:54:33.996821Z","shell.execute_reply":"2021-08-23T12:54:34.005434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function inputs `x`, `y` coordinates as well as the tag of each player (to extract H or V for coloring). Here is an example:","metadata":{}},{"cell_type":"code","source":"tracking_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_player_tracking.csv')\ntracking_df = add_track_features(tracking_df)\nx, y, player = tracking_df.query(f\"game_play == '57583_000082' and est_frame == 10\")[['x', 'y', 'player']].values.transpose()\nannotate_field(x, y, player, r = 20)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T12:57:43.673989Z","iopub.execute_input":"2021-08-23T12:57:43.674401Z","iopub.status.idle":"2021-08-23T12:57:46.124768Z","shell.execute_reply.started":"2021-08-23T12:57:43.674366Z","shell.execute_reply":"2021-08-23T12:57:46.123748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combining all together (tracking + camera)\n\nFor this, I decided to use a class that initializes by creating the expanded dataframes.","metadata":{}},{"cell_type":"code","source":"class show_play_with_tracking():\n    \n    def __init__(self, video_df = None, track_df = None):\n        if video_df is None:\n            video_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_baseline_helmets.csv')\n            self.video_df = add_video_features(video_df)\n        if track_df is None:\n            tracking_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_player_tracking.csv')\n            tracking_df = add_track_features(tracking_df)\n            self.tracking_df = tracking_df.query(\"est_frame > 0\")\n       \n    def __call__(self, game_play, frame, img_size = 800, video_folder = '../input/nfl-health-and-safety-helmet-assignment/train/'):\n        \n        camera = 'Sideline'\n        frame_side = get_frame_from_video(frame, video_folder + game_play + '_' + camera + '.mp4')\n        df = self.video_df.query(f\"game_play == '{game_play}' and frame == '{frame}' and camera == '{camera}'\")\n        frame_side = annotate_frame(frame_side, df.xc, df.yc, 10)\n\n        camera = 'Endzone'\n        frame_end = get_frame_from_video(frame, video_folder + game_play + '_' + camera + '.mp4')\n        df = self.video_df.query(f\"game_play == '{game_play}' and frame == '{frame}' and camera == '{camera}'\")\n        frame_end = annotate_frame(frame_end, df.xc, df.yc, 10)\n\n        frames = self.tracking_df['est_frame'].values\n        if frame not in frames:\n            index = np.absolute(frames-frame).argmin()\n            frame = frames[index]\n        df = self.tracking_df.query(f\"game_play == '{game_play}' and est_frame == {frame}\")\n        field = annotate_field(df.x, df.y, df.player, 10, crop = 0.01)\n\n        wf, hf = field.size\n        wc, hc = frame_side.size\n        field = field.resize((int(wf*2*hc/hf), 2*hc))\n        wf, hf = field.size\n\n        img = Image.new('RGB', (wf+wc+20, 2*hc+20))\n        img.paste(im=field, box=(5, 10))\n        img.paste(im=frame_side, box=(wf+15, 5))\n        img.paste(im=frame_end, box=(wf+15, hc+15))\n        img.thumbnail((img_size,img_size))\n        return img","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:03:18.107472Z","iopub.execute_input":"2021-08-23T13:03:18.107818Z","iopub.status.idle":"2021-08-23T13:03:18.131602Z","shell.execute_reply.started":"2021-08-23T13:03:18.107787Z","shell.execute_reply":"2021-08-23T13:03:18.130565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initializing the class with the default dataframes (`train_baseline_helmets.csv` and `train_player_tracking.csv`)","metadata":{}},{"cell_type":"code","source":"spwt = show_play_with_tracking()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:03:19.828985Z","iopub.execute_input":"2021-08-23T13:03:19.82936Z","iopub.status.idle":"2021-08-23T13:03:25.147873Z","shell.execute_reply.started":"2021-08-23T13:03:19.829328Z","shell.execute_reply":"2021-08-23T13:03:25.146792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here is an example for the gameplay `57682_002630` at frame 1:","metadata":{}},{"cell_type":"code","source":"spwt('57682_002630', 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:03:39.564676Z","iopub.execute_input":"2021-08-23T13:03:39.565053Z","iopub.status.idle":"2021-08-23T13:03:42.166215Z","shell.execute_reply.started":"2021-08-23T13:03:39.565015Z","shell.execute_reply":"2021-08-23T13:03:42.165201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With this function we could easily do that for all 60 videos!","metadata":{}},{"cell_type":"code","source":"all_plays = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_baseline_helmets.csv')['video_frame'].\\\n                apply(lambda x: '_'.join(x.split('_')[:2])).unique()\nlen(all_plays)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:04:38.577422Z","iopub.execute_input":"2021-08-23T13:04:38.577825Z","iopub.status.idle":"2021-08-23T13:04:40.408648Z","shell.execute_reply.started":"2021-08-23T13:04:38.577788Z","shell.execute_reply":"2021-08-23T13:04:40.407681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grab a coffee coz this will take a while ☕","metadata":{}},{"cell_type":"code","source":"imgs = []\nfor play in tqdm(all_plays):\n    imgs.append(spwt(play, 1, 400)) # gameplay, frame, img_size\nimgs = [imgs[0:20], imgs[20:40], imgs[40:60]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"W, H = 400, 250\nimg = Image.new('RGB', (W*3, H*20), (255, 255, 255))\nfor x in range(3):\n    for y in range(20):\n        img.paste(im=imgs[x][y], box=(W*x, H*y))\nimg","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:10:30.981709Z","iopub.execute_input":"2021-08-23T13:10:30.982085Z","iopub.status.idle":"2021-08-23T13:10:32.468222Z","shell.execute_reply.started":"2021-08-23T13:10:30.982049Z","shell.execute_reply":"2021-08-23T13:10:32.465271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A few learned lessons","metadata":{}},{"cell_type":"markdown","source":"### Lesson 1 \n\nIf you are planing to use tracking data mapping. You can't have perfect score just by predicting each frame independently. On this example, we can't see the red guy in the endzone on either cameras.","metadata":{}},{"cell_type":"code","source":"spwt('57682_002630', 300)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The only way you could predict the red dot in the Endzone is by having temporal coherence. If you rewind this 100 frames you can see him.","metadata":{}},{"cell_type":"code","source":"spwt('57682_002630', 200)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lesson 2\n\nCamera placemente is not consistent. Some gameplays, have the camera on the home endzone some on the visitor endzone","metadata":{}},{"cell_type":"code","source":"# Camera is on the TOP and LEFT in relation to the tracking data\nspwt(all_plays[30], 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:12:59.585149Z","iopub.execute_input":"2021-08-23T13:12:59.58554Z","iopub.status.idle":"2021-08-23T13:13:02.238862Z","shell.execute_reply.started":"2021-08-23T13:12:59.585503Z","shell.execute_reply":"2021-08-23T13:13:02.237817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Camera is on the BOTTOM and LEFT in relation to the tracking data\nspwt(all_plays[1], 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:15:08.23263Z","iopub.execute_input":"2021-08-23T13:15:08.233009Z","iopub.status.idle":"2021-08-23T13:15:10.864287Z","shell.execute_reply.started":"2021-08-23T13:15:08.232971Z","shell.execute_reply":"2021-08-23T13:15:10.863128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Camera is on the BOTTOM and RIGHT in relation to the tracking data\nspwt(all_plays[2], 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T13:16:04.800143Z","iopub.execute_input":"2021-08-23T13:16:04.800551Z","iopub.status.idle":"2021-08-23T13:16:07.489236Z","shell.execute_reply.started":"2021-08-23T13:16:04.800514Z","shell.execute_reply":"2021-08-23T13:16:07.488288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# That is it for now! more coming soon! =)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}