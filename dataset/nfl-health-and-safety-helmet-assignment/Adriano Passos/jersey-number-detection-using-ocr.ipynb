{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using OCR to read players numbers\n\nIn this notebook:\n1. I use EasyOCR package in an attempt at reading the number on the players jerseys\n\nThis code was inspired on [this](http://https://www.kaggle.com/jinssaa/jersey-number-detection-using-ocr) great kernel","metadata":{}},{"cell_type":"markdown","source":"The first thing is to install EasyOCR with `pip install`","metadata":{}},{"cell_type":"code","source":"! pip install -q easyocr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-16T14:23:19.133825Z","iopub.execute_input":"2021-09-16T14:23:19.134673Z","iopub.status.idle":"2021-09-16T14:23:28.792461Z","shell.execute_reply.started":"2021-09-16T14:23:19.134629Z","shell.execute_reply":"2021-09-16T14:23:28.791336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Folowed by importing some basic libraries","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport easyocr\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\n\nfrom glob import glob\nfrom random import sample\nfrom PIL import Image, ImageFont, ImageDraw, ImageEnhance\n\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:28.794832Z","iopub.execute_input":"2021-09-16T14:23:28.795183Z","iopub.status.idle":"2021-09-16T14:23:30.783318Z","shell.execute_reply.started":"2021-09-16T14:23:28.795139Z","shell.execute_reply":"2021-09-16T14:23:30.782575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I also loaded some defaults like the font I will be using and the color for the overlay text","metadata":{}},{"cell_type":"code","source":"FONT = ImageFont.truetype(\"../input/arial-font/arial.ttf\", 15)\nGREEN = (57,255,20)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:41.42802Z","iopub.execute_input":"2021-09-16T14:23:41.428334Z","iopub.status.idle":"2021-09-16T14:23:41.436809Z","shell.execute_reply.started":"2021-09-16T14:23:41.428301Z","shell.execute_reply":"2021-09-16T14:23:41.435664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To use EasyOCR, first you need to initialize the model. This will load (or download it too if needed). You can pass the language an if it should be loaded into the GPU or not (and some other paramters too)","metadata":{}},{"cell_type":"code","source":"reader = easyocr.Reader(['en'], gpu=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:42.373026Z","iopub.execute_input":"2021-09-16T14:23:42.373345Z","iopub.status.idle":"2021-09-16T14:23:46.021098Z","shell.execute_reply.started":"2021-09-16T14:23:42.373313Z","shell.execute_reply":"2021-09-16T14:23:46.020166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To apply the OCR model to an image, it is as easy as a single line","metadata":{}},{"cell_type":"code","source":"file = '../input/nfl-helmet-safety-cropped-jerseys-dataset-png/57583_000082_Sideline_342_H36.png'\nreader.readtext(file, allowlist ='0123456789')","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:26:58.449376Z","iopub.execute_input":"2021-09-16T14:26:58.449688Z","iopub.status.idle":"2021-09-16T14:26:58.522893Z","shell.execute_reply.started":"2021-09-16T14:26:58.449657Z","shell.execute_reply":"2021-09-16T14:26:58.522074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But this didn't work... The reason why is that our crop is too small. A quick-n-dirty hack is to re-scale the image","metadata":{}},{"cell_type":"code","source":"img = Image.open(file)\nimg","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:27:52.195157Z","iopub.execute_input":"2021-09-16T14:27:52.195444Z","iopub.status.idle":"2021-09-16T14:27:52.205303Z","shell.execute_reply.started":"2021-09-16T14:27:52.195393Z","shell.execute_reply":"2021-09-16T14:27:52.204438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open(file).resize((128,128))\nimg","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:28:23.137207Z","iopub.execute_input":"2021-09-16T14:28:23.137956Z","iopub.status.idle":"2021-09-16T14:28:23.155707Z","shell.execute_reply.started":"2021-09-16T14:28:23.137917Z","shell.execute_reply":"2021-09-16T14:28:23.154728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reader.readtext(np.array(img), allowlist ='0123456789')","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:28:25.945489Z","iopub.execute_input":"2021-09-16T14:28:25.945762Z","iopub.status.idle":"2021-09-16T14:28:26.12047Z","shell.execute_reply.started":"2021-09-16T14:28:25.945735Z","shell.execute_reply":"2021-09-16T14:28:26.118793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model now reads the number '36' (second argument). The values `readtext` returns are:\n1. Bounding box\n1. Label\n1. Confidence","metadata":{}},{"cell_type":"markdown","source":"## Runing against 1k images\n\nNow that we got the basics covered, we can run this trough a bunch of images. The folowing code do:\n1. Get all the files inside my custom cropped dataset\n1. Make a new directory named `annotated`\n1. Loop trough the first N pictures and:\n    1. Try to read any number on the image\n    1. If it finds anything it writes the bbox, label and confidence over the image and save it inside `annotated` folder\n1. Zip the folder and delete all files\n\nWith that, you can simply download the zipped folder and see the final results","metadata":{}},{"cell_type":"code","source":"FILES = glob('../input/nfl-helmet-safety-cropped-jerseys-dataset-png/*.png')","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:46.022828Z","iopub.execute_input":"2021-09-16T14:23:46.023166Z","iopub.status.idle":"2021-09-16T14:24:53.034523Z","shell.execute_reply.started":"2021-09-16T14:23:46.023123Z","shell.execute_reply":"2021-09-16T14:24:53.033853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir annotated","metadata":{"execution":{"iopub.status.busy":"2021-09-16T01:16:28.331444Z","iopub.execute_input":"2021-09-16T01:16:28.332125Z","iopub.status.idle":"2021-09-16T01:16:29.06771Z","shell.execute_reply.started":"2021-09-16T01:16:28.332084Z","shell.execute_reply":"2021-09-16T01:16:29.066639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 1000\ncorrect_predictions = []\nconf_th = 0.01\nsave = False\nfor file in tqdm(FILES[:N]):\n    file = Path(file)\n    img = Image.open(file).resize((128,128))\n    draw = ImageDraw.Draw(img)\n    for bbox, label, conf in reader.readtext(np.array(img), allowlist ='0123456789'):\n        correct = file.stem.split('_')[-1][1:] == label\n        correct_predictions.append(correct)\n        if conf > conf_th:\n            save = True\n            draw.rectangle((tuple(bbox[0]), tuple(bbox[2])), outline = GREEN, width = 2)\n            draw.text(((bbox[0][0] + bbox[1][0])/2, bbox[0][1] - 2), f'{label}({conf:.2f})', anchor=\"ms\", font=FONT, fill = GREEN)\n    if save:\n        img.save(Path('./annotated')/file.name)\n        save = False","metadata":{"execution":{"iopub.status.busy":"2021-09-16T01:16:29.069715Z","iopub.execute_input":"2021-09-16T01:16:29.0701Z","iopub.status.idle":"2021-09-16T01:18:59.398159Z","shell.execute_reply.started":"2021-09-16T01:16:29.07005Z","shell.execute_reply":"2021-09-16T01:18:59.397249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, the accuracy is not very good. We get about 30% right when we try to predict anything at all. That number alone is not that bad. The problem is that the algoritm hardly predicts anything. Most of the time the numbers are too blury or just simply occluded for the model to do any prediction.","metadata":{}},{"cell_type":"code","source":"print(f'Average number of RELATIVE correct predictions {np.array(correct_predictions).mean()}')\nprint(f'Average number of TOTAL correct predictions {np.array(correct_predictions).sum()/N}')","metadata":{"execution":{"iopub.status.busy":"2021-09-16T01:18:59.45819Z","iopub.execute_input":"2021-09-16T01:18:59.45895Z","iopub.status.idle":"2021-09-16T01:18:59.464773Z","shell.execute_reply.started":"2021-09-16T01:18:59.45891Z","shell.execute_reply":"2021-09-16T01:18:59.463688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thanks for reading\n\nThat would be all for this kernel. As you can see this technique is not strong enough to be used alone. My hopes of sharing this publicly is that maybe someone could improve this approach so we can actualy use it.","metadata":{}},{"cell_type":"code","source":"from zipfile import ZipFile\nimport shutil\nimport os\ndef zip_folder(folder, rm_original = True):\n    # iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(folder):\n        # create a ZipFile object\n        with ZipFile(folderName.split('/')[-1] + '.zip', 'w') as zipObj:\n            for filename in filenames:\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # add file to zip\n                zipObj.write(filePath, os.path.basename(filePath))\n                # delete the file to open space\n                if rm_original:\n                    os.remove(filePath)\n    if rm_original:\n        shutil.rmtree(folder)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T01:16:17.082385Z","iopub.execute_input":"2021-09-16T01:16:17.082635Z","iopub.status.idle":"2021-09-16T01:16:17.091819Z","shell.execute_reply.started":"2021-09-16T01:16:17.082607Z","shell.execute_reply":"2021-09-16T01:16:17.090686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip_folder('annotated')","metadata":{"execution":{"iopub.status.busy":"2021-09-16T01:18:59.399698Z","iopub.execute_input":"2021-09-16T01:18:59.400018Z","iopub.status.idle":"2021-09-16T01:18:59.45681Z","shell.execute_reply.started":"2021-09-16T01:18:59.399976Z","shell.execute_reply":"2021-09-16T01:18:59.455965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}