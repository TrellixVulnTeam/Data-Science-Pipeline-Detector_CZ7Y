{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Install helmet-assignment helper code\n!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\nfrom helmet_assignment.score import NFLAssignmentScorer, check_submission\nfrom helmet_assignment.features import add_track_features\nfrom helmet_assignment.video import video_with_predictions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T07:57:18.432411Z","iopub.execute_input":"2021-09-09T07:57:18.432921Z","iopub.status.idle":"2021-09-09T07:57:48.776158Z","shell.execute_reply.started":"2021-09-09T07:57:18.43288Z","shell.execute_reply":"2021-09-09T07:57:48.774757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nimport glob\nimport os\nimport copy\nimport cv2\nimport math\nimport shutil\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nfrom IPython.display import Video, display\nfrom tqdm.auto import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import KDTree\nfrom scipy.optimize import linear_sum_assignment\nfrom scipy.spatial import distance\nimport random\nimport sys\nsys.path.append('../input/easydict-master/easydict-master/')\n# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\nsys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\nfrom deep_sort.deep_sort import DeepSort\nfrom utils.parser import get_config\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:57:48.779248Z","iopub.execute_input":"2021-09-09T07:57:48.779535Z","iopub.status.idle":"2021-09-09T07:57:48.789363Z","shell.execute_reply.started":"2021-09-09T07:57:48.779506Z","shell.execute_reply":"2021-09-09T07:57:48.788411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions\n## line param pred","metadata":{}},{"cell_type":"code","source":"def calc_dif_angle(theta1, theta2):\n    theta_large, theta_small = np.zeros_like(theta1), np.zeros_like(theta2)\n    theta_large = np.max(np.array([theta1, theta2]), axis=0)\n    theta_small = np.min(np.array([theta1, theta2]), axis=0)\n\n    dif1 = theta_large - theta_small\n    dif2 = np.pi + theta_small - theta_large\n    return np.min(np.array([dif1, dif2]), axis=0)\n\ndef calc_loss_angles(angles, target_angle, thres = 0.4):\n    dif = calc_dif_angle(angles, np.ones_like(angles) * target_angle)\n    loss = dif * dif\n    loss[dif > thres] = np.abs(dif[dif > thres]) # Huber loss\n    return np.sum(loss)\n\ndef calc_optimal_angle(angles):\n    angle_opt = 0\n    loss_opt = 1e9\n    for ang in np.linspace(0, np.pi, 100):\n        loss = calc_loss_angles(angles, ang)\n        if loss < loss_opt:\n            loss_opt = loss\n            angle_opt = ang\n    return angle_opt\n\ndef loss_func(cand_scale, dif_list):\n    loss_residual = np.sum([\n        np.min([np.abs(dif % cand_scale), np.abs(cand_scale - dif % cand_scale)]\n              ) ** 2 for dif in dif_list]) # 割ったあまり\n    loss_multipled = np.sum([np.max(dif // cand_scale - 1, 0) for dif in dif_list]) # n倍なら、n-1を罰則として与える（n >= 1ならなし）\n    loss_under = np.sum([np.max(cand_scale // dif - 1, 0) for dif in dif_list]) # 1/n倍なら、n-1を罰則として与える（n <= 1ならなし）\n    return loss_residual + loss_multipled + loss_under\n\ndef get_optimal_dif(dif_list, view):\n    opt_dif = 0\n    opt_loss = 1e9\n    if view == 'Sideline':\n        candidates = np.arange(100, 250, 5)\n    else:\n        candidates = np.arange(70, 170, 5)\n        \n    for x in candidates:\n        loss = loss_func(x, dif_list)\n        if loss < opt_loss:\n            opt_dif = x\n            opt_loss = loss\n    return opt_dif\n\ndef get_average_dist_from_lines(line_pos_list, view):\n    sets = []\n    min_thres = 30\n    for d in sorted(line_pos_list):\n        if len(sets) == 0:\n            sets.append([d])\n        else:\n            if d - sets[-1][-1] < min_thres:\n                sets[-1].append(d)\n            else:\n                sets.append([d])\n    pos_list = np.array([np.mean(set_pos) for set_pos in sets])\n    \n    if True:\n        dist_pred = get_optimal_dif(pos_list[1:] - pos_list[:-1], view)\n    else:\n        dist_pred = np.mean(pos_list[1:] - pos_list[:-1])\n    # print(*pos_list, sep=',')\n    # print(*pos_list[1:] - pos_list[:-1], sep=',')\n    return dist_pred\n\ndef predict_line_parameters(img, view = 'Endzone'):\n    kernel_size = 40\n    img_dif_threshold = 70\n\n    kernel = np.ones((kernel_size, kernel_size)) / kernel_size **2\n    img_morph = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n    counter = 0\n\n    while True:\n        img_dif = np.linalg.norm(img_morph - np.median(img, axis=(0, 1)), axis=2)\n        img_field = np.copy(img)\n        img_field[img_dif > img_dif_threshold - counter * 10] = 0\n        edges = cv2.Canny(img_field, 50, 150, apertureSize = 3)\n        lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n        if lines is None:\n            return np.nan, np.nan\n        if len(lines) < 100:\n            break\n        counter += 1\n        if img_dif_threshold - counter * 10 < 0:\n            return np.nan, np.nan\n    \n    if lines is None:\n        return np.nan, np.nan\n    if len(lines) > 100:\n        return np.nan, np.nan\n\n    # Drop duplicates\n    lines_new = np.copy(lines)\n    thres_angle = 0.1\n    thres_dist = 20\n    idx = 0\n    while len(lines_new) > idx:\n        dif_dist = lines_new[:, 0, 0] - lines_new[idx, 0, 0]\n        dif_angle = calc_dif_angle(lines_new[:, 0, 1], np.ones_like(lines_new[:, 0, 1]) * lines_new[idx, 0, 1])\n        duplicate = (dif_dist < thres_dist) & (dif_angle < thres_angle) & (dif_dist > 0) & (dif_angle > 0)\n        lines_new = lines_new[~duplicate]\n        idx += 1\n\n    if view == 'Sideline':\n        lines_new = lines_new[np.abs(lines_new[:, 0, 1] - np.pi / 2) > np.pi / 4]\n    else:\n        lines_new = lines_new[np.abs(lines_new[:, 0, 1] - np.pi / 2) < np.pi / 4]\n    lines_new = lines_new[lines_new[:, 0, 1] != 0] # Remove edges\n\n    # Calculate angles (Took a lot of time defining optimal angle...)\n    theta_pred = calc_optimal_angle(lines_new[:, 0, 1])\n    lines_same_direction = lines_new[calc_dif_angle(lines_new[:, 0, 1], np.ones_like(lines_new[:, 0, 1]) * theta_pred) < 0.4]\n    if len(lines_same_direction) == 0:\n        return np.nan, np.nan\n\n    if view == 'Sideline':\n        ym = 360\n        rho = lines_same_direction[:, 0, 0]\n        theta = lines_same_direction[:, 0, 1]\n        xms = (rho - ym * np.sin(theta)) / np.cos(theta)\n        dist_pred = get_average_dist_from_lines(xms, view) * np.abs(np.cos(theta_pred))\n    else:\n        xm = 640\n        rho = lines_same_direction[:, 0, 0]\n        theta = lines_same_direction[:, 0, 1]\n        yms = (rho - xm * np.cos(theta)) / np.sin(theta)\n        dist_pred = get_average_dist_from_lines(yms, view) * np.abs(np.sin(theta_pred))\n\n    return theta_pred, dist_pred","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T07:57:48.791898Z","iopub.execute_input":"2021-09-09T07:57:48.792331Z","iopub.status.idle":"2021-09-09T07:57:48.831686Z","shell.execute_reply.started":"2021-09-09T07:57:48.792288Z","shell.execute_reply":"2021-09-09T07:57:48.830503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## icp","metadata":{}},{"cell_type":"code","source":"from scipy.spatial import KDTree\nimport numpy as np\n\nclass ICP(object):\n    def __init__(self, pointsA, pointsB):\n        self.pointsA = pointsA\n        self.pointsB = pointsB\n        self.kdtree = KDTree(self.pointsA)\n        self.loss = 0\n\n    def calculate(self, iter):\n        old_points = np.copy(self.pointsB)\n        new_points = np.copy(self.pointsB)\n\n        try:\n            for i in range(iter):\n                neighbor_idx = self.kdtree.query(old_points)[1]\n                targets = self.pointsA[neighbor_idx]\n                R, T = calcRigidTranformation(old_points, targets)\n                new_points = np.dot(R, old_points.T).T + T\n                if  np.sum(np.abs(old_points - new_points)) < 1e-10:\n                    break\n\n                old_points = np.copy(new_points)\n\n                self.loss = np.mean(np.linalg.norm(targets - new_points, axis=1))\n        except:\n            return new_points\n\n        return new_points\n\ndef calcRigidTranformation(MatA, MatB):\n    A, B = np.copy(MatA), np.copy(MatB)\n\n    centroid_A = np.mean(A, axis=0)\n    centroid_B = np.mean(B, axis=0)\n\n    A -= centroid_A\n    B -= centroid_B\n\n    H = np.dot(A.T, B)\n    U, S, V = np.linalg.svd(H)\n    R = np.dot(V.T, U.T)\n    T = np.dot(-R, centroid_A) + centroid_B\n\n    return R, T","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T07:57:48.834019Z","iopub.execute_input":"2021-09-09T07:57:48.834475Z","iopub.status.idle":"2021-09-09T07:57:48.850269Z","shell.execute_reply.started":"2021-09-09T07:57:48.834429Z","shell.execute_reply":"2021-09-09T07:57:48.849268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_hungarian_matching(pos_helmets_input, pos_tracking_input, rate_x2y):\n    pos_helmets = np.copy(pos_helmets_input)\n    pos_tracking = np.copy(pos_tracking_input)\n    pos_helmets[:, 0] *= rate_x2y\n    pos_tracking[:, 0] *= rate_x2y\n    dist_matrix = distance.cdist(pos_helmets, pos_tracking, metric='euclidean')\n    helmets_idx, tracking_idx = linear_sum_assignment(dist_matrix)\n    dist = np.array([dist_matrix[i, j] for i, j in zip(helmets_idx, tracking_idx)])\n    return dist, helmets_idx, tracking_idx","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T07:57:48.851432Z","iopub.execute_input":"2021-09-09T07:57:48.851788Z","iopub.status.idle":"2021-09-09T07:57:48.866131Z","shell.execute_reply.started":"2021-09-09T07:57:48.851735Z","shell.execute_reply":"2021-09-09T07:57:48.865133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_icp_results(pos_helmets, pos_tracking, theta_init, initial_scale_x, initial_scale_y):\n    pos_helmets_scaled = np.copy(pos_helmets)\n    pos_helmets_scaled[:, 0] = pos_helmets_scaled[:, 0] * initial_scale_x\n    pos_helmets_scaled[:, 1] = pos_helmets_scaled[:, 1] * initial_scale_y\n\n    initial_rot = np.array([[np.cos(theta_init), np.sin(theta_init)],\n                            [-np.sin(theta_init), np.cos(theta_init)]])\n    pos_helmets_initialized = pos_helmets_scaled @ initial_rot\n    pos_helmets_initialized -= np.mean(pos_helmets_initialized, axis=0) - np.mean(pos_tracking, axis=0)\n\n    icp = ICP(pos_tracking, pos_helmets_initialized)\n    pos_helmets_icp = icp.calculate(3000)\n\n    return pos_helmets_icp, icp.loss","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T07:57:48.867534Z","iopub.execute_input":"2021-09-09T07:57:48.868074Z","iopub.status.idle":"2021-09-09T07:57:48.877441Z","shell.execute_reply.started":"2021-09-09T07:57:48.868035Z","shell.execute_reply":"2021-09-09T07:57:48.87658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MonteCarloICP:\n    def __init__(self, initial_scale_factor, view, num_iter, rate_x2y):\n        self.scale_factors = initial_scale_factor\n        self.num_iter = num_iter\n        self.view = view\n        self.rate_x2y = rate_x2y\n\n    def get_icp_results_montecarlo(self, pos_helmets_input, pos_tracking_input, theta_init, tracking_orientation,):\n        ###### PARAMETERS ######\n        pixel_per_line_cand_sideline=np.hstack([np.arange(150, 250, 10), np.arange(250, 701, 50)])\n        # pixel_per_line_cand_sideline=np.arange(150, 250, 10)\n        pixel_per_line_cand_endzone=np.hstack([np.arange(60, 160, 15), np.arange(200, 401, 40)])\n        # pixel_per_line_cand_endzone=np.arange(60, 160, 15)\n        ###### PARAMETERS ######\n\n\n        opt_loss = 1e9\n        pos_helmets_opt = None\n        self.opt_params = None # Dont forget to initialize!!!!\n        for i in range(self.num_iter):\n            if self.view == 'Sideline':\n                pixel_per_line = random.choice(pixel_per_line_cand_sideline)\n            else:\n                pixel_per_line = random.choice(pixel_per_line_cand_endzone)\n            # pixel_per_line = pixel_per_line_init\n            \n            if np.isnan(theta_init):\n                if self.view == \"Sideline\":\n                    theta_init = random.gauss(0, np.pi / 8)\n                else:\n                    theta_init = random.gauss(np.pi / 2, np.pi / 8)\n\n            initial_scale_x = self.scale_factors[0] / pixel_per_line * np.exp(np.log(1.5) * (0.5 - np.random.random()) * 2)\n            initial_scale_y = self.scale_factors[1] / pixel_per_line * np.exp(np.log(1.5) * (0.5 - np.random.random()) * 2)\n            forward_shift_scale = random.random() * 0.4\n\n            # Copy variables\n            pos_tracking = np.copy(pos_tracking_input)\n            pos_helmets = np.copy(pos_helmets_input)\n\n            pos_tracking += forward_shift_scale * np.array([\n                np.cos((- tracking_orientation + 90) / 180 * np.pi),\n                np.sin((- tracking_orientation + 90) / 180 * np.pi)]\n            ).T\n\n            pos_helmets_icp, icp_loss = get_icp_results(\n                pos_helmets, pos_tracking,\n                theta_init, initial_scale_x, initial_scale_y)\n\n            dist, helmets_idx, tracking_idx = calculate_hungarian_matching(\n                pos_helmets_icp,\n                pos_tracking,\n                self.rate_x2y\n            )\n            score = np.sum(dist)\n            if score < opt_loss:\n                opt_loss = score\n                pos_helmets_opt = pos_helmets_icp\n                self.opt_params = (initial_scale_x, initial_scale_y, forward_shift_scale)\n            \n        return pos_helmets_opt, opt_loss","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T07:57:48.879133Z","iopub.execute_input":"2021-09-09T07:57:48.879512Z","iopub.status.idle":"2021-09-09T07:57:48.895791Z","shell.execute_reply.started":"2021-09-09T07:57:48.879482Z","shell.execute_reply":"2021-09-09T07:57:48.894744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_icp_per_frame_by_team(args):\n    ###### PARAMETERS ######\n    num_particles=100\n    rate_x2y={'Endzone': 0.5, 'Sideline': 1.0}\n    scale_factor={'Endzone': [2, 4.5], 'Sideline': [4, 10]}\n    team_dif_penalty=2.0\n    ###### PARAMETERS ######\n\n    game_play, view, frame, tracking_frame, helmets_frame = args\n    tracking_frame = tracking_frame[~tracking_frame.duplicated('player')] # drop duplicates!\n\n    pos_tracking = tracking_frame[['x', 'y']].values\n    labels_tracking = tracking_frame['player'].values\n    helmets_frame = helmets_frame[helmets_frame['conf'] > CONF_THRE]\n    pos_helmets = helmets_frame[['x', 'y']].values\n    pos_helmets[:, 0] *= -1\n\n    # Get theta pred from image\n    image = Image.open(f'/kaggle/working/temp/{frame}.png')\n    image = np.array(image)\n    theta_line, pixel_per_line = predict_line_parameters(image, view=view)        \n    if np.isnan(theta_line):\n        if view == 'Sideline':\n            theta_cand_list = list(np.linspace(- np.pi / 4, np.pi / 4, 5))\n            theta_cand_list += list(np.linspace(- np.pi / 4 + np.pi, np.pi / 4 + np.pi, 5))\n        else:\n            theta_cand_list = list(np.linspace(np.pi / 4, 3 * np.pi / 4, 5))\n            theta_cand_list += list(np.linspace(np.pi / 4 + np.pi, 3 * np.pi / 4 + np.pi, 5))\n    else:\n        theta_cand_list = [\n            theta_line,\n            np.pi + theta_line\n        ]\n\n    # Start ICP\n    micp = MonteCarloICP(scale_factor[view], view, num_iter=num_particles, rate_x2y=rate_x2y[view])\n    opt_loss = 1e9\n    pos_helmets_opt = None\n    idx_of_interest = [True for _ in pos_helmets]\n    for i, theta_cand in enumerate(theta_cand_list):\n        pos_helmets_icp, icp_loss = micp.get_icp_results_montecarlo(pos_helmets,\n                                                                    pos_tracking,\n                                                                    theta_cand,\n                                                                    tracking_frame['o'],)\n        if opt_loss > icp_loss:\n            opt_loss = icp_loss\n            pos_helmets_opt = pos_helmets_icp\n            opt_micp = micp\n\n    if len(pos_helmets) > 24:\n        # print('Try here too')\n        counter = 0\n        while counter < 3:\n            for i, theta_cand in enumerate(theta_cand_list):\n                thres_y_top = random.choice(np.arange(0, 201, 100))\n                thres_y_bottom = 720 - random.choice(np.arange(0, 201, 100))\n                idx_of_interest_tmp = (pos_helmets[:, 1] > thres_y_top) & (pos_helmets[:, 1] < thres_y_bottom)\n                if np.sum(idx_of_interest_tmp) < 15:\n                    continue\n                pos_helmets_without_edges = pos_helmets[idx_of_interest_tmp]\n\n                pos_helmets_icp, icp_loss = micp.get_icp_results_montecarlo(\n                    pos_helmets_without_edges,\n                    pos_tracking,\n                    theta_cand,\n                    tracking_frame['o']\n                )\n                if opt_loss > icp_loss:\n                    opt_loss = icp_loss\n                    pos_helmets_opt = pos_helmets_icp\n                    opt_micp = micp\n                    idx_of_interest = idx_of_interest_tmp\n            counter += 1\n\n    # Post Processing\n    pos_tracking_tmp = pos_tracking + opt_micp.opt_params[2] * np.array([\n        np.cos((- tracking_frame['o'] + 90) / 180 * np.pi),\n        np.sin((- tracking_frame['o'] + 90) / 180 * np.pi)]\n    ).T\n    \n    if helmets_frame['cluster_id'].nunique() == 1:\n        dist, helmets_idx, tracking_idx = calculate_hungarian_matching(\n           pos_helmets_opt,\n           pos_tracking_tmp,\n           rate_x2y[view],\n        )\n    else:\n        dist, helmets_idx, tracking_idx = calculate_hungarian_matching_with_team(\n            pos_helmets_opt,\n            pos_tracking_tmp,\n            rate_x2y[view],\n            helmets_frame['cluster_id'].values[idx_of_interest],\n            labels_tracking,\n            team_dif_penalty\n        )\n    labels_predicted = labels_tracking[tracking_idx] # [idx_of_interest]\n    helmets_pred_frame = helmets_frame.iloc[idx_of_interest].iloc[helmets_idx].copy()\n    helmets_pred_frame['label'] = labels_predicted\n    helmets_pred_frame['opt_loss'] = opt_loss\n    helmets_pred_frame['matching_dist'] = dist\n\n    return helmets_pred_frame","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T08:19:49.698414Z","iopub.execute_input":"2021-09-09T08:19:49.698901Z","iopub.status.idle":"2021-09-09T08:19:49.726498Z","shell.execute_reply.started":"2021-09-09T08:19:49.698858Z","shell.execute_reply":"2021-09-09T08:19:49.725414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_icp_multiprocess_by_team(helmets, tracking_processed, video_dir):\n    ###### PARAMETERS ######\n    clusterization_rate_thres=1e9\n    clusterization_dist_thres=0\n    clusterization_helmet_shrink_rate=0.7\n    ###### PARAMETERS ######\n\n    df_results_icp_list = []\n    df_results_icp = pd.DataFrame()\n    game_play2tracking = dict(tuple(tracking_processed.groupby('game_play')))\n    for video, helmets_video in helmets.groupby('video'):\n        game_play = video.split('_')[0] + '_' + video.split('_')[1]\n        view = video.split('_')[2].split('.')[0]\n        tracking_video = game_play2tracking[game_play] # tracking_processed[tracking_processed['game_play'] == game_play]\n        helmets_video = helmets_video[helmets_video['conf'] > CONF_THRE]\n        video_name = f'{game_play}_{view}'\n\n        ### FFMPEG ###\n        video_file = f'{video_dir}/{video_name}.mp4'\n        if os.path.exists('/kaggle/working/temp'):\n            shutil.rmtree('/kaggle/working/temp')\n        os.mkdir('/kaggle/working/temp')\n        !ffmpeg \\\n            -hide_banner \\\n            -loglevel fatal \\\n            -nostats \\\n            -i $video_file temp/%d.png\n        ### FFMPEG ###\n\n        helmets_clusterized_video = helmet_clusterization_video(helmets_video,\n                                                                                                              clusterization_rate_thres,\n                                                                                                              clusterization_dist_thres,\n                                                                                                              clusterization_helmet_shrink_rate)\n\n        p = Pool(processes=4)\n        submission_df_list = []\n        \n        tracking_video_dict = dict(list(tracking_video.groupby('frame')))\n        helmets_video_dict = dict(list(helmets_clusterized_video.groupby('frame')))\n        data_video_list = [(game_play, view, int(k), tracking_video_dict[k], helmets_video_dict[k]) for k in helmets_video_dict.keys()]\n        with tqdm(total=len(data_video_list)) as pbar:\n            for this_df in p.imap(apply_icp_per_frame_by_team, data_video_list):\n                df_results_icp_list.append(this_df)\n                pbar.update(1)\n        p.close()\n\n        ### Delete the results of FFMPEG ###\n        shutil.rmtree('/kaggle/working/temp')\n        ### Delete the results of FFMPEG ###\n\n    df_results_icp = pd.concat(df_results_icp_list, axis=0)\n    return df_results_icp","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T08:19:49.970283Z","iopub.execute_input":"2021-09-09T08:19:49.970882Z","iopub.status.idle":"2021-09-09T08:19:49.991596Z","shell.execute_reply.started":"2021-09-09T08:19:49.97081Z","shell.execute_reply":"2021-09-09T08:19:49.990482Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def helmet_clusterization_video(helmets_video, rate_thres, dist_thres, helmet_shrink_rate, using_gt=False):\n    def return_mean_helmets(d):\n        radius_x = d.height / 2 * helmet_shrink_rate \n        radius_y = d.width / 2 * helmet_shrink_rate\n        center_x = d.top + d.height / 2\n        center_y = d.left + d.width / 2\n        return np.mean(image[max([int(center_x - radius_x), 0]): int(center_x + radius_x),\n                                                max([int(center_y - radius_y), 0]): int(center_y + radius_y)], axis=(0, 1))\n        # return np.mean(image[d.top: d.top + d.height, d.left: d.left + d.width,], axis=(0, 1)), axis=1)\n\n    helmets_info_video_list = []\n    helmets_ans_video_list = []\n    for frame in sorted(helmets_video['frame'].unique()):\n        helmets_frame = helmets_video[helmets_video['frame'] == frame]\n\n        image = Image.open(f'/kaggle/working/temp/{frame}.png')\n        image = np.array(image)\n        image[:, :, 1] = 0\n        # helmets_info_frame = helmets_frame.apply(lambda d: np.mean(\n        #     image[np.max([int(d.y - radius), 0]): int(d.y + radius),\n        #           np.max([int(d.x - radius), 0]): int(d.x + radius)],\n        #     axis=(0, 1)), axis=1)\n        # helmets_info_frame = helmets_frame.apply(lambda d: np.mean(\n        #    image[d.top: d.top + d.height, d.left: d.left + d.width,],\n        #     axis=(0, 1)), axis=1)\n        helmets_info_frame = helmets_frame.apply(return_mean_helmets, axis=1)\n        helmets_info_frame = np.array([data for data in helmets_info_frame.values])\n        helmets_info_video_list.append(helmets_info_frame)\n        if using_gt:\n            helmets_ans_video_list.append(helmets_frame['label'].apply(lambda x: 'H' in x).values * 1)\n\n    helmets_info_video = np.vstack(helmets_info_video_list)\n    if using_gt:\n        helmets_ans_video = np.hstack(helmets_ans_video_list)\n\n    try:\n        pred = KMeans(n_clusters=2).fit_predict(helmets_info_video)\n    except:\n        print('DETECTED ERROR IN Kmeans!!!!! OH NO!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n        import traceback\n        traceback.print_exc()\n        df_tmp = helmets_video.copy()\n        df_tmp['cluster_id'] = -1\n        return df_tmp\n\n    same_rate = np.sum(pred) / np.sum(1 - pred)\n    dist = np.linalg.norm(\n        helmets_info_video[pred == 1].mean(axis=0) - helmets_info_video[pred == 0].mean(axis=0)\n    )\n\n    df_tmp = helmets_video.copy()\n    df_tmp['cluster_id'] = pred\n\n    detected_anomaly = False\n    if dist < dist_thres:\n        detected_anomaly = True\n    if same_rate > rate_thres or same_rate < 1 / rate_thres:\n        detected_anomaly = True\n\n    if detected_anomaly:\n        df_tmp['cluster_id'] = -1\n\n    print(helmets_video['video'].unique()[0],\n          df_tmp['cluster_id'].sum(),\n          df_tmp['cluster_id'].shape[0] - df_tmp['cluster_id'].sum(),\n          dist)\n    if detected_anomaly:\n        print('ANOMALY DETECTED!')\n    else:\n        print('Use team info for this video')\n\n    if using_gt:\n        acc_rate = (helmets_ans_video == pred).sum() / len(pred)\n        print('======================================================')\n        print(video)\n        print('accuracy: {}'.format(np.max((acc_rate, 1-same_rate))))\n        print('class num: {0} to {1}'.format(np.sum(pred), len(pred) - np.sum(pred)))\n        print('metric? :{}'.format(dist))\n        if detected_anomaly:\n            print('DETECTED ANOMALY! NOT USING THIS VIDEO')\n\n    return df_tmp","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T08:12:38.034026Z","iopub.execute_input":"2021-09-09T08:12:38.03461Z","iopub.status.idle":"2021-09-09T08:12:38.053566Z","shell.execute_reply.started":"2021-09-09T08:12:38.034554Z","shell.execute_reply":"2021-09-09T08:12:38.052742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_hungarian_matching_with_team(\n        pos_helmets_input,\n        pos_tracking_input,\n        rate_x2y,\n        team_helmets,\n        labels_tracking,\n        team_dif_penalty\n    ):\n    \"\"\"\n    pos_helmets: np.ndarray\n    pos_tracking: np.ndarray\n    rate_x2y: float\n    team_helmets: [0 or 1]\n    team_tracking: ['Hn' for 'Vn']\n    \"\"\"\n    dist_sum_opt = 1e9\n    dist_opt = None\n    helmets_idx_opt = None\n    tracking_idx_opt = None\n    team_cand = ['H', 'V']\n\n    for cand_1 in team_cand:\n        team_tracking = np.array([cand_1 in label for label in labels_tracking]) * 1\n        pos_helmets = np.copy(pos_helmets_input)\n        pos_tracking = np.copy(pos_tracking_input)\n        pos_helmets[:, 0] *= rate_x2y\n        pos_tracking[:, 0] *= rate_x2y\n        dist_matrix = distance.cdist(pos_helmets, pos_tracking, metric='euclidean')\n        for i in range(len(pos_helmets)):\n            for j in range(len(pos_tracking)):\n                if team_helmets[i] != team_tracking[j]:\n                    # dist_matrix[i, j] *= team_dif_penalty\n                    # dist_matrix[i, j] += team_dif_penalty\n                    dist_matrix[i, j] = np.sqrt(dist_matrix[i, j] ** 2 + team_dif_penalty ** 2)\n        helmets_idx, tracking_idx = linear_sum_assignment(dist_matrix)\n        dist = np.array([dist_matrix[i, j] for i, j in zip(helmets_idx, tracking_idx)])\n\n        if np.sum(dist) < dist_sum_opt:\n            dist_sum_opt = np.sum(dist)\n            dist_opt = dist\n            helmets_idx_opt = helmets_idx\n            tracking_idx_opt = tracking_idx\n\n    return dist_opt, helmets_idx_opt, tracking_idx_opt","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T08:12:38.171554Z","iopub.execute_input":"2021-09-09T08:12:38.172141Z","iopub.status.idle":"2021-09-09T08:12:38.18216Z","shell.execute_reply.started":"2021-09-09T08:12:38.172099Z","shell.execute_reply":"2021-09-09T08:12:38.181324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DeepSORT","metadata":{}},{"cell_type":"code","source":"def deepsort_helmets(video_data,\n                     video_dir,\n                     myvideo,\n                     deepsort_config='deepsort.yaml',\n                     plot=False,\n                     plot_frames=[]):\n    \n    # Setup Deepsort\n    cfg = get_config()\n    cfg.merge_from_file(deepsort_config)    \n    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n                        max_dist=cfg.DEEPSORT.MAX_DIST,\n                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n                        max_age=cfg.DEEPSORT.MAX_AGE,\n                        n_init=cfg.DEEPSORT.N_INIT,\n                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n                        use_cuda=True)\n    \n    # Run through frames.\n    video_data = video_data.sort_values('frame').reset_index(drop=True)\n    \n    ## Start fo my code ##\n    video_file = f'{video_dir}/{myvideo}.mp4'\n    if os.path.exists('/kaggle/working/temp'):\n        shutil.rmtree('/kaggle/working/temp')\n    os.mkdir('/kaggle/working/temp')\n    !ffmpeg \\\n        -hide_banner \\\n        -loglevel fatal \\\n        -nostats \\\n        -i $video_file temp/%d.png\n    ## End of my code ##\n    \n    ds = []\n    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n        d['x'] = (d['left'] + round(d['width'] / 2))\n        d['y'] = (d['top'] + round(d['height'] / 2))\n\n        xywhs = d[['x','y','width','height']].values\n\n        ## Start fo my code ##\n        image = Image.open(f'/kaggle/working/temp/{frame}.png')\n        image = np.array(image)\n        ## End of my code ##\n\n        confs = np.ones([len(d),])\n        clss =  np.zeros([len(d),])\n        try:\n            outputs = deepsort.update(xywhs, confs, clss, image)\n        except:\n            ds.append(d)\n            continue\n\n        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n            for j, (output, conf) in enumerate(zip(outputs, confs)): \n\n                bboxes = output[0:4]\n                id = output[4]\n                cls = output[5]\n\n                c = int(cls)  # integer class\n                label = f'{id}'\n                color = compute_color_for_id(id)\n                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n            fig, ax = plt.subplots(figsize=(15, 10))\n            video_frame = d['video_frame'].values[0]\n            ax.set_title(f'Deepsort labels: {video_frame}')\n            plt.imshow(im)\n            plt.show()\n\n        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n        if len(preds_df) > 0:\n            # # TODO Fix this messy merge\n            # d = pd.merge_asof(d.sort_values(['left','top']),\n            #                   preds_df[['left','top','deepsort_cluster']] \\\n            #                   .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n            #                   direction='nearest')\n            preds_df['x'] = (preds_df['left'] + preds_df['right']) / 2\n            preds_df['y'] = (preds_df['top'] + preds_df['bottom']) / 2\n\n            dist_matrix = distance.cdist(d[['x', 'y']].values, preds_df[['x', 'y']].values, metric='euclidean')\n            d_idx, preds_idx = linear_sum_assignment(dist_matrix)\n\n            preds_df_aligned = preds_df.iloc[preds_idx, :]\n            preds_df_aligned.index = d.index[d_idx]\n            preds_df_aligned = preds_df_aligned.rename({'left': 'left_deepsort', 'top': 'top_deepsort', 'x': 'x_deepsort', 'y': 'y_deepsort'}, axis=1)\n            d = pd.concat([d, preds_df_aligned], axis=1)\n\n        ds.append(d)\n        # if len(ds) > 5:\n        #     break\n    dout = pd.concat(ds)\n    \n    ## Start fo my code ##\n    shutil.rmtree('/kaggle/working/temp')\n    ## End of my code ##\n    \n    return dout\n\ndef add_deepsort_label_col(out):\n    # use_opt_loss = False\n    # if 'opt_loss' in out.columns:\n    #     if out['opt_loss'].nunique() != 1:\n    #         print('Use loss-weight based DeepSORT')\n    #         use_opt_loss = True\n\n    # if use_opt_loss:\n    #     out['score'] = 1.0 / out['opt_loss'] ** 0.5\n\n    #     sortlabel_map = out.groupby(['deepsort_cluster', 'label'])['score'].sum() \\\n    #         .sort_values(ascending=False).to_frame() \\\n    #         .rename(columns={'score_from_loss': 'score_sum'}) \\\n    #         .reset_index() \\\n    #         .groupby(['deepsort_cluster']) \\\n    #         .first()['label'].to_dict()\n\n    #     sortlabelcount_map = out.groupby(['deepsort_cluster', 'label'])['score'].sum() \\\n    #         .sort_values(ascending=False).to_frame() \\\n    #         .rename(columns={'score': 'score_sum'}) \\\n    #         .reset_index() \\\n    #         .groupby(['deepsort_cluster']) \\\n    #         .first()['score_sum'].to_dict()\n    # else:\n    #     # Find the top occuring label for each deepsort_cluster\n    #     sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n    #         .sort_values(ascending=False).to_frame() \\\n    #         .rename(columns={'label':'label_count'}) \\\n    #         .reset_index() \\\n    #         .groupby(['deepsort_cluster']) \\\n    #         .first()['label'].to_dict()\n    #     # Find the # of times that label appears for the deepsort_cluster.\n    #     sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n    #         .sort_values(ascending=False).to_frame() \\\n    #         .rename(columns={'label':'label_count'}) \\\n    #         .reset_index() \\\n    #         .groupby(['deepsort_cluster']) \\\n    #         .first()['label_count'].to_dict()\n\n    # Find the top occuring label for each deepsort_cluster\n    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['label'].to_dict()\n    # Find the # of times that label appears for the deepsort_cluster.\n    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'label':'label_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['label_count'].to_dict()\n\n    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n\n    return out\n\ndef score_vs_deepsort(myvideo, out, labels):\n    # Score the base predictions compared to the deepsort postprocessed predictions.\n    myvideo_mp4 = myvideo + '.mp4'\n    labels_video = labels.query('video == @myvideo_mp4')\n    scorer = NFLAssignmentScorer(labels_video)\n    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n    base_video_score = scorer.score(out_deduped)\n    \n    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n    print(out_preds.shape)\n    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n    print(out_preds.shape)\n    deepsort_video_score = scorer.score(out_preds)\n    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:12:38.833695Z","iopub.execute_input":"2021-09-09T08:12:38.834129Z","iopub.status.idle":"2021-09-09T08:12:38.886295Z","shell.execute_reply.started":"2021-09-09T08:12:38.834093Z","shell.execute_reply":"2021-09-09T08:12:38.885178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHelper functions from yolov5 to plot deepsort labels.\n\"\"\"\n\ndef compute_color_for_id(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the id\n    \"\"\"\n    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\n\ndef plot_one_box(x, im, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image 'im' using OpenCV\n    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label: \n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n    return im","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:12:39.023563Z","iopub.execute_input":"2021-09-09T08:12:39.024052Z","iopub.status.idle":"2021-09-09T08:12:39.03783Z","shell.execute_reply.started":"2021-09-09T08:12:39.024011Z","shell.execute_reply":"2021-09-09T08:12:39.036605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_deepsort(df_pred):\n    submission_df = df_pred.copy()\n    # Add video and frame columns to submission.\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\n    submission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n\n    if debug:\n        video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\n    else:\n        video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n\n    # Loop through test videos and apply. If in debug mode show the score change.\n    outs = []\n    for myvideo, video_data in tqdm(submission_df.groupby('video'), total=submission_df['video'].nunique()):\n        print(f'==== {myvideo} ====')\n        if debug:\n            # Plot deepsort labels when in debug mode.\n            out = deepsort_helmets(video_data, video_dir, myvideo, plot_frames=[])\n        else:\n            out = deepsort_helmets(video_data, video_dir, myvideo)\n        out = add_deepsort_label_col(out)\n        outs.append(out)\n        if debug:\n            # Score\n            score_vs_deepsort(myvideo, out, labels)\n    submission_deepsort = pd.concat(outs).copy()\n    submission_deepsort['label_deepsort'] = submission_deepsort['label_deepsort'] \\\n        .fillna(submission_deepsort['label'])\n    submission_deepsort = submission_deepsort.drop('label', axis=1) \\\n        .rename(columns={'label_deepsort':'label'})\n    \n    submission_deepsort = submission_deepsort.sort_values('label_count_deepsort', ascending=False)\n\n    submission_deepsort = submission_deepsort.loc[\n        ~submission_deepsort[['video_frame','label']].duplicated()]\n    return submission_deepsort","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:12:39.412235Z","iopub.execute_input":"2021-09-09T08:12:39.412668Z","iopub.status.idle":"2021-09-09T08:12:39.424726Z","shell.execute_reply.started":"2021-09-09T08:12:39.412621Z","shell.execute_reply":"2021-09-09T08:12:39.423244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ghost detection","metadata":{}},{"cell_type":"code","source":"def frames_list_to_segment_list(frames):\n    segment_list = []\n    start_frame = -1\n    prev_frame = -1\n    for frame in frames:\n        if prev_frame == -1:\n            prev_frame = frame\n        if start_frame == -1:\n            start_frame = frame\n    \n        if frame - prev_frame >= 2:\n            segment_list.append([start_frame, prev_frame])\n            start_frame = frame\n\n        prev_frame = frame\n    segment_list.append([start_frame, prev_frame])\n    return segment_list\n\ndef get_closest_label(frame, df_pred_video, query_label):\n    df_pred_frame = df_pred_video[df_pred_video['frame'] == frame]\n    df_pred_frame['dx'] = df_pred_frame['x'] - df_pred_frame[df_pred_frame['label'] == query_label]['x'].values[0]\n    df_pred_frame['dy'] = df_pred_frame['y'] - df_pred_frame[df_pred_frame['label'] == query_label]['y'].values[0]\n    dist = np.sqrt(df_pred_frame['dx'].values**2 + df_pred_frame['dy']**2)\n    dist[dist==0] = 1e9\n    closest_id = np.argmin(dist)\n    closest_label = df_pred_frame['label'].values[closest_id]\n    closest_pos = df_pred_frame[['x', 'y']].values[closest_id]\n    relative_pos = df_pred_frame[df_pred_frame['label'] == query_label][['x', 'y']].values[0] - closest_pos\n    return closest_label, closest_pos, relative_pos\n\ndef get_data(df_video, frame, label):\n    return df_video[(df_video['frame'] == frame) & (df_video['label'] == label)]\n\ndef get_base_data(df_video, frame0, frame1, target_label):\n    df_base = df_video[(df_video['frame'] >= frame0) & (df_video['frame'] <= frame1) & (df_video['label'] == target_label)]\n    return df_base","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_ghost_simple(df_pred):\n    update_list = []\n\n    for video, df_pred_video in tqdm(df_pred.groupby('video')):\n        df_pred_video_updated = df_pred_video.copy()\n\n        video_name = video[:-4]\n\n        for label in df_pred_video['label'].unique():\n            # if label != 'H90':\n            #     continue\n            df_pred_video = df_pred_video.sort_values('frame')\n            cond_visible = np.array([label in labels.values for _, labels in df_pred_video.groupby('frame')['label']])\n            non_visible_frames = df_pred_video['frame'].unique()[~cond_visible]\n\n            non_visible_segment_list = frames_list_to_segment_list(non_visible_frames)\n            for seg in non_visible_segment_list:\n                closest_labels = [0, 0]\n                closest_pos_list = [0, 0]\n                relative_pos_list = [0, 0]\n\n                for i in range(len(seg)):\n                    frame_tmp = seg[i] - (-1)**i\n                    if frame_tmp not in df_pred_video.frame.unique():\n                        closest_labels[i] = 'NaN'\n                    else:\n                        closest_labels[i], closest_pos_list[i], relative_pos_list[i] = get_closest_label(frame_tmp, df_pred_video, label)\n\n                if closest_labels[0] == closest_labels[1] and closest_labels[0] != 'NaN' and np.mean(np.linalg.norm(relative_pos_list, axis=1)) < 30:\n                    relative_pos = np.mean(relative_pos_list, axis=0)\n                    if np.linalg.norm(relative_pos) == 0:\n                        relative_pos = [1, 1]\n                    bases_df = get_base_data(df_pred_video, seg[0], seg[1], closest_labels[0])\n                    bases_df['label'] = label\n                    bases_df['left'] += relative_pos[0]\n                    bases_df['top'] += relative_pos[1]\n                    update_list.append(bases_df)\n    df_pred_updated = pd.concat([df_pred, pd.concat(update_list)])\n    df_pred_updated = df_pred_updated.sort_values('frame')\n    return df_pred_updated\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_ghosts(df_pred, tracking):\n    update_list = []\n\n    for video, df_pred_video in tqdm(df_pred.groupby('video')):\n        game_play = video.split('_')[0] + '_' + video.split('_')[1]\n        tracking_video = tracking[tracking['game_play'] == game_play]\n\n        closest_labels_to_frame = {}\n        # Iterate over frames to detect frames that are close enough\n        for frame, df_pred_frame in df_pred_video.sort_values('frame').groupby('frame'):\n            dist_thres = (df_pred_frame['width'].mean() + df_pred_frame['height'].mean()) / 2 * 1.\n\n            pos_helmets = df_pred_frame[['x', 'y']].values\n            dist = distance.cdist(pos_helmets, pos_helmets, metric='euclidean') + np.eye(len(pos_helmets)) * 1e9\n            closest_idxs = np.argmin(dist, axis=1)\n            for label0_idx, label1_idx in enumerate(closest_idxs):\n                if dist[label0_idx, label1_idx] > dist_thres:\n                    continue\n                if closest_idxs[label1_idx] == label0_idx:\n                    label0 = df_pred_frame['label'].values[label0_idx]\n                    label1 = df_pred_frame['label'].values[label1_idx]\n                    key = sorted([label0, label1])[0] + '_' + sorted([label0, label1])[1]\n                    if key not in closest_labels_to_frame.keys():\n                        closest_labels_to_frame[key] = set()\n                    closest_labels_to_frame[key].add(frame)\n\n        tracking_dist_thres = 1.5\n        for label0_label1, frames in closest_labels_to_frame.items():\n            label0, label1 = label0_label1.split('_')\n            pred_label0 = df_pred_video[df_pred_video['label'] == label0]\n            pred_label1 = df_pred_video[df_pred_video['label'] == label1]\n            frames = sorted(list(frames))\n            non_visible_seg_list = []\n            prev_frame_visible = frames[0]\n            for frame_visible in frames:\n                if frame_visible - prev_frame_visible > 1:\n                    non_visible_seg_list.append([prev_frame_visible + 1, frame_visible - 1])\n                prev_frame_visible = frame_visible\n\n            for frame0, frame1 in non_visible_seg_list:\n                # Check the distance between two tracking data\n                tracking_0 = tracking_video[(tracking_video['player'] == label0) & (tracking_video['frame'] >= frame0) & (tracking_video['frame'] <= frame1)][['x', 'y']].values\n                tracking_1 = tracking_video[(tracking_video['player'] == label1) & (tracking_video['frame'] >= frame0) & (tracking_video['frame'] <= frame1)][['x', 'y']].values\n                assert len(tracking_0) == len(tracking_1)\n                if np.linalg.norm(tracking_0 - tracking_1, axis=1).max() > tracking_dist_thres:\n                    continue\n\n               #  print(\"Complete! frame: {0} to {1}, label: {2} and {3}\".format(frame0, frame1, label0, label1))\n                relative_pos_0to1 = (pred_label1[pred_label1['frame'] == frame0 - 1][['x', 'y']].values + pred_label1[pred_label1['frame'] == frame1 + 1][['x', 'y']].values) - \\\n                                                     (pred_label0[pred_label0['frame'] == frame0 - 1][['x', 'y']].values  + pred_label0[pred_label0['frame'] == frame1 + 1][['x', 'y']].values)\n                relative_pos_0to1 /= 2\n                # if np.linalg.norm(relative_pos_0to1) < 5:\n                #    print('here')\n                #    relative_pos_0to1 = np.array([[2, 2]])\n\n                # Complement missing label0 with label1\n                df_label0_complemented = pred_label1[(pred_label1['frame'] >= frame0) & (pred_label1['frame'] <= frame1)]\n                df_label0_complemented['label'] = label0\n                df_label0_complemented['left'] -= relative_pos_0to1[0][0]\n                df_label0_complemented['top'] -= relative_pos_0to1[0][1]\n                df_label0_complemented = df_label0_complemented[~df_label0_complemented['frame'].isin(pred_label0['frame'].values)]\n\n                # Complement missing label0 with label1\n                df_label1_complemented = pred_label0[(pred_label0['frame'] >= frame0) & (pred_label0['frame'] <= frame1)]\n                df_label1_complemented['label'] = label1\n                df_label1_complemented['left'] += relative_pos_0to1[0][0]\n                df_label1_complemented['top'] += relative_pos_0to1[0][1]\n                df_label1_complemented = df_label1_complemented[~df_label1_complemented['frame'].isin(pred_label1['frame'].values)]\n\n                update_list.append(df_label0_complemented)\n                update_list.append(df_label1_complemented)\n                # print(relative_pos_0to1)\n    df_pred_updated = pd.concat([df_pred, pd.concat(update_list)])\n    df_pred_updated = df_pred_updated[~df_pred_updated[['video_frame', 'label']].duplicated()]\n    df_pred_updated = df_pred_updated[~df_pred_updated[[\"video_frame\", \"left\", \"width\", \"top\", \"height\"]].duplicated()]\n\n    return df_pred_updated","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## others","metadata":{}},{"cell_type":"code","source":"def generate_video(submission_df, labels):\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    debug_videos = submission_df['video'].unique()\n    debug_labels = labels.query('video in @debug_videos')\n    scorer = NFLAssignmentScorer(debug_labels)\n    scorer.score(submission_df)\n\n    # Create video showing predictions for one of the videos.\n    video_out = video_with_predictions(\n        f'../input/nfl-health-and-safety-helmet-assignment/train/{debug_videos[0]}',\n        scorer.sub_labels)\n    \n    frac = 0.60 # scaling factor for display\n    display(Video(data=video_out,\n                  embed=True,\n                  height=int(720*frac),\n                  width=int(1280*frac))\n           )\n    \ndef eval_sub(submission_df, labels):\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    for video, sub in submission_df.groupby('video'):\n        scorer = NFLAssignmentScorer(labels[labels['video'] == video])\n        baseline_score = scorer.score(submission_df[submission_df['video'] == video])\n        print(f\"Score @ {video}: {baseline_score:0.4f}\")\n    print('============')\n    scorer = NFLAssignmentScorer(labels)\n    baseline_score = scorer.score(submission_df)\n    print(f\"validation score {baseline_score:0.4f}\")\n    \n\ndef save_sub(submission_df, filename, all_cols = False):\n    ss = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n\n    # Final Checks\n    if not all_cols:\n        submission_df = submission_df[ss.columns]\n    submission_df = submission_df.loc[\n        ~submission_df[['video_frame','label']].duplicated()]\n    if not all_cols:\n        check_submission(submission_df)\n\n    submission_df.to_csv(filename, index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T08:12:39.832528Z","iopub.execute_input":"2021-09-09T08:12:39.832983Z","iopub.status.idle":"2021-09-09T08:12:39.846165Z","shell.execute_reply.started":"2021-09-09T08:12:39.832919Z","shell.execute_reply":"2021-09-09T08:12:39.845014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare","metadata":{}},{"cell_type":"code","source":"n_test_videos = len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/'))\n# Run in debug mode unless during submission\nif n_test_videos == 6:\n    debug = True\nelse:\n    debug = False\n\n# Configurables\nn_debug_samples = 30\nrandom_state = 41\nCONF_THRE = 0.3\nmax_iter = 1000\nDIG_STEP = 3\nDIG_MAX = DIG_STEP*10\n\n# Read in the data.\n\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nif debug:\n    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\n    video_dir = BASE_DIR + '/train'\nelse:\n    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n    video_dir = BASE_DIR + '/test'\n\ntracking = add_track_features(tracking)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:28:03.752583Z","iopub.execute_input":"2021-09-09T08:28:03.75348Z","iopub.status.idle":"2021-09-09T08:28:08.545986Z","shell.execute_reply.started":"2021-09-09T08:28:03.753427Z","shell.execute_reply":"2021-09-09T08:28:08.545136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_cols(df):\n    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\nif debug:\n    helmets = add_cols(helmets)\n    labels = add_cols(labels)\n    # Select `n_debug_samples` worth of videos to debug with\n    sample_videos = labels['video'].drop_duplicates() \\\n        .sample(n_debug_samples, random_state=random_state).tolist()\n    # sample_videos = ['57586_004152_Endzone.mp4', '57586_004152_Sideline.mp4']\n    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n    helmets = helmets[helmets['video'].isin(sample_videos)]\n    labels = labels[labels['video'].isin(sample_videos)]\n    print(sample_videos)\ntracking.shape, helmets.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:28:08.547885Z","iopub.execute_input":"2021-09-09T08:28:08.548502Z","iopub.status.idle":"2021-09-09T08:28:26.26616Z","shell.execute_reply.started":"2021-09-09T08:28:08.548456Z","shell.execute_reply":"2021-09-09T08:28:26.265102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helmets['video'] = helmets['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\nhelmets['view'] = helmets['video_frame'].str.split('_').str[2].astype(str)\nhelmets['frame'] = helmets['video_frame'].str.split('_').str[3].astype(np.int64)\nhelmets['x'] = helmets['left'] + helmets['width'] / 2.0\nhelmets['y'] = helmets['top'] + helmets['height'] / 2.0\n\ntracking_merged_list = []\nfor video, df_pred_video in tqdm(helmets.groupby('video')):\n    game_play = video.split('_')[0] + '_' + video.split('_')[1]\n    tracking_video = tracking[tracking['game_play'] == game_play]\n    est_frame_to_tracking_video = dict(list(tracking_video.groupby('est_frame')))\n    keys = np.array(list(est_frame_to_tracking_video.keys()))\n    for frame_id in df_pred_video['frame'].unique():\n        opt_idx = np.argmin(np.abs(keys - frame_id))\n        tmp = est_frame_to_tracking_video[keys[opt_idx]].copy()\n        tmp['frame'] = frame_id\n        tracking_merged_list.append(tmp)\ntracking_processed = pd.concat(tracking_merged_list)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:28:26.268201Z","iopub.execute_input":"2021-09-09T08:28:26.268843Z","iopub.status.idle":"2021-09-09T08:28:35.941307Z","shell.execute_reply.started":"2021-09-09T08:28:26.26879Z","shell.execute_reply":"2021-09-09T08:28:35.940403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ICP","metadata":{}},{"cell_type":"code","source":"df_results_icp = apply_icp_multiprocess_by_team(helmets, tracking_processed, video_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:28:35.951863Z","iopub.execute_input":"2021-09-09T08:28:35.952193Z","iopub.status.idle":"2021-09-09T08:43:29.301592Z","shell.execute_reply.started":"2021-09-09T08:28:35.952164Z","shell.execute_reply":"2021-09-09T08:43:29.300518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    eval_sub(df_results_icp, labels)\nsave_sub(df_results_icp, 'submission_icp.csv', all_cols=True)\n# save_sub(df_results_icp, 'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:09:04.430325Z","iopub.status.idle":"2021-09-09T08:09:04.433141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DeepSORT","metadata":{}},{"cell_type":"code","source":"%%writefile deepsort.yaml\nDEEPSORT:\n  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n  MAX_DIST: 0.2\n  MIN_CONFIDENCE: 0.3\n  NMS_MAX_OVERLAP: 0.5\n  MAX_IOU_DISTANCE: 0.9\n  MAX_AGE: 3\n  N_INIT: 1\n  NN_BUDGET: 30","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:09:04.437543Z","iopub.status.idle":"2021-09-09T08:09:04.440297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_results_deepsort = apply_deepsort(df_results_icp)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:09:04.444607Z","iopub.status.idle":"2021-09-09T08:09:04.447323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    eval_sub(df_results_deepsort, labels)\nsave_sub(df_results_deepsort, 'submission_deepsort.csv', all_cols=True)\n# save_sub(df_results_deepsort, 'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:09:04.450737Z","iopub.status.idle":"2021-09-09T08:09:04.454284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ghost Detection","metadata":{}},{"cell_type":"code","source":"df_results_simple_ghosts = add_ghost_simple(df_results_deepsort)\nsave_sub(df_results_simple_ghosts, 'submission_few_ghosts.csv', all_cols=True)\n\ndf_results_plenty_ghosts = add_ghosts(df_results_simple_ghosts, tracking_processed)\nsave_sub(df_results_plenty_ghosts, 'submission_plenty_ghosts.csv', all_cols=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    eval_sub(df_results_plenty_ghosts, labels)\nsave_sub(df_results_plenty_ghosts, 'submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Video","metadata":{}},{"cell_type":"code","source":"if debug:\n    generate_video(df_results_plenty_ghosts, labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:09:04.455912Z","iopub.status.idle":"2021-09-09T08:09:04.461169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}