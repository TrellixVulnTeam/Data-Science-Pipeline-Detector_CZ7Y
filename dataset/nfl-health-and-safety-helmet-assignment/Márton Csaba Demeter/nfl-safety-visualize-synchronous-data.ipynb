{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd\nimport itertools\nimport glob\nimport os\nimport cv2\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.auto import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom bokeh.plotting import figure\nfrom bokeh.io import output_notebook, show, push_notebook\nimport random\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T20:35:30.936535Z","iopub.execute_input":"2021-08-17T20:35:30.93707Z","iopub.status.idle":"2021-08-17T20:35:30.942104Z","shell.execute_reply.started":"2021-08-17T20:35:30.937007Z","shell.execute_reply":"2021-08-17T20:35:30.941369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"debug = True\nCONF_THRE = 0.3\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\n\n# used from https://www.kaggle.com/go5kuramubon/merge-label-and-tracking-data?select=train_label_tracking_merged.csv\nmerged_train_labels = pd.read_csv('../input/merged/train_label_tracking_merged.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T20:35:30.943556Z","iopub.execute_input":"2021-08-17T20:35:30.943987Z","iopub.status.idle":"2021-08-17T20:35:37.062166Z","shell.execute_reply.started":"2021-08-17T20:35:30.943943Z","shell.execute_reply":"2021-08-17T20:35:37.061366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pylab inline \nimport cv2\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2021-08-17T20:35:37.063566Z","iopub.execute_input":"2021-08-17T20:35:37.064001Z","iopub.status.idle":"2021-08-17T20:35:37.07242Z","shell.execute_reply.started":"2021-08-17T20:35:37.063956Z","shell.execute_reply":"2021-08-17T20:35:37.071162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_labels.sort_values(by=['video','frame']).head(8498)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T20:35:37.074448Z","iopub.execute_input":"2021-08-17T20:35:37.074846Z","iopub.status.idle":"2021-08-17T20:35:37.442655Z","shell.execute_reply.started":"2021-08-17T20:35:37.074803Z","shell.execute_reply":"2021-08-17T20:35:37.44196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_sorted_data = np.array(merged_train_labels.sort_values(by=['video','frame']))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-17T20:35:37.443898Z","iopub.execute_input":"2021-08-17T20:35:37.444199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reorganize data for visualization\n# split dataset to sideline and endline\n\nmerged_sorted_reorganized_data_Endzone = []\nmerged_sorted_reorganized_data_Sideline = []\ntmp_array = []\nframe_counter = 0\n\nfor k in range(len(merged_sorted_data)):\n    if str(merged_sorted_data[k][3]) == \"Endzone\":\n        if merged_sorted_data[k][5] > frame_counter :\n            if frame_counter > 0:\n                merged_sorted_reorganized_data_Endzone.append(tmp_array)\n            tmp_array = []\n            tmp_array.append(merged_sorted_data[k][0])\n        tmp_array.append(np.concatenate((merged_sorted_data[k][5:10],merged_sorted_data[k][15:22])))\n        frame_counter = merged_sorted_data[k][5]\ntmp_array = []\nframe_counter = 0\n\nfor k in range(len(merged_sorted_data)):\n    if str(merged_sorted_data[k][3]) == \"Sideline\":\n        if merged_sorted_data[k][5] > frame_counter :\n            if frame_counter > 0:\n                merged_sorted_reorganized_data_Sideline.append(tmp_array)\n            tmp_array = []\n            tmp_array.append(merged_sorted_data[k][0])\n        tmp_array.append(np.concatenate((merged_sorted_data[k][5:10],merged_sorted_data[k][15:22])))\n        frame_counter = merged_sorted_data[k][5]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_sorted_reorganized_data_Sideline[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a VideoCapture object and read from input file\n# If the input is the camera, pass 0 instead of the video file name\nplt.rcParams['figure.figsize'] = [12, 8]\nplt.rcParams['figure.dpi'] = 200 # 200 e.g. is really fine, but slower\n\nNFL_Field = cv2.imread(\"../input/nfl-football-field/1200px-AmFBfield.svg.png\")\n\n#renormalization factors for  x,y coordinates, based on NFL_Field png width and height\n\nw_real = 120\nh_real = 53.3\nx_factor = NFL_Field.shape[1]/120\ny_factor = NFL_Field.shape[0]/53.3\n\n\n\nmerged_sorted_reorganized_data = merged_sorted_reorganized_data_Endzone\nmerged_sorted_reorganized_data2 = merged_sorted_reorganized_data_Sideline\n\nframe_idx = 0\nvid = cv2.VideoCapture(f'{BASE_DIR}/train/'+str(merged_sorted_reorganized_data[frame_idx][0][0:-2]+\".mp4\"))\nvid2 = cv2.VideoCapture(f'{BASE_DIR}/train/'+str(merged_sorted_reorganized_data2[frame_idx][0][0:-2]+\".mp4\"))\ntry:\n    while(True):\n                \n        # Capture frame-by-frame\n        ret, frame = vid.read()\n        ret2, frame2 = vid2.read()\n        if not ret:\n            # Release the Video Device if ret is false\n            vid.release()\n            # Message to be displayed after releasing the device\n            break\n            \n        if not ret2:\n            # Release the Video Device if ret is false\n            vid2.release()\n            # Message to be displayed after releasing the device\n            break            \n        # Convert the image from OpenCV BGR format to matplotlib RGB format\n        # to display the image\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n        frame3 = cv2.cvtColor(NFL_Field, cv2.COLOR_BGR2RGB)\n        \n        # visualize helmet detection for endline camera \n        for helmets in range(1,len(merged_sorted_reorganized_data[frame_idx])):\n            left = int(merged_sorted_reorganized_data[frame_idx][helmets][2]) \n            top = int(merged_sorted_reorganized_data[frame_idx][helmets][4])\n            w,h = int(merged_sorted_reorganized_data[frame_idx][helmets][3]),int(merged_sorted_reorganized_data[frame_idx][helmets][5])\n            start_point = (left,top)\n            end_point = (left+w,top+h)\n            color = (255,255,255)\n            thickness = 5\n            frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n        \n        # visualize helmet detection for sideline camera            \n        for helmets in range(1,len(merged_sorted_reorganized_data2[frame_idx])):\n            left2 = int(merged_sorted_reorganized_data2[frame_idx][helmets][2]) \n            top2 = int(merged_sorted_reorganized_data2[frame_idx][helmets][4])\n            w2,h2 = int(merged_sorted_reorganized_data2[frame_idx][helmets][3]),int(merged_sorted_reorganized_data2[frame_idx][helmets][5])\n            start_point2 = (left2,top2)\n            end_point2 = (left2+w2,top2+h2)\n            color = (255,255,255)\n            thickness = 5\n            frame2 = cv2.rectangle(frame2, start_point2, end_point2, color, thickness) \n        \n        # visualize detection of NGS data         \n        for coords in range(1,len(merged_sorted_reorganized_data2[frame_idx])):\n            # invert y coordinates, as the origo of the y coordinates is not same as usual convention of x,y image plane... duhhh :D\n            x = int(x_factor * (merged_sorted_reorganized_data2[frame_idx][coords][5]) ) \n            y = int(y_factor * (53.3-merged_sorted_reorganized_data2[frame_idx][coords][6]) )\n            color = (255,0,0)\n            thickness = 5\n            frame3 = cv2.circle(frame3, (int(x),int(y) ),1, color, thickness) \n        # Turn off the axis\n        axis('off')\n        # Title of the window\n        title(\"Input Stream\")\n        # Display the frame\n        #imshow(frame)\n        #imshow(frame2)\n        columns = 3\n        images = [frame,frame2,frame3]\n        for i, image in enumerate(images):\n            plt.subplot(len(images) / columns + 1, columns, i + 1)\n            plt.imshow(image)\n        \n        show()\n\n        # Display the frame until new frame is available\n        time.sleep(0.05)\n        clear_output(wait=True)\n        \n        frame_idx+=1\nexcept KeyboardInterrupt:\n    # Release the Video Device\n    vid.release()\n    # Message to be displayed after releasing the device","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\n\n\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]}]}