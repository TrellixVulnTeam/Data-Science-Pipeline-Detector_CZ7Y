{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\n\nfrom pathlib import Path\ndata_dir = Path('../input/')\n\nimport os\nos.listdir(data_dir)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/covid19-global-forecasting-week-4/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/covid19-global-forecasting-week-4/train.csv')\n# df.rename(columns={'Country_Region' : 'country'}, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/covid19-global-forecasting-week-4/test.csv')\ntest[ test['Country_Region'] == 'India']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/covid19-global-forecasting-week-4/submission.csv')\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df , test])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the cleaned data from https://www.kaggle.com/imdevskp/corona-virus-report."},{"metadata":{"trusted":true},"cell_type":"code","source":"icu_df = pd.read_csv(\"../input/hospital-beds-by-country/API_SH.MED.BEDS.ZS_DS2_en_csv_v2_887506.csv\")\nicu_df['Country Name'] = icu_df['Country Name'].replace('United States', 'US')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Russian Federation', 'Russia')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Iran, Islamic Rep.', 'Iran')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Egypt, Arab Rep.', 'Egypt')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Venezuela, RB', 'Venezuela')\ndf['Country_Region'] = df['Country_Region'].replace('Czechia', 'Czech Republic')\n\n\n# We wish to have the most recent values, thus we need to go through every year and extract the most recent one, if it exists.\nicu_cleaned = pd.DataFrame()\nicu_cleaned[\"Country_Region\"] = icu_df[\"Country Name\"]\nicu_cleaned[\"icu\"] = np.nan\n\nfor year in range(1960, 2020):\n    year_df = icu_df[str(year)].dropna()\n    icu_cleaned[\"icu\"].loc[year_df.index] = year_df.values\n\ndf = pd.merge(df, icu_cleaned, on='Country_Region' , how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CS'] = df['Country_Region'].astype(str) + df['Date'].astype(str) + df['Province_State'].astype(str)\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Temperature Data\nIn our next step, we wish to analyze the weather and temperature data of the respective countries since the outbreak of the virus. We have composed a dataset here: https://www.kaggle.com/winterpierre91/covid19-global-weather-data\n\nWe hope to find some colleration between certain weather metrics and the speed of the number of infections/deaths."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_temperature = pd.read_csv(\"../input/covid19-global-weather-data/temperature_dataframe.csv\")\ndf_temperature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_temperature.rename(columns={'country' : 'Country_Region'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_temperature['Country_Region'] = df_temperature['Country_Region'].replace('USA', 'US')\ndf_temperature['Country_Region'] = df_temperature['Country_Region'].replace('UK', 'United Kingdom')\ndf_temperature = df_temperature[[\"Country_Region\",  \"date\", \"humidity\", \"sunHour\", \"tempC\", \"windspeedKmph\"]].reset_index()\ndf_temperature.rename(columns={'province': 'state'}, inplace=True)\ndf_temperature[\"Date\"] = pd.to_datetime(df_temperature['date'])\n# df_temperature['state'] = df_temperature['state'].fillna('')\ndf_t = df_temperature.groupby('Country_Region').mean()\n\ndf_t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_temperature['CS'] = df_temperature['Country_Region'].astype(str) + df_temperature['date'].astype(str)\n# df_temperature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Date\"] = pd.to_datetime(df['Date'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.merge(df , df_t, on=['Country_Region'],how = 'left' )\n# df1.to_csv(\"countries_icu_temp.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Province_State'] = df1['Province_State'].fillna(df1['Country_Region'])\ncols = ['icu', 'humidity', 'sunHour', 'tempC',\n       'windspeedKmph']\nfor col in cols : \n    df1[col] = df1[col].fillna(df1[col].mean())\n# df1 = df1.set_index('CS')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df1['Province_State'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_start_death = 100\nn_start_death1 = 1\n\n# fatality_top_countires = top_country_df.sort_values('fatalities', ascending=False).iloc[:n_countries]['country'].values\n# country_df['date'] = pd.to_datetime(country_df['date'])\n\n## DAYS SINCE\n\ndf_list = []\nfor country in df1['Province_State'].unique():\n    this_country_df = df1.query('Province_State == @country')\n    start_date = this_country_df.query('ConfirmedCases > @n_start_death')['Date'].min()\n    start_date1 = this_country_df.query('ConfirmedCases > @n_start_death1')['Date'].min()\n    this_country_df['DConfirmed'] = this_country_df['Date'] - start_date\n    this_country_df['DConfirmed1'] = this_country_df['Date'] - start_date1\n#     this_country_df = this_country_df.query('Date >= @start_date')\n#     this_country_df['date_since'] = this_country_df['Date'] - start_date\n#     this_country_df['ConfirmedCases'] = np.log10(this_country_df['fatalities'] + 1)\n#     this_country_df['fatalities_log1p'] -= this_country_df['fatalities_log1p'].values[0]\n    df_list.append(this_country_df)\n\ntmpdf = pd.concat(df_list)\ntmpdf['DConfirmed'] = tmpdf['DConfirmed'] / pd.Timedelta('1 days')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tmpdf[2050:2100]\ntmpdf['DConfirmed'] = tmpdf['DConfirmed'].fillna(-50)\ntmpdf['DConfirmed1'] = tmpdf['DConfirmed1'].fillna(-50)\n\ndf1 = tmpdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## split into yr , month , date\ndf1['y'] , df1['m'] ,df1['d'] = df1['Date'].astype(str).str.split('-').str\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1[['ConfirmedCases', 'Date', 'Fatalities',\n       'Province_State', 'icu', 'humidity', 'sunHour', 'tempC',\n       'windspeedKmph' , 'DConfirmed' , 'ForecastId' ,  'DConfirmed1', 'y', 'm', 'd']]\n# df1 = df1[['ConfirmedCases', 'Country_Region', 'Date', 'Fatalities',\n#         'Province_State','DConfirmed' , 'ForecastId' ,  'DConfirmed1', 'y', 'm', 'd']]\n# df1['ConfirmedCases'] = np.log(df1['ConfirmedCases'] +1 )\n# df1['Fatalities'] = np.log(df1['Fatalities'] + 1)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf1['Province_State'] = le.fit_transform(df1['Province_State'])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df1[df1['ForecastId'].isnull()]\n# train = df1[df1['Date'] < '2020-03-26']\ntrain.head()\ntesting = df1[~df1['ForecastId'].isnull()]\n# len(testing)\n\n\ntrain1 = train[train['Date'] < '2020-03-26']\nval = train[train['Date'] >= '2020-03-26']\ntrain_X = train1.drop(['ConfirmedCases' , 'Fatalities'] , axis = 1)\ntrain_y = train1[['ConfirmedCases' , 'Fatalities']] \n\nval_X = val.drop(['ConfirmedCases' , 'Fatalities'] , axis = 1)\nval_y = val[['ConfirmedCases' , 'Fatalities']] \n\n\ntestX = testing.drop(['ConfirmedCases' , 'Fatalities'] , axis = 1)\n\n\ncategorical = ['Country_Region' , 'Province_State']\n\ndef column_index(df, query_cols):\n    cols = df.columns.values\n    sidx = np.argsort(cols)\n    return sidx[np.searchsorted(cols, query_cols, sorter=sidx)]\ncategorical_features_indices = column_index(train_X, categorical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(testing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.describe()\nfrom catboost import CatBoostRegressor\n\n# model = LGBMRegressor(num_leaves = 85,learning_rate =10**-1.89,n_estimators=100,min_sum_hessian_in_leaf=(10**-4.1),min_child_samples =2,subsample =0.97,subsample_freq=10,\n#                    colsample_bytree = 0.68,reg_lambda=10**1.4,random_state=1234,n_jobs=4)\nmodel =  CatBoostRegressor(iterations= 500,\n#                              learning_rate=0.001,\n                             depth=16,\n                             eval_metric='RMSE',\n                             random_seed = 42,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 50,\n                                 task_type = \"GPU\",\n                                 devices='0:1',\n\n                             od_wait=100)\n\n    \nmodel.fit(train_X, train_y['ConfirmedCases'],\n                 eval_set=(val_X, val_y['ConfirmedCases']),\n#                   cat_features=categorical_features_indices,\n                  use_best_model=True)\n\n## Start model \n# By implementing a regression model which tries to use the country input variables to predict the most recent number of infections and deaths as target, we can extract the relative feature importance. This can be done pretty well with a Random Forest Regressor.\n\n# sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX.info()\n\ntestX['ConfirmedCases'] = model.predict(testX) \n# sample['ConfirmedCases'] = np.exp(sample['ConfirmedCases'])\n# sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 500)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try :\n    testX['Province_State'] = le.inverse_transform(testX['Province_State'])\nexcept :\n    x = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX[testX['Province_State'] == 'India']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 =  CatBoostRegressor(iterations=500,\n#                              learning_rate=0.001,\n                             depth=16,\n                             eval_metric='RMSE',\n                             random_seed = 42,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 50,\n                             task_type = \"GPU\",\n                             devices='0:1',\n                             \n                             od_wait=100)\n\nmodel1.fit(train_X, train_y['Fatalities'],\n                 eval_set=(val_X, val_y['Fatalities']),\n#                   cat_features=categorical_features_indices,\n                 use_best_model=True)\n\n# ## Start model \n# By implementing a regression model which tries to use the country input variables to predict the most recent number of infections and deaths as target, we can extract the relative feature importance. This can be done pretty well with a Random Forest Regressor.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample\n\ntestX.info()\ntestX['Fatalities'] = model1.predict(testX)\n# sample['Fatalities'] = np.exp(sample['Fatalities'])\n# sample['Fatalities'] = 2**(model1.predict(testX) - 1)\nsample = sample.set_index(['ForecastId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('./submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample[:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}