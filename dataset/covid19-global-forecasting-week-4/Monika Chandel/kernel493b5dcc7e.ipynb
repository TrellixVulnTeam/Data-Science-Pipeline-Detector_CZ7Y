{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"! pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import  math\nfrom pmdarima.arima import auto_arima\nimport seaborn as sns\nfrom datetime import datetime,date,timedelta\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nsubmission_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)\nprint(submission_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)\nprint(train_data.info())\nprint(test_data.info())\nprint(train_data.isna().sum())\nprint(test_data.isna().sum())\nprint(train_data.describe())\nprint(train_data.head(5))\nprint(test_data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### exclude null values\ntrain_data.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.columns)\nprint(test_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Date = pd.to_datetime(train_data.Date)\ntest_data.Date = pd.to_datetime(test_data.Date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.info())\nprint(test_data.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train data range from \",min(train_data.Date),\" to\",max(train_data.Date))\nprint(\"test data range from \",min(test_data.Date),\" to\",max(test_data.Date))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### train and test data manipulation\n\n### train data manipulation\n\ntrain_data.Date = pd.to_datetime(train_data.Date)\ntrain_data['Province_State'] = train_data['Province_State'].astype(str)\ntrain_data['Province_State'] = train_data['Province_State'].str.replace(',','_').str.replace('nan','').str.lower()\ntrain_data['Country_Region'] = train_data['Country_Region'].astype(str).str.lower().str.replace(' ','_')\ntrain_data['province_state_country'] = train_data['Country_Region'].astype(str).str.lower().str.replace(' ','_') + '_' + train_data['Province_State']\n### change '_' to empty space'\ntrain_data['province_state_country'] = train_data['province_state_country'].str.replace('_$','')\n\n\n### train data manipulation\ntest_data.Date = pd.to_datetime(test_data.Date)\ntest_data['Province_State'] = test_data['Province_State'].astype(str)\ntest_data['Province_State'] = test_data['Province_State'].str.replace(',','_').str.replace('nan','').str.lower()\ntest_data['Country_Region'] = test_data['Country_Region'].astype(str).str.lower().str.replace(' ','_')\ntest_data['province_state_country'] = test_data['Country_Region'].astype(str).str.lower().str.replace(' ','_') + '_' + test_data['Province_State']\n### change '_' to empty space'\ntest_data['province_state_country'] = test_data['province_state_country'].str.replace('_$','')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### sort the data\ntrain_data = train_data.sort_values(['province_state_country','Date'])\ntest_data = test_data.sort_values(['province_state_country','Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_start_date = min(train_data.Date)\ntrain_data_end_date = max(train_data.Date)\ntest_data_start_date = min(test_data.Date)\ntest_data_end_Date = max(test_data.Date)\n# public_test_data_start_date = pd.datetime(2020,4,1)\n\npublic_test_data_start_date = test_data_start_date\npublic_test_data_end_date = pd.datetime(2020,4,15)\nprivate_test_data_start_date = pd.datetime(2020,4,16)\nprivate_test_data_end_date = test_data_end_Date\n#### dates for filtering the train and test datasets\nprint(\"train_data_start_date\",train_data_start_date)\nprint(\"train_data_end_date\",train_data_end_date)\nprint(\"test_data_start_date\",test_data_start_date)\nprint(\"test_data_end_Date\",test_data_end_Date)\nprint(\"public_test_data_start_date\",public_test_data_start_date)\nprint(\"public_test_data_end_date\",public_test_data_end_date)\nprint(\"private_test_data_start_date\",private_test_data_start_date)\nprint(\"private_test_data_end_date\",private_test_data_end_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### function for creating feature\n# feature_day = [1,20,50,100,200,500,1000,2000,5000,10000]\n\nfeature_day = [1]\ndef create_feature(data):\n    feature_list = []\n    for day in feature_day:\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if(data[data['ConfirmedCases'] < day]['Date'].count() > 0):\n            \n            fromday = data[data['ConfirmedCases'] < day]['Date'].max()\n            print(fromday)\n            \n        elif(data[data['ConfirmedCases'] >= day]['Date'].count() > 0):\n            max_date = data[data['ConfirmedCases'] >= day]['Date'].min()\n            fromday = max_date- timedelta(days =1)\n            print(\"fromday\",fromday)\n        \n        else:\n            fromday = data[data['ConfirmedCases'] < day]['Date'].min()\n            \n        for i in range(0,len(data)):\n            if(data['Date'].iloc[i] > fromday):\n                day_number = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_number.days\n        feature_list = feature_list + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature_list]\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\nprovince_state_country_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\n\n# province_state_country_list = np.asarray(['france_saint pierre and miquelon'])\n\n#        'france_new caledonia', 'france_reunion',\n#        'france_saint barthelemy', 'france_saint pierre and miquelon',\n#        'france_st martin','gabon','france_mayotte','france_martinique','france_guadeloupe','china_anhui','china_beijing','us_california','us_new york'])\n\nsubmission_df = pd.DataFrame(columns= ['ForecastId', 'Province_State', 'Country_Region', 'Date', 'province_state_country','days','Confirmed_pred','Fatalities_pred'])\n\nvalidation_df = pd.DataFrame(columns= ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n       'Fatalities', 'province_state_country','days','Confirmed_pred','Fatalities_pred'])\n\nfor s in province_state_country_list:\n    \n    print(\"province_country_region\",s)\n    ### train and test data for that country\n    train_df = train_data.loc[(train_data['province_state_country'] == s)]\n    test_df =  test_data.loc[(test_data['province_state_country'] == s)]\n    train_df_2 = train_data.loc[(train_data['province_state_country'] == s)]\n    \n    \n    train_df = train_df.sort_values(['province_state_country','Date'])\n    test_df = test_df.sort_values(['province_state_country','Date'])\n#     \n    print(train_df.head(5))\n    print(\"train_df_2\",train_df_2.head(5))\n    print(test_df.head(5))\n    \n    train_feature = create_feature(train_df_2)\n    print(\"train_df\",train_df.head(5))\n    print(\"train_feature\",train_feature.head(5))\n    \n    adjusted_train_feature_min_index = min(train_df.index)\n    \n    for day in sorted(feature_day, reverse = True):\n        print(\"day\",day)\n        feature_use = 'Number day from ' + str(day) + ' case'\n        print(\"feature_use\",feature_use)\n        train_feature_zero_count = train_feature[train_feature[feature_use] == 0].shape[0]\n        train_feature_nonzero_count = train_feature[train_feature[feature_use] > 0].shape[0]\n        print(\"train_feature_zero_count\",train_feature_zero_count)\n        print(\"train_feature_nonzero_count\",train_feature_nonzero_count)\n        \n        adjusted_train_feature_min_index = min(train_feature[train_feature[feature_use]>0].index)\n        \n#         if(train_feature_nonzero_count >= 30):\n#             adjusted_train_feature_min_index = min(train_feature[train_feature[feature_use]>0].index)\n#             adjusted_train_feature_max_index = max(train_feature[train_feature[feature_use]>0].index)\n#             print(\"adjusted_train_feature_min_index\",adjusted_train_feature_min_index)\n#             print(\"adjusted_train_feature_max_index\",adjusted_train_feature_max_index)\n#             break\n            \n           \n    adjusted_train_data_1 = train_df.loc[train_df.index >= adjusted_train_feature_min_index]\n    adjusted_train_data_start_date = adjusted_train_data_1['Date'].min()\n    \n#     adjusted_train_data_2 = adjusted_train_data_1.loc[(adjusted_train_data_1['Date'] < public_test_data_start_date)]\n    \n    if((adjusted_train_data_start_date < public_test_data_start_date) & (adjusted_train_data_1.shape[0] >= 20)) :\n        adjusted_train_data = adjusted_train_data_1\n        adjusted_train_data_start_date = adjusted_train_data_1['Date'].min()     \n    else:\n        adjusted_train_data = train_df\n        adjusted_train_data_start_date = train_df['Date'].min()\n    \n    if((adjusted_train_data_1.shape[0] >= 13)) :\n        adjusted_private_train_data = adjusted_train_data_1\n        adjusted_private_train_data_start_date = adjusted_train_data_1['Date'].min()     \n    else:\n        adjusted_private_train_data = train_df\n        adjusted_private_train_data_start_date = train_df['Date'].min()\n    \n        \n    \n    print(adjusted_train_data)\n\n    #     adjusted_train_feature = train_feature[train_feature_zero_count:][feature_use].values.reshape(-1,1)\n#     print(\"adjusted_train_feature\",adjusted_train_feature)\n\n    ### training data for public board\n    train_data_1 = adjusted_train_data.loc[(adjusted_train_data['Date'] < public_test_data_start_date)]\n    train_data_1['days'] = (train_data_1.Date - adjusted_train_data_start_date).dt.days\n    train_data_1.index = pd.to_datetime(train_data_1.Date)\n    train_data_exog_1 = np.array(train_data_1[['days']])\n    print(\"train_data_1\",train_data_1.head(5))\n\n    #### Validation data\n    train_data_validation_1 = adjusted_train_data.loc[(adjusted_train_data['Date'] >= public_test_data_start_date)]\n    train_data_validation_1['days'] = (train_data_validation_1.Date - adjusted_train_data_start_date).dt.days\n    train_data_validation_exog_1 = np.array(train_data_validation_1[['days']])\n    print(\"train_data_validation_1\",train_data_validation_1.head(5))\n    \n    ###3 test data for public data\n    ### test data starts from '2020 -04-02' and public data starts from '2020-04-01'\n    test_data_1 = test_data.loc[(test_data['province_state_country'] == s) & (test_data['Date'] <= public_test_data_end_date)]\n    test_data_1['days'] = (test_data_1.Date - adjusted_train_data_start_date).dt.days\n    test_data_exog_1 = np.array(test_data_1[['days']])\n    print(\"test_data_1\", test_data_1.head(5))\n    \n    #### train data for private board\n    \n    train_data_2 = adjusted_private_train_data.loc[(adjusted_private_train_data['Date'] <= train_data_end_date )]\n    train_data_2['days'] = (train_data_2.Date - adjusted_private_train_data_start_date).dt.days\n    train_data_2.index = pd.to_datetime(train_data_2.Date)\n    train_data_exog_2 = np.array(train_data_2[['days']])\n    print(\"train_data_2\",train_data_2.head(5))\n    \n    ###3 test data for private data\n    ### Private board data from '2020-04-16 to '2020-05-14'\n    test_data_2 = test_data.loc[(test_data['province_state_country'] == s) & (test_data['Date'] >= private_test_data_start_date)]\n    \n    test_data_2['days'] = (test_data_2.Date - adjusted_private_train_data_start_date).dt.days\n    test_data_exog_2 = np.array(test_data_2[['days']])\n    print(\"test_data_2\", test_data_2.head(4))\n    \n    ### for public board\n    ### for confirmed cases\n    trained_Model_Confirmed_1 = auto_arima(train_data_1['ConfirmedCases'], exogenous = train_data_exog_1 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n    print(\"trained_Model_Confirmed_1\",trained_Model_Confirmed_1)\n    \n    prediction_confirmed_1 = trained_Model_Confirmed_1.predict(exogenous = train_data_validation_exog_1 , n_periods =train_data_validation_1['days'].shape[0])\n    \n    print(\"prediction_confirmed_1\",prediction_confirmed_1)\n    \n    prediction_confirmed_public_1 = trained_Model_Confirmed_1.predict(exogenous = test_data_exog_1 , n_periods =test_data_1['days'].shape[0])\n    print(\"prediction_confirmed_public_1\",prediction_confirmed_public_1)\n\n    ### for Fatalities\n    trained_Model_Fatalities_1 = auto_arima(train_data_1['Fatalities'], exogenous = train_data_exog_1 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n    print(\"trained_Model_Fatalities_1\",trained_Model_Fatalities_1)\n    \n    prediction_Fatalities_1 = trained_Model_Fatalities_1.predict(exogenous = train_data_validation_exog_1 , n_periods =train_data_validation_1['days'].shape[0])\n    print(\"prediction_Fatalities_1\",prediction_Fatalities_1)\n    \n    prediction_Fatalities_public_1 = trained_Model_Fatalities_1.predict(exogenous = test_data_exog_1 , n_periods =test_data_1['days'].shape[0])\n    \n    print(\"prediction_Fatalities_public_1\",prediction_Fatalities_public_1)\n\n    ### for private board\n    ### for confirmed cases\n    trained_Model_Confirmed_2 = auto_arima(train_data_2['ConfirmedCases'], exogenous = train_data_exog_2 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n    print(\"trained_Model_Confirmed_2\",trained_Model_Confirmed_2)\n    \n    prediction_confirmed_private_2 = trained_Model_Confirmed_2.predict(exogenous = test_data_exog_2 , n_periods =test_data_2['days'].shape[0])\n    \n    print(\"prediction_confirmed_public_2\",prediction_confirmed_private_2)\n\n    ### for Fatalities\n    trained_Model_Fatalities_2 = auto_arima(train_data_2['Fatalities'], exogenous = train_data_exog_2 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n    print(\"trained_Model_Fatalities_2\",trained_Model_Fatalities_2)\n    \n    prediction_Fatalities_private_2 = trained_Model_Fatalities_2.predict(exogenous = test_data_exog_2 , n_periods =test_data_2['days'].shape[0])\n    \n    print(\"prediction_Fatalities_private_2\",prediction_Fatalities_private_2)\n    \n    ##### public data prediction from 2020-04-01 to 2020-04-15'\n    ### test data starts from '2020-04-02'\n    #### Validation data start from '2020-04-01  to maimum date of training dataset'\n    ### public data prediction data frame\n    public_data_pred = test_data_1\n    public_data_pred['Confirmed_pred'] = prediction_confirmed_public_1\n    public_data_pred['Fatalities_pred'] = prediction_Fatalities_public_1\n    \n    ### Validation data\n    validation_data = train_data_validation_1\n    validation_data['Confirmed_pred'] = prediction_confirmed_1\n    validation_data['Fatalities_pred'] = prediction_Fatalities_1\n    \n    \n    #### Private dataset prediction from 2020-04-15 to 2020-05-14\n    ### test data have data from '2020-04-02' to '2020-05-14'\n    private_data_pred = test_data_2\n    private_data_pred['Confirmed_pred'] = prediction_confirmed_private_2\n    private_data_pred['Fatalities_pred'] = prediction_Fatalities_private_2\n    \n    ### Private data prediction filter\n    private_data_pred_till_date = private_data_pred.loc[private_data_pred.Date >= private_test_data_start_date]\n    \n    Evaluation_df = public_data_pred\n    Evaluation_df = Evaluation_df.append(private_data_pred_till_date , ignore_index = True)\n    \n    submission_df = submission_df.append(Evaluation_df , ignore_index = True)\n    \n    validation_df = validation_df.append(validation_data , ignore_index = True)\n    \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\n# # province_state_country_list = np.asarray(['us_california','us_new york'])\n# submission_df = pd.DataFrame(columns= ['ForecastId', 'Province_State', 'Country_Region', 'Date', 'province_state_country','days','Confirmed_pred','Fatalities_pred'])\n\n# validation_df = pd.DataFrame(columns= ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n#        'Fatalities', 'province_state_country','days','Confirmed_pred','Fatalities_pred'])\n\n# for s in province_state_country_list:\n    \n#     print(\"province_country_region\",s)\n#     ### train and test data for that country\n#     train_df = train_data.loc[(train_data['province_state_country'] == s)]\n#     test_df =  test_data.loc[(test_data['province_state_country'] == s)]\n#     train_df_2 = train_data.loc[(train_data['province_state_country'] == s)]\n    \n    \n#     train_df = train_df.sort_values(['province_state_country','Date'])\n#     test_df = test_df.sort_values(['province_state_country','Date'])\n# #     \n#     print(train_df.head(5))\n#     print(test_df.head(5))\n    \n#     train_feature = create_feature(train_df_2)\n#     print(\"train_df\",train_df.head(5))\n#     print(\"train_feature\",train_feature.head(5))\n    \n#     adjusted_train_feature_min_index = min(train_df.index)\n#     for day in sorted(feature_day, reverse = True):\n#         print(\"day\",day)\n#         feature_use = 'Number day from ' + str(day) + ' case'\n#         print(\"feature_use\",feature_use)\n#         train_feature_zero_count = train_feature[train_feature[feature_use] == 0].shape[0]\n#         train_feature_nonzero_count = train_feature[train_feature[feature_use] > 0].shape[0]\n#         print(\"train_feature_zero_count\",train_feature_zero_count)\n#         print(\"train_feature_nonzero_count\",train_feature_nonzero_count)\n#         if(train_feature_nonzero_count >= 30):\n#             adjusted_train_feature_min_index = min(train_feature[train_feature[feature_use]>0].index)\n#             adjusted_train_feature_max_index = max(train_feature[train_feature[feature_use]>0].index)\n#             print(\"adjusted_train_feature_min_index\",adjusted_train_feature_min_index)\n#             print(\"adjusted_train_feature_max_index\",adjusted_train_feature_max_index)\n#             break\n            \n           \n#     adjusted_train_data = train_df.loc[train_df.index >= adjusted_train_feature_min_index]\n#     adjusted_train_data_start_date = adjusted_train_data['Date'].min()\n#     print(adjusted_train_data)\n\n#     #     adjusted_train_feature = train_feature[train_feature_zero_count:][feature_use].values.reshape(-1,1)\n# #     print(\"adjusted_train_feature\",adjusted_train_feature)\n\n#     ### training data for public board\n#     train_data_1 = adjusted_train_data.loc[(adjusted_train_data['Date'] < public_test_data_start_date)]\n#     train_data_1['days'] = (train_data_1.Date - adjusted_train_data_start_date).dt.days\n#     train_data_1.index = pd.to_datetime(train_data_1.Date)\n#     train_data_exog_1 = np.array(train_data_1[['days']])\n#     print(\"train_data_1\",train_data_1.head(5))\n\n#     #### Validation data\n#     train_data_validation_1 = adjusted_train_data.loc[(adjusted_train_data['Date'] >= public_test_data_start_date)]\n#     train_data_validation_1['days'] = (train_data_validation_1.Date - adjusted_train_data_start_date).dt.days\n#     train_data_validation_exog_1 = np.array(train_data_validation_1[['days']])\n#     print(\"train_data_validation_1\",train_data_validation_1.head(5))\n    \n#     ###3 test data for public data\n#     ### test data starts from '2020 -04-02' and public data starts from '2020-04-01'\n#     test_data_1 = test_data.loc[(test_data['province_state_country'] == s) & (test_data['Date'] <= public_test_data_end_date)]\n#     test_data_1['days'] = (test_data_1.Date - adjusted_train_data_start_date).dt.days\n#     test_data_exog_1 = np.array(test_data_1[['days']])\n#     print(\"test_data_1\", test_data_1.head(5))\n    \n#     #### train data for private board\n#     train_data_2 = adjusted_train_data.loc[(adjusted_train_data['Date'] <= train_data_end_date )]\n#     train_data_2['days'] = (train_data_2.Date - adjusted_train_data_start_date).dt.days\n#     train_data_2.index = pd.to_datetime(train_data_2.Date)\n#     train_data_exog_2 = np.array(train_data_2[['days']])\n#     print(\"train_data_2\",train_data_2.head(5))\n    \n#     ###3 test data for private data\n#     ### Private board data from '2020-04-16 to '2020-05-14'\n#     test_data_2 = test_data.loc[(test_data['province_state_country'] == s) & (test_data['Date'] >= private_test_data_start_date)]\n    \n#     test_data_2['days'] = (test_data_2.Date - adjusted_train_data_start_date).dt.days\n#     test_data_exog_2 = np.array(test_data_2[['days']])\n#     print(\"test_data_2\", test_data_2.head(4))\n    \n#     ### for public board\n#     ### for confirmed cases\n#     trained_Model_Confirmed_1 = auto_arima(train_data_1['ConfirmedCases'], exogenous = train_data_exog_1 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Confirmed_1\",trained_Model_Confirmed_1)\n    \n#     prediction_confirmed_1 = trained_Model_Confirmed_1.predict(exogenous = train_data_validation_exog_1 , n_periods =train_data_validation_1['days'].shape[0])\n    \n#     print(\"prediction_confirmed_1\",prediction_confirmed_1)\n    \n#     prediction_confirmed_public_1 = trained_Model_Confirmed_1.predict(exogenous = test_data_exog_1 , n_periods =test_data_1['days'].shape[0])\n#     print(\"prediction_confirmed_public_1\",prediction_confirmed_public_1)\n\n#     ### for Fatalities\n#     trained_Model_Fatalities_1 = auto_arima(train_data_1['Fatalities'], exogenous = train_data_exog_1 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Fatalities_1\",trained_Model_Fatalities_1)\n    \n#     prediction_Fatalities_1 = trained_Model_Fatalities_1.predict(exogenous = train_data_validation_exog_1 , n_periods =train_data_validation_1['days'].shape[0])\n#     print(\"prediction_Fatalities_1\",prediction_Fatalities_1)\n    \n#     prediction_Fatalities_public_1 = trained_Model_Fatalities_1.predict(exogenous = test_data_exog_1 , n_periods =test_data_1['days'].shape[0])\n    \n#     print(\"prediction_Fatalities_public_1\",prediction_Fatalities_public_1)\n\n#     ### for private board\n#     ### for confirmed cases\n#     trained_Model_Confirmed_2 = auto_arima(train_data_2['ConfirmedCases'], exogenous = train_data_exog_2 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Confirmed_2\",trained_Model_Confirmed_2)\n    \n#     prediction_confirmed_private_2 = trained_Model_Confirmed_2.predict(exogenous = test_data_exog_2 , n_periods =test_data_2['days'].shape[0])\n    \n#     print(\"prediction_confirmed_public_2\",prediction_confirmed_private_2)\n\n#     ### for Fatalities\n#     trained_Model_Fatalities_2 = auto_arima(train_data_2['Fatalities'], exogenous = train_data_exog_2 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Fatalities_2\",trained_Model_Fatalities_2)\n    \n#     prediction_Fatalities_private_2 = trained_Model_Fatalities_2.predict(exogenous = test_data_exog_2 , n_periods =test_data_2['days'].shape[0])\n    \n#     print(\"prediction_Fatalities_private_2\",prediction_Fatalities_private_2)\n    \n#     ##### public data prediction from 2020-04-01 to 2020-04-15'\n#     ### test data starts from '2020-04-02'\n#     #### Validation data start from '2020-04-01  to maimum date of training dataset'\n#     ### public data prediction data frame\n#     public_data_pred = test_data_1\n#     public_data_pred['Confirmed_pred'] = prediction_confirmed_public_1\n#     public_data_pred['Fatalities_pred'] = prediction_Fatalities_public_1\n    \n#     ### Validation data\n#     validation_data = train_data_validation_1\n#     validation_data['Confirmed_pred'] = prediction_confirmed_1\n#     validation_data['Fatalities_pred'] = prediction_Fatalities_1\n    \n    \n#     #### Private dataset prediction from 2020-04-15 to 2020-05-14\n#     ### test data have data from '2020-04-02' to '2020-05-14'\n#     private_data_pred = test_data_2\n#     private_data_pred['Confirmed_pred'] = prediction_confirmed_private_2\n#     private_data_pred['Fatalities_pred'] = prediction_Fatalities_private_2\n    \n#     ### Private data prediction filter\n#     private_data_pred_till_date = private_data_pred.loc[private_data_pred.Date >= private_test_data_start_date]\n    \n#     Evaluation_df = public_data_pred\n#     Evaluation_df = Evaluation_df.append(private_data_pred_till_date , ignore_index = True)\n    \n#     submission_df = submission_df.append(Evaluation_df , ignore_index = True)\n    \n#     validation_df = validation_df.append(validation_data , ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\n\n# # province_state_country_list = np.asarray(['us_california','us_new york'])\n\n# # print(province_state_country_list)\n\n# submission_df = pd.DataFrame(columns= ['ForecastId', 'Province_State', 'Country_Region', 'Date', 'province_state_country','days','Confirmed_pred','Fatalities_pred'])\n\n# validation_df = pd.DataFrame(columns= ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n#        'Fatalities', 'province_state_country','days','Confirmed_pred','Fatalities_pred'])\n\n# for s in province_state_country_list:\n#     print(\"province_country_region\",s)\n    \n#     #### train data for public data\n    \n#     train_data_1 = train_data.loc[(train_data['province_state_country'] == s) & (train_data['Date']< public_test_data_start_date)]\n    \n#     train_data_1['days'] = (train_data_1.Date - train_data_start_date).dt.days\n#     train_data_1.index = pd.to_datetime(train_data_1.Date)\n#     train_data_exog_1 = np.array(train_data_1[['days']])\n    \n#     print(\"train_data_1\",train_data_1.head(5))\n    \n#     #### Validation data\n#     train_data_validation_1 = train_data.loc[(train_data['province_state_country'] == s) & (train_data['Date'] >= public_test_data_start_date)]\n    \n#     train_data_validation_1['days'] = (train_data_validation_1.Date - train_data_start_date).dt.days\n#     train_data_validation_exog_1 = np.array(train_data_validation_1[['days']])\n    \n#     ###3 test data for public data\n#     ### test data starts from '2020 -04-02' and public data starts from '2020-04-01'\n#     test_data_1 = test_data.loc[(test_data['province_state_country'] == s) & (test_data['Date'] <= public_test_data_end_date)]\n#     test_data_1['days'] = (test_data_1.Date - train_data_start_date).dt.days\n#     test_data_exog_1 = np.array(test_data_1[['days']])\n    \n#     print(\"test_data_1\", test_data_1.head(4))\n    \n#     #### train data for private board\n    \n#     train_data_2 = train_data.loc[(train_data['province_state_country'] == s) & (train_data['Date']<=train_data_end_date )]\n#     train_data_2['days'] = (train_data_2.Date - train_data_start_date).dt.days\n#     train_data_2.index = pd.to_datetime(train_data_2.Date)\n#     train_data_exog_2 = np.array(train_data_2[['days']])\n    \n#     print(\"train_data_2\",train_data_2.head(5))\n    \n#     ###3 test data for private data\n#     ### Private board data from '2020-04-16 to '2020-05-14'\n#     test_data_2 = test_data.loc[(test_data['province_state_country'] == s) & (test_data['Date'] >= private_test_data_start_date)]\n    \n#     test_data_2['days'] = (test_data_2.Date - train_data_start_date).dt.days\n#     test_data_exog_2 = np.array(test_data_2[['days']])\n#     print(\"test_data_2\", test_data_2.head(4))\n    \n#     ### for public board\n#     ### for confirmed cases\n#     trained_Model_Confirmed_1 = auto_arima(train_data_1['ConfirmedCases'], exogenous = train_data_exog_1 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Confirmed_1\",trained_Model_Confirmed_1)\n    \n#     prediction_confirmed_1 = trained_Model_Confirmed_1.predict(exogenous = train_data_validation_exog_1 , n_periods =train_data_validation_1['days'].shape[0])\n    \n#     print(\"prediction_confirmed_1\",prediction_confirmed_1)\n    \n#     prediction_confirmed_public_1 = trained_Model_Confirmed_1.predict(exogenous = test_data_exog_1 , n_periods =test_data_1['days'].shape[0])\n#     print(\"prediction_confirmed_public_1\",prediction_confirmed_public_1)\n\n#     ### for Fatalities\n#     trained_Model_Fatalities_1 = auto_arima(train_data_1['Fatalities'], exogenous = train_data_exog_1 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Fatalities_1\",trained_Model_Fatalities_1)\n    \n#     prediction_Fatalities_1 = trained_Model_Fatalities_1.predict(exogenous = train_data_validation_exog_1 , n_periods =train_data_validation_1['days'].shape[0])\n#     print(\"prediction_Fatalities_1\",prediction_Fatalities_1)\n    \n#     prediction_Fatalities_public_1 = trained_Model_Fatalities_1.predict(exogenous = test_data_exog_1 , n_periods =test_data_1['days'].shape[0])\n    \n#     print(\"prediction_Fatalities_public_1\",prediction_Fatalities_public_1)\n\n#     ### for private board\n#     ### for confirmed cases\n#     trained_Model_Confirmed_2 = auto_arima(train_data_2['ConfirmedCases'], exogenous = train_data_exog_2 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Confirmed_2\",trained_Model_Confirmed_2)\n    \n#     prediction_confirmed_private_2 = trained_Model_Confirmed_2.predict(exogenous = test_data_exog_2 , n_periods =test_data_2['days'].shape[0])\n    \n#     print(\"prediction_confirmed_public_2\",prediction_confirmed_private_2)\n\n#     ### for Fatalities\n#     trained_Model_Fatalities_2 = auto_arima(train_data_2['Fatalities'], exogenous = train_data_exog_2 , supress_warnings =  True, m = 1, stepwise = True, error_action = 'ignore', stationary = False)\n#     print(\"trained_Model_Fatalities_2\",trained_Model_Fatalities_2)\n    \n#     prediction_Fatalities_private_2 = trained_Model_Fatalities_2.predict(exogenous = test_data_exog_2 , n_periods =test_data_2['days'].shape[0])\n    \n#     print(\"prediction_Fatalities_private_2\",prediction_Fatalities_private_2)\n    \n#     ##### public data prediction from 2020-04-01 to 2020-04-15'\n#     ### test data starts from '2020-04-02'\n#     #### Validation data start from '2020-04-01  to maimum date of training dataset'\n#     ### public data prediction data frame\n#     public_data_pred = test_data_1\n#     public_data_pred['Confirmed_pred'] = prediction_confirmed_public_1\n#     public_data_pred['Fatalities_pred'] = prediction_Fatalities_public_1\n    \n#     ### Validation data\n#     validation_data = train_data_validation_1\n#     validation_data['Confirmed_pred'] = prediction_confirmed_1\n#     validation_data['Fatalities_pred'] = prediction_Fatalities_1\n    \n    \n#     #### Private dataset prediction from 2020-04-15 to 2020-05-14\n#     ### test data have data from '2020-04-02' to '2020-05-14'\n#     private_data_pred = test_data_2\n#     private_data_pred['Confirmed_pred'] = prediction_confirmed_private_2\n#     private_data_pred['Fatalities_pred'] = prediction_Fatalities_private_2\n    \n#     ### Private data prediction filter\n#     private_data_pred_till_date = private_data_pred.loc[private_data_pred.Date >= private_test_data_start_date]\n    \n#     Evaluation_df = public_data_pred\n#     Evaluation_df = Evaluation_df.append(private_data_pred_till_date , ignore_index = True)\n    \n#     submission_df = submission_df.append(Evaluation_df , ignore_index = True)\n    \n#     validation_df = validation_df.append(validation_data , ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.loc[submission_df['Confirmed_pred'] <0 ,'Confirmed_pred'] =0\nsubmission_df.loc[submission_df['Fatalities_pred'] <0 ,'Fatalities_pred'] =0\nvalidation_df.loc[submission_df['Confirmed_pred'] <0 ,'Confirmed_pred'] =0\nvalidation_df.loc[submission_df['Fatalities_pred'] <0 ,'Fatalities_pred'] =0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = submission_df[['ForecastId','Confirmed_pred','Fatalities_pred']]\n### renaming columns\nsubmission_data.rename(columns = {\"Confirmed_pred\":\"ConfirmedCases\" ,\"Fatalities_pred\":\"Fatalities\"},inplace =True)\n\nsubmission_data['ConfirmedCases'] =submission_data['ConfirmedCases'].apply(np.ceil)\nsubmission_data['Fatalities'] = submission_data['Fatalities'].apply(np.ceil)\n\nsubmission_data['ConfirmedCases'] =submission_data['ConfirmedCases'].astype(int)\nsubmission_data['Fatalities'] = submission_data['Fatalities'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data.to_csv(\"submission.csv\",index = None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}