{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets extract data about India out and plot it.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"india = train_df[train_df[\"Country_Region\"]==\"India\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It started slow but as you can see it has started to increase rapidly and its not a good sign.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"india.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(india[\"ConfirmedCases\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Confirmed Cases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Both the plot looks pretty same. For a minute I thought that I have done some mistake but not. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(india[\"Fatalities\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Fatalities\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I was checking how many states/province are there in china**"},{"metadata":{"trusted":true},"cell_type":"code","source":"china_states = train_df[train_df[\"Country_Region\"]==\"China\"][\"Province_State\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Province_State\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As there are many countries for which the province/state column is nan so i thought to put the country name if it is nan.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def province(state,country):\n    if state == \"nan\":\n        return country\n    return state","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I filled all the nan value with a string nan this string could be anything.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.fillna(\"nan\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Province_State\"] = train_df.apply(lambda x: province(x[\"Province_State\"],x[\"Country_Region\"]),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"china_states","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Italy is struggling right now so i thought to so see whats going on.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"italy = train_df[train_df[\"Country_Region\"]==\"Italy\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The condition has not improved a lot its still increasing and thats not good.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(italy[\"ConfirmedCases\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Confirmed Cases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Again you see both the plot looks the same.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(italy[\"Fatalities\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Fatalities Cases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **One Thing I have noticed that the curve of a countries confirmed cases and fatalities looks pretty same And it make sense if you think, if the confirmed cases fluctuates deaths would also increase or decrease. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting the date column to datetime datatype so that we can extract day and month from it**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Date\"] = pd.to_datetime(train_df[\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"month\"] = train_df[\"Date\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extracting the day of the month**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['day'] = train_df['Date'].dt.day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**No need fot the date column now, so dropping it**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop('Date',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I thought of using the country and state column as a variable but the results were not good so I excluded them. So labelencoder is not required and but I kept it.(you can remove this as this will not effect the result)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def labelencoder(data):\n    le = preprocessing.LabelEncoder()\n    new_data = le.fit_transform(data)\n    return new_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Country_Region\"] = labelencoder(train_df[\"Country_Region\"].values)\ntrain_df[\"Province_State\"] = labelencoder(train_df[\"Province_State\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here I did all the steps for the test data as I did with train."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"Date\"] = pd.to_datetime(test_df[\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['day'] = test_df['Date'].dt.day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"month\"] = test_df[\"Date\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.drop('Date',axis=1,inplace=True)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.fillna(\"nan\",inplace=True)\ntest_df[\"Province_State\"] = test_df.apply(lambda x: province(x[\"Province_State\"],x[\"Country_Region\"]),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"Country_Region\"] = labelencoder(test_df[\"Country_Region\"].values)\ntest_df[\"Province_State\"] = labelencoder(test_df[\"Province_State\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = train_df[\"Country_Region\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This is the important part.\n\n# Using a linear regressor wont work well as you can see the curve is not really linear.\n# Using just Linear regression will just coincide with some of the data.\n# Here is a link to a good post about it https://towardsdatascience.com/machine-learning-polynomial-regression-with-python-5328e4e8a386)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n#from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_reg_cc = PolynomialFeatures(degree = 4)\npoly_reg_ft = PolynomialFeatures(degree = 4)\n\nreg_cc = LinearRegression()\nreg_ft = LinearRegression()\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = train_df[train_df[\"Country_Region\"]==country][\"Province_State\"].unique()\n    for state in states:\n        train_df_filt = train_df[(train_df[\"Country_Region\"]==country)&(train_df[\"Province_State\"]==state)]\n        y_train_cc = train_df_filt[\"ConfirmedCases\"].values\n        y_train_ft = train_df_filt[\"Fatalities\"].values\n        \n        \n        X_train = train_df_filt[[\"month\",\"day\"]]\n    \n        \n        test_df_filt = test_df[(test_df[\"Country_Region\"]==country)&(test_df[\"Province_State\"]==state)]\n        X_test = test_df_filt.drop('ForecastId',axis=1)\n        X_test = X_test[[\"month\",\"day\"]]\n        test_Id = test_df_filt[\"ForecastId\"].values\n        \n        scaler = MinMaxScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n        \n        \n        scaler_cc = MinMaxScaler()\n        scaler_ft = MinMaxScaler()\n        \n        y_train_cc=y_train_cc.reshape(-1,1)\n        y_train_ft=y_train_ft.reshape(-1,1)\n        \n        y_train_cc=scaler_cc.fit_transform(y_train_cc)\n        y_train_ft=scaler_ft.fit_transform(y_train_ft)\n        \n        y_train_cc = y_train_cc.flatten()\n        y_train_ft = y_train_ft.flatten()\n        \n        X_train_poly = poly_reg_cc.fit_transform(X_train)\n        reg_cc.fit(X_train_poly,y_train_cc)\n        X_test_poly = poly_reg_cc.fit_transform(X_test)\n        test_cc = reg_cc.predict(X_test_poly)\n        \n        test_cc = test_cc.reshape(-1,1)\n        test_cc = scaler_cc.inverse_transform(test_cc)\n        test_cc = test_cc.flatten()\n        \n        X_train_poly = poly_reg_ft.fit_transform(X_train)\n        reg_ft.fit(X_train_poly,y_train_ft)\n        X_test_poly = poly_reg_ft.fit_transform(X_test)\n        test_ft = reg_ft.predict(X_test_poly)\n        \n        test_ft = test_ft.reshape(-1,1)\n        \n        test_ft = scaler_ft.inverse_transform(test_ft)\n        test_ft = test_ft.flatten()\n        \n        df = pd.DataFrame({'ForecastId': test_Id, 'ConfirmedCases': test_cc, 'Fatalities': test_ft})\n        \n        df_out = pd.concat([df_out, df], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out[\"Fatalities\"] = df_out[\"Fatalities\"].apply(int)\ndf_out[\"ConfirmedCases\"] = df_out[\"ConfirmedCases\"].apply(int)\ndf_out[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out[\"ForecastId\"] = df_out[\"ForecastId\"].astype('int32')\ndf_out[\"Fatalities\"] = df_out[\"Fatalities\"].astype('int32')\ndf_out[\"ConfirmedCases\"] = df_out[\"ConfirmedCases\"].astype('int32')\ndf_out.info()\ndf_out.to_csv(\"submission.csv\",index=False)\nsub = pd.read_csv(\"submission.csv\")\nsub[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This is my first kernel explanation, I am not that good at explaining but the code is pretty clear in it self. I hope you are safe and fit.\n# Please upvote if you think it helped\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\n\ntrain[\"Province_State\"] = train[\"Province_State\"].fillna('')\ntest[\"Province_State\"] = test[\"Province_State\"].fillna('')\n\ntrain[\"Month\"], train[\"Day\"] = 0, 0\nfor i in range(len(train)):\n    train[\"Month\"][i] = (train[\"Date\"][i]).split(\"-\")[1]\n    train[\"Day\"][i] = (train[\"Date\"][i]).split(\"-\")[2]\n    \ntest[\"Month\"], test[\"Day\"] = 0, 0\nfor i in range(len(test)):\n    test[\"Month\"][i] = (test[\"Date\"][i]).split(\"-\")[1]\n    test[\"Day\"][i] = (test[\"Date\"][i]).split(\"-\")[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(train)):\n    if train[\"Province_State\"][i] != '':\n        train[\"Country_Region\"][i] = str(train[\"Province_State\"][i]) + \" (\" + str(train[\"Country_Region\"][i]) + \")\"\n       \nfor i in range(len(test)):\n    if test[\"Province_State\"][i] != '':\n        test[\"Country_Region\"][i] = str(test[\"Province_State\"][i]) + \" (\" + str(test[\"Country_Region\"][i]) + \")\"\n        \ntrain.drop(columns = \"Province_State\", inplace=True)\ntest.drop(columns = \"Province_State\", inplace=True)\n\ntrain.rename(columns = {\"Country_Region\" : \"Country/State\"}, inplace=True)\ntest.rename(columns = {\"Country_Region\" : \"Country/State\"}, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor value in train[\"Country/State\"].unique():\n    if i < len(train):\n        j = 1\n        while(train[\"Country/State\"][i] == value):\n            train[\"Day\"][i] = j\n            j += 1; i += 1\n            if i == len(train):\n                break\n\ni = 0\nfor value in test[\"Country/State\"].unique():\n    if i < len(test):\n        j = 72\n        while(test[\"Country/State\"][i] == value):\n            test[\"Day\"][i] = j\n            j += 1; i += 1\n            if i == len(test):\n                break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns = [\"Date\"])\ntest = test.drop(columns = [\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = train[\"Country/State\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg_cc = PolynomialFeatures(degree = 4)\npoly_reg_ft = PolynomialFeatures(degree = 4)\n\nfrom sklearn.linear_model import LinearRegression\nreg_cc = LinearRegression()\nreg_ft = LinearRegression()\n\nfrom sklearn.preprocessing import StandardScaler\n\nsub = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\nfor value in countries:\n    train_temp = train.loc[train[\"Country/State\"] == value]\n    test_temp = test.loc[test[\"Country/State\"] == value]\n    train_temp_cc = train_temp[\"ConfirmedCases\"].loc[train[\"Country/State\"] == value].to_frame()\n    train_temp_ft = train_temp[\"Fatalities\"].loc[train[\"Country/State\"] == value].to_frame()\n    \n    train_temp_X = train_temp.iloc[:, 4:6]\n    test_temp_X = test_temp.iloc[:, 2:4]\n    sc1 = StandardScaler()\n    train_temp_X = sc1.fit_transform(train_temp_X)\n    test_temp_X = sc1.transform(test_temp_X)\n    \n    sc_cc = StandardScaler()\n    sc_ft = StandardScaler()\n    train_temp_cc = sc_cc.fit_transform(train_temp_cc)\n    train_temp_ft = sc_ft.fit_transform(train_temp_ft)\n    \n    X_poly = poly_reg_cc.fit_transform(train_temp_X)\n    reg_cc.fit(X_poly, train_temp_cc)\n    test_cc = sc_cc.inverse_transform(reg_cc.predict(poly_reg_cc.fit_transform(test_temp_X)))\n    \n    X_poly = poly_reg_ft.fit_transform(train_temp_X)\n    reg_ft.fit(X_poly, train_temp_ft)\n    test_ft = sc_ft.inverse_transform(reg_ft.predict(poly_reg_ft.fit_transform(test_temp_X)))\n    \n    a = int(train[\"Day\"].loc[train[\"Country/State\"] == \"India\"].max())\n    b = int(a - test_temp[\"Day\"].min())\n    \n    test_cc[0:b+1] = sc_cc.inverse_transform(train_temp_cc)[(a-b-1):(a)]\n    test_ft[0:b+1] = sc_ft.inverse_transform(train_temp_ft)[(a-b-1):(a)]\n    \n    test_cc = test_cc.flatten()\n    test_ft = test_ft.flatten()\n    sub_temp = pd.DataFrame({'ForecastId': test_temp[\"ForecastId\"].loc[test[\"Country/State\"] == value],\n                             'ConfirmedCases': test_cc, 'Fatalities': test_ft})\n    sub = pd.concat([sub, sub_temp], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[\"ForecastId\"] = sub[\"ForecastId\"].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}