{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.model_selection import LeaveOneOut\nfrom statsmodels import api as sm\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import preprocessing\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv') \ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\ntr_len = len(df_train)\nte_len = len(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"covid_train\")\nprint(df_train.shape)\nprint(df_train.columns)\nprint(df_train.head())\nprint(\"covid_test\")\nprint(df_test.shape)\nprint(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Days'] = pd.to_datetime(df_train['Date']).sub(pd.Timestamp('2020-01-21')).dt.days\ndf_test['Days'] = pd.to_datetime(df_test['Date']).sub(pd.Timestamp('2020-01-21')).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([df_train,df_test],axis=0)\ndf_all = df_all.reset_index()\nprint(df_all)\n#print(\"Original features:\\n\", list(df_all.columns), \"\\n\")\ndummies = pd.get_dummies(df_all[\"Country_Region\"])\n#print(\"Features after get_dummies:\\n\", list(dummies.columns))\ndummies\ndf_all_trans = pd.concat([df_all, dummies],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_length = len(df_all_trans)\ndate_num = df_all_trans[\"Date\"].values\ndf_all_trans = df_all_trans.drop(columns=['Date', 'Country_Region'])\n#date_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(all_length):\n    a,b,c = date_num[i].split(\"-\")\n    num_date = int(a)*10000+int(b)*100+int(c)\n    #print(num_date)\n    if i==0:\n        num_dates = num_date\n    else:\n        num_dates = np.vstack((num_dates,num_date))\ndf_temp = pd.DataFrame(num_dates, columns=[\"Date_transer\"])\ndf_end = pd.concat([df_all_trans, df_temp],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df_end[0:tr_len]\ntest = df_end[tr_len:]\nprint(test)\ntrain_lavel = pd.concat([train[\"Fatalities\"],train[\"ConfirmedCases\"]],axis=1)\ntrain_lavel\nx_data_1 = train.drop(columns=[\"Fatalities\",\"ConfirmedCases\"])\nx_data_1 = x_data_1.drop(columns=[\"Province_State\",\"ForecastId\",\"Id\"])\nx_data_2 = train.drop(columns=[\"ConfirmedCases\",\"Province_State\",\"ForecastId\",\"Id\"])\n\ntest_pre = test.drop(columns=[\"Fatalities\",\"ConfirmedCases\"])\ntest_pre = test_pre.drop(columns=[\"Province_State\",\"ForecastId\",\"Id\"])\nlast_test = test_pre.values\n\n\nx_data = x_data_1.values\nx_data_2 = x_data_2.values\ny_data_1 = train[\"Fatalities\"]\ny_data_1 = y_data_1.values\ny_data_2 = train[\"ConfirmedCases\"]\ny_data_2 = y_data_2.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\nprint(x_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def XGBReg(X_tra,y_tra,X_eval,y_eval):\n    #xgboostモデルの作成\n    #reg = xgb.XGBRegressor()\n    # ハイパーパラメータ探索\n    #reg_cv = GridSearchCV(reg, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\n    #reg_cv.fit(X_tra, y_tra)\n    #print(reg_cv.best_params_, reg_cv.best_score_)\n\n# 改めて最適パラメータで学習\n    #reg = xgb.XGBRegressor(**reg_cv.best_params_)\n    reg = xgb.XGBRegressor(max_depth = 4, n_estimators = 100)\n    reg.fit(X_tra, y_tra)\n    y_pred = reg.predict(X_eval)\n    \n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ = train[\"Fatalities\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([df_train,df_test],axis=0)\nprint(df_all)\n#print(\"Original features:\\n\", list(df_all.columns), \"\\n\")\ndummies = pd.get_dummies(df_all[\"Country_Region\"])\n#print(\"Features after get_dummies:\\n\", list(dummies.columns))\ndummies\ndf_all_trans = pd.concat([df_all, dummies],axis=1)\n#df_all = pd.concat([df_train, df_test])\ndf_all_trans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ＣＶ"},{"metadata":{"trusted":true},"cell_type":"code","source":"n=5\nkf = KFold(n_splits=n,shuffle = True)\n#skf = StratifiedKFold(n_splits=10)\nkunikunosaku = []\n#STANDARD = True\nSTANDARD = False\n\nfor train_index, eval_index in kf.split(x_data,y_data_1):\n    X_tra, X_eval = x_data[train_index],x_data[eval_index]\n    y_tra, y_eval = y_data_1[train_index], y_data_1[eval_index]\n    print(train_index)\n    print(train_index.shape)\n    print(eval_index)\n    print(eval_index.shape)\n    \n    if STANDARD==True:\n        #標準化\n        #scaler = MinMaxScaler(feature_range=(0, 1))\n        scaler = StandardScaler()\n        scaler.fit(X_tra)\n        X_tra = scaler.transform(X_tra)\n        X_eval = scaler.transform(X_eval)\n        \n        #教師なし\n        #untamed = TSNE(n_components=2, random_state=0)\n        untamed = PCA(n_components=100)\n        untamed.fit(X_tra)\n        ev_ratio = untamed.explained_variance_ratio_\n        print(\"sum = \",sum(ev_ratio))\n        \n        \n        \n        X_tra = untamed.transform(X_tra)\n        X_eval = untamed.transform(X_eval)\n    \n    #clf = linear_model.LassoCV()\n    #result = clf.fit(X_tra,y_tra)\n    #y_pred = clf.predict(X_eval)\n    y_pred = XGBReg(X_tra,y_tra,X_eval,y_eval)\n    plt.scatter(y_eval, y_pred)\n    print(y_pred.shape)\n    connection = np.vstack([eval_index,y_pred])\n    print(connection.shape)\n    kunikunosaku.append(connection)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(n):\n    kunikunosaku_np = kunikunosaku[i].transpose(1, 0)\n    clone = pd.DataFrame(kunikunosaku_np)\n    clone.columns = ['Row', 'Fatalities']\n    clone = clone.set_index('Row')\n    if i==0:\n        connectior = clone\n    else:\n        connectior = pd.concat([connectior, clone],axis=1)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"connectior = connectior.fillna(0)\nFata_predict = connectior.sum(axis=1)\nFata_predict\nclonez = pd.DataFrame(Fata_predict)\nclonez=clonez.reset_index()\nclonez = clonez.drop(columns=[\"Row\"])\nclonez\ndata_plus = pd.concat([x_data_1,clonez],axis=1)\ndata_plus = data_plus.drop(columns=[\"index\"])\nadd_data = data_plus.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=5\nkf = KFold(n_splits=n,shuffle = True)\n#skf = StratifiedKFold(n_splits=10)\npredict_ans = []\ntrue_ans = []\n#STANDARD = True\n\nfor train_index, eval_index in kf.split(add_data,y_data_2):\n    X_tra, X_eval = add_data[train_index],add_data[eval_index]\n    y_tra, y_eval = y_data_2[train_index], y_data_2[eval_index]\n    \n    if STANDARD==True:\n        #標準化\n        #scaler = MinMaxScaler(feature_range=(0, 1))\n        scaler = StandardScaler()\n        scaler.fit(X_tra)\n        X_tra = scaler.transform(X_tra)\n        X_eval = scaler.transform(X_eval)\n        \n        untamed = PCA(n_components=100)\n\n        \n        untamed.fit(X_tra)\n        ev_ratio = untamed.explained_variance_ratio_\n        print(\"sum = \",sum(ev_ratio))\n\n        X_tra = untamed.transform(X_tra)\n        X_eval = untamed.transform(X_eval)\n        \n    y_pred = XGBReg(X_tra,y_tra,X_eval,y_eval)\n    \n    #clf = linear_model.LassoCV()\n    #result = clf.fit(X_tra,y_tra)\n    #y_pred = clf.predict(X_eval)\n    \n    plt.scatter(y_eval, y_pred)\n    print(y_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"こっから提出用"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = xgb.XGBRegressor(max_depth = 4, n_estimators = 100)\nSTANDARD=False\n\nif STANDARD==True:\n    scaler = StandardScaler()\n    scaler.fit(x_data)\n    x_data = scaler.transform(x_data)\n    last_test = scaler.transform(last_test)\n    untamed = PCA(n_components=100)\n    untamed.fit(x_data)\n    x_data = untamed.transform(x_data)\n    last_test = untamed.transform(last_test)\n\nreg.fit(x_data,y_data_1)\nprint(x_data.shape)\nprint(last_test.shape)\ny_pred_1 = reg.predict(last_test)\ny_pred_1 = y_pred_1.reshape([13459,1])\ncl = pd.DataFrame(y_pred_1)\ncl.columns = [\"Fatalities\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pre = test_pre.reset_index()\nSTANDARD==True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_pl = pd.concat([test_pre,cl],axis=1)\n\ndata_pl = data_pl.drop(columns=[\"index\"])\nadd_data_last = data_pl.values\nadd_data_last.shape\n\nif STANDARD==True:\n    scaler = StandardScaler()\n    scaler.fit(x_data_2)\n    x_data_2 = scaler.transform(x_data_2)\n    add_data_last = scaler.transform(add_data_last)\n    untamed = PCA(n_components=100)\n    untamed.fit(x_data_2)\n    x_data_2 = untamed.transform(x_data_2)\n    add_data_last = untamed.transform(add_data_last)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = xgb.XGBRegressor(max_depth = 4, n_estimators = 100)\nreg.fit(x_data_2,y_data_2)\ny_pred_2 = reg.predict(add_data_last)\ny_pred_2 = y_pred_2.reshape([13459,1])\ncler = pd.DataFrame(y_pred_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.hstack([y_pred_2,y_pred_1])\nresult.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_csv = pd.DataFrame(result)\nresult_csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[\"ForecastId\"]\n#result_csv\ndf_end = pd.concat([df_test[\"ForecastId\"], result_csv],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_end.columns = ['ForecastId', 'ConfirmedCases', 'Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_end.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}