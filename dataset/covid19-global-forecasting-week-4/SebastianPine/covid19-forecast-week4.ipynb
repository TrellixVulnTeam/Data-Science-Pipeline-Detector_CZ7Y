{"cells":[{"metadata":{},"cell_type":"markdown","source":"- Characterize which countries are about to reach (country_p0) or already reached the maximum number of infections per day (country_p1).\n- Find the day and maximum of country_p1.\n- Predict day and maximum of country_p0.\n- Predict development for country_0\n- Predict development for country_1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras.backend as keb\nfrom scipy.optimize import curve_fit\nfrom datetime import datetime as dtime\nfrom datetime import timedelta\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading data\npath = \"../input/covid19-global-forecasting-week-4/\"\n#path = \"\"\ndata = pd.read_csv(path+\"train.csv\")\ndata= data.drop(\"Id\", axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"isCountry\"] = data.Province_State.isna()\ndata.Province_State[data.Province_State.isna()] = \"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_non_countries = data[data.isCountry==False]\ndata_non_countries = data_non_countries[[\"Country_Region\", \"Date\",\"ConfirmedCases\", \"Fatalities\"]].groupby([\"Country_Region\", \"Date\"]).sum()\ndata_non_countries.reset_index(inplace=True)\ndata_non_countries[\"Province_State\"] = np.nan\ndata_non_countries = data_non_countries[[\"Province_State\", \"Country_Region\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]]\ndata_non_countries[\"isCountry\"] = True\n\ndata = pd.concat([data, data_non_countries])\ndata.reset_index(inplace=True)\ndata[\"Id\"] = data.index\ndata = data.drop(\"index\", axis=1)\ndata[\"Region\"]= data.Country_Region \ndata[\"Region\"][~data.isCountry]= data.Country_Region + \"-\" + data.Province_State\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_rows = data.shape[0]\nregisters_count_by_region = data[[\"Id\", \"Region\"]].groupby(\"Region\").count()\nregisters_count_by_region.columns = [\"Count\"]\nregisters_count_by_region.reset_index(inplace=True)#\ndays = np.unique(data.Date)\nn_days = len(days)\nregions = np.unique(data.Region)\n\n#new confirmed column\ndata[\"Id_by_Region\"] = data[[\"Region\", \"Id\"]].groupby(\"Region\").cumcount()\ndata[\"PreviousConfirmed\"] = data[\"ConfirmedCases\"].shift()\ndata.loc[ data.Id_by_Region==0, \"PreviousConfirmed\"] = 0\ndata[\"NewConfirmed\"]= data.ConfirmedCases - data.PreviousConfirmed\n\n#new fatalities column\ndata[\"Id_by_Region\"] = data[[\"Region\", \"Id\"]].groupby(\"Region\").cumcount()\ndata[\"PreviousFatalities\"] = data[\"Fatalities\"].shift()\ndata.loc[ data.Id_by_Region==0,\"PreviousFatalities\"] = 0\ndata[\"NewFatalities\"]= data.Fatalities - data.PreviousFatalities\n\ndata[\"FirstConfirmed\"] = data.apply(lambda x: x[\"ConfirmedCases\"]>0, axis=1)\ndata[\"FirstFatality\"] = data.apply(lambda x: x[\"Fatalities\"]>0, axis=1)\ndata[\"DayFromFirstConfirmed\"] = data[[\"FirstConfirmed\", \"Region\"]].groupby(\"Region\").cumsum()\ndata[\"DayFromFirstFatality\"] = data[[\"FirstFatality\", \"Region\"]].groupby(\"Region\").cumsum()\n\ndata[\"TenConfirmed\"] = data.apply(lambda x: x[\"ConfirmedCases\"]>10, axis=1)\ndata[\"TenFatality\"] = data.apply(lambda x: x[\"Fatalities\"]>10, axis=1)\ndata[\"DayFromTenConfirmed\"] = data[[\"TenConfirmed\", \"Region\"]].groupby(\"Region\").cumsum()\ndata[\"DayFromTenFatality\"] = data[[\"TenFatality\", \"Region\"]].groupby(\"Region\").cumsum()\n\ndata[\"LogNewConfirmed\"] = np.log(data[\"NewConfirmed\"]+1) \ndata[\"LogNewFatalities\"] = np.log(data[\"NewFatalities\"]+1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Days:\", days)\nprint(\"No. regions:\", len(regions))\nprint(\"Regions:\", regions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 5\ndata [\"NewConfirmedSmoothed\"] = np.convolve(data.NewConfirmed, np.ones((N,))/N, mode='same')\ndata [\"NewFatalitiesSmoothed\"] = np.convolve(data.NewFatalities, np.ones((N,))/N, mode='same')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data [\"NewConfirmedSmoothed\"] = 0\ndata [\"NewFatalitiesSmoothed\"] = 0\n\nfor region in regions:\n    data [\"NewConfirmedSmoothed\"][data.Region==region] = np.convolve(data[data.Region==region].NewConfirmed, np.ones((N,))/N, mode='same')\n    data [\"NewFatalitiesSmoothed\"][data.Region==region] = np.convolve(data[data.Region==region].NewFatalities, np.ones((N,))/N, mode='same')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_countries = [\"Spain\", \"Italy\", \"Germany\", \"Singapore\", 'Korea, South']\n\nfig, ax = plt.subplots(len(selected_countries),2, figsize=(15,10))\n\nfor i, country in enumerate(selected_countries):\n    \n    confirmed_country = data[data.Region==country].NewConfirmed\n    confirmed_country_smoothed = data[data.Region==country].NewConfirmedSmoothed\n    ax[i][0].plot(days, confirmed_country)\n    ax[i][0].plot(days, confirmed_country_smoothed)\n    ax[i][0].set_xticks(np.arange(0, n_days,20 ))\n\n    ax[i][0].set_title(\"Confirmed cases\")\n    ax[i][0].grid()\n\nfor i, country in enumerate(selected_countries):\n    \n    fatalities_country = data[data.Region==country].NewFatalities\n    fatalities_country_smoothed = data[data.Region==country].NewFatalitiesSmoothed\n    ax[i][1].plot(days, fatalities_country)\n    ax[i][1].plot(days, fatalities_country_smoothed)\n    ax[i][1].set_xticks(np.arange(0, n_days,20 ))\n    \n    ax[i][1].set_title(\"Fatalities\")\n    ax[i][1].grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_confirmed = data[[\"Region\", \"NewConfirmed\"]].groupby(\"Region\").max()\nmax_confirmed.reset_index(inplace=True)\nmax_confirmed.columns = [\"Region\", \"MaxConfirmed\"]\n\nday_max_confirmed = data[[\"Region\", \"NewConfirmed\"]].groupby(\"Region\").idxmax()\nday_max_confirmed2 = data[[\"DayFromTenConfirmed\"]].iloc[day_max_confirmed.NewConfirmed]\n\nday_max_confirmed.NewConfirmed = np.array(day_max_confirmed2.DayFromTenConfirmed)\nday_max_confirmed.reset_index(inplace=True)\nday_max_confirmed.columns = [\"Region\", \"DayMaxConfirmed\"]\n\ncurrent_day_count = data[[\"Region\", \"DayFromTenConfirmed\"]].groupby(\"Region\").max()\ncurrent_day_count .reset_index(inplace=True)\ncurrent_day_count.columns = [\"Region\", \"CurrentDayCount\"]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged = max_confirmed.merge(day_max_confirmed, on = \"Region\").merge(current_day_count, on = \"Region\")\ndata_merged.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_fatalities = data[[\"Region\", \"NewFatalities\"]].groupby(\"Region\").max()#smoothed?\nmax_fatalities.reset_index(inplace=True)\nmax_fatalities.columns = [\"Region\", \"MaxFatalities\"]\n\nday_max_fatalities = data[[\"Region\", \"NewFatalities\"]].groupby(\"Region\").idxmax()#smoothed\nday_max_fatalities2 = data[[\"DayFromTenFatality\"]].iloc[day_max_fatalities.NewFatalities]#smoothed\n\nday_max_fatalities.NewFatalities = np.array(day_max_fatalities2.DayFromTenFatality)\nday_max_fatalities.reset_index(inplace=True)\nday_max_fatalities.columns = [\"Region\", \"DayMaxFatalities\"]\n\ndata_merged = data_merged.merge(max_fatalities, on=\"Region\").merge(day_max_fatalities, on = \"Region\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged[\"LastConfirmed\"] = 0\ndata_merged[\"LastFatalities\"] = 0\ndata_merged[\"LastLastConfirmed\"] = 0\ndata_merged[\"LastLastFatalities\"] = 0\n\nfor region in data_merged.Region:\n    data_merged[\"LastConfirmed\"][data_merged.Region==region] = data[data.Region==region][\"NewConfirmed\"].iloc[-1]\n    data_merged[\"LastFatalities\"][data_merged.Region==region] = data[data.Region==region][\"NewFatalities\"].iloc[-1]\n    data_merged[\"LastLastConfirmed\"][data_merged.Region==region] = data[data.Region==region][\"NewConfirmed\"].iloc[-2]\n    data_merged[\"LastLastFatalities\"][data_merged.Region==region] = data[data.Region==region][\"NewFatalities\"].iloc[-2]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = []\nfor threshold in range(20):\n    \n    country_type = data_merged[[\"DayMaxConfirmed\", \"CurrentDayCount\"]].apply(lambda x: (x[1]-x[0])>threshold, 1)\n    count.append(np.sum(country_type))\n    \nplt.plot(range(20), count)\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged[\"CountryType\"] = data_merged[[\"DayMaxConfirmed\", \"CurrentDayCount\"]].apply(lambda x: int((x[1]-x[0])>7), 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(data_merged[data_merged.CountryType == 1].Region)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color = [\"red\", \"green\"]\ncolor_assigned = [color[i] for i in data_merged.CountryType]\nplt.scatter(data_merged.DayMaxConfirmed, np.log(data_merged.MaxConfirmed), c=color_assigned)\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight: there is a strong linear relationship between the maximum number of infected per day and the day when it occurs. It is unterstandable, countries which good measures reach the maximum earlier and this number is relative lower."},{"metadata":{},"cell_type":"markdown","source":"# Computing desaccelerating rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_data = data[data.Region==\"Germany\"][data.TenConfirmed==True]\nday_max_confirmed = int(data_merged[data_merged.Region==\"Germany\"].DayMaxConfirmed)\nmax_confirmed = int(data_merged[data_merged.Region==\"Germany\"].MaxConfirmed)\nplt.plot(temp_data.DayFromTenConfirmed,temp_data.NewConfirmed)\nplt.axvline(x=day_max_confirmed, c=\"red\")\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.optimize import curve_fit\n\ndef linear(x, a):\n    \n    return a*x\n\npos_data = temp_data[temp_data.DayFromTenConfirmed>int(day_max_confirmed)].NewConfirmed\nx_data = np.arange(pos_data.shape[0])\nlog_data = np.log(pos_data)-np.log(max_confirmed)\n\npopt, pcov = curve_fit(linear, x_data, log_data)\npred = linear(x_data, *popt)\nplt.plot(x_data, np.exp(log_data+np.log(max_confirmed)))\nplt.plot(x_data, np.exp(pred+np.log(max_confirmed)))\nplt.grid()\nprint(\"Desacelerating rate:\", popt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged[\"DesacceleratingRateConfirmed\"] = 0.0\ndata_merged[\"DesacceleratingRateFatalities\"] = 0.0\n\nfor region in regions:\n    \n    temp_data = data[data.Region==region][data.TenConfirmed==True]\n    \n    if(temp_data.shape[0]>0):\n        \n        temp_data_merged = data_merged[data_merged.Region==region]\n\n        country_type = int(temp_data_merged.CountryType)\n        \n        if(country_type==1):\n            \n\n            day_max_confirmed = int(temp_data_merged.DayMaxConfirmed)\n            max_confirmed = int(temp_data_merged.MaxConfirmed)\n            day_max_fatalities = int(temp_data_merged.DayMaxFatalities)\n            max_fatalities = int(temp_data_merged.MaxFatalities)\n            isCountry = temp_data.isCountry.iloc[0]\n            \n            pos_data = temp_data[temp_data.DayFromTenConfirmed>int(day_max_confirmed)].NewConfirmed\n            x_data = np.arange(pos_data.shape[0])\n            log_data = np.log(pos_data.clip(0)+1)-np.log(max_confirmed+1)\n            popt, pcov = curve_fit(linear, x_data, log_data)        \n            data_merged.loc[data_merged.Region==region, \"DesacceleratingRateConfirmed\"]= popt[0]\n            \n            pos_data = temp_data[temp_data.DayFromTenConfirmed>int(day_max_fatalities)].NewFatalities\n            x_data = np.arange(pos_data.shape[0])\n            log_data = np.log(pos_data.clip(0)+1)-np.log(max_fatalities+1)\n            popt, pcov = curve_fit(linear, x_data, log_data)        \n            data_merged.loc[data_merged.Region==region, \"DesacceleratingRateFatalities\"]= popt[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding demographic data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#obtain the country name\npath2 = \"../input/demographic/\"\ncountry_region = data[[\"Region\", \"Country_Region\", \"isCountry\"]].drop_duplicates()\ndata_merged = data_merged.merge(country_region, on=\"Region\", how=\"left\")\ndata_merged.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gini = pd.read_csv(path2+\"gini.csv\")\ngini_2019 = gini[[\"country\",\"2019\"]]\ngini_2019.columns = [\"Country_Region\", \"Gini\"]\ngini_2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population = pd.read_csv(path2+\"population_total.csv\")\npopulation_2019 = population[[\"country\", \"2019\"]]\npopulation_2019.columns = [\"Country_Region\", \"Population\"]\npopulation_2019.Population = population_2019.Population/1000000\npopulation_2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health_system = pd.read_csv(path2+\"government_health_spending_of_total_gov_spending_percent.csv\")\nhealth_system_2010 = health_system [[\"country\", \"2010\"]]\nhealth_system_2010.columns = [\"Country_Region\", \"HealthSystem\"]\nhealth_system_2010.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gdp = pd.read_csv(path2+\"gdp_total_yearly_growth.csv\")\ngdp_2013 = gdp[[\"country\", \"2013\"]]\ngdp_2013.columns = [\"Country_Region\", \"GDP\"]\ngdp_2013.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"life_expectancy = pd.read_csv(path2+\"life_expectancy_years.csv\")\nlife_expectancy_2019 = life_expectancy[[\"country\", \"2019\"]]\nlife_expectancy_2019.columns = [\"Country_Region\", \"LifeExpectancy\"]\nlife_expectancy_2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smokers = pd.read_csv(path2+\"smoking_adults_percent_of_population_over_age_15.csv\")\nsmokers_2005 = smokers[[\"country\", \"2005\"]]\nsmokers_2005.columns = [\"Country_Region\", \"Smokers\"]\nsmokers_2005.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"demographic_data = gini_2019.merge(population_2019, on=\"Country_Region\", how=\"outer\")\ndemographic_data = demographic_data.merge(health_system_2010, on=\"Country_Region\", how=\"outer\")\ndemographic_data = demographic_data.merge(gdp_2013, on = \"Country_Region\", how=\"outer\")\ndemographic_data = demographic_data.merge(life_expectancy_2019, on = \"Country_Region\", how=\"outer\")\ndemographic_data = demographic_data.merge(smokers_2005, on = \"Country_Region\", how=\"outer\")\ndemographic_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_names_dict ={\"Congo, Dem. Rep.\": \"Congo (Kinshasa)\",\n                     \"Congo, Rep.\": \"Congo (Brazzaville)\",\n                     \"Czech Republic\": \"Czechia\",\n                     \"Kyrgyz Republic\": \"Kyrgyzstan\",\n                     \"South Korea\": \"Korea, South\",\n                     \"Lao\": \"Laos\",\n                     \"St. Kitts and Nevis\":\"Saint Kitts and Nevis\",\n                     \"St. Lucia\":\"Saint Lucia\",\n                     \"St. Vincent and the Grenadines\": \"Saint Vincent and the Grenadines\",\n                     \"Slovak Republic\": \"Slovakia\",\n                     \"United States\": \"US\"}\ndemographic_data[\"Country_Region\"] = demographic_data[\"Country_Region\"].replace(country_names_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged2 = data_merged.merge(demographic_data, on=\"Country_Region\", how=\"outer\")\ndata_merged2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(data_merged2[np.isnan(data_merged2.MaxConfirmed) | np.isnan(data_merged2.Gini)].Country_Region)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged3 = data_merged2[~np.isnan(data_merged2.MaxConfirmed)]\ndata_merged3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputing demographic variables\nfrom sklearn.impute import SimpleImputer\n\nfeatures = [\"CurrentDayCount\", \"Gini\", \"Population\", \"HealthSystem\", \"GDP\", \"LifeExpectancy\", \"Smokers\", \"LastConfirmed\", \"LastFatalities\", \"LastLastConfirmed\", \"LastLastFatalities\"]\ntargets = [\"MaxConfirmed\", \"DayMaxConfirmed\", \"MaxFatalities\", \"DayMaxFatalities\", \"DesacceleratingRateConfirmed\", \"DesacceleratingRateFatalities\"]\nX = data_merged3[features][data_merged3.isCountry][data_merged3.CountryType==1]\ny = data_merged3[targets][data_merged3.isCountry][data_merged3.CountryType==1]\n\nimputer = SimpleImputer(missing_values=np.nan,  strategy=\"mean\")\nX_imputed = imputer.fit_transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_imputed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ny = np.array(y)\ny[:,0] = np.log(y[:,0]+1)\ny[:,2] = np.log(y[:,2]+1)\n\n\nX_train, X_test, y_train, y_test = train_test_split( X_imputed, y, test_size=0.33, random_state=42)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_regression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\nrgr_list = []\nfor i in range(len(targets)):\n    rgr = RandomForestRegressor(max_depth=4, random_state=0)\n    rgr.fit(X_train_scaled, y_train[:,i])\n    rgr_list.append(rgr)\n    \n    pred_train = rgr.predict(X_train_scaled)\n    pred = rgr.predict(X_test_scaled)\n    score = mean_squared_error(pred, y_test[:,i])\n    print(\"Score for \"+targets[i]+\" :\", score)\n    \n    fig = plt.figure()\n    plt.scatter(pred, y_test[:,i])\n    plt.grid()\n    plt.title(targets[i])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled = scaler.fit_transform(X_imputed)\n\nrgr_list = []\nfor i in range(len(targets)):\n    rgr = RandomForestRegressor(max_depth=3, random_state=0)\n    rgr.fit(X_scaled, y[:,i])\n    rgr_list.append(rgr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_merged3[features][data_merged3.isCountry]\nX_imputed = imputer.transform(X)\nX_scaled = scaler.transform(X_imputed)\n\npred= []\nfor i in range(len(targets)):\n    \n    pred.append(rgr_list[i].predict(X_scaled))\n    \npred = np.array(pred).T\npred[:,0] = np.exp(pred[:,0]).astype(int)\npred[:,1] = pred[:,1].astype(int)\npred[:,2] = np.exp(pred[:,2]).astype(int)\npred[:,3] = pred[:,3].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame(pred)\npred_df.columns = [\"Pred\"+target for target in targets]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_pred = data_merged3[data_merged3.isCountry]\ndata_pred.reset_index(inplace=True)\ndata_pred= data_pred.assign(**pred_df)\ndata_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_pred[\"PredMaxConfirmed\"] = data_pred[[\"PredMaxConfirmed\", \"MaxConfirmed\"]].apply(lambda x: np.max((x[0], x[1])),1)\ndata_pred[\"PredMaxFatalities\"] = data_pred[[\"PredMaxFatalities\", \"MaxFatalities\"]].apply(lambda x: max(x[0], x[1]),1)\ndata_pred[\"PredDayMaxConfirmed\"] = data_pred[[\"PredDayMaxConfirmed\", \"DayMaxConfirmed\"]].apply(lambda x: max(x[0], x[1]),1)\ndata_pred[\"PredDayMaxFatalities\"] = data_pred[[\"PredDayMaxFatalities\", \"DayMaxFatalities\"]].apply(lambda x: max(x[0], x[1]),1)\n\n\ndata_pred[\"PredMaxConfirmed\"] = data_pred[[\"PredMaxConfirmed\", \"MaxConfirmed\", \"CountryType\"]].apply(lambda x: x[1] if x[2]==1 else x[0],1)\ndata_pred[\"PredMaxFatalities\"] = data_pred[[\"PredMaxFatalities\", \"MaxFatalities\", \"CountryType\"]].apply(lambda x: x[1] if x[2]==1 else x[0],1)\ndata_pred[\"PredDayMaxConfirmed\"] = data_pred[[\"PredDayMaxConfirmed\", \"DayMaxConfirmed\", \"CountryType\"]].apply(lambda x: x[1] if x[2]==1 else x[0],1)\ndata_pred[\"PredDayMaxFatalities\"] = data_pred[[\"PredDayMaxFatalities\", \"DayMaxFatalities\", \"CountryType\"]].apply(lambda x: x[1] if x[2]==1 else x[0],1)\ndata_pred[\"PredDesacceleratingRateConfirmed\"] = data_pred[[\"PredDesacceleratingRateConfirmed\", \"DesacceleratingRateConfirmed\", \"CountryType\"]].apply(lambda x: x[1] if x[2]==1 else x[0],1)\ndata_pred[\"PredDesacceleratingRateFatalities\"] = data_pred[[\"PredDesacceleratingRateFatalities\", \"DesacceleratingRateFatalities\", \"CountryType\"]].apply(lambda x: x[1] if x[2]==1 else x[0],1)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis for non-countries\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_countries = data[data.isCountry==False][[\"Country_Region\", \"ConfirmedCases\"]].groupby([\"Country_Region\"]).max()\ndata_non_countries = data[data.isCountry==False][[\"Province_State\", \"Country_Region\", \"ConfirmedCases\"]].groupby([\"Province_State\", \"Country_Region\"]).max()\ndata_non_countries.reset_index(inplace=True)\ndata_non_countries = data_non_countries.merge(data_countries, on=\"Country_Region\", how=\"left\")\ndata_non_countries[\"RegionFraction\"] = data_non_countries[[\"ConfirmedCases_x\", \"ConfirmedCases_y\"]].apply(lambda x: x[0]/x[1], axis=1)\ndata_non_countries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forecasting for countries\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred_type1 (max_value, desaccelerating_rate, time_horizon):\n    \n    x = np.arange(time_horizon)\n    pred = np.exp(x*desaccelerating_rate+np.log(max_value+1))\n    return pred\n\n\ndef pred_type0 (current_day, day_max_value, current_value, max_value, time_horizon):\n    \n    x = np.arange(current_day, current_day+time_horizon)\n    x0, x1, y0, y1 = current_day, day_max_value, current_value, max_value\n    \n    a = (1/(x1-x0))*(np.log(y1+1)-np.log(y0+1))\n    b = (1/(x1-x0))*(-x0*np.log(y1+1)+x1*np.log(y0+1))\n\n    pred = np.exp(a*x+b)\n    return pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(path+\"test.csv\")\ntest_data.head()\n\ntest_data[\"isCountry\"] = test_data.Province_State.isna()\ntest_data.Province_State[test_data.Province_State.isna()] = \"\"\ntest_data[\"Region\"]= test_data.Country_Region \ntest_data[\"Region\"][~test_data.isCountry]= test_data.Country_Region + \"-\" + test_data.Province_State\n\nnumber_of_rows = test_data.shape[0]\nregisters_count_by_region_test = test_data[[\"ForecastId\", \"Region\"]].groupby(\"Region\").count()\nregisters_count_by_region_test.columns = [\"Count\"]\nregisters_count_by_region_test.reset_index(inplace=True)#\ndays_test = np.unique(test_data.Date)\nn_days_test = len(days_test)\n\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(data_merged.Region)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_to_predict = [dtime.strftime(dtime.strptime(days[-1],  \"%Y-%m-%d\")+timedelta(i), \"%Y-%m-%d\") for i in range(1,34)]\nn_days_to_predict = len(days_to_predict)\nconcat_df = pd.DataFrame()\nprint(days_to_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concat_df = pd.DataFrame()\n\nfor i, region in enumerate(regions):\n    data_region = data[data.Region == region]\n    data_merged_region = data_merged[data_merged.Region == region]\n    data_pred_region = data_pred[data_pred.Region==region]\n    isCountry = int(data_region.isCountry.iloc[-1])\n    \n    temp_df = pd.DataFrame({\"Date\":days_to_predict, \"Country_Region\": [data_region.Country_Region.iloc[0]]*n_days_to_predict, \n                            \"Province_State\": [data_region.Province_State.iloc[0]]*n_days_to_predict,\n                            \"isCountry\": [data_region.isCountry.iloc[0]]*n_days_to_predict})\n      \n    \n    if(isCountry==0):\n\n        province = data_region.Province_State.iloc[-1]\n        temp_data_non_country = data_non_countries[data_non_countries.Province_State==province]\n        country = data_region.Country_Region.iloc[-1]\n        data_region = data[data.Region==country]\n        data_pred_region = data_pred[data_pred.Region==country]\n        data_merged_region = data_merged[data_merged.Region == country]\n\n\n    current_day = int(data_merged_region[\"CurrentDayCount\"])\n    day_max_confirmed = int(data_pred_region[\"PredDayMaxConfirmed\"])\n    day_max_fatalities = int(data_pred_region[\"PredDayMaxFatalities\"])\n    max_confirmed = int(data_pred_region[\"PredMaxConfirmed\"])\n    max_fatalities = int(data_pred_region[\"PredMaxFatalities\"])\n    des_confirmed = float(data_pred_region[\"PredDesacceleratingRateConfirmed\"])\n    des_fatalities = float(data_pred_region[\"PredDesacceleratingRateFatalities\"])\n    current_new_confirmed = int(data_region.NewConfirmed.iloc[-1])\n    current_new_fatalities = int(data_region.NewFatalities.iloc[-1])\n\n    current_confirmed = data_region.ConfirmedCases.iloc[-1]\n    current_fatalities = data_region.Fatalities.iloc[-1]\n\n    if(current_day < day_max_confirmed):\n        print(region)\n\n        pred_0_confirmed = pred_type0 (current_day, day_max_confirmed, current_new_confirmed, max_confirmed, day_max_confirmed-current_day)            \n        pred_1_confirmed = pred_type1 (current_new_confirmed+1, des_confirmed, n_days_to_predict-day_max_confirmed+current_day)            \n        predicted_confirmed = list(pred_0_confirmed) + list(pred_1_confirmed)\n\n    else:\n\n        pred_1_confirmed = pred_type1 (current_new_confirmed+1, des_confirmed, n_days_to_predict)                  \n        predicted_confirmed = pred_1_confirmed\n\n    if(current_day< day_max_fatalities):\n        pred_0_fatalities = pred_type0 (current_day, day_max_fatalities, current_new_fatalities, max_fatalities, day_max_fatalities-current_day)                   \n        pred_1_fatalities = pred_type1 (current_new_fatalities+1, des_fatalities, n_days_to_predict-day_max_fatalities+current_day)            \n        predicted_fatalities = list(pred_0_fatalities) + list(pred_1_fatalities)        \n\n    else:\n        pred_1_fatalities = pred_type1 (current_new_fatalities+1, des_fatalities, n_days_to_predict)            \n        predicted_fatalities = pred_1_fatalities   \n        \n    if(isCountry==0):\n        fraction = float(temp_data_non_country.RegionFraction)\n        predicted_confirmed = predicted_confirmed*fraction\n        predicted_fatalities = predicted_fatalities*fraction\n        \n    predicted_confirmed[0] = predicted_confirmed[0] + current_confirmed\n    predicted_confirmed = np.cumsum(predicted_confirmed)\n\n    predicted_fatalities[0] = predicted_fatalities[0] + current_fatalities\n    predicted_fatalities = np.cumsum(predicted_fatalities)\n        \n    temp_df[\"Region\"]= temp_df.Country_Region \n    temp_df[\"Region\"][~temp_df.isCountry] = temp_df.Country_Region + \"-\" + temp_df.Province_State\n    \n    \n    \n    temp_df[\"ConfirmedCases\"] = predicted_confirmed\n    temp_df[\"Fatalities\"] = predicted_fatalities\n    concat_df = pd.concat([concat_df, temp_df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"current_data = data[[\"Date\", \"Country_Region\", \"Province_State\", \"ConfirmedCases\", \"Fatalities\", \"Region\"]]\ncurrent_data.Province_State[current_data.Province_State.isna()] = \"\"\ncurrent_data = current_data.groupby([\"Date\", \"Country_Region\", \"Province_State\", \"Region\"]).max()\nsubmission1 = test_data.merge(current_data, on=[\"Region\", \"Date\"] ,  how='left')\nsubmission2 = submission1.merge(concat_df, on= [\"Region\", \"Date\"], how=\"left\")\nsubmission2[\"ConfirmedCases\"] = submission2[[\"ConfirmedCases_x\", \"ConfirmedCases_y\"]].apply(lambda x: x[0] if ~np.isnan(x[0]) else x[1], axis=1)\nsubmission2[\"Fatalities\"] = submission2[[\"Fatalities_x\", \"Fatalities_y\"]].apply(lambda x: x[0] if ~np.isnan(x[0]) else x[1], axis=1)\nsubmission_data = pd.read_csv(path+\"submission.csv\")#\nsubmission3 = submission_data[[\"ForecastId\"]].merge(submission2[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\" ]], on= \"ForecastId\", how=\"left\")\n\nsubmission3 = submission3.astype(\"int32\")\nsubmission3.reset_index(inplace=True)\nsubmission3 = submission3.drop([\"index\"], axis=1)\nsubmission3.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":4}