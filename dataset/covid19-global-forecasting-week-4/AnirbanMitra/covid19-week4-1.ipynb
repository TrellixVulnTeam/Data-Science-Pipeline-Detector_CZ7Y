{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Author: Anirban Mitra(amitra@cs.iitr.ac.in)\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport datetime\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\nsubmission_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/submission.csv')\ntrain_df = train_df.drop(['Id'],axis=1)\ntrain_df.rename(columns={'Country_Region':'Country'}, inplace=True)\ntest_df.rename(columns={'Country_Region':'Country'}, inplace=True)\ntrain_df['Province_State'].fillna(\"None*\", inplace = True)\ntest_df['Province_State'].fillna(\"None*\", inplace = True)\nrenameCountryNames = {\n    \"Congo (Brazzaville)\": \"Congo1\",\n    \"Congo (Kinshasa)\": \"Congo2\",\n    \"Cote d'Ivoire\": \"CÃ´te d'Ivoire\",\n    \"Czechia\": \"Czech Republic (Czechia)\",\n    \"Korea, South\": \"South Korea\",\n    \"Saint Kitts and Nevis\": \"Saint Kitts & Nevis\",\n    \"Saint Vincent and the Grenadines\": \"St. Vincent & Grenadines\",\n    \"Taiwan*\": \"Taiwan\",\n    \"US\": \"United States\"\n}\n#train_df_modified.replace({'Country': renameCountryNames}, inplace=True)\ntrain_df.replace({'Country': renameCountryNames}, inplace=True)\ntest_df.replace({'Country': renameCountryNames}, inplace=True)\nspecific_countries = ['United States', 'United Kingdom','Netherlands']\ndays_df = train_df['Date'].apply(lambda dt: datetime.datetime.strptime(dt, '%Y-%m-%d') - datetime.datetime.strptime('2020-01-21', '%Y-%m-%d')).apply(lambda x : str(x).split()[0]).astype(int)\ntrain_df['Days'] = days_df\ndays_df = test_df['Date'].apply(lambda dt: datetime.datetime.strptime(dt, '%Y-%m-%d') - datetime.datetime.strptime('2020-01-21', '%Y-%m-%d')).apply(lambda x : str(x).split()[0]).astype(int)\ntest_df['Days'] = days_df\n\nall_countries = train_df['Country'].unique()\n\ndisplay(train_df.tail())\ndisplay(test_df.head())\n\nww_df = train_df.groupby('Date')[['ConfirmedCases', 'Fatalities']].sum().reset_index()\nww_df['new_case'] = ww_df['ConfirmedCases'] - ww_df['ConfirmedCases'].shift(1)\nww_df['new_deaths'] = ww_df['Fatalities'] - ww_df['Fatalities'].shift(1)\ncountry_df = train_df.groupby(['Date', 'Country'])[['ConfirmedCases', 'Fatalities']].sum().reset_index()\ntarget_date = country_df['Date'].max()\ntrain_end_day = train_df['Days'].max()\ntest_start_day = test_df['Days'].min()\ntest_end_day = test_df['Days'].max()\ndisplay(country_df[country_df['Country']=='France'][80:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"py.init_notebook_mode()\ntop_country_df = country_df.query('(Date == @target_date) & (ConfirmedCases > 2000)').sort_values('ConfirmedCases', ascending=False)\nprint(len(top_country_df))\ntop_country_melt_df = pd.melt(top_country_df, id_vars='Country', value_vars=['ConfirmedCases', 'Fatalities'])\ndisplay(top_country_df.head())\ndisplay(top_country_melt_df.head())\nfig = px.bar(top_country_melt_df.iloc[::-1],\n             x='value', y='Country', color='variable', barmode='group',\n             title=f'Confirmed Cases/Deaths on {target_date}', text='value', height=1500, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_province_df = train_df[train_df['Country']=='United States'].groupby(['Date', 'Province_State'])[['ConfirmedCases', 'Fatalities']].sum().reset_index()\n\ntop_province_df = country_province_df.query('(Date == @target_date)').sort_values('ConfirmedCases', ascending=False)\ntop30_provinces = top_province_df.sort_values('ConfirmedCases', ascending=False).iloc[:30]['Province_State'].unique()\n\ncountry_province_df['prev_cases'] = country_province_df.groupby('Province_State')['ConfirmedCases'].shift(1)\ncountry_province_df['New Case'] = country_province_df['ConfirmedCases'] - country_province_df['prev_cases']\ncountry_province_df['New Case'].fillna(0, inplace=True)\ncountry_province_df['prev_deaths'] = country_province_df.groupby('Province_State')['Fatalities'].shift(1)\ncountry_province_df['New Death'] = country_province_df['Fatalities'] - country_province_df['prev_deaths']\ncountry_province_df['New Death'].fillna(0, inplace=True)\n\ndisplay(country_province_df[-30:])\nfor province in top30_provinces:\n    present_country_df = country_province_df[country_province_df['Province_State']==province]\n    px.bar(present_country_df,\n              x='Date', y='New Case', color='Province_State',\n              title=f'United States : DAILY NEW Confirmed cases in '+province).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top30_countries = top_country_df.sort_values('ConfirmedCases', ascending=False).iloc[:30]['Country'].unique()\ndisplay(country_df[:20])\ncountry_df['prev_cases'] = country_df.groupby('Country')['ConfirmedCases'].shift(1)\ncountry_df['New Case'] = country_df['ConfirmedCases'] - country_df['prev_cases']\ncountry_df['New Case'].fillna(0, inplace=True)\ncountry_df['prev_deaths'] = country_df.groupby('Country')['Fatalities'].shift(1)\ncountry_df['New Death'] = country_df['Fatalities'] - country_df['prev_deaths']\ncountry_df['New Death'].fillna(0, inplace=True)\ntop30_country_df = country_df[country_df['Country'].isin(top30_countries)]\ndisplay(country_df[:10])\nfor country in top30_countries:\n    present_country_df = top30_country_df[top30_country_df['Country']==country]\n    px.bar(present_country_df,\n              x='Date', y='New Case', color='Country',\n              title=f'DAILY NEW Confirmed cases in '+country).show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, From the graphs above we can get a humane idea of which countries fall in which area of their hill\n\nCountries most definitively in their downhill / almost cured(unless second wave) : china, south korea\n\nCountries likely in their downhill: Australia, Austria,Iran, Italy,Spain,Germany,Switzerland,Norway\n\nCountries likely in their uphill: US*, UK, India,Turkey,Russia,Sweden,Chile,Poland,Peru\n\nBelgium*,Netherland*,Canada,Brazil,Portugal,Israel,Ireland,Equador,Denmark,Czechia,France\n\n['Austria', 'Belgium', 'Brazil', 'Chile', 'Ecuador', 'Germany', 'India', 'Iran', 'Ireland', 'Israel', 'Italy', 'Japan', 'South Korea', 'Norway', 'Peru', 'Poland', 'Portugal', 'Russia', 'Spain', 'Sweden', 'Switzerland', 'Turkey']\n\n['Australia', 'Canada', 'China', 'Denmark', 'France', 'Netherlands', 'United States', 'United Kingdom']\n\nCanada should hit a increase a bit in first test week\n\nDenmark would keep simiar increase rate for first test week\n\nFrance will likely stay similar growth for april\n\nNEtherlands US and UK needs to be looked into\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_time_series(df,country_name,insert=False):\n    # for some countries, data is spread over several Provinces\n    if df[df['Country'] == country_name]['Province_State'].nunique() > 1:\n        country_table = df[df['Country'] == country_name] \n        if insert:\n          country_df = pd.DataFrame(pd.pivot_table(country_table, values = ['ConfirmedCases','Fatalities','Days'],\n                               index='Date', aggfunc=sum).to_records())\n          return country_df.set_index('Date')[['ConfirmedCases','Fatalities']] \n        return country_table.set_index('Date')[['Province_State','ConfirmedCases','Fatalities','Days']]\n    df = df[(df['Country'] == country_name)]\n    return df.set_index('Date')[['ConfirmedCases','Fatalities','Days']]\n\n\ndef get_time_series_province(province):\n    # for some countries, data is spread over several Provinces\n    df = full_table[(full_table['Province_State'] == province)]\n    return df.set_index('Date')[['ConfirmedCases','Fatalities']]\n\nprovince_country_dfs = {}\nno_province_country_dfs = {}\nabsent_country_in_age_data_dfs = {}\n\nprovince_country_dfs_list=[]\nno_province_country_dfs_list=[]\nabsent_country_in_age_data_dfs_list=[]\n\nprovince_countries=train_df[train_df['Province_State']!=\"None*\"]['Country'].unique()\nno_province_countries=train_df[train_df['Province_State']==\"None*\"]['Country'].unique()\nno_province_countries= [x for x in no_province_countries if x not in province_countries] #exclude countries like denmark\n\n# print(province_countries)\n# print(no_province_countries)\n\nfor country  in province_countries:\n    province_country_dfs[country] = get_time_series(train_df,country)\nfor country  in no_province_countries:\n    no_province_country_dfs[country] = get_time_series(train_df,country)\n    \nprint([x for x in no_province_countries if x  in top30_countries])\nprint([x for x in province_countries if x  in top30_countries])\n\n\nassert(len([x for x in all_countries if x not in list(no_province_countries)+list(province_countries)])==0)\ndisplay(province_country_dfs['United States'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nfrom numpy import array\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Province_State'].fillna(\"None*\", inplace = True) \ntest_df['Province_State'].fillna(\"None*\", inplace = True) \ntest_df[\"ConfirmedCases\"] = np.nan\ntest_df[\"Fatalities\"] = np.nan\ntest_df = test_df.set_index('Date')\ndisplay(test_df)\nprediction={}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(n_steps):\n    model = Sequential()\n    model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, 1)))\n    model.add(LSTM(50, activation='relu'))\n    model.add(Dense(1))\n    model.compile(optimizer='RMSprop', loss='mse')\n    return model\n\ndef split_sequence(sequence, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequence)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the sequence\n\t\tif end_ix > len(sequence)-1:\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn array(X), array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_df[train_df['Country']=='Afghanistan'].tail())\nprint(province_countries)\nmax_train_date = train_df['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for country in province_countries:\n #if country in ['France','Denmark','United Kingdom']:\n #if country in ['United States']:\n    current_country_provinces = province_country_dfs[country]['Province_State'].unique()\n    for province in current_country_provinces:\n      #if province in ['New York','Rhode Island','Texas']:\n        current_considered_country_df = province_country_dfs[country][province_country_dfs[country]['Province_State']==province][['ConfirmedCases','Fatalities','Days']].reset_index()\n        print(country+\" \"+province)\n        current_considered_country_df_copy=current_considered_country_df\n        \n        for i in range(train_end_day-test_start_day+1):\n            test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==i+test_start_day), 'ConfirmedCases'] = current_considered_country_df.loc[current_considered_country_df['Days'] == i+test_start_day, 'ConfirmedCases'].values[0]\n            test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==i+test_start_day), 'Fatalities'] = current_considered_country_df.loc[current_considered_country_df['Days'] == i+test_start_day, 'Fatalities'].values[0]\n        \n        indexNames = current_considered_country_df[ current_considered_country_df['ConfirmedCases'] == 0 ].index\n        current_considered_country_df.drop(indexNames , inplace=True)\n        \n#         x_train_full= current_considered_country_df[['Days','Population','Density','Below14','15-64','Over65']].to_numpy()\n        cases_train = np.diff(current_considered_country_df['ConfirmedCases'].to_numpy())\n        fatalities_train = np.diff(current_considered_country_df['Fatalities'].to_numpy())\n        #there are many anomalies in data,like new cases per day are negative, which refers to previous incorrect reporting or wrongful data entry,\n        # nevertheless we need to consider this as is or trim down to zero\n        cases_train[cases_train<0] = 0\n        fatalities_train[fatalities_train<0] = 0\n        \n        fatal_rate = 0.0\n        if(current_considered_country_df['Fatalities'].to_numpy()[-1]>0):\n            fatal_rate = current_considered_country_df['Fatalities'].to_numpy()[-1]/current_considered_country_df['ConfirmedCases'].to_numpy()[-1]\n            print(\"fatal rate is: \"+str(fatal_rate))\n        \n        #get last 15 days increasing average\n        cases_increase_avg = 0\n        days=0\n        for i in range(len(cases_train)-1):\n            cases_increase_avg +=  (cases_train[i+1] -cases_train[i])\n            days+=1\n        if(days>0):\n            cases_increase_avg = int(cases_increase_avg/days)\n            \n        days=0\n        fatal_increase_avg=0\n        for i in range(len(fatalities_train)-1):\n            fatal_increase_avg +=  (fatalities_train[i+1] -fatalities_train[i])\n            days+=1\n        if(days>0):\n            fatal_increase_avg = int(fatal_increase_avg/days)\n        del current_considered_country_df\n        n_steps = max(int(len(cases_train)*0.1),3)\n#         print(\"case increase avg: \"+str(cases_increase_avg)+\" \"+ str(days))\n#         print(\"cases train len: \"+str(len(cases_train)))\n        \n        # get avg per day increase trend:\n        avg_weekly_per_day_case = []\n        avg_window = 4\n        avg_step = 2 \n        if int(len(cases_train)/avg_window) > avg_step:\n            for i in range(int(len(cases_train)/avg_window)):\n                    temp_list = cases_train[i*avg_window:i*avg_window+avg_window]\n                    avg_weekly_per_day_case.append(np.sum(temp_list)/len(temp_list))\n            avg_weekly_per_day_case = np.array(avg_weekly_per_day_case)\n            #print(\"window avg: \"+str(avg_weekly_per_day_case))\n            # predict weekly avg\n            X_weekly_avg_val, y_weekly_avg_val = split_sequence(avg_weekly_per_day_case,avg_step)\n            X_weekly_avg_val = np.reshape(X_weekly_avg_val, (X_weekly_avg_val.shape[0],X_weekly_avg_val.shape[1],1))  #####\n            model_weekly_avg=build_model(avg_step)\n            model_weekly_avg.fit(X_weekly_avg_val, y_weekly_avg_val, epochs=50, verbose=0)\n            new_entry_avg=X_weekly_avg_val[len(X_weekly_avg_val)-1]\n            for i in range(int(30/avg_window)+1):\n                weekly_avg_predict_next = model_weekly_avg.predict(np.reshape(new_entry_avg,(1,avg_step,1)), verbose=0).astype(int)\n                avg_weekly_per_day_case = np.append(avg_weekly_per_day_case,weekly_avg_predict_next[0])\n\n                last_series = np.reshape(new_entry_avg,(1,avg_step,1))\n                new_entry_avg=np.delete(last_series,[0])\n                new_entry_avg = np.insert(new_entry_avg,avg_step-1,weekly_avg_predict_next[0])\n            #print(\"7 weeks avg after predict: \"+str(avg_weekly_per_day_case))\n        \n        X_cases_val, y_cases_val = split_sequence(cases_train,n_steps)\n        X_cases_val = np.reshape(X_cases_val, (X_cases_val.shape[0],X_cases_val.shape[1],1))\n        \n        X_fatal_val, y_fatal_val = split_sequence(fatalities_train,n_steps)\n        X_fatal_val = np.reshape(X_fatal_val, (X_fatal_val.shape[0],X_fatal_val.shape[1],1))\n        \n        assert(len(X_fatal_val)==len(X_cases_val))\n        assert(len(y_fatal_val)==len(y_cases_val))\n        \n        model_cases=build_model(n_steps)\n        model_cases.fit(X_cases_val, y_cases_val, epochs=50, verbose=0)\n        cases_predict_next = model_cases.predict(np.reshape(X_cases_val[len(X_cases_val)-1],(1,n_steps,1)), verbose=0).astype(int)\n        cases_predict_next[0] =  np.array([max(0,cases_predict_next[0])])\n        \n        model_fatalities=build_model(n_steps)\n        model_fatalities.fit(X_fatal_val, y_fatal_val, epochs=50, verbose=0)\n        fatality_predict_next = model_fatalities.predict(np.reshape(X_fatal_val[len(X_fatal_val)-1],(1,n_steps,1)), verbose=0).astype(int)\n        fatality_predict_next[0] =  np.array([max(0,fatality_predict_next[0])])\n        fatality_predict_next[0] = np.array([max(fatality_predict_next[0],cases_predict_next[0]*fatal_rate)])\n        \n        test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==train_end_day+1), 'ConfirmedCases'] = test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==train_end_day), 'ConfirmedCases'].values[0] + cases_predict_next[0]\n        test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==train_end_day+1), 'Fatalities'] = test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==train_end_day), 'Fatalities'].values[0] + fatality_predict_next[0]\n            \n#         print(cases_predict_next[0])\n#         print(X_cases_val[len(X_cases_val)-1])\n        new_entry_cases=X_cases_val[len(X_cases_val)-1]\n        new_entry_fatal=X_fatal_val[len(X_fatal_val)-1]\n        \n        for i in range(test_end_day-train_end_day-1):\n            \n          # Cases\n          last_series = np.reshape(new_entry_cases,(1,n_steps,1))\n          new_entry_cases=np.delete(last_series,[0])\n          new_entry_cases = np.insert(new_entry_cases,n_steps-1,cases_predict_next[0])\n        \n          cases_predict_next = model_cases.predict(np.reshape(new_entry_cases,(1,n_steps,1)), verbose=0).astype(int)\n          if(cases_predict_next[0]-new_entry_cases[n_steps-1]>cases_increase_avg):\n            cases_predict_next =  np.array([max(0,new_entry_cases[n_steps-1]+cases_increase_avg)])\n          if (province in ['Kentucky','New Mexico','Sint Maarten','Cayman Islands','Isle of Man']):\n            cases_predict_next[0] = avg_weekly_per_day_case[-int(30/avg_window)-1+int(i/avg_window)]\n          cases_predict_next[0] =  np.array([max(0,cases_predict_next[0])])\n#           print(np.array(new_entry_cases))\n#           print(cases_predict_next[0])\n\n          # fatality\n          last_series = np.reshape(new_entry_fatal,(1,n_steps,1))\n          new_entry_fatal=np.delete(last_series,[0])\n          new_entry_fatal = np.insert(new_entry_fatal,n_steps-1,fatality_predict_next[0])\n        \n          fatality_predict_next = model_fatalities.predict(np.reshape(new_entry_fatal,(1,n_steps,1)), verbose=0).astype(int)\n          if(fatality_predict_next[0]-new_entry_fatal[n_steps-1]>fatal_increase_avg):\n            fatality_predict_next[0] =  max(0,new_entry_fatal[n_steps-1]+fatal_increase_avg)\n          fatality_predict_next[0] =  np.array([max(0,fatality_predict_next[0])])\n          fatality_predict_next[0] = np.array([max(fatality_predict_next[0],int(cases_predict_next[0]*fatal_rate))])\n        \n          test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==i+train_end_day+2), 'ConfirmedCases'] = test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==i+train_end_day+1), 'ConfirmedCases'].values[0] + cases_predict_next[0]\n          test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==i+train_end_day+2), 'Fatalities'] = test_df.loc[(test_df['Country']==country) & (test_df['Province_State']==province) & (test_df['Days']==i+train_end_day+1), 'Fatalities'].values[0] + fatality_predict_next[0]\n        del model_fatalities\n        del model_cases","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Follow new model: \nUS:kentucky,New Mexico\nNetherlands: Sint Maarten\nUK: Cayman Islands,Isle of Man, None*(its first bracket is over-inflated)\nDenmark:None*\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_province_df = test_df[test_df['Country']=='United States'].groupby(['Date', 'Province_State'])[['ConfirmedCases', 'Fatalities']].sum().reset_index()\n\ncountry_province_df['prev_cases'] = country_province_df.groupby('Province_State')['ConfirmedCases'].shift(1)\ncountry_province_df['New Case'] = country_province_df['ConfirmedCases'] - country_province_df['prev_cases']\ncountry_province_df['New Case'].fillna(0, inplace=True)\ncountry_province_df['prev_deaths'] = country_province_df.groupby('Province_State')['Fatalities'].shift(1)\ncountry_province_df['New Death'] = country_province_df['Fatalities'] - country_province_df['prev_deaths']\ncountry_province_df['New Death'].fillna(0, inplace=True)\n\ndisplay(country_province_df.head())\nfor province in top30_provinces:\n    present_country_df = country_province_df[country_province_df['Province_State']==province]\n    px.bar(present_country_df,\n              x='Date', y='New Case', color='Province_State',\n              title=f'United States : DAILY NEW Confirmed cases in '+province).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_country_df = test_df.groupby(['Date', 'Country'])[['ConfirmedCases', 'Fatalities']].sum().reset_index()\ndisplay(test_country_df[test_country_df['Country']=='Australia'][:20])\nfor country in [x for x in province_countries if x  in top30_countries]:\n    present_country_df = test_country_df[test_country_df['Country']==country].reset_index()\n    present_country_df['prev_cases'] = present_country_df.groupby('Country')['ConfirmedCases'].shift(1)\n    present_country_df['New Case'] = present_country_df['ConfirmedCases'] - present_country_df['prev_cases']\n    present_country_df['New Case'].fillna(0, inplace=True)\n    present_country_df['prev_deaths'] = present_country_df.groupby('Country')['Fatalities'].shift(1)\n    present_country_df['New Death'] = present_country_df['Fatalities'] - present_country_df['prev_deaths']\n    present_country_df['New Death'].fillna(0, inplace=True)\n    #display(present_country_df[:20])\n    px.bar(present_country_df,\n              x='Date', y='New Case', color='Country',\n              title=f'DAILY NEW Confirmed cases in '+country).show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for country in no_province_countries:\n  #if country in ['South Korea', 'Norway', 'Peru', 'Poland', 'Portugal', 'Russia', 'Spain', 'Sweden', 'Switzerland', 'Turkey']:\n    current_considered_country_df = no_province_country_dfs[country][['ConfirmedCases','Fatalities','Days']].reset_index()\n    print(country)\n    \n    for i in range(train_end_day-test_start_day+1):\n            test_df.loc[(test_df['Country']==country) & (test_df['Days']==i+test_start_day), 'ConfirmedCases'] = current_considered_country_df.loc[current_considered_country_df['Days'] == i+test_start_day, 'ConfirmedCases'].values[0]\n            test_df.loc[(test_df['Country']==country) & (test_df['Days']==i+test_start_day), 'Fatalities'] = current_considered_country_df.loc[current_considered_country_df['Days'] == i+test_start_day, 'Fatalities'].values[0]\n\n    indexNames = current_considered_country_df[ current_considered_country_df['ConfirmedCases'] == 0 ].index\n    current_considered_country_df.drop(indexNames , inplace=True)\n    \n    cases_train = np.diff(current_considered_country_df['ConfirmedCases'].to_numpy())\n    fatalities_train = np.diff(current_considered_country_df['Fatalities'].to_numpy())\n    fatal_rate = 0.0\n    if(current_considered_country_df['Fatalities'].to_numpy()[-1]>0):\n        fatal_rate = current_considered_country_df['Fatalities'].to_numpy()[-1]/current_considered_country_df['ConfirmedCases'].to_numpy()[-1]\n        print(\"fatal rate is: \"+str(fatal_rate))\n    \n    \n    #get previous days increasing average\n    cases_increase_avg = 0\n    days=0\n    for i in range(len(cases_train)-1):\n        cases_increase_avg +=  (cases_train[i+1] -cases_train[i])\n        days+=1\n    if(days>0):\n        cases_increase_avg = int(cases_increase_avg/days)\n    fatal_increase_avg = 0\n    days=0\n    for i in range(len(fatalities_train)-1):\n        fatal_increase_avg +=  (fatalities_train[i+1] -fatalities_train[i])\n        days+=1\n    if(days>0):\n        fatal_increase_avg = int(fatal_increase_avg/days)\n    \n    n_steps = max(int(len(cases_train)*0.15),2)\n#     print(len(cases_train))\n#     print(\"cases increase avg: \"+str(cases_increase_avg)+\" \"+ str(days))\n#     print(\"cases train len: \"+str(len(cases_train)))\n    \n    # get avg per day increase trend:\n    avg_weekly_per_day_case = []\n    avg_window = 4\n    avg_step = 2 \n#     if int(len(cases_train)/avg_window) > avg_step:\n#         for i in range(int(len(cases_train)/avg_window)):\n#                 temp_list = cases_train[i*avg_window:i*avg_window+avg_window]\n#                 avg_weekly_per_day_case.append(np.sum(temp_list)/len(temp_list))\n#         avg_weekly_per_day_case = np.array(avg_weekly_per_day_case)\n#         #print(\"window avg: \"+str(avg_weekly_per_day_case))\n#         # predict weekly avg\n#         X_weekly_avg_val, y_weekly_avg_val = split_sequence(avg_weekly_per_day_case,avg_step)\n#         X_weekly_avg_val = np.reshape(X_weekly_avg_val, (X_weekly_avg_val.shape[0],X_weekly_avg_val.shape[1],1))  #####\n#         model_weekly_avg=build_model(avg_step)\n#         model_weekly_avg.fit(X_weekly_avg_val, y_weekly_avg_val, epochs=50, verbose=0)\n#         new_entry_avg=X_weekly_avg_val[len(X_weekly_avg_val)-1]\n#         for i in range(int(30/avg_window)+1):\n#             weekly_avg_predict_next = model_weekly_avg.predict(np.reshape(new_entry_avg,(1,avg_step,1)), verbose=0).astype(int)\n#             avg_weekly_per_day_case = np.append(avg_weekly_per_day_case,weekly_avg_predict_next[0])\n\n#             last_series = np.reshape(new_entry_avg,(1,avg_step,1))\n#             new_entry_avg=np.delete(last_series,[0])\n#             new_entry_avg = np.insert(new_entry_avg,avg_step-1,weekly_avg_predict_next[0])\n#         del weekly_avg_predict_next\n#         del model_weekly_avg\n#         #print(\"7 weeks avg after predict: \"+str(avg_weekly_per_day_case))\n    \n    X_cases_val, y_cases_val = split_sequence(cases_train,n_steps)\n    X_cases_val = np.reshape(X_cases_val, (X_cases_val.shape[0],X_cases_val.shape[1],1))\n    model_cases=build_model(n_steps)\n    model_cases.fit(X_cases_val, y_cases_val, epochs=50, verbose=0)\n    cases_predict_next = model_cases.predict(np.reshape(X_cases_val[len(X_cases_val)-1],(1,n_steps,1)), verbose=0).astype(int)\n    cases_predict_next[0] =  np.array([max(0,cases_predict_next[0])])\n    \n    X_fatal_val, y_fatal_val = split_sequence(fatalities_train,n_steps)    \n    X_fatal_val = np.reshape(X_fatal_val, (X_fatal_val.shape[0],X_fatal_val.shape[1],1))\n    model_fatalities=build_model(n_steps)\n    model_fatalities.fit(X_fatal_val, y_fatal_val, epochs=50, verbose=0)\n    fatality_predict_next = model_fatalities.predict(np.reshape(X_fatal_val[len(X_fatal_val)-1],(1,n_steps,1)), verbose=0).astype(int)\n    fatality_predict_next[0] =  np.array([max(0,fatality_predict_next[0])])\n    fatality_predict_next[0] = np.array([max(fatality_predict_next[0],cases_predict_next[0]*fatal_rate)])\n    \n    test_df.loc[(test_df['Country']==country) & (test_df['Days']==train_end_day+1), 'ConfirmedCases'] = test_df.loc[(test_df['Country']==country) & (test_df['Days']==train_end_day), 'ConfirmedCases'].values[0] + cases_predict_next[0]\n    test_df.loc[(test_df['Country']==country) & (test_df['Days']==train_end_day+1), 'Fatalities'] = test_df.loc[(test_df['Country']==country) & (test_df['Days']==train_end_day), 'Fatalities'].values[0] + fatality_predict_next[0]\n\n#     print(cases_predict_next[0])\n#     print(X_cases_val[len(X_cases_val)-1])\n    \n    new_entry_cases=X_cases_val[len(X_cases_val)-1]\n    new_entry_fatal=X_fatal_val[len(X_fatal_val)-1]\n        \n    for i in range(test_end_day-train_end_day-1):\n\n      # after 7 days rates will mostly decline in these countries\n      last_series = np.reshape(new_entry_cases,(1,n_steps,1))\n      new_entry_cases=np.delete(last_series,[0])\n      new_entry_cases = np.insert(new_entry_cases,n_steps-1,cases_predict_next[0])\n\n      cases_predict_next = model_cases.predict(np.reshape(new_entry_cases,(1,n_steps,1)), verbose=0).astype(int)\n      if(cases_predict_next[0]-new_entry_cases[n_steps-1]>cases_increase_avg):\n        cases_predict_next[0] =  np.array([max(0,new_entry_cases[n_steps-1]+cases_increase_avg)])\n      cases_predict_next[0] =  np.array([max(0,cases_predict_next[0])])\n#       print(np.array(new_entry_cases))\n#       print(cases_predict_next[0])\n\n      last_series = np.reshape(new_entry_fatal,(1,n_steps,1))\n      new_entry_fatal=np.delete(last_series,[0])\n      new_entry_fatal = np.insert(new_entry_fatal,n_steps-1,fatality_predict_next[0])\n      #X_fatal_val = np.append(X_fatal_val, np.reshape(new_entry_fatal,(1,n_steps,1)), axis=0)\n\n      fatality_predict_next = model_fatalities.predict(np.reshape(new_entry_fatal,(1,n_steps,1)), verbose=0).astype(int)\n      if(fatality_predict_next[0]-new_entry_fatal[n_steps-1]>fatal_increase_avg):\n        fatality_predict_next[0] =  max(0,new_entry_fatal[n_steps-1]+fatal_increase_avg) \n      fatality_predict_next[0] =  np.array([max(0,fatality_predict_next[0])])\n      fatality_predict_next[0] = np.array([max(fatality_predict_next[0],int(cases_predict_next[0]*fatal_rate))])\n\n      test_df.loc[(test_df['Country']==country)  & (test_df['Days']==i+train_end_day+2), 'ConfirmedCases'] = test_df.loc[(test_df['Country']==country)  & (test_df['Days']==i+train_end_day+1), 'ConfirmedCases'].values[0] + cases_predict_next[0]\n      test_df.loc[(test_df['Country']==country) & (test_df['Days']==i+train_end_day+2), 'Fatalities'] = test_df.loc[(test_df['Country']==country)  & (test_df['Days']==i+train_end_day+1), 'Fatalities'].values[0] + fatality_predict_next[0]\n    del model_fatalities\n    del model_cases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_copy = test_df\nsubmission_df_copy = submission_df\n\nsubmit = pd.DataFrame()\nsubmit['ForecastId'] = test_df['ForecastId']\nsubmit['ConfirmedCases'] = test_df['ConfirmedCases']\nsubmit['Fatalities'] = test_df['Fatalities']\nsubmit = submit.reset_index()\nsubmit = submit.drop(['Date'], axis=1)\ndisplay(submit.tail())\n\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}