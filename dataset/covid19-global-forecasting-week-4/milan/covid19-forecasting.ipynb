{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBRegressor\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.impute import SimpleImputer\n\nfrom shapely.geometry import Point,Polygon\nimport requests ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading Training and Testing Data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest_data = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\nsubmission_csv = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert String Datetime to python datetime**"},{"metadata":{"trusted":false},"cell_type":"code","source":"convert_dict = {'Province_State': str,'Country_Region':str,'ConfirmedCases':int,'Fatalities':int}\nconvert_dict_test = {'Province_State': str,'Country_Region':str}\ntrain_data = train_data.astype(convert_dict)\ntest_data = test_data.astype(convert_dict_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data['Date'] = pd.to_datetime(train_data['Date'], infer_datetime_format=True)\ntest_data['Date'] = pd.to_datetime(test_data['Date'], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.loc[:, 'Date'] = train_data.Date.dt.strftime('%m%d')\ntrain_data.loc[:, 'Date'] = train_data['Date'].astype(int)\n\ntest_data.loc[:, 'Date'] = test_data.Date.dt.strftime('%m%d')\ntest_data.loc[:, 'Date'] = test_data['Date'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data['Country_Region'] = np.where(train_data['Province_State'] == 'nan',train_data['Country_Region'],train_data['Province_State']+' '+train_data['Country_Region'])\ntest_data['Country_Region'] = np.where(test_data['Province_State'] == 'nan',test_data['Country_Region'],test_data['Province_State']+' '+test_data['Country_Region'])\n\n#train_data['Province_State'] = np.where(train_data['Province_State'] == 'nan',train_data['Country_Region'],train_data['Province_State']+train_data['Country_Region'])\n#test_data['Province_State'] = np.where(test_data['Province_State'] == 'nan',test_data['Country_Region'],test_data['Province_State']+test_data['Country_Region'])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data = train_data.drop(columns=['Province_State'])\ntest_data = test_data.drop(columns=['Province_State'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Label Encoding Country**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#get list of categorical variables\ns = (train_data.dtypes == 'object')\nobject_cols = list(s[s].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Try using Label Encoder**"},{"metadata":{"trusted":false},"cell_type":"code","source":"label_encoder1 = LabelEncoder()\nlabel_encoder2 = LabelEncoder()\n\n#train_data['Province_State'] = label_encoder1.fit_transform(train_data['Province_State'])\n#test_data['Province_State'] = label_encoder1.transform(test_data['Province_State'])\n\ntrain_data['Country_Region'] = label_encoder2.fit_transform(train_data['Country_Region'])\ntest_data['Country_Region'] = label_encoder2.transform(test_data['Country_Region'])\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Test_id = test_data.ForecastId","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.drop(['Id'], axis=1, inplace=True)\ntest_data.drop('ForecastId', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check missing value**"},{"metadata":{"trusted":false},"cell_type":"code","source":"missing_val_count_by_column = (train_data.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column>0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Make model XGBRegressor**"},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = train_data[['Country_Region','Date']]\ny_train = train_data[['ConfirmedCases', 'Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train = X_train.iloc[:,:].values\nx_test = test_data.iloc[:,:].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting data train/test**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#X_train,X_test,Y_train,Y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"error_list = []\ndef return_error(estimator, x_train,x_test,y_train):\n    model = MultiOutputRegressor(XGBRegressor(n_estimators=estimator, random_state=0, max_depth=20))\n    model.fit(x_train, y_train)\n\n    predict = MultiOutputRegressor(model.predict(x_test))\n    \n    #error = mean_squared_error( y_test.values, predict.estimator)\n    #error_list.append(error)\n    \n    return predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#from sklearn.model_selection import RandomizedSearchCV, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#num_estimators = [1000,1100,1200,1250,1300]\n#learn_rates = [0.02,0.05,0.06,0.07]\n\n#param_grid = {'n_estimators':num_estimators,\n #             'learning_rate':learn_rates\n#            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#random_search = GridSearchCV(XGBRegressor(loss='huber'), param_grid,cv=3,return_train_score=True, n_jobs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#random_search.fit(x_train, y_train.Fatalities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#estimator_list = [1200,1250,1300,1350]\n#for value in estimator_list:\n#    error_ = return_error(value, X_train,X_test,Y_train,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predict = return_error(1500,x_train,x_test,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_sub = pd.DataFrame()\ndf_sub['ForecastId'] = Test_id\ndf_sub['ConfirmedCases'] = (predict.estimator[:,0]).astype(int)\ndf_sub['Fatalities'] = (predict.estimator[:,1]).astype(int)\n\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_sub","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}