{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nOn my [Week 3 notebook](https://www.kaggle.com/gabrielmilan/eda-regressors-ensembling) I said that I wanted to check the Gompertz model as seen on [sadiakhalil's notebook](https://www.kaggle.com/sadiakhalil/covid-19-global-eda-forecast-2#Final-Submission-Using-Gompertz-Model) using [this](https://arxiv.org/ftp/arxiv/papers/2003/2003.05447.pdf).\n\nThis is the purpose of this notebook. For referring to my Custom Regressors Ensemble click [here](https://www.kaggle.com/gabrielmilan/custom-regressors-ensembling). The output of this notebook is a merge of both this one and my Custom Regressors Ensemble, also publicly available."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nPUBLIC_PRIVATE = 1 # 0 for public leaderboard, 1 for private\n\n# Listing files\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train    = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ndf_test     = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\nsub_example = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/submission.csv')\nregr_ensemble_sub = pd.read_csv('/kaggle/input/regressors-ensemble-submission-week-4/submission (4).csv')\nregr_ensemble_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['ForecastId'] = -1\ndf_train['DataType'] = 0\ndf_test['DataType'] = 2\ndf_test['ConfirmedCases'] = -1\ndf_test['Fatalities'] = -1\ndf_test['Id'] = df_test['ForecastId'] + df_train['Id'].max()\ndf_intersection = df_train[df_train['Date'] >= df_test['Date'].min()]\ndf_intersection['DataType'] = 1\ndf_intersection['ForecastId'] = df_test[df_test['Date'] <= df_train['Date'].max()]['ForecastId'].values\ndf_train = df_train[df_train['Date'] < df_test['Date'].min()]\ndf_test = df_test[df_test['Date'] > df_intersection['Date'].max()]\nif not PUBLIC_PRIVATE:\n    df_intersection['ConfirmedCases'] = -1\n    df_intersection['Fatalities'] = -1\n    df_full = pd.concat([df_train, df_intersection, df_test], sort=False, axis=0)\nelse:\n    df_full = pd.concat([df_train, df_intersection, df_test], sort=False, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining Country_Region and Province_State cols\ndf_full['Province_State'] = df_full['Province_State'].fillna('')\ndf_full['Location'] = ['_'.join(x) for x in zip(df_full['Country_Region'], df_full['Province_State'])]\ndf_full.drop(columns=['Province_State', 'Country_Region'], inplace=True)\n\ndf_full.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom datetime import datetime\ndf_full['Date'] = pd.to_datetime(df_full['Date'])\ndf_full['Date'] = df_full['Date'].apply(lambda s: time.mktime(s.timetuple()))\nmin_timestamp = np.min(df_full['Date'])\ndf_full['Date'] = df_full['Date'].apply(lambda s: (s - min_timestamp) / 86400.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfrom scipy.optimize.minpack import curve_fit\nfrom sklearn.metrics import r2_score\nfrom scipy.special import expit\n\ndef Gompertz(a, c, t, t0):    \n    Q = a * np.exp(-np.exp(-c*(t-t0)))\n    return Q\n\nref = df_full[(df_full['DataType'].isin([0,1])) & (df_full['Location'] == 'China_Anhui')]\nref['ConfirmedCases'] /= ref['ConfirmedCases'].max()\nref['Fatalities'] /= ref['Fatalities'].max()\n\ndef getMultiplier (date):\n    try:\n        return 1.0 / ref[ref['Date'] == date]['ConfirmedCases'].values[0]\n    except:\n        return 3.5\n\nlocations = list(set(df_full['Location']))\nlocation_sample = ['Brazil_']#random.sample(locations, 1)\n\ntrain = df_full[df_full['DataType'] == 0]\nvalid = df_full[df_full['DataType'] == 1]\ntest =  df_full[df_full['DataType'] == 2]\n\nfor location in tqdm(locations):\n    _train = train[train['Location'] == location]\n    _valid = valid[valid['Location'] == location]\n    _test  = test [test ['Location'] == location]\n            \n    n_train_days = _train.Date.nunique()\n    n_valid_days = _valid.Date.nunique()\n    n_test_days  = _test.Date.nunique()\n    x_train      = range(n_train_days)\n    x_test       = range(n_train_days + n_valid_days + n_test_days + 200)\n    y_train_f    = _train['Fatalities']\n    y_train_c    = _train['ConfirmedCases']\n    \n    # ConfirmedCases\n    the_first_one = _train[_train['ConfirmedCases'] > 0.05 * _train['ConfirmedCases'].max()]['Date'].min()\n    first_cases = _train[_train['ConfirmedCases'] > 0.4 * _train['ConfirmedCases'].max()]['Date'].min()\n    if math.isnan(the_first_one):\n        the_first_one = _train['Date'].max()\n        first_cases = _train['Date'].max() + 8\n    current = _train['Date'].max() - first_cases\n    if location.startswith('China'):\n        lower_c = [0, 0.02, 0]\n        upper_c = [2*y_train_c.max()+1, 0.15, 25]\n    else:\n        lower_c = [0, 0.02, the_first_one]\n        upper_c = [getMultiplier(current)*np.max(y_train_c)+1, 0.15, first_cases + 28]\n    popt_c, pcov_c = curve_fit(Gompertz, x_train, y_train_c, method='trf', bounds=(lower_c,upper_c))\n    a_max_c, estimated_c_c, estimated_t0_c = popt_c\n    y_predict_c = Gompertz(a_max_c, estimated_c_c, x_test, estimated_t0_c)\n    y_predict_c_at_t0 =  Gompertz(a_max_c, estimated_c_c, estimated_t0_c, estimated_t0_c)\n\n    # Fatalities\n    the_first_one = _train[_train['Fatalities'] > 0.05 * _train['Fatalities'].max()]['Date'].min()\n    first_cases = _train[_train['Fatalities'] > 0.37 * _train['Fatalities'].max()]['Date'].min()\n    if math.isnan(the_first_one):\n        the_first_one = _train['Date'].max()\n        first_cases = _train['Date'].max() + 8\n    current = _train['Date'].max() - first_cases\n    if location.startswith('China'):\n        lower = [0, 0.02, 0]\n        upper = [2*y_train_f.max()+1, 0.15, 25]\n    else:\n        lower = [0, 0.02, the_first_one]\n        upper = [getMultiplier(current)*np.max(y_train_f)+1, 0.15, first_cases + 28]\n    popt_f, pcov_f = curve_fit(Gompertz, x_train, y_train_f, method='trf', bounds=(lower,upper))\n    a_max, estimated_c, estimated_t0 = popt_f\n    y_predict_f = Gompertz(a_max, estimated_c, x_test, estimated_t0)\n    y_predict_f_at_t0 =  Gompertz(a_max, estimated_c, estimated_t0, estimated_t0)\n    \n    \n    from datetime import datetime, timedelta\n    initial_date = datetime (2020, 1, 22)\n    \n    dates_train = list(x_train)\n    dates_test = list(x_test)\n    for i in range(len(dates_train)):\n        dates_train[i] = initial_date + timedelta(days=dates_train[i])\n    for i in range(len(dates_test)):\n        dates_test[i] = initial_date + timedelta(days=dates_test[i])\n        \n#     plt.figure(figsize=(14,8))\n#     plt.title('COVID-19 cases on Brazil')\n#     plt.xlabel('Date')\n#     plt.ylabel('Number')\n#     plt.plot(dates_train, y_train_c, linewidth=2, color='#ff9933')\n#     plt.plot(dates_test , y_predict_c, linewidth=2, color='#e67300', linestyle='dashed')\n#     legend = []\n#     legend.append('{} confirmed cases'.format('Brazil'))\n#     legend.append('{} predicted cases'.format('Brazil'))\n#     plt.legend(legend)\n#     plt.show()\n\n#     plt.figure(figsize=(14,8))\n#     plt.title('COVID-19 cases on Brazil')\n#     plt.xlabel('Date')\n#     plt.ylabel('Number')\n#     plt.plot(dates_train, y_train_f, linewidth=2, color='#ff9933')\n#     plt.plot(dates_test , y_predict_f, linewidth=2, color='#e67300', linestyle='dashed')\n#     legend = []\n#     legend.append('{} fatalities'.format('Brazil'))\n#     legend.append('{} fatalities'.format('Brazil'))\n#     plt.legend(legend)\n#     plt.show()\n\n    values = y_predict_c[df_full[df_full['DataType'] == 2]['Date'].astype(int).min():df_full[df_full['DataType'] == 2]['Date'].astype(int).max() + 1]\n    df_full.loc[(df_full['DataType'] == 2) & (df_full['Location'] == location), 'ConfirmedCases'] = values\n    values = y_predict_f[df_full[df_full['DataType'] == 2]['Date'].astype(int).min():df_full[df_full['DataType'] == 2]['Date'].astype(int).max() + 1]\n    df_full.loc[(df_full['DataType'] == 2) & (df_full['Location'] == location), 'Fatalities'] = values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sanity Check"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotStatus (location):\n    from datetime import datetime\n    plt.figure(figsize=(14,8))\n    plt.title('COVID-19 cases on {}'.format(location))\n    _train = df_full.loc[(df_full['DataType'] == 0) & (df_full['Location'] == location)]\n    _test = df_full.loc[(df_full['DataType'] == 1) & (df_full['Location'] == location)]\n    _valid = df_full.loc[(df_full['DataType'] == 2) & (df_full['Location'] == location)]\n    idx = test[test['Location'] == location].index\n    legend = []\n    plt.xlabel('Date')\n    plt.ylabel('Number')\n    plt.plot(_train['Date'], _train['ConfirmedCases'], linewidth=2)\n    plt.plot(_test['Date'], _test['ConfirmedCases'], linewidth=2)\n    plt.plot(_valid['Date'], _valid['ConfirmedCases'], linewidth=2)\n    legend.append('{} train cases'.format(location))\n    legend.append('{} test cases'.format(location))\n    legend.append('{} validation cases'.format(location))\n    plt.legend(legend)\n    plt.show()\n    legend = []\n    plt.figure(figsize=(14,8))\n    plt.title('COVID-19 fatalities on {}'.format(location))\n    plt.xlabel('Date')\n    plt.ylabel('Number')\n    plt.plot(_train['Date'], _train['Fatalities'], linewidth=2)\n    plt.plot(_test['Date'], _test['Fatalities'], linewidth=2)\n    plt.plot(_valid['Date'], _valid['Fatalities'], linewidth=2)\n    legend.append('{} train fatalities'.format(location))\n    legend.append('{} test fatalities'.format(location))\n    legend.append('{} validation fatalities'.format(location))\n    plt.show()\n\nlocation_sample = random.sample(locations, 10)\nfor location in location_sample:\n    plotStatus(location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df_full[df_full['ForecastId'] > 0][['ForecastId', 'ConfirmedCases', 'Fatalities']].sort_values('ForecastId')\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging submissions"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_sub = pd.DataFrame()\nWEIGHT_CC_REGR = .3\nWEIGHT_CC_GOMP = .7\nWEIGHT_FT_REGR = .3\nWEIGHT_FT_GOMP = .7\nmerged_sub['ForecastId'] = submission['ForecastId']\nmerged_sub['ConfirmedCases'] = (regr_ensemble_sub['ConfirmedCases'].values * WEIGHT_CC_REGR + submission['ConfirmedCases'].values * WEIGHT_CC_GOMP)\nmerged_sub['Fatalities'] = (regr_ensemble_sub['Fatalities'].values * WEIGHT_FT_REGR + submission['Fatalities'].values * WEIGHT_FT_GOMP)\nmerged_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}