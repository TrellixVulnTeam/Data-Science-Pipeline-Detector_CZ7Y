{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT=1\noptimize_model=False\nMake_submission=True\nn_estimators=150 #400 #500  #1500\nmax_depth=2 #4 #12  #8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For some countries we also have data for individual regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['Province_State'].notna()].groupby(['Country_Region'], sort=False)['Province_State'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping country names and provinces into variable - location"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def add_location(df_old):\n    df=df_old.copy()\n    df['Date']=pd.to_datetime(df['Date'])\n    df['Country_Region']=df['Country_Region'].fillna('')\n    df['Province_State']=df['Province_State'].fillna('')\n    df['location']=df['Province_State'].astype('str')+\" \"+df['Country_Region'].astype('str')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_location(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Locations with less than 5 cases:"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_cases_old=train[train['Date']<'2020-03-22'].groupby(['location'], sort=False)['ConfirmedCases'].max()\nmax_cases=train.groupby(['location'], sort=False)['ConfirmedCases'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index('location',inplace=True)\n\ntrain['day_of_year']=train['Date'].dt.dayofyear\ntrain['day_of_week']=train['Date'].dt.dayofweek\n\n\n\nfirst_day=train[(train['ConfirmedCases']>0)].groupby(['location'], sort=False)['day_of_year'].min()\nfirst_day.rename('first_day',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_days_passed(df_old,first_day):\n    df=df_old.copy()\n    df=pd.concat([df,first_day],axis=1,join='inner')\n    df['days_passed']=df['day_of_year']-df['first_day']\n    df.drop(columns=['first_day'],inplace=True)\n    df['location']=df.index\n    df.set_index('Id',inplace=True)\n    df['Id']=df.index\n    return df\n\n \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_days_passed(train,first_day)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stat=pd.read_csv('../input/countryinfo/covid19countryinfo.csv')\ncountry_stat = country_stat[country_stat['region'].isnull()] \n\ndef add_country_stat(old_df,country_stat):\n    df=old_df.copy()\n    df=df.merge(country_stat[['country','pop','medianage','sex65plus','lung','smokers','density']],left_on=['Country_Region'],right_on=['country'],how='left')\n    df.drop(columns=['country'],inplace=True)\n    \n    df['pop']=df['pop'].fillna(1000)\n    df['pop']=df['pop'].apply(lambda x: int(str(x).replace(',', '')))\n    #df['gdp2019']=df['gdp2019'].fillna(0)\n    #df['gdp2019']=df['gdp2019'].apply(lambda x: int(str(x).replace(',', '')))\n    #df['gdp2019']=df['gdp2019']/df['pop']\n    \n    \n    df['density']=df['density'].fillna(0)\n    df['medianage']=df['medianage'].fillna(0)\n    #df['sexratio']=df['sexratio'].fillna(1)\n    df['sex65plus']=df['sex65plus'].fillna(1)\n    df['lung']=df['lung'].fillna(24)\n    df['smokers']=df['smokers'].fillna(24)\n    #df['lung']=df['lung']*df['pop']\n    \n    return df\n    \n\ntrain=add_country_stat(train,country_stat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"border_info=pd.read_csv(\"https://raw.githubusercontent.com/geodatasource/country-borders/master/GEODATASOURCE-COUNTRY-BORDERS.CSV\")\nborder_info.drop(columns=[\"country_code\",\"country_border_code\"],inplace=True)\nborder_info.replace({'United States of America':'US',\n                    'United Kingdom of Great Britain and Northern Ireland':'United Kingdom',\n                    'Bolivia (Plurinational State Of)':'Bolivia',\n                    'Brunei Darussalam':'Brunei',\n                    'Gambia (the)':'Gambia',\n                     'Congo':'Congo (Kinshasa)',\n                     'Cote dâ€™Ivoire':\"Cote d'Ivoire\",\n                     \"Iran (Islamic Republic of)\":'Iran',\n                     \"Korea (the Republic of)\":'Korea, South',\n                    \"Lao People's Democratic Republic\":'Laos',\n                     \"Moldova (the Republic of)\":'Moldova',\n                     \"Russian Federation\":'Russia',\n                    \"Syrian Arab Republic\":'Syria',\n                     \"Taiwan (Province of China)\":'Taiwan*',\n                    \"Tanzania (the United Republic of)\":'Tanzania',\n                     \"Venezuela (Bolivarian Republic of)\":'Venezuela',\n                     \"Viet Nam\":'Vietnam'},inplace=True)\nborder_info=border_info.fillna(\"\")\nborder_info.to_csv(\"border_info.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product as it_product\ndef expand_grid(data_dict):\n  rows = it_product(*data_dict.values())\n  return pd.DataFrame.from_records(rows, columns=data_dict.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skel=expand_grid({'Index':border_info.index,'Date':train['Date'].unique()})\nskel.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info=train.groupby(['Date','Country_Region'])['ConfirmedCases'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skel=expand_grid({'Index':border_info.index,'Date':train['Date'].unique()})\n\nskel=skel.merge(border_info, how='inner', left_on=['Index'],right_index=True)\nskel=skel.merge(country_info, how='inner', \n                left_on=['Date','country_border_name'],right_on=['Date','Country_Region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta\nskel['Date']=skel['Date']+timedelta(days=DT)\nborder_cases=skel.groupby(['country_name','Date'])['ConfirmedCases'].sum()\nlen(skel['country_name'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.merge(border_cases, how='left', left_on=['Country_Region','Date'],right_on=['country_name','Date'])\ntrain['ConfirmedCases_y']=train['ConfirmedCases_y'].fillna(0)\ntrain.rename(columns={'ConfirmedCases_y':'ConfirmedCases_neighbors','ConfirmedCases_x':'ConfirmedCases'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train = pd.concat([train,pd.get_dummies(train['location'], prefix='loc')],axis=1)\nbig_train['ConfirmedCases_neighbors']=np.log1p(big_train['ConfirmedCases_neighbors'])\nbig_train.reset_index(inplace=True)\nbig_train.drop(columns=[\"Id\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_add_deltas(df_old):\n    df=df_old.copy()\n    df=df.sort_values(by=['location', 'Date'])\n    df['d_ConfirmedCases'] = df.groupby(['location'])['ConfirmedCases'].diff()\n    df['d_Fatalities'] = df.groupby(['location'])['Fatalities'].diff()\n    df.loc[df['d_Fatalities']<0,'d_Fatalities']=0\n    df.loc[df['d_ConfirmedCases']<0,'d_ConfirmedCases']=0\n    \n    df['prev_ConfirmedCases']=df['ConfirmedCases']-df['d_ConfirmedCases']\n    df['prev_Fatalities']=df['Fatalities']-df['d_Fatalities']\n    \n    df['prev_ConfirmedCases']=np.log1p(df['prev_ConfirmedCases'])\n    df['prev_Fatalities']=np.log1p(df['prev_Fatalities'])\n    \n    df['prev5_ConfirmedCases'] = df.groupby(['location'])['ConfirmedCases'].shift(5).fillna(0)\n    df['prev5_Fatalities'] = df.groupby(['location'])['Fatalities'].shift(5).fillna(0)\n    \n    df['prev5_ConfirmedCases']=np.log1p(df['prev5_ConfirmedCases'])\n    df['prev5_Fatalities']=np.log1p(df['prev5_Fatalities'])\n    \n    first_day_stat=df[df['Date']=='2020-01-22']\n    df.drop(df[df['Date']=='2020-01-22'].index, inplace=True)\n    \n    return df,first_day_stat\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train,first_day_stat=df_add_deltas(big_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#big_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=big_train.drop(columns=['Province_State','Country_Region','Date','ConfirmedCases','Fatalities','location',\n                          'd_ConfirmedCases','d_Fatalities'])\n\ny=big_train['d_ConfirmedCases']\ny_2=big_train['d_Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_day=X['day_of_year'].max()\nmask_train=X['day_of_year']<max_day-DT+1\nmask_test=X['day_of_year']>=max_day-DT+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X[mask_train]\nX_test=X[mask_test]\n\n\ny_train=y[mask_train]\ny_test=y[mask_test]\n\ny_train_2=y_2[mask_train]\ny_test_2=y_2[mask_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test['day_of_year'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\ncorr = big_train[['d_ConfirmedCases','d_Fatalities','days_passed','ConfirmedCases_neighbors','pop',\n                  'medianage','sex65plus','lung','smokers','density','prev_ConfirmedCases','prev_Fatalities']].corr(\"spearman\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(columns=['day_of_year'],inplace=True)  #including day of year makes things worse RMLSE goes up from 0.49 to 0.7\nX_test.drop(columns=['day_of_year'],inplace=True)   #including day of year makes things worse RMLSE goes up from 0.49 to 0.7\n\nX_train.drop(columns=['day_of_week'],inplace=True)  #including day of week makes things worse RMLSE goes up from 0.49 to 0.57\nX_test.drop(columns=['day_of_week'],inplace=True)   #including day of week makes things worse RMLSE goes up from 0.49 to 0.57\n\nX.drop(columns=['day_of_year'],inplace=True)  \nX.drop(columns=['day_of_week'],inplace=True)   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(columns=['index'],inplace=True)   \nX_train.drop(columns=['index'],inplace=True)\nX_test.drop(columns=['index'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best: -0.252369 using {'max_depth': 6, 'n_estimators': 1500}\n\n# Best: -1.051575 using {'max_depth': 6, 'n_estimators': 500} - predict shifts log\n\n# Best: -278.598983 using {'max_depth': 10, 'n_estimators': 500} - predict values\n\n# Best: -1.111758 using {'max_depth': 6, 'n_estimators': 500} - predict shifts log, knowing prev log \n\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n    n_estimators_grid = [500, 750,1000]\n    max_depth_grid = [4, 6, 8]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best: -0.211438 using {'max_depth': 5, 'n_estimators': 2500}\n\n# Best: -0.974302 using {'max_depth': 5, 'n_estimators': 400} - predict shifts log\n\n# Best: -274.964946 using {'max_depth': 12, 'n_estimators': 500}\n\n# Best: -1.064197 using {'max_depth': 5, 'n_estimators': 400}\n\n\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n    n_estimators_grid = [400,500,600]\n    max_depth_grid = [3,4,5]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best: -0.211107 using {'max_depth': 5, 'n_estimators': 3000}\n\n#Best: -0.940498 using {'max_depth': 4, 'n_estimators': 400}\n\n#Best: -274.964946 using {'max_depth': 12, 'n_estimators': 500}\n\n#Best: -0.861262 using {'max_depth': 2, 'n_estimators': 200}\n\n#Best: -0.834393 using {'max_depth': 2, 'n_estimators': 150}\n\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n    n_estimators_grid = [125,150,175]\n    max_depth_grid = [1,2,3]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = xgb.XGBRegressor(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\nreg_2 = xgb.XGBRegressor(n_estimators=n_estimators,max_depth=max_depth,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(X_train,np.log1p(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = xgb.plot_importance(reg, max_num_features=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(y_pred,np.log1p(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_2=X_train.copy()\nX_train_2['d_confirmed']=y_train  #0.4412899060661785 <- without , with - 0.4463  \nX_test_2=X_test.copy()\nX_test_2['d_confirmed']=y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_2.fit(X_train_2,np.log1p(y_train_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = xgb.plot_importance(reg_2, max_num_features=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_2 = reg_2.predict(X_test_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_pred_2,np.log1p(y_test_2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\ntest.rename(columns={'ForecastId':'Id'},inplace=True)\ntest=add_location(test)\n\ntest.set_index('location',inplace=True)\n\ntest['day_of_year']=test['Date'].dt.dayofyear\ntest['day_of_week']=test['Date'].dt.dayofweek\ntest=add_days_passed(test,first_day)\ntest=add_country_stat(test,country_stat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_to_predict=test['Date'].unique()\ndays_to_predict.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train=big_train.drop(columns=[\"index\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"known=big_train['Date'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    results=[]\n\n    for d in days_to_predict:\n        print(\"Predicting {}\".format(d))\n        if d in known:\n            print(\"Data Known\")\n        \n            X=big_train.drop(columns=['Province_State','Country_Region','ConfirmedCases','Fatalities','location','Date',\n                                  'day_of_year','day_of_week','d_ConfirmedCases','d_Fatalities'])\n\n            y=big_train['d_ConfirmedCases']\n            y_2=big_train['d_Fatalities']\n        \n            mask_train=big_train['Date']<d\n            mask_val=big_train['Date']==d\n        \n            X_train=X[mask_train]\n            y_train=y[mask_train]\n            y_train_2=y_2[mask_train]\n        \n            X_val=X[mask_val]\n            y_val=y[mask_val]\n            y_val_2=y_2[mask_val]\n        \n            reg = xgb.XGBRegressor(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\n            reg_2 = xgb.XGBRegressor(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\n        \n            reg.fit(X_train,np.log1p(y_train))\n        \n            y_pred = reg.predict(X_val)\n            print(\"MSLE {}\".format(mean_squared_error(y_pred,np.log1p(y_val))))\n        \n            X_train_2=X_train.copy()\n            X_train_2['d_ConfirmedCases']=np.log1p(y_train)  #0.4412899060661785 <- without , with - 0.4463  \n            X_val_2=X_val.copy()\n            X_val_2['d_ConfirmedCases']=y_pred\n        \n            reg_2.fit(X_train_2,np.log1p(y_train_2))\n        \n            y_pred_2 = reg_2.predict(X_val_2)\n        \n            print(\"MSLE {}\".format(mean_squared_error(y_pred_2,np.log1p(y_val_2))))\n        \n        #result=X_test[['']]\n        elif d-np.timedelta64(86400000000000,'ns') in known:\n            print(\"Data Known\")\n        \n            X=big_train.drop(columns=['Province_State','Country_Region','ConfirmedCases','Fatalities','location','Date',\n                                  'day_of_year','day_of_week','d_ConfirmedCases','d_Fatalities'])\n\n            y=big_train['d_ConfirmedCases']\n            y_2=big_train['d_Fatalities']\n        \n            mask_train=big_train['Date']<d\n        \n            X_train=X[mask_train]\n            y_train=y[mask_train]\n            y_train_2=y_2[mask_train]\n        \n        \n            reg = xgb.XGBRegressor(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\n            reg_2 = xgb.XGBRegressor(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\n        \n            reg.fit(X_train,np.log1p(y_train))\n        \n            X_train_2=X_train.copy()\n            X_train_2['d_ConfirmedCases']=np.log1p(y_train)  #0.4412899060661785 <- without , with - 0.4463  \n            \n            reg_2.fit(X_train_2,np.log1p(y_train_2))\n        \n        \n        \n        X_test=test[test['Date']==d]\n    \n        day=X_test['day_of_year'].iloc[0]\n    \n        country_info=big_train[big_train['day_of_year']==day-1].groupby(['Country_Region'])['ConfirmedCases'].sum()\n    \n        border_cases=border_info.merge(country_info, how='inner', \n                left_on=['country_border_name'],right_on=['Country_Region'])\n    \n        border_cases=border_cases.groupby(['country_name'])['ConfirmedCases'].sum()\n        border_cases=border_cases.rename('ConfirmedCases_neighbors')\n    \n        X_test=X_test.merge(border_cases, how='left', left_on=['Country_Region'],right_on=['country_name'])\n        X_test['ConfirmedCases_neighbors']=X_test['ConfirmedCases_neighbors'].fillna(0)\n    \n        X_test = pd.concat([X_test,pd.get_dummies(X_test['location'], prefix='loc')],axis=1)\n        X_test['ConfirmedCases_neighbors']=np.log1p(X_test['ConfirmedCases_neighbors'])\n        \n        X_test=X_test.merge(big_train[big_train['day_of_year']==day-1][['location','ConfirmedCases','Fatalities']], how='left', \n                 left_on=['location'],right_on=['location'])\n        X_test.rename(columns={'ConfirmedCases':'prev_ConfirmedCases','Fatalities':'prev_Fatalities'},inplace=True)\n        \n        X_test['prev_ConfirmedCases']=np.log1p(X_test['prev_ConfirmedCases'])\n        X_test['prev_Fatalities']=np.log1p(X_test['prev_Fatalities'])\n        \n        X_test=X_test.merge(big_train[big_train['day_of_year']==day-5][['location','ConfirmedCases','Fatalities']], how='left', \n                 left_on=['location'],right_on=['location'])\n        X_test.rename(columns={'ConfirmedCases':'prev5_ConfirmedCases','Fatalities':'prev5_Fatalities'},inplace=True)\n        \n        X_test['prev_ConfirmedCases']=np.log1p(X_test['prev_ConfirmedCases'])\n        X_test['prev_Fatalities']=np.log1p(X_test['prev_Fatalities'])\n        \n    \n        X_test.set_index('Id',inplace=True)\n    \n    #print(X_test.head(5))\n    \n        y_test=reg.predict(X_test.drop(columns=['Province_State','Country_Region','location','Date','day_of_year','day_of_week']))\n    \n    #print(y_test)\n    \n        X_test['d_ConfirmedCases']=y_test\n    \n        y_test=reg_2.predict(X_test.drop(columns=['Province_State','Country_Region','location','Date',\n                                            'day_of_year','day_of_week']))\n    \n        X_test['d_Fatalities']=y_test\n    \n    #print(X_test.shape)\n    \n        X_test['Id']=X_test.index\n    \n        X_test=X_test.merge(big_train[big_train['day_of_year']==day-1][['location','ConfirmedCases','Fatalities']], how='left', \n                 left_on=['location'],right_on=['location'])\n    \n    #print(X_test.head(5))\n    \n    #X_test.set_index('Id',inplace=True)\n    \n    #print(X_test.shape)\n    \n        X_test.set_index('Id',inplace=True)\n    \n        print(X_test.head(5))\n        \n        X_test['d_ConfirmedCases']=np.expm1(X_test['d_ConfirmedCases'])\n        X_test['d_Fatalities']=np.expm1(X_test['d_Fatalities'])\n    \n        X_test['ConfirmedCases']+=X_test['d_ConfirmedCases']\n        X_test['Fatalities']+=X_test['d_Fatalities']\n       \n    \n    \n        results.append(X_test[['ConfirmedCases','Fatalities']])\n    \n        if not d in known: #Needed to correctly get data on neighbors         \n            big_train=pd.concat([big_train,X_test])\n    \n    \n    \n    \n    \n    \n    \n    \n        \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    submission=pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\n    submission.drop(columns=['ConfirmedCases','Fatalities'],inplace=True)\n    submission=submission.merge(pd.concat(results),left_on=['ForecastId'],right_index=True).clip(lower=0)\n    submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}