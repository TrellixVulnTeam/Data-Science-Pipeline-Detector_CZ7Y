{"cells":[{"metadata":{"_uuid":"5f79b877-054f-4fca-8022-aa3215b02af0","_cell_guid":"65ad0eef-420b-4c45-b9ec-87be952c5c51","trusted":true},"cell_type":"code","source":"week = 4","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"45db322b-2043-4e07-8e17-e87d48b27290","_cell_guid":"b7d74eff-ff97-4fc5-890e-eadc1608f0b7","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport datetime\nimport os\nimport matplotlib.pyplot as plt","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"230cfa13-22d6-48f5-917a-8a4e395cdd2b","_cell_guid":"3bb6afb7-0d16-4976-ac1c-1f065ab4288c","trusted":true},"cell_type":"code","source":"train = pd.read_csv(f\"/kaggle/input/covid19-global-forecasting-week-{week}/train.csv\")\ntrain.loc[:, \"geo\"] = np.where(train.loc[:, \"Province_State\"].isna(), train.loc[:, \"Country_Region\"], train.loc[:, \"Country_Region\"] + \"_\" + train.loc[:, \"Province_State\"])\n\ntrain.loc[:, 'Date'] = pd.to_datetime(train.loc[:, 'Date'])\ntrain = train.loc[train.loc[:, 'Date'] > '2020-02-20', :]\ntrain_last_date = train.Date.unique()[-1]\nprint(f\"Dataset has training data untill : {str(train_last_date)[:10]}\")\nprint(f\"Training dates: {len(train.Date.unique())}\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"1e53c211-3c09-4923-9928-152f8cea2901","_cell_guid":"93fe7377-da8b-45cf-889e-cd030c4549fe","trusted":true},"cell_type":"code","source":"world_pop = pd.read_csv(\"/kaggle/input/population-by-country-2020/population_by_country_2020.csv\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7e1dffc4-1aa4-45fd-9dbf-f7ef5ee82951","_cell_guid":"7a21b3c3-4a16-481c-a264-d717353031a8","trusted":true},"cell_type":"code","source":"additional_pop = {\n    'Australia_Australian Capital Territory': 426709,\n    'Australia_New South Wales': 8089526,\n    'Australia_Northern Territory': 245869,\n    'Australia_Queensland': 5095100,\n    'Australia_South Australia': 1751693,\n    'Australia_Tasmania': 534281,\n    'Australia_Victoria': 6594804,\n    'Australia_Western Australia': 2621680,\n    'Burma': 54329979,\n    'Canada_Alberta': 4345737,\n    'Canada_British Columbia': 5020302,\n    'Canada_Manitoba': 1360396,\n    'Canada_New Brunswick': 772094,\n    'Canada_Newfoundland and Labrador': 523790,\n    'Canada_Northwest Territories': 44598,\n    'Canada_Nova Scotia': 965382,\n    'Canada_Ontario': 14446515,\n    'Canada_Prince Edward Island': 154748,\n    'Canada_Quebec': 8433301,\n    'Canada_Saskatchewan': 1168423,\n    'Canada_Yukon': 40854,\n    'China_Anhui': 62550000,\n    'China_Beijing': 21710000,\n    'China_Chongqing': 30750000,\n    'China_Fujian': 39110000,\n    'China_Gansu': 26260000,\n    'China_Guangdong': 111690000,\n    'China_Guangxi': 48850000,\n    'China_Guizhou': 35550000,\n    'China_Hainan': 9170000,\n    'China_Hebei': 75200000,\n    'China_Heilongjiang': 37890000,\n    'China_Henan': 95590000,\n    'China_Hong Kong': 7335384,\n    'China_Hubei': 59020000,\n    'China_Hunan': 68600000,\n    'China_Inner Mongolia': 25290000,\n    'China_Jiangsu': 80290000,\n    'China_Jiangxi': 46220000,\n    'China_Jilin': 27170000,\n    'China_Liaoning': 43690000,\n    'China_Macau': 644900,\n    'China_Ningxia': 6820000,\n    'China_Qinghai': 5980000,\n    'China_Shaanxi': 38350000,\n    'China_Shandong': 100060000,\n    'China_Shanghai': 24180000,\n    'China_Shanxi': 36820000,\n    'China_Sichuan': 83020000,\n    'China_Tianjin': 15570000,\n    'China_Tibet': 3370000,\n    'China_Xinjiang': 24450000,\n    'China_Yunnan': 48010000,\n    'China_Zhejiang': 56570000,\n    'Congo (Brazzaville)': 5293070,\n    'Congo (Kinshasa)': 101780263,\n    \"Cote d'Ivoire\": 26228509,\n    'Czechia': 10704633,\n    'Denmark_Faroe Islands': 52110,\n    'Denmark_Greenland': 56025,\n    'Diamond Princess': 2670,\n    'France_French Guiana': 296880,\n    'France_French Polynesia': 280553,\n    'France_Guadeloupe': 400109, \n    'France_Martinique': 375327,\n    'France_Mayotte': 271290,\n    'France_New Caledonia': 284885,\n    'France_Reunion': 893895,\n    'France_Saint Barthelemy': 9793,\n    'France_Saint Pierre and Miquelon': 5800,\n    'France_St Martin': 36824,\n    'Korea, South': 51259674,\n    'Kosovo': 1808257,\n    'MS Zaandam': 1432,\n    'Netherlands_Aruba': 106766,\n    'Netherlands_Bonaire, Sint Eustatius and Saba': 25157,\n    'Netherlands_Curacao': 163947,\n    'Netherlands_Sint Maarten': 44548,\n    'Saint Kitts and Nevis': 53117,\n    'Saint Vincent and the Grenadines': 110864,\n    'Sao Tome and Principe': 218230,\n    'Taiwan*': 23807342,\n    'West Bank and Gaza': 5075897,\n    'United Kingdom_Anguilla': 14974,\n    'United Kingdom_Bermuda': 62328,\n    'United Kingdom_British Virgin Islands': 30186,\n    'United Kingdom_Cayman Islands': 65551,\n    'United Kingdom_Channel Islands': 173506,\n    'United Kingdom_Falkland Islands (Malvinas)': 3456,\n    'United Kingdom_Gibraltar': 33693,\n    'United Kingdom_Isle of Man': 84934,\n    'United Kingdom_Montserrat': 4991,\n    'United Kingdom_Turks and Caicos Islands': 38599,\n    'US_Alabama': 4903185,\n    'US_Alaska': 731545,\n    'US_Arizona': 7278717,\n    'US_Arkansas': 3017825,\n    'US_California': 39512223,\n    'US_Colorado': 5758736,\n    'US_Connecticut': 3565287,\n    'US_Delaware': 973764,\n    'US_District of Columbia': 705749,\n    'US_Florida': 21477737,\n    'US_Georgia': 10617423,\n    'US_Guam': 165718,\n    'US_Hawaii': 1415872,\n    'US_Idaho': 1787065,\n    'US_Illinois': 12671821,\n    'US_Indiana': 6732219,\n    'US_Iowa': 3155070,\n    'US_Kansas': 2913314,\n    'US_Kentucky': 4467673,\n    'US_Louisiana': 4648794,\n    'US_Maine': 1344212,\n    'US_Maryland': 6045680,\n    'US_Massachusetts': 6949503,\n    'US_Michigan': 9986857,\n    'US_Minnesota': 5639632,\n    'US_Mississippi': 2976149,\n    'US_Missouri': 6137428,    \n    'US_Montana': 1068778,    \n    'US_Nebraska': 1934408,\n    'US_Nevada': 3080156,\n    'US_New Hampshire': 1359711,\n    'US_New Jersey': 8882190,\n    'US_New Mexico': 2096829,\n    'US_New York': 19453561,\n    'US_North Carolina': 10488084,\n    'US_North Dakota': 762062,\n    'US_Ohio': 11689100,\n    'US_Oklahoma': 3956971,\n    'US_Oregon': 4217737,\n    'US_Pennsylvania': 12801989,\n    'US_Puerto Rico': 3193694,\n    'US_Rhode Island': 1059361,\n    'US_South Carolina': 5148714,\n    'US_South Dakota': 884659,\n    'US_Tennessee': 6833174,\n    'US_Texas': 28995881,\n    'US_Utah': 3205958,\n    'US_Vermont': 623989,\n    'US_Virgin Islands': 104914,\n    'US_Virginia': 8535519,\n    'US_Washington': 7614893,\n    'US_West Virginia': 1792147,\n    'US_Wisconsin': 5822434,\n    'US_Wyoming': 578759\n}\n\nadditional_pop = pd.DataFrame({\n    'Country_Region': np.array(list(additional_pop.keys())), \n    'population': np.array(list(additional_pop.values()))\n})\n\nadditional_pop","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"eea8ff47-31db-42af-9171-3e7caf114c5e","_cell_guid":"0ca39c9e-9099-492c-bcbb-72943efaf083","trusted":true},"cell_type":"code","source":"world_pop = train.loc[:, ['geo']].rename(columns={'geo': 'Country_Region'}).drop_duplicates() \\\n    .merge(\n    pd.concat([world_pop.loc[:, ['Country (or dependency)', 'Population (2020)']].rename(columns={'Country (or dependency)': 'Country_Region',\n                                                                                  'Population (2020)': 'population'}), additional_pop], axis=0), how='left', on='Country_Region'\n)\n\nworld_pop","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"6b379bbb-ba98-4a6f-bb83-a399045dc9ca","_cell_guid":"a6dd6548-de65-4af1-8f1f-b89677f34b68","trusted":true},"cell_type":"code","source":"_ = train.groupby(['Date']).agg({'ConfirmedCases': np.sum}).plot()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"cd4e04a4-d64f-4285-b764-274c65365f97","_cell_guid":"c4c36d72-0193-4edf-9159-9799bd520ebe","trusted":true},"cell_type":"code","source":"_ = train.groupby(['Date']).agg({'Fatalities': np.sum}).plot()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"583f4af4-b95f-43b1-b525-11d4235cf0b0","_cell_guid":"e88b85a8-69f9-4c99-b313-27b1694c91df","trusted":true},"cell_type":"code","source":"all_countries = train.groupby(['Date']).agg({'ConfirmedCases': np.sum}).reset_index()\n\nall_countries['sh'] = train.groupby(['Date']).agg({'ConfirmedCases': np.sum}).reset_index().shift(1)['ConfirmedCases']\nall_countries['sh'] = (all_countries['ConfirmedCases'] / all_countries['sh']) - 1\n\nall_countries = all_countries.set_index(\"Date\")\n\n_ = all_countries['sh'].plot()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b686a9db-1d4a-4fe6-a878-86d6d5cf24f5","_cell_guid":"4a17120d-d97c-45a6-b04b-d7673f42834f","trusted":true},"cell_type":"code","source":"all_countries = train.groupby(['Date']).agg({'Fatalities': np.sum}).reset_index()\n\nall_countries['sh'] = train.groupby(['Date']).agg({'Fatalities': np.sum}).reset_index().shift(1)['Fatalities']\nall_countries['sh'] = all_countries['Fatalities'] - all_countries['sh']\n\nall_countries = all_countries.set_index(\"Date\")\n\n_ = all_countries['sh'].plot()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"224fbbdb-65ae-4e9b-a515-b66322da40e8","_cell_guid":"b265190d-d8ab-4739-a753-3858c36ef092","trusted":true},"cell_type":"code","source":"test = pd.read_csv(f\"/kaggle/input/covid19-global-forecasting-week-{week}/test.csv\")\ntest.loc[:, 'Date'] = pd.to_datetime(test.loc[:, 'Date'])\ntest_first_date = test.loc[:, 'Date'].values[0]\ntest_last_date = test.loc[:, 'Date'].values[-1]\nprint(f'Test period from {str(test_first_date)[:10]} to {str(test_last_date)[:10]}')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"cd451158-582c-4ed7-889f-91c1c330ed7f","_cell_guid":"7da301d2-4e35-4197-ae9b-93a8cdf3ec40","trusted":true},"cell_type":"code","source":"period = (np.array(test_last_date, dtype='datetime64[D]').astype(np.int64) - np.array(train_last_date, dtype='datetime64[D]').astype(np.int64))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ed2e5820-d61e-4e33-8ab6-e75fda841190","_cell_guid":"2caef017-0933-4b27-a4bc-97d447f51aca","trusted":true},"cell_type":"code","source":"print(f\"Prediction days: {(np.array(test_last_date, dtype='datetime64[D]').astype(np.int64) - np.array(train_last_date, dtype='datetime64[D]').astype(np.int64))+1}\")\nprint(f\"Public set: {(np.array(train_last_date, dtype='datetime64[D]').astype(np.int64) - np.array(test_first_date, dtype='datetime64[D]').astype(np.int64))+1}\")\nprint(f\"Full prediction set: {(np.array(test_last_date, dtype='datetime64[D]').astype(np.int64) - np.array(test_first_date, dtype='datetime64[D]').astype(np.int64))+1}\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"82ca9ff1-6672-42dc-8ab9-c648c4671a20","_cell_guid":"c141265d-f8b7-47bf-8cc4-10bac1286dc1","trusted":true},"cell_type":"code","source":"win = 15\nhor = 1","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"4428a747-d4ad-403c-9482-5fb37219c331","_cell_guid":"05b97d36-e0c3-4b4e-af46-6f74caa53622","trusted":true},"cell_type":"code","source":"base_1 = train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').iloc[-(win+1),:].values\nbase_2 = train.pivot(index='Date', columns=\"geo\", values='Fatalities').iloc[-(win+1),:].values","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"81d35750-2785-4e27-95e4-c8c1a5a9218b","_cell_guid":"54ca2c92-f65d-43d8-87fb-aa4487ad5d1a","trusted":true},"cell_type":"code","source":"#train = train.merge(world_pop.rename(columns={'Country_Region': 'geo'}), how='left', on=['geo'])\n\n#train","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"cc419718-9689-4ed6-943a-90036d36a704","_cell_guid":"fcb1ccf0-8968-4952-8432-74c965a730fe","trusted":true},"cell_type":"code","source":"#train.loc[train['geo'] == 'Diamond Princess', :]","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8ea8847a-3fbc-45a8-8772-e2cce2b3b795","_cell_guid":"e05f9a98-5353-4509-bbcf-4ec7a178d500","trusted":true},"cell_type":"code","source":"#train.loc[train['geo'] == 'MS Zaandam', :]","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b6db71ce-b120-44d6-98b9-2ad816b78fb3","_cell_guid":"1dc07797-1960-43fd-b577-be0b594a5aca","trusted":true},"cell_type":"code","source":"geo_dict = {j:i for i, j in enumerate(train.loc[:, 'geo'].unique())}","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8270d0d4-05a6-4a16-8e3a-b142369cf5dc","_cell_guid":"e13f1c42-0106-4a60-bc57-a1d79eb33c9e","trusted":true},"cell_type":"code","source":"#train = train.loc[train.loc[:, 'geo'].isin(['MS Zaandam', 'Diamond Princess']) == False, :]","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a7c99363-659d-4f16-a842-0971237e1441","_cell_guid":"effe0403-aba8-4d25-8a66-cc7e3b45c0fd","trusted":true},"cell_type":"code","source":"train.loc[:, 'ConfirmedCases'] = ((train.loc[:, 'ConfirmedCases'] - train.groupby('geo')['ConfirmedCases'].shift(periods=1))) #/ np.log(train.loc[:, 'population'])) # * 10000\ntrain.loc[:, 'Fatalities'] = ((train.loc[:, 'Fatalities'] - train.groupby('geo')['Fatalities'].shift(periods=1))) #/ np.log(train.loc[:, 'population'])) #* 100000\n\ntrain = train.groupby('geo').tail(train.groupby('geo').size().values[0]-1)\n\ntrain.loc[train.loc[:, 'ConfirmedCases'] < 0, 'ConfirmedCases'] =  0.0\ntrain.loc[train.loc[:, 'Fatalities'] < 0, 'Fatalities'] = 0.0\ntrain","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b305f0a1-6679-45b0-9053-b772c7c51a76","_cell_guid":"f7328bba-0955-418e-858e-7c1b95a473c7","trusted":true},"cell_type":"code","source":"train_cases = train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').iloc[:-hor,:].values\nvalid_cases = train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').iloc[-(win+hor):,:].values\n\ntrain_fatal = train.pivot(index='Date', columns=\"geo\", values='Fatalities').iloc[:-hor,:].values\nvalid_fatal = train.pivot(index='Date', columns=\"geo\", values='Fatalities').iloc[-(win+hor):,:].values","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"dbb095b1-186d-4f12-a43e-5ee51647657c","_cell_guid":"c4cff73d-b784-4815-b776-23dbbc03a233","trusted":true},"cell_type":"code","source":"train.sort_values(\"Fatalities\").tail(30)#.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').reset_index().","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"959590f7-a9ca-4ef8-b660-87db9c7176a9","_cell_guid":"66bbfec5-452a-48e8-b1bb-eb302311c922","trusted":true},"cell_type":"code","source":"_ = plt.plot(train_cases)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"774a9fd9-c694-4616-93d8-460602c3fd56","_cell_guid":"29f04cc4-cb2d-467d-a3fd-f72dbcbed376","trusted":true},"cell_type":"code","source":"_ = plt.plot(valid_cases)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f2b27f12-7c49-4e7a-94d2-c4e1cfb7cb3c","_cell_guid":"e3db1871-cf0f-456f-a6c9-c2e7b2a92839","trusted":true},"cell_type":"code","source":"_ = plt.plot(train_fatal)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"6c93e337-5d6a-4ca2-8840-7ca0f1657006","_cell_guid":"208d1ff2-2463-48f7-a74f-1bcf5f206c14","trusted":true},"cell_type":"code","source":"_ = plt.plot(valid_fatal)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"2b770e10-b4a6-4943-82e5-7b9faa6c3950","_cell_guid":"f7cdc62a-2297-4b11-805f-d8c081f75b46","trusted":true},"cell_type":"code","source":"%%bash\n\npip install pytorch_lightning","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a9e39c35-3cca-4841-aae6-ae4a2ec9aa52","_cell_guid":"9ebb39b8-6321-422d-a148-b2ffef6cddc5","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.nn.functional as F\nimport pytorch_lightning as ptl\n\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom collections import OrderedDict","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c3ad05fe-c2bb-4ebc-ba3e-8dd350ba0aa1","_cell_guid":"e9c3d586-4b19-41b0-8e07-a6fe90dda2ed","trusted":true},"cell_type":"code","source":"def rmsle(predict, target): \n    return torch.sqrt(((torch.log(predict + 1) - torch.log(target + 1))**2).mean())","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"304ef3d6-d576-4a5e-af8a-177c722c9b08","_cell_guid":"3c812dc1-30d2-4410-b617-34c629838ccb","trusted":true},"cell_type":"code","source":"class MTSFDataset(torch.utils.data.Dataset):\n\n    def __init__(self, window, horizon, set_type, tra, validation):\n        \n        assert type(set_type) == type('str')\n        \n        self.window = window\n        self.horizon = horizon\n        self.tra = tra\n        self.validation = validation\n        self.set_type = set_type\n        \n        if set_type == 'train':\n            rawdata = tra\n        elif set_type == 'validation':\n            rawdata = validation\n\n        _, self.len, self.var_num = rawdata.shape\n        self.sample_num = max(self.len - self.window - self.horizon + 1, 0)\n        self.samples, self.labels = self.__getsamples(rawdata)\n    \n    def __getsamples(self, data):\n        \n        x, y = [], []\n\n        for j in range(len(data)):\n            X = torch.zeros((self.sample_num, self.window, self.var_num))\n            Y = torch.zeros((self.sample_num, 1, self.var_num))#1))#\n\n            for i in range(self.sample_num):\n                start = i\n                end = i + self.window\n                X[i, :, :] = torch.from_numpy(data[j, start:end, :])\n                Y[i, :, :] = torch.from_numpy(data[j, end+self.horizon-1, :])#torch.from_numpy(np.array())#-1])#.reshape(1,1,1)\n            \n            x.append(X)\n            y.append(Y)\n\n        return (torch.cat(x), torch.cat(y))\n\n    def __len__(self):\n        return self.sample_num\n\n    def __getitem__(self, idx):\n        sample = [self.samples[idx, :, :], self.labels[idx, :, :]]\n\n        return sample","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"5e87dc78-4f93-4ce1-99ac-942b93a45ff3","_cell_guid":"cdfb0259-1734-4239-937e-90b1cfb0600e","trusted":true},"cell_type":"code","source":"class ScaledDotProductAttention(nn.Module):\n\n    def __init__(self, temperature, attn_dropout=0.1):\n        super().__init__()\n        self.temperature = temperature\n        self.dropout = nn.Dropout(attn_dropout)\n        self.softmax = nn.Softmax(dim=2)\n\n    def forward(self, q, k, v):\n\n        attn = torch.bmm(q, k.transpose(1, 2))\n        attn = attn / self.temperature\n\n        attn = self.softmax(attn)\n        attn = self.dropout(attn)\n        output = torch.bmm(attn, v)\n\n        return output, attn\n\nclass MultiHeadAttention(nn.Module):\n\n    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n        super().__init__()\n\n        self.n_head = n_head\n        self.d_k = d_k\n        self.d_v = d_v\n\n        self.w_qs = nn.Linear(d_model, n_head * d_k)\n        self.w_ks = nn.Linear(d_model, n_head * d_k)\n        self.w_vs = nn.Linear(d_model, n_head * d_v)\n        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n\n        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5))\n        self.layer_norm = nn.LayerNorm(d_model)\n\n        self.fc = nn.Linear(n_head * d_v, d_model)\n        nn.init.xavier_normal_(self.fc.weight)\n\n        self.dropout = nn.Dropout(dropout)\n\n\n    def forward(self, q, k, v):\n\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n\n        sz_b, len_q, _ = q.size()\n        sz_b, len_k, _ = k.size()\n        sz_b, len_v, _ = v.size()\n\n        residual = q\n\n        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n\n        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k)\n        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k)\n        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v)\n\n        output, attn = self.attention(q, k, v)\n\n        output = output.view(n_head, sz_b, len_q, d_v)\n        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1)\n\n        output = self.dropout(self.fc(output))\n        output = self.layer_norm(output + residual)\n\n        return output, attn\n\nclass PositionwiseFeedForward(nn.Module):\n\n    def __init__(self, d_in, d_hid, dropout=0.1):\n        super().__init__()\n        self.w_1 = nn.Conv1d(d_in, d_hid, 1)\n        self.w_2 = nn.Conv1d(d_hid, d_in, 1)\n        self.layer_norm = nn.LayerNorm(d_in)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        residual = x\n        output = x.transpose(1, 2)\n        output = self.w_2(F.relu(self.w_1(output)))\n        output = output.transpose(1, 2)\n        output = self.dropout(output)\n        output = self.layer_norm(output + residual)\n        return output\n\nclass EncoderLayer(nn.Module):\n\n    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n        super(EncoderLayer, self).__init__()\n        self.slf_attn = MultiHeadAttention(\n            n_head, d_model, d_k, d_v, dropout=dropout)\n        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n\n    def forward(self, enc_input):\n        enc_output, enc_slf_attn = self.slf_attn(\n            enc_input, enc_input, enc_input)\n\n        enc_output = self.pos_ffn(enc_output)\n\n        return enc_output, enc_slf_attn\n\n\nclass DecoderLayer(nn.Module):\n\n    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n        super(DecoderLayer, self).__init__()\n        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n        self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n\n    def forward(self, dec_input, enc_output, non_pad_mask=None, slf_attn_mask=None, dec_enc_attn_mask=None):\n        dec_output, dec_slf_attn = self.slf_attn(\n            dec_input, dec_input, dec_input, mask=slf_attn_mask)\n\n        dec_output, dec_enc_attn = self.enc_attn(\n            dec_output, enc_output, enc_output, mask=dec_enc_attn_mask)\n\n        dec_output = self.pos_ffn(dec_output)\n\n        return dec_output, dec_slf_attn, dec_enc_attn\n\n\nclass Single_Global_SelfAttn_Module(nn.Module):\n\n    def __init__(\n            self,\n            window, n_multiv, n_kernels, w_kernel,\n            d_k, d_v, d_model, d_inner,\n            n_layers, n_head, drop_prob=0.1):\n        '''\n        Args:\n        window (int): the length of the input window size\n        n_multiv (int): num of univariate time series\n        n_kernels (int): the num of channels\n        w_kernel (int): the default is 1\n        d_k (int): d_model / n_head\n        d_v (int): d_model / n_head\n        d_model (int): outputs of dimension\n        d_inner (int): the inner-layer dimension of Position-wise Feed-Forward Networks\n        n_layers (int): num of layers in Encoder\n        n_head (int): num of Multi-head\n        drop_prob (float): the probability of dropout\n        '''\n\n        super(Single_Global_SelfAttn_Module, self).__init__()\n\n        self.window = window\n        self.w_kernel = w_kernel\n        self.n_multiv = n_multiv\n        self.d_model = d_model\n        self.drop_prob = drop_prob\n        self.conv2 = nn.Conv2d(1, n_kernels, (window, w_kernel))\n        self.in_linear = nn.Linear(n_kernels, d_model)\n        self.out_linear = nn.Linear(d_model, n_kernels)\n\n        self.layer_stack = nn.ModuleList([\n            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=drop_prob)\n            for _ in range(n_layers)])\n\n    def forward(self, x, return_attns=False):\n\n        x = x.view(-1, self.w_kernel, self.window, self.n_multiv)\n        x2 = F.relu(self.conv2(x))\n        x2 = nn.Dropout(p=self.drop_prob)(x2)\n        x = torch.squeeze(x2, 2)\n        x = torch.transpose(x, 1, 2)\n        src_seq = self.in_linear(x)\n\n        enc_slf_attn_list = []\n\n        enc_output = src_seq\n\n        for enc_layer in self.layer_stack:\n            enc_output, enc_slf_attn = enc_layer(enc_output)\n            if return_attns:\n                enc_slf_attn_list += [enc_slf_attn]\n\n        if return_attns:\n            return enc_output, enc_slf_attn_list\n        enc_output = self.out_linear(enc_output)\n        return enc_output,\n\n\nclass Single_Local_SelfAttn_Module(nn.Module):\n\n    def __init__(\n            self,\n            window, local, n_multiv, n_kernels, w_kernel,\n            d_k, d_v, d_model, d_inner,\n            n_layers, n_head, drop_prob=0.1):\n        '''\n        Args:\n        window (int): the length of the input window size\n        n_multiv (int): num of univariate time series\n        n_kernels (int): the num of channels\n        w_kernel (int): the default is 1\n        d_k (int): d_model / n_head\n        d_v (int): d_model / n_head\n        d_model (int): outputs of dimension\n        d_inner (int): the inner-layer dimension of Position-wise Feed-Forward Networks\n        n_layers (int): num of layers in Encoder\n        n_head (int): num of Multi-head\n        drop_prob (float): the probability of dropout\n        '''\n\n        super(Single_Local_SelfAttn_Module, self).__init__()\n\n        self.window = window\n        self.w_kernel = w_kernel\n        self.n_multiv = n_multiv\n        self.d_model = d_model\n        self.drop_prob = drop_prob\n        self.conv1 = nn.Conv2d(1, n_kernels, (local, w_kernel))\n        self.pooling1 = nn.AdaptiveMaxPool2d((1, n_multiv))\n        self.in_linear = nn.Linear(n_kernels, d_model)\n        self.out_linear = nn.Linear(d_model, n_kernels)\n\n        self.layer_stack = nn.ModuleList([\n            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=drop_prob)\n            for _ in range(n_layers)])\n\n    def forward(self, x, return_attns=False):\n\n        x = x.view(-1, self.w_kernel, self.window, self.n_multiv)\n        x1 = F.relu(self.conv1(x))\n        x1 = self.pooling1(x1)\n        x1 = nn.Dropout(p=self.drop_prob)(x1)\n        x = torch.squeeze(x1, 2)\n        x = torch.transpose(x, 1, 2)\n        src_seq = self.in_linear(x)\n\n        enc_slf_attn_list = []\n\n        enc_output = src_seq\n\n        for enc_layer in self.layer_stack:\n            enc_output, enc_slf_attn = enc_layer(enc_output)\n            if return_attns:\n                enc_slf_attn_list += [enc_slf_attn]\n\n        if return_attns:\n            return enc_output, enc_slf_attn_list\n        enc_output = self.out_linear(enc_output)\n        return enc_output,\n\nclass AR(nn.Module):\n\n    def __init__(self, window):\n        super(AR, self).__init__()\n        self.linear = nn.Linear(window, 1)\n\n    def forward(self, x):\n        x = torch.transpose(x, 1, 2)\n        x = self.linear(x)\n        x = torch.transpose(x, 1, 2)\n        return x\n\nclass DSANet(ptl.LightningModule):\n\n    def __init__(self, tra, validation, n_multiv, batch_size=16, window=64, local=3, n_kernels=32, \n                 drop_prob=0.1, criterion='rmsle_loss', learning_rate=0.005, horizon=14):\n        \n        super(DSANet, self).__init__()\n\n        self.batch_size = batch_size\n\n        self.window = window\n        self.local = local\n        self.n_multiv = n_multiv\n        self.n_kernels = n_kernels\n        self.w_kernel = 1\n\n        self.d_model = 512\n        self.d_inner = 2048\n        self.n_layers = 6\n        self.n_head = 8\n        self.d_k = 64\n        self.d_v = 64\n        self.drop_prob = drop_prob\n\n        self.criterion = criterion\n        self.learning_rate = learning_rate\n        self.horizon = horizon\n        self.tra = tra\n        self.validation = validation\n\n        self.__build_model()\n\n    def __build_model(self):\n\n        self.sgsf = Single_Global_SelfAttn_Module(\n            window=self.window, n_multiv=self.n_multiv, n_kernels=self.n_kernels,\n            w_kernel=self.w_kernel, d_k=self.d_k, d_v=self.d_v, d_model=self.d_model,\n            d_inner=self.d_inner, n_layers=self.n_layers, n_head=self.n_head, drop_prob=self.drop_prob)\n\n        self.slsf = Single_Local_SelfAttn_Module(\n            window=self.window, local=self.local, n_multiv=self.n_multiv, n_kernels=self.n_kernels,\n            w_kernel=self.w_kernel, d_k=self.d_k, d_v=self.d_v, d_model=self.d_model,\n            d_inner=self.d_inner, n_layers=self.n_layers, n_head=self.n_head, drop_prob=self.drop_prob)\n\n        self.ar = AR(window=self.window)\n        self.W_output1 = nn.Linear(2 * self.n_kernels, 1)\n        self.dropout = nn.Dropout(p=self.drop_prob)\n        self.active_func = nn.Tanh()\n\n    def forward(self, x):\n \n        sgsf_output, *_ = self.sgsf(x)\n        slsf_output, *_ = self.slsf(x)\n        sf_output = torch.cat((sgsf_output, slsf_output), 2)\n        sf_output = self.dropout(sf_output)\n        sf_output = self.W_output1(sf_output)\n\n        sf_output = torch.transpose(sf_output, 1, 2)\n\n        ar_output = self.ar(x)\n\n        output = sf_output + ar_output\n        output[output < 0] = 0.0\n\n        return output\n\n    def loss(self, labels, predictions):\n        if self.criterion == 'l1_loss':\n            loss = F.l1_loss(predictions, labels)\n        elif self.criterion == 'mse_loss':\n            loss = F.mse_loss(predictions, labels)\n        elif self.criterion == 'rmsle_loss':\n            loss = rmsle(predictions, labels)\n        return loss\n\n    def training_step(self, data_batch, batch_i):\n\n        x, y = data_batch\n\n        y_hat = self.forward(x)\n\n        loss_val = self.loss(y, y_hat)\n\n        if self.trainer.use_dp:\n            loss_val = loss_val.unsqueeze(0)\n\n        output = OrderedDict({\n            'loss': loss_val\n        })\n\n        return output\n\n    def validation_step(self, data_batch, batch_i):\n\n        x, y = data_batch\n\n        y_hat = self.forward(x)\n\n        loss_val = self.loss(y, y_hat)\n\n        if self.trainer.use_dp:\n            loss_val = loss_val.unsqueeze(0)\n\n        output = OrderedDict({\n            'val_loss': loss_val,\n            'y': y,\n            'y_hat': y_hat,\n        })\n\n        return output\n\n    def validation_epoch_end(self, outputs):\n\n        loss_sum = 0\n        for x in outputs:\n            loss_sum += x['val_loss'].item()\n        val_loss_mean = loss_sum / len(outputs)\n\n        y = torch.cat(([x['y'] for x in outputs]), 0)\n        y_hat = torch.cat(([x['y_hat'] for x in outputs]), 0)\n\n        num_var = y.size(-1)\n        y = y.view(-1, num_var)\n        y_hat = y_hat.view(-1, num_var)\n        sample_num = y.size(0)\n\n        y_diff = y_hat - y\n        y_mean = torch.mean(y)\n        y_translation = y - y_mean\n\n        val_rrse = torch.sqrt(torch.sum(torch.pow(y_diff, 2))) / torch.sqrt(torch.sum(torch.pow(y_translation, 2)))\n\n        y_m = torch.mean(y, 0, True)\n        y_hat_m = torch.mean(y_hat, 0, True)\n        y_d = y - y_m\n        y_hat_d = y_hat - y_hat_m\n        corr_top = torch.sum(y_d * y_hat_d, 0)\n        corr_bottom = torch.sqrt((torch.sum(torch.pow(y_d, 2), 0) * torch.sum(torch.pow(y_hat_d, 2), 0)))\n        corr_inter = corr_top / corr_bottom\n        val_corr = (1. / num_var) * torch.sum(corr_inter)\n\n        val_mae = (1. / (sample_num * num_var)) * torch.sum(torch.abs(y_diff))\n\n        tqdm_dic = {\n            'val_loss': val_loss_mean,\n            'RRSE': val_rrse.item(),\n            'CORR': val_corr.item(),\n            'MAE': val_mae.item()\n        }\n        return tqdm_dic\n\n    def configure_optimizers(self):\n\n        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n        return [optimizer], [scheduler] \n\n    def __dataloader(self, train):\n\n        set_type = train\n        dataset = MTSFDataset(window=self.window, horizon=self.horizon,\n                              set_type=set_type, \n                              tra=self.tra, validation=self.validation)\n\n        train_sampler = None\n        batch_size = self.batch_size\n\n        should_shuffle = train_sampler is None\n        loader = DataLoader(\n            dataset=dataset,\n            batch_size=batch_size,\n            shuffle=should_shuffle,\n            sampler=train_sampler,\n            num_workers=4\n        )\n\n        return loader\n\n    @ptl.data_loader\n    def train_dataloader(self):\n        return self.__dataloader(train='train')\n\n    @ptl.data_loader\n    def val_dataloader(self):\n        return self.__dataloader(train='validation')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"8845cb1b-ef0f-408d-8c22-c4e9e2db0d57","_cell_guid":"118e68a3-cbb1-4cf4-9d3d-60525cb8f50b","trusted":true},"cell_type":"code","source":"model_cases = DSANet(np.array([train_fatal, train_cases]), np.array([valid_fatal, valid_cases]), train_cases.shape[1], window=win, \n                     learning_rate=0.01, horizon=hor, drop_prob=0.5, batch_size=128)\n\ntrainer = ptl.Trainer(val_check_interval=1, max_steps=10000, gpus=1, show_progress_bar=False) \ntrainer.fit(model_cases)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"2b56b578-6bea-443b-8c5a-965a8e516b61","_cell_guid":"6c458d08-8b28-4194-96c2-f882e2283ff2","trusted":true},"cell_type":"code","source":"from glob import glob\n\nsd = torch.load(glob(\"/kaggle/working/lightning_logs/version_0/checkpoints/*.ckpt\")[0])\nmodel_cases.load_state_dict(sd['state_dict'])","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"17ef64ad-36c2-43ab-97a9-98e9f944905e","_cell_guid":"c87c6588-0417-4942-9a5f-46db54f4a7ac","trusted":true},"cell_type":"code","source":"#(train.pivot(index='Date', columns=\"geo\", values='Fatalities').iloc[-win:,:].values * \\\n#np.log(train.pivot(index='Date', columns=\"geo\", values='population').iloc[-win:,:].values)) #/ 100000","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"70ea1673-1dba-4300-a64a-d01de4fe4cf6","_cell_guid":"3a421e37-8054-493d-8b89-c7b4ee0caeed","trusted":true},"cell_type":"code","source":"input = np.array([\n    train.pivot(index='Date', columns=\"geo\", values='Fatalities').iloc[-win:,:].values,\n    train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').iloc[-win:,:].values\n])\n\nfor i in range(period+1):\n    \n    ins = torch.tensor(input[:, -win:, :]).cuda()\n    pred = model_cases(ins.float())\n    \n    input = np.concatenate([input, np.array(pred.detach().cpu().numpy(), dtype=np.int)], axis=1)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"efce80a4-2dad-4537-90ef-2b030315d80d","_cell_guid":"a2d6b9d3-d346-42c2-9526-f0e54d82aa07","trusted":true},"cell_type":"code","source":"#input.max()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c9cb19be-4608-4301-a795-f35bd47013db","_cell_guid":"f63124a0-5ee8-40ca-97b6-4d92ba97a613","trusted":true},"cell_type":"code","source":"#input = input * np.log(train.pivot(index='Date', columns=\"geo\", values='population').iloc[win:,:].values[0, :]) #/ 100000","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"58f3808a-df34-4eb3-b8f4-86a184717436","_cell_guid":"938d4d1b-81d7-4419-9a17-e4a1a2dc347d","trusted":true},"cell_type":"code","source":"pred_size = (np.array(test_last_date, dtype='datetime64[D]').astype(np.int64) - np.array(test_first_date, dtype='datetime64[D]').astype(np.int64))+1","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"1399f928-3a8e-4d1c-a103-57dbdcc38c79","_cell_guid":"49df6efb-30f8-429a-a878-8e1ba71d267b","trusted":true},"cell_type":"code","source":"pd.DataFrame(np.array(input[1,:,:].cumsum(0) + base_1, \n                      dtype=np.int)[-pred_size:,:], \n             columns=train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').columns).loc[:, ['US_New York', 'Ukraine', 'Italy', 'Spain']]","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"400aded5-26cd-42a7-95df-5ff9e81c410d","_cell_guid":"df8a34a9-858a-44e5-975d-2167e5c46142","trusted":true},"cell_type":"code","source":"pd.DataFrame(np.array(input[0, :, :].cumsum(0) + base_2, \n                      dtype=np.int)[-pred_size:,:], \n             columns=train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').columns).loc[:, ['US_New York', 'Ukraine', 'Italy', 'Spain']]","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"cfd5435c-75fe-41c4-8fc2-9796b4d58420","_cell_guid":"c493e4b7-e37c-4ec4-bc59-5d7d7c62d9f9","trusted":true},"cell_type":"code","source":"input[1, :, :] = input[1, :, :].cumsum(0) + base_1\ninput[0, :, :] = input[0, :, :].cumsum(0) + base_2","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"036dfbc0-671f-4922-824b-016b630c4fb4","_cell_guid":"f858c77d-767a-4e3e-be06-fda64b99a71f","trusted":true},"cell_type":"code","source":"import datetime \n\ndef prov(i):\n    try:\n        return i.split(\"_\")[1]\n    except:\n        return None\n\nres = pd.DataFrame(input[0, -pred_size:,:], columns=train.pivot(index='Date', columns=\"geo\", values='Fatalities').columns).unstack().reset_index(name='Fatalities') \\\n    .merge(\n    pd.DataFrame(input[1, -pred_size:,:], columns=train.pivot(index='Date', columns=\"geo\", values='ConfirmedCases').columns).unstack().reset_index(name='ConfirmedCases'),\n          how='left', on=['geo', 'level_1']\n)\n\nres['Date'] = [test.Date[0] + datetime.timedelta(days=i) for i in res['level_1']]\nres['Province_State'] = [prov(i) for i in res['geo']]\nres['Country_Region'] = [i.split(\"_\")[0] for i in res['geo']]\n\nres","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c5876e8c-4d47-417f-ae85-fd60b75ba8e9","_cell_guid":"6ba39355-664d-4a7f-8250-d10247fe4522","trusted":true},"cell_type":"code","source":"sub = pd.read_csv(f\"/kaggle/input/covid19-global-forecasting-week-{week}/submission.csv\")\n\nsub = test.merge(res, how='left', on=['Date', 'Province_State', 'Country_Region']).loc[:, [\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]]\n\nsub['Fatalities'] = np.array(sub['Fatalities'], dtype=np.int)\nsub[\"ConfirmedCases\"] = np.array(sub[\"ConfirmedCases\"], dtype=np.int)\n\nsub","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c0fdde33-a254-4224-9282-a5a8003dc01f","_cell_guid":"f7d0118f-d0b7-4a7c-b98e-04345ddbf731","trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}