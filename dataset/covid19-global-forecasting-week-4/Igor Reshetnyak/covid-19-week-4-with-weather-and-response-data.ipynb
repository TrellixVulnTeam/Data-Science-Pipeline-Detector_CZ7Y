{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.graph_objects as go\npy.init_notebook_mode()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT=1\noptimize_model=False\n\noptimize_model_2=False\n\nMake_submission=True\n\nMake_DT_test=False\n\n\nmax_depth=2\nmin_child_weight=3.5\nn_estimators=1200\nlearning_rate=0.1\n\n\n\nmax_depth_2=2\nmin_child_weight_2=1\nn_estimators_2=100\nlearning_rate_2=0.05\n\n\nROOT_DIR=\"/kaggle/input/covid19-global-forecasting-week-4/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(ROOT_DIR+\"train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For some countries we also have data for individual regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"have_states=train[train['Province_State'].notna()].groupby(['Country_Region'], sort=False)['Province_State'].nunique()\nprint(have_states)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"US data prior to March 10 is wrongly set to 0. So update using NY Times"},{"metadata":{"trusted":true},"cell_type":"code","source":"NY_data=pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')\nalt_initial=NY_data.groupby(['date','state'])[['cases','deaths']].sum().reset_index(drop=False)\nUS_data_to_add=alt_initial[alt_initial['date']<'2020-03-10']\nUS_data_to_add['Country_Region']='US'\nUS_data_to_add.set_index(['date','state','Country_Region'],drop=True,inplace=True)\ntrain=train.merge(US_data_to_add,left_on=['Date','Province_State','Country_Region'],right_index=True,how='left')\ntrain.loc[train['cases'].notnull(),'ConfirmedCases']=train['cases']\ntrain.loc[train['deaths'].notnull(),'Fatalities']=train['deaths']\ntrain.drop(columns=['cases','deaths'],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['Country_Region']=='US') & (train['ConfirmedCases']>0)].groupby(['Province_State'])['Date'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping country names and provinces into variable - location. Adding a true/false variable for Islands."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def add_location(df_old):\n    df=df_old.copy()\n    df['Date']=pd.to_datetime(df['Date'])\n    df['Country_Region']=df['Country_Region'].fillna('')\n    df['Province_State']=df['Province_State'].fillna('')\n    df['location']=df['Province_State'].astype('str')+\" \"+df['Country_Region'].astype('str')\n    \n    df['Island']=False \n    df.loc[df['Province_State'].str.contains(\"Islan\"),'Island']=True\n    df.loc[df['Province_State'].isin(['French Polynesia',\n       'Guadeloupe', 'Martinique', 'Mayotte', 'New Caledonia', 'Reunion',\n       'Saint Barthelemy','Anguilla', 'Bermuda','Isle of Man', 'Montserrat','Aruba',\n       'Curacao','Bonaire, Sint Eustatius and Saba','Saint Pierre and Miquelon','Greenland',\n                                     'Hawaii']),'Island']=True \n    \n    df.loc[df['Country_Region'].isin(['Diamond Princess', 'MS Zaandam']),'Island']=True \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_location(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['Province_State']!=\"\") & (train['Island']==False)]['Province_State'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Locations with less than 5 cases:"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_cases_old=train[train['Date']<'2020-04-05'].groupby(['location'], sort=False)['ConfirmedCases'].max()\nmax_cases=train.groupby(['location'], sort=False)['ConfirmedCases'].max()\nprint(\"Now: {}\\r\\nSeven Days ago: {}\".format(len(max_cases[max_cases<5]),len(max_cases_old[max_cases_old<5])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_cases[max_cases<5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index('location',inplace=True)\n\ntrain['day_of_year']=train['Date'].dt.dayofyear\ntrain['day_of_week']=train['Date'].dt.dayofweek\n\n\nfirst_day=train[(train['ConfirmedCases']>0)].groupby(['location'], sort=False)['day_of_year'].min()\nfirst_day.rename('first_day',inplace=True)\n\nday_ten=train[(train['ConfirmedCases']>10)].groupby(['location'], sort=False)['day_of_year'].min()\nday_ten.rename('day_ten',inplace=True)\n\nday_hundred=train[(train['ConfirmedCases']>100)].groupby(['location'], sort=False)['day_of_year'].min()\nday_hundred.rename('day_hundred',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_days_passed(df_old,first_day,day_ten,day_hundred):\n    df=df_old.copy()\n    df=pd.concat([df,first_day],axis=1,join='inner')\n    \n    df['days_passed']=df['day_of_year']-df['first_day']\n    df.drop(columns=['first_day'],inplace=True)\n    \n    #print(first_day) \n    \n    \n    df.loc[df['days_passed']<0,'days_passed']=-1\n    \n    df=df.merge(day_ten,left_index=True,right_index=True,how=\"outer\")\n    \n    df['days_passed_10']=df['day_of_year']-df['day_ten']\n    df.loc[df['day_ten'].isna(),'days_passed_10']=-1\n    df.loc[df['days_passed_10']<0,'days_passed_10']=-1\n    df.drop(columns=['day_ten'],inplace=True)\n    \n    df=df.merge(day_hundred,left_index=True,right_index=True,how=\"outer\")\n    \n    df['days_passed_100']=df['day_of_year']-df['day_hundred']\n    df.loc[df['day_hundred'].isna(),'days_passed_100']=-1\n    df.loc[df['days_passed_100']<0,'days_passed_100']=-1\n    df.drop(columns=['day_hundred'],inplace=True)\n   \n    df['location']=df.index\n    \n    df.loc[df['location']=='Hubei China','days_passed']+=35\n    df.loc[df['location']=='Hubei China','days_passed_10']+=22\n    df.loc[df['location']=='Hubei China','days_passed_100']+=4\n    \n    df.set_index('Id',inplace=True)\n    df['Id']=df.index\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_days_passed(train,first_day,day_ten,day_hundred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_first_day=train[train['days_passed']==0].groupby(['location'])[['ConfirmedCases']].min()\ncases_first_day.rename(columns={'ConfirmedCases':'Cases_first_day'},inplace=True)\n#print(cases_first_day)\ncases_seven_day=train[train['days_passed']==7].groupby(['location'])[['ConfirmedCases']].min()\ncases_seven_day.rename(columns={'ConfirmedCases':'Cases_seven_day'},inplace=True)\n#print(cases_six_day)\n    \ndef add_first_days(old_df,cases_first_day,cases_seven_day):\n    df=old_df.copy()\n    \n    df=df.merge(cases_first_day,left_on=['location'],right_index=True,how=\"left\")\n    \n    df['Cases_first_day']=np.log1p(df['Cases_first_day'])\n    df.loc[df['days_passed']<0,'Cases_first_day']=-1\n    df.loc[df['location']=='Hubei China','Cases_first_day']=1 \n    \n    df=df.merge(cases_seven_day,left_on=['location'],right_index=True,how=\"left\")\n    \n    df['Cases_seven_day']=np.log1p(df['Cases_seven_day'])\n    df.loc[df['days_passed']<0,'Cases_seven_day']=-1\n    df.loc[df['location']=='Hubei China','Cases_seven_day']=3\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_first_days(train,cases_first_day,cases_seven_day)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stat=pd.read_csv('../input/countryinfo/covid19countryinfo.csv')\ncountry_stat = country_stat[country_stat['region'].isnull()] \n\nus_stat=pd.read_csv('../input/covid19-state-data/COVID19_state.csv')\nus_stat.rename(columns={'State':'location','Population':'pop','Pop Density':'density','Smoking Rate':'smokers','Respiratory Deaths':'lung'},inplace=True)\nus_stat['location']+=\" US\"\nus_stat.set_index('location',inplace=True)\n\ncountry_metadata=pd.read_csv(\"../input/covid19-forecasting-metadata/region_metadata.csv\")\ncountry_metadata['location']=country_metadata['Province_State'].astype('str')+\" \"+country_metadata['Country_Region'].astype('str')\ncountry_metadata.rename(columns={'population':'pop'},inplace=True)\ncountry_metadata.set_index('location',inplace=True)\n\n\ndef add_country_stat(old_df,country_stat,us_stat,country_metadata):\n    df=old_df.copy()\n    df=df.merge(country_stat[['country','pop','medianage','sex65plus','lung','smokers','density']],left_on=['Country_Region'],right_on=['country'],how='left')\n    df.drop(columns=['country'],inplace=True)\n    \n    df['pop']=df['pop'].fillna(1000)\n    df['pop']=df['pop'].apply(lambda x: int(str(x).replace(',', '')))\n    \n    #df['gdp2019']=df['gdp2019'].fillna(0)\n    #df['gdp2019']=df['gdp2019'].apply(lambda x: int(str(x).replace(',', '')))\n    #df['gdp2019']=df['gdp2019']/df['pop']\n    \n    \n    df['density']=df['density'].fillna(0)\n    df['medianage']=df['medianage'].fillna(0) #highly correlated with Temperature... \n    #df['sexratio']=df['sexratio'].fillna(1)\n    df['sex65plus']=df['sex65plus'].fillna(1)\n    df['lung']=df['lung'].fillna(24)\n    df['smokers']=df['smokers'].fillna(24)\n    #df['lung']=df['lung']*df['pop']\n    \n    df.set_index('location',inplace=True)\n    df.update(us_stat[['pop','density','smokers','lung']])\n    \n    df.update(country_metadata[['pop','density']])\n    \n    df['pop']=np.log1p(df['pop'])\n    \n    df['location']=df.index\n    df.set_index('Id',inplace=True)\n    df['Id']=df.index\n    \n    \n    \n    return df\n    \n\ntrain=add_country_stat(train,country_stat,us_stat,country_metadata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_stat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_info=pd.read_csv(\"../input/climate-change-earth-surface-temperature-data/GlobalLandTemperaturesByCountry.csv\")\nweather_info['dt']=pd.to_datetime(weather_info['dt'])\nweather_info=weather_info[weather_info['dt']>'2000-12-30']\nweather_info['month']=weather_info['dt'].dt.month\nweather_info.drop(weather_info[weather_info['Country'].isin(\n    ['Denmark', 'France', 'Netherlands','United Kingdom'])].index,axis=0,inplace=True)\n\nweather_info.replace(\n   ['Denmark (Europe)', 'France (Europe)', 'Netherlands (Europe)', 'United Kingdom (Europe)'],\n   ['Denmark', 'France', 'Netherlands', 'United Kingdom'],inplace=True)\n\nweather_info.replace({\n    'Antigua And Barbuda':'Antigua and Barbuda',\n    'Bosnia And Herzegovina':'Bosnia and Herzegovina',\n    'Congo (Democratic Republic Of The)':'Congo (Kinshasa)',\n    'Congo':'Congo (Brazzaville)',\n    'Palestina':'West Bank and Gaza',\n    'Cape Verde':'Cabo Verde',\n    \"Côte D'Ivoire\":\"Cote d'Ivoire\",\n    'Trinidad And Tobago':'Trinidad and Tobago',\n    'Saint Kitts And Nevis':'Saint Kitts and Nevis',\n    'Czech Republic':'Czechia',\n    'Swaziland':'Eswatini',\n    'Guinea Bissau':'Guinea-Bissau',\n    'South Korea':'Korea, South', \n    'Macedonia':'North Macedonia',\n    'Saint Vincent And The Grenadines':'Saint Vincent and the Grenadines',\n    'Sao Tome And Principe':'Sao Tome and Principe',\n    'Taiwan':'Taiwan*', \n    'Timor Leste':'Timor-Leste',\n    'United States':'US'\n},inplace=True)\nweather_country=weather_info.groupby(['Country','month'])['AverageTemperature'].mean()\n\n\nstate_weather_info=pd.read_csv(\"../input/climate-change-earth-surface-temperature-data/GlobalLandTemperaturesByState.csv\")\nstate_weather_info.replace({'United States':'US','Georgia (State)':'Georgia','District Of Columbia':'District of Columbia'},inplace=True)\nstate_weather_info['dt']=pd.to_datetime(state_weather_info['dt'])\nstate_weather_info=state_weather_info[state_weather_info['dt']>'2000-12-30']\nstate_weather_info['month']=state_weather_info['dt'].dt.month\nweather_state=state_weather_info[state_weather_info['Country'].isin(have_states.index)].groupby(['Country','State','month'])['AverageTemperature'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_temperature(old_df,weather_country,weather_state):\n    df=old_df.copy()\n    df['Month']=df['Date'].dt.month\n    df=df.merge(weather_country,how=\"left\",left_on=['Country_Region','Month'],right_index=True)\n    df=df.merge(weather_state,how=\"left\",left_on=['Country_Region','Province_State','Month'],right_index=True)\n    df.loc[df['AverageTemperature_y'].notnull(),'AverageTemperature_x']=df['AverageTemperature_y']\n    \n    inhirit=[['Holy See','Italy'],['South Sudan','Sudan'],['Kosovo','Serbia'],['Brunei','Malaysia'],['Maldives','Sri Lanka']]\n    \n    for pairs in inhirit:\n        for m in df['Month'].unique():\n            df.loc[(df['Country_Region']==pairs[0]) & (df['Month']==m),'AverageTemperature_x']=df.loc[(df['Country_Region']==pairs[0]) & (df['Month']==m)]['AverageTemperature_x'].fillna(weather_country[(pairs[1],m)])\n        \n    df.drop(columns=['AverageTemperature_y','Month'],inplace=True)\n    df.rename(columns={'AverageTemperature_x':'AverageTemperature'},inplace=True)\n        \n    \n    return df\n\ntrain=add_temperature(train,weather_country,weather_state)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['AverageTemperature'].isnull()]['Country_Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"border_info=pd.read_csv(\"../input/country-borders/border_info.csv\")\n#border_info.drop(columns=[\"country_code\",\"country_border_code\"],inplace=True)\nborder_info.replace({'United States of America':'US',\n                    'United Kingdom of Great Britain and Northern Ireland':'United Kingdom',\n                    'Bolivia (Plurinational State Of)':'Bolivia',\n                    'Brunei Darussalam':'Brunei',\n                    'Gambia (the)':'Gambia',\n                     'Congo (the Democratic Republic of the)':'Congo (Kinshasa)',\n                     'Cote d’Ivoire':\"Cote d'Ivoire\",\n                     \"Iran (Islamic Republic of)\":'Iran',\n                     \"Korea (the Republic of)\":'Korea, South',\n                    \"Lao People's Democratic Republic\":'Laos',\n                     \"Moldova (the Republic of)\":'Moldova',\n                     'Myanmar':'Burma',\n                     'Palestine, State of':'West Bank and Gaza',\n                     \"Russian Federation\":'Russia',\n                    \"Syrian Arab Republic\":'Syria',\n                     \"Taiwan (Province of China)\":'Taiwan*',\n                    \"Tanzania (the United Republic of)\":'Tanzania',\n                     \"Venezuela (Bolivarian Republic of)\":'Venezuela',\n                     \"Viet Nam\":'Vietnam'},inplace=True)\nborder_info=border_info.fillna(\"\")\n\nborder_info=pd.concat([border_info,pd.DataFrame({'country_name':[\"Kosovo\",\"Kosovo\",\"Kosovo\",\"Congo (Brazzaville)\",\"Congo (Brazzaville)\",\"Congo (Brazzaville)\",\"Congo (Brazzaville)\",\"Montenegro\",\"Serbia\",\"North Macedonia\",\"Congo (Kinshasa)\",\"Gabon\",\"Cameroon\",\"Central African Republic\"],\n                                                'country_border_name':[\"Montenegro\",\"Serbia\",\"North Macedonia\",\"Congo (Kinshasa)\",\"Gabon\",\"Cameroon\",\"Central African Republic\",\"Kosovo\",\"Kosovo\",\"Kosovo\",\"Congo (Brazzaville)\",\"Congo (Brazzaville)\",\"Congo (Brazzaville)\",\"Congo (Brazzaville)\"]})],axis=0)\n\n\n\n#border_info.to_csv(\"border_info.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set(border_info['country_name'].unique()).difference(set(train['Country_Region'].unique()))\nset(train['Country_Region'].unique()).difference(set(border_info['country_name'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"islands=border_info[border_info['country_border_name']=='']['country_name'].unique()\nislands=np.delete(islands,np.where(islands==\"Australia\"))\ntrain.loc[train['Country_Region'].isin(islands),'Island']=True ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"response_info=pd.read_csv(\"../input/oxford-gouvernement-response-tracker/OxCGRT_Download_150420_152128_Full.csv\")\nresponse_info['Date']=pd.to_datetime(response_info['Date'], format='%Y%m%d', errors='ignore')\nresponse_info['Date']=response_info['Date'].dt.dayofyear\ntravel_control=response_info[response_info['S7_International travel controls']>1].groupby(['CountryName'])['Date'].min()\ntravel_control=travel_control.rename('Date_travel_restriction')\n#travel_control=response_info[response_info['S2_Workplace closing']>1].groupby(['CountryName'])['Date'].min()\ntravel_control_1=response_info[(response_info['S6_Restrictions on internal movement']>1)].groupby(['CountryName'])['Date'].min()\ntravel_control_1=travel_control_1.rename('Date_travel_restriction_1')\n#travel_control_2=response_info[response_info['S3_Cancel public events']>1].groupby(['CountryName'])['Date'].min()\n#travel_control_2=travel_control_2.rename('Date_travel_restriction_2')\ntravel_control=pd.concat([travel_control,travel_control_1],axis=1,sort=True)\n\n\ndef add_restriction_info(old_df,travel_control):\n    df=old_df.copy()\n    df=df.merge(travel_control,left_on='Country_Region',right_index=True,how=\"left\")\n    df['days_since_restriction']=df['day_of_year']-df['Date_travel_restriction']\n    df.loc[df['days_since_restriction']<0,'days_since_restriction']=-1\n    df.loc[df['Date_travel_restriction'].isna(),'days_since_restriction']=-1\n\n    df['days_since_restriction_1']=df['day_of_year']-df['Date_travel_restriction_1']\n    df.loc[df['days_since_restriction_1']<0,'days_since_restriction_1']=-1\n    df.loc[df['Date_travel_restriction_1'].isna(),'days_since_restriction_1']=-1\n\n#train['days_since_restriction_2']=train['day_of_year']-train['Date_travel_restriction_2']\n#train.loc[train['days_since_restriction_2']<0,'days_since_restriction_2']=-1\n#train.loc[train['Date_travel_restriction_2'].isna(),'days_since_restriction_2']=-1\n\n    df.drop(columns=['Date_travel_restriction','Date_travel_restriction_1'],inplace=True)\n    \n    return df\n\ntrain=add_restriction_info(train,travel_control)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"response_info.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product as it_product\ndef expand_grid(data_dict):\n  rows = it_product(*data_dict.values())\n  return pd.DataFrame.from_records(rows, columns=data_dict.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skel=expand_grid({'Index':border_info.index,'Date':train['Date'].unique()})\n\ncountry_info=train.groupby(['Date','Country_Region'])['ConfirmedCases'].sum()\n\nskel=skel.merge(border_info, how='inner', left_on=['Index'],right_index=True)\nskel=skel.merge(country_info, how='inner', \n                left_on=['Date','country_border_name'],right_on=['Date','Country_Region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta\nskel['Date']=skel['Date']+timedelta(days=DT)\nborder_cases=skel.groupby(['country_name','Date'])['ConfirmedCases'].sum()\nlen(skel['country_name'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.merge(border_cases, how='left', left_on=['Country_Region','Date'],right_on=['country_name','Date'])\ntrain['ConfirmedCases_y']=train['ConfirmedCases_y'].fillna(0)\ntrain.rename(columns={'ConfirmedCases_y':'ConfirmedCases_neighbors','ConfirmedCases_x':'ConfirmedCases'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train = pd.concat([train,pd.get_dummies(train['location'], prefix='loc')],axis=1)\nbig_train['ConfirmedCases_neighbors']=np.log1p(big_train['ConfirmedCases_neighbors'])\nbig_train.reset_index(inplace=True)\nbig_train.drop(columns=[\"Id\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_add_deltas(df_old):\n    df=df_old.copy()\n    df=df.sort_values(by=['location', 'Date'])\n    \n    df['growth_ConfirmedCases_neighbors']=df.groupby(['location'])['ConfirmedCases_neighbors'].diff()\n    \n    df['d_ConfirmedCases'] = df.groupby(['location'])['ConfirmedCases'].diff()\n    df['d_Fatalities'] = df.groupby(['location'])['Fatalities'].diff()\n    \n        \n    df.loc[df['d_Fatalities']<0,'d_Fatalities']=0\n    df.loc[df['d_ConfirmedCases']<0,'d_ConfirmedCases']=0\n    \n    df['prev_ConfirmedCases']=df['ConfirmedCases']-df['d_ConfirmedCases']\n    df['prev_Fatalities']=df['Fatalities']-df['d_Fatalities']\n    \n      \n    df['growth_ConfirmedCases']=df['d_ConfirmedCases']/(df['prev_ConfirmedCases']+1)\n    df['growth_Fatalities']=df['d_Fatalities']/(df['prev_Fatalities']+1)\n    \n    df['growth_ConfirmedCases']=np.log1p(df['growth_ConfirmedCases'])\n    df['growth_Fatalities']=np.log1p(df['growth_Fatalities'])\n    \n    df['prev_ConfirmedCases']=np.log1p(df['prev_ConfirmedCases'])\n    df['prev_Fatalities']=np.log1p(df['prev_Fatalities'])\n    \n    #df.drop(columns=['prev_ConfirmedCases','prev_Fatalities'], inplace=True)\n    \n    first_day_stat=df[df['Date']=='2020-01-22']\n    \n    df.drop(df[df['Date']=='2020-01-22'].index, inplace=True)\n    \n    return df,first_day_stat\n\nbig_train,first_day_stat=df_add_deltas(big_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=big_train.drop(columns=['Province_State','Country_Region','Date','ConfirmedCases','Fatalities','location',\n                          'd_ConfirmedCases','d_Fatalities','growth_ConfirmedCases','growth_Fatalities'])\n\ny=big_train['d_ConfirmedCases']\ny_2=big_train['d_Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_day=X['day_of_year'].max()\nmask_train=X['day_of_year']<max_day-DT+1\nmask_test=X['day_of_year']>=max_day-DT+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X[mask_train]\nX_test=X[mask_test]\n\n\ny_train=y[mask_train]\ny_test=y[mask_test]\n\ny_train_2=y_2[mask_train]\ny_test_2=y_2[mask_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test['day_of_year'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\ncorr = big_train[['d_ConfirmedCases','d_Fatalities','days_passed','ConfirmedCases_neighbors','pop',\n                  'medianage','sex65plus','lung','smokers','density','Island','growth_ConfirmedCases',\n                  'growth_Fatalities','AverageTemperature','days_passed_10'#,'prev_ConfirmedCases','prev_Fatalities'\n                 ]].corr(\"spearman\")\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(12,12))\n    ax = sns.heatmap(corr, annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(big_train[(big_train['growth_ConfirmedCases']==0)]['growth_ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(big_train[(big_train['growth_ConfirmedCases']>0)]['growth_ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train[(big_train['growth_ConfirmedCases']>0) & (big_train['growth_ConfirmedCases']<=1)]['growth_ConfirmedCases'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train[(big_train['growth_ConfirmedCases']<2) & (big_train['Country_Region']=='Italy')],x='Date',y='growth_ConfirmedCases')\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train[(big_train['Country_Region']=='Italy')],x='Date',y='d_ConfirmedCases')\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train,x='days_passed',y='d_ConfirmedCases')\nfig1.update_layout(yaxis_type=\"log\")\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a rather good distinction between countries with a lot of cases in their neighbors and those with only a little."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train,x='days_passed_10',y='d_ConfirmedCases',color='ConfirmedCases_neighbors')\nfig1.update_layout(yaxis_type=\"log\")\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train[big_train['Country_Region']!='China'],x='days_since_restriction',y='d_ConfirmedCases',color='location')\nfig1.update_layout(yaxis_type=\"log\")\n\ntrend=big_train[big_train['Country_Region']!='China'][big_train['days_since_restriction']<70].groupby('days_since_restriction')['d_ConfirmedCases'].mean()\n\nfig1.add_trace(go.Scatter(\n        x=trend.index,\n        y=trend,\n        mode=\"lines\",\n        line=go.scatter.Line(color=\"red\"),\n        showlegend=False))\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train[big_train['Country_Region']!='China'],x='days_since_restriction_1',y='d_ConfirmedCases',color='location')\nfig1.update_layout(yaxis_type=\"log\")\n\ntrend=big_train[big_train['Country_Region']!='China'][big_train['days_since_restriction_1']<70].groupby('days_since_restriction_1')['d_ConfirmedCases'].mean()\n\nfig1.add_trace(go.Scatter(\n        x=trend.index,\n        y=trend,\n        mode=\"lines\",\n        line=go.scatter.Line(color=\"red\"),\n        showlegend=False))\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(columns=['day_of_year'],inplace=True)  #including day of year makes things worse RMLSE goes up from 0.49 to 0.7\nX_test.drop(columns=['day_of_year'],inplace=True)   #including day of year makes things worse RMLSE goes up from 0.49 to 0.7\n\nX_train.drop(columns=['day_of_week'],inplace=True)  #including day of week makes things worse RMLSE goes up from 0.49 to 0.57\nX_test.drop(columns=['day_of_week'],inplace=True)   #including day of week makes things worse RMLSE goes up from 0.49 to 0.57\n\nX.drop(columns=['day_of_year'],inplace=True)  \nX.drop(columns=['day_of_week'],inplace=True)   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(columns=['index'],inplace=True)   \nX_train.drop(columns=['index'],inplace=True)\nX_test.drop(columns=['index'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = xgb.XGBRegressor(n_estimators=n_estimators,\n    max_depth=max_depth,\n    min_child_weight=min_child_weight,\n    learning_rate=learning_rate,\n    random_state=42)\nreg_2 = xgb.XGBRegressor(n_estimators=n_estimators_2,\n    max_depth=max_depth_2,\n    min_child_weight=min_child_weight_2,\n    learning_rate=learning_rate_2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    reg.fit(X_train,np.log1p(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    plot = xgb.plot_importance(reg, max_num_features=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    y_pred = reg.predict(X_test)\n    np.sqrt(mean_squared_error(y_pred,np.log1p(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    X_train_2=X_train.copy().drop(columns=['medianage','density'])\n    X_train_2['d_confirmed']=np.log1p(y_train)  \n    X_test_2=X_test.copy().drop(columns=['medianage','density'])\n    X_test_2['d_confirmed']=y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    reg_2.fit(X_train_2,np.log1p(y_train_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    plot = xgb.plot_importance(reg_2, max_num_features=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_DT_test:\n    y_pred_2 = reg_2.predict(X_test_2)\n    np.sqrt(mean_squared_error(y_pred_2,np.log1p(y_test_2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train=big_train.drop(columns=[\"index\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(ROOT_DIR+\"test.csv\")\ntest.rename(columns={'ForecastId':'Id'},inplace=True)\ntest=add_location(test)\n\ntest.set_index('location',inplace=True)\n\ntest['day_of_year']=test['Date'].dt.dayofyear\ntest['day_of_week']=test['Date'].dt.dayofweek\ntest=add_days_passed(test,first_day,day_ten,day_hundred)\ntest=add_first_days(test,cases_first_day,cases_seven_day)\ntest=add_country_stat(test,country_stat,us_stat,country_metadata)\ntest=add_temperature(test,weather_country,weather_state)\ntest.loc[train['Country_Region'].isin(islands),'Island']=True \ntest=add_restriction_info(test,travel_control)\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_prediction(old_big_train,old_test,border_info,verbosity=0):\n\n    big_train=old_big_train.copy()\n    test=old_test.copy()\n    \n\n    known=big_train['Date'].unique()\n    \n    days_to_predict=test['Date'].unique()\n    days_to_predict.sort()\n\n\n    results=[]\n    full_results=[]\n\n    for d in days_to_predict:\n        if verbosity>0: print(\"Predicting {}\".format(d))\n        if d in known:\n            if verbosity>0: print(\"Data Known\")\n        \n            X=big_train.drop(columns=['Province_State','Country_Region','ConfirmedCases','Fatalities','location','Date',\n                                  'day_of_year','day_of_week','d_ConfirmedCases','d_Fatalities','growth_Fatalities',\n                                      'growth_ConfirmedCases'])\n\n            y=big_train['d_ConfirmedCases']\n            y_2=big_train['d_Fatalities']\n        \n            mask_train=big_train['Date']<d\n            mask_val=big_train['Date']==d\n        \n            X_train=X[mask_train]\n            y_train=y[mask_train]\n            y_train_2=y_2[mask_train]\n        \n            X_val=X[mask_val]\n            y_val=y[mask_val]\n            y_val_2=y_2[mask_val]\n        \n            reg = xgb.XGBRegressor(n_estimators=n_estimators,\n                                   max_depth=max_depth,\n                                   min_child_weight=min_child_weight,\n                                   learning_rate=learning_rate,\n                                   #subsample=0.95,\n                                   random_state=42)\n            reg_2 = xgb.XGBRegressor(n_estimators=n_estimators_2,\n                                   max_depth=max_depth_2,\n                                   min_child_weight=min_child_weight_2,\n                                   learning_rate=learning_rate_2,random_state=42)\n        \n            reg.fit(X_train,np.log1p(y_train))\n        \n            y_pred = reg.predict(X_val)\n            if verbosity>0: print(\"MSLE {}\".format(mean_squared_error(y_pred,np.log1p(y_val))))\n        \n            X_train_2=X_train.copy().drop(columns=['medianage','density'])\n            X_train_2['d_ConfirmedCases']=np.log1p(y_train)  #0.4412899060661785 <- without , with - 0.4463  \n            X_val_2=X_val.copy().drop(columns=['medianage','density'])\n            X_val_2['d_ConfirmedCases']=y_pred\n        \n            reg_2.fit(X_train_2,np.log1p(y_train_2))\n        \n            y_pred_2 = reg_2.predict(X_val_2)\n        \n            if verbosity>0: print(\"MSLE {}\".format(mean_squared_error(y_pred_2,np.log1p(y_val_2))))\n        \n        #result=X_test[['']]\n        elif d-np.timedelta64(86400000000000,'ns') in known:\n            if verbosity>0: print(\"Data Known\")\n        \n            X=big_train.drop(columns=['Province_State','Country_Region','ConfirmedCases','Fatalities','location','Date',\n                                  'day_of_year','day_of_week','d_ConfirmedCases','d_Fatalities','growth_Fatalities',\n                                      'growth_ConfirmedCases'])\n\n            y=big_train['d_ConfirmedCases']\n            y_2=big_train['d_Fatalities']\n        \n            mask_train=big_train['Date']<d\n        \n            X_train=X[mask_train]\n            y_train=y[mask_train]\n            y_train_2=y_2[mask_train]\n        \n        \n            reg = xgb.XGBRegressor(n_estimators=n_estimators,\n                                   max_depth=max_depth,\n                                   min_child_weight=min_child_weight,\n                                   learning_rate=learning_rate,\n                                   #subsample=0.95,\n                                   random_state=42)\n            reg_2 = xgb.XGBRegressor(n_estimators=n_estimators_2,\n                                   max_depth=max_depth_2,\n                                   min_child_weight=min_child_weight_2,\n                                   learning_rate=learning_rate_2,\n                                     random_state=42)\n        \n            reg.fit(X_train,np.log1p(y_train))\n        \n            X_train_2=X_train.copy().drop(columns=['medianage','density'])\n            X_train_2['d_ConfirmedCases']=np.log1p(y_train)  #0.4412899060661785 <- without , with - 0.4463  \n            \n            reg_2.fit(X_train_2,np.log1p(y_train_2))\n        \n        \n        \n        X_test=test[test['Date']==d]\n    \n        day=X_test['day_of_year'].iloc[0]\n    \n        country_info=big_train[big_train['day_of_year']==day-1].groupby(['Country_Region'])['ConfirmedCases','prev_ConfirmedCases'].sum()\n    \n        border_cases=border_info.merge(country_info, how='inner', \n                left_on=['country_border_name'],right_on=['Country_Region'])\n    \n        border_cases=border_cases.groupby(['country_name'])['ConfirmedCases','prev_ConfirmedCases'].sum()\n        border_cases=border_cases.rename(columns={'ConfirmedCases':'ConfirmedCases_neighbors','prev_ConfirmedCases':'prev_ConfirmedCases_neighbors'})\n    \n    \n        X_test=X_test.merge(border_cases, how='left', left_on=['Country_Region'],right_on=['country_name'])\n        X_test['ConfirmedCases_neighbors']=X_test['ConfirmedCases_neighbors'].fillna(0)\n        X_test['prev_ConfirmedCases_neighbors']=X_test['prev_ConfirmedCases_neighbors'].fillna(0)\n    \n        X_test = pd.concat([X_test,pd.get_dummies(X_test['location'], prefix='loc')],axis=1)\n\n        \n        X_test['ConfirmedCases_neighbors']=np.log1p(X_test['ConfirmedCases_neighbors'])\n        X_test['prev_ConfirmedCases_neighbors']=np.log1p(X_test['prev_ConfirmedCases_neighbors'])\n        \n        X_test['growth_ConfirmedCases_neighbors']=X_test['ConfirmedCases_neighbors']-X_test['prev_ConfirmedCases_neighbors']\n        \n        X_test.drop(columns=['prev_ConfirmedCases_neighbors'],inplace=True)\n        \n        \n        X_test=X_test.merge(big_train[big_train['day_of_year']==day-1][['location','ConfirmedCases','Fatalities']], how='left', \n                 left_on=['location'],right_on=['location'])\n        X_test.rename(columns={'ConfirmedCases':'prev_ConfirmedCases','Fatalities':'prev_Fatalities'},inplace=True)\n        \n        #print(X_test)\n        \n        X_test['prev_ConfirmedCases']=np.log1p(X_test['prev_ConfirmedCases'])\n        X_test['prev_Fatalities']=np.log1p(X_test['prev_Fatalities'])\n        \n    \n        X_test.set_index('Id',inplace=True)\n        #X_test.drop(columns=['Id'],inplace=True)\n        \n        #print(X_test.columns)\n    \n    #print(X_test.head(5))\n    \n        y_test=reg.predict(X_test.drop(columns=['Province_State','Country_Region','location','Date','day_of_year','day_of_week']))\n    \n    #print(y_test)\n    \n        X_test['d_ConfirmedCases']=y_test\n    \n        y_test=reg_2.predict(X_test.drop(columns=['Province_State','Country_Region','location','Date',\n                                            'day_of_year','day_of_week','medianage','density']))\n    \n        X_test['d_Fatalities']=y_test\n    \n    #print(X_test.shape)\n    \n        X_test['Id']=X_test.index\n        \n    \n        X_test=X_test.merge(big_train[big_train['day_of_year']==day-1][['location','ConfirmedCases','Fatalities']], how='left', \n                 left_on=['location'],right_on=['location'])\n    \n    #print(X_test.head(5))\n    \n    #X_test.set_index('Id',inplace=True)\n    \n    #print(X_test.shape)\n    \n        \n    \n        X_test.set_index('Id',inplace=True,drop=True)\n    \n        #print(X_test.head(5))\n        \n        X_test['d_ConfirmedCases']=np.expm1(X_test['d_ConfirmedCases'])\n        X_test['d_Fatalities']=np.expm1(X_test['d_Fatalities'])\n        \n        X_test['d_ConfirmedCases'].clip(0,inplace=True)\n        X_test['d_Fatalities'].clip(0,inplace=True)\n    \n        X_test['ConfirmedCases']+=X_test['d_ConfirmedCases']\n        X_test['Fatalities']+=X_test['d_Fatalities']\n        \n        if not d in known: #updates for the days_passed_* \n        \n            to_update=X_test.loc[(X_test['ConfirmedCases']>=10) & (X_test['days_passed_10']<0) & (X_test['day_of_year']==day),'location'].to_numpy()\n\n            for loc in to_update:\n                test.loc[(test['location']==loc) & (test['day_of_year']>=day),'days_passed_10']=test.loc[(test['location']==loc) & (test['day_of_year']>=day),'day_of_year']-day\n                #print(day)\n                #print(test.loc[(test['location']==loc) & (test['day_of_year']>=day),['location','days_passed_10']])\n\n            to_update=X_test.loc[(X_test['ConfirmedCases']>=100) & (X_test['days_passed_100']<0) & (X_test['day_of_year']==day),'location'].to_numpy()\n\n            for loc in to_update:\n                test.loc[(test['location']==loc) & (test['day_of_year']>=day),'days_passed_100']=test.loc[(test['location']==loc) & (test['day_of_year']>=day),'day_of_year']-day\n                #print(day)\n                #print(test.loc[(test['location']==loc) & (test['day_of_year']>=day),['location','days_passed_100']])\n       \n    \n    \n        results.append(X_test[['ConfirmedCases','Fatalities']])\n        full_results.append(X_test)\n    \n        if not d in known: #Needed to correctly get data on neighbors         \n            big_train=pd.concat([big_train,X_test],sort=False)\n        \n    return results,full_results\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_prediction(train,border_info,date_end_train,date_end_new):\n    \n    df_train=train.copy()\n    \n    loc_to_drop=df_train[(df_train['Date']==date_end_new)& (df_train['ConfirmedCases']==0)]['location'].unique()\n    \n    df_train.drop(df_train[df_train['location'].isin(loc_to_drop)].index,inplace=True)\n\n    df_train.drop(columns='loc_'+loc_to_drop,inplace=True)\n    \n    \n    df_test=df_train[df_train['Date']>=date_end_train].drop(columns=['d_ConfirmedCases','d_Fatalities','growth_Fatalities',\n                                      'growth_ConfirmedCases','prev_ConfirmedCases','prev_Fatalities','ConfirmedCases_neighbors',\n                                                                   'growth_ConfirmedCases_neighbors','ConfirmedCases','Fatalities'])\n    df_test['Id']=df_test.index\n\n    df_test.set_index('Id',drop=True,inplace=True)\n    df_test['Id']=df_test.index\n\n    df_test.drop(columns=list(filter(lambda c: 'loc_' in str(c), df_test.columns)),inplace=True)\n\n\n    results,_=create_prediction(df_train[df_train['Date']<date_end_train],df_test,border_info)\n    \n    mask_9=df_train[df_train['Date']>date_end_train].index\n    \n    return np.sqrt(mean_squared_error(np.log1p(pd.concat(results).sort_index()).loc[(mask_9)],\n                               np.log1p(df_train.loc[(mask_9)][['ConfirmedCases','Fatalities']])))\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model_2:\n    scores=[]\n    params=[]\n\n    for n_estimators_2 in range(25,201,25):\n        for learning_rate_2 in np.arange(0.05,0.31,0.05):\n            params.append({'n_estimators_2':n_estimators_2,'learning_rate_2':learning_rate_2})\n            score=score_prediction(big_train,border_info,'2020-04-01','2020-03-24')\n            scores.append(score)\n            print('For params {} score {}'.format(params[-1],scores[-1]))\n\n    print(params[scores.index(min(scores))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model_2:\n    n_estimators_2=params[scores.index(min(scores))]['n_estimators_2']\n    learning_rate_2=params[scores.index(min(scores))]['learning_rate_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model_2:\n\n\n    scores=[]\n    params=[]\n\n    for max_depth_2 in range(1,5,1):\n        for min_child_weight_2 in np.arange(0.5,5.1,0.5):\n            params.append({'max_depth_2':max_depth_2,'min_child_weight_2':min_child_weight_2})\n        \n            score=score_prediction(big_train,border_info,'2020-04-01','2020-03-24')\n            scores.append(score)\n            print('For params {} score {}'.format(params[-1],scores[-1]))\n\n    print(params[scores.index(min(scores))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model_2:\n    max_depth_2=params[scores.index(min(scores))]['max_depth_2']\n    min_child_weight_2=params[scores.index(min(scores))]['min_child_weight_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model:\n    scores=[]\n    params=[]\n\n    for n_estimators in range(300,1400,50):\n        for learning_rate in np.arange(0.1,0.31,0.2):\n            params.append({'n_estimators':n_estimators,'learning_rate':learning_rate})\n            score=score_prediction(big_train,border_info,'2020-04-01','2020-03-24')\n            scores.append(score)\n            print('For params {} score {}'.format(params[-1],scores[-1]))\n\n    print(params[scores.index(min(scores))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model:\n    n_estimators=params[scores.index(min(scores))]['n_estimators']\n    learning_rate=params[scores.index(min(scores))]['learning_rate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model:\n    scores=[]\n    params=[]\n\n    for max_depth in range(1,7,1):\n        for min_child_weight in np.arange(0.5,5.1,0.5):\n            params.append({'max_depth':max_depth,'min_child_weight':min_child_weight})\n        \n            score=score_prediction(big_train,border_info,'2020-04-01','2020-03-24')\n            scores.append(score)\n            print('For params {} score {}'.format(params[-1],scores[-1]))\n        \n    print(params[scores.index(min(scores))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if optimize_model:\n    max_depth=params[scores.index(min(scores))]['max_depth']\n    min_child_weight=params[scores.index(min(scores))]['min_child_weight']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Would be Week 3 score {}\".format(score_prediction(big_train,border_info,'2020-04-08','2020-04-01')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Would be Week 2 score {}\".format(score_prediction(big_train,border_info,'2020-04-01','2020-03-24')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission:\n    results,full_results=create_prediction(big_train,test,border_info,verbosity=1)\n    \n    full_res=pd.concat(full_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    submission=pd.read_csv(ROOT_DIR+\"submission.csv\")\n    submission.drop(columns=['ConfirmedCases','Fatalities'],inplace=True)\n    submission=submission.merge(pd.concat(results),left_on=['ForecastId'],right_index=True).clip(lower=0)\n    submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    trained=big_train[(big_train['loc_ Switzerland']==1) & (big_train['Date']<'2020-04-13')][['Date','ConfirmedCases','Fatalities']]\n    prediction=full_res[full_res['loc_ Switzerland']==1][['Date','ConfirmedCases','Fatalities']]\n    fig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\n    fig1.add_trace(go.Scatter(\n            x=prediction[\"Date\"],\n            y=prediction[\"ConfirmedCases\"],\n            mode=\"lines\",\n            line=go.scatter.Line(color=\"red\"),\n            showlegend=False))\n\n    fig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    trained=big_train[(big_train['loc_ Italy']==1) & (big_train['Date']<'2020-04-13')][['Date','ConfirmedCases','Fatalities']]\n    prediction=full_res[full_res['loc_ Italy']==1][['Date','ConfirmedCases','Fatalities']]\n    fig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\n    fig1.add_trace(go.Scatter(\n            x=prediction[\"Date\"],\n            y=prediction[\"ConfirmedCases\"],\n            mode=\"lines\",\n            line=go.scatter.Line(color=\"red\"),\n            showlegend=False))\n\n    fig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    trained=big_train[(big_train['loc_ Ukraine']==1) & (big_train['Date']<'2020-04-13')][['Date','ConfirmedCases','Fatalities']]\n    prediction=full_res[full_res['loc_ Ukraine']==1][['Date','ConfirmedCases','Fatalities']]\n    fig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\n    fig1.add_trace(go.Scatter(\n            x=prediction[\"Date\"],\n            y=prediction[\"ConfirmedCases\"],\n            mode=\"lines\",\n            line=go.scatter.Line(color=\"red\"),\n            showlegend=False))\n\n    fig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    trained=big_train[(big_train['loc_New York US']==1) & (big_train['Date']<'2020-04-13')][['Date','ConfirmedCases','Fatalities']]\n    prediction=full_res[full_res['loc_New York US']==1][['Date','ConfirmedCases','Fatalities']]\n    fig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\n    fig1.add_trace(go.Scatter(\n            x=prediction[\"Date\"],\n            y=prediction[\"ConfirmedCases\"],\n            mode=\"lines\",\n            line=go.scatter.Line(color=\"red\"),\n            showlegend=False))\n\n    fig1.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}