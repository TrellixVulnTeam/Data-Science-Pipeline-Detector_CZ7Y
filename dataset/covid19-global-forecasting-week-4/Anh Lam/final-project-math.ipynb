{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Đồ án cuối kì môn Toán ứng dụng và thống kê\n## Xây dựng mô hình dự đoán: Nhiễm, nhiễm khỏi, nhiễm chết, không nhiễm từ dữ liệu COVID-19\n## Nhóm người dễ chết khi nhiễm COVID-19","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Danh sách thành viên\n    1. Lâm Đức Anh - 1712273\n    2. Hoàng Đức Công - 1712304\n    3. Trương Khắc Triệu - 1712838\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Câu 1: Các mô hình dự đoán","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Phân tích dữ liệu\nDatasets lấy từ Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). <br>\nLink đến repository chứa datasets: https://github.com/CSSEGISandData/COVID-19 <br>\nBao gồm số ca confirms, deaths, và recovered<br>\nMỗi file dữ liệu có cấu trúc Province/State, Country/Region, Lat, Long, n cột tiếp theo là cập nhật số ca theo ngày<br>\nNgày update cuối là ngày 05 tháng 08 năm 2020","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Đọc và phân tích cấu trúc dữ liệu ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\nconfirms_data = pd.read_csv(\"/kaggle/input/time-series-data/confirm.csv\")\ndeaths_data = pd.read_csv(\"/kaggle/input/time-series-data/death.csv\")\nrecovered_data = pd.read_csv(\"/kaggle/input/time-series-data/recovered.csv\")\n# Get columns name\ncolumn_comfirms_names= list(confirms_data.columns.values)\ncolumn_deaths_names= list(deaths_data.columns.values)\ncolumn_recovered_names= list(recovered_data.columns.values)\n# Total rows and columns each tabale\nprint('Confirms data has total:',len(confirms_data) ,'rows, and',len(column_comfirms_names),'columns.')\nprint('Deaths data has total:',len(deaths_data) ,'rows, and',len(column_deaths_names),'columns.')\nprint('Recovered data has total:',len(recovered_data) ,'rows, and',len(column_recovered_names),'columns.')\n\n# Number of countries in data\nprint(\"Number of Country/Region: \", confirms_data['Country/Region'].nunique())\nprint(\"From day\", column_deaths_names[4], \"to day\", column_deaths_names[-1], \":\", len(column_comfirms_names)-4, \"days\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(confirms_data)\ndisplay(deaths_data)\ndisplay(recovered_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Biểu đồ mô phỏng dữ liệu\n#### a. Biểu đồ trên toàn bộ các quốc gia","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confirm_data_totals = confirms_data.sum(axis = 0, skipna = True)[3:]\ndeaths_data_totals = deaths_data.sum(axis = 0, skipna = True)[3:]\nrecovered_data_totals = recovered_data.sum(axis = 0, skipna = True)[3:]\ntotal = [confirm_data_totals,deaths_data_totals,recovered_data_totals]\ntotals = pd.concat(total,axis=1)\ntotals.columns = [ 'Confirmed','Deaths','Recovered']\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(17,7))\ntotals.plot(ax=ax1)\nax1.set_title(\"Global cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\n\ndeaths_data_totals.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deaths cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)\n\nrecovered_data_totals.plot(ax=ax3, color='green')\nax3.set_title(\"Global recovered cases\", size=13)\nax3.set_ylabel(\"Number of cases\", size=13)\nax3.set_xlabel(\"Date\", size=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### b. Biểu đồ tại các quốc gia đang có số ca nhiễm đứng đầu\nTính đến ngày 4 tháng 8 năm 2020, các nước có số lượng ca nhiễm nhiều trên 500000 ca gồm: US, Brazil, India, Russia, South Africa<br>\nCó quan tâm đến mô hình ở Trung Quốc, nơi khởi phát của dịch bệnh","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def showPLTByCountry(country,axs):\n    confirm_data_totals= confirms_data.loc[confirms_data[\"Country/Region\"] == country].sum(axis = 0, skipna = True)[4:]\n    deaths_data_totals = deaths_data.loc[deaths_data[\"Country/Region\"] == country].sum(axis = 0, skipna = True)[4:]\n    recovered_data_totals = recovered_data.loc[recovered_data[\"Country/Region\"] == country].sum(axis = 0, skipna = True)[4:]\n    total_ = [confirm_data_totals,deaths_data_totals,recovered_data_totals]\n    total = pd.concat(total_,axis=1)\n    total.columns = [ 'Confirmed','Deaths','Recovered']\n    total.plot(ax=axs)\n    axs.set_title(country+\"'s cases\", size=13)\n    axs.set_ylabel(\"Number of cases\", size=13)\n#     axs.set_xlabel(\"Date\", size=13)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, (axs) = plt.subplots(2,3,figsize=(17,7))\nshowPLTByCountry(\"US\",axs[0][0])\nshowPLTByCountry(\"Brazil\",axs[0][1])\nshowPLTByCountry(\"India\",axs[0][2])\nshowPLTByCountry(\"Russia\",axs[1][0])\nshowPLTByCountry(\"South Africa\",axs[1][1])\nshowPLTByCountry(\"China\",axs[1][2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Đánh giá\nTa nhận thấy rằng, hình dạng đường cong trong biểu đồ trên có sự tương đồng với mô hình SIR<br>\nMô hình SIR cho thấy sự gia tăng lớn về số lượng nhiễm , một khi nó đạt đến mức tối đa của bệnh truyền nhiễm, sẽ giảm xuống với độ dốc thấp hơn. <br>\nChẳng hạn như đối với Trung Quốc, số lượng ca nhiễm dường như đạt đỉnh vào tháng giữa tháng 2, từ đó số ca nhiễm băt đầu giảm xuống<br>\nBiểu đồ mô hình SIR như sau: <br>\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2a/Graph_SIR_model_without_vital_dynamics.svg\" alt=\"SIR MODEL\" title=\"Biểu đồ mô hình SIR\">\nYellow=Susceptible, Maroon=Infectious, Teal=Recovered<br>\nSource: https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2. SIR Model \n### 2.1 Định nghĩa mô hình dịch bệnh SIR\nLà một mô hình toán học về dịch bệnh, trong đó, dân số sẽ được chia làm 3 nhóm\n    - S: Susceptible (=All - Confirmed) : Những người có khản năng nhiễm bệnh\n    - I: Infected (=Confirmed - Recovered - Deaths) : Những người đang nhiễm bệnh\n    - R: Recovered or fatal (=Recovered + Deaths) : Những người đã hồi phục hoặc chết (không còn khả năng nhiễm).\nỞ dạng SIR chuẩn, thì chỉ xét số người đã hồi phục, tuy nhiên với thực tế, số lượng người chết lớn nên không thể bỏ qua được, cho nên, gộp nhóm hồi phục và tử vong vào nhóm R <br>\nỞ mô hình này, chỉ xét trường hợp người có thể chuyển từ trạng thái từ $S$ sang $I$ và từ $I$ sang $R$<br>\n![SIR_MODEL](https://www.lewuathe.com/assets/img/posts/2020-03-11-covid-19-dynamics-with-sir-model/sir.png)\nTrong 1 thời điểm thì $S + I + R = N$, với N là tổng số dân. Đại lượng cần được quan tâm đến chính là $I$ bởi nó cho biết xu hướng lây lan và quy mô của dịch bệnh tại thời điểm đang xét.<br>\nVà với N là số dân (thông thường từ vài triệu đến hàng tỉ), được xem là 1 đại lượng đủ lớn. Khi đó, ta có hệ sau: <br>\n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}t}= -{\\beta S I}  \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}t}= {\\beta S I }- \\gamma I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}t}= \\gamma I  \\\\\n\\end{align*}\nTrong đó $\\beta$ là tỉ lệ lây nhiễm, có thể được hiểu là xác suất 1 người khỏe mạnh bị nhiễm. $\\gamma$ là tỉ lệ hồi phục của một người\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Triển khai mô hình SIR","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Triển khai công thức lý thuyết được đề cập ở phần 2.1 ta có các hàm tương ứng","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# susceptible\ndef dS_dt(S, I, beta):\n    return -beta*S*I\n    \n# infected\ndef dI_dt(S, I, beta, gamma):\n    return beta*S*I - gamma*I\n\n# recovered\ndef dR_dt(I, gamma):\n    return gamma*I","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Để giải phương trình vi phân với độ chính xác gần đúng, ta sẽ sử dụng phương pháp [Runge-Kutta](https://vi.wikipedia.org/wiki/Ph%C6%B0%C6%A1ng_ph%C3%A1p_Runge-Kutta). <br>\nPhương pháp này sẽ giúp chúng ta tìm giá trị gần đúng của Yn+1 khi đã biết được giá trị của Yn. \n    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def runge_kutta(Sn, In, Rn, beta, gamma, h):\n    ks1 = dS_dt(Sn, In, beta)\n    ki1 = dI_dt(Sn, In, beta, gamma)\n    kr1 = dR_dt(In, gamma)\n    \n    ks2 = dS_dt(Sn + 0.5*h*ks1, In + 0.5*h*ki1, beta)\n    ki2 = dI_dt(Sn + 0.5*h*ks1, In + 0.5*h*ki1, beta, gamma)\n    kr2 = dR_dt(In + 0.5*h*ki1, gamma)\n    \n    ks3 = dS_dt(Sn + 0.5*h*ks2, In + 0.5*h*ki2, beta)\n    ki3 = dI_dt(Sn + 0.5*h*ks2, In + 0.5*h*ki2, beta, gamma)\n    kr3 = dR_dt(In + 0.5*h*ki2, gamma)\n    \n    ks4 = dS_dt(Sn + h*ks3, In + h*ki3, beta)\n    ki4 = dI_dt(Sn + h*ks3, In + h*ki3, beta, gamma)\n    kr4 = dR_dt(In + h*ki3, gamma)\n    \n    Sn_1 = Sn + (ks1 + 2*ks2 + 2*ks3 + ks4)*h/6\n    In_1 = In + (ki1 + 2*ki2 + 2*ki3 + ki4)*h/6\n    Rn_1 = Rn + (kr1 + 2*kr2 + 2*kr3 + kr4)*h/6\n    \n    return Sn_1, In_1, Rn_1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def SIR_model(N, beta, gamma, h):\n    # N là dân số thế giới hiện tại\n    # giả sử ban đầu có 1 người nhiễm nên S0=N-1, I0=1, R0=0\n    # ở đây ta sẽ chuẩn hóa dữ liệu nẳm trong [0,1]\n    s = float(N-1)/N\n    i = float(1)/N\n    r = 0.\n    \n    susceptible, infected, recovered = [], [], []\n    #ta sẽ lặp 10000 lần (time-steps) để lấy dữ liệu tương ứng\n    for k in range(10000):\n        susceptible.append(s)\n        infected.append(i)\n        recovered.append(r)\n        s, i, r = runge_kutta(s, i, r, beta, gamma, h)\n        \n    return susceptible, infected, recovered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 7800000000 # dân số thế giới hiện tại\nbeta = 0.7\ngamma = 0.2\nh = 0.1\n\nsusceptible, infected, recovered = SIR_model(N, beta, gamma, h)\n\nf = plt.figure(figsize=(8,5)) \nplt.plot(susceptible, '#2ca02c', label='susceptible');\nplt.plot(infected, '#ff7f0e', label='infected');\nplt.plot(recovered, '#17becf', label='recovered/deceased');\nplt.title(\"SIR model\")\nplt.xlabel(\"time\", fontsize=10);\nplt.ylabel(\"Normalized population\", fontsize=10);\nplt.legend(loc='best')\nplt.xlim(0,1000)\nplt.savefig('SIR_model.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Khớp mô hình với dữ liệu","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Khớp mô hình SIR với 1 nước. Lấy ví dụ là US, đang có số dân là 330578810.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t= confirms_data.loc[confirms_data[\"Country/Region\"] == \"US\"]\ncolumn_day= list(t.columns.values)\ncolumn_day= column_day[4:]\nt = t.sum(axis = 0, skipna = True).to_frame()\nt = t.T\n\nx= t.loc[:,column_day[0]:column_day[-1]]\nx = x.diff(axis=1).fillna(0)\nx.values[0][0] = t[column_day[0]].values[0]\n\npopulation = float(330578810)\n# population = float(1439323776)\n\nday_count = list(range(1,len(column_day)+1))\nxdata = day_count\nydata = np.array(x.values[0], dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for US confirmed cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Khớp mô hình SIR với toàn bộ quốc gia","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t = confirms_data.sum(axis = 0, skipna = True).to_frame()\nt = t.T\ncolumn_day= list(t.columns.values)\ncolumn_day= column_day[4:]\n\nx= t.loc[:,column_day[0]:column_day[-1]]\nx = x.diff(axis=1).fillna(0)\nx.values[0][0] = t[column_day[0]].values[0]\n\npopulation = float(7800000000)\n# population = float(1439323776)\n\nday_count = list(range(1,len(column_day)+1))\nxdata = day_count\nydata = np.array(x.values[0], dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for global confirmed cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Tăng cường dữ liệu <a id=\"section3\"></a>\nViệc phân tích mô hình SIR bên trên nhằm tìm hiểu mô hình gần giống với cơ chế lan truyền của nhiều loại virus, bao gồm cả COVID-19. Ngoài ra, chúng ta có nhiều phương pháp khác hữu ích tương tự để dự đoán và hiểu hơn về quá trình phát triển đại dịch. Các phương pháp đòi hỏi dữ liệu đầy đủ hơn để rút trích ra các kết luận và đảm bảo thuật toán phát hiện được các tri thức trong dữ liệu. Đó cũng là mục đích cho việc mở rộng dữ liệu.  \n\n\nCác công việc chính trong mở rộng dữ liệu\n1. Tiền xử lý dữ liệu (xử lý các điểm dữ liệu bị mất, ...)\n2. Tính toán các đặc trưng mới lags và trends\n3. Thêm thông tin quốc gia\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Tiền xử lý dữ liệu <a id=\"section31\"></a>\n\nCác công việc trong tiền xử lý dữ liệu\n\n* **Gộp dữ liệu**: gộp tập huấn luyện và tập kiểm thử thành một tập dữ liệu mới để biến đổi.\n* **Lọc ngày**: xóa ConfirmedCases và Fatalities sau 12/03/2020. tạo cột thuộc tính \"date\".\n* **Mất dữ liệu**: thay thế các điểm dữ liệu bị mất.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\ntrain.Province_State.fillna(\"None\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do dữ liệu được lấy từ cuộc thi nên ta gộp 2 bộ dữ liệu train và test với nhau\ndates_overlap = ['2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n                 '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14']\ntrain2 = train.loc[~train['Date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Chắc chắn chỉ có thông tin về số ca nhiễm và số ca tử vong trước ngày 11/03/2020\n# Mục đích: ta huấn luyện với bộ dữ liệu trước ngày 11/03/2020 để dự đoán \nall_data.loc[all_data['Date'] >= '2020-04-01', 'ConfirmedCases'] = 0\nall_data.loc[all_data['Date'] >= '2020-04-01', 'Fatalities'] = 0\nall_data['Date'] = pd.to_datetime(all_data['Date'])\n\n# Tạo các cột dữ liệu chứ thời gian: ngày, tháng, năm\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\n\n# Xử lý dữ liệu bị mất trong dữ liệu bằng cách thay thế\nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['ConfirmedCases'].fillna(0, inplace=True)\nall_data['Fatalities'].fillna(0, inplace=True)\nall_data['Id'].fillna(-1, inplace=True)\nall_data['ForecastId'].fillna(-1, inplace=True)\n\ndisplay(all_data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kiểm tra xem dữ liệu còn thiếu hay không ?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.info() # Số lượng phần tử non-null trong từng cột đểu bằng số lượng phần tử","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Tính hai đặc trưng mới lags và trends <a id=\"section32\"></a>\n\n**Lag**: là giá trị ở bước thời gian trước đó của cột, chẳng hạn giá trị của $lag_1$ số ca nhiễm sẽ bằng giá trị của số ca nhiễm của ngày hôm trước. Và $lag_p$ của thuộc tính X có dạng  \n$$X_{lag_p}(t) = X(t-p)$$\n\n\n**Trend**: Tỷ lệ tăng hay giảm của thuộc tính đó ở thời điểm hiện tại so với p bước thời điểm trước đó. Định nghĩa trend bậc p của thuộc tính X như sau: \n$$Trend_p(X(t)) = {X(t) - X(t-p) \\over X(t-p)}$$\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Định nghĩa các hàm tính lags và trends của dữ liệu \n\ndef calculate_lag(dataframe, lag_list, column):\n    for lag in lag_list:\n        column_lag = f\"{column}_{lag}\"\n        dataframe[column_lag] = dataframe.groupby(['Country_Region', 'Province_State'])[column].shift(lag, fill_value=0)\n    return dataframe\n\ndef calculate_trend(dataframe, lag_list, column):\n    df_groupby = dataframe.groupby(['Country_Region', 'Province_State'])\n    for lag in lag_list:\n        trend_column_lag = f\"Trend_{column}_{lag}\"\n        dataframe[trend_column_lag] = (df_groupby[column].shift(0, fill_value=0) - \n                                df_groupby[column].shift(lag, fill_value=0))/df_groupby[column].shift(lag, fill_value=0.001)\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = calculate_lag(all_data.reset_index(), range(1,7), 'ConfirmedCases')\nall_data = calculate_lag(all_data, range(1,7), 'Fatalities')\nall_data = calculate_trend(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_trend(all_data, range(1,7), 'Fatalities')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. Thêm các thông tin về quốc gia <a id=\"section33\"></a>\n\nCác thông tin về: tổng dân số của một quốc gia, tuổi trung bình của dân thành thị hoặc tỉ lệ người sống trong thành phố có thể ảnh hướng đến khả năng lây truyền của Covid. Từ đó, Chúng ta sẽ thêm dữ liệu về các yếu tố trên bộ dữ liệu chúng ta [Tanu's dataset](https://www.kaggle.com/tanuprabhu/population-by-country-2020).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Đọc dữ liệu từ data file\nworld_population = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Chọn các cột mong muốn , và sửa đổi lại tên \nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country_Dependency', 'Population', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Thay tên \"United States\" thành \"US\"\nworld_population.loc[world_population['Country_Dependency']=='United States', 'Country_Dependency)'] = 'US'\n\n# Xóa dấu % ở cột dữ liệu Urban Pop\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes\n# Thay thế các giá trị \"N.A\" trong cột \"Urban Pop\" và cột \"Med Age\" bằng mode của nó\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\n\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country_Dependency', how='left')\nall_data[['Population', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\ndisplay(all_data.head())\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country_Dependency)', inplace=True, axis=1)\n\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \n\nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) \ndisplay(all_data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Sử dụng mô hình Linear Regression để dự đoán giai đoạn đầu đại dịch <a id=\"section4\"></a>\n\nCác mô hình sử dụng\n1. Linear Regression cho một quốc gia\n2. Linear Regression với đặc trưng lags","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1. Linear Regression cho một quốc gia <a id=\"section41\"></a>\n\nVì chúng ta quan tâm đến việc dự đoán diễn biến theo thời gian trong tương lai của đại dịch, nên cách tiếp cận đầu tiên của chúng ta bao gồm mô hình hồi quy tuyến tính đơn giản. Tuy nhiên, sự phát triển đại dịch không phải tuyến tính mà là theo cấp số nhân (chỉ trong giai đoạn đầu của quá trình lây nhiễm), do đó cần có một phép biến đổi logarithm.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trực quan dữ liệu cả hai trường hợp đối với Tây Ban Nha với dữ liệu 10 ngày cuối mà có thông tin, bắt đầu từ 01/03/2020\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\ncondition = (all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)\n\n# Day_num = 38 is March 1st\ny1 = all_data[condition][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\n\ny2 = all_data[condition][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chọn lọc các đặc trưng làm đầu vào mô hình\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities', \n       'Day_num']\ndata = data[features]\n\n# Áp dụng biến đổi Logarithm cho ConfirmedCases và Fatalities cột\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log1p(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chia thành tập huấn luyện và tập kiểm thử\ndef split_data(df, train_lim, test_lim):\n    \n    df.loc[df['Day_num']<=train_lim , 'ForecastId'] = -1\n    df = df[df['Day_num']<=test_lim]\n    \n    # Tập huấn luyện\n    x_train = df[df.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = df[df.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = df[df.ForecastId == -1]['Fatalities']\n\n    # Tập kiểm thử \n    x_test = df[df.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Loại bỏ hai cột Id và ForecastId\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hàm mô hình hồi quy tuyến tính\ndef lin_reg(X_train, Y_train, X_test):\n    regr = linear_model.LinearRegression()\n\n    # Huấn luyện mô hình dựa trên tập huấn luyện\n    regr.fit(X_train, Y_train)\n\n    # Dự đoán tập kiểm thử\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta, date\n\ndef daterange(start_date, end_date):\n    for n in range(int((end_date - start_date).days)):\n        yield start_date + timedelta(n)\n\nstart_date = date(2020, 3, 1)\nend_date = date(2020, 4, 15)\n\ndates_list = [single_date.strftime(\"%Y-%m-%d\") for single_date in daterange(start_date, end_date)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_linreg_basic_country(data, country_name, dates_list, day_start, shift, train_lim, test_lim):\n    \n    data_country = data[data['Country_Region']==country_dict[country_name]]\n    data_country = data_country.loc[data_country['Day_num']>day_start]\n    X_train, Y_train_1, Y_train_2, X_test = split_data(data_country, train_lim, test_lim)\n    model, pred = lin_reg(X_train, Y_train_1, X_test)\n\n    # Create a df with both real cases and predictions (predictions starting on March 12th)\n    X_train_check = X_train.copy()\n    X_train_check['Target'] = Y_train_1\n\n    X_test_check = X_test.copy()\n    X_test_check['Target'] = pred\n\n    X_final_check = pd.concat([X_train_check, X_test_check])\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n    ax1.plot(list(range(len(predicted_data))), np.expm1(predicted_data))\n    ax1.plot(list(range(len(real_data))), real_data)\n    ax1.axvline(30-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(f\"Day count (from March {1+shift})\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(list(range(len(predicted_data))), predicted_data)\n    ax2.plot(list(range(len(real_data))), np.log1p(real_data))\n    ax2.axvline(30-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(f\"Day count (from March {str(1+shift)})\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lim, test_lim = 69, 112\n\noutput_lr = widgets.Output()\n\ndef linear_reg_country():\n    country_name = country_combobox.value\n    march_day = marchDay_text.value\n    if not (country_name and march_day):\n        return\n    march_day = int(march_day)\n    day_start = 39 + march_day # 39 là thứ tự của ngày 01/03/2020\n    date_list_temp = dates_list[march_day:]\n    with output_lr:\n        output_lr.clear_output()\n        plot_linreg_basic_country(data, country_name, date_list_temp, day_start, march_day, train_lim, test_lim)\n        plt.show()\n        \ncountry_combobox = widgets.Combobox(\n    placeholder='Country',\n    options= tuple(country_dict.keys()),\n    description='Country: ',\n    ensure_option=True,\n    disabled=False\n)    \n\nmarchDay_text = widgets.Text(\n    placeholder='Enter number',\n    description=\"March day:\"\n)\n\nsubmit_lr_btn = widgets.Button(description=\"run\")\n\ndef run_linear_reg_country(b):\n    linear_reg_country()\n\ndisplay(country_combobox, marchDay_text, submit_lr_btn, output_lr)\n\nsubmit_lr_btn.on_click(run_linear_reg_country)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Nhận xét**:\n* Với một mô hình khá đơn giản thì quá trình phát triển đại dịch được dự đoán khá rõ ràng.\n* Tuy nhiên, khi thời gian càng về sau mô hình ước tính ngày càng tệ, từ đó cho thấy mô hình chưa thực sự hiệu quả để ước tính các giá trị ở tượng lại.\n* Các quốc gia gần đây đã xác nhận trường hợp lây nhiễm đầu tiên của họ rất khó dự đoán (ít điểm dữ liệu hơn)\n* Các quốc gia có 0 trường hợp trong toàn bộ tập dữ liệu huấn luyện được dự đoán là không bị nhiễm (không có điểm dữ liệu)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Hồi quy tuyến tính với đặc trưng lags <a id=\"section44\"></a>\nTa sẽ sử dụng đặc trưng lags để thực hiện mô hình dự đoán. Nhưng một vấn đề xảy ra là chúng ta chỉ bik được thông tin về ca nhiễm cũng như ca tử vong trong tập huấn luyện nên có nhiều lags ở những ngày sau mang giá trị 0. Để giải quyết cho vấn đề này ta thực hiện phương pháp sau:\n1. Bắt đầu với tập huấn luyện, khi mà thông tin về số ca nhiễm và đặc trưng lags có đầy đủ\n2. Dự đoán ngày tiếp theo với hồi quy tuyến tính\n3. Gán dự đoán vừa rồi là giá trị ca nhiễm của ngày hôm đó\n4. Tính toán lại lags\n5. Lặp đi lặp lại từ bước 2 -> 4 cho các ngày còn lại.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hàm chia tập huấn luyện và tập test cho dự đoán sau 1 ngày\ndef split_data_one_day(df, d, train_lim, test_lim):\n    df.loc[df['Day_num']<=train_lim , 'ForecastId'] = -1\n    df = df[df['Day_num']<=test_lim]\n    \n    # Tập huấn luyện\n    x_train = df[df.Day_num<d]\n    y_train_1 = x_train.ConfirmedCases\n    y_train_2 = x_train.Fatalities\n    x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    # Tập kiểm thử \n    x_test = df[df.Day_num==d]\n    x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    # Loại bỏ hai cột Id và ForcastId \n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\n# Hàm cấu hình biểu đồ \ndef config_axis(axis, march_day, msg):\n    axis.axvline(30-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    axis.set_xlabel(\"Day count (starting on March \" + str(march_day) + \"))\")\n    axis.set_ylabel(msg)\n    return axis\n\n\n# Hàm chuẩn bị dữ liệu để vẽ\ndef prepare_data(data, train, country_name, day_start, dates_list, fatalities=False):\n    column = \"ConfirmedCases\"\n    if fatalities:\n        column = \"Fatalities\"\n    \n    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))][column]\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))][column]\n    \n    dates_list_num = list(range(0,len(dates_list)))\n    \n    return predicted_data, real_data, dates_list_num\n\n\ndef plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list, march_day):\n    predicted_data, real_data, dates_list_num = prepare_data(data, train, country_name, day_start, dates_list)\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n    \n    config_axis(ax1, march_day, \"Confirmed Cases\")\n    ax1.plot(list(range(len(predicted_data))), np.expm1(predicted_data))\n    ax1.plot(list(range(len(real_data))), real_data)\n    \n    config_axis(ax2, march_day, \"Log Confirmed Cases\")\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \ndef plot_real_vs_prediction_country_fatalities(data, train, country_name, day_start, dates_list, march_day):\n    predicted_data, real_data, dates_list_num = prepare_data(data, train, country_name, day_start, dates_list, True)\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n    \n    ax1 = config_axis(ax1, march_day, \"Fatalities Cases\")\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    \n    ax2 = config_axis(ax2, march_day, \"Log Fatalities Cases\")\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    plt.suptitle((\"Fatalities predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hàm dự đoán sử dụng mô hình Hồi quy tuyến tính với thêm đặc trưng lags cho một quốc gia\ndef lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict, train_lim, test_lim):\n    data = all_data.copy()\n    features = ['Id', 'Province_State', 'Country_Region',\n           'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n    data = data[features]\n\n    # Select country an data start (all days)\n    data = data[data['Country_Region']==country_dict[country_name]]\n    data = data.loc[data['Day_num'] > day_start]\n\n    # Lags\n    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n    data = calculate_lag(data, range(1,8), 'Fatalities')\n    \n    # Chọn ra các cột thuộc tính Confirmed\n    filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n    filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    \n    # Apply log transformation\n    data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n    data.replace([np.inf, -np.inf], 0, inplace=True)\n    data.fillna(0, inplace=True)\n\n\n    # Start/end of forecast\n    start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n    end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n    for d in list(range(start_fcst, end_fcst+1)):\n        X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d, train_lim, test_lim)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n        # Tính toán lại lags\n        data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n        data = calculate_lag(data, range(1,8), 'Fatalities')\n        data.replace([np.inf, -np.inf], 0, inplace=True)\n        data.fillna(0, inplace=True)\n   \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lim, test_lim = 69, 112\n\noutput = widgets.Output()\n\ndef linear_reg_with_lag_country():\n    country_name = country_combobox_lag.value\n    march_day = marchDay_text_lag.value\n    lag_size = lagSize_text.value\n    \n    if not (country_name and march_day and lag_size):\n        return\n    march_day = int(march_day)\n    lag_size = int(lag_size)\n    day_start = 39 + march_day # 39 là thứ tự của ngày 01/03/2020\n    date_list_temp = dates_list[march_day:]\n    data_c = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict, train_lim, test_lim)\n    with output:\n        output.clear_output()\n        print(country_name, march_day, lag_size)\n        plot_real_vs_prediction_country(data_c, train, country_name, day_start, date_list_temp, march_day)\n        plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, date_list_temp, march_day)\n        plt.show()\n\ncountry_combobox_lag = widgets.Combobox(\n    placeholder='Country',\n    options= tuple(country_dict.keys()),\n    description='Country: ',\n    ensure_option=True,\n    disabled=False\n)    \n\nmarchDay_text_lag = widgets.Text(\n    placeholder='Enter number',\n    description=\"March day:\"\n)\nlagSize_text = widgets.Text(\n    placeholder=\"Enter number\",\n    description=\"Lag size:\"\n)\n\nsubmit_btn = widgets.Button(description=\"run\")\n\ndef run_linear_reg_with_lag_country(button):\n    linear_reg_with_lag_country()\n    \ndisplay(country_combobox_lag, marchDay_text_lag, lagSize_text, submit_btn, output)\n\nsubmit_btn.on_click(run_linear_reg_with_lag_country)\n\n# Spain, Italy, Germany, Albania, Andora","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Nhận xét**:\n* **Lượng tham số:** 2 tuần đầy đủ tập huấn luyện được sử dụng (từ 26/02 to 11/03), với số lượng tham số lags là 30\n* **Dữ liệu đầy đủ:**: (Spain, Italy, Germany). Với những quốc gia có dữ liệu đầy đủ và số ca nhiễm lớn hơn 0, việc dự đoán có phần chính xác hơn và gần với dữ liệu thực tế hơn\n* **Dữ liệu thiếu thốn:** (Algeria, Andorra). Với những quốc gia dữ liệu nhỏ thì không thể dự đoán tốt. Việc dữ liệu ít dẫn đến việc biến đổi logarithm không năm được đặc trưng của diễn biến trong tương lai.\n* **Không có dữ liệu:**. Với các quốc gia không có dữ liệu, thì mô hình luôn đoán không bị nhiễm.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 5. Dự đoán cho giai đoạn sau của đại dịch<a id=\"section5\"></a>\n\nTrong quá trình phát triển của đại dịch, mô hình tuyến tính bắt đầu cho một số kết quả tội tệ hơn khi dự báo. Và việc biết trước được hạn chế của mô hình tuyến tính thì chúng ta cần tìm ra các phương pháp thay thế cho mô hình trên. <br/><br/>\nMô hình mà chúng ta cân nhắc đến:\n- Logistic curve fit\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 5.1. Logistic curve fit <a id=\"section51\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Định nghĩa hàm Logistic tổng quát\ndef logistic_function(x, a, b, c, d):\n    return a / (1. + np.exp(-c * (x - d))) + b\n\n# Huấn luyện mô hình tìm ra bộ tham số tối ưu nhất\ndef fit_logistic(all_data, country_name, province_name, train_lim, target):\n    data_cp = all_data.loc[(all_data['Country_Region']==country_dict[country_name]) & (all_data['Province_State']==province_dict[province_name])]\n    y = data_cp.loc[(data_cp['Day_num'])<=train_lim, target].astype(np.int32)\n    x = list(range(0, len(y)))\n\n    # Khởi tạo bộ tham số đầu tiên\n    p0 = [0,1,1,0]\n\n    (a_, b_, c_, d_), cov = optimize.curve_fit(logistic_function, x, y, bounds=(0, [500000., 10., 1000., 1000., ]), p0=p0, maxfev=10**9)\n    y_fit = logistic_function(x, a_, b_, c_, d_)\n    return x, y, y_fit, (a_, b_, c_, d_), cov\n\n# Vẽ hàm logistic\ndef plot_logistic(x, y, y_fit, country_name, province_name, target):\n    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n    ax.plot(x, y, 'o')\n    ax.plot(x, y_fit, '-')\n    ax.set_xlabel(\"Day count (starting on January 22nd)\")\n    ax.set_ylabel(target)\n    ax.set_title(\"Fit to logistic regression for \"+ country_name+\"/\"+province_name)\n    \n# Vẽ giá trị dự đoán cho một quốc gia\ndef plot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, target, x, a_, b_, c_, d_):\n    forecast = logistic_function(list(range(len(x)+60)), a_, b_, c_, d_)\n    df_train = train.loc[(train['Country_Region']==country_name) & (train['Province_State']==province_name), target]\n    df_fcst = forecast[:len(df_train)]\n    dates = list(range(len(df_train)))\n    \n    # Vẽ kết quả\n    fig, (ax1) = plt.subplots(1, 1, figsize=(6,4))\n    ax1.plot(dates, df_fcst)\n    ax1.plot(dates, df_train)\n    ax1.axvline(len(df_train)-valid_num-1, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.set_title(\"Actual ConfirmedCases vs predictions based on Logistic curve for \"+country_name + \"/\"+province_name)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count starting on January 22nd\")\n    ax1.set_ylabel(\"ConfirmedCases\")\n\n\ntrain_lim = 69\nvalid_lim = 84 \ntest_lim = 112\nvalid_num=valid_lim-train_lim ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Spain**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country_name = 'Spain'\nprovince_name = 'None'\n\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Italy**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country_name = 'Italy'\nprovince_name = 'None'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gemany**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country_name = 'Germany'\nprovince_name = 'None'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Andorra**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country_name = 'Andorra'\nprovince_name = 'None'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**China/Hubei**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country_name = 'China'\nprovince_name = 'Hubei'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Câu 3: Đối tượng dễ chết khi nhiễm COVID-19\nDatasets được lấy từ 3 nguồn: \n    - https://github.com/nytimes/covid-19-data\n    - https://data.cdc.gov/NCHS/Provisional-COVID-19-Death-Counts-by-Sex-Age-and-W/vsak-wrfu\n    - https://catalog.data.gov/dataset/covid-19-confirmed-cases-and-deaths-by-age-group/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#############\n# Daily report : from 22/1/2020\ndata_us = pd.read_csv(\"/kaggle/input/datadeathbygroups/us-states.csv\")\n# data_us.to_excel ('hle.xlsx', index = None, header=True)\n# Weekly report : from \ndata_by_group = pd.read_csv(\"/kaggle/input/datadeathbygroups/death_weekly.csv\")\n##############\n\n# Connecticut\n# Daily report in Connecticut : Chi dung duoc data nay\ndata_by_group_st_conn = pd.read_csv(\"/kaggle/input/datadeathbygroups/case_connecticut.csv\")\n# Sort the data frame by date updated\n# data_by_group_st_conn[\"DateUpdated\"] = pd.to_datetime(data_by_group_st_conn[\"DateUpdated\"])\nprint ('Total case infected in 08/05/2020 (mm/dd/yyyy):' ,sum(data_by_group_st_conn.loc[data_by_group_st_conn[\"DateUpdated\"] == \"08/05/2020\"]['Total cases'].tolist()))\ndisplay(data_by_group_st_conn)\n\nprint(data_by_group_st_conn['AgeGroups'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Chuẩn hóa dữ liệu\nChỉ sử dụng được dữ liệu của bang Connecticut ở Mỹ. Tuy nhiên, số lượng ca nhiễm tại ngày cuối cùng lấy dữ liệu là 50189 khá lớn. Cho nên dùng dữ liệu này để phân tích nhóm em cho rằng có thể chấp nhận được. <br> \nỞ dữ liệu ban đầu, các giá trị trong age groups có sự khác nhau. Cho nên sửa lại các giá trị của age group để dễ dàng xử lý hơn <br>\nNgày tháng ở DateUpdated không theo thứ tự \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sắp xếp lại dữ liệu theo ngày tháng\ndata_by_group_st_conn = data_by_group_st_conn.sort_values(by=\"DateUpdated\")\ndays= data_by_group_st_conn['DateUpdated'].unique().tolist()\nprint(\"From day\", days[0], \"to day\", days[-1], \":\",len(days) ,\"days\")\n# Thay đổi giá trị của age groups\ncol_age = data_by_group_st_conn['AgeGroups'].tolist()\ncol_age = [i.replace(\" \", \"\").replace(\"andolder\",\"+\").replace('19-Oct','10-19') for i in col_age]\ndata_by_group_st_conn.loc[:,'AgeGroups'] = col_age\n\nprint(data_by_group_st_conn['AgeGroups'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Biểu đồ thể hiện số ca","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (myax,myax2) = plt.subplots(1,2,figsize=(17,7))\ndate = data_by_group_st_conn['DateUpdated'].tolist();\ncase_by_age = []\ncol_age = data_by_group_st_conn['AgeGroups'].unique().tolist()\ncol_age.sort()\nfor i in col_age:\n    newlist= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total cases'].tolist()\n    case_by_age.append(newlist)\nidx =0\nfor lists in case_by_age:\n    myax.plot(lists, label= str(col_age[idx]))\n    idx+=1\n\n# Add legend\nmyax.legend(loc=2, ncol=2)\nstrTitle= '1: Total cases infected from ' +days[0]\nmyax.title.set_text(strTitle)\nmyax.set_ylabel(\"Number of cases\", size=13)\nmyax.set_xlabel(\"Days\", size=13)\n# fig, (myax) = plt.subplots(1,1,figsize=(17,7))\n# date = data_by_group_st_conn['DateUpdated'].tolist();\n# date.sort()\ncase_by_age = []\nfor i in col_age:\n    newlist= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total deaths'].tolist()\n    case_by_age.append(newlist)\nidx =0\nfor lists in case_by_age:\n    myax2.plot(lists, label= str(col_age[idx]))\n    idx+=1\n\n# Add legend\nplt.legend(loc=2, ncol=2)\nstrTitle= '2: Total deaths from ' +days[0]\nmyax2.title.set_text(strTitle)\nmyax2.set_ylabel(\"Number of cases\", size=13)\nmyax2.set_xlabel(\"Days\", size=13)\n## Ratio for deaths and infected\nfig, (ratio) = plt.subplots(1,1,figsize=(17,7))\ncase_by_age = []\nfor i in col_age:\n    newlistCase= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total cases'].tolist()\n    newlistDeaths= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total deaths'].tolist()\n    newlist =[newlistDeaths[i]/newlistCase[i] for i in range(len(newlistCase))]\n    print(i ,' : ', statistics.mean(newlist))\n\n    case_by_age.append(newlist)\nidx =0\nfor lists in case_by_age:\n    ratio.plot(lists, label= str(col_age[idx]))\n    idx+=1\n\n# Add legend\nratio.legend(loc=2, ncol=2)\nstrTitle= '3: Ratio between deaths and infected case ' +days[0]\nratio.title.set_text(strTitle)\nratio.set_ylabel(\"Ratio\", size=13)\nratio.set_xlabel(\"Days\", size=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3 Nhận xét\nTrong khoảng thời gian bắt đầu xét là từ ngày 5 tháng 4 năm 2020 đến ngày 5 tháng 8 năm 2020. <br>\nNhóm tuổi từ 50-59 luôn là nhóm có số ca nhiễm lớn nhất. Nhóm dưới 19 tuổi có số ca nhiễm ít hơn các nhóm còn lại (dưới 1000 ca mỗi nhóm nhỏ).  Các nhóm tuổi còn lại có số ca nhiễm từ khoảng 4000 đến 7000 ca.  <br>\n\nTuy nhiên, với số ca tử vong, ta thấy rằng có sự phân hóa rất lớn. Nhóm từ 60 tuổi trở lên có số ca tử vong lớn hơn hẳn các nhóm còn lại. <br>\n\nSau đây là tỉ lệ tử vong trung bình của từng nhóm tuổi\n                <pre><code>\n                0-9    :  0.0036805436389047916\n                10-19  :  0.0011339023561485675\n                20-29  :  0.0008836140413264112\n                30-39  :  0.003452531926642996\n                40-49  :  0.008284981036868547\n                50-59  :  0.019849466571340665\n                60-69  :  0.07255307531462857\n                70-79  :  0.19300914838215322\n                80+    :  0.3501340387535907\n</code></pre>\nVậy với dữ liệu từ bang Connecticut ở Mỹ, ta có thể nói rằng nhóm người **từ 80 tuổi trở lên** khi nhiễm COVID có khả năng chết cao hơn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}