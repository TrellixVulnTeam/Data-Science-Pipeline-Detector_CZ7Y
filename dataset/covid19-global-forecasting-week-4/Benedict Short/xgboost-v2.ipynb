{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"#import libs\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n\n\n#TODO: add lag features with https://medium.com/@NatalieOlivo/use-pandas-to-lag-your-timeseries-data-in-order-to-examine-causal-relationships-f8186451b3a9\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#train = pd.read_csv(\"train.csv\")\n#test = pd.read_csv(\"test.csv\")\n#region_metadata = pd.read_csv(\"region_metadata.csv\")\n#region_date_metadata = pd.read_csv(\"region_date_metadata.csv\")\n# Load Data\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#pandas profiling over data to check for NaNs etc\nimport pandas_profiling as pp\n\npp.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#fix data etc\ndef fixData(input_set):\n    input_set.rename(columns={'Country_Region':'Country'}, inplace=True) #Rename columns\n    input_set.rename(columns={'Province_State':'State'}, inplace=True)   #Rename columns\n    input_set['Date'] = pd.to_datetime(input_set['Date'], infer_datetime_format=True) # change date\n    input_set['Date'] = input_set.Date.dt.strftime(\"%m%d\") # convert format to month-day \n    input_set['Date']  = input_set['Date'].astype(int) # convert to int\n    input_set[\"State\"].fillna(\"\",inplace=True) # fill with \"\"\n    input_set[\"CountryState\"] = input_set[\"Country\"] + input_set[\"State\"]\n    return input_set\n\n#train2 = fixData(train)\ntrain = fixData(train)\ntest = fixData(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#build model and encode\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nfrom xgboost import XGBRegressor as boostmodel\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import r2_score, log_loss\nimport math\n\nlabel = LabelEncoder()\n\nsub = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\nCountryState = train.CountryState.unique()\nfor CS in CountryState:\n    train2 = train[train[\"CountryState\"] == CS]\n    test2 = test[test[\"CountryState\"] == CS]\n    train2.CountryState = label.fit_transform(train2.CountryState)\n    X = train2[['CountryState', 'Date']]\n    Y = train2[['ConfirmedCases']]\n    eval_set  = [(X,Y)]\n    model1 = boostmodel(learning_rate=0.3,silent=0, n_estimators=1000)\n    model1.fit(X, Y,eval_set=eval_set,early_stopping_rounds=100)\n    testX = test2[['CountryState', 'Date']]\n    testX.CountryState = label.fit_transform(testX.CountryState)\n    ConfirmedCases_Pred = model1.predict(testX)\n    X = train2[['CountryState', 'Date']]\n    Y = train2[['Fatalities']]\n    eval_set  = [(X,Y)]\n    model2 = boostmodel(learning_rate=0.3,silent=0, n_estimators=1020)\n    model2.fit(X, Y,eval_set=eval_set,early_stopping_rounds=100)\n    testX = test2[['CountryState', 'Date']]\n    testX.CountryState = label.fit_transform(testX.CountryState)\n    Fatalities_Pred = model2.predict(testX)\n    XForecastId = test2.loc[:, 'ForecastId']\n    output = pd.DataFrame({'ForecastId': XForecastId, 'ConfirmedCases': ConfirmedCases_Pred, 'Fatalities': Fatalities_Pred})\n    sub = pd.concat([sub, output], axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"round(sub,1).head()\n#finaloutput.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub.ConfirmedCases.apply(math.floor)\nsub.ForecastId = sub.ForecastId.astype('int')\nsub.ConfirmedCases = round(sub.ConfirmedCases,1)\nsub.Fatalities = round(sub.Fatalities,1)\nsub = sub[['ForecastId','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creating final submission file\nsub.to_csv(\"submission.csv\",index=False) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":true}},"nbformat":4,"nbformat_minor":4}