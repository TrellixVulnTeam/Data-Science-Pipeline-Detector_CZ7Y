{"cells":[{"metadata":{},"cell_type":"markdown","source":"# I) Quick Introduction"},{"metadata":{},"cell_type":"markdown","source":"What if we can predict the ConfirmedCases and the Fatalities using only one feature? \nWhat if that feature is just the number of days since the start of pandemic in each single region?\n\nI think that could be possible especially in the short term predictions. \n\nSo to make sure I am not totally wrong, I decided to write this notebook to show a possible model using one feature **NbDay**\n\n** $ ConfirmedCases = γ1 * exp( log(α1) * NbDay ) + β1 $ **\n\n** $ Fatalities = γ2 * exp( log(α2) * NbDay ) + β2 $ **\n\nWhere ** $ γ1, α1, β1, γ2, α2, β2 $ ** are all hyperparameters. \n\nAnd the **NbDay** repesents the Number of Days since the start of the pandemic in each Country.\n\nWe can model assuming that ** $ γ1, α1, β1, γ2, α2, β2 $ ** are the same for all the countries. But that won’t be accurate for many reasons.  In fact not all countries have the same political reaction to this pandemic. And not all countries have the same demographical feautures such as the population, the median age, the density of population. In plus, not all countries have the same economical situation. And many other reasons that justifies that it won’t be possible to have same hyperparameters for all the countries.\n\nWe can approximate optimal hyperparameters to model the propagation for each country but the true problem is if all the countries have an exponential growth?! \n\nCan the exponential model be accurate for all the countries? If not, what are the countries that have an exponential growth? \n\nLet's read and check!"},{"metadata":{},"cell_type":"markdown","source":"# II) Preparing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1) Reading the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/covid19-global-forecasting-week-4/train.csv')\ntest = pd.read_csv('../input/covid19-global-forecasting-week-4/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y1=train['ConfirmedCases']\nY2=train['Fatalities']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Modifiying date feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Complete_Date'] = train['Date'].astype('datetime64[ns]')\ntest['Complete_Date'] = test['Date'].astype('datetime64[ns]')\n\nmonth = [int(el[5:7]) for el in list(train['Date'].values)]\nday = [int(el[8:10]) for el in list(train['Date'].values)]\n\nmonth_test = [int(el[5:7]) for el in list(test['Date'].values)]\nday_test = [int(el[8:10]) for el in list(test['Date'].values)]\n\ndf_month= pd.DataFrame(month, columns= ['Month'])\ndf_day= pd.DataFrame(day, columns= ['Day'])\n\ndf_month_test= pd.DataFrame(month_test, columns= ['Month'])\ndf_day_test= pd.DataFrame(day_test, columns= ['Day'])\n\ntrain=pd.concat([train, df_month], axis=1)\ntest=pd.concat([test, df_month_test], axis=1)\n\ntrain=pd.concat([train, df_day], axis=1)\ntest=pd.concat([test, df_day_test], axis=1)\n\ntrain['Date']=train['Month']*100+train['Day']\ntest['Date']=test['Month']*100+test['Day']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3) Combining Province_State and Country_Region in one Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Province_State'].fillna('',inplace=True)\ntest['Province_State'].fillna('',inplace=True)\n\ntrain['Province_State']=train['Province_State'].astype(str)\ntest['Province_State']=test['Province_State'].astype(str)\n\ny= train['Country_Region']+train['Province_State']\ny= pd.DataFrame(y, columns= ['Place'])\n\ny_test= test['Country_Region']+test['Province_State']\ny_test= pd.DataFrame(y_test, columns= ['Place'])\n\ntrain=pd.concat([train, y], axis=1)\ntest=pd.concat([test, y_test], axis=1)\n\nCountry_df=train[\"Place\"]\nConfirmedCases_df=train[\"ConfirmedCases\"]\nCountry_df.to_numpy()\nConfirmedCases_df.to_numpy()\nCountry=Country_df[0]\nNbDay = pd.DataFrame(columns=['NbDay'])\nday=0\ncount=0\nfor x in train[\"Month\"]:\n    if (ConfirmedCases_df[count]==0):      \n        NbDay = NbDay.append({'NbDay': int(0)}, ignore_index=True)\n        count=count+1 \n    else:\n        if (Country_df[count]==Country):\n            day=day+1\n            NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n            count=count+1\n        else:\n            Country=Country_df[count]\n            day=1\n            NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n            count=count+1\ntrain=pd.concat([train, NbDay], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4) Making a new features counting days since the starting of the pandemic for each country"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding NbDay feature to the test data\nNbDay_test_array=np.zeros(test.shape[0])\ni=0\ndf=test[\"Place\"]\nPlace_array=df.to_numpy()\nfor t in test.Date:\n    place=Place_array[i]\n    if t==402:\n        row=train.loc[(train['Place'] == place) & (train['Date'] ==t)]\n        row=row.to_numpy()\n        NbDay_test_array[i]= row[0][10]\n    else: \n        NbDay_test_array[i]=0\n    i=i+1\n\nNbDay=pd.DataFrame(NbDay_test_array, columns=['NbDay1'])\ntest=pd.concat([test,NbDay], axis=1)\n\nCountry_df=test[\"Place\"]\nNbDay_df=test['NbDay1']\nCountry_df.to_numpy()\nday_array=NbDay_df.to_numpy()\nCountry=Country_df[0]\nNbDay = pd.DataFrame(columns=['NbDay'])\nday=0\ncount=0\nfor t in test[\"Date\"]:\n    if (t==402):\n        day=day_array[count] \n        NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)  \n        count=count+1\n    else:\n        day=day+1\n        NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n        count=count+1\ntest=pd.concat([test,NbDay], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5) Taking the essential features for the next steps"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train[['Place','NbDay','ConfirmedCases','Fatalities']]\ntest=test[['Place','NbDay']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III) Warm-up: Checking the exponential shape in my homecountry"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_xy(column1,column2):\n    x=column1.to_numpy()\n    y=column2.to_numpy()\n    \n    f, ax = plt.subplots(figsize=(15,10))\n    plt.plot(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_xy(train[train['Place']=='Tunisia']['NbDay'],train[train['Place']=='Tunisia']['ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train\ntest_data = test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IV) Finding best hyperparameters: alphas to fit the exponential forecasting and Classifiying Countries based on their pandemic growth"},{"metadata":{},"cell_type":"markdown","source":"## 1) Creating a list of all the regions "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_array=train_data['Place'].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def distinct_values(country_array):\n    liste=[]\n    liste.append(country_array[0])\n    for i in range(1,len(country_array)): \n        if country_array[i]!=country_array[i-1]:\n            liste.append(country_array[i])\n    return liste","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Countries_liste=distinct_values(country_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Countries_liste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Finding best alpha1 for each country"},{"metadata":{"trusted":true},"cell_type":"code","source":"def exponentiate_alpha(column,v):\n\n    \n    array=column.to_numpy()\n    \n    string='NbDay'+str(v)\n    \n    array=np.power(v,array)\n        \n    frame=pd.DataFrame(array, columns=[string])\n    \n        \n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nliste_mse_countries=[]\nliste_r2_countries=[]\nresults=[]\n\ni=1\nfor country in Countries_liste:\n    \n    \n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['ConfirmedCases']\n    \n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    #alpha=[1+i*0.0001 for i in range(1,6001)]\n    alpha=[1+i*0.01 for i in range(1,101)]\n\n    liste_mse_countries=[]\n    liste_r2_countries=[]\n    liste_mse=[]\n    liste_r2=[]\n    liste_rmsle=[]\n    \n    print('For country ',i,': *******************', country, '')\n    \n    i=i+1\n    \n    for v in alpha: \n    \n        \n        X1=exponentiate_alpha(train_NbDay,v)\n    \n        \n        X_train,X_test,y_train,y_test = train_test_split(X1,y_NbDay,test_size = 0.3, shuffle= False)\n    \n        # Create linear regression object\n        regr = linear_model.LinearRegression()\n\n        # Train the model using the training sets\n        regr.fit(X_train, y_train)\n\n        # Make predictions using the testing set\n        y_pred = regr.predict(X_test)\n        y_pred = np.maximum(y_pred, 0)\n    \n        #print('For alpha =',v)\n        # The coefficients\n        #print('Coefficients: \\n', regr.coef_)\n        # The mean squared error\n        #print('Mean squared error: %.2f'\n        # % mean_squared_error(y_test, y_pred))\n        #liste_mse.append(mean_squared_error(y_test, y_pred))\n        liste_rmsle.append(np.sqrt(mean_squared_log_error( y_test, y_pred )))\n        \n        # The coefficient of determination: 1 is perfect prediction\n        #print('Coefficient of determination: %.2f'\n        #  % r2_score(y_test, y_pred))\n        liste_r2.append(r2_score(y_test, y_pred))\n\n        #print('***********************************************************************')\n    \n    #argminimum = np.argmin(liste_mse)\n    #argminimum = np.argmin(liste_rmsle)\n    argmaximum = np.argmax(liste_r2)\n    \n    maximum = liste_r2[argmaximum]\n    #minimummse = liste_mse[argmaximum]\n    minimum = liste_rmsle[argmaximum]\n    \n    #liste_mse_countries.append((minimum,argminimum))\n    #liste_r2_countries.append((maximum,argmaximum))\n    \n    results.append([country,maximum,minimum,alpha[argmaximum]])\n    print('Best R2=', maximum, 'where alpha=', alpha[argmaximum])\n    print('where RMLSE=', minimum)\n    #print('where MSE=', minimummse)\n    #print('Best MSE=', minimum, 'where alpha=', alpha[argminimum])\n    print('___________________________________________')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3) Classfiying Places in two groups: Countries with clear ConfirmedCases exponential growth & Countries not showing clear exponential growth"},{"metadata":{"trusted":true},"cell_type":"code","source":"exponential_countries=[]\nnon_exponential_countries=[]\n\nfor liste in results: \n    if liste[1]<0.80 and liste[2]>0.2 : \n        non_exponential_countries.append(liste[0])\n    else : \n        exponential_countries.append((liste[0],liste[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of regions where we can fit an exponential ConfirmedCases model is:',len(exponential_countries),'among a total of:',len(Countries_liste),'.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4) Finding best alpha2 for each country and Classifiying countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"liste_mse_countries=[]\nliste_r2_countries=[]\nresults2=[]\n\ni=1\nfor country in Countries_liste:\n    \n    \n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['Fatalities']\n    \n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    #alpha=[1+i*0.0001 for i in range(1,6001)]\n    alpha=[1+i*0.01 for i in range(1,101)]\n\n    liste_mse_countries=[]\n    liste_r2_countries=[]\n    liste_mse=[]\n    liste_r2=[]\n    liste_rmsle=[]\n    \n    print('For country ',i,': *******************', country, '')\n    \n    i=i+1\n    \n    for v in alpha: \n    \n        \n        X1=exponentiate_alpha(train_NbDay,v)\n    \n        \n        X_train,X_test,y_train,y_test = train_test_split(X1,y_NbDay,test_size = 0.3, shuffle= False)\n    \n        # Create linear regression object\n        regr = linear_model.LinearRegression()\n\n        # Train the model using the training sets\n        regr.fit(X_train, y_train)\n\n        # Make predictions using the testing set\n        y_pred = regr.predict(X_test)\n        y_pred = np.maximum(y_pred, 0)\n    \n        #print('For alpha =',v)\n        # The coefficients\n        #print('Coefficients: \\n', regr.coef_)\n        # The mean squared error\n        #print('Mean squared error: %.2f'\n        # % mean_squared_error(y_test, y_pred))\n        #liste_mse.append(mean_squared_error(y_test, y_pred))\n        liste_rmsle.append(np.sqrt(mean_squared_log_error( y_test, y_pred )))\n        \n        # The coefficient of determination: 1 is perfect prediction\n        #print('Coefficient of determination: %.2f'\n        #  % r2_score(y_test, y_pred))\n        liste_r2.append(r2_score(y_test, y_pred))\n\n        #print('***********************************************************************')\n    \n    #argminimum = np.argmin(liste_mse)\n    #argminimum = np.argmin(liste_rmsle)\n    argmaximum = np.argmax(liste_r2)\n    \n    maximum = liste_r2[argmaximum]\n    #minimummse = liste_mse[argmaximum]\n    minimum = liste_rmsle[argmaximum]\n    \n    #liste_mse_countries.append((minimum,argminimum))\n    #liste_r2_countries.append((maximum,argmaximum))\n    \n    results2.append([country,maximum,minimum,alpha[argmaximum]])\n    print('Best R2=', maximum, 'where alpha=', alpha[argmaximum])\n    print('where RMLSE=', minimum)\n    #print('where MSE=', minimummse)\n    #print('Best MSE=', minimum, 'where alpha=', alpha[argminimum])\n    print('___________________________________________')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5) Classfiying Places in two groups: Countries with clear Fatalities exponential growth & Countries not showing clear exponential growth"},{"metadata":{"trusted":true},"cell_type":"code","source":"exponential_countries=[]\nnon_exponential_countries=[]\n\nfor liste in results2: \n    if liste[1]<0.80 and liste[2]>0.2 : \n        non_exponential_countries.append(liste[0])\n    else : \n        exponential_countries.append((liste[0],liste[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of regions where we can fit an exponential ConfirmedCases model is:',len(exponential_countries),'among a total of:',len(Countries_liste),'.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V) Conclusion"},{"metadata":{},"cell_type":"markdown","source":"$1$) Almost one half of the countries show an exponential growth of confirmedcases and fatalities.\n\n$2$) We can safely model the ConfirmedCases growth with an exponential model for $128$ region and having an $R2$ score higher than $0.8$ and an $RMSLE$ score lower than $0.2$ .\n\n$3$) We can safely model the Fatalities growth with an exponential model for $116$ region and having an $R2$ score higher than $0.8$ and an RMSLE score lower than $0.2$ .\n\n$4$) It is true that this model shows good $R2$ and $RMSLE$ scores for the predictions of half of the regions. However we are aware that its predictions are reliable only on the short term because in the long term we are totally aware that the growth will slow down in all the countries sooner or later so the exponential modeling won't resist in the long term predictions."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}