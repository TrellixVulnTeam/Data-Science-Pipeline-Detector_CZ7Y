{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\ntrain.Province_State.fillna(\"None\", inplace=True)\ndisplay(train.head(5))\ndisplay(train.describe())\nprint(\"Number of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province/State informed: \", train.loc[train['Province_State']!='None']['Country_Region'].unique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_total_date = train.groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date = train.groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_total_date_noChina = train[train['Country_Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_noChina = train[train['Country_Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_country_Italy = train[train['Country_Region']=='Italy'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Italy = train[train['Country_Region']=='Italy'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Italy = train[train['Country_Region']=='Italy'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Italy = train[train['Country_Region']=='Italy'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#confirmed_country_Spain = train[train['Country_Region']=='Spain'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Spain = train[train['Country_Region']=='Spain'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Spain = train[train['Country_Region']=='Spain'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Spain = train[train['Country_Region']=='Spain'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n\n#confirmed_country_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n\n#confirmed_country_Australia = train[train['Country_Region']=='Australia'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Australia = train[train['Country_Region']=='Australia'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Australia = train[train['Country_Region']=='Australia'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Australia = train[train['Country_Region']=='Australia'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n\n#confirmed_country_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\nplt.figure(figsize=(17,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_UK.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pop_italy = 60486683.\npop_spain = 46749696.\npop_UK = 67784927.\npop_singapore = 5837230.\n\ntotal_date_Italy.ConfirmedCases = total_date_Italy.ConfirmedCases/pop_italy*100.\ntotal_date_Italy.Fatalities = total_date_Italy.ConfirmedCases/pop_italy*100.\ntotal_date_Spain.ConfirmedCases = total_date_Spain.ConfirmedCases/pop_spain*100.\ntotal_date_Spain.Fatalities = total_date_Spain.ConfirmedCases/pop_spain*100.\ntotal_date_UK.ConfirmedCases = total_date_UK.ConfirmedCases/pop_UK*100.\ntotal_date_UK.Fatalities = total_date_UK.ConfirmedCases/pop_UK*100.\ntotal_date_Singapore.ConfirmedCases = total_date_Singapore.ConfirmedCases/pop_singapore*100.\ntotal_date_Singapore.Fatalities = total_date_Singapore.ConfirmedCases/pop_singapore*100.\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.ConfirmedCases.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.5)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.ConfirmedCases.plot(ax=plt.gca(), title='Spain')\nplt.ylim(0, 0.5)\n\nplt.subplot(2, 2, 3)\ntotal_date_UK.ConfirmedCases.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.1)\n\nplt.subplot(2, 2, 4)\ntotal_date_Singapore.ConfirmedCases.plot(ax=plt.gca(), title='Singapore')\nplt.ylim(0, 0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population = float(46750238)\ncountry_df = pd.DataFrame()\ncountry_df['ConfirmedCases'] = train.loc[train['Country_Region']=='Spain'].ConfirmedCases.diff().fillna(0)\ncountry_df = country_df[10:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for Spain infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge train and test, exclude overlap\ndates_overlap = ['2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n                 '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14']\ntrain2 = train.loc[~train['Date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Double check that there are no informed ConfirmedCases and Fatalities after 2020-03-11\nall_data.loc[all_data['Date'] >= '2020-04-01', 'ConfirmedCases'] = 0\nall_data.loc[all_data['Date'] >= '2020-04-01', 'Fatalities'] = 0\nall_data['Date'] = pd.to_datetime(all_data['Date'])\n\n# Create date columns\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\n\n# Fill null values given that we merged train-test datasets\nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['ConfirmedCases'].fillna(0, inplace=True)\nall_data['Fatalities'].fillna(0, inplace=True)\nall_data['Id'].fillna(-1, inplace=True)\nall_data['ForecastId'].fillna(-1, inplace=True)\n\ndisplay(all_data)\ndisplay(all_data.loc[all_data['Date'] == '2020-04-01'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missings_count = {col:all_data[col].isnull().sum() for col in all_data.columns}\nmissings = pd.DataFrame.from_dict(missings_count, orient='index')\nprint(missings.nlargest(30, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_lag(df, lag_list, column):\n    for lag in lag_list:\n        column_lag = column + \"_\" + str(lag)\n        df[column_lag] = df.groupby(['Country_Region', 'Province_State'])[column].shift(lag, fill_value=0)\n    return df\n\ndef calculate_trend(df, lag_list, column):\n    for lag in lag_list:\n        trend_column_lag = \"Trend_\" + column + \"_\" + str(lag)\n        df[trend_column_lag] = (df.groupby(['Country_Region', 'Province_State'])[column].shift(0, fill_value=0) - \n                                df.groupby(['Country_Region', 'Province_State'])[column].shift(lag, fill_value=0))/df.groupby(['Country_Region', 'Province_State'])[column].shift(lag, fill_value=0.001)\n    return df\n\n\nts = time.time()\nall_data = calculate_lag(all_data.reset_index(), range(1,7), 'ConfirmedCases')\nall_data = calculate_lag(all_data, range(1,7), 'Fatalities')\nall_data = calculate_trend(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_trend(all_data, range(1,7), 'Fatalities')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)\nprint(\"Time spent: \", time.time()-ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data['Country_Region']=='Spain'].iloc[40:50][['Id', 'Province_State', 'Country_Region', 'Date',\n       'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num', 'ConfirmedCases_1',\n       'ConfirmedCases_2', 'ConfirmedCases_3', 'Fatalities_1', 'Fatalities_2',\n       'Fatalities_3']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load countries data file\nworld_population = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\ndisplay(world_population)\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country (or dependency)', how='left')\nall_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\ndisplay(all_data)\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country (or dependency)', inplace=True, axis=1)\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) \ndisplay(all_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n# Day_num = 38 is March 1st\ny1 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\ny2 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter selected features\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities', \n       'Day_num']\ndata = data[features]\n\n# Apply log transformation to all ConfirmedCases and Fatalities columns, except for trends\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log1p(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)\n\n\n# Split data into train/test\ndef split_data(df, train_lim, test_lim):\n    \n    df.loc[df['Day_num']<=train_lim , 'ForecastId'] = -1\n    df = df[df['Day_num']<=test_lim]\n    \n    # Train set\n    x_train = df[df.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = df[df.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = df[df.ForecastId == -1]['Fatalities']\n\n    # Test set\n    x_test = df[df.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\n# Linear regression model\ndef lin_reg(X_train, Y_train, X_test):\n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    # Train the model using the training sets\n    regr.fit(X_train, Y_train)\n\n    # Make predictions using the testing set\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred\n\n\n# Submission function\ndef get_submission(df, target1, target2):\n    \n    prediction_1 = df[target1]\n    prediction_2 = df[target2]\n\n    # Submit predictions\n    prediction_1 = [int(item) for item in list(map(round, prediction_1))]\n    prediction_2 = [int(item) for item in list(map(round, prediction_2))]\n    \n    submission = pd.DataFrame({\n        \"ForecastId\": df['ForecastId'].astype('int32'), \n        \"ConfirmedCases\": prediction_1, \n        \"Fatalities\": prediction_2\n    })\n    submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select train (real) data from March 1 to last day updated\ndates_list = ['2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', \n                 '2020-03-10', '2020-03-11','2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n                 '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', \n                 '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', \n                 '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.loc[all_data['Country_Region']==country_dict['Spain']][50:70]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_linreg_basic_country(data, country_name, dates_list, day_start, shift, train_lim, test_lim):\n    \n    data_country = data[data['Country_Region']==country_dict[country_name]]\n    data_country = data_country.loc[data_country['Day_num']>=day_start]\n    X_train, Y_train_1, Y_train_2, X_test = split_data(data_country, train_lim, test_lim)\n    model, pred = lin_reg(X_train, Y_train_1, X_test)\n\n    # Create a df with both real cases and predictions (predictions starting on March 12th)\n    X_train_check = X_train.copy()\n    X_train_check['Target'] = Y_train_1\n\n    X_test_check = X_test.copy()\n    X_test_check['Target'] = pred\n\n    X_final_check = pd.concat([X_train_check, X_test_check])\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(30-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (from March \" + str(1+shift) + \" to March 25th)\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    ax2.axvline(30-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (from March \" + str(1+shift) + \" to March 30th)\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \n    \n# Filter Spain, run the Linear Regression workflow\ncountry_name = \"Spain\"\nmarch_day = 10\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\ntrain_lim, test_lim = 69, 113\nplot_linreg_basic_country(data, country_name, dates_list2, day_start, march_day, train_lim, test_lim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\n# Set the dataframe where we will update the predictions\nday_start = 65\ndata2 = data.loc[data.Day_num >= day_start]\ndata_pred3 = data2[data2.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\ndata_pred3['Predicted_ConfirmedCases'] = [0]*len(data_pred3)\ndata_pred3['Predicted_Fatalities'] = [0]*len(data_pred3)\nhow_many_days = test.Date.nunique()\n    \nprint(\"Currently running Linear Regression for all countries\")\n\n# Main loop for countries\nfor c in data['Country_Region'].unique():\n    \n    # List of provinces\n    provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n        \n    # If the country has several Province/State informed\n    if len(provinces_list)>1:\n        \n        for p in provinces_list:\n            # Only fit starting from the first confirmed case in the country\n            train_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n            test_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) &  (data.ForecastId!=-1)]\n            data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n            # If there are no previous cases, predict 0\n            if len(train_countries_no0) == 0:\n                data_pred3.loc[((data_pred2['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n                data_pred3.loc[((data_pred2['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n                \n            # Else run LinReg\n            else: \n                data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp, train_lim, test_lim)\n                model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n                model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n                data_pred3.loc[((data_pred3['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n                data_pred3.loc[((data_pred3['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n    # No Province/State informed\n    else:\n        # Only fit starting from the first confirmed case in the country\n        train_countries_no0 = data.loc[(data['Country_Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n        test_countries_no0 = data.loc[(data['Country_Region']==c) &  (data.ForecastId!=-1)]\n        data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n        # If there are no previous cases, predict 0\n        if len(train_countries_no0) == 0:\n            data_pred3.loc[((data_pred3['Country_Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n            data_pred3.loc[((data_pred3['Country_Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n        \n        # Else, run LinReg\n        else:\n            data_c = data2[(data2['Country_Region']==c)]\n            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c, train_lim, test_lim)\n            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n            data_pred3.loc[(data_pred3['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred3.loc[(data_pred3['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# Aplly exponential transf. and clean potential infinites due to final numerical precision\n#data_pred3[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred3[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n#data_pred3.replace([np.inf, -np.inf], 0, inplace=True) \n\n#get_submission(data_pred3, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Andorra, run the Linear Regression workflow\ncountry_name = \"Andorra\"\nshift = 21\nday_start = 39+shift\ndates_list2 = dates_list[shift:]\nplot_linreg_basic_country(data, country_name, dates_list2, day_start, shift, train_lim, test_lim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New split function, for one forecast day\ndef split_data_one_day(df, d, train_lim, test_lim):\n    \n    df.loc[df['Day_num']<=train_lim , 'ForecastId'] = -1\n    df = df[df['Day_num']<=test_lim]\n    \n    #Train\n    x_train = df[df.Day_num<d]\n    y_train_1 = x_train.ConfirmedCases\n    y_train_2 = x_train.Fatalities\n    x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    #Test\n    x_test = df[df.Day_num==d]\n    x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\ndef plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list, march_day):\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].ConfirmedCases\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(30-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (starting on March \" + str(march_day) + \"))\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    ax2.axvline(30-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \ndef plot_real_vs_prediction_country_fatalities(data, train, country_name, day_start, dates_list, march_day):\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Fatalities\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['Fatalities']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(30-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n    ax1.set_ylabel(\"Fatalities Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    ax2.axvline(30-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n    ax2.set_ylabel(\"Log Fatalities Cases\")\n\n    plt.suptitle((\"Fatalities predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to compute the Linear Regression predictions with lags, for a certain Country/Region\ndef lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict, train_lim, test_lim):\n    \n    ts = time.time()\n    \n    # Filter country and features from all_data (dataset without data leaking)\n    data = all_data.copy()\n    features = ['Id', 'Province_State', 'Country_Region',\n           'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n    data = data[features]\n\n    # Select country an data start (all days)\n    data = data[data['Country_Region']==country_dict[country_name]]\n    data = data.loc[data['Day_num']>=day_start]\n\n    # Lags\n    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n    data = calculate_lag(data, range(1,8), 'Fatalities')\n\n    filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n    filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    \n    # Apply log transformation\n    data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n    data.replace([np.inf, -np.inf], 0, inplace=True)\n    data.fillna(0, inplace=True)\n\n\n    # Start/end of forecast\n    start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n    end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n    for d in list(range(start_fcst, end_fcst+1)):\n        X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d, train_lim, test_lim)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n        # Recompute lags \n        data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n        data = calculate_lag(data, range(1,8), 'Fatalities')\n        data.replace([np.inf, -np.inf], 0, inplace=True)\n        data.fillna(0, inplace=True)\n\n    #print(\"Process for \", country_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n    return data\n\n\n# Function to compute the Linear Regression predictions with lags, for a certain Country/Region and State/province\ndef lin_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict, train_lim, test_lim):\n    \n    ts = time.time()\n    \n    # Filter country and features from all_data (dataset without data leaking)\n    data = all_data.copy()\n    features = ['Id', 'Province_State', 'Country_Region',\n           'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n    data = data[features]\n\n    # Select country an data start (all days)\n    data = data[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])]\n    data = data.loc[data['Day_num']>=day_start]\n\n    # Lags\n    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n    data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n\n    # Apply log transformation\n    filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n    filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n    data.replace([np.inf, -np.inf], 0, inplace=True)\n    data.fillna(0, inplace=True)\n\n    # Start/end of forecast\n    start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n    end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n    for d in list(range(start_fcst, end_fcst+1)):\n        X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d, train_lim, test_lim)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name]) \n                 & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])\n                 & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n        # Recompute lags \n        data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n        data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n        data.replace([np.inf, -np.inf], 0, inplace=True)\n        data.fillna(0, inplace=True)\n\n    #print(\"Process for \", country_name, \"/\", province_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n    return data\n\n\n\n# Run the model for Spain\ncountry_name = 'Spain'\nmarch_day = 10\nday_start = 39 + march_day\ndates_list2 = dates_list[march_day:]\nlag_size = 30\n\ndata_c = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict, train_lim, test_lim)\nplot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\nplot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logistic_function(x, a, b, c, d):\n    return a / (1. + np.exp(-c * (x - d))) + b\n\ndef fit_logistic(all_data, country_name, province_name, train_lim, target):\n    data_cp = all_data.loc[(all_data['Country_Region']==country_dict[country_name]) & (all_data['Province_State']==province_dict[province_name])]\n    y = data_cp.loc[(data_cp['Day_num'])<=train_lim, target].astype(np.int32)\n    x = list(range(0, len(y)))\n\n    # Initial guess\n    p0 = [0,1,1,0]\n\n    (a_, b_, c_, d_), cov = optimize.curve_fit(logistic_function, x, y, bounds=(0, [500000., 10., 1000., 1000., ]), p0=p0, maxfev=10**9)\n    y_fit = logistic_function(x, a_, b_, c_, d_)\n    \n    return x, y, y_fit, (a_, b_, c_, d_), cov\n\ndef plot_logistic(x, y, y_fit, country_name, province_name, target):\n    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n    ax.plot(x, y, 'o')\n    ax.plot(x, y_fit, '-')\n    ax.set_xlabel(\"Day count (starting on January 22nd)\")\n    ax.set_ylabel(target)\n    ax.set_title(\"Fit to logistic regression for \"+ country_name+\"/\"+province_name)\n    \n\ndef plot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, target, x, a_, b_, c_, d_):\n    forecast = logistic_function(list(range(len(x)+60)), a_, b_, c_, d_)\n    df_train = train.loc[(train['Country_Region']==country_name) & (train['Province_State']==province_name), target]\n    df_fcst = forecast[:len(df_train)]\n    dates = list(range(0,len(df_train)))\n    \n    # Plot results\n    fig, (ax1) = plt.subplots(1, 1, figsize=(6,4))\n    ax1.plot(dates, df_fcst)\n    ax1.plot(dates, df_train)\n    ax1.axvline(len(df_train)-valid_num-1, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.set_title(\"Actual ConfirmedCases vs predictions based on Logistic curve for \"+country_name + \"/\"+province_name)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count starting on January 22nd\")\n    ax1.set_ylabel(\"ConfirmedCases\")\n\n\n# Fit country to logistic curve\ncountry_name = 'Spain'\nprovince_name = 'None'\ntrain_lim = 69\nvalid_lim = 84 # needs to be changed as more days of training data are included\ntest_lim = 112\nvalid_num=valid_lim-train_lim \n\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub= pd.read_csv(\"submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}