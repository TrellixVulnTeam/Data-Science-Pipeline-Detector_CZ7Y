{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#plot import\nimport matplotlib.pyplot as plt\nimport seaborn as sns; \n#f, ax = plt.subplots(figsize=(16, 5))\n\n# sklearn machine learning tools import\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import ElasticNet, BayesianRidge\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.metrics import mean_absolute_error\n\n\n\n\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso, RidgeCV\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor, BaggingRegressor\nfrom sklearn.svm import SVR\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold, cross_val_score\ndef create_number_of_dates_feature(dataset):\n    \"\"\"\n    Create a new feature called number_of_days,\n    from the dates in the entire dataset.\n    dataset: train or test\n    \"\"\"\n    data_frame_list = []\n    countries = sorted(list(set(dataset[\"Country_Region\"])))\n    for k, country_name in enumerate(countries):\n        country_dataset = dataset[dataset[\"Country_Region\"] == countries[k]]\n        m = len(country_dataset[\"Date\"])\n        country_dataset[\"number_of_days\"] = [k for k in range(m)]\n        data_frame_list.append(country_dataset)\n    dataset = pd.concat(data_frame_list, axis=0)\n    return dataset\n\ndef country_dataset(dataset, country_index):\n    \"\"\"\n    dataset: train or test\n    country_index: 1:len(countries)\n    \"\"\"\n    countries = sorted(list(set(dataset[\"Country_Region\"])))\n    country = dataset[dataset[\"Country_Region\"] == countries[country_index]]\n    return country\n\ndef cv_rmse(model, X, y):\n    kf = KFold(n_splits=12, random_state=42, shuffle=True)\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kf))\n    return rmse.mean()\n\n\ndef get_best_polynomial_degree(degrees, model, X_train, y_train, X_valid,\n                                y_valid):\n    \"\"\"\n    degrees: list of polynomial degree (degrees = [1,2,3])\n    \"\"\"\n    R2 = {}; MAE = {}; cross_val_error = {}\n    for d in degrees:\n        poly = PolynomialFeatures(d)\n        X_train_poly = poly.fit_transform(X_train)\n        X_valid_poly = poly.fit_transform(X_valid)\n        model.fit(X_train_poly, y_train)\n        cv_rms = cv_rmse(model, X_train_poly, y_train)\n        y_preds = model.predict(X_valid_poly)\n        mae = mean_absolute_error(y_valid, y_preds)\n        r2 = r2_score(y_valid, y_preds)\n        R2[d] = r2; MAE[d] = mae\n        cross_val_error[d] = cv_rms\n    R2 = dict(sorted(R2.items(), key=lambda x: x[1], reverse=True))\n    MAE = sorted(MAE.items(), key=lambda x: x[1])\n    cross_val_error = sorted(cross_val_error.items(), key=lambda x: x[1])\n    return R2, MAE, cross_val_error\n\n\n\n\n\nMODELS = {\n\"KernelRideg\": KernelRidge(), \"LinerRegression\": LinearRegression(),\n\"Ridge\": Ridge(), \"lasso\": Lasso(), \"RidgeCV\": RidgeCV(),\n\"BayessianRidge\": BayesianRidge(), \"ElasticNet\": ElasticNet(),\n\"ElasticNetCV\": ElasticNetCV(), \"RandomForestRegressor\":RandomForestRegressor(),\n\"AdaBoostRegressor\": AdaBoostRegressor(),\n\"GradientBoostingRegressor\": GradientBoostingRegressor(),\n\"BaggingRegressor\": BaggingRegressor(), \"SVR\": SVR(),\n\"LGBMRegressor\": LGBMRegressor(), \"XGBRegressor\": XGBRegressor()\n}\ndef get_best_model(degree, X_train, y_train, X_valid,y_valid):\n    fitted_models = {}\n    R2 = {}; MAE = {}; cross_val_error = {}\n    poly = PolynomialFeatures(degree)\n    for name, model in MODELS.items():\n        X_train_poly = poly.fit_transform(X_train)\n        X_valid_poly = poly.fit_transform(X_valid)\n        model.fit(X_train_poly, y_train)\n        fitted_models[name] = model\n        cv_rms = cv_rmse(model, X_train_poly, y_train)\n        y_preds = model.predict(X_valid_poly)\n        mae = mean_absolute_error(y_valid, y_preds)\n        r2 = r2_score(y_valid, y_preds)\n        R2[name] = r2; MAE[name] = mae\n        cross_val_error[name] = cv_rms\n    R2 = dict(sorted(R2.items(), key=lambda x: x[1], reverse=True))\n    MAE = sorted(MAE.items(), key=lambda x: x[1])\n    optimum_model_name  = MAE[0][0]\n    optimum_model = fitted_models[optimum_model_name]\n    return R2, MAE, cross_val_error, optimum_model\n\n\n\ndef get_predictions(degree, X_train, y_train, X_valid,\n                                y_valid, X_test):\n    poly = PolynomialFeatures(degree)\n    X_test_poly = poly.fit_transform(X_test)\n    _, _, _, optimum_model = get_best_model(degree, X_train,\n                                    y_train, X_valid, y_valid)\n    #print(optimum_model)\n    test_preds = optimum_model.predict(X_test_poly)\n    return test_preds\n\n\n\n\ndef fatality_prediction_per_country(country_index, train, test):\n    train = create_number_of_dates_feature(train)\n    test = create_number_of_dates_feature(test)\n    country_train = country_dataset(train, country_index)\n    country_test = country_dataset(test, country_index)\n    scalar_test = StandardScaler()\n    # fatalities split train test\n    X_test = country_test[[\"number_of_days\"]]\n    X_test = scalar_test.fit_transform(X_test)\n    X_train_fatalities = country_train[[\"number_of_days\"]]\n    y_train_fatalities = country_train[\"Fatalities\"].values.reshape(-1,1)\n\n\n    X_train_fat, X_valid_fat, y_train_fat, y_valid_fat = train_test_split(X_train_fatalities, y_train_fatalities,\n                                                                test_size=0.20, random_state=42)\n    # Normalization for fatalities\n    scalar_train = StandardScaler()\n    X_train_fat = scalar_train.fit_transform(X_train_fat)\n    y_train_fat = scalar_train.fit_transform(y_train_fat)\n\n    scalar_valid = StandardScaler()\n    X_valid_fat = scalar_valid.fit_transform(X_valid_fat)\n    y_valid_fat = scalar_valid.fit_transform(y_valid_fat)\n    degrees = [4,5,6,7]\n    model = LinearRegression()\n    R21, MAE1, cross_val_err1 = get_best_polynomial_degree(degrees, model, X_train_fat, y_train_fat, X_valid_fat, y_valid_fat)\n    optimum_degree, mae_score = MAE1[0][0], MAE1[0][1]\n    predictions = get_predictions(optimum_degree, X_train_fat, y_train_fat, X_valid_fat, y_valid_fat, X_test)\n    y_pr = list(scalar_test.inverse_transform(predictions))\n    y_prediction = list(map(lambda x: int(x), y_pr))\n    return y_prediction\n\n\n\ndef confirm_cases_prediction_per_country(country_index, train, test):\n    train = create_number_of_dates_feature(train)\n    test = create_number_of_dates_feature(test)\n    country_train = country_dataset(train, country_index)\n    country_test = country_dataset(test, country_index)\n    scalar_test = StandardScaler()\n    # fatalities split train test\n    X_test = country_test[[\"number_of_days\"]]\n    X_test = scalar_test.fit_transform(X_test)\n    X_train_fatalities = country_train[[\"number_of_days\"]]\n    y_train_fatalities = country_train[\"ConfirmedCases\"].values.reshape(-1,1)\n\n\n    X_train_fat, X_valid_fat, y_train_fat, y_valid_fat = train_test_split(X_train_fatalities, y_train_fatalities,\n                                                                test_size=0.20, random_state=42)\n    # Normalization for fatalities\n    scalar_train = StandardScaler()\n    X_train_fat = scalar_train.fit_transform(X_train_fat)\n    y_train_fat = scalar_train.fit_transform(y_train_fat)\n\n    scalar_valid = StandardScaler()\n    X_valid_fat = scalar_valid.fit_transform(X_valid_fat)\n    y_valid_fat = scalar_valid.fit_transform(y_valid_fat)\n    degrees = [4,5,6,7]\n    model = LinearRegression()\n    R21, MAE1, cross_val_err1 = get_best_polynomial_degree(degrees, model, X_train_fat, y_train_fat, X_valid_fat, y_valid_fat)\n    optimum_degree, mae_score = MAE1[0][0], MAE1[0][1]\n    predictions = get_predictions(optimum_degree, X_train_fat, y_train_fat, X_valid_fat, y_valid_fat, X_test)\n    y_pr = list(scalar_test.inverse_transform(predictions))\n    y_prediction = list(map(lambda x: int(x), y_pr))\n    return y_prediction\n\n\ndef prediction_dataframe(test, train):\n    container = []\n    countries = sorted(list(set(test[\"Country_Region\"])))\n    m = len(countries)\n    indexes = [k for k in range(m)]\n    for country_index in indexes:\n        country = test[test[\"Country_Region\"] == countries[country_index]]\n        ForecastId = list(country[\"ForecastId\"])\n        fat_preds = fatality_prediction_per_country(country_index, train, test)\n        conf_preds = confirm_cases_prediction_per_country(country_index, train, test)\n        d = {\"ForecastId\":ForecastId, \"ConfirmedCases\":conf_preds,\"Fatalities\":fat_preds}\n        df = pd.DataFrame(d)\n        container.append(df)\n    df_sub = pd.concat(container, axis=0)\n    df_sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = create_number_of_dates_feature(train)\ntest = create_number_of_dates_feature(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_dataframe(test, train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}