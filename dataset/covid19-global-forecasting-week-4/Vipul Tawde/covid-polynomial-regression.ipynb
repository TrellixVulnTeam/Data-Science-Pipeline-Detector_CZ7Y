{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Read Data & Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_log_error\nfrom math import sqrt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv');\ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Date'] = pd.to_datetime(df_train['Date'], format = '%Y-%m-%d');\ndf_test['Date'] = pd.to_datetime(df_test['Date'], format = '%Y-%m-%d');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Country_Region'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Why would some countries have more data points"},{"metadata":{"trusted":true},"cell_type":"code","source":"grp_obj = df_train.groupby(['Country_Region','Province_State']);\ndf = pd.DataFrame(grp_obj.agg({'Date':['min','max','count']}))\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[('Date','min')].value_counts())\nprint(df[('Date','max')].value_counts())\nprint(df[('Date','count')].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So every region level has 81 data points corresponding to each day."},{"metadata":{"trusted":true},"cell_type":"code","source":"grp_obj = df_test.groupby(['Country_Region','Province_State']);\ndf = pd.DataFrame(grp_obj.agg({'Date':['min','max','count']}))\nprint(df[('Date','count')].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine Country and Province\ndef combine_country_province(df):\n    df.loc[:,'Province_State'] = df['Province_State'].fillna(\"\")\n    df.loc[:,'Region'] = df['Country_Region'] + \" \" + df['Province_State']\n    df.loc[:,'Region'] = df.loc[:,'Region'].str.strip();\n    df = df.drop(\n        labels=['Province_State','Country_Region'],\n        axis='columns',\n        inplace=False\n        )\n    return df;\n    \ndf_train = combine_country_province(df_train);\ndf_test = combine_country_province(df_test);\ndf_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Convert Date to Days since # 22 Jan 2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"def days_since_dataset(df):\n    df['Date2'] = df['Date'] - datetime.datetime.strptime('22012020', \"%d%m%Y\")\n    df['Date2'] = df['Date2'].dt.days;\n    return df['Date2'];\n    \ndf_train['Date2'] = days_since_dataset(df_train)\ndf_test['Date2'] = days_since_dataset(df_test)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_train['Region'].unique();\nfor idx, val in enumerate(temp):\n    print(idx,val);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regions = df_train['Region'].unique();\nregions = regions[65:68]\n\nfor idx, region in enumerate(regions):\n    plt.figure(idx);\n    f, ax = plt.subplots(1, 2, figsize=(20,5*1));\n    text = \"*\"*10+'INDEX='+str(idx)+\"*\"*10+\"REGION <---->\"+region+\"*\"*10\n    plt.figtext(.5,.9,text, fontsize=20, color='red', ha='center')\n    df = df_train.loc[df_train['Region'] == region,:]\n    sns.regplot(data = df, x='Date2', y='ConfirmedCases', ax=ax[0],order=4)\n    sns.regplot(data = df, x='Date2', y='Fatalities', ax=ax[1],order=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* A plot of order 5 seems better fit for most variables.\n* We will develop models for 'UPTO' 5 degree polynomials and compare scores to finalize on one."},{"metadata":{},"cell_type":"markdown","source":"# 4. CUSTOM FUNCTIONS"},{"metadata":{"trusted":true},"cell_type":"code","source":"def err_func(y_true,y_pred):\n    msle =  mean_squared_log_error(y_true, y_pred);\n    return sqrt(msle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Test Split\n# n = len(df_train['Date2'].unique());\n# print(n);\n# train_bool = df_train['Date2'] < 70;\n\n# train = df_train.loc[train_bool,:];\n# valid = df_train.loc[~train_bool,:];\n\n# train.shape, valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PARAMS\ndegree = 4\n# MODEL\npoly = PolynomialFeatures(degree = degree, include_bias=False)\nmodel1 = LinearRegression()\nmodel2 = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_cols = ['Date2'];\n# y1_col = ['ConfirmedCases']\n# y2_col = ['Fatalities']\n\n# all_pred_train = pd.DataFrame();\n# all_pred_valid = pd.DataFrame();\n\n# regions = df_train['Region'].unique();\n# regions = ['Japan','Portugal']\n# for idx, region in enumerate(regions):\n#     this_region_train = train['Region'] == region;\n#     this_region_valid = valid['Region'] == region;\n    \n#     X0_train_iter = train.loc[this_region_train,X_cols];\n#     y1_train_iter = train.loc[this_region_train,y1_col];\n#     y2_train_iter = train.loc[this_region_train,y2_col];\n    \n#     X0_valid_iter = valid.loc[this_region_valid,X_cols];\n#     y1_valid_iter = valid.loc[this_region_valid,y1_col];\n#     y2_valid_iter = valid.loc[this_region_valid,y2_col];\n    \n#     X0_train_iter = poly.fit_transform(X0_train_iter);\n#     X0_valid_iter = poly.fit_transform(X0_valid_iter);\n\n#     model1.fit(X0_train_iter, y1_train_iter);\n#     y1_train_iter_pred = model1.predict(X0_train_iter);\n#     y1_valid_iter_pred = model1.predict(X0_valid_iter);\n\n#     model2.fit(X0_train_iter, y2_train_iter);\n#     y2_train_iter_pred = model2.predict(X0_train_iter);\n#     y2_valid_iter_pred = model2.predict(X0_valid_iter);\n    \n#     pred_iter_train = pd.DataFrame({\n#         'Id': train.loc[this_region_train,'Id'],\n#         'ConfirmedCases': y1_train_iter_pred.reshape(-1),\n#         'Fatalities': y2_train_iter_pred.reshape(-1)\n#     })\n#     all_pred_train = pd.concat([all_pred_train, pred_iter_train], axis = 0);\n    \n    \n#     pred_iter_valid = pd.DataFrame({\n#         'Id': valid.loc[this_region_valid,'Id'],\n#         'ConfirmedCases': y1_valid_iter_pred.reshape(-1),\n#         'Fatalities': y2_valid_iter_pred.reshape(-1)\n#     })\n#     all_pred_valid = pd.concat([all_pred_valid, pred_iter_valid], axis = 0);\n    \n# print(all_pred_train)\n# print(all_pred_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cols = ['Date2'];\ny1_col = ['ConfirmedCases']\ny2_col = ['Fatalities']\n\nall_pred_train = pd.DataFrame();\nall_pred_test = pd.DataFrame();\n\nregions = df_train['Region'].unique();\n\ntrain = df_train.copy();\ntest = df_test.copy();\n\n\nfor idx, region in enumerate(regions):\n    scaler = StandardScaler();\n    \n    this_region_train = train['Region'] == region;\n    this_region_test = test['Region'] == region;\n    \n    X0_train_iter = train.loc[this_region_train,X_cols];\n    y1_train_iter = train.loc[this_region_train,y1_col];\n    y2_train_iter = train.loc[this_region_train,y2_col];\n    \n    X0_test_iter = test.loc[this_region_test,X_cols];\n\n    X0_train_iter = poly.fit_transform(X0_train_iter);\n    X0_test_iter = poly.fit_transform(X0_test_iter);\n    \n    X0_train_iter = scaler.fit_transform(X0_train_iter)\n    X0_test_iter = scaler.transform(X0_test_iter)\n    \n#     scaler_y1 = StandardScaler();\n#     scaler_y1.fit_transform(y1_train_iter);\n    \n    model1.fit(X0_train_iter, y1_train_iter);\n    y1_train_iter_pred = model1.predict(X0_train_iter);\n    y1_test_iter_pred = model1.predict(X0_test_iter);\n\n#     scaler_y2 = StandardScaler();\n#     scaler_y2.fit_transform(y2_train_iter);\n    \n    model2.fit(X0_train_iter, y2_train_iter);\n    y2_train_iter_pred = model2.predict(X0_train_iter);\n    y2_test_iter_pred = model2.predict(X0_test_iter);\n    \n    pred_iter_train = pd.DataFrame({\n        'Id': train.loc[this_region_train,'Id'],\n        'ConfirmedCases': y1_train_iter_pred.reshape(-1),\n        'Fatalities': y2_train_iter_pred.reshape(-1)\n    })\n    all_pred_train = pd.concat([all_pred_train, pred_iter_train], axis = 0);\n    \n    \n    pred_iter_test = pd.DataFrame({\n        'ForecastId': test.loc[this_region_test,'ForecastId'],\n        'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n        'Fatalities': y2_test_iter_pred.reshape(-1)\n    })\n    all_pred_test = pd.concat([all_pred_test, pred_iter_test], axis = 0);\n    \nprint(all_pred_train)\nprint(all_pred_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pred_test = all_pred_test.astype('int')\n\n# all_pred_test.to_csv(\"submission.csv\", index = False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# answer = pd.merge(df_test,all_pred_test, left_on = 'ForecastId',right_on = 'ForecastId');\n\n# answer['true_cc'] = -1;\n# answer['true_fat'] = -1;\n\n# train_max_date = train['Date2'].max()\n# test_min_date = test['Date2'].min()\n# for idx, region in enumerate(regions):\n#     temp = train.loc[((train['Date2'] >= test_min_date) & (train['Region'] == region)),['ConfirmedCases','Fatalities']]\n#     answer.loc[((answer['Date2'] <= train_max_date) & (answer['Region'] == region)),['true_cc','true_fat']] = temp\n#     print(temp.info())\n    \n\n# answer2 = answer.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pred_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = pd.merge(df_test,all_pred_test, left_on = 'ForecastId',right_on = 'ForecastId');\n\ntrain_max_date = train['Date2'].max()\ntest_min_date = test['Date2'].min()\nfor idx, region in enumerate(regions):\n    sel1 = ((train['Date2'] >= test_min_date) & (train['Region'] == region));\n    to_paste = train.loc[sel1,['ConfirmedCases','Fatalities']].copy();\n    sel2 = ((answer['Date2'] <= train_max_date) & (answer['Region'] == region))\n    answer.loc[sel2,['ConfirmedCases','Fatalities']] = to_paste.loc[:,['ConfirmedCases','Fatalities']].values;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = answer.loc[:,['ForecastId','ConfirmedCases','Fatalities']]\nanswer = answer.astype('int');\nanswer.to_csv(\"submission.csv\", index = False);\nanswer.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# a = pd.DataFrame({'c1':[1,2,3],'c2':[1,2,3]})\n# b = pd.DataFrame({'c3':[82,73,77],'c4':[9,9,9]})\n\n# a.loc[:,['c1','c2']] = b.loc[:,['c3','c4']].values;\n# a","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}