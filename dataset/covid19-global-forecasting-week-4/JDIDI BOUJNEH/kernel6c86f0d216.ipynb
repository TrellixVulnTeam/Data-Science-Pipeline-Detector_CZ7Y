{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")#index_col=0\ndisplay(train_data.head())\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")#index_col=0\ndisplay(test_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_df = pd.pivot_table(train_data, values=['ConfirmedCases','Fatalities'], index=['Date'],aggfunc=np.sum)\ndisplay(sum_df.max())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#UPDATES TO ADD THE NEW COLUMNS\ntrain_data['NewConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\ntrain_data['NewConfirmedCases'] = train_data['NewConfirmedCases'].fillna(0.0)\ntrain_data['NewFatalities']     = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\ntrain_data['NewFatalities']     = train_data['NewFatalities'].fillna(0.0)#.astype(int)\ntrain_data['MortalityRate']     = train_data['Fatalities'] / train_data['ConfirmedCases']\ntrain_data['MortalityRate']     = train_data['MortalityRate'].fillna(0.0)\ntrain_data['GrowthRate']        = train_data['NewConfirmedCases']/train_data['NewConfirmedCases'].shift(1)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].replace([-np.inf, np.inf],  0.0)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].fillna(0.0) \ndisplay(train_data.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getColumnInfo(df):\n    n_province =  df['Province_State'].nunique()\n    n_country  =  df['Country_Region'].nunique()\n    n_days     =  df['Date'].nunique()\n    start_date =  df['Date'].unique()[0]\n    end_date   =  df['Date'].unique()[-1]\n    return n_province, n_country, n_days, start_date, end_date\n\nn_train = train_data.shape[0]\nn_test = test_data.shape[0]\n\nn_prov_train, n_count_train, n_train_days, start_date_train, end_date_train = getColumnInfo(train_data)\nn_prov_test,  n_count_test,  n_test_days,  start_date_test,  end_date_test  = getColumnInfo(test_data)\n\nprint ('<==Train data==> \\n # of Province_State: '+str(n_prov_train),', # of Country_Region:'+str(n_count_train), \n       ', Time Period: '+str(start_date_train)+' to '+str(end_date_train), '==> days:',str(n_train_days))\nprint(\"\\n Countries with Province/State information:  \", train_data[train_data['Province_State'].isna()==False]['Country_Region'].unique())\nprint ('\\n <==Test  data==> \\n # of Province_State: '+str(n_prov_test),', # of Country_Region:'+str(n_count_test),\n       ', Time Period: '+start_date_test+' to '+end_date_test, '==> days:',n_test_days)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = test_data.loc[test_data.Date > '2020-04-03']\noverlap_days = n_test_days - df_test.Date.nunique()\nprint('\\n overlap days with training data: ', overlap_days, ', total days: ', n_train_days+n_test_days-overlap_days)\n\nprob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\nprob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\n\nn_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\nn_fatal_train = train_data.Fatalities.value_counts()[1:].sum()\n\nprint('Percentage of confirmed case  = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_confirm_train, n_train, prob_confirm_check_train[1:].sum()*100))\nprint('Percentage of fatality  = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_fatal_train, n_train, prob_fatal_check_train[1:].sum()*100))\n\ntrain_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum',\n                                                                                         'GrowthRate':'mean' })\nmax_train_date = train_data['Date'].max()\ntrain_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\ntrain_data_by_country_confirm.set_index('Country_Region', inplace=True)\ndisplay(train_data_by_country_confirm.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom itertools import cycle, islice\ndiscrete_col = list(islice(cycle(['BLUE', 'r', 'g', 'k', 'b', 'c', 'm']), None, len(train_data_by_country_confirm.head(30))))\nplt.rcParams.update({'font.size': 24})\ntrain_data_by_country_confirm.head(20).plot(figsize=(20,15), kind='barh', color=discrete_col)\nplt.legend([\"Confirmed Cases\", \"Fatalities\"]);\nplt.xlabel(\"Number of Covid-19 Affectees\")\nplt.title(\"First 20 Countries with Highest Confirmed Cases\")\nylocs, ylabs = plt.yticks()\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"ConfirmedCases\"][:]):\n    plt.text(v+0.01, ylocs[i]-0.25, str(int(v)), fontsize=12)\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"Fatalities\"][:]):\n    if v > 0: #disply for only >300 fatalities\n        plt.text(v+0.01,ylocs[i]+0.1,str(int(v)),fontsize=12)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reformat_time(reformat, ax):\n    ax.xaxis.set_major_locator(dates.WeekdayLocator())\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%b %d'))    \n    if reformat: #reformat again if you wish\n        date_list = train_data_by_date.reset_index()[\"Date\"].tolist()\n        x_ticks = [dt.datetime.strftime(t,'%Y-%m-%d') for t in date_list]\n        x_ticks = [tick for i,tick in enumerate(x_ticks) if i%8==0 ]# split labels into same number of ticks as by pandas\n        ax.set_xticklabels(x_ticks, rotation=90)\n    # cosmetics\n    ax.yaxis.grid(linestyle='dotted')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['left'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'sum','Fatalities': 'sum', \n                                                                     'NewConfirmedCases':'sum', 'NewFatalities':'sum', 'MortalityRate':'mean'})\nnum0 = train_data_by_date._get_numeric_data() \nnum0[num0 < 0.0] = 0.0\n\n\ntrain_data_by_country_max = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\ntrain_data_by_country_fatal = train_data_by_country_max[train_data_by_country_max['Fatalities']>500]\ntrain_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\ndisplay(train_data_by_country_fatal.head(20))\n\ndf_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\ndf_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n                                                                                                     'Fatalities': 'sum',\n                                                                                                     'NewConfirmedCases':'sum',\n                                                                                                     'NewFatalities':'sum',\n                                                                                                     'MortalityRate':'mean'})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig,(ax4,ax5) = plt.subplots(1,2,figsize=(20, 8))\n\ntrain_data_by_date.MortalityRate.plot(ax=ax4, x_compat=True, legend='Mortality Rate',color='r')\nreformat_time(0,ax4)\nfor num, country in enumerate(countries):\n    match = df_max_fatality_country.Country_Region==country \n    df_fatality_by_country = df_max_fatality_country[match] \n    df_fatality_by_country.MortalityRate.plot(ax=ax5, x_compat=True, title='Average Mortality Rate Nationally')    \n    reformat_time(0,ax5)\n\nax5.legend(countries, loc='center left',bbox_to_anchor=(1.0, 0.5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_max_date = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)')\ntrain_data_by_max_date.loc[:, 'MortalityRate'] = train_data_by_max_date.loc[:,'Fatalities']/train_data_by_max_date.loc[:,'ConfirmedCases']\ntrain_data_by_mortality = train_data_by_max_date.sort_values('MortalityRate', ascending=False)\ntrain_data_by_mortality.set_index('Country_Region', inplace=True)\ndisplay(train_data_by_mortality.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"palette = plt.get_cmap('gist_rainbow')\n\nrainbow_col = [palette(1.*i/20.0) for i in range(20)]\n\ntrain_data_by_mortality.MortalityRate.head(20).plot(figsize=(15,10), kind='barh', color=rainbow_col)\nplt.xlabel(\"Mortality Rate\")\nplt.title(\"First 20 Countries with Highest Mortality Rate\")\nylocs, ylabs = plt.yticks()\n\nworld_df = train_data_by_country.query('Date == @max_train_date')\nworld_df.loc[:,'Date']           = world_df.loc[:,'Date'].apply(str)\nworld_df.loc[:,'Confirmed_log']  = round(np.log10(world_df.loc[:,'ConfirmedCases'] + 1), 3)\nworld_df.loc[:,'Fatalities_log'] = np.log10(world_df.loc[:,'Fatalities'] + 1)\nworld_df.loc[:,'MortalityRate']  = round(world_df.loc[:, 'Fatalities'] / world_df.loc[:,'ConfirmedCases'], 3)\nworld_df.loc[:,'AveGrowthFactor']  = round(world_df.loc[:,'GrowthRate'], 3)\nworld_df.drop(['GrowthRate'], axis=1) #drop as this is actually the average over all the 74 days\ndisplay(world_df.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Models\n\ntrain_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\n\n# Replacing all the Province_State that are null by the Country_Region values\ntrain_df.Province_State.fillna(train_df.Country_Region, inplace=True)\ntest_df.Province_State.fillna(test_df.Country_Region, inplace=True)\n\n# Handling the Date column\n# 1. Converting the object type column into datetime type\ntrain_df.Date = train_df.Date.apply(pd.to_datetime)\ntest_df.Date = test_df.Date.apply(pd.to_datetime)\n\n#Extracting Date and Month from the datetime and converting the feature as int\ntrain_df.Date = train_df.Date.dt.strftime(\"%m%d\").astype(int)\ntest_df.Date = test_df.Date.dt.strftime(\"%m%d\").astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ntrain_df.Country_Region = le.fit_transform(train_df.Country_Region)\ntrain_df['Province_State'] = le.fit_transform(train_df['Province_State'])\n\ntest_df.Country_Region = le.fit_transform(test_df.Country_Region)\ntest_df['Province_State'] = le.fit_transform(test_df['Province_State'])\n\n\nX_train = train_df.drop([\"Id\", \"ConfirmedCases\", \"Fatalities\"], axis = 1) \n \nY_train_CC = train_df[\"ConfirmedCases\"] \nY_train_Fat = train_df[\"Fatalities\"] \n\nX_test = test_df.drop([\"ForecastId\"], axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit, cross_val_score\nskfold = ShuffleSplit(random_state=7)\n\n\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf_bgr_CC = BaggingRegressor(base_estimator = DecisionTreeRegressor(), n_estimators = 40)\nclf_bgr_Fat = BaggingRegressor(base_estimator = DecisionTreeRegressor(), n_estimators = 20)\n\nbgr_acc = cross_val_score(clf_bgr_CC, X_train, Y_train_CC, cv = skfold)\nbgr_acc_fat = cross_val_score(clf_bgr_Fat, X_train, Y_train_Fat, cv = skfold)\nprint (bgr_acc.mean(), bgr_acc_fat.mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_bgr_CC.fit(X_train, Y_train_CC)\nY_pred_CC = clf_bgr_CC.predict(X_test) \n\nclf_bgr_Fat.fit(X_train, Y_train_Fat)\nY_pred_Fat = clf_bgr_Fat.predict(X_test) \n\nprint (Y_pred_Fat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\nsoln = pd.DataFrame({'ForecastId': test_df.ForecastId, 'ConfirmedCases': Y_pred_CC, 'Fatalities': Y_pred_Fat})\ndf_out = pd.concat([df_out, soln], axis=0)\ndf_out.ForecastId = df_out.ForecastId.astype('int')\ndf_out.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}