{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Logistic, Exponential and Linear regimes\n\n> The goal of this notebook is to check if we reach similar RMSE using very simple models. The intuition is that each epidemic is vastly more complex than what our models can predict.\n\nMy hypothesis:\n1. Only if we noticed an inflexion point can we roughly predict the final value of cases\n1. Slowdown in the exponential growth cannot be predicted, thus we will randomly predict it\n1. Slow growth will stay slow (unless an outbreak really starts)\n\nWe then have three regimes, **the only one** we would accept to give a proper prediction would be the ones that have experienced their inflexion point. In other words, we can predict something once it's almost finished.\n\nFor the two other _unpredictable_ regimes — that we will call linear and exponential — we will rely on nothing complex:\n*  simple linear regression for those in the linear regime\n*  random exponential drop (between 7 and 21 days) for those in the exponential regime"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Downgrades matplotlib since plotnine is not yet compatible.\n!pip install -q \"matplotlib==3.2.1\" \"plotnine==0.5.1\" adjustText","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime\nimport random\n\nimport matplotlib.pyplot as plt\nfrom mizani.breaks import date_breaks\nfrom mizani.breaks import timedelta_breaks\nfrom mizani.formatters import date_format\nfrom mizani.formatters import timedelta_format\nfrom mizani.formatters import comma_format\nfrom mizani.transforms import log2_trans\nimport numpy as np\nimport pandas as pd\nimport plotnine as gg\nfrom plotnine.themes import elements\nimport statsmodels.api as sm\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SUBMIT_FOR_PRIVATE_LEADERBOARD = True\n\nif SUBMIT_FOR_PRIVATE_LEADERBOARD:\n    train_end_date = '2020-04-15'\n    pred_start_date = '2020-04-16'\n    pred_end_date = '2020-05-14'\nelse:\n    train_end_date = '2020-03-31'\n    pred_start_date = '2020-04-01'\n    pred_end_date = '2020-04-15'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\n    '/kaggle/input/covid19-global-forecasting-week-4/train.csv',\n    parse_dates=['Date'])\ndf_train = df_train[df_train.Date <= train_end_date]\ndf_train.groupby('Country_Region').tail(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\n    '/kaggle/input/covid19-global-forecasting-week-4/test.csv',\n    parse_dates=['Date'])\ndf_test = df_test[(df_test.Date >= pred_start_date) & (df_test.Date <= pred_end_date)]\ndf_test.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(_df):\n    df = _df.copy()\n    df['GeoEntity'] = _df['Country_Region'] + '_' + _df['Province_State'].fillna('All')\n    \n    # Generates the rolling means for `confirmed`.\n    if 'ConfirmedCases' in df.columns:\n        group_frames = []\n        grouped = df.sort_values('Date').groupby('GeoEntity')\n        for group in grouped.groups:\n            frame = grouped.get_group(group).copy()\n            frame['NewConfirmedCases'] = frame.ConfirmedCases - frame.ConfirmedCases.shift(1)\n            frame['NewConfirmedCasesSmoothed'] = frame.rolling(7).NewConfirmedCases.mean()\n            frame['NewConfirmedCasesGrowth'] = frame.NewConfirmedCases.pct_change()\n            frame['NewConfirmedCasesGrowthSmoothed'] = frame.rolling(7).NewConfirmedCasesGrowth.mean()\n            group_frames.append(frame)\n        df = pd.concat(group_frames)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = preprocess(df_train)\ndf_test = preprocess(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df_train.sample(5))\ndisplay(df_test.sample(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic regime\n\nInspired by the [YouTube video of MinutePhysics](https://youtu.be/54XLXg4fYsc), we will identify logistic regime when a consistent slow down in the number of new cases has been observed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plots for validation.\nselected_countries = ['Spain']\ndisplay(df_train.query('Country_Region in @selected_countries').groupby('GeoEntity').tail(5))\n(df_train.query('Country_Region in @selected_countries')\n     .groupby('GeoEntity')\n     .plot(x='ConfirmedCases', y='NewConfirmedCasesSmoothed'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot new_cases vs cumulated_cases\n\nlast_update = datetime.datetime.now().strftime('%d-%m-%Y')\nbg_color = '#ffffff'\nfont_family = 'Liberation Sans'\ny_upper_bound = 5e4\n\nselected_countries = [\n    'China',\n    #'South Korea',\n    #'Japan',\n    'Italy',\n    'France',\n    #'Germany',\n    #'Ireland',\n    'Spain',\n    'Switzerland',\n    'Canada',\n    #'Egypt',\n    'Lebanon',\n    'United Arab Emirates',\n    'Sweden',\n    'United Kingdom',\n    'United States of America',\n]\n\ndf_subset = df_train.query('Country_Region in @selected_countries')\ndisplay(df_subset.groupby('GeoEntity').tail(1))\n\n\ndef plot_exp_growth(df_selected):\n    p = (gg.ggplot(df_selected, gg.aes(x='ConfirmedCases', y='NewConfirmedCasesSmoothed'))\n        + gg.geom_line(gg.aes(color='GeoEntity'),\n                       size=1, alpha=1.0,\n                       show_legend=False)\n        + gg.geom_point(gg.aes(fill='GeoEntity'),\n                        data=df_selected.groupby('GeoEntity').tail(1),\n                        size=3,\n                        color='black',\n                        alpha=0.8,\n                        show_legend=False)\n        + gg.geom_text(\n              gg.aes(label='GeoEntity', color='GeoEntity'),\n              data=df_selected.groupby('GeoEntity').tail(1),\n              family=font_family,\n              fontweight='bold',\n              size=10.0,\n              show_legend=False,\n              ha='left',\n              va='bottom',\n              nudge_x=0.2)\n        + gg.annotate('text', x=100, y=y_upper_bound,\n                      label=f'last update on {last_update}',\n                      ha='left',\n                      va='top',\n                      nudge_y=-0.2,\n                      nudge_x=0.2,\n                      family=font_family,\n                      size=10,\n                      color='#999999')\n        + gg.scale_y_continuous(\n            trans=log2_trans,\n            breaks=[2e1, 5e1, 1e2, 2e2, 5e2, 1e3, 2e3, 5e3, 1e4, 2e4, 5e4, 1e5, 2e5, 5e5, 1e6],\n            limits=[1e1, y_upper_bound],\n            expand=(0, 0, 0, 0),\n            labels=comma_format())\n        + gg.scale_x_continuous(\n            trans=log2_trans,\n            expand=(0.0, 0.0, 0.1, 0.0),\n            breaks=[1e2, 2e2, 5e2, 1e3, 2e3, 5e3, 1e4, 2e4, 5e4, 1e5, 2e5, 5e5, 1e6],\n            limits=[100, 5e5],\n            labels=comma_format())\n        + gg.labs(title=f'SARS-Cov-2 - New Cases as a function of Cumulative Cases',\n                  x='cumulative cases', y='new cases')\n        + gg.theme_minimal()\n        + gg.theme(figure_size=(12, 5),\n                   title=elements.element_text(ha='left', color='#454545', family=font_family),\n                   plot_title=elements.element_text(family=font_family, ha='center'),\n                   plot_background=elements.element_rect(fill=bg_color, color='None'),\n                   panel_grid_major=elements.element_line(color='#eadcd2', size=0.5),\n                   panel_grid_minor=elements.element_line(color='#eadcd2', size=0.25)))\n\n    print(p)\n\n    \nplot_exp_growth(df_subset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Automatically detects which countries dropped from the exponential growth.\n# NB: we define a dropper as 5 days below the max value of `new_confirmed_smooth`\ndropping_geoentities = []\ngrouped = df_train.sort_values('Date').groupby('GeoEntity')\nfor group in grouped.groups:\n    frame = grouped.get_group(group)\n    max_idx = frame.NewConfirmedCasesSmoothed.idxmax()\n    max_val = frame.NewConfirmedCasesSmoothed[max_idx]\n    downtrend_count = len(frame[(frame.index > max_idx) & (frame.NewConfirmedCasesSmoothed < max_val)])\n    if downtrend_count >= 5:\n        dropping_geoentities.append(group)\n        print(group)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_subset = df_train.query('GeoEntity in @dropping_geoentities')\n\nplot_exp_growth(df_subset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot curves of cases for dropping countries\n\ndf_subset = df_train.query('GeoEntity in @dropping_geoentities')\n\np = (gg.ggplot(df_subset, gg.aes(x='Date', y='ConfirmedCases'))\n    + gg.geom_line(gg.aes(color='GeoEntity'),\n                   size=1, alpha=1.0,\n                   show_legend=False)\n    + gg.facet_wrap('GeoEntity', scales='free_y', ncol=4)\n    + gg.scale_x_datetime(breaks=date_breaks('2 weeks'), labels=date_format('%W'))\n    + gg.labs(title=f'SARS-Cov-2 - Confirmed Cases over time for dropping countries',\n              x='week of year', y='cumulative cases')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(15, 50),\n               axis_text_y=elements.element_blank()))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comment**: Above curves demonstrates our ability to identify _dropping countries_ based on their slow down in `new_confirmed` cases. "},{"metadata":{},"cell_type":"markdown","source":"## Try fitting a simple model\nThese slowing down curves almost all demonstrate a logistic pattern, so let's fit a logistic curves for these ones only."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Fit a simple logistic curve, for dropping countries\n\nfrom scipy.optimize import curve_fit\n\ngeoentity = 'Spain_All'\nstart_date = '2020-03-01'\npred_num_days =   30\n\n\ndef func_logistic(x, L, k, x0): \n    return L / (1.0 + np.exp(-k*(x - x0)))\n\n\ndef generate_predictions(_df, num_days, col_name, col_pred_name, stats=True):\n    # these are the same as the scipy defaults\n    initialParameters = np.array([_df[col_name].max(), 0.1, 1.0])\n    if stats:\n        print(f'Initial parameters: {initialParameters}')\n\n    # curve fit the test data, ignoring warning due to initial parameter estimates\n    x = range(len(_df))\n    y = _df[col_name].values\n    fittedParameters, pcov = curve_fit(func_logistic, x, y, initialParameters)\n\n    y_pred = func_logistic(x, *fittedParameters) \n\n    SE = np.square(y_pred - y) # squared errors\n    MSE = np.mean(SE) # mean squared errors\n    RMSE = np.sqrt(MSE) # Root Mean Squared Error, RMSE\n    Rsquared = 1.0 - (np.var(y_pred - y) / np.var(y))\n\n    if stats:\n        print('Parameters:', fittedParameters)\n        print('RMSE:', RMSE)\n        print('R-squared:', Rsquared)\n        print(f'Population infected: {int(fittedParameters[0]):,}')\n\n    date_initial = _df.Date.iloc[-1]\n    x_future_dates = pd.Series([date_initial + pd.Timedelta('%d days' % d) for d in range(1, pred_num_days+1)])\n    x_dates = pd.concat([_df.Date, x_future_dates])\n    x = range(len(x_dates))\n    y_pred = func_logistic(x, *fittedParameters) \n    \n    df_y = pd.DataFrame({\n        'Date': x_dates,\n        'GeoEntity': _df.GeoEntity.values[0],\n        col_pred_name: y_pred,\n    })\n    df_y = df_y.merge(_df, on=['Date', 'GeoEntity'], how='left')\n    return df_y\n\n\n\ndf = df_train.query('GeoEntity == @geoentity')[df_train.Date > start_date]\ntry:\n    df_pred = generate_predictions(df, pred_num_days, 'ConfirmedCases', 'ConfirmedCasesPredicted')\nexcept RuntimeError:\n    df_pred = None\n    print('! Failed to fit logistic curve.')\n    \nif df_pred is not None:\n    #display(df_pred)\n\n    df_tidy = pd.melt(df_pred,\n                      id_vars=['Date'],\n                      value_vars=['ConfirmedCases', 'ConfirmedCasesPredicted'],\n                      value_name='y',\n                      var_name='series')\n\n    p = (gg.ggplot(df_tidy)\n        + gg.geom_line(gg.aes(x='Date', y='y', color='series'), size=2, alpha=0.5)\n        + gg.scale_x_datetime(breaks=date_breaks('1 weeks'))\n        + gg.labs(title=f'{geoentity} COVID-19 prediction of cases', x='date', y='cases predicted')\n        + gg.theme(figure_size=(10, 6)))\n\n    print(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we should validate that the parameters of the estimate are table over time. Let's do this for the total number of cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\n\ngeoentity = 'Spain_All'\npred_num_days = 30\nlookback_days = 10\n\ndf = df_train.query('GeoEntity == @geoentity')\n\ndf_proj_upper_bounds = pd.DataFrame({\n    'Date': [],\n    'TotalCasesProjected': []\n})\n\nfor lookback in range(lookback_days):\n    if lookback == 0:\n        df_past = df.copy()\n        past_dt = df_past.Date.max()\n    else:\n        df_past = df[:-lookback].copy()\n        past_dt = df_past.iloc[-1].Date\n\n    # Get predicitons\n    try:\n        df_pred = generate_predictions(df_past, pred_num_days, 'ConfirmedCases', 'ConfirmedCasesPredicted',\n                                       stats=False)\n    except RuntimeError:\n        df_pred = None\n        print('! Failed to fit logistic curve.')\n    \n    if df_pred is not None:\n        pred_30d = df_pred.ConfirmedCasesPredicted.iloc[-1]\n        df_proj_upper_bounds = df_proj_upper_bounds.append(\n            pd.Series({\n                'Date': past_dt, \n                'TotalCasesProjected': pred_30d}),\n            ignore_index=True)\n\n\ndisplay(df_proj_upper_bounds.tail())\n\np = (gg.ggplot(df_proj_upper_bounds,\n               gg.aes(x='Date', y='TotalCasesProjected'))\n    + gg.geom_point(size=2, alpha=0.5)\n    + gg.stat_smooth(geom=\"line\", size=2, alpha=0.3, se=False)\n    + gg.scale_x_datetime(breaks=date_breaks('1 weeks'))\n    + gg.scale_colour_brewer(palette=7)\n    + gg.labs(title=f'{geoentity} COVID-19 - total cases predicted at each point in time',\n              x='date', y='total confirmed estimated')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(10, 6)))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comments**:  \n* This estimate has been relatively stable for the past 7 days, which reassures us in modeling only dropping countries.\n* Whereas, for non-dropping countries, to the best of our knowledge, we have no clue when they will reach their inflexion point."},{"metadata":{},"cell_type":"markdown","source":"## Fit logistic curves on all dropping countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_frames = []\ndf_train_dropping = df_train.query('GeoEntity in @dropping_geoentities')\ngrouped = df_train_dropping.groupby('GeoEntity')\nfor group in grouped.groups:\n    frame = grouped.get_group(group)\n    pred_num_days = (pd.to_datetime(pred_end_date) - frame.Date.max()).days\n    \n    # Predict metrics\n    df_pred = pd.DataFrame({\n        'GeoEntity': frame.GeoEntity.values[0],\n        'Date': list(frame.Date.values) + [\n            frame.Date.max() + pd.to_timedelta('%d days' % delta) for delta in range(1, pred_num_days+1)],\n    })\n    fit_metrics = ['ConfirmedCases', 'Fatalities']\n    for metric_name in fit_metrics:\n        print(f'\\n--> Fit [{metric_name}] for {group}')\n        pred_metric_name = metric_name + 'Predicted'\n        try:\n            df_pred_metric = generate_predictions(frame, pred_num_days, metric_name, pred_metric_name,\n                                                  stats=True)\n            df_pred = df_pred.merge(df_pred_metric[['Date', 'GeoEntity', pred_metric_name]],\n                                    on=['Date', 'GeoEntity'], how='left')\n        except RuntimeError:\n            print(f'!!! Failed to find parameters for {metric_name}')\n            dropping_geoentities.remove(group)\n            df_pred = None\n            break\n        if len(df_pred[pd.isna(df_pred.GeoEntity)]):\n            raise ValueError('Missing some GeoEntity: ' + group)\n            \n    if df_pred is not None:\n        pred_frames.append(df_pred)\n        \ndf_pred_agg = pd.concat(pred_frames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot curves with predicted cases for dropping countries\n\nsample_log_geoentities = np.random.choice(df_train_dropping.GeoEntity.unique(), 20)\n\np = (gg.ggplot(gg.aes(x='Date'))\n    + gg.geom_line(df_train_dropping.query('GeoEntity in @sample_log_geoentities'),\n                   gg.aes(y='ConfirmedCases', color='GeoEntity'),\n                   size=2, alpha=1.0,\n                   show_legend=False)\n    + gg.geom_line(df_pred_agg.query('GeoEntity in @sample_log_geoentities'),\n                   gg.aes(y='ConfirmedCasesPredicted'),\n                   size=1, alpha=0.5, linetype='dashed',\n                   show_legend=False)\n    + gg.facet_wrap('GeoEntity', scales='free_y', ncol=4)\n    + gg.scale_x_datetime(breaks=date_breaks('2 weeks'), labels=date_format('%W'))\n    + gg.labs(title=f'SARS-Cov-2 - Confirmed Cases over time for dropping countries',\n              x='week of year', y='cumulative cases')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(15, 10),\n               axis_text_y=elements.element_blank()))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot curves with predictions deaths for dropping countries\n\nsample_log_geoentities = np.random.choice(df_train_dropping.GeoEntity.unique(), 20)\n\np = (gg.ggplot(gg.aes(x='Date'))\n    + gg.geom_line(df_train_dropping.query('GeoEntity in @sample_log_geoentities'),\n                   gg.aes(y='Fatalities', color='GeoEntity'),\n                   size=2, alpha=1.0,\n                   show_legend=False)\n    + gg.geom_line(df_pred_agg.query('GeoEntity in @sample_log_geoentities'),\n                   gg.aes(y='FatalitiesPredicted'),\n                   size=1, alpha=0.5, linetype='dashed',\n                   show_legend=False)\n    + gg.facet_wrap('GeoEntity', scales='free_y', ncol=4)\n    + gg.scale_x_datetime(breaks=date_breaks('2 weeks'), labels=date_format('%W'))\n    + gg.labs(title=f'SARS-Cov-2 - Fatalities over time for dropping countries',\n              x='week of year', y='cumulative cases')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(15, 10),\n               axis_text_y=elements.element_blank()))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The pool of remaining countries to predict values for.\ndf_train_others = df_train.query('GeoEntity not in @dropping_geoentities')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exponential regime\n\nLet's define exponential regime in a quick and dirty way, using R^2 only on the past 30 days."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_country = df_train_others.query('GeoEntity == \"US_Kansas\"')\ndf_country = df_country[-7:]\n\nx = np.arange(len(df_country))\nx = sm.add_constant(x)\nmodel = sm.OLS(np.log1p(df_country.ConfirmedCases.values), x)\nresults = model.fit()\ndisplay(results.summary())\n\nfig, ax = plt.subplots()\nfig = sm.graphics.plot_fit(results, 1, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsquared_threshold = 0.60\n\nexp_geoentities = []\ngrouped = df_train_others.groupby('GeoEntity')\nfor group in grouped.groups:\n    frame = grouped.get_group(group)\n    frame = frame[-7:]\n\n    # Fit linear model on log-values\n    x = np.arange(len(frame))\n    x = sm.add_constant(x)\n    model = sm.OLS(np.log1p(frame.ConfirmedCases.values), x)\n    results = model.fit()\n    \n    if results.rsquared_adj > rsquared_threshold:\n        exp_geoentities.append(group)\n        \nprint(f'Exponential regime geoentities (#{len(exp_geoentities)}): {exp_geoentities}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_exp = df_train_others.query('GeoEntity in @exp_geoentities')\ndisplay(df_train_exp.groupby('GeoEntity').tail(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_exp_geoentities = np.random.choice(df_train_exp.GeoEntity.unique(), 20)\n\np = (gg.ggplot(gg.aes(x='Date'))\n    + gg.geom_line(df_train_exp.query('GeoEntity in @sample_exp_geoentities'),\n                   gg.aes(y='ConfirmedCases', color='GeoEntity'),\n                   size=2, alpha=1.0,\n                   show_legend=False)\n    + gg.facet_wrap('GeoEntity', scales='free_y', ncol=4)\n    + gg.scale_x_datetime(breaks=date_breaks('2 weeks'), labels=date_format('%W'))\n    + gg.labs(title=f'SARS-Cov-2 - Confirmed Cases over time for exponential regime',\n              x='week of year', y='cumulative cases')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(15, 10),\n               axis_text_y=elements.element_blank()))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run experiments, randomly predicting the inflexion point for each country.\n# Take the mean value of all experiments.\n# Constraint the inflexion point to the interval: 2-30 days\n\n\nclass ExponentialModelWithRandomPeak(object):\n    \"\"\"Models all peak values.\"\"\"\n    \n    def __init__(self, peak_range=None):\n        self.peak_range = peak_range or (1, 30)\n    \n    def _fit(self, y_series):\n        x = np.arange(len(y_series))\n        x = sm.add_constant(x)\n        self._model = sm.OLS(np.log1p(y_series), x)\n        self._results = self._model.fit()\n        \n    def _predict(self, x):\n        x = sm.add_constant(x)\n        return np.expm1(self._results.predict(x))\n    \n    def _run_experiment(self, frame, col_pred_name, peak_days, pred_num_days):\n        pred_num_days_extended = max(peak_days, pred_num_days)\n        \n        # until peak\n        x1 = np.arange(len(frame), len(frame)+peak_days, 1)\n        y_pred_until_peak = self._predict(x1)\n\n        # after peak (simple symetry here)\n        x2 = np.arange(len(frame)+peak_days-2, -100, -1)\n        y_sym = self._predict(x2)\n        y_diff = np.diff(y_sym)[1:(pred_num_days_extended - len(x1) + 1)]\n        y_pred_after_peak = np.cumsum(np.abs(y_diff)) + y_pred_until_peak[-1]\n\n        y_pred = list(y_pred_until_peak) + list(y_pred_after_peak)\n        return pd.DataFrame({\n            'GeoEntity': group,\n            'Date': [frame.Date.max() + pd.to_timedelta('%d days' % delta) for delta in range(1, pred_num_days+1)],\n            col_pred_name: y_pred[:pred_num_days],\n        })\n    \n    def run(self, frame, col_name, col_pred_name, pred_end_date):\n        \"\"\"Runs all experiments.\"\"\"\n        if pd.to_datetime(pred_end_date) <= frame.Date.max():\n            raise ValueError('The prediction end date should be in the future.')\n            \n        # Fits our messy exponential model.\n        self._fit(frame[col_name])\n        \n        pred_frames = []\n        pred_num_days = (pd.to_datetime(pred_end_date) - frame.Date.max()).days\n        for peak_days in range(*self.peak_range):\n            df = self._run_experiment(frame, col_pred_name, peak_days, pred_num_days)\n            pred_frames.append(df)\n        return pd.concat(pred_frames)\n        \n    def run_and_predict(self, frame, col_name, col_pred_name, pred_end_date):\n        df_all_pred = self.run(frame, col_name, col_pred_name, pred_end_date)\n        agg_fields = {\n            col_pred_name: lambda x: np.quantile(x.unique(), 0.50),\n            ('%s_lower' % col_pred_name): lambda x: np.quantile(x.unique(), 0.01),\n            ('%s_upper' % col_pred_name): lambda x: np.quantile(x.unique(), 0.99),\n        }\n        #print(df_all_pred[df_all_pred['Date'] == '2020-04-18'])\n        #print(df_all_pred[df_all_pred['Date'] == '2020-04-18'][col_pred_name].agg(agg_fields))\n        df_pred = df_all_pred.groupby(['GeoEntity', 'Date'])[col_pred_name].agg(agg_fields).reset_index()\n        # Add the last known value to start our predictions with.\n        #df_pred = df_pred.append(pd.DataFrame({\n        #    'GeoEntity': frame.tail(1).GeoEntity.values[0],\n        #    'Date': frame.tail(1).Date.values[0],\n        #    col_pred_name: frame.tail(1)[col_name].values[0],\n        #    ('%s_lower' % col_pred_name): frame.tail(1)[col_name].values[0],\n        #    ('%s_upper' % col_pred_name): frame.tail(1)[col_name].values[0],\n        #}, index=[0]), ignore_index=True).reset_index(drop=True)\n        df_pred = df_pred.sort_values('Date', ascending=True)\n        return df_pred\n    \n\nprint(f'Predict until {pred_end_date}')\ndf_pred_agg_exp = pd.DataFrame()\ngrouped = df_train_exp.groupby('GeoEntity')\nfor group in grouped.groups:\n    frame = grouped.get_group(group)\n    frame = frame[-7:]\n    \n    # Predict cases\n    model = ExponentialModelWithRandomPeak(peak_range=(2, 10))\n    df_pred_cases = model.run_and_predict(frame, 'ConfirmedCases', 'ConfirmedCasesPredicted', pred_end_date)\n    \n    # Predict fatalities\n    model = ExponentialModelWithRandomPeak(peak_range=(12, 20))\n    df_pred_fatalities = model.run_and_predict(frame, 'Fatalities', 'FatalitiesPredicted', pred_end_date)\n    \n    df_pred = pd.merge(df_pred_cases, df_pred_fatalities, on=['GeoEntity', 'Date'])\n    df_pred_agg_exp = pd.concat([df_pred_agg_exp, df_pred])\n\ndf_pred_agg_exp.groupby('GeoEntity').tail(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_exp_geoentities = np.random.choice(df_train_exp.GeoEntity.unique(), 20)\n\np = (gg.ggplot(gg.aes(x='Date'))\n    + gg.geom_line(df_train_exp.query('GeoEntity in @sample_exp_geoentities'),\n                   gg.aes(y='ConfirmedCases', color='GeoEntity'),\n                   size=2, alpha=1.0,\n                   show_legend=False)\n    + gg.geom_ribbon(df_pred_agg_exp.query('GeoEntity in @sample_exp_geoentities'),\n                     gg.aes(ymin='ConfirmedCasesPredicted_lower',\n                            ymax='ConfirmedCasesPredicted_upper'),\n                     alpha=0.3, fill='red',\n                     show_legend=False)\n    + gg.geom_line(df_pred_agg_exp.query('GeoEntity in @sample_exp_geoentities'),\n                   gg.aes(y='ConfirmedCasesPredicted'),\n                   size=1, alpha=0.5, linetype='dashed',\n                   show_legend=False)\n    + gg.facet_wrap('GeoEntity', scales='free_y', ncol=4)\n    + gg.scale_x_datetime(breaks=date_breaks('2 weeks'), labels=date_format('%W'))\n    + gg.scale_y_log10()\n    + gg.labs(title=f'SARS-Cov-2 - Confirmed Cases over time for exponential regime',\n              x='week of year', y='cumulative cases')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(15, 10)))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The pool of remaining countries to predict values for.\ndf_train_others = (df_train\n    .query('GeoEntity not in @dropping_geoentities')\n    .query('GeoEntity not in @exp_geoentities'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear regime\n\nWe define the linear regime as countries which have a steady incease in new cases but independant of the confirmed cases, which means it's not a multiple of the number of total cases (exponential regime).\n\nBrute forcing it by fitting linear models and only keep those with a good fit."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_frames = []\ngrouped = df_train_others.groupby('GeoEntity')\nfor group in grouped.groups:\n    frame = grouped.get_group(group)\n\n    # Check if same value for 15 consecutive days\n    last_15days = frame[-15:]\n    if (last_15days.NewConfirmedCases == 0).all():\n        df_pred = pd.DataFrame({\n            'GeoEntity': group,\n            'Date': df_test.query('GeoEntity == @group').Date,\n            'ConfirmedCasesPredicted': frame.tail(1).ConfirmedCases.values[0],\n            'FatalitiesPredicted': frame.tail(1).Fatalities.values[0],\n        })\n        pred_frames.append(df_pred)\n        continue\n            \n    # Final fallback to a linear regime, since day of 1 case.\n    first_case_date = frame[frame.ConfirmedCases >= 1].Date.values[0]\n    frame = frame[frame.Date >= (first_case_date - pd.to_timedelta('1 day'))]\n    frame = frame[-15:]  # max of 15 days for linreg\n    x = np.arange(-len(frame), 0, 1)\n    x = sm.add_constant(x)\n    model = sm.OLS(frame.ConfirmedCases.values, x)\n    results = model.fit()\n    #display(results.summary())\n    \n    # Predict values with linear fit\n    x = np.arange(len(df_test.query('GeoEntity == @group')))\n    x = sm.add_constant(x)\n    y_pred = results.predict(x)\n    df_pred = pd.DataFrame({\n        'GeoEntity': group,\n        'Date': df_test.query('GeoEntity == @group').Date,\n        'ConfirmedCasesPredicted': y_pred,\n        'FatalitiesPredicted': 0,\n    })\n    pred_frames.append(df_pred)\n        \ndf_pred_agg_lin = pd.concat(pred_frames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train_lin = df_train_others.query('GeoEntity in @lin_geoentities')\ndf_train_lin = df_train_others.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = (gg.ggplot(gg.aes(x='Date'))\n    + gg.geom_line(df_train_lin,\n                   gg.aes(y='ConfirmedCases', color='GeoEntity'),\n                   size=2, alpha=1.0,\n                   show_legend=False)\n    + gg.geom_line(df_pred_agg_lin,\n                   gg.aes(y='ConfirmedCasesPredicted'),\n                   size=1, alpha=0.5, linetype='dashed',\n                   show_legend=False)\n    + gg.facet_wrap('GeoEntity', scales='free_y', ncol=4)\n    + gg.scale_x_datetime(breaks=date_breaks('2 weeks'), labels=date_format('%W'))\n    + gg.labs(title=f'SARS-Cov-2 - Confirmed Cases over time for exponential regime',\n              x='week of year', y='cumulative cases')\n    + gg.theme_minimal()\n    + gg.theme(figure_size=(15, 10)))\n\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission_log = df_test.merge(\n    df_pred_agg[['Date', 'GeoEntity', 'ConfirmedCasesPredicted', 'FatalitiesPredicted']],\n    on=['Date', 'GeoEntity'], how='inner')\ndf_submission_lin = df_test.merge(\n    df_pred_agg_lin[['Date', 'GeoEntity', 'ConfirmedCasesPredicted', 'FatalitiesPredicted']],\n    on=['Date', 'GeoEntity'], how='inner')\ndf_submission_exp = df_test.merge(\n    df_pred_agg_exp[['Date', 'GeoEntity', 'ConfirmedCasesPredicted', 'FatalitiesPredicted']],\n    on=['Date', 'GeoEntity'], how='inner')\ndf_submission = pd.concat([df_submission_log, df_submission_lin, df_submission_exp])\n#display(df_submission.groupby('GeoEntity').head(1))\n\n# Format submission data\ndf_submission['ConfirmedCases'] = df_submission['ConfirmedCasesPredicted']\ndf_submission['Fatalities'] = df_submission['FatalitiesPredicted']\ndf_submission = df_submission[['ForecastId', 'ConfirmedCases', 'Fatalities']]\ndisplay(df_submission.sample(3))\n\n# Merge with public leaderboard predictions\nif SUBMIT_FOR_PRIVATE_LEADERBOARD:\n    df_submission_public = pd.read_csv(\n        '/kaggle/input/submission-for-public-leaderboard/submission_public_w4.csv')\n    df_submission = pd.concat([df_submission_public, df_submission])\n\ndf_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_submission), len(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}