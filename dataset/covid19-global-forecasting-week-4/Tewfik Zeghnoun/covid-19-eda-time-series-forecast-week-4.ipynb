{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport sys\nimport datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.linear_model import LinearRegression\n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A function to read and clean the dataser\ndef read_csv(url, since_cases_num = 10):\n    '''\n    Read csv file from the COVID-19 Data Repository by Kaggle. \n    Cleans and adds two columns :\n        - lgp_cases = np.log1p(df.ConfirmedCases,\n        - lgp_deaths = np.log1p(df.Fatalities)\n    \n    Return two datasets with Date as an index and a sorted list of countries by number of casualities.\n    '''\n    # read data\n    df = pd.read_csv(url)\n    \n    # Rename culomns 'Country/Region' & the South Korea's name \n    df.rename(columns={'Country_Region' : 'Country'}, inplace=True)\n    df['Country'] = df['Country'].replace({'Korea, South': 'South Korea'})\n    \n    # Grouping by country, rename columns & parse dates\n  \n    df['Date'] = pd.to_datetime(df['Date'], format='%Y/%m/%d')\n    df = df.assign(days = df['Date'].dt.dayofyear - 21)\n    \n    # Generate the second df with the minimum case\n    dff = df.groupby(['Country', 'Date']).sum()\n    dff = dff.reset_index()\n    \n    LAST_DATE = dff.iloc[-1, 1]\n    \n    countries = dff[dff['Date'].eq(LAST_DATE) & dff['Fatalities'].ge(since_cases_num)\n           ].sort_values(by='Fatalities', ascending=False)\n    countries = countries['Country'].values\n    \n    COL_X = f'Days since {since_cases_num}th death'\n    df_since = dff[dff['Country'].isin(countries)].copy()\n    days_since = (df_since.assign(F=df_since['Fatalities'].ge(since_cases_num))\n                  .set_index('Date')\n                  .groupby('Country')['F'].transform('idxmax'))\n    \n    df_since[COL_X] = (df_since['Date'] - days_since.values).dt.days.values + 1\n    df_since = df_since[df_since[COL_X].ge(0)]\n    \n    return df.set_index('Date'), df_since.set_index('Date'), list(countries[:7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = '/kaggle/input/covid19-global-forecasting-week-4/'\n# url_test = '/kaggle/input/covid19-global-forecasting-week-4/test.csv'\n# Train dataset\nsince_cases_num = 10\ntrain, train_since, top_countries = read_csv(url+'train.csv', since_cases_num)\n# Test dataset\ntest = pd.read_csv(url+'test.csv', parse_dates=['Date'], index_col=['Date'])\ntest = test.rename(columns={'Country_Region' : 'Country'})\ntest['Country'] = test['Country'].replace({'Korea, South': 'South Korea'})\n\nxsubmission = pd.read_csv(url+'submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_since.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replacing empty (nan) rows in column 'Province_State'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def province(df):\n    '''\n    Replacing empty rows in column 'Province_State' with the corresponding 'Country' and adding 'Country' to the corresponding states if the row is not empty.\n    return the cleaned dataset\n    '''\n    df = df.reset_index()\n    df['Province_State'] = df['Province_State'].map(str)\n    for row, state in enumerate(df['Province_State']):\n        if state == \"nan\":\n            df.loc[row, 'Province_State'] = df.loc[row, 'Country']\n        else:\n            df.loc[row, 'Province_State'] = df.loc[row, 'Country'] + '_' + df.loc[row, 'Province_State']\n    df = df.set_index('Date')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = province(train)\ntest = province(test)\nprint(f'Number of states :\\nTrain = {len(train.Province_State.unique())}\\nTest = {len(test.Province_State.unique())}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_countries = list(train.Country.unique())\nfull_sc = list(train.Province_State.unique())\nnum_country = len(full_countries)\nnum_sc = len(full_sc)\n\nprint(f'Number of countries : {num_country}')\nprint(f'Number of state_countries : {num_sc}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I. Exploring a selected number of countries\n\nLet's take a look at top 7 countries with high casualities"},{"metadata":{},"cell_type":"markdown","source":"### Number of confirmed cases since the 10th cases officially reported"},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of countries to look at & corresponding colors\ncolors = [[0,0,0], [255/255,165/255, 0], [86/255,180/255,233/255], [0, 191/255, 255/255],\n          [213/255,94/255,0], [0,114/255,178/255], [0,0,128/255]]\n\n# Plotting\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(16, 7))\nsns.lineplot(x=f'Days since {since_cases_num}th death', y='ConfirmedCases', hue='Country', data=train_since.loc[train_since['Country'].isin(top_countries)], palette=colors)\nplt.title('Number of confirmed cases for the selected countries')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of deaths since the 10th deaths officially reported"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotti,g the number of deaths for the selected countries\nplt.figure(figsize=(16, 7))\nsns.lineplot(x=f'Days since {since_cases_num}th death', y='Fatalities', hue='Country', data=train_since[train_since['Country'].isin(top_countries)], palette=colors)\nplt.title(\"Number of deaths for the selelcted countries\")\nplt.xlabel(f'Days after {since_cases_num}th death officially reported')\nplt.ylabel('Number of cumulative death')\n# plt.ylim(0, 500)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II. Correlation between log Confirmed Cases and log Fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a list of datasets for the selected countries\nselected_df = [train.loc[train['Country'] == country] for country in top_countries]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_agg(df, agg=True):\n    '''\n    Aggregating the dataset by country if agg. And adding two columns:\n        - lgp_cases = np.log1p(df.ConfirmedCases),\n        - lgp_deaths = np.log1p(df.Fatalities)\n    '''\n    if agg:\n        df = df.reset_index()\n        df = df.groupby(['Country', 'Date']).sum()\n        df = df.reset_index()\n    df = df.assign(lgp_cases = np.log1p(df.ConfirmedCases),\n                   lgp_deaths = np.log1p(df.Fatalities))\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the number of confirmed cases vs fatalities (log values)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_log_CaseDeath(df = selected_df[0], country=top_countries[0], delta=0):\n    '''\n    Display one of the two following plots:\n        - Number of confirmed cases vs. deaths for the corresponding country (log values),\n        - Number of confirmed cases vs. deaths for the corresponding country (Ajusted values with a lag of time in days)\n    '''\n    df = df_agg(df)\n    x_1 = np.array(range(df.shape[0]))\n    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n    ax.plot(df.lgp_cases.values)\n    ax.plot(df.loc[delta:, 'lgp_deaths'].values)\n    if delta == 0:\n        plt.title(f'Number of confirmed cases vs. deaths for {country} (log values)')\n        plt.legend(('log_confirmed_cases', 'log_deaths'))\n    else:\n        plt.title(f'Number of confirmed cases vs. deaths for {country}\\n(Ajusted values with a lag of {delta} days)')\n        plt.legend(('log_confirmed_cases', 'Ajusted_log_deaths'))\n    plt.xlabel('Days since the 1st reported case')\n    plt.ylabel('Values (log)')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in range(len(selected_df)):\n    plot_log_CaseDeath(df= selected_df[idx], country=top_countries[idx], delta=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate the delta for each country"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_delta(df=selected_df[0], agg=True):\n    '''\n    Calculate the lag time in days between the Confirmed Cases and the Fatalities (in log values)\n    '''\n    if agg:\n        df = df_agg(df, agg=True)\n    else:\n        df = df_agg(df, agg=False)\n    for num in range(1, 50):\n        shift = pd.DataFrame(data=df.lgp_cases.values - df.lgp_deaths.shift(-num).values, columns=['value'])\n        shift.dropna(axis=0, inplace=True)\n        if len(shift.query('value >= 0')) != len(shift):   # We need to check if all the values of log_deaths are less than log_cases\n            break\n        else : \n            sum_shift = shift.sum() / len(shift)\n    return num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dlt = []\nfor df in selected_df:\n    dlt.append(get_delta(df))\ndlt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in range(len(selected_df)):\n    plot_log_CaseDeath(df= selected_df[idx], country=top_countries[idx], delta=dlt[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling the linear regression between log_cases and ajusted log_fatalities for the selected countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_mod(df=selected_df[0], country=top_countries[0], delta=dlt[0]):\n    '''\n    Calculate the linear regression between x = log1p(Confirmed Cases) & y = log1p(deaths).\n    Returns df, x, y, slope, intercept.\n    '''\n    df = df_agg(df)\n    df = df.query('lgp_deaths > 0')\n    \n    y=df.lgp_deaths.iloc[delta:].values\n    x=df.lgp_cases.iloc[:y.shape[0]].values\n    \n    # Find the slope and intercept of the best fit line\n    slope, intercept = np.polyfit(x, y, 1)\n\n    # Create a list of values in the best fit line\n    abline_values =  [slope * i + intercept for i in x]\n        \n    # Add the projections to the orginal df \n    d = len(df) - len(x)\n    df = df.assign(predictions = 0)\n    df.predictions.iloc[d:] = np.expm1(abline_values).astype(int)\n    \n    df.predictions = pd.to_numeric(df.predictions, errors='coerce')\n    df = df.dropna(subset = ['predictions'])    \n    \n    return df, x, y, slope, intercept, abline_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = ['x_' + country for country in top_countries]\nY = ['y_'  + country for country in top_countries]\nSlope = ['slope_' + country for country in top_countries]\nIntercept = ['intercept_' + country for country in top_countries]\nAb_line = ['abline_' + country for country in top_countries]\npredictions = ['predict_' + country for country in top_countries]\n\n\nfor idx in range(len(selected_df)):    \n    selected_df[idx], X[idx], Y[idx], Slope[idx], Intercept[idx], Ab_line[idx] = linear_mod(df=selected_df[idx], country=top_countries[idx], delta=dlt[idx])\n    fig, ax = plt.subplots(1, 1, figsize=(14, 4))\n    sns.scatterplot(X[idx], Y[idx], ax = ax, )\n    sns.lineplot(X[idx], Ab_line[idx], ax = ax)\n    plt.title(f'{top_countries[idx]} : The linear regression between log_cases vs. ajusted log_deaths\\n {round(Slope[idx], 2)} * x + {round(Intercept[idx], 2)}')\n    plt.xlabel('Confirmed Cases (log)')\n    plt.ylabel('Reported deaths (log)')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_df[0].head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to plot the predictions vs. observed values\ndef plot_predict(df=selected_df[0], country=top_countries[0]):\n    df = df_agg(df)\n    mae = round(mean_absolute_error(df.Fatalities.values, df.predictions.values), 4)\n    rmse = round(r2_score(df.Fatalities.values, df.predictions.values), 4)\n    x_1 = np.array(range(df.shape[0]))\n    fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n    ax.plot(df.Fatalities.values)\n    ax.plot(df.predictions.values, 'o-')\n    plt.title(f'Observed vs. Projected values of the number of deaths in {country}\\n mae = {mae} ; rmse = {rmse}')\n    plt.legend(('Observed_deaths', 'Predicted_deaths'))\n    plt.xlabel('Days since the 1st reported case')\n    plt.ylabel('Number of deaths')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in range(len(selected_df)):\n    plot_predict(df=selected_df[idx], country=top_countries[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III. Predicting new cases and future fatalities for the whole dataset"},{"metadata":{},"cell_type":"markdown","source":"### I will be proceeding in two steps :\n\n1. Extrpolate the number of new cases. The assumption behind is that there is a correlation between the confirmed cases and the future cases as part of the contamination process in each country.\n\n2. Part of the observed values of cases and the predicted ones will serve to predict the number of fatalities. The assumption is as shown in the first part of this notebook, there is a correlation between confirmed cases and fatalities with a lag time that varies from country to another. "},{"metadata":{},"cell_type":"markdown","source":"### Forecast a univariate time series : Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train[['days', 'Province_State', 'ConfirmedCases', 'Fatalities']].reset_index(drop=True).set_index('days')\ndf.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import interpolate\n\ncases_int = {}\nfor state in full_sc: \n    data = df.loc[df['Province_State'] == state]\n    x = np.arange(0, len(data))\n    x_val = list(range(len(x), len(x)+43))\n    y = data['ConfirmedCases'].values\n    poly = np.polyfit(x, y, deg=5)\n    y_hat = np.maximum(0, np.polyval(poly, x_val))\n    cases_int[state] = (test.loc[test['Province_State'] == state, 'ForecastId'].values, y_hat.astype(int))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting Fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dictionnary of deltas by state\nDelta = {}\nfor state in full_sc:\n    Delta[state] = get_delta(df.loc[df['Province_State'] == state], agg=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_fit(train, state, label='lgp_deaths', features='lgp_cases', print_=False):\n    '''\n    Building and training a model for each State/Country.\n    Return the corresponding predictions\n    '''\n    \n    delta = Delta[state] \n    df1 = train.loc[train['Province_State'] == state]\n    df1 = df_agg(df1, agg=False)\n\n    X = df1.loc[:, features].values\n    y = df1.loc[:, label].values\n    y_train = y[delta:].reshape(-1, 1)\n    X_train = X[:y_train.shape[0]].reshape(-1, 1)\n    \n    # X_test\n    X_test_full =  np.concatenate((X[y_train.shape[0]:], np.log1p(cases_int[state][1])), axis=0)\n    X_test = X_test_full[:43].reshape(-1, 1)\n    if print_:\n        print(f'Delta : {delta} / X shape : {X.shape} / y shape : {y.shape}')\n        print(f'X_train shape : {X_train.shape}, y_train shape : {y_train.shape}')\n        print(f'X_test_full shape : {X_test_full.shape} / X_test shape : {X_test.shape}')\n    \n    # Create the model\n    model = LinearRegression()\n    # Fit the model\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    exp_predictions = np.expm1(predictions)\n\n    return exp_predictions.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the function in the case of Algeria\ny_preds = model_fit(train, 'Algeria', label='lgp_deaths', features='lgp_cases', print_=True)\n\nstart = np.datetime64('2020-04-09')\nx_preds = np.arange(start, start + np.timedelta64(43,'D'))\n\nplt.figure(figsize=(10, 5))\nplt.plot(x_preds, y_preds, '--')\nplt.title('Forecasted Fatalities for Algeria')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generatin the forecast of fatalities for each State/Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looping through the full list of States/Country to forecast number of fatalities\ndeaths_preds = {}\nfor state in full_sc:\n    y_hat = model_fit(train, state, label='lgp_deaths', features='lgp_cases')\n    deaths_preds[state] = (test.loc[test['Province_State'] == state, 'ForecastId'].values, y_hat.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Puting it all together\ndef create_sub():\n    x_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n    for state in full_sc:\n        df_tmp = pd.DataFrame({'ForecastId': cases_int[state][0], 'ConfirmedCases': cases_int[state][1], 'Fatalities': deaths_preds[state][1]})\n        x_out = pd.concat([x_out, df_tmp], axis = 0)\n    return x_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submitting\nx_out = create_sub()\nx_out.ForecastId = x_out.ForecastId.astype('int')\nx_out.tail()\nx_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**---------------------------------------------------------------------------------**"},{"metadata":{},"cell_type":"markdown","source":"P.S: The was inspired by a notebook I read here but I could find it to put it as a reference. I will be grateful if you can send me the link to add it. Thanks in advance."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}