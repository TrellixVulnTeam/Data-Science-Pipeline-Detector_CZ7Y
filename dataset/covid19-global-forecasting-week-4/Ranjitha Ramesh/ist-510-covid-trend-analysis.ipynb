{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom itertools import cycle, islice\nimport seaborn as sb\nimport matplotlib.dates as dates\nimport datetime as dt\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly import tools, subplots\nimport plotly.figure_factory as ff\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Population Data:**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\npop_dir = Path('../input/countryinfo/covid19countryinfo.csv')\npop_data = pd.read_csv('../input/countryinfo/covid19countryinfo.csv')\npdata = pop_data[[\"country\", \"pop\", \"density\"]]\npdata =pdata.rename(columns={'country':'Country_Region', 'pop':'Population'})\n\n# convert columns population from String to float, to be able to divide\npdata['Population'] = pdata['Population'].str.replace(',', '')\npdata['Population'] = pdata['Population'].astype(float)\n\nupdata = pd.DataFrame(pdata.groupby('Country_Region')['Population', 'density'].max()).reset_index()\n# Korea, South\nupdata.head()\n\nupdata['Country_Region'] = updata['Country_Region'].map({'US': 'United States', \n                                                         'Korea, South': 'South Korea'}).fillna(updata['Country_Region'])\nprint(updata[updata['Country_Region']=='South Korea'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\", parse_dates=['Date'])#index_col=0\ndisplay(train_data.head())\n# display(train_data.dtypes)\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\", parse_dates=['Date'])#index_col=0\ndisplay(test_data.head())\n\n# train_data[train_data['Country_Region']== 'US']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_df = pd.pivot_table(train_data, values=['ConfirmedCases','Fatalities'], index=['Date'],aggfunc=np.sum)\ndisplay(sum_df.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets create some new features, such as\n* Daily Confirmed cases\n* Daily Fatalities\n* Growth factor (ratio of daily new cases to the previous day)\n* Mortality rate (ratio of fatalities to the confirmed cases)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['NewConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\ntrain_data['NewConfirmedCases'] = train_data['NewConfirmedCases'].fillna(0.0)\ntrain_data['NewFatalities']     = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\ntrain_data['NewFatalities']     = train_data['NewFatalities'].fillna(0.0)#.astype(int)\ntrain_data['MortalityRate']     = train_data['Fatalities'] / train_data['ConfirmedCases']\ntrain_data['MortalityRate']     = train_data['MortalityRate'].fillna(0.0)\ntrain_data['GrowthRate']        = train_data['NewConfirmedCases']/train_data['NewConfirmedCases'].shift(1)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].replace([-np.inf, np.inf],  0.0)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].fillna(0.0) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets learn the time stamp for the training and test dataset, and the countries with further details by Province or State."},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"def getColumnInfo(df):\n    n_province =  df['Province_State'].nunique()\n    n_country  =  df['Country_Region'].nunique()\n    n_days     =  df['Date'].nunique()\n    start_date =  df['Date'].unique()[0]\n    end_date   =  df['Date'].unique()[-1]\n    return n_province, n_country, n_days, start_date, end_date\n\nn_train = train_data.shape[0]\nn_test = test_data.shape[0]\n\nn_prov_train, n_count_train, n_train_days, start_date_train, end_date_train = getColumnInfo(train_data)\nn_prov_test,  n_count_test,  n_test_days,  start_date_test,  end_date_test  = getColumnInfo(test_data)\n\n# print ('<==Train data==> \\n # of Province_State: '+str(n_prov_train),', # of Country_Region:'+str(n_count_train), \n#        ', Time Period: '+str(start_date_train)+' to '+str(end_date_train), '==> days:',str(n_train_days))\n# print(\"\\n Countries with Province/State information:  \", train_data[train_data['Province_State'].isna()==False]['Country_Region'].unique())\n# print ('\\n <==Test  data==> \\n # of Province_State: '+str(n_prov_test),', # of Country_Region:'+str(n_count_test),\n#        ', Time Period: '+start_date_test+' to '+end_date_test, '==> days:',n_test_days)\n\ndf_test = test_data.loc[test_data['Date'] > '2020-04-14']\noverlap_days = n_test_days - df_test.Date.nunique()\nprint('\\n overlap days with training data: ', overlap_days, ', total days: ', n_train_days+n_test_days-overlap_days)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to do the predictions for 43 days, with overlap with of 13 days in training data that we will use to test our forecast model. Lets look at the data records with entries greater than zero."},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\nprob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\n\nn_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\nn_fatal_train = train_data.Fatalities.value_counts()[1:].sum()\n\nprint('Percentage of confirmed case records = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_confirm_train, n_train, prob_confirm_check_train[1:].sum()*100))\nprint('Percentage of fatality records = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_fatal_train, n_train, prob_fatal_check_train[1:].sum()*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trend by Country/Region for the maximum cases"},{"metadata":{},"cell_type":"markdown","source":"Merging the Population entries with disease analysis, setting InfectedPopulation_Ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum',\n                                                                                         'GrowthRate':'last' })\n\n#display(train_data_by_country.tail(10))\nmax_train_date = train_data['Date'].max()\ntrain_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\n\n\n#\ntrain_data_by_country_confirm = train_data_by_country_confirm.merge(updata, on =\"Country_Region\", how='left')\n\ntrain_data_by_country_confirm['InfectedPopulation_Ratio'] = train_data_by_country_confirm['ConfirmedCases'].div(train_data_by_country_confirm['Population'],fill_value=0)*100\ntrain_data_by_country_confirm['InfectedPopulation_Ratio'] = train_data_by_country_confirm['InfectedPopulation_Ratio'].replace([-np.inf, np.inf],  0.0)\n\n\ntrain_data_by_country_confirm.set_index('Country_Region', inplace=True)\ntrain_data_by_country_confirm.style.background_gradient(cmap='Reds').format({'ConfirmedCases': \"{:.0f}\", 'GrowthRate': \"{:.2f}\", 'InfectedPopulation_Ratio': \"{:.4f}\"})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"COUNTRIES BY THE PORTION OF THE POPULATION DECEASED:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain_data_by_country_confirm['DeceasedPopulation_Ratio'] = train_data_by_country_confirm['Fatalities'].div(train_data_by_country_confirm['Population'],fill_value=0)*100\ntrain_data_by_country_confirm['DeceasedPopulation_Ratio'] = train_data_by_country_confirm['DeceasedPopulation_Ratio'].replace([-np.inf, np.inf],  0.0)\n\n\ntrain_data_by_country_confirm= train_data_by_country_confirm.sort_values('DeceasedPopulation_Ratio', ascending=False).reset_index()\ntrain_data_by_country_confirm.style.background_gradient(cmap='Reds').format({'ConfirmedCases': \"{:.0f}\", 'GrowthRate': \"{:.2f}\", 'InfectedPopulation_Ratio': \"{:.4f}\", 'DeceasedPopulation_Ratio':\"{:.4f}\"})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"COUNTRIES BY THE HIGHEST GROWTH RATES TODAY:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data_by_country_confirm= train_data_by_country_confirm.sort_values('GrowthRate', ascending=False)\ntrain_data_by_country_confirm.style.background_gradient(cmap='Reds').format({'ConfirmedCases': \"{:.0f}\", 'GrowthRate': \"{:.2f}\", 'InfectedPopulation_Ratio': \"{:.4f}\"})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seeing the bar chart for infection ratio by countries, with and without Diamond Princess:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\nimport folium \nfrom folium import plugins\nfrom tqdm.notebook import tqdm as tqdm\n\ntrain_data_by_country_confirm= train_data_by_country_confirm.reset_index()\nglobal_confirmedcases = train_data_by_country_confirm[['Country_Region','InfectedPopulation_Ratio']]\n\nfig = px.bar(global_confirmedcases.sort_values('InfectedPopulation_Ratio',ascending=False)[:20],x='InfectedPopulation_Ratio',y='Country_Region',title='Country wise infected population ratio',text='InfectedPopulation_Ratio', height=900, orientation='h')\nfig.show()\n\n# without diamond princess\nrest = global_confirmedcases[global_confirmedcases['Country_Region'] != 'Diamond Princess'].sort_values('InfectedPopulation_Ratio',ascending=False)[1:20]\nfig = px.bar(rest,x='InfectedPopulation_Ratio',y='Country_Region',title='Country wise infected population ratio excluding Diamond Princess',text='InfectedPopulation_Ratio', height=900, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Graphs of Country wise measures****"},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data_mitigation = pd.read_csv('../input/covid19-containment-and-mitigation-measures/COVID 19 Containment measures data.csv', parse_dates=['Date Start','Date end intended' ])\ntotal_data = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv', parse_dates=['Date'])\n\n# cases \ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\ntotal_data['Active'] = total_data['Confirmed'] - total_data['Deaths'] - total_data['Recovered']\n\n# filling missing values \ntotal_data[['Province/State']] = total_data[['Province/State']].fillna('')\ntotal_data[cases] = total_data[cases].fillna(0)\ntotal_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge the mitigation and spread data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data_mitigation = cleaned_data_mitigation.rename(columns={\"Date Start\": \"Date\", 'Country':'Country/Region'})\n# row = cleaned_data_mitigation[(cleaned_data_mitigation['Country/Region']=='Iran') & (cleaned_data_mitigation['Date']=='2020-03-17')]\n# str = pd.DataFrame(pd.Series(['shutdown']))\n# print(type(row['Keywords']))\n# row['Keywords'] = row['Keywords'].append(str, )\n# print(row['Keywords'])\n# print(cleaned_data_mitigation[(cleaned_data_mitigation['Country/Region']=='Iran') & (cleaned_data_mitigation['Date']=='2020-03-17')])\n# cleaned_data_mitigation = pd.concat([row, cleaned_data_mitigation], ignore_index=True)\n# including the mitigation measure for Iran\n\n\ncont_spread = cleaned_data_mitigation.merge(total_data, how='outer', on=[\"Date\", 'Country/Region'] )\n\nprint(len(cont_spread))\n# # cond2  = cont_spread.Fatalities.notnull()\n# cond2 = cont_spread['Date']=='2020-03-09'\nttc = cont_spread.loc[(cont_spread['Country/Region'] == 'South Korea')]\ndisplay(ttc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = ['South Korea','Germany','Iceland','Iran','Italy', 'Spain', 'Russia',  'Japan', 'China', 'United Kingdom', 'United States','Netherlands', 'France']\n\n\ndef country_cont(data, country):\n    df = data[data['Country/Region'] == country][['Date',\n                                    'Description of measure implemented',\n                                    'Exceptions', \n                                    'Keywords', \n                                    'Target region']].copy()\n    df['region'] = df['Target region'].fillna('All')\n    df['Keywords'] = df['Keywords'].fillna('-')\n#     df['date'] = pd.to_datetime(df['Date'])\n#     df.drop(['Date', 'Target region'], axis=1, inplace=True)\n    df = df.sort_values(by='Date').reset_index(drop=True)\n    \n    return df\n\ncont_all = []\n\nfor country in countries:\n    tmp = country_cont(cont_spread, country)\n    tmp['Country/Region'] = country\n    tmp = tmp[tmp.Keywords.str.contains('lockdown|business suspension|school closure|travel ban|social distancing|blanket curfew|shutdown|emergency|nonessential|outdoor gatherings banned|contact tracing|traveller screening|remote work|personal hygiene')]\n#     tmp= tmp[tmp.Keywords.str.contains('\\a*', regex= True)]\n    cont_all.append(tmp[['Country/Region', 'Date', 'Keywords', 'region']])\n    \ncont_all = pd.concat(cont_all, ignore_index=False)\n\ncont_spread2 = cont_all.merge(total_data, how='outer', on=[\"Date\", \"Country/Region\"] )\n\ncond2 = cont_spread2['Date']=='2020-03-22'\ncont_spreadwq = cont_spread2.loc[(cont_spread2['Country/Region']=='South Korea') & (cond2)]\ncont_spreadwq.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# without the keyword labels\nfor country in countries:\n \n grouped_country = cont_spread2[cont_spread2['Country/Region'] == country].reset_index()\n grouped_country_date = grouped_country.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'\n                                                  ].sum().reset_index()\n\n fig = make_subplots(rows=1, cols=1)\n trace4 = go.Scatter(x=grouped_country_date['Date'],y=grouped_country_date['Active'],name=\"Active\",\n                    line_color='green',mode='lines+markers',opacity=0.8)\n fig.append_trace(trace4, 1, 1)\n\n fig.update_layout(template=\"plotly_dark\",title_text = '<b>Spread of the COVID19 over time in {}</b>'.format(country),\n                   height= 400,font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\n#  fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for country in countries:\n \n grouped_country = cont_spread2[cont_spread2['Country/Region'] == country].reset_index()\n grouped_country_date = grouped_country\n#  grouped_country_date = grouped_country.groupby('Date')['Date', 'Confirmed', 'Deaths','Recovered','Active'\n#                                                   ].sum().reset_index()\n#  grouped_country_date['Keywords']= grouped_country['Keywords']\n\n# keywords = []\n# for date in grouped_country_date['Date']:\n#     keyword_value = ''\n#     for dateStart in grouped_country['Date']:\n#         if date == dateStart:\n#             keyword_value = grouped_country[grouped_country['Date'] == dateStart]['Keywords']\n#             break\n#     keywords.append(keyword_value)\n# grouped_country_date['Keywords'] = keywords\n# print(keywords)\n\n fig = make_subplots(rows=1, cols=1)\n#  trace1 = go.Scatter(x=grouped_country_date['Date'],y=grouped_country_date['Confirmed'],name=\"Confirmed\",hovertext=grouped_country_date['Keywords']\n#                     ,line_color='yellow',mode='lines+markers',opacity=0.8)\n#  trace2 = go.Scatter(x=grouped_country_date['Date'],y=grouped_country_date['Deaths'],name=\"Deaths\",hovertext=grouped_country_date['Keywords'],\n#                     line_color='orange',mode='lines+markers',opacity=0.8)\n#  trace3 = go.Scatter(x=grouped_country_date['Date'],y=grouped_country_date['Recovered'],name=\"Recovered\",\n#                      line_color='red',mode='lines+markers',opacity=0.8)\n trace4 = go.Scatter(x=grouped_country_date['Date'],y=grouped_country_date['Active'],name=\"Active\",hovertext=grouped_country_date['Keywords'],\n                    line_color='green',mode='lines+markers',opacity=0.8)\n#  fig.append_trace(trace1, 1, 1)\n#  fig.append_trace(trace2, 2, 1)\n#  fig.append_trace(trace3, 3, 1)\n fig.append_trace(trace4, 1, 1)\n\n fig.update_layout(template=\"plotly_dark\",title_text = '<b>Spread of the COVID19 over time in {}</b>'.format(country),\n                   height= 400,font=dict(family=\"Arial, Balto, Courier New, Droid Sans\",color='white'))\n fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ignore the spike in the above graph as there are created due to merge of new dates from keywords dataset for which no cases were reported in the other dataset."},{"metadata":{},"cell_type":"markdown","source":"# Understanding the Measures, Impact and Categories:\n"},{"metadata":{},"cell_type":"markdown","source":"1.international traveller screening: \nGermany\nSouth Korea\nIran\nFrance\nNetherlands\nUK\nJapan\nItaly \nSpain\n2 domestic traveller screening:\n\n2.social distancing\n3.lockdown, \n4.shutdown, \n5.emergency declaration \n6.contact isolation, \n7.phone based tracking\n\nLets call school closure, gathering, travel ban, social distancing as medium measures and \nblanket, lockdown, emergency, stay,tracing, isolation as critical measures"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom scipy.optimize import curve_fit\n\nfrom datetime import timedelta\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.lines import Line2D\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def min_date(data, num, text, by=None):\n    \n    if by is None:\n        by = 'Country_Region'\n    \n    min_dates = data[data['n_cases'] > num].groupby(by, as_index=False).date.min()\n    \n    return min_dates.rename(columns={'date': text})\n\n\ndef increase(data):\n    increase = data[['Country_Region', 'date', 'n_cases']].sort_values(['Country_Region', 'date'], ascending=True).copy()\n    increase['increase'] = increase.n_cases.diff().fillna(0)\n    increase.loc[increase.increase < 0, 'increase'] = 0\n    increase['perc_increase'] = (increase.increase / (increase.n_cases - increase.increase) * 100).fillna(0)\n    \n    return increase[['Country_Region', 'date', 'increase', 'perc_increase']]\n\n\ndef load_series(path):\n    ignore = ['Province/State', 'Lat', 'Long']\n    data = pd.read_csv(path)\n    \n    data = data[[col for col in data if col not in ignore]].groupby('Country/Region', as_index=False).sum()\n    data.rename(columns={'Country/Region': 'Country_Region'}, inplace=True)\n    \n    data = data.melt(id_vars='Country_Region')\n    data['date'] = pd.to_datetime(data['variable'])\n    del data['variable']\n    data.rename(columns={'value': 'n_cases'}, inplace=True)\n    \n    first_case = min_date(data, 0, 'first_date')\n    data = pd.merge(data, first_case, on='Country_Region', how='left')\n    data['from_first'] = (data['date'] - data['first_date']).dt.days\n    \n    case_10 = min_date(data, 9, '10th_date')\n    data = pd.merge(data, case_10, on='Country_Region', how='left')\n    data['from_10th'] = (data['date'] - data['10th_date']).dt.days\n    \n    case_50 = min_date(data, 49, '50th_date')\n    data = pd.merge(data, case_50, on='Country_Region', how='left')\n    data['from_50th'] = (data['date'] - data['50th_date']).dt.days\n    \n    case_100 = min_date(data, 99, '100th_date')\n    data = pd.merge(data, case_100, on='Country_Region', how='left')\n    data['from_100th'] = (data['date'] - data['100th_date']).dt.days\n    \n    case_500 = min_date(data, 499, '500th_date')\n    data = pd.merge(data, case_500, on='Country_Region', how='left')\n    data['from_500th'] = (data['date'] - data['500th_date']).dt.days\n    \n    data['Country_Region'] = data['Country_Region'].map({'US': 'United States', \n                                                         'Korea, South': 'South Korea'}).fillna(data['Country_Region'])\n    \n    continents = pd.read_csv('/kaggle/input/country-to-continent/countryContinent.csv', encoding = 'ISO-8859-1')\n    continents['country'] = continents['country'].map({'United States of America': 'United States', \n                                                       'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n                                                       'Korea (Republic of)': 'South Korea', \n                                                       \"Korea (Democratic People's Republic of)\": 'North Korea'}).fillna(continents['country'])\n    \n    data = pd.merge(data, continents[['country', 'continent', 'sub_region']], left_on='Country_Region', right_on='country', how='left')\n    del data['country']\n    \n    country_info = pd.read_csv('/kaggle/input/population-by-country-2020/population_by_country_2020.csv')\n    data = pd.merge(data, country_info[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Med. Age']], \n                    left_on='Country_Region', right_on='Country (or dependency)', how='left')\n    data.rename(columns={'Population (2020)': 'population', 'Density (P/Km²)': 'pop_density', 'Med. Age': 'median_age'}, inplace=True)\n    data.loc[data.median_age == 'N.A.', 'median_age'] = np.nan\n    data['median_age'] = pd.to_numeric(data.median_age)\n    del data['Country (or dependency)']\n    \n    new_cases = increase(data)\n    data = pd.merge(data, new_cases, on=['Country_Region', 'date'], how='left')\n    \n    return data\n\n\ndef start_from(cases, deaths, col_start, on_cases=False, n_top=10, true_count='x', make_rate=False, ch_date=True):\n    if on_cases:\n        tmp = pd.merge(cases[['Country_Region', 'date', 'continent', 'population', 'n_cases']+[col_start]], \n                      deaths[['Country_Region', 'date', 'n_cases']], on=['Country_Region', 'date'])\n    else:\n        tmp = pd.merge(cases[['Country_Region', 'date', 'continent', 'population', 'n_cases']], \n                      deaths[['Country_Region', 'date', 'n_cases']+[col_start]], on=['Country_Region', 'date'])\n        \n    top_countries = tmp.groupby('Country_Region').n_cases_x.max().sort_values(ascending=True).tail(n_top).index.tolist()\n    tmp = tmp[tmp[col_start] > 0]\n    tmp = tmp[tmp.Country_Region.isin(top_countries)]\n    if ch_date:\n        tmp['date'] = tmp[col_start]\n    if make_rate:\n        tmp['n_cases_y'] = (tmp['n_cases_y'] / tmp['n_cases_x'] * 100).fillna(0)\n        true_count = 'y'\n    \n    tmp['n_cases'] = tmp[f'n_cases_{true_count}']\n    \n    return tmp\n\n\ndef country_cont(data, country):\n    df = data[data.Country == country][['Date Start',\n                                    'Description of measure implemented',\n                                    'Exceptions', \n                                    'Keywords', \n                                    'Target region']].copy()\n    df['region'] = df['Target region'].fillna('All')\n    df['Keywords'] = df['Keywords'].fillna('-')\n    df['date'] = pd.to_datetime(df['Date Start'])\n    df.drop(['Date Start', 'Target region'], axis=1, inplace=True)\n    df = df.sort_values(by='date').reset_index(drop=True)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_cases = load_series('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv')\nrecovered = load_series('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_recovered.csv')\ndeaths = load_series('/kaggle/input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv')\n\n# containment = pd.read_csv('/kaggle/input/covid19-containment-and-mitigation-measures/COVID%2019%20Containment%20measures%202020-03-30.csv')\n# tmp = pd.read_csv('/kaggle/input/covid19-containment-and-mitigation-measures/COVID-19%20containment%20measures/COVID 19 Containment measures data.csv')\n# containment = pd.concat([containment, tmp], ignore_index=True)\n# containment.loc[containment.Country.fillna('-').str.contains('US:'), 'Country'] = 'United States'\ncontainment = pd.read_csv('/kaggle/input/covid19-containment-and-mitigation-measures/COVID 19 Containment measures data.csv')\ncontainment.loc[containment.Country.fillna('-').str.contains('US:'), 'Country'] = 'United States'\n\nconf_cases[(conf_cases.median_age <45) &(conf_cases.median_age >20)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_use = ['Country_Region', 'n_cases', 'increase', 'perc_increase', 'date', 'first_date', 'from_first', \n          '10th_date', 'from_10th', '50th_date', 'from_50th', '100th_date', 'from_100th', '500th_date', 'from_500th']\n\nfull_data = pd.merge(conf_cases[to_use].rename(columns={'first_date': 'first_case_date', \n                                                        'from_first': 'from_first_case', \n                                                        '10th_date': '10th_case_date', \n                                                        'from_10th': 'from_10th_case', \n                                                        '50th_date': '10th_case_date', \n                                                        'from_50th': 'from_50th_date',\n                                                        '100th_date': '100th_case_date', \n                                                        'from_100th': 'from_100th_case', \n                                                        '500th_date': '500th_case_date',\n                                                        'from_500th': 'from_500th_case', \n                                                        'increase': 'new_cases', \n                                                        'perc_increase': 'new_cases_perc'}), \n                     deaths[to_use].rename(columns={'first_date': 'first_victim_date', \n                                                        'from_first': 'from_first_victim', \n                                                        '10th_date': '10th_victim_date', \n                                                        'from_10th': 'from_10th_victim', \n                                                        '50th_date': '50th_victim_date', \n                                                        'from_50th': 'from_50th_victim',\n                                                        '100th_date': '100th_victim_date', \n                                                        'from_100th': 'from_100th_victim', \n                                                        '500th_date': '500th_victim_date',\n                                                        'from_500th': 'from_500th_victim', \n                                                    'n_cases': 'n_victims', \n                                                        'increase': 'new_victims', \n                                                        'perc_increase': 'new_victims_perc'}), \n                    on=['Country_Region', 'date'])\n\n\nfull_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures ='lockdown|business suspension|school closure|travel ban|social distancing|blanket curfew|shutdown|emergency|nonessential|outdoor gatherings banned|contact tracing|traveller screening|remote work|personal hygiene'\ncountries = ['South Korea','Germany', 'Iceland','Iran','Italy', 'Spain', 'Russia',  'Japan', 'United Kingdom','Netherlands', 'France']\n\n\ncont_all = []\n\nfor country in countries:\n    tmp = country_cont(containment, country)\n    tmp['Country_Region'] = country\n    tmp['date'] = tmp['date'].fillna('-')\n    tmp = tmp[tmp.Keywords.str.contains(measures)]\n    cont_all.append(tmp[['Country_Region', 'date', 'Keywords', 'region']])\n    \ncont_all = pd.concat(cont_all, ignore_index=False)\n# cont_all = cont_all[(cont_all.date >= pd.to_datetime('2020-02-01'))]  # a school ban that I can't find proof of\n\ncont_all.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Looking for measures that aided in controlling the spread:\nWe see from previous graphs that measures like international traveller screening,social distancing followed by lockdown, shutdown,  emergency declaration have yielded commendable results in few countries (but not in others). Measures like contact isolation, phone based tracking have bolstered the previous measures and typically taken once the previous measures had started to decrease the spread. Hence, it is quite not evident if these methods really made the impact or were surrogate.\nLets further try to individually inspect the measures and their impact based on the curves."},{"metadata":{},"cell_type":"markdown","source":"Interesting dates to note in these countries:\n* SouthKorea: March 9 Cases:7307\n* Germany: March 30, April 5 Cases:52k, 72k\n* Iceland: M17, M21, M24 Cases: 219, 450, 595\n* Iran: March 29, April 6 Cases:23k, 34k\n* Italy:  M 29, A12, A19 Cases:73k, 102k, 108k\n* Spain: M27, A6, A18 Cases: 51k, 82k, 96k\n\n\nIncreasing\n* Russia: A17, 29k\n* Japan: A10, Cases: 4746\n* UK: A5 Cases:29k\n* Netherlands: A6 Cases:16k\n* France: A12 Cases:79k\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.signal import argrelextrema\ndef pop(df):\n    Population =[]\n    Density= []\n    countries = df['Country_Region'].values\n    \n    countries = list(countries)\n    for country in countries:\n#       updata.groupby('Country_Region')[Population]\n#         print(updata[updata['Country_Region']==country])\n        pop = updata[updata['Country_Region']==country].Population.values\n        density =updata[updata['Country_Region']==country].density.values\n        Population.append(pop)\n        Density.append(density)\n    df['Population'] =  Population   \n    df['Density'] = Density\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getDaysTaken(df):\n    measure_Date = []\n    peak_Date = []\n    Peak_cases = []\n    Days =[] \n    countries = df['Country_Region'].values\n    \n    countries = list(countries)\n    for country in countries:\n     grouped_country = cont_spread2[cont_spread2['Country/Region'] == country].reset_index()\n     grouped_country_date = grouped_country\n     n=6 # number of points to be checked before and after \n# Find local peaks\n     grouped_country_date['min'] = grouped_country_date.iloc[argrelextrema(grouped_country_date.Active.values, np.less_equal, order=n)[0]]['Active']\n     grouped_country_date['max'] = grouped_country_date.iloc[argrelextrema(grouped_country_date.Active.values, np.greater_equal, order=n)[0]]['Active']\n     maxpeak= grouped_country_date['max'].max()\n#      print(maxpeak)\n     pdate = grouped_country_date[grouped_country_date.Active == maxpeak].Date\n     \n#      print(country)\n     \n     date_first= res[res['Country_Region']==country].date.values\n#      print('measure date:{}'.format(pd.Timestamp(date_first[0])))\n\n     date_peak = pdate.values\n#      print('peak date:{}'.format(pd.Timestamp(date_peak[0])))\n     \n     days = (pd.Timestamp(date_peak[0]) - pd.Timestamp(date_first[0]))\n#      print(days)\n     \n#      print()\n     measure_Date.append(pd.Timestamp(date_first[0]))\n     peak_Date.append(pd.Timestamp(date_peak[0]))\n     Days.append(days)\n     Peak_cases.append(maxpeak)\n    df['measure_Date'] = measure_Date\n    df['peak_Date'] =peak_Date\n    df['Days']= Days\n    df['Peak_cases'] =Peak_cases\n      \n    return res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Country wise dates for the earliest date of one of the low measures implementation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlow_measures = 'school closure|gathering|travel ban|hygiene'\nmed_measures = 'social distancing|remote work'\ncrit_measures = 'blanket|lockdown|emergency|stay|tracing|isolation'\n\ntmp = cont_all[cont_all.Keywords.str.contains(low_measures)].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Country wise dates for the earliest date of one of the medium measures implementation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmed_measures = 'social distancing|remote work'\ntmp = cont_all[cont_all.Keywords.str.contains(med_measures)].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Country wise dates for the earliest date of one of the critical measures implementation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"crit_measures = 'blanket|lockdown|emergency|stay|tracing|isolation'\n\ntmp = cont_all[cont_all.Keywords.str.contains(crit_measures)].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"International Travel/Hygiene"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntmp = cont_all[cont_all.Keywords.str.contains('travel|hygiene')].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Social Distancing* "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntmp = cont_all[cont_all.Keywords.str.contains('social distancing')].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Isolation/Blanket curfews"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntmp = cont_all[cont_all.Keywords.str.contains('isolation|blanket')].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*emergency/lockdown*"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = cont_all[cont_all.Keywords.str.contains('lockdown|curfew|isolation')].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\ncrit =tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ngetDaysTaken(crit)\npop(crit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = cont_all[cont_all.Keywords.str.contains('social distancing|isolation|blanket|hygiene')].groupby('Country_Region', as_index=False).date.min()\n\ntmp = pd.merge(tmp, full_data, on=['Country_Region', 'date'])\nres= tmp[['Country_Region', 'date','n_cases', 'n_victims', 'from_10th_case', 'from_first_victim', 'from_100th_case', 'from_10th_victim']].sort_values('n_cases')\ndisplay(getDaysTaken(res))\ndisplay(pop(res))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum',\n                                                                                         'GrowthRate':'last' })\n#display(train_data_by_country.tail(10))\nmax_train_date = train_data['Date'].max()\ntrain_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\ntrain_data_by_country_confirm.set_index('Country_Region', inplace=True)\n\ntrain_data_by_country_confirm.style.background_gradient(cmap='Reds').format({'ConfirmedCases': \"{:.0f}\", 'GrowthRate': \"{:.2f}\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}