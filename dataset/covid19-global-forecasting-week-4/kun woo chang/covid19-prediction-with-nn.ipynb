{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n%config InlineBackend.figure_format = 'retina'\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\nLoad and prepare the data**\n\nSupposed, accumulated data, daily data, flight data, tested data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '/kaggle/input/covid19-global-forecasting-week-4/train.csv'\n\ndata_train = pd.read_csv(data_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data_train.head())\ndisplay(data_train.describe())\ndisplay(data_train.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking out the data**\n\nFirst, checking for US, Italy, Spain, South Korea."},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_total_date_Italy = data_train[data_train['Country_Region']=='Italy'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Italy = data_train[data_train['Country_Region']=='Italy'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\nplt.figure(figsize=(17,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nconfirmed_total_date_US = data_train[data_train['Country_Region']=='US'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_US = data_train[data_train['Country_Region']=='US'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_US = confirmed_total_date_US.join(fatalities_total_date_US)\n\n#plt.figure(figsize=(17,10))\nplt.subplot(2, 2, 2)\ntotal_date_US.plot(ax=plt.gca(), title='US')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nconfirmed_total_date_Spain = data_train[data_train['Country_Region']=='Spain'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Spain = data_train[data_train['Country_Region']=='Spain'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n\n#plt.figure(figsize=(17,10))\nplt.subplot(2, 2, 3)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nconfirmed_total_date_Korea = data_train[data_train['Country_Region']=='Korea, South'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Korea = data_train[data_train['Country_Region']=='Korea, South'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Korea = confirmed_total_date_Korea.join(fatalities_total_date_Korea)\n\n#plt.figure(figsize=(17,10))\nplt.subplot(2, 2, 4)\ntotal_date_Korea.plot(ax=plt.gca(), title='Korea, South')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\n# Plots\nplt.figure(figsize=(17,10))\nplt.subplot(2, 2, 1)\nplt.plot(confirmed_total_date_Italy)\nplt.plot(confirmed_total_date_US)\nplt.plot(confirmed_total_date_Spain)\nplt.plot(confirmed_total_date_Korea)\nplt.legend([\"Italy\", \"US\", \"Spain\", \"Korea, South\"], loc='upper left')\nplt.title(\"COVID-19 infections from the first confirmed case\", size=15)\nplt.xlabel(\"Days\", size=13)\nplt.ylabel(\"Infected cases\", size=13)\nplt.ylim(0, 180000)\n#plt.show()\n\n# Plots\n#plt.figure(figsize=(12,6))\nplt.subplot(2, 2, 2)\nplt.plot(fatalities_total_date_Italy)\nplt.plot(fatalities_total_date_US)\nplt.plot(fatalities_total_date_Spain)\nplt.plot(fatalities_total_date_Korea)\nplt.legend([\"Italy\", \"US\", \"Spain\", \"Korea, South\"], loc='upper left')\nplt.title(\"COVID-19 Fatalities\", size=15)\nplt.xlabel(\"Days\", size=13)\nplt.ylabel(\"Infected cases\", size=13)\nplt.ylim(0, 23000)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Daily values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_daily_measures(df):\n    df.loc[0,'Daily Cases'] = df.loc[0,'ConfirmedCases']\n    df.loc[0,'Daily Deaths'] = df.loc[0,'Fatalities']\n    for i in range(1,len(df)):\n        df.loc[i,'Daily Cases'] = df.loc[i,'ConfirmedCases'] - df.loc[i-1,'ConfirmedCases']\n        df.loc[i,'Daily Deaths'] = df.loc[i,'Fatalities'] - df.loc[i-1,'Fatalities']\n    #Make the first row as 0 because we don't know the previous value\n    df.loc[0,'Daily Cases'] = 0\n    df.loc[0,'Daily Deaths'] = 0\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_world = data_train.copy()\ndf_world = df_world.groupby('Date',as_index=False)['ConfirmedCases','Fatalities'].sum()\ndf_world = add_daily_measures(df_world)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_world.plot(title ='Covid19 World daily status', y=['Daily Cases','Daily Deaths'], x='Date', figsize=(12,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Daily status**\n\nFour countries : US, Italy, Spain, South Korea"},{"metadata":{"trusted":true},"cell_type":"code","source":"# USA\ndf_usa = data_train.query(\"Country_Region=='US'\")\ndf_usa = df_usa.groupby('Date',as_index=False)['ConfirmedCases','Fatalities'].sum()\ndf_usa = add_daily_measures(df_usa)\n\n#Italy\ndf_italy = data_train.query(\"Country_Region=='Italy'\")\ndf_italy = df_italy.groupby('Date',as_index=False)['ConfirmedCases','Fatalities'].sum()\ndf_italy = add_daily_measures(df_italy)\n\n#Spain\ndf_spain = data_train.query(\"Country_Region=='Spain'\")\ndf_spain = df_spain.groupby('Date',as_index=False)['ConfirmedCases','Fatalities'].sum()\ndf_spain = add_daily_measures(df_spain)\n\n#Korea\ndf_korea = data_train.query(\"Country_Region=='Korea, South'\")\ndf_korea = df_korea.groupby('Date',as_index=False)['ConfirmedCases','Fatalities'].sum()\ndf_korea = add_daily_measures(df_korea)\n\n\ndf_usa.plot(title = \"USA\", y=['Daily Cases','Daily Deaths'], x='Date', figsize=(12,6))\n\ndf_italy.plot(title = \"Italy\", y=['Daily Cases','Daily Deaths'], x='Date', figsize=(12,6))\n\ndf_spain.plot(title = \"Spain\", y=['Daily Cases','Daily Deaths'], x='Date', figsize=(12,6))\n\ndf_korea.plot(title = \"South Korea\", y=['Daily Cases','Daily Deaths'], x='Date', figsize=(12,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Flight information for countries**\n\nReference : https://www.radarbox.com/statistics/total"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_flight = pd.read_csv('/kaggle/input/covid19/covid19_flight_countries_mod.csv')\n\ndata_flight.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_flight.plot(x='Date', figsize=(12,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Testd value per day**\n\nReference : https://ourworldindata.org/grapher/full-list-covid-19-tests-per-day"},{"metadata":{"trusted":true},"cell_type":"code","source":"#full-list-covid-19-tests-per-day\ndata_daily_tested = pd.read_csv('/kaggle/input/covid19/full-list-covid-19-tests-per-day.csv')\n\ndata_daily_tested.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_daily_tested.plot(x='Date', figsize=(12,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa_tested = data_daily_tested.query(\"Code=='USA'\")\ndf_italy_tested = data_daily_tested.query(\"Entity=='Italy'\")\ndf_spain_tested = data_daily_tested.query(\"Entity=='Spain'\")\ndf_korea_tested = data_daily_tested.query(\"Entity=='South Korea'\")\n#df_usa_tested.head()\n#df_italy_tested.head()\n#df_spain_tested.head()\n#df_korea_tested.head()\ndf_usa_tested.plot(title='USA', x='Date', figsize=(12,6))\ndf_italy_tested.plot(title='Italy', x='Date', figsize=(12,6))\ndf_korea_tested.plot(title='Korea', x='Date', figsize=(12,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test data**\n\nAt this moment, focused on USA data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa_merge = pd.merge(df_usa, df_usa_tested)\ndf_usa_merge = pd.merge(df_usa_merge, data_flight)\ndf_usa_merge.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Currently, only consider USA data\ndf_usa_data = df_usa_merge.drop(['Date', 'Entity', 'Code', 'US <-> Latin America', 'US <-> China', 'Canada <-> Canada', 'Canada <-> NON Canada', 'Europe <-> Europe', 'Europe <-> UK', 'Europe <-> Latin America', 'UK <-> UK', 'UK <-> NON UK', 'Italy <-> Italy', 'China <-> China', 'Brazil <-> Brazil', 'Brazil <-> NON Brazil', 'India <-> India', 'India <-> NON India', 'Iran <-> Iran'], axis=1)\ndf_usa_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa_data.plot(figsize=(12,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scaling target variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"quant_features = ['Daily Cases', 'Daily change in cumulative total tests', 'US <-> US', 'US <-> NON US','US <-> Europe', 'ConfirmedCases']\n# Store scalings in a dictionary so we can convert back later\nscaled_features = {}\nfor each in quant_features:\n    mean, std = df_usa_data[each].mean(), df_usa_data[each].std()\n    scaled_features[each] = [mean, std]\n    df_usa_data.loc[:, each] = (df_usa_data[each] - mean)/std\n\ndf_usa_data.head()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the data into training, testing, and validation sets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save data for approximately the last 15 days \ntest_data = df_usa_data[-15:]\n\n# Now remove the test data from the data set \ndata = df_usa_data[:-15]\n\n# Separate the data into features and targets\ntarget_fields = ['Daily Cases', 'Daily change in cumulative total tests', 'ConfirmedCases']\nfeatures, targets = df_usa_data.drop(target_fields, axis=1), df_usa_data[target_fields]\ntest_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hold out the last 60 days or so of the remaining data as a validation set\ntrain_features, train_targets = features[:-43], targets[:-43]\nval_features, val_targets = features[-43:], targets[-43:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Build the neural network**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNetwork(object):\n    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n        # Set number of nodes in input, hidden and output layers.\n        self.input_nodes = input_nodes\n        self.hidden_nodes = hidden_nodes\n        self.output_nodes = output_nodes\n\n        # Initialize weights\n        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n                                       (self.input_nodes, self.hidden_nodes))\n\n        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n                                       (self.hidden_nodes, self.output_nodes))\n        self.lr = learning_rate\n        \n        # Sigmoid activation function\n        self.activation_function = lambda x : (1/(1+np.exp(-x)))  \n                    \n    def train(self, features, targets):\n        n_records = features.shape[0]\n        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n        for X, y in zip(features, targets):\n            \n            final_outputs, hidden_outputs = self.forward_pass_train(X) \n            \n            delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y, \n                                                                        delta_weights_i_h, delta_weights_h_o)\n        self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n\n\n    def forward_pass_train(self, X):\n\n        hidden_inputs = np.dot(X, self.weights_input_to_hidden) # signals into hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n\n        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n        final_outputs = final_inputs # signals from final output layer\n        \n        \n        return final_outputs, hidden_outputs\n\n    def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n        \n        error = y-final_outputs # Output layer error is the difference between desired target and actual output.\n        \n        # The hidden layer's contribution to the error\n        hidden_error = np.dot(self.weights_hidden_to_output, error)\n        \n        #Backpropagated error terms\n        output_error_term = error * 1\n        \n        hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)\n        \n        # Weight step (input to hidden)\n        delta_weights_i_h += hidden_error_term * X[:,None]\n        # Weight step (hidden to output)\n        delta_weights_h_o += (output_error_term * hidden_outputs[:,None])\n        return delta_weights_i_h, delta_weights_h_o\n\n    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n        \n        # update hidden-to-output weights with gradient descent step\n        self.weights_hidden_to_output += self.lr * delta_weights_h_o/n_records \n\n        # update input-to-hidden weights with gradient descent step\n        self.weights_input_to_hidden += self.lr * delta_weights_i_h/n_records \n\n    def run(self, features):\n        \n        #Hidden layer\n        hidden_inputs = np.dot(features, self.weights_input_to_hidden) # signals into hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n        \n        #Output layer \n        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n        final_outputs = final_inputs # signals from final output layer \n        \n        return final_outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MSE(y, Y):\n    return np.mean((y-Y)**2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyper parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hyperparameter\n\niterations = 1000\nlearning_rate = 0.3\nhidden_nodes = 7\noutput_nodes = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nN_i = train_features.shape[1]\nnetwork = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n\nlosses = {'train':[], 'validation':[]}\nfor ii in range(iterations):\n    # Go through a random batch of 128 records from the training data set\n    batch = np.random.choice(train_features.index, size=128)\n    X, y = train_features.iloc[batch].values, train_targets.iloc[batch]['Daily Cases']\n                             \n    network.train(X, y)\n    \n    # Printing out the training progress\n    train_loss = MSE(network.run(train_features).T, train_targets['Daily Cases'].values)\n    val_loss = MSE(network.run(val_features).T, val_targets['Daily Cases'].values)\n    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n                     + \" ... Validation loss: \" + str(val_loss)[:5])\n    sys.stdout.flush()\n    \n    losses['train'].append(train_loss)\n    losses['validation'].append(val_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(losses['train'], label='Training loss')\nplt.plot(losses['validation'], label='Validation loss')\nplt.legend()\n_ = plt.ylim()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,6))\n\nmean, std = scaled_features['Daily Cases']\npredictions = network.run(test_features).T*std + mean\nax.plot(predictions[0], label='Prediction')\nax.plot((test_targets['Daily Cases']*std + mean).values, label='Daily Cases')\nax.set_xlim(right=len(predictions))\nax.legend()\n\ndates = pd.to_datetime(df_usa_merge.iloc[test_data.index]['Date'])\ndates = dates.apply(lambda d: d.strftime('%b %d'))\nax.set_xticks(np.arange(len(dates)))\n_ = ax.set_xticklabels(dates, rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}