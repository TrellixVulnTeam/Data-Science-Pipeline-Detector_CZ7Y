{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Model 3: Using XGB Regressor"},{"metadata":{},"cell_type":"markdown","source":"# Importing all the necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport seaborn as sns\nimport csv\nimport numpy as np\nimport operator\nimport random\nimport datetime\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport sklearn.discriminant_analysis\nimport sklearn.linear_model as skl_lm\n\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom datetime import timedelta\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.metrics import hamming_loss, accuracy_score \nfrom pandas import DataFrame\nfrom datetime import datetime\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH ='/kaggle/input/covid19-global-forecasting-week-4'\ndatatrain = pd.read_csv(f'{PATH}/train.csv')\ndatatest = pd.read_csv(f'{PATH}/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date = pd.to_datetime(datatrain[\"Date\"])\ndatet = pd.to_datetime(datatest[\"Date\"])\nprint (date)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldate = int(len(date))\nldatet = int(len(datet))\nprint(\"Length of training- date is\", ldate)\nprint(\"Length of test- date is\", ldatet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = []\nd = []\nfor i in range(0,ldate):\n    dx = (date[i].strftime(\"%d\"))\n    mx = (date[i].strftime(\"%m\"))\n    m.append(int(mx))\n    d.append(int(dx))\n\nmt = []\ndt = []\nfor i in range(0,ldatet):\n    dtx = (datet[i].strftime(\"%d\"))\n    mtx = (datet[i].strftime(\"%m\"))\n    mt.append(int(mtx))\n    dt.append(int(dtx))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = datatrain\ntest = datatest\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.insert(6,\"Month\",m,False)\ntrain.insert(7,\"Day\",d,False)\ntest.insert(4,\"Month\",mt,False)\ntest.insert(5,\"Day\",dt,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Datatrain\")\ntraindays = datatrain['Date'].nunique()\nprint(\"Number of Country_Region: \", datatrain['Country_Region'].nunique())\nprint(\"Number of Province_State: \", datatrain['Province_State'].nunique())\nprint(\"Number of Days: \", traindays)\n\nnotrain = datatrain['Id'].nunique()\nprint(\"Number of datapoints in train:\", notrain)\nlotrain = int(notrain/traindays)\nprint(\"L Trains:\", lotrain)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Datatest\")\ntestdays = datatest['Date'].nunique()\nprint(\"Number of Days: \", testdays)\nnotest = datatest['ForecastId'].nunique()\nprint(\"Number of datapoints in test:\", notest)\nlotest = int(notest/testdays)\nprint(\"L Test:\", lotest)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nzt = datet[0]\ndaycount = []\nfor i in range(0,lotrain):\n    for j in range(1,traindays+1):\n        daycount.append(j)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(traindays):\n    if(zt == date[i]):\n        zx = i\n        print(zx)\n        \ndaytest = []\nfor i in range(0,lotest):\n    for j in range(1,testdays+1):\n        jr = zx + j\n        daytest.append(jr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.insert(8,\"DayCount\",daycount,False)\ntest.insert(6,\"DayCount\",daytest,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traincount = int(len(train[\"Date\"]))\n\ntestcount = int(len(test[\"Date\"]))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Province_State = train.Province_State.fillna(0)\nempty = 0\nfor i in range(0,traincount):\n    if(train.Province_State[i] == empty):\n        train.Province_State[i] = train.Country_Region[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Province_State = test.Province_State.fillna(0)\nempty = 0\nfor i in range(0,testcount):\n    if(test.Province_State[i] == empty):\n        test.Province_State[i] = test.Country_Region[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = preprocessing.LabelEncoder()\ntrain.Country_Region = label.fit_transform(train.Country_Region)\ntrain.Province_State = label.fit_transform(train.Province_State)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Country_Region = label.fit_transform(test.Country_Region)\ntest.Province_State = label.fit_transform(test.Province_State)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.c_[train[\"Province_State\"], train[\"Country_Region\"], train[\"DayCount\"], train[\"Month\"], train[\"Day\"]]\nXt = np.c_[test[\"Province_State\"], test[\"Country_Region\"], test[\"DayCount\"], test[\"Month\"], test[\"Day\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(X.shape)\ndisplay(Xt.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y1 = train[\"ConfirmedCases\"]\nY2 = train[\"Fatalities\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(Y1.shape)\ndisplay(Y2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y1.head(100)\n#Y1.shape\nY2.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y_true, y_pred):\n    return mean_squared_log_error(y_true, y_pred)**(1/2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the XGB Regressor Model"},{"metadata":{},"cell_type":"markdown","source":"* # Default settings:\n\n(n_estimators = 1000, \n\ngamma = 0, \n\nlearning_rate = 0.05,  \n\nrandom_state = 42 , \n\nmax_depth = 20)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 1000, gamma = 0, learning_rate = 0.05,  \n                                  random_state = 42 , max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 1000 , gamma = 0, learning_rate = 0.05,  \n                                    random_state = 42 , max_depth = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Regressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nyptest = Regressor_fatalities.predict(X)\nyptest = np.round(yptest)\nB = mean_squared_error(yptest,Y2)\nprint(\"Training - (Fatalities) Mean Squared Error is\", B)\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training - (Fatalities) Mean Squared Error is 0.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = pd.DataFrame()\nforecast = test[\"ForecastId\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#yp = yp.drop(['Country_Region', 'Date', 'Month', 'Day', 'DayCount', 'Province_State'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred.insert(0,\"ForecastId\",forecast,False)\nfinal_pred.insert(1,\"ConfirmedCases\",ypred,False)\nfinal_pred.insert(2, \"Fatalities\",ypred2,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Changing the Learning Rate:\n\n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"learning_rate = 0.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 1000, gamma = 0, learning_rate = 0.5,  \n                                  random_state = 42 ,max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 1000 , gamma = 0, learning_rate = 0.5,  \n                                    random_state = 42 , max_depth = 20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing the learning rate to 0.01"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 1000, gamma = 0, learning_rate = 0.01,  \n                                  random_state = 42 , max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 1000 , gamma = 0, learning_rate = 0.01,  \n                                    random_state = 42 , max_depth = 20)\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# changing the learning rate to 0.99"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 1000, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 1000 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 , max_depth = 20)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Changing the n_estimators\nn_estimators: number of trees you want to build."},{"metadata":{},"cell_type":"markdown","source":"n_estimators = 10"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 10, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 10 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 , max_depth = 20)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the n_estimators to 2500","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 , max_depth = 20)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The training time increase when we increase the number of n_estimators since it is the number of trees we want to build. However we need an ideal sweet spot such that we get low training error rate and acceptable training time"},{"metadata":{},"cell_type":"markdown","source":"# Also there is a interdependence between the number of n_estimators i.e. number of trees used and learning rate. If we reduce the learning rate too much we need to add the number of trees."},{"metadata":{},"cell_type":"markdown","source":"# Changing the n_estimators to 5000"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 5000, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 20) \nRegressor_fatalities = XGBRegressor(n_estimators = 5000 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 , max_depth = 20)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The above scenario takes too much training time and the error is similar to the previous case thus we revert back to 2500"},{"metadata":{},"cell_type":"markdown","source":"# Changing the max depth\n\nmax_depth: determines how deeply each tree is allowed to grow during any boosting round.\n"},{"metadata":{},"cell_type":"markdown","source":"changing the max depth to 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 2) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  r\n                                    andom_state = 42 , max_depth = 2)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Too bad MSE in the above case"},{"metadata":{},"cell_type":"markdown","source":"Changing the max depth to 200"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 200) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99, \n                                    random_state = 42 , max_depth = 200)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Changing max_depth = 50"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99, \n                                    random_state = 42 , max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing max_depth = 30"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 , max_depth = 30) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 , max_depth = 30)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding Min_child weight =100\ndefault=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 ,min_child_weight=100, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 ,min_child_weight=100, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# changing min_child_weight=10"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 ,min_child_weight=10, max_depth = 30) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 ,min_child_weight=10, max_depth = 30)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"changing the  min_child_weight back to 1"},{"metadata":{},"cell_type":"markdown","source":"# Changing the min_split_loss (gamma)"},{"metadata":{},"cell_type":"markdown","source":"gamma [default=0, alias: min_split_loss]\n\ngamma: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits."},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 ,min_child_weight=1,min_split_loss=10, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 ,min_child_weight=1,min_split_loss=10, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since the MSE is higher than the previous case we change it back to zero (default value)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,  \n                                  random_state = 42 ,min_child_weight=1,min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,  \n                                    random_state = 42 ,min_child_weight=1,min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Effect of Lambda (L2 Regularization) -> changing the value to 0 i.e. NO Regularization\nL2 regularization term on weights. Increasing this value will make model more conservative."},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,\n                                  reg_lambda=0,  random_state = 42 ,min_child_weight=1,\n                                  min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,\n                                    reg_lambda=0,  random_state = 42 ,min_child_weight=1,\n                                    min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thus L2 regularization plays an important role\nchanging back to the default value of 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,\n                                  reg_lambda=1,  random_state = 42 ,min_child_weight=1,\n                                  min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,\n                                    reg_lambda=1,  random_state = 42 ,min_child_weight=1,\n                                    min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Effect of alpha ( L1 regularization)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,\n                                  reg_lambda=0,reg_alpha=1,  random_state = 42 ,min_child_weight=1,\n                                  min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,\n                                    reg_lambda=0,reg_alpha=1,  random_state = 42 ,min_child_weight=1,\n                                    min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thus we prefer L2 regularization which is the default value in XGB Python API"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0, learning_rate = 0.99,\n                                  reg_lambda=1,reg_alpha=0,  random_state = 42 ,min_child_weight=1,\n                                  min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0, learning_rate = 0.99,\n                                    reg_lambda=1,reg_alpha=0,  random_state = 42 ,min_child_weight=1,\n                                    min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tweaking subsample\ndefault=1 and range (0,1)"},{"metadata":{},"cell_type":"markdown","source":"# Changing the subsample to 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0,subsample=0, learning_rate = 0.99,\n                                  reg_lambda=1,reg_alpha=0,  random_state = 42 ,min_child_weight=1,\n                                  min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0,subsample=0, learning_rate = 0.99,\n                                    reg_lambda=1,reg_alpha=0,  random_state = 42 ,min_child_weight=1,\n                                    min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing the subsample to 0.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regressor_Concases = XGBRegressor(n_estimators = 2500, gamma = 0,subsample=0.5, learning_rate = 0.99,\n                                  reg_lambda=1,reg_alpha=0,  random_state = 42 ,min_child_weight=1,\n                                  min_split_loss=0, max_depth = 50) \nRegressor_fatalities = XGBRegressor(n_estimators = 2500 , gamma = 0,subsample=0.5, \n                                    learning_rate = 0.99,reg_lambda=1,reg_alpha=0,  \n                                    random_state = 42 ,min_child_weight=1,min_split_loss=0, max_depth = 50)\n\n\n\nimport math\nfrom sklearn.metrics import mean_squared_log_error\nRegressor_Concases.fit(X,Y1.ravel())\nA1 = Regressor_Concases.predict(X)\n#B = mean_squared_error(A,Y1)\n#print(\"Training - Mean Squared Error is: \",B) \n\nA1=abs(A1)\nY1=abs(Y1)\n\n\nB1 = mean_squared_error(A1,Y1)\nB2 = mean_squared_log_error(A1,Y1)\nprint(\"-------Confirmed Case---------s\")\nprint(\"Training - Mean Squared Error is: \",B1)\nprint(\"Training - Mean Squared LOG Error is: \",B2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A1,Y1))\ndisplay(A1.shape)\n#print(\"Training - ROOT Mean Squared Error is: \",math.sqrt(B1))\n#print(rmsle(A1,Y1))\n\n\nypred = Regressor_Concases.predict(Xt)\nypred = pd.DataFrame({'ConfirmedCases' : ypred}) \nypred = round(ypred)\nypred.head(20) \n\nRegressor_fatalities.fit(X,Y2.ravel())\nypred2= Regressor_fatalities.predict(Xt)\nA2 = Regressor_fatalities.predict(X)\nA2 = np.round(A2)\nA2=abs(A2)\nY2=abs(Y2)\n\nC1 = mean_squared_error(A2,Y2)\nC2 = mean_squared_log_error(A2,Y2)\nprint(\"--------Fatalities-------\")\nprint(\"Training - Mean Squared Error is: \",C1)\nprint(\"Training - Mean Squared LOG Error is: \",C2)\nprint(\"Training - ROOT Mean Squared LOG Error is: \",rmsle(A2,Y2))\ndisplay(A2.shape)\n\nypred2 = pd.DataFrame({'Fatalities' : ypred2}) \nypred2 = round(ypred2)\nypred2.head(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We preserve this subsample rate"},{"metadata":{},"cell_type":"markdown","source":"# Thus our best performing model settings can be given as follows:\n**(n_estimators = 2500, \n\n**gamma = 0,**\n\n**subsample=0.5, **\n\n**learning_rate = 0.99,\n**\nreg_lambda=1,\n\n**reg_alpha=0, ** \n\n**random_state = 42 ,**\n\n**min_child_weight=1,**\n\n**min_split_loss=0, **\n\n**max_depth = 50) ****"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"End\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}