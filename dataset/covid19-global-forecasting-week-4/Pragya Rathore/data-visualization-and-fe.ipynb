{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Importing all the necessary libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport seaborn as sns\nimport csv\nimport numpy as np\nimport operator\nimport random\nimport datetime\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport sklearn.discriminant_analysis\nimport sklearn.linear_model as skl_lm\n\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom datetime import timedelta\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.metrics import hamming_loss, accuracy_score \nfrom pandas import DataFrame\nfrom datetime import datetime\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nimport datetime as dt\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\n\nfrom itertools import cycle, islice\nfrom sklearn.linear_model import LinearRegression\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport datetime as dt\nfrom itertools import cycle, islice\npy.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Import the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\n\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\n\ndf_sub=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_data.head(200))\ndisplay(test_data.head(200))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_of_data = pd.pivot_table(train_data, values=['ConfirmedCases','Fatalities'], index=['Date'],aggfunc=np.sum)\ndisplay(sum_of_data.max())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Feature Engineering**"},{"metadata":{},"cell_type":"markdown","source":"Features:\n\n* Daily Confirmed cases\n* Daily Fatalities\n* Growth factor (ratio of daily new cases to the previous day)\n* Mortality rate (ratio of fatalities to the confirmed cases)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['NewConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\ntrain_data['NewConfirmedCases'] = train_data['NewConfirmedCases'].fillna(0.0)\ntrain_data['NewFatalities']     = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\ntrain_data['NewFatalities']     = train_data['NewFatalities'].fillna(0.0)#.astype(int)\ntrain_data['MortalityRate']     = train_data['Fatalities'] / train_data['ConfirmedCases']\ntrain_data['MortalityRate']     = train_data['MortalityRate'].fillna(0.0)\ntrain_data['GrowthRate']        = train_data['NewConfirmedCases']/train_data['NewConfirmedCases'].shift(1)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].replace([-np.inf, np.inf],  0.0)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].fillna(0.0)\n\n\ndisplay(train_data.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ColumnInfo(df):\n    n_province =  df['Province_State'].nunique()\n    n_country  =  df['Country_Region'].nunique()\n    n_days     =  df['Date'].nunique()\n    start_date =  df['Date'].unique()[0]\n    end_date   =  df['Date'].unique()[-1]\n    return n_province, n_country, n_days, start_date, end_date\n\nn_train = train_data.shape[0]\nn_test = test_data.shape[0]\n\nn_prov_train, n_count_train, n_train_days, start_date_train, end_date_train = ColumnInfo(train_data)\nn_prov_test,  n_count_test,  n_test_days,  start_date_test,  end_date_test  = ColumnInfo(test_data)\n\nprint ('<==Train data==> \\n # of Province_State: '+str(n_prov_train),', # of Country_Region:'+str(n_count_train), \n       ', Time Period: '+str(start_date_train)+' to '+str(end_date_train), '==> days:',str(n_train_days))\nprint(\"\\n Countries with Province/State information:  \", train_data[train_data['Province_State'].isna()==False]['Country_Region'].unique())\nprint ('\\n <==Test  data==> \\n # of Province_State: '+str(n_prov_test),', # of Country_Region:'+str(n_count_test),\n       ', Time Period: '+start_date_test+' to '+end_date_test, '==> days:',n_test_days)\n\ndf_test = test_data.loc[test_data.Date > '2020-04-03']\noverlap_days = n_test_days - df_test.Date.nunique()\nprint('\\n overlap days with training data: ', overlap_days, ', total days: ', n_train_days+n_test_days-overlap_days)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Country/Region for the maximum cases**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\nprob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\n\nn_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\nn_fatal_train = train_data.Fatalities.value_counts()[1:].sum()\n\nprint('Percentage of confirmed case records = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_confirm_train, n_train, prob_confirm_check_train[1:].sum()*100))\nprint('Percentage of fatality records = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_fatal_train, n_train, prob_fatal_check_train[1:].sum()*100))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum',\n                                                                                         'GrowthRate':'last' })\n#display(train_data_by_country.tail(10))\nmax_train_date = train_data['Date'].max()\ntrain_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\ntrain_data_by_country_confirm.set_index('Country_Region', inplace=True)\n\ntrain_data_by_country_confirm.style.background_gradient(cmap='PuBu_r').format({'ConfirmedCases': \"{:.0f}\", 'GrowthRate': \"{:.2f}\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_col = list(islice(cycle(['purple', 'r', 'g', 'k', 'b', 'c', 'm']), None, len(train_data_by_country_confirm.head(30))))\nplt.rcParams.update({'font.size': 22})\ntrain_data_by_country_confirm.head(20).plot(figsize=(20,15), kind='barh', color=discrete_col)\nplt.legend([\"Confirmed Cases\", \"Fatalities\"]);\nplt.xlabel(\"Number of Covid-19 Affectees\")\nplt.title(\"First 20 Countries with Highest Confirmed Cases\")\nylocs, ylabs = plt.yticks()\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"ConfirmedCases\"][:]):\n    plt.text(v+0.01, ylocs[i]-0.25, str(int(v)), fontsize=12)\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"Fatalities\"][:]):\n    if v > 0: #disply for only >300 fatalities\n        plt.text(v+0.01,ylocs[i]+0.1,str(int(v)),fontsize=12) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plots of confirmed cases and fatalities for nations with fatalities > 500**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.dates as dates\ndef reformat_time(reformat, ax):\n    ax.xaxis.set_major_locator(dates.WeekdayLocator())\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%b %d'))    \n    if reformat: #reformat again if you wish\n        date_list = train_data_by_date.reset_index()[\"Date\"].tolist()\n        x_ticks = [dt.datetime.strftime(t,'%Y-%m-%d') for t in date_list]\n        x_ticks = [tick for i,tick in enumerate(x_ticks) if i%8==0 ]# split labels into same number of ticks as by pandas\n        ax.set_xticklabels(x_ticks, rotation=90)\n    # cosmetics\n    ax.yaxis.grid(linestyle='dotted')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['left'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'sum','Fatalities': 'sum', \n                                                                     'NewConfirmedCases':'sum', 'NewFatalities':'sum', 'MortalityRate':'mean'})\nnum0 = train_data_by_date._get_numeric_data() \nnum0[num0 < 0.0] = 0.0\n#display(train_data_by_date.head())\n\n## ======= Sort by countries with fatalities > 500 ========      \n        \n   \ntrain_data_by_country_max = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\ntrain_data_by_country_fatal = train_data_by_country_max[train_data_by_country_max['Fatalities']>500]\ntrain_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\n#display(train_data_by_country_fatal.head(20))\n\ndf_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\ndf_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n                                                                                                     'Fatalities': 'sum',\n                                                                                                     'NewConfirmedCases':'sum',\n                                                                                                     'NewFatalities':'sum',\n                                                                                                     'MortalityRate':'mean'})\n\nnum1 = df_max_fatality_country._get_numeric_data() \nnum1[num1 < 0.0] = 0.0\ndf_max_fatality_country.set_index('Date',inplace=True)\n#display(df_max_fatality_country.head(20))\n     \n\n\ncountries = train_data_by_country_fatal['Country_Region'].unique()\n\nplt.rcParams.update({'font.size': 16})\n\nfig,(ax0,ax1) = plt.subplots(1,2,figsize=(15, 8))\nfig,(ax2,ax3) = plt.subplots(1,2,figsize=(15, 8))#,sharey=True)\n\ntrain_data_by_date.ConfirmedCases.plot(ax=ax0, x_compat=True, title='Confirmed Cases Globally', legend='Confirmed Cases',\n                                       color=discrete_col)#, logy=True)\nreformat_time(0,ax0)\ntrain_data_by_date.NewConfirmedCases.plot(ax=ax0, x_compat=True, linestyle='dotted', legend='New Confirmed Cases',\n                                          color=discrete_col)#, logy=True)\nreformat_time(0,ax0)\n\ntrain_data_by_date.Fatalities.plot(ax=ax2, x_compat=True, title='Fatalities Globally', legend='Fatalities', color='r')\nreformat_time(0,ax2)\ntrain_data_by_date.NewFatalities.plot(ax=ax2, x_compat=True, linestyle='dotted', legend='Daily Deaths',color='r')#tell pandas not to use its own datetime format\nreformat_time(0,ax2)\n\nfor country in countries:\n    match = df_max_fatality_country.Country_Region==country\n    df_fatality_by_country = df_max_fatality_country[match] \n    df_fatality_by_country.ConfirmedCases.plot(ax=ax1, x_compat=True, title='Confirmed Cases Nationally')\n    reformat_time(0,ax1)\n    df_fatality_by_country.Fatalities.plot(ax=ax3, x_compat=True, title='Fatalities Nationally')\n    reformat_time(0,ax3)\n    \nax1.legend(countries)\nax3.legend(countries)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig,(ax4,ax5) = plt.subplots(1,2,figsize=(20, 8))\n#train_data_by_date.loc[(train_data_by_date.ConfirmedCases > 200)]#useless, its already summed.\ntrain_data_by_date.MortalityRate.plot(ax=ax4, x_compat=True, legend='Mortality Rate',color='purple')#tell pandas not to use its own datetime format\nreformat_time(0,ax4)\n\nfor num, country in enumerate(countries):\n    match = df_max_fatality_country.Country_Region==country \n    df_fatality_by_country = df_max_fatality_country[match] \n    df_fatality_by_country.MortalityRate.plot(ax=ax5, x_compat=True, title='Average Mortality Rate Nationally')    \n    reformat_time(0,ax5)\n\nax5.legend(countries, loc='center left',bbox_to_anchor=(1.0, 0.5))     \n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Here, one should be cautioned as these numbers truly depend on the number of confirmed cases, which itself depends on how many tests were performed during that time. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_max_date = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)')\ntrain_data_by_max_date.loc[:, 'MortalityRate'] = train_data_by_max_date.loc[:,'Fatalities']/train_data_by_max_date.loc[:,'ConfirmedCases']\ntrain_data_by_mortality = train_data_by_max_date.sort_values('MortalityRate', ascending=False)\ntrain_data_by_mortality.set_index('Country_Region', inplace=True)\n#display(train_data_by_mortality.head())\n\npalette = plt.get_cmap('PuRd_r')\nrainbow_col = [palette(1.*i/20.0) for i in range(20)]\n\ntrain_data_by_mortality.MortalityRate.head(20).plot(figsize=(15,10), kind='barh', color=rainbow_col)\nplt.xlabel(\"Mortality Rate\")\nplt.title(\"First 20 Countries with Highest Mortality Rate\")\nylocs, ylabs = plt.yticks() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here, We classify attributes with respect to their category"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique Countries: {len(train_data.Country_Region.unique())}\")\n\ntrain_dates=list(train_data.Date.unique())\nprint(f\"Period : {len(train_data.Date.unique())} days\")\nprint(f\"From : {train_data.Date.min()} To : {train_data.Date.max()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique Regions: {train_data.shape[0]/75}\")\ntrain_data.Country_Region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of rows without Country_Region : {train_data.Country_Region.isna().sum()}\")\n\ntrain_data[\"UniqueRegion\"]=train_data.Country_Region\ntrain_data.UniqueRegion[train_data.Province_State.isna()==False]=train_data.Province_State+\" , \"+train_data.Country_Region\ntrain_data[train_data.Province_State.isna()==False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(950\n               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete the unwanted columns/attributes.\ntrain_data.drop(labels=[\"Id\",\"Province_State\",\"Country_Region\"], axis=1, inplace=True)\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dates=list(test_data.Date.unique())\nprint(f\"Period :{len(test_data.Date.unique())} days\")\nprint(f\"From : {test_data.Date.min()} To : {test_data.Date.max()}\")\nprint(f\"Total Regions : {test_data.shape[0]/43}\")\n\n\ntest_data[\"UniqueRegion\"]=test_data.Country_Region\ntest_data.UniqueRegion[test_data.Province_State.isna()==False]=test_data.Province_State+\" , \"+test_data.Country_Region\ntest_data.drop(labels=[\"Province_State\",\"Country_Region\"], axis=1, inplace=True)\nlen(test_data.UniqueRegion.unique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"only_train_dates=set(train_dates)-set(test_dates)\nprint(\"Only train dates : \",len(only_train_dates))\n#dates in train and test\nintersection_dates=set(test_dates)&set(train_dates)\nprint(\"Intersection dates : \",len(intersection_dates))\n#dates in only test\nonly_test_dates=set(test_dates)-set(train_dates)\nprint(\"Only Test dates : \",len(only_test_dates))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_temp=pd.DataFrame()\ndf_test_temp[\"Date\"]=test_data.Date\ndf_test_temp[\"ConfirmedCases\"]=0.0\ndf_test_temp[\"Fatalities\"]=0.0\ndf_test_temp[\"UniqueRegion\"]=test_data.UniqueRegion\ndf_test_temp[\"Delta\"]=1.0       \n     \ndisplay(df_test_temp) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Implementing Linear Regression**"},{"metadata":{},"cell_type":"markdown","source":"# Here the linear regression model has default arguments"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}