{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Description of this kernel"},{"metadata":{},"cell_type":"markdown","source":"In this kernel I used a very basic xgboost regressor algorithm to predict Covid-19 cases and then I see which states give rise the the largest error. \n\nA big error in predicting 'ConfirmedCases' means that the trend cannot be easily predicted by a simple model, there are several possible explanations : \n\n* not enough test to detect all covid-19 cases\n* Local policies that are difficult to predict\n* environmental factor\n* atypical place (e.g. China, origin of the epidemy)\n\nOn the other hand, a big error in predicting'Fatalities' cannot be explained by the first reason."},{"metadata":{},"cell_type":"markdown","source":"## Data processing"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"X_train=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv' )\nX_test=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sample_submission=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/submission.csv' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we process the data so that the time is given by an integer and we simplify the name of the features."},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X_train['Date'] = pd.to_datetime(X_train['Date'], infer_datetime_format=True)\nX_test['Date'] = pd.to_datetime(X_test['Date'], infer_datetime_format=True)\n\nX_train.loc[:, 'Date'] = X_train.Date.dt.strftime(\"%m%d\")\nX_train[\"Date\"]  = X_train[\"Date\"].astype(int)\n\nX_test.loc[:, 'Date'] = X_test.Date.dt.strftime(\"%m%d\")\nX_test[\"Date\"]  = X_test[\"Date\"].astype(int)\n\nX_train.rename(columns={'Country_Region':'Country'}, inplace=True)\nX_test.rename(columns={'Country_Region':'Country'}, inplace=True)\n\nX_train.rename(columns={'Province_State':'State'}, inplace=True)\nX_test.rename(columns={'Province_State':'State'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rename nan states as the string \"nan\". We will need this later."},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X_train.loc[X_train['State'].isna(), 'State']=\"nan\"\nX_test.loc[X_test['State'].isna(), 'State']=\"nan\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction with xgboost and comparison of error on several countries."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\n\n# Create a regressor that does not give negative results\nclass booster(BaseEstimator):\n    def __init__(self, **params):\n        self.reg=XGBRegressor(**params)\n\n    def fit(self, X, y=None):\n        self.reg.fit(X,y)\n        return self\n\n    def predict(self,X):\n        pred=self.reg.predict(X)\n        pred[pred<0]=0\n        return pred\n    \n    def set_params(self,**params):\n        self.reg.set_params(**params)\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We make a model for each country/state. We use TimeSeriesSplit a cross-validation adapted to time-series to get validation scores. Instead of the mean_squared_log_error used in the leaderboard we use r2 score as it seems less influenced by the total population of a country."},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"countries = X_train['Country'].unique()\n\nfrom sklearn import preprocessing, clone\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import r2_score\ntscv = TimeSeriesSplit(n_splits=10)\ncv_score=[]\ncs=[]\n\nle = preprocessing.LabelEncoder()\n\nxout = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\ncv_score=[]\n\nfor country in countries:\n    states = X_train.loc[X_train['Country'] == country, :]['State'].unique()\n    #print(country, states)\n    # check whether string is nan or not\n    for state in states:\n        X_train_CS = X_train.loc[(X_train['Country'] == country) & (X_train['State'] == state), ['State', 'Country', 'Date', 'ConfirmedCases', 'Fatalities']]\n\n        y1_train_CS = X_train_CS.loc[:, 'ConfirmedCases']\n        y2_train_CS = X_train_CS.loc[:, 'Fatalities']\n\n\n        X_train_CS = X_train_CS.loc[:, ['State', 'Country', 'Date']]\n\n        X_train_CS['Country'] = le.fit_transform(X_train_CS['Country'])\n        X_train_CS['State'] = le.fit_transform(X_train_CS['State'])\n\n        X_test_CS = X_test.loc[(X_test['Country'] == country) & (X_test['State'] == state), ['State', 'Country', 'Date', 'ForecastId']]\n\n        X_test_CS_Id = X_test_CS.loc[:, 'ForecastId']\n        X_test_CS = X_test_CS.loc[:, ['State', 'Country', 'Date']]\n\n        X_test_CS['Country'] = le.fit_transform(X_test_CS['Country'])\n        X_test_CS['State'] = le.fit_transform(X_test_CS['State'])\n\n        regressor = booster(mad_depth=3,n_estimators=10)\n\n        # cross-validation for confirmed cases\n        cv=[]\n        for train_index, test_index in tscv.split(X_train_CS):\n            xtrain, ytrain = X_train_CS.iloc[train_index], y1_train_CS.iloc[train_index]\n            xtest, ytest = X_train_CS.iloc[test_index], y1_train_CS.iloc[test_index]\n            reg=clone(regressor)\n            reg.fit(xtrain,ytrain)\n            cv+=[np.mean(r2_score(ytest,reg.predict(xtest)))]\n            \n        # cross validation for fatalities\n        cv2=[]\n        for train_index, test_index in tscv.split(X_train_CS):\n            xtrain, ytrain = X_train_CS.iloc[train_index], y2_train_CS.iloc[train_index]\n            xtest, ytest = X_train_CS.iloc[test_index], y2_train_CS.iloc[test_index]\n            reg=clone(regressor)\n            reg.fit(xtrain,ytrain)\n            cv2+=[np.mean(r2_score(ytest,reg.predict(xtest)))]\n            \n        cv_score += [[np.mean(cv), np.mean(cv2)]]\n\n        cs += [(country, state)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"cv_score=np.array(cv_score)\nnp.mean(cv_score, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.distplot(cv_score[:,0], label='Error for Confirmed Cases')\nsns.distplot(cv_score[:,1], label='Error for Fatalities')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* See which are the 15 most \"Confirmed cases\" difficult to predict with our model (it can change according to which loss you choose)"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"country_state= [country+'/'+state for country,state in cs]\nN=15\nind_sort_cc=np.argsort(cv_score[:,0])\n\nprint(pd.DataFrame({'Coutry/State':np.array(country_state)[ind_sort_cc[:N]],'error':np.array(cv_score)[ind_sort_cc[:N],0] }))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We do the same with the number of fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_sort_f=np.argsort(cv_score[:,1])\n\nprint(pd.DataFrame({'Coutry/State':np.array(country_state)[ind_sort_f[:N]],'error':np.array(cv_score)[ind_sort_f[:N],1] }))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without surprise, China present a lot of difficult to predict regions because of its place as origin of the epidemy."},{"metadata":{},"cell_type":"markdown","source":"## A small vizualization"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import plotly.graph_objects as go #Plotlygo for plotting\n\n#Plotting a bar graph for error by couple (country,state).\nN=50 # number of country/state to plot\nindices=ind_sort_cc[:N]\nscores = {'Country/State' : np.array(country_state)[indices], 'error': np.array(cv_score[:,0])[indices]}\nscores_df = pd.DataFrame(scores)\n\n#Plotting the Graph.\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=scores_df['Country/State'], y=scores_df['error'], name='States most difficult to predict for ConfirmedCases'))\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nindices=ind_sort_f[:N]\nscores = {'Country/State' : np.array(country_state)[indices], 'error': np.array(cv_score[:,1])[indices]}\nscores_df = pd.DataFrame(scores)\n\n#Plotting the Graph.\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=scores_df['Country/State'], y=scores_df['error'], name='States most difficult to predict for Fatalities'))\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}