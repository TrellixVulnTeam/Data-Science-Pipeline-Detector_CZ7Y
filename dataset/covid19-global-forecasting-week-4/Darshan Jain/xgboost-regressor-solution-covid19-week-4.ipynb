{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\ntest_df = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Data Study\nfrom pandas_profiling import ProfileReport\ntrain_profile = ProfileReport(train_df, title='Pandas Profiling Report', html={'style':{'full_width':True}})\ntrain_profile\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing all the Province_State that are null by the Country_Region values\ntrain_df.Province_State.fillna(train_df.Country_Region, inplace=True)\ntest_df.Province_State.fillna(test_df.Country_Region, inplace=True)\n\n# Handling the Date column\n# 1. Converting the object type column into datetime type\ntrain_df.Date = train_df.Date.apply(pd.to_datetime)\ntest_df.Date = test_df.Date.apply(pd.to_datetime)\n\n#Extracting Date and Month from the datetime and converting the feature as int\ntrain_df.Date = train_df.Date.dt.strftime(\"%m%d\").astype(int)\ntest_df.Date = test_df.Date.dt.strftime(\"%m%d\").astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Label Encoding for object to numeric conversion - Option 1\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ntrain_df.Country_Region = le.fit_transform(train_df.Country_Region)\ntrain_df['Province_State'] = le.fit_transform(train_df['Province_State'])\n\ntest_df.Country_Region = le.fit_transform(test_df.Country_Region)\ntest_df['Province_State'] = le.fit_transform(test_df['Province_State'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#One Hot Encoding for object to numeric conversion - Option 2\n\ndef one_hot(df, cols):\n    \"\"\"\n    @param df pandas DataFrame\n    @param cols a list of columns to encode \n    @return a DataFrame with one-hot encoding\n    \"\"\"\n    i = 0\n    for each in cols:\n        #print (each)\n        dummies = pd.get_dummies(df[each], prefix=each, drop_first= True)\n        if i == 0: \n            print (dummies)\n            i = i + 1\n        df = pd.concat([df, dummies], axis=1)\n    return df\n    '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Handling categorical data\n\nobjList = train_df.select_dtypes(include = \"object\").columns\ntrain_df = one_hot(train_df, objList) \ntest_df = one_hot(test_df, objList) \n\nprint (train_df.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# Removing duplicate entries\ntrain_df = train_df.loc[:,~train_df.columns.duplicated()]\ntest_df = test_df.loc[:,~test_df.columns.duplicated()]\nprint (test_df.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# Dropping the object type columns\ntrain_df.drop(objList, axis=1, inplace=True)\ntest_df.drop(objList, axis=1, inplace=True)\nprint (train_df.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Final check on the data\ntrain_df.select_dtypes(include = \"object\").columns\n#So, no columns with object data is there. Our data is ready for training\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.drop([\"Id\", \"ConfirmedCases\", \"Fatalities\"], axis = 1) \n \nY_train_CC = train_df[\"ConfirmedCases\"] \nY_train_Fat = train_df[\"Fatalities\"] \n\nX_test = test_df.drop([\"ForecastId\"], axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit, cross_val_score\nskfold = ShuffleSplit(random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#2. XGBRegressor\nimport xgboost as xgb\n\nclf_xgb_CC = xgb.XGBRegressor(n_estimators = 40000)\nclf_xgb_Fat = xgb.XGBRegressor(n_estimators = 20000)\n\nxgb_acc = cross_val_score(clf_xgb_CC, X_train, Y_train_CC, cv = skfold)\nxgb_acc_fat = cross_val_score(clf_xgb_Fat, X_train, Y_train_Fat, cv = skfold)\n\nprint (xgb_acc.mean(), xgb_acc_fat.mean())\n#0.9855346531774586 0.9742142138236705 with LE\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_xgb_CC.fit(X_train, Y_train_CC)\nY_pred_CC = clf_xgb_CC.predict(X_test) \n\nclf_xgb_Fat.fit(X_train, Y_train_Fat)\nY_pred_Fat = clf_xgb_Fat.predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (Y_pred_Fat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\nsoln = pd.DataFrame({'ForecastId': test_df.ForecastId, 'ConfirmedCases': Y_pred_CC, 'Fatalities': Y_pred_Fat})\ndf_out = pd.concat([df_out, soln], axis=0)\ndf_out.ForecastId = df_out.ForecastId.astype('int')\ndf_out.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}