{"cells":[{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"color:black;font-size:4em\"><center >Covid-19 forecasting (Week 4)</center></h1>\n\n---\nCreated on Thu Apr 09 14:54:03 2020\n\n@author: IKNE Hicham\n---"},{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 1- Libraries</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('default')\nimport numpy as np\nfrom numpy import random\nimport warnings\nwarnings.filterwarnings('ignore')\nimport datetime\nfrom dateutil.relativedelta import relativedelta\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n##\nimport sys\nfrom IPython.display import display\nfrom scipy.stats import skew\nimport lightgbm as lgb\nimport os\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nfrom itertools import product\n# DNN\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 2- Exploratory data analysis</h1>\n\n---"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\n            \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 2.1-  Clean & prepare features</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"catcols=train.select_dtypes(include='object').columns.values.tolist()\ncatcols.remove('Date')\nnumcols=train.select_dtypes(include='number').columns.values[1:-1].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[catcols].describe().merge(test[catcols].describe(),left_index=True,right_index=True,suffixes=('_train','_test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'TRAIN -> date_min= {train[\"Date\"].min()} ; date_max= {train[\"Date\"].max()}')\nprint(f'TEST -> date_min= {test[\"Date\"].min()} ; date_max= {test[\"Date\"].max()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(train.Date.unique()) & set(test.Date.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_loc_features(data):\n    # lower Province_State & Country_Region in order to use them to add more information\n    data['Province_State']=data['Province_State'].str.lower()\n    data['Country_Region']=data['Country_Region'].str.lower()\n    \n\n    # Fill missing Province_State & Country_Region missing values \n    data.fillna({'Province_State':'','Country_Region':''},inplace=True)\n    \n    # Remove non-alpha charachters \n    data['Province_State']=data['Province_State'].apply(lambda x: ''.join([ch for ch in x if ch.isalpha()]))\n    data['Country_Region']=data['Country_Region'].apply(lambda x: ''.join([ch for ch in x if ch.isalpha()]))\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing Province_State & Country_Region missing values \ntrain=clean_loc_features(train)\ntest=clean_loc_features(test)\n#\ntest.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Date into datetime format \ntrain['Date'] = pd.to_datetime(train['Date'], format = '%Y-%m-%d')\ntest['Date'] = pd.to_datetime(test['Date'], format = '%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Date characteristics\ndef create_date_features(df):\n    df['day'] = df['Date'].dt.day\n    df['month'] = df['Date'].dt.month\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['dayofyear'] = df['Date'].dt.dayofyear\n    df['quarter'] = df['Date'].dt.quarter\n    df['weekofyear'] = df['Date'].dt.weekofyear\n    return df\n# \ntrain=create_date_features(train)\ntest=create_date_features(test)\n# \ntest.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reverse Date transformation\ntrain['Date']=train['Date'].apply(lambda x:x.strftime('%Y-%m-%d'))\ntest['Date']=test['Date'].apply(lambda x:x.strftime('%Y-%m-%d'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 2.2- Additional information</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_keep=['Country Name','Population ages 0-14, total', 'Population ages 15-64, female','Population ages 15-64, male',\n'Population ages 15-64, total','Population ages 65 and above, total',\n'Population ages 80 and above, female (% of female population)',\n'Population ages 80 and above, male (% of male population)','Population, male',\n'Population, total','Rural population (% of total population)']\n\nadd_inf=pd.read_csv('/kaggle/input/world-population-and-development-indicators/data.csv')[cols_to_keep]\nadd_inf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf['Country Name'].replace({'bahamasthe':'bahamas','bruneidarussalam':'bahamas','czechrepublic':'czechia',\n                   'congodemrep':'congokinshasa','congorep':'congobrazzaville','egyptarabrep':'egypt',\n                  'gambiathe':'gambia','iranislamicrep':'iran','korearep':'koreasouth','unitedstates':'us',\n                   'kyrgyzrepublic':'kyrgyzstan','russianfederation':'russia','stkittsandnevis':'saintkittsandnevis',\n                  'stlucia':'saintlucia','stvincentandthegrenadines':'saintvincentandthegrenadines',\n                  'slovakrepublic':'slovakia','syrianarabrepublic':'syria','venezuelarb':'venezuela'},inplace=True)\nprint('us' in add_inf['Country Name'].unique())\n\nadd_inf.drop_duplicates(subset=['Country Name'],inplace=True)\nprint(add_inf['Country Name'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_popultaion_features(data):\n    # replace 0 with a more probable value\n    data['Population ages 0-14, total'].replace(0,data['Population ages 0-14, total'].mode(),inplace=True)\n    data['Population ages 15-64, total'].replace(0,data['Population ages 15-64, total'].mode(),inplace=True)\n    data['Population ages 65 and above, total'].replace(0,data['Population ages 65 and above, total'].mode(),inplace=True)\n    data['Population, total'].replace(0,data['Population, total'].mode(),inplace=True)\n    \n    # Normalize\n    data['Population ages 15-64, male']=data['Population ages 15-64, male']/data['Population ages 15-64, total']\n    data['Population ages 15-64, female']=data['Population ages 15-64, female']/data['Population ages 15-64, total']\n    #\n    data['Population ages 0-14, total']=data['Population ages 0-14, total']/data['Population, total']\n    data['Population ages 15-64, total']=data['Population ages 15-64, total']/data['Population, total']    \n    data['Population ages 65 and above, total']=data['Population ages 65 and above, total']/data['Population, total'] \n    #\n    data['Population, male']=data['Population, male']/data['Population, total'] \n    \n    # rescale % features (bring them back to [0,1] interval)\n    pcq_features=[col for col in data.columns if '%' in col]\n    print(pcq_features)\n    data[pcq_features]=.01*data[pcq_features]\n    data.drop(columns=['Population, total'],inplace=True)\n    # fillna\n    data.fillna(data.median().to_dict(),inplace=True)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf=scale_popultaion_features(add_inf)\nadd_inf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('From train:{}  ;  From add_inf:{}  ; intersection:{}'.format(train['Country_Region'].nunique(),add_inf['Country Name'].nunique(),\n                                                                    len(set(train['Country_Region']) & set(add_inf['Country Name']))))\n\nprint('From test:{}  ;  From add_inf:{}  ; intersection:{}'.format(test['Country_Region'].nunique(),add_inf['Country Name'].nunique(),\n                                                                    len(set(test['Country_Region']) & set(add_inf['Country Name']))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (1) add world population & developement indicators \nprint('train shape: {}  ;  test shape: {}'.format(train.shape,test.shape))\n#\ntrain=train.merge(add_inf,left_on='Country_Region',right_on='Country Name',how='left')\ntest=test.merge(add_inf,left_on='Country_Region',right_on='Country Name',how='left')\n#\ntrain.fillna(train.median().to_dict(),inplace=True)\ntest.fillna(train.median().to_dict(),inplace=True)\n\nprint('train shape: {}  ;  test shape: {}'.format(train.shape,test.shape))\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatenate Province_State & Country_Region as \"Province_State\" ID\ntrain['Province_State']=train['Country_Region']+' '+train['Province_State']\ntest['Province_State']=test['Country_Region']+' '+test['Province_State']\n\n# reset index with Date\ntrain.index=train['Date']\ntest.index=test['Date']\n\n# Drop useless columns\ntrain.drop(columns=['Date','Country_Region','Country Name'],inplace=True)\ntest.drop(columns=['Date','Country_Region','Country Name'],inplace=True)\n#\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display ConfirmedCases & Fatatilities charts of a random Province state\n\n# Pick one random Province_State\nprovince=np.random.choice(train['Province_State'].unique())\ns=train.loc[train['Province_State']==province,['ConfirmedCases','Fatalities']]\n\nplt.style.use('default')\nplt.figure(figsize=(10,3))\nplt.subplot(121)\ns['ConfirmedCases'].plot(kind='area',color='lightskyblue',alpha=.4,label='ConfirmedCases')\ns['Fatalities'].plot('area',color='orangered',alpha=.4,label='Fatalities')\nplt.legend()\nplt.xticks(rotation=80)\nplt.title('ConfirmedCases & Fatalities',fontsize=10)\n#\nplt.subplot(122)\ns['Fatalities'].plot('area',color='lightcoral',alpha=.7)\nplt.xticks(rotation=80)\nplt.title('Fatalities',fontsize=10)\n\nplt.suptitle(province.upper(),fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features(df):\n    #-----------------------#\n    # 1. Global indicators  #\n    #-----------------------#\n    # add mortality rate\n    df['MortalityRate'] = np.where(df['ConfirmedCases']>0,df['Fatalities']/df['ConfirmedCases'],0)\n    df['MortalityRate'] = df['MortalityRate'].fillna(0.0)\n    #\n    # add daily measures\n    df['Daily Cases']=df.groupby('Province_State')['ConfirmedCases'].shift(1)\n    df['Daily Deaths']=df.groupby('Province_State')['Fatalities'].shift(1)\n    # fill na with 0\n    df.fillna({'Daily Cases':0,'Daily Deaths':0},inplace=True)\n\n    #\n    df['New cases rate']=np.where(df['ConfirmedCases']>0,df['Daily Cases']/df['ConfirmedCases'],np.sign(df['Daily Cases']))\n    df['New deaths rate']=np.where(df['Fatalities']>0,df['Daily Deaths']/df['Fatalities'],np.sign(df['Daily Deaths']))\n\n    # fill na with 0\n    df.fillna({'New cases rate':0,'New deaths rate':0},inplace=True)\n    #\n    #-----------------------#\n    # 2. Ind by Popultaion  #\n    #-----------------------#\n    pop_cols=[col for col in df.columns if 'opulation' in col]\n    covid_cols=['ConfirmedCases','Fatalities','MortalityRate','Daily Cases','Daily Deaths','New cases rate','New deaths rate']\n    for col,cov_col in product(pop_cols,covid_cols):\n        df[f'{cov_col}_{col}']=df[col]*df[cov_col]\n    #-----------------------#\n    # 3. Ind by weekofyear  #\n    #-----------------------# \n \n    df=df.merge(df.groupby(['Province_State','weekofyear'],as_index=True).agg(\n        week_ConfirmedCases=('ConfirmedCases',sum),\n        week_Fatalities=('Fatalities',sum),\n        week_Daily_Cases=('Daily Cases','mean'),\n        week_Daily_Deaths=('Daily Deaths','mean'),\n        week_New_cases_rate=('New cases rate','mean'),\n        week_New_deaths_rate=('New deaths rate','mean')),left_on=['Province_State','weekofyear'],right_index=True)\n    \n    return df\n#\nprint(train.shape)\ntrain=create_features(train)\nprint(train.shape)\n\nprint(train['New cases rate'].describe())\nprint(train['New deaths rate'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log transform highly skewed features\ns=train.select_dtypes('number').max()\nfeatures_to_transform=s[s>10**4].index.values[1:]\nprint(features_to_transform)\n\ntrain[features_to_transform]=np.log(train[features_to_transform]+1)\n#\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show target (ConfirmedCases, Fatalities)\nplt.figure(figsize=(10,3))\nplt.subplot(121)\ntrain['ConfirmedCases'].plot.hist(bins=50,density=True,color='lightskyblue',edgecolor='k')\n\nplt.title('ConfirmedCases')\n#\nplt.subplot(122)\ntrain['Fatalities'].plot.hist(bins=50,density=True,color='lightcoral',edgecolor='k')\nplt.title('Fatalities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\ns=round(100*(train.isnull().sum()/train.shape[0]).to_frame('Nan (%)'),2)\ns[s['Nan (%)']>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=train.select_dtypes(include='number').columns.values[1:]\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross-correlation between \"Added informtaion\" and target\ncorr={'ConfirmedCases':[],'Fatalities':[]}\nfor col in features:\n    corr['ConfirmedCases'].append(train[[col,'ConfirmedCases']].corr().values[0,1])\n    corr['Fatalities'].append(train[[col,'Fatalities']].corr().values[0,1]) \ncorr=pd.DataFrame(corr,index=features)\ncorr['min']=np.abs(corr).min(axis=1)\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop feature with very low correlation with target\nfeatures=corr[corr['min']>.05].index.values\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_seq(df,features):\n    # define identifier\n    idf=(df['Province_State'].unique()[0],df.index.values)\n    # define target \n    tar=df[['ConfirmedCases', 'Fatalities']].values[-1]\n    # define sequence \n    seq=df[features].values[:-1,:]\n    return idf,seq,tar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def procces_sequnces(train,n=11):\n    days_list=train.index.unique()\n    identifiers,sequences,targets=[],[],[]\n    #\n    for i in tqdm(range(days_list.shape[0]-n)):\n        dfx=train[(train.index>=days_list[i]) & (train.index<days_list[i+n])].copy()\n        #\n        #df_sub[features]=preprocessing.MinMaxScaler().fit_transform(df_sub[features])\n        out=dfx.groupby(['Province_State']).apply(process_seq,features=features).values\n        # add out to \n        for idf,seq,tar in out:\n            identifiers.append(idf)\n            sequences.append(seq)\n            targets.append(tar)\n            \n    return np.array(identifiers),np.array(sequences),np.array(targets).reshape(-1,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identifiers,sequences,targets=procces_sequnces(train)\nprint(' identifiers: {} \\n sequences: {} \\n targets: {}'.format(identifiers.shape,sequences.shape,targets.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize sequences\ndef visualize_seq():\n    idx=np.random.randint(low=0,high=identifiers.shape[0])\n    # pick a random subset of features\n    feat_idx=np.random.choice(range(len(features)),size=20,replace=True)\n    #\n    plt.figure(figsize=(16,5))\n    plt.pcolor(sequences[idx][:,feat_idx],edgecolors='k', linewidths=1)\n    plt.xticks(ticks=.5+np.arange(20),labels=features[feat_idx],rotation=85)        \n    plt.yticks(ticks=.5+np.arange(sequences.shape[1]),labels=identifiers[idx][1])\n    #\n    plt.colorbar()\n    plt.title(identifiers[idx][0],fontsize=20,style='italic')\n    plt.show()\n    \nvisualize_seq()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 3- Model</h1>\n\n---"},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 3.1- Split dataset</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\nX_train,X_test,y_train,y_test=train_test_split(sequences,targets,test_size=.15,random_state=42)\n\nprint('X_train.shape: ',X_train.shape)\nprint('X_test.shape: ',X_test.shape)\nprint('y_train_Conf.shape: ',y_train.shape)\nprint('y_test_Conf.shape: ',y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 3.2- Train model</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(LSTM(128,input_shape=X_train.shape[1:],dropout=.1,return_sequences=True))\nmodel.add(Dropout(.2))\nmodel.add(BatchNormalization())\n\n###\nmodel.add(LSTM(128,input_shape=X_train.shape[1:],dropout=.2,return_sequences=True,activation='tanh'))\nmodel.add(BatchNormalization())\n\n###\nmodel.add(LSTM(128,input_shape=X_train.shape[1:],dropout=.15,return_sequences=True,activation='tanh'))\nmodel.add(BatchNormalization())\n###\n\n\n\n\nmodel.add(LSTM(128,input_shape=X_train.shape[1:]))\nmodel.add(Dropout(.2))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Dense(128,activation=\"relu\"),)\nmodel.add(Dropout(.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(64,activation=\"relu\"),)\nmodel.add(Dropout(.2))\n### \nmodel.add(Dense(2))\nopt=tf.keras.optimizers.Adam(lr=.002,decay=1e-6)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=128\nEPOCHS=70\nNAME=f'{datetime.datetime.now()}.h5'\nNAME","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def root_mean_squared_error(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=root_mean_squared_error,\n             optimizer=opt,\n             metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(X_train,y_train,\n                 batch_size=BATCH_SIZE,\n                 epochs=EPOCHS,\n                 validation_data=[X_test,y_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict=history.history\nhistory_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.subplot(121)\nplt.plot(np.arange(1,EPOCHS+1),history_dict['loss'],color='b',label='train')\nplt.plot(np.arange(1,EPOCHS+1),history_dict['val_loss'],color='r',label='validation')\nplt.title('loss')\nplt.legend()\n\n###\nplt.subplot(122)\nplt.plot(np.arange(1,EPOCHS+1),history_dict['mae'],color='b',label='train')\nplt.plot(np.arange(1,EPOCHS+1),history_dict['val_mae'],color='r',label='validation')\nplt.title('accuracy')\n\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 3.3- Prepare test set & make predictions</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(list(set(test.index) & set(train.index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.reset_index(inplace=True)\ntest.reset_index(inplace=True)\n#\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\ntest=test.merge(train[['Date','Province_State','ConfirmedCases','Fatalities']],on=['Date','Province_State'],how='left')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(train.Date.unique()) & set(test.Date.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test.shape[0]-test[['ConfirmedCases','Fatalities']].isnull().sum())/test.Province_State.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=10\ndate='2020-04-18'\n\ndef delta(date,n):\n    return (datetime.datetime.strptime(date,'%Y-%m-%d')-relativedelta(days= n)).strftime('%Y-%m-%d')\ndelta(date,n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_list=np.sort(test.loc[test.ConfirmedCases.isnull(),'Date'].unique())\ndate_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions(test,n=10):\n    out=test.copy()\n    # remaining days (with empty targets)\n    date_list=np.sort(test.loc[test.ConfirmedCases.isnull(),'Date'].unique())\n    \n    for date in date_list:\n        # pick previuous data -> prediction\n        print(out[['ConfirmedCases','Fatalities']].isnull().sum())\n        \n        test_data=out[(out['Date']<date) & (out['Date']>=delta(date,n))].copy()\n        \n        print('date min: {} ; date max: {}'.format(test_data.Date.min(),test_data.Date.max()))\n        print(test_data['Province_State'].value_counts().unique(),test_data.shape)\n        print(test_data[['ConfirmedCases','Fatalities']].isnull().sum())\n        \n        # create features\n        test_data=create_features(test_data)\n        # log-transform highly skewed features\n        test_data[features_to_transform]=np.log(test_data[features_to_transform]+1)\n        # make prediction\n        predictions=test_data.groupby(['Province_State']).apply(lambda x:model.predict(x[features].values.reshape(-1,n,len(features)))[0])\n        \n        # impute predictions\n        print(out[['ConfirmedCases','Fatalities']].isnull().sum())\n        out.loc[out['Date']==date,['ConfirmedCases','Fatalities']]=predictions.apply(lambda x:pd.Series([x[0],x[1]])).values\n        print(out[['ConfirmedCases','Fatalities']].isnull().sum())\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=make_predictions(test)\nout.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out[['ForecastId','ConfirmedCases','Fatalities']].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply exp to target (reverse transformation)\nout['ConfirmedCases']=np.exp(out['ConfirmedCases'])-1\nout['Fatalities']=np.exp(out['Fatalities'])-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out[['ForecastId','ConfirmedCases','Fatalities']].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out[['ForecastId','ConfirmedCases','Fatalities']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out['Fatalities']=np.where(out['Fatalities']>=0,out['Fatalities'],0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sumbit predictions\nout[['ForecastId','ConfirmedCases','Fatalities']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def demo():\n    idx=np.random.randint(low=0,high=train['Province_State'].nunique()-1)\n    #\n    idfs=[]\n    pred=[]\n    true=[]\n    #\n    for i in range(16):\n        pred.append(np.exp(model.predict(sequences[idx+(i*train['Province_State'].nunique())].reshape(-1,10,len(features)))[0])-1)\n        true.append(np.exp(targets[idx+(i*train['Province_State'].nunique())])-1)\n        #\n        idf=identifiers[idx+(i*train['Province_State'].nunique())]\n        idfs.append([idf[0],(datetime.datetime.strptime(idf[1][-1],'%Y-%m-%d')+relativedelta(days= 1)).strftime('%Y-%m-%d')])\n    #\n    idfs,pred,true=np.array(idfs),np.array(pred),np.array(true)\n    #\n    df_demo=pd.DataFrame({'Province_State':idfs[:,0],\n                          'ConfirmedCases_true':true[:,0],\n                          'ConfirmedCases_pred':pred[:,0],\n                          'Fatalities_true':true[:,1],\n                          'Fatalities_pred':pred[:,1]},index=idfs[:,1])\n    #\n    plt.style.use('default')\n    plt.figure(figsize=(10,3))\n    plt.subplot(121)\n    df_demo['ConfirmedCases_true'].plot(kind='area',color='lightskyblue',alpha=.4,label='True')\n    df_demo['ConfirmedCases_pred'].plot(kind='area',color='orangered',alpha=.4,label='Prediction')\n    plt.legend()\n    plt.xticks(rotation=80)\n    plt.title('ConfirmedCases',fontsize=10)\n    #\n    plt.subplot(122)\n    df_demo['Fatalities_true'].plot(kind='area',color='lightskyblue',alpha=.4,label='True')\n    df_demo['Fatalities_pred'].plot(kind='area',color='orangered',alpha=.4,label='Prediction')\n    plt.xticks(rotation=80)\n    plt.title('Fatalities',fontsize=10)\n    plt.legend()\n    #\n    plt.suptitle(idfs[0,0],fontsize=14)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"demo()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}