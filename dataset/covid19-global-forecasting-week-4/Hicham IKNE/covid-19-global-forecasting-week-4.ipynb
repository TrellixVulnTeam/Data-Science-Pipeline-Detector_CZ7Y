{"cells":[{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"color:black;font-size:4em\"><center >Covid-19 forecasting (Week 4)</center></h1>\n\n---\nCreated on Wed Apr 15 14:44:03 2020\n\n@author: IKNE Hicham\n---"},{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 1- Libraries</h1>\n\n---"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('default')\nimport numpy as np\nfrom numpy import random\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import metrics,preprocessing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn import svm\nfrom sklearn import model_selection\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom xgboost import XGBRegressor\nimport warnings\n# more Classifiers\n## \nimport sys\nfrom itertools import product\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom IPython.display import display\nfrom scipy.stats import skew\nimport lightgbm as lgb\nimport os\nfrom tqdm import tqdm\n#from pandas_profiling import ProfileReport\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 2- EDA </h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\n            \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 2.1-  Clean & prepare features</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"catcols=train.select_dtypes(include='object').columns.values.tolist()\ncatcols.remove('Date')\nnumcols=train.select_dtypes(include='number').columns.values[1:-1].tolist()\n\n#\ntrain[catcols].describe().merge(test[catcols].describe(),left_index=True,right_index=True,suffixes=('_train','_test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\npd.concat([round(100*train[catcols].isnull().sum()/train.shape[0],2).to_frame('train'),\n           round(100*test[catcols].isnull().sum()/test.shape[0],2).to_frame('test')],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'TRAIN -> date_min= {train[\"Date\"].min()} ; date_max= {train[\"Date\"].max()}')\nprint(f'TEST -> date_min= {test[\"Date\"].min()} ; date_max= {test[\"Date\"].max()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(train.Date.unique()) & set(test.Date.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_features(data):\n    # lower Province_State & Country_Region in order to use them to add more information\n    data['Province_State']=data['Province_State'].str.lower()\n    data['Country_Region']=data['Country_Region'].str.lower()\n    \n    # Create a new feature = weither the Province_State is known or not\n    data['UnkownProvince_State']=data['Province_State'].isnull().astype(int)\n    \n    # Fill missing Province_State & Country_Region missing values \n    data.fillna({'Province_State':''},inplace=True)\n\n    \n    # Remove non-alpha charachters \n    data['Province_State']=data['Province_State'].apply(lambda x: ''.join([ch for ch in x if ch.isalpha()]))\n    data['Country_Region']=data['Country_Region'].apply(lambda x: ''.join([ch for ch in x if ch.isalpha()]))\n    \n    # Create a new feature = Country_Region frequency\n    data['Country_RegionFreq']=data['Country_Region'].map(data['Country_Region'].value_counts(1).to_dict())\n    \n    return data\n\ncatcols.append('UnkownProvince_State')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean & transform features\ntrain=prepare_features(train)\ntest=prepare_features(test)\n#\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Country_Region'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 2.2- Additional information</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_keep=['Country Name','Population ages 0-14, total', 'Population ages 15-64, female','Population ages 15-64, male',\n'Population ages 15-64, total','Population ages 65 and above, total',\n'Population ages 80 and above, female (% of female population)',\n'Population ages 80 and above, male (% of male population)','Population, male',\n'Population, total','Rural population (% of total population)']\n\nadd_inf=pd.read_csv('/kaggle/input/world-population-and-development-indicators/data.csv')[cols_to_keep]\nadd_inf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf['Country Name'].replace({'bahamasthe':'bahamas','bruneidarussalam':'bahamas','czechrepublic':'czechia',\n                   'congodemrep':'congokinshasa','congorep':'congobrazzaville','egyptarabrep':'egypt',\n                  'gambiathe':'gambia','iranislamicrep':'iran','korearep':'koreasouth','unitedstates':'us',\n                   'kyrgyzrepublic':'kyrgyzstan','russianfederation':'russia','stkittsandnevis':'saintkittsandnevis',\n                  'stlucia':'saintlucia','stvincentandthegrenadines':'saintvincentandthegrenadines',\n                  'slovakrepublic':'slovakia','syrianarabrepublic':'syria','venezuelarb':'venezuela'},inplace=True)\nprint('us' in add_inf['Country Name'].unique())\n\nadd_inf.drop_duplicates(subset=['Country Name'],inplace=True)\nprint(add_inf['Country Name'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('From train:{}  ;  From add_inf:{}  ; intersection:{}'.format(train['Country_Region'].nunique(),add_inf['Country Name'].nunique(),\n                                                                    len(set(train['Country_Region']) & set(add_inf['Country Name']))))\n\nprint('From test:{}  ;  From add_inf:{}  ; intersection:{}'.format(test['Country_Region'].nunique(),add_inf['Country Name'].nunique(),\n                                                                    len(set(test['Country_Region']) & set(add_inf['Country Name']))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_popultaion_features(data):\n    # replace 0 with a more probable value\n    data['Population ages 0-14, total'].replace(0,data['Population ages 0-14, total'].mode(),inplace=True)\n    data['Population ages 15-64, total'].replace(0,data['Population ages 15-64, total'].mode(),inplace=True)\n    data['Population ages 65 and above, total'].replace(0,data['Population ages 65 and above, total'].mode(),inplace=True)\n    data['Population, total'].replace(0,data['Population, total'].mode(),inplace=True)\n    \n    # Normalize\n    data['Population ages 15-64, male']=data['Population ages 15-64, male']/data['Population ages 15-64, total']\n    data['Population ages 15-64, female']=data['Population ages 15-64, female']/data['Population ages 15-64, total']\n    #\n    data['Population ages 0-14, total']=data['Population ages 0-14, total']/data['Population, total']\n    data['Population ages 15-64, total']=data['Population ages 15-64, total']/data['Population, total']    \n    data['Population ages 65 and above, total']=data['Population ages 65 and above, total']/data['Population, total'] \n    #\n    data['Population, male']=data['Population, male']/data['Population, total'] \n    \n    # rescale % features (bring them back to [0,1] interval)\n    pcq_features=[col for col in data.columns if '%' in col]\n    print(pcq_features)\n    data[pcq_features]=.01*data[pcq_features]\n    data.drop(columns=['Population, total'],inplace=True)\n    # fillna\n    data.fillna(data.median().to_dict(),inplace=True)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf=scale_popultaion_features(add_inf)\nadd_inf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(train['Country_Region'])-set(add_inf['Country Name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (1) add world population & developement indicators \nprint('train shape: {}  ;  test shape: {}'.format(train.shape,test.shape))\n#\ntrain=train.merge(add_inf,left_on='Country_Region',right_on='Country Name',how='left')\ntest=test.merge(add_inf,left_on='Country_Region',right_on='Country Name',how='left')\n#\nprint('train shape: {}  ;  test shape: {}'.format(train.shape,test.shape))\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-size:2em\">WHO data</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_keep=['country', 'total_covid_19_tests',\n       'total_covid_19_tests_per_million_people',\n       'inform_risk', 'inform_p2p_hazard_and_exposure_dimension',\n       'people_using_at_least_basic_sanitation_services',\n       'inform_vulnerability', 'inform_health_conditions',\n       'inform_epidemic_vulnerability', 'mortality_rate_under_5',\n       'prevalence_of_undernourishment', 'inform_lack_of_coping_capacity',\n       'inform_access_to_healthcare',\n       'inform_epidemic_lack_of_coping_capacity', 'physicians_density',\n       'current_health_expenditure_per_capita',\n       'maternal_mortality_ratio', 'entry_date', 'category',\n       'measure', 'global-school-closures']\n\nwho_data=pd.read_csv('/kaggle/input/whodata/WHO data.csv')[cols_to_keep]\nwho_data.drop_duplicates(subset=['country'],inplace=True)\nprint(who_data.shape)\nwho_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"who_data['country'].replace({'capeverde':'caboverde','czechrepublic':'czechia','myanmar':'burma',\n                            'congodemrep':'congokinshasa','congorep':'congobrazzaville','guinea':'guineabissau',\n                            'swaziland':'eswatini','southkorea':'koreasouth','macedonia':'northmacedonia',\n                            'timor':'timorleste','unitedstates':'us','unitedstatesvirginislands':'us',\n                            'vatican':'holysee','palestine':'westbankandgaza'},inplace=True)\n\nprint(who_data['country'].nunique())\nwho_data.drop_duplicates(subset=['country'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('From train:{}  ;  From who-data:{}  ; intersection:{}'.format(train['Country_Region'].nunique(),who_data['country'].nunique(),\n                                                                    len(set(train['Country_Region']) & set(who_data['country']))))\n\nprint('From test:{}  ;  From who-data:{}  ; intersection:{}'.format(test['Country_Region'].nunique(),who_data['country'].nunique(),\n                                                                    len(set(test['Country_Region']) & set(who_data['country']))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\nwho_data.select_dtypes(include='number').isnull().sum()/who_data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (2) add WHO health system information \nprint('train shape: {}  ;  test shape: {}'.format(train.shape,test.shape))\n\ntrain=train.merge(who_data,left_on='Country_Region',right_on='country',how='left')\ntest=test.merge(who_data,left_on='Country_Region',right_on='country',how='left')\n\n# fillna\ntrain.fillna(train.quantile(.15).to_dict(),inplace=True)\ntest.fillna(train.quantile(.15).to_dict(),inplace=True)\n\nprint('train shape: {}  ;  test shape: {}'.format(train.shape,test.shape))\n\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Date into datetime format \ntrain['Date'] = pd.to_datetime(train['Date'], format = '%Y-%m-%d')\ntest['Date'] = pd.to_datetime(test['Date'], format = '%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Date characteristics\ndef create_date_features(df):\n    df['day'] = df['Date'].dt.day\n    df['month'] = df['Date'].dt.month\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['dayofyear'] = df['Date'].dt.dayofyear\n    df['weekofyear'] = df['Date'].dt.weekofyear\n    df['Date_day_month'] = df['Date'].dt.strftime(\"%m%d\").astype(int)\n    return df\n# \ntrain=create_date_features(train)\ntest=create_date_features(test)\n\n# \ntest.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatenate Province_State & Country_Region as \"Province_State\" ID\ntrain['Province_State']=train['Country_Region']+' '+train['Province_State']\ntest['Province_State']=test['Country_Region']+' '+test['Province_State']\n\n#\ntrain['Province_State']=train['Province_State'].str.replace(' ','')\ntest['Province_State']=test['Province_State'].str.replace(' ','')\n\n\n# Drop useless columns\ntrain.drop(columns=['Country Name','Country_Region','country'],inplace=True)\ntest.drop(columns=['Country Name','Country_Region','country'],inplace=True)\n#\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weither the added mesures were applied at Date or not\ntrain['measures_applied']=(train.Date.dt.strftime('%Y-%m-%d')>=train['entry_date']).astype(int)\ntest['measures_applied']=(test.Date.dt.strftime('%Y-%m-%d')>=test['entry_date']).astype(int)\n#\ntrain.drop(columns=['entry_date'],inplace=True)\ntest.drop(columns=['entry_date'],inplace=True)\n#\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode categorical features\ntrain=pd.get_dummies(columns=['category','measure','global-school-closures'],data=train)\ntest=pd.get_dummies(columns=['category','measure','global-school-closures'],data=test)\n#\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display ConfirmedCases & Fatatilities charts for a random Province state\n\n# Pick one random Province_State\nprovince=np.random.choice(train['Province_State'].unique())\ns=train.loc[train['Province_State']==province,['ConfirmedCases','Fatalities']]\n\nplt.style.use('default')\nplt.figure(figsize=(10,3))\nplt.subplot(121)\ns['ConfirmedCases'].plot(kind='area',color='deepskyblue',alpha=.4,label='ConfirmedCases')\ns['Fatalities'].plot(kind='area',color='orangered',alpha=.4,label='Fatalities')\nplt.legend()\nplt.xticks(rotation=80)\nplt.title('ConfirmedCases',fontsize=10)\n#\nplt.subplot(122)\ns['Fatalities'].plot('area',color='orange',alpha=.4)\nplt.xticks(rotation=80)\nplt.title('Fatalities',fontsize=10)\n\nplt.suptitle(province.upper(),fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show target (ConfirmedCases, Fatalities)\nplt.figure(figsize=(10,3))\nplt.subplot(121)\nplt.hist(np.log(1+train['ConfirmedCases']),bins=100,edgecolor='k',facecolor='deepskyblue',density=True)\nplt.title('log ConfirmedCases')\n#\nplt.subplot(122)\nplt.hist(np.log(1+train['Fatalities']),bins=100,edgecolor='k',facecolor='orangered',density=True)\nplt.title('log Fatalities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s=test.select_dtypes(include='number').nunique()\nbinary_features=s[s==2].index.values\nbinary_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize binary features ditribution\ndef feat_pie(col):\n    print('ConfirmedCases*{}  Correlation = {}'.format(col,np.corrcoef(train['ConfirmedCases'],train[col])[0,1]))\n    print('Fatalities*{}  Correlation = {}'.format(col,np.corrcoef(train['Fatalities'],train[col])[0,1]))\n    \n    plt.figure(figsize=(7,3))\n    plt.subplot(121)\n    train[col].value_counts().plot.pie(autopct='%1.1f%%')\n    plt.title('train')\n    plt.subplot(122)\n    test[col].value_counts().plot.pie(autopct='%1.1f%%')\n    plt.title('test')\n    plt.show()\n    \nfeat_pie(np.random.choice(binary_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill binary data with 0\ntrain.fillna({col:0 for col in binary_features},inplace=True)\ntest.fillna({col:0 for col in binary_features},inplace=True)\n\n# fill missing values with mean-value\nfilling_dict=train.median().to_dict()\ntrain.fillna(filling_dict,inplace=True)\ntest.fillna(filling_dict,inplace=True)\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=test.select_dtypes(include='number').columns.values[1:]\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feat_dist(col):\n    print('ConfirmedCases*{}  Correlation = {}'.format(col,np.corrcoef(train['ConfirmedCases'],train[col])[0,1]))\n    print('Fatalities*{}  Correlation = {}'.format(col,np.corrcoef(train['Fatalities'],train[col])[0,1]))\n    \n    plt.figure(figsize=(6,3))\n    train[col].plot.hist(bins=100,edgecolor='k',facecolor='deepskyblue')\n    plt.title(col)\n    plt.show()\n    \nfeat_dist(np.random.choice(features))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 3- Model</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict data and Create submission file from test data\nout = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\n# fit a model for every Province, Then make prediction\nfor province in tqdm(train['Province_State'].unique()):\n    # train set\n    train_province = train.loc[(train['Province_State'] == province)].copy()\n    \n    # targets   \n    y_Conf_true = train_province['ConfirmedCases']\n    y_Fat_true = train_province['Fatalities']\n    \n    # Input\n    X_train_prov = train_province[features]\n\n    #  test set\n    test_province = test[(test['Province_State']== province)].copy()\n\n    X_test_Id = test_province['ForecastId']\n    X_test_prov = test_province[features]\n\n    # fit regressors & Make predictions\n    reg_Conf = XGBRegressor(n_estimators=1000)\n    reg_Conf.fit(X_train_prov, y_Conf_true)\n    y_Conf_pred = reg_Conf.predict(X_test_prov)\n\n    reg_Fat = XGBRegressor(n_estimators=1000)\n    reg_Fat.fit(X_train_prov, y_Fat_true)\n    y_Fat_pred = reg_Fat.predict(X_test_prov)\n\n    predictions = pd.DataFrame({'ForecastId': X_test_Id, 'ConfirmedCases': y_Conf_pred, 'Fatalities': y_Fat_pred})\n    out = pd.concat([out, predictions], axis=0)\n    \nout['ForecastId']=out['ForecastId'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features importances\n\ndef feature_importance(features,reg,nb=-1):\n    if hasattr(reg,'feature_importances_'):\n        feature_imp=reg.feature_importances_\n    else:\n        feature_imp=reg.coef_\n    imp_=pd.DataFrame({'feature':features,'importance':feature_imp},index=range(len(features))).sort_values(by=['importance'],ascending=False)\n    if nb==-1:\n        nb=20\n    imp_[imp_.index<nb].plot.bar(x='feature',y='importance',rot=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_importance(features,reg_Conf,nb=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission file\nout.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}