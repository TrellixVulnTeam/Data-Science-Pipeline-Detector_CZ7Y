{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://media.giphy.com/media/dVuyBgq2z5gVBkFtDc/giphy.gif)"},{"metadata":{},"cell_type":"markdown","source":"Coronaviruses(COVID-19) are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19.COVID-19 is the infectious disease caused by the most recently discovered coronavirus. This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n\nMost people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.\n\n[Source](https://www.who.int/news-room/q-a-detail/q-a-coronaviruses)"},{"metadata":{},"cell_type":"markdown","source":"# **Introduction**"},{"metadata":{},"cell_type":"markdown","source":"\n\nThis kernel was inspired in part by the work of Abhijith Chandra Das's analysis that I thank very much for the quality of his analysis. This work represents a deeper analysis by playing on several parameters while using only logistic regression estimator. In a future work, I will discuss other techniques. I am open to any criticism and proposal. You do not hesitate to evaluate this analysis."},{"metadata":{"_uuid":"58411f3a-4873-4958-9e88-bb387d705421","_cell_guid":"8eb73106-b7c0-4a45-88ff-631f6497e547","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\nimport seaborn as sb\nimport matplotlib.dates as dates\n\nimport datetime as dt\nfrom itertools import cycle, islice\npy.init_notebook_mode(connected=True)\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom itertools import cycle, islice\nfrom sklearn.linear_model import LinearRegression\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Learning about the data**"},{"metadata":{},"cell_type":"markdown","source":"Let's take a quick look at the primary CoVid-19 dataset that is imported."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ndisplay(train_data.head())\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\ndisplay(test_data.head())\ndf_sub=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_of_data = pd.pivot_table(train_data, values=['ConfirmedCases','Fatalities'], index=['Date'],aggfunc=np.sum)\ndisplay(sum_of_data.max())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets create some new features, such as\n\n* Daily Confirmed cases\n* Daily Fatalities\n* Growth factor (ratio of daily new cases to the previous day)\n* Mortality rate (ratio of fatalities to the confirmed cases)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['NewConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\ntrain_data['NewConfirmedCases'] = train_data['NewConfirmedCases'].fillna(0.0)\ntrain_data['NewFatalities']     = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\ntrain_data['NewFatalities']     = train_data['NewFatalities'].fillna(0.0)#.astype(int)\ntrain_data['MortalityRate']     = train_data['Fatalities'] / train_data['ConfirmedCases']\ntrain_data['MortalityRate']     = train_data['MortalityRate'].fillna(0.0)\ntrain_data['GrowthRate']        = train_data['NewConfirmedCases']/train_data['NewConfirmedCases'].shift(1)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].replace([-np.inf, np.inf],  0.0)\ntrain_data['GrowthRate']        = train_data['GrowthRate'].fillna(0.0) \ndisplay(train_data.head())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" By using Province or State,lets learn the time stamp for the training and test dataset,and the countries with further details."},{"metadata":{"trusted":true},"cell_type":"code","source":"def ColumnInfo(df):\n    n_province =  df['Province_State'].nunique()\n    n_country  =  df['Country_Region'].nunique()\n    n_days     =  df['Date'].nunique()\n    start_date =  df['Date'].unique()[0]\n    end_date   =  df['Date'].unique()[-1]\n    return n_province, n_country, n_days, start_date, end_date\n\nn_train = train_data.shape[0]\nn_test = test_data.shape[0]\n\nn_prov_train, n_count_train, n_train_days, start_date_train, end_date_train = ColumnInfo(train_data)\nn_prov_test,  n_count_test,  n_test_days,  start_date_test,  end_date_test  = ColumnInfo(test_data)\n\nprint ('<==Train data==> \\n # of Province_State: '+str(n_prov_train),', # of Country_Region:'+str(n_count_train), \n       ', Time Period: '+str(start_date_train)+' to '+str(end_date_train), '==> days:',str(n_train_days))\nprint(\"\\n Countries with Province/State information:  \", train_data[train_data['Province_State'].isna()==False]['Country_Region'].unique())\nprint ('\\n <==Test  data==> \\n # of Province_State: '+str(n_prov_test),', # of Country_Region:'+str(n_count_test),\n       ', Time Period: '+start_date_test+' to '+end_date_test, '==> days:',n_test_days)\n\ndf_test = test_data.loc[test_data.Date > '2020-04-03']\noverlap_days = n_test_days - df_test.Date.nunique()\nprint('\\n overlap days with training data: ', overlap_days, ', total days: ', n_train_days+n_test_days-overlap_days)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to do the predictions for 43 days, with overlap with of 2 days in training data that we will use to test our forecast model. Lets look at the data records with entries greater than zero."},{"metadata":{},"cell_type":"markdown","source":"# **Country/Region for the maximum cases**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_confirm_check_train = train_data.ConfirmedCases.value_counts(normalize=True)\nprob_fatal_check_train = train_data.Fatalities.value_counts(normalize=True)\n\nn_confirm_train = train_data.ConfirmedCases.value_counts()[1:].sum()\nn_fatal_train = train_data.Fatalities.value_counts()[1:].sum()\n\nprint('Percentage of confirmed case records = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_confirm_train, n_train, prob_confirm_check_train[1:].sum()*100))\nprint('Percentage of fatality records = {0:<2.0f}/{1:<2.0f} = {2:<2.1f}%'.format(n_fatal_train, n_train, prob_fatal_check_train[1:].sum()*100))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_country = train_data.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum',\n                                                                                         'GrowthRate':'last' })\n#display(train_data_by_country.tail(10))\nmax_train_date = train_data['Date'].max()\ntrain_data_by_country_confirm = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)').sort_values('ConfirmedCases', ascending=False)\ntrain_data_by_country_confirm.set_index('Country_Region', inplace=True)\n\ntrain_data_by_country_confirm.style.background_gradient(cmap='PuBu_r').format({'ConfirmedCases': \"{:.0f}\", 'GrowthRate': \"{:.2f}\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_col = list(islice(cycle(['purple', 'r', 'g', 'k', 'b', 'c', 'm']), None, len(train_data_by_country_confirm.head(30))))\nplt.rcParams.update({'font.size': 22})\ntrain_data_by_country_confirm.head(20).plot(figsize=(20,15), kind='barh', color=discrete_col)\nplt.legend([\"Confirmed Cases\", \"Fatalities\"]);\nplt.xlabel(\"Number of Covid-19 Affectees\")\nplt.title(\"First 20 Countries with Highest Confirmed Cases\")\nylocs, ylabs = plt.yticks()\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"ConfirmedCases\"][:]):\n    plt.text(v+0.01, ylocs[i]-0.25, str(int(v)), fontsize=12)\nfor i, v in enumerate(train_data_by_country_confirm.head(20)[\"Fatalities\"][:]):\n    if v > 0: #disply for only >300 fatalities\n        plt.text(v+0.01,ylocs[i]+0.1,str(int(v)),fontsize=12) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plots of confirmed cases and fatalities for nations with fatalities > 500"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reformat_time(reformat, ax):\n    ax.xaxis.set_major_locator(dates.WeekdayLocator())\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%b %d'))    \n    if reformat: #reformat again if you wish\n        date_list = train_data_by_date.reset_index()[\"Date\"].tolist()\n        x_ticks = [dt.datetime.strftime(t,'%Y-%m-%d') for t in date_list]\n        x_ticks = [tick for i,tick in enumerate(x_ticks) if i%8==0 ]# split labels into same number of ticks as by pandas\n        ax.set_xticklabels(x_ticks, rotation=90)\n    # cosmetics\n    ax.yaxis.grid(linestyle='dotted')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.spines['left'].set_color('none')\n    ax.spines['bottom'].set_color('none')\n\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data_by_date = train_data.groupby(['Date'],as_index=True).agg({'ConfirmedCases': 'sum','Fatalities': 'sum', \n                                                                     'NewConfirmedCases':'sum', 'NewFatalities':'sum', 'MortalityRate':'mean'})\nnum0 = train_data_by_date._get_numeric_data() \nnum0[num0 < 0.0] = 0.0\n#display(train_data_by_date.head())\n\n## ======= Sort by countries with fatalities > 500 ========      \n        \n   \ntrain_data_by_country_max = train_data.groupby(['Country_Region'],as_index=True).agg({'ConfirmedCases': 'max', 'Fatalities': 'max'})\ntrain_data_by_country_fatal = train_data_by_country_max[train_data_by_country_max['Fatalities']>500]\ntrain_data_by_country_fatal = train_data_by_country_fatal.sort_values(by=['Fatalities'],ascending=False).reset_index()\n#display(train_data_by_country_fatal.head(20))\n\ndf_merge_by_country = pd.merge(train_data,train_data_by_country_fatal['Country_Region'],on=['Country_Region'],how='inner')\ndf_max_fatality_country = df_merge_by_country.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum',\n                                                                                                     'Fatalities': 'sum',\n                                                                                                     'NewConfirmedCases':'sum',\n                                                                                                     'NewFatalities':'sum',\n                                                                                                     'MortalityRate':'mean'})\n\nnum1 = df_max_fatality_country._get_numeric_data() \nnum1[num1 < 0.0] = 0.0\ndf_max_fatality_country.set_index('Date',inplace=True)\n#display(df_max_fatality_country.head(20))\n     \n\n\ncountries = train_data_by_country_fatal['Country_Region'].unique()\n\nplt.rcParams.update({'font.size': 16})\n\nfig,(ax0,ax1) = plt.subplots(1,2,figsize=(15, 8))\nfig,(ax2,ax3) = plt.subplots(1,2,figsize=(15, 8))#,sharey=True)\n\ntrain_data_by_date.ConfirmedCases.plot(ax=ax0, x_compat=True, title='Confirmed Cases Globally', legend='Confirmed Cases',\n                                       color=discrete_col)#, logy=True)\nreformat_time(0,ax0)\ntrain_data_by_date.NewConfirmedCases.plot(ax=ax0, x_compat=True, linestyle='dotted', legend='New Confirmed Cases',\n                                          color=discrete_col)#, logy=True)\nreformat_time(0,ax0)\n\ntrain_data_by_date.Fatalities.plot(ax=ax2, x_compat=True, title='Fatalities Globally', legend='Fatalities', color='r')\nreformat_time(0,ax2)\ntrain_data_by_date.NewFatalities.plot(ax=ax2, x_compat=True, linestyle='dotted', legend='Daily Deaths',color='r')#tell pandas not to use its own datetime format\nreformat_time(0,ax2)\n\nfor country in countries:\n    match = df_max_fatality_country.Country_Region==country\n    df_fatality_by_country = df_max_fatality_country[match] \n    df_fatality_by_country.ConfirmedCases.plot(ax=ax1, x_compat=True, title='Confirmed Cases Nationally')\n    reformat_time(0,ax1)\n    df_fatality_by_country.Fatalities.plot(ax=ax3, x_compat=True, title='Fatalities Nationally')\n    reformat_time(0,ax3)\n    \nax1.legend(countries)\nax3.legend(countries)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig,(ax4,ax5) = plt.subplots(1,2,figsize=(20, 8))\n#train_data_by_date.loc[(train_data_by_date.ConfirmedCases > 200)]#useless, its already summed.\ntrain_data_by_date.MortalityRate.plot(ax=ax4, x_compat=True, legend='Mortality Rate',color='purple')#tell pandas not to use its own datetime format\nreformat_time(0,ax4)\n\nfor num, country in enumerate(countries):\n    match = df_max_fatality_country.Country_Region==country \n    df_fatality_by_country = df_max_fatality_country[match] \n    df_fatality_by_country.MortalityRate.plot(ax=ax5, x_compat=True, title='Average Mortality Rate Nationally')    \n    reformat_time(0,ax5)\n\nax5.legend(countries, loc='center left',bbox_to_anchor=(1.0, 0.5))     \n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Here, one should be cautioned as these numbers truely depends on the number of confirmed cases, which itself depends on how many tests were performed during that time. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_by_max_date = train_data_by_country.query('(Date == @max_train_date) & (ConfirmedCases > 100)')\ntrain_data_by_max_date.loc[:, 'MortalityRate'] = train_data_by_max_date.loc[:,'Fatalities']/train_data_by_max_date.loc[:,'ConfirmedCases']\ntrain_data_by_mortality = train_data_by_max_date.sort_values('MortalityRate', ascending=False)\ntrain_data_by_mortality.set_index('Country_Region', inplace=True)\n#display(train_data_by_mortality.head())\n\npalette = plt.get_cmap('PuRd_r')\nrainbow_col = [palette(1.*i/20.0) for i in range(20)]\n\ntrain_data_by_mortality.MortalityRate.head(20).plot(figsize=(15,10), kind='barh', color=rainbow_col)\nplt.xlabel(\"Mortality Rate\")\nplt.title(\"First 20 Countries with Highest Mortality Rate\")\nylocs, ylabs = plt.yticks() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here, We classify attributes with respect to their category"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique Countries: {len(train_data.Country_Region.unique())}\")\n\ntrain_dates=list(train_data.Date.unique())\nprint(f\"Period : {len(train_data.Date.unique())} days\")\nprint(f\"From : {train_data.Date.min()} To : {train_data.Date.max()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique Regions: {train_data.shape[0]/75}\")\ntrain_data.Country_Region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of rows without Country_Region : {train_data.Country_Region.isna().sum()}\")\n\ntrain_data[\"UniqueRegion\"]=train_data.Country_Region\ntrain_data.UniqueRegion[train_data.Province_State.isna()==False]=train_data.Province_State+\" , \"+train_data.Country_Region\ntrain_data[train_data.Province_State.isna()==False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete the unwanted columns/attributes.\ntrain_data.drop(labels=[\"Id\",\"Province_State\",\"Country_Region\"], axis=1, inplace=True)\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dates=list(test_data.Date.unique())\nprint(f\"Period :{len(test_data.Date.unique())} days\")\nprint(f\"From : {test_data.Date.min()} To : {test_data.Date.max()}\")\nprint(f\"Total Regions : {test_data.shape[0]/43}\")\n\n\ntest_data[\"UniqueRegion\"]=test_data.Country_Region\ntest_data.UniqueRegion[test_data.Province_State.isna()==False]=test_data.Province_State+\" , \"+test_data.Country_Region\ntest_data.drop(labels=[\"Province_State\",\"Country_Region\"], axis=1, inplace=True)\nlen(test_data.UniqueRegion.unique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"only_train_dates=set(train_dates)-set(test_dates)\nprint(\"Only train dates : \",len(only_train_dates))\n#dates in train and test\nintersection_dates=set(test_dates)&set(train_dates)\nprint(\"Intersection dates : \",len(intersection_dates))\n#dates in only test\nonly_test_dates=set(test_dates)-set(train_dates)\nprint(\"Only Test dates : \",len(only_test_dates))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_temp=pd.DataFrame()\ndf_test_temp[\"Date\"]=test_data.Date\ndf_test_temp[\"ConfirmedCases\"]=0.0\ndf_test_temp[\"Fatalities\"]=0.0\ndf_test_temp[\"UniqueRegion\"]=test_data.UniqueRegion\ndf_test_temp[\"Delta\"]=1.0       \n     \ndisplay(df_test_temp) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Implementing Linear Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfinal_df=pd.DataFrame(columns=[\"Date\",\"ConfirmedCases\",\"Fatalities\",\"UniqueRegion\"])\n\nfor region in train_data.UniqueRegion.unique():\n    df_temp=train_data[train_data.UniqueRegion==region].reset_index()\n    df_temp[\"Delta\"]=1.0\n    size_train=df_temp.shape[0]\n    for i in range(1,df_temp.shape[0]):\n        if(df_temp.ConfirmedCases[i-1]>0):\n            df_temp.Delta[i]=df_temp.ConfirmedCases[i]/df_temp.ConfirmedCases[i-1]\n            #number of days for delta trend\n    n=5     \n\n    #delta as average of previous n days\n    delta_avg=df_temp.tail(n).Delta.mean()\n\n    #delta as trend for previous n days\n    delta_list=df_temp.tail(n).Delta\n    death_rate=df_temp.tail(1).Fatalities.sum()/df_temp.tail(1).ConfirmedCases.sum()\n    df_test_app=df_test_temp[df_test_temp.UniqueRegion==region]\n    \n    X=np.arange(1,n+1).reshape(-1,1)\n    Y=delta_list\n    model=LinearRegression()\n    model.fit(X,Y)\n\n    df_temp=pd.concat([df_temp,df_test_app])\n    df_temp=df_temp.reset_index()\n\n    for i in range (size_train, df_temp.shape[0]):\n        n=n+1\n        df_temp.Delta[i]=max(1,model.predict(np.array([n]).reshape(-1,1))[0])\n        df_temp.ConfirmedCases[i]=round(df_temp.ConfirmedCases[i-1]*df_temp.Delta[i],0)\n        df_temp.Fatalities[i]=round(death_rate*df_temp.ConfirmedCases[i],0)\n\n\n    size_test=df_temp.shape[0]-df_test_temp[df_test_temp.UniqueRegion==region].shape[0]\n\n    df_temp=df_temp.iloc[size_test:,:]\n    \n    df_temp=df_temp[[\"Date\",\"ConfirmedCases\",\"Fatalities\",\"UniqueRegion\"]]\n    final_df=pd.concat([final_df,df_temp], ignore_index=True)\n    \nfinal_df.shape\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.Fatalities=final_df.Fatalities\ndf_sub.ConfirmedCases=final_df.ConfirmedCases\ndf_sub.to_csv(\"submission.csv\", index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}