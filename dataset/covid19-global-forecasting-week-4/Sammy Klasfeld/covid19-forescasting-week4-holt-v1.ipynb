{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook I am interested in using Holt's algorithm to model the trend of the virus in each location. The problem with Holt's algorithm is that it only accounts for trend and then predicts accordingly. I eventually want to add information about lock-downs and testing to my model to make more accurate predictions."},{"metadata":{},"cell_type":"markdown","source":"# Set up Python Environment\nLoad the necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting libraries\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt\nfrom matplotlib.dates import (\n        MonthLocator,\n        num2date,\n        AutoDateLocator,\n        AutoDateFormatter,\n)\nimport gc # garbage collector\n\n# stats models\nimport statsmodels.api as sm\nfrom fbprophet import Prophet\n\n# time libraries\nimport datetime\n\n# warning libraries for debugging\nimport warnings\n\n# deal with date in x-axis of plots\nfrom pandas.plotting import register_matplotlib_converters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pykalman import KalmanFilter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"code to create time bar to run functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time, sys\nfrom IPython.display import clear_output\n\ndef update_progress(progress):\n    bar_length = 20\n    if isinstance(progress, int):\n        progress = float(progress)\n    if not isinstance(progress, float):\n        progress = 0\n    if progress < 0:\n        progress = 0\n    if progress >= 1:\n        progress = 1\n\n    block = int(round(bar_length * progress))\n\n    clear_output(wait = True)\n    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n    print(text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\nLet's take a quick look at our training and testing data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/covid19-global-forecasting-week-4/train.csv')\ntest_df = pd.read_csv('../input/covid19-global-forecasting-week-4/test.csv')\n\ntrain_df[\"Date\"] = pd.to_datetime(train_df[\"Date\"], infer_datetime_format=True)\ntest_df[\"Date\"] = pd.to_datetime(test_df[\"Date\"], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Data\nlet's look at the training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the top of the training data frame\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_values=[\"ConfirmedCases\",\"Fatalities\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# breathe of the target values\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of nulls in the training set\n# compared to the number of rows\nprint(\"number of rows in training set:\")\nprint(len(train_df))\nprint(\"null values in each column:\")\nprint(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Countries and Provinces"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of unique countries in training data: %i\" %\n    train_df['Country_Region'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Of the countries with provinces, how many provinces do they have?\")\nprint(train_df.loc[train_df['Province_State'].notnull(),:]. \\\n    groupby('Country_Region')['Province_State'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Of the countries with provinces, do they have any rows with no province listed?\")\nprint(\"How many rows do they have?\")\ncountriesWithProvinces = list(train_df.loc[train_df['Province_State'].notnull(),\"Country_Region\"])\ntrain_df.loc[((train_df[\"Country_Region\"].isin(countriesWithProvinces))\n              & (train_df[\"Province_State\"].isnull())),\"Country_Region\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So basically we can count the \"N/A\" province as a province in these 4 countries since they have a data point for each day. I want to create a column that contains both the province and country in one string."},{"metadata":{"trusted":true},"cell_type":"code","source":"def location(country, province):\n    if province == province:\n        loc = (\"%s, %s\" % \n               (province, \n               country))\n        return(loc)\n    else:\n        return(country)\n    \ntrain_df['location'] = train_df.apply(\n    lambda x: location(x[\"Country_Region\"],\n                      x[\"Province_State\"]), axis=1)\ntest_df['location'] = test_df.apply(\n    lambda x: location(x[\"Country_Region\"],\n                      x[\"Province_State\"]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Start Date:\")\nprint (train_df['Date'].min())\nprint (\"End Date:\")\nprint (train_df['Date'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of dates for each country/provice\nprint(train_df. \\\n    groupby(['Country_Region','Province_State'])['Date']. \\\n      nunique(). \\\n     reset_index()['Date'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each country has a count for each of the 65 days."},{"metadata":{},"cell_type":"markdown","source":"### Plot of the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"uniq_location=list(train_df[\"location\"].unique())\nfor target in target_values:\n    plt.figure(figsize =(15,8))\n    plt.title(target)\n    for l_id in uniq_location:\n        train_locationX = train_df.loc[(\n                train_df[\"location\"]==l_id),:].copy()\n        plt.plot(train_locationX[\"Date\"],\n                 train_locationX[target], \n                 label = l_id)    \n    #plt.legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the top of the training data frame\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Start Date:\")\nprint (test_df['Date'].min())\nprint (\"End Date:\")\nprint (test_df['Date'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Metric\nThe evaluation metric for this competition is the root mean squared logarithmic error. Below I created a method that can calculate this value."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(pred_series,true_series):\n    sum_series = (np.log(pred_series+1) - \\\n        np.log(true_series+1))**2\n    return np.sqrt(np.sum(sum_series))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the Training Dataset\nWe need to split the original training data into a training and validation set. I decided to splits the training set into the before March 19th and the validation set as past March 19th since that is the earliest date on the testing set."},{"metadata":{"trusted":true},"cell_type":"code","source":"start_validation='2020-03-19'\ntrain = train_df.loc[train_df[\"Date\"]<start_validation,:]\nvalid = train_df.loc[train_df[\"Date\"]>=start_validation,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The holt algorithm only works if the data frames have the date as the index so let's refort our data frames."},{"metadata":{"trusted":true},"cell_type":"code","source":"# for the training data I want to reformat\n# the dataframe so that the timestamp is the \n# index\nprint(\"reformat training data frame...\")\ndef trainDF2timeDF(training_df):\n    timeValue_df =  train.copy()\n    timeValue_df = timeValue_df.set_index(\"Date\")\n    warnings.simplefilter(\"ignore\")\n    timeValue_df.index = pd.to_datetime(timeValue_df.index.values)\n    return(timeValue_df)\n\ntimeIndexed_train = trainDF2timeDF(train)\ntimeIndexed_train_df = trainDF2timeDF(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To seperate the true targets in the validation set we create a new data frame with their name changed."},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_holt = valid.copy().rename(\n    columns={\"timestamp\": \"now\", \n             \"ConfirmedCases\": \"true_ConfirmedCases\",\n            \"Fatalities\":\"true_Fatalities\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Holt model\nThis model accounts for trend but not seasonality. Below we test this model without any filter. We also try out different parameters."},{"metadata":{},"cell_type":"markdown","source":"We can test the damped parameter:"},{"metadata":{"trusted":true},"cell_type":"code","source":"holt_params={}\nholt_params[\"damped_False\"]=[False]\nholt_params[\"damped_True\"]=[True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This model splits the data based on \n# location\nuniq_location=list(valid[\"location\"].unique())\nnlocations=len(uniq_location)\nprint(\"number of locations: \"+ str(nlocations))\nx=0\nfor l_id in uniq_location:\n    update_progress(x / nlocations)\n    x+=1\n    # fit the model to the target_values of this location\n    for target in target_values:\n        sub_timeTrain_df = timeIndexed_train.loc[(\n            timeIndexed_train[\"location\"]==l_id),target].copy()\n        numValid = len(valid_holt.loc[(\n            valid_holt[\"location\"]==l_id),:])\n        for param in holt_params.keys():\n            fit_holt = Holt(\n                sub_timeTrain_df,\n                damped=holt_params[param][0]).fit(optimized=True)\n            # forecast the targets\n            target_col = (\"%s_%s\" %\n                         (param,target))\n            valid_holt.loc[(\n                valid_holt[\"location\"]==l_id),target_col] = \\\n                fit_holt.forecast(numValid).values\n            alpha_col = ((\"%s_alpha\") % param)\n            valid_holt.loc[(\n                valid_holt[\"location\"]==l_id),alpha_col] = \\\n                    fit_holt.model.params['smoothing_level']\nupdate_progress(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing Validation Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore this code. \n# I just use it when I am too lazy to wait for the plots below\nl_id=\"France\"\nif 1==0:\n    for target in target_values:\n        train_bidX_meterY = train.loc[(\n                train[\"location\"]==l_id),:].copy()\n        valid_bidX_meterY = valid.loc[(\n                valid[\"location\"]==l_id),:].copy()\n        pred_bidX_meterY = valid_holt.loc[(\n                valid_holt[\"location\"]==l_id),:].copy()\n        plt.figure(figsize =(15,8))\n        plt.title(l_id+\" \"+target)\n        plt.plot(train_bidX_meterY[\"Date\"],\n                 train_bidX_meterY[target], \n                 label = 'Train')\n        plt.plot(valid_bidX_meterY[\"Date\"],\n                 valid_bidX_meterY[target],\n                 label = 'Validation')\n        plt.plot(pred_bidX_meterY[\"Date\"],\n                pred_bidX_meterY[\"damped_False_\"+target],\n                 label = 'Holt Model (damped=False)')\n        plt.plot(pred_bidX_meterY[\"Date\"],\n                pred_bidX_meterY[\"damped_True_\"+target],\n                 label = 'Holt Model (damped=True)')\n        plt.legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for target in target_values:\n    for l_id in uniq_location:\n        train_bidX_meterY = train.loc[(\n                train[\"location\"]==l_id),:].copy()\n        valid_bidX_meterY = valid.loc[(\n                valid[\"location\"]==l_id),:].copy()\n        pred_bidX_meterY = valid_holt.loc[(\n                valid_holt[\"location\"]==l_id),:].copy()\n        plt.figure(figsize =(15,8))\n        plt.title(l_id+\" \"+target)\n        plt.plot(train_bidX_meterY[\"Date\"],\n                 train_bidX_meterY[target], \n                 label = 'Train')\n        plt.plot(valid_bidX_meterY[\"Date\"],\n                 valid_bidX_meterY[target],\n                 label = 'Validation')\n        plt.plot(pred_bidX_meterY[\"Date\"],\n                pred_bidX_meterY[\"damped_False_\"+target],\n                 label = 'Holt Model (damped=False)')\n        plt.plot(pred_bidX_meterY[\"Date\"],\n                pred_bidX_meterY[\"damped_True_\"+target],\n                 label = 'Holt Model (damped=True)')\n        plt.legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It may seem obvious, but the model works best once there is a linear trend to begin with. In other words, the Holt's model cannot predict when the virus is going to hit the particular location, but it can predict the exponential trend."},{"metadata":{},"cell_type":"markdown","source":"## Calculate Error Rate for Holt's Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"for target in target_values:\n    print(\"Holt (damped=False) RMSLE value for %s:\" % target)\n    print(rmsle(valid_holt[\"damped_False_\"+target],\n               valid_holt[\"true_\"+target]))\n    print(\"Holt (damped=True) RMSLE value for %s:\" % target)\n    print(rmsle(valid_holt[\"damped_True_\"+target],\n               valid_holt[\"true_\"+target]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission for Holt's Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This model splits the data based on \n# location\nnlocations=len(uniq_location)\nprint(\"number of locations: \"+ str(nlocations))\nx=0\nfor l_id in uniq_location:\n    update_progress(x / nlocations)\n    x+=1\n    # fit the model to the target_values of this location\n    for target in target_values:\n        sub_timeTrain_df = timeIndexed_train_df.loc[(\n            timeIndexed_train_df[\"location\"]==l_id),target].copy()\n        numValid = len(test_df.loc[(\n            test_df[\"location\"]==l_id),:])\n        fit_holt = Holt(\n            sub_timeTrain_df,\n            damped=False).fit(optimized=True)\n        # forecast the targets\n        test_df.loc[(\n            test_df[\"location\"]==l_id),target] = \\\n            fit_holt.forecast(numValid).values\nupdate_progress(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test_df.loc[:,[\"ForecastId\",\"ConfirmedCases\",\"Fatalities\"]]\nsubmission.to_csv(\"submission_holt_dampedFalse.csv\",sep=\",\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}