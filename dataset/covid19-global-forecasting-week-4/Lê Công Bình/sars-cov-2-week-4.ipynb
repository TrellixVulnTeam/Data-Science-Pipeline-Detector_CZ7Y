{"cells":[{"metadata":{},"cell_type":"markdown","source":"Link to week 1 version: https://www.kaggle.com/binhlc/sars-cov-2-voting-regressor\n* Data Visualization: Matplotlib\n* Focus to ARIMA, compare to many difference algorithm \n\nLink to week 2 version: https://www.kaggle.com/binhlc/sars-cov-2-exponential-model-week-2\n* Data Visualization: Plotly\n* Focus to Exponential \n\nLink to week 3 version: https://www.kaggle.com/binhlc/sars-cov-2-arima-model-week-3\n* Data Visualization: Bokeh\n* Aprrove Auto Arima and SARIMAX\n\nWeek 4 version:\n* Data Visualization: Altair\n* Nothing new to do - keep SARIMAX, ARIMA with new train data "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['Country_Region'] == 'US'].sort_values('ConfirmedCases',ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['Country_Region'] == 'US'].groupby(['Date']).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import altair as alt\n\ndf_total = train.groupby(['Date']).sum().reset_index()\nbase = alt.Chart(df_total).encode(alt.X('Date:T'))\nline_A = base.mark_line(point=False, color='#5276A7').encode(alt.Y('ConfirmedCases:Q', axis=alt.Axis(titleColor='#5276A7')))\nline_B = base.mark_line(point=False, color='#F18727').encode(alt.Y('Fatalities:Q', axis=alt.Axis(titleColor='#F18727')))\nalt.layer(line_A, line_B).resolve_scale(y='independent')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alt.Chart(df_total, title = \"Total of World\").mark_line().encode(\n    alt.X('Date:T'),\n    alt.Y(alt.repeat(\"column\"), type='quantitative'),\n    #color='species:N'\n#).properties(\n#    width=500,\n#    height=200\n).repeat(\n    #row=['ConfirmedCases', 'Fatalities'],\n    column=['ConfirmedCases', 'Fatalities']\n)#.interactive()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_now = train.groupby(['Date','Country_Region']).sum().sort_values(['Country_Region','Date']).reset_index()\ndf_now['New Cases'] = df_now['ConfirmedCases'].diff()\ndf_now['New Fatalities'] = df_now['Fatalities'].diff()\ndf_now = df_now.groupby('Country_Region').apply(lambda group: group.iloc[-1:]).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alt.Chart(df_now.sort_values('ConfirmedCases', ascending=False).head(15)).mark_bar().encode(\n    alt.X(alt.repeat(\"column\"), type='quantitative'),\n    alt.Y('Country_Region', type='nominal', sort='-x'),\n    tooltip=['Country_Region', 'ConfirmedCases', 'Fatalities','New Cases', 'New Fatalities'],\n    color = alt.value('orange')\n).repeat(column=['New Cases', 'New Fatalities'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alt.Chart(df_now.sort_values('ConfirmedCases', ascending=False).head(15), title = \"Top country\").mark_bar().encode(\n    alt.X(alt.repeat(\"column\"), type='quantitative'),\n    alt.Y('Country_Region', type='nominal', sort='-x'),\n    tooltip=['Country_Region', 'ConfirmedCases', 'Fatalities','New Cases', 'New Fatalities'],\n    color = alt.value('orange')\n).repeat(column=['ConfirmedCases', 'Fatalities'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])\n\n# Fix error in train data\ntrain[['ConfirmedCases', 'Fatalities']] = train.groupby(['Country_Region', 'Province_State'])[['ConfirmedCases', 'Fatalities']].transform('cummax') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport warnings\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))\n\nfeature_day = [1,20,50,100,200,500,1000,5000,10000,15000,20000,50000,100000,200000, 500000]\n\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SARIMAX"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['US']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        #for province in ['New York']:\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n                df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                X_train = CreateInput(df_train)\n                y_train_confirmed = df_train['ConfirmedCases'].ravel()\n                y_train_fatalities = df_train['Fatalities'].ravel()\n                X_pred = CreateInput(df_test)\n\n                # Define feature to use by X_pred\n                feature_use = X_pred.columns[0]\n                for i in range(X_pred.shape[1] - 1,0,-1):\n                    if (X_pred.iloc[0,i] > 10):\n                        feature_use = X_pred.columns[i]\n                        break\n                idx = X_train[X_train[feature_use] == 0].shape[0]          \n                adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n\n                adjusted_y_train_confirmed = y_train_confirmed[idx:]\n                adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n                \n                pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n                min_test_date = pred_data['Date'].min()            \n\n                model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0),\n                                #seasonal_order=(1,1,0,12),\n                                measurement_error=True).fit(disp=False)\n                y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                \n                y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n                y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)                        \n\n                model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0),\n                                #seasonal_order=(1,1,0,12),\n                                measurement_error=True).fit(disp=False)\n                y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                                \n                y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n                y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)            \n\n                pred_data['ConfirmedCases_hat'] = y_hat_confirmed\n                pred_data['Fatalities_hat'] = y_hat_fatalities\n                pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n    \ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val = df_val.round({'ConfirmedCases': 0, 'Fatalities': 0})\ndf_val_1 = df_val.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Auto ARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pmdarima as pm\n\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['Vietnam']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n                df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                X_train = CreateInput(df_train)\n                y_train_confirmed = df_train['ConfirmedCases'].ravel()\n                y_train_fatalities = df_train['Fatalities'].ravel()\n                X_pred = CreateInput(df_test)\n\n                # Define feature to use by X_pred\n                feature_use = X_pred.columns[0]\n                for i in range(X_pred.shape[1] - 1,0,-1):\n                    if (X_pred.iloc[0,i] > 10):\n                        feature_use = X_pred.columns[i]\n                        break\n                idx = X_train[X_train[feature_use] == 0].shape[0]          \n                adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n                adjusted_y_train_confirmed = y_train_confirmed[idx:]\n                adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n\n                pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n                min_test_date = pred_data['Date'].min()            \n\n                model = pm.auto_arima(adjusted_y_train_confirmed, suppress_warnings=True, seasonal=False, error_action=\"ignore\")            \n                y_hat_confirmed = model.predict(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n                y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)                        \n\n                model = pm.auto_arima(adjusted_y_train_fatalities, suppress_warnings=True, seasonal=False, error_action=\"ignore\")            \n                y_hat_fatalities = model.predict(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n                y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)            \n\n                pred_data['ConfirmedCases_hat'] = y_hat_confirmed\n                pred_data['Fatalities_hat'] = y_hat_fatalities\n                pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n    \ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\n\ndf_val_2 = df_val.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_SARIMAX = df_val_1.groupby(['Date']).sum()[['ConfirmedCases_hat','Fatalities_hat']].reset_index()\ndf_SARIMAX['Model'] = 'SARIMAX'\ndf_ARIMA = df_val_2.groupby(['Date']).sum()[['ConfirmedCases_hat','Fatalities_hat']].reset_index()\ndf_ARIMA['Model'] = 'ARIMA'\n\nsource = pd.concat([df_SARIMAX,df_ARIMA], ignore_index=True)\n\nalt.Chart(source).mark_line(point=True).encode(\n    x='Date',\n    y=alt.Y(alt.repeat(\"column\"), type='quantitative'),\n    tooltip=['Model', 'Model', 'ConfirmedCases_hat', 'Fatalities_hat'],\n    color='Model',\n    #strokeDash='Country_Region'\n).repeat(column=['ConfirmedCases_hat', 'Fatalities_hat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val = df_val_1\nalt.Chart(df_val.groupby(['Date']).sum().reset_index()).mark_line(point=True).encode(\n    alt.X('Date:T'), \n    alt.Y(alt.repeat(\"column\"), type='quantitative'),\n    color=alt.condition(alt.datum.Date >= alt.expr.toDate(df_now.Date.values[0]), \n                        alt.value('orange'),     \n                        alt.value('steelblue')),\n    tooltip=['Date', 'ConfirmedCases_hat', 'Fatalities_hat']\n).repeat(column=['ConfirmedCases_hat', 'Fatalities_hat'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source = df_val[df_val['Country_Region'].isin(df_now.sort_values('ConfirmedCases', ascending=False).head(5)['Country_Region'].values)]\nsource = source.groupby(['Date','Country_Region']).sum().sort_values(['Country_Region','Date']).reset_index()\nalt.Chart(source).mark_line(point=True).encode(\n    x='Date',\n    y=alt.Y(alt.repeat(\"column\"), type='quantitative'),\n    tooltip=['Date', 'Country_Region', 'ConfirmedCases_hat', 'Fatalities_hat'],\n    color='Country_Region',\n    #strokeDash='Country_Region'\n).repeat(column=['ConfirmedCases_hat', 'Fatalities_hat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'US'\nsource = df_val[df_val['Country_Region'] == country]\nsource = source.groupby(['Date','Country_Region']).sum().sort_values(['Country_Region','Date']).reset_index()\nalt.Chart(source).mark_line(point=True).encode(\n    x='Date',\n    y=alt.Y(alt.repeat(\"column\"), type='quantitative'),\n    tooltip=['Date', 'ConfirmedCases_hat', 'Fatalities_hat'],\n    color=alt.condition(alt.datum.Date >= alt.expr.toDate(df_now.Date.values[0]), \n                        alt.value('orange'),     \n                        alt.value('steelblue')),\n).repeat(column=['ConfirmedCases_hat', 'Fatalities_hat'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val = df_val_2\nsubmission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission = submission.round({'ConfirmedCases': 0, 'Fatalities': 0})\nsubmission.to_csv('submission.csv', index=False)\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}