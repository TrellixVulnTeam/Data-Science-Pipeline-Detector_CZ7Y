{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Coronavirus Logistic Regression XGBoost"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom random import shuffle\nfrom itertools import count\nfrom copy import deepcopy\n\nimport matplotlib.pyplot as plt\nimport math\n\nfrom sklearn.metrics import accuracy_score\nimport sklearn.preprocessing as preprocessing\nimport sklearn.utils as utils\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBRegressor, plot_importance\nimport xgboost as xgb\n\nimport time\n\nfrom colorama import Fore, Style ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def dateToInt(date):\n    days = [0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n    month, day = date.split('-')[1:]\n    return sum(days[:int(month)]) + int(day) - 22\ndateToInt(\"2020-01-22\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def dateToInt2(date):\n#     days = [0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n#     month, day = date.split('/')[:-1]\n#     return sum(days[:int(month)]) + int(day) - 22","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ustempname = \"/kaggle/input/ustemperature/usTemp.csv\"\n# pustemp = pd.read_csv(ustempname)\n# def getTemp(state):\n#     if state == \"District of Columbia\":\n#         return getTemp(\"Maryland\")\n#     return pustemp[pustemp[\"State\"] == state].to_numpy()[0][1]\n# getTemp(\"Alabama\")\n# pustemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# otherinfoname = \"/kaggle/input/countryinfo/covid19countryinfo.csv\"\n# pinfo = pd.read_csv(otherinfoname)\n# # pinfo = pinfo.drop(pinfo.index[182])\n# pinfo = pinfo[[\"region\", \"country\", \"density\", \"quarantine\", \"pop\", \"avgtemp\"]][pinfo[\"country\"] == \"US\"]\n# # pinfo.columns\n# # len(pinfo[pinfo[\"country\"] == \"Italy\"])\n# pinfo\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states = [\"AL - Alabama\", \"AK - Alaska\", \"AZ - Arizona\", \"AR - Arkansas\", \"CA - California\", \"CO - Colorado\",\n\"CT - Connecticut\", \"DE - Delaware\", \"FL - Florida\", \"GA - Georgia\",\n\"HI - Hawaii\", \"ID - Idaho\", \"IL - Illinois\", \"IN - Indiana\", \"IA - Iowa\",\n\"KS - Kansas\", \"KY - Kentucky\", \"LA - Louisiana\", \"ME - Maine\", \"MD - Maryland\",\n\"MA - Massachusetts\", \"MI - Michigan\", \"MN - Minnesota\", \"MS - Mississippi\",\n\"MO - Missouri\", \"MT - Montana\", \"NE - Nebraska\", \"NV - Nevada\", \"NH - New Hampshire\",\n\"NJ - New Jersey\", \"NM - New Mexico\", \"NY - New York\", \"NC - North Carolina\",\n\"ND - North Dakota\", \"OH - Ohio\", \"OK - Oklahoma\", \"OR - Oregon\", \"PA - Pennsylvania\",\n\"RI - Rhode Island\", \"SC - South Carolina\", \"SD - South Dakota\", \"TN - Tennessee\",\n\"TX - Texas\", \"UT - Utah\", \"VT - Vermont\", \"VA - Virginia\", \"WA - Washington\", \"WV - West Virginia\",\n\"WI - Wisconsin\", \"WY - Wyoming\", \"DC - District of Columbia\"]\nstates = tuple(i[5:] for i in states)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testname = \"/kaggle/input/covid19-global-forecasting-week-4/test.csv\"\nptest = pd.read_csv(testname)\ntestnames = [p[1] if type(p[1]) is str else p[2] for p in ptest.to_numpy()]\nptest\n\n# Change location of training path\ntrainname = \"/kaggle/input/covid19-global-forecasting-week-4/train.csv\"\nptrain = pd.read_csv(trainname)\nnptrain = ptrain.to_numpy()\nnames = set()\nprovinces = set()\npdatas = dict()\nfor data in nptrain:\n    name = data[2]\n    names.add(name)\nfor name in names:\n    pdatas.update({name: ptrain[ptrain[\"Country_Region\"] == name].to_numpy()})\nfor name, data in list(pdatas.items()):\n    for d in data:\n        state = d[1]\n        if type(state) is float or state in provinces:\n            continue\n        try:\n            if name not in (\"Canada\",) and name not in testnames:\n                del pdatas[name]\n                names.remove(name)\n        except:\n            pass\n        names.add(state)\n        provinces.add(state)\n        pdatas.update({state: ptrain[ptrain[\"Province_State\"] == state].to_numpy()})\ncounter = 0\nstuff = [0 for i in range(72)]\nfor i in pdatas[\"Illinois\"]:\n    stuff[counter % 72] += i[-2]\n    counter += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oldxbycountry = dict()\noldybycountry = dict()\nxbycountry = dict()\nybycountry = dict()\nshufflexbycountry = dict()\nshuffleybycountry = dict()\n\nfor name in names:\n    data = pdatas[name]\n    countryx = [dateToInt(p[3]) for p in data]\n    countryy = [p[4:] for p in data]\n    oldxbycountry.update({name: countryx})\n    oldybycountry.update({name: countryy})\nl = len(oldxbycountry[\"Italy\"])\nfor name in names:\n    scheme = list(range(l))\n    shuffle(scheme)\n    newx = list(0 for i in range(l))\n    newy = list([0, 0] for i in range(l))\n    shufflex = list(0 for i in range(l))\n    shuffley = list([0,0] for i in range(l))\n    for i, x, y in zip(count(), oldxbycountry[name], oldybycountry[name]):\n        newx[i%l] = x\n        newy[i%l][0] += y[0]\n        newy[i%l][1] += y[1]\n        shufflex[scheme[i%l]] = x\n        shuffley[scheme[i%l]][0] += y[0]\n        shuffley[scheme[i%l]][1] += y[1]\n    xbycountry.update({name: np.array(newx)})\n    ybycountry.update({name: np.array(newy)})\n    shufflexbycountry.update({name: np.array(shufflex)})\n    shuffleybycountry.update({name: np.array(shuffley)})\nlen(ybycountry[\"California\"])\nshufflexbycountry[\"California\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given an objective, find the optimal normalization factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"#TODO Implement binary search\ndef optimize(objective, possiblerange, x, y, xtest, ytest, params, name=''):\n    beg = time.time()\n    goodmodel = None\n    score = 0\n    n = 0\n    l = len(possiblerange)\n    try:\n        for i, norm in enumerate(possiblerange):\n            print(progressbar(i/l), end = '\\r', flush=True)\n            model = XGBRegressor(**params)\n            model.fit(x,y/norm)\n            y_pred = model.predict(xtest)\n            predictions = np.array([round(value*norm) for value in y_pred])\n            try:\n                mscore = objective(ytest, predictions)\n            except AssertionError:\n                mscore = 0\n            if mscore >= score:\n                score = mscore\n                goodmodel = deepcopy(model)\n                n = norm\n    except KeyboardInterrupt:\n        pass\n    print(f\"\\nMax Score: {score}\")\n    print(f\"{name} trained in {time.time()-beg} seconds\")\n    return [n, goodmodel]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(y_actual, y_pred):\n    assert np.mean(y_actual) != 0\n    try:\n        percentincorrect =  np.mean(abs(y_actual-y_pred))/np.mean(y_actual)\n    except:\n        return 0\n    return 1-percentincorrect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ncat(*arrs):\n    new = []\n    for arr in arrs:\n        new += list(arr)\n    return np.array(new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Progress Bar\n\nOne of the most crucial parts of this project\n>\"10/10\"-anonymous\n\nIt starts off as red and turns green when complete"},{"metadata":{"trusted":true},"cell_type":"code","source":"def progressbar(percent):\n    numberpound = round(percent*20)\n    numberdash = 20 - numberpound\n    prog =  '[' + '#'*numberpound + '-'*numberdash + ']'\n    if numberpound == 20:\n        prog = Style.BRIGHT + Fore.GREEN + prog + Style.RESET_ALL\n    else:\n        prog = Fore.RED + prog + Style.RESET_ALL\n    return prog","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eu = (\"Sweden\", \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Ireland\", \"Italy\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\", \"Poland\", \"Portugal\", \"Romania\", \"Slovakia\", \"Slovenia\", \"Spain\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnames = (\"Alaska\", \"New Jersey\", \"Arizona\", \"Colorado\", \"Florida\", \"Hawaii\", \"Idaho\", \"Kentucky\", \"Maine\", \"Minnesota\", \"Montana\", \"New Jersey\", \"Oregon\", \"Tennessee\", \"Wyoming\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Underfit certain blacklisted regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"blacklist = (\"Andorra\", \"Austria\", \"British Columbia\", \"French Polynesia\", \"Iceland\", \"Italy\", \"Jordan\", \"Latvia\", \"Lebanon\", \"Luxembourg\", \"Mongolia\", \"New Brunswick\", \"New South\", \"Newfoundland and Labrador\", \"Norway\", \"Reunion\", \"Queensland\", \"Rwanda\", \"Saint Kitts and Nevis\", \"Saskatchewan\", \"Senegal\", \"Slovenia\", \"Slovakia\", \"South Africa\", \"Sri Lanka\", \"Switzerland\", \"Syria\", \"Uruguay\", \"Venezuela\", \"Victoria\", \"Western Australia\", \"Zimbabwe\")\ncnames = list(names)\ncnames.sort()\n\ncasemodels = dict()\nfatmodels = dict()\nfor cname in cnames:\n    try:\n        portion = slice(20,None)\n        x = xbycountry[cname]\n        y = ybycountry[cname]\n        \n#         x = ncat(*[xbycountry[name] for name in names])\n#         y = ncat(*[ybycountry[name] for name in names])\n\n        mnorm = max([i[0] for i in y])\n        mnormfat = max([i[1] for i in y]) + .01\n        \n        blacklisted = cname in blacklist\n        \n\n\n        x_train = np.array([[float(i)] for i in x])\n        y_train_case = np.array([i[0] for i in y])\n        y_train_fat = np.array([i[1] for i in y])\n        x_test = np.array([[float(i)] for i in ncat(x[-20:-18], x[-4:], x[-4:], x[-2:], x[-2:], x[-2:], x[-2:])])\n        y_test_case = np.array([i[0] for i in ncat(y[-20:-18], y[-4:], y[-4:], y[-2:], y[-2:], y[-2:], y[-2:])])\n        y_test_fat = np.array([i[1] for i in ncat(y[-20:-18], y[-4:], y[-4:], y[-2:], y[-2:], y[-2:], y[-2:])])\n\n        params = {\n            \"objective\": \"reg:logistic\",\n            \"booster\": \"gblinear\",\n            \"learning_rate\": .1,\n            \"n_estimators\": 1000 if blacklisted else 2500,#10000,\n            \"n_jobs\": 4\n        }\n\n        casemodels[cname] = optimize(accuracy, mnorm * np.linspace(1, 10 if cname != \"Japan\" else 15), x_train, y_train_case, x_test, y_test_case, params, cname + \" cases\")\n        fatmodels[cname] = optimize(accuracy, mnormfat * np.linspace(1, 10 if cname != \"Japan\" else 15), x_train, y_train_fat, x_test, y_test_fat, params, cname + \" fatalities\")\n#         print(mnorm, mnormfat)\n#         model = XGBRegressor(**params)\n#         model.fit(x_train, y_train_case/mnorm)\n#         casemodels[\"New Jersey\"] = mnorm, model\n        print()\n    except KeyError:\n        print(f\"{cname} is not a country\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = model.predict(x_test)\n# predictions = np.array([round(value*norm) for value in y_pred])\n# # predictions = lmodel.predict(np.array([[i] for i in y_pred]))\n# print(\"Predictions:\", *predictions, sep='\\t')\n# print(\"Results:\", *y_test, sep='\\t')\n# print(f\"Accuracy: {100*accuracy(y_test, predictions)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cases\nfor cname in cnames:\n    try:\n        norm, model = casemodels[cname]\n        x = list(xbycountry[cname])\n        del plt\n\n        import matplotlib.pyplot as plt\n\n        plotx = np.array([[float(i)] for i in xbycountry[cname]])\n        ploty_actual = np.array([i[0] for i in ybycountry[cname]])\n#         ploty_model = model.predict(np.array([[float(i)] for i in xbycountry[cname]]))*norm\n\n        futureplotx = np.array(list([i] for i in range(150)))\n#         futurex = np.array([[float(i)] + x[1:] for i in range(150)])\n        futurey = model.predict(futureplotx)*norm\n\n        plt.plot(futureplotx, futurey, label=\"Future\")\n        plt.plot(plotx, ploty_actual, label=\"Actual\")\n        # plt.plot(plotx, ploty_model, label=\"Model\")\n\n        plt.legend()\n        plt.show()\n        print(f\"{cname} hopefully good\")\n    except KeyError:\n        print(f\"{cname} is not a country\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fatalities\nfor cname in cnames:\n    try:\n        norm, model = fatmodels[cname]\n        x = list(xbycountry[cname])\n        del plt\n\n        import matplotlib.pyplot as plt\n\n        plotx = np.array([[float(i)] for i in xbycountry[cname]])\n        ploty_actual = np.array([i[1] for i in ybycountry[cname]])\n#         ploty_model = model.predict(np.array([[float(i)] for i in xbycountry[cname]]))*norm\n\n        futureplotx = np.array(list([i] for i in range(150)))\n#         futurex = np.array([[float(i/70)] + x[1:] for i in range(150)])\n        futurey = model.predict(futureplotx)*norm\n\n        plt.plot(futureplotx, futurey, label=\"Future\")\n        plt.plot(plotx, ploty_actual, label=\"Actual\")\n        # plt.plot(plotx, ploty_model, label=\"Model\")\n\n        plt.legend()\n        plt.show()\n        print(f\"{cname} hopefully good\")\n    except KeyError:\n        print(f\"{cname} is not a country\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm /kaggle/working/submission.csv\nstuff = []\nwith open(\"/kaggle/working/submission.csv\", 'a+') as fout:\n    fout.write(\"ForecastId,ConfirmedCases,Fatalities\\n\")\n    for i, p in enumerate(ptest.to_numpy()):\n        cname = p[1] if type(p[1]) is str else p[2]\n        casenorm, casemodel = deepcopy(casemodels[cname])\n        fatnorm, fatmodel = deepcopy(fatmodels[cname])\n        date = dateToInt(p[3])\n        cases = casemodel.predict(np.array([[date]]))[0]*casenorm\n        fatalities = fatmodel.predict(np.array([[date]]))[0]*fatnorm\n        print(i + 1, round(cases), round(fatalities), sep=',', file=fout)\n#         stuff.append((i+1, predictions[0]))\n# print(len(stuff))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Who needs ``pd.write_csv()`` NOOBS"},{"metadata":{},"cell_type":"markdown","source":"# Please UPVOTE if you found this helpful"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}