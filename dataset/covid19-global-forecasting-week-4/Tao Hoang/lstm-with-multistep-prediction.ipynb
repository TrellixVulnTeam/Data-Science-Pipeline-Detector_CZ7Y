{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom datetime import timedelta\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n        \n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if any col is null\ntrain_df.apply(lambda col: col.isnull().value_counts(), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.apply(lambda col: col.isna().value_counts(), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill na\ntrain_df[\"Province_State\"] = train_df[\"Province_State\"].fillna(\"\")\ntest_df[\"Province_State\"] = test_df[\"Province_State\"].fillna(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Date\"] = pd.to_datetime(train_df[\"Date\"])\ntest_df[\"Date\"] = pd.to_datetime(test_df[\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"NewCases\"] = train_df.groupby([\"Country_Region\", \"Province_State\"])[\"ConfirmedCases\"].diff(periods=1)\ntrain_df[\"NewCases\"] = train_df[\"NewCases\"].fillna(0)\ntrain_df[\"NewCases\"] = np.where(train_df[\"NewCases\"] < 0, 0, train_df[\"NewCases\"])\ntrain_df[\"NewFatalities\"] = train_df.groupby([\"Country_Region\", \"Province_State\"])[\"Fatalities\"].diff(periods=1)\ntrain_df[\"NewFatalities\"] = train_df[\"NewFatalities\"].fillna(0)\ntrain_df[\"NewFatalities\"] = np.where(train_df[\"NewFatalities\"] < 0, 0, train_df[\"NewFatalities\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"NewCases\"] = np.log(train_df[\"NewCases\"] + 1)\ntrain_df[\"NewFatalities\"] = np.log(train_df[\"NewFatalities\"] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_train(n_prev, n_next):\n    df = train_df.copy()\n    input_feats, output_feats = [], []\n    for i in range(1, n_prev+1):\n        for feat in [\"NewCases\", \"NewFatalities\"]:\n            df[\"{}_prev_{}\".format(feat, i)] = df.groupby([\"Country_Region\", \"Province_State\"])[feat].shift(i)\n            input_feats.append(\"{}_prev_{}\".format(feat, i))\n    \n    output_feats.extend([\"NewCases\", \"NewFatalities\"])\n    for i in range(1, n_next):\n        for feat in [\"NewCases\", \"NewFatalities\"]:\n            df[\"{}_next_{}\".format(feat, i)] = df.groupby([\"Country_Region\", \"Province_State\"])[feat].shift(-i)\n            output_feats.append(\"{}_next_{}\".format(feat, i))\n    df.dropna(inplace=True)       \n            \n    const_df = pd.get_dummies(df[[\"Province_State\", \"Country_Region\"]], drop_first=True)\n    time_df = df[input_feats]\n    time_df = time_df.values.reshape((df.shape[0],-1,2))\n    output_df = df[output_feats]\n    return const_df, time_df, output_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_test(n_prev):\n    input_feats = []\n    append_df = pd.concat([train_df, test_df[test_df[\"Date\"] == train_df[\"Date\"].max() + timedelta(days=1)]])\n    append_df.sort_values([\"Country_Region\", \"Province_State\", \"Date\"], ascending=[True, True, True], inplace=True)\n    for i in range(1, n_prev+1):\n        for feat in [\"NewCases\", \"NewFatalities\"]:\n            append_df[\"{}_prev_{}\".format(feat, i)] = append_df.groupby([\"Country_Region\", \"Province_State\"])[feat].shift(i)\n            input_feats.append(\"{}_prev_{}\".format(feat, i))\n    append_df = append_df[append_df[\"ForecastId\"].notnull()]\n            \n    const_df = pd.get_dummies(append_df[[\"Province_State\", \"Country_Region\"]], drop_first=True)\n    time_df = append_df[input_feats]\n    time_df = time_df.values.reshape((append_df.shape[0],-1,2))\n    return const_df, time_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_next = (test_df[\"Date\"].max() - train_df[\"Date\"].max()).days\nn_next","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_prev = 7\nconst_df, time_df, output_df = preprocess_train(n_prev, n_next)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"const_test_df, time_test_df = preprocess_test(n_prev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras import layers\nfrom keras import Input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_input = Input(shape=(time_df.shape[1], time_df.shape[2]))\nlstm = layers.LSTM(32)(time_input)\n\nconst_input = Input(shape=(const_df.shape[1],))\n\ncombine = layers.concatenate([lstm, const_input], axis=-1)\noutput = layers.Dense(output_df.shape[1], activation='relu')(combine)\nmodel = Model([time_input, const_input], output)\nmodel.compile(optimizer='adam',\n              loss='mean_squared_error')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit([time_df, const_df], output_df, epochs=300, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = model.predict([time_test_df, const_test_df])\noutput.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_test_df = test_df[test_df[\"Date\"] > train_df[\"Date\"].max()]\nsub_test_df = pd.concat([sub_test_df,\n                         pd.DataFrame(output.reshape((-1, 2)), columns=[\"NewCases\", \"NewFatalities\"], index=sub_test_df.index)],\n                         axis=1)\nsub_test_df[\"NewCases\"] = np.exp(sub_test_df[\"NewCases\"]) - 1\nsub_test_df[\"NewFatalities\"] = np.exp(sub_test_df[\"NewFatalities\"]) - 1\nsub_test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fixed_test_df = test_df[test_df[\"Date\"] <= train_df[\"Date\"].max()].merge(train_df[train_df[\"Date\"] >= test_df[\"Date\"].min()][[\"Province_State\",\"Country_Region\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]],\n                                                                         how=\"left\", on=[\"Province_State\",\"Country_Region\", \"Date\"])\nfixed_test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_df = pd.concat([sub_test_df, fixed_test_df]).sort_values([\"Country_Region\", \"Province_State\", \"Date\"],\n                                                                 ascending=[True, True, True])\npredict_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_df = predict_df.reset_index()\nfor i in range(len(predict_df)):\n    if pd.isnull(predict_df.iloc[i][\"ConfirmedCases\"]):\n        predict_df.loc[i, \"ConfirmedCases\"] = predict_df.iloc[i - 1][\"ConfirmedCases\"] + predict_df.iloc[i][\"NewCases\"]\n    if pd.isnull(predict_df.iloc[i][\"Fatalities\"]):\n        predict_df.loc[i, \"Fatalities\"] = predict_df.iloc[i - 1][\"Fatalities\"] + predict_df.iloc[i][\"NewFatalities\"]\npredict_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert predict_df.shape[0] == test_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_df[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = \"Australia\"\nstate = \"South Australia\"\ntarget = \"ConfirmedCases\"\nregion_train_df = train_df[(train_df[\"Country_Region\"]==country) & (train_df[\"Province_State\"]==state)]\nregion_predict_df = predict_df[(predict_df[\"Country_Region\"]==country) & (predict_df[\"Province_State\"]==state)]\n\nfig = plt.figure(figsize=(10, 6))\nax1 = fig.add_axes([0, 0, 1, 1])\nax1.plot(region_train_df[\"Date\"],\n         region_train_df[target],\n         color=\"green\")\n\nax1.plot(region_predict_df[\"Date\"],\n         region_predict_df[target],\n         color=\"red\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}