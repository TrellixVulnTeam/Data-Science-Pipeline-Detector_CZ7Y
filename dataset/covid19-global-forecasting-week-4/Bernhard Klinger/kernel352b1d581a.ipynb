{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Linear regression analysis for the COVID 19 Global Forecasting Challenge Week 4\n\n### Data import\n\nThe external data for the submission has been derived from some of the World Development Indicators from the World Bank Open Data (Population, GDP and health spending) - with some adjustments and estimates for missing data items. \n\nYou can find the full dateset and licence here: https://www.kaggle.com/theworldbank/world-development-indicators"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score\nfrom datetime import datetime\n\npd.set_option('display.max_rows', None)\n\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntrain.columns = [\"Id\",\"Prov\",\"Ctry\",\"Date\",\"Cases\",\"Death\"]\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\ntest.columns = [\"Id\",\"Prov\",\"Ctry\",\"Date\"]\ntest[\"Cases\"]=0\ntest[\"Death\"]=0\ntrain[\"Date\"]= pd.to_datetime(train.Date,infer_datetime_format=True)\ntest[\"Date\"]= pd.to_datetime(test.Date,infer_datetime_format=True)\nworld = pd.read_csv(\"/kaggle/input/wb0904/WorldBankData.csv\")\nfor col in world.columns[1:]:\n    avgcol= world[col].mean()\n    world.loc[world[col]==0,col]=avgcol\n\npop = pd.read_csv(\"/kaggle/input/pop1204/Population11.04.2020.csv\")\nsample_sub = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\nold_cols = sample_sub.columns\nsample_sub.columns=[\"Id\",\"Case\",\"Death\"]\nmysub=sample_sub.set_index('Id')\n\ntrain[\"Test\"]=0\ntest[\"Test\"]=1\n\nX_full = pd.concat((train[train.Date < \"2020-04-02\"], test[test.Date >= \"2020-04-02\"]),sort=True).reset_index(drop=True)\n\nX_full[\"Reg\"]=X_full[\"Ctry\"]+X_full[\"Prov\"].fillna(\"None\")\npop[\"Reg\"]=pop[\"Ctry\"]+pop[\"Prov\"].fillna(\"None\")\n\nX_full= X_full.merge(world, on=[\"Ctry\"],how=\"left\")\nX_full= X_full.merge(pop[[\"Pop\",\"Reg\"]], on=[\"Reg\"],how=\"left\")\n\nX_full.loc[:,\"GDPPerc\"]= X_full.GDPPerc.astype(\"float\")\nX_full.loc[:,\"GDPperCapita\"]= X_full.GDPperCapita.astype(\"float\")\nX_full.loc[X_full.GDPperCapita == 0,\"GDPperCapita\"]=10000\n    \nX_full.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit linear regression model to log of case numbers "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n\n\ndef model_fit(model,X,target_col,folds=3):\n    \n    kf = KFold(folds, shuffle=True, random_state=4991)\n    \n    drop_cols = set(X.columns).intersection({\"Test\",\"Id\",\"Cases\",\"Death\",\"LogD\",\"Week\",\"Day\",\"Date\",\"Prov\",\"FirstDate\",\"DayYear\",\"Sub\",\"Ctry\",\"Pop\",target_col})\n    \n    # create predictors for each region\n    \n    X_r=X\n    X_r =pd.get_dummies(X.copy(),columns=[\"Reg\"])\n    \n    # add an indicator for countries/states with a significant number of cases\n    \n    for col in X_r.columns:\n        if col[:4]== \"Reg_\":\n            reg = col[4:]\n            if X.loc[(X.Reg==reg) & (X.DayYear == (100)),\"Cases\"].mean() > 250:\n                X_r[col+\"1\"]=X_r[\"Week1\"]*X_r[col]\n                X_r[col+\"2\"]=X_r[\"Week2\"]*X_r[col]\n                X_r[col+\"3\"]=X_r[\"Week3\"]*X_r[col]\n                          \n    \n    # add interactions with health spending indicators \n    # the relationship is very weak but I have kept these features in the model for now\n    \n    inter_features ={\"DollarPPP\",\"GDPPerc\",\"Week1\",\"Week2\",\"Week3\",\"Age65Perc\",\"GDPperCapita\",\"LogPop\"}.difference(set(drop_cols)).intersection(set(X.columns)) \n    poly = PolynomialFeatures(degree=2,include_bias=False) \n    inter_cols = poly.fit_transform(X[inter_features])\n    X1= pd.DataFrame(inter_cols,columns= poly.get_feature_names(list(inter_features)),index=X.index)                            \n    X_r = pd.concat([X1,X_r.drop(columns=inter_features)],axis=1)\n    \n    X_train = X_r[X_r.Test==0].drop(columns=drop_cols).copy()\n    \n    y_train = X.loc[X_r.Test==0,target_col]\n    model.fit(X_train,y_train)\n    X[\"Pred\"] = np.maximum(model.predict(X_r.drop(columns=drop_cols)),0)\n    X[\"Res\"]= X.Pred-X[target_col]\n    score = (-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))**0.5\n    \n    return X, score\n\n\nmodel =Ridge(alpha=0.0065,random_state=35591,max_iter=10000,fit_intercept=True,normalize=True)\n\n\ngraph = []\n\n# create separate predictions for the public and private leaderboard (i.e. remove values from 1/4 from public submission)\n\nfor loop in [\"Public\",\"Private\"]:\n    \n    X_all=X_full.copy()\n    if loop == \"Public\":\n        start=78+14 # last day of train data \n        val_end=91+14 # end date for validation data (public submission only )\n        sub_start=79+14\n        sub_end=92+14\n        startint= 85 # fit more recent data only - this is a key parameter\n    \n        X_all.loc[:,\"Test\"] = (X_all.Date > \"2020-04-01\") *1\n        \n    else:\n        start=91+15\n        sub_start=93+14\n        sub_end=999\n        X_all.loc[:,\"Test\"] = (X_all.Date > \"2020-04-15\") *1 \n        val_end=88+14\n        startint= 95 # fit more recent data only - this is a key parameter\n    \n    last_train = \"2020-04-15\"    \n    X_all.loc[(X_all.Date > \"2020-04-01\") & (X_all.Date <= last_train),\"Cases\"]=train.loc[\n        (train.Date > \"2020-04-01\") & (train.Date <= last_train),\"Cases\"].values\n    X_all.loc[(X_all.Date > \"2020-04-01\") & (X_all.Date <= last_train),\"Death\"]=train.loc[\n        (train.Date > \"2020-04-01\") & (train.Date <= last_train),\"Death\"].values\n    \n    # select as start day of the analysis: first day with 50+ cases or a recorded death\n    \n    X_reg= X_all[~((X_all.Test ==0) & (X_all.Cases < 50) & (X_all.Death<=0))].copy()\n    X_reg[\"Date\"]= pd.to_datetime(X_reg.Date,infer_datetime_format=True)\n    first_p_map= X_reg[[\"Reg\",\"Date\"]].groupby(\"Reg\").min().to_dict()[\"Date\"]\n    X_reg[\"FirstDate\"]=X_reg[\"Reg\"].map(first_p_map)\n    \n    X_reg[\"Day\"]=(X_reg.Date-X_reg.FirstDate).dt.days\n    X_reg[\"Week\"]=X_reg.Day/7\n    X_reg[\"DayYear\"]=X_reg.Date.dt.dayofyear\n    \n    \n    X_reg[\"LogC\"]= np.log(X_reg.Cases+1)\n    X_reg[\"LogD\"]= np.log(X_reg.Death+1)\n    X_reg[\"LogPop\"]=np.log(X_reg.Pop+1)\n\n    X_reg[\"Week1\"]=np.tanh((X_reg.Week)/10)\n    X_reg[\"Week2\"]=np.tanh((X_reg.Week)/10*3)\n    X_reg[\"Week3\"]=np.tanh((X_reg.Week)/10*5)\n    X_reg[\"Week4\"]=np.tanh((X_reg.Week-1)/10)\n    X_reg[\"Week5\"]=np.tanh((X_reg.Week-3)/10)\n    X_reg[\"Week6\"]=np.tanh((X_reg.Week-5)/10)\n    \n    \n    X_reg[\"Sub\"]=loop\n    \n    X= X_reg.copy()\n    print(\"\\nLast day of year for train\",start,\": \",X.loc[X.DayYear== start,\"Date\"].min())\n    print(\"First day of year for test\",start+1,\": \",X.loc[X.Test == 1,\"Date\"].min())\n    \n    \n    # fit regressmodel to log of cases to align with evaluation metric\n    \n    X_res, score = model_fit(model,X.loc[(X.DayYear >= startint)].copy(),\"LogC\")\n    X.loc[(X.DayYear >= startint),\"PredC\"]=np.exp(X_res.Pred)-1\n    \n    print(\"\\nCV score: \",score,\"\\nMean: {:.4f} Std: {:.4f}\\n\".format(score.mean(), score.std()))\n    \n    # Scale predicted cases to the number of cases on the final day of the train data \n    # Derive the mortality rate based on deaths and predicted cases at the final day in the train data\n    # Model does not allow for expected time lag between cases and deaths, which could be significant limitation\n    \n    maptab = pd.DataFrame(None,index=list(set(X.Reg)))\n    maptab[\"CaseScaler\"]=0\n    maptab[\"MortScaler\"]=0\n    \n    for reg in set(X.Reg):        \n        \n        Xslice = X[(X.Reg==reg) & (X.Test==0) & (X.DayYear == start)]\n\n        if len(Xslice) > 0:\n            if Xslice[\"PredC\"].mean() > 0:\n                maptab.loc[reg,\"CaseScaler\"] = Xslice[\"Cases\"].mean()/Xslice[\"PredC\"].mean()\n                # also set a maximum mortality rate to adjust outliers\n                maptab.loc[reg,\"MortScaler\"]= np.minimum(Xslice[\"Death\"].mean()/Xslice[\"Cases\"].mean(),0.10)\n        \n        # add adjustments for missing data and set minimum mortality rate                \n        \n        elif len(X_all[(X_all.Reg==reg) & (X_all.Test==0) & (X_all.Cases > 0)]) > 0:\n            maxcase = X_all.loc[(X_all.Reg==reg) & (X_all.Test==0) & (X_all.Cases > 0),\"Cases\"].max()\n            maptab.loc[reg,\"CaseScaler\"]=maxcase/X.loc[(X.Reg==reg) &(X.Test==1),\"PredC\"].min()\n            maptab.loc[reg,\"MortScaler\"]=0.01\n        else:\n            maptab.loc[reg,\"CaseScaler\"]=0\n            maptab.loc[reg,\"MortScaler\"]=0.01\n    \n    \n    X.loc[:,\"PredC\"]= X.loc[:,\"Reg\"].map(maptab[\"CaseScaler\"].to_dict())*X.loc[:,\"PredC\"]\n    X[\"MortS\"]=X.loc[:,\"Reg\"].map(maptab[\"MortScaler\"].to_dict())\n    \n    # apply a rough adjustment to expected minimum death rate (= rate per number of postive cases, not per population) for lower income countries\n    \n    X.loc[X.GDPperCapita >=5000,\"PredD\"]= np.maximum(X.loc[:,\"Reg\"].map(maptab[\"MortScaler\"].to_dict())*X.loc[:,\"PredC\"],0.0008*X[\"PredC\"]) \n    X.loc[X.GDPperCapita <5000,\"PredD\"]= np.maximum(X.loc[:,\"Reg\"].map(maptab[\"MortScaler\"].to_dict())*X.loc[:,\"PredC\"],0.002*X[\"PredC\"]) \n    \n    # cap overall cases at 20% of population\n    # cap mortality at 10% of maximum infected population \n    \n    X.fillna(0,inplace=True)\n    X.loc[:,\"PredC\"]=np.minimum(X.Pop * 0.2,X.PredC)\n    X.loc[:,\"PredD\"]=np.minimum(np.minimum(X.Pop * 0.02,X.PredD),0.2*X.PredC)\n    \n    X[\"ResLC\"] = np.log(X.PredC+1)-X.LogC\n    X[\"ResLD\"] = np.log(X.PredD+1)-X.LogD\n    X[\"ResLC2\"]=X.ResLC**2\n    X[\"ResLD2\"]=X.ResLD**2\n\n    \n    if len(graph) == 0: graph=X.copy()\n    else: graph = pd.concat([graph,X])\n    \n    res_def=X[(X.DayYear >= sub_start) & (X.DayYear <= sub_end)].copy()\n    mysub = mysub.combine_first(res_def.set_index('Id')[[\"PredC\",\"PredD\"]])\n    if loop == \"Public\": \n        print(X.loc[(X.DayYear > start) & (X.DayYear <=val_end),[\"ResLC\",\"ResLD\",\"PredC\",\"PredD\"]].describe())\n        print(\"\\n\",loop,\" submission - Score: \",np.sqrt(X.loc[(X.DayYear > start) & (X.DayYear <=val_end),[\"ResLC\",\"ResLD\"]].var().mean())) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Public and private submission for selected countries "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = px.scatter(graph[graph.Reg==\"AustriaNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"RussiaNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"NigeriaNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"BarbadosNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"MaldivesNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"SwedenNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"United KingdomNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"USNew York\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Graph for all countries "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(graph.loc[graph.Sub==\"Private\",[\"PredC\",\"PredD\",\"Date\"]].groupby(\"Date\").sum().reset_index(), x='Date', y='PredD')\nfig.show()\nfig = px.scatter(graph.loc[graph.Sub==\"Public\",[\"PredC\",\"PredD\",\"Date\"]].groupby(\"Date\").sum().reset_index(), x='Date', y='PredD')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"mysub.drop(columns =[\"Case\",\"Death\"],inplace=True)\nmysub.insert(0,\"Id\",mysub.index)\nmysub.columns=old_cols\nmysub.fillna(0,inplace=True)\nmysub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}