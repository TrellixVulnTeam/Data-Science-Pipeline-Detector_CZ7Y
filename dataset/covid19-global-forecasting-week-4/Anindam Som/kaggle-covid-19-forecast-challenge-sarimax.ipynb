{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Kaggle COVID - 19 forecast challenge"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing necessary packages\nimport numpy as np\nimport pandas as pd\nimport math as m\nimport time\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport datetime as dt\nfrom itertools import product\nfrom collections import Counter\nfrom matplotlib.pylab import rcParams\nfrom sklearn.metrics import r2_score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\nfrom statistics import stdev\nimport re\nfrom category_encoders import *\nfrom datetime import timedelta\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom scipy.stats import norm\n\n# Importing SARIMA packages\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# To visualise all the columns in a dataframe\npd.pandas.set_option('display.max_columns', None)\n\n# Setting maximum row numbers\npd.set_option('display.max_rows', 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the dataset\n\ndata_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ndata_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\n\nprint(data_train.shape)\nprint(data_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for Null values\ndata_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting feature 'Date' into datetime format\n\ndata_train['Date'] = pd.to_datetime(data_train['Date'])\n\n# Creating new feature column - 'Countries_Province'\ndata_train['Countries_Province'] = data_train['Country_Region']+data_train['Province_State'].fillna('')\ndata_test['Countries_Province'] = data_test['Country_Region']+data_test['Province_State'].fillna('')\n\nprint(data_train.shape)\nprint(data_test.shape)\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic EDA\n\nprint('Unique count of ID :',len(data_train['Id'].unique()))\nprint('\\n')\nprint('Unique count of Country_Region :',len(data_train['Country_Region'].unique()))\nprint('\\n')\nprint('Minimum Date :',data_train['Date'].min())\nprint('\\n')\nprint('Maximum Date :',data_train['Date'].max())\nprint('\\n')\nprint(\"Unique count of Countries_Province :\",len(data_train['Countries_Province'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping feature Id and Province_State\n\ndata_train.drop(['Id','Province_State'],axis = 1,inplace = True)\n\nprint(data_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking distribution along 25%,50%,75% percentiles\ndata_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization -- Worldwide\n\nd = data_train.groupby(data_train['Date']).sum()\nd.plot(figsize = (15,6));\nplt.ylabel('Sum');\nplt.title('Summary of COVID 19 cases Worldwide');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization -- US\n\ndf_usa = data_train.loc[data_train['Country_Region']== 'US']\ndf_usa = df_usa.groupby(df_usa['Date']).sum()\ndf_usa.plot(figsize = (15,6));\nplt.ylabel('Sum');\nplt.title('Summary of COVID 19 cases for US');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization -- Italy\n\ndf_ita = data_train.loc[data_train['Country_Region']== 'Italy']\ndf_ita = df_ita.groupby(df_ita['Date']).sum()\ndf_ita.plot(figsize = (15,6));\nplt.ylabel('Sum');\nplt.title('Summary of COVID 19 cases for Italy');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization -- Spain\n\ndf_spain =  data_train[data_train.Country_Region=='Spain'].groupby('Date')['ConfirmedCases','Fatalities'].sum()\ndf_spain.plot(figsize = (15,6));\nplt.ylabel('Sum');\nplt.title('Summary of COVID 19 cases for Spain');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization -- India\n\ndf_ind = data_train.loc[data_train['Country_Region']== 'India']\ndf_ind = df_ind.groupby(df_ind['Date']).sum()\ndf_ind.plot(figsize = (15,6));\nplt.ylabel('Sum');\nplt.title('Summary of COVID 19 cases for India');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram plot of Confirmed cases worldwide\nplt.figure(figsize=(15,6));\nplt.xticks(rotation = 30)\nsb.distplot(d['ConfirmedCases'],kde = False,color=\"g\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram plot of Fatalities cases worldwide\nplt.figure(figsize=(15,6));\nplt.xticks(rotation = 30)\nsb.distplot(d['Fatalities'],kde = False,color=\"b\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stationarity Check\nfrom statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') \n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          \n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dickey Fuller test for feature 'ConfirmedCases'\nadf_test(data_train['ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dickey Fuller test for feature 'Fatalities'\nadf_test(data_train['Fatalities'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting the index\n\ndata_train.index = data_train['Date']\n\nstart_date = '2020-04-02'\nend_date = '2020-05-14'\n\ncountries_pr = data_train['Countries_Province'].unique()\n\n# Training & Prediction\n\ncolumn_names = ['Country','ConfirmedCases','Fatalities']\ndata_predict = pd.DataFrame(columns = column_names)\ndata_result = pd.DataFrame()\n\n\nfor value in countries_pr:\n    #print(\"Country :\",value)\n    \n    data_sarima = data_train[(data_train['Countries_Province'] == value)]\n    sarima1 = SARIMAX(data_sarima['ConfirmedCases'],order=(2,1,0),freq = 'D',enforce_stationarity=False, enforce_invertibility=False).fit()                       \n    sarima2 = SARIMAX(data_sarima['Fatalities'],order=(2,1,0),freq = 'D',enforce_stationarity=False, enforce_invertibility=False).fit()                        \n    \n    pred1 = sarima1.predict(start_date,end_date) \n    #pred1 = (np.exp(pred1)-1)\n    pred2 = sarima2.predict(start_date,end_date)\n    #pred2 = (np.exp(pred2)-1)\n    \n    data_predict['ConfirmedCases'] = round(pred1)\n    \n    data_predict['Fatalities'] = round(pred2)\n    \n    data_predict['Country'] = value\n    \n    data_result = data_result.append(data_predict,sort = True)\n    \n    data_predict = data_predict[0:0]  # Resetting the dataframe\n    \n#print('Prediction for Confirmed Cases :',pred1)\n#print('Prediction for Fatalities :',pred2)\nprint('Shape of the dataframe :',data_result.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submissions\n\ndata_result['ForecastId'] = range(1,13460)\n\ndf = data_result[['ForecastId','ConfirmedCases','Fatalities']]\n\ndf.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}