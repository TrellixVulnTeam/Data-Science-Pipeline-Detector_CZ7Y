{"cells":[{"metadata":{},"cell_type":"markdown","source":"This combines a few COVID datasets to try to predict the number of new cases per thousand people in geographic areas for which we have data.\n\nDesired features:\n- cases per thousand\n- new cases per thousand over the last week\n- tests per thousand\n- tests % positive\n- days of quarantine\n- days of school closures\n- days of public closures\n- days of gathering limits\n- density (missing state level data)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\npd.set_option(\"display.max_columns\", 1000)\npd.set_option(\"display.max_rows\", 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\", parse_dates=['Date'])\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\", parse_dates=['Date'])\ncountryinfo = pd.read_csv(\n    \"../input/countryinfo/covid19countryinfo.csv\", \n    parse_dates=['quarantine', 'schools', 'publicplace', 'nonessential', 'gathering']\n)\ncountryinfo['pop'] = countryinfo['pop'].apply(lambda x: float(str(x).replace(',', '')))\nstates = pd.read_csv(\"../input/covid19-in-usa/us_states_covid19_daily.csv\", parse_dates=['date'])\nstate_pops = pd.read_csv(\"../input/us-state-populations-2018/State Populations.csv\")\nstate_abbr = pd.read_csv(\"../input/state-abbreviations/state_abbrev.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# pick out regions with more than 1000 cases on April 12th\nfiltered = (\n    train[\n        (train[\"Date\"] == \"2020-04-12\") &\n        (train['ConfirmedCases'] > 1000)\n    ]\n)[['Country_Region', 'Province_State']]\nprint(f'Found {len(filtered)} matching regions')\n\ndataset = train.merge(\n    filtered,\n    on=['Country_Region', 'Province_State']\n)[train['ConfirmedCases'] > 100]\n\ndataset[train[\"Date\"] == \"2020-04-12\"]\\\n.sort_values(by=['ConfirmedCases'], ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge datasets\nmerged = dataset.merge(\n    countryinfo, \n    left_on=['Country_Region', 'Province_State'],\n    right_on=['country', 'region'],\n    how='left'\n).merge(\n    state_pops,\n    left_on=['Province_State'],\n    right_on=['State'],\n    how='left'\n).merge(\n    state_abbr,\n    left_on=['Province_State'],\n    right_on=['State'],\n    how='left'\n).merge(\n    states,\n    left_on=['Abbreviation', 'Date'],\n    right_on=['state', 'date'],\n    how='left'\n)\n# print(merged[merged[\"Country_Region\"] == \"Italy\"].head(10))\nmerged['pop'].fillna(merged['2018 Population'], inplace=True)\nmerged['tests'].fillna(merged['posNeg'], inplace=True)\nmerged['Province_State'].fillna('', inplace=True)\n# these are all shut as well if there is a quarantine\nmerged['nonessential'].fillna(merged['quarantine'], inplace=True)\nmerged['publicplace'].fillna(merged['quarantine'], inplace=True)\nmerged['gathering'].fillna(merged['quarantine'], inplace=True)\nmerged['schools'].fillna(merged['quarantine'], inplace=True)\nmerged = merged[[\n    'Country_Region', 'Province_State', 'Date', 'ConfirmedCases', 'density',\n    'tests', 'pop', 'quarantine', 'schools', 'publicplace', 'nonessential', 'gathering']]\nmerged['CasesPerK'] = merged['ConfirmedCases'] / merged['pop'] * 1000\nmerged['TestsPerK'] = merged['tests'] / merged['pop'] * 1000\nmerged['TestsPositive'] = merged['ConfirmedCases'] / merged['tests']\nmerged = merged[(merged[\"tests\"] > 100) & (merged['ConfirmedCases'] > 100)]\nmerged[merged[\"Date\"] == \"2020-04-12\"]\\\n.sort_values(by=['ConfirmedCases'], ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the daily percent increase in confirmed cases\nby_ctry_prov = merged.groupby(['Country_Region','Province_State'])[['CasesPerK']]\nmerged[['DeltaCasesPerK']]= by_ctry_prov.transform(lambda x: x.diff().fillna(0))\nby_ctry_prov = merged.groupby(['Country_Region','Province_State'])[['CasesPerK']]\nperiod = 1\nmerged[['AvgDeltaCasesPerK']]= by_ctry_prov.transform(lambda x: x.diff(periods=period).fillna(0) / period)\n# the days since restriction was added\nmerged['quarantine_days'] = (merged['Date'] - merged['quarantine']).transform(lambda x: x.days).fillna(0)\nmerged['schools_days'] = (merged['Date'] - merged['schools']).transform(lambda x: x.days).fillna(0)\nmerged['publicplace_days'] = (merged['Date'] - merged['publicplace']).transform(lambda x: x.days).fillna(0)\nmerged['nonessential_days'] = (merged['Date'] - merged['nonessential']).transform(lambda x: x.days).fillna(0)\nmerged['gathering_days'] = (merged['Date'] - merged['gathering']).transform(lambda x: x.days).fillna(0)\nfinal = merged[[\n    'Country_Region', 'Province_State', 'Date', 'DeltaCasesPerK',\n    'CasesPerK', 'TestsPerK', # 'AvgDeltaCasesPerK',\n    'quarantine_days', 'schools_days', 'publicplace_days', 'nonessential_days',\n    'gathering_days', 'TestsPositive'\n]]\n# final[final[\"Date\"] == \"2020-04-12\"].head(10)\nfinal[final[\"Country_Region\"] == \"Italy\"].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\ny = final['DeltaCasesPerK']\nX = final\ntrain_X, test_X, train_y, test_y = train_test_split(\n    X.as_matrix(), y.as_matrix(), test_size=0.25)\ntrain_index = train_X[:,:4]\ntrain_X = train_X[:,4:]\ntest_index = test_X[:,:4]\ntest_X = test_X[:,4:]\nmy_model = XGBRegressor(n_estimators=100, max_depth=3)\n# was 0.0698 before parameters, bounces around with each run\nmy_model.fit(train_X, train_y, verbose=False)\npredictions = my_model.predict(test_X)\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, test_y)))\noutput = pd.DataFrame(data=test_X, columns=X.columns[4:])\noutput['DeltaCasesActual'] = test_y\noutput['DeltaCasesPrediction'] = predictions\noutput['Country_Region'] = test_index[:,0]\noutput['Province_State'] = test_index[:,1]\noutput['Date'] = test_index[:,2]\noutput.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot cases (y) by feature value (X)\nimport numpy as np\n\n# 'Country_Region', 'Province_State', 'Date', 'DeltaCasesPerK',\n# 'AvgDeltaCasesPerK',\nfeatures = ('CasesPerK', 'TestsPerK',\n    'quarantine_days', 'schools_days', 'publicplace_days', 'nonessential_days',\n    'gathering_days', 'TestsPositive')\n\nmaximums = [5, 25, 100, 100, 100, 100, 100, 1]\n\nfor index, maximum in enumerate(maximums):\n    feature_X = np.array([[.5, 2.5, 20, 20, 20, 20, 20, 0.2]] * 100)\n    feature_X[:, index] = np.arange(0, maximum, maximum/100)\n    feature_y = my_model.predict(feature_X)\n    plt.figure(figsize=(14,2))    \n    plt.subplot(1,2,1)\n    plt.plot(feature_X[:, index], feature_y)\n    plt.title(features[index])\n    plt.ylabel('DeltaCases')\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}