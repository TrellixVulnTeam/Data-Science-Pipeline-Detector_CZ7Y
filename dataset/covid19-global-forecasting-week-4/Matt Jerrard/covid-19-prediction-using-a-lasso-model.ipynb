{"cells":[{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"1.-Introduction-1\">1. Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1.-Aim\" data-toc-modified-id=\"1.1.-Aim-1.1\">1.1. Aim</a></span></li><li><span><a href=\"#1.2.-Background\" data-toc-modified-id=\"1.2.-Background-1.2\">1.2. Background</a></span></li><li><span><a href=\"#1.3.-A-Note-on-the-Kaggle-Challenge\" data-toc-modified-id=\"1.3.-A-Note-on-the-Kaggle-Challenge-1.3\">1.3. A Note on the Kaggle Challenge</a></span></li></ul></li><li><span><a href=\"#2.-Data-Understanding\" data-toc-modified-id=\"2.-Data-Understanding-2\">2. Data Understanding</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.-Data-Source\" data-toc-modified-id=\"2.1.-Data-Source-2.1\">2.1. Data Source</a></span></li><li><span><a href=\"#2.2.-Initial-Look-at-the-Data\" data-toc-modified-id=\"2.2.-Initial-Look-at-the-Data-2.2\">2.2. Initial Look at the Data</a></span></li><li><span><a href=\"#2.3.-Data-Reliability\" data-toc-modified-id=\"2.3.-Data-Reliability-2.3\">2.3. Data Reliability</a></span></li></ul></li><li><span><a href=\"#3.-Data-Preparation\" data-toc-modified-id=\"3.-Data-Preparation-3\">3. Data Preparation</a></span></li><li><span><a href=\"#4.-Data-Analysis-and-Visualisation\" data-toc-modified-id=\"4.-Data-Analysis-and-Visualisation-4\">4. Data Analysis and Visualisation</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1.-Worst-Affected-Countries-by-Number-of-Confirmed-Cases\" data-toc-modified-id=\"4.1.-Worst-Affected-Countries-by-Number-of-Confirmed-Cases-4.1\">4.1. Worst Affected Countries by Number of Confirmed Cases</a></span></li><li><span><a href=\"#4.2.-Progression-of-the-Virus-in-Different-Countries\" data-toc-modified-id=\"4.2.-Progression-of-the-Virus-in-Different-Countries-4.2\">4.2. Progression of the Virus in Different Countries</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.2.1.-United-Kingdom\" data-toc-modified-id=\"4.2.1.-United-Kingdom-4.2.1\">4.2.1. United Kingdom</a></span></li><li><span><a href=\"#4.2.2.-South-Korea\" data-toc-modified-id=\"4.2.2.-South-Korea-4.2.2\">4.2.2. South Korea</a></span></li></ul></li></ul></li><li><span><a href=\"#5.-Modelling-and-Prediction\" data-toc-modified-id=\"5.-Modelling-and-Prediction-5\">5. Modelling and Prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1.-Approach\" data-toc-modified-id=\"5.1.-Approach-5.1\">5.1. Approach</a></span></li><li><span><a href=\"#5.2.-Engineering-a-Feature-for-Social-Distancing\" data-toc-modified-id=\"5.2.-Engineering-a-Feature-for-Social-Distancing-5.2\">5.2. Engineering a Feature for Social Distancing</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.2.1.-Social-Distancing-as-a-Binary-Value\" data-toc-modified-id=\"5.2.1.-Social-Distancing-as-a-Binary-Value-5.2.1\">5.2.1. Social Distancing as a Binary Value</a></span></li></ul></li><li><span><a href=\"#5.3.-Engineering-Features-for-New-Cases,-New-Fatalities-and-Active-Cases\" data-toc-modified-id=\"5.3.-Engineering-Features-for-New-Cases,-New-Fatalities-and-Active-Cases-5.3\">5.3. Engineering Features for New Cases, New Fatalities and Active Cases</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.3.1.-New-Cases\" data-toc-modified-id=\"5.3.1.-New-Cases-5.3.1\">5.3.1. New Cases</a></span></li><li><span><a href=\"#5.3.2.-New-Fatalities\" data-toc-modified-id=\"5.3.2.-New-Fatalities-5.3.2\">5.3.2. New Fatalities</a></span></li><li><span><a href=\"#5.3.3.-Active-Cases\" data-toc-modified-id=\"5.3.3.-Active-Cases-5.3.3\">5.3.3. Active Cases</a></span></li></ul></li><li><span><a href=\"#5.4.-Accounting-for-Lag-in-the-Data\" data-toc-modified-id=\"5.4.-Accounting-for-Lag-in-the-Data-5.4\">5.4. Accounting for Lag in the Data</a></span></li><li><span><a href=\"#5.5.-Time-Series-Prediction--using-a-Regression-Model\" data-toc-modified-id=\"5.5.-Time-Series-Prediction--using-a-Regression-Model-5.5\">5.5. Time Series Prediction  using a Regression Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.5.1.-Approach\" data-toc-modified-id=\"5.5.1.-Approach-5.5.1\">5.5.1. Approach</a></span></li><li><span><a href=\"#5.5.2.-Training-the-&quot;Public&quot;-Model-for-Confirmed-Cases\" data-toc-modified-id=\"5.5.2.-Training-the-&quot;Public&quot;-Model-for-Confirmed-Cases-5.5.2\">5.5.2. Training the \"Public\" Model for Confirmed Cases</a></span></li><li><span><a href=\"#5.5.3.-Training-the-&quot;Public&quot;-Model-for-Fatalities\" data-toc-modified-id=\"5.5.3.-Training-the-&quot;Public&quot;-Model-for-Fatalities-5.5.3\">5.5.3. Training the \"Public\" Model for Fatalities</a></span></li><li><span><a href=\"#5.5.4.-Prediction-for-the-&quot;Public&quot;-Model\" data-toc-modified-id=\"5.5.4.-Prediction-for-the-&quot;Public&quot;-Model-5.5.4\">5.5.4. Prediction for the \"Public\" Model</a></span></li><li><span><a href=\"#5.5.5.-Training-the-&quot;Private&quot;-Model-for-Confirmed-Cases\" data-toc-modified-id=\"5.5.5.-Training-the-&quot;Private&quot;-Model-for-Confirmed-Cases-5.5.5\">5.5.5. Training the \"Private\" Model for Confirmed Cases</a></span></li><li><span><a href=\"#5.5.6.-Training-the-&quot;Private&quot;-Model-for-Fatalities\" data-toc-modified-id=\"5.5.6.-Training-the-&quot;Private&quot;-Model-for-Fatalities-5.5.6\">5.5.6. Training the \"Private\" Model for Fatalities</a></span></li><li><span><a href=\"#5.5.6.-Predictions-for-the-&quot;Private&quot;-Model\" data-toc-modified-id=\"5.5.6.-Predictions-for-the-&quot;Private&quot;-Model-5.5.7\">5.5.6. Predictions for the \"Private\" Model</a></span></li></ul></li></ul></li><li><span><a href=\"#6.-Evaluation\" data-toc-modified-id=\"6.-Evaluation-6\">6. Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1.-Evaluation-Metric---Root-Mean-Squared-Logarithmic-Error\" data-toc-modified-id=\"6.1.-Evaluation-Metric---Root-Mean-Squared-Logarithmic-Error-6.1\">6.1. Evaluation Metric - Root Mean Squared Logarithmic Error</a></span></li><li><span><a href=\"#6.2.-Discussion-of-Model-Performance\" data-toc-modified-id=\"6.2.-Discussion-of-Model-Performance-6.2\">6.2. Discussion of Model Performance</a></span></li><li><span><a href=\"#6.3.-Conclusions\" data-toc-modified-id=\"6.3.-Conclusions-6.3\">6.3. Conclusions</a></span></li><li><span><a href=\"#6.4.-Ideas-for-Further-Work\" data-toc-modified-id=\"6.4.-Ideas-for-Further-Work-6.4\">6.4. Ideas for Further Work</a></span></li></ul></li><li><span><a href=\"#7.-References\" data-toc-modified-id=\"7.-References-7\">7. References</a></span></li></ul></div>"},{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Prediction"},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"### 1.1. Aim"},{"metadata":{},"cell_type":"markdown","source":"The aim of this project is to predict the spread of the COVID-19 virus and identify what factors influence its spread.\n\nThe author makes no claim to be an expert in any branch of medicine or related fields. There are many good sources of information about what to do in the current COVID-19 crisis, for example here: https://www.gov.uk/coronavirus and in the References section below.\n\nThe author has absolutely no wish to trivialise this extremely serious situation. This is a project seeking to further our collective understanding of the virus and how it can best be stopped.\n\nThis is an ongoing project and a work in progress. The prediction model does not yet perform well, there are still many improvements to be made."},{"metadata":{},"cell_type":"markdown","source":"### 1.2. Background"},{"metadata":{},"cell_type":"markdown","source":"Virus COVID-19 first emerged iin China in late 2019. Since then it has spread around the world and the World Health Organisation declared it a pandemic on 12th March 2020. On the 31st March 2020, there have been more than 850000 confirmed cases and over 42000 fatalities worldwide."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Matplotlib converters\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# For handling time/date series\nfrom datetime import datetime, time, timedelta, date\n\n# For modeling\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\n# Evaluation - RMSLE\nfrom sklearn.metrics import mean_squared_log_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3. A Note on the Kaggle Challenge"},{"metadata":{},"cell_type":"markdown","source":"Kaggle are running a number of challenges aimed at furthering understanding of the virus through data analysis. This notebook produces the required output for one of these challenges (https://www.kaggle.com/c/covid19-global-forecasting-week-4). The purpose of this challenge is to understand the factors that influence the spread of the virus by data anlysis, modelling and prediction.\n\nThere are two sets of predictions required for the Kaggle challenge:\n\n1) \"Public\" predictions. These must come from a model trained only with data prior to 2020-04-01, and the predictions should encompass cumulative numbes of Confirmed Cases and Fatalities from 2020-04-02 to 2020-04-15.\n\n2) \"Private\" predictions. These can be trained with all data available up to the present day, and the predictions should encompass cumulative numbes of Confirmed Cases and Fatalities from 2020-04-16 to 2020-05-14.\n\nThis is required for the Kaggle challenge rules, and to make a valid submission to Kaggle. It allows Kaggle to make a \"public leaderboard\" for the earlier date range and a \"private leaderboard\" for the later date range.\n\nFor this reason, the following definitions describe the date windows for public and private model training and predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"LAST_PUB_TRAIN_DATE = datetime(2020, 3, 31)\nFIRST_PUB_PRED_DATE = LAST_PUB_TRAIN_DATE + timedelta(1)\nFIRST_STORED_PUB_PRED_DATE = datetime(2020, 4, 2)\nLAST_PUB_PRED_DATE = datetime(2020, 4, 15)\n\nLAST_PRIV_TRAIN_DATE = datetime(2020, 4, 9)\nFIRST_PRIV_PRED_DATE = LAST_PRIV_TRAIN_DATE + timedelta(1)\nFIRST_STORED_PRIV_PRED_DATE = datetime(2020, 4, 16)\nLAST_PRIV_PRED_DATE = datetime(2020, 5, 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Understanding"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Data Source"},{"metadata":{},"cell_type":"markdown","source":"* Kaggle:\nhttps://www.kaggle.com/c/covid19-global-forecasting-week-4\n\n* Live dashboard:\nhttps://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6\n\n* Database:\nhttps://github.com/CSSEGISandData/COVID-19"},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Initial Look at the Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do a \"sanity check\" on the output file - check the number of unique country/province pairs we need to predict for."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_province_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\nprint(\"Number of unique province_country groups in test file: {}\".format(\n    len(test_province_country_groups.groups.keys())))\n\nprovince_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\nprint(\"Number of unique province_country groups in training file: {}\".format(\n    len(province_country_groups.groups.keys())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of unique combinations of Province_State and Country_Region is equal in both the train and test files. "},{"metadata":{},"cell_type":"markdown","source":"Convert 'Date' column to type datetime, because we will use this later in the analysis."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['Date'] = pd.to_datetime(df_train['Date'], format='%Y-%m-%d')\ndf_test['Date'] = pd.to_datetime(df_test['Date'], format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Data Reliability\nFor now, we regard all the data available as reliable. However this is an oversimplification. A judgement will need to be made on the reliability of data provided by all countries. Some considerations about data reliability are:\n\n1. The amount of testing being performed. More tests will always lead to more confirmed cases, and also better reliability.\n\n2. Even the number of fatalities due to the COVID-19 may be unreliable. There can be delays in reporting the day to day figures, and according to the UK Office of National Statistics, some deaths outside of hospital may not be counted in the overall COVID-19 fatality rate at all (https://www.bbc.co.uk/news/health-52167016).\n\n3. Politics and government. It has been alleged that China, Iran and Russia have not been completely honest about their experiences of the virus (UK Government Commons Foreign Affairs Committee, reported in *The Independent* newspaper, 6th April (https://www.independent.co.uk/news/uk/politics/coronavirus-china-disinformation-commons-foreign-affairs-report-russia-iran-a9448241.html). For this reason, there are probably some countries where the data should either be regarded with scepticism."},{"metadata":{},"cell_type":"markdown","source":"## 3. Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"First check for null values."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove null values from Province_State, replacing with string \"None\"."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.loc[df_train['Province_State'].isnull(), \n             'Province_State'] = 'None'\ndf_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\nprint(\"Number of unique province_country groups in training data: {}\".format(\n    len(province_country_groups.groups.keys())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This removed the null values from Province_State but preserved all the different unique combinations of Province_State and Country_Region."},{"metadata":{},"cell_type":"markdown","source":"Do the same for df_test."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test.loc[df_test['Province_State'].isnull(), \n             'Province_State'] = 'None'\ndf_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do some basic checks on the data.\n* Make sure ConfirmedCases and Fatalities never **decrease**. If they do, correct the data point. In that case, assume the later data point is erroneous and should have the value of the earlier data point (in effect, this could overestimate the number of cases).\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\nconfirmed_cases_list = []\nfor p_c in province_country_groups.groups.keys():\n    #print(p_c)\n    confirmed_cases_list = province_country_groups.get_group(p_c)['ConfirmedCases'].tolist()\n    corrected = False\n    for i in range(len(confirmed_cases_list)-1):\n    #for i in range(len(confirmed_cases_list) - 1):\n        # Detect a data error\n        if (confirmed_cases_list[i] > confirmed_cases_list[i+1]):\n            # Correct a one-off low data point\n            try:\n                if (confirmed_cases_list[i] <= confirmed_cases_list[i+2]):\n                    print('Correcting low data point. Replaced {0} with {1} for country/province {2}'.format(\n                      confirmed_cases_list[i+1],\n                      confirmed_cases_list[i],\n                      p_c))\n                    confirmed_cases_list[i+1] = confirmed_cases_list[i]\n                # Correct a one-off high data point\n                else:\n                    if (confirmed_cases_list[i-1] <= confirmed_cases_list[i+1]):\n                        print('Correcting high data point. Replaced {0} with {1} for country/province {2}'.format(\n                          confirmed_cases_list[i],\n                          confirmed_cases_list[i-1],\n                          p_c))\n                        confirmed_cases_list[i] = confirmed_cases_list[i-1]\n                    else:\n                        print('Not able to correct an erroneous point for for country/province {0} automatically'.format(p_c))\n            # Where there is no data point at i+2, i.e. i is penultimate\n            except IndexError:\n                print('Correcting penultimate data point. Replaced {0} with {1} for country/province {2}'.format(\n                      confirmed_cases_list[i+1],\n                      confirmed_cases_list[i],\n                      p_c))\n                confirmed_cases_list[i+1] = confirmed_cases_list[i]\n            corrected = True\n    if corrected == True:\n        print(\"Correcting for country/province {0}\".format(p_c))\n        df_train.loc[(df_train['Country_Region'] == p_c[1]) &\n                     (df_train['Province_State'] == p_c[0]), 'ConfirmedCases'] = confirmed_cases_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a few places where automatic corection wasn't possible.\n\nThese are currenly places with smaller numbers so for now, leave these."},{"metadata":{},"cell_type":"markdown","source":"## 4. Data Analysis and Visualisation"},{"metadata":{},"cell_type":"markdown","source":"### 4.1. Worst Affected Countries by Number of Confirmed Cases"},{"metadata":{"trusted":false},"cell_type":"code","source":"date_range = df_train['Date']\nday_groups = df_train.groupby('Date')\nlatest = day_groups.get_group((max(date_range)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"worst_affected = latest.sort_values(by = 'ConfirmedCases', ascending = False).head(20)\nworst_affected.drop(columns = ['Id', 'Date'], inplace=True)\nworst_affected","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be as precise as possible, and deal with smaller geographical areas, create a list of the smallest usable region for each item in the worst_affected list. This will be the 'Province_State' value if it is not 'None', otherwise it will be the 'Country_Region'."},{"metadata":{"trusted":false},"cell_type":"code","source":"worst_affected_locations = [worst_affected['Province_State'].iloc[i] if (worst_affected['Province_State'].iloc[i] != 'None') else\n                    worst_affected['Country_Region'].iloc[i] for i in range(len(worst_affected))]\nworst_affected_locations","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18, 9))\nplt.bar(worst_affected_locations, worst_affected['ConfirmedCases'])\nplt.title('Number of Confirmed Cases in the 20 Worst Affected Locations')\nplt.ylabel('Number of confirmed cases')\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (18, 9))\nplt.bar(worst_affected_locations, worst_affected['Fatalities'])\nplt.title('Number of Fatalities in the 20 Worst Affected Locations')\nplt.ylabel('Number of fatalities')\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some interesting differences here. Why are the fatality rates so differerent in different locations? Possible reasons:\n\n* Different standards of healthcare\n* Different demographics (e.g. age distribution of population)\n* Different amounts of testing being carried out"},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Progression of the Virus in Different Countries"},{"metadata":{},"cell_type":"markdown","source":"#### 4.2.1. United Kingdom"},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train.groupby(['Province_State', 'Country_Region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"uk_group = province_country_groups.get_group(('None', 'United Kingdom'))\nticks = list(uk_group['Date'])[0::1]\nplt.figure(figsize=(18, 9))\nplt.plot(uk_group['Date'], uk_group['ConfirmedCases'], label = 'Confirmed Cases')\nplt.plot(uk_group['Date'], uk_group['Fatalities'], label = 'Fatalities')\nplt.xticks(ticks, rotation='vertical')\nplt.xlabel('Date')\nplt.ylabel('Number of cases, number of fatalities')\nplt.legend()\nplt.title('Graph to show number of confirmed cases in the UK')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2.2. South Korea"},{"metadata":{"trusted":false},"cell_type":"code","source":"sk_group = province_country_groups.get_group(('None', 'Korea, South'))\nticks = list(sk_group['Date'])[0::1]\nplt.figure(figsize=(18, 9))\nplt.plot(uk_group['Date'], sk_group['ConfirmedCases'], label = 'Confirmed Cases')\nplt.plot(uk_group['Date'], sk_group['Fatalities'], label = 'Fatalities')\nplt.xticks(ticks, rotation='vertical')\nplt.xlabel('Date')\nplt.ylabel('Number of cases, number of fatalities')\nplt.legend()\nplt.title('Graph to show number of confirmed cases in South Korea')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's clear just by comparing these two graphs that the UK and South Korea are at very different stages of the virus crisis. This will be true for many countries."},{"metadata":{},"cell_type":"markdown","source":"## 5. Modelling and Prediction"},{"metadata":{},"cell_type":"markdown","source":"### 5.1. Approach"},{"metadata":{},"cell_type":"markdown","source":"The aim is to predict the cumulative number of confirmed cases and fatalities from the virus.\n\nTo predict the total confirmed cases on any day, we need to predict the number of new confirmed cases each day. This will be the main target value for the prediction model.\n\nFor simplicity (in a first approximate model - to be improved) assume that the model to predcit fatalities uses the same input features as the model to predict confirmed cases."},{"metadata":{},"cell_type":"markdown","source":"Adopt a simple approach for the first model with the intention of improving it later.\nVery approximately, the virus seems to follow this course:\n\n1. Day 0: Infection.\n2. Day 5: Symptoms show. The patient is now infectious.\n3. Day 10: Severe cases may require hospital treatment.\n4. Day 15: Mild cases recover. The patient is no longer infectious.\n\nSevere cases may require longer hospitalisation, perhaps several weeks.\n\n(References 5 and 6.)\n\nWith this in mind, assume a model with only two factors determining the number of new cases each day:\n\n1. The number of confirmed cases 5-15 days prior to the day of the prediction.\n\n2. Whether social distancing measures were in force in the 5-15 day period when infection would need to happen to produce a new case today. 0 if not in force, 1 if already in force.\n\nThe values in 1 and 2 above are chosen to be consistent with the 5 day incubation period. Patients who contract the virus 5 days before are likely to develop worsening symptoms over the following 5 days, and may be diagnosed any time within this period. Social distancing measures act as a brake on infection rates.\n\nThis is a first approximation to allow us to construct a simple model - it is not realistic because it does not include the many other factors that could determine the spread of the virus. However, we know that social distancing is one of the key factors that does affect the spread of the virus."},{"metadata":{},"cell_type":"markdown","source":"To construct a simple model, we will add a column to the training data indicating if government-imposed social distancing rules are in effect. This takes a value equal to the number of days since the rules came into effect (0 if no rules are in effect). This data is not available for all locations. However, we will implement the following algorithm:\n\n* For the 20 worst affected locations, try to find a date when social distancing was first imposed by the government from reliable news sources.\n* For all remaining countries, assume there is currently no social distancing in place, but that there will be at an arbitrary future date (say, 15th April).\n\nThis is an oversimplification but we will adopt this approach for now to give us a starting point. The model can be improved later."},{"metadata":{},"cell_type":"markdown","source":"First, add the SocDist (Social Distancing) column. By default, all values will be initially set to 0. Afterwards, we will adjust the values for the 20 worst affected regions to known values.\n\nLater in the modelling process the value for all locations will be set for all dates on or after 15th April."},{"metadata":{},"cell_type":"markdown","source":"### 5.2. Engineering a Feature for Social Distancing"},{"metadata":{},"cell_type":"markdown","source":"#### 5.2.1. Social Distancing as a Binary Value"},{"metadata":{},"cell_type":"markdown","source":"This is a feature simply indicating whether social distancing is in force (1) or not (1). Later, we will take account of the time lag for this to make any difference to predicted new cases."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['SocDist'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that this feature is very \"blunt\". A better feature would take account of different levels of social distancing in effect. However, it is a simple place to start and can be developed later."},{"metadata":{},"cell_type":"markdown","source":"Manually construct a list of dates when social distancing rules came into effect. Note, this list is constructed manually, and is \"best effort\" - apologies for any inaccuracies. The situation is changing fast so this will quickly become outdated. I will endeavour to keep it up to date."},{"metadata":{},"cell_type":"markdown","source":"Sources used:\n\n* Hubei - 2020-01-23 - https://www.sciencemag.org/news/2020/03/china-s-aggressive-measures-have-slowed-coronavirus-they-may-not-work-other-countries\n* Italy - 2020-03-09 - https://www.newscientist.com/article/2236864-italy-on-full-lockdown-to-slow-the-spread-of-coronavirus/\n* Spain - 2020-03-14 - https://www.ft.com/content/428babc4-66c9-11ea-800d-da70cff6e4d3\n* Germany - 2020-03-22 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* Iran - None? - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Iran\n* France - 2020-03-17 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* New York - 2020-03-15 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* Korea, South - 2020-02-25 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_South_Korea#Containment (Agressive warnings from government)\n* Switzerland - 2020-03-20 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Switzerland\n* United Kingdom - 2020-03-22 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* Netherlands - 2020-03-23 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_the_Netherlands\n* Belgium - 2020-03-17 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Belgium#'Lockdown_light'\n* Austria - 2020-03-16 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Austria\n* Norway - 2020-03-12 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Norway\n* Washington - 2020-03-15 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* Sweden - 2020-03-24 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Sweden\n* Guangdong - 2020-01-24 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic_in_mainland_China\n* California - 2020-03-15 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* New Jersey - 2020-03-15 - https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n* Denmark - 2020-03-18 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Denmark\n* Turkey - 2020-03-18 - https://en.wikipedia.org/wiki/Timeline_of_the_2020_coronavirus_pandemic_in_Turkey\n* Portugal - 2020-03-19 - https://uk.reuters.com/article/uk-health-coronavirus-portugal/portugal-restricts-movement-to-stem-coronavirus-rules-out-rationing-idUKKBN2163VP\n* Michigan - 2020-03-23 - https://windsorstar.com/news/local-news/michigan-issues-lockdown-order-as-number-of-covid-19-cases-surge-across-state/\n* Florida - Local actions (not state-wide) - https://www.wsj.com/articles/florida-unlike-other-hard-hit-states-avoids-broad-coronavirus-lockdown-11585560601\n* Massachusetts - No statewide action - https://wbsm.com/governor-baker-no-forced-covid-19-lockdown-order-planned-in-massachusetts/\n* Louisiana - 2020-03-19 - https://www.dailymail.co.uk/news/article-8140597/Ohio-Louisiana-order-residents-stay-home-slow-coronavirus-spread.html\n* Pennsylvania - 2020-03-19 - https://www.inquirer.com/health/coronavirus/spl/pennsylvania-coronavirus-shutdown-statewide-governor-tom-wolf-20200316.html\n* Brazil - 2020-03-18 - https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Brazil - But the situation in Brazil is very unclear, and social distancing measures are being urged at state/city level rather than nationally, and they are not always adhered to (https://www.ft.com/content/4cc27429-778e-4c64-9523-9b5937250485, https://uk.reuters.com/article/us-health-coronavirus-brazil-lockdown/brazil-lockdowns-attacked-by-bolsonaro-begin-to-slip-idUKKCN21R30B)."},{"metadata":{"trusted":false},"cell_type":"code","source":"socdist_dict = {('None', 'Italy'): datetime(2020, 3, 9),\n                 ('None', 'Spain'): datetime(2020, 3, 14),\n                 ('Hubei', 'China'): datetime(2020, 1, 23),\n                 ('None', 'Germany'): datetime(2020, 3, 22),\n                 ('New York', 'US'): datetime(2020, 3, 15),\n                 ('None', 'France'): datetime(2020, 3, 17),\n                 ('None', 'Iran'): datetime(2020, 12, 31),\n                 ('None', 'United Kingdom'): datetime(2020, 3, 22),\n                 ('New Jersey', 'US'): datetime(2020, 3, 15),\n                 ('None', 'Switzerland'): datetime(2020, 3, 20),\n                 ('None', 'Belgium'): datetime(2020, 3, 17),\n                 ('None', 'Netherlands'): datetime(2020, 3, 23),\n                 ('None', 'Turkey'): datetime(2020, 3, 18),\n                 ('None', 'Korea, South'): datetime(2020, 2, 25),\n                 ('None', 'Austria'): datetime(2020, 3, 16),\n                 ('California', 'US'): datetime(2020, 3, 15),\n                 ('Michigan', 'US'): datetime(2020, 3, 23),\n                 ('None', 'Portugal'): datetime(2020, 3, 19),\n                 ('Massachusetts', 'US'): datetime(2020, 12, 31),\n                 ('Florida', 'US'): datetime(2020, 12, 31),\n                 ('Louisiana', 'US'): datetime(2020, 3, 19),\n                 ('Pennsylvania', 'US'): datetime(2020, 3, 19),\n                 ('None', 'Brazil'): datetime(2020, 3, 19)\n               }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\nworst_affected_groups = worst_affected.groupby(['Province_State', 'Country_Region'])\nfor location in worst_affected_groups.groups.keys():\n    socdist_list = []\n    p_c = province_country_groups.get_group(location)\n    for i in range(p_c.shape[0]):\n        if (p_c.iloc[i]['Date'] - socdist_dict[location]).days > 0:\n            socdist_list.append(1)\n        else:\n            socdist_list.append(0)\n    \n    df_train.loc[(df_train['Country_Region'] == location[1]) &\n                 (df_train['Province_State'] == location[0]),\n                 'SocDist'] = socdist_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train[df_train['SocDist']>0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3. Engineering Features for New Cases, New Fatalities and Active Cases"},{"metadata":{},"cell_type":"markdown","source":"#### 5.3.1. New Cases"},{"metadata":{},"cell_type":"markdown","source":"NewCases is the difference between the ConfirmedCases on one day and the previous day. Predicting NewCases, rather than ConfirmedCases directly, could help the model avoid the \"persistence problem\", i.e. a tendency for a time series model to simply predict what happened in the previous time period."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['NewCases'] = 0\nprovince_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\n\nfor p_c in list(province_country_groups.groups.keys()):\n    province_country_group = province_country_groups.get_group(p_c)\n    \n    # Confirmed cases\n    df_train.loc[(df_train['Country_Region'] == p_c[1]) &\n                 (df_train['Province_State'] == p_c[0]),\n                 'NewCases'] = province_country_group['ConfirmedCases'].diff()\n\n# Replace null values with 0.\ndf_train.loc[df_train['NewCases'].isnull(), 'NewCases'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.3.2. New Fatalities"},{"metadata":{},"cell_type":"markdown","source":"NewFatalities is the difference between the Fatalities on one day and the previous day. Predicting NewFatalities, rather than Fatalities directly, could also help the model avoid the \"persistence problem\"."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['NewFatalities'] = 0\nprovince_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\n\nfor p_c in list(province_country_groups.groups.keys()):\n    province_country_group = province_country_groups.get_group(p_c)\n    \n    # Confirmed cases\n    df_train.loc[(df_train['Country_Region'] == p_c[1]) &\n                 (df_train['Province_State'] == p_c[0]),\n                 'NewFatalities'] = province_country_group['Fatalities'].diff()\n\n# Replace null values with 0.\ndf_train.loc[df_train['NewFatalities'].isnull(), 'NewFatalities'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.3.3. Active Cases"},{"metadata":{},"cell_type":"markdown","source":"ActiveCases is the sum of the number of new cases in a 10 day rolling window. 10 days is chosen to be consistent with the expected typical length of the infectious period, from start of symptoms to recovery, for mild cases."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['ActiveCases'] = 0\nprovince_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\n\nfor p_c in list(province_country_groups.groups.keys()):\n    province_country_group = province_country_groups.get_group(p_c)\n    \n    # Active cases (proxy value)\n    df_train.loc[(df_train['Country_Region'] == p_c[1]) &\n                 (df_train['Province_State'] == p_c[0]),\n                 'ActiveCases'] = province_country_group['NewCases'].rolling(10, min_periods=1).sum()\n\n# Replace null values with 0.\ndf_train.loc[df_train['ActiveCases'].isnull(), 'ActiveCases'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have now engineered features ActiveCases and SocDist and we can use these to make preictions about the number of new cases and new fatalities (NewCases, NewFatalities) every day."},{"metadata":{},"cell_type":"markdown","source":"### 5.4. Accounting for Lag in the Data"},{"metadata":{},"cell_type":"markdown","source":"It takes about 5 days for the virus to incubate and for a patient to become infected (reference 5). Therefore, to predict new cases *today*, it's neccessary to use features in the time window 5-15 days prior to today. To do this, we will engineer lagged features for ActiveCases and SocDist. Thes will be denoted:\n\n* ActiveCases-1: Active cases on day-1\n* ActiveCases-2: Active cases on day-2\n* ...\n* ActiveCases-n: Active cases on day-n\n\nWith a similar notation for SocDist.\n\nFor this problem, the range of lag values ActiveCases-5 and SocDist-5 to ActiveCases-14 and SocDist-14 are of interest, and they will be constructed here.\n\nIn addition, so that the lagged features are saved for future dates, and not simply lost, we will create a new dataframe called df_train_ex. This will include all the data in df_train, and in addition, we will insert additional rows for each province/country combination corresponding to the future dates to be used for prediction. These dates are obtained from the df_test file read in above."},{"metadata":{"trusted":false},"cell_type":"code","source":"all_training_dates = df_train['Date'].unique()\nall_testing_dates = df_test['Date'].unique()\nall_prediction_dates = np.setdiff1d(all_testing_dates, all_training_dates)\nall_prediction_dates","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now create a template data frame to insert in df_train_ex for each country:"},{"metadata":{"trusted":false},"cell_type":"code","source":"template_data = {'Id': np.nan,\n                 'Province_State': np.nan,\n                 'Country_Region': np.nan,\n                 'Date': all_prediction_dates,\n                 'ConfirmedCases': np.nan,\n                 'Fatalities': np.nan,\n                 'SocDist': np.nan,\n                 'NewCases': np.nan,\n                 'NewFatalities': np.nan,\n                 'ActiveCases': np.nan\n                }\ntemplate_df = pd.DataFrame(data=template_data)\ntemplate_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train_ex = pd.DataFrame(columns = df_train.columns)\ndf_train_ex.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train.groupby(['Province_State', 'Country_Region'])\nfor p_c in list(province_country_groups.groups.keys()):\n    province_country_group = province_country_groups.get_group(p_c)\n    df_train_ex = df_train_ex.append(province_country_group)\n    template_df['Province_State'] = p_c[0]\n    template_df['Country_Region'] = p_c[1]\n    df_train_ex = df_train_ex.append(template_df)\n    \ndf_train_ex.sort_values(by=['Country_Region', 'Province_State'], inplace=True)\ndf_train_ex.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train_ex.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the following sections updates will be made in df_train_ex."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define the lag time window.\nmax_lag=15\nmin_lag=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train_ex.groupby(['Province_State', 'Country_Region'])\n\nfor p_c in list(province_country_groups.groups.keys()):\n    province_country_group = province_country_groups.get_group(p_c)\n    for i in range (min_lag, max_lag):\n        feat = 'ActiveCases-{}'.format(str(i))\n        df_train_ex.loc[(df_train_ex['Country_Region'] == p_c[1]) &\n                 (df_train_ex['Province_State'] == p_c[0]),\n                 feat] = province_country_group['ActiveCases'].shift(i)\n\n        feat = 'SocDist-{}'.format(str(i))\n        df_train_ex.loc[(df_train_ex['Country_Region'] == p_c[1]) &\n                 (df_train_ex['Province_State'] == p_c[0]),\n                 feat] = province_country_group['SocDist'].shift(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train_ex.head(16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop the first 15 rows of data for each ['Province_State', 'Country_Region'] combination, because these will contain NaN values in the lag columns."},{"metadata":{"trusted":false},"cell_type":"code","source":"province_country_groups = df_train_ex.groupby(['Province_State', 'Country_Region'])\nto_drop = []\nfor p_c in list(province_country_groups.groups.keys()):\n    province_country_group = province_country_groups.get_group(p_c)\n    to_drop.extend(list(df_train_ex.loc[(df_train_ex['Country_Region'] == p_c[1]) &\n         (df_train_ex['Province_State'] == p_c[0])].iloc[0:14].index))\n    \ndf_train_ex.drop(index=to_drop, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.5. Time Series Prediction  using a Regression Model"},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.1. Approach"},{"metadata":{},"cell_type":"markdown","source":"The plan is to start with a simple regression model.\n\nThe walk-forward training and testing approach will be used.\n\nThe trained model will then be used to make predictions.\n\nThere is a wide spread in the range of data values. SocDist will be 1 or 0, but the number of ActiveCases could be in the tens of thousands. To help account for this wide range, data is scaled with the MinMaxScaler.\n\nSeveral experiments were conducted with the following models from SciKit-Learn:\n* LinearRegression\n* Ridge\n* Lasso\n\nThese were tried with different numbers of polynomial features.\n\nSo far, the best model seems to be Lasso with a small value of alpha and a polynomial order of just 1.\n\nThere is still more to do in experimenting with different models, so this is not a final decision - but it's OK for now."},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.2. Training the \"Public\" Model for Confirmed Cases"},{"metadata":{},"cell_type":"markdown","source":"Create a new data frame, df_train_ex_public. This is a copy of df_train_ex, excluding data values on or after 2020-04-01. This will be used to train the model for the public predictions. df_train_ex will be used for the private predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train_ex_public = df_train_ex.copy()\ndf_train_ex_public.loc[df_train_ex_public['Date'] >= datetime(2020, 4, 1),\n                       ['ConfirmedCases', 'Fatalities', 'NewCases', 'ActiveCases']] = np.nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First train the \"public\" model."},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(X, y, min_rows, total_rows):\n    \"\"\"\n    Function to train the prediction model.\n    Returns trained models and some prediction/test pairs to check performance.\n    \n    Input parameters:\n    X - training data\n    y - output labels\n    min_rows - minimum number of rows to train before attempting walk-forward\n    total_rows - total number of data points to train\n\n    Returns:\n    model                - the trained prediction model\n    poly_transform_model - the trained polynomial transform model\n    predictions          - list of predicted values obtained via \"walk forward\"\n    test_values          - list of test values\n    \"\"\"\n    \n    predictions = []\n    test_values = []\n    \n    for i in range(min_rows, total_rows):\n        #print(\"Training step {}\".format(i-min_rows+1))\n        X_train, X_test = X[0:i], X[i:i+1]\n        y_train, y_test = y[0:i], y[i:i+1]\n        poly_transform_model = PolynomialFeatures(degree=1).fit(X_train)\n        X_train_t = poly_transform_model.transform(X_train)\n        X_test_t = poly_transform_model.transform(X_test)\n        model = Lasso(alpha=0.001, max_iter=200000).fit(X_train_t, y_train)\n        y_pred = model.predict(X_test_t)\n        predictions.append(int(y_pred))\n        test_values.append(y_test)\n    \n    return model, poly_transform_model, predictions, test_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set training data\ntraining_features = []\nfor i in range(min_lag, max_lag):\n    feat = 'ActiveCases-{}'.format(str(i))\n    training_features.append(feat)\n    feat = 'SocDist-{}'.format(str(i))\n    training_features.append(feat)\n\nX = df_train_ex_public[df_train_ex_public['Date'] <= LAST_PUB_TRAIN_DATE][training_features]\ny = df_train_ex_public[df_train_ex_public['Date'] <= LAST_PUB_TRAIN_DATE]['NewCases'].to_list()\n\n# Scaling\nscaler = MinMaxScaler()\ncases_scaler_model = scaler.fit(X)\nX_scaled = cases_scaler_model.transform(X)\n\n# Total number of rows\nnum_rows = X_scaled.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"public_cases_model, public_cases_poly_transform_model, predictions, test_values = train_model(X_scaled, y, int(num_rows*0.95), num_rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a quick graph of the output to see if it is making any reasonable predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(list(np.arange(len(predictions)))[-1000:], predictions[-1000:], label = 'Predicted New Cases')\nplt.plot(list(np.arange(len(predictions)))[-1000:], test_values[-1000:], label = 'Actual New Cases')\nplt.xlabel('Index')\nplt.ylabel('Predicted and Actual New Cases')\nplt.legend()\nplt.title('Quick Plot of Predicted and Actual New Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The predicted line seems to follow the actual line, although we will not examine how closely just yet."},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.3. Training the \"Public\" Model for Fatalities"},{"metadata":{},"cell_type":"markdown","source":"To create a very simple initial model, use the same input features to predict fatalities as for confirmed cases. This is unlikely to work on its own, and is only done here as a base for further development."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set training data\ntraining_features = []\nfor i in range(min_lag, max_lag):\n    feat = 'ActiveCases-{}'.format(str(i))\n    training_features.append(feat)\n    feat = 'SocDist-{}'.format(str(i))\n    training_features.append(feat)\n\nX = df_train_ex_public[df_train_ex_public['Date'] <= LAST_PUB_TRAIN_DATE][training_features]\ny = df_train_ex_public[df_train_ex_public['Date'] <= LAST_PUB_TRAIN_DATE]['NewFatalities'].to_list()\n\n# Scaling\nscaler = MinMaxScaler()\nfatalities_scaler_model = scaler.fit(X)\nX_scaled = fatalities_scaler_model.transform(X)\n\n# Total number of rows\nnum_rows = X_scaled.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"public_fatalities_model, public_fatalities_poly_transform_model, predictions, test_values = train_model(X_scaled, y, int(num_rows*0.95), num_rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a quick graph of the output to see if it is making any reasonable predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(list(np.arange(len(predictions)))[-1000:], predictions[-1000:], label = 'Predicted New Fatalities')\nplt.plot(list(np.arange(len(predictions)))[-1000:], test_values[-1000:], label = 'Actual New Fatalities')\nplt.xlabel('Index')\nplt.ylabel('Predicted and Actual New Fatalities')\nplt.legend()\nplt.title('Quick Plot of Predicted and Actual New Fatalities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicted new fatalities follows the actual results somewhat, os it is learning something, but the predicted peak in this subset of the data is too low."},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.4. Prediction for the \"Public\" Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"def predict(df,\n            latest, earliest, \n            cases_prediction_model,\n            fatalities_prediction_model,\n            cases_scaler_model = None,\n            cases_poly_transform_model = None,\n            fatalities_scaler_model = None,\n            fatalities_poly_transform_model = None):\n    \"\"\"\n    Function to make predictions of confirmed cases and fatalities from trained models.\n    This function updates dataframe df as it goes along.\n    \n    Input parameters:\n    df                              - dataframe to use for reading/writing\n    latest                          - latest date to predict\n    earliest                        - earliest date to predict\n    cases_prediction_model          - trained model for predicting confirmed cases\n    fatalities_prediction_model     - trained model for predicting fatalities\n    cases_scaler_model              - trained scaler model to use (optional)\n    cases_poly_transform_model      - trained polynomial model to use (optional)\n    fatalities_scaler_model         - trained scaler model to use (optional)\n    fatalities_poly_transform_model - trained polynomial model to use (optional)\n    \n    Returns:\n    None\n    \"\"\"\n    province_country_groups = df.groupby(['Province_State', 'Country_Region'])\n    for p_c in list(province_country_groups.groups.keys()):\n        province_country_group = province_country_groups.get_group(p_c)\n\n        for i in range((latest-earliest).days + 1):\n            prediction_date = earliest + timedelta(i)\n            #print(prediction_date)\n            X = df[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date)][training_features]\n\n            if cases_scaler_model != None:\n                X_cases_scaled = cases_scaler_model.transform(X)\n            else:\n                X_cases_scaled = X\n            if cases_poly_transform_model != None:\n                X_cases_scaled_poly = cases_poly_transform_model.transform(X_cases_scaled)\n            else:\n                X_cases_scaled_poly = X_cases_scaled\n\n            y_pred = cases_prediction_model.predict(X_cases_scaled_poly)\n            #print(y_pred)\n            # The model sometimes produces negative values when the input features are low.\n            # Correct these to 0 here.\n            if y_pred < 0:\n                y_pred = 0\n            predicted_new_cases = int(y_pred)\n            \n            if fatalities_scaler_model != None:\n                X_fatalities_scaled = fatalities_scaler_model.transform(X)\n            else:\n                X_fatalities_scaled = X\n            if fatalities_poly_transform_model != None:\n                X_fatalities_scaled_poly = fatalities_poly_transform_model.transform(X_fatalities_scaled)\n            else:\n                X_fatalities_scaled_poly = X_fatalities_scaled\n            \n            y_pred = fatalities_prediction_model.predict(X_fatalities_scaled_poly)\n            #print(y_pred)\n            # The model sometimes produces negative values when the input features are low.\n            # Correct these to 0 here.\n            if y_pred < 0:\n                y_pred = 0\n            predicted_new_fatalities = int(y_pred)\n            \n            # Write fatality prediction to data frame\n            df.loc[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date),\n                            'NewFatalities'] = predicted_new_fatalities\n            \n            # Update cumulative fatalities\n            df.loc[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date),\n                            'Fatalities'] = df[\n                            (df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date-timedelta(1))\n            ]['Fatalities'].values[0] + predicted_new_fatalities\n\n            # Write case prediction to data frame\n            df.loc[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date),\n                            'NewCases'] = predicted_new_cases\n\n            # Update cumulative confirmed cases\n            df.loc[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date),\n                            'ConfirmedCases'] = df[\n                            (df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date-timedelta(1))\n            ]['ConfirmedCases'].values[0] + predicted_new_cases\n\n            # Update features according to new prediction\n            # ActiveCases is the sum of NewCases in a rolling ten day window.\n            # Hence subtract the value 10 days agao (which is lost from the ten day window)\n            # and add the new predicted value.\n            new_cases_ten_days_ago = df[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date-timedelta(10))]['NewCases'].values[0]\n\n            updated_active_cases = df[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date-timedelta(1))\n                                     ]['ActiveCases'].values[0] - new_cases_ten_days_ago + predicted_new_cases\n\n\n            df.loc[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date),\n                            'ActiveCases'] = updated_active_cases\n\n            # SocDist\n            # Assume this takes the same value as the day before\n            # Unless after 2020-04-15, in which case assume all locations have value 1\n            if prediction_date < datetime(2020, 4, 16):\n                updated_socdist = df[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date-timedelta(1))]['SocDist'].values[0]\n            else:\n                updated_socdist = 1\n\n            df.loc[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] == prediction_date),\n                            'SocDist'] = updated_socdist\n\n            # Lag features\n            for i in range (min_lag, max_lag):\n                feat = 'ActiveCases-{}'.format(str(i))\n                if (prediction_date + timedelta(i)) <= latest:\n                    df.loc[(df['Country_Region'] == p_c[1]) &\n                         (df['Province_State'] == p_c[0]) &\n                         (df['Date'] == prediction_date + timedelta(i)),\n                         feat] = updated_active_cases\n                feat = 'SocDist-{}'.format(str(i))\n                if (prediction_date + timedelta(i)) <= latest:\n                    df.loc[(df['Country_Region'] == p_c[1]) &\n                         (df['Province_State'] == p_c[0]) &\n                         (df['Date'] == prediction_date + timedelta(i)),\n                         feat] = updated_socdist\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predict(df_train_ex_public,\n        LAST_PUB_PRED_DATE,\n        FIRST_PUB_PRED_DATE,\n        public_cases_model,\n        public_fatalities_model,\n        cases_scaler_model = cases_scaler_model,\n        cases_poly_transform_model = public_cases_poly_transform_model,\n        fatalities_scaler_model = fatalities_scaler_model,\n        fatalities_poly_transform_model = public_fatalities_poly_transform_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def store_predictions(df, earliest, latest):\n    \"\"\"\n    Function to store predictions.\n    \n    Input Parameters:\n    df       - dataframe to read data values from\n    earliest - earliest date to read/write\n    latest   - latest date to read/write\n    \n    Returns:\n    None\n    \"\"\"\n    \n    province_country_groups = df.groupby(['Province_State', 'Country_Region'])\n    for p_c in list(province_country_groups.groups.keys()):\n        province_country_group = province_country_groups.get_group(p_c)\n        df_test.loc[(df_test['Country_Region'] == p_c[1]) &\n                            (df_test['Province_State'] == p_c[0]) &\n                            (df_test['Date'] >= earliest) &\n                            (df_test['Date'] <= latest),\n                            'ConfirmedCases'] = df[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] >= earliest) &\n                            (df['Date'] <= latest)]['ConfirmedCases'].values\n        \n        df_test.loc[(df_test['Country_Region'] == p_c[1]) &\n                            (df_test['Province_State'] == p_c[0]) &\n                            (df_test['Date'] >= earliest) &\n                            (df_test['Date'] <= latest),\n                            'Fatalities'] = df[(df['Country_Region'] == p_c[1]) &\n                            (df['Province_State'] == p_c[0]) &\n                            (df['Date'] >= earliest) &\n                            (df['Date'] <= latest)]['Fatalities'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Store the output data in df_test."},{"metadata":{"trusted":false},"cell_type":"code","source":"store_predictions(df_train_ex_public, FIRST_STORED_PUB_PRED_DATE, LAST_PUB_PRED_DATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.5. Training the \"Private\" Model for Confirmed Cases"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set training data\ntraining_features = []\nfor i in range(min_lag, max_lag):\n    feat = 'ActiveCases-{}'.format(str(i))\n    training_features.append(feat)\n    feat = 'SocDist-{}'.format(str(i))\n    training_features.append(feat)\n\nX = df_train_ex[df_train_ex['Date'] <= LAST_PRIV_TRAIN_DATE][training_features]\ny = df_train_ex[df_train_ex['Date'] <= LAST_PRIV_TRAIN_DATE]['NewCases'].to_list()\n\n# Scaling\nscaler = MinMaxScaler()\ncases_scaler_model = scaler.fit(X)\nX_scaled = cases_scaler_model.transform(X)\n\n# Number of rows\nnum_rows = X_scaled.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"private_cases_model, private_cases_poly_transform_model, predictions, test_values = train_model(X_scaled, y, int(num_rows*0.95), num_rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a quick graph of the output to see if it is making any reasonable predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(list(np.arange(len(predictions)))[-1000:], predictions[-1000:], label = 'Predicted New Cases')\nplt.plot(list(np.arange(len(predictions)))[-1000:], test_values[-1000:], label = 'Actual New Cases')\nplt.xlabel('Index')\nplt.ylabel('Predicted and Actual New Cases')\nplt.legend()\nplt.title('Quick Plot of Predicted and Actual New Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As in the previous section, this doesn't tell us how well the model is performing, but the fact that the predicted line does follow the actual line (at least to some extent) tells us the model has learned from the training data and is attempting to make predictions."},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.6. Training the \"Private\" Model for Fatalities"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set training data\ntraining_features = []\nfor i in range(min_lag, max_lag):\n    feat = 'ActiveCases-{}'.format(str(i))\n    training_features.append(feat)\n    feat = 'SocDist-{}'.format(str(i))\n    training_features.append(feat)\n\nX = df_train_ex[df_train_ex['Date'] <= LAST_PRIV_TRAIN_DATE][training_features]\ny = df_train_ex[df_train_ex['Date'] <= LAST_PRIV_TRAIN_DATE]['Fatalities'].to_list()\n\n# Scaling\nscaler = MinMaxScaler()\nfatalities_scaler_model = scaler.fit(X)\nX_scaled = fatalities_scaler_model.transform(X)\n\n# Number of rows\nnum_rows = X_scaled.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"private_fatalities_model, private_fatalities_poly_transform_model, predictions, test_values = train_model(X_scaled, y, int(num_rows*0.95), num_rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a quick graph of the output to see if it is making any reasonable predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(list(np.arange(len(predictions)))[-1000:], predictions[-1000:], label = 'Predicted New Fatalities')\nplt.plot(list(np.arange(len(predictions)))[-1000:], test_values[-1000:], label = 'Actual New Fatalities')\nplt.xlabel('Index')\nplt.ylabel('Predicted and Actual New Fatalities')\nplt.legend()\nplt.title('Quick Plot of Predicted and Actual New Fatalities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicted new fatalities follows the actual results somewhat, os it is learning something, but the predicted peak in this subset of the data is too low."},{"metadata":{},"cell_type":"markdown","source":"#### 5.5.6. Predictions for the \"Private\" Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"predict(df_train_ex,\n        LAST_PRIV_PRED_DATE,\n        FIRST_PRIV_PRED_DATE,\n        private_cases_model,\n        private_fatalities_model,\n        cases_scaler_model = cases_scaler_model,\n        cases_poly_transform_model = private_cases_poly_transform_model,\n        fatalities_scaler_model = fatalities_scaler_model,\n        fatalities_poly_transform_model = private_fatalities_poly_transform_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Store predictions in df_test."},{"metadata":{"trusted":false},"cell_type":"code","source":"store_predictions(df_train_ex, FIRST_STORED_PRIV_PRED_DATE, LAST_PRIV_PRED_DATE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write data to the output file in the required format."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test.to_csv('submission.csv', columns = ['ForecastId', 'ConfirmedCases', 'Fatalities'], index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Evaluation"},{"metadata":{},"cell_type":"markdown","source":"### 6.1. Evaluation Metric - Root Mean Squared Logarithmic Error"},{"metadata":{},"cell_type":"markdown","source":"The root mean squared logarithmic error (RMSLE) is chosen (by Kaggle) as the overall evaluation metric. This is calculated on predictions for confirmed cases and fatalities, and these are combined into an overall figure by calculating the mean of the two.\n\nThe prediction model will be evaluated continuously by Kaggle up to 14th May, 2020, as more data becomes available.\n\nHowever, the RMSLE can be calculated now for predictions in the \"public\" period up until the present date, i.e. from 2020-04-02 to 2020-04-09 (to date)."},{"metadata":{"trusted":false},"cell_type":"code","source":"predicted_cases = df_test[(df_test['Date'] >= FIRST_STORED_PUB_PRED_DATE) &\n                         (df_test['Date'] <= LAST_PRIV_TRAIN_DATE)]['ConfirmedCases'].values\npredicted_fatalities = df_test[(df_test['Date'] >= FIRST_STORED_PUB_PRED_DATE) &\n                         (df_test['Date'] <= LAST_PRIV_TRAIN_DATE)]['Fatalities'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_cases = df_train[df_train['Date'] >= FIRST_STORED_PUB_PRED_DATE]['ConfirmedCases'].values\ntest_fatalities = df_train[df_train['Date'] >= FIRST_STORED_PUB_PRED_DATE]['Fatalities'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cases_rmsle = np.sqrt(mean_squared_log_error(test_cases, predicted_cases))\nprint(\"RMSLE on confirmed cases: {}\".format(cases_rmsle))\n\nfatalities_rmsle = np.sqrt(mean_squared_log_error(test_fatalities, predicted_fatalities))\nprint(\"RMSLE on fatalities: {}\".format(fatalities_rmsle))\n\nprint(\"Overall (mean) RMSLE: {}\".format((cases_rmsle+fatalities_rmsle)/2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now create a few sample graphs to compare predictions to truth for confirmed cases and fatalities."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sample_locations = [('None', 'United Kingdom'), ('None', 'Korea, South'), ('None', 'Germany')]\ntest_p_c_groups = df_train.groupby(['Province_State', 'Country_Region'])\npred_p_c_groups = df_test.groupby(['Province_State', 'Country_Region'])\nfor loc in sample_locations:\n    test_grp = test_p_c_groups.get_group(loc)\n    pred_grp = pred_p_c_groups.get_group(loc)\n    test = test_grp[test_grp['Date'] >= FIRST_STORED_PUB_PRED_DATE]\n    pred = pred_grp[(pred_grp['Date'] >= FIRST_STORED_PUB_PRED_DATE) &\n                     (pred_grp['Date'] <= LAST_PRIV_TRAIN_DATE)]\n    plt.figure(figsize=(12, 6))\n    plt.plot(test['Date'], test['ConfirmedCases'], label = 'True Confirmed Cases')\n    plt.plot(pred['Date'], pred['ConfirmedCases'], label = 'Predicted Confirmed Cases')\n    plt.xlabel('Date')\n    plt.ylabel('Number of confirmed cases')\n    plt.xticks(rotation='vertical')\n    plt.legend()\n    plt.title('Graph Comparing True and Predicted Confirmed Cases in {0}'.format(loc))\n    plt.show()\n    \n    plt.figure(figsize=(12, 6))\n    plt.plot(test['Date'], test['Fatalities'], label = 'True Fatalities')\n    plt.plot(pred['Date'], pred['Fatalities'], label = 'Predicted Fatalities')\n    plt.xlabel('Date')\n    plt.ylabel('Number of fatalities')\n    plt.xticks(rotation='vertical')\n    plt.legend()\n    plt.title('Graph Comparing True and Predicted Fatalities in {0}'.format(loc))\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now create a few graphs to show where future predictions are going."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sample_locations = [('None', 'United Kingdom'), ('New York', 'US'), ('None', 'Italy')]\npred_p_c_groups = df_test.groupby(['Province_State', 'Country_Region'])\nfor loc in sample_locations:\n    pred_grp = pred_p_c_groups.get_group(loc)\n    pred = pred_grp[(pred_grp['Date'] >= FIRST_STORED_PRIV_PRED_DATE) &\n                     (pred_grp['Date'] <= LAST_PRIV_PRED_DATE)]\n    plt.figure(figsize=(12, 6))\n    plt.plot(pred['Date'], pred['ConfirmedCases'], label = 'Predicted Confirmed Cases')\n    plt.xlabel('Date')\n    plt.ylabel('Number of confirmed cases')\n    plt.xticks(rotation='vertical')\n    plt.legend()\n    plt.title('Graph Showing Predicted Confirmed Cases in {0}'.format(loc))\n    plt.show()\n    \n    plt.figure(figsize=(12, 6))\n    plt.plot(pred['Date'], pred['Fatalities'], label = 'Predicted Fatalities')\n    plt.xlabel('Date')\n    plt.ylabel('Number of fatalities')\n    plt.xticks(rotation='vertical')\n    plt.legend()\n    plt.title('Graph Showing Predicted Fatalities in {0}'.format(loc))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.2. Discussion of Model Performance"},{"metadata":{},"cell_type":"markdown","source":"Looking at the graphs above, the prediction models for both confirmed cases and fatalities need improvement.\n\nFor the comparison of predicted and true confirmed cases, one of the graphs (UK) seems to show quite good predictions, but in the other two, the predicted cases are too high.\n\nThe predicted fatalities are all too high in these three examples.\n\nThe shapes of the prediction models plotted above generally look reasonable, with cases and fatalities rising to a peak in the next few weeks then falling again. Fatalities is peaking after confirmed cases peaks, which makes sense. The confirmed cases for Italy above looks wrong though, with a \"plateau\" in the middle, followed by another rise.\n\nOne clear problem is that sometimes the number of fatlities is exceeding the number of confirmed cases. This does not make sense, and points to a problem with the model.\n\nThe models often produce erroneous negative values, especially when the number of Active Cases is low or 0. For example, the fatalities model sometimes predicts a small negative number of fatalities (-1 or -2), and the confirmed cases model consistently predicts a low number of new cases (usually around 130) even when there are no confirmed cases in a country. These are clear deficiencies in the model, although these are small numbers, relative to the overall numbers we are dealing with (likely in the millions)."},{"metadata":{},"cell_type":"markdown","source":"### 6.3. Conclusions"},{"metadata":{},"cell_type":"markdown","source":"At this stage, it is not surprising that the models are performing poorly. As noted above, the input features are simple. The social distancing feature is a very \"blunt\" binary value, surely not represenatative of the many shades of response from different governemtns around the world. Active cases is also a proxy value - very many cases are not officially confirmed since testing is not widespread in most countries. As well as deficiencies with these features, there may well be other different features which influence the virus, and it is finding these that is the core purpose of this project. Using the same features for bothe the confirmed cases model and the fatalities model was a convenience, but is also unlikely to capture the true variation of each. Developing the features for bothe models is the most important next step in this project."},{"metadata":{},"cell_type":"markdown","source":"### 6.4. Ideas for Further Work"},{"metadata":{},"cell_type":"markdown","source":"Experiment with adding the following additional features to the model:\n* A more nuanced view of social distancing, perhaps using this data set: https://covidtracker.bsg.ox.ac.uk/\n* Population mobility, perhaps using this data set: https://www.google.com/covid19/mobility/\n* Testing levels\n* Number of critical care beds\n* Correcting for under-reporting of cases/fatalities (see https://www.google.com/covid19/mobility/\n\nExperiment with different types of model, e.g.:\n* Different types of regression model\n* Neural networks, e.g. RNNs, neural ODEs."},{"metadata":{},"cell_type":"markdown","source":"## 7. References"},{"metadata":{},"cell_type":"markdown","source":"1. Data on COVID-19 testing. Accessed at: https://ourworldindata.org/covid-testing. 5th April, 2020.\n\n2. The COVID Tracking Project, accessed at: https://covidtracking.com/data/. 5th April, 2020.\n\n3. UK Government, 2020. Coronavirus (COVID-19): what you need to do. Accessed at: https://www.gov.uk/coronavirus - UK Governement information on COVID-19 5th April, 2020.\n\n4. John Hopkins University coronavirus dashboard: Coronavirus COVID-19 Global Cases by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU) https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6. Accessed daily during the crisis.\n\n5. Flaxman, Mishra, Gandy, 2020. Estimating the number of infections and the impact of nonpharmaceutical interventions on COVID-19 in 11 European countries. Imperial College COVID-19 Response Team. Accessed at: https://www.imperial.ac.uk/media/imperial-college/medicine/sph/ide/gida-fellowships/Imperial-College-COVID19-Europe-estimates-and-NPI-impact-30-03-2020.pdf 5th April, 2020.\n\n6. World Health Organisation, 2020. Report of the WHO-China Joint Mission on Coronavirus Disease 2019 (COVID-19). Accessed at: https://www.who.int/docs/default-source/coronaviruse/who-china-joint-mission-on-covid-19-final-report.pdf 5th April, 2020.\n\n7. Historical weather data for London: https://www.weatheronline.co.uk/weather/maps/city?LANG=en&WMO=03772&ART=SON&CONT=ukuk&R=0&LEVEL=150&REGION=0003&LAND=UK&NOREGION=0&MOD=&TMX=&TMN=&SON=&PRE=&MONAT=&OFFS=&SORT=. Accessed 5th April, 2020.\n\n8. Citymapper Mobility index accessed here: https://citymapper.com/cmi. 5th April, 2020.\n\n9. John Hopkins University coronavirus dashboard (UK figures): Total UK COVID-19 Cases Update. https://www.arcgis.com/apps/opsdashboard/index.html#/f94c3c90da5b4e9f9a0b19484dd4bb14. 5th April. 2020.\n\n10. Jagodnik, Ray, Giorgi, Lachmann1. Correcting under-reported COVID-19 case numbers: estimating the true scale of the pandemic. Preprint accessed from https://www.medrxiv.org/content/10.1101/2020.03.14.20036178v2.full.pdf, 14th April, 2020.\n\n11. Oxford COVID-19 Government Response Tracker. https://covidtracker.bsg.ox.ac.uk/, accessed 14th April, 2020.\n\n12. COVID-19 Community Mobility Reports. https://www.google.com/covid19/mobility/, accessed 14th April, 2020."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":4}