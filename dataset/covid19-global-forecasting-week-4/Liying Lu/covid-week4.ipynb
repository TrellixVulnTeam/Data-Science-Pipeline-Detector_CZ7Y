{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom datetime import date\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nsubmit = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")\nc2 = pd.read_csv(\"/kaggle/input/covid19-forecasting-metadata/region_metadata.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Data Transformation\n1.  Combine the 'Country_Region' and 'Province_State' columns into 'country_province'.\n2.  Calculate the cumulative cases and fatalities for each country_province as 'cumCases' and 'cumDeath'\n3.  Chagnge the datatype of 'Date' to datetime  \n4.  Log transform the cases and deaths\n5.  Add 'prevCases' and 'prevDeath' for train data\n6.  Add 'Days' since the first cases in each region","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Steps 1 to 6\ndef dataTrans(df):\n    # 1. Combine the Country_Region and Province_State columns into country_province.\n    df.Province_State[df['Province_State'].isnull()] = '' # change the null to empty string\n    df['country_province'] = df.apply(lambda x: x.Country_Region+'-' if x.Province_State == '' else x.Country_Region+'-'+x.Province_State, axis = 1)\n    # 3. Chagnge the datatype of Date to datetime\n    df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)    \n    # 4. Log transform the cases and deaths.\n    #df['log_ConfirmedCases'] = df['ConfirmedCases'].apply(lambda x: np.log(x) if x > 0 else 0)\n    #df['log_Fatalities'] = df['Fatalities'].apply(lambda x: np.log(x) if x > 0 else 0)\n    \n    ##################################################################################################\n    # 2. Calculate the cumulative cases and fatalities for each country_province for the train data\n    # 5.  Add column for prevCases and prevDeath\n    cumCases = pd.Series()\n    cumDeath = pd.Series()\n    prevCases = pd.Series()\n    prevDeath = pd.Series()\n    \n    for region in df.country_province.unique():\n        cases = df.ConfirmedCases[df.country_province==region].cumsum() # cumulative sum of log cases\n        death = df.Fatalities[df.country_province==region].cumsum() # cumulative sum of log deaths\n        cumCases = pd.concat([cumCases,cases])\n        cumDeath = pd.concat([cumDeath,death])\n        prevCases = pd.concat([prevCases,pd.Series([0]),cases.iloc[:len(cases)-1]])\n        prevDeath = pd.concat([prevDeath,pd.Series([0]),death.iloc[:len(death)-1]])\n        \n        # 7.  Add a column for the days since the first cases\n        date_firstCase = df.iloc[df.ConfirmedCases.to_numpy().nonzero()[0][0]].Date # date of the first cases\n        df[\"DaySinceFirstCase\"] = (df.Date - date_firstCase).dt.days # calculates the day since the first case\n        df[\"DaySinceFirstCase\"] = df['DaySinceFirstCase'].apply(lambda x: x if x>0 else 0) # change the negative values to zero\n\n    prevCases = prevCases.reset_index(drop=True)\n    prevDeath = prevDeath.reset_index(drop=True)\n    df_trans = pd.concat([df,cumCases,cumDeath,prevCases,prevDeath], axis=1)\n    df_trans = df_trans.rename(columns={0:'log_cumCases', 1:'log_cumDeath', 2:'log_prevCases', 3:'log_prevDeath'})\n    log_transform = lambda x: np.log(x) if x>0 else 0\n    df_trans['log_cumCases'] = df_trans['log_cumCases'].apply(log_transform)\n    df_trans['log_cumDeath'] = df_trans['log_cumDeath'].apply(log_transform)\n    df_trans['log_prevCases'] = df_trans['log_prevCases'].apply(log_transform)\n    df_trans['log_prevDeath'] = df_trans['log_prevDeath'].apply(log_transform)\n    return df_trans\n###############################################################################################################################################\n\ndf_train = dataTrans(train)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train), len(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Additional Dataset: country info\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# add north america and south america in the continents\nnorthamerica = ['Antigua and Barbuda','Bahamas','Barbados','Belize','Canada','Costa Rica','Cuba', 'Dominica', \\\n                'Dominican Republic','El Salvador', 'Grenada', 'Guatemala','Haiti','Honduras', 'Jamaica', \\\n                'Mexico', 'Nicaragua', 'Panama','Saint Kitts and Nevis', 'Saint Lucia','Saint Vincent and the Grenadines',\\\n                'Trinidad and Tobago', 'US']\nsouthamerica = ['Argentina','Bolivia', 'Brazil','Chile', 'Colombia', 'Ecuador','Guyana','Paraguay','Peru',\\\n                'Suriname','Uruguay', 'Venezuela']\n#print(len(c2[c2.continent == \"Americas\"].Country_Region.unique()) == (len(northamerica)+len(southamerica)))\nfor country in c2.Country_Region.unique():\n    #print(country)\n    if country in northamerica:\n        c2.loc[c2.Country_Region==country,['continent']] = 'North_America'\n    elif country in southamerica:\n        c2.loc[c2.Country_Region==country,['continent']] = 'South_America'\nprint(c2.continent.unique())\n\n# change the continents to codes\nc2.continent = pd.Categorical(c2.continent)\nc2['continent_code'] = c2.continent.cat.codes \n\n# add a column for country_province\nc2.Province_State[c2['Province_State'].isnull()] = '' # change the null to empty string\nc2['country_province'] = c2.apply(lambda x: x.Country_Region+'-' if x.Province_State == '' else x.Country_Region+'-'+x.Province_State, axis = 1)\nc2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(c2.country_province.unique()), len(df_train.country_province.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge columns from the additional datasets to the training set and testing set\n#weather.rename(columns={'country+province':'country_province'}, inplace=True)\n\ndf_train = pd.merge(df_train, c2[['country_province','lat', 'lon', 'continent_code','population', 'area', 'density']], on='country_province', how='left')\ndf_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train), len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making the testdata the same\ndef dataTrans_test(df):\n    # 1. Combine the Country_Region and Province_State columns into country_province.\n    df.Province_State[df['Province_State'].isnull()] = '' # change the null to empty string\n    df['country_province'] = df.apply(lambda x: x.Country_Region+'-' if x.Province_State == '' else x.Country_Region+'-'+x.Province_State, axis = 1)\n    # 3. Chagnge the datatype of Date to datetime\n    df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)    \n    return df\n\ndf_test = dataTrans_test(test)\ndf_test = pd.merge(df_test, c2[['country_province','lat', 'lon', 'continent_code','population', 'area', 'density']], on='country_province', how='left')\ndf_test = df_test.merge(df_train[['Date', 'ConfirmedCases',\n                                   'Fatalities', 'country_province', \n                                   'DaySinceFirstCase', 'log_cumCases', 'log_cumDeath',\n                                   'log_prevCases', 'log_prevDeath']], on=['country_province','Date'],how='left')\n\n# calculate the DaySinceFirstCase column\ns = df_test.groupby('country_province').DaySinceFirstCase.cumcount()\ns1 = (df_test.DaySinceFirstCase - s).groupby(df_test.country_province).transform('first')\ndf_test['DaySinceFirstCase'] = s1 + s\n\ndf_test.columns\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = df_train.columns.tolist()\ncolumns = ['ForecastId'] + columns[1:]\ncolumns\ndf_test = df_test.loc[:,columns]\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train), len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_test), len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modelTraining(model, df_train, df_test, predictors, targets):\n    # train the models separately for each region\n    for region in df_train.country_province.unique():\n        firstIndex = df_test[(df_test.country_province == region)].index[0]\n        lastIndex = df_test[(df_test.country_province == region)].index[-1]\n        lastValidIndex = df_test[(df_test.country_province == region)].index[-1]\n        lastValideDate = df_test[(df_test.country_province == region)].Date.min()\n        while (lastValidIndex < lastIndex):\n            # assign the latest cumulated cases and deaths to the next day as previous cases and deaths\n            data = df_train.loc[(df_train.Date == lastValidDate) & (df_train.country_province == region) , 'log_cumCases':'log_cumDeath']\n            df_test.loc[lastValidIndex+1,'log_prevCases':'log_prevDeath'] = data[0], data[1]\n\n            # train the models separately for log_cumCases and log_cumDeath\n            for target in targets:\n                X_train = df_train[df_train.country_province == region][predictors]\n                y_train = df_train[df_train.country_province == region][target]\n\n                X_test = df_test.loc[lastValidIndex+1, predictors].values.reshape(1,-1)\n                \n                model.fit(X_train, y_train)\n                \n                df_test.loc[lastValidIndex+1, target] = model.predict(X_test)[0]\n                \n            # update the last valid index where the cumulative cases is not null\n            lastValidIndex = df_test[(df_test.country_province == region) & (df_test.log_cumCases.notnull())].index[-1]\n            \n    # change the predicted outcome from log scale to linear scale\n    df_test['cumCases'] = np.exp(df_test['log_cumCases'])\n    df_test['cumDeaths'] = np.exp(df_test['log_cumDeath'])\n    # calculate the daily new cases\n    df_test['ConfirmedCases_predicted'] = df_test.groupby('country_province').cumCases.diff()\n    df_test['Fatalities_predicted'] = df_test.groupby('country_province').cumDeaths.diff()\n    # fill the nan in daily cases and deaths with predicted values\n    df_test['ConfirmedCases'] = df_test['ConfirmedCases'].fillna(df_test['ConfirmedCases_predicted'])\n    df_test['Fatalities'] = df_test['Fatalities'].fillna(df_test['Fatalities_predicted'])\n    \n    return df_test\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\nrfr = RandomForestRegressor(n_estimators=100)\nridge = Ridge(alpha=1.0)\nlinear = LinearRegression()\n\npredictors =['DaySinceFirstCase','log_prevCases','log_prevDeath', 'lat', 'lon', 'continent_code', 'population', 'area', 'density']\ntargets = ['log_cumCases','log_cumDeath']\n\n# subset df_train into train and test into 7:3\ndates = np.sort(df_train['Date'].unique())\ntraining = df_train[df_train['Date'] <= df_test.Date.min()]\ntesting = df_train[df_train['Date'] > dates[int(len(dates)*0.7)]]\nvalidation = testing.copy()\ntesting.loc[:,'log_cumCases':'log_prevDeath'] = np.nan\n\n#for model,model_name in zip([rfr, ridge, linear],['Random Forest Regression', 'Ridge Regression', 'Linear Regression']):\n    #result = modelTraining(model, training, df_test, predictors, targets)\n    #mse = np.mean((result['ConfirmedCases'] - validation['ConfirmedCases'])**2 + (result['Fatalities'] - validation['Fatalities'])**2)\n    #print('Model:',model_name)\n    #print('Mean Square Error:', mse)\nresult_linear = modelTraining(linear, training, df_test, predictors, targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['ForecastId', 'ConfirmedCases_predicted', 'Fatalities_predicted']\nsubmission = result_linear.loc[:,cols]\nsubmission = submission.rename(columns={'ConfirmedCases_predicted':'ConfirmedCases', 'Fatalities_predicted':'Fatalities'})\nsubmission.describe()\nsubmission = submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}