{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ndatas = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        datas.append(pd.read_csv(os.path.join(dirname, filename)))\n\ndatas[1] = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ndatas[2] = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\npopulation = pd.read_csv('/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv')\npopulation = population.rename(columns = {'Province.State':'Province_State', 'Country.Region':'Country_Region'})\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenate country region and province state for using tag. It will be using by country index."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_country_label = []\nfor idata in datas[1].itertuples():\n    try:\n        tmp_country_label.append(idata.Country_Region + '_' + idata.Province_State)\n    except:\n        tmp_country_label.append(idata.Country_Region)\ndatas[1]['country_label'] = tmp_country_label\n# datas[1].loc[0].Country_Region + datas[1].loc[0].Province_State\nnp.isnan(datas[1].loc[0].Province_State)\ncountry_list = datas[1].country_label.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mortality rate of each country is different.     \nSo I predict mortality rate by time sequence.    \nBut early step has high rate. It will be working like noise.\n\nThe country of Guyana has 100% mortality rate at early steps.    \nIt needs preprocessing or flag for steps to learning.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pylab as plt\ndatas[1]['Mortality_rate'] = datas[1]['Fatalities'].values / (datas[1]['ConfirmedCases'].values + 1e-8)\ndatas[1][datas[1]['Mortality_rate'] > 0.5]\nplt.plot(datas[1][datas[1]['Country_Region'] == 'Guyana']['Mortality_rate'].values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nfrom datetime import timedelta\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Input, GRU, Masking, Permute, Concatenate, LSTM, BatchNormalization, Flatten\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend as K\nfrom tqdm import tqdm\nimport gzip\nimport pickle\n\ndef rmsle(pred,true):\n    assert pred.shape[0]==true.shape[0]\n    return K.sqrt(K.mean(K.square(K.log(pred+1) - K.log(true+1))))\n\ndef attention_mechanism(days, input_):\n    x = Dense(256, activation='sigmoid')(input_)\n    x = Dense(days, activation='softmax')(x)\n    return x\n\ndef attention_model(input_size, days=21, batch_size=32, epochs=200, lr=1e-3):\n\n    country_input = Input(shape=(313,), name='country_onehot')\n    inputs = Input(shape=(None, input_size), name='encoder_input')    \n    target_number = Input(shape=(1,), name='target_input')\n    flag_input = Input(shape=(1,), name='flag_input')\n\n    x = Masking(mask_value=0, input_shape=(None, input_size))(inputs)\n    x = GRU(128, name='GRU_layer1', return_sequences=True)(x)\n\n    attention_x = attention_mechanism(days, x)\n    gru_out = Permute((2, 1))(x)\n    attention_mul = K.batch_dot(gru_out, attention_x)\n    attention_mul = Permute((2, 1))(attention_mul)       \n\n    x = GRU(128, name='GRU_layer2', return_sequences=True)(attention_mul)\n    gru_x = Flatten()(x)\n    # country onehot concatenate\n#     x = Concatenate(axis=-1)([country_input, gru_x])\n    x = Dense(32, activation='relu')(gru_x)\n#     x = BatchNormalization()(x)\n    x = Dense(128, activation='relu')(x)\n#     x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)        \n#     x = Dense(16, activation='relu')(x)        \n#     x = Concatenate(axis=-1)([x, gru_x])\n    outputs = Dense(1, activation='sigmoid')(x)\n    print(outputs.shape, flag_input.shape, target_number.shape)\n    \n    outputs = target_number * (flag_input + outputs)\n\n    optimizer = Adam(lr=lr, name='adam')\n    model = Model([inputs, country_input, target_number, flag_input], outputs, name='gru_network')\n    model.compile(optimizer=optimizer, loss=rmsle)\n#     print(self.model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I need some more data like increase rate.  \nCaclulate each increase rate and create model learning class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class corona19_predict:\n    def __init__(self, df, population, days=21, batch_size=8, epochs=200):\n        self.days = days\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.confirmed_cases_model = attention_model(2, days, lr=1e-4)\n        self.fatalities_model = attention_model(5, days, lr=1e-6)\n        self.cal_increase_rate(df, population)\n    \n    def cal_increase_rate(self, df, population):\n        # calculate increase rate & set target dataframe\n        pre_ccd = 0\n        pre_fd = 0\n        confirmed_cases_diff = []\n        fatalities_diff = []\n        for idata in df.itertuples():\n            if idata.ConfirmedCases < pre_ccd:\n                pre_ccd = 0\n                pre_fd = 0\n            confirmed_cases_diff.append(idata.ConfirmedCases - pre_ccd)\n            fatalities_diff.append(idata.Fatalities - pre_fd)\n            pre_ccd = idata.ConfirmedCases\n            pre_fd = idata.Fatalities\n\n        df['ConfirmedCases_diff'] = confirmed_cases_diff\n        df['Fatalities_diff'] = fatalities_diff \n        \n        df['Fatalities_diff'] = df['Fatalities_diff'].clip(0) # dead man never live\n        \n        df['ConfirmedCases_diff_percent'] = df['ConfirmedCases_diff'].values / (df['ConfirmedCases'].values + 1.0e-10)\n        df['Fatalities_diff_percent'] = df['Fatalities_diff'].values / (df['Fatalities'].values + 1.0e-10)        \n        \n        tmp_country_label = []\n        for idata in df.itertuples():\n            try:\n                tmp_country_label.append(idata.Country_Region + '_' + idata.Province_State)\n            except:\n                tmp_country_label.append(idata.Country_Region)\n        df['country_label'] = tmp_country_label\n        \n        tmp_country_label = []\n        for idata in population.itertuples():\n            try:\n                tmp_country_label.append(idata.Country_Region + '_' + idata.Province_State)\n            except:\n                tmp_country_label.append(idata.Country_Region)\n        population['country_label'] = tmp_country_label\n        \n        self.target_df = df\n        self.population_df = population\n        self.country_list = df['country_label'].unique().tolist()\n        return df\n    \n    def get_country_onehot(self, country_str):\n        # country onehot encoding\n        country_onehot = np.zeros(len(self.country_list))\n        country_onehot[self.country_list.index(country_str)] = 1\n        return country_onehot  \n    \n    def encoded_data(self, country_onehot, target_date_str, country_population):        \n        # get target date list\n        date_list = target_date_str.split('-')\n        delta = timedelta(days=1)\n        date = datetime(int(date_list[0]), int(date_list[1]), int(date_list[2])) - delta        \n        day_list = []\n        for i in range(self.days):\n            day_list.append(date.strftime('%Y-%m-%d'))\n            date -= delta\n        day_list = day_list[::-1]\n        \n        # get data\n        confirmed_cases = 0\n        fatalities = 0\n        encoded_data = []  \n        if self.country_df.country_label.values[0] != self.country_list[np.argmax(country_onehot)]:\n            self.country_df = self.target_df[self.target_df.country_label == self.country_list[np.argmax(country_onehot)]]\n        for date_str in day_list:\n            tmp_data_df = self.country_df[self.country_df.Date == date_str]\n            if len(tmp_data_df) == 0:\n                'train data not exist'                \n            else:                \n                confirmed_cases_diff = tmp_data_df.ConfirmedCases_diff.values[0]\n                fatalities_diff = tmp_data_df.Fatalities_diff.values[0]\n                confirmed_cases = tmp_data_df.ConfirmedCases.values[0]\n                fatalities = tmp_data_df.Fatalities.values[0]\n                confirmed_cases_diff_percent = tmp_data_df.ConfirmedCases_diff_percent.values[0]\n                fatalities_diff_percent = tmp_data_df.Fatalities_diff_percent.values[0]\n            encoded_data.append([confirmed_cases, fatalities, confirmed_cases_diff, fatalities_diff, confirmed_cases_diff_percent, fatalities_diff_percent, country_population])\n        return encoded_data\n    \n    def make_train_data(self):\n        train_data = {'country_onehot': [], 'encoder_input': []}\n        train_label = []\n        p_country = ''\n        for idata in tqdm(self.target_df.itertuples(), total=len(self.target_df), position=0):\n            if p_country != idata.country_label:\n                self.country_df = self.target_df[self.target_df.country_label == idata.country_label]\n                country_population = self.population_df[self.population_df.country_label == idata.country_label].Population.values[0]\n                p_country = idata.country_label\n            if idata.Date > self.target_df.iloc[self.days + 1].Date:\n                tmp_onehot_data = self.get_country_onehot(idata.country_label)                        \n                tmp_encoded_data = self.encoded_data(tmp_onehot_data, idata.Date, country_population)\n#                 print(tmp_encoded_data)\n                try:\n                    if np.sum(np.array(tmp_encoded_data)[:, :]) != 0:\n                        train_data['country_onehot'].append(tmp_onehot_data)\n                        train_data['encoder_input'].append(tmp_encoded_data) \n                        train_label.append([idata.ConfirmedCases, idata.Fatalities, idata.ConfirmedCases_diff, idata.Fatalities_diff, idata.ConfirmedCases_diff_percent, idata.Fatalities_diff_percent, country_population])\n                except:\n                    print(idata.country_label, country_population)\n                    print(tmp_ecoded_data, idata.country_label, country_population)\n        \n        return [np.array(train_data['encoder_input']), np.array(train_data['country_onehot'])], np.array(train_label)\n    \n    def train_data_fatalities(self):  \n        try:\n            with gzip.open('encoded_data.dat', 'rb') as f:\n                X_train, y_train = pickle.load(f)\n        except:        \n            X_train, y_train = self.make_train_data()\n            with gzip.open('encoded_data.dat', 'wb') as f:\n                pickle.dump([X_train, y_train], f)\n        x_train = X_train.copy()\n        x_train[0] = np.concatenate([\\\n                      (x_train[0][:, :, 0] / x_train[0][:, :, 6]).reshape(list(x_train[0].shape[:-1]) + [1]), \\\n                      (x_train[0][:, :, 2] / x_train[0][:, :, 6] ).reshape(list(x_train[0].shape[:-1]) + [1]), \\\n                      (x_train[0][:, :, 1] / x_train[0][:, :, 6]).reshape(list(x_train[0].shape[:-1]) + [1]), \\\n                      (x_train[0][:, :, 3] / x_train[0][:, :, 6]).reshape(list(x_train[0].shape[:-1]) + [1]), \\\n                      (x_train[0][:, :, 1] / (x_train[0][:, :, 0] + 1e-8)).reshape(list(x_train[0].shape[:-1]) + [1]) \\\n                      ], axis=2)\n        death_rate_index = np.where(y_train[:, 1] / (y_train[:, 0] + 1e-8) < 0.15)[0]\n#         death_rate_index = np.where(y_train[:, 1] / (y_train[:, 0] + 1e-8) < 20)[0]\n        \n        tb_hist = tensorflow.keras.callbacks.TensorBoard(log_dir='./graph_gru_attention', histogram_freq=1, write_graph=True, write_images=True)\n        model_path = './fatalities_gru_attention.h5'  # '{epoch:02d}-{val_loss:.4f}.h5'\n        cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n        early_stopping = EarlyStopping(patience=10)\n\n        history = self.fatalities_model.fit({'encoder_input':x_train[0][death_rate_index], 'country_onehot':x_train[1][death_rate_index], 'target_input': X_train[0][death_rate_index][:, -1, 1].reshape(list(X_train[0][death_rate_index].shape[:-2]) + [1]), 'flag_input': np.ones(len(x_train[0][death_rate_index]))}, y_train[:, 1][death_rate_index], batch_size=self.batch_size, epochs=self.epochs, verbose=1, shuffle=True,\n                              validation_split=0.2,\n                               callbacks=[tb_hist, cb_checkpoint, early_stopping])  # , class_weight=class_weights) \n        y_predict = self.fatalities_model.predict({'encoder_input':x_train[0], 'country_onehot':x_train[1], 'target_input': X_train[0][:, -1, 0].reshape(list(X_train[0].shape[:-2]) + [1]), 'flag_input': np.zeros(len(x_train[0]))})\n        return y_predict, y_train\n    \n    def train_data_confirmed_cases(self):  \n        try:\n            with gzip.open('encoded_data.dat', 'rb') as f:\n                X_train, y_train = pickle.load(f)\n        except:        \n            X_train, y_train = self.make_train_data()\n            with gzip.open('encoded_data.dat', 'wb') as f:\n                pickle.dump([X_train, y_train], f)\n                \n        x_train = X_train.copy()\n        x_train[0] = np.concatenate([(x_train[0][:, :, 0] / x_train[0][:, :, 6]).reshape(list(x_train[0].shape[:-1]) + [1]), (x_train[0][:, :, 2] / x_train[0][:, :, 6]).reshape(list(x_train[0].shape[:-1]) + [1])], axis=2)\n        \n        tb_hist = tensorflow.keras.callbacks.TensorBoard(log_dir='./graph_gru_attention', histogram_freq=1, write_graph=True, write_images=True)\n        model_path = './confirmed_cases_gru_attention.h5'  # '{epoch:02d}-{val_loss:.4f}.h5'\n        cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n        early_stopping = EarlyStopping(patience=10)\n        \n        history = self.confirmed_cases_model.fit({'encoder_input':x_train[0], 'country_onehot':X_train[1], 'target_input': X_train[0][:,-1,0].reshape(list(X_train[0].shape[:-2]) + [1]), 'flag_input':np.ones((len(x_train[0]), 1))}, y_train[:, 0], batch_size=self.batch_size, epochs=self.epochs, verbose=1, shuffle=True,\n                              validation_split=0.2,\n                               callbacks=[tb_hist, cb_checkpoint, early_stopping])  # , class_weight=class_weights) \n        y_predict = self.confirmed_cases_model.predict({'encoder_input':x_train[0], 'country_onehot':X_train[1], 'target_input': X_train[0][:,-1,0].reshape(list(X_train[0].shape[:-2]) + [1]), 'flag_input':np.ones((len(x_train[0]), 1))})\n        return y_predict, y_train\n    \n    def load_models(self, country_list):\n        self.confirmed_cases_model.load_weights('/kaggle/working/confirmed_cases_gru_attention.h5')\n        self.fatalities_model.load_weights('/kaggle/working/fatalities_gru_attention.h5')\n        self.country_list = country_list\n        \n    def predict_encoder_confirmed_cases(self, day_list, country_label, data_df, country_population):\n        encoded_data_c = []\n        encoded_data_f = []\n        country_onehot = np.zeros(len(self.country_list))\n        country_onehot[self.country_list.index(country_label)] = 1\n        before_confirmed_case = 0\n        before_fatalities_case = 0\n        for day in day_list:            \n            tmp_data_df = data_df[data_df.Date == day]            \n            try:\n                encoded_data_c.append([(tmp_data_df.ConfirmedCases.values[0] / country_population),tmp_data_df.ConfirmedCases_diff.values[0] / country_population])\n            except:\n                print(country_population, day, country_label, tmp_data_df, day_list)\n                return\n            encoded_data_f.append([\\\n                                 (tmp_data_df.ConfirmedCases.values[0] / country_population), \\\n                                 (tmp_data_df.ConfirmedCases_diff.values[0] / country_population), \\\n                                 (tmp_data_df.Fatalities.values[0] / country_population), \\\n                                 (tmp_data_df.Fatalities_diff.values[0] / country_population),\n                                 (tmp_data_df.Fatalities.values[0] / (tmp_data_df.ConfirmedCases.values[0] + 1e-8))\\\n                                 ])  \n            \n            before_confirmed_case = tmp_data_df.ConfirmedCases.values[0]\n            before_fatalities_case = tmp_data_df.Fatalities.values[0]\n        return np.array([country_onehot]), np.array([encoded_data_c]), before_confirmed_case, np.array([encoded_data_f]), before_fatalities_case\n    \n    def predict_encoder_fatalities(self, day_list, country_label, data_df, country_population):\n        encoded_data = []  \n        before_fatalities = 0\n        for day in day_list:\n            tmp_data_df = data_df[data_df.Date == day]\n            encoded_data.append([\\\n                                 (tmp_data_df.ConfirmedCases.values[0] / country_population), \\\n                                 (tmp_data_df.ConfirmedCases_diff.values[0] / country_population), \\\n                                 (tmp_data_df.Fatalities.values[0] / country_population), \\\n                                 (tmp_data_df.Fatalities_diff.values[0] / country_population),\n                                 (tmp_data_df.Fatalities.values[0] / (tmp_data_df.ConfirmedCases.values[0] + 1e-8))\\\n                                 ])    \n#             if day == day_list[-1]:\n            before_fatalities = tmp_data_df.Fatalities.values[0]\n        return np.array([encoded_data]), before_fatalities\n        \n    def predict_test(self, test_df):\n        predict_confirmed_cases = []\n        predict_fatalities = []\n        country_list = self.country_list.copy()\n        p_country = ''\n        for itest in tqdm(test_df.itertuples(), total=len(test_df), position=0):\n            # get target date list            \n            date_list = itest.Date.split('-')\n            delta = timedelta(days=1)\n            date = datetime(int(date_list[0]), int(date_list[1]), int(date_list[2])) - delta        \n            day_list = []\n            self.country_list = country_list.copy()\n            for i in range(self.days):\n                day_list.append(date.strftime('%Y-%m-%d'))\n                date -= delta\n            day_list = day_list[::-1]\n            \n            try:\n                country_label = itest.Country_Region + '_' + itest.Province_State\n            except:\n                country_label = itest.Country_Region\n            \n            if p_country != country_label:\n                data_df = self.target_df[self.target_df.country_label == country_label]\n                country_population = self.population_df[self.population_df.country_label == country_label].Population.values[0]\n                p_country = country_label\n            \n            country_onehot, encoded_data_c, bc, encoded_data_f, bf = self.predict_encoder_confirmed_cases(day_list, country_label, data_df, country_population)\n#             encoded_data_f, bf = self.predict_encoder_fatalities(day_list, country_label, data_df, country_population)\n#             try:\n            confirmed_cases_increase_rate = self.confirmed_cases_model.predict_on_batch({'encoder_input':encoded_data_c, 'country_onehot':country_onehot, 'target_input':np.array([bc]).reshape((1,1)), 'flag_input':np.array([1])})\n#             except:\n#                 print(bc, itest.Date)\n            mortality_rate = self.fatalities_model.predict_on_batch({'encoder_input':encoded_data_f, 'country_onehot':country_onehot, 'target_input': np.array([bf]).reshape((1,1)), 'flag_input':np.array([1])})\n            confirmed_cases_increase_rate = confirmed_cases_increase_rate.numpy().reshape(1)\n            mortality_rate = mortality_rate.numpy().reshape(1)\n#             confirmed_cases = int(bc * (1 + confirmed_cases_increase_rate))\n#             fatalities = int(confirmed_cases * mortality_rate)\n            \n            t_df = self.target_df[(self.target_df.Date == itest.Date) & (self.target_df.country_label == country_label)]\n            if len(t_df) == 0:\n#                 print(itest.Date, confirmed_cases, fatalities, confirmed_cases_increase_rate, mortality_rate)\n                # add new predict data\n                new_data = [-1, itest.Province_State, itest.Country_Region, itest.Date, confirmed_cases_increase_rate[0], mortality_rate[0]]\n                new_data += [0] * (len(self.target_df.columns) - len(new_data))\n                self.target_df.loc[len(self.target_df)] = new_data#[-1, itest.Province_State, itest.Country_Region, itest.Date, round(confirmed_cases_increase_rate[0]), round(mortality_rate[0]), 0, 0, 0, 0, 0]\n                self.target_df = self.target_df.sort_values(by='Date')\n                self.target_df = self.target_df.sort_values(by='Province_State')\n                self.target_df = self.target_df.sort_values(by='Country_Region')\n                self.cal_increase_rate(self.target_df, self.population_df)\n                data_df = self.target_df[self.target_df.country_label == country_label]\n                predict_confirmed_cases.append(confirmed_cases_increase_rate[0])\n                predict_fatalities.append(mortality_rate[0])\n            else:\n                predict_confirmed_cases.append(t_df.ConfirmedCases.values[0])\n                predict_fatalities.append(t_df.Fatalities.values[0])\n                \n        test_df['ConfirmedCases'] = predict_confirmed_cases\n        test_df['Fatalities'] = predict_fatalities\n        test_df[['ForecastId', 'ConfirmedCases', 'Fatalities']].to_csv('submission.csv', index=False)\n        return test_df\n            \n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_c19 = corona19_predict(datas[1], population, 71, epochs=200)\ny_predict_f, y_train_f = test_c19.train_data_fatalities()\n# y_predict_c, y_train_c = test_c19.train_data_confirmed_cases()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_c, y_train_c = test_c19.train_data_confirmed_cases()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_c19 = corona19_predict(datas[1], population, 71, epochs=200)\ncountry_list = test_c19.country_list.copy()\ntest_c19.load_models(country_list)\n# y_predict_f, y_train_f = test_c19.train_data_fatalities()\n# y_predict_c, y_train_c = test_c19.train_data_confirmed_cases()\n# rr = test_c19.predict_test(datas[2][datas[2].Country_Region == 'Albania'])\n# rr = test_c19.predict_test(datas[2][(datas[2].Country_Region == 'Canada') & (datas[2].Province_State == 'Yukon')])\nrr = test_c19.predict_test(datas[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas[1][(datas[1].Country_Region == 'Canada') & (datas[1].Province_State == 'Yukon')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttt = pd.read_csv('/kaggle/working/submission.csv')\nttt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_ = pd.DataFrame()\nresult_['y_predict'] = y_predict_f[:].reshape(len(y_predict_f))\nresult_['y_label'] = y_train_f[:, 1]\n# print(y_predict[:20], y_train[:20, 0].reshape(20 ,1))\n# print(result_[8150:8170])\n# print(np.max(y_predict_f), np.max(y_train[:, ]))\nplt.plot(y_predict_f[:])\nplt.plot(y_train_f[:, 1])\n# plt.plot((y_train_f[:, 1] / (y_train_f[:, 0] + 1e-8)))\nplt.ylim(0,)\nplt.show()\n\n# import matplotlib.pylab as plt\n# result_ = pd.DataFrame()\n# result_['y_predict'] = y_predict[:].reshape(len(y_predict))\n# result_['y_label'] = y_train[:, 1]\n# print(y_predict[:20], y_train[:20, 0].reshape(20 ,1))\n# print(result_[8150:8170])\nprint(np.max(y_predict_c), np.max(y_train_c[:, 0]))\nplt.plot(y_predict_c[:])\nplt.plot(y_train_c[:, 0])\n# plt.plot((y_train[:, 1] / (y_train[:, 0] + 1e-8)))\nplt.ylim(0,)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}