{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\ntrain['Date'] = pd.to_datetime(train['Date']).dt.date\ntest['Date'] = pd.to_datetime(test['Date']).dt.date\ndf_train = train[train.ConfirmedCases>0]\n\ntest_start = min(test.Date)\ndf_regions = df_train[['Province_State', 'Country_Region']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose method\nmethod = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Method 1: Fit sigmoid function\n## Takes 14 minutes to fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"if method == 1:\n    from scipy.optimize import curve_fit\n    from scipy.optimize import differential_evolution\n    from scipy.optimize import minimize\n    import warnings, datetime\n    from statsmodels.regression.linear_model import OLS\n\n\n    # We test the model on the entire data set df_cty here!!!\n    country_names = pd.unique(test.Country_Region)\n\n    def generate_Initial_Parameters(xData,yData):\n        # min and max used for bounds\n        maxX = max(xData)\n        minX = min(xData)\n        maxY = max(yData)\n        minY = min(yData)\n\n        parameterBounds = []\n        parameterBounds.append([minX, maxX]) # search bounds for a0\n        parameterBounds.append([minX, maxX]) # search bounds for b0\n        parameterBounds.append([0.0, maxY]) # search bounds for a1\n        parameterBounds.append([0.0, maxY]) # search bounds for b1\n\n        def sumOfSquaredError(parameterTuple):\n            warnings.filterwarnings(\"ignore\") # do not print warnings by genetic algorithm\n            val = sigmoid(xData, *parameterTuple)\n            return np.sum((yData - val) ** 2.0)\n\n        # \"seed\" the numpy random number generator for repeatable results\n        result = differential_evolution(sumOfSquaredError, parameterBounds, seed=3)\n        return result.x\n\n    def sigmoid(x, a0, b0, a1, b1):\n        y = a1 / (1 + np.exp(-a0*(x-b0)))+b1\n        return y\n\n    def sig(x,param):\n        return (param[2]/(1 + np.exp(-param[0]*(x-param[1])))+param[3])\n    num_regions = df_regions.shape[0]\n    for i in range(num_regions): \n        if pd.notna(df_regions.iloc[i].Province_State):\n            df_region = df_train.loc[(df_train.Country_Region==df_regions.iloc[i].Country_Region) & (df_train.Province_State==df_regions.iloc[i].Province_State)]\n        else:\n            df_region =  df_train.loc[(df_train.Country_Region==df_regions.iloc[i].Country_Region) & df_train.Province_State.isna()]\n\n        y1_start = min(df_region.Date)\n        y1 = df_region.ConfirmedCases\n        x1_train = np.arange(len(y1))/100\n        y1_scale = y1/max(y1)\n        x1_test_start = (min(test.Date) - y1_start).days\n        x1_test_end = (max(test.Date) - y1_start).days\n        x1_test = np.arange(x1_test_start-1,x1_test_end)/100    \n\n        # Confirmed Cases\n        fig, ax = plt.subplots(figsize=(15,5))\n        plt.title([df_regions.iloc[i].Country_Region, df_regions.iloc[i].Province_State,'Confirmed'])\n        ax.plot(x1_train*100, y1, 'o', label='Confirmed_actual')\n        if len(y1)>1:\n            try:\n                coef1 = curve_fit(sigmoid, x1_train,y1_scale, generate_Initial_Parameters(x1_train,y1_scale))[0]\n                y1_pred = sig(x1_train,coef1)*max(y1)\n                y1_test = sig(x1_test, coef1)*max(y1)\n            except:\n                x = x1_train\n                def polynomial(p, x):\n                    return p[0]+p[1]*x+p[2]*x**2+p[3]*x**3\n\n                def constraint_1st_der(p):\n                    return p[1]+2*p[2]*x+3*p[3]*x**2\n                \n                def constraint_2nd_der(p):\n                    return 2*p[2]+6*p[3]*x\n\n                def objective(p):\n                    return ((polynomial(p, x)- y1)**2).sum()\n\n                cons = (dict(type='ineq', fun=constraint_1st_der), dict(type='ineq', fun=constraint_2nd_der))\n                res = minimize(objective, x0=np.array([0., 0., 0., 0.]), method='SLSQP', constraints=cons)\n                \n                if res.success:\n                    y1_pred = polynomial(res.x, x1_train)\n                    y1_test = polynomial(res.x, x1_test)\n                else:\n                    poly_fit1 = np.poly1d(np.polyfit(x1_train,y1,deg = 2))\n                    y1_pred = poly_fit1(x1_train)\n                    y1_test = poly_fit1(x1_test)\n        else:\n            y1_pred = np.full(len(x1_train),y1)\n            y1_test = np.full(len(x1_test),y1)   \n\n\n        ax.plot(x1_train*100,y1_pred, label='Confirmed_train')\n        ax.plot(x1_test*100,y1_test, label='Confirmed_test')\n        ax.legend()\n        if pd.isnull(df_regions.iloc[i].Province_State):\n            test.loc[(test.Country_Region==df_regions.iloc[i].Country_Region) & test.Province_State.isna(),'ConfirmedCases'] = y1_test\n        else:        \n            test.loc[(test.Country_Region==df_regions.iloc[i].Country_Region) & \\\n                     (test.Province_State==df_regions.iloc[i].Province_State),'ConfirmedCases'] = y1_test\n\n        # Death\n        if len(df_region.loc[df_region.Fatalities>0,'Date'])>0:\n            y2_start = min(df_region.loc[df_region.Fatalities>0,'Date'])\n            y2 = df_region.loc[df_region.Fatalities>0,'Fatalities']        \n            x2_train = np.arange(len(y2))/100    \n            y2_scale = y2/max(y2) \n            x2_test_start = (min(test.Date) - y2_start).days\n            x2_test_end = (max(test.Date) - y2_start).days\n            x2_test = np.arange(x2_test_start-1,x2_test_end)/100     \n            fig, ax = plt.subplots(figsize=(15,5))        \n            ax.plot(x2_train*100, y2, 'o', label='Death_actual')\n            plt.title([df_regions.iloc[i].Country_Region, df_regions.iloc[i].Province_State,'Death'])\n\n            if len(y2)>1:\n                try:\n                    coef2 = curve_fit(sigmoid, x2_train,y2_scale, generate_Initial_Parameters(x2_train,y2_scale))[0]\n                    y2_pred = sig(x2_train,coef2)*max(y2)\n                    y2_test = sig(x2_test, coef2)*max(y2)\n                except:\n                    x = x2_train\n                    def polynomial(p, x):\n                        return p[0]+p[1]*x+p[2]*x**2+p[3]*x**3\n\n                    def constraint_1st_der(p):\n                        return p[1]+2*p[2]*x+3*p[3]*x**2\n                    \n                    def constraint_2nd_der(p):\n                        return 2*p[2]+6*p[3]*x\n\n                    def objective(p):\n                        return ((polynomial(p, x)- y2)**2).sum()\n\n                    cons = (dict(type='ineq', fun=constraint_1st_der), dict(type='ineq', fun=constraint_2nd_der))\n                    res = minimize(objective, x0=np.array([0., 0., 0., 0.]), method='SLSQP', constraints=cons)\n\n                    if res.success:\n                        y2_pred = polynomial(res.x, x2_train)\n                        y2_test = polynomial(res.x, x2_test)\n                    else:\n#                         olsmod2 = OLS(np.log(y2),x2_train)\n#                         olsres2 = olsmod2.fit()\n#                         y2_pred = np.exp(olsres2.predict(x2_train))\n#                         y2_test = np.exp(olsres2.predict(x2_test))\n                        poly_fit2 = np.poly1d(np.polyfit(x2_train,y2,deg = 2))\n                        y2_pred = poly_fit2(x2_train)\n                        y2_test = poly_fit2(x2_test)\n            else:\n                y2_pred = np.full(len(x2_train),y2)\n                y2_test = np.full(len(x2_test),y2)    \n\n            ax.plot(x2_train*100,y2_pred, label='Death_train')\n            ax.plot(x2_test*100,y2_test, label='Death_test')\n            ax.legend()\n            if pd.isnull(df_regions.iloc[i].Province_State):\n                test.loc[(test.Country_Region==df_regions.iloc[i].Country_Region) & test.Province_State.isna(),'Fatalities'] = y2_test\n            else:\n                test.loc[(test.Country_Region==df_regions.iloc[i].Country_Region) & \\\n                         (test.Province_State==df_regions.iloc[i].Province_State),'Fatalities'] = y2_test\n\n        #else:\n        #    print(df_regions.iloc[i], ' has 0 deaths')\n        submission = test.copy()\n        submission.loc[submission.ConfirmedCases.isna(),'ConfirmedCases'] = 0\n        submission.loc[submission.Fatalities.isna(),'Fatalities'] = 0\n        submission['ConfirmedCases'] = submission.ConfirmedCases.astype(int)\n        submission['Fatalities'] = submission.Fatalities.astype(int)\n        submission.loc[submission.Fatalities<0,'Fatalities'] = 0\n        submission.to_csv('/kaggle/working/submission.csv')\n        submission[['ForecastId','ConfirmedCases','Fatalities']].to_csv('submission.csv',index = False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Method 2: Xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder,MinMaxScaler\nfrom xgboost import XGBRegressor\nimport timeit\nfrom random import sample\n\n\ndf_train = train.copy()\ndf_test = test.copy()\n\n# Concate country and state name\ndf_train['Province_State'].fillna('',inplace =True)\ndf_test['Province_State'].fillna('',inplace =True)\ndf_train['Country_Region'] = df_train.Country_Region +'_'+df_train.Province_State\ndf_test['Country_Region'] = df_test.Country_Region +'_'+df_test.Province_State\n\n# Calculate the days since the begining of training data\ntrain_start = min(df_train.Date)\ndf_train['Days'] = df_train['Date'] - train_start\ndf_train['Days'] = df_train.Days.dt.days\ndf_test['Days'] = df_test['Date'] - train_start\ndf_test['Days'] = df_test.Days.dt.days\n\n# Encode country and region name\nle = LabelEncoder()\ndf_train['Country_Region'] = le.fit_transform(df_train['Country_Region'])\ndf_test['Country_Region'] = le.transform(df_test['Country_Region'])\n\n# define y variable\ny_cc = df_train.ConfirmedCases.astype(int)\ny_ft = df_train.Fatalities.astype(int)\n\n# Prepare training data for ConfirmedCases\nx_train_cc = df_train[['Country_Region','Days']]\ntrain_sample = sample(range(df_train.shape[0]),df_train.shape[0]*7//10)\nvald_sample = [i for i in range(df_train.shape[0]) if i not in train_sample]\nx_train1_cc = x_train_cc.iloc[train_sample]\ny_train1_cc = y_cc.iloc[train_sample]\nx_train2_cc = x_train_cc.iloc[vald_sample]\ny_train2_cc = y_cc.iloc[vald_sample]\nx_test_cc = df_test[['Country_Region','Days']]\n\n# Scale input\nmms = MinMaxScaler()\nx_train_cc = mms.fit_transform(x_train_cc)\nx_train1_cc = mms.transform(x_train1_cc)\nx_train2_cc = mms.transform(x_train2_cc)\nx_test_cc = mms.transform(x_test_cc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train XGB model for Confirmed Cases\nstart = timeit.default_timer()\nmodel_cc = XGBRegressor(n_estimators = 1500 , random_state = 0 , max_depth = 15)\nmodel_cc.fit(x_train_cc,y_cc)\n#eval_set = [(x_train2_cc, y_train2_cc)]\n#model_cc.fit(x_train1_cc, y_train1_cc, early_stopping_rounds=10, eval_set=eval_set, verbose=False)\nprint(np.round(timeit.default_timer() - start,decimals =0),'seconds')\n\ny_train_cc_pred = model_cc.predict(x_train_cc)\ny_test_cc_pred = model_cc.predict(x_test_cc)\n\n# Projeciton for training\ndf_train['Pred_CC'] = np.round(y_train_cc_pred,decimals=0)\ndf_test['Pred_CC'] = np.round(y_test_cc_pred,decimals=0)\nfig, ax = plt.subplots(figsize=(15,5))\ntmp = df_train.pivot_table(index ='Date', values =['ConfirmedCases','Pred_CC'],aggfunc = sum).reset_index()\nax.plot(tmp.Date,tmp.ConfirmedCases,'o',label ='Actual')\nax.plot(tmp.Date,tmp.Pred_CC,label ='Pred')\nplt.legend()\n\n# Projeciton for test\nfig, ax = plt.subplots(figsize=(15,5))\ntmp = df_test.pivot_table(index ='Date', values =['Pred_CC'],aggfunc = sum).reset_index()\nax.plot(tmp.Date,tmp.Pred_CC,label ='Pred')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train XGB model for Fatalities\n#x_train_ft = np.array(df_train[['Country_Region','Days','ConfirmedCases']])\nx_train_ft = np.array(df_train[['Country_Region','Days']])\nx_train_ft = mms.fit_transform(x_train_ft)\nx_test_ft = x_test_cc\n\nstart = timeit.default_timer()\nmodel_ft = XGBRegressor(n_estimators = 1500 , random_state = 0 , max_depth = 15)\nmodel_ft.fit(x_train_ft,y_ft)\n#eval_set = [(x_train2_cc, y_train2_cc)]\n#model_cc.fit(x_train1_cc, y_train1_cc, early_stopping_rounds=10, eval_set=eval_set, verbose=False)\nprint(np.round(timeit.default_timer() - start,decimals =0),'seconds')\n\ny_train_ft_pred = model_ft.predict(x_train_ft)\ny_test_ft_pred = model_ft.predict(x_test_ft)\n\n# Projeciton for training\ndf_train['Pred_FT'] = np.round(y_train_ft_pred,decimals=0)\ndf_test['Pred_FT'] = np.round(y_test_ft_pred,decimals=0)\nfig, ax = plt.subplots(figsize=(15,5))\ntmp = df_train.pivot_table(index ='Date', values =['Fatalities','Pred_FT'],aggfunc = sum).reset_index()\nax.plot(tmp.Date,tmp.Fatalities,'o',label ='Actual')\nax.plot(tmp.Date,tmp.Pred_FT,label ='Pred')\nplt.legend()\n\n# Projeciton for test\nfig, ax = plt.subplots(figsize=(15,5))\ntmp = df_test.pivot_table(index ='Date', values =['Pred_FT'],aggfunc = sum).reset_index()\nax.plot(tmp.Date,tmp.Pred_FT,label ='Pred')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission\nsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/submission.csv')\nsubmission['ConfirmedCases'] = y_test_cc_pred.astype(int)\nsubmission['Fatalities'] = y_test_ft_pred.astype(int)\nsubmission.head()\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission = pd.read_csv('/kaggle/input/covid19-week4/submission.csv')\n#submission = submission.merge(test[['ForecastId','Country_Region','Province_State','Date']],on ='ForecastId', how='left')\n#submission['Date'] = pd.to_datetime(submission['Date']).dt.date\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig, ax = plt.subplots(figsize=(15,5))\n#country ='US'\n#submission.loc[submission.Country_Region==country].groupby('Date').ConfirmedCases.sum().plot(ax = ax)\n#submission.loc[submission.Country_Region=='China'].groupby('Date').Fatalities.sum().plot(ax = ax)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}