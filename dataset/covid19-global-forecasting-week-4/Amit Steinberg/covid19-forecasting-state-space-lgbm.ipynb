{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv ('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\ntest = pd.read_csv ('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\ntrain['CRPS']=train.Country_Region+train.Province_State.fillna('')\ntest['CRPS']=test.Country_Region+test.Province_State.fillna('')\ntrain['serd']=train.groupby('CRPS').cumcount()\ntrain.Date=pd.to_datetime(train.Date)\ntest.Date=pd.to_datetime(test.Date)\ntraintest=pd.concat((train[train.Date<min(test.Date)],test)).copy(deep=True)\ntraintest.ConfirmedCases[traintest.ConfirmedCases.isnull()]=1\ntraintest.loc[traintest.ConfirmedCases==0,'days_since_confirmed']=0\ntraintest.loc[traintest.ConfirmedCases>0,'days_since_confirmed']=traintest[traintest.ConfirmedCases>0].groupby('CRPS').cumcount() #The first is 0 to avoid leakakge\ntest=traintest[traintest.Date>=min(test.Date)].copy(deep=True)\ntest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Date=pd.to_datetime(train.Date)\ntrain.set_index('Date',inplace=True,drop=False)\ntrain['LConfirmedCases']=np.log1p(train['ConfirmedCases'])\ntrain['LFatalities']=np.log1p(train['Fatalities'])\ntrain['LDConfirmedCases']=train.groupby('CRPS')[['LConfirmedCases']].diff()\ntrain['LDFatalities']=train.groupby('CRPS')[['LFatalities']].diff()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ntrain['serd']=train.groupby('CRPS').cumcount()\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error\narimas={}\n\nfrom skopt import gbrt_minimize,gp_minimize,forest_minimize\nfrom joblib import dump,load\nimport time \n\nerrs=[]\nx0=load('/kaggle/input/farimas-cov/farimas_cov.joblib')\n\nfor crps in train.CRPS.unique():\n    def opt_arima(p):\n        try:\n            start_time = time.time()\n\n            train_series=train.Fatalities[(train.CRPS==crps) & (train.serd<=70)]\n            test_series=train.Fatalities[(train.CRPS==crps) & (train.serd>70)]\n            mod=SARIMAX(train_series, exog=train.ConfirmedCases[(train.CRPS==crps) & (train.serd<=70)],test_series=train.LFatalities[(train.CRPS==crps) & (train.serd>70)], order=(p[0],p[1], p[2]), freq='D', dates=train_series.index.values,simple_differencing=False, enforce_stationarity=False, enforce_invertibility=False, \n                        hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=True,seasonal_order=(p[3],p[4],p[5],7))\n            res=mod.fit(maxiter=10, method='powell')\n            forecast=res.forecast(len(test_series),exog=train.ConfirmedCases[(train.CRPS==crps) & (train.serd>70)])\n            forecast[forecast<0]=0\n            forecast=np.nan_to_num(forecast)\n            crps_error=np.sqrt(mean_squared_log_error(test_series[10:],forecast[10:]))\n            print(p,crps_error)\n            elapsed_time = time.time() - start_time\n        except:\n            crps_error=1000000\n        return crps_error\n    print(crps)\n    ret=forest_minimize(opt_arima,[[0,5],[0,2],[0,5],[0,2],[0,2],[0,2]],n_calls=20,n_random_starts=5)\n    print(ret.fun,ret.x)\n    errs.append(ret.fun)\n    arimas[crps]=ret.x\n    dump(arimas,'farimas_cov.joblib')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.median(errs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ntrain['serd']=train.groupby('CRPS').cumcount()\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error\narimas={}\n\nfrom skopt import gbrt_minimize,gp_minimize\nfrom joblib import dump,load\nimport time \n\nerrs=[]\nx0=load('/kaggle/input/ccarimas/ccarimas.joblib')\n\nfor crps in train.CRPS.unique():\n    def opt_arima(p):\n        try:\n            train_series=train.ConfirmedCases[(train.CRPS==crps) & (train.serd<=70)]\n            test_series=train.ConfirmedCases[(train.CRPS==crps) & (train.serd>70)]\n            mod=SARIMAX(train_series, order=(p[0],p[1], p[2]), freq='D', dates=train_series.index.values,simple_differencing=False, enforce_stationarity=False, enforce_invertibility=False, \n                        hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=True,seasonal_order=(p[3],p[4],p[5],7))\n            res=mod.fit(maxiter=10, method='powell')\n            forecast=res.forecast(len(test_series))\n            forecast[forecast<0]=0\n            forecast=np.nan_to_num(forecast)\n            crps_error=np.sqrt(mean_squared_log_error(test_series,forecast))\n            print(p,crps_error)\n        except:\n            crps_error=1000000\n        return crps_error\n    print(crps)\n    ret=gbrt_minimize(opt_arima,[[0,10],[0,2],[0,10],[0,2],[0,2],[0,2]],n_calls=20,n_random_starts=5,x0=x0[crps])\n    print(ret.fun,ret.x)\n    errs.append(ret.fun)\n    arimas[crps]=ret.x\n    dump(arimas,'ccarimas.joblib')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.mean(errs))\nnp.median(errs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import load\narimas=load('/kaggle/input/farimas-cov/farimas_cov.joblib')\npd.DataFrame(arimas).transpose().iloc[:,0].value_counts()\n#2\n#1\n#3..5\n#1\n#1\n#1\n#7/13","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_log_error\nfrom joblib import load\narimas=load('/kaggle/input/final-arimas/ccarimas (1).joblib')\nerrors=[]\ntrain.Date=pd.to_datetime(train.Date)\ntest.Date=pd.to_datetime(test.Date)\nfor crps in train.CRPS.unique():\n        print(crps)\n        train_series=train.ConfirmedCases[(train.CRPS==crps) & (train.serd<=70)]\n        test_series=train.ConfirmedCases[(train.CRPS==crps) & (train.serd>70)]\n        p=arimas[crps]\n        mod=SARIMAX(train_series, order=(p[0],p[1], p[2]), freq='D', dates=train_series.index.values,simple_differencing=False, enforce_stationarity=False, enforce_invertibility=False, \n                    hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=True,seasonal_order=(p[3],p[4],p[5],7))\n        res=mod.fit(maxiter=200, method='powell')\n        forecast=res.forecast(len(test[test.CRPS==crps]))\n        forecast[forecast<0]=0\n        forecast=np.nan_to_num(forecast)\n        crps_error=np.sqrt(mean_squared_log_error(test_series,forecast[:len(test_series)]))\n        print(crps_error)\n        errors.append(crps_error)\n        train.loc[(train.CRPS==crps) & (train.Date>=min(test.Date)),'ARIMApred']=forecast[:len(test_series)]\n        test.loc[(test.CRPS==crps),'ARIMApred']=forecast\n       \nprint(np.mean(errors)) #0.65\nprint(np.median(errors)) #0.21\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\narimas=load('/kaggle/input/finals/farimas_cov (2).joblib')\nerrors=[]\nfor crps in train.CRPS.unique():\n        print(crps)\n        train_series=train.Fatalities[(train.CRPS==crps) & (train.serd<=70)]\n        test_series=train.Fatalities[(train.CRPS==crps) & (train.serd>70)]\n        p=arimas[crps]\n        mod=SARIMAX(train_series, exog=train.ConfirmedCases[(train.CRPS==crps) & (train.serd<=70)],order=(p[0],p[1], p[2]), freq='D', dates=train_series.index.values,simple_differencing=False, enforce_stationarity=False, enforce_invertibility=False, \n                    hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=True,seasonal_order=(p[3],p[4],p[5],7))\n        res=mod.fit(maxiter=200, method='powell')\n        forecast=res.forecast(len(test[test.CRPS==crps]),exog=test.ARIMApred[test.CRPS==crps].values)\n        forecast[forecast<0]=0\n        forecast=np.nan_to_num(forecast)\n        crps_error=np.sqrt(mean_squared_log_error(test_series,forecast[:len(test_series)]))\n        print(crps_error)\n        errors.append(crps_error)\n        \n        train.loc[(train.CRPS==crps) & (train.Date>=min(test.Date)),'FARIMApred']=forecast[:len(test_series)]\n        test.loc[(test.CRPS==crps),'FARIMApred']=forecast\n       \nprint(np.mean(errors)) #0.65\nprint(np.median(errors)) #0.21\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test.Country_Region=='Israel',['Date','ARIMApred','FARIMApred']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Public LB"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['LARIMApred']=np.log1p(train['ARIMApred'])\ntrain['LDARIMApred']=train.groupby('CRPS')[['LARIMApred']].diff()\ntrain['LFARIMApred']=np.log1p(train['FARIMApred'])\ntrain['LFDARIMApred']=train.groupby('CRPS')[['LFARIMApred']].diff()\ntrain['LConfirmedCases']=np.log1p(train['ConfirmedCases'])\ntrain['LFatalities']=np.log1p(train['Fatalities'])\ntrain['LDConfirmedCases']=train.groupby('CRPS')[['LConfirmedCases']].diff()\ntrain['LDFatalities']=train.groupby('CRPS')[['LFatalities']].diff()\n\nfor i in range(1,15,1):\n    train['LFatalities'+str(i)]=train.groupby('CRPS')[['LFatalities']].shift(i)\n    train['LDFatalities'+str(i)]=train.groupby('CRPS')[['LDFatalities']].shift(i)\n    train['LConfirmedCases'+str(i)]=train.groupby('CRPS')[['LConfirmedCases']].shift(i)\n    train['LDConfirmedCases'+str(i)]=train.groupby('CRPS')[['LDConfirmedCases']].shift(i)\n\ntrain['LDConfirmedCasesMA']=(train.LDConfirmedCases+train.LDConfirmedCases1+train.LDConfirmedCases2+train.LDConfirmedCases3+train.LDConfirmedCases4)/5\ntrain['LDFatalitiesMA']=(train.LDFatalities+train.LDFatalities1+train.LDFatalities2+train.LDFatalities3+train.LDFatalities4)/5\n\nfor i in range(1,15,1):\n    train['LDFatalitiesMA'+str(i)]=train.groupby('CRPS')[['LDFatalitiesMA']].shift(i)\n    train['LDConfirmedCasesMA'+str(i)]=train.groupby('CRPS')[['LDConfirmedCasesMA']].shift(i)\n\n\ntrain['serd']=train.groupby('CRPS').cumcount()\ntrain.loc[train.ConfirmedCases==0,'days_since_confirmed']=0\ntrain.loc[train.ConfirmedCases>0,'days_since_confirmed']=train[train.ConfirmedCases>0].groupby('CRPS').cumcount() #The first is 0 to avoid leakakge\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\n\nlgbm_cc=LGBMRegressor(num_leaves = 76,learning_rate =10**-1.94,n_estimators=100,min_sum_hessian_in_leaf=(10**-4.2),min_child_samples =138,\n                   colsample_bytree = 0.38,reg_lambda=10**1.35,random_state=1234,n_jobs=4)\nlgbm_f=LGBMRegressor(num_leaves = 27,learning_rate =10**-1.79,n_estimators=100,min_sum_hessian_in_leaf=(10**-4.69),min_child_samples =54,subsample =0.8,subsample_freq=2,\n                   colsample_bytree = 0.76,reg_lambda=10**1.08,random_state=1234,n_jobs=4)\n\nfrom sklearn.preprocessing import OrdinalEncoder\noe=OrdinalEncoder()\nX=oe.fit_transform(train[['Country_Region','Province_State']].fillna(''))\ntrain['CR']=X[:,0]\ntrain['PS']=X[:,1]\n\nlgbm_cc.fit(train.loc[train.serd<=70,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']],train.LDConfirmedCases[train.serd<=70],categorical_feature=['CR','PS'])\nlgbm_f.fit(train.loc[train.serd<=70,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']],train.LDFatalities[train.serd<=70],categorical_feature=['CR','PS'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp=pd.DataFrame()\nimp['feature']=['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']\nimp['imp']=lgbm_f.feature_importances_\npd.options.display.max_rows=999\nimp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\ntrain['serd']=train.groupby('CRPS').cumcount()\ntrainpred = pd.concat((train[train.serd<=70],test)).reset_index(drop=True)\n\n\ntrainpred.sort_values(['Country_Region','Province_State','Date'],inplace=True)\n\nX=oe.transform(trainpred[['Country_Region','Province_State']].fillna(''))\ntrainpred['CR']=X[:,0]\ntrainpred['PS']=X[:,1]\n\ntrainpred['serd']=trainpred.groupby('CRPS').cumcount()\ntrainpred.loc[trainpred.ConfirmedCases.isnull(),'ConfirmedCases']=1 #Heuristic\ntrainpred.loc[trainpred.ConfirmedCases==0,'days_since_confirmed']=0\ntrainpred.loc[trainpred.ConfirmedCases>0,'days_since_confirmed']=trainpred[trainpred.ConfirmedCases>0].groupby('CRPS').cumcount() #The first is 0 to avoid leakakge\ntrainpred['LConfirmedCases']=np.log1p(trainpred['ConfirmedCases'])\ntrainpred['LFatalities']=np.log1p(trainpred['Fatalities'])\ntrainpred['LDConfirmedCases']=trainpred.groupby('CRPS')[['LConfirmedCases']].diff()\ntrainpred['LDFatalities']=trainpred.groupby('CRPS')[['LFatalities']].diff()\ntrainpred['LARIMApred']=np.log1p(trainpred['ARIMApred'])\ntrainpred['LFARIMApred']=np.log1p(trainpred['FARIMApred'])\ntrainpred['LDARIMApred']=trainpred.groupby('CRPS')[['LARIMApred']].diff()\ntrainpred['LDFARIMApred']=trainpred.groupby('CRPS')[['LFARIMApred']].diff()\n\nfor serd in range(71,max(trainpred.serd)+1):\n    print(serd)\n    for i in range(1,8,1):\n        trainpred['LFatalities'+str(i)]=trainpred.groupby('CRPS')[['LFatalities']].shift(i)\n        trainpred['LDFatalities'+str(i)]=trainpred.groupby('CRPS')[['LDFatalities']].shift(i)\n        trainpred['LConfirmedCases'+str(i)]=trainpred.groupby('CRPS')[['LConfirmedCases']].shift(i)\n        trainpred['LDConfirmedCases'+str(i)]=trainpred.groupby('CRPS')[['LDConfirmedCases']].shift(i)\n    trainpred['LDConfirmedCasesMA']=(trainpred.LDConfirmedCases+trainpred.LDConfirmedCases1+trainpred.LDConfirmedCases2+trainpred.LDConfirmedCases3+trainpred.LDConfirmedCases4)/5\n    trainpred['LDFatalitiesMA']=(trainpred.LDFatalities+trainpred.LDFatalities1+trainpred.LDFatalities2+trainpred.LDFatalities3+trainpred.LDFatalities4)/5\n\n    for i in range(1,8,1):\n        trainpred['LDFatalitiesMA'+str(i)]=trainpred.groupby('CRPS')[['LDFatalitiesMA']].shift(i)\n        trainpred['LDConfirmedCasesMA'+str(i)]=trainpred.groupby('CRPS')[['LDConfirmedCasesMA']].shift(i)\n\n    trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']= lgbm_cc.predict(trainpred.loc[trainpred.serd==serd,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']])\n    trainpred.loc[(trainpred.serd==serd) & (trainpred.LDConfirmedCases<0),'LDConfirmedCases']=0\n    trainpred.loc[trainpred.serd==serd,'LConfirmedCases']=trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']+trainpred.loc[trainpred.serd==serd,'LConfirmedCases1']\n    trainpred.loc[trainpred.serd==serd,'ConfirmedCases']=np.exp(trainpred.loc[trainpred.serd==serd,'LConfirmedCases'])-1\n\n    trainpred.loc[trainpred.serd==serd,'LDFatalities']= lgbm_f.predict(trainpred.loc[trainpred.serd==serd,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']])\n    trainpred.loc[(trainpred.serd==serd) & (trainpred.LDFatalities<0),'LDFatalities']=0\n    trainpred.loc[trainpred.serd==serd,'LFatalities']=trainpred.loc[trainpred.serd==serd,'LDFatalities']+trainpred.loc[trainpred.serd==serd,'LFatalities1']\n    trainpred.loc[trainpred.serd==serd,'Fatalities']=np.exp(trainpred.loc[trainpred.serd==serd,'LFatalities'])-1\n    \nprint(np.sqrt(mean_squared_log_error (train.ConfirmedCases[train.serd>70],trainpred.ConfirmedCases[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))])))\nprint(np.sqrt(mean_squared_log_error (train.Fatalities[train.serd>70],trainpred.Fatalities[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict,cross_val_score\nfrom sklearn.linear_model import HuberRegressor,LinearRegression,BayesianRidge,RidgeCV,RANSACRegressor,ElasticNetCV\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor,NeighborhoodComponentsAnalysis\nfrom sklearn.preprocessing import StandardScaler,RobustScaler,QuantileTransformer,PolynomialFeatures\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error\nimport sklearn\nqtx=StandardScaler()\nqty=StandardScaler()\ndf=trainpred.loc[(trainpred.serd>70) & (trainpred.serd<=max(train.serd)),['LConfirmedCases','LARIMApred']]\n\nprint(np.sqrt(-np.mean(cross_val_score(SVR(kernel='rbf',C=10),qtx.fit_transform(df),qty.fit_transform(train.LConfirmedCases[train.serd>70].values.reshape(-1,1)),cv=10,scoring='neg_mean_squared_error'))))\nprint(np.sqrt(mean_squared_error(trainpred.LARIMApred[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))],train.LConfirmedCases[train.serd>70])))\nrc=SVR(kernel='rbf',C=10)\nrc.fit(qtx.fit_transform(df),qty.transform(train.LConfirmedCases[train.serd>70].values.reshape(-1,1)))\ntrainpred.loc[(trainpred.serd>70) & (trainpred.serd<=max(train.serd)),'RLConfirmedCases']=qty.inverse_transform(cross_val_predict(SVR(kernel='rbf',C=10),qtx.transform(df),qty.transform(train.LConfirmedCases[train.serd>70].values.reshape(-1,1)),cv=10).reshape(-1,1))\nprint(np.sqrt(mean_squared_error(trainpred.RLConfirmedCases[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))],train.LConfirmedCases[train.serd>70])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RobustScaler?\nfrom sklearn.model_selection import cross_val_predict,cross_val_score\nfrom sklearn.linear_model import HuberRegressor,LinearRegression,BayesianRidge,RidgeCV,RANSACRegressor,ElasticNetCV\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor,NeighborhoodComponentsAnalysis\nfrom sklearn.preprocessing import StandardScaler,RobustScaler,QuantileTransformer,PolynomialFeatures\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error\nimport sklearn\nqtx_f=StandardScaler()\nqty_f=StandardScaler()\ndf=trainpred.loc[(trainpred.serd>70) & (trainpred.serd<=max(train.serd)),['LConfirmedCases','LARIMApred','LFatalities','LFARIMApred','LDConfirmedCases','LDFatalities']]\n\nprint(np.sqrt(-np.mean(cross_val_score(SVR(kernel='rbf',C=1),qtx_f.fit_transform(df),qty_f.fit_transform(train.LFatalities[train.serd>70].values.reshape(-1,1)),cv=10,scoring='neg_mean_squared_error'))))\nprint(np.sqrt(mean_squared_error(trainpred.LFatalities[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))],train.LFatalities[train.serd>70])))\nrc_f=SVR(kernel='rbf',C=1)\nrc_f.fit(qtx_f.fit_transform(df),qty_f.transform(train.LFatalities[train.serd>70].values.reshape(-1,1)))\ntrainpred.loc[(trainpred.serd>70) & (trainpred.serd<=max(train.serd)),'RLFatalities']=qty_f.inverse_transform(cross_val_predict(SVR(kernel='rbf',C=1),qtx_f.transform(df),qty_f.transform(train.LFatalities[train.serd>70].values.reshape(-1,1)),cv=10).reshape(-1,1))\nprint(np.sqrt(mean_squared_error(trainpred.RLFatalities[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))],train.LFatalities[train.serd>70])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for serd in range(71,max(trainpred.serd)+1):\n    print(serd)\n    \n    if serd<=max(train.serd):\n        trainpred.loc[trainpred.serd==serd,'LConfirmedCases']= trainpred.loc[trainpred.serd==serd,'RLConfirmedCases']\n    else:\n        trainpred.loc[trainpred.serd==serd,'LConfirmedCases']= qty.inverse_transform(rc.predict(qtx.transform(trainpred.loc[trainpred.serd==serd,['LConfirmedCases','LARIMApred']])).reshape(-1,1))\n    trainpred.loc[trainpred.LConfirmedCases<0,'LConfirmedCases']=0\n    trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']=trainpred.loc[trainpred.serd==serd,'LConfirmedCases']-trainpred.loc[trainpred.serd==serd,'LConfirmedCases1']\n    trainpred.loc[trainpred.LDConfirmedCases<0,'LDConfirmedCases']=0\n    trainpred.loc[trainpred.serd==serd,'ConfirmedCases']=np.exp(trainpred.loc[trainpred.serd==serd,'LConfirmedCases'])-1    \n\n    if serd<=max(train.serd):\n        trainpred.loc[trainpred.serd==serd,'LFatalities']= trainpred.loc[trainpred.serd==serd,'RLFatalities']\n    else:\n        trainpred.loc[trainpred.serd==serd,'LFatalities']= qty_f.inverse_transform(rc_f.predict(qtx_f.transform(trainpred.loc[trainpred.serd==serd,['LConfirmedCases','LARIMApred','LFatalities','LFARIMApred','LDConfirmedCases','LDFatalities']])).reshape(-1,1))\n    trainpred.loc[trainpred.LFatalities<0,'LFatalities']=0\n    trainpred.loc[trainpred.serd==serd,'Fatalities']=np.exp(trainpred.loc[trainpred.serd==serd,'LFatalities'])-1    \n    \npublic_trainpred=trainpred.copy()\nprint(np.sqrt(mean_squared_log_error (train.ConfirmedCases[train.serd>70],trainpred.ConfirmedCases[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))])))\nprint(np.sqrt(mean_squared_log_error (train.Fatalities[train.serd>70],trainpred.Fatalities[(trainpred.serd>70) & (trainpred.serd<=max(train.serd))])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_trainpred.loc[public_trainpred.Country_Region.str.contains('Israel'),['Date','ConfirmedCases','Fatalities']].round()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Private Leaderboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_log_error\nfrom joblib import load\narimas=load('/kaggle/input/final-arimas/ccarimas (1).joblib')\nfor crps in train.CRPS.unique():\n        print(crps)\n        train_series=train.ConfirmedCases[(train.CRPS==crps)]\n        p=arimas[crps]\n        mod=SARIMAX(train_series, order=(p[0],p[1], p[2]), freq='D', dates=train_series.index.values,simple_differencing=False, enforce_stationarity=False, enforce_invertibility=False, \n                    hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=True,seasonal_order=(p[3],p[4],p[5],7))\n        res=mod.fit(maxiter=200, method='powell')\n        forecast=res.forecast(len(test[test.CRPS==crps]))\n        forecast[forecast<0]=0\n        forecast=np.nan_to_num(forecast)\n        test.loc[(test.CRPS==crps),'ARIMApred']=forecast\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arimas=load('/kaggle/input/finals/farimas_cov (2).joblib')\nfor crps in train.CRPS.unique():\n        print(crps)\n        train_series=train.Fatalities[(train.CRPS==crps)]\n        p=arimas[crps]\n        mod=SARIMAX(train_series, exog=train.ConfirmedCases[(train.CRPS==crps)],order=(p[0],p[1], p[2]), freq='D', dates=train_series.index.values,simple_differencing=False, enforce_stationarity=False, enforce_invertibility=False, \n                    hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=True,seasonal_order=(p[3],p[4],p[5],7))\n        res=mod.fit(maxiter=200, method='powell')\n        forecast=res.forecast(len(test[test.CRPS==crps]),exog=test.ConfirmedCases[(test.CRPS==crps)].values)\n        forecast[forecast<0]=0\n        forecast=np.nan_to_num(forecast)\n        test.loc[(test.CRPS==crps),'FARIMApred']=forecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\nlgbm_cc=LGBMRegressor(num_leaves = 76,learning_rate =10**-1.94,n_estimators=100,min_sum_hessian_in_leaf=(10**-4.2),min_child_samples =138,\n                   colsample_bytree = 0.38,reg_lambda=10**1.35,random_state=1234,n_jobs=4)\nlgbm_f=LGBMRegressor(num_leaves = 27,learning_rate =10**-1.79,n_estimators=100,min_sum_hessian_in_leaf=(10**-4.69),min_child_samples =54,subsample =0.8,subsample_freq=2,\n                   colsample_bytree = 0.76,reg_lambda=10**1.08,random_state=1234,n_jobs=4)\n\nfrom sklearn.preprocessing import OrdinalEncoder\noe=OrdinalEncoder()\nX=oe.fit_transform(train[['Country_Region','Province_State']].fillna(''))\ntrain['CR']=X[:,0]\ntrain['PS']=X[:,1]\n\nlgbm_cc.fit(train.loc[:,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']],train.LDConfirmedCases,categorical_feature=['CR','PS'])\nlgbm_f.fit(train.loc[:,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']],train.LDFatalities,categorical_feature=['CR','PS'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\ntrainpred = pd.concat((train,test[test.Date>max(train.Date)])).reset_index(drop=True)\ntrainpred.sort_values(['Country_Region','Province_State','Date'],inplace=True)\n\nX=oe.transform(trainpred[['Country_Region','Province_State']].fillna(''))\ntrainpred['CR']=X[:,0]\ntrainpred['PS']=X[:,1]\n\ntrainpred['serd']=trainpred.groupby('CRPS').cumcount()\ntrainpred['LConfirmedCases']=np.log1p(trainpred['ConfirmedCases'])\ntrainpred['LFatalities']=np.log1p(trainpred['Fatalities'])\ntrainpred['LDConfirmedCases']=trainpred.groupby('CRPS')[['LConfirmedCases']].diff()\ntrainpred['LDFatalities']=trainpred.groupby('CRPS')[['LFatalities']].diff()\ntrainpred['LARIMApred']=np.log1p(trainpred['ARIMApred'])\ntrainpred['LFARIMApred']=np.log1p(trainpred['FARIMApred'])\ntrainpred['LDARIMApred']=trainpred.groupby('CRPS')[['LARIMApred']].diff()\ntrainpred['LDFARIMApred']=trainpred.groupby('CRPS')[['LFARIMApred']].diff()\n\nfor serd in range(train.serd.max()+1,trainpred.serd.max()+1):\n    print(serd)\n    for i in range(1,8,1):\n        trainpred['LFatalities'+str(i)]=trainpred.groupby('CRPS')[['LFatalities']].shift(i)\n        trainpred['LDFatalities'+str(i)]=trainpred.groupby('CRPS')[['LDFatalities']].shift(i)\n        trainpred['LConfirmedCases'+str(i)]=trainpred.groupby('CRPS')[['LConfirmedCases']].shift(i)\n        trainpred['LDConfirmedCases'+str(i)]=trainpred.groupby('CRPS')[['LDConfirmedCases']].shift(i)\n    trainpred['LDConfirmedCasesMA']=(trainpred.LDConfirmedCases+trainpred.LDConfirmedCases1+trainpred.LDConfirmedCases2+trainpred.LDConfirmedCases3+trainpred.LDConfirmedCases4)/5\n    trainpred['LDFatalitiesMA']=(trainpred.LDFatalities+trainpred.LDFatalities1+trainpred.LDFatalities2+trainpred.LDFatalities3+trainpred.LDFatalities4)/5\n\n    for i in range(1,8,1):\n        trainpred['LDFatalitiesMA'+str(i)]=trainpred.groupby('CRPS')[['LDFatalitiesMA']].shift(i)\n        trainpred['LDConfirmedCasesMA'+str(i)]=trainpred.groupby('CRPS')[['LDConfirmedCasesMA']].shift(i)\n\n    trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']= lgbm_cc.predict(trainpred.loc[trainpred.serd==serd,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']])\n    trainpred.loc[(trainpred.serd==serd) & (trainpred.LDConfirmedCases<0),'LDConfirmedCases']=0\n    trainpred.loc[trainpred.serd==serd,'LConfirmedCases']=trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']+trainpred.loc[trainpred.serd==serd,'LConfirmedCases1']\n    trainpred.loc[trainpred.serd==serd,'ConfirmedCases']=np.exp(trainpred.loc[trainpred.serd==serd,'LConfirmedCases'])-1\n\n    trainpred.loc[trainpred.serd==serd,'LDFatalities']= lgbm_f.predict(trainpred.loc[trainpred.serd==serd,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                      'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                         'CR','PS',\n                                     'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                     'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']])\n    trainpred.loc[(trainpred.serd==serd) & (trainpred.LDFatalities<0),'LDFatalities']=0\n    trainpred.loc[trainpred.serd==serd,'LFatalities']=trainpred.loc[trainpred.serd==serd,'LDFatalities']+trainpred.loc[trainpred.serd==serd,'LFatalities1']\n    trainpred.loc[trainpred.serd==serd,'Fatalities']=np.exp(trainpred.loc[trainpred.serd==serd,'LFatalities'])-1\n\nprint(np.sqrt(mean_squared_log_error (train.ConfirmedCases[train.serd>=71],trainpred.ConfirmedCases[(trainpred.serd>=71) & (trainpred.serd<=max(train.serd))])))\nprint(np.sqrt(mean_squared_log_error (train.Fatalities[train.serd>=71],trainpred.Fatalities[(trainpred.serd>=71) & (trainpred.serd<=max(train.serd))])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for serd in range(train.serd.max()+1,trainpred.serd.max()+1):\n    print(serd)\n    if serd<=max(train.serd):\n        trainpred.loc[trainpred.serd==serd,'LConfirmedCases']= trainpred.loc[trainpred.serd==serd,'RLConfirmedCases']\n    else:\n        trainpred.loc[trainpred.serd==serd,'LConfirmedCases']= qty.inverse_transform(rc.predict(qtx.transform(trainpred.loc[trainpred.serd==serd,['LConfirmedCases','LARIMApred']])).reshape(-1,1))\n    trainpred.loc[trainpred.LConfirmedCases<0,'LConfirmedCases']=0\n    trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']=trainpred.loc[trainpred.serd==serd,'LConfirmedCases']-trainpred.loc[trainpred.serd==serd,'LConfirmedCases1']\n    trainpred.loc[trainpred.LDConfirmedCases<0,'LDConfirmedCases']=0\n    trainpred.loc[trainpred.serd==serd,'ConfirmedCases']=np.exp(trainpred.loc[trainpred.serd==serd,'LConfirmedCases'])-1    \n\n    if serd<=max(train.serd):\n        trainpred.loc[trainpred.serd==serd,'LFatalities']= trainpred.loc[trainpred.serd==serd,'RLFatalities']\n    else:\n        trainpred.loc[trainpred.serd==serd,'LFatalities']= qty_f.inverse_transform(rc_f.predict(qtx_f.transform(trainpred.loc[trainpred.serd==serd,['LConfirmedCases','LARIMApred','LFatalities','LFARIMApred','LDConfirmedCases','LDFatalities']])).reshape(-1,1))\n    trainpred.loc[trainpred.LFatalities<0,'LFatalities']=0\n    trainpred.loc[trainpred.serd==serd,'Fatalities']=np.exp(trainpred.loc[trainpred.serd==serd,'LFatalities'])-1    \n\nprivate_trainpred=trainpred.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"private_trainpred.loc[private_trainpred.Country_Region.str.contains('Israel'),['Date','ConfirmedCases','Fatalities']].round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.concat((public_trainpred[(public_trainpred.Date>=min(test.Date)) & (public_trainpred.Date<=max(train.Date))],private_trainpred[(private_trainpred.Date>max(train.Date))]),axis=0)[['ForecastId','ConfirmedCases','Fatalities']]\nsubmission.ForecastId=submission.ForecastId.astype('int')\nsubmission.sort_values('ForecastId',inplace=True)\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\ndef opt_lgbm(p):\n    print(p)\n    lgbm_cc=LGBMRegressor(num_leaves = p[0],learning_rate =10**p[1],n_estimators=100,min_sum_hessian_in_leaf=(10**p[2]),min_child_samples =p[3],subsample =p[4],subsample_freq=p[5],\n                       colsample_bytree = p[6],reg_lambda=10**p[7],random_state=1234,n_jobs=4)\n    lgbm_f=LGBMRegressor(num_leaves = p[8],learning_rate =10**p[9],n_estimators=100,min_sum_hessian_in_leaf=(10**p[10]),min_child_samples =p[11],subsample =p[12],subsample_freq=p[13],\n                       colsample_bytree = p[14],reg_lambda=10**p[15],random_state=1234,n_jobs=4)\n\n    lgbm_cc.fit(train.loc[train.serd<=70,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                          'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                             'CR','PS',\n                                         'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                         'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']],train.LDConfirmedCases[train.serd<=70],categorical_feature=['CR','PS'])\n    lgbm_f.fit(train.loc[train.serd<=70,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                          'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                             'CR','PS',\n                                         'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                         'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']],train.LDFatalities[train.serd<=70],categorical_feature=['CR','PS'])\n    trainpred = train.copy()\n    for serd in range(71,max(train.serd)+1):\n        for i in range(1,8,1):\n            trainpred['LFatalities'+str(i)]=trainpred.groupby('CRPS')[['LFatalities']].shift(i)\n            trainpred['LDFatalities'+str(i)]=trainpred.groupby('CRPS')[['LDFatalities']].shift(i)\n            trainpred['LConfirmedCases'+str(i)]=trainpred.groupby('CRPS')[['LConfirmedCases']].shift(i)\n            trainpred['LDConfirmedCases'+str(i)]=trainpred.groupby('CRPS')[['LDConfirmedCases']].shift(i)\n        trainpred['LDConfirmedCasesMA']=(trainpred.LDConfirmedCases+trainpred.LDConfirmedCases1+trainpred.LDConfirmedCases2+trainpred.LDConfirmedCases3+trainpred.LDConfirmedCases4)/5\n        trainpred['LDFatalitiesMA']=(trainpred.LDFatalities+trainpred.LDFatalities1+trainpred.LDFatalities2+trainpred.LDFatalities3+trainpred.LDFatalities4)/5\n\n        for i in range(1,8,1):\n            trainpred['LDFatalitiesMA'+str(i)]=trainpred.groupby('CRPS')[['LDFatalitiesMA']].shift(i)\n            trainpred['LDConfirmedCasesMA'+str(i)]=trainpred.groupby('CRPS')[['LDConfirmedCasesMA']].shift(i)\n\n        trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']= lgbm_cc.predict(trainpred.loc[trainpred.serd==serd,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                          'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                             'CR','PS',\n                                         'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                         'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']])\n        trainpred.loc[(trainpred.serd==serd) & (trainpred.LDConfirmedCases<0),'LDConfirmedCases']=0\n        trainpred.loc[trainpred.serd==serd,'LConfirmedCases']=trainpred.loc[trainpred.serd==serd,'LDConfirmedCases']+trainpred.loc[trainpred.serd==serd,'LConfirmedCases1']\n        trainpred.loc[trainpred.serd==serd,'ConfirmedCases']=np.exp(trainpred.loc[trainpred.serd==serd,'LConfirmedCases'])-1\n\n        trainpred.loc[trainpred.serd==serd,'LDFatalities']= lgbm_f.predict(trainpred.loc[trainpred.serd==serd,['LDConfirmedCases1','LDConfirmedCases2','LDConfirmedCases3','LDConfirmedCases4','LDConfirmedCases5','LDConfirmedCases6','LDConfirmedCases7','LDConfirmedCases8',\n                                          'LDFatalities1','LDFatalities2','LDFatalities3','LDFatalities4','LDFatalities5','LDFatalities6','LDFatalities7','LDFatalities8',\n                                             'CR','PS',\n                                         'LDConfirmedCasesMA1','LDConfirmedCasesMA2','LDConfirmedCasesMA3','LDConfirmedCasesMA4','LDConfirmedCasesMA5','LDConfirmedCasesMA6','LDConfirmedCasesMA7','LDConfirmedCasesMA8',\n                                         'LDFatalitiesMA1','LDFatalitiesMA2','LDFatalitiesMA3','LDFatalitiesMA4','LDFatalitiesMA5','LDFatalitiesMA6','LDFatalitiesMA7','LDFatalitiesMA8']])\n        trainpred.loc[(trainpred.serd==serd) & (trainpred.LDFatalities<0),'LDFatalities']=0\n        trainpred.loc[trainpred.serd==serd,'LFatalities']=trainpred.loc[trainpred.serd==serd,'LDFatalities']+trainpred.loc[trainpred.serd==serd,'LFatalities1']\n        trainpred.loc[trainpred.serd==serd,'Fatalities']=np.exp(trainpred.loc[trainpred.serd==serd,'LFatalities'])-1\n\n    ret=(np.sqrt(mean_squared_log_error (train.ConfirmedCases[train.serd>80],trainpred.ConfirmedCases[trainpred.serd>80]))+np.sqrt(mean_squared_log_error (train.Fatalities[train.serd>80],trainpred.Fatalities[train.serd>80])))/2\n    \n    print(ret)\n    return ret\n\nfrom skopt import gbrt_minimize,gp_minimize\nret=gbrt_minimize(opt_lgbm,[[5,80],[-4.0,0],[-5.0,-2],[1,200],[0.5,1.0],[1,20],[0.2,1.0],[-3.0,3.0],[5,80],[-4.0,0],[-5.0,-2],[1,200],[0.5,1.0],[1,20],[0.2,1.0],[-3.0,3.0]],n_calls=1,n_random_starts=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ret.fun","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ret.x","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}