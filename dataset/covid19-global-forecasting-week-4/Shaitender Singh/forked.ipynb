{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n!pip install mpld3\nimport mpld3\nmpld3.enable_notebook()\n\nfrom sklearn.metrics import mean_squared_log_error\n\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continents = pd.read_csv(\"/kaggle/input/data-for-covid-prediction/Countries-Continents.csv\")\nbeds = pd.read_csv(\"/kaggle/input/data-for-covid-prediction/icu_beds.csv\", header=0)\nagegroups = pd.read_csv(\"/kaggle/input/data-for-covid-prediction/population.csv\")\ndelta_alpha = pd.read_csv(\"/kaggle/input/data-for-covid-prediction/delta_alpha.csv\")\nfixed_vars = pd.read_csv(\"/kaggle/input/data-for-covid-prediction/fixed_vars.csv\")\npop_info = pd.read_csv('/kaggle/input/data-for-covid-prediction/population_data.csv')\n\n# competition data\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv', parse_dates=['Date'])\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv', parse_dates=['Date'])\nsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/submission.csv', index_col=['ForecastId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATE_BORDER = '2020-04-08'\n\n# Create lookup dicts etc.\n# 1. population\ncountry_pop = pop_info.query('Type == \"Country/Region\"')\nprovince_pop = pop_info.query('Type == \"Province/State\"')\npopulation_country_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\npopulation_province_lookup = dict(zip(province_pop['Name'], province_pop['Population']))\npopulation_province_lookup[\"Northwest Territories\"] = 44800\npopulation_province_lookup[\"Yukon\"] = 35874\npopulation_province_lookup[\"Anguilla\"] = 15094\npopulation_province_lookup[\"British Virgin Islands\"] = 31196\npopulation_province_lookup[\"Turks and Caicos Islands\"] = 35446\n# 2. continents\ncontinent_lookup = dict(zip(continents[\"Country\"], continents[\"Continent\"]))\ncontinent_lookup[\"Burma\"] = \"Asia\"\ncontinent_lookup[\"Kosovo\"] = \"Europe\"\ncontinent_lookup[\"MS Zaandam\"] = \"North America\"\ncontinent_lookup[\"West Bank and Gaza\"] = \"Asia\"\ncontinent_lookup[\"Fiji\"] = \"Asia\"\ncontinent_lookup[\"Papua New Guinea\"] = \"Asia\"\n# 3. beds\nbeds_lookup = dict(zip(beds[\"Country\"], beds[\"ICU_Beds\"]))\nbeds_lookup[\"Israel\"] = 10.0\n# 4. agegroups\nagegroup_lookup = dict(zip(agegroups['Location'], agegroups[['0_9', '10_19', '20_29', '30_39', '40_49', '50_59', '60_69', '70_79', '80_89', '90_100']].values))\nagegroup_lookup[\"Burma\"] = agegroup_lookup[\"Myanmar\"]\nagegroup_lookup[\"Dominican Republic\"] = agegroup_lookup[\"Dominica\"]\nagegroup_lookup[\"MS Zaandam\"] = agegroup_lookup[\"Diamond Princess\"]\nagegroup_lookup[\"Holy See\"] = np.asarray(np.ones(10))\nagegroup_lookup[\"West Bank and Gaza\"] = agegroup_lookup[\"Eastern Africa\"] * (4685000 / sum(agegroup_lookup[\"Eastern Africa\"]))\n\n\n# 5. delta and alpha values\ndelta_1 = [float(x.replace(\",\", \".\")) for x in list(delta_alpha.delta_1.values)]\ndelta_2 = [float(x.replace(\",\", \".\")) for x in list(delta_alpha.delta_2.values)]\nalpha_1 = [float(x.replace(\",\", \".\")) for x in list(delta_alpha.alpha_1.values)]\nalpha_2 = [float(x.replace(\",\", \".\")) for x in list(delta_alpha.alpha_2.values)]\n# 6. already fixed variables\n\nfixed_vars_lookup = dict(zip(fixed_vars[\"Area\"], [dict(zip([\"shift\", \"R_0_start\", \"R_0_end\", \"k\", \"x0\", \"get_from\"], vals)) for vals in fixed_vars[[\"shift\", \"R_0_start\", \"R_0_end\", \"k\", \"x0\", \"get_from\"]].values]))\n#!!!#\nfixed_vars_lookup = {}\n#!!!#\n\ntrain['Province_State'] = train['Province_State'].replace('Georgia', 'Georgia (State)')\ntest['Province_State'] = test['Province_State'].replace('Georgia', 'Georgia (State)')\npopulation_province_lookup['Georgia (State)'] = population_province_lookup['Georgia']\n\ntrain['Area'] = train['Province_State'].fillna(train['Country_Region'])\ntest['Area'] = test['Province_State'].fillna(test['Country_Region'])\n\n\n# https://www.kaggle.com/c/covid19-global-forecasting-week-1/discussion/139172\ntrain['ConfirmedCases'] = train.groupby('Area')['ConfirmedCases'].cummax()\ntrain['Fatalities'] = train.groupby('Area')['Fatalities'].cummax()\n\n# Remove the leaking data\ntrain_full = train.copy()\nvalid = train[train['Date'] >= test['Date'].min()]\ntrain = train[train['Date'] < test['Date'].min()]\n\n# Split the test into public & private\ntest['ConfirmedCases'] = 0\ntest['Fatalities'] = 0\ntest_public = test[test['Date'] <= DATE_BORDER]\ntest_private = test[test['Date'] > DATE_BORDER]\n\nsubmission['ConfirmedCases'] = 0\nsubmission['Fatalities'] = 0\n\nFIRST_PRED_DATE = np.datetime64(test_public[\"Date\"].min())\nLAST_PRED_DATE = np.datetime64(test_private[\"Date\"].max())\nNUMBER_OF_PRED_DATES = np.timedelta64(LAST_PRED_DATE - FIRST_PRED_DATE, 'D').astype(int) + 1\nNUMBER_OF_PUBLIC_PRED_DATES = len(test_public[\"Date\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.integrate import odeint\n!pip install lmfit\nfrom lmfit import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extended_deriv_SEIR(y, t, beta, gamma, sigma, N, S_1, S_2, B):\n    '''\n    gamma, sigma, N, S_1, S_2: fixed floats\n    beta, B: callable\n    '''\n    S, E, I, C, R, D = y\n\n    dSdt = -beta(t) * I * S / N\n    dEdt = beta(t) * I * S / N - sigma * E\n    dIdt = sigma * E - 1/12.0 * S_1 * I - gamma * (1 - S_1) * I\n    dCdt = 1/12.0 * S_1 * I - 1/7.5 * S_2 * min(B(t), C) - max(0, C-B(t)) - (1 - S_2) * 1/6.5 * min(B(t), C)\n    dRdt = gamma * (1 - S_1) * I + (1 - S_2) * 1/6.5 * min(B(t), C)\n    dDdt = 1/7.5 * S_2 * min(B(t), C) + max(0, C-B(t))\n    return dSdt, dEdt, dIdt, dCdt, dRdt, dDdt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma = 1.0/9.0\nsigma = 1.0/3.0\n\ndef logistic_R_0(t, R_0_start, k, x0, R_0_end):\n    return (R_0_start-R_0_end) / (1 + np.exp(-k*(-t+x0))) + R_0_end\n\ndef SEIR_Model(days, agegroups, beds_per_100k, delta_agegroups, alpha_agegroups, **R0_kwargs):\n    R_0_start, k, x0, R_0_end = 2.7, 0.2, 95, 1.4\n    def beta(t):\n        return logistic_R_0(t, **R0_kwargs) * gamma\n\n    N = sum(agegroups)\n    rel_freq_delta_agegroups = [agegroups[i]/N * delta_agegroups[i] for i in range(len(agegroups))]\n    S_1 = sum(rel_freq_delta_agegroups)\n    S_2 = sum([rel_freq_delta_agegroups[j] / S_1 * alpha_agegroups[j] for j in range(len(agegroups))])\n    def B(t):\n        # return beds_per_100k / 100_000 * N\n        return 0.003*(beds_per_100k / 100_000 * N)*t + (beds_per_100k / 100_000 * N)\n\n    y0 = N-1.0, 1.0, 0.0, 0.0, 0.0, 0.0\n    t = np.linspace(0, days, days)\n    ret = odeint(extended_deriv_SEIR, y0, t, args=(beta, gamma, sigma, N, S_1, S_2, B))\n    S, E, I, C, R, D = ret.T\n    R_0 = [beta(i)/gamma for i in range(len(t))]\n\n    return t, S, E, I, C, R, D, R_0, B, S_1, S_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_extended_SEIR(y_data, agegroups, beds_per_100k, delta_agegroups, alpha_agegroups, fit_method=\"leastsq\", outbreak_shift=45, fixed=[], **R_0_kwargs_minmax):\n\n    max_days = outbreak_shift + len(y_data)\n    if outbreak_shift >= 0:\n        y_data = np.concatenate((np.zeros(outbreak_shift), y_data))\n    else:\n        y_data = y_data[-outbreak_shift:]\n\n    x_data = np.linspace(0, max_days - 1, max_days, dtype=int)  # x_data is just [0, 1, ..., max_days] array\n    \n    def SEIR_deaths(x, **R_0_kwargs):\n        ret =  SEIR_Model(max_days, agegroups, beds_per_100k, delta_agegroups, alpha_agegroups, **R_0_kwargs)\n        return ret[6][x]\n\n    mod = Model(SEIR_deaths)\n\n    for kwarg, (init, mini, maxi) in R_0_kwargs_minmax.items():\n        mod.set_param_hint(str(kwarg), value=init, min=mini, max=maxi, vary=True)\n\n    params = mod.make_params()\n    for par in fixed:\n        params[par].set(vary=False)\n\n    result = mod.fit(y_data, params, method=fit_method, x=x_data)  # , fit_kws={'maxfev': 100}\n\n    R_0_result_params = {}\n    for val in R_0_kwargs_minmax:\n        R_0_result_params[val] = result.params[val].value\n\n    return result, R_0_result_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def area_to_pred(area):\n    print(\"Area: {}\".format(area), end=\"    \")\n    # 1.\n    y_data_fat = train_full[train_full[\"Area\"] == area][\"Fatalities\"].values\n    y_data_cc = train_full[train_full[\"Area\"] == area][\"ConfirmedCases\"].values\n    country = train_full[train_full[\"Area\"] == area][\"Country_Region\"].values[0]\n    continent = continent_lookup[country]\n    assert(y_data_fat.shape == train_full.Date.unique().shape == y_data_cc.shape)\n    # 2.\n    last_10_days = y_data_fat[-10:]\n    if max(last_10_days) - min(last_10_days) < 10 or max(y_data_fat) < 10:\n        cases_pred, fatalities_pred = simple_predict(y_data_fat, y_data_cc)\n        assert(cases_pred.shape == (NUMBER_OF_PRED_DATES,) == fatalities_pred.shape)\n    else:\n        # 3.\n        # beds\n        beds = beds_lookup.get(area, beds_lookup.get(country, beds_lookup.get(continent, None)))\n        assert(beds is not None)\n        # agegroups and total pop.\n        agegroups = get_agegroups(area, country, continent)\n        N = sum(agegroups)\n        assert(not np.isnan(N))\n        # 4.\n        fixed_vars = fixed_vars_lookup.get(area, fixed_vars_lookup.get(country, None))\n        fixed_vars, fixed, shifts = handle_fixed_vars(fixed_vars)\n        shifts = [int(i) for i in shifts]\n        # 5.\n        #if max(y_data_fat) < 100:\n         #   fixed_vars = {\"R_0_start\": (3.5, 2.0, 5.0),\n          #                \"R_0_end\": (0.9, 0.3, 3.5),\n           #               \"k\": (3.2, 0.01, 5.0),\n            #              \"x0\": (60, 0, 120)}\n           # fixed = [\"R_0_start\"]\n        \n        new_shift, new_vars, cases_pred, fatalities_pred = predict_fatalities(y_data_cc, y_data_fat, beds, \n                                                                              agegroups, N, \n                                                                              fixed_vars, fixed, shifts) \n        cases_pred, fatalities_pred = cases_pred[new_shift:], fatalities_pred[new_shift:]\n        # preds go from first data date until last day of private prediction PLUS 20 days extra\n        # 6.\n        # both 127,\n        fatalities_pred = fatalities_pred[:-20]\n        fatalities_pred = fatalities_pred[-NUMBER_OF_PRED_DATES:]\n        try:\n            cases_pred = extrapolate_cases(cases_pred, y_data_cc)\n            cases_pred = cases_pred[-NUMBER_OF_PRED_DATES:]\n        except:\n            cases_pred, fatalities_pred = simple_predict(y_data_fat, y_data_cc)\n        \n        # preds go from first day of public pred until last day of private pred v/\n\n        # 9.\n       # if not isinstance(fixed_vars[\"get_from\"], str):\n        #    new_row = [area, new_shift, new_vars[\"R_0_start\"], new_vars[\"R_0_end\"], new_vars[\"k\"], new_vars[\"x0\"], np.nan]\n         #   # either replace or add new row at area\n          #  if area in fixed_vars_lookup:\n           #     fixed_vars[fixed_vars[\"Area\"]== area] = new_row\n            #else:\n             #   fixed_vars.loc[len(fixed_vars)] = new_row\n\n    # 7.\n    RMSLE_cc = np.sqrt(mean_squared_log_error(y_data_cc[-NUMBER_OF_PUBLIC_PRED_DATES:], \n                                                cases_pred[:NUMBER_OF_PUBLIC_PRED_DATES]))\n    RMSLE_fa = np.sqrt(mean_squared_log_error(y_data_fat[-NUMBER_OF_PUBLIC_PRED_DATES:],\n                                                fatalities_pred[:NUMBER_OF_PUBLIC_PRED_DATES]))\n    print(\"RMSLE Confirmed Cases: {}, RMSLE Fatalities: {}\".format(np.mean(RMSLE_cc), np.mean(RMSLE_fa)))\n    # 8.\n    test_public[\"Fatalities\"][test_public[\"Area\"] == area] = fatalities_pred[:NUMBER_OF_PUBLIC_PRED_DATES]\n    test_public[\"ConfirmedCases\"][test_public[\"Area\"] == area] = cases_pred[:NUMBER_OF_PUBLIC_PRED_DATES]\n    test_private[\"Fatalities\"][test_private[\"Area\"] == area] = fatalities_pred[NUMBER_OF_PUBLIC_PRED_DATES:]\n    test_private[\"ConfirmedCases\"][test_private[\"Area\"] == area] = cases_pred[NUMBER_OF_PUBLIC_PRED_DATES:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extrapolate_cases(y_hat, y):\n\n    def optfloat(intcoef, ys):\n        xs = np.linspace(0, len(ys), len(ys), dtype=int)\n        from scipy.optimize import curve_fit\n\n        def f(t, m, b, c, d):\n            t = t.astype(int)\n            # return (m*t + b) * y_hat_cc[t + intcoef]\n            return logistic_R_0(t, m, b, c, d) * y_hat[t + intcoef]\n        \n        popt, pcov = curve_fit(f, xs, ys)\n        errsqr = np.linalg.norm(f(xs, *popt) - ys)\n        return dict(errsqr=errsqr, floatcoef=popt)\n\n    def errfun(intcoef, *args):\n        ys = args[0]\n        return optfloat(intcoef, ys)['errsqr']\n    \n    from scipy.optimize import brute\n    ys = y\n    grid = [slice(0, 20, 1)]\n    intcoef = int(brute(errfun, grid, args=(ys,), finish=None))\n    floatcoef = optfloat(intcoef, ys)[\"floatcoef\"]\n    m, b, c, d = floatcoef\n    if intcoef > 0:\n        y_fit = np.asarray([logistic_R_0(t, m, b, c, d) * y_hat[t + intcoef] for t in range(len(y_hat[:-intcoef]))])\n    else:\n        y_fit = np.asarray([logistic_R_0(t, m, b, c, d) * y_hat[t + intcoef] for t in range(len(y_hat))])\n    lost_days = intcoef\n    # print(intcoef, floatcoef)\n    if 20 - lost_days > 0:\n        y_fit = y_fit[:-(20-lost_days)]\n    return np.asarray([max(0.0, x) for x in y_fit])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_fatalities(y_cases, y_data_fat, beds, agegroups, N, fixed_vars, fixed, shifts):\n    curr_ret = None\n    curr_redchi = float(\"+inf\")\n    curr_shift = 0\n    for shift in shifts:\n        ret = fit_extended_SEIR(y_data=y_data_fat, agegroups=agegroups, beds_per_100k=beds, \n                                delta_agegroups=delta_1, alpha_agegroups=alpha_1, fit_method=\"least_squares\", \n                                outbreak_shift=shift, fixed=fixed,\n                                **fixed_vars)\n        try:\n            if ret[0].redchi < curr_redchi:\n                curr_redchi = ret[0].redchi\n                curr_ret = ret\n                curr_shift = shift\n        except:\n            print(\"shift {}: no redchi\".format(shift))\n            continue\n    assert(curr_ret is not None)\n    start_date = np.datetime64(train_full[\"Date\"].min()) - np.timedelta64(curr_shift,'D')\n    x_ticks = np.arange(start_date, LAST_PRED_DATE + np.timedelta64(21, 'D'), step=np.timedelta64(1,'D')) # +20\n    x_ticks = [pd.to_datetime(str(t)).strftime(\"%m/%d\") for t in x_ticks]\n    \n    if curr_ret is None:\n        print(\"Fitting unsuccessful.\")\n        cases_pred, fatalities_pred = simple_predict(y_data_fat, y_cases)\n        return curr_shift, curr_ret[1], cases_pred, fatalities_pred\n        \n    \n    t, S, E, I, C, R, D, R_0, B, S_1, S_2 = SEIR_Model(days=len(x_ticks), agegroups=agegroups, \n                                                       beds_per_100k=beds, delta_agegroups=delta_1, \n                                                       alpha_agegroups=alpha_1, \n                                                       **curr_ret[1])\n    # cases_pred, fatalities_pred = E[-NUMBER_OF_PRED_DAYS:], D[-NUMBER_OF_PRED_DAYS:]\n    return curr_shift, curr_ret[1], I, D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_predict(y_data_fat, y_data_cc):\n    ''' predict last value for all future days '''\n    # print(y_data_fat[-1])\n    return np.full((NUMBER_OF_PRED_DATES,), y_data_cc[-1]), np.full((NUMBER_OF_PRED_DATES,), y_data_fat[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def handle_fixed_vars(fixed_vars):\n    default_fixed_vars = {\"R_0_start\": (3.5, 2.0, 5.0),\n                          \"R_0_end\": (0.9, 0.3, 3.5),\n                          \"k\": (3.2, 0.01, 5.0),\n                          \"x0\": (60, 0, 120)}\n    default_shifts = [50, 30, 10, -10, -30, -50]\n    if fixed_vars is None:\n        return default_fixed_vars, [], default_shifts\n    if isinstance(fixed_vars[\"get_from\"], str):\n        fixed_vars = fixed_vars_lookup[fixed_vars[\"get_from\"]]\n    ret = default_fixed_vars.copy()\n    ret_fixed = []\n    for var in ret.keys():\n        if not np.isnan(fixed_vars[var]):\n            ret[var] = (fixed_vars[var], float(\"-inf\"), float(\"+inf\"))\n            ret_fixed.append(var)\n    if not np.isnan(fixed_vars[\"shift\"]):\n        return ret, ret_fixed, [fixed_vars[\"shift\"]]\n    else:\n        return ret, ret_fixed, default_shifts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_agegroups(area, country, continent):\n    if area in agegroup_lookup:\n        return agegroup_lookup[area]\n    else:\n        area_total_pop = population_country_lookup.get(area, population_province_lookup.get(area, None))\n        region_agegroups = agegroup_lookup.get(country, agegroup_lookup.get(continent, None))\n        assert(area_total_pop is not None and region_agegroups is not None)\n        region_total_pop = sum(region_agegroups)\n        return region_agegroups * (area_total_pop / region_total_pop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_areas = train_full.Area.unique().tolist()\nfailed_areas = set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in tqdm(all_areas):\n    try:\n        area_to_pred(x)\n    except:\n        print(\"Area {} failed\".format(x))\n        failed_areas.add(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = submission.copy()\nt_pub, t_priv = test_public.copy(), test_private.copy()\n\nt_pub = t_pub.set_index('ForecastId')\nt_priv = t_priv.set_index('ForecastId')\n#sub = sub.set_index('ForecastId')\n\nsub.update(t_pub)\nsub.update(t_priv)\nsub.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(r'submission.csv', index=False)\nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}