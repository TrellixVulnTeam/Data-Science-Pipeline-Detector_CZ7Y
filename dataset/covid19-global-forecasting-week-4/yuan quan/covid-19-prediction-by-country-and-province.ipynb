{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NOTICE"},{"metadata":{},"cell_type":"markdown","source":"#### The predict value is not accurate unless the confirm/deaths/recorverd has a huge increasement duration > 2-3 weeks, so please not be scared and keep patient. Figures are for reference only.\n\n\n**NOTE:**\n\n* The model inherited from this notebook : https://www.kaggle.com/alixmartin/covid-19-predictions\n* Use the Github data to predict newest cases https://github.com/CSSEGISandData/COVID-19\n* Can prediction Confirmed / Deaths / Recovered / Active cases\n* Can prediction by specify Province and Country \n* World prediction (With China Data / Without China Data)\n* Predict Province of United States Confirmed / Deaths cases\n* I will update the prediction every day (Last Update 2020/05/15)\n\n\n**Please vote if you like!**"},{"metadata":{},"cell_type":"markdown","source":"# Import"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{},"cell_type":"markdown","source":"Get data from https://github.com/CSSEGISandData/COVID-19"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the old format\nconfirmed_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\ndeath_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\nrecovered_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n\nconfirmed_table = confirmed_df.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Confirmed\").fillna('').drop(['Lat', 'Long'], axis=1)\ndeath_table = death_df.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Deaths\").fillna('').drop(['Lat', 'Long'], axis=1)\nrecovered_table = recovered_df.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Recovered\").fillna('').drop(['Lat', 'Long'], axis=1)\n\nfull_table = confirmed_table.merge(death_table).merge(recovered_table)\n\nfull_table['Date'] = pd.to_datetime(full_table['Date'])\nfull_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning Data"},{"metadata":{},"cell_type":"markdown","source":"Add active column"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# cases \n#cases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\nfull_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n\n# replacing Mainland china with just China\nfull_table['Country/Region'] = full_table['Country/Region'].replace('Mainland China', 'China')\n\n# filling missing values \nfull_table[['Province/State']] = full_table[['Province/State']].fillna('')\n# full_table[cases] = full_table[cases].fillna(0)\nfull_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_time_series(country):\n    # for some countries, data is spread over several Provinces\n    if full_table[full_table['Country/Region'] == country]['Province/State'].nunique() > 1:\n        country_table = full_table[full_table['Country/Region'] == country]\n        country_df = pd.DataFrame(pd.pivot_table(country_table, values = ['Confirmed', 'Deaths', 'Recovered', 'Active'],\n                              index='Date', aggfunc=sum).to_records())\n        return country_df.set_index('Date')[['Confirmed', 'Deaths', 'Recovered', 'Active']]\n    df = full_table[(full_table['Country/Region'] == country) \n                & (full_table['Province/State'].isin(['', country]))]\n    return df.set_index('Date')[['Confirmed', 'Deaths', 'Recovered', 'Active']]\n\n\ndef get_time_series_province(province):\n    # for some countries, data is spread over several Provinces\n    df = full_table[(full_table['Province/State'] == province)]\n    return df.set_index('Date')[['Confirmed', 'Deaths', 'Recovered', 'Active']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data looks a bit dirty, we might get an overly optimistic prediction because the last number is not the final one for instance.\n\nThe model is quite sensitive to this as it has only a handful of points to infer the dynamics from.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'China'\ndf = get_time_series(country)\nif len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n    df.drop(df.tail(1).index,inplace=True)\ndf.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use china data to build model."},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{},"cell_type":"markdown","source":"I will use a model from a marketing paper by Emmanuelle Le Nagard and Alexandre Steyer, that attempts to reflect the social structure of a diffusion process. Their application was the diffusion of innovations, not epidemics. However, there are commonalities in both domains, as the number of contacts each infected person / innovation adopter has seems relevant. It also has the added benefit to allow fitting parameters to the beginning of a time series.\n\npaper is available (in French) [here](https://www.jstor.org/stable/40588987)\n\nThe model is also sensitive to when we define the origin of time for the epidemic process. Here, I just took the first point of the time series available, but adding a lag parameter could be attempted."},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef model_with_lag(N, a, alpha, lag, t):\n    # we enforce N, a and alpha to be positive numbers using min and max functions\n    lag = min(max(lag, -100), 100) # lag must be less than +/- 100 days \n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * (t - lag))) ** max(alpha, 0)\n\ndef model(N, a, alpha, t):\n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * t)) ** max(alpha, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_index = 0\n\ndef model_loss(params):\n#     N, a, alpha, lag = params\n    N, a, alpha = params\n    model_x = []\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, model_index]) ** 2\n#         r += (math.log(1 + model(N, a, alpha, t)) - math.log(1 + df.iloc[t, 0])) ** 2 \n#         r += (model_with_lag(N, a, alpha, lag, t) - df.iloc[t, 0]) ** 2\n#         print(model(N, a, alpha, t), df.iloc[t, 0])\n    return math.sqrt(r) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to explore the 3d parameter space to find a minimum, using gradient descent. There are a number of algorithms to do that in scipy.optimize, I stopped at the first one that seemed to work. Generalized Reduced Gradient as in Excel solver also works."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.optimize import minimize\nuse_lag_model = False\nif use_lag_model:\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15, 0]), method='Nelder-Mead', tol=1e-5).x\nelse:\n    model_index = 0\n    opt_confirmed = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 1\n    opt_deaths = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 2\n    opt_recovered = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nmodel_x = []\nfor t in range(len(df)):\n    model_x.append([df.index[t], model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\nmodel_sim = pd.DataFrame(model_x, dtype=int)\nmodel_sim.set_index(0, inplace=True)\nmodel_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\n\nmodel_sim['Model-Active'] = model_sim['Model-Confirmed'] - model_sim['Model-Deaths'] - model_sim['Model-Recovered']\nmodel_sim.loc[model_sim['Model-Active']<0,'Model-Active'] = 0\nplot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\npd.concat([model_sim, df], axis=1).plot(color = plot_color)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Curve look perfect, let's extend the prediction curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nstart_date = df.index[0]\nn_days = len(df) + 30\nextended_model_x = []\nlast_row = []\n\nisValid = True\nlast_death_rate = 0\n\nfor t in range(n_days):\n    extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\n    \n    #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n    if (t > len(df)):\n        last_row = extended_model_x[-1]\n        if (last_row[2] + last_row[3] > last_row[1]) or (last_row[2] > last_row[1]*0.12):\n            if (isValid):\n                last_row2 = extended_model_x[-2]\n                last_death_rate = last_row2[2]/last_row2[1]\n                isValid = False\n\n        if (last_row[2] > last_row[1]*0.05):\n            last_row[2] = last_row[1]*last_death_rate\n            \n        if (last_row[2] + last_row[3] > last_row[1]):\n            last_row[2] = last_row[1]*last_death_rate\n            last_row[3] = last_row[1]*(1-last_death_rate)\n\nextended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\nextended_model_sim.set_index(0, inplace=True)\n\nextended_model_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\nextended_model_sim['Model-Active'] = extended_model_sim['Model-Confirmed'] - extended_model_sim['Model-Deaths'] - extended_model_sim['Model-Recovered']\nextended_model_sim.loc[extended_model_sim['Model-Active']<0,'Model-Active'] = 0\n\nplot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\npd.concat([extended_model_sim, df], axis=1).plot(color = plot_color)\nprint('China COVID-19 Prediction')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's display predictions for future weeks"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = '{:20,.0f}'.format\nconcat_df = pd.concat([df, extended_model_sim], axis=1)\nconcat_df[concat_df.index.day % 3 == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like no problem, Let's build the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_fit(df, opt_confirmed, opt_deaths, opt_recovered, ax):\n    model_x = []\n    \n    isValid = True\n    last_death_rate = 0\n    \n    for t in range(len(df)):\n        model_x.append([df.index[t], model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\n        \n        #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n        if (t > len(df)):\n            last_row = model_x[-1]\n            if (last_row[2] + last_row[3] > last_row[1]) or (last_row[2] > last_row[1]*0.05):\n                if (isValid):\n                    last_row2 = model_x[-2]\n                    last_death_rate = last_row2[2]/last_row2[1]\n                    isValid = False\n                    \n            if (last_row[2] > last_row[1]*0.05):\n                last_row[2] = last_row[1]*last_death_rate\n                \n            if (last_row[2] + last_row[3] > last_row[1]):\n                last_row[2] = last_row[1]*last_death_rate\n                last_row[3] = last_row[1]*(1-last_death_rate)\n                \n                \n    model_sim = pd.DataFrame(model_x, dtype=int)\n    model_sim.set_index(0, inplace=True)\n    model_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\n\n    model_sim['Model-Active'] = model_sim['Model-Confirmed'] - model_sim['Model-Deaths'] - model_sim['Model-Recovered']\n    model_sim.loc[model_sim['Model-Active']<0,'Model-Active'] = 0\n    plot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\n    return pd.concat([model_sim, df], axis=1).plot(ax=ax, figsize=(14, 10), color = plot_color)\n\ndef display_extended_curve(df, opt_confirmed, opt_deaths, opt_recovered, ax):\n    start_date = df.index[0]\n    n_days = len(df) + 40\n    extended_model_x = []\n    \n    isValid = True\n    last_death_rate = 0\n    \n    for t in range(n_days):\n        extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt_confirmed, t), model(*opt_deaths, t), model(*opt_recovered, t)])\n        \n        #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n        if (t > len(df)):\n            last_row = extended_model_x[-1]\n            if (last_row[2] + last_row[3] > last_row[1]) or (last_row[2] > last_row[1]*0.05):\n                if (isValid):\n                    last_row2 = extended_model_x[-2]\n                    last_death_rate = last_row2[2]/last_row2[1]\n                    isValid = False\n            \n            if (last_row[2] > last_row[1]*0.05):\n                last_row[2] = last_row[1]*last_death_rate\n                    \n            if (last_row[2] + last_row[3] > last_row[1]):\n                last_row[2] = last_row[1]*last_death_rate\n                last_row[3] = last_row[1]*(1-last_death_rate)\n                \n                \n    extended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\n    extended_model_sim.set_index(0, inplace=True)\n    extended_model_sim.columns = ['Model-Confirmed', 'Model-Deaths', 'Model-Recovered']\n\n    extended_model_sim['Model-Active'] = extended_model_sim['Model-Confirmed'] - extended_model_sim['Model-Deaths'] - extended_model_sim['Model-Recovered']\n    \n    extended_model_sim.loc[extended_model_sim['Model-Active']<0,'Model-Active'] = 0\n    plot_color = ['#99990077', '#FF000055', '#0000FF55', '#00FF0055', '#999900FF', '#FF0000FF', '#0000FFFF', '#00FF00FF']\n\n    return pd.concat([extended_model_sim, df], axis=1).plot(ax=ax, figsize=(14, 10), color = plot_color)\n\n\ndef opt_display_model(df, stats):\n    # if the last data point repeats the previous one, or is lower, drop it\n    if len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n        df.drop(df.tail(1).index,inplace=True)\n    global model_index\n    model_index = 0\n    opt_confirmed = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 1\n    opt_deaths = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 2\n    opt_recovered = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    if min(opt_confirmed) > 0:\n        stats.append([country, *opt_confirmed, *opt_deaths, *opt_recovered])\n        n_plot = len(stats)\n        plt.figure(1)\n        ax1 = plt.subplot(221)\n        display_fit(df, opt_confirmed, opt_deaths, opt_recovered, ax1)\n        ax2 = plt.subplot(222)\n        display_extended_curve(df, opt_confirmed, opt_deaths, opt_recovered, ax2)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# World COVID-19 Prediction"},{"metadata":{},"cell_type":"markdown","source":"* **Predict World (With China Data) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\n\ndf = full_table[['Province/State','Country/Region', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Active']].groupby('Date').sum()\nprint('World COVID-19 Prediction (With China Data)')\nopt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Predict World (Without China Data) **\n\nBecause china nearly cleared COVID-19, and data is ahead of the world, so maybe exclude china data sounds resonable."},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\n\ndf = full_table[full_table['Country/Region'] != 'China'][['Province/State','Country/Region', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Active']].groupby('Date').sum()\nprint('World COVID-19 Prediction(Without China Data)')\nopt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict by Specify Province"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\n\n# Province Specify\nfor Province in ['Hong Kong', 'Hubei']:\n    df = get_time_series_province(Province)\n    print('{} COVID-19 Prediction'.format(Province))\n    opt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict by Specify Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country Specify\nstats = []\nfor country in ['US', 'United Kingdom', 'Russia', 'Singapore', 'New Zealand']:\n# for country in ['Sweden']:\n    df = get_time_series(country)\n\n    print('{} COVID-19 Prediction'.format(country))\n    \n    opt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict all country greater than 1000"},{"metadata":{"trusted":true},"cell_type":"code","source":"# All Country Confirmed Greater than 1000\n\nstats = []\nfor country in sorted(full_table['Country/Region'].unique()):\n    df = get_time_series(country)\n    # only consider countries with at least 1000 cases (plus Sweden)\n    if len(df) == 0 or (max(df['Confirmed']) < 1000): \n        continue\n    print('{} COVID-19 Prediction'.format(country))\n    opt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see if we can make some sense from the parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nstats_df = pd.DataFrame(stats)\n# stats_df.columns = ['country', 'N', 'a', 'alpha', 'lag']\nstats_df.columns = ['country', 'Confirmed-N', 'Confirmed-a', 'Confirmed-alpha', 'Deaths-N', 'Deaths-a', 'Deaths-alpha', 'Recorved-N', 'Recorved-a', 'Recorved-alpha']\nstats_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\npd.options.display.float_format = '{:20,.4f}'.format\nstats_df.astype({'Confirmed-N': 'int'}).sort_values(by='Confirmed-N', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = stats_df.plot.scatter(x='Confirmed-alpha', y='Confirmed-a')\n# ax.set_xlim([0, 100])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"N is the potential spread in the country if the dynamics since the beginning of the epidemy persist. One problem is that sometimes we're measuring the spread of testing rather than of the epidemy. For instance New York allegedly started tesing a lot of people, which might explain the current explosive dynamic in the US numbers."},{"metadata":{},"cell_type":"markdown","source":"# Predict all province greater than 500"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\nfor Province in sorted(full_table['Province/State'].unique()):\n    if (Province == ''):\n        continue\n    df = get_time_series_province(Province)\n    # only consider Province with at least 500 cases\n    if len(df) == 0 or (max(df['Confirmed']) < 500): \n        continue\n    print('{} COVID-19 Prediction'.format(Province))\n    opt_display_model(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict United States by Province"},{"metadata":{},"cell_type":"markdown","source":"Finally there is data with United States by Province, let's make models"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the old format\nfulltable_us = pd.read_csv('../input/us-counties-covid-19-dataset/us-counties.csv')\nfulltable_us = fulltable_us.drop(['fips'], axis=1).groupby(['date','state']).sum().reset_index()\nfulltable_us.columns = ['Date', 'Province/State', 'Confirmed', 'Deaths']\nfulltable_us['Date'] = pd.to_datetime(fulltable_us['Date'])\n\nfulltable_us","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only has confirmed and deaths two column, So we build a new model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_fit_us(df, opt_confirmed, opt_deaths, ax):\n    model_x = []\n    \n    isValid = True\n    last_death_rate = 0\n    \n    for t in range(len(df)):\n        model_x.append([df.index[t], model(*opt_confirmed, t), model(*opt_deaths, t)])\n        \n        #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n        if (t > len(df)):\n            last_row = model_x[-1]\n            if (last_row[2] > last_row[1]*0.05):\n                if (isValid):\n                    last_row2 = model_x[-2]\n                    last_death_rate = last_row2[2]/last_row2[1]\n                    isValid = False\n                    \n            if (last_row[2] > last_row[1]*0.05):\n                last_row[2] = last_row[1]*last_death_rate\n                \n                \n    model_sim = pd.DataFrame(model_x, dtype=int)\n    model_sim.set_index(0, inplace=True)\n    model_sim.columns = ['Model-Confirmed', 'Model-Deaths']\n    plot_color = ['#99990077', '#FF000055', '#999900FF', '#FF0000FF']\n\n    return pd.concat([model_sim, df], axis=1).plot(ax=ax, figsize=(14, 10), color = plot_color)\n\ndef display_extended_curve_us(df, opt_confirmed, opt_deaths, ax):\n    start_date = df.index[0]\n    n_days = len(df) + 40\n    extended_model_x = []\n    \n    isValid = True\n    last_death_rate = 0\n    \n    for t in range(n_days):\n        extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt_confirmed, t), model(*opt_deaths, t)])\n        \n        #if deaths + recovered > confirmed or deaths rate > 5%, maybe not valid\n        if (t > len(df)):\n            last_row = extended_model_x[-1]\n            if (last_row[2] > last_row[1]*0.05):\n                if (isValid):\n                    last_row2 = extended_model_x[-2]\n                    last_death_rate = last_row2[2]/last_row2[1]\n                    isValid = False\n            \n            if (last_row[2] > last_row[1]*0.05):\n                last_row[2] = last_row[1]*last_death_rate\n                    \n                \n                \n    extended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\n    extended_model_sim.set_index(0, inplace=True)\n    extended_model_sim.columns = ['Model-Confirmed', 'Model-Deaths']\n\n    plot_color = ['#99990077', '#FF000055', '#999900FF', '#FF0000FF']\n\n    return pd.concat([extended_model_sim, df], axis=1).plot(ax=ax, figsize=(14, 10), color = plot_color)\n\n\ndef opt_display_model_us(df, stats):\n    # if the last data point repeats the previous one, or is lower, drop it\n    if len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n        df.drop(df.tail(1).index,inplace=True)\n    global model_index\n    model_index = 0\n    opt_confirmed = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    model_index = 1\n    opt_deaths = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n    if min(opt_confirmed) > 0:\n        stats.append([country, *opt_confirmed, *opt_deaths])\n        n_plot = len(stats)\n        plt.figure(1)\n        ax1 = plt.subplot(221)\n        display_fit_us(df, opt_confirmed, opt_deaths, ax1)\n        ax2 = plt.subplot(222)\n        display_extended_curve_us(df, opt_confirmed, opt_deaths, ax2)\n        plt.show()\n\n\ndef get_time_series_province_us(province):\n    # for some countries, data is spread over several Provinces\n    global fulltable_us\n    df = fulltable_us[(fulltable_us['Province/State'] == province)]\n    return df.set_index('Date')[['Confirmed', 'Deaths']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test Washington prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = get_time_series_province_us('Washington')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\nprint('{} of United States COVID-19 Prediction'.format('Washington'))\nopt_display_model_us(df, stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks no problem! Let's predict all provinces of United States which confirm cases greater than 500"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\nfor Province in sorted(fulltable_us['Province/State'].unique()):\n    if (Province == ''):\n        continue\n    df = get_time_series_province_us(Province)\n    if len(df) == 0 or (max(df['Confirmed']) < 500): \n        continue\n    print('{} of United States COVID-19 Prediction'.format(Province))\n    opt_display_model_us(df, stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}