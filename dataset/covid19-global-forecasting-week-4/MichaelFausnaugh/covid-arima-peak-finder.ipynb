{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Empirical ARIMA model for the time of COVID-19 peak infections\n\n## Abstract\nI present a method to analyze and predict the reported number of COVID-19 cases, with the goal of identifying the time of peak infections.  Autoregressive Integrated Moving Average (ARIMA) models can provide a reasonable description of the data and appear to make accurate predictions over short time  scales (3--7 days).  The general idea is to extrapolate trends observed in the first derivative using the autocorrelation structure and noise properties of the second differences of the data.  The available data are highly non-stationary, and I describe the transforms required to impose an (approximate) stationary condidtion on the data.\n\nI find that.... there is some issues with overfitting, the data change state a lot, \n\nUnfortunately, this empirical approach cannot address the Kaggle challenge's goal of identifying factors that contribute to the transmission of COVID-19.  Nor can the model predict changes in the statistial properties of the infection data, which might be caused by sudden increases/decreases in the spread of the virus or changes in data reporting practices.  Overall, the model suggests that it is better to rely on the expertise of epidemiologists and pandemic models that make use of the properties of the disease/virus.  On the other hand, discrepancies between the model and data can identify times whent he statistical properties of the data change, which may be useful in interpreting the data and assessing its reliability."},{"metadata":{},"cell_type":"markdown","source":"## Introduction\nAutoregressive moving average (ARMA) models are a flexible family of statistical models that attempt to predict the $i$th observation $y_i$ from previous observations:\n\n$$\\hat y_i = \\sum_{j=1}^p a_j y_{i-j} + \\sum_{k=1}^q b_k \\epsilon_{i-k}$$\n\nwhere $a$ and $b$ are coefficients that will be optimized in a fit, $y_{i-j}$ are previous observations, and $\\epsilon_{i-k}$ are the random deviants (or noise) associated with the previous observations.  ARMA models have two hyperparameters, $p$ and $q$, where $p$ gives the number of points to use in the \"autoregressive part\" of the model $\\left(\\sum_{j=0}^p a_j y_{i-j}\\right)$ and and $q$ gives the number of points in the \"moving average part\" of the model $\\left(\\sum_{k=0}^q b_j \\epsilon_{i-k}\\right)$.  An ARMA model of order $p,q$ is designated ARMA($p,q$).  Loosely speaking, the autoregressive part of the model takes into account the data's correlation structure and defines over how many data points the system preserves it's \"memory\" of the current state, while the moving average part takes into account the system's response to random impulses or \"shocks.\"\n\nARMA models assume that the system's statistical properties (mean, variance, etc.) are constant in time.  Obviously, this is not the case for the COVID-19 data, which quickly grow in time and appear to have an increasing variance (in absolute units) as the counts move through several orders of magnitude.  However, by examining the first or second differences of the data and estimating the variance as a function of time, the trends can be removed and stationary conditions can be imposed.  If the differences of the data are fit with an ARMA model, the original data can be reconstructed by integration---such models are known as Autoregressive Integrated Moving Averages (ARIMA models, also known as Box-Jenkins models).  \n\nThe the code block below, I construct some basic figures to explore the data, and show that the second differences of the COVID-19 data can be made approximately stationary.  I use the total number of cases around the world on each day to make these figures, but have found similar results for country, state, and county data in the US."},{"metadata":{"_uuid":"315cd08e-f61b-4e39-af02-4c503275a2c7","_cell_guid":"1724a3d8-197e-4743-b252-fb08e2b5cc96","trusted":true},"cell_type":"code","source":"#this cell shows imports and calculation \nimport numpy as np\nimport scipy as sp\n\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (12,6)\nmatplotlib.rcParams['figure.dpi'] = 100\nmatplotlib.rcParams['axes.titlesize'] = 20\nmatplotlib.rcParams['axes.labelsize'] = 18\nmatplotlib.rcParams['font.family'] = 'serif'\nmatplotlib.rcParams['mathtext.fontset'] = 'cm'\nmatplotlib.rcParams['mathtext.rm'] = 'serif'\n\nfrom matplotlib.ticker import MultipleLocator\nimport matplotlib.pyplot as plt\n\nfrom datetime import datetime\nimport sys\nimport os\n\nimport pandas as pd\n\nfrom statsmodels.tsa.arima_model import ARMA\n\n#helper function to translate date strings to day of year integers, easier for fitting \ndef str_date_to_doy(date_str):\n        y,m,d = date_str.split('-')\n        doy = int(datetime(int(y),\n                            int(m),\n                            int(d)).strftime('%j'))\n        return int(y),int(m),int(d),doy\n\n    \n#helper function to calculate the rolling variance of w in some window length\ndef get_sliding_var(n,w_length):\n    w = np.ones(w_length)\n    w /= w.sum()\n    return np.convolve( (n - n.mean())**2 ,w,'same')\n    \n#load data, reformat dates\ndf = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\nyear, month, day, day_of_year = [],[],[],[]\nfor t in df['Date'].values:\n    y,m,d,doy = str_date_to_doy(t)\n    year.append(y)\n    month.append(m)\n    day.append(d)\n    day_of_year.append(doy)\n\n#extract the columns that I care the most about\nday_of_year = np.array(day_of_year)\nconfirmed_cases = df['ConfirmedCases'].values\nN_cases = []\nfor doy in np.unique(day_of_year):\n    m = day_of_year == doy\n    N_cases.append(np.sum( confirmed_cases[m] ))\ndoy,u_idx = np.unique(day_of_year,return_index=True)\nmonth = np.array(month)[u_idx]\nday = np.array(day)[u_idx]\nN_cases = np.array(N_cases)\n\n#rename, compute 1st/2nd difference, and compute rolling variance\nt = doy\nn = N_cases\ndiff_n  = np.diff(n)\ndiff2_n = np.diff(np.diff(n))\nw  = np.ones(5)\nw /= np.sum(w)\nvar = get_sliding_var( diff2_n, 5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this cell makes plots of these calculations for inspection\nF,(ax1,ax2,ax3,ax4) = plt.subplots(4,1,sharex='col')\n\nax1.plot(t,n,'k.-')\n\nax2.plot(t[1::],diff_n,'r.-',label='1st difference')\nax2.plot(t[2::],diff2_n,'b.-',label='2nd difference')\nxl,xh = ax2.get_xlim()\nax2.plot([xl,xh],[0,0],'k--')\n\nax3.plot(t[2::], np.sqrt(var),'m.-')\n\nax4.plot(t[2::], diff2_n/np.sqrt(var),'b.-')\n\n#all the formatting follows\nax1.set_yscale('log')\nxl,xh = ax3.get_xlim()\nax4.plot([xl,xh],[0,0],'k--')\nax4.set_xticks(t[::7])\nax4.set_xticklabels(['{:1.0f}/{:02.0f}'.format(z[0],z[1]) for z in zip(month[::7],day[::7])])\nax4.set_xlim([xl,xh])\n\nax1.set_title('Global COVID-19 cases (training)')\nax4.set_xlabel('Date')\nplt.figtext(0.04, 0.75,'Reported\\nCases',fontsize=16,rotation=90)\nplt.figtext(0.04, 0.53,'Derivatives',fontsize=16,rotation=90)\nplt.figtext(0.04, 0.38, 'Rolling\\nSTD',fontsize=16,rotation=90)\nplt.figtext(0.04, 0.18, '2nd_diff/\\nroll_std',fontsize=16,rotation=90)\n\nax2.legend()\n\nF.subplots_adjust(hspace=0)\nF.set_size_inches(12,8)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final plot shows the 2nd difference normalized by an estimate of the rolling standard deviation.  It is fairly flat and random, allowing us to model it as an ARMA process.  \n\n\n## Fitting the Model\n\nI use the `statsmodels` package to fit an ARMA model to the normalized second differences.  The next code block gives the workhorse function that fits the model and returns predictions (and uncertainties on forecasted values).  For now, I will explore relatively simple process models, with order (3,1).  Tuning these hyper parameters is defered to future work.\n\nNote that reconstructing the original function by integrating the predicted 2nd derivative twice results in very poor performance.  This is not unexpected; small errors at early timestamps will grow quickly if using Euler's method.  Based on the `statsmodels` source code, I believe the solution is to use the derivative to predict the next point over one time interval, but to use the observed data lagged by one timestep for every predictions.  This makes the model something like a semi-empirical correction to the observed data.  This has applications for identifying random noise and systematic errors in the data, while Euler's method can be used to predict the data at future times."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_second_derivative_and_predict(t,n,t_extrap, p, q, check_plots=False):\n    \"\"\"\n    for timeseries data 'n' at timestamps t, transform the data \n    to a stationary state (second derivative normalized by rolling standard deviation),\n    and fit an ARMA(p,q) model.  Reconstruct prediction of 1st derivative and original function.  \n    Includes the ability to forecase some number of epochs into the future.\n    \n    Parameters\n    ----------\n    t : ndarray\n        timestamp for data, should be a sequence of integers\n    n : ndarray\n        counts of data to fit\n    t_extrap : int\n        how many epochs beyond the end of the time series to forecast\n    p : int\n        autoreggesive order of the model (timscale of \"memory\")\n    q : int\n        moving average order of the model (response to random impulses/shocks)\n    check_plots : bool\n        flag to plot the data being fitted.  Useful to check if model fails\n    \n    \n    Returns\n    -------\n    predb : ndarray\n        model predictions for original data, has size len(n) + t_extrap\n    preda :\n        model predictions of 1st difference, has size len(n) + t_extrap - 1\n    pred : ndarray\n        model predictions of 2nd differences, has size len(n) + t_extrap - 2\n    epredb : ndarray\n        1sigma estimate of uncertainty on predb, only produced for forecasted (future) epochs\n    res : ndarray\n        residual (data - model)\n    tout : ndarray\n        timestamps of forecast\n    \n    \"\"\"\n    \n    #transform to stationary state--take 2nd difference,\n    #remove the mean, and divide by rolling standard deviation\n    diff_n  = np.diff(n)\n    diff2_n = np.diff(np.diff(n))\n    var = get_sliding_var(diff2_n , 5)\n    std_norm = (diff2_n - diff2_n.mean())/np.sqrt(var)\n    \n\n    if check_plots:\n        print('n data to fit',len(std_norm))\n        F,(ax1,ax2) = plt.subplots(2,1)\n        ax1.plot(t[2::],diff2_n,'k.-')\n        ax2.plot(t[2::],std_norm,'r.-')\n \n\n    tout  = np.r_[t[-1]+1: t[-1] + t_extrap + 1] \n    #print(t,tout)\n\n    #statsmodels interface:  define model, fit, \n    #get the predictions, get the forecasts and errors\n    model = ARMA(std_norm, (p,q), t[2:])\n    m_fit = model.fit(#solver='powell',\n                      disp=0,\n                      #tol=1.e-10\n                       )\n    #pred will have length len(std_dev) + t_extrap\n    #std_norm is missing two points from differencing,\n    #and the index starts at zero.  so subtract 3 from\n    #len(t) to get index of last point\n    pred = m_fit.predict(start = 0,\n                        end=len(t) - 3 + t_extrap,\n                         exog=tout,\n    )\n    fc,stderr,conf_int = m_fit.forecast(steps = t_extrap, exog = tout)\n    \n    #To reconstruct 1st diff and data, \n    #add back the mean, rescale for the non-stationary variance\n    #predicted data needs some estimate of the variance.  \n    #Use the most recent value from rolling variance; but this estimate\n    #has edge effects.  For a window of length 5, the most recent uncorrupted value \n    #is 3 timesteps in the past.\n    #print(sp.sqrt(var))\n    e_data = np.sqrt(var[-3])\n    pred = (pred )*np.r_[np.sqrt(var), [e_data]*t_extrap]\n    epreda = stderr*np.sqrt(var[-3])\n\n    #reconstruct first derivative, and propagate uncertainty.  \n    #I believe this matches the statsmodels algorithm,\n    #where data are used to ancor each successive estimate.  \n    #If we integrated the derivatives (cumsum), small errors at\n    #the begining compound and the model does very poorly\n    preda = np.r_[diff_n[0], diff_n[0:-1] + pred[0:-t_extrap]]\n    for ii in range(t_extrap):\n        preda = np.r_[preda, preda[-1] + pred[-(t_extrap - ii)] ]\n    #cannot have negative new cases\n    preda[preda < 0] = 0\n    #note that e_data term (estimate of data variance) seems to dominate over epreda,\n    #error from model parameter uncertainties\n    epreda = np.sqrt(np.cumsum(epreda**2 + e_data**2))\n    \n    #reconstruct original data and propagate uncertainty.    \n    predb = np.r_[n[0], n[0:-1] + preda[0:-t_extrap]]\n    for ii in range(t_extrap):\n        predb = np.r_[predb, predb[-1] + preda[-(t_extrap - ii)] ] \n    epredb = np.sqrt(np.cumsum(epreda**2 + e_data**2))\n\n    res = n - predb[0:-t_extrap]\n    return predb, preda, pred, epredb, res, tout\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I fit the model and make predictions.  I have included an option to \"freeze\" the prediction date, which makes it easier to asses the results.  I froze the model at April 8, and have been comparing the predictions to new data as it comes in.  (This also makes it easier to comply with the Kaggle rules)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# variables for the fitting\nt_extrap = 7\np = 3\nq = 1\ncheck_std_norm_in_fits = False\n\n#t_freeze = int(datetime(2020,4,11).strftime('%j'))\nt_freeze = int(datetime(2020,4,8).strftime('%j'))\n\nt_fit = t[ t <= t_freeze ]\nn_fit = n[ t <= t_freeze ]\n\n\npredb, preda, pred,\\\nepredb, res, tout = fit_second_derivative_and_predict(t_fit,\n                                                      n_fit,\n                                                      t_extrap,\n                                                      p,\n                                                      q,\n                                                      check_plots=check_std_norm_in_fits)\n\n#fit a second test, but based on data up to t_extrap days in the past.  \n#This is a straight forward way of testing the model, and investigating its limitations\npre_predb, pre_preda,\\\npre_pred, epre_predb,\\\npre_res, pre_tout = fit_second_derivative_and_predict(t_fit[0:-t_extrap],\n                                                       n_fit[0:-t_extrap],\n                                                       2*t_extrap,\n                                                       p,\n                                                       q,\n                                                       check_plots=check_std_norm_in_fits)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_arima_results(t_fit, n_fit, t, n,\n                       t_test, n_test,\n                       predb, preda, pred,\n                       epredb, res, tout,\n                       pre_predb, pre_preda,\n                       pre_pred, epre_predb,\n                       pre_res, pre_tout,\n                       month, day):\n    \"\"\"\n    This functions takes all outputs from the previous cell block,\n    and constructs figures to see the performance of the model.\n    \n    Two figures are produced.  The first shows the data, and to predictions,\n    one from April 1st onward and one from april 8 onward.  \n    The 90% confidence intervals are also plotted.\n    \n    The second figure has the pannels.  \n    The first panel is identical to the first figure (above).  The second panel\n    shows the residuals (data - model).  The third panel shows the first and\n    second differences, and the model predictions of both.\n    \"\"\"\n    #this is just the data and the model/predictions\n    Fa,(ax1a) = plt.subplots(1,1)\n    #this includes three panels to look at the\n    #residuals and 1st/2nd differences\n    F,(ax1,ax2,ax3) = plt.subplots(3,1,sharex='col')\n\n    #print(pred, len(pred))\n    #print(len(sp.r_[t,tout]), len(predb))\n\n\n    ###################################\n    #Panel 1/main plot---data and model\n    ###################################\n    #use data to april 8 to predict the future\n    ax1.plot(np.r_[t_fit,tout],predb,'c.-')\n    #use data to april 1 to predict the future\n    ax1.plot(np.r_[t_fit[0:-t_extrap],pre_tout],pre_predb,'b.-')\n\n    ax1a.plot(np.r_[t_fit,tout],predb,'c.-')\n    ax1a.plot(np.r_[t_fit[0:-t_extrap], pre_tout],pre_predb,'b.-')\n\n\n    #multiply 1 sigma uncertainty by 2.04 to get +/- 45% confidence interval\n    ax1.fill_between(tout,\n                     predb[-t_extrap::] + 2.04*epredb,\n                     predb[-t_extrap::] - 2.04*epredb,\n                     facecolor='c',alpha=0.3)\n    ax1a.fill_between(tout,\n                     predb[-t_extrap::] + 2.04*epredb,\n                     predb[-t_extrap::] - 2.04*epredb,\n                     facecolor='c',alpha=0.3)\n    ax1.fill_between(pre_tout,\n                     pre_predb[-2*t_extrap::] + 2.04*epre_predb,\n                     pre_predb[-2*t_extrap::] - 2.04*epre_predb,\n                     facecolor='b',alpha=0.3)\n    ax1a.fill_between(pre_tout,\n                     pre_predb[-2*t_extrap::] + 2.04*epre_predb,\n                     pre_predb[-2*t_extrap::] - 2.04*epre_predb,\n                     facecolor='b',alpha=0.3)\n\n    #plot data last so that it appears on top\n    ax1.plot(t, n,'k.')\n    ax1a.plot(t,n,'k.')\n\n    ###############################\n    #Panel 2:  residuals and comparison to predictions\n    ###############################\n    ax2.plot(t_fit,res,'c.-')\n    #would plot with residual, except want to connect dots from early times to\n    #new data;  need to find common times between prediction and data\n    ax2.plot(t_fit, n_fit - pre_predb[0:-t_extrap],'b.-')\n    \n    \n    #will fail if t_test goes beyond t_extrap.  For now, let's just cut these points out\n    mask_test = t_test <= max(tout)\n    t_test,n_test = t_test[mask_test], n_test[mask_test]\n    idx_test = np.where(np.in1d(t, t_test))[0]\n    if len(idx_test) > 0:\n        #small offset in time to see data points, if the overlap is too close\n        ax2.plot(t_test+0.1, n_test - predb[idx_test],'co')\n\n    ly,hy = ax2.get_ylim()\n    mask_t = np.in1d(t, pre_tout)\n    idx_pred = np.where(np.in1d( np.r_[t_fit[0:-t_extrap],pre_tout], t[mask_t]))[0]\n    idx_epred = np.where(np.in1d( pre_tout, t))[0]    \n    ax2.errorbar(t[mask_t],\n                 n[mask_t] - pre_predb[idx_pred],\n                 2.04*epre_predb[idx_epred],fmt='bo-',mfc='w')\n\n    ax2.errorbar(tout, np.zeros(t_extrap), 2.04*epredb,fmt='co-',mfc='w')\n    ax2.plot([t_freeze,t_freeze],[ly- 0.2*(hy - ly),hy + 0.2*(hy - ly)],'k--')\n    ax2.set_ylim([ly- 0.2*(hy - ly),hy + 0.2*(hy - ly)])\n\n    xl,xh = ax2.get_xlim()\n    ax2.plot([xl - 0.1*(xh - xl),xh],[0,0],'k--')\n    ax2.set_xlim([xl - 0.1*(xh - xl),xh])\n\n    ###############################\n    #Panel 3:  1st and 2nd differences, along with predictions\n    ###############################\n    ax3.plot(t[1:],diff_n,'r.-',label='$y^{\\prime}$ data')\n    ax3.plot(np.r_[t_fit[1:],tout], preda,'.-',color='m',label='$y^{\\prime}$ model')\n    ax3.plot(np.r_[t_fit[1:-t_extrap],pre_tout], pre_preda,'-.',color='m')\n\n    ax3.plot(t[2:],diff2_n,'.-',color='b',label='$y^{\\prime \\prime}$ data')\n    ax3.plot(np.r_[t_fit[2::],tout], pred,'.-',color='c',label='$y^{\\prime \\prime}$ model')\n    ax3.plot(np.r_[t_fit[2:-t_extrap],pre_tout], pre_pred,'-.',color='c')\n    #xl,xh = ax3.get_xlim()\n\n    ax3.plot([xl - 0.1*(xh - xl), xh],[0,0],'k--')\n    ax3.set_xlim([xl - 0.1*(xh - xl), xh])\n    ly,hy = ax3.get_ylim()\n    ax3.plot([t_freeze,t_freeze],[ly,hy],'k--')\n    ax3.set_ylim([ly,hy])\n\n\n\n    ################################\n    #Formatting commands and labels\n    ################################\n    F.subplots_adjust(hspace=0)\n\n\n    ax3.legend(loc = 'upper left',fontsize=12)\n    tick_locs = np.r_[t_fit, tout]\n    tick_locs = tick_locs[::7]\n    month = np.r_[month, [month[-1]]*len(tout)]\n    day = np.r_[day, sp.r_[0:t_extrap] + 1 + day[-1]]\n\n    ax3.set_xticks(tick_locs)\n    ax3.set_xticklabels(['{:1.0f}/{:02.0f}'.format(z[0],z[1]) for z in zip(month[::7],day[::7])])\n    #print(tick_locs)\n    #print(['{:1.0f}/{:02.0f}'.format(z[0],z[1]) for z in zip(month[::7],day[::7])])\n    ax1a.set_xticks(tick_locs)\n    ax1a.set_xticklabels(['{:1.0f}/{:02.0f}'.format(z[0],z[1]) for z in zip(month[::7],day[::7])])\n\n\n    ax3.xaxis.set_minor_locator(MultipleLocator(1))\n    ax1a.xaxis.set_minor_locator(MultipleLocator(1))\n\n\n    ax3.set_xlabel('Date')\n    #ax1.set_ylabel('Reported Cases',fontsize=16)\n    #ax2.set_ylabel('Residuals',fontsize=16)\n    #ax3.set_ylabel('Derivatives',fontsize=16)\n    plt.figtext(0.04, 0.65,'Reported Cases',fontsize=16,rotation=90)\n    plt.figtext(0.04, 0.45,'Residuals',fontsize=16,rotation=90)\n    plt.figtext(0.04, 0.2,'Derivatives',fontsize=16,rotation=90)\n\n    ax1a.set_ylabel('Reported Cases')\n\n    ax1.set_title('World Coronavirus Cases')\n    ax1a.set_title('World Coronavirus Cases')\n\n    ax1.set_yscale('log')\n    ax1a.set_yscale('log')\n\n    ly,hy = ax1.get_ylim()\n    #print(ly,hy)\n    ax1.set_ylim([ly,hy*3])\n    ax1a.set_ylim([ly,hy*3])\n\n    F.set_size_inches(12,8)\n    #F.savefig('plots/{}_arima_fits_derivatives.png'.format(sys.argv[1]))\n    #Fa.savefig('plots/{}_arima_fits.png'.format(sys.argv[1]))\n\n    \nt_test = t[ t > t_freeze ]\nn_test = n[ t > t_freeze ]\n\nplot_arima_results(t_fit,n_fit, t, n,\n                   t_test,n_test,\n                   predb, preda, pred,\n                   epredb, res, tout,\n                   pre_predb, pre_preda,\n                   pre_pred, epre_predb,\n                   pre_res, pre_tout,\n                   month,day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"*add description of results*\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Predictions for the Kaggle Challenge\n\nThe challenge requires predictions for each country.  In this section, I loop over countries, fit models, and write the predictions to the `submission.csv` file."},{"metadata":{"trusted":true},"cell_type":"code","source":"#need to predict 4-2 to 5-14\ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\n\nt_freeze = int(datetime(2020,4,14).strftime('%j'))\nt_extrap = 30\n\ndef get_states_with_nans(dataframe):\n    \"\"\"\n    assumes we pass only a data frame from a given country, \n    extract the unique list of province/state names.\n    \n    just have to tip toe around the NaN, so it doesn't crash everything\n    \"\"\"\n    states = dataframe['Province_State']\n    state_list = np.unique(states[~states.isnull()])\n    if dataframe['Province_State'].isnull().any():\n        state_list = np.r_[state_list, np.nan]\n    return state_list\n\nfout = open('submission.csv','w')\nfout.write('{},{},{}\\n'.format('ForecastId',\n                               'ConfirmedCases',\n                               'Fatalities'))\n\nfout2 = open('annotated_submission.csv','w')\nfout2.write('{},{},{},{},{},{},{},{}\\n'.format( 'ForecastId',\n                                                'ConfirmedCases',\n                                                'Fatalities',\n                                                'Country_Region',\n                                                'Province_State',\n                                                'N_cases',\n                                                'N_fatalities',\n                                                'Dates'))\n\n\nfor country in np.unique(df_test['Country_Region']):\n    df_use1 = df[ df['Country_Region'].isin([country])]        \n    state_list = get_states_with_nans(df_use1)\n        \n    for state in state_list:\n        print(country,state)\n        if isinstance(state, (str)):\n            state_str = state.replace(',','_')\n        else:\n            state_str = 'nan'\n        try:\n\n            #print(state)\n            if state is np.nan:\n                df_use = df_use1[df_use1['Province_State'].isnull()]\n            else:\n                #print(state)\n                df_use = df_use1[ df_use1['Province_State'].isin([state]) ]\n            \n            year, month, day, day_of_year = [],[],[],[]\n            dates = df_use['Date'].values            \n            for t in dates:\n                y,m,d,doy = str_date_to_doy(t)\n                day_of_year.append(doy)\n            #extract the columns that I care the most about\n            #day_of_year = np.array(day_of_year)\n            t = np.array(day_of_year)\n            N_cases = df_use['ConfirmedCases'].values\n            N_fatalities  = df_use['Fatalities'].values\n            \n            #print(country,state,N_cases[-10:])\n            #if len(N_cases) == 0:\n            #    print(df_use)\n            \n            \n            #to look up the date and ForecastID number of the country/region in question\n            df_test_use = df_test[ df_test['Country_Region'].isin([country])]\n            df_test_use = df_test_use[ df_test_use['Province_State'].isin([state])]\n\n            out_day_of_year = []                \n            for date_out in df_test_use['Date']:\n                y,m,d,doy = str_date_to_doy(date_out)\n                out_day_of_year.append(doy)\n                \n            out_forecast_id = df_test_use['ForecastId'].values\n\n            data_mask = np.in1d(t,out_day_of_year)\n            out_cases_data = np.r_[N_cases[data_mask],\n                                   [np.nan]*(len(out_day_of_year) - len(np.where(data_mask == True)[0]))]\n            out_fatalities_data = np.r_[N_fatalities[data_mask],\n                                       [np.nan]*(len(out_day_of_year) - len(np.where(data_mask == True)[0]))]\n\n\n            \n            \n            for ii,n in enumerate([N_cases, N_fatalities]):\n            \n                t_fit = t[ t <= t_freeze ]\n                n_fit = n[ t <= t_freeze ]                \n                \n                mask = (n_fit == np.nan) | (n_fit == np.inf)\n                t_fit, n_fit = t_fit[~mask], n_fit[~mask]\n                \n                if len(n_fit) == 0:\n                    #print('all data removed!')\n                    raise ValueError('all data removed!')                    \n\n\n                predb, preda, pred,\\\n                epredb, res, tout = fit_second_derivative_and_predict(t_fit,\n                                                                      n_fit,\n                                                                      t_extrap,\n                                                                      p,\n                                                                      q,\n                                                                      check_plots=check_std_norm_in_fits)\n\n                t_pred = np.r_[t_fit, tout]\n                predb = np.around(predb).astype(int)\n                                \n                mask_pred = np.in1d(t_pred,out_day_of_year)\n                                \n                #print(np.c_[t_pred[mask_pred], \n                #            predb[mask_pred], \n                #            out_day_of_year,\n                #            df_test_use['Date'],\n                #            df_test_use['ForecastId']])\n                \n                #ii is either 0 (cases) or 1 (fatalities)\n                if ii == 0:\n                    out_cases = predb[mask_pred]\n                                        \n                else:\n                    out_fatalities = predb[mask_pred]\n                    \n            \n            \n            #print(len(out_forecast_id))\n            #print(len(out_cases))\n            #print(len(out_fatalities))\n            #print(np.shape(out_countries))\n            #print(out_countries)\n            #print(np.shape(out_states))\n            #print(out_states)\n            #print(len(out_cases_data))\n            #print(out_cases_data)\n            #print(len(out_fatalities_data))\n            #print(len(out_dates))\n            #input()\n            \n            #print(len(out_forecast_id), len(out_cases), len(out_fatalities))\n\n                \n                \n            for ii in range(len(out_forecast_id)):\n                fout.write('{},{},{}\\n'.format(int(out_forecast_id[ii]),\n                                               out_cases[ii],\n                                               out_fatalities[ii]))\n                \n                fout2.write('{},{},{},{},{},{},{},{}\\n'.format(\n                    int(out_forecast_id[ii]),\n                        out_cases[ii],\n                        out_fatalities[ii],\n                        country.replace(',','_'),\n                        state_str,\n                        out_cases_data[ii],\n                        out_fatalities_data[ii],\n                        out_day_of_year[ii]))\n            \n            \n        except Exception as e:\n            #raise\n            print(country, state, e)\n            #print(n_fit)\n            out_forecast_id = df_test_use['ForecastId'].values\n            for ii in range(len(out_forecast_id)):\n                if not np.isnan(out_cases_data[ii]): \n                    fout.write('{},{},{}\\n'.format(out_forecast_id[ii],\n                                                   out_cases_data[ii],\n                                                   out_fatalities[ii]))\n                else:\n                    #print(out_cases_data)\n                    idx_write = np.where(~np.isnan(out_cases_data))[0]\n                    #print(idx_write)\n                    fout.write('{},{},{}\\n'.format(out_forecast_id[ii],\n                                                   out_cases_data[idx_write[-1]],\n                                                   out_fatalities[idx_write[-1]]))\n\n            \n                fout2.write('{},{},{},{},{},{},{},{}\\n'.format(\n                            int(out_forecast_id[ii]),\n                            0,\n                            0,\n                            country.replace(',','_'),\n                            state_str,\n                            out_cases_data[ii],\n                            out_fatalities_data[ii],\n                            out_day_of_year[ii]))\n            \n            \n            \n\nfout.close()\nfout2.close()\n#france = df_test[df_test['Country_Region'] == 'France']\n#for state in france['Province_State'].values:\n#    print(state)\n    \n#print(len(np.where(france['Province_State'].isnull())[0]))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_annotate = pd.read_csv('annotated_submission.csv')\n#df_annotate\ndiffs = np.diff(df_annotate['ForecastId'].values)\nidx = np.where(diffs > 1)[0]\nprint(idx)\nidx = np.r_[idx,idx + 1,idx -1]\nprint(np.sort(idx))\n\nmissing_countries = []\nmissing_state = []\nfor country in np.unique(df_test['Country_Region']):\n    if country not in np.unique(df_annotate['Country_Region']):\n        #print(country)\n        missing_countries.append(country)\n    \n \nprint(missing_countries)\nprint(len(np.where(diffs>1)[0]))\nprint(len(df_test))\nprint(len(df_annotate))\n#df_annotate.iloc[np.sort(idx)].head(2000)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results for select states in the US\n\nMy original intent of developing this model was to search for when the peak number of infections might be coming or has happened.  Here are select state with either interesting results or of personal interest to me, along with minor comments.\n"},{"metadata":{},"cell_type":"markdown","source":"## Future Work\n\nI may pursue some of these issues in the week 5 competition.\n\n* For now, I have picked a relatively low order of the ARMA model (p=3, q=1).  These hyperparameters could be optimized---an often pursued approach is to use the Akaike Information Criterion.\n* There is some indication that the model is too sensitive to noise (see, for example, the peak predictions for New York state).  Some regularization or tweaks to the data/model might help with this.\n* The assement of the peak and time thereof is qualitative in this analysis.  It would be desirable to make this quantitative (fit a parabola?) and establish confidence intervals on the time.\n* The infected cases and fatalities are not independent.  Perhaps information from the infections can be used to inform the fit to the fatalities, or a simpler model (shifted and scaled version of the same curve) would work better than fitting the two timeseries independently.\n* It would be interesting to take a list of known events (i.e., when testing ramps up, when hospitalization policy changes, when data reporting methods change, etc.), and correlate it with breaks in the first derivative and outliers in the 2nd derivative."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}