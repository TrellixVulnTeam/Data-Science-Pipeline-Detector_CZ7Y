{"cells":[{"metadata":{"_cell_guid":"a2b0c508-7688-4ed9-9acf-b95b4a9f2dd3","_uuid":"b9e54ae2e59bbe01fae9ae8538f9051a7cc5523f","collapsed":true},"cell_type":"markdown","source":"#  Time Series Forecasting \n"},{"metadata":{"_cell_guid":"323c4a34-6421-4288-ac99-2916900dd11e","_uuid":"10592e734dd2568886858d69960a1e2c8f3f5ed9"},"cell_type":"markdown","source":"# Import libraries and data files"},{"metadata":{"_cell_guid":"102debc2-87d8-41c4-bfac-82508f003abb","_uuid":"28610d78b73a0eb79868e208dd46f91045c7bb75","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom fbprophet import Prophet\nimport matplotlib.pyplot as plt\nimport math as math\nimport seaborn as sns\n\nfrom datetime import datetime\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a7bd9791-f58e-4b4b-ad28-dab934014da8","_uuid":"9d9e2a33b5f7e70d1e3f080c01ef8b4f28a14bc6","trusted":true},"cell_type":"code","source":"# Load the data\ntrain =pd.read_csv(\"/kaggle/input/web-traffic-time-series-forecasting/train_1.csv.zip\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7cf073a9-c545-4199-865e-8ffd911cb53b","_uuid":"f340420a80c636df3d8c6e45f07a418bd0d57583","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9c72cdb3-e2ce-4ad5-8fbd-4cf501441145","_uuid":"9ffedd5f603ceafcd6e6b192f813f64b22fdc9e9"},"cell_type":"markdown","source":"##  Missing values"},{"metadata":{"_cell_guid":"b897047e-daa0-49e7-8f60-2bb46487b9a6","_uuid":"c1be90c632f06a95e31a19a6305d4b204fe0c3dd","trusted":true},"cell_type":"code","source":"# Check the data\nprint(\"Number of data: \", train.shape[0], \"\\n\")\n\nMissing = train[train.isnull().any(axis=1)]\nprint(\"Number of records contain 1+ null: \", Missing.shape[0], \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the number of missing data points per column\nmissing_values_count =train.isnull().sum()\n\n# look at the # of missing points in the first ten columns\nmissing_values_count[0:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e47c83b5-c349-45c0-be65-a333871f14fc","_uuid":"7ff43c83dacae8bbdea49114e98c73808628dba5","scrolled":false,"trusted":true},"cell_type":"code","source":"Missing.iloc[np.r_[0:10, len(Missing)-10:len(Missing)]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.interpolate()\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d6370b56-3177-46af-a1f3-58c1d2c8eb6a","_uuid":"5375f461500b9994ec73ee54bbb50f9dfa566708"},"cell_type":"markdown","source":"##  Data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_time_series(df, row_num, start_col =1, ax=None):\n    if ax is None:\n            fig = plt.figure(facecolor='w', figsize=(10, 6))\n            ax = fig.add_subplot(111)\n    else:\n        fig = ax.get_figure()\n        \n    series_title = df.iloc[row_num, 0]\n    sample_series = df.iloc[row_num, start_col:]\n    sample_series.plot(style=\".\", ax=ax)\n    ax.set_title(\"Series: %s\" % series_title)\n\nfig, axs  = plt.subplots(4,1,figsize=(12,12))\nplot_time_series(train, 1, ax=axs[0])\nplot_time_series(train, 10, ax=axs[1])\nplot_time_series(train, 100, ax=axs[2])\nplot_time_series(train, 1005, ax=axs[3])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6feda8d9-9b89-4c3a-ac5a-4c15ea2b1f8a","_uuid":"e8471f75073027f67fdf8bd9d2427d19451af98b"},"cell_type":"markdown","source":" \n## Article names "},{"metadata":{"_cell_guid":"8682bf5e-f60f-45d3-8df3-88a0996f4031","_uuid":"89747bd76d2f750f36e7335f2012262f5926edd0","trusted":true},"cell_type":"code","source":"train_flattened = pd.melt(train[list(train.columns[-50:])+['Page']], id_vars='Page', var_name='date', value_name='Visits')\ntrain_flattened['date'] = train_flattened['date'].astype('datetime64[ns]')\ntrain_flattened['weekend'] = ((train_flattened.date.dt.dayofweek) // 5 == 1).astype(float)\n\n# Median by page\ndf_median = pd.DataFrame(train_flattened.groupby(['Page'])['Visits'].median())\ndf_median.columns = ['median']\n\n# Average by page\ndf_mean = pd.DataFrame(train_flattened.groupby(['Page'])['Visits'].mean())\ndf_mean.columns = ['mean']\n\n# Max by page\ndf_mean = pd.DataFrame(train_flattened.groupby(['Page'])['Visits'].max())\ndf_mean.columns = ['max']\n\n# Merging data\ntrain_flattened = train_flattened.set_index('Page').join(df_mean).join(df_median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_flattened.reset_index(drop=False,inplace=True)\ntrain_flattened['weekday'] = train_flattened['date'].apply(lambda x: x.weekday())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature engineering with the date\ntrain_flattened['year']=train_flattened.date.dt.year \ntrain_flattened['month']=train_flattened.date.dt.month \ntrain_flattened['day']=train_flattened.date.dt.day\n\ntrain_flattened.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_flattened.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_name=train_flattened.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting language of the page from it's name and adding it to a set so that we only have \n# unique entry and can easily find out the total number of languages in dataset\nlang=set()\nfor k in page_name:\n  index=k.find('.wikipedia')\n  lang.add(k[index-1:index-3:-1][::-1])\nprint(lang)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_flattened.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_flattened['date'] = pd.to_datetime(train_flattened['date'])\ntrain_flattened = train_flattened.set_index('date') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train_flattened.dropna(),\n            \n             x_vars=['weekday','year',\n                     'month','day'],\n             y_vars='Visits',\n             height=5,\n             plot_kws={'alpha':0.15, 'linewidth':0}\n            )\nplt.suptitle('Visit by weekday, year of Month , day')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train_flattened['Visits'].resample('W').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sort_index(inplace=True)\ny","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stationarity For Sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\n\ndef test_stationarity(timeseries):\n    \n    #Determing rolling statistics\n\n    rolmean = pd.Series(timeseries).rolling(window=12).mean()\n    rolstd = pd.Series(timeseries).rolling(window=12).std()\n    \n\n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ARIMA Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n\np = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(y,\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting the ARIMA model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nmod = sm.tsa.statespace.SARIMAX(y,\n                                order=(1, 1, 1),\n                                seasonal_order=(1, 1, 0, 12),\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary().tables[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = results.get_prediction(start=pd.to_datetime('2017-01-01'), dynamic=False)\n\ny_forecasted = pred.predicted_mean\ny_truth = y['2015-01-01':]\nmse = ((y_forecasted - y_truth) ** 2).mean()\nprint('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing forecasts\npred_uc = results.get_forecast(steps=100)\npred_ci = pred_uc.conf_int()\nax = y.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('Date')\nax.set_ylabel('Visit')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}