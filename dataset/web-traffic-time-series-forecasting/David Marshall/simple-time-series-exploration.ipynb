{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Simple Time Series Methods\n\nThis notebook demonstrates some simple time series methods from the statsmodels package and simple predictions generated."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport timeit\nstart_time = timeit.default_timer()\ntrain = pd.read_csv('../input/train_2.csv')\nelapsed = timeit.default_timer() - start_time\nprint(\"Time to load data: \", round(elapsed, 2), \"s\")\nprint(\"Shape of Data: \", train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to run the tume series I need the data to be transposed to show 1 article per column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.transpose()\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turn the first row to a header:"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_header = train.iloc[0]\ntrain = train[1:]\ntrain.columns = new_header\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the average number of missing values for each website:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each page has an average of 48 missing rows. This is a lot. I'm going to do simple forwards (and backwards) fill imputation."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(method = \"ffill\")\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(method = \"bfill\")\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To decide which model is best, I'll use a small sample of 100 websites:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = train.sample(n = 100, axis = 1)\nsample.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now withold 1 month for testing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test = sample.tail(30)\nsample = sample.head(803 - 30)\nsample.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data sets match. Now I try 8 different time series models and make predictions with the test set, one after the other. I'm going to measure the time and compare the RMSE to the test set, before choosing one to predict on all the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 1. Autoregression (AR)\nfrom statsmodels.tsa.ar_model import AR\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = AR(sample[column], freq = 'D')\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.predict(start_date, end_date)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Moving Average (MA)\nfrom statsmodels.tsa.arima_model import ARMA\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = ARMA(sample[column], order = (0,1), freq = 'D')\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.predict(start_date, end_date)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 3. Autoregressive Moving Average (ARMA)\nfrom statsmodels.tsa.arima_model import ARMA\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = ARMA(sample[column], order = (1,0), freq = 'D')\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.predict(start_date, end_date)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Autoregressive Integrated Moving Average (ARIMA)\nfrom statsmodels.tsa.arima_model import ARIMA\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = ARIMA(sample[column], order = (1, 0, 0), freq = 'D')\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.predict(start_date, end_date)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. SARIMAX\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = SARIMAX(sample[column], freq = 'D')\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.forecast(steps = 30)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. SARIMAX parameters\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = SARIMAX(sample[column], order = (1,1,0), freq = 'D')\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.forecast(steps = 30)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7. Simple Exponential Smoothing (SES)\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = SimpleExpSmoothing(sample[column])\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.predict(start_date, end_date)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 8. Holt Winters Exponential Smoothing (HWES)\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n\npreds_data = pd.DataFrame()\nstart_date = \"2017-08-12\"\nend_date = \"2017-09-10\"\n\n# Measure time\nstart_time = timeit.default_timer()\n\n# Fit model\nfor column in sample:\n    model = ExponentialSmoothing(sample[column])\n    model_fit = model.fit()\n# Make prediction\n    yhat = model_fit.predict(start_date, end_date)\n    preds_data[column] = yhat\n\n# End time\nelapsed = timeit.default_timer() - start_time\n\nprint(\"Time for 100 predictions: \", round(elapsed, 2), \"s\")\nprint(\"RMSE: \", (((preds_data - sample_test) ** 2).mean() ** 0.5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With these tested I can pick one and then generate predictions for all the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}