{"cells":[{"metadata":{},"cell_type":"markdown","source":"### 0.0 Load libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\ninit_notebook_mode(connected=True)\n\nimport re\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        continue\n        print(os.path.join(dirname, filename))\n        \nimport colorlover as cl\nfrom IPython.display import HTML\n\nimport collections","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 0.1 Load dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/web-traffic-time-series-forecasting/train_1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train.iloc[34436].Page","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing values"},{"metadata":{},"cell_type":"markdown","source":"I have a function that computes the number of missing values per column. There appear to be quite a few of those in this dataset, and they'll need to be dealt with!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missingData(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum())/df.isnull().count().sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\n    return missing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"missingData(train).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"missingData(train).tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Individual Webpages"},{"metadata":{},"cell_type":"markdown","source":"The dataset consists of time series for a decently large number of pages. The first thing I did to explore the data was look at random at the time series for particular entries. "},{"metadata":{"trusted":true},"cell_type":"code","source":" sns.distplot(np.log1p(train.drop(columns='Page').sum(axis=1)), rug=True, kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [\n    go.Histogram(\n        x=np.log1p(train.drop(columns='Page').sum(axis=1))/np.log(10),\n        histnorm='probability'\n    )\n]\n\n\nlayout = dict(\n            title='Distribution of page views',\n            autosize= True,\n            bargap= 0.015,\n            height= 400,\n            width= 600,       \n            hovermode= 'x',\n            xaxis=dict(\n            autorange= True,\n            zeroline= False,\n            tickvals=[0,1,2, 3, 4,5, 6, 7,8, 9,10],\n            ticktext=['10$^0$', '10$^1$', '10$^2$', '10$^3$', '10$^4$', '10$^5$','10$^6$', '10$^7$','10$^8$','10$^9$', '10$^{10}$',]),\n            yaxis= dict(\n            autorange= True,\n            showticklabels= True,\n           ))\n\nfig1 = dict(data=data, layout=layout)\n\n\niplot(fig1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(\n    go.Histogram(\n        x = np.log1p(train.drop(columns='Page').sum(axis=1)),\n        histnorm='probability',\n        name = 'Training set')\n)\n\n\nfig.update_layout(height=450, width=900, title = 'Distribution of total no. views')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"webpage = train.iloc[11214]\nwebpage_name = webpage['Page']\nwebpage = webpage.drop(labels = ['Page', 'lang'])\ndomnhall_gleeson = we\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage,\n        name='signal', \n        line = dict(color='crimson', width=4)\n        )\n)\n\n\"\"\"\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage.rolling(14).mean(),\n        name='2-week rolling average', \n        line = dict(color='crimson', width=4)\n        )\n)\n\"\"\"    \n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=webpage_name,\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Daily Traffic\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"webpage = train.iloc[34436]\nwebpage_name = webpage['Page']\nwebpage = webpage.drop(labels = ['Page'])\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage,\n        name='signal', \n        line = dict(color='crimson', width=4)\n        )\n)\n\n\"\"\"\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage.rolling(14).mean(),\n        name='2-week rolling average', \n        line = dict(color='crimson', width=4)\n        )\n)\n\"\"\"    \n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=webpage_name,\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Daily Traffic\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"webpage = train.iloc[4436]\nwebpage_name = webpage['Page']\nwebpage = webpage.drop(labels = ['Page'])\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage,\n        name='signal', \n        line = dict(color='crimson', width=4)\n        )\n)\n\n\"\"\"\nfig.add_trace(\n    go.Scatter(\n        x = webpage.index,\n        y = webpage.rolling(14).mean(),\n        name='2-week rolling average', \n        line = dict(color='crimson', width=4)\n        )\n)\n\"\"\"    \n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=webpage_name,\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Daily Traffic\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"npages = 5\ntop_pages = {}\nfor key in lang_sets:\n    print(key)\n    sum_set = pd.DataFrame(lang_sets[key][['Page']])\n    sum_set['total'] = lang_sets[key].sum(axis=1)\n    sum_set = sum_set.sort_values('total',ascending=False)\n    print(sum_set.head(10))\n    top_pages[key] = sum_set.index[0]\n    print('\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Global features: Page Language"},{"metadata":{},"cell_type":"markdown","source":"I'm reusing [muonneutrino's function](https://www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration) for computing the language of a webpage."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_language(page):\n    res = re.search('[a-z][a-z].wikipedia.org', page)\n    if res:\n        return res[0][0:2]\n    return 'na'\n\ntrain['lang'] = train.Page.map(get_language)\n\nfrom collections import Counter\n\nlanguages = pd.DataFrame.from_dict(dict(Counter(train.lang)), orient='index', columns=['Count'])\n\nfig = go.Figure([go.Bar(x=languages.index, y=languages.Count, marker_color='crimson')])\n\nfig.update_layout(\n    title=go.layout.Title(\n        text=\"Wikipage total counts per language\",\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            text=\"Language\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Number of Webpages\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n\nfig.update_xaxes( tickfont=dict(size=16))\nfig.update_yaxes( tickfont=dict(size=16))\n\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"lang_sets = {}\n\nfor language in languages.index:\n    print(language)\n    lang_sets[language] = train[train.lang==language].iloc[:,0:-1]\n    lang_sets[language].index = pd.to_datetime(lang_sets[language].index)\n    \nsums = {}\nfor language in lang_sets:\n    sums[language] = lang_sets[language].iloc[:,1:].sum(axis=0)/lang_sets[language].shape[0]\n\noffset = collections.defaultdict(int)\noffset['en'] = 1000\noffset['ru'] =  3000\noffset['es'] = 1800\noffset['de'] = 1300\noffset['ja'] = 1000\noffset['fr'] = 600\noffset['zh'] = 300","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"lang_dict = {'zh': 'Chinese', 'fr': 'French', 'en': 'English', 'ru': 'Russian', 'de': 'German', 'ja': 'Japanese', 'es': 'Spanish', 'na': 'Other'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#cl.scales['7']\n#HTML(cl.to_html( cl.scales['8'] )) # All scales with 11 colors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\ncolorscale = cl.scales['8']['qual']['Set1']\ni=0\nfor language in sums.keys():\n    if offset[language]: name=lang_dict[language] + '(+' + str(offset[language])+')'\n    else: name = lang_dict[language] \n    fig.add_trace(\n        go.Scatter(\n        x = sums[language].index,\n        y = sums[language] + offset[language],\n        name=name , \n        line = dict(color=colorscale[i], width=4)\n        )\n    )\n    i+=1\n    \n    \nfig.update_layout(\n    height=600, \n    width=1400, \n    title=go.layout.Title(\n        text=\"Time Series of Webpage Traffic in different languages (offsets for clarity)\",\n        xref=\"paper\",\n        font=dict(\n                size=24,\n                #color=\"#7f7f7f\"\n            ),\n        x=0\n    ),\n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            text=\"Language\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            text=\"Aggregate Number of Views\",\n            font=dict(\n                size=18,\n                #color=\"#7f7f7f\"\n            )\n        )\n    )\n)\n    \n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most popular webpages"},{"metadata":{"trusted":true},"cell_type":"code","source":"npages = 5\ntop_pages = {}\nfor key in lang_sets:\n    print(key)\n    sum_set = pd.DataFrame(lang_sets[key][['Page']])\n    sum_set['total'] = lang_sets[key].sum(axis=1)\n    sum_set = sum_set.sort_values('total',ascending=False)\n    print(sum_set.head(10))\n    top_pages[key] = sum_set.index[0]\n    print('\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Periodicities with FFT"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import acf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}