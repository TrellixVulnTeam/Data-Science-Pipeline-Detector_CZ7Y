{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport math\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \ntrain = pd.read_csv('/kaggle/input/web-traffic-time-series-forecasting/train_1.csv.zip')\ntrain.shape","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T06:57:24.426546Z","iopub.execute_input":"2022-01-06T06:57:24.426811Z","iopub.status.idle":"2022-01-06T06:57:38.65425Z","shell.execute_reply.started":"2022-01-06T06:57:24.426782Z","shell.execute_reply":"2022-01-06T06:57:38.653591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:17:58.983337Z","iopub.execute_input":"2022-01-06T05:17:58.983606Z","iopub.status.idle":"2022-01-06T05:17:59.029409Z","shell.execute_reply.started":"2022-01-06T05:17:58.983556Z","shell.execute_reply":"2022-01-06T05:17:59.028558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_language(page):\n    res = re.search('[a-z][a-z].wikipedia.org',page)\n    if res:\n        return res[0][0:2]\n    return 'na'\n\ntrain['lang'] = train.Page.map(get_language)\n\nfrom collections import Counter\nprint(Counter(train.lang))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:17:59.030656Z","iopub.execute_input":"2022-01-06T05:17:59.031398Z","iopub.status.idle":"2022-01-06T05:17:59.469661Z","shell.execute_reply.started":"2022-01-06T05:17:59.031357Z","shell.execute_reply":"2022-01-06T05:17:59.468916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lang_sets = {}\nlang_sets['en'] = train[train.lang=='en'].iloc[:,0:-1]\nlang_sets['ja'] = train[train.lang=='ja'].iloc[:,0:-1]\nlang_sets['de'] = train[train.lang=='de'].iloc[:,0:-1]\nlang_sets['na'] = train[train.lang=='na'].iloc[:,0:-1]\nlang_sets['fr'] = train[train.lang=='fr'].iloc[:,0:-1]\nlang_sets['zh'] = train[train.lang=='zh'].iloc[:,0:-1]\nlang_sets['ru'] = train[train.lang=='ru'].iloc[:,0:-1]\nlang_sets['es'] = train[train.lang=='es'].iloc[:,0:-1]\n\nsums = {}\nfor key in lang_sets:\n    sums[key] = lang_sets[key].iloc[:,1:].sum(axis=0) / lang_sets[key].shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:17:59.471704Z","iopub.execute_input":"2022-01-06T05:17:59.472133Z","iopub.status.idle":"2022-01-06T05:18:00.766068Z","shell.execute_reply.started":"2022-01-06T05:17:59.472094Z","shell.execute_reply":"2022-01-06T05:18:00.765354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndays = [r for r in range(sums['en'].shape[0])]\n\nfig = plt.figure(1,figsize=[10,10])\nplt.ylabel('Views per page')\nplt.xlabel('Day')\nplt.title('Pages in Different Languages')\nlabels = {'en' : 'English','ja' : 'Japanese','de':'German',\n         'na' : 'Media','fr': 'French','zh':'Chinese','ru':'Russian','es':'Spanish'}\n\nfor key in sums:\n    plt.plot(days,sums[key],label = labels[key])\n    \n    \nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:00.767327Z","iopub.execute_input":"2022-01-06T05:18:00.767605Z","iopub.status.idle":"2022-01-06T05:18:01.082889Z","shell.execute_reply.started":"2022-01-06T05:18:00.767547Z","shell.execute_reply":"2022-01-06T05:18:01.082171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Periodic Structure and FFTs","metadata":{}},{"cell_type":"code","source":"from scipy.fftpack import fft\n\ndef plot_with_fft(key):\n    \n    fig = plt.figure(1,figsize=[15,5])\n    plt.ylabel('Views per page')\n    plt.xlabel('Day')\n    plt.title(labels[key])\n    plt.plot(days,sums[key], label = labels[key])\n    \n    \n    fig = plt.figure(2,figsize=[15,5])\n    fft_complex = fft(sums[key].values)\n    fft_mag = [np.sqrt(np.real(x)*np.real(x)+np.imag(x)*np.imag(x)) for x in fft_complex]\n    fft_xvals = [day / days[-1] for day in days]\n    npts = len(fft_xvals) // 2 + 1\n    fft_mag = fft_mag[:npts]\n    fft_xvals = fft_xvals[:npts]\n    \n    plt.ylabel('FFT Magnitude')\n    plt.xlabel(f'Frequency {days[-1]}')\n    plt.title('Fourier transform')\n    plt.plot(fft_xvals[1:],fft_mag[1:],label = labels[key])\n    \n    plt.axvline(x=1./7,color='red',alpha = 0.3)\n    plt.axvline(x=2./7,color='red',alpha = 0.3)\n    plt.axvline(x=3./7,color='red',alpha = 0.3)\n    \n    plt.show()\n    \nfor key in sums:\n    plot_with_fft(key)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:01.08394Z","iopub.execute_input":"2022-01-06T05:18:01.084183Z","iopub.status.idle":"2022-01-06T05:18:04.694074Z","shell.execute_reply.started":"2022-01-06T05:18:01.084152Z","shell.execute_reply":"2022-01-06T05:18:04.693417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Individual Entries","metadata":{}},{"cell_type":"code","source":"def plot_entry(key,idx):\n    data = lang_sets[key].iloc[idx,1:]\n    fig = plt.figure(1,figsize=(10,5))\n    plt.plot(days,data)\n    plt.xlabel('day')\n    plt.ylabel('views')\n    plt.title(train.iloc[lang_sets[key].index[idx],0])\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:04.695278Z","iopub.execute_input":"2022-01-06T05:18:04.69569Z","iopub.status.idle":"2022-01-06T05:18:04.701235Z","shell.execute_reply.started":"2022-01-06T05:18:04.695651Z","shell.execute_reply":"2022-01-06T05:18:04.700442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = [1,5,10,50,100,250,500,750,1000,1500,2000,3000,4000,5000]\n\nfor i in idx:\n    plot_entry('en',i)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:04.702445Z","iopub.execute_input":"2022-01-06T05:18:04.70271Z","iopub.status.idle":"2022-01-06T05:18:07.301898Z","shell.execute_reply.started":"2022-01-06T05:18:04.702675Z","shell.execute_reply":"2022-01-06T05:18:07.301212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = [1,5,10,50,100,250,500,750,1000,1500,2000,3000,4000,5000]\n\nfor i in idx:\n    plot_entry('es',i)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:07.303194Z","iopub.execute_input":"2022-01-06T05:18:07.303879Z","iopub.status.idle":"2022-01-06T05:18:10.057668Z","shell.execute_reply.started":"2022-01-06T05:18:07.303838Z","shell.execute_reply":"2022-01-06T05:18:10.056996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Aggregated Data Compared to Popular pages","metadata":{}},{"cell_type":"code","source":"npages = 5\ntop_pages = {}\nfor key in lang_sets:\n    print(key)\n    sum_set = pd.DataFrame(lang_sets[key]['Page'])\n    sum_set['total'] = lang_sets[key].sum(axis=1)\n    sum_set = sum_set.sort_values('total',ascending=False)\n    print(sum_set.head(10))\n    top_pages[key] = sum_set.index[0]\n    print('\\n\\n')\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:10.060531Z","iopub.execute_input":"2022-01-06T05:18:10.061215Z","iopub.status.idle":"2022-01-06T05:18:43.060966Z","shell.execute_reply.started":"2022-01-06T05:18:10.061175Z","shell.execute_reply":"2022-01-06T05:18:43.060251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in top_pages:\n    \n    fig=plt.figure(1,figsize=(10,5))\n    cols=train.columns\n    cols=cols[1:-1]\n    data = train.loc[top_pages[key],cols]\n    plt.plot(days,data)\n    plt.xlabel('Days')\n    plt.ylabel('Views')\n    plt.title(train.loc[top_pages[key],'Page'])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:43.062485Z","iopub.execute_input":"2022-01-06T05:18:43.063043Z","iopub.status.idle":"2022-01-06T05:18:44.540387Z","shell.execute_reply.started":"2022-01-06T05:18:43.063003Z","shell.execute_reply":"2022-01-06T05:18:44.53973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## More Analysis Tools","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import acf\n\nfor key in top_pages:\n    fig = plt.figure(1,figsize=[10,5])\n    ax1 = fig.add_subplot(121)\n    ax2 = fig.add_subplot(122)\n    cols = train.columns[1:-1]\n    data = np.array(train.loc[top_pages[key],cols])\n    data_diff = [data[i] - data[i-1] for i in range(1,len(data))]\n    autocorr = acf(data_diff)\n    pac = pacf(data_diff)\n    \n    x = [x for x in range(len(pac))]\n    ax1.plot(x[1:],autocorr[1:])\n    \n    ax2.plot(x[1:],pac[1:])\n    ax1.set_xlabel('Lag')\n    ax1.set_ylabel('Autocorrelation')\n    ax1.set_title(train.loc[top_pages[key],'Page'])\n    \n    ax2.set_xlabel('Lag')\n    ax2.set_ylabel('Partial Autocorrelation')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:44.541498Z","iopub.execute_input":"2022-01-06T05:18:44.542065Z","iopub.status.idle":"2022-01-06T05:18:47.931017Z","shell.execute_reply.started":"2022-01-06T05:18:44.542022Z","shell.execute_reply":"2022-01-06T05:18:47.927945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ARIMA Models","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nimport warnings\n\ncols = train.columns[1:-1]\nfor key in top_pages:\n    data = np.array(train.loc[top_pages[key],cols],'f')\n    result = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore')\n        try:\n            arima = ARIMA(data,[2,1,4])\n            result = arima.fit(disp=False)\n        except:\n            try:\n                arima = ARIMA(data,[2,1,2])\n                result = arima.fit(disp=False)\n                \n            except:\n                print(train.loc[top_pages[key],'Page'])\n                print('\\tARIMA failed')\n    pred = result.predict(2,599,typ = 'levels')\n    x = [i for i in range(600)]\n    \n    i=0\n    \n    \n    plt.plot(x[2:len(data)],data[2:],label='Data')\n    plt.plot(x[2:],pred,label='ARIMA Model')\n    plt.title(train.loc[top_pages[key],'Page'])\n    plt.xlabel('Days')\n    plt.ylabel('Views')\n    plt.legend()\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:47.933949Z","iopub.execute_input":"2022-01-06T05:18:47.934147Z","iopub.status.idle":"2022-01-06T05:18:57.233278Z","shell.execute_reply.started":"2022-01-06T05:18:47.934122Z","shell.execute_reply":"2022-01-06T05:18:57.232439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4 Models","metadata":{}},{"cell_type":"code","source":"page_details = train.Page.str.extract(r'(?P<topic>.*)\\_(?P<lang>.*).wikipedia.org\\_(?P<access>.*)\\_(?P<type>.*)')\n\npage_details[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:18:57.234867Z","iopub.execute_input":"2022-01-06T05:18:57.235448Z","iopub.status.idle":"2022-01-06T05:19:05.667441Z","shell.execute_reply.started":"2022-01-06T05:18:57.235409Z","shell.execute_reply":"2022-01-06T05:19:05.666615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_topic = page_details['topic'].unique()\nprint(unique_topic)\nprint('Number of Unique Topics: ',len(unique_topic))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:05.668731Z","iopub.execute_input":"2022-01-06T05:19:05.669045Z","iopub.status.idle":"2022-01-06T05:19:05.704665Z","shell.execute_reply.started":"2022-01-06T05:19:05.669008Z","shell.execute_reply":"2022-01-06T05:19:05.703886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(page_details['access'].unique())\nprint(page_details['type'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:05.706074Z","iopub.execute_input":"2022-01-06T05:19:05.706482Z","iopub.status.idle":"2022-01-06T05:19:05.756889Z","shell.execute_reply.started":"2022-01-06T05:19:05.706446Z","shell.execute_reply":"2022-01-06T05:19:05.756174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axs = plt.subplots(3,1,figsize=(12,12))\n\npage_details['lang'].value_counts().sort_index().plot.bar(ax=axs[0])\naxs[0].set_title('Language - Distribution')\n\npage_details['access'].value_counts().sort_index().plot.bar(ax=axs[1])\naxs[1].set_title('access - Distribution')\n\npage_details['type'].value_counts().sort_index().plot.bar(ax=axs[2])\naxs[2].set_title('type - Distribution')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:05.758238Z","iopub.execute_input":"2022-01-06T05:19:05.759021Z","iopub.status.idle":"2022-01-06T05:19:06.256077Z","shell.execute_reply.started":"2022-01-06T05:19:05.758979Z","shell.execute_reply":"2022-01-06T05:19:06.255418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split into Train and Validation dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.concat([page_details,train],axis=1)\n\ndef get_train_validate_set(train_df,test_percent):\n    train_end = math.floor((train_df.shape[1]-5) * (1-test_percent))\n    train_ds = train_df.iloc[:,np.r_[0,1,2,3,4,5:train_end]]\n    test_ds = train_df.iloc[:,np.r_[0,1,2,3,4,train_end:train_df.shape[1]]]\n    \n    return train_ds,test_ds\n\nX_train,y_train = get_train_validate_set(train_df,0.1)\nprint(X_train.head())\nprint(y_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:06.257372Z","iopub.execute_input":"2022-01-06T05:19:06.257979Z","iopub.status.idle":"2022-01-06T05:19:06.765231Z","shell.execute_reply.started":"2022-01-06T05:19:06.257939Z","shell.execute_reply":"2022-01-06T05:19:06.764511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:06.766392Z","iopub.execute_input":"2022-01-06T05:19:06.767Z","iopub.status.idle":"2022-01-06T05:19:06.799749Z","shell.execute_reply.started":"2022-01-06T05:19:06.766958Z","shell.execute_reply":"2022-01-06T05:19:06.799053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:06.801041Z","iopub.execute_input":"2022-01-06T05:19:06.801296Z","iopub.status.idle":"2022-01-06T05:19:06.927171Z","shell.execute_reply.started":"2022-01-06T05:19:06.801263Z","shell.execute_reply":"2022-01-06T05:19:06.926441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Zoupet Predictive analytics with different approaches","metadata":{}},{"cell_type":"markdown","source":"### Importation and Data Cleaning","metadata":{}},{"cell_type":"code","source":"import warnings\nimport scipy\nfrom datetime import timedelta\n\n# Forecasting with Decomposable Model\nfrom pylab import rcParams\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\n\n# Fore Machine learning Approach\n\nfrom statsmodels.tsa.tsatools import lagmat\nfrom sklearn.linear_model import LinearRegression, RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\n#Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('fivethirtyeight')\n\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:06.928561Z","iopub.execute_input":"2022-01-06T05:19:06.928852Z","iopub.status.idle":"2022-01-06T05:19:07.704197Z","shell.execute_reply.started":"2022-01-06T05:19:06.928815Z","shell.execute_reply":"2022-01-06T05:19:07.703491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/web-traffic-time-series-forecasting/train_1.csv.zip')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:07.70543Z","iopub.execute_input":"2022-01-06T05:19:07.7057Z","iopub.status.idle":"2022-01-06T05:19:18.698421Z","shell.execute_reply.started":"2022-01-06T05:19:07.705666Z","shell.execute_reply":"2022-01-06T05:19:18.697589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_flattened = pd.melt(train[list(train.columns[-50:])+['Page']],id_vars='Page',var_name='date',value_name='Visits')\ntrain_flattened['date'] = train_flattened['date'].astype('datetime64[ns]')\ntrain_flattened['weekend'] = ((train_flattened.date.dt.dayofweek)//5 ==1).astype(float)\ntrain_flattened","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:18.699837Z","iopub.execute_input":"2022-01-06T05:19:18.700123Z","iopub.status.idle":"2022-01-06T05:19:21.246377Z","shell.execute_reply.started":"2022-01-06T05:19:18.700086Z","shell.execute_reply":"2022-01-06T05:19:21.245717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_flattened.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:21.250037Z","iopub.execute_input":"2022-01-06T05:19:21.252091Z","iopub.status.idle":"2022-01-06T05:19:21.26215Z","shell.execute_reply.started":"2022-01-06T05:19:21.252049Z","shell.execute_reply":"2022-01-06T05:19:21.258979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_median = pd.DataFrame(train_flattened.groupby(['Page'])['Visits'].median())\ndf_median.columns = ['median']\n\ndf_mean = pd.DataFrame(train_flattened.groupby('Page')['Visits'].mean())\ndf_mean.columns = ['mean']\n\ntrain_flattened = train_flattened.set_index('Page').join(df_mean).join(df_median)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:21.263704Z","iopub.execute_input":"2022-01-06T05:19:21.264159Z","iopub.status.idle":"2022-01-06T05:19:30.966338Z","shell.execute_reply.started":"2022-01-06T05:19:21.264117Z","shell.execute_reply":"2022-01-06T05:19:30.965616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_flattened.reset_index(drop=False,inplace=True)\ntrain_flattened['weekday'] = train_flattened['date'].apply(lambda x: x.weekday())\ntrain_flattened['year'] = train_flattened.date.dt.year\ntrain_flattened['month'] = train_flattened.date.dt.month\ntrain_flattened['day'] = train_flattened.date.dt.day\ntrain_flattened","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:19:30.967705Z","iopub.execute_input":"2022-01-06T05:19:30.967944Z","iopub.status.idle":"2022-01-06T05:20:13.100342Z","shell.execute_reply.started":"2022-01-06T05:19:30.967911Z","shell.execute_reply":"2022-01-06T05:20:13.099691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Aggregation and Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(50,8))\nmean_group = train_flattened[['Page','date','Visits']].groupby(['date'])['Visits'].mean()\nplt.plot(mean_group)\nplt.title('Time Series - Average')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:13.101647Z","iopub.execute_input":"2022-01-06T05:20:13.101883Z","iopub.status.idle":"2022-01-06T05:20:13.977169Z","shell.execute_reply.started":"2022-01-06T05:20:13.10185Z","shell.execute_reply":"2022-01-06T05:20:13.976527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(50,8))\nmean_group = train_flattened[['Page','date','Visits']].groupby(['date'])['Visits'].median()\nplt.plot(mean_group,color = 'r')\nplt.title('Time Series - Meidian')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:13.981718Z","iopub.execute_input":"2022-01-06T05:20:13.982242Z","iopub.status.idle":"2022-01-06T05:20:14.69909Z","shell.execute_reply.started":"2022-01-06T05:20:13.9822Z","shell.execute_reply":"2022-01-06T05:20:14.698428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(50,8))\nstd_group = train_flattened[['Page','date','Visits']].groupby(['date'])['Visits'].std()\nplt.plot(std_group,color = 'g')\nplt.title('Time Series - STD')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:14.700437Z","iopub.execute_input":"2022-01-06T05:20:14.700904Z","iopub.status.idle":"2022-01-06T05:20:15.296974Z","shell.execute_reply.started":"2022-01-06T05:20:14.700866Z","shell.execute_reply":"2022-01-06T05:20:15.296151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ML APPROACH","metadata":{}},{"cell_type":"code","source":"times_series_means = pd.DataFrame(mean_group).reset_index(drop=False)\ntimes_series_means['weekday'] = times_series_means['date'].apply(lambda x:x.weekday())\ntimes_series_means['Date_str'] = times_series_means['date'].apply(lambda x:str(x))\ntimes_series_means[['year','month','day']] = pd.DataFrame(times_series_means['Date_str'].str.split('-',2).tolist(),columns=['year','month','day'])\n\ndate_staging = pd.DataFrame(times_series_means['day'].str.split(' ',2).tolist(),columns=['day','other'])\ntimes_series_means['day'] = date_staging['day']*1\ntimes_series_means.drop('Date_str',axis=1,inplace=True)\ntimes_series_means.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:15.300235Z","iopub.execute_input":"2022-01-06T05:20:15.301711Z","iopub.status.idle":"2022-01-06T05:20:15.345332Z","shell.execute_reply.started":"2022-01-06T05:20:15.301668Z","shell.execute_reply":"2022-01-06T05:20:15.344547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"times_series_means.reset_index(drop=True,inplace=True)\n\ndef lag_func(data,lag):\n    lag = lag\n    X = lagmat(data['diff'],lag)\n    lagged = data.copy()\n    for c in range(1,lag+1):\n        lagged['lag%d' %c] = X[:,c-1]\n        \n    return lagged\n\n\ndef diff_creation(data):\n    \n    data['diff'] = np.nan\n    data.loc[1:,'diff'] = (data.iloc[1:,1].values - data.iloc[:len(data)-1,1].values)\n    return data\n\ndf_count = diff_creation(times_series_means)\n\nlag = 7\nlagged = lag_func(df_count,lag)\nlast_date = lagged['date'].max()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:15.349317Z","iopub.execute_input":"2022-01-06T05:20:15.352176Z","iopub.status.idle":"2022-01-06T05:20:15.370793Z","shell.execute_reply.started":"2022-01-06T05:20:15.352137Z","shell.execute_reply":"2022-01-06T05:20:15.369857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lagged.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:15.372642Z","iopub.execute_input":"2022-01-06T05:20:15.372962Z","iopub.status.idle":"2022-01-06T05:20:15.406543Z","shell.execute_reply.started":"2022-01-06T05:20:15.372925Z","shell.execute_reply":"2022-01-06T05:20:15.405764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test(data_lag):\n    xc = ['lag%d' % i for i in range(1,lag+1)] + ['weekday'] +['day']\n    split = 0.70\n    xt = data_lag[(lag+1):][xc]\n    yt = data_lag[(lag+1):]['diff']\n    isplit = int(len(xt) * split)\n    x_train,y_train,x_test,y_test = xt[:isplit],yt[:isplit],xt[isplit:],yt[isplit:]\n    return x_train,y_train,x_test,y_test,xt,yt\n\nx_train,y_train,x_test,y_test,xt,yt = train_test(lagged)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:15.407951Z","iopub.execute_input":"2022-01-06T05:20:15.40831Z","iopub.status.idle":"2022-01-06T05:20:15.41966Z","shell.execute_reply.started":"2022-01-06T05:20:15.408275Z","shell.execute_reply":"2022-01-06T05:20:15.418881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesRegressor,GradientBoostingRegressor, BaggingRegressor,AdaBoostRegressor\n\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\ndef modelisation(x_tr,y_tr,x_ts,y_ts,xt,yt,model0,model1):\n    model0.fit(x_tr,y_tr)\n    \n    prediction = model0.predict(x_ts)\n    r2 = r2_score(y_ts.values,model0.predict(x_ts))\n    mae = mean_absolute_error(y_ts.values,model0.predict(x_ts))\n    print('mae with 70% data',mae)\n    \n    model1.fit(xt,yt)#with all data\n    \n    return model1,prediction,model0\n\nmodel0 = AdaBoostRegressor(n_estimators=5000,random_state=42,learning_rate=0.01)\nmodel1 = AdaBoostRegressor(n_estimators=5000,random_state=42,learning_rate=0.01)\n\nclr,prediction,clr0 = modelisation(x_train,y_train,x_test,y_test,xt,yt,model0,model1)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:20:15.421221Z","iopub.execute_input":"2022-01-06T05:20:15.421751Z","iopub.status.idle":"2022-01-06T05:20:28.322958Z","shell.execute_reply.started":"2022-01-06T05:20:15.421712Z","shell.execute_reply":"2022-01-06T05:20:28.322135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_df(data,number_of_days):\n    data_pred = pd.DataFrame(pd.Series(data['date'][data.shape[0]-1] + timedelta(days=1)),columns = ['date'])\n    for i in range(number_of_days):\n        inter = pd.DataFrame(pd.Series(data['date'][data.shape[0]-1] + timedelta(days=i+2)),columns=['date'])\n        \n        date_pred = pd.concat([data_pred,inter]).reset_index(drop=True)\n        \n    return data_pred\n\ndata_to_pred = pred_df(df_count,30)\ndata_to_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:21:10.605239Z","iopub.execute_input":"2022-01-06T05:21:10.605498Z","iopub.status.idle":"2022-01-06T05:21:10.654142Z","shell.execute_reply.started":"2022-01-06T05:21:10.60547Z","shell.execute_reply":"2022-01-06T05:21:10.653421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialisation(data_lag,data_pred,model,xtrain,ytrain,number_of_days):\n    \n    model.fit(xtrain,ytrain)\n    \n    for i in range(number_of_days):\n        lag1 = data_lag.tail(1)['diff'].values[0]\n        lag2 = data_lag.tail(1)['lag1'].values[0]\n        lag3 = data_lag.tail(1)['lag2'].values[0]\n        lag4 = data_lag.tail(1)['lag3'].values[0]\n        lag5 = data_lag.tail(1)['lag4'].values[0]\n        lag6 = data_lag.tail(1)['lag5'].values[0]\n        lag7 = data_lag.tail(1)['lag6'].values[0]\n        lag8 = data_lag.tail(1)['lag7'].values[0]\n        \n        data_pred['weekday'] = data_pred['date'].apply(lambda x:x.weekday)\n        weekday = data_pred['weekday'][0]\n        \n        row = pd.Series([lag1,lag2,lag3,lag4,lag5,lag6,lag7,lag8,weekday],\n                       ['lag1','lag2','lag3','lag4','lag5','lag6','lag7','lag8','weekday'])\n        \n        to_predict = pd.DataFrame(columns=['lag1','lag2','lag3','lag4','lag5','lag6','lag7','lag8','weekday'])\n        \n        prediction = pd.DataFrame(columns=['diff'])\n        to_predict = to_predict.append([row])\n        prediction = pd.DataFrame(model.predict(to_predict),columns=['diff'])\n        \n        if i == 0:\n            last_predict = data_lag['Visits'][data_lag.shape[0]-1] + prediction.values[0][0]\n            \n        if i > 0 :\n            \n            last_predict = data_lag['Visits'][data_lag.shape[0]-1] + prediction.values[0][0]\n            \n        data_lag = pd.concat([data_lag,prediction.join(data_pred['date']).join(to_predict)]).reset_index(drop=True)\n        \n        data_lag['Visits'][data_lag.shape[0]-1] = last_predict\n        \n        #test\n        data_pred = data_pred[data_pred['date']>data_pred['date'][0]].reset_index(drop=True)\n        \n    \n    \n    return data_lag\n\n\nmodel_fin = AdaBoostRegressor(n_estimators=5000,random_state=42,learning_rate=0.01)\n\n\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:44:57.249372Z","iopub.execute_input":"2022-01-06T05:44:57.249825Z","iopub.status.idle":"2022-01-06T05:44:57.270197Z","shell.execute_reply.started":"2022-01-06T05:44:57.249781Z","shell.execute_reply":"2022-01-06T05:44:57.269403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lagged = initialisation(lagged,data_to_pred,model_fin,xt,yt,30)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:44:59.529167Z","iopub.execute_input":"2022-01-06T05:44:59.529551Z","iopub.status.idle":"2022-01-06T05:45:05.880424Z","shell.execute_reply.started":"2022-01-06T05:44:59.529515Z","shell.execute_reply":"2022-01-06T05:45:05.879402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fin = AdaBoostRegressor(n_estimators=5000,random_state=42,learning_rate=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T05:50:03.525005Z","iopub.execute_input":"2022-01-06T05:50:03.525259Z","iopub.status.idle":"2022-01-06T05:50:03.529484Z","shell.execute_reply.started":"2022-01-06T05:50:03.525229Z","shell.execute_reply":"2022-01-06T05:50:03.528621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fin.fit(xt,yt)\n    \nfor i in range(30):\n    lag1 = lagged.tail(1)['diff'].values[0]\n    lag2 = lagged.tail(1)['lag1'].values[0]\n    lag3 = lagged.tail(1)['lag2'].values[0]\n    lag4 = lagged.tail(1)['lag3'].values[0]\n    lag5 = lagged.tail(1)['lag4'].values[0]\n    lag6 = lagged.tail(1)['lag5'].values[0]\n    lag7 = lagged.tail(1)['lag6'].values[0]\n    lag8 = lagged.tail(1)['lag7'].values[0]\n        \n    data_to_pred['weekday'] = data_to_pred['date'].apply(lambda x:x.weekday)\n    weekday = data_to_pred['weekday'][0]\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:39:26.921936Z","iopub.execute_input":"2022-01-06T06:39:26.922199Z","iopub.status.idle":"2022-01-06T06:39:26.940664Z","shell.execute_reply.started":"2022-01-06T06:39:26.92217Z","shell.execute_reply":"2022-01-06T06:39:26.939661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:57:58.804329Z","iopub.execute_input":"2022-01-06T06:57:58.805142Z","iopub.status.idle":"2022-01-06T06:57:58.810232Z","shell.execute_reply.started":"2022-01-06T06:57:58.805101Z","shell.execute_reply":"2022-01-06T06:57:58.809554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_eda = train.iloc[:2000,:50]\ndf_eda.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:58:50.030521Z","iopub.execute_input":"2022-01-06T06:58:50.030797Z","iopub.status.idle":"2022-01-06T06:58:50.062086Z","shell.execute_reply.started":"2022-01-06T06:58:50.03076Z","shell.execute_reply":"2022-01-06T06:58:50.061437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_eda.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:59:03.570892Z","iopub.execute_input":"2022-01-06T06:59:03.571613Z","iopub.status.idle":"2022-01-06T06:59:03.576475Z","shell.execute_reply.started":"2022-01-06T06:59:03.571576Z","shell.execute_reply":"2022-01-06T06:59:03.575649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataprep import eda as dp_eda","metadata":{"execution":{"iopub.status.busy":"2022-01-06T07:00:48.244373Z","iopub.execute_input":"2022-01-06T07:00:48.2447Z","iopub.status.idle":"2022-01-06T07:00:52.063183Z","shell.execute_reply.started":"2022-01-06T07:00:48.24466Z","shell.execute_reply":"2022-01-06T07:00:52.061659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = dp_eda.create_report(df_eda)\nreport","metadata":{"execution":{"iopub.status.busy":"2022-01-06T07:01:22.903213Z","iopub.execute_input":"2022-01-06T07:01:22.904035Z","iopub.status.idle":"2022-01-06T07:01:51.20857Z","shell.execute_reply.started":"2022-01-06T07:01:22.903992Z","shell.execute_reply":"2022-01-06T07:01:51.207704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}