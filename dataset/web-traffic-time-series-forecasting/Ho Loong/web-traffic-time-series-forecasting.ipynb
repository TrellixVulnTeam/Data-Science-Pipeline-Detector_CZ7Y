{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom scipy.stats import probplot\nfrom fbprophet import Prophet\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.system('unzip -d /kaggle/input /kaggle/input/web-traffic-time-series-forecasting/train_2.csv.zip')\nos.system('unzip -d /kaggle/input /kaggle/input/web-traffic-time-series-forecasting/train_1.csv.zip')\nos.system('unzip -d /kaggle/input /kaggle/input/web-traffic-time-series-forecasting/key_2.csv.zip')\nos.system('unzip -d /kaggle/input /kaggle/input/web-traffic-time-series-forecasting/key_1.csv.zip')\nos.system('unzip -d /kaggle/input /kaggle/input/web-traffic-time-series-forecasting/sample_submission_2.csv.zip')\nos.system('unzip -d /kaggle/input /kaggle/input/web-traffic-time-series-forecasting/sample_submission_1.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder = '../input/'\n\ntrain2 = pd.read_csv(folder+'train_2.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess\n\n1. 缺失处理\n2. Page列分割后处理\n3. 降低类型减少内存占用\n4. 数据整理到符合train和test"},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = train2.join(train2['Page'].str.rsplit('_',n=3,expand=True)).rename(columns={0:'article',1:'source',2:'access',3:'agent'})\ntrain2 = train2.drop('Page', axis=1)\ntrain2.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deal with Missing\n\ntrain中日期对应visitors有缺失，且缺失不代表0，这里要处理，初步考虑填充方式使用传统时序模型(先知)进行预测填充；"},{"metadata":{},"cell_type":"markdown","source":"#### Full with prophet\n\nToo long."},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# rcParams['figure.figsize'] = 10, 5\n\n# count = 0\n# idxs = []\n# for i in range(len(train2)):\n#     _row = train2.iloc[i]\n#     if sum(_row.isnull())>0:\n#         count += 1\n#         idxs.append(i)\n# #         if count>5:\n# #             break\n# #print(len(idxs),idxs)\n\n# _tmp = train2\n# for ii,idx in enumerate(idxs):\n#     print(ii,len(idxs))\n#     features,values=[],[]\n#     dss,ys,idxs_null = [],[],[]\n#     # reshape row to dataframe\n#     for col,value in train2.iloc[idx].items():\n#         if col in ['Page','article','source','access','agent']:\n#             features.append(col)\n#             values.append(value)\n#             continue\n#         dss.append(col)\n#         ys.append(value)\n#         if np.isnan(value):\n#             idxs_null.append(len(ys)-1)\n#     _row = pd.DataFrame({'ds':dss,'y':ys})\n#     #print(len(_row))\n#     #print(idxs_null[-1])\n#     #_first = idxs_null[-1]+1\n#     #_row_train = _row[_first:]\n#     #_row_test = _row[:_first]\n#     #print(len(_row_train),len(_row_test))\n#     m = Prophet()\n#     m.fit(_row)\n#     #forecast = m.predict(pd.concat([_row_test[['ds']],_row_train[['ds']]]))\n#     forecast = m.predict(_row[['ds']])\n#     #m.plot(forecast)\n#     for i in idxs_null:\n#         ys[i] = forecast[forecast.ds==_row.iloc[i].ds].iloc[0].yhat\n#     _row = pd.Series(values+ys, index=features+dss)\n#     #print(sum(_row.isnull()))\n#     _tmp.iloc[idx] = _row\n#     #break\n\n# train2 = _tmp\n\n# for i in idxs:\n#     _row = _tmp.iloc[i]\n#     if sum(_row.isnull())>0:\n#         print(sum(_row.isnull()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Full with bfill"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(set(train2.columns.tolist())-set(['article','source','access','agent']))\ntrain2[cols] = train2[cols].fillna(method='bfill', axis=1)\ntrain2[cols] = train2[cols].fillna(method='ffill', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Full with 0 backup"},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = train2.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Clip to 0 in left"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in train2.columns:\n#     if train2[col].dtype != 'object':\n#         train2[col] = train2[col].clip(0)\ntrain2[cols] = train2[cols].clip(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Type Down\n\n缺失处理后，需要对visitors进行类型下降；"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 部分列做类型转换\ntrain2[['article','source','access','agent']] = train2[['article','source','access','agent']].astype('category')\ntrain2[cols] = train2[cols].apply(pd.to_numeric, downcast='unsigned')\ntrain2.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Reshape\n\n1. 构建test\n2. 将原始数据格式转为直接用于train和test的格式；"},{"metadata":{"trusted":true},"cell_type":"code","source":"visits = train2[cols].stack().reset_index(level=1)\nvisits.columns = ['date','visits']\n#visits.date = visits.date.astype(np.datetime64)\nvisits.date = visits.date.astype('category')\nvisits.visits = visits.visits.astype(np.int32)\nvisits.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = train2.drop(cols, axis=1).join(visits)\ndel visits\ntrain2.info(memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import seaborn as sns\n# sns.set(style=\"darkgrid\")\n# sns.lineplot(x=\"date\", y=\"visits\", hue=\"article\", \n#              data=train2[['article','date','visits']][(train2.article=='董子健')|(train2.article=='何廣沛')|(train2.article=='李宗伟')])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FE\n\nlog1p；"},{"metadata":{},"cell_type":"markdown","source":"### 构建test数据\n\n2017年9月13日至2017年11月13日"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # 2017-09-11, 2017-09-12\n# for k,group in train2.groupby(['article','source','access','agent']):\n# #for k,group in train2.groupby('article'):\n#     _article,_source,_access,_agent,_visits = k[0],k[1],k[2],k[3],0\n#     #_date1,_date2 = np.datetime64('2017-09-11'),np.datetime64('2017-09-12')\n#     _date1 = np.datetime64('2017-11-13')\n#     train2 = train2.append({'article':_article,'source':_source,'access':_access,'agent':_agent,'visits':_visits,'date':_date1}, ignore_index=True)\n#     #train2 = train2.append({'article':_article,'source':_source,'access':_access,'agent':_agent,'visits':_visits,'date':_date2}, ignore_index=True)\n\n# 2017-09-13 ~ 2017-11-13\nkey2 = pd.read_csv(folder+'key_2.csv')\nkey2 = key2.join(key2['Page'].str.rsplit('_',n=4,expand=True)).rename(columns={0:'article',1:'source',2:'access',3:'agent',4:'date'})\nkey2 = key2.drop(['Page','Id'], axis=1)\nkey2['visits'] = 0\nkey2.visits = key2.visits.astype(np.int8)\n# 部分列做类型转换\nkey2[['date','article','source','access','agent']] = key2[['date','article','source','access','agent']].astype('category')\nkey2.info(memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.api.types import union_categoricals\n\n# matrix = pd.DataFrame({})\n# matrix['article'] = pd.Series(union_categoricals([train2.article,key2.article]))\n# matrix['source'] = pd.Series(union_categoricals([train2.source,key2.source]))\n# matrix['access'] = pd.Series(union_categoricals([train2.access,key2.access]))\n# matrix['agent'] = pd.Series(union_categoricals([train2.agent,key2.agent]))\n# matrix['date'] = pd.concat([train2.date,key2.date])\n# matrix['visits'] = pd.concat([train2.visits,key2.visits])\n# del key2,train2\n# matrix.info()\n\nmatrix = pd.DataFrame({})\nprint('article ....')\nmatrix['article'] = pd.Series(union_categoricals([train2.article,key2.article]))\ndel train2['article'],key2['article']\nprint('source ....')\nmatrix['source'] = pd.Series(union_categoricals([train2.source,key2.source]))\ndel train2['source'],key2['source']\nprint('access ....')\nmatrix['access'] = pd.Series(union_categoricals([train2.access,key2.access]))\ndel train2['access'],key2['access']\nprint('agent ....')\nmatrix['agent'] = pd.Series(union_categoricals([train2.agent,key2.agent]))\ndel train2['agent'],key2['agent']\nprint('date ....')\nmatrix['date'] = pd.Series(union_categoricals([train2.date,key2.date]))\nmatrix.date = matrix.date.astype('datetime64')\ndel train2['date'],key2['date']\nprint('visits ....')\nmatrix['visits'] = train2.visits.append(key2.visits, ignore_index=True)\ndel train2['visits'],key2['visits']\ndel train2,key2\nprint('show info ....')\nmatrix.info(memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(matrix[matrix.article=='2NE1'].access.unique()))\nprint(len(matrix[matrix.article=='2NE1'].agent.unique()))\nprint(len(matrix[matrix.article=='2NE1'].source.unique()))\nprint(len(matrix[matrix.article=='2NE1'].date.unique()))\nprint(len(matrix[matrix.article=='2NE1'].visits.unique()))\nprint(len(matrix[matrix.article=='2NE1']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 经典时序FE\n\n内存问题，先不做这一步；"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# def split_date(df):\n#     df['year'] = df.date.apply(lambda dt:dt.year).astype(np.int16)\n#     df['month'] = df.date.apply(lambda dt:dt.month).astype(np.int8)\n#     df['quarter'] = df.date.apply(lambda dt:dt.quarter).astype(np.int16)\n#     df['day'] = df.date.apply(lambda dt:dt.day).astype(np.int8)\n#     df['dayofweek'] = df.date.apply(lambda dt:dt.dayofweek).astype(np.int8)\n#     df['dayofyear'] = df.date.apply(lambda dt:dt.dayofyear).astype(np.int16)\n#     df['weekofyear'] = df.date.apply(lambda dt:dt.weekofyear).astype(np.int16)\n#     df['is_month_start'] = df.date.apply(lambda dt:dt.is_month_start).astype(np.int16)\n#     df['is_month_end'] = df.date.apply(lambda dt:dt.is_month_end).astype(np.int16)\n#     df['is_quarter_start'] = df.date.apply(lambda dt:dt.is_quarter_start).astype(np.int16)\n#     df['is_quarter_end'] = df.date.apply(lambda dt:dt.is_quarter_end).astype(np.int16)\n#     df['is_year_start'] = df.date.apply(lambda dt:dt.is_year_start).astype(np.int16)\n#     df['is_year_end'] = df.date.apply(lambda dt:dt.is_year_end).astype(np.int16)\n\n# split_date(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first_date = matrix.date.min()\n# matrix['day_block_num'] = (matrix.date - first_date).apply(lambda delta:delta.days).astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nles = {}\nfor col in ['article','source','access','agent']:\n    les[col] = LabelEncoder().fit(matrix[col])\n    matrix[col] = les[col].transform(matrix[col])\n    if col == 'article':\n        matrix['article'] = matrix['article'].astype('int16')\n    else:\n        matrix[col] = matrix[col].astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# matrix['article'] = matrix['article'].astype('int16')\n# matrix['source'] = matrix['source'].astype('int8')\n# matrix['access'] = matrix['access'].astype('int8')\n# matrix['agent'] = matrix['agent'].astype('int8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Select"},{"metadata":{"trusted":true},"cell_type":"code","source":"# matrix = matrix.drop('date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 划分数据"},{"metadata":{"trusted":true},"cell_type":"code","source":"_train = matrix[matrix.date<np.datetime64('2017-09-13')]\n_test = matrix[matrix.date>=np.datetime64('2017-09-13')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = _train[_train.date<=np.datetime64('2017-07-10')].drop(['date','visits'], axis=1)\nY_train = _train[_train.date<=np.datetime64('2017-07-10')].visits\nX_valid = _train[_train.date>np.datetime64('2017-07-10')].drop(['date','visits'], axis=1)\nY_valid = _train[_train.date>np.datetime64('2017-07-10')].visits","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def smape(y_true, y_pred):\n    return 2.0 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n\ndef smape_4_xgboost(y_pred, dtrain):\n    y_true = dtrain.get_label()\n    return 'smape', smape(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\nmodel = XGBRegressor(\n    n_estimators=10000,\n    eta=0.3,\n    seed=10086)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=smape_4_xgboost,\n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}