{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.integrate import odeint\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt  \n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\ndef getConfirmedCases(country, startingAt=5):\n    data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\n    dataOfCountry = data[data.Country_Region == country]\n    result = dataOfCountry.ConfirmedCases[dataOfCountry.ConfirmedCases > startingAt]\n    return result\n\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So I guess the SIR model is known to people who visit this kind of website by now. Just in case: https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model.\n\nIn this notebook I will use it in a slightly different context than that of the wikipedia article though. In the data supplied by John Hohpkin's we obviously don't have access to the number of people walking around downtown carrying the virus, the variable I (infected), but we do have access to the confirmed cases and recovered cases. \n\nLets assume that people upon being diagnosed with Covid will be successfully quarantined/isolated and unable to spread the disease so that only the unconfirmed cases (which we don't have data for) can spread the disease. Then we can use the same diff equation as used in SIR but replacing the var R (recovered) by R for quarantined (or Q if you'd prefer that i guess). The parameter gamma of the SIR model will then indicate chance that an infected, not quarantined person will test positive and subsequently be quarantined.\n\nI will keep the variables of the O.G. SIR model in my notebook because they somehow stuck to my brain as it were..\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def SIR(X, t, beta, gamma, N):\n    \"\"\"\n    S = X[0], I=X[1], R=X[2]\n    \"\"\"\n    dSdt = -beta*X[0]*X[1]/N\n    dIdt = -dSdt - gamma*X[1]\n    dRdt = gamma*X[1]\n    return [dSdt, dIdt, dRdt]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We forward-integrate the SIR model for a population the size of Italy's to get the following disastrous graph for what could happen. "},{"metadata":{"trusted":true},"cell_type":"code","source":"    beta, gamma, N = 0.9, 0.2, 6*10**7\n    I0 = 5\n    X0 = [N-I0, I0, 0]\n    ts = np.linspace(0, 100 - 1, 100)\n    Xs = odeint(SIR, X0, ts, args=(beta, gamma, N))\n    \n    f = plt.figure(figsize=(10,5))\n    plt.plot(ts, Xs[:,0], label='susceptible');\n    plt.plot(ts, Xs[:,1], label='infected, not yet quarantined');\n    plt.plot(ts, Xs[:,2], label='confirmed infections');\n    plt.ylabel(\"number of people\", fontsize=10);\n    plt.xlabel(\"time [days]\", fontsize=10);\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Ok but what if we fit a SIR model to data?"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\ndef confirmedSIR(t, beta, gamma):\n    N = 6*10**7\n    #N = 1000\n    I0 = 1\n    X0 = [N-I0, I0, 0]\n    return odeint(SIR, X0, t, args=(beta, gamma, N))[:,2]\n\ndef allSIR(t, beta, gamma):\n    N = 6*10**7\n    #N = 1000\n    I0 = 1\n    X0 = [N-I0, I0, 0]\n    return odeint(SIR, X0, t, args=(beta, gamma, N))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    observed = getConfirmedCases(\"Spain\")\n\n    N = 6*10**7\n    X0 = [N-I0, I0, 0]\n    ts = np.linspace(0, len(observed) - 1, len(observed))\n    \n    popt, pcov = curve_fit(confirmedSIR, ts, observed)\n    \n    longerTime = np.linspace(0, 100, 1000)\n    fitted = allSIR(longerTime, *popt)\n    \n    f = plt.figure(figsize=(10,5))\n    plt.title(\"Best fitting SIR model for Spain\")\n    plt.plot(ts, observed, \"ro\")\n    plt.plot(longerTime, fitted[:,1], label='Infected, not quarantined yet')\n    plt.plot(longerTime, fitted[:,2], label='Confirmed cases')\n    plt.legend()\n    plt.show()\n              ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, 400 000 infected in the end huh. The result is a lot more optimistic than I had thought from such a model. Remember that this model can't change its parameters beta, gamma meaning it can't take 'actions' such as improved hygene or social distancing into account.\n\nThe way it appears to achieve its optimism is by setting a very small number of people to be infected on the street at a time. We can print its parameters to confirm this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"fitted infectiousness\",popt[0])\nprint(\"fitted chance of being quarantined when sick: \", popt[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They're almost the same value! \n\nIf you look at the SIR diff eq you will see that when these parameters are similar and when S is almost N (population size) then approximately as many people fall sick as who are quarantined so the number of unquarantined people is small. And as the S decreases the balance will shift so that fewer people fall sick than are isolated. In the end only a small part of the population will catch the disease."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotSIR(country, usingLogScale=False, I0=5):\n\n    observed = getConfirmedCases(country, I0)\n    observed = observed[~np.isnan(observed)]\n\n    beta, gamma, N = 0.6, 0.2, 6*10**7\n    X0 = [N-I0, I0, 0]\n    ts = np.linspace(0, len(observed) - 1, len(observed))\n    Xs = odeint(SIR, X0, ts, args=(beta, gamma, N))\n\n    shortening = 10\n    popt_partialData, pcov_partialData = curve_fit(confirmedSIR,\n                                       ts[:len(ts) - shortening],\n                                       observed[:len(ts) - shortening])\n    longerTime = np.linspace(0, 100, 1000)\n    fitted_partialData = allSIR(longerTime, *popt_partialData)\n\n    popt, pcov = curve_fit(confirmedSIR, ts, observed)\n    fitted = allSIR(longerTime, *popt)\n\n    predicted = confirmedSIR(ts, *popt)\n    residuals = predicted - observed\n    predicted_partialData = confirmedSIR(ts[:len(ts) - shortening], *popt_partialData)\n    residuals_partialData = predicted_partialData - observed[:len(ts) - shortening]\n\n    f = plt.figure(figsize=(20,10))\n    plt.subplot(311)\n    plt.title(\"SIR model for \" + country)\n    plt.legend(loc='best')\n    if usingLogScale:\n        plt.ylabel(\"Logarithm of confirmed infections\", fontsize=10);\n        plt.plot(ts, np.log(observed),'ro', label='observed')\n        plt.plot(longerTime, np.log(fitted[:,2]), label='fitted')\n        plt.plot(longerTime, np.log(fitted_partialData[:,2]), label='fitted on partial data')\n    else:\n        plt.xlabel(\"time [days]\", fontsize=10);\n        plt.plot(ts,observed,'ro', label='observed')\n        plt.plot(longerTime,fitted[:,2], label='fitted')\n        plt.plot(longerTime, fitted_partialData[:,2], label='fitted on partial data')\n    plt.legend()\n\n    plt.subplot(312)\n    plt.ylabel(\"Infected, not quarantined\")\n    plt.plot(longerTime, fitted[:,1], label='fitted')\n    plt.plot(longerTime, fitted_partialData[:,1], label='fitted on partial data')\n\n    plt.subplot(313)\n    plt.ylabel(\"Residuals\")\n    plt.plot(ts, residuals, 'o')\n    plt.plot(ts[:len(ts) - shortening], residuals_partialData, 'o')\n    plt.xlim(0, longerTime[-1])\n    plt.xlabel(\"time [days]\", fontsize=10);\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets plot fitted models for some more countries. I don't believe the fit is very good so I will plot the residuals and also fit models with reduced amount of observed data. As you can see the residuals aren't wonderful (they should ideally be spread around zero with no time-correlation I believe) "},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSIR(\"Spain\", usingLogScale=True)\nplotSIR(\"Italy\", usingLogScale=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK but now I predicted what will happen in Spain before checking whether the model can describe what already has happened in South Korea. Lets have a go at that then.\n\nWe can see that the scipy curve fitter does manage to find a fit to the korean data. Note that I had to cut off the first part of the korean epidemic because the SIR model has no chance of describing an epidemic that comes in waves. The residuals, however, indicate once more that the fit is not good.."},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSIR(\"Korea, South\", I0=np.exp(4.5), usingLogScale=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we are interested in predicting the future behavior of the epidemic we are more interested in evaluating our models in terms of accuracy on the observed samples outside the training set than in terms of accuracy inside the training set, i.e. residuals.\n\nLets split the fitting/training data into multiple chunks and see whether we would trust their individual predictions. We can then choose some metric, such as 1-norm, 2-norm, etc to evaluate the prediction performance. To help visualize the process as well as the goodness of prediction I will also plot each prediction on its individual test data chunk."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\ndef evaluateModel(countries=[\"Spain\"], usingPlotting=False):\n    tscv = TimeSeriesSplit(n_splits=5)\n    scores = []\n    parameters = []\n\n    for country in countries:\n        observed = getConfirmedCases(country).to_numpy()\n        observed = observed[~np.isnan(observed)]\n\n        I0, N = 5, 6*10**7\n        X0 = [N-I0, I0, 0]\n        for train, test in tscv.split(observed):\n            popt, pcov = curve_fit(confirmedSIR, train, observed[train])\n            fitted = allSIR(np.linspace(0,50 -1, 50), *popt)\n\n            scores.append(mean_absolute_error(fitted[test,2], observed[test]))\n            parameters.append(popt)\n            if usingPlotting:\n                plt.plot(test,np.log(fitted[test,2]))\n        if usingPlotting:\n            plt.plot(np.log(observed), 'o')\n            plt.show()\n    return parameters, scores\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params, scores = evaluateModel(usingPlotting=True)\nprint(\"Prediction error: \", *scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turns out the three last predictions where more aggressive than the observed data. Due to the log scale of the plot, they look ok but looking at the prediction errors (using the mean absolute error for simplicity) we see that they are quite a way off. \n\nIt is interesting to think about how one should evaluate the prediction error. One way of looking at it may be that the mean absolute error and even more so mean squared error are less useful for evaluating this models for this type of problem since they will be very punishing for the last few data points. Glancing at the documentation for scipy's curve fitting function https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html we find out that it uses least squares a.k.a. mean squared error to find good parameters. This sounds like it could be a problem when fitting in linear scale. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}