{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center>\n    <h1>\n        Covid-19 Spread and Conatainment Measures\n    </h1>\n</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"white\", font_scale=1.2)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Gathering and Wrangling\n\nData was collected from different sources. My main source to search for data was: https://www.kaggle.com\n\n### Datasets included:\n\n- **[Covid Containment Dataset][1]:** The dataset was collected from http://epidemicforecasting.org/containment. The description included:\n>>Each measure in the database has entries on:\n  - Country (and state for the US)\n  - Textual description of the measure\n  - Start date of measure\n  - End date (if available)\n  - URL to source of more information\n  - Systematic keyword labels (e.g. \"travel ban\" or \"hygiene enforcement\")\n\n- **[Covid-19 Dataset][2]:** Collected from the [World Health Organisation][3]. Content includes:\n>> This dataset has daily level information on the number of affected cases, deaths and recovery from 2019 novel coronavirus. Please note that this is a time series data and so the number of cases on any given day is the cumulative number.\n  - Sno - Serial number\n  - ObservationDate - Date of the observation in MM/DD/YYYY\n  - Province/State - Province or state of the observation (Could be empty when missing)\n  - Country/Region - Country of observation\n  - Last Update - Time in UTC at which the row is updated for the given province or country. (Not standardised and so please clean before using it)\n  - Confirmed - Cumulative number of confirmed cases till that date\n  - Deaths - Cumulative number of of deaths till that date\n  - Recovered - Cumulative number of recovered cases till that date\n- **[Country population and other data][4]:** Collected from a kaggle dataset. Only specific columns like population and median age are useful to compare countrie.\n\n[1]:https://www.kaggle.com/paultimothymooney/covid19-containment-and-mitigation-measures\n[2]:https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\n[3]:https://www.who.int/emergencies/diseases/novel-coronavirus-2019\n[4]:https://www.kaggle.com/tanuprabhu/population-by-country-2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"containment = pd.read_csv('/kaggle/input/covid19-containment-and-mitigation-measures/COVID 19 Containment measures data.csv')\ncontainment.head()\nrename_col  = {'Country': 'country',\n               'Date Start': 'date', 'Keywords':'keywords'}\ncols_to_keep = list(rename_col.values())\ncontainment = containment.rename(columns=rename_col)\ncontainment = containment.drop(containment.columns.difference(cols_to_keep),axis=1)\ncontainment['date'] = pd.to_datetime(containment['date'])\ncontainment.dropna(subset=['country','date','keywords'],inplace=True)\ncontainment.loc[containment.country.str.contains('US:'),'country'] = 'United States' #replace all states with just US\ncontainment.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add data for lebanon\nleb_cont = pd.read_csv('/kaggle/input/lebanon-containtmentcsv/lebanon_containment.csv')\nleb_cont['date']= pd.to_datetime(leb_cont['date'])\ncontainment = pd.concat([containment,leb_cont],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"containment.query('country == \"Lebanon\"').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid= pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv')\ncols_rename = {'Country/Region':'country','ObservationDate':'date','Confirmed':'confirmed',\n               'Deaths':'deaths','Recovered':'recovered'}\ncovid.rename(columns=cols_rename,inplace=True)\ncols_keep = ['date','country','confirmed','deaths','recovered']\ncovid.drop(covid.columns.difference(cols_keep),axis=1,inplace=True)\ncovid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pop = pd.read_csv('/kaggle/input/population-by-country-2020/population_by_country_2020.csv')\ncol_rename = {'Country (or dependency)': 'country','Population (2020)':'population',\n              'Density (P/Km²)':'density','Med. Age':'median_age','Urban Pop %':'urban_pop'}\npop.rename(columns=col_rename,inplace=True)\ncols_keep = col_rename.values()\npop.drop(pop.columns.difference(cols_keep),axis=1,inplace=True)\npop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rename some countries for merging\ncontainment_country_names= {'Czechia':'Czech Republic','Kosovo':'Serbia','Vatican City': 'Italy','Macau':'Macao',\n                            'Guernsey': 'Others','Jersey': 'Others'}\ncontainment= containment.replace({'country':containment_country_names})\ncontainment = containment.query('country != \"Others\"') # removing 'Others' as country","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging containment and covid data but first we need to rename some countries\n# long list of names since I collected data from 2 different sources\n# found this list by doing a left merge then checking the nan values\ncountry_map= {'Mainland China': 'China','US': 'United States','UK':'United Kingdom',\n              'Republic of Ireland':'Ireland','North Ireland':'Ireland', 'The Bahamas': 'Bahamas',\n              'Bahamas, The': 'Bahamas', 'Burma': 'Myanmar','Cape Verde': 'Cabo Verde','Macau':'Macao',\n              'Ivory Coast': 'Côte d\\'Ivoire', 'occupied Palestinian territory': 'Palestine',\n              'West Bank and Gaza':'Palestine','Republic of the Congo':'Congo',\n              'Saint Vincent and the Grenadines':'St. Vincent & Grenadines','The Gambia':'Gambia',\n              'Gambia, The':'Gambia','Saint Kitts and Nevis': 'Saint Pierre & Miquelon',\n              'Reunion': 'France','Kosovo':'Serbia','Curacao':'Curaçao', 'East Timor':'Timor-Leste',\n              'Vatican City': 'Italy','Faroe Islands':'Faeroe Islands','Guernsey': 'Others',\n              'Diamond Princess': 'Others','Jersey': 'Others','North Macedonia':'Macedonia', 'MS Zaandam':'Others'\n             }\ncovid.loc[covid.country.str.contains('Brazzaville'),'country'] = 'Congo' # dataset contains different city names for congo\ncovid.loc[covid.country.str.contains('Kinshasa'),'country'] = 'Congo'\ncovid.loc[covid.country.str.contains('\\)'),'country'] = 'St. Martin' # just for proper formatting\ncovid.country = covid.country.str.strip() #removing whitespace so it doesnt cause problems with merge\ncovid= covid.replace({'country':country_map}) # now replace all country names\ncovid = covid.groupby(['country','date'])[['confirmed','deaths','recovered']].sum() # make sure we add the cases in all countries\ncovid = covid.reset_index()\ncovid['date'] = pd.to_datetime(covid['date'])\ncovid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix some data for Lebanon\ncovid.loc[(covid.country == \"Lebanon\") & (covid.confirmed == 110),'confirmed'],  covid.loc[(covid.country == \"Lebanon\") & (covid.confirmed == 99),'confirmed'] = 99 ,110\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just make names easier to work with\npop = pop.replace({'country':{'Czech Republic (Czechia)': 'Czech Republic','State of Palestine': 'Palestine',\n                             'Saint Martin':'St. Martin', 'North Macedonia': 'Macedonia'\n                             }})\npop['urban_pop']= pop['urban_pop'].str.replace('%','')\npop['urban_pop'] = pd.to_numeric(pop['urban_pop'],errors='coerce') /100\npop['median_age'] = pd.to_numeric(pop['median_age'],errors='coerce').fillna(0).astype('int')\npop[pop.median_age == 0 ].head() # many missing values but thats fine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = pd.merge(covid,pop,how='left',on='country') # doing a left merge to check that no country name is different\ncountries[countries.population.isna()].country.value_counts() # one last check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(containment,countries,how='outer',on=['country','date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concat duplicate values\n# idea from https://stackoverflow.com/a/53463151/4145941\nindex_cols = df.columns.tolist()\nindex_cols.remove(\"keywords\") \ndf = df.groupby(index_cols)[\"keywords\"].apply(list)\ndf = df.reset_index()\ndf.keywords = [','.join(map(str, l)) for l in df['keywords']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.confirmed.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finally here is our data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nAfter Collecting the data and removing unnecessary columns, it is time to start exploring. \n    \n### Structure of the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset contains 10 columns and 4251 rows. Here is a quick summary of the columns:\n- country: name of the country\n- date: the date at which the entry was observed.\n- confirmed: confirmed cases of Covid-19 in the country (cumulative value)\n- deaths: confirmed cases of death due to Covid-19 (cumulative value)\n- recovered: recovered cases from Covid-19 (cumulative value)\n- population: population of the country\n- density: density calculated as Person/Km2\n- median_age: median age of people in the country\n- urban_pop: Urban population (given as percent value)\n- keywords: some of the measures taken to limit the spread of the infection by each country.\n\nIn addition, here is an overview of the column types and summary of their values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Main Feature of Interest\n\nLike most researchers nowadays, I am interested in understanding more about the Covid-19. Our main focus is its spread and the effictiveness of measures taken to slow its progress. For that here are some main questions to be answered:\n\n- Which countries are doing better than others and why ?\n- What measures are the most effective against the spread of the virus?\n- How do the death and recovery rates compare according to population, density and median age of a country?\n- How does Lebanon compare to other countries regarding measures taken and spread of the virus ? \n\n### Features that Will Help in the Investigation\n\nI have removed most of the columns that will not have any use. For that almost all of the columns in the above dataset are useful in answering the questions."},{"metadata":{},"cell_type":"markdown","source":"## Univariate Plots\n\nIn this section, we will take a look at individual variables and their distributions. The three main variables we should look at are 'confirmed', 'recovered' and 'deaths' since they relate directly to our interest. In addition, we will take a look at the 'keywords' variable to check the most common measures."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting on a log scale because of the huge difference in the data\nplt.figure(figsize=(18,5))\nplt.hist(df.confirmed,log=True, bins=np.arange(0,120000,4000));\nyticks = [1,2,5,10,20,50,100,200,500,1000,2000,5000]\nplt.yticks(yticks,yticks);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data we see is bimodal. Two peaks are very apparent: one is close to 0 and the other one is centered at 80000. Given that data is collected for about 3 months only, the 2 peaks explain the scary nature of the exponential spread of the virus: It doesn't take a long time for a country to go from very few cases to cases in thousands."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,5))\nplt.hist(df.deaths,log=True, bins=np.arange(0,10000,500));\nyticks = [1,2,5,10,20,50,100,200,500,1000,2000,5000]\nplt.yticks(yticks,yticks);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similar to the above case, the data is generally bimodal. However, it is more skewed to the right which is a good sign: the mortality rate is low in general. In addition, the data is more spread and there are many individual cases with high death rate: These are probably cases like Italy and the United States where the virus spread very fast."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,5))\nplt.hist(df.recovered,log=True, bins=np.arange(0,77000,4000));\nyticks = [1,2,5,10,20,50,100,200,500,1000,2000,5000]\nplt.yticks(yticks,yticks);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here again, we see two distant peaks with one at the very beginning and one at the end. Data in both cases seem to be cut off suddenly. The 2 peaks probably match with the 2 peaks in the 'confirmed' variable. More infections = More recovery. \n\nFinally, if we look at all the three plots, we can see a common theme: many countries have a low amount of infections (between 0 and 1000) and if no measures are taken, the virus will spread quickly and become a high threat to the country."},{"metadata":{"trusted":true},"cell_type":"code","source":"# in order for this to work we need to install an additional library\n# !pip install wordcloud\n# idea from https://www.datacamp.com/community/tutorials/wordcloud-python\n\nfrom wordcloud import WordCloud\ntext = ' '.join(df.keywords).replace('nan','')\nwordcloud = WordCloud(min_font_size= 5,max_font_size=100).generate(text)\nplt.figure(figsize=[18,8])\nplt.title('Containment Measures')\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\");\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The word cloud gives the most common measures taken by countries to slow the spread of the disease. Most common measures include:\n- Closing of public buildings (schools, universities)\n- Banning travel\n- canceling social events\n- social distancing and banning the gathering of people"},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Plots\n\nNow lets take a look at the relationship between pairs of data. One main plot to consider is the spread through time."},{"metadata":{"trusted":true},"cell_type":"code","source":"# increase in total confirmed cases\n# again, using log scale because of the exponential growth\nplt.figure(figsize=(18,10))\nnp.log10(df.groupby('date')['confirmed'].sum()).plot()\nyticks = [200,500,1000,2000,5000,10000,20000,50000,100000,200000,500000,1000000]\nplt.yticks(np.log10(yticks),yticks)\nplt.title('Total Infections through time (log scale)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general, we would expect the infection to spread linearly on a log scale. This is not the case here, it seems that there is a certain time (during the period of discovery of the virus) where the infection rates increased much more greatly than we might expect. However, in the end the curve flattens out and is becoming linear as we expect. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# similarly lets take a look at the other variables with time\nplt.figure(figsize=(18,10))\nnp.log10(df.groupby('date')['deaths'].sum()).plot()\nyticks = [10,20,50,100,200,500,1000,2000,5000,10000,20000,50000]\nplt.yticks(np.log10(yticks),yticks);\nplt.title('Total Confirmed Deaths with Time (log scale)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,10))\nnp.log10(df.groupby('date')['recovered'].sum()).plot()\nyticks = [10,20,50,100,200,500,1000,2000,5000,10000,20000,50000,100000,200000]\nplt.yticks(np.log10(yticks),yticks);\nplt.title('Total Confirmed Recoveries with Time (log scale)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deaths and recoveries show a similar behavior to the confirmed cases. However, deaths are much quicker in adjusting and recoveries seem to take more time peak and readjust. This makes sense because recoveries can only happen after a period of time from infections."},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirmed cases across countries\ndata = df.query('date == \"2020-03-27\"') # pick the most recent date\ndata = np.log10(data.groupby('country')['confirmed'].sum().sort_values(ascending=False)) # sorting countries and using log scale\nyticks= [1,2,5,10,20,50,100,200,500,1000,2000,5000,10000,20000,50000,100000,200000]\nplt.figure(figsize=(25,7))\ndata.plot(kind='bar')\nplt.yticks(np.log10(yticks),yticks);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the nature of the total  distribution across countries. The data looks linear with some slight 'bumps' in certain regions. Again, a log scale is used to account for the huge difference in data and the exponential nature of the virus transmission.\n\nThe graph also show that the country with the most confirmed cases is the United States followed by Italy and China. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets take a look at the correlation between all variables\nplt.figure(figsize=(14,5))\nsns.heatmap(df.corr(),annot = True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a very interesting plot. What we are mostly interested in is the upper left (bright) rectangle. Here are the main observations:\n- The number of confirmed infections is highly correlated with: the number of deaths,  the number of recoveries and the population of the country.\n- The number of deaths is also correlated with the number of recovering cases but has a week correlation with the population.\n- The median age, density, and percentage of urban population seem to have no effect on any of the cases.\n\nThe relation between the above variables is worth looking at more closely."},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets first take a look at the relationship between confirmed cases and number of deaths\n# lets also not forget to use a log scale for both values\n# since some of these values are 0 we have to make sure to remove these values\ndf2 = df #.query('date == \"2020-03-27\"') # we can choose a single date to see the data more clearly\ndf2 = df2[(df2.confirmed != 0) & (df2.deaths != 0)]\nx = np.log10(df2.confirmed)\ny= np.log10(df2.deaths)\nplt.figure(figsize=(18,10))\nxticks = [1,3,10,30,100,300,1000,3000,10000,30000,100000,300000]\nyticks= xticks[:-2]\nsns.regplot(x,y,scatter_kws={'alpha':1/5});\nplt.xticks(np.log10(xticks),xticks,rotation=90)\nplt.yticks(np.log10(yticks),yticks);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a clear trend here: with a low number of cases, the data is very scattered. It starts to converge slowly into a single line as the number of cases increase. The line has a slope of around 0.1 (which is close to the global mortality rate).\n\nIt is also clear that the regression line deviates from that line due to the high number of cases at 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets look at the confirmed cases vs population\ndf2 = df.query(\"date == '2020-03-27'\") # lets take a look at just 1 day to avoid duplicate values\ndf2 = df2[(df2.confirmed != 0) & (df2.population !=0)]\nx = np.log10(df2.confirmed)\ny = np.log10(df2.population)\nplt.figure(figsize=(18,10))\nxticks = [1,3,10,30,100,300,1000,3000,10000,30000,100000,300000]\nplt.xticks(np.log10(xticks),xticks,rotation=90)\nyticks = [5000,10000,100000,1000000,int(3e6),int(1e7),int(3e7),int(1e8),int(3e8),int(1e9),int(3e9)]\nplt.yticks(np.log10(yticks),yticks)\nsns.regplot(x,y,scatter_kws={'alpha':1/2});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph above suggests that there is no relation between the confirmed infection rates and the population of the country. This could be due to several reasons:\n- Measures taken by countries to stop the infection\n- Since we can check only 'confirmed' cases. The confirmed variable could be affected by the ability of a country to do tests.\n- Some countries do not report the actual confirmed cases they have"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets take a look to see if the density of a country is related\ndf2 = df.query(\"date == '2020-03-27'\") # also last date so we can filter by country\ndf2 = df2[(df2.confirmed != 0) & (df2.density !=0)]\nx = np.log10(df2.confirmed)\ny = df2.density # no need to use log here\nplt.figure(figsize=(18,10))\nxticks = [1,3,10,30,100,300,1000,3000,10000,30000,100000,300000]\nplt.xticks(np.log10(xticks),xticks,rotation=90) # same xticks as above\n#yticks = [5000,10000,100000,1000000,int(3e6),int(1e7),int(3e7),int(1e8),int(3e8),int(1e9),int(3e9)]\n#plt.yticks(np.log10(yticks),yticks)\nplt.ylim(0,500) # zooming in\nsns.regplot(x,y,scatter_kws={'alpha':1/2});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, no apparent relation is found between the confirmed cases and the density of a country. Although we could say that more dense countries are more scattered than the less dense ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we take a look at median age vs deaths\ndf2 = df.query(\"date == '2020-03-27'\")\ndf2 = df2[(df2.deaths != 0) & (df2.median_age !=0)]\nx = np.log10(df2.deaths)\ny= df2.median_age\nplt.figure(figsize=(18,10))\nxticks = [0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3,0.6]\nplt.xticks(np.log10(xticks),xticks)\nsns.regplot(x,y,scatter_kws={'alpha':0.4});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data verifies what we know about the virus: it is generally more lethal to older people. However, no clear trend is observed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# one final thought: are people in the cities more suscptible to the virus\ndf2 = df.query(\"date == '2020-03-27'\")\ndf2 = df2[(df2.confirmed != 0) & (df2.urban_pop !=0)]\nx = np.log10(df2.confirmed)\ny= df2.urban_pop\nplt.figure(figsize=(18,10))\nxticks = [1,3,10,30,100,300,1000,3000,10000,30000,100000,300000]\nplt.xticks(np.log10(xticks),xticks,rotation=90)\nsns.regplot(x,y,scatter_kws={'alpha':0.4});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although the data is scattered and no clear line can be drawn, the trend of the data seems to be going upwards suggesting that cities can be a factor in spreading the virus (as expected)."},{"metadata":{},"cell_type":"markdown","source":"## Multivariate Exploration\n\nAfter looking through our variables, it is time to check how to combine them together to check for more useful results.\n\nIn the Bivariate Plots section, we looked at the spread of infection through time. This time however, we will take a look at the spread in a different way: we will compare the new cases vs total cases in a specific date and for each country (each country represents a dot). This was inspired by this [video][1].\n\nIn short, if we plot new cases vs total cases, we can tell which countries are doing better and which are doing worse. Ultimately, this could serve as a prediction for how well a country will do in the following days. In order to do that however, we will need to create a new variable called 'new_cases' which is the increase in the number of cases from the previous day.\n\n[1]:https://youtu.be/54XLXg4fYsc"},{"metadata":{"trusted":true},"cell_type":"code","source":"# add a new column called 'new cases'\n# this will count the increase in new cases (per day) instead of the total cumulative value\ndf2 = df.groupby(['country','date'])['confirmed'].sum().diff()\ndf2 = df2.reset_index()\ndf2.loc[df2.confirmed<0,'confirmed'] =0 \ndf2= df2.fillna(0)\ndf['new_cases'] = df2['confirmed']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After creating the variable, we can check the performance of each country and try to predict future performance. For that, I have selected 2 dates to compare: 'Mar,27' (most recent update of data I have) and 'Mar,13' (around 14 days before 27 march). \n\nIn addition, since there are many different countries, I have chosen to highlight only few of them for comparison purposes."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_on_date(interest_date,interest_countries):\n    '''\n    interest_date: the date we are interested in (yyyy-mm-dd)\n    interest_countries: a list of countries we are interested in.\n    '''\n    df2 = df.query(('date == @interest_date'))\n    df2 = df2[(df2.confirmed != 0) & (df2.new_cases !=0)]\n    x = np.log10(df2.confirmed)\n    y = np.log10(df2.new_cases)\n    xticks = [1,3,10,30,100,300,1000,3000,10000,30000,100000,300000]\n    plt.xticks(np.log10(xticks),xticks)\n    yticks =  [1,3,10,30,100,300,1000,3000,10000,30000]\n    plt.yticks(np.log10(yticks),yticks)\n    ax = sns.regplot(x,y,scatter_kws={'alpha':0.5},fit_reg=False);\n    plt.title(interest_date)\n    for i in interest_countries:\n        subset = df2.query('country == @i')\n        x = np.log10(subset.confirmed) - 0.1\n        y = np.log10(subset.new_cases) + 0.1\n        ax.text(x,y,i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interest_countries = ['United States', 'Italy','China','Lebanon','South Korea', 'United Kingdom','Spain','Egypt','Qatar','Netherlands','Turkey']\nfig, (ax1,ax2) = plt.subplots(1,2)\nfig.set_figheight(10)\nfig.set_figwidth(20)\n\nplt.subplot(121)\nplot_on_date('2020-03-25',interest_countries)\n\nplt.subplot(122)\nplot_on_date(str(df.date.max().date()),interest_countries)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By comparing the plots, we can see that countries that are doing the worst are all aligned on a line. By comparing the countries on the left (Mar,20) to those on the right (latest date), we can predict the countries that are going to do better or worse on the upcoming days. Here are some examples:\n\n- **United States:** In Mar, 25 the United States plot was situated on the 'danger line' like many other countries. In the second plot, we can see how quickly the number of cases increased. Unfortunately, The United States doesn't seem to have dropped from the line in the second plot as well.\n- **Italy:** Italy was in the very high right in the first plot. However, in the second plot we can see a noticable improvement.\n- **Spain:** Spain seems to be becoming more and more dangerous each day\n- **China and South Korea:** They seem to be recovering after a huge battle with the virus.\n- **Lebanon:** We can see the position of Lebanon within countries. We can see it performing much better than Egypt and Qatar for example.\n- **Turkey:** Turkey seems to be climbing up the danger line and following the United States.\n- **Netherlands:** Netherlands seem to have things under control but still in the danger zone.\n- **Qatar:** Qatar was relatively safe but it seems to be climbing back up: there seems to be a chance of a wide spread of infections in the upcoming days.\n\nComparing countries is good if we know what we are looking for. However, a better way of understanding the virus globally is to check how certain containment measures have affected the spread of the virus. \n\nOne such factor is how long it took the country to start enforcing serious measures such as school and university closure and business suspension. To do that, we need to create some more variables.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get first case for each country\nkeywords = ['closure school','university closure','closure university','business suspension']\nlast_date = str(df.date.max().date())\ndf2= df.query('date == @last_date')\ntest_df = df[df.confirmed >  1].groupby('country',as_index=False).date.min().rename(columns={'date': 'date_first_case'})\ntest2_df = df[df.keywords.str.contains('|'.join(keywords))].groupby('country',as_index=False).date.min().rename(columns={'date': 'date_first_measure'})\ndata = pd.merge(test_df,test2_df,how='inner',on='country')\ndata['delay'] = (data['date_first_measure'] - data['date_first_case']).dt.days\ndf3 = pd.merge(data,df2,how='inner',on='country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we created three variables:\n- `date_first_case`: the date of the first confirmed case in a country.\n- `date_first_measure`: the date when certain measures were taken (suggested by the `keywords` list).\n- `delay`: the difference between the first measure taken and the first case (in days)\n\nThe reason for this is that we expect that countries that did not close public establishments quickly after discovering the first case, are going to have a higher chance of spreading the virus."},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df3.query('new_cases > 0')\nx = np.log10(df3.confirmed)\ny = np.log10(df3.new_cases)\nz = df3.delay\nplt.figure(figsize=(15,8))\nxticks = [1,3,10,30,100,300,1000,3000,10000,30000,100000,300000]\nplt.xticks(np.log10(xticks),xticks)\nyticks =  [1,3,10,30,100,300,1000,3000,10000,30000]\nplt.yticks(np.log10(yticks),yticks)\nax = sns.scatterplot(x,y,hue=z,palette='RdBu_r');\nplt.title('Effect of delay on country performance ({})'.format(last_date));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above shows that taking certain measures after discovering the first case of Covid-19 really helps in fighting the virus. The delay in applying such measures is an important factor in determining how quickly the virus would spread across the country.\n\nThe keywords of interest ('school closure','university closure',etc) represent - in my opinion - the time where a country starts taking more serious measures to contain the virus. Although there are many more. the data that we have is limited and might not be very accurate. \n\nHowever, we can clearly see that countries that took more time to start closing public establishment have a much greater spread than others. "},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nIn this report we took a look at the global spread and containment of the Covid-19 virus. Some of the questions that we were able to answer:\n\n*Q: Which countries are doing better than others and why?*\n\nMany countries were able to reduce the impact of the virus not only by taking suitable measure but also by being able to enforce them quickly after discovering the first case.\n\n*Q: What measures are the most effective against the spread of the virus?*\n\nWe have seen that the most common measures taken to limit the spread of the virus include: 'university closure', 'school closure','travel ban'. However, what is more important is being able to enforce them correctly and within time.\n\n*Q: How do the death and recovery rates compare according to population, density and median age of a country?*\n\nIn general, countries with high population tend to have a higher number of cases. Median age seem to be weakly correlated with the number of deaths. \n\n*Q: How does Lebanon compare to other countries regarding measures taken and spread of the virus?*\n\nWe saw how Lebanon compared with other countries. It is performing well in general but still has a long battle ahead."},{"metadata":{"trusted":true},"cell_type":"code","source":"# finally saving\ndf.to_csv('./final_dataset.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":4}