{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datetime import date\n\nfrom sklearn.linear_model import LinearRegression, ElasticNetCV, RidgeCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold, train_test_split, GridSearchCV\n\nimport xgboost as xgb\n\nimport sys\n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def num_days(date1, date2):\n    dt1 = date1.split(\"-\")\n    dt2 = date2.split(\"-\")\n    \n    d2 = date(int(dt2[0]),int(dt2[1]),int(dt2[2]))\n    d1 = date(int(dt1[0]),int(dt1[1]),int(dt1[2]))\n              \n    delta = d2-d1\n    return(delta.days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Province_State'] = train['Province_State'].apply(lambda x: \"CountryLevel\" if pd.isna(x) else x)\ntest['Province_State'] = test['Province_State'].apply(lambda x: \"CountryLevel\" if pd.isna(x) else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Day'] = train['Date'].apply(lambda x: num_days('2020-01-22',x))\ntest['Day'] = test['Date'].apply(lambda x: num_days('2020-01-22',x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_countries = train['Country_Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    return np.sqrt(np.mean((np.log(1+y) - np.log(1+y_pred))**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_countries = train['Country_Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_df = pd.DataFrame()\nfor country in unique_countries:\n    localdf = train.copy()\n    testdf = test.copy()\n    localdf = localdf[localdf.Country_Region == country]\n    unique_province = localdf['Province_State'].unique()\n    for province in unique_province:\n        print(country+\" - \"+province)\n        tdf = localdf[localdf['Province_State']==province]\n        testdf = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        \n        ## Confirmed Cases\n        polynomial_features= PolynomialFeatures(degree=5)\n        x_train = tdf['Day'].values\n\n        y_train = tdf['ConfirmedCases'].values\n        x_train = x_train[:, np.newaxis]\n        y_train = y_train[:, np.newaxis]\n\n        x_poly = polynomial_features.fit_transform(x_train)\n        x_poly1 = xgb.DMatrix(x_poly)\n        param = {'max_depth':2, 'eta':1, 'objective':'linear' }\n        #model = LinearRegression()\n        #model = DecisionTreeRegressor()\n        model = RandomForestRegressor()\n        num_round = 2\n        #model = xgb.XGBRFRegressor()\n        clf = GridSearchCV(model,\n                           {'max_depth': [2,4,6]\n                            }, verbose=1)        \n        clf.fit(x_poly, y_train)\n        y_insample_pred = clf.predict(x_poly)\n        print(\"RMSE : \"+str(np.sqrt(mean_squared_error(y_train,y_insample_pred))))\n        print(\"R-sq : \"+str(np.sqrt(r2_score(y_train,y_insample_pred))))\n        print(\"RMSLE : \"+str(np.sqrt(rmsle(y_train,y_insample_pred))))\n\n        x_test = testdf['Day']\n        testdf['ConfirmedCases'] = clf.predict(polynomial_features.fit_transform(x_test[:,np.newaxis]))\n\n        polynomial_features1= PolynomialFeatures(degree=4)\n        y_train = tdf['Fatalities'].values\n        y_train = y_train[:, np.newaxis]        \n        #model = DecisionTreeRegressor()\n        model = RandomForestRegressor()\n        #model = xgb.XGBRFRegressor()\n        clf = GridSearchCV(model,\n                           {'max_depth': [2,4,6]\n                            }, verbose=1)         \n        clf.fit(x_poly, y_train)\n        y_insample_pred = clf.predict(x_poly)\n        print(\"RMSE : \"+str(np.sqrt(mean_squared_error(y_train,y_insample_pred))))\n        print(\"R-sq : \"+str(np.sqrt(r2_score(y_train,y_insample_pred))))\n        print(\"RMSLE : \"+str(np.sqrt(rmsle(y_train,y_insample_pred))))\n        x_test = testdf['Day']\n        testdf['Fatalities'] = clf.predict(polynomial_features.fit_transform(x_test[:,np.newaxis]))\n        predict_df = pd.concat([predict_df,testdf],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_df.ConfirmedCases = predict_df.ConfirmedCases.apply(lambda x: np.round(x,0))\npredict_df.Fatalities = predict_df.Fatalities.apply(lambda x: np.round(x,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_df[['ForecastId','ConfirmedCases','Fatalities']].to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newdf = predict_df.merge(right=train, how=\"inner\",on=['Province_State', 'Country_Region', 'Date'])\nnewdf.drop(['Day_x','Day_y','Id','ForecastId'],axis=1, inplace=True)\nnewdf['ConfirmedCases_LSE'] = (np.log(newdf.ConfirmedCases_x+1)-np.log(newdf.ConfirmedCases_y+1))**2\nnewdf['Fatalities_LSE'] = (np.log(newdf.Fatalities_x+1)-np.log(newdf.Fatalities_y+1))**2\nprint(np.sqrt(np.sum(newdf.ConfirmedCases_LSE)/len(newdf)))\nprint(np.sqrt(np.sum(newdf.Fatalities_LSE)/len(newdf)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}