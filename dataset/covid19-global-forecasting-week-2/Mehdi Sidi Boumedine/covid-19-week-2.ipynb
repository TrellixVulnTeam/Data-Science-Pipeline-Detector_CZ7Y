{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nI'm focussing on having the most meaningful external data added to the original data set, use simple off the shelf tools to make my predictions. Most of the data I've got are from https://data.worldbank.org/ from http://www.stats.gov.cn/english/Statisticaldata/AnnualData/ and https://catalog.data.gov/dataset/age-adjusted-death-rates-and-life-expectancy-at-birth-all-races-both-sexes-united-sta-1900\n\nJoined and cleaned the data on Excel before uploading"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n#submission = pd.read_csv(\"../input/covid19-global-forecasting-week-1/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\", parse_dates=[\"Date\"])\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\", parse_dates=[\"Date\"])\nglobal_data = pd.read_csv(\"../input/externalcountrydata/Global_Data_by_Country_2019.csv\")\ncountry_info=pd.read_csv(\"../input/countryinfo/covid19countryinfo.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train[\"Province_State\"].isnull(), \"Province_State\"]=train.loc[train[\"Province_State\"].isnull(), \"Country_Region\"]\n\ntrain.rename(columns = {'Country_Region':'Country', 'Province_State':'Province'}, inplace = True) \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain=train.merge(global_data, how='left', left_on=['Country', 'Province'], right_on=['CountryName', 'Province'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train=train.merge(country_info[[\"country\", \"medianage\"]], how='left', left_on='Country', right_on='country' )\n\n#medianage, smoker, hospibed, lung","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.rename(columns = {'Country_Region':'Country', 'Province_State':'Province'}, inplace = True) \n#test=test.merge(country_info[[\"country\", \"medianage\"]], how='left', left_on='Country', right_on='country' )\ntest.loc[test[\"Province\"].isnull(), \"Province\"]=test.loc[test[\"Province\"].isnull(), \"Country\"]\n\nX_test=test.merge(global_data, how='left', left_on=['Country', 'Province'], right_on=['CountryName', 'Province'])\nX_test=X_test.drop(\"Population\", axis=1)\nX_test=X_test.drop(\"CountryName\", axis=1)\nX_test=X_test.rename(columns={\"ExtraColumn\": \"Population\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del global_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(\"Population\", axis=1)\ntrain=train.drop(\"CountryName\", axis=1)\n\ntrain=train.rename(columns={\"ExtraColumn\": \"Population\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mindates = train[train[\"ConfirmedCases\"]>0].groupby(['Province'])[\"Date\"].min()\nmindates.reset_index()\nmindatesDF = mindates.to_frame()\nmindatesDF.rename(columns={\"Date\":\"MinDate\"}, inplace=True)\ntrain=train.merge(mindatesDF, how='left', left_on=\"Province\", right_on=\"Province\")\ntrain[\"DaysFrom1stCase\"]=(train[\"Date\"]-train[\"MinDate\"]).dt.days\ntrain.loc [train[\"DaysFrom1stCase\"]<0 , \"DaysFrom1stCase\"] =0\nfirst_day=train[train[\"ConfirmedCases\"]>0].Date.min()\ntrain[\"DaysFromStart\"]=(train[\"Date\"]-first_day).dt.days \n## after version 2 ###\n#train=pd.get_dummies(train, prefix='prov', prefix_sep='_', dummy_na=True, columns=\"Province\", sparse=False, drop_first=False, dtype=None)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \n\nlabelencoder = LabelEncoder()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province=labelencoder.fit_transform(train[\"Province\"])\ntrain=pd.concat([train, pd.DataFrame(province)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain=train.drop([\"Country\",\"MinDate\", \"Province\"], axis=1)\n#train=train.drop([\"Country\",\"MinDate\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.rename(columns={0:\"Province\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\n\n\ny_train_CC=train.loc[:,\"ConfirmedCases\"]\ny_train_F=train.loc[:, \"Fatalities\"]\nX_train=train.drop([\"ConfirmedCases\", \"Fatalities\", \"Id\", \"Date\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X_train.columns:\n    X_train[col]=X_train[col].fillna(X_train[col].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\n#pca = PCA(n_components=7)\n#pca.fit(X_train)\n#X_train= pd.DataFrame(pca.transform(X_train))\n\n\n\nX_train_real_CC, X_test_val_CC, y_train_real_CC, y_test_val_CC = train_test_split(\n        X_train, y_train_CC, test_size=0.3, random_state=0)\n\n\n\nlgb_train_CC = lgb.Dataset(X_train_real_CC, y_train_real_CC)\nlgb_eval_CC = lgb.Dataset(X_test_val_CC, y_test_val_CC, reference=lgb_train_CC)\n\n\nX_train_real_F, X_test_val_F, y_train_real_F, y_test_val_F = train_test_split(\n        X_train, y_train_F, test_size=0.3, random_state=0)\n\nlgb_train_F = lgb.Dataset(X_train_real, y_train_real_F)\nlgb_eval_F = lgb.Dataset(X_test_val, y_test_val_F, reference=lgb_train_F)\n\n\n#X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"params_CC = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'learning_rate': 0.3,\n        'num_leaves': 30,\n        'min_data_in_leaf': 1,\n        'num_iteration': 100,\n        'verbose': 20\n}\n\n\nparams_F = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'learning_rate': 0.28,\n        'num_leaves': 35,\n        'min_data_in_leaf': 2,\n        'num_iteration': 100,\n        'verbose': 20\n}\ngbm_CC = lgb.train(params_CC,\n            lgb_train_CC,\n            num_boost_round=100,\n            valid_sets=lgb_eval_CC,\n            early_stopping_rounds=10)\n\ngbm_F = lgb.train(params_F,\n            lgb_train_F,\n            num_boost_round=100,\n            valid_sets=lgb_eval_F,\n            early_stopping_rounds=10)"},{"metadata":{"trusted":true},"cell_type":"code","source":"params_CC = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'learning_rate': 0.3,\n        'num_leaves': 30,\n        'min_data_in_leaf': 1,\n        'num_iteration': 100,\n        'verbose': 20\n}\n\n\nparams_F = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'learning_rate': 0.28,\n        'num_leaves': 35,\n        'min_data_in_leaf': 2,\n        'num_iteration': 100,\n        'verbose': 20\n}\n\n\ngbm_CC = lgb.LGBMRegressor(n_jobs=-1)\ngbm_F = lgb.LGBMRegressor(n_jobs=-1)\n\nparam_grid = {\n    \"num_leaves\" : np.linspace(10, 200, 4, dtype=np.int32),\n    'learning_rate': np.linspace(0.1, 1, 5),\n    'n_estimators': np.linspace(10, 1000, 5, dtype=np.int32),\n    'early_stopping_rounds' : [20],\n}\n\ngbm_CC = GridSearchCV(gbm_CC, param_grid, cv=3, scoring=\"neg_mean_squared_error\", verbose=100, n_jobs=-1)\ngbm_CC.fit(X_train_real_CC, y_train_real_CC, eval_set=[(X_test_val_CC, y_test_val_CC)], eval_metric=\"rmse\")\nprint('Best parameters:', gbm_CC.best_params_)\n\ngbm_F = GridSearchCV(gbm_F, param_grid, cv=3, scoring=\"neg_mean_squared_error\", verbose=100, n_jobs=-1)\ngbm_F.fit(X_train_real_F, y_train_real_F, eval_set=[(X_test_val_F, y_test_val_F)], eval_metric=\"rmse\")\nprint('Best parameters:', gbm_F.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transform the Test Dataset before prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## add days since first case column ##\nX_test=X_test.merge(mindatesDF, how='left', left_on=\"Province\", right_on=\"Province\")\nX_test[\"DaysFrom1stCase\"]=(X_test[\"Date\"]-X_test[\"MinDate\"]).dt.days\nX_test.loc [X_test[\"DaysFrom1stCase\"]<0 , \"DaysFrom1stCase\"] =0\nX_test[\"DaysFromStart\"]=(X_test[\"Date\"]-first_day).dt.days \n\n#X_test=pd.get_dummies(X_test, prefix='prov', prefix_sep='_', dummy_na=True, columns=\"Province\", sparse=False, drop_first=False, dtype=None)\n\nX_test=X_test.drop([\"Country\", \"MinDate\"], axis=1)\n\nX_test=X_test.drop([\"ForecastId\", \"Date\"], axis=1)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province=labelencoder.transform(X_test[\"Province\"])\nX_test=pd.concat([X_test,pd.DataFrame(province) ], axis=1)\nX_test=X_test.drop([\"Province\"], axis=1)\nfor col in X_test.columns:\n    X_test[col]=X_test[col].fillna(X_test[col].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test= pca.transform(X_test)\n\n#y_pred=regressor.predict(X_test)\n#y_pred_CC = gbm_CC.predict(X_test, num_iteration=gbm_CC.best_iteration)\n#y_pred_F = gbm_F.predict(X_test, num_iteration=gbm_F.best_iteration)\n\n\ny_pred_CC = gbm_CC.predict(X_test)\ny_pred_F = gbm_F.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecastId=test.ForecastId.to_numpy()\nsubmission_CC=pd.DataFrame(y_pred_CC)\nsubmission_CC=submission_CC.rename(columns={0:\"ConfirmedCases\"})\nsubmission_F=pd.DataFrame(y_pred_F)\nsubmission_F=submission_F.rename(columns={0:\"Fatalities\"})\nforecastIdDF=pd.DataFrame(forecastId)\nforecastIdDF=forecastIdDF.rename(columns={0:\"ForecastId\"})\nsubmission=pd.concat([forecastIdDF, submission_CC, submission_F ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.concat([test, submission ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test.Province==\"Algeria\"]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}