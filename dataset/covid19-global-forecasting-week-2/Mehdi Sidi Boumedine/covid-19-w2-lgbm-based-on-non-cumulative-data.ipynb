{"cells":[{"metadata":{},"cell_type":"markdown","source":"Private note : Forked from best submission v4 \nBased on lgbm\nTry to fine tune hyperparameters via gridsearchCV\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n#submission = pd.read_csv(\"../input/covid19-global-forecasting-week-1/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\", parse_dates=[\"Date\"])\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\", parse_dates=[\"Date\"])\nglobal_data = pd.read_csv(\"../input/externalcountrydata/Global_Data_by_Country_2019.csv\")\ncountry_info=pd.read_csv(\"../input/countryinfo/covid19countryinfo.csv\")\nglobal_data=global_data.drop( [\"HealthExpenditure\"], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train[\"Province_State\"].isnull(), \"Province_State\"]=train.loc[train[\"Province_State\"].isnull(), \"Country_Region\"]\n\ntrain.rename(columns = {'Country_Region':'Country', 'Province_State':'Province'}, inplace = True) \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain=train.merge(global_data, how='left', left_on=['Country', 'Province'], right_on=['CountryName', 'Province'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train=train.merge(country_info[[\"country\", \"medianage\",\"urbanpop\"]], how='left', left_on='Country', right_on='country' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.rename(columns = {'Country_Region':'Country', 'Province_State':'Province'}, inplace = True) \n\ntest.loc[test[\"Province\"].isnull(), \"Province\"]=test.loc[test[\"Province\"].isnull(), \"Country\"]\n#test=test.merge(country_info[[\"country\", \"medianage\", \"urbanpop\"]], how='left', left_on='Country', right_on='country' )\n\n\nX_test=test.merge(global_data, how='left', left_on=['Country', 'Province'], right_on=['CountryName', 'Province'])\nX_test=X_test.drop(\"Population\", axis=1)\nX_test=X_test.drop([\"CountryName\"], axis=1)\nX_test=X_test.rename(columns={\"ExtraColumn\": \"Population\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del global_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(\"Population\", axis=1)\ntrain=train.drop(\"CountryName\", axis=1)\n\ntrain=train.rename(columns={\"ExtraColumn\": \"Population\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mindates = train[train[\"ConfirmedCases\"]>0].groupby(['Province'])[\"Date\"].min()\nmindates.reset_index()\nmindatesDF = mindates.to_frame()\nmindatesDF.rename(columns={\"Date\":\"MinDate\"}, inplace=True)\ntrain=train.merge(mindatesDF, how='left', left_on=\"Province\", right_on=\"Province\")\ntrain[\"DaysFrom1stCase\"]=(train[\"Date\"]-train[\"MinDate\"]).dt.days\ntrain.loc [train[\"DaysFrom1stCase\"]<0 , \"DaysFrom1stCase\"] =0\n\n## after version 2 ###\n#train=pd.get_dummies(train, prefix='prov', prefix_sep='_', dummy_na=True, columns=\"Province\", sparse=False, drop_first=False, dtype=None)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adds_to_cumulative(df, col, newlabel):\n    work=df[df.Province==\"No Such Country\"]\n    work[newlabel]=np.NaN\n    print(1)\n    for province in df.Province.unique():\n        subframe=df[df.Province==province].copy()\n        subframe=subframe.sort_values(\"Date\")\n        minvalue=subframe[col].min()\n        subframesize=df[df.Province==province].size\n        temparray=subframe[col].values.tolist()\n        for i in range(1,len(temparray)-1 ):\n            temparray[i]=temparray[i]+temparray[i-1]\n            #print(temparray[i],temparray[i]-temparray[i-1])\n        temparray[0]=minvalue\n        subframe[newlabel]=temparray\n        #print(country, temparray[-1])\n        work=pd.concat([work,subframe])\n        del(subframe)\n        del(temparray)\n        #work.to_csv(\"work.csv\")\n    #df=df.merge(subframe[[\"Country\", \"Date\", \"add\"]], how=\"left\", left_on=[\"Country\", \"Date\"], right_on=[\"Country\", \"Date\"])\n    return work \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cumulative_to_adds(df, col, newlabel):\n    work=df[df.Province==\"No Such Country\"]\n    work[newlabel]=np.NaN\n    print(1)\n    for province in df.Province.unique():\n        subframe=df[df.Province==province].copy()\n        minvalue=subframe[col].min()\n        df=df.sort_values(\"Date\")\n        subframesize=df[df.Province==province].size\n        temparray=subframe[col].values.tolist()\n        for i in range(len(temparray)-1,1,-1 ):\n            temparray[i]=temparray[i]-temparray[i-1]\n            #print(temparray[i],temparray[i]-temparray[i-1])\n        temparray[0]=minvalue\n        subframe[newlabel]=temparray\n        #print(country, temparray[-1])\n        work=pd.concat([work,subframe])\n        del(subframe)\n        del(temparray)\n        #work.to_csv(\"work.csv\")\n    #df=df.merge(subframe[[\"Country\", \"Date\", \"add\"]], how=\"left\", left_on=[\"Country\", \"Date\"], right_on=[\"Country\", \"Date\"])\n    return work ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=cumulative_to_adds(train, \"ConfirmedCases\", \"ConfirmedAdds\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.Country==\"Algeria\"].sort_values(\"ConfirmedCases\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=cumulative_to_adds(train, \"Fatalities\", \"FatalitiesAdds\")\ntrain=train.drop([\"ConfirmedCases\", \"Fatalities\"], axis=1)\ntrain=train.rename(columns={\"ConfirmedAdds\": \"ConfirmedCases\", \"FatalitiesAdds\":\"Fatalities\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test=cumulative_to_adds(X_test, \"ConfirmedCases\", \"ConfirmedAdds\")\n#X_test=cumulative_to_adds(X_test, \"Fatalities\", \"FatalitiesAdds\")\n#X_test.drop([\"ConfirmedCases\", \"Fatalities\"], axis=1)\n#X_test.rename(columns={\"ConfirmedAdds\": \"ConfirmedCases\", \"FatalitiesAdds\":\"Fatalities\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \n\nlabelencoder = LabelEncoder()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province=labelencoder.fit_transform(train[\"Province\"])\ntrain=pd.concat([train, pd.DataFrame(province)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain=train.drop([\"Country\",\"MinDate\", \"Province\"], axis=1)\n#train=train.drop([\"Country\",\"MinDate\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot(x=\"Date\", y=\"ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\n\n\ny_train_CC=train.loc[:,\"ConfirmedCases\"]\ny_train_F=train.loc[:, \"Fatalities\"]\nX_train=train.drop([\"ConfirmedCases\", \"Fatalities\", \"Id\", \"Date\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X_train.columns:\n    X_train[col]=X_train[col].fillna(X_train[col].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\n#pca = PCA(n_components=5)\n#pca.fit(X_train)\n\n#X_train= pd.DataFrame(pca.transform(X_train))\n\n\nX_train_real, X_test_val, y_train_real_CC, y_test_val_CC = train_test_split(\n        X_train, y_train_CC, test_size=0.3, random_state=0)\n\n\n\nlgb_train_CC = lgb.Dataset(X_train_real, y_train_real_CC)\nlgb_eval_CC = lgb.Dataset(X_test_val, y_test_val_CC, reference=lgb_train_CC)\n\n\nX_train_real, X_test_val, y_train_real_F, y_test_val_F = train_test_split(\n        X_train, y_train_F, test_size=0.3, random_state=0)\n\nlgb_train_F = lgb.Dataset(X_train_real, y_train_real_F)\nlgb_eval_F = lgb.Dataset(X_test_val, y_test_val_F, reference=lgb_train_F)\n\n\n#X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_real.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'learning_rate': 0.3,\n        'num_leaves': 30,\n        'min_data_in_leaf': 1,\n        'num_iteration': 100,\n        'verbose': 20\n}\n\ngbm_CC = lgb.train(params,\n            lgb_train_CC,\n            num_boost_round=100,\n            valid_sets=lgb_eval_CC,\n            early_stopping_rounds=10)\n\ngbm_F = lgb.train(params,\n            lgb_train_F,\n            num_boost_round=100,\n            valid_sets=lgb_eval_F,\n            early_stopping_rounds=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transform the Test Dataset before prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## add days since first case column ##\nX_test=X_test.merge(mindatesDF, how='left', left_on=\"Province\", right_on=\"Province\")\nX_test[\"DaysFrom1stCase\"]=(X_test[\"Date\"]-X_test[\"MinDate\"]).dt.days\nX_test.loc [X_test[\"DaysFrom1stCase\"]<0 , \"DaysFrom1stCase\"] =0\n\n#X_test=pd.get_dummies(X_test, prefix='prov', prefix_sep='_', dummy_na=True, columns=\"Province\", sparse=False, drop_first=False, dtype=None)\n\nX_test=X_test.drop([\"Country\", \"MinDate\"], axis=1)\n\nX_test=X_test.drop([\"ForecastId\", \"Date\"], axis=1)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province=labelencoder.transform(X_test[\"Province\"])\nX_test=pd.concat([X_test,pd.DataFrame(province) ], axis=1)\nX_test=X_test.drop([\"Province\"], axis=1)\nfor col in X_test.columns:\n    X_test[col]=X_test[col].fillna(X_test[col].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()\n\ntest[\"DaysFrom1stCase\"] =X_test.DaysFrom1stCase\ntest[\"DaysFromBeginning\"] = X_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test= pca.transform(X_test)\n\n#y_pred=regressor.predict(X_test)\ny_pred_CC = gbm_CC.predict(X_test, num_iteration=gbm_CC.best_iteration)\ny_pred_F = gbm_F.predict(X_test, num_iteration=gbm_F.best_iteration)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecastId=test.ForecastId.to_numpy()\nsubmission_CC=pd.DataFrame(y_pred_CC)\nsubmission_CC=submission_CC.rename(columns={0:\"ConfirmedAdd\"})\nsubmission_F=pd.DataFrame(y_pred_F)\nsubmission_F=submission_F.rename(columns={0:\"FatalitiesAdd\"})\nforecastIdDF=pd.DataFrame(forecastId)\nforecastIdDF=forecastIdDF.rename(columns={0:\"ForecastId\"})\nsubmission=pd.concat([forecastIdDF, submission_CC, submission_F ], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=submission.drop(\"ForecastId\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.concat([test, submission ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.groupby(\"Date\").ConfirmedAdd.sum().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=adds_to_cumulative(test, \"ConfirmedAdd\", \"ConfirmedCases\")\ntest=adds_to_cumulative(test, \"FatalitiesAdd\", \"Fatalities\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test.Country=='Algeria'].sort_values(\"Date\").head(120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.groupby(\"DaysFrom1stCase\").ConfirmedCases.sum().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.plot(x=\"Date\", y=\"ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame(test[[\"ForecastId\",\"ConfirmedCases\", \"Fatalities\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.reset_index()\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}