{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH_WEEK2 = '/kaggle/input/covid19-global-forecasting-week-2'\n\ndf_Train = pd.read_csv(f'{PATH_WEEK2}/train.csv')\ndf_test = pd.read_csv(f'{PATH_WEEK2}/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_POPULATION = '/kaggle/input/population-by-country-2020'\n\ndf_Population = pd.read_csv(f'{PATH_POPULATION}/population_by_country_2020.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"PATH_GOV_RESPONSE_TRACKER = '/kaggle/input/oxford-covid19-government-response-tracker'\n\ndf_Gov_Response = pd.read_excel(f'{PATH_GOV_RESPONSE_TRACKER}/OxCGRT_Download_latest_data.xlsx')"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"PATH_GOOGLE_TRENDS = '/kaggle/input/covid19-googletrends'\n\ndf_GT = pd.read_csv(f'{PATH_GOOGLE_TRENDS}/GoogleTrend_Latest.csv')"},{"metadata":{},"cell_type":"markdown","source":"## Print first and last few rows of Train Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train.iloc[np.r_[0:5, -6:-1], :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Print first and last few rows of Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.iloc[np.r_[0:5, -6:-1], :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Print first and last few rows of Population Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population.iloc[np.r_[0:5, -6:-1], :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Print first and last few rows of Government Response Tracker Dataset"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_Gov_Response.iloc[np.r_[0:5, -6:-1], :]"},{"metadata":{},"cell_type":"markdown","source":"## Print first and last few rows of Covid19 Google Trends Dataset"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_GT.iloc[np.r_[0:5, -6:-1], :]"},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Rename the Columns of Train and Test Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train.rename(columns={'Country_Region':'Country'}, inplace=True)\ndf_test.rename(columns={'Country_Region':'Country'}, inplace=True)\n\ndf_Train.rename(columns={'Province_State':'State'}, inplace=True)\ndf_test.rename(columns={'Province_State':'State'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport plotly.express as px\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train.loc[: , ['Country', 'ConfirmedCases', 'Fatalities']].groupby(['Country']).max().sort_values(by='ConfirmedCases', ascending=False).reset_index()[:15].style.background_gradient(cmap='rainbow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train['Date'] = pd.to_datetime(df_Train['Date'], infer_datetime_format=True)\ndf_plot = df_Train.loc[: , ['Date', 'Country', 'ConfirmedCases', 'Fatalities']].groupby(['Date', 'Country']).max().reset_index()\n\ndf_plot.loc[:, 'Date'] = df_plot.Date.dt.strftime(\"%Y-%m-%d\")\ndf_plot.loc[:, 'Size'] = np.power(df_plot[\"ConfirmedCases\"]+1,0.3)-1 #np.where(df_plot['Country'].isin(['China', 'Italy']), df_plot['ConfirmedCases'], df_plot['ConfirmedCases']*300)\nfig = px.scatter_geo(df_plot,\n                     locations=\"Country\",\n                     locationmode = \"country names\",\n                     hover_name=\"Country\",\n                     color=\"ConfirmedCases\",\n                     animation_frame=\"Date\", \n                     size='Size',\n                     #projection=\"natural earth\",\n                     title=\"Rise of Coronavirus Confirmed Cases\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_10_countries = df_Train.groupby('Country')['Date', 'ConfirmedCases', 'Fatalities'].max().sort_values(by='ConfirmedCases', ascending=False).reset_index().loc[:, 'Country'][:10]\ndf_plot = df_Train.loc[df_Train.Country.isin(top_10_countries), ['Date', 'Country', 'ConfirmedCases', 'Fatalities']].groupby(['Date', 'Country']).max().reset_index()\n\nfig = px.line(df_plot, x=\"Date\", y=\"ConfirmedCases\", color='Country')\nfig.update_layout(title='No.of Confirmed Cases per Day for Top 10 Countries',\n                   xaxis_title='Date',\n                   yaxis_title='No.of Confirmed Cases')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population.rename(columns={'Country (or dependency)':'Country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_countries = df_Train.Country.unique().tolist()\npop_countries = df_Population.Country.unique().tolist()\n\nfor country in train_countries:\n    if country not in pop_countries:\n        print (country)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"renameCountryNames = {\n    \"Congo (Brazzaville)\": \"Congo\",\n    \"Congo (Kinshasa)\": \"Congo\",\n    \"Cote d'Ivoire\": \"Côte d'Ivoire\",\n    \"Czechia\": \"Czech Republic (Czechia)\",\n    \"Korea, South\": \"South Korea\",\n    \"Saint Kitts and Nevis\": \"Saint Kitts & Nevis\",\n    \"Saint Vincent and the Grenadines\": \"St. Vincent & Grenadines\",\n    \"Taiwan*\": \"Taiwan\",\n    \"US\": \"United States\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_Train.loc[df_Train.Country in renameCountryNames.keys(), 'Country'] = df_Train.loc[df_Train.Country in renameCountryNames.keys(), 'Country'].map(country_map)\ndf_Train.replace({'Country': renameCountryNames}, inplace=True)\ndf_test.replace({'Country': renameCountryNames}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population.loc[df_Population['Med. Age']=='N.A.', 'Med. Age'] = df_Population.loc[df_Population['Med. Age']!='N.A.', 'Med. Age'].mode()[0]\ndf_Population.loc[df_Population['Urban Pop %']=='N.A.', 'Urban Pop %'] = df_Population.loc[df_Population['Urban Pop %']!='N.A.', 'Urban Pop %'].mode()[0]\ndf_Population.loc[df_Population['Fert. Rate']=='N.A.', 'Fert. Rate'] = df_Population.loc[df_Population['Fert. Rate']!='N.A.', 'Fert. Rate'].mode()[0]\ndf_Population.loc[:, 'Migrants (net)'] = df_Population.loc[:, 'Migrants (net)'].fillna(0)\ndf_Population['Yearly Change'] = df_Population['Yearly Change'].str.rstrip('%')\ndf_Population['World Share'] = df_Population['World Share'].str.rstrip('%')\ndf_Population['Urban Pop %'] = df_Population['Urban Pop %'].str.rstrip('%')\ndf_Population = df_Population.astype({\"Net Change\": int,\"Density (P/Km²)\": int,\"Population (2020)\": int,\"Land Area (Km²)\": int,\"Yearly Change\": float,\"Urban Pop %\": int,\"Fert. Rate\": float,\"Med. Age\": int,\"World Share\": float, \"Migrants (net)\": float,})\n\n# As the Country value \"Diamond Princess\" is a CRUISE, we replace the population \ndf_Population = df_Population.append(pd.Series(['Diamond Princess', 3500, 0, 0, 0, 0, 0.0, 1, 30, 0, 0.0], index=df_Population.columns ), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population[df_Population['Population (2020)'] <= 5000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train_countries = df_Train.Country.unique().tolist()\ngt_countries = df_GT.Country.unique().tolist()\n\nfor country in train_countries:\n    if country not in pop_countries:\n        print (country)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_GT.isna().sum()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_GT.fillna(0, inplace=True)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_GT[df_GT.Country == 'India']"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train = df_Train.merge(df_Population, how='left', left_on='Country', right_on='Country')\ndf_test = df_test.merge(df_Population, how='left', left_on='Country', right_on='Country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_Train1 = df_Train.merge(df_GT, how='left', left_on=['Country', 'Date'], right_on=['Country', 'date'])\ndf_test1 = df_test.merge(df_GT, how='left', left_on=['Country', 'Date'], right_on=['Country', 'date'])"},{"metadata":{},"cell_type":"markdown","source":"### Train Dataset Information"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Dataset Information"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Population.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Transformation"},{"metadata":{},"cell_type":"markdown","source":"## Transform the Date to Pandas DataTime"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train['Date'] = pd.to_datetime(df_Train['Date'], infer_datetime_format=True)\ndf_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset for Model Training "},{"metadata":{},"cell_type":"markdown","source":"## Avoid Data Leakage\nAs the Train Dataset has records till 27th March 2020 and Test Dataset has partial intersection of records from 19th March 2020. Let us concise the Train Dataset to 18th March 2020."},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_TEST_DATE = df_test.Date.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_Train.loc[df_Train.Date < MIN_TEST_DATE, :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target#1 ConfirmedCases Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"y1_Train = df_train.iloc[:, -2]\ny1_Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Target#1 Fatalities Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_Train = df_train.iloc[:, -1]\ny2_Train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill NaN from State feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"EMPTY_VAL = \"EMPTY_VAL\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_Train = df_train.loc[:, ['State', 'Country', 'Date']]\nX_Train = df_train.copy()\n\nX_Train['State'].fillna(EMPTY_VAL, inplace=True)\nX_Train['State'] = X_Train.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_Train['year'] = X_Train['Date'].dt.year\nX_Train['month'] = X_Train['Date'].dt.month\nX_Train['week'] = X_Train['Date'].dt.week\nX_Train['day'] = X_Train['Date'].dt.day\nX_Train['dayofweek'] = X_Train['Date'].dt.dayofweek\n\nX_Train.loc[:, 'Date'] = X_Train.Date.dt.strftime(\"%m%d\")\nX_Train[\"Date\"]  = X_Train[\"Date\"].astype(int)\n\n#X_Train.drop(columns=['Date'], axis=1, inplace=True)\n\nX_Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_Test = df_test.loc[:, ['State', 'Country', 'Date']]\nX_Test = df_test.copy()\n\nX_Test['State'].fillna(EMPTY_VAL, inplace=True)\nX_Test['State'] = X_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_Test['year'] = X_Test['Date'].dt.year\nX_Test['month'] = X_Test['Date'].dt.month\nX_Test['week'] = X_Test['Date'].dt.week\nX_Test['day'] = X_Test['Date'].dt.day\nX_Test['dayofweek'] = X_Test['Date'].dt.dayofweek\n\nX_Test.loc[:, 'Date'] = X_Test.Date.dt.strftime(\"%m%d\")\nX_Test[\"Date\"]  = X_Test[\"Date\"].astype(int)\n\n#X_Test.drop(columns=['Date'], axis=1, inplace=True)\n\nX_Test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Encoding using Label Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transforming the Country and State to Numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train.Country = le.fit_transform(X_Train.Country)\nX_Train['State'] = le.fit_transform(X_Train['State'])\n\nX_Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Test.Country = le.fit_transform(X_Test.Country)\nX_Test['State'] = le.fit_transform(X_Test['State'])\n\nX_Test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[df_train.Country == 'Afghanistan', :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X_Train['confirmed_lag_t3'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(3))\nX_Train['confirmed_lag_t5'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(5))\nX_Train['confirmed_lag_t9'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(9))\n\nX_Train['confirmed_rolling_mean_t3'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(15).rolling(3).mean())\nX_Train['confirmed_rolling_mean_t5'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(15).rolling(5).mean())\nX_Train['confirmed_rolling_mean_t7'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(15).rolling(7).mean())\n\nX_Train['confirmed_rolling_std_t3'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(15).rolling(3).std())\nX_Train['confirmed_rolling_std_t5'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(15).rolling(5).std())\nX_Train['confirmed_rolling_std_t9'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(15).rolling(9).std())\n\nX_Train['confirmed_rolling_skew_t15'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(21).rolling(15).skew())\nX_Train['confirmed_rolling_kurt_t15'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(21).rolling(15).kurt())\n\nX_Train['fatalities_lag_t3'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(3))\nX_Train['fatalities_lag_t5'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(5))\nX_Train['fatalities_lag_t9'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(9))\n\nX_Train['fatalities_rolling_mean_t3'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(15).rolling(3).mean())\nX_Train['fatalities_rolling_mean_t5'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(15).rolling(5).mean())\nX_Train['fatalities_rolling_mean_t7'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(15).rolling(7).mean())\n\nX_Train['fatalities_rolling_std_t3'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(15).rolling(3).std())\nX_Train['fatalities_rolling_std_t5'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(15).rolling(5).std())\nX_Train['fatalities_rolling_std_t9'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(15).rolling(9).std())\n\nX_Train['fatalities_rolling_skew_t15'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(21).rolling(15).skew())\nX_Train['fatalities_rolling_kurt_t15'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(21).rolling(15).kurt())\n\nX_Train['lag_confirmed_t1'] = X_Train.groupby(['State', 'Country'])['ConfirmedCases'].transform(lambda x: x.shift(1))\nX_Train['lag_fatalities_t1'] = X_Train.groupby(['State', 'Country'])['Fatalities'].transform(lambda x: x.shift(1))\n\nX_Train['confirmed_change_t1'] = (X_Train['lag_confirmed_t1'] - X_Train['ConfirmedCases']) / (X_Train['lag_confirmed_t1'])\nX_Train['fatalities_change_t1'] = (X_Train['lag_fatalities_t1'] - X_Train['Fatalities']) / (X_Train['lag_fatalities_t1'])\n\nX_Train.drop(columns=['lag_confirmed_t1', 'lag_fatalities_t1'], axis=1, inplace=True)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train.iloc[3990:4020]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import GridSearchCV\nimport time\nparam_grid = {'n_estimators': [1000]}\n#param_grid = {'nthread':[4], 'objective':['reg:linear'], 'learning_rate': [.03, 0.05], 'max_depth': [5, 6], 'min_child_weight': [4], 'silent': [1], 'subsample': [0.7], 'colsample_bytree': [0.7], 'n_estimators': [500, 1000]}\n\ndef gridSearchCV(model, X_Train, y_Train, param_grid, cv=10, scoring='neg_mean_squared_error'):\n    start = time.time()\n    \n    grid_cv = GridSearchCV(model, param_grid, cv=cv, scoring=scoring)\n    grid_cv.fit(X_Train, y_Train)\n    \n    print (f'{type(model).__name__} Hyper Paramter Tuning took a Time: {time.time() - start}')\n    print (f'Best {scoring}: {grid_cv.best_score_}')\n    print (\"Best Hyper Parameters:\\n{}\".format(grid_cv.best_params_))\n    \n    return grid_cv.best_estimator_\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor()\n\nmodel1 = gridSearchCV(model, X_Train, y1_Train, param_grid, 10, 'neg_mean_squared_error')\nmodel2 = gridSearchCV(model, X_Train, y2_Train, param_grid, 10, 'neg_mean_squared_error')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def applyMLA(model, X_train, X_test, y_train, y_test):\n    start_time = time.time()\n    model.fit(X_train, y_train)\n    end_time = time.time()\n    time2 = end_time-start_time\n\n    predictions = model.predict(X_test)\n    RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, predictions))\n    \n    return [RMSE_test, time2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.decomposition import PCA\n\ndef applyPCA(ncomponents, X):\n    pca = PCA(n_components = ncomponents, random_state = 0)\n    pca.fit(X)\n    return pca.transform(X) "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"X_Train_PCA = applyPCA(21, X_Train)\nX_Test_PCA = applyPCA(19, X_Test)"},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. For each State of a Country,<br>\n2. Train the Model<br>\n3. Predict the Target from trained the Model<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n#from sklearn.ensemble import RandomForestRegressor\n\ncountries = X_Train.Country.unique().tolist()\n\n#models_C = {}\n#models_F = {}\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = X_Train.loc[X_Train.Country == country, :].State.unique().tolist()\n    #print(country, states)\n    # check whether string is nan or not\n    for state in states:\n        X_Train_CS = X_Train.loc[(X_Train.Country == country) & (X_Train.State == state), :]\n        \n        y1_Train_CS = X_Train_CS.loc[:, 'ConfirmedCases']\n        y2_Train_CS = X_Train_CS.loc[:, 'Fatalities']\n        #y1_Train_CS_log = np.log1p(X_Train_CS.loc[:, 'ConfirmedCases'])\n        #y2_Train_CS_log = np.log1p(X_Train_CS.loc[:, 'Fatalities'])\n        \n        X_Train_CS.drop(columns=['Id', 'ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n        \n        X_Train_CS_PCA = X_Train_CS#applyPCA(18, X_Train_CS)\n        \n        #X_Train_CS.Country = le.fit_transform(X_Train_CS.Country)\n        #X_Train_CS['State'] = le.fit_transform(X_Train_CS['State'])\n        \n        X_Test_CS = X_Test.loc[(X_Test.Country == country) & (X_Test.State == state), :]\n        \n        X_Test_CS_Id = X_Test_CS.loc[:, 'ForecastId']\n        X_Test_CS.drop(columns=['ForecastId'], axis=1, inplace=True)\n        \n        X_Test_CS_PCA = X_Test_CS#applyPCA(18, X_Test_CS)\n        \n        #X_Test_CS.Country = le.fit_transform(X_Test_CS.Country)\n        #X_Test_CS['State'] = le.fit_transform(X_Test_CS['State'])\n        \n        #models_C[country] = gridSearchCV(model, X_Train_CS, y1_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        #models_F[country] = gridSearchCV(model, X_Train_CS, y2_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        \n        model1 = XGBRegressor(n_estimators=1250)\n        #model1 = RandomForestRegressor(bootstrap=True, max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n        model1.fit(X_Train_CS_PCA, y1_Train_CS)\n        y1_pred = model1.predict(X_Test_CS_PCA)\n        #model1.fit(X_Train_CS_PCA, y1_Train_CS_log)\n        #y1_pred = np.expm1(model1.predict(X_Test_CS_PCA))\n        \n        model2 = XGBRegressor(n_estimators=1000)\n        #model2 = RandomForestRegressor(bootstrap=True, max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n        model2.fit(X_Train_CS_PCA, y2_Train_CS)\n        y2_pred = model2.predict(X_Test_CS_PCA)\n        #model2.fit(X_Train_CS_PCA, y2_Train_CS_log)\n        #y2_pred = np.expm1(model2.predict(X_Test_CS_PCA))\n        \n        df = pd.DataFrame({'ForecastId': X_Test_CS_Id, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n        df_out = pd.concat([df_out, df], axis=0)\n    # Done for state loop\n# Done for country Loop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, r2_score, mean_squared_log_error\n\nscore = 'neg_root_mean_squared_error'\n\ndef evalModel(model, X_Train, y_Train):\n    cv = KFold(n_splits=10, shuffle=True, random_state=25).get_n_splits(X_Train.values)\n    return cross_val_score(model, X_Train, y_Train, cv=cv, scoring=score)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"X_Train1 = X_Train.copy()\nX_Test1 = X_Test.copy()\n\ny1_Train = X_Train1.loc[:, 'ConfirmedCases']\ny2_Train = X_Train1.loc[:, 'Fatalities']\n\nX_Train1.drop(columns=['Id', 'ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n#X_Train1.drop(columns=['Migrants (net)', 'Net Change', 'Yearly Change'], axis=1, inplace=True)\n\nX_Test1.drop(columns=['ForecastId'], axis=1, inplace=True)\ncols = X_Train1.columns"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from xgboost import XGBRegressor\n\nmodel = XGBRegressor(n_estimators=1000)\n\ny1_rmsle = evalModel(model, X_Train1, y1_Train)\ny2_rmsle = evalModel(model, X_Train1, y2_Train)\n\nprint(y1_rmsle, y2_rmsle)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor()\n\ny1_rmsle = evalModel(model, X_Train1, y1_Train)\ny2_rmsle = evalModel(model, X_Train1, y2_Train)\n\nprint(y1_rmsle, y2_rmsle)\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()\n\ny1_rmsle = evalModel(model, X_Train1, y1_Train)\ny2_rmsle = evalModel(model, X_Train1, y2_Train)\n\nprint(y1_rmsle, y2_rmsle)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.ensemble import AdaBoostRegressor\n\nmodel = AdaBoostRegressor()\n\ny1_rmsle = evalModel(model, X_Train1, y1_Train)\ny2_rmsle = evalModel(model, X_Train1, y2_Train)\n\nprint(y1_rmsle, y2_rmsle)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print(dict(zip(X_Train1.columns, model.feature_importances_)))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"px.bar(x=cols, y=model.feature_importances_)"},{"metadata":{},"cell_type":"markdown","source":"### Change the ForecastId datatype from float to int"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.ForecastId = df_out.ForecastId.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out[3990:4020]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit\n### Use pandas to_csv to create a submission.csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"y1_pred = model1.predict(X_Test)\ny1_pred = y1_pred.round()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"y2_pred = model2.predict(X_Test)\ny2_pred = y2_pred.round()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df_sub = pd.read_csv(f'{PATH_WEEK2}/submission.csv')"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df = pd.DataFrame({'ForecastId': df_sub.ForecastId, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\ndf.head(10)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df.info()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"df.to_csv('submission.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}