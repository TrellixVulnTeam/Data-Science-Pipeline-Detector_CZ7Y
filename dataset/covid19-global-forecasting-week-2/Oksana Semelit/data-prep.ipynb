{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv', sep=',')\ndf['Date'] = pd.to_datetime(df['Date'])\ntrain_last_date = df.Date.unique()[-1]\nprint(f\"Dataset has training data untill : {train_last_date}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add Population Distributions By Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwpop = pd.read_csv('/kaggle/input/worldpopulationbyage/WPP2019_PopulationByAgeSex_Medium.csv')\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"Côte d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'Réunion' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n'China, Taiwan Province of China' : \"Taiwan*\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas\": \"The Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States of America (and dependencies)\" : \"US\",\n\"Venezuela (Bolivarian Republic of)\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\"}\n\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\nwpop = wpop[wpop['Time']==2020].reset_index(drop=True)\nwpop['Location'] = wpop.Location.apply(lambda x : rename_countries(x, country_mapper))\nclean_wpop = wpop[wpop['Location'].isin(df['Country_Region'].unique())].reset_index()\n\npopulation_distribution = []\nfor country, gpdf in clean_wpop.groupby(\"Location\"):\n    aux = {f\"age_{age_grp}\": tot for age_grp, tot in zip(gpdf.AgeGrp, gpdf.PopTotal)}\n    aux[\"Country_Region\"] = country\n    population_distribution.append(aux)\n    \ndf_pop_distrib = pd.DataFrame(population_distribution)\n\n# add missing countries with median values\nno_data = []\nfor country in df['Country_Region'].unique():\n    if country not in df_pop_distrib['Country_Region'].unique():\n        aux = df_pop_distrib.drop('Country_Region', axis=1).median(axis=0).to_dict()\n        aux[\"Country_Region\"] = country\n        no_data.append(aux)\ndf_no_data = pd.DataFrame(no_data)\n\ndf_pop_distrib = pd.concat([df_pop_distrib, df_no_data], axis=0)\n\n# normalize features\nnorm_pop_distrib = df_pop_distrib.drop(\"Country_Region\", axis=1).div(df_pop_distrib.drop(\"Country_Region\", axis=1).sum(axis=1), axis=0)\nnorm_pop_distrib['total_pop'] = df_pop_distrib.drop(\"Country_Region\", axis=1).sum(axis=1)\nnorm_pop_distrib[\"Country_Region\"] = df_pop_distrib[\"Country_Region\"]\n\ndel df_pop_distrib\ndel df_no_data\n# del clean_wpop\n# del wpop\n\ndf = df.merge(norm_pop_distrib, on=\"Country_Region\", how='left')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wpop.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add Smokers Percentages By Country****"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://ourworldindata.org/smoking#prevalence-of-smoking-across-the-world\nsmokers = pd.read_csv('/kaggle/input/smokingstats/share-of-adults-who-smoke.csv')\nsmokers = smokers[smokers.Year == 2016].reset_index(drop=True)\n\nsmokers_country_dict = {'North America' : \"US\",\n 'Gambia' : \"The Gambia\",\n 'Bahamas': \"The Bahamas\",\n \"'South Korea'\" : \"Korea, South\",\n'Papua New Guinea' : \"Guinea\",\n \"'Czech Republic'\" : \"Czechia\",\n 'Congo' : \"Congo (Brazzaville)\"}\n\nsmokers['Entity'] = smokers.Entity.apply(lambda x : rename_countries(x, smokers_country_dict))\n\nno_datas_smoker = []\nfor country in df['Country_Region'].unique():\n    if country not in smokers.Entity.unique():\n        mean_score = smokers[['Smoking prevalence, total (ages 15+) (% of adults)']].mean().to_dict()\n        mean_score['Entity'] = country\n        no_datas_smoker.append(mean_score)\nno_data_smoker_df = pd.DataFrame(no_datas_smoker)   \nclean_smoke_data = pd.concat([smokers, no_data_smoker_df], axis=0)[['Entity','Smoking prevalence, total (ages 15+) (% of adults)']]\nclean_smoke_data.rename(columns={\"Entity\": \"Country_Region\",\n                                  \"Smoking prevalence, total (ages 15+) (% of adults)\" : \"smokers_perc\"}, inplace=True)\n\ndf = df.merge(clean_smoke_data, on=\"Country_Region\", how='left')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Health, Corruption"},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = list(df.Country_Region.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healht_info = pd.read_csv('../input/health-nutrition-and-population-statistics/data.csv')\n#healht_info.sample(5)\n\nhealth_cols_2014 = [\n'GNI per capita, Atlas method (current US$)',\n       'Health expenditure per capita (current US$)',\n       'Health expenditure per capita, PPP',\n       'Health expenditure, private (% of GDP)',\n       'Health expenditure, private (% of total health expenditure)',\n       'Health expenditure, public (% of GDP)',\n       'Health expenditure, public (% of government expenditure)',\n       'Health expenditure, public (% of total health expenditure)',\n       'Health expenditure, total (% of GDP)',\n        'Prevalence of overweight (% of adults)']\nhealth_cols_2015 = ['Diabetes prevalence (% of population ages 20 to 79)',]\nhealth_BCG_col =['Immunization, BCG (% of one-year-old children)',]\nhealth_cols_index = ['Country Name', 'Country Code', 'Indicator Name']\n\nhealht1 = healht_info[healht_info['Indicator Name'].isin(health_cols_2014)].pivot(index ='Country Code', columns ='Indicator Name', values = '2014').reset_index()\nhealht2 = healht_info[healht_info['Indicator Name'].isin(health_cols_2015)].pivot(index ='Country Code', columns ='Indicator Name', values = '2015').reset_index()\nhealht3 = healht_info[healht_info['Indicator Name'].isin(health_BCG_col)].pivot(index ='Country Code', columns ='Indicator Name', values = [ '1980', '1990', '2000'])\nhealht3.columns = healht3.columns.get_level_values(0)\nhealht3.columns = [' '.join(col).strip() for col in healht3.columns.values]\nhealht3 = healht3.add_prefix('BCG_')\nhealht3 = healht3.reset_index()\n#healht1.drop(columns=['Indicator Name'], axis=1, inplace=True)\n\nhealth_countries = healht_info[['Country Code','Country Name']].drop_duplicates(subset=['Country Code','Country Name'], keep=\"first\", inplace=False)\n#health_countries\n\nhealht_merged = health_countries.merge(healht1, on='Country Code').merge(healht2, on='Country Code').merge(healht3, on='Country Code')\nhealht_merged.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n****"},{"metadata":{"trusted":true},"cell_type":"code","source":"corruption_info = pd.read_csv('../input/corruption-index/index.csv')\ncorruption_info.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged1 = healht_merged.merge(corruption_info[['Country Code', 'Corruption Perceptions Index (CPI)']], on='Country Code', how='left')\n#merged1.info()\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n    'The Bahamas': 'Bahamas',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"Côte d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'Réunion' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n'China, Taiwan Province of China' : \"Taiwan*\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas\": \"The Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States\" : \"US\",\n\"Venezuela, RB\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\",\n'Egypt, Arab Rep.':'Egypt',\n'Czech Republic': 'Czechia',\n'Macedonia, FYR':'North Macedonia',\n'Gambia, The':'Gambia',\n'Iran, Islamic Rep.':'Iran',\n'Slovak Republic':'Slovakia',\n'Korea, Dem. People’s Rep.':'Korea, South',\n'Kyrgyz Republic':'Kyrgyzstan',\n    'Syrian Arab Republic':'Syria'}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nmerged1['Country Name'] = merged1['Country Name'].apply(lambda x : rename_countries(x, country_mapper))\n\n\nlist(set(countries) - set(merged1.loc[:,'Country Name'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(merged1, left_on=\"Country_Region\",right_on=\"Country Name\", how='left')\ndf.drop(columns=['Country Code', 'Country Name'], axis=1, inplace=True)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Concatenate Country and Region Province"},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_country_province(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        return country+\"_\"+province\n\n# Concatenate region and province for training\ndf[\"Country_Region\"] = df[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info = pd.read_csv('/kaggle/input/countryinfo/covid19countryinfo.csv')\ncountry_info = country_info[~country_info.country.isnull()].reset_index(drop=True)\ncountry_info.drop([ c for c in country_info.columns if c.startswith(\"Unnamed\")], axis=1, inplace=True)\ncountry_info.drop(columns=['pop', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'medianage', \"smokers\", \"sexratio\"],\n                  axis=1,\n                  inplace=True)\n##\ncountry_info = country_info.drop(country_info[country_info.country=='Mali'].index)\n#country_info.loc[country_info.country=='Mali','nonessential':] = pd.to_datetime('2020-03-17')\n#country_info.loc[country_info.country=='Mali','gathering':] = pd.to_datetime('2020-03-17')\n#country_info.loc[country_info.country=='Mali','gatheringlimit':] = 50\n####\n# Columns with dates\ncountry_info[\"quarantine\"] = pd.to_datetime(country_info[\"quarantine\"])\ncountry_info[\"publicplace\"] = pd.to_datetime(country_info[\"publicplace\"])\ncountry_info[\"gathering\"] = pd.to_datetime(country_info[\"gathering\"])\ncountry_info[\"nonessential\"] = pd.to_datetime(country_info[\"nonessential\"])\ncountry_info[\"schools\"] = pd.to_datetime(country_info[\"schools\"])\ncountry_info[\"firstcase\"] = pd.to_datetime(country_info[\"firstcase\"])\n##\ncountry_info['gdp2019'] = country_info['gdp2019'].str.replace(',', '')\ncountry_info['healthexp'] = country_info['healthexp'].str.replace(',', '')\n\n\n\n\nsame_state = []\nfor country in df[\"Province_State\"].unique():\n    if country in country_info.country.unique():\n        same_state.append(country)\n    else:\n        pass\n        # This part can help matching different external dataset and find corresponding countries\n        #print(country)\n        #matches = []\n        #scores = []\n        #if str(country)==\"nan\":\n        #    continue\n        #for possible_match in country_info.country.unique():\n        #    matches.append(possible_match)\n        #    scores.append(fuzz.partial_ratio(country, possible_match))\n            \n        #top_5_index = np.argsort(scores)[::-1][:5]\n        #print(np.array(matches)[top_5_index])\n        #print(np.array(scores)[top_5_index])\n        #print(\"-------------------\")\n        \ncountry_to_state_country = {}\nfor state in same_state:\n    #print(state)\n    #print(df[df[\"Province/State\"]==state][\"Country/Region\"].unique())\n    #print(\"----\")\n    country_to_state_country[state] = df[df[\"Province_State\"]==state][\"Country_Region\"].unique()[0]+\"_\"+state\n\ncountry_info['country'] =country_info[[\"country\", \"region\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)                                                                      \n\n\ndates_info = [\"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]\ncoutry_merge_info = country_info[[\"country\", \"density\", \"urbanpop\", \"hospibed\", \"lung\",\n                                  \"femalelung\", \"malelung\",'gdp2019', 'healthexp', 'healthperpop', 'fertility'] + dates_info]\n\ncols_median = [\"density\", \"urbanpop\", \"hospibed\", \"lung\", \"femalelung\", \"malelung\",'gdp2019', 'healthexp', 'healthperpop', 'fertility']\ncoutry_merge_info.loc[:, cols_median] = coutry_merge_info.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\n\nmerged = df.merge(coutry_merge_info, left_on=\"Country_Region\", right_on=\"country\", how=\"left\")\nmerged.loc[:, cols_median] = merged.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\ncountry_dates_info = country_info[[\"country\", \"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]]\n\n\n\ndef dates_diff_days(date_curr, date_):\n    if date_curr>date_:\n        return (date_curr - date_).days\n    else :\n        return 0\n\n\nfor col in dates_info:\n    #print(merged.shape)\n    merged[col+'_days'] =merged[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)                                                                      \n\nprint(merged.shape)\n#drop_country_cols = [x for x in merged.columns if x.startswith(\"country\")] + dates_info\ndrop_country_cols = [x for x in merged.columns if x.startswith(\"country\")]\nmerged.drop(columns=drop_country_cols, axis=1, inplace=True)\nprint(merged.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.Country_Region.value_counts().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weather"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_info = pd.read_csv('../input/weather-info/training_data_with_weather_info_week_2.csv')\nweather_info.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_info.Date.min(), weather_info.Date.max() , weather_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.Date.min(), merged.Date.max(), merged.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_info[\"Country_Region\"] = weather_info[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\nweather_info[\"Date\"] = pd.to_datetime(weather_info[\"Date\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_ = merged.merge(weather_info[['temp','min','max','stp','wdsp','prcp','fog','Country_Region', 'Date']], on=[\"Country_Region\", 'Date'])\nmerged_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_.Country_Region.value_counts().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## HH"},{"metadata":{"trusted":true},"cell_type":"code","source":"hh_info = pd.read_csv('../input/covid19aug/augmented/train_aug.csv')\nhh_cols = ['hh%1',\n'hh%2-3',\n'hh%4-5',\n'hh%6+',\n'hh65+']\nhh_info.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_country_province_(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        if country==province:\n            return country\n        else:\n            return country+\"_\"+province\n\n# Concatenate region and province for training\nhh_info[\"Country_Region\"] = hh_info[[\"Province/State\", \"Country/Region\"]].apply(lambda x : concat_country_province_(x[0], x[1]), axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hh_info.loc[hh_info[\"Country/Region\"]=='US', 'hh%1'] = 28\nhh_info.loc[hh_info[\"Country/Region\"]=='US', 'hh%2-3'] = 49\nhh_info.loc[hh_info[\"Country/Region\"]=='US', 'hh%4-5'] = 19\nhh_info.loc[hh_info[\"Country/Region\"]=='US', 'hh%6+'] = 4\nhh_info.loc[hh_info[\"Country/Region\"]=='US', 'hh65+'] = 28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hh_info_ = hh_info[['Country_Region']+hh_cols].drop_duplicates(subset=['Country_Region'], keep=\"first\", inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hh_info_.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merged_ = merged_.merge(hh_info_, on=[\"Country_Region\"], how='left')\n#merged_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_.to_csv('enriched_covid_19_week_2_2.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}