{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import csv\nimport os\nimport xgboost\n\nimport re\nimport string\nfrom sklearn import ensemble\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.offline as pyo\npyo.init_notebook_mode()\n\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ndf_1 = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Date'].min())\nprint(train['Date'].max())\n\nprint(test['Date'].min())\nprint(test['Date'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Added new features in train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'] = pd.to_datetime(train['Date'])\ntest['Date'] = pd.to_datetime(test['Date'])\n\ntrain['dayofmonth'] = train['Date'].dt.day\ntrain['dayofweek'] = train['Date'].dt.dayofweek\ntrain['month'] = train['Date'].dt.month\ntrain['weekNumber'] = train['Date'].dt.week\ntrain['dayofyear'] = train['Date'].dt.dayofyear\n## added in training set\ntrain['Fatalities_ratio'] = train['Fatalities'] / train['ConfirmedCases']\n\n#train['Change_ConfirmedCases'] = train.groupby('Country_Region').ConfirmedCases.pct_change()\n#train['Change_Fatalities'] = train.groupby('Country_Region').Fatalities.pct_change()\n\n## to deal with data wih Province State\ntrain['Change_ConfirmedCases'] = train.groupby(np.where(train['Province_State'].isnull(), train['Country_Region'], train['Province_State'])).ConfirmedCases.pct_change()\ntrain['Change_Fatalities'] = train.groupby(np.where(train['Province_State'].isnull(), train['Country_Region'], train['Province_State'])).Fatalities.pct_change()\n\n## added in Test set\ntest['dayofmonth'] = test['Date'].dt.day\ntest['dayofweek'] = test['Date'].dt.dayofweek\ntest['month'] = test['Date'].dt.month\ntest['weekNumber'] = test['Date'].dt.week\ntest['dayofyear'] = test['Date'].dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total Confirmed Cases and Fatalities By Countries On World Map"},{"metadata":{},"cell_type":"markdown","source":"### Grouped by Date and added ratio by running total for visualizations "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exponential Moving Average with 7 days and 14 days average"},{"metadata":{},"cell_type":"markdown","source":"## Training and Fitting the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"enriched = pd.read_csv(\"/kaggle/input/data-prep/enriched_covid_19_week_2_2.csv\")\nenriched['Date'] = pd.to_datetime(train['Date'])\nenriched['Date'] = pd.to_datetime(test['Date'])\nenriched[\"quarantine\"] = pd.to_datetime(enriched[\"quarantine\"])\nenriched[\"publicplace\"] = pd.to_datetime(enriched[\"publicplace\"])\nenriched[\"gathering\"] = pd.to_datetime(enriched[\"gathering\"])\nenriched[\"nonessential\"] = pd.to_datetime(enriched[\"nonessential\"])\nenriched[\"schools\"] = pd.to_datetime(enriched[\"schools\"])\nenriched[\"firstcase\"] = pd.to_datetime(enriched[\"firstcase\"])\n\ndates_info = [\"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]\n\nenriched = enriched.iloc[:,:-13]\nenriched.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enriched.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_country_province(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        return country+\"_\"+province\n\n# Concatenate region and province for training\ntrain[\"Country_Region_\"] = train[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\ntest[\"Country_Region_\"] = test[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n\nenriched[\"Country_Region_\"] = enriched[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\nenriched = enriched.drop_duplicates(subset=['Country_Region_'], keep=\"first\", inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(enriched.iloc[:, 6:], on ='Country_Region_', how='left')\ntest = test.merge(enriched.iloc[:, 6:], on ='Country_Region_', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dates_diff_days(date_curr, date_):\n    if date_curr>date_:\n        return (date_curr - date_).days\n    else :\n        return 0\n\n\nfor col in dates_info:\n    #print(merged.shape)\n    train[col] =train[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)  \n    test[col] =test[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1) \n\nprint(test.shape)\n\n#drop_country_cols = [x for x in merged.columns if x.startswith(\"country\")] + dates_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nfrom xgboost import XGBRegressor\n\n\ntrain['ConfirmedCases_diff'] = train.loc[:, ['ConfirmedCases', 'Country_Region_']].groupby('Country_Region_').diff().fillna('0')\ntrain['Fatalities_diff'] = train.loc[:, ['Fatalities', 'Country_Region_']].groupby('Country_Region_').diff().fillna('0')\n\ntrain = train.astype({'ConfirmedCases_diff': 'int64','Fatalities_diff': 'int64' })\n\ntrain['Country_Region'] = le.fit_transform(train['Country_Region'])\ntrain['Province_State'] = le.fit_transform(train['Province_State'].fillna('0'))\n\ntest['Country_Region'] = le.fit_transform(test['Country_Region'])\ntest['Province_State'] = le.fit_transform(test['Province_State'].fillna('0'))\n\ny1_train = train['ConfirmedCases_diff']\ny2_train = train['Fatalities_diff']\nX_Id = train['Id']\n\n# X_train = train.drop(columns=['Id', 'Date','ConfirmedCases', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId', 'Date'])\n\nX_train = train.drop(columns=['Id', 'Fatalities', 'Date',\n                              'Fatalities_ratio','Change_ConfirmedCases'\n                              ,'Change_Fatalities','Country_Region_','ConfirmedCases','Fatalities_diff','ConfirmedCases_diff'])\nX_test  = test.drop(columns=['ForecastId','Country_Region_', 'Date'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = train.drop(columns=['Id', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId'])\n\n# model=Prophet()\n# model.fit(X_train \\\n#               .rename(columns={'Date':'ds',\n#                                'ConfirmedCases':'y'}))\n# forecast_conf=model.predict(df=X_test \\\n#                                    .rename(columns={'Date':'ds'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = train.drop(columns=['Id', 'ConfirmedCases', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId'])\n\n# model_1=Prophet()\n# model_1.fit(X_train \\\n#               .rename(columns={'Date':'ds',\n#                                'Fatalities':'y'}))\n# forecast_Fatilities=model.predict(df=X_test \\\n#                                    .rename(columns={'Date':'ds'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_xgb_d = pd.DataFrame({'ForecastId': test.ForecastId, 'ConfirmedCases': forecast_conf.yhat, 'Fatalities': forecast_Fatilities.yhat })\n# df_xgb_d.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = train.drop(columns=['Id', 'Date','ConfirmedCases', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId', 'Date'])\n\nmodel = xgboost.XGBRegressor(colsample_bytree=0.7,\n                 gamma=0,                 \n                 learning_rate=0.1,\n                 max_depth=6,\n                 min_child_weight=1.5,\n                 n_estimators=3000,                                                                    \n                 reg_alpha=0.75,\n                 reg_lambda=0.45,\n                 subsample=0.5,\n                 seed=42) \n\n\nmodel.fit(X_train, y1_train)\ny1_pred = model.predict(X_test)\n\n\nmodel.fit(X_train, y2_train)\ny2_pred = model.predict(X_test)\n\n\ndf = pd.DataFrame({'ForecastId': test.ForecastId, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = test.copy()\ntest1['ConfirmedCases'] = y1_pred\ntest1['Fatalities']=y2_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_max = train[['Country_Region_', 'ConfirmedCases','Fatalities']].groupby('Country_Region_').max().add_prefix('max_').reset_index()\ntrain_max.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = test1.merge(train_max, on='Country_Region_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1.loc[test1.ConfirmedCases<0, 'ConfirmedCases']=0\ntest1.loc[test1.Fatalities<0, 'Fatalities']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['ConfirmedCases'] = test1.groupby('Country_Region_')['ConfirmedCases'].cumsum()\ntest1['Fatalities'] = test1.groupby('Country_Region_')['Fatalities'].cumsum()\ntest1['ConfirmedCases'] = test1['ConfirmedCases'] + test1['max_ConfirmedCases']\ntest1['Fatalities'] = test1['Fatalities'] + test1['max_Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df =test1[['ForecastId','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df =test1[['ForecastId','ConfirmedCases','Fatalities']]\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_xgb_default = XGBRegressor(n_estimators=1000)\n# model_xgb_default.fit(X_train, y1_train)\n# y1_pred_xgb_d = model_xgb_default.predict(X_test)\n# model_xgb_default.fit(X_train, y2_train)\n# y2_pred_xgb_d = model_xgb_default.predict(X_test)\n# df_xgb_d = pd.DataFrame({'ForecastId': test.ForecastId, 'ConfirmedCases': y1_pred_xgb_d, 'Fatalities': y2_pred_xgb_d})\n# #df_xgb_d.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}