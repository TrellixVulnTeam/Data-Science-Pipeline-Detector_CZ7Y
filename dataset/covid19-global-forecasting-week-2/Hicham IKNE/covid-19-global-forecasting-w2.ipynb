{"cells":[{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"color:black;font-size:4em\"><center >Covid-19 forecasting </center></h1>\n\n---\nCreated on Mon Mar 30 12:34:52 2020\n\n@author: IKNE Hicham\n---"},{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 1- Libraries</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('default')\nimport numpy as np\nfrom numpy import random\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import metrics\n## \nimport sys\n\n\nfrom IPython.display import display\nfrom scipy.stats import skew\nimport lightgbm as lgb\nimport os\nfrom xgboost import XGBRegressor\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 2- Data exploration</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')\ntest=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 2.1-  Clean & prepare features</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"catcols=train.select_dtypes(include='object').columns.values.tolist()\ncatcols.remove('Date')\nnumcols=train.select_dtypes(include='number').columns.values[1:-1].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[catcols].describe().merge(test[catcols].describe(),left_index=True,right_index=True,suffixes=('_train','_test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\npd.concat([round(100*train[catcols].isnull().sum()/train.shape[0],2).to_frame('train'),\n           round(100*test[catcols].isnull().sum()/test.shape[0],2).to_frame('test')],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'TRAIN -> date_min= {train[\"Date\"].min()} ; date_max= {train[\"Date\"].max()}')\nprint(f'TEST -> date_min= {test[\"Date\"].min()} ; date_max= {test[\"Date\"].max()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_features(data):\n    # lower Province_State & Country_Region in order to use them to add more information\n    data['Province_State']=data['Province_State'].str.lower()\n    data['Country_Region']=data['Country_Region'].str.lower()\n    \n    # Create a new feature = weither the Province_State is known or not\n    data['UnkownProvince_State']=data['Province_State'].isnull().astype(int)\n    \n    # Fill missing Province_State & Country_Region missing values \n    data.fillna({'Province_State':'unknown'},inplace=True)\n    data.fillna({'Country_Region':'unknown'},inplace=True)\n    \n    # Remove non-alpha charachters \n    data['Province_State']=data['Province_State'].apply(lambda x: ''.join([ch for ch in x if ch.isalpha()]))\n    data['Country_Region']=data['Country_Region'].apply(lambda x: ''.join([ch for ch in x if ch.isalpha()]))\n    \n    # Create a new feature = Country_Region frequency\n    data['Country_RegionFreq']=data['Country_Region'].map(data['Country_Region'].value_counts(1).to_dict())\n    \n    return data\n\ncatcols.append('UnkownProvince_State')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean & transform features\ntrain=prepare_features(train)\ntest=prepare_features(test)\n#\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 2.2- Additional information</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"add_inf=pd.read_csv('/kaggle/input/world-population-and-development-indicators/data.csv')\nadd_inf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add world population & developement indicators \ntrain=train.merge(add_inf,left_on='Country_Region',right_on='Country Name',how='left')\ntest=test.merge(add_inf,left_on='Country_Region',right_on='Country Name',how='left')\n# concatenate Province_State & Country_Region as \"Province_State\" ID\ntrain['Province_State']=train['Country_Region']+'-'+train['Province_State']\ntest['Province_State']=test['Country_Region']+'-'+test['Province_State']\n\n# reset index with Date\ntrain.index=train['Date']\ntest.index=test['Date']\n\n# Drop useless columns\ntrain.drop(columns=['Date','Country Name','Country_Region'],inplace=True)\ntest.drop(columns=['Date','Country Name','Country_Region'],inplace=True)\n#\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display ConfirmedCases & Fatatilities charts for a random Province state\n\n# Pick one random Province_State\nprovince=np.random.choice(train['Province_State'].unique())\ns=train.loc[train['Province_State']==province,['ConfirmedCases','Fatalities']]\n\nplt.style.use('default')\nplt.figure(figsize=(8,3))\nplt.subplot(121)\ns['ConfirmedCases'].plot(kind='area',color='blue',alpha=.4)\nplt.xticks(rotation=80)\nplt.title('ConfirmedCases',fontsize=10)\n#\nplt.subplot(122)\ns['Fatalities'].plot('area',color='orange',alpha=.4)\nplt.xticks(rotation=80)\nplt.title('Fatalities',fontsize=10)\n\nplt.suptitle(province.upper(),fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log-transform target\ntrain['ConfirmedCases']=np.log(train['ConfirmedCases']+1)\ntrain['Fatalities']=np.log(train['Fatalities']+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show target (ConfirmedCases, Fatalities)\nplt.figure(figsize=(10,3))\nplt.subplot(121)\nsns.distplot(train['ConfirmedCases'])\nplt.title('ConfirmedCases')\n#\nplt.subplot(122)\ntrain['Fatalities'].plot.hist(bins=100,density=True)\nplt.title('Fatalities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\nround(100*(train.isnull().sum()/train.shape[0]).to_frame('Nan (%)'),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill missing values with mean-value\ntrain.fillna(train.mean().to_dict(),inplace=True)\ntest.fillna(train.mean().to_dict(),inplace=True)\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross-correlation between \"Added informtaion\" and target\ncorr={'ConfirmedCases':[],'Fatalities':[]}\nfor col in train.select_dtypes(include='number').columns.values[3:]:\n    corr['ConfirmedCases'].append(train[[col,'ConfirmedCases']].corr().values[0,1])\n    corr['Fatalities'].append(train[[col,'Fatalities']].corr().values[0,1]) \ncorr=pd.DataFrame(corr,index=train.select_dtypes(include='number').columns.values[3:])\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display added feature distributions\nplt.figure(figsize=(18,22))\nfor i,col in enumerate(train.select_dtypes(include='number').columns.values[4:],start=1):\n    plt.subplot(9,3,i)\n    sns.distplot(train[col],label='train',color='blue')\n    sns.distplot(test[col],label='test',color='red') \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n<h1 style=\"font-size:3em; color:#01018a\"> 3- Model</h1>\n\n---"},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 3.1- More features</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_before=test.select_dtypes(include='number').columns.values[1:]\nprint(cols_before.shape)\ncols_before","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shifting_features(df):\n    data=df.copy()\n    for step in [1,2,3,5,12]:\n        # shiffting columns\n        dfu=data.groupby(['Province_State'],as_index=True)['ConfirmedCases','Fatalities'].shift(step)\n        dfu.rename(columns={'ConfirmedCases':f'ConfirmedCases_D-{step}','Fatalities':f'Fatalities_D-{step}'},inplace=True)\n        data=pd.concat((data,dfu),axis=1)\n        # Rolling columns\n        #-----# mean columns\n        dfu=data.groupby(['Province_State'],as_index=True).rolling(window=step)['ConfirmedCases','Fatalities'].mean()\n        dfu.rename(columns={'ConfirmedCases':f'ConfirmedCases_Mean-{step}','Fatalities':f'Fatalities_Mean-{step}'},inplace=True)\n        dfu.index=data.index.copy()\n        data=pd.concat((data,dfu),axis=1)\n    \n        #-----# quantile columns\n        dfu=data.groupby(['Province_State'],as_index=True).rolling(window=step)['ConfirmedCases','Fatalities'].quantile(.05)\n        dfu.rename(columns={'ConfirmedCases':f'ConfirmedCases_Q05-{step}','Fatalities':f'Fatalities_Q05-{step}'},inplace=True)\n        dfu.index=data.index.copy()\n        data=pd.concat((data,dfu),axis=1)\n        \n        dfu=data.groupby(['Province_State'],as_index=True).rolling(window=step)['ConfirmedCases','Fatalities'].quantile(.25)\n        dfu.rename(columns={'ConfirmedCases':f'ConfirmedCases_Q25-{step}','Fatalities':f'Fatalities_Q25-{step}'},inplace=True)\n        dfu.index=data.index.copy()\n        data=pd.concat((data,dfu),axis=1)\n        \n        dfu=data.groupby(['Province_State'],as_index=True).rolling(window=step)['ConfirmedCases','Fatalities'].quantile(.75)\n        dfu.rename(columns={'ConfirmedCases':f'ConfirmedCases_Q75-{step}','Fatalities':f'Fatalities_Q75-{step}'},inplace=True)\n        dfu.index=data.index.copy()\n        data=pd.concat((data,dfu),axis=1)\n        \n        dfu=data.groupby(['Province_State'],as_index=True).rolling(window=step)['ConfirmedCases','Fatalities'].quantile(.95)\n        dfu.rename(columns={'ConfirmedCases':f'ConfirmedCases_Q95-{step}','Fatalities':f'Fatalities_Q95-{step}'},inplace=True)\n        dfu.index=data.index.copy()\n        data=pd.concat((data,dfu),axis=1)\n        \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=shifting_features(train)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(axis=0,inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 3.2- Split dataset</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.index.unique())\ndata.index.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sort(data.index.unique())[-11])\n\ndata['TRAIN_SAMPLE']=(data.index<=np.sort(data.index.unique())[-11])\ndata['TRAIN_SAMPLE'].value_counts(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=data.select_dtypes(include='number').columns.values[3:]\nprint(features.shape)\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\nX_train,X_test=data.loc[data['TRAIN_SAMPLE'],features],data.loc[~data['TRAIN_SAMPLE'],features]\n\n# ConfirmedCases outputs\ny_train_Conf,y_test_Conf=data.loc[data['TRAIN_SAMPLE'],'ConfirmedCases'],data.loc[~data['TRAIN_SAMPLE'],'ConfirmedCases']\n\n# Fatalities outputs\ny_train_Fat,y_test_Fat=data.loc[data['TRAIN_SAMPLE'],'Fatalities'],data.loc[~data['TRAIN_SAMPLE'],'Fatalities']\n\nprint('X_train.shape: ',X_train.shape)\nprint('X_test.shape: ',X_test.shape)\nprint('y_train_Conf.shape: ',y_train_Conf.shape)\nprint('y_test_Conf.shape: ',y_test_Conf.shape)\nprint('y_train_Fat.shape: ',y_train_Fat.shape)\nprint('y_test_Fat.shape: ',y_test_Fat.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_Conf=XGBRegressor(**{'learning_rate': 0.2, 'max_depth': 5,'n_estimators': 120, 'objective': 'reg:squarederror'})\n%time clf_Conf.fit(X_train,y_train_Conf)\nprint('train score: {}'.format(np.sqrt(metrics.mean_squared_error(y_train_Conf,clf_Conf.predict(X_train)))))\nprint('test score: {}'.format(np.sqrt(metrics.mean_squared_error(y_test_Conf,clf_Conf.predict(X_test)))))\n##\n\nprint('train score: {}'.format(metrics.r2_score(y_train_Conf,clf_Conf.predict(X_train))))\nprint('test score: {}'.format(metrics.r2_score(y_test_Conf,clf_Conf.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_Fat=XGBRegressor(**{'learning_rate': 0.07, 'max_depth': 5,'n_estimators': 120, 'objective': 'reg:squarederror'})\n%time clf_Fat.fit(X_train,y_train_Fat)\nprint('train score: {}'.format(np.sqrt(metrics.mean_squared_error(y_train_Fat,clf_Fat.predict(X_train)))))\nprint('test score: {}'.format(np.sqrt(metrics.mean_squared_error(y_test_Fat,clf_Fat.predict(X_test)))))\n##\n\nprint('train score: {}'.format(metrics.r2_score(y_train_Fat,clf_Fat.predict(X_train))))\nprint('test score: {}'.format(metrics.r2_score(y_test_Fat,clf_Fat.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"font-size:2em; color:#880303\"> 3.3- Prepare test set & make predictions</h1>\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(list(set(test.index) & set(train.index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.reset_index(inplace=True)\ntest.reset_index(inplace=True)\n#\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\ntest=test.merge(train[['Date','Province_State','ConfirmedCases','Fatalities']],on=['Date','Province_State'],how='left')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test.shape[0]-test[['ConfirmedCases','Fatalities']].isnull().sum())/test.Province_State.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions(test):\n    for i in range(test.Date.nunique()-13):\n        day_list=np.sort(test.Date.unique())[i:i+14]\n        print(len(day_list),day_list)\n        test_data=shifting_features(test[np.isin(test['Date'],day_list)])\n        test_data=test_data[test_data['Date']==day_list[-2]]\n        print(test_data[test_data[features].isnull().sum(axis=1)==0].shape)\n\n        # make predictions\n        print(test[['ConfirmedCases','Fatalities']].isnull().sum())\n        test.loc[test['Date']==day_list[-1],'ConfirmedCases']=clf_Conf.predict(test_data[features])\n        test.loc[test['Date']==day_list[-1],'Fatalities']=clf_Fat.predict(test_data[features])\n        print(test[['ConfirmedCases','Fatalities']].isnull().sum())\n    return test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=make_predictions(test)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['ForecastId','ConfirmedCases','Fatalities']].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply exp to target (reverse transformation)\ntest['ConfirmedCases']=np.exp(test['ConfirmedCases'])-1\ntest['Fatalities']=np.exp(test['Fatalities'])-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sumbit predictions\ntest[['ForecastId','ConfirmedCases','Fatalities']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['ForecastId','ConfirmedCases','Fatalities']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}