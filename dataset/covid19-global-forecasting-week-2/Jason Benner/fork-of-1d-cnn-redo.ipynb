{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom numpy import split\nfrom numpy import array\nfrom pandas import read_csv\nfrom sklearn.metrics import mean_squared_error\nfrom matplotlib import pyplot\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = read_csv('../input/covid19-global-forecasting-week-2/train.csv', header=0, infer_datetime_format=True, parse_dates=['Date'], index_col=['Date'])\ntest = read_csv('../input/covid19-global-forecasting-week-2/test.csv', header=0, infer_datetime_format=True, parse_dates=['Date'], index_col=['Date'])\nsubmission = read_csv('../input/covid19-global-forecasting-week-2/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"Id\", \"Province_State\", \"Fatalities\"], axis=1, inplace=True)\ntest.drop([\"ForecastId\", \"Province_State\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"date\"] = train.index\ntest[\"date\"] = test.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add in more data"},{"metadata":{"trusted":true},"cell_type":"code","source":"hdi = pd.read_csv(\"../input/world-bank-datasets/Human_Development_Index.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(left=train, right=hdi, how='left', left_on='Country_Region', right_on='Country')\ntest = pd.merge(left=test, right=hdi, how='left', left_on='Country_Region', right_on='Country')\ntrain.drop(['Country', 'Gross national income (GNI) per capita 2018'],axis=1, inplace=True)\ntest.drop(['Country', 'Gross national income (GNI) per capita 2018'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = pd.concat([train,pd.get_dummies(train['Country_Region'], prefix='cr')],axis=1)\n#train.drop(['Country_Region'],axis=1, inplace=True)\n#test = pd.concat([test,pd.get_dummies(test['Country_Region'], prefix='cr')],axis=1)\n#test.drop(['Country_Region'],axis=1, inplace=True)\n#le = preprocessing.LabelEncoder()\n#le.fit(train['Country_Region'])\n#train['Country_Region'] = le.transform(train['Country_Region']) \n#test['Country_Region'] = le.transform(test['Country_Region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(0, inplace=True)\ntest.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Country_Region'],axis=1, inplace=True)\ntest.drop(['Country_Region'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['ConfirmedCases'] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = test.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ntest = test[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basedate = pd.Timestamp('2020-01-01')\ntrain['time since'] = train.apply(lambda x: (x.date - basedate).days, axis=1)\ntest['time since'] = test.apply(lambda x: (x.date - basedate).days, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(\"date\", axis=1, inplace=True)\ntest.drop(\"date\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_dataset(data):\n    train, test = data[:-328], data[-328:]\n    train = array(split(train, len(train)))\n    test = array(split(test, len(test)))\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_forecasts(actual, predicted):\n    scores = list()\n    for i in range(actual.shape[1]):\n        mse = mean_squared_error(actual[:,i], predicted[:,i])\n        rmse = sqrt(mse)\n        scores.append(rmse)\n    s = 0\n    for row in range(actual.shape[0]):\n        for col in range(actual.shape[1]):\n            s += (actual[row,col] - predicted[row,col])**2\n    score = sqrt(s/(actual.shape[0]*actual.shape[1]))\n    return score, scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarize_scores(name, score, scores):\n    s_scores = \", \".join([\"%.1f\" % s for s in scores])\n    print(\"%s: [%.3f] %s\" %(name, score, s_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_supervised(train, n_input, n_out=1):\n    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n    X, y = list(), list()\n    in_start = 0\n    for _ in range(len(data)):\n        in_end = in_start + n_input\n        out_end = in_end + n_out\n        if out_end <= len(data):\n            X.append(data[in_start:in_end, :])\n            y.append(data[in_end:out_end, 0])\n        in_start += 1\n    return array(X), array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(train, n_input):\n    train_x, train_y = to_supervised(train, n_input)\n    verbose, epochs, batch_size = 0, 140, 16\n    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n    model = Sequential()\n    model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_timesteps, n_features)))\n    model.add(MaxPooling1D(pool_size=1))\n    model.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\n    model.add(MaxPooling1D(pool_size=1))\n    model.add(Conv1D(filters=8, kernel_size=2, activation='relu'))\n    model.add(Flatten())\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(n_outputs))\n    model.compile(loss='mse', optimizer='adam')\n    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forecast(model, history, n_input):\n    data = array(history)\n    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n    input_x = data[-n_input:,:]\n    input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n    yhat = model.predict(input_x, verbose=0)\n    yhat = yhat[0]\n    if yhat < 0.0:\n        yhat = array(0.0)\n    print(yhat)\n    return yhat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(train, test, n_input):\n    model = build_model(train, n_input)\n    history = [x for x in train]\n    predictions = list()\n    for i in range(len(test)):\n        yhat_sequence = forecast(model, history, n_input)\n        predictions.append(yhat_sequence)\n        history.append(test[i,:])\n    predictions = array(predictions)\n    #score, scores = evaluate_forecasts(test[:,:,0], predictions)\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_input = 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_v = train.values\ntest_v = test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_v","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_v = array(split(train_v, len(train)))\ntest_v = array(split(test_v, len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_v","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictionsConfirmedCases = evaluate_model(train_v, test_v, n_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[\"ConfirmedCases\"] = predictionsConfirmedCases.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = read_csv('../input/covid19-global-forecasting-week-2/train.csv', header=0, infer_datetime_format=True, parse_dates=['Date'], index_col=['Date'])\ntest = read_csv('../input/covid19-global-forecasting-week-2/test.csv', header=0, infer_datetime_format=True, parse_dates=['Date'], index_col=['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"Id\", \"Province_State\", \"ConfirmedCases\"], axis=1, inplace=True)\ntest.drop([\"ForecastId\", \"Province_State\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(left=train, right=hdi, how='left', left_on='Country_Region', right_on='Country')\ntest = pd.merge(left=test, right=hdi, how='left', left_on='Country_Region', right_on='Country')\ntrain.drop(['Country', 'Gross national income (GNI) per capita 2018'],axis=1, inplace=True)\ntest.drop(['Country', 'Gross national income (GNI) per capita 2018'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = pd.concat([train,pd.get_dummies(train['Country_Region'], prefix='cr')],axis=1)\ntrain.drop(['Country_Region'],axis=1, inplace=True)\n#test = pd.concat([test,pd.get_dummies(test['Country_Region'], prefix='cr')],axis=1)\ntest.drop(['Country_Region'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(0, inplace=True)\ntest.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Fatalities'] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = test.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ntest = test[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basedate = pd.Timestamp('2020-01-01')\ntrain['time since'] = train.apply(lambda x: (x.date - basedate).days, axis=1)\ntest['time since'] = test.apply(lambda x: (x.date - basedate).days, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(\"date\", axis=1, inplace=True)\ntest.drop(\"date\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_v = train.values\ntest_v = test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_v = array(split(train_v, len(train)))\ntest_v = array(split(test_v, len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictionsFatalities = evaluate_model(train_v, test_v, n_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[\"Fatalities\"] = predictionsFatalities.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}