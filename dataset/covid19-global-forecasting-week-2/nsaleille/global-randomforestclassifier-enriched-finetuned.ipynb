{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\n\ndef preprocess(total, country_info = None, longlat = None, lags = True, dummies = False):\n\n    df = total.copy()\n\n    df['Province_State'].fillna('-', inplace = True)\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Weekday'] = df['Date'].apply(lambda x: x.weekday())\n    df['t'] = (df['Date'] - df['Date'].min()) / pd.to_timedelta(1, unit='D')\n\n    if country_info is not None:\n        country_info.drop(country_info.loc[country_info['region'].notnull()].index, inplace = True)\n        add_variables = [\"country\", \"medianage\", \"density\", 'hospibed', 'sexratio']\n        df = df.merge(country_info[add_variables], how = 'left', left_on = 'Country_Region', right_on = 'country')\n        for var in add_variables:\n            df[var] = df[var].fillna(0)\n\n    groups = df.groupby(['Country_Region', 'Province_State'])\n\n    # Dernier nombre de cas connu\n    c_last = [group.loc[group['Date'] == '2020-03-18']['ConfirmedCases'].to_numpy()[0] for (name, group) in groups]\n    c_last = pd.Series(c_last, name = 'ConfirmedCases_Last', index = groups.groups.keys())\n    c_last = c_last.reset_index()\n    df = df.merge(c_last, how = 'right', left_on = ['Country_Region', 'Province_State'], right_on = ['level_0', 'level_1'])\n\n    # Dernier nombre de morts connu\n    f_last = [group.loc[group['Date'] == '2020-03-18']['Fatalities'].to_numpy()[0] for (name, group) in groups]\n    f_last = pd.Series(f_last, name = 'Fatalities_Last', index = groups.groups.keys())\n    f_last = f_last.reset_index()\n    df = df.merge(f_last, how = 'right', left_on = ['Country_Region', 'Province_State'], right_on = ['level_0', 'level_1'])\n\n    #df.drop(['level_0_x', 'level_1_x', 'level_0_y', 'level_1_y'], inplace = True)\n\n    if longlat is not None:\n        longlat['Province/State'].fillna('-', inplace = True)\n        longlat = longlat.groupby(['Province/State', 'Country/Region']).first()[['Lat', 'Long']]\n        longlat = longlat.reset_index()\n        df = df.merge(longlat, how = 'left', left_on = ['Province_State', 'Country_Region'], right_on = ['Province/State', 'Country/Region'])\n\n    # COMPUTE TIME TO FIRST CASE\n    ttf_vec = []\n    for name,group in groups:\n\n        first_case_index = group['ConfirmedCases'].loc[group['ConfirmedCases'] > 0].first_valid_index()\n        if first_case_index is not None:\n            first_case_date = group.loc[first_case_index]['Date']\n            ttf = (group['Date'] - first_case_date) / pd.to_timedelta(1, unit='D')\n            ttf.loc[ttf<0] = 0\n        else:\n            ttf = pd.Series([0]*len(group))\n        ttf.index = group.index\n        ttf_vec.append(ttf)\n\n    df['TTF'] = pd.concat(ttf_vec)\n\n    # Add DailyCases\n    df['DailyCases'] = pd.concat([group['ConfirmedCases'].diff(1).copy() for (name, group) in groups], axis = 0)\n\n    # Add lag variables\n    if lags is True:\n        df['DailyCases_L1'] = pd.concat([group['DailyCases'].shift(1).copy() for (name, group) in groups], axis = 0)\n        df['ConfirmedCases_L1'] = pd.concat([group['ConfirmedCases'].shift(1).copy() for (name, group) in groups], axis = 0)\n        df['Fatalities_L1'] = pd.concat([group['Fatalities'].shift(1).copy() for (name, group) in groups], axis = 0)\n\n    if dummies:\n        dummies = pd.get_dummies(df['Country_Region'])\n        df = df.join(dummies)\n\n    return df\n\ndef train_test_split(total, daily_cases = False, lags = False):\n\n    #date_train_last = '2020-03-19'\n    #date_test_first = '2020-03-20'\n\n    total_copy = total.copy()\n    train = total_copy.loc[total_copy['ForecastId'].isnull()]\n\n    # remove unknown variables from test\n    test = total.loc[total['ForecastId'].notnull()].copy()\n    if not daily_cases:\n        test['DailyCases'] = np.nan\n    if lags:\n        test['ConfirmedCases_L1'] = np.nan\n        test['DailyCases_L1'] = np.nan\n        test['Fatalities_L1'] = np.nan\n\n    print('Train timeframe : {} - {}'.format(train['Date'].min(), train['Date'].max()))\n    print('Train shape : {}'.format(train.shape))\n\n    print('Test timeframe  : {} - {}'.format(test['Date'].min(), test['Date'].max()))\n    print('Test shape : {}'.format(test.shape))\n\n    return train, test\n\ndef print_feature_importances(clf, index):\n    return pd.Series(clf.feature_importances_, index = index).sort_values(ascending = False)\n\ndef obs_vs_pred_plot(y_train, y_pred_train, y_test, y_pred_test, title = None):\n\n    plot_train = pd.concat([y_train, pd.Series(y_pred_train, index = y_train.index)], axis = 1)\n    plot_train.columns = [\"Observations\", \"Predictions\"]\n\n    plot_test = pd.concat([y_test, pd.Series(y_pred_test, index = y_test.index)], axis = 1)\n    plot_test.columns = [\"Observations\", \"Predictions\"]\n\n    f, ax = plt.subplots(figsize=(7, 7))\n    plt.title(title)\n\n    sc = sns.scatterplot(x=\"Observations\", y=\"Predictions\", data = plot_train, label = \"Train\")\n    sc.axes.set_ylim(0,max(plot_train.max().max(), plot_test.max().max()))\n    sc.axes.set_xlim(0,max(plot_train.max().max(), plot_test.max().max()))\n\n    sns.scatterplot(x=\"Observations\", y=\"Predictions\", data = plot_test, label = \"Test\")\n    return None\n\ndef plot_region_pred(group, test_, dependant = 'ConfirmedCases'):\n\n    test_gr = test_.groupby(['Country_Region', 'Province_State'])\n    gr = test_gr.get_group(group)\n    gr.set_index('Date', inplace = True)\n\n    f, ax = plt.subplots(figsize=(7, 7))\n    gr[[dependant, dependant+'_pred']].plot()\n\ndef preprocess_train_RFC(train, regressors, dependant, daily_cases = False, lags = False):\n\n    if daily_cases:\n        train = train.loc[train['DailyCases'].notnull()]\n\n    X_train = train[regressors].copy()\n    c_train = train[dependant].copy()\n\n    train_gr = train.groupby(['Country_Region', 'Province_State'])\n\n    if lags:\n        X_train['ConfirmedCases_L1'] = X_train['ConfirmedCases_L1'].fillna(0)\n        X_train['Fatalities_L1'] = X_train['Fatalities_L1'].fillna(0)\n\n    X_train['Lat'] = X_train['Lat'].fillna(0)\n    X_train['Long'] = X_train['Long'].fillna(0)\n\n    return X_train, c_train\n\ndef preprocess_test_RFC(test, X_train, regressors, dependant):\n\n    X_test = test[regressors].copy()\n    c_test = test[dependant].copy()\n\n    X_test['Lat'] = X_test['Lat'].fillna(0)\n    X_test['Long'] = X_test['Long'].fillna(0)\n\n    return X_test, c_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npath = \"/kaggle/input/\"\n\ntrain = pd.read_csv(path + 'covid19-global-forecasting-week-2/train.csv')\ntest = pd.read_csv(path + 'covid19-global-forecasting-week-2/test.csv')\ncountry_info = pd.read_csv(path + 'countryinfo/covid19countryinfo.csv')\nlonglat = pd.read_csv(path + 'longlat/train_longlat.csv')\n\ntotal = train.merge(test, how = 'outer', on = ['Province_State', 'Country_Region', 'Date'])\ntotal = preprocess(total, country_info, longlat, lags = False)\ntrain, test = train_test_split(total, daily_cases = True, lags = False)\ntotal.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dependant = 'ConfirmedCases'\nregressors = ['Lat', \n              'Long', \n              'Weekday', \n              'TTF', \n              't', \n              'ConfirmedCases_Last', \n              'Fatalities_Last',\n              \"medianage\", \n              \"density\", \n              'hospibed', \n              'sexratio'\n             ]\n\nX_train, c_train = preprocess_train_RFC(train, regressors, dependant, daily_cases=False)\nX_test, c_test = preprocess_test_RFC(test, X_train, regressors, dependant)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(max_depth=None, \n                             max_features = 'auto', \n                             n_estimators = 200, \n                             random_state=0, \n                             bootstrap = False,\n                            criterion = 'entropy')\nrfc.fit(X_train, c_train)\nc_train_pred = rfc.predict(X_train)\nprint_feature_importances(rfc, X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict ConfirmedCases\n\nc_hat_test = rfc.predict(X_test)\nc_hat_test = pd.Series(c_hat_test, index = X_test.index, name = 'ConfirmedCases_pred')\n\nfrom sklearn.metrics import mean_squared_log_error\n\ntest_ = test.join(c_hat_test).loc[test['ConfirmedCases'].notnull()]\nRMSLE_test = np.sqrt(mean_squared_log_error(test_['ConfirmedCases'], test_[\"ConfirmedCases_pred\"]))\nRMSLE_train = np.sqrt(mean_squared_log_error(train['ConfirmedCases'], c_train))                                              \n\n# Test / train errors\nprint('RMSLE (train) : {}'.format(RMSLE_train))\nprint('RMSLE (test) : {}'.format(RMSLE_test))\n\n# Compute test error wrt horizon\nfor t in test_['t'].unique():\n    test_t = test_.loc[test_['t'] == t]\n    RMSLE_test = np.sqrt(mean_squared_log_error(test_t['ConfirmedCases'], test_t[\"ConfirmedCases_pred\"]))\n    print('RMSLE (horizon t={}) : {}'.format(int(t), RMSLE_test))\n    \n# Compute test error wrt Region\n\nRMSE_region = []\ntest_gr = test_.groupby(['Country_Region', 'Province_State'])\nfor key in test_gr.groups.keys():\n    test_region = test_gr.get_group(key)\n    RMSE = np.sqrt(mean_squared_log_error(test_region['ConfirmedCases'], test_region[\"ConfirmedCases_pred\"]))\n    RMSE_region.append(RMSE)\nRMSE_region = pd.Series(RMSE_region, index = test_gr.groups.keys())\nRMSE_region.sort_values(ascending = True).tail(10).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\n\ndef plot_region_pred(group, test_, dependant = 'ConfirmedCases'):\n\n    test_gr = test_.groupby(['Country_Region', 'Province_State'])\n    \n    gr = test_gr.get_group(group)\n    gr.set_index('Date', inplace = True)\n\n    #fig, axs = plt.subplots(2,2, figsize=(15, 15), facecolor='w', edgecolor='k')\n\n    gr[[dependant, dependant+'_pred']].plot.bar(title = group[0] + '/' + group[1])\n    #gr[dependant+'_pred'].hist(ax = axs[1])\n    return gr\n\nregion = ('Philippines', '-')\n\ngr = plot_region_pred(region, test_, 'ConfirmedCases')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dependant = 'Fatalities'\nregressors = ['Lat', \n              'Long', \n              'Weekday', \n              'TTF', \n              't', \n              'ConfirmedCases_Last']\n\nX_train, f_train = preprocess_train_RFC(train, regressors, dependant, daily_cases=False)\nX_test, f_test = preprocess_test_RFC(test, X_train, regressors, dependant)\nrfc_fatalities = RandomForestClassifier(max_depth=200, random_state=0)\nrfc_fatalities.fit(X_train, f_train)\nf_train_pred = rfc_fatalities.predict(X_train)\nprint_feature_importances(rfc, X_train.columns)\n\nf_hat_test = rfc_fatalities.predict(X_test)\nf_hat_test = pd.Series(f_hat_test, index = X_test.index, name = 'Fatalities_pred')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ = test.join(f_hat_test).loc[test['Fatalities'].notnull()]\nRMSLE_test = np.sqrt(mean_squared_log_error(test_['Fatalities'], test_[\"Fatalities_pred\"]))\n\nprint('RMSLE (test) : {}'.format(RMSLE_test))\n\n# Compute test error wrt horizon\nfor t in test_['t'].unique():\n    test_t = test_.loc[test_['t'] == t]\n    RMSLE_test = np.sqrt(mean_squared_log_error(test_t['Fatalities'], test_t[\"Fatalities_pred\"]))\n    print('RMSLE (horizon t={}) : {}'.format(int(t), RMSLE_test))\n    \n# Compute test error wrt Region\nRMSE_region = []\ntest_gr = test_.groupby(['Country_Region', 'Province_State'])\nfor key in test_gr.groups.keys():\n    test_region = test_gr.get_group(key)\n    RMSE = np.sqrt(mean_squared_log_error(test_region['Fatalities'], test_region[\"Fatalities_pred\"]))\n    RMSE_region.append(RMSE)\nRMSE_region = pd.Series(RMSE_region, index = test_gr.groups.keys())\nRMSE_region.sort_values(ascending = True).tail(30).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.concat([test['ForecastId'], c_hat_test, f_hat_test], axis = 1)\nsub.columns = ['ForecastId', 'ConfirmedCases', 'Fatalities']\nsub['ForecastId'] = sub['ForecastId'].apply(int)\nsub.set_index('ForecastId', inplace = True)\nsub.to_csv('submission.csv')\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}