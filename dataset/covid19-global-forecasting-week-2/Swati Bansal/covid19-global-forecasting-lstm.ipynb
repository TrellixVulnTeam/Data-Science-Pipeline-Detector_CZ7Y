{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Covid-19 Global Forecasting using LSTM\n\nThe goal of notebook is to forecast Confirmed Cases globallly using LSTM modellimg technqiues.\nThe architechture is very simple to implement and gives close forecast to actuals"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing necessary libraries \nimport numpy as np\nimport pandas as pd\nimport math\n\nfrom sklearn.metrics import mean_squared_error\nfrom shapely.geometry import Point\nimport os\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom datetime import timedelta\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Preparation and Understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Data\nData = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\nData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.Date.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check null values in dataset\nData.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is seen above that only Province_State has null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking number of data records under each country\nData.Country_Region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is seen above that US and China has majority of the data records as it has data for various Province_State"},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = Data['Country_Region'].unique()\nprint(f'{len(countries)} countries are in dataset:\\n{countries}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_date_max = Data.Date.value_counts().max()\ngroup_date_min = Data.Date.value_counts().min()\nprint(group_date_max,group_date_min)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_date = Data.Date.min()\nmax_date = Data.Date.max()\nprint(min_date,max_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following Code exclude China and group by on Date so create a dataset for global forcast."},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_total_date_noChina = Data[Data['Country_Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_noChina = Data[Data['Country_Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1) = plt.subplots(1, figsize=(10,5))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_date_noChina.ConfirmedCases.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_date_noChina","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_date_noChina = total_date_noChina.sort_values('Date',ascending=True)\n\ntotal_date_noChina","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following code creates input data which is full data set, train data which 10 less than total dataset, test data has 10 records"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating input data \ninput_data = total_date_noChina.iloc[:,0:1].values\n# getting total record count to create train and test data test\nrecords = total_date_noChina.count()\n# train data set which is 3 less than total data set\nrecords = records[0] - 7\ntrain = total_date_noChina.iloc[0:records,0:1].values\n\n# test data set with 10 records\ntest = total_date_noChina.iloc[records:,0:1].values\n#print(input_data.shape)\nprint(input_data.shape,train.shape,test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Model Building using multistep LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# multi-step data preparation\nfrom numpy import array\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps_in, n_steps_out):\n    X, y1 = list(), list()\n    for i in range(len(sequence)):\n    # find the end of this pattern\n        end_ix = i + n_steps_in\n        out_end_ix = end_ix + n_steps_out\n    # check if we are beyond the sequence\n        if out_end_ix > len(sequence):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n        X.append(seq_x)\n        y1.append(seq_y)\n    return array(X), array(y1)\n\n# define input sequence\nraw_seq = train\n# choose a number of time steps\nn_steps_in, n_steps_out = 3, 7\n# split into samples\nX, y1 = split_sequence(raw_seq, n_steps_in, n_steps_out)\n# summarize the data\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\ny1 = y1.reshape(y1.shape[0], y1.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Building\n\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', return_sequences=True, input_shape=((X.shape[1],1))))\nmodel.add(LSTM(50, activation='relu', return_sequences=True,))\nmodel.add(LSTM(50, activation='relu'))\nmodel.add(Dense(n_steps_out))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(X, y1, epochs=1000, batch_size = 30, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model testing to forcast 7 consecutive day wich will be compared with test data actuals\nx_input = train[(records - n_steps_in):records,0:1]\nx_input = x_input.reshape((1, n_steps_in, n_features))\ntest_predicted = model.predict(x_input, verbose=0)\ntest_predicted = test_predicted.reshape(n_steps_out,)\ntest_predicted1 = pd.Series(test_predicted)\ntest = test.reshape(n_steps_out,)\ntest1 = pd.Series(test)\npd.concat([test1,test_predicted1], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the Forcast for Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(test, color= 'red', label = 'test_data')\nplt.plot(test_predicted, color= 'blue', label = 'predicted_test_data')\nplt.title('Test Data Forecast')\nplt.xlabel('time')\nplt.ylabel('Confirmed_Cases')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Great!! the plot shows predicted values are very  close to actual values"},{"metadata":{},"cell_type":"markdown","source":"Let's Forecast Confirmed Cases for next 3 days from the input data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forcast Confirmed Cases for 7 consecutive days\n#x_input = input_data[-n_steps_in:]\nx_input = test[-3:]\nx_input = x_input.reshape((1, n_steps_in, n_features))\n\nforecast = model.predict(x_input, verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#forecast = test_predicted.reshape(n_steps_in,1)\nforecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Forecast Data\nmaximum_date = Data.Date.max()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date = pd.date_range(maximum_date, periods=8, closed='right')\ndate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date = pd.Series(date)\nforecast1 = forecast.reshape(n_steps_out,)\nforecast2 = pd.Series(forecast1)\nforcast_data = pd.concat([date,forecast2], axis=1)\nforcast_data.columns = ['Date','Forecast_Corfirmed_Cases']\nplt.figure(figsize=(10,5))\nplt.plot(date,forecast2)\nplt.title('7 Days Forecast')\nplt.xlabel('Time')\nplt.ylabel('Confirmed_Cases')\nprint(forcast_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### If you found this notebook helpful, please give it an upvote. It will be greatly appreciated!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}