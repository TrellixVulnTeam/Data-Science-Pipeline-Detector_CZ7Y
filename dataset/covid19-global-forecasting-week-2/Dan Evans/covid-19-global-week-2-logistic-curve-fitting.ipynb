{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exponential growth is (literally) only half the answer!\nThis is my attempt to fit the existing data for each country to a logistic curve, since expoenetial curves don't really exist in the natural world: what we see as exponential growth is the bottom half of a logistic curve.  The tricks are trying to figure out how high the curve goes, and how long it takes to get there.\n\nI'll define a logistic function and then use the curve fitting code from scipy to optimize the values in the logistic expression, then use those optimized values to predict the next weeks of growth.\n\nAs to fatalities, the ideas are that until a country hits is medical system's saturation point, there will be a set ratio of deaths to cases, but then that number will rise as people start to die due to lack of care.  My thinking is: in a country with great surveillance but no care, the death rate will be close to fixed with the cases.  In a country with good care (regardless of surveillance) the death rate will be low, then high, then low again as the system can deal, gets overwhelmed, then can deal again (i.e. Italy)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\nfrom scipy.stats import linregress, norm\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def logistic(x, K, a, b):\n    \"\"\"a logistic curve generating function\n    x: x values\n    K: the carrying capacity; the maximum value the population can grow to.\n    a: shape value 1; influences the length of the left tail\n    b: shape value 2, must be < 0\n    \n    a and b together approximate r_max below\n    \n    The calculus version of this is:\n    dN/dT = r_max * ((K-N)/K) * N\n    Where r_max is the maximum per-capita rate of increase, K is the carrying capacity, and N is the number of individuals in the population.\n    Taken from: https://www.khanacademy.org/science/biology/ecology/population-growth-and-regulation/a/exponential-logistic-growth\n\n    Code equation taken from: http://www.curve-fitting.com/aids.htm\n\n    \"\"\"\n    xrun = np.array(x)\n    krun = np.float128(K)\n    arun = np.float128(a)\n    brun = np.float128(b)\n    #if b >= 0:\n        #return None\n\n    return K / (1 + np.exp(a + b * xrun))\n\ndef rmsle(y_true, y_pred):\n    \"\"\"return root mean squared log error between true and predicted value lists\"\"\"\n    return np.sqrt(np.mean(np.power(np.log1p(y_true) - np.log1p(y_pred),2)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load and preprocess the training data\n- add a column to make it easier to chunk things up\n- remove the overlap between train and test to prevent leakage"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/covid19-global-forecasting-week-2/train.csv', header=0, parse_dates=['Date'])\ntest_df = pd.read_csv('../input/covid19-global-forecasting-week-2/test.csv', header=0, parse_dates=['Date'])\n\n# drop training dates on or after the first testing date to prevent data leakage\ntrain_df = train_df.loc[train_df['Date'] < test_df['Date'].min()]\n\n# do some feature engineering on the training data\ntrain_df['Area'] = train_df['Country_Region'].str.cat(train_df['Province_State'], sep=\"/\", na_rep='').str.replace('\\/$', '')\ntrain_df['ConfirmedCases_log1p'] = train_df.apply(lambda x: np.log1p(x['ConfirmedCases']), axis=1)\ntrain_df['FatalityRatio'] = train_df.apply(lambda x:  x['Fatalities'] / x['ConfirmedCases'] if x['ConfirmedCases'] > 0 else np.nan, axis=1)\n\n# add the area column to the test data too\ntest_df['Area'] = test_df['Country_Region'].str.cat(test_df['Province_State'], sep=\"/\", na_rep='').str.replace('\\/$', '')\n\n#sub_df = pd.read_csv('../input/covid19-global-forecasting-week-2/submission.csv', header=0)\nprint(train_df.shape)\nprint(train_df.columns)\nprint(test_df.shape)\nprint(test_df.columns)\n#print(sub_df.shape)\n#print(sub_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# make a list of all the different areas\narea_list = list(train_df['Area'].unique())\n\n# create a submission dataframe\nsub_df = pd.DataFrame({'ForecastId':[],\n                      'ConfirmedCases': [],\n                      'Fatalities': []\n                      },dtype=np.int64)\n\n# for each area in the unique list of areas\nfor one_area in area_list:\n\n    # isolate one area's worth of data\n    X_train = train_df.loc[train_df['Area'] == one_area]\n    X_test = test_df.loc[test_df['Area'] == one_area]\n    \n    # get x and y values for modeling\n    xs = range(0, X_train.shape[0])\n    y_train_case = list(X_train['ConfirmedCases'])\n    y_train_fat = list(X_train['Fatalities'])\n\n    # prepare the range of x values needed for forecasting\n    forecastxs = range(X_train.shape[0], X_train.shape[0] + X_test.shape[0])\n    \n    # decide if there's enough data to do logistic curve fitting, or fall back to linear regression\n    if (len(X_train['ConfirmedCases'].unique()) > 4):\n        \n        # first guess as to the values needed in the logistic function, for curve_fit\n        case_p0 = [1000000, 25, -.1] \n        # fit a logistic curve for case count with 10k iterations and initial values stored in p0\n        case_opt, case_cov = curve_fit(logistic, xs, y_train_case, maxfev=500000, p0=case_p0)\n    \n        y_fitted_train_case = np.round(logistic(xs, case_opt[0], case_opt[1], case_opt[2]), 0)\n\n        # forecast the values for case count from the curve we just fit\n        y_pred_case = np.round(logistic(forecastxs, case_opt[0], case_opt[1], case_opt[2]), 0)    \n    \n        # calculate the value of 1 std dev for each of those measures\n        case_sd = np.sqrt(np.diag(case_cov))\n\n        # plot all lines for context\n        low_y_pred_case = np.round(logistic(forecastxs, case_opt[0]-case_sd[0], case_opt[1]-case_sd[1], case_opt[2]-case_sd[2]))\n        high_y_pred_case = np.round(logistic(forecastxs, case_opt[0]+case_sd[0], case_opt[1]+case_sd[1], case_opt[2]+case_sd[2]))\n             \n    else:\n    \n        # perform linear regression\n        m, b, r, p, std_err = linregress(xs, y_train_case)\n        y_fitted_train_case = np.maximum(np.zeros(len(xs)), np.round((m * xs) + b, 0))\n        y_pred_case = np.round((m * forecastxs) + b, 0)\n    \n    # model fatalities\n    \n    fatality_ratio = np.mean(list(X_train.loc[np.isnan(X_train['FatalityRatio']) == False, 'FatalityRatio']))\n    if np.isnan(fatality_ratio) == True:\n        \n        # use the global average for this country\n        fatality_ratio = X_train['FatalityRatio'].mean()\n        \n    y_fat_ratio_train = np.round(X_train['ConfirmedCases'] * fatality_ratio, 0)\n    y_fat_ratio_forecast = np.round(fatality_ratio * y_pred_case, 0)\n    #plt.plot(xs, X_train['Fatalities'], '-', label='training fatality ratio')\n    #plt.plot(xs, y_fat_ratio_train, '.', label='fitted fatality ratio')\n    #plt.plot(forecastxs, y_fat_ratio_forecast, 'o', label='forecast fatalities')\n    #plt.legend(loc='best')\n    #plt.plot(ndx, normal_pdf, 'o', label='normal pdf')\n    #plt.title(one_area)\n    #plt.show()\n    \n    # write out this information to the submission dataframe\n    \n    ids = test_df.loc[test_df['Area'] == one_area, 'ForecastId']\n    sub_df = pd.concat([sub_df, pd.DataFrame({'ForecastId' : ids,\n                                            'ConfirmedCases' : y_pred_case,\n                                            'Fatalities' : y_fat_ratio_forecast\n                                            },dtype=np.int64)])\n    \n    train_case_rmsle = rmsle(y_train_case, y_fitted_train_case)\n    print(\"{0} rmsle cases: {1:.3f}\".format(one_area, train_case_rmsle))\n    #plt.plot(xs, y_train_case, '-', label='training')\n    #plt.plot(xs, y_fitted_train_case, '.', label='fitted training')\n    #plt.plot(forecastxs, y_pred_case, 'x', label='forecaset')\n    #plt.legend(loc='best')\n    #plt.title(one_area)\n    #plt.show()\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sub_df.describe())\nprint(sub_df.isnull().sum())\n\n#\n# there are countries that have not reported any cases, so they have no fatalities  do an NA fill\n#\n\nsub_df['Fatalities'] = sub_df['Fatalities'].fillna(value=0)\nsub_df['Fatalities'] = sub_df['Fatalities'].astype('int64')\nprint(sub_df.describe())\nprint(sub_df.isnull().sum())\nprint(sub_df.info())\nprint(sub_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write out the header, then commit and submit!\nsub_df.to_csv('submission.csv', header=True, index=False)\nprint(\"Complete.\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}