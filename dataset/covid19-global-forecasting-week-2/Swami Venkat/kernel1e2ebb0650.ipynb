{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom scipy.optimize import curve_fit\nfrom scipy.integrate import odeint\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore the Dataset\nExploring the dataset to see what is inside, and what information we can get."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\")\n# test['Province_State'].fillna('', inplace = True)\n# train['Province_State'].fillna('', inplace = True)\ntest['Date'] = pd.to_datetime(test['Date'])\ntrain['Date'] = pd.to_datetime(train['Date'])\ntrain['Province_State'] = train['Province_State'].fillna('None')\ntrain['unique_id'] = train['Country_Region'].astype(str) + '_' + train['Province_State'].astype(str)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total Number of Country in Training Data: ', train['Country_Region'].nunique())\nprint('Has in total number of Province or States: ', train['Province_State'].nunique())\nprint('Date range: ', min(train['Date']), max(train['Date']), 'Today number of days: ', train['Date'].nunique())\n\nprint('Total Number of Country in Test Data: ', test['Country_Region'].nunique())\nprint('Has in total number of Province or States: ', test['Province_State'].nunique())\nprint('Date range: ', min(test['Date']), max(test['Date']), 'Today number of days: ', test['Date'].nunique())\n\nprint('For the training dataset, the number of regions on the first day ', min(train['Date']), ' are ', train[train['Date'] == min(train['Date'])]['Country_Region'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can tell from this number, the training dataset has all 173 confirmed case and fatalities regardless whether that was the first day the country found its first case or not. Our training dataset will be driving by a lot of zero values from the earlier days.\n\nThe Public and Private Leaderboard requirement is: Only use data prior to 2020-03-19 for predictions on the public leaderboard period. Use up to and including the most recent data for predictions on the private leaderboard period.\n* Public Leaderboard Period - 2020-03-19 - 2020-04-01\n* Private Leaderboard Period - 2020-04-02 - 2020-04-30\n\nLets see globally, how the coronavirus cases number change. I will use plotly here."},{"metadata":{"trusted":true},"cell_type":"code","source":"tot_confirmed = train.groupby(['Date']).agg({'ConfirmedCases':['sum']})\ntot_fatalities = train.groupby(['Date']).agg({'Fatalities':['sum']})\ntot_case_bydate = tot_confirmed.join(tot_fatalities)\ntot_case_bydate.reset_index(inplace = True)\ntot_case_bydate.head()\n\nfig = px.scatter(tot_case_bydate, x = 'Date', y = 'ConfirmedCases')\nfig.update_layout(title='Global Confirmed Cases - Cumulative')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(tot_case_bydate, x = 'Date', y = 'Fatalities')\nfig.update_layout(title='Global Fatalities Cases - Cumulative')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIR Model:\n\nWe used SIR model for the prediction when the number of cases for a country is more than 20. If smaller than 20, we used simple linear regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_curve_fit_diff_S(y1,y2,N0):\n   \n    I0 = y1[0]\n    R0 = y2[0]\n    def deriv(y, t,N0, beta,gamma,tau):\n\n        S,I,R,N = y\n        dNdT = N*(1-(1/np.exp(tau)))\n        dSdt = -beta * S * I/N\n        \n        dIdt = beta * S * I/N  - gamma * I\n        dRdt = gamma * I\n        return dSdt,dIdt,dRdt,dNdT\n    \n    def odeint_func(t,N0,beta,gamma,tau,I0,R0):\n        \n        S0 = (N0 - I0 - R0)\n        y0 = S0, I0, R0,N0\n        ret = odeint(deriv, y0, t, args=(N0,beta, gamma,tau))\n        print()\n        return np.ravel(np.vstack((ret[:,1],ret[:,2])))\n\n    t = np.arange(0,len(y1),1)\n    y_t = np.vstack((y1,y2))\n\n    values , pcov = curve_fit(lambda t,beta,gamma,tau: odeint_func(t,N0,beta,gamma,tau,I0,R0), \n                          t, np.ravel(y_t) ,bounds=((0,0,-np.inf),(1,1,np.inf)),maxfev=999999)\n        \n    return values[0],values[1],values[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def deriv(y, t, N,beta,gamma):\n\n            S,I,R = y\n            dSdt = -beta * S * I/N\n            dIdt = beta * S * I/N  - gamma * I\n            dRdt = gamma * I\n            return dSdt,dIdt,dRdt\ndef odeint_func(t,N,I0,R0,beta,gamma):\n    \n    S0 = (N - I0 - R0)\n    y0 = S0, I0, R0\n    ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n\n    return np.ravel(np.vstack((ret[:,1],ret[:,2])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/worldpopulation/world_population.csv')\nus_state_pop = pd.read_csv('../input/worldpopulation/state_population.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_confirm = []\npred_fatality = []\n\nbetas,gammas = [],[]\nfor uid in train['unique_id'].unique():\n    country, state = None, None\n    df = train[train['unique_id'] == uid]\n#     display(df)\n    y_conf = df.set_index('Date')['ConfirmedCases'].values.flatten()\n    y_death = df.set_index('Date')['Fatalities'].values.flatten()\n    idx = np.argwhere(y_conf>0)[0][0]\n    \n    y_active = y_conf[idx:]\n    y_deaths = y_death[idx:]\n    if y_conf[-1] < 20:\n        lreg = LinearRegression()\n        pred_confirm.append(y_conf[56:69])\n        pred_fatality.append(y_death[56:69])\n        x = np.arange(0,len(y_conf),1)\n        x = x.reshape(-1,1)\n        x_test = np.arange(max(x) + 1, max(x) + 31, 1)\n        x_test = x_test.reshape(-1,1)\n        lreg.fit(x,y_conf)\n        predict_c = lreg.predict(x_test)\n        pred_confirm.append(predict_c)\n\n        lreg.fit(x,y_death)\n        predict_f = lreg.predict(x_test)\n        pred_fatality.append(predict_f)\n        continue\n\n    \n    \n    if 'None' in uid:\n        \n        country = uid.split('_None')[0]\n        if ' ' in country:\n            country = country.replace(' ', '_')\n        if country in data['countriesAndTerritories'].unique():\n            N = data[data['countriesAndTerritories']==country]['popData2018'].values[0]\n            \n        else:\n            N = 1000000\n            \n        \n    elif 'US' in uid:\n        state = uid.split('US_')[1]\n        \n        if state in us_state_pop['NAME'].unique():\n            N = us_state_pop[us_state_pop['NAME']==state]['POPESTIMATE2019'].values[0]\n        else: \n            N = 150000\n        \n    else:\n        \n        country = uid.split('_')[0]\n        \n        uniq_list = train['unique_id'].unique()\n        tot = len([s for s in uniq_list if \"United Kingdom\" in s])\n        if ' ' in country:\n            country = country.replace(' ', '_')\n        \n        N = data[data['countriesAndTerritories']==country]['popData2018'].values[0]/tot\n        \n    beta,gamma,tau = run_curve_fit_diff_S(y_active,y_deaths,N)\n    betas.append(beta)\n    gammas.append(gamma)\n    t_pred = np.arange(0,len(y_active)+30,1)\n    pred_confirm.append(y_conf[56:69])\n    pred_fatality.append(y_death[56:69])\n    y_pred_conf = odeint_func(t_pred,N,y_active[0],y_deaths[0],beta, gamma)[:len(y_active)+30]\n    y_pred_death = odeint_func(t_pred,N,y_active[0],y_deaths[0],beta, gamma)[30+len(y_active):]\n    pred_confirm.append(y_pred_conf[-30:])\n    pred_fatality.append(y_pred_death[-30:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_confirm = [item for sublist in pred_confirm for item in sublist]\npred_fatality = [item for sublist in pred_fatality for item in sublist]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'ForecastId': test['ForecastId'], \n                           'ConfirmedCases': pred_confirm, \n                           'Fatalities': pred_fatality})\nsubmission_int = submission.round(0)\nsubmission_int = submission_int.astype(int)\n\nsubmission_int.to_csv('submission.csv', index = False)\nlen(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}