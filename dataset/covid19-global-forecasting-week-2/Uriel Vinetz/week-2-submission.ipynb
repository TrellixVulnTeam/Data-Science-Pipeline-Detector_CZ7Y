{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Gathering"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"pd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.max_rows\", 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info = pd.read_csv(\"/kaggle/input/countryinfo/covid19countryinfo.csv\")\ncountry_info = country_info.rename({\"region\": \"state\"}, axis=1)\ncountry_info.loc[country_info[\"state\"].isna(), \"state\"] = \"Unknown\"\ncountry_info = country_info.drop([col for col in country_info.columns if \"Unnamed\" in col], axis=1)\ncountry_info[\"pop\"] = country_info[\"pop\"].str.replace(',', '').astype(float)\n\npollution = pd.read_csv(\"/kaggle/input/pollution-by-country-for-covid19-analysis/region_pollution.csv\")\npollution = pollution.rename({\"Region\": \"country\",\n                             \"Outdoor Pollution (deaths per 100000)\": \"outdoor_pol\",\n                             \"Indoor Pollution (deaths per 100000)\": \"indoor_pol\"}, axis=1)\n\neconomy = pd.read_csv(\"/kaggle/input/the-economic-freedom-index/economic_freedom_index2019_data.csv\", engine='python')\neconomy_cols = [col for col in economy.columns if economy[col].dtype == \"float64\"] + [\"Country\"]\neconomy = economy[economy_cols]\neconomy = economy.rename({\"Country\": \"country\"}, axis=1)\n\ndef append_external_data(df):\n    df = pd.merge(df, country_info, on=[\"country\", \"state\"], how=\"left\")\n    df = pd.merge(df, pollution, on=\"country\", how=\"left\")\n    df = pd.merge(df, economy, on=\"country\", how=\"left\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info[\"publicplace\"] = np.where(country_info[\"publicplace\"].str.contains(\"/\"), country_info[\"publicplace\"], np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info[\"publicplace\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_rel_columns = ['state', 'country', 'pop', 'tests',\n       'testpop', 'density', 'medianage', 'urbanpop', 'quarantine', 'schools',\n       'publicplace', 'gatheringlimit', 'gathering', 'nonessential',\n       'hospibed', 'smokers', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64',\n       'sex65plus', 'sexratio', 'lung', 'femalelung', 'malelung', 'gdp2019',\n       'healthexp', 'healthperpop', 'fertility']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info = country_info[list_rel_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info.loc[country_info[\"country\"] == \"China\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def aggregate_label(df):\n    country_df = df[[\"country\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]].groupby([\"country\", \"Date\"], as_index=False).sum()\n    country_df = country_df.rename({\"ConfirmedCases\": \"country_cases\", \"Fatalities\": \"country_fatalities\"}, axis=1)\n    df = pd.merge(df, country_df, on=[\"country\", \"Date\"], how=\"left\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_days_since_event(df, feature_name, casualties, casualties_amount, groupby=[\"country\"]):\n    cases_df = df.loc[df[casualties] > casualties_amount][groupby + [\"Date\"]].groupby(groupby, as_index=False).min()\n    cases_df = cases_df.rename({\"Date\": \"relevant_date\"}, axis=1)\n    df = pd.merge(df, cases_df, on=groupby, how=\"left\")\n    df[feature_name] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(df[\"relevant_date\"])).dt.days\n    df.loc[df[feature_name] < 0, feature_name] = 0\n    df = df.drop(\"relevant_date\", axis = 1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_time_features(df):\n    df = calculate_days_since_event(df, \"days_from_first_death\", \"Fatalities\", 0, [\"country\"])\n    df = calculate_days_since_event(df, \"days_from_first_case\", \"ConfirmedCases\", 0, [\"country\"])\n    df = calculate_days_since_event(df, \"days_from_first_case_province\", \"ConfirmedCases\", 0, [\"country\", \"state\"])\n    df = calculate_days_since_event(df, \"days_from_first_death_province\", \"Fatalities\", 0, [\"country\", \"state\"])\n    df = calculate_days_since_event(df, \"days_from_centenary_case\", \"ConfirmedCases\", 99, [\"country\"])\n    df = calculate_days_since_event(df, \"days_from_centenary_case_province\", \"Fatalities\", 99, [\"country\", \"state\"])\n    df = calculate_days_since_event(df, \"days_from_centenary_daily_cases_province\", \"ConfirmedCases_daily\", 99, [\"country\", \"state\"])\n    df = calculate_days_since_event(df, \"days_from_centenary_daily_cases\", \"ConfirmedCases_daily\", 99, [\"country\"])\n    \n    # Days from first detected case\n    df[\"days_from_first_ever_case\"] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(\"2019-12-01\")).dt.days\n    df.loc[df[\"days_from_first_ever_case\"] < 0, \"days_from_first_ever_case\"] = 0\n    \n    #Days from quarantine, school closures and restrictions\n    df[\"days_from_quarantine\"] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(df[\"quarantine\"])).dt.days\n    df[\"days_from_quarantine\"].fillna(0)\n    df.loc[df[\"days_from_quarantine\"] < 30, \"days_from_quarantine\"] = 0\n    df.loc[df[\"days_from_quarantine\"] >= 30, \"days_from_quarantine\"] = 1\n\n    df[\"days_from_school\"] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(df[\"schools\"])).dt.days\n    df[\"days_from_school\"].fillna(df[\"days_from_quarantine\"])\n    df.loc[df[\"days_from_school\"] < 30, \"days_from_school\"] = 0\n    df.loc[df[\"days_from_school\"] >= 30, \"days_from_school\"] = 1\n\n    df[\"days_from_publicplace\"] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(df[\"publicplace\"])).dt.days\n    df[\"days_from_publicplace\"].fillna(df[\"days_from_quarantine\"])\n    df.loc[df[\"days_from_publicplace\"] < 30, \"days_from_publicplace\"] = 0\n    df.loc[df[\"days_from_publicplace\"] >= 30, \"days_from_publicplace\"] = 1\n    \n    df[\"days_from_gathering\"] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(df[\"gathering\"])).dt.days\n    df[\"days_from_gathering\"].fillna(df[\"days_from_quarantine\"])\n    df.loc[df[\"days_from_gathering\"] < 30, \"days_from_gathering\"] = 0\n    df.loc[df[\"days_from_gathering\"] >= 30, \"days_from_gathering\"] = 1\n    \n    df[\"days_from_nonessential\"] = (pd.to_datetime(df[\"Date\"]) - pd.to_datetime(df[\"nonessential\"])).dt.days\n    df[\"days_from_nonessential\"].fillna(df[\"days_from_quarantine\"])\n    df.loc[df[\"days_from_nonessential\"] < 30, \"days_from_nonessential\"] = 0\n    df.loc[df[\"days_from_nonessential\"] >= 30, \"days_from_nonessential\"] = 1\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_ar_features(df, group_by_cols, value_cols):\n    \n    # Daily cases\n    diff_df = df.groupby(group_by_cols)[value_cols].diff().fillna(0)\n    diff_df.columns = [col + \"_daily\" for col in value_cols]\n    value_cols += [col + \"_daily\" for col in value_cols]\n    df = pd.concat([df, diff_df], axis=1)\n    \n    # Daily percentage increase\n    pct_df = df.groupby(group_by_cols)[value_cols].pct_change().fillna(0)\n    pct_df.columns = [col + \"_pct_change\" for col in value_cols]\n    value_cols += [col + \"_pct_change\" for col in value_cols]\n    df = pd.concat([df, pct_df], axis=1)\n\n    # Shift to yesterday's data\n    yesterday_df = df.groupby(group_by_cols)[value_cols].shift()\n    value_cols = [col + \"_yesterday\" for col in value_cols]\n    yesterday_df.columns = value_cols\n    df = pd.concat([df, yesterday_df], axis=1)\n\n    # Average of the percentage change in the last 3 days\n    three_days_avg = df.groupby(group_by_cols)[value_cols].rolling(3).mean()\n    three_days_avg = three_days_avg.reset_index()[value_cols]\n    three_days_avg.columns = [col + \"_3_day_avg\" for col in three_days_avg.columns]\n    df = pd.concat([df, three_days_avg], axis=1)\n\n    # Average of the percentage change in the last 7 days\n    seven_days_avg = df.groupby(group_by_cols)[value_cols].rolling(7).mean()\n    seven_days_avg = seven_days_avg.reset_index()[value_cols]\n    seven_days_avg.columns = [col + \"_7_day_avg\" for col in seven_days_avg.columns]\n    df = pd.concat([df, seven_days_avg], axis=1)\n    \n    df = df.replace([np.inf, -np.inf], 0)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_features(df):\n    group_by_cols = [\"state\",\"country\"]\n    value_cols = [\"ConfirmedCases\", \"Fatalities\", \"country_cases\", \"country_fatalities\"]\n    \n    df = aggregate_label(df)\n    df = append_external_data(df)\n    df = generate_ar_features(df, group_by_cols, value_cols)\n    df = generate_time_features(df)\n    df[\"dow\"] = pd.to_datetime(df[\"Date\"]).dt.dayofweek\n    df.loc[df[\"ConfirmedCases_yesterday\"]<0, \"ConfirmedCases_yesterday\"] = 0\n    df.loc[df[\"Fatalities_yesterday\"]<0, \"Fatalities_yesterday\"] = 0\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\ntrain = train.rename({\"Province_State\": \"state\", \"Country_Region\": \"country\"}, axis=1)\ntrain.loc[train[\"state\"].isna(), \"state\"] = \"Unknown\"\ntrain = generate_features(train)\nprint(train[\"Date\"].min(), \"-\", train[\"Date\"].max())\ntrain.loc[train[\"country\"] == \"Italy\"].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train[\"state\"] == \"Hubei\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/test.csv\")\ntest = test.rename({\"Province_State\": \"state\", \"Country_Region\": \"country\"}, axis=1)\ntest.loc[test[\"state\"].isna(), \"state\"] = \"Unknown\"\nprint(test[\"Date\"].min(), \"-\", test[\"Date\"].max())\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train[\"Date\"]<\"2020-03-22\", \"split\"] = \"train\"\ntrain.loc[train[\"Date\"]>=\"2020-03-22\", \"split\"] = \"test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nfeatures = [col for col in train.columns if (\"yesterday\" in col) | (\"days_from\" in col)]\nfeatures += country_info.select_dtypes(include=numerics).columns.tolist()\nfeatures += pollution.select_dtypes(include=numerics).columns.tolist()\nfeatures += economy.select_dtypes(include=numerics).columns.tolist()\nfeatures += [\"dow\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(df, label, base_label, features=features, **kwargs):\n    X_train = df.loc[df[\"split\"] == \"train\"][features]\n    y_train = np.log(df.loc[df[\"split\"] == \"train\"][label] + 1)\n    b_train = np.log(df.loc[df[\"split\"] == \"train\"][base_label] + 1)\n    X_test = df.loc[df[\"split\"] == \"test\"][features]\n    y_test = np.log(df.loc[df[\"split\"] == \"test\", label] + 1)\n    b_test = np.log(df.loc[df[\"split\"] == \"test\", base_label] + 1)\n    print(kwargs)\n    model = lgb.LGBMRegressor(**kwargs)\n    model.fit(X_train, y_train, init_score = b_train)\n    y_pred = model.predict(X_test)\n    print(np.sqrt(mean_squared_error(y_test, y_pred + b_test)))\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model_cases = train_model(train, \"ConfirmedCases\", \"ConfirmedCases_yesterday\",\n                                   max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(lgb_model_cases)\nsample = train.loc[train[\"split\"] == \"test\"].sample(500)\nshap_values = explainer.shap_values(sample[features])\nshap.summary_plot(\n    shap_values,\n    sample[features],\n    max_display=110,\n    show=True,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model_fatalities = train_model(train, \"Fatalities\", \"Fatalities_yesterday\", features,\n                                   max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8\n                                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(lgb_model_fatalities)\nsample = train.loc[train[\"split\"] == \"test\"].sample(500)\nshap_values = explainer.shap_values(sample[features])\nshap.summary_plot(\n    shap_values,\n    sample[features],\n    max_display=110,\n    show=True,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train on full data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[features]\ny_train = np.log(train[\"ConfirmedCases\"] + 1)\nb_train = np.log(train[\"ConfirmedCases_yesterday\"] + 1)\ncases_model = lgb.LGBMRegressor(max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8\n                               )\ncases_model.fit(X_train, y_train, init_score = b_train)\n\nX_train = train[features]\ny_train = np.log(train[\"Fatalities\"] + 1)\nb_train = np.log(train[\"Fatalities_yesterday\"] + 1)\nfatalities_model = lgb.LGBMRegressor(max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8)\nfatalities_model.fit(X_train, y_train, init_score = b_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict submission dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\nbase_df = base_df.rename({\"Province_State\": \"state\", \"Country_Region\": \"country\"}, axis=1)\nbase_df.loc[base_df[\"state\"].isna(), \"state\"] = \"Unknown\"\nscoring_dates = test[\"Date\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring_dates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime as dt, timedelta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame(columns=base_df.columns)\nfor date in scoring_dates.tolist():\n    print(date)\n    new_df = base_df.loc[base_df[\"Date\"] < date].copy()\n    curr_date_df = test.loc[test[\"Date\"] == date].copy()\n    curr_date_df[\"ConfirmedCases\"] = 0\n    curr_date_df[\"Fatalities\"] = 0\n    new_df = new_df.append(curr_date_df).reset_index(drop=True)\n    new_df = generate_features(new_df)\n    new_df[features] = new_df[features]\n    predictions = cases_model.predict(new_df[features]) + np.log(new_df[\"ConfirmedCases_yesterday\"] + 1)\n    new_df[\"predicted_cases\"] = round(np.maximum(np.exp(predictions) - 1, new_df[\"ConfirmedCases_yesterday\"]))\n    predictions = fatalities_model.predict(new_df[features]) + np.log(new_df[\"Fatalities_yesterday\"] + 1)\n    new_df[\"predicted_fatalities\"] = np.maximum(np.exp(predictions) - 1, new_df[\"Fatalities_yesterday\"])\n    new_df[\"predicted_fatalities\"] = round(np.minimum(new_df[\"predicted_fatalities\"], new_df[\"predicted_cases\"]*0.2))\n    new_df.loc[new_df[\"Date\"] == date, \"ConfirmedCases\"] = new_df.loc[new_df[\"Date\"] == date, \"predicted_cases\"]\n    new_df.loc[new_df[\"Date\"] == date, \"Fatalities\"] = new_df.loc[new_df[\"Date\"] == date, \"predicted_fatalities\"]\n    pred_df = pred_df.append(new_df.loc[new_df[\"Date\"] == date][pred_df.columns.tolist()])\n    if date not in base_df[\"Date\"].unique():\n        base_df = base_df.append(new_df.loc[new_df[\"Date\"] == date][base_df.columns.tolist()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.loc[pred_df[\"state\"] == \"Hubei\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.loc[pred_df[\"country\"] == \"Italy\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.loc[pred_df[\"country\"] == \"Israel\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.loc[pred_df[\"country\"] == \"Argentina\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.loc[pred_df[\"country\"] == \"Uruguay\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.merge(test, pred_df[[\"state\", \"country\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]], on=[\"state\", \"country\", \"Date\"], how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}