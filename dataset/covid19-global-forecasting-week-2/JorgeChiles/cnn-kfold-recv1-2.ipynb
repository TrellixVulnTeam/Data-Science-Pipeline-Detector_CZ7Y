{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport tensorflow\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation,SimpleRNN,LSTM\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras import backend\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D, Bidirectional,TimeDistributed\nfrom tensorflow.keras.constraints import max_norm,unit_norm\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\nfrom termcolor import colored\n\nimport numpy\nfrom numpy import arange\nfrom numpy import array\nfrom numpy import mean\nfrom numpy import std\n\nfrom pandas import concat\nfrom pandas import Series\nfrom pandas import DataFrame\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')\ntest=pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')\n\ntrain.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data=train.groupby('Date')['ConfirmedCases','Fatalities'].sum().reset_index()\n\nprint(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\nfrom math import sqrt\nimport matplotlib\n\n# Grafica\npyplot.figure(figsize = (18,9))\npyplot.plot(training_data.ConfirmedCases,'o--',c='b', label='Confirmed')\npyplot.plot(training_data.Fatalities,'o--',c='r', label='Fatalities')\n\n\npyplot.xlabel('Date',fontsize=18)\npyplot.ylabel('cases',fontsize=18)\npyplot.title('COVID19',fontsize=18)\npyplot.grid(True,linestyle='-.')\nleg=pyplot.legend(loc=\"best\",fontsize=18, shadow=True, fancybox=True)\nleg.get_frame().set_alpha(0.8)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some STATS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# hietograma\ntraining_data.Fatalities.hist()\npyplot.show()\n\n# Densidad\ntraining_data.Fatalities.plot(kind='density')\npyplot.show()\n\n#boxplot\ntraining_data.Fatalities.plot(kind='box')\npyplot.show()\n\nprint(training_data.Fatalities.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hietograma\ntraining_data.ConfirmedCases.hist()\npyplot.show()\n\n# Densidad\ntraining_data.ConfirmedCases.plot(kind='density')\npyplot.show()\n\n#boxplot\ntraining_data.ConfirmedCases.plot(kind='box')\npyplot.show()\n\nprint(training_data.ConfirmedCases.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ACF PACF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\npyplot.figure(figsize = (18,9))\nplot_acf(training_data.ConfirmedCases,lags=20)\nplot_pacf(training_data.ConfirmedCases,lags=20)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npyplot.figure(figsize = (18,9))\nplot_acf(training_data.Fatalities,lags=20)\nplot_pacf(training_data.Fatalities,lags=20)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pyplot.scatter(training_data.ConfirmedCases, training_data.Fatalities)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pyplot.matshow(training_data.corr())\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Additive Decomposition"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nresult_addConfirm = seasonal_decompose(training_data.ConfirmedCases, model='additive',period=1)\n\nresult_addConfirm.plot()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nresult_addFatal = seasonal_decompose(training_data.Fatalities, model='additive',period=1)\n\nresult_addFatal.plot()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### no seasonal and strong trend"},{"metadata":{},"cell_type":"markdown","source":"# test for stationarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller, kpss\n\nresult = adfuller(training_data.ConfirmedCases, autolag='AIC')\nprint(f'ADF Statistic: {result[0]}')\nprint(f'p-value: {result[1]}')\nfor key, value in result[4].items():\n    print('Critial Values:')\n    print(f'   {key}, {value}')\n    \n    \nresult = kpss(training_data.ConfirmedCases, regression='c')\nprint('\\nKPSS Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nfor key, value in result[3].items():\n    print('Critial Values:')\n    print(f'   {key}, {value}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Differencing"},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = training_data.ConfirmedCases.diff()\npyplot.plot(diff)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = training_data.Fatalities.diff()\npyplot.plot(diff)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Detrend"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nresult_addConfir = seasonal_decompose(training_data.ConfirmedCases, model='additive',period=1)\ndetrendedConfirmed = training_data.ConfirmedCases.values - result_addConfir.trend\npyplot.plot(detrendedConfirmed )\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nresult_addFatal = seasonal_decompose(training_data.Fatalities.values, model='additive',period=1)\ndetrendedFatal = training_data.Fatalities.values - result_addFatal.trend\npyplot.plot(detrendedFatal)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deseasonalize"},{"metadata":{"trusted":true},"cell_type":"code","source":"deseasonalizedConfirmed = training_data.ConfirmedCases.values - result_addConfir.seasonal\npyplot.plot(deseasonalizedConfirmed )\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deseasonalizedFatal = training_data.Fatalities.values - result_addFatal.seasonal\npyplot.plot(deseasonalizedFatal)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BestLag=DataFrame()\nlags=list()\nautoCorr=list()\n\nfor _ in range(20):\n    autoCorr.append( training_data.Fatalities.autocorr(lag=(_+1)))\n    lags.append((_+1))\n\n\nBestLag['Lag'],BestLag['AutoCorr']=lags,autoCorr\nprint(BestLag)\n    \nOrder=BestLag.sort_values('AutoCorr',ascending=False)\nprint(Order)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test data#"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail()\ntest_data=test.groupby('Date').sum().reset_index()\n\n\n\nh=len(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confirmed to Fatal Cases Model\n"},{"metadata":{},"cell_type":"markdown","source":"# scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nvalores=training_data.ConfirmedCases.values\nvalores=valores.astype('float32')\nvalores=valores.reshape(len(valores),1)\n\nscaler = MinMaxScaler()\nscaled = scaler.fit_transform(valores)\ndataset = scaled.reshape(len(scaled),1 )\n\nprint(dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stops=tensorflow.keras.callbacks.EarlyStopping(monitor='val_mean_squared_error', \n                                                  min_delta=0.01, \n                                                  patience=20, \n                                                  verbose=0, \n                                                  mode='min', \n                                                  baseline=None,\n                                                  restore_best_weights=True)\n        \nfilepath=\"LSTMPolvoOct19.best.hdf5\"\ncheckpoint = tensorflow.keras.callbacks.ModelCheckpoint(filepath, \n                                                        monitor= 'val_mean_squared_error' , \n                                                        verbose=0, \n                                                        save_best_only=True,\n                                                        mode= 'min' )\n        \nreduce_lr = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_mean_squared_error', \n                                                         factor=0.1,\n                                                         patience=10, \n                                                         min_lr=0.0001)\n            \ncallbacks_list = [early_stops,checkpoint,reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_CNN(filters=100,n_layers=1,n_input=1):\n    \n    modelCNN = Sequential()\n\n    modelCNN.add(Conv1D(filters=filters, \n                        kernel_size=n_kernel,\n                        kernel_initializer='random_uniform', \n                        bias_initializer='zeros',\n                        padding=\"causal\",\n                        activation='relu',\n                        kernel_constraint=unit_norm(),\n                        input_shape=(n_input, 1)))\n    modelCNN.add(Dropout(0.5))\n    \n    for _ in range(1, n_layers):\n        \n    \n        modelCNN.add(Conv1D(filters=filters, \n                            kernel_size=n_kernel,\n                            kernel_initializer='random_uniform', \n                            bias_initializer='zeros',\n                            padding=\"causal\",\n                            kernel_constraint=unit_norm(), \n                            activation='relu'))\n        modelCNN.add(Dropout(0.5))\n        \n    modelCNN.add(MaxPooling1D(pool_size=1))\n    modelCNN.add(Dropout(0.5))\n    modelCNN.add(Flatten())\n    modelCNN.add(Dense(1))\n\n    modelCNN.compile(loss='mean_squared_error',\n                        optimizer='adam',\n                        metrics=['mean_squared_error'])\n\n\n\n\n    \n    return modelCNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nn_epochs=[100]\nn_kernel=1\nn_stride=1\nrepeats=1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndatosPronosticoCNN=DataFrame()\ndatosPronosticoCNN=DataFrame(columns=['Param','Day','Forec']) \nPronostico=list()\nrep =list()\ndia=list()\n\n\n\nvalores2=training_data.Fatalities.values\nvalores2=valores2.astype('float32')\nvalores2=valores2.reshape(len(valores2),1)\nscaler2 = MinMaxScaler()\nscaled2 = scaler2.fit_transform(valores2)\nscaled_values= scaled2.reshape(len(scaled2),1 )\n\ntemps = DataFrame(scaled_values) # Datos sin pronosticos\ntemps=temps.astype('float32')\n    \ndataframe = concat([temps.shift(Order.Lag.values[0]), temps], axis=1)\ndataframe.columns = ['t+%d'%(Order.Lag.values[0]),'t']\ndataframe.dropna(inplace=True)\ntrain= dataframe.values\n\nX, y = train[:,0:-1], train[:,-1]\nX=X.reshape(X.shape[0],X.shape[1],1)\n\n\nnum_folds=10\nscoring = 'neg_mean_squared_error'\n\nkfold = KFold(n_splits=num_folds, random_state=None,shuffle=False)\n\nkeras_reg = tensorflow.keras.wrappers.scikit_learn.KerasRegressor(fit_CNN,verbose=0)\n\nparam_CNN = dict(n_layers=[1,2],\n                 filters=[500,1000,2000],\n                 epochs=n_epochs,\n                 n_input=[X.shape[1]])\n\nrnd_search_cv = GridSearchCV(keras_reg, param_CNN,scoring,cv=kfold)\n\nprint(colored(\"\\nfitting model...\",'red'))\n\nModelCNN=rnd_search_cv.fit(X, y,\n      callbacks=[tensorflow.keras.callbacks.EarlyStopping(patience=10)])\n\n\nprint(colored(\"\\nBest score: %f using %s\" % (ModelCNN.best_score_, ModelCNN.best_params_),'yellow')) \n\n\n\nfor _ in range (h):\n\n\n    print(colored(\"\\ngetting day: %d prediction...\"% ((_+1)),'magenta'))\n\n\n    X_pred=X[-1].reshape(1,1,1)\n    predictions_CNN = ModelCNN.predict(X_pred)\n    \n    X=numpy.append(X,predictions_CNN)\n    X=X.reshape(len(X),1,1)\n\n    prediction_CNN = predictions_CNN.reshape(1, 1)\n    Pronosticos = scaler2.inverse_transform(prediction_CNN)\n\n\n    print(colored(\"Prediction day %d: %d Fatalcases\"% ((_+1), Pronosticos) ,'blue'))\n\n    Pronostico.append(Pronosticos)\n    dia.append(_+1)\n\n\nPronostico2=array(Pronostico)\n\n# Grafica\npyplot.figure(figsize = (18,9))\npyplot.plot([None for i in training_data.Fatalities.values] + [x for x in Pronostico2[:,0]],'o-',c='orange', label='Pron CNN')\npyplot.plot(training_data.Fatalities.values,'o--',c='b', label='Data Train')\npyplot.xlabel('Days',fontsize=18)\npyplot.ylabel('Cases',fontsize=18)\npyplot.title('COVID Fatalities.values',fontsize=18)\npyplot.grid(True,linestyle='-.')\nleg=pyplot.legend(loc=\"best\",fontsize=18, shadow=True, fancybox=True)\nleg.get_frame().set_alpha(0.8)\npyplot.show()\n\n\nfor t in range (len(Pronostico)):\n    datosPronosticoCNN=datosPronosticoCNN.append({'Param':ModelCNN.best_params_,'Day':dia[t],'Forec':Pronostico[t]},ignore_index=True)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datosPronosticoCNN","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}