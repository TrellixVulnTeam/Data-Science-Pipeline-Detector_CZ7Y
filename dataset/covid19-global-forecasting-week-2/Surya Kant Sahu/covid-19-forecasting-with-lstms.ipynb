{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\nnp.random.seed(420)\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input\n!mkdir models","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\").replace(np.nan, 0)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"COLUMNS_TO_DROP = ['Id', 'Province_State', 'Country_Region', 'Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly import graph_objects as go\ncountry_name = \"India\"\ncountry = train[train['Country_Region'] == country_name]\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=country['Date'], y=country['ConfirmedCases'], name='Confirmed Cases'))\nfig.add_trace(go.Scatter(x=country['Date'], y=country['Fatalities'], name='Fatalities'))\nfig.update_layout(title='Total COVID-19 in {}'.format(country_name))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Cummulative_to_Absolute(df):\n    df = df.copy()\n    new_cases = [0]\n    new_fatalities = [0]\n    for i in range(1, len(df)):\n        new_cases.append(df['ConfirmedCases'].iloc[i] - df['ConfirmedCases'].iloc[i-1])\n        new_fatalities.append(df['Fatalities'].iloc[i] - df['Fatalities'].iloc[i-1])\n    df['ConfirmedCases'] = new_cases\n    df['Fatalities'] = new_fatalities\n    return df\n\ncountry_absolute = Cummulative_to_Absolute(country)\n#print(sum(country_absolute['ConfirmedCases'].values))\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=country_absolute['Date'], y=country_absolute['ConfirmedCases'], name='Confirmed Cases'))\nfig.add_trace(go.Scatter(x=country_absolute['Date'], y=country_absolute['Fatalities'], name='Fatalities'))\nfig.update_layout(title='Daily COVID-19 in {}'.format(country_name))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = train.groupby('Country_Region')\ncountries = list(grouped.sum().index)\nnum_provinces = [(c, len(train[train['Country_Region'] == c])// 61) for c in countries]\nnum_provinces","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"long = train['Province_State'].to_list()\nlat = train['Country_Region'].to_list()\nunique_long_lat = list(set(zip(long, lat)))\nlen(unique_long_lat) # Unique Places where the stats were recorded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_long_lat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.shuffle(unique_long_lat)\ntrain_long_lat = unique_long_lat[:int(len(unique_long_lat) * 0.7)]\nval_long_lat = unique_long_lat[int(len(unique_long_lat) * 0.7):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to split the Dataframe by longtitude and latitude\ndef make_df_by_long_lat(df, long_lat):\n    #print(long_lat)\n    one = df[df['Province_State'] == long_lat[0]]\n    #print(one)\n    two = one.loc[one['Country_Region'] == long_lat[1]]\n    two = two.drop(columns=COLUMNS_TO_DROP)\n    return two","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_df_by_long_lat(train, (0, \"Afghanistan\"))#train_long_lat[0])\n#train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ntrain_copy = train.drop(columns=COLUMNS_TO_DROP)\nscaler.fit(train_copy.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sliding_window(series, seq_len, scaler):\n    series = scaler.transform(series)\n    x = []\n    y = []\n    for i in range(len(series) - seq_len - 1):\n        x.append(np.expand_dims(series[i:i+seq_len],  axis=0))\n        y.append(np.expand_dims(series[i+seq_len], axis=0))\n    x = np.concatenate(x, axis=0)\n    y = np.concatenate(y, axis=0)\n    return x, y\n\ncountry = country.drop(columns=COLUMNS_TO_DROP)\n#print(india)\nx, y = sliding_window(country, 14, scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = make_df_by_long_lat(train, (0, 'Uruguay'))\nx, y = sliding_window(test, 14, scaler)\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def states_countries(df, seq_len, states_countries, scaler):\n    x_final, y_final = [], []\n    for state_country in states_countries:\n        #print(state_country)\n        x, y = sliding_window(Cummulative_to_Absolute(make_df_by_long_lat(df, state_country)), seq_len, scaler)\n        #print(x, y)\n        x_final.append(x)\n        y_final.append(y)\n    x_final = np.concatenate(x_final, axis=0)\n    y_final = np.concatenate(y_final, axis=0)\n    return x_final, y_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train = states_countries(train, 14, train_long_lat, scaler)\nx_val, y_val = states_countries(train, 14, val_long_lat, scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape, y_train.shape)\nprint(x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset\ntrain_ds = TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\nval_ds = TensorDataset(torch.FloatTensor(x_val), torch.FloatTensor(y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\n\nclass DoomsDayPredictor(nn.Module):\n    def __init__(self, in_features, out_features, hidden_layers, hidden_dim):\n        super(DoomsDayPredictor, self).__init__()\n        \n        self.lstm = nn.LSTM(in_features, num_layers=hidden_layers, hidden_size=hidden_dim, dropout=0.3, batch_first=True)\n        \n        self.fc1 = nn.Linear(hidden_dim, out_features)\n        self.prelu = nn.PReLU()\n        \n    def reset_hidden(self):\n        self.hidden = (torch.zeros(self.hidden[0].shape), torch.zeros(self.hidden[1].shape))\n    \n    def forward(self, x):\n        out, self.hidden = self.lstm(x)\n        #print(out.shape)\n        out = self.prelu(out[:, -1, :])\n        out = self.fc1(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DoomsDayPredictor(2, 2, 1, 5)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_dummy, y_dummy = train_ds[0]\nx_dummy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_dummy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model(torch.FloatTensor(x_dummy.unsqueeze(0)))\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\nmetrics = {\n    'r2': lambda y_pred, y_true: r2_score(y_true.cpu().numpy(), y_pred.cpu().numpy()),\n    'mse': lambda y_pred, y_true: mean_squared_error(y_true.cpu().numpy(), y_pred.cpu().numpy()),\n    'mae': lambda y_pred, y_true: mean_absolute_error(y_true.cpu().numpy(), y_pred.cpu().numpy()),    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, dataloader, metrics):\n    with torch.no_grad():\n        y_pred = []\n        y_true = []\n        for x, y in dataloader:\n            model.reset_hidden()\n            \n            out = model(x)\n\n            y_pred.append(out)\n            y_true.append(y)\n            #print(out.shape, y.shape)\n        y_pred = torch.cat(y_pred, dim=0)\n        y_true = torch.cat(y_true, dim=0)\n\n        computed = {} \n        for metric_name, metric in metrics.items():\n            computed[metric_name] = metric(y_true, y_pred)\n    return computed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optimizer, train_dl, val_dl, metrics):\n    \n    patience = 5\n    p = 0\n    \n    # Hyperparameters\n    max_epochs = 50\n    \n    # Loss function\n    loss_fn = nn.SmoothL1Loss(reduction='sum')\n    loss_history = []\n    \n    evaluate_interval = 500\n    steps = 0\n    \n    best_r2 = float(\"-inf\")\n    \n    # flag for stopping train loop \n    flag = 0\n    \n    # training loop\n    for ep in range(max_epochs):\n        if flag == 1:\n            break\n        for x, y in train_dl:\n            \n            model.reset_hidden()\n            \n            optimizer.zero_grad()\n            \n            out = model(x)\n            \n            loss = loss_fn(y, out)\n            loss_history.append(loss.item())\n            \n            loss_history = loss_history[-10:]\n            avg_loss = sum(loss_history)/len(loss_history)\n            \n            loss.backward()\n            optimizer.step()\n            \n            #if steps % 10:\n            #    print(steps, loss.item(), avg_loss)#, optimizer.learning_rate)\n            \n            #if steps % 10:\n            #    lr_scheduler.step()\n                \n            if steps % evaluate_interval == 0:\n                #print(steps)\n                val_metrics = evaluate(model, val_dl, metrics)\n                if best_r2 < val_metrics['r2']:\n                    best_r2 = val_metrics['r2']\n                    torch.save(model, 'models/best.pth')\n                else:\n                    p += 1\n                    if p >= patience:\n                        flag = 1\n                        print(\"Training stopped at epoch\", ep)\n                        break\n            steps += 1\n            \n    return torch.load('models/best.pth'), best_r2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 32\n\ntr_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\nval_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\nbest, best_r2 = train_model(model, optimizer, tr_dl, val_dl, metrics)\nprint(\"Best Checkpoint Validation R^2 Value: \", best_r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india = train[train['Country_Region'] == 'India']\nindia = india.drop(columns=COLUMNS_TO_DROP)\n\ntwo_weeks = torch.FloatTensor(scaler.transform(india.iloc[-14:, :])).unsqueeze(0)\ntwo_weeks.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y_pred = best(two_weeks).numpy()\n    y_pred = scaler.inverse_transform(y_pred)\ntomorrow = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_days_to_predict = 7\ncountry_name = \"India\"\ndays_to_show = 7 * 3\n\ncountry = train[train['Country_Region'] == country_name]\ntoday_cases = country['ConfirmedCases'].iloc[-1]\ntoday_fatalities = country['Fatalities'].iloc[-1]\n\ncountry = Cummulative_to_Absolute(country)\nx_dates = country['Date'][-days_to_show:]\ncountry = country.drop(columns=COLUMNS_TO_DROP)\n\ntwo_weeks = torch.FloatTensor(scaler.transform(india.iloc[-14:, :])).unsqueeze(0)\n\n# Predict for One Week\nwith torch.no_grad():\n    for _ in range(num_days_to_predict):\n        y_pred = best(two_weeks).unsqueeze(0)\n        two_weeks = torch.cat([two_weeks, y_pred], dim=1)[:, -14:, :]\n        #print(two_weeks.shape)\n\ny_pred = scaler.inverse_transform(two_weeks.squeeze(0).numpy())\n#print(y_pred.shape)\ncountry = country.iloc[-days_to_show:, :]\nfig = go.Figure()\n\nx_new_dates = pd.date_range(start=x_dates.iloc[-1], periods=num_days_to_predict)\n\nfig.add_trace(go.Scatter(x=x_dates, y=country['ConfirmedCases'], name='Confirmed Cases'))\nfig.add_trace(go.Scatter(x=x_dates, y=country['Fatalities'], name='Fatalities'))\nfig.add_trace(go.Scatter(x=x_new_dates, y=y_pred[:, 0], name='Predicted Confirmed Cases'))\nfig.add_trace(go.Scatter(x=x_new_dates, y=y_pred[:, 1], name='Predicted Fatalities'))\nfig.update_layout(title='Forecast for COVID-19 in {}'.format(country_name), xaxis_title=\"Date\", yaxis_title=\"New Cases/Fatalities\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next_cases = int(today_cases + y_pred[:, 0].sum())\nnext_fatal = int(today_fatalities + y_pred[:, 1].sum())\n\nprint(\"Predictions\")\nprint(\"                   Tomorrow          After {} Days\".format(num_days_to_predict))\nprint(\"New Cases:        \", int(tomorrow[0][0]),\"             \", next_cases)\nprint(\"Total Fatalities: \", int(tomorrow[0][1]),\"              \", next_fatal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}