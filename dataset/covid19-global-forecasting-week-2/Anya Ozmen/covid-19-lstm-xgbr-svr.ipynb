{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dependencies\nimport pandas as pd\nimport keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing, svm  \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Embedding\nimport math\nfrom keras import metrics\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM \nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport datetime as dt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/covid19-global-forecasting-week-2/train.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train['Fatalities'].plt.show()\ndf_train.drop(columns=['Province_State'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.fillna(0, inplace=True)\n#df_train.set_index('Date', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train)*0.80","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ndf_train['Country_Region'] = le.fit_transform(df_train['Country_Region'])\ndf_train['Date'] = le.fit_transform(df_train['Date'])\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.drop(columns=['Fatalities','ConfirmedCases']) \nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(X) #t_scaled_data = preprocessing.scale(X)\nX= np.array(X)\nX = preprocessing.scale(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.scale_\nscale=1/ 1.51515152e-02","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_train.drop(columns=['Date','Country_Region','Fatalities'])\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(y)\ny = np.array(y)\ny = preprocessing.scale(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"19698-15523","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"X_train= X[0:15523]\ny_train = y[0:15523]\nX_test = X[:-3881]\ny_test = y[:-3881]\n#X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20)\ny_train.shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n#X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import sys\n#def random_forest_classifier(features, target):\n   #clf = RandomForestClassifier()\n    #clf.fit(features, target)\n   # return clf\n#clf = SVR(C=1.0, epsilon=0.2)\nclf = RandomForestRegressor(n_estimators=100, n_jobs= -1, min_samples_leaf=3, random_state=13)\n# Train the model on training data\nclf.fit(X_train, y_train)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#Build LSTM model\nmodel =Sequential()\nmodel.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nmodel.add(LSTM(50, return_sequences=False))\nmodel.add(Dense(5))\nmodel.add(Dense(1))"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBRegressor(n_estimators=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#Compile the model, because this is a binary classification problem, accuracy can be used\nmodel.compile(optimizer='Adam', loss= 'mean_squared_error')"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train) #,batch_size = 50, epochs= 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the forest's predict method on the test data\nprediction_s = model.predict(X_test)\n# Calculate the absolute errors\nerrors_s = abs(prediction_s - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors_s), 2), 'degrees.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors_s - y_test)\n#\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = model.score(X_test, y_test) #test Accuracy squared error for linreg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t = pd.read_csv('../input/covid19-global-forecasting-week-2/test.csv',index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t.drop(columns=['Province_State'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t['Country_Region'] = le.fit_transform(df_t['Country_Region'])\ndf_t['Date'] = le.fit_transform(df_t['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_t.drop(columns=['ForecastId'], inplace=True)\n#subt_data = np.array(df_t)\nsubt_data = scaler.fit_transform(df_t)\nsubt_data= np.array(subt_data)\nsubt_data = preprocessing.scale(subt_data)\n#subt_data  = np.reshape(subt_data, (subt_data.shape[0], subt_data.shape[1], 1))\nsubt_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_t = np.array(scaled_data)\n#t_scaled_data = scaler.fit_transform(df_t)\n#t_scaled_data = preprocessing.scale(df_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = model.predict(subt_data)\ntest_predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_predictions = test_predictions.reshape(12642,)\n#test_predictions = test_predictions.reshape(-1, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_predictions = scaler.inverse_transform(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#INVERSE TRANSFORM\n#test_predictions = test_predictions.reshape(12642,)\n#test_predictions_c = test_predictions* scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_predictions = test_predictions.reshape(12642,)\ntest_predictions = test_predictions_c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions_c.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.read_csv('../input/covid19-global-forecasting-week-2/submission.csv')\ndf_sub.drop(columns=['Fatalities','ConfirmedCases'], inplace=True)\n\nsave_file_c = pd.DataFrame(test_predictions_c, columns=[['ConfirmedCases']])\n\nresult_c = pd.merge(df_sub, save_file_c,left_index=True, right_index=True)\nresult_c.columns = ['ForecastId','ConfirmedCases']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_c = pd.merge(df_t,result_c ,on='ForecastId')\ndf_t.drop(columns=['Country_Region'], inplace=True)\n#result_c.drop(columns=['Country_Region_y','Country_Region_x'], inplace=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_c.set_index('ForecastId', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_c['ConfirmedCases'] = [0 if result_c.loc[i, 'ConfirmedCases'] <= -0 \n                                else result_c.loc[i, 'ConfirmedCases'] for i in result_c.index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fatalities X\nX = df_train.drop(columns=['Fatalities', ]) \nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(X) #t_scaled_data = preprocessing.scale(X)\nX= np.array(X)\nX = preprocessing.scale(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fatalities y\ny = df_train.drop(columns=['Date','Country_Region','ConfirmedCases'])\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(y)\ny = np.array(y)\ny = preprocessing.scale(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"X_train= X[0:15523]\ny_train = y[0:15523]\nX_test = X[:-3881]\ny_test = y[:-3881]"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#Build LSTM model\nmodel1 =Sequential()\nmodel1.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nmodel1.add(LSTM(50, return_sequences=False))\nmodel1.add(Dense(25))\nmodel1.add(Dense(1))"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = XGBRegressor(n_estimators=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compile the model, because this is a binary classification problem, accuracy can be used\n#model1.compile(optimizer='Adam', loss= 'mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(X_train, y_train)#, batch_size = 50, epochs= 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import sys\n#def random_forest_classifier(features, target):\n   #clf = RandomForestClassifier()\n    #clf.fit(features, target)\n   # return clf\n#clf1 = SVR(C=1.0, epsilon=0.2)\nclf1 = RandomForestRegressor(n_estimators=100, n_jobs= -1, min_samples_leaf=3, random_state=13)\n# Train the model on training data\nclf1.fit(X_train, y_train)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Use the forest's predict method on the test data\nprediction_s = clf1.predict(X_test)\n# Calculate the absolute errors\nerrors_s = abs(prediction_s - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors_s), 2), 'degrees.')"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors_s - y_test)\n#\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')\nrmse = np.sqrt(np.mean(prediction_s- y_test)**2)\nrmse"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"accuracy = clf1.score(X_test, y_test) \naccuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_c = result_c\ntrain_c = scaler.fit_transform(train_c)\ntrain_c= np.array(train_c)\ntrain_c = preprocessing.scale(train_c)\n#train_c  = np.reshape(train_c, (train_c.shape[0], train_c.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_f = model1.predict(train_c)\n#pred_f = pred_f.reshape(-1,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#INVERSE TRANSFORM\n#pred_f = pred_f*scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_f.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_file_f = pd.DataFrame(pred_f, columns=['Fatalities'])\nsave_file_f.index += 1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.merge(result_c, save_file_f, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#result.set_index('ForecastId', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#result= result[['ConfirmedCases','Fatalities']].round(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Fatalities'] = [0 if submission.loc[i, 'Fatalities'] < 0 \n                                else submission.loc[i, 'Fatalities'] for i in submission.index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #submission['ConfirmedCases'] = [0 if submission.loc[i, 'ConfirmedCases'] <= -0 \n             #                   else submission.loc[i, 'ConfirmedCases'] for i in submission.index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" submission.drop(columns=['Country_Region','Date'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" submission['Fatalities'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}