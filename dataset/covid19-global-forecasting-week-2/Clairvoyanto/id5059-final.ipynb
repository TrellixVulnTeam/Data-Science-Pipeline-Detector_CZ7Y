{"cells":[{"metadata":{},"cell_type":"markdown","source":"I confirm that this is my own work, except where clearly indicated.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load csv files into dataframe.\ndf_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')\ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')\ndf_submission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/submission.csv')\ndf_countryinfo = pd.read_csv('/kaggle/input/countryinfo/covid19countryinfo.csv')\ndf_lockdown = pd.read_csv('/kaggle/input/covid19-lockdown-dates-by-country/countryLockdowndates.csv')\ndf_testdates = pd.read_csv('/kaggle/input/covid19-tests-conducted-by-country/TestsConducted_AllDates_11May2020.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert to standard datatypes\n\ndf_train['Date'] = pd.to_datetime(df_train['Date'], format='%Y-%m-%d', errors='coerce')\ndf_test['Date'] = pd.to_datetime(df_test['Date'], format='%Y-%m-%d', errors='coerce')\ndf_lockdown['Date'] = pd.to_datetime(df_lockdown['Date'], format='%d/%m/%Y', errors='coerce')\n\nmonthReplace = {'Feb' : '02', 'Mar' : '03', 'Apr' : '04', 'May' : '05'}\ndf_testdates['Date'] = df_testdates['Date'].replace(' ', '-', regex=True)\ndf_testdates['Date'] = df_testdates['Date'].replace(monthReplace, regex=True)\ndf_testdates['Date'] = df_testdates['Date'].astype(str) + '-2020'\n\ndf_testdates['Date'] = pd.to_datetime(df_testdates['Date'], format='%d-%m-%Y', errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove columns\ndf_lockdown = df_lockdown.drop(columns=['Reference'])\ndf_testdates = df_testdates.drop(columns=['Source_1', 'Source_2', 'FileDate', 'Units', 'Tested', 'Positive'])\n\n#Select country population info for further merging\ndf_selectedinfo = pd.DataFrame(df_countryinfo, columns=['region', 'country', 'pop', 'density', 'medianage', 'urbanpop'])\ndf_selectedinfo['region'].fillna('', inplace=True)\ndf_selectedinfo = df_selectedinfo.dropna()\ndf_selectedinfo['geo'] = ['_'.join(x) for x in zip(df_selectedinfo['country'], df_selectedinfo['region'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concat primary key\ndf_train['Province_State'].fillna('', inplace=True)\ndf_train['geo'] = ['_'.join(x) for x in zip(df_train['Country_Region'], df_train['Province_State'])]\ndf_train = df_train.drop(columns=['Province_State'])\n\ndf_lockdown['Province'].fillna('', inplace=True)\ndf_lockdown['geo'] = ['_'.join(x) for x in zip(df_lockdown['Country/Region'], df_lockdown['Province'])]\ndf_lockdown = df_lockdown.drop(columns=['Province'])\n\ndf_test['Province_State'].fillna('', inplace=True)\ndf_test['geo'] = ['_'.join(x) for x in zip(df_test['Country_Region'], df_test['Province_State'])]\ndf_test = df_test.drop(columns=['Province_State'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge train data with lockdown data\n\ndf_merged = df_train.merge(df_lockdown,on=[\"geo\"],how=\"left\")\ndf_merged['Lockdown_length'] = df_merged['Date_x'] - df_merged['Date_y']\n\ndf_merged = df_merged.drop(columns=['Country/Region'])\ndf_merged = df_merged.rename(columns={'Date_x': 'Date', 'Date_y': 'Lockdown_Date'})\n\n#From testing, 210 instances' country are missing in lockdown data\n\ndf_merged_test = df_test.merge(df_lockdown,on=[\"geo\"],how=\"left\")\ndf_merged_test['Lockdown_length'] = df_merged_test['Date_x'] - df_merged_test['Date_y']\n\ndf_merged_test = df_merged_test.drop(columns=['Country/Region'])\ndf_merged_test = df_merged_test.rename(columns={'Date_x': 'Date', 'Date_y': 'Lockdown_Date'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge pop info for each country\ndf_merged1 = df_merged.merge(df_selectedinfo,on=[\"geo\"],how=\"left\")\ndf_merged1 = df_merged1.drop(columns=['country', 'region'])\ndf_merged1 = df_merged1.rename(columns={'Country_Region': 'country'})\n\n#Merge pop info for test set\ndf_merged_test1 = df_merged_test.merge(df_selectedinfo,on=[\"geo\"],how=\"left\")\ndf_merged_test1 = df_merged_test1.drop(columns=['country', 'region'])\ndf_merged_test1 = df_merged_test1.rename(columns={'Country_Region': 'country'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge countries general info for those doesn't provide province info\n#df_merged2 = df_merged1.merge(df_selectedinfo, how='left', left_on=['Country_Region'], right_on=['country'])\n\ndf_merged2 = df_merged1.merge(df_selectedinfo.drop_duplicates('country'),how='left',on='country')\n\n#Merge country info for test set\ndf_merged_test2 = df_merged_test1.merge(df_selectedinfo.drop_duplicates('country'),how='left',on='country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_info(geo_x,geo_y, info_x, info_y):\n    if geo_x == geo_y:\n        return info_x\n    else:\n        return info_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def retype_lockdown(lock_type, lock_date, current_date):\n  if lock_date > current_date:\n    return \"Before\"\n  else:\n    return lock_type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged2['pop'] = df_merged2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['pop_x'], x['pop_y']),axis=1)\ndf_merged2['density'] = df_merged2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['density_x'], x['density_y']),axis=1)\ndf_merged2['medianage'] = df_merged2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['medianage_x'], x['medianage_y']),axis=1)\ndf_merged2['urbanpop'] = df_merged2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['urbanpop_x'], x['urbanpop_y']),axis=1)\n\ndf_merged2 = df_merged2.drop(columns=['pop_x', 'pop_y', 'density_x', 'density_y', 'medianage_x', 'medianage_y', 'urbanpop_x', 'urbanpop_y', 'geo_y', 'region'])\ndf_merged2 = df_merged2.rename(columns={'geo_x': 'geo'})\n\ndf_merged2['Type'] = df_merged2.apply(lambda x: retype_lockdown(x['Type'], x['Lockdown_Date'], x['Date']),axis=1)\n\n\n#Reformat test data\ndf_merged_test2['pop'] = df_merged_test2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['pop_x'], x['pop_y']),axis=1)\ndf_merged_test2['density'] = df_merged_test2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['density_x'], x['density_y']),axis=1)\ndf_merged_test2['medianage'] = df_merged_test2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['medianage_x'], x['medianage_y']),axis=1)\ndf_merged_test2['urbanpop'] = df_merged_test2.apply(lambda x: custom_info(x['geo_x'],x['geo_y'], x['urbanpop_x'], x['urbanpop_y']),axis=1)\n\ndf_merged_test2 = df_merged_test2.drop(columns=['pop_x', 'pop_y', 'density_x', 'density_y', 'medianage_x', 'medianage_y', 'urbanpop_x', 'urbanpop_y', 'geo_y', 'region'])\ndf_merged_test2 = df_merged_test2.rename(columns={'geo_x': 'geo'})\n\ndf_merged_test2['Type'] = df_merged_test2.apply(lambda x: retype_lockdown(x['Type'], x['Lockdown_Date'], x['Date']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_x = df_merged2\ndf_testx = df_merged_test2\n\n#Reformat population data\ndf_x['pop'] = df_x['pop'].str.replace(',', '').astype(float)\ndf_x['Lockdown_length'] = df_x['Lockdown_length'].astype('timedelta64[D]')\n\nstart = df_x['Date'].min()\ndf_x['Date_length'] = df_x['Date'] - start\ndf_x['Date_length'] = df_x['Date_length'].astype('timedelta64[D]')\ndf_x = df_x.drop(columns=['Lockdown_Date', 'Date'])\n\n\n#Reformat for test set\ndf_testx['pop'] = df_testx['pop'].str.replace(',', '').astype(float)\ndf_testx['Lockdown_length'] = df_testx['Lockdown_length'].astype('timedelta64[D]')\n\ndf_testx['Date_length'] = df_testx['Date'] - start\ndf_testx['Date_length'] = df_testx['Date_length'].astype('timedelta64[D]')\ndf_testx = df_testx.drop(columns=['Lockdown_Date', 'Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OneHotEncoding\ndf_x = pd.get_dummies(df_x, columns=['Type'])\ndf_testx = pd.get_dummies(df_testx, columns=['Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Factorize country and geo\ntestdf = pd.concat([df_x, df_testx])\ntestdf['country'] = pd.factorize(testdf['country'])[0]\ntestdf['geo'] = pd.factorize(testdf['geo'])[0]\n\ndf1 = testdf[0:20580]\ndf2 = testdf[20580:]\n\ndf1 = df1.drop(columns=['ForecastId'])\ndf2 = df2.drop(columns=['Id', 'ConfirmedCases', 'Fatalities'])\n\ntrain_id = df1['Id']\ndf_y = pd.DataFrame(df1, columns=['ConfirmedCases', 'Fatalities'])\ndf_x = df1.drop(columns=['Id', 'ConfirmedCases', 'Fatalities'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_x['missing'] = df_x.apply(lambda x: x.isna().sum(), axis=1)\n\ndf_x['Lockdown_length'].fillna(0, inplace=True)\ndf_x['pop'].fillna(-1, inplace=True)\ndf_x['pop'].fillna(-1, inplace=True)\ndf_x['density'].fillna(-1, inplace=True)\ndf_x['medianage'].fillna(-1, inplace=True)\ndf_x['urbanpop'].fillna(-1, inplace=True)\n\n# for test set\ndf2['missing'] = df2.apply(lambda x: x.isna().sum(), axis=1)\ndf2['Lockdown_length'].fillna(0, inplace=True)\ndf2['pop'].fillna(-1, inplace=True)\ndf2['pop'].fillna(-1, inplace=True)\ndf2['density'].fillna(-1, inplace=True)\ndf2['medianage'].fillna(-1, inplace=True)\ndf2['urbanpop'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Regressors\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RidgeCV\n\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom skimage.io import imshow\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.multioutput import MultiOutputRegressor\n\nESTIMATORS = {\n    \"K-nn\": KNeighborsRegressor(),\n    \"Ridge\": RidgeCV(),\n    \"Lasso\": Lasso(),\n    \"ElasticNet\": ElasticNet(random_state=1),\n    \"RandomForestRegressor\": RandomForestRegressor(),\n    \"Decision Tree Regressor\":DecisionTreeRegressor(max_depth=5),\n    \"MultiO/P GBR\" :MultiOutputRegressor(GradientBoostingRegressor(n_estimators=5)),\n    \"MultiO/P AdaB\" :MultiOutputRegressor(AdaBoostRegressor(n_estimators=5))\n}\n  \n\ny_test_predict = dict()\ny_mse = dict()\n\nfor name, estimator in ESTIMATORS.items():     \n    estimator.fit(X_train, y_train)                    # fit() with instantiated object\n    y_test_predict[name] = estimator.predict(X_test)   # Make predictions and save it in dict under key: name\n    y_mse[name] = RMSLE(estimator.predict(X_test), y_test)\n    print('RMSE for ',name,' is ',y_mse[name])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multioutput import RegressorChain\n# define model\nmodel = KNeighborsRegressor()\nwrapper = RegressorChain(model)\n# fit model\nwrapper.fit(X_train, y_train)\n# make a prediction\nyhat = wrapper.predict(X_test)\n# evaluate prediction\nRMSLE(yhat, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nmodel = MultiOutputRegressor(xgb.XGBRegressor()).fit(X_train, y_train)\ny_test_predict1 = model.predict(X_test)\ny_mse1 = RMSLE(y_test_predict1, y_test)\nprint('RMSE for is ',y_mse1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nin_dim = X_train.shape[1]\nout_dim = y_train.shape[1]\n\n#add layers\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=in_dim, activation=\"relu\"))\nmodel.add(Dense(32, activation=\"relu\"))\nmodel.add(Dense(out_dim))\nmodel.compile(loss=\"mse\", optimizer=\"adam\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs=100, batch_size=12, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred = model.predict(X_test)\nmse = RMSLE(ypred, y_test)\nprint(\"RMSLE for MLP:\", mse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = df2['ForecastId']\nx_mytest = df2.drop(columns=['ForecastId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor()\n# fit model\nmodel.fit(X_train, y_train)\n# make a prediction\nyhat = model.predict(x_mytest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df_submission.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_yhat = pd.DataFrame(yhat, columns=['ConfirmedCases', 'Fatalities'])\nsubmission['ConfirmedCases'] = df_yhat['ConfirmedCases']\nsubmission['Fatalities'] = df_yhat['Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}