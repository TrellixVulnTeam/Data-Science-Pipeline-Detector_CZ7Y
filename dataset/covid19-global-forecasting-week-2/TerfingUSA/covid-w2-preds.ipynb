{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project 3 - 140001742\n\nI confirm that this is my own work, except where clearly indicated.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Import","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import in all the data sets I will be using for this model creation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_main = pd.read_csv(\"../input/corona/train (1).csv\", header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First ensure the province/state column is consistently filled\ndata_main['Province_State'].fillna('', inplace=True)\n#now change the date into datetime for ease of analysis\ndata_main['Date'] = pd.to_datetime(data_main['Date'])\n#add new column DayOfYear stating which day of the year it is, this is as we do not want any data ater March 31st (the 91st day of the year)\ndata_main['DOY'] = data_main.Date.dt.dayofyear\n#the submission must be given in terms of cumulative values of cases and deaths so the data set will be transformed to mirror this.\ndata_main[['ConfirmedCases','Fatalities']]=data_main.groupby(['Country_Region', 'Province_State'])[['ConfirmedCases', 'Fatalities']].transform('cummax')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_info = pd.read_csv(\"../input/corona/covid19countryinfo.csv\", header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_info['region'].fillna('', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lockdown = pd.read_csv(\"../input/corona/countryLockdowndates.csv\", header=0)\ndata_lockdown['Date'] = pd.to_datetime(data_lockdown['Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I need to condense all of this information into one data table. \nFirst I will merge data_main with data_info, as data_main is the data set from the kaggle competition and so is necessary whilst data_info contains a wide range of information about each country and region.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new1 = pd.merge(data_main, data_info, how='left', left_on=['Country_Region', 'Province_State'], right_on=['country', 'region'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To check that this merge was done correctly I will compare the dimensions of each of the datasets. If the merge was implemented correctly then the new dataset should have the same number of rows as data_main (20580) and the number of columns should be equal to data_main columns + data_info columns = 67.\n\nNext I want to also include the Lockdown information from data_lockdown, so I will merge this with data_new1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new2 = pd.merge(data_new1, data_lockdown, how='left', left_on=['Country_Region', 'Province_State', 'Date'], right_on=['Country/Region', 'Province', 'Date'])\n# note in this new data set the column Type denotes the type of lockdown, this value changes on the date on which Lockdown was introduced for that specific country/region.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again the merge can be checked by simply viewing the dimensions of the new dataset, data_new2 contains the same number of rows as data_new1, but contains 4 new columns; country/region, province, type, reference.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Preparing the Data\n\nNow that I have merged the different datasets to create data_new2 I will clean this data so that it is ready for model creation.\n\nThere are a lot of superfluous columns in this dataset (due to the merging process) and so I will drop those columns to reduce the size of the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new2.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns to drop:\n\n\n\n*   region\n*   country\n*   alpha3code\n*   alpha2code\n*   active1\n*   active2\n*   active3\n*   newcases1\n*   newcases2\n*   newcases3\n*   newdeaths1\n*   newdeaths2\n*   newdeaths3\n*   critical1\n*   critical2\n*   critical3\n*   Country/Region\n*   Province\n*   Reference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"coldrop = ['region', 'country', 'alpha3code', 'alpha2code', 'active1', 'active2', 'active3', 'newcases1', 'newcases2', 'newcases3', 'newdeaths1', 'newdeaths2', 'newdeaths3', 'critical1', 'critical2', 'critical3', 'Country/Region', 'Province', 'Reference']\ndata_new2.drop(coldrop, inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This has reduced the dataset to 52 columns, 49 of which are possible variables for the model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n\n## NAs\n\nLooking at the latest printout from data_new2.info() it is clear that there are many null cells in the dataset, otherwise the value in the non-null column would be 20580. I do not want NAs in the dataset so I will replace them with a 0 instead.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new2.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DateTime\n\nFirst I want to transform all of the variables that describe a date to the datetime format as this will ease the modelling process. I have already changed the Date column but there are others from the datasets which were merged.\n\nThose variables are:\n\n\n*   quarantine\n*   schools\n*   publicplace\n*   gathering\n*   nonessential\n*   firstcase","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new2['quarantine'] = pd.to_datetime(data_new2['quarantine'])\ndata_new2['schools'] = pd.to_datetime(data_new2['schools'])\ndata_new2['publicplace'] = pd.to_datetime(data_new2['publicplace'])\ndata_new2['gathering'] = pd.to_datetime(data_new2['gathering'])\ndata_new2['nonessential'] = pd.to_datetime(data_new2['nonessential'])\ndata_new2['firstcase'] = pd.to_datetime(data_new2['firstcase'])\n\n# Now change each to day of year format for ease of modelling.\n\ndata_new2['quarantine'] = data_new2.quarantine.dt.dayofyear\ndata_new2['schools'] = data_new2.schools.dt.dayofyear\ndata_new2['publicplace'] = data_new2.publicplace.dt.dayofyear\ndata_new2['gathering'] = data_new2.gathering.dt.dayofyear\ndata_new2['nonessential'] = data_new2.nonessential.dt.dayofyear\ndata_new2['firstcase'] = data_new2.firstcase.dt.dayofyear\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Location Variable\n\nAs the location is a combination of two columns; 'Country_Region' and 'Province_State', I will combine these two to create a single variable called 'Location'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new2['Location'] = data_new2.Country_Region.astype(str) + \":\" + data_new2.Province_State.astype(str)\n\n# Now drop the two columns 'Country_Region' and 'Province_State'\n\ndata_new2.drop('Country_Region', inplace=True, axis=1)\ndata_new2.drop('Province_State', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting objects to float64","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"objcols = ['pop', 'tests', 'testpop', 'density', 'medianage', 'urbanpop', 'gatheringlimit', 'hospibed', 'smokers', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'sexratio', 'lung', 'femalelung', 'malelung', 'gdp2019', 'healthexp', 'healthperpop', 'fertility', 'avgtemp', 'avghumidity', 'totalcases', 'active30', 'active31', 'deaths', 'newdeaths30', 'newdeaths31', 'recovered', 'critical30', 'critical31', 'casediv1m', 'deathdiv1m', 'Type', 'Location', 'newcases30', 'newcases31']\nfor i in objcols:\n  data_new2[i] = pd.to_numeric(data_new2[i], errors='coerce')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NAs again","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new2.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring the Variables\n\nFor the models we are making we have two target variables: 'ConfirmedCases' and 'Fatalities'.\nWhich variables will be used as features for the model will now have to be decided.\nI will create a correlation matrix to see if any of the variables stand out as being related to either of the target variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = data_new2.corr()\ncorr_matrix['ConfirmedCases'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix['Fatalities'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix.to_csv('corrr.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at these correlation matrices the variables I will begin my modeling process with will be\n\nConfirmedCases:\n\n*   newdeaths31\n*   newdeaths30\n*   tests\n*   quarantine\n*   firstcase\n*   deathdiv1m\n\n\n\nFatalities:\n\n*   newdeaths31\n*   newdeaths30\n*   tests\n*   deathdiv1m\n*   quarantine\n*   nonessential\n\n\nBoth of these will also contain 'DOY', 'Id' and 'Location'.\n\nFor my modelling process I will tackle each of the target variables individually.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CCfeatures = ['Location', 'DOY', 'Id', 'newdeaths31', 'newdeaths30', 'tests', 'quarantine', 'firstcase', 'deathdiv1m']\nCCtarget = ['ConfirmedCases']\nFfeatures = ['Location', 'DOY', 'Id', 'newdeaths31', 'newdeaths30', 'tests', 'deathdiv1m', 'quarantine', 'nonessential']\nFtarget = ['Fatalities']\n\nyCC = data_new2.loc[:,CCtarget]\nyF = data_new2.loc[:,Ftarget]\nxCC = data_new2.loc[:,CCfeatures]\nxF = data_new2.loc[:,Ffeatures]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting into Training and Validation Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxCC_train,xCC_test,yCC_train,yCC_test=train_test_split(xCC,yCC,test_size=0.2, random_state = 140001742)\nxF_train,xF_test,yF_train,yF_test=train_test_split(xF,yF,test_size=0.2, random_state = 140001742)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Models\n\n## ConfirmedCases\n\n### Model 1 - Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(xCC_train, yCC_train)\n\n# Now to check the validity of the model\n\nlin_predictions = lin_reg.predict(xCC_test)\n\nfrom sklearn.metrics import mean_squared_error\nlin_mse = mean_squared_error(lin_predictions, yCC_test)\nlin_rmse = np.sqrt(lin_mse)\nprint(\"MSE: %d\" % lin_mse, end=\"\\n\")\nprint(\"RMSE: %d\" % lin_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 2 - Random Forest Regressor Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr_reg = RandomForestRegressor()\nrfr_reg.fit(xCC_train, yCC_train)\n\n# Check validity\n\nrfr_predictions = rfr_reg.predict(xCC_test)\n\nrfr_mse = mean_squared_error(yCC_test, rfr_predictions)\nrfr_rmse = np.sqrt(rfr_mse)\nprint(\"MSE: %d\" % rfr_mse, end=\"\\n\")\nprint(\"RMSE: %d\" % rfr_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 3 - Decision Tree Regressor Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(xCC_train, yCC_train)\n\n# Now to check the validity of the model\n\ndtr_predictions = tree_reg.predict(xCC_test)\n\ndtr_mse = mean_squared_error(yCC_test, dtr_predictions)\ndtr_rmse = np.sqrt(dtr_mse)\nprint(\"MSE: %d\" % dtr_mse, end=\"\\n\")\nprint(\"RMSE: %d\" % dtr_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 4 - Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math as math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nranforclas = RandomForestClassifier(random_state=140001742)\nranforclas.fit(xCC_train, yCC_train)\n\n# Now to check the validity of the model\n\nranforclas_predictions = ranforclas.predict(xCC_test)\n\nrfc_mse = mean_squared_error(yCC_test, ranforclas_predictions)\nrfc_rmse = math.sqrt(rfc_mse)\nprint(\"MSE: %d\" % rfc_mse, end=\"\\n\")\nprint(\"RMSE: %d\" % rfc_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Out of these four models the third (Decision Tree Regressor Model) has the lowest RMSE score and so provides the best predictions from the four models available. This will be the model used to predict the ConfirmedCases variable for the test data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Fatalities \n\n### Model 1 - Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg1 = LinearRegression()\nlin_reg1.fit(xF_train, yF_train)\n\n# check validity\n\nlin_predictions1 = lin_reg1.predict(xF_test)\n\nlin_mse1 = mean_squared_error(lin_predictions1, yF_test)\nlin_rmse1 = np.sqrt(lin_mse1)\nprint(\"MSE: %d\" % lin_mse1, end=\"\\n\")\nprint(\"RMSE: %d\" % lin_rmse1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 2 - Random Forest Regressor Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_reg1 = RandomForestRegressor()\nrfr_reg1.fit(xF_train, yF_train)\n\n# check validity\n\nrfr_predictions1 = rfr_reg1.predict(xF_test)\n\nrfr_mse1 = mean_squared_error(yF_test, rfr_predictions1)\nrfr_rmse1 = np.sqrt(rfr_mse1)\nprint(\"MSE: %d\" % rfr_mse1, end=\"\\n\")\nprint(\"RMSE: %d\" % rfr_rmse1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 3 - Decision Tree Regressor Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_reg1 = DecisionTreeRegressor()\ntree_reg1.fit(xF_train, yF_train)\n\n# Check Validity\n\ndtr_predictions1 = tree_reg1.predict(xF_test)\n\ndtr_mse1 = mean_squared_error(yF_test, dtr_predictions1)\ndtr_rmse1 = np.sqrt(dtr_mse1)\nprint(\"MSE: %d\" % dtr_mse1, end=\"\\n\")\nprint(\"RMSE: %d\" % dtr_rmse1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 4 - Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ranforclas1 = RandomForestClassifier(random_state=140001742)\nranforclas1.fit(xF_train, yF_train)\n\n# Check Validity\n\nranforclas_predictions1 = ranforclas1.predict(xF_test)\n\nrfc_mse1 = mean_squared_error(yF_test, ranforclas_predictions1)\nrfc_rmse1 = math.sqrt(rfr_mse1)\nprint(\"MSE: %d\" % rfc_mse1, end=\"\\n\")\nprint(\"RMSE: %d\" % rfc_rmse1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of these four models two (2 and 4) share an RMSE of 25, the lowest of the models. This suggests that both models provide a similar standard of predictions. The model chosen for predicting Fatalities is model two Random Forest Regressor Model, this is because it ran substantially faster than model 4 and as they provide similar predictions it is more efficient to select the faster model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Test Data\n\n## Prepare the test Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.read_csv(\"../input/corona/test (1).csv\", header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test['Province_State'].fillna('', inplace=True)\ndata_test['Date'] = pd.to_datetime(data_test['Date'])\ndata_test['DOY'] = data_test.Date.dt.dayofyear\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge with the other data sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test1 = pd.merge(data_test, data_info, how='left', left_on=['Country_Region', 'Province_State'], right_on=['country', 'region'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test1['Date'] = pd.to_datetime(data_test1['Date'])\ndata_test1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lockdown['Date'] = pd.to_datetime(data_lockdown['Date'])\ndata_test2 = pd.merge(data_test1, data_lockdown, how='left', left_on=['Country_Region', 'Province_State', 'Date'], right_on=['Country/Region', 'Province', 'Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test2.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test2['quarantine'] = pd.to_datetime(data_test2['quarantine'])\ndata_test2['quarantine'] = data_test2.quarantine.dt.dayofyear\ndata_test2['nonessential'] = pd.to_datetime(data_test2['nonessential'])\ndata_test2['firstcase'] = pd.to_datetime(data_test2['firstcase'])\ndata_test2['nonessential'] = data_test2.nonessential.dt.dayofyear\ndata_test2['firstcase'] = data_test2.firstcase.dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test2['Location'] = data_test2.Country_Region.astype(str) + \":\" + data_test2.Province_State.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"objcols = ['pop', 'tests', 'testpop', 'density', 'medianage', 'urbanpop', 'gatheringlimit', 'hospibed', 'smokers', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'sexratio', 'lung', 'femalelung', 'malelung', 'gdp2019', 'healthexp', 'healthperpop', 'fertility', 'avgtemp', 'avghumidity', 'totalcases', 'active30', 'active31', 'deaths', 'newdeaths30', 'newdeaths31', 'recovered', 'critical30', 'critical31', 'casediv1m', 'deathdiv1m', 'Type', 'Location', 'newcases30', 'newcases31']\nfor i in objcols:\n  data_test2[i] = pd.to_numeric(data_new2[i], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test2.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CCfeatures = ['Location', 'DOY', 'ForecastId', 'newdeaths31', 'newdeaths30', 'tests', 'quarantine', 'firstcase', 'deathdiv1m']\nFfeatures = ['Location', 'DOY', 'ForecastId', 'newdeaths31', 'newdeaths30', 'tests', 'deathdiv1m', 'quarantine', 'nonessential']\nXCC = data_test2.loc[:,CCfeatures]\nXF = data_test2.loc[:,Ffeatures]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions_CC = tree_reg.predict(XCC)\nfinal_predictions_F = rfr_reg1.predict(XF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"My_Preds = pd.DataFrame(data_test['ForecastId'])\nMy_Preds['ConfirmedCases'] = final_predictions_CC\nMy_Preds['Fatalities'] = final_predictions_F\n\nprint(My_Preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"My_Preds.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}