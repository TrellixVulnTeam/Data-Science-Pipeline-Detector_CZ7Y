{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime as dt\nfrom sklearn import preprocessing\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import SGDRegressor\nimport lightgbm as lgb\nimport statistics as s\nfrom sklearn.model_selection import cross_validate\nfrom tqdm import tqdm\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.head())\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def date_processor(string):\n    string = dt.strptime(string, '%Y-%m-%d').date()\n#     print(type(string.toordinal()))\n    return string.toordinal()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'] = train['Date'].apply(date_processor)\n# train.drop(['Province_State'], axis=1, inplace = True)\ntest['Date'] = test['Date'].apply(date_processor)\n# test.drop(['Province_State'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.set_index('Id', inplace=True)\n# test.set_index('ForecastId', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.rename(columns={\n    'Country_Region' : 'cr',\n    'Province_State' : 'ps',\n    'Fatalities' : 'dead',\n    'ConfirmedCases' : 'cases',\n    'Date' : 'date',\n})\ntest = test.rename(columns={\n    'Country_Region' : 'cr',\n    'Province_State' : 'ps',\n    'Date' : 'date',\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.head()\nprint(type(train.ps.iloc[0]) == float)\n# train.ps.iloc[0] == None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(set(train.cr) == set(test.cr))\nprint(set(train.ps) == set(test.ps))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_state(state ,country):\n    if type(state) == float:\n        return country\n    else:\n        return state","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.ps = train.loc[:,['ps','cr']].apply(lambda x: fill_state(x['ps'],x['cr']), axis = 1)\ntest.ps = test.loc[:,['ps','cr']].apply(lambda x: fill_state(x['ps'],x['cr']), axis = 1)\ndisplay(train.head())\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ntrain.cr = le.fit_transform(train.cr)\ntest.cr = le.fit_transform(test.cr)\nle_state = preprocessing.LabelEncoder()\ntrain.ps = le.fit_transform(train.ps)\ntest.ps = le.fit_transform(test.ps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.date = train.date / max(train.date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.get_dummies(train, columns = train.columns[1:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = pd.get_dummies(train, columns = train.columns[1:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test = pd.get_dummies(test, columns = test.columns[1:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.columns)\nprint(submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = list(train.cr.unique())\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\ndf_out2 = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nscore_mean_t1 = []\nscore_mean_t2 = []\n\nCV = 5\nN_ESTIMATORS = 500\n\nsgd = DecisionTreeRegressor()\nrf = RandomForestRegressor(n_estimators = N_ESTIMATORS)\nmodels = [sgd]\nfor model in models:\n    for c in tqdm(countries,position=0, leave=True):\n        states = train.loc[train.cr == c, :].ps.unique()\n        for s in states:\n            train_data = train.loc[(train.ps==s) & (train.cr==c),['ps','cr','date']] \n            train_data = pd.get_dummies(train_data, columns = train_data.columns[1:4])\n            t1 = train.loc[(train.ps==s) & (train.cr==c),'cases']\n            t2 = train.loc[(train.ps==s) & (train.cr==c),'dead']\n\n            test_data  = test.loc[(test.ps==s) & (test.cr==c),['ps','cr','date']]\n            ids = test.loc[(test.ps==s) & (test.cr==c),'ForecastId']\n            test_data = pd.get_dummies(test_data,  columns = test.columns[1:2])\n            model1 = model\n#             cv_result = cross_validate(model1, train_data, t1, scoring = 'r2', cv= CV)\n#             print(\"CV Test Score : Mean : %.7g\" % (np.mean(cv_result['test_score'])))\n#             score_mean_t1.append(np.mean(cv_result['test_score']))\n\n            model1.fit(train_data, t1)\n            t1_pred = model1.predict(test_data)\n\n            model2 = model\n#             cv_result = cross_validate(model2, train_data, t2,scoring = 'r2', cv= CV)\n#             print(\"CV Test Score : Mean : %.7g\" % (np.mean(cv_result['test_score'])))\n#             score_mean_t2.append(np.mean(cv_result['test_score']))\n            model2.fit(train_data,t2)\n            t2_pred = model2.predict(test_data)\n\n            # LightGBM\n    #         model3 = lgb.LGBMRegressor(n_estimators=2000)\n    #         model3.fit(train_data, t1)\n    #         t3_pred = model3.predict(test_data)\n\n    #         model4 = lgb.LGBMRegressor(n_estimators=2000)\n    #         model4.fit(train_data, t2)\n    #         t4_pred = model4.predict(test_data)\n\n            df = pd.DataFrame({'ForecastId': ids, 'ConfirmedCases': t1_pred, 'Fatalities': t2_pred})\n    #         df2 = pd.DataFrame({'ForecastId': ids, 'ConfirmedCases': t3_pred, 'Fatalities': t4_pred})\n            df_out = pd.concat([df_out, df], axis=0)\n    #         df_out2 = pd.concat([df_out2, df2], axis=0)\n    print(\"T1 mean test score for : \",model, \"is :\" , np.mean(score_mean_t1))\n    print(\"T1 mean test score for : \",model, \"is :\" , np.mean(score_mean_t2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries[161:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.ForecastId = df_out.ForecastId.astype('int')\n# df_out2.ForecastId = df_out2.ForecastId.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_out['ConfirmedCases'] = (1/2)*(df_out['ConfirmedCases'] + df_out2['ConfirmedCases'])\n# df_out['Fatalities'] = (1/2)*(df_out['Fatalities'] + df_out2['Fatalities'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out['ConfirmedCases'] = df_out['ConfirmedCases'].round().astype(int)\ndf_out['Fatalities'] = df_out['Fatalities'].round().astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_out.shape)\ndf_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}