{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\")\ntrain['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forecast with BayesianRidge"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n#for country in ['New Zealand']:\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 10):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        model = make_pipeline(PolynomialFeatures(2), BayesianRidge())\n        model.fit(adjusted_X_train,adjusted_y_train_confirmed)                \n        y_hat_confirmed = model.predict(adjusted_X_pred)\n                \n        model.fit(adjusted_X_train,adjusted_y_train_fatalities)                \n        y_hat_fatalities = model.predict(adjusted_X_pred)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        pred_data['ConfirmedCases_hat'] = np.concatenate((np.repeat(0, len(pred_data) - len(y_hat_confirmed)), y_hat_confirmed), axis = 0)\n        pred_data['Fatalities_hat'] = np.concatenate((np.repeat(float(0), len(pred_data) - len(y_hat_fatalities)), y_hat_fatalities), axis = 0) \n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_score = []\nfor country in df_val['Country_Region'].unique():\n    df_val_country = df_val[(df_val['Country_Region'] == country) & (df_val['Fatalities'].isnull() == False)]\n    val_score.append([country, RMSLE(df_val_country['ConfirmedCases'].values,df_val_country['ConfirmedCases_hat'].values),RMSLE(df_val_country['Fatalities'].values,df_val_country['Fatalities_hat'].values)])\n    \ndf_val_score = pd.DataFrame(val_score) \ndf_val_score.columns = ['Country','ConfirmedCases_Scored','Fatalities_Scored']\ndf_val_score.sort_values('ConfirmedCases_Scored', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"country = \"Vietnam\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_now = train.groupby(['Date','Country_Region']).sum().reset_index().sort_values('Date').groupby('Country_Region').apply(lambda group: group.iloc[-1:])\ndf_now = df_now.sort_values('ConfirmedCases', ascending = False)\n\nfig = go.Figure()\nfor country in df_now.sort_values('ConfirmedCases', ascending=False).head(5)['Country_Region'].values:\n    df_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\n    idx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\n    fig.add_trace(go.Scatter(x=df_country['Date'][0:idx],y= df_country['ConfirmedCases'][0:idx], name = country))\n    fig.add_trace(go.Scatter(x=df_country['Date'],y= df_country['ConfirmedCases_hat'], name = country + ' forecast'))\nfig.update_layout(title_text='Top 5 ConfirmedCases forecast')\nfig.show()\n\nfig = go.Figure()\nfor country in df_now.sort_values('Fatalities', ascending=False).head(5)['Country_Region'].values:\n    df_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\n    idx = df_country[((df_country['Fatalities'].isnull() == False) & (df_country['Fatalities'] > 0))].shape[0]\n    fig.add_trace(go.Scatter(x=df_country['Date'][0:idx],y= df_country['Fatalities'][0:idx], name = country))\n    fig.add_trace(go.Scatter(x=df_country['Date'],y= df_country['Fatalities_hat'], name = country + ' forecast'))\nfig.update_layout(title_text='Top 5 Fatalities forecast')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_now = df_now.sort_values('ConfirmedCases', ascending = False)\nfig = make_subplots(rows = 1, cols = 2)\nfig.add_bar(x=df_now['Country_Region'].head(10), y = df_now['ConfirmedCases'].head(10), row=1, col=1, name = 'Total cases')\ndf_now = df_now.sort_values('Fatalities', ascending=False)\nfig.add_bar(x=df_now['Country_Region'].head(10), y = df_now['Fatalities'].head(10), row=1, col=2, name = 'Total Fatalities')\nfig.update_layout(title_text='Top 10 Country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Alternative version"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n#for country in ['Vietnam']:\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        #The number of day forcast\n        #pred_data[pred_data['Date'] > max_train_date].shape[0]\n        #model = SimpleExpSmoothing(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True, damped=True).fit()\n        model = ExponentialSmoothing(adjusted_y_train_confirmed, trend = 'additive').fit()\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        #model = Holt(adjusted_y_train_fatalities).fit()\n        model = ExponentialSmoothing(adjusted_y_train_fatalities, trend = 'additive').fit()\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = \"Vietnam\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}