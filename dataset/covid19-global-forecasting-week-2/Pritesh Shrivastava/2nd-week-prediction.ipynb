{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:47.659285Z","start_time":"2020-03-22T06:54:46.887611Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# from pandas_profiling import ProfileReport\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:47.708301Z","start_time":"2020-03-22T06:54:47.660259Z"},"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')\nsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:47.737261Z","start_time":"2020-03-22T06:54:47.70926Z"},"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:47.751246Z","start_time":"2020-03-22T06:54:47.73923Z"},"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:47.781225Z","start_time":"2020-03-22T06:54:47.777228Z"},"trusted":true},"cell_type":"code","source":"# train_profile = ProfileReport(train, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# train_profile","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:47.786246Z","start_time":"2020-03-22T06:54:47.783231Z"},"trusted":true},"cell_type":"code","source":"# test_profile = ProfileReport(test, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# test_profile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\npy.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Disease spread over the countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby(['Date', 'Country_Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m/%d/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country_Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale=\"greens\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confirmed cases over time"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = train.groupby('Date')['Date', 'ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases Over Time\")\nfig.show()\n\nfig = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases (Logarithmic Scale) Over Time\", \n              log_y=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest_grouped = train.groupby('Country_Region')['ConfirmedCases', 'Fatalities'].sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(latest_grouped.sort_values('ConfirmedCases', ascending=False)[:20][::-1], \n             x='ConfirmedCases', y='Country_Region',\n             title='Confirmed Cases Worldwide', text='ConfirmedCases', height=1000, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take a look at Europe"},{"metadata":{"trusted":true},"cell_type":"code","source":"europe = list(['Austria','Belgium','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Ireland',\n               'Italy', 'Latvia','Luxembourg','Lithuania','Malta','Norway','Netherlands','Poland','Portugal','Romania','Slovakia','Slovenia',\n               'Spain', 'Sweden', 'United Kingdom', 'Iceland', 'Russia', 'Switzerland', 'Serbia', 'Ukraine', 'Belarus',\n               'Albania', 'Bosnia and Herzegovina', 'Kosovo', 'Moldova', 'Montenegro', 'North Macedonia'])\neurope_grouped_latest = latest_grouped[latest_grouped['Country_Region'].isin(europe)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train[train['Country_Region'].isin(europe)]\ntemp = temp.groupby(['Date', 'Country_Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m/%d/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country_Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],scope='europe',\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale='Cividis_r')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(europe_grouped_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Country_Region', color_discrete_sequence=['#84DCC6'],\n             title='Confirmed Cases in Europe', text='ConfirmedCases', orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### take a look at US"},{"metadata":{"trusted":true},"cell_type":"code","source":"usa = train[train['Country_Region'] == \"US\"]\nusa_latest = usa[usa['Date'] == max(usa['Date'])]\nusa_latest = usa_latest.groupby('Province_State')['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = px.bar(usa_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Province_State', color_discrete_sequence=['#D63230'],\n             title='Confirmed Cases in USA', text='ConfirmedCases', orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### take a look at China"},{"metadata":{"trusted":true},"cell_type":"code","source":"ch = train[train['Country_Region'] == \"China\"]\nch = ch[ch['Date'] == max(ch['Date'])]\nch = ch.groupby('Province_State')['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = px.bar(ch.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Province_State', color_discrete_sequence=['#D63230'],\n             title='Confirmed Cases in china', text='ConfirmedCases', orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding Categorical Data\n\n1. Province Encoding\n2. Country Encoding\n3. Date Encoding\n4. Extra Dataset\n5. Missing Value Imputation"},{"metadata":{},"cell_type":"markdown","source":"### Province Encoding\nProvince is a string-type object in the dataset. To take advantage of them, we convert Province to a numeric index as shown below. `province_encoded` collects all states in the training data. Specially, `nan` cells indicate to index `0` avoiding missing data."},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.019227Z","start_time":"2020-03-22T06:54:49.011227Z"},"trusted":true},"cell_type":"code","source":"province_encoded = {state:index for index, state in enumerate(train['Province_State'].unique())}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.047236Z","start_time":"2020-03-22T06:54:49.021228Z"},"trusted":true},"cell_type":"code","source":"train['province_encoded'] = train['Province_State'].apply(lambda x: province_encoded[x])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Country Encoding"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.056227Z","start_time":"2020-03-22T06:54:49.050234Z"},"trusted":true},"cell_type":"code","source":"country_encoded = dict(enumerate(train['Country_Region'].unique()))\ncountry_encoded = dict(map(reversed, country_encoded.items()))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.082226Z","start_time":"2020-03-22T06:54:49.05823Z"},"trusted":true},"cell_type":"code","source":"train['country_encoded'] = train['Country_Region'].apply(lambda x: country_encoded[x])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date Encoding: sequential timestamp (poor design)"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.088228Z","start_time":"2020-03-22T06:54:49.083232Z"},"trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport time","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.09523Z","start_time":"2020-03-22T06:54:49.090228Z"},"trusted":true},"cell_type":"code","source":"# date_encoded = {}\n# for s in train['Date'].unique():\n#     date_encoded[s] = time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple())","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.104231Z","start_time":"2020-03-22T06:54:49.100233Z"},"trusted":true},"cell_type":"code","source":"# train['date_encoded'] = train['Date'].apply(lambda x: date_encoded[x])\n# train['date_encoded'] = (train['date_encoded'] - train['date_encoded'].mean()) / train['date_encoded'].std()\n# train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date encoding: convert `y-m-d`  to Month.and Day."},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.140228Z","start_time":"2020-03-22T06:54:49.107228Z"},"trusted":true},"cell_type":"code","source":"train['Mon'] = train['Date'].apply(lambda x: int(x.split('-')[1]))\ntrain['Day'] = train['Date'].apply(lambda x: int(x.split('-')[2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date encoding: enhance by serial fetures (poor design)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['serial'] = train['Mon'] * 30 + train['Day']\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['serial'] = train['serial'] - train['serial'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extra Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"gdp2020 = pd.read_csv('/kaggle/input/gdp2020/GDP2020.csv')\npopulation2020 = pd.read_csv('/kaggle/input/population2020/population2020.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gdp2020 = gdp2020.rename(columns={\"rank\":\"rank_gdp\"})\ngdp2020_numeric_list = [list(gdp2020)[0]] + list(gdp2020)[2:-1]\ngdp2020.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Redefine all mismatch Country "},{"metadata":{"trusted":true},"cell_type":"code","source":"map_state = {'US':'United States', \n             'Korea, South':'South Korea',\n             'Cote d\\'Ivoire':'Ivory Coast',\n             'Czechia':'Czech Republic',\n             'Eswatini':'Swaziland',\n             'Holy See':'Vatican City',\n             'Jersey':'United Kingdom',\n             'North Macedonia':'Macedonia',\n             'Taiwan*':'Taiwan',\n             'occupied Palestinian territory':'Palestine'\n            }\nmap_state_rev = {v: k for k, v in map_state.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population2020['name'] = population2020['name'].apply(lambda x: map_state_rev[x] if x in map_state_rev else x)\ngdp2020['country'] = gdp2020['country'].apply(lambda x: map_state_rev[x] if x in map_state_rev else x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Losing Country in Population"},{"metadata":{"trusted":true},"cell_type":"code","source":"set(train['Country_Region']) - set(population2020['name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Losing Country in GDP2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"set(train['Country_Region']) - set(gdp2020['country'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population2020 = population2020.rename(columns={\"rank\":\"rank_pop\"})\npopulation2020_numeric_list = [list(population2020)[0]] + list(gdp2020)[2:]\npopulation2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\ntrain = pd.merge(train, gdp2020, how='left', left_on = 'Country_Region', right_on = 'country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Nan cells or repalce them to more suitable values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Set extra attributes to zero"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate the numeric input for training"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.17923Z","start_time":"2020-03-22T06:54:49.173231Z"},"trusted":true},"cell_type":"code","source":"# numeric_features_X = ['Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day']\nnumeric_features_X = ['province_encoded' ,'country_encoded','Mon','Day'] + population2020_numeric_list + gdp2020_numeric_list\nnumeric_features_Y = ['ConfirmedCases', 'Fatalities']\ntrain_numeric_X = train[numeric_features_X]\ntrain_numeric_Y = train[numeric_features_Y]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate the numeric input for testing "},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.328227Z","start_time":"2020-03-22T06:54:49.317227Z"},"trusted":true},"cell_type":"code","source":"test['province_encoded'] = test['Province_State'].apply(lambda x: province_encoded[x] if x in province_encoded else max(province_encoded.values())+1)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.342225Z","start_time":"2020-03-22T06:54:49.330229Z"},"trusted":true},"cell_type":"code","source":"test['country_encoded'] = test['Country_Region'].apply(lambda x: country_encoded[x] if x in country_encoded else max(country_encoded.values())+1)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.373223Z","start_time":"2020-03-22T06:54:49.344231Z"},"trusted":true},"cell_type":"code","source":"test['Mon'] = test['Date'].apply(lambda x: int(x.split('-')[1]))\ntest['Day'] = test['Date'].apply(lambda x: int(x.split('-')[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['serial'] = test['Mon'] * 30 + test['Day']\ntest['serial'] = test['serial'] - test['serial'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.merge(test, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\ntest = pd.merge(test, gdp2020, how='left', left_on = 'Country_Region', right_on = 'country')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.379229Z","start_time":"2020-03-22T06:54:49.374226Z"},"trusted":true},"cell_type":"code","source":"# date_encoded = {}\n# for s in test['Date'].unique():\n#     date_encoded[s] = time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple())\n# test['date_encoded'] = test['Date'].apply(lambda x: date_encoded[x])\n# test['date_encoded'] = (test['date_encoded'] - test['date_encoded'].mean()) / test['date_encoded'].std()\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.406227Z","start_time":"2020-03-22T06:54:49.394226Z"},"trusted":true},"cell_type":"code","source":"# test.loc[:,'Lat'][test['Country/Region']=='Aruba'] = -69.9683\n# test.loc[:,'Long'][test['Country/Region']=='Aruba'] = 12.5211","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.417227Z","start_time":"2020-03-22T06:54:49.408228Z"},"trusted":true},"cell_type":"code","source":"test_numeric_X = test[numeric_features_X]\ntest_numeric_X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_numeric_X = test_numeric_X.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\n#### Single Model \n1. Linear Regression\n2. SVM Regression\n3. KNN \n\n#### Ensemble \n1. Random Forest\n2. Adaboost \n\n#### SIR Model"},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.272227Z","start_time":"2020-03-22T06:54:49.181228Z"},"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.316226Z","start_time":"2020-03-22T06:54:49.27423Z"},"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([('scaler', StandardScaler()), ('lr', LinearRegression())])\npipeline.fit(train_numeric_X, train_numeric_Y)\npredicted = pipeline.predict(test_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = go.Figure()\n\n# Make traces for graph\ntrace1 = go.Bar(x=train_numeric_X.columns, y=pipeline['lr'].coef_[0], xaxis='x2', yaxis='y2',\n                marker=dict(color='#0099ff'),\n                name='ConfirmedCases')\ntrace2 = go.Bar(x=train_numeric_X.columns, y=pipeline['lr'].coef_[1], xaxis='x2', yaxis='y2',\n                marker=dict(color='#404040'),\n                name='Fatalities')\n\n# Add trace data to figure\nfig.add_traces([trace1, trace2])\n\nfig.update_layout(\n    title_text='LR trainable weights', # title of plot\n    xaxis_title_text='feature', # xaxis label\n    yaxis_title_text='weight', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n# Plot!\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.436226Z","start_time":"2020-03-22T06:54:49.430225Z"},"trusted":true},"cell_type":"code","source":"# submission = np.vstack((test['ForecastId'], predicted[:,0],predicted[:,1])).T\n# submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('LR_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVR"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:49.792228Z","start_time":"2020-03-22T06:54:49.788228Z"},"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:54:57.708228Z","start_time":"2020-03-22T06:54:49.79423Z"},"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', SVR())])\npipeline.fit(train_numeric_X, train_numeric_Y.values[:,0])\npipeline2 = Pipeline([('scaler', StandardScaler()), ('estimator', SVR())])\npipeline2.fit(train_numeric_X, train_numeric_Y.values[:,1])\ndiscovered, fatal = pipeline.predict(test_numeric_X), pipeline2.predict(test_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:04.409228Z","start_time":"2020-03-22T06:55:04.403258Z"},"trusted":true},"cell_type":"code","source":"# submission = np.vstack((test['ForecastId'], discovered, fatal)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('SVR_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_x1 =  pipeline.predict(train_numeric_X)\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x=train_numeric_Y['ConfirmedCases'],\n    histnorm='percent',\n    name='actual discovered', # name used in legend and hover labels\n    xbins=dict( # bins used for histogram\n        start=-4.0,\n        end=3.0,\n        size=0.5\n    ),\n    opacity=0.75\n))\nfig.add_trace(go.Histogram(\n    x=predicted_x1,\n    histnorm='percent',\n    name='predicted discovered',\n    xbins=dict(\n        start=-3.0,\n        end=4,\n        size=0.5\n    ),\n    opacity=0.75\n))\n\nfig.update_layout(\n    title_text='SVR Histogram of ConfirmedCases', # title of plot\n    xaxis_title_text='bins', # xaxis label\n    yaxis_title_text='ConfirmedCases', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_x2 =  pipeline2.predict(train_numeric_X)\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x=train_numeric_Y['Fatalities'],\n    histnorm='percent',\n    name='actual died', # name used in legend and hover labels\n    xbins=dict( # bins used for histogram\n        start=-4.0,\n        end=3.0,\n        size=0.5\n    ),\n    opacity=0.75\n))\nfig.add_trace(go.Histogram(\n    x=predicted_x2,\n    histnorm='percent',\n    name='predicted died',\n    xbins=dict(\n        start=-3.0,\n        end=4,\n        size=0.5\n    ),\n    opacity=0.75\n))\n\nfig.update_layout(\n    title_text='SVR Histogram of Fatalities', # title of plot\n    xaxis_title_text='bins', # xaxis label\n    yaxis_title_text='Fatalities', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\noutcomes = []\n    \nfold = 0\nfor train_index, test_index in kf.split(train_numeric_X):\n    fold += 1\n    X_train, X_test = train_numeric_X.values[train_index], train_numeric_X.values[test_index]\n    y_train, y_test = train_numeric_Y['ConfirmedCases'].values[train_index], train_numeric_Y['ConfirmedCases'].values[test_index]\n    pipeline.fit(X_train, y_train)\n    predictions = RF_model.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \nmean_outcome = np.mean(outcomes)\nprint(\"\\n\\nMean Accuracy: {0}\".format(mean_outcome)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', KNeighborsClassifier(n_jobs=4))])\npipeline.fit(train_numeric_X, train_numeric_Y)\npredicted_x = pipeline.predict(train_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=train_numeric_Y['ConfirmedCases'],\n    y=train_numeric_Y['Fatalities'],\n    marker=dict(color=\"crimson\", size=12),\n    mode=\"markers\",\n    name=\"actual\",\n))\n\nfig.add_trace(go.Scatter(\n    x=predicted_x[:,0],\n    y=predicted_x[:,1],\n    marker=dict(color=\"lightseagreen\", size=8),\n    mode=\"markers\",\n    name=\"predicted\",\n))\n\nfig.update_layout(title=\"RF result\",\n                  xaxis_title=\"ConfirmedCases\",\n                  yaxis_title=\"Fatalities\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\noutcomes = []\n    \nfold = 0\nfor train_index, test_index in kf.split(train_numeric_X):\n    fold += 1\n    X_train, X_test = train_numeric_X.values[train_index], train_numeric_X.values[test_index]\n    y_train, y_test = train_numeric_Y['ConfirmedCases'].values[train_index], train_numeric_Y['ConfirmedCases'].values[test_index]\n    pipeline.fit(X_train, y_train)\n    predictions = RF_model.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \nmean_outcome = np.mean(outcomes)\nprint(\"\\n\\nMean Accuracy: {0}\".format(mean_outcome)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble"},{"metadata":{},"cell_type":"markdown","source":"### Bagging: Random Forest"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:04.51029Z","start_time":"2020-03-22T06:55:04.452228Z"},"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:11.51829Z","start_time":"2020-03-22T06:55:04.512226Z"},"trusted":true},"cell_type":"code","source":"RF_model = RandomForestClassifier(n_estimators=50, n_jobs=4, max_depth=5)\nRF_model.fit(train_numeric_X, train_numeric_Y)\npredicted = RF_model.predict(test_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:21.559264Z","start_time":"2020-03-22T06:55:11.525283Z"},"trusted":true},"cell_type":"code","source":"# submission = np.vstack((test['ForecastId'], predicted[:,0],predicted[:,1])).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('RF_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_x = RF_model.predict(train_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = go.Figure()\n# fig.add_trace(go.Scatter(\n#     x=train_numeric_Y['ConfirmedCases'],\n#     y=train_numeric_Y['Fatalities'],\n#     marker=dict(color=\"crimson\", size=12),\n#     mode=\"markers\",\n#     name=\"actual\",\n# ))\n\n# fig.add_trace(go.Scatter(\n#     x=predicted_x[:,0],\n#     y=predicted_x[:,1],\n#     marker=dict(color=\"lightseagreen\", size=8),\n#     mode=\"markers\",\n#     name=\"predicted\",\n# ))\n\n# fig.update_layout(title=\"RF result\",\n#                   xaxis_title=\"ConfirmedCases\",\n#                   yaxis_title=\"Fatalities\")\n\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x=train_numeric_Y['ConfirmedCases'],\n    histnorm='percent',\n    name='actual discovered', # name used in legend and hover labels\n    xbins=dict( # bins used for histogram\n        start=-4.0,\n        end=3.0,\n        size=0.5\n    ),\n    opacity=0.75\n))\nfig.add_trace(go.Histogram(\n    x=predicted_x[:,0],\n    histnorm='percent',\n    name='predicted discovered',\n    xbins=dict(\n        start=-3.0,\n        end=4,\n        size=0.5\n    ),\n    opacity=0.75\n))\n\nfig.update_layout(\n    title_text='RF Histogram of ConfirmedCases', # title of plot\n    xaxis_title_text='bins', # xaxis label\n    yaxis_title_text='ConfirmedCases', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import make_scorer, accuracy_score\naccuracy_score(train_numeric_Y['ConfirmedCases'], predicted_x[:,0]), accuracy_score(train_numeric_Y['Fatalities'], predicted_x[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" from sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\noutcomes = []\n    \nfold = 0\nfor train_index, test_index in kf.split(train_numeric_X):\n    fold += 1\n    X_train, X_test = train_numeric_X.values[train_index], train_numeric_X.values[test_index]\n    y_train, y_test = train_numeric_Y['ConfirmedCases'].values[train_index], train_numeric_Y['ConfirmedCases'].values[test_index]\n    RF_model.fit(X_train, y_train)\n    predictions = RF_model.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \nmean_outcome = np.mean(outcomes)\nprint(\"\\n\\nMean Accuracy: {0}\".format(mean_outcome)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Boosting: Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adaboost_model_for_ConfirmedCases = AdaBoostClassifier(n_estimators=5)\nadaboost_model_for_ConfirmedCases.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[0]])\nadaboost_model_for_Fatalities = AdaBoostClassifier(n_estimators=5)\nadaboost_model_for_Fatalities.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted = adaboost_model_for_ConfirmedCases.predict(test_numeric_X)\n# predicted2 = adaboost_model_for_Fatalities.predict(test_numeric_X)\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('Adaboost_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_x1 = adaboost_model_for_ConfirmedCases.predict(train_numeric_X)\npredicted_x2 = adaboost_model_for_Fatalities.predict(train_numeric_X)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=train_numeric_Y['ConfirmedCases'],\n    y=train_numeric_Y['Fatalities'],\n    marker=dict(color=\"crimson\", size=12),\n    mode=\"markers\",\n    name=\"actual\",\n))\n\nfig.add_trace(go.Scatter(\n    x=predicted_x1,\n    y=predicted_x2,\n    marker=dict(color=\"lightseagreen\", size=8),\n    mode=\"markers\",\n    name=\"predicted\",\n))\n\nfig.update_layout(title=\"ADB result\",\n                  xaxis_title=\"ConfirmedCases\",\n                  yaxis_title=\"Fatalities\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stacking"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import StackingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# estimators = [('rf',RF_model ), ('ada', adaboost_model_for_ConfirmedCases)]\n# stacking_model_for_ConfirmedCases = StackingClassifier(estimators=estimators, n_jobs=4)\n# stacking_model_for_ConfirmedCases.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stacking_model_for_Fatalities = StackingClassifier(estimators=estimators, n_jobs=4)\n# stacking_model_for_Fatalities.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted = stacking_model_for_ConfirmedCases.predict(test_numeric_X)\n# predicted2 = stacking_model_for_Fatalities.predict(test_numeric_X)\n\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('stacking_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic Model Comparasion"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.naive_bayes import GaussianNB \n# from sklearn.linear_model import LogisticRegression\n# from sklearn import model_selection\n# from mlxtend.classifier import StackingCVClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1 = KNeighborsClassifier(n_neighbors=100)\n# clf2 = RandomForestClassifier(n_estimators=5)\n# clf3 = GaussianNB()\n# # Logit will be used for stacking\n# lr = LogisticRegression(solver='lbfgs')\n# # sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr, use_probas=True, cv=3)\n# sclf = StackingCVClassifier(classifiers=[clf1, clf2], meta_classifier=lr, use_probas=True, cv=3)\n\n\n# # Do CV\n# for clf, label in zip([clf1, clf2, clf3, sclf], \n#                       ['KNN', \n#                        'Random Forest', \n#                        'Naive Bayes',\n#                        'StackingClassifier']):\n\n#     scores = model_selection.cross_val_score(clf, train_numeric_X.values, train_numeric_Y[numeric_features_Y[0]].values, cv=3, scoring='neg_mean_squared_log_error')\n#     print(\"Avg_rmse: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- KNN: -6.54\n- Random Forest: -6.90\n- Naive Bayes: -25.89\n- StackingClassifier: -4.76"},{"metadata":{},"cell_type":"markdown","source":"### After Model Comparing, here provide an optimal result "},{"metadata":{},"cell_type":"markdown","source":"- KNN attains the better performance than others w.r.t. Fatalities\n- RF attains the better performance than others w.r.t. ConfirmedCases"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1 = KNeighborsClassifier(n_neighbors=100)\n# clf1.fit(train_numeric_X.values, train_numeric_Y[numeric_features_Y[1]])\n# predicted2 = clf1.predict(test_numeric_X)\n\n# clf2 = RandomForestClassifier(n_estimators=10)\n# clf2.fit(train_numeric_X.values, train_numeric_Y[numeric_features_Y[0]])\n# predicted = clf2.predict(test_numeric_X)\n\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('opt_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SIR Model (Not yet)"},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:36.083258Z","start_time":"2020-03-22T06:55:21.561251Z"},"trusted":true},"cell_type":"code","source":"train_y_pred = RF_model.predict(train_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_y_pred2 = clf2.predict(train_numeric_X)\n# train_y_pred =  np.stack((train_y_pred, train_y_pred2), axis=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Actual Value v.s. Predicted Results"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:36.73826Z","start_time":"2020-03-22T06:55:36.085227Z"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.hist([train_numeric_Y['ConfirmedCases'],train_y_pred[:,0]],bins=100, range=(1,100), label=['ConfirmedCases_actual','ConfirmedCases_pred'],alpha=0.75)\nplt.title('ConfirmedCases Comparison',fontsize=20)\nplt.xlabel('sample',fontsize=20)\nplt.ylabel('match',fontsize=20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:37.361228Z","start_time":"2020-03-22T06:55:36.740227Z"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.hist([train_numeric_Y['Fatalities'],train_y_pred[:,1]],bins=100, range=(1,100), label=['Fatalities_actual','Fatalities_pred'],alpha=0.75)\nplt.title('Fatalities Comparison',fontsize=20)\nplt.xlabel('sample',fontsize=20)\nplt.ylabel('match',fontsize=20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Root Mean Square Error\n\n> Submissions are evaluated using the column-wise root mean squared logarithmic error."},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:37.370259Z","start_time":"2020-03-22T06:55:37.363228Z"},"trusted":true},"cell_type":"code","source":"error = np.sqrt((train_y_pred - train_numeric_Y)**2)\nerror = error.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:37.680228Z","start_time":"2020-03-22T06:55:37.372228Z"},"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\n \nplt.xlabel('sample')\nplt.ylabel('error')\nplt.subplot(2, 1, 1)\nplt.plot(range(len(error)), error['ConfirmedCases'], \"x-\",label=\"ConfirmedCases\",color='orange')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(range(len(error)), error['Fatalities'], \"+-\", label=\"Fatalities\")\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:37.699226Z","start_time":"2020-03-22T06:55:37.682231Z"},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nrmse = mean_squared_error(train_numeric_Y, train_y_pred , squared=False)\nrmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Visualization"},{"metadata":{},"cell_type":"markdown","source":"#### Pearson"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:38.117228Z","start_time":"2020-03-22T06:55:37.701231Z"},"trusted":true},"cell_type":"code","source":"corr = train[numeric_features_X+numeric_features_Y].corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Spearman"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:38.471227Z","start_time":"2020-03-22T06:55:38.119226Z"},"trusted":true},"cell_type":"code","source":"corr = train[numeric_features_X+numeric_features_Y].corr(method='spearman')\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Kendall"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:38.907227Z","start_time":"2020-03-22T06:55:38.474231Z"},"trusted":true},"cell_type":"code","source":"corr = train[numeric_features_X+numeric_features_Y].corr(method='kendall')\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Weights"},{"metadata":{},"cell_type":"markdown","source":"Parameter weights corresponding to `'Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day'`"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:39.026226Z","start_time":"2020-03-22T06:55:38.913228Z"},"trusted":true},"cell_type":"code","source":"RF_model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:39.283254Z","start_time":"2020-03-22T06:55:39.030229Z"},"trusted":true},"cell_type":"code","source":"plt.bar(range(len(numeric_features_X)), RF_model.feature_importances_, tick_label=numeric_features_X)\nplt.xlabel('feature')\nplt.ylabel('weight')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Scatter Data points "},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T06:55:39.707255Z","start_time":"2020-03-22T06:55:39.286232Z"},"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots()\nax.scatter(train_numeric_Y['ConfirmedCases'], train_y_pred[:,0])\nax.scatter(train_numeric_Y['Fatalities'], train_y_pred[:,1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Look into the number of decision tree composed of RF"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1 = RandomForestClassifier(n_estimators=1,n_jobs=4)\n# clf3 = RandomForestClassifier(n_estimators=3,n_jobs=4)\n# clf5 = RandomForestClassifier(n_estimators=5,n_jobs=4)\n# clf10 = RandomForestClassifier(n_estimators=10,n_jobs=4)\n# clf50 = RandomForestClassifier(n_estimators=50,n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1.fit(train_numeric_X, train_numeric_Y)\n# clf3.fit(train_numeric_X, train_numeric_Y)\n# clf5.fit(train_numeric_X, train_numeric_Y)\n# clf10.fit(train_numeric_X, train_numeric_Y)\n# clf50.fit(train_numeric_X, train_numeric_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted1 = clf1.predict(train_numeric_X)\n# predicted3 = clf3.predict(train_numeric_X)\n# predicted5 = clf5.predict(train_numeric_X)\n# predicted10 = clf10.predict(train_numeric_X)\n# predicted50 = clf50.predict(train_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a = np.sum((predicted1) - (train_numeric_Y))**2 / len(predicted1)\n# b = np.sum((predicted3) - (train_numeric_Y))**2 / len(predicted3)\n# c = np.sum((predicted5) - (train_numeric_Y))**2 / len(predicted5)\n# d = np.sum((predicted10) - (train_numeric_Y))**2 / len(predicted10)\n# e = np.sum((predicted50) - (train_numeric_Y))**2 / len(predicted50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dt_nums = [1,3,5,10,50]\n# plt.figure(figsize=(15,10))\n\n# plt.subplot(221)\n# plt.title('Decision Tree Number & MSE \\n of ConfirmedCases',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['ConfirmedCases'],b['ConfirmedCases'],c['ConfirmedCases'],d['ConfirmedCases'],e['ConfirmedCases']],\n#          label='ConfirmedCases')\n# plt.xlabel('decision tree numbers')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.subplot(222)\n# plt.title('Decision Tree Number & MSE \\n of Fatalities',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['Fatalities'],b['Fatalities'],c['Fatalities'],d['Fatalities'],e['Fatalities']],\n#          label='Fatalities',color='y')\n# plt.xlabel('decision tree numbers')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above diagram demostrated that with about 5 decision tree, RF had been enough good to fit in our dataset "},{"metadata":{},"cell_type":"markdown","source":"### Look into the depth of decision tree composed of RF - Avoiding Overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=1)\n# clf2 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=2)\n# clf3 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=3)\n# clf4 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=4)\n# clf5 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=5)\n# clf10 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1.fit(train_numeric_X, train_numeric_Y)\n# clf2.fit(train_numeric_X, train_numeric_Y)\n# clf3.fit(train_numeric_X, train_numeric_Y)\n# clf4.fit(train_numeric_X, train_numeric_Y)\n# clf5.fit(train_numeric_X, train_numeric_Y)\n# clf10.fit(train_numeric_X, train_numeric_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted1 = clf1.predict(train_numeric_X)\n# predicted2 = clf2.predict(train_numeric_X)\n# predicted3 = clf3.predict(train_numeric_X)\n# predicted4 = clf4.predict(train_numeric_X)\n# predicted5 = clf5.predict(train_numeric_X)\n# predicted10 = clf10.predict(train_numeric_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a = np.sum((predicted1) - (train_numeric_Y))**2 / len(predicted1)\n# b = np.sum((predicted2) - (train_numeric_Y))**2 / len(predicted2)\n# c = np.sum((predicted3) - (train_numeric_Y))**2 / len(predicted3)\n# d = np.sum((predicted4) - (train_numeric_Y))**2 / len(predicted4)\n# e = np.sum((predicted5) - (train_numeric_Y))**2 / len(predicted5)\n# f = np.sum((predicted10) - (train_numeric_Y))**2 / len(predicted10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dt_nums = [1,2,3,4,5,10]\n# plt.figure(figsize=(15,10))\n\n# plt.subplot(221)\n# plt.title('Decision Tree Depth & MSE \\n of ConfirmedCases',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['ConfirmedCases'],b['ConfirmedCases'],c['ConfirmedCases'],d['ConfirmedCases'],e['ConfirmedCases'],f['ConfirmedCases']],\n#          label='ConfirmedCases')\n# plt.xlabel('decision tree depth')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.subplot(222)\n# plt.title('Decision Tree Depth & MSE \\n of Fatalities',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['Fatalities'],b['Fatalities'],c['Fatalities'],d['Fatalities'],e['Fatalities'],f['ConfirmedCases']],\n#          label='Fatalities',color='y')\n# plt.xlabel('decision tree depth')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The deeper depth gets the lower mse in confirmedCases but the higher fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":4}