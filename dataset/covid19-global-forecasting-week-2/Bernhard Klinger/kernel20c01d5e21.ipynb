{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Linear regression baseline for the COVID 19 Global Forecasting Challenge Week 2\n\n#### Data import\n\nThe external data for the submission has been derived from some of the World Development Indicators from the World Bank Open Data (Population, GDP and health spending). You can find the full dateset and licence here: https://www.kaggle.com/theworldbank/world-development-indicators"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom datetime import datetime\n\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\")\ntrain.columns = [\"Id\",\"Prov\",\"Ctry\",\"Date\",\"Cases\",\"Death\"]\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ntest.columns = [\"Id\",\"Prov\",\"Ctry\",\"Date\"]\ntest[\"Cases\"]=0\ntest[\"Death\"]=0\ntrain[\"Date\"]= pd.to_datetime(train.Date,infer_datetime_format=True)\ntest[\"Date\"]= pd.to_datetime(test.Date,infer_datetime_format=True)\nworld = pd.read_csv(\"/kaggle/input/corona-wb/WorldBankData.csv\")\npop = pd.read_csv(\"/kaggle/input/coronawb/Population.csv\")\nsample_sub = pd.read_csv(\"../input/covid19-global-forecasting-week-2/submission.csv\")\nold_cols = sample_sub.columns\nsample_sub.columns=[\"Id\",\"Case\",\"Death\"]\nmysub=sample_sub.set_index('Id')\n\ntrain[\"Test\"]=0\ntest[\"Test\"]=1\n\nX_full = pd.concat((train[train.Date < \"2020-03-19\"], test[test.Date > \"2020-03-18\"]),sort=True).reset_index(drop=True)\n\nX_full[\"Reg\"]=X_full[\"Ctry\"]+X_full[\"Prov\"].fillna(\"None\")\npop[\"Reg\"]=pop[\"Ctry\"]+pop[\"Prov\"].fillna(\"None\")\n\nX_full= X_full.merge(world, on=[\"Ctry\"],how=\"left\")\nX_full= X_full.merge(pop[[\"Pop\",\"Reg\"]], on=[\"Reg\"],how=\"left\")\n\nX_full.loc[:,\"GDPPerc\"]= X_full.GDPPerc.astype(\"float\")\nX_full.loc[:,\"GDPperCapita\"]= X_full.GDPperCapita.astype(\"float\")\n    \nX_full.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit linear regression model "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\ndef model_fit(model,X,target_col,folds=3):\n    \n    kf = KFold(folds, shuffle=True, random_state=4991)\n    \n    drop_cols = set(X.columns).intersection({\"Test\",\"Id\",\"Cases\",\"Death\",\"LogD\",\"Day\",\"Week\",\"Date\",\"Prov\",\"FirstDate\",\"DayYear\",\"Sub\",\"Ctry\",\"Pop\",target_col})\n    \n    # create predictors for each region\n    \n    X_r=X\n    X_r =pd.get_dummies(X.copy(),columns=[\"Reg\"])\n                \n    for col in X_r.columns:\n        if col[:4]== \"Reg_\":\n            reg = col[4:]\n            if X.loc[(X.Reg==reg) & (X.DayYear == 85),\"Cases\"].mean() > 500:\n                X_r[col+\"1\"]=X_r[\"Week1\"]*X_r[col]\n                X_r[col+\"2\"]=X_r[\"Week2\"]*X_r[col]\n                X_r[col+\"3\"]=X_r[\"Week3\"]*X_r[col]\n                          \n    \n    # add interactions with health spending indictors\n    # the relationship is very weak but I have kept the features in the model for now\n    \n    inter_features ={\"DollarPPP\",\"GDPPerc\",\"Week1\",\"Week2\",\"Week3\",\"Age65Perc\",\"GDPperCapita\"}.difference(set(drop_cols)).intersection(set(X.columns)) \n    poly = PolynomialFeatures(interaction_only=True,include_bias=False) \n    inter_cols = poly.fit_transform(X[inter_features])\n    X1= pd.DataFrame(inter_cols,columns= poly.get_feature_names(list(inter_features)),index=X.index)                            \n    X_r = pd.concat([X1,X_r.drop(columns=inter_features)],axis=1)\n    \n    X_train = X_r[X_r.Test==0].drop(columns=drop_cols).copy()\n    \n    y_train = X.loc[X_r.Test==0,target_col]\n    model.fit(X_train,y_train)\n    X[\"Pred\"] = np.maximum(model.predict(X_r.drop(columns=drop_cols)),0)\n    X[\"Res\"]= X.Pred-X[target_col]\n    score = (-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))**0.5\n    \n    return X, score\n\n\nmodel =Ridge(alpha=0.01,random_state=35591,max_iter=10000,fit_intercept=True,normalize=True)\ngraph = []\n\n# separate predictions for public and private leaderboard (i.e. remove values post 3/18 from public submission)\n\nfor loop in [\"Public\",\"Private\"]:\n    \n    X_all=X_full.copy()\n    if loop == \"Public\":\n        start=78 # last day of train data \n        val_end=91 # end date for validation data (public submission only )\n        sub_start=79\n        sub_end=92\n        X_all.loc[:,\"Test\"] = (X_all.Date > \"2020-03-18\") *1\n        \n    else:\n        start=91\n        sub_start=93\n        sub_end=999\n        X_all.loc[:,\"Test\"] = (X_all.Date > \"2020-03-31\") *1 \n        val_end=88\n    X_all.loc[(X_all.Date > \"2020-03-18\") & (X_all.Date < \"2020-04-01\"),\"Cases\"]=train.loc[train.Date > \"2020-03-18\",\"Cases\"].values\n    X_all.loc[(X_all.Date > \"2020-03-18\") & (X_all.Date < \"2020-04-01\"),\"Death\"]=train.loc[train.Date > \"2020-03-18\",\"Death\"].values\n    \n    # start day for eac region predection = first day with 5+ cases\n    X_reg= X_all[~((X_all.Test ==0) & (X_all.Cases < 5))].copy()\n    X_reg[\"Date\"]= pd.to_datetime(X_reg.Date,infer_datetime_format=True)\n    first_p_map= X_reg[[\"Reg\",\"Date\"]].groupby(\"Reg\").min().to_dict()[\"Date\"]\n    X_reg[\"FirstDate\"]=X_reg[\"Reg\"].map(first_p_map)\n    \n    X_reg[\"Day\"]=(X_reg.Date-X_reg.FirstDate).dt.days\n    X_reg[\"Week\"]=X_reg.Day/7\n    \n    X_reg[\"DayYear\"]=X_reg.Date.dt.dayofyear\n    \n    X_reg[\"LogC\"]= np.log(X_reg.Cases+1)\n    X_reg[\"LogD\"]= np.log(X_reg.Death+1)\n    X_reg[\"LogPop\"]=np.log(X_reg.Pop+1)\n\n    X_reg[\"Week1\"]=np.tanh((X_reg.Week)/10)\n    X_reg[\"Week2\"]=np.tanh((X_reg.Week)/10*2)\n    X_reg[\"Week3\"]=np.tanh((X_reg.Week)/10*4)\n    X_reg[\"Week4\"]=np.tanh((X_reg.Week-1)/10)\n    X_reg[\"Week5\"]=np.tanh((X_reg.Week-2)/10)\n    X_reg[\"Week6\"]=np.tanh((X_reg.Week-4)/10)\n   \n    \n    X_reg[\"Sub\"]=loop\n    \n    X= X_reg.copy()\n    print(\"Last day of year for train\",start,\": \",X.loc[X.DayYear== start,\"Date\"].min())\n    print(\"First day of year for test\",start+1,\": \",X.loc[X.Test == 1,\"Date\"].min())\n    \n    startint= 60 # fit data from start of March only\n    \n    # fit model to log of cases to align with evaluation metric\n    \n    X_res, score = model_fit(model,X.loc[(X.DayYear >= startint)].copy(),\"LogC\")\n    X.loc[(X.DayYear >= startint),\"PredC\"]=np.exp(X_res.Pred)-1\n    \n    print(\"\\nCV score: \",score,\"\\nMean: {:.4f} Std: {:.4f}\\n\".format(score.mean(), score.std()))\n    \n    # Scale predicted cases to the number of cases on final day of the train data \n    # Derive the mortality rate based on deaths and predicted cases at the final day in the train data\n    \n    maptab = pd.DataFrame(None,index=list(set(X.Reg)))\n    maptab[\"CaseScaler\"]=0\n    maptab[\"MortScaler\"]=0\n    \n    for reg in set(X.Reg):        \n        \n        Xslice = X[(X.Reg==reg) & (X.Test==0) & (X.DayYear >= start)]\n\n        if len(Xslice) > 0:\n            if Xslice[\"PredC\"].mean() > 0:\n                maptab.loc[reg,\"CaseScaler\"] = Xslice[\"Cases\"].mean()/Xslice[\"PredC\"].mean()\n                # also set a maximum mortality rate to adjust outliers\n                maptab.loc[reg,\"MortScaler\"]= np.minimum(Xslice[\"Death\"].mean()/Xslice[\"Cases\"].mean(),0.1)\n        \n        # add adjustments for missing data and set minimum mortality rate                \n        \n        elif len(X_all[(X_all.Reg==reg) & (X_all.Test==0) & (X_all.Cases > 0)]) > 0:\n            maxcase = X_all.loc[(X_all.Reg==reg) & (X_all.Test==0) & (X_all.Cases > 0),\"Cases\"].max()\n            maptab.loc[reg,\"CaseScaler\"]=maxcase/X.loc[(X.Reg==reg) &(X.Test==1),\"PredC\"].min()\n            maptab.loc[reg,\"MortScaler\"]=0.01\n        else:\n            maptab.loc[reg,\"CaseScaler\"]=0\n            maptab.loc[reg,\"MortScaler\"]=0.01\n    \n    \n    X.loc[:,\"PredC\"]= X.loc[:,\"Reg\"].map(maptab[\"CaseScaler\"].to_dict())*X.loc[:,\"PredC\"]\n    X[\"MortS\"]=X.loc[:,\"Reg\"].map(maptab[\"MortScaler\"].to_dict())\n    X.loc[:,\"PredD\"]= np.maximum(X.loc[:,\"Reg\"].map(maptab[\"MortScaler\"].to_dict())*X.loc[:,\"PredC\"],0.005*X[\"PredC\"]) \n    \n    # cap overall cases at 20% of population\n    # cap mortality at 10% of maximum infected population \n    \n    X.fillna(0,inplace=True)\n    X.loc[:,\"PredC\"]=np.minimum(X.Pop * 0.02,X.PredC)\n    X.loc[:,\"PredD\"]=np.minimum(X.Pop * 0.002,X.PredD)\n    \n    X[\"ResLC\"] = np.log(X.PredC+1)-X.LogC\n    X[\"ResLD\"] = np.log(X.PredD+1)-X.LogD\n    \n    if len(graph) == 0: graph=X.copy()\n    else: graph = pd.concat([graph,X])\n    \n    res_def=X[(X.DayYear >= sub_start) & (X.DayYear <= sub_end)].copy()\n    mysub = mysub.combine_first(res_def.set_index('Id')[[\"PredC\",\"PredD\"]])\n    if loop == \"Public\": \n        print(X.loc[(X.DayYear > start) & (X.DayYear <=val_end),[\"ResLC\",\"ResLD\",\"PredC\",\"PredD\"]].describe())\n        print(loop,\" Score: \",np.sqrt(X.loc[(X.DayYear > start) & (X.DayYear <=val_end),[\"ResLC\",\"ResLD\"]].var().mean()))    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extrapolation for private and public submissions"},{"metadata":{"trusted":true},"cell_type":"code","source":"graph[\"PredL\"]=np.log(X.PredD+1)\nfig = px.scatter(graph[graph.Reg==\"USNew York\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"ItalyNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()\nfig = px.scatter(graph[graph.Reg==\"United KingdomNone\"], x='Date', y='PredD', color=\"Sub\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extrapolation of total for all regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(graph.loc[graph.Sub==\"Private\",[\"PredC\",\"PredD\",\"Date\"]].groupby(\"Date\").sum().reset_index(), x='Date', y='PredD')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"mysub.drop(columns =[\"Case\",\"Death\"],inplace=True)\nmysub.insert(0,\"Id\",mysub.index)\nmysub.columns=old_cols\nmysub.fillna(0,inplace=True)\nmysub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}