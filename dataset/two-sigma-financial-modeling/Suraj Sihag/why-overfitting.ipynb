{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c0a746fb-e7aa-9dea-2e89-43d7f361199b"},"source":"Short summary:\n-------\nI minimize the X term in R^2 = 1-X. \n\n - r2obj1 : minimize X\n - r2obj2 : minimize sum of each timestamp's X\n - drop : drops y outliers from each timestamp group. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"541a1b2b-c0cd-d093-be62-9a49d8146df2"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport kagglegym\nimport gc\nimport math\nimport time\nimport seaborn as sns\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\n\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17606c65-572f-1eee-aa2a-7ec998cd6a66"},"outputs":[],"source":"def get_reward(y_true, y_fit):\n    R2 = 1 - np.sum((y_true - y_fit)**2) / np.sum((y_true - np.mean(y_true))**2)\n    R = np.sign(R2) * math.sqrt(abs(R2))\n    return(R)\n\ndef drop(group): \n    mean, std = group.mean(), group.std()\n    inliers = (group - mean).abs() <= 1*std\n    return inliers\n\ndef r2obj1(y_fit, dtrain):\n    y_true = dtrain.get_label()\n    deno = np.sum((y_true - np.mean(y_true))**2)\n    grad = (-2.0/deno)*(y_true - y_fit)\n    hess = (2.0/deno)*np.ones(shape=len(y_true))\n    return grad, hess\n\ndef r2obj2(y_fit, dtrain):\n    y_true = dtrain.get_label()\n    grad = (-2.0*(y_true - y_fit))/deno\n    hess = (2.0*np.ones(shape=len(y_true)))/deno\n    return grad, hess\n\ndef r2eval(y_fit, dtrain):\n    y_true = dtrain.get_label()\n    R2_proxy = np.sum((y_true - y_fit)**2) / np.sum((y_true - np.mean(y_true))**2)\n    return 'R2', R2_proxy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad797275-f227-5f74-3436-42e794f5118c"},"outputs":[],"source":"df_full = pd.read_hdf('../input/train.h5')\n\n# Observed with histograns:\nlow_y_cut = -0.086093\nhigh_y_cut = 0.093497\n\ny_is_above_cut = (df_full.y > high_y_cut)\ny_is_below_cut = (df_full.y < low_y_cut)\ny_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n\ntrain = df_full.query('timestamp<=905')\ntest = df_full.query('timestamp>905')\n\nmask = train.groupby('timestamp')['y'].apply(drop)\nbase_scor = train[mask].y.mean() #base score after removing outliers\n\ntrain = train.loc[y_is_within_cut]\ntrain.reset_index(drop=1,inplace=1)\n\ntrain['tmp_deno'] = (train.y - train.timestamp.map(train.groupby('timestamp')['y'].mean()))**2\ndeno = train.timestamp.map(train.groupby('timestamp')['tmp_deno'].sum())\ntrain.drop(['tmp_deno'],axis=1,inplace=1)\n\nbsm = train.timestamp.map(train.groupby('timestamp')['y'].mean()).values #xgb base margin\n\nfeature_cols = [col for col in train.columns if col not in ['id','timestamp','y']]\ncols = ['technical_20','technical_30']\n\ndtrain = xgb.DMatrix(train[cols],label=train.y)\ndtest = xgb.DMatrix(test[cols],label=test.y)\n\ndtrain.set_base_margin(bsm)\ndtest.set_base_margin([base_scor]*test.shape[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2712727-db70-47bb-df46-569323d781cb"},"outputs":[],"source":"param = {\n    'booster':'gbtree',\n    'eta':0.01,\n    'max_depth':2,\n    #'gamma':0.1,\n    'seed': 5\n    }\nwatchlist = [(dtrain, 'train'), (dtest, 'eval')]\nbst = xgb.train(param,dtrain,num_boost_round=1000,\n                evals=watchlist,obj=r2obj2,feval=r2eval,\n                maximize=False,early_stopping_rounds=10,verbose_eval=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d48efa5d-1206-94a0-7e63-9307d000b575"},"outputs":[],"source":"bst.get_fscore()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c037933a-2eb8-696d-6909-dd831bc38a07"},"outputs":[],"source":"np.sqrt(1-bst.best_score)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"508c2f51-c903-0ab6-dbfe-3a3d5f170a8c"},"outputs":[],"source":"pred = bst.predict(dtest).clip(low_y_cut, high_y_cut)\nget_reward(dtest.get_label(),pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d309c5b1-2d79-fcf7-b649-23b5c57ae3b6"},"outputs":[],"source":"env = kagglegym.make()\n\n# We get our initial observation by calling \"reset\"\nobservation = env.reset()\n\ny_actual_list = []\ny_pred_list = []\nr1_overall_reward_list = []\nr1_reward_list = []\nts_list = []\nwhile True:\n    timestamp = observation.features[\"timestamp\"][0]\n    actual_y = list(df_full[df_full[\"timestamp\"] == timestamp][\"y\"].values)\n    test_x = xgb.DMatrix(observation.features[cols])\n    test_x.set_base_margin([base_scor]*test_x.num_row())\n    observation.target.y = bst.predict(test_x)\n    \n    target = observation.target\n    observation, reward, done, info = env.step(target)\n    \n    if timestamp % 100 == 0:\n        print(\"Timestamp #{}\".format(timestamp))\n    \n    pred_y = list(target.y.values)\n    y_actual_list.extend(actual_y)\n    y_pred_list.extend(pred_y)\n    overall_reward = get_reward(np.array(y_actual_list), np.array(y_pred_list))\n    r1_overall_reward_list.append(overall_reward)\n    r1_reward_list.append(reward)\n    ts_list.append(timestamp)\n    if done:\n        break\n    \nprint(info)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23fa7696-7a50-661e-867d-670a6b736d23"},"outputs":[],"source":"fig, ax = plt.subplots(figsize=(12, 6))\nax.plot(ts_list, r1_overall_reward_list, c='black', label='xgb_tree')\nax.plot(ts_list, [0]*len(ts_list), c='red', label='zero line')\nax.legend(loc='lower right')\nax.set_ylim([-0.04,0.04])\nax.set_xlim([850, 1850])\nplt.title(\"Cumulative R value\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7450708e-ae9c-7ff4-3821-2965f95fccf1"},"source":"It looks so good but performs poorly on LB. I got a score of -0.004. \nRight now I don't have the motivation to pursue this further. If you find it useful, please **upvote**."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}