{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#print(os.listdir(\"../input\"))\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames[:15]: \n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T20:45:45.984701Z","iopub.execute_input":"2022-02-21T20:45:45.985019Z","iopub.status.idle":"2022-02-21T20:45:45.990653Z","shell.execute_reply.started":"2022-02-21T20:45:45.984982Z","shell.execute_reply":"2022-02-21T20:45:45.989777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport cv2\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nsample = pd.read_csv(\"/kaggle/input/open-images-object-detection-rvc-2020/sample_submission.csv\")\nprint(sample)\n#print(sample.head())\n#print(sample.shape)\n#print(sample.dtypes)\n#print(sample.columns)\n\n#sample.head()\n\nsample = pd.read_csv(\"/kaggle/input/open-images-object-detection-rvc-2020/sample_submission.csv\")\nsample.head()\n\nids = []\nfor i in range(len(sample)):\n    ids.append(sample['ImageId'][i])\nprint(f\"length of ids: {len(ids)}\")\n\n#img_data=[]\n#for i in range(len(sample)):\n#    img_data.append(glob.glob('/kaggle/input/open-images-object-detection-rvc-2020/test/{0}.jpg'.format(ids[i])))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:45:46.017892Z","iopub.execute_input":"2022-02-21T20:45:46.018114Z","iopub.status.idle":"2022-02-21T20:45:46.907567Z","shell.execute_reply.started":"2022-02-21T20:45:46.01809Z","shell.execute_reply":"2022-02-21T20:45:46.904112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create a model**","metadata":{}},{"cell_type":"markdown","source":"* Load an SSD model pretrained on COCO dataset.\n* Load a a set of utility methods for convenient and comprehensive formatting of input and output of the model.\n* Pytorch Hub(torch.hub) is a pre-trained model repository designed to facilitate research reproducibility.\n    - torch.hub.load(repo_or_dir, model, *args, source='github', force_reload=False, verbose=True, skip_validation=False, **kwargs)\n    - Load a model from a github repo or a local directory.\n    - returns the output of the model","metadata":{}},{"cell_type":"code","source":"ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\nutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n\nssd_model.to('cuda')\nssd_model.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:45:46.909507Z","iopub.execute_input":"2022-02-21T20:45:46.9109Z","iopub.status.idle":"2022-02-21T20:45:47.539287Z","shell.execute_reply.started":"2022-02-21T20:45:46.910859Z","shell.execute_reply":"2022-02-21T20:45:47.538498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"New input images for inference","metadata":{}},{"cell_type":"code","source":"uris =[\n    '/kaggle/input/open-images-object-detection-rvc-2020/test/15fe48f0b21740d2.jpg',\n    '/kaggle/input/open-images-object-detection-rvc-2020/test/1e0efd102f2c709c.jpg',\n    '/kaggle/input/open-images-object-detection-rvc-2020/test/c67ad5d1d3b72cd5.jpg',\n    '/kaggle/input/open-images-object-detection-rvc-2020/test/e57d7ee692d8cf47.jpg',\n    '/kaggle/input/open-images-object-detection-rvc-2020/test/1d8aa515a8501a15.jpg'   \n]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:45:47.540734Z","iopub.execute_input":"2022-02-21T20:45:47.542092Z","iopub.status.idle":"2022-02-21T20:45:47.546995Z","shell.execute_reply.started":"2022-02-21T20:45:47.542049Z","shell.execute_reply":"2022-02-21T20:45:47.546153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Format the images to comply with the network input and convert them to tensor","metadata":{}},{"cell_type":"markdown","source":"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n* Pytorch Hub is a pre-trained model repository designed to facilitate research reproducibility.","metadata":{}},{"cell_type":"code","source":"inputs = [utils.prepare_input(uri) for uri in uris]\ntensor = utils.prepare_tensor(inputs)\nprint(inputs)\nprint(tensor.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:45:47.550102Z","iopub.execute_input":"2022-02-21T20:45:47.550712Z","iopub.status.idle":"2022-02-21T20:45:48.04052Z","shell.execute_reply.started":"2022-02-21T20:45:47.550668Z","shell.execute_reply":"2022-02-21T20:45:48.039699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run the SSD network to perform object detection.","metadata":{}},{"cell_type":"markdown","source":"**Run the SSD network to perform object detection.**","metadata":{}},{"cell_type":"markdown","source":"what is torch.no_grad()?\n\n: Context-manager that disabled gradient calculation.\n\n: Disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward(). It will reduce memory consumption for computations that would otherwise have requires_grad=True.","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    detections_batch = ssd_model(tensor)\n    #print(type(detections_batch))\n#print(ssd_model(tensor))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:45:48.04178Z","iopub.execute_input":"2022-02-21T20:45:48.042046Z","iopub.status.idle":"2022-02-21T20:45:53.006606Z","shell.execute_reply.started":"2022-02-21T20:45:48.042012Z","shell.execute_reply":"2022-02-21T20:45:53.00587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"results_per_input = utils.decode_results(detections_batch)\n#print(results_per_input)\nbest_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n\nclasses_to_labels = utils.get_coco_object_dictionary()\n#print(len(classes_to_labels))\n#print(classes_to_labels)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:45:53.00782Z","iopub.execute_input":"2022-02-21T20:45:53.008098Z","iopub.status.idle":"2022-02-21T20:46:06.593989Z","shell.execute_reply.started":"2022-02-21T20:45:53.008062Z","shell.execute_reply":"2022-02-21T20:46:06.59318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport matplotlib.patches as patches\n\nfor image_idx in range(len(best_results_per_input)):\n    fig, ax = plt.subplots(1)\n    # Show original, denormalized image...\n    image = inputs[image_idx] / 2 + 0.5\n    ax.imshow(image)\n    # ...with detections\n    bboxes, classes, confidences = best_results_per_input[image_idx]\n    for idx in range(len(bboxes)):\n        left, bot, right, top = bboxes[idx]\n        x, y, w, h = [val * 300 for val in [left, bot, right - left, top - bot]]\n        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n        ax.add_patch(rect)\n        ax.text(x, y, \"{} {:.0f}%\".format(classes_to_labels[classes[idx] - 1], confidences[idx]*100), bbox=dict(facecolor='white', alpha=0.5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:46:06.595306Z","iopub.execute_input":"2022-02-21T20:46:06.595548Z","iopub.status.idle":"2022-02-21T20:46:07.782848Z","shell.execute_reply.started":"2022-02-21T20:46:06.595514Z","shell.execute_reply":"2022-02-21T20:46:07.782116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}