{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import modules","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os.path\nimport json\nimport codecs\nfrom collections import Counter\nimport random\nimport math\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch.utils.data as D\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_PATH = \"../input/herbarium-2020-fgvc7/nybg2020/train/\"\nTRAIN_META_PATH = \"../input/herbarium-2020-fgvc7/nybg2020/train/metadata.json\"\n\nTEST_PATH = \"../input/herbarium-2020-fgvc7/nybg2020/test/\"\nTEST_META_PATH = \"../input/herbarium-2020-fgvc7/nybg2020/test/metadata.json\"\n\nSUBMISSION_PATH = '../input/herbarium-2020-fgvc7/sample_submission.csv'\n\n\nwith codecs.open(TRAIN_META_PATH, 'r', encoding='utf-8', errors='ignore') as f:\n    train_meta = json.load(f)\n    \nwith codecs.open(TEST_META_PATH, 'r', encoding='utf-8', errors='ignore') as f:\n    test_meta = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick look and represent data as spreadsheets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Quick look on train and test sets (as could be seen there are no 'annotations', 'categories',  'regions' provided to test set)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train keys: ', train_meta.keys())\nprint('Test keys: ', test_meta.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look on training data annotations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.DataFrame(train_meta['annotations'])\ndisplay(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look on training data caregories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat = pd.DataFrame(train_meta['categories'])\ntrain_cat.columns = ['family', 'genus', 'category_id', 'category_name']\ndisplay(train_cat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look on training data images info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = pd.DataFrame(train_meta['images'])\ntrain_img.columns = ['file_name', 'height', 'image_id', 'license', 'width']\ndisplay(train_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look on training data regions info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reg = pd.DataFrame(train_meta['regions'])\ntrain_reg.columns = ['region_id', 'region_name', ]\ndisplay(train_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge training data to a single spreadsheet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.merge(train_cat, on='category_id', how='outer')\ntrain_df = train_df.merge(train_img, on='image_id', how='outer')\ntrain_df = train_df.merge(train_reg, on='region_id', how='outer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Print training dataset info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_meta['info'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look on test (submission) data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(test_meta['images'])\ndisplay(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look on submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(SUBMISSION_PATH)\ndisplay(sample_sub)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot histograms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Images HW distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"heights = [int(w) for w in train_df['height'] if isinstance(w, float) and not math.isnan(w)]\nh, b = np.histogram(heights, bins=len(set(widths)))\nfig = plt.figure(figsize = (25, 5))\nax = fig.gca()\nplt.plot(b[1:], h)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"widths = [int(w) for w in train_df['width'] if isinstance(w, float) and not math.isnan(w)]\nh, b = np.histogram(widths, bins=len(set(widths)))\nfig = plt.figure(figsize = (25, 5))\nax = fig.gca()\nplt.plot(b[1:], h)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution category -> image count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"h, b = np.histogram(train_df['category_id'], bins=len(np.unique(train_df['category_id'])))\nh.sort()\nfig = plt.figure(figsize = (25, 5))\nax = fig.gca()\nplt.plot(h[::-1])\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution genus -> image count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GENUS_INDEX = 5\n\ncounts = list(Counter(train_df.iloc[:, GENUS_INDEX]).values())\ncounts.sort()\ncounts.reverse()\n\nfig = plt.figure(figsize = (25, 5))\nax = fig.gca()\nplt.plot(counts)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution family -> image count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"FAMILY_INDEX = 4\n\ncounts = list(Counter(train_df.iloc[:, FAMILY_INDEX]).values())\ncounts.sort()\ncounts.reverse()\n\nfig = plt.figure(figsize = (25, 5))\nax = fig.gca()\nplt.plot(counts)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare simple torch dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class HerbariumDataset(D.Dataset):\n    def __init__(self, data, path):\n        self.data = data\n        self.path = path\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        fname = self.data['file_name'].values[i]\n        fpath = os.path.join(self.path, fname)\n        image = cv2.imread(fpath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        label = self.data['category_id'].values[i]\n        \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data = train_test_split(train_df)\n\ntrain_dataset = HerbariumDataset(train_data, TRAIN_PATH)\ntest_dataset = HerbariumDataset(test_data, TRAIN_PATH)  # There should be train path, it is correct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = train_dataset[random.randint(0, len(train_dataset))]\nprint(label)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[random.randint(0, len(test_dataset))]\nprint(label)\nplt.imshow(img)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}