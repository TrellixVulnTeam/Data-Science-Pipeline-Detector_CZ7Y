{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Store Sales - Time Series Forecasting: Baseline Model\n\nThis is a short notebook that builds a couple of simple models as a performance baseline for the Store Sales competition.\n\n- Mean: for each store/family, use the mean of the prior $n$ weeks sales as the prediction for future dates\n- WeekDay Mean: for each store/family/week_day, use the mean of the prior $n$ weeks as the prediction for \nfuture dates (i.e. use the average of the last 3 sundays to predict future sundays for each store/family combination)\n\nWe'll use scikit cross-validation to assess performance, so we'll create a fold generator, and wrap our models as estimators.","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nfrom warnings import simplefilter\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nsimplefilter(\"ignore\")\ncomp_dir = Path('../input/store-sales-time-series-forecasting')\n\nimport os\nfor dirname, _, filenames in os.walk(comp_dir):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T12:02:19.027855Z","iopub.execute_input":"2022-05-19T12:02:19.028226Z","iopub.status.idle":"2022-05-19T12:02:19.042897Z","shell.execute_reply.started":"2022-05-19T12:02:19.028185Z","shell.execute_reply":"2022-05-19T12:02:19.041774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Load training and test datasets","metadata":{}},{"cell_type":"code","source":"def load_training_data(input_dir):\n    train = pd.read_csv(\n        input_dir / 'train.csv',\n        usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n        dtype={\n            'store_nbr': 'category',\n            'family': 'category',\n            'sales': 'float32',\n            'onpromotion': 'uint32',\n        },\n        parse_dates=['date'],\n        infer_datetime_format=True,\n    )\n    train['date'] = train.date.dt.to_period('D')\n    train = train.set_index(['store_nbr', 'family', 'date']).sort_index()\n    return train\n\ndef load_test_data(input_dir):\n    test = pd.read_csv(\n        input_dir / 'test.csv',\n        dtype={\n            'id': 'uint32',\n            'store_nbr': 'category',\n            'family': 'category',\n            'onpromotion': 'uint32',\n        },\n        parse_dates=['date'],\n        infer_datetime_format=True,\n    )\n    test['date'] = test.date.dt.to_period('D')\n    test = test.set_index(['store_nbr', 'family', 'date']).sort_index()\n    return test","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:19.047891Z","iopub.execute_input":"2022-05-19T12:02:19.048421Z","iopub.status.idle":"2022-05-19T12:02:19.05746Z","shell.execute_reply.started":"2022-05-19T12:02:19.048387Z","shell.execute_reply":"2022-05-19T12:02:19.056624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = load_training_data(comp_dir)\ntest = load_test_data(comp_dir)\ny = train['sales']\nX = train.drop(columns=['sales'])\ndisplay(X)\ndisplay(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:19.064331Z","iopub.execute_input":"2022-05-19T12:02:19.064681Z","iopub.status.idle":"2022-05-19T12:02:23.457352Z","shell.execute_reply.started":"2022-05-19T12:02:19.064639Z","shell.execute_reply":"2022-05-19T12:02:23.456385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scorer for cross-validation\n\nI don't think scikit offers rmsle as a scoring option out-of-the-box","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\ndef rmsle(y, yhat):\n    y = y.to_numpy()\n    yhat = yhat.to_numpy()\n    return np.sqrt(np.mean((np.log1p(yhat)-np.log1p(y))**2))\n\nnrmsle_scorer = make_scorer(rmsle, greater_is_better=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:23.459613Z","iopub.execute_input":"2022-05-19T12:02:23.459937Z","iopub.status.idle":"2022-05-19T12:02:23.465745Z","shell.execute_reply.started":"2022-05-19T12:02:23.459894Z","shell.execute_reply":"2022-05-19T12:02:23.464925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Fold generator for cross validation\n\nWe are going to model all store/family series in one shot, so here we create all the folds for \nall the series in one pass.\n","metadata":{}},{"cell_type":"code","source":"class MultiSeriesKFold:\n    def __init__(self, n_splits, n_test, n_train):\n        \"\"\"\n        n_splits: number of folds\n        n_test: test size for one series/fold\n        n_train: training set size for one series/fold\n        \"\"\"\n        self.n_splits = n_splits\n        self.n_test = n_test\n        self.n_train = n_train\n\n    def split(self, X, y, groups=None):\n        \"\"\"\n        X,y: assume indexed by store_nbr+family+date\n        \n        returns: generator yielding train,test pairs\n        \"\"\"\n        \n        # figure the number of product/family series and the size of the series\n        n_series = len(X.index.unique(level=0)) * len(X.index.unique(level=1))\n        n_obs = len(X.index) // n_series\n        \n        # make sure all series of same size\n        assert n_obs * n_series == len(X.index)\n        \n        for split in range(1,self.n_splits+1):\n            train, test = np.empty(0,np.int_), np.empty(0, np.int_)\n            for i in range(n_series):\n                # process the tail of each series to extract train and test for current fold\n                offset = (i + 1) * n_obs - self.n_train - split * self.n_test\n                train = np.append(train, np.arange(self.n_train) + offset)\n                test = np.append(test, np.arange(self.n_test) + offset + self.n_train)\n            yield train,test\n                \n    def get_n_splits(self, X, y, groups=None):\n        return self.n_splits","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:23.467255Z","iopub.execute_input":"2022-05-19T12:02:23.467734Z","iopub.status.idle":"2022-05-19T12:02:23.483032Z","shell.execute_reply.started":"2022-05-19T12:02:23.467693Z","shell.execute_reply":"2022-05-19T12:02:23.482193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Mean Model\n\nUse the mean of sales over prior $n$ weeks for each product/family as prediction for all\ndesired future dates. Again, we will estimate all product/family series in one pass from\nthe original full training set.\n\nHere we wrap the model as a scikit estimator for use in cross-validation. ","metadata":{}},{"cell_type":"code","source":"from sklearn.base import RegressorMixin, BaseEstimator\n\nclass MeanRegressor(BaseEstimator, RegressorMixin):\n    def __init__(self, mean_weeks = 3):\n        super().__init__()\n        self.mean_weeks = mean_weeks\n        self.mean_days = 7 * mean_weeks\n    \n    def fit(self, X, y):\n        \"\"\"\n        X,y: assume indexed by store_nbr+family+date\n        \"\"\"\n        self.target = f'{y.name}_hat'\n        self.y_hat = y.groupby(level=[0,1]).tail(self.mean_days).groupby(level=[0,1]).mean().rename(self.target)\n    \n    def predict(self, X):\n        \"\"\"\n        X: assume indexed by store_nbr+family+date\n        \n        returns: fitted mean predictions\n        \"\"\"\n        return X.join(self.y_hat)[self.target]\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:23.485097Z","iopub.execute_input":"2022-05-19T12:02:23.485345Z","iopub.status.idle":"2022-05-19T12:02:23.499533Z","shell.execute_reply.started":"2022-05-19T12:02:23.485317Z","shell.execute_reply":"2022-05-19T12:02:23.498932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Sanity Check\n\nPlot model predictions vs truth as a sanity check. Here we plot a single store/family for clarity:\nwe expect a straight line prediction.","metadata":{}},{"cell_type":"code","source":"cvs = MultiSeriesKFold(1,14,100)\nfor train_idx, test_idx in cvs.split(X,y):\n    X_train = X.iloc[train_idx]\n    X_test = X.iloc[test_idx]\n    y_train = y.iloc[train_idx]\n    y_test = y.iloc[test_idx]\n    model = MeanRegressor(mean_weeks=2)\n    model.fit(X_train,y_train)\n    y_hat = model.predict(X_test)\n    y_hat['1','BEVERAGES'].plot()\n    y_test['1','BEVERAGES'].plot()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:23.501892Z","iopub.execute_input":"2022-05-19T12:02:23.502141Z","iopub.status.idle":"2022-05-19T12:02:24.120601Z","shell.execute_reply.started":"2022-05-19T12:02:23.502114Z","shell.execute_reply":"2022-05-19T12:02:24.119786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cross Validation\n\nRun cross validation and get our first score.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncv_results = cross_val_score(MeanRegressor(mean_weeks=2),\n                             X, y, \n                             cv=MultiSeriesKFold(5,15,500), \n                             scoring=nrmsle_scorer)\ncv_results.mean(), cv_results.std()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:24.121662Z","iopub.execute_input":"2022-05-19T12:02:24.121909Z","iopub.status.idle":"2022-05-19T12:02:28.144891Z","shell.execute_reply.started":"2022-05-19T12:02:24.121878Z","shell.execute_reply":"2022-05-19T12:02:28.144066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Weekday Mean Model\n\nAnother mean model, only this time we additionally group by the day of the week; e.g. we\nwill average of prior Sundays to predict future Sundays.","metadata":{}},{"cell_type":"code","source":"class WeekdayMeanRegressor(BaseEstimator, RegressorMixin):\n    def __init__(self, mean_weeks=3):\n        super().__init__()\n        self.mean_weeks = mean_weeks\n        self.mean_days = 7 * mean_weeks\n    \n    def fit(self, X, y):\n        \"\"\"\n        X,y: assume indexed by store_nbr+family+date\n        \"\"\"\n        self.target = f'{y.name}_hat'\n        # truncate to trailing mean_weeks observations\n        y = y.groupby(level=[0,1]).tail(self.mean_days)\n        \n        # group by store/family/weekday and take the mean\n        y = y.reset_index()\n        y['weekday'] =  y.date.dt.weekday\n        y = y.set_index(['store_nbr','family','date','weekday']).sort_index()\n        self.y_hat = y.groupby(level=[0,1,3]).sales.mean()\n        self.y_hat = self.y_hat.rename(self.target)\n        \n    def predict(self, X):\n        \"\"\"\n        X: assume indexed by store_nbr+family+date\n        \n        returns: fitted mean predictions\n        \"\"\"\n        # add weekday to index in order to join\n        y = X.reset_index()\n        y['weekday'] =  y.date.dt.weekday\n        y = y.set_index(['store_nbr','family','weekday','date']).sort_index()\n        y = y.join(self.y_hat)\n        y = y.reset_index(level=2).sort_index()[self.target]\n        return y\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:28.145984Z","iopub.execute_input":"2022-05-19T12:02:28.146197Z","iopub.status.idle":"2022-05-19T12:02:28.15666Z","shell.execute_reply.started":"2022-05-19T12:02:28.146171Z","shell.execute_reply":"2022-05-19T12:02:28.15587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sanity Check\n\nRepeat the sanity check; here we expect to see variance across weekdays, hopefully in line with the actual values.\n\nLooks about right...","metadata":{}},{"cell_type":"code","source":"cvs = MultiSeriesKFold(1,14,100)\nfor train_idx, test_idx in cvs.split(X,y):\n    X_train = X.iloc[train_idx]\n    X_test = X.iloc[test_idx]\n    y_train = y.iloc[train_idx]\n    y_test = y.iloc[test_idx]\n    model = WeekdayMeanRegressor(mean_weeks=2)\n    model.fit(X_train,y_train)\n    y_hat = model.predict(X_test)\n    y_hat['1','BEVERAGES'].plot()\n    y_test['1','BEVERAGES'].plot()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:28.157765Z","iopub.execute_input":"2022-05-19T12:02:28.158036Z","iopub.status.idle":"2022-05-19T12:02:28.690251Z","shell.execute_reply.started":"2022-05-19T12:02:28.158007Z","shell.execute_reply":"2022-05-19T12:02:28.689349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cross Validation\n\nHere we see a modest improvement in metric, though at the expense of a bit more variance\nacross the fold results","metadata":{}},{"cell_type":"code","source":"cv_results = cross_val_score(WeekdayMeanRegressor(mean_weeks=3),\n                             X, y, \n                             cv=MultiSeriesKFold(5,15,500), \n                             scoring=nrmsle_scorer)\ncv_results.mean(), cv_results.std()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:28.691823Z","iopub.execute_input":"2022-05-19T12:02:28.692038Z","iopub.status.idle":"2022-05-19T12:02:33.087957Z","shell.execute_reply.started":"2022-05-19T12:02:28.692011Z","shell.execute_reply":"2022-05-19T12:02:33.087029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Make a submission\n\nUse our WeekdayMeanRegressor to generate a submission to give us a baseline score for future model comparisons.","metadata":{}},{"cell_type":"code","source":"model = WeekdayMeanRegressor(mean_weeks=3)\nmodel.fit(X,y)\ny_hat = model.predict(test)\ndisplay(y_hat)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:33.090743Z","iopub.execute_input":"2022-05-19T12:02:33.09116Z","iopub.status.idle":"2022-05-19T12:02:33.576688Z","shell.execute_reply.started":"2022-05-19T12:02:33.091114Z","shell.execute_reply":"2022-05-19T12:02:33.575799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test.join(y_hat).set_index('id').sales_hat\nsubmission = submission.rename('sales')\ndisplay(submission)\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T12:02:33.57814Z","iopub.execute_input":"2022-05-19T12:02:33.578467Z","iopub.status.idle":"2022-05-19T12:02:34.023363Z","shell.execute_reply.started":"2022-05-19T12:02:33.578423Z","shell.execute_reply":"2022-05-19T12:02:34.022708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}