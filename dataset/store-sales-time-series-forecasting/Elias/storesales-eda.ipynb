{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#<div style=\"padding:20px;color:white;margin:0;font-size:175%;text-align:center;display:fill;border-radius:5px;background-color:#016CC9;overflow:hidden;font-weight:500\"> Competition target.</div>","metadata":{}},{"cell_type":"markdown","source":"In this competition, the training data contains the daily sales of various families of product in various stores.\nWe are asked to predict the sales for the 16 days following the training period.","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>1 |</span><span style='color:#016CC9'> Load data </span></b>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as plticker\nimport seaborn as sns\npd.options.mode.chained_assignment = None\ntrain=pd.read_csv('../input/store-sales-time-series-forecasting/train.csv')\nprint(train.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:03.161702Z","iopub.execute_input":"2022-06-12T09:44:03.162171Z","iopub.status.idle":"2022-06-12T09:44:07.731617Z","shell.execute_reply.started":"2022-06-12T09:44:03.162073Z","shell.execute_reply":"2022-06-12T09:44:07.730365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stores=pd.read_csv('../input/store-sales-time-series-forecasting/stores.csv')\nprint(stores.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:07.733768Z","iopub.execute_input":"2022-06-12T09:44:07.734302Z","iopub.status.idle":"2022-06-12T09:44:07.763769Z","shell.execute_reply.started":"2022-06-12T09:44:07.734255Z","shell.execute_reply":"2022-06-12T09:44:07.762346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>2 |</span><span style='color:#016CC9'> First look at the data</span></b> ","metadata":{}},{"cell_type":"markdown","source":"We would like to have a quantitative idea of the amount of data we need to process for the training.","metadata":{}},{"cell_type":"code","source":"print('There are {} days, {} stores and {} families in the training data'.format(train['date'].nunique(),\n                                                                                train['family'].nunique(),\n                                                                                train['store_nbr'].nunique()))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:07.770628Z","iopub.execute_input":"2022-06-12T09:44:07.771176Z","iopub.status.idle":"2022-06-12T09:44:08.278329Z","shell.execute_reply.started":"2022-06-12T09:44:07.771129Z","shell.execute_reply":"2022-06-12T09:44:08.277184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are **33x54=1782** possible pairs of (store, family). We have to predict the sales over 16 days. We have to produce **16x1782=28512** values. Let's check if this is consistent with the test file.","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv('../input/store-sales-time-series-forecasting/test.csv')\nprint(test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:08.279578Z","iopub.execute_input":"2022-06-12T09:44:08.279982Z","iopub.status.idle":"2022-06-12T09:44:08.319986Z","shell.execute_reply.started":"2022-06-12T09:44:08.279948Z","shell.execute_reply":"2022-06-12T09:44:08.318834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('Test has {} rows, {} days, {} stores and {} families'.format(len(test),test['date'].nunique(),\n                                                                                test['family'].nunique(),\n                                                                                test['store_nbr'].nunique()))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:08.321605Z","iopub.execute_input":"2022-06-12T09:44:08.322303Z","iopub.status.idle":"2022-06-12T09:44:08.334953Z","shell.execute_reply.started":"2022-06-12T09:44:08.322259Z","shell.execute_reply":"2022-06-12T09:44:08.334031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have checked that **test** is consistent with **train** and now have a clear quantitative idea of the competition. There are 1782 pairs (store, family). It is a large number for visualization and grouping will help us to get a clear picture of the time series. We will group by **stores** first and then by **families**.","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>3 |</span><span style='color:#016CC9'> Stores  </span></b>","metadata":{}},{"cell_type":"markdown","source":"Let's group the training data by stores.","metadata":{}},{"cell_type":"code","source":"store_daily=train.groupby(['date','store_nbr']).agg({'sales':'sum'}).reset_index()\nstore_daily.rename(columns={'sales':'store_daily_sales'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:08.336729Z","iopub.execute_input":"2022-06-12T09:44:08.337226Z","iopub.status.idle":"2022-06-12T09:44:08.834933Z","shell.execute_reply.started":"2022-06-12T09:44:08.33718Z","shell.execute_reply":"2022-06-12T09:44:08.834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now visualize the time series for each store. We will use a 150 day moving average for more clarity.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,10))\nfor store_nbr in store_daily['store_nbr'].unique():\n    store_daily_i = store_daily.loc[store_daily['store_nbr']==store_nbr]\n    store_daily_i['MA_store_daily_sales']=store_daily_i['store_daily_sales'].rolling(150).mean()\n    ax.plot(store_daily_i['date'],store_daily_i['MA_store_daily_sales'])\nax.set_xlabel('date', fontsize=18)\nax.set_ylabel('sales / store', fontsize=16)\nax.set_title('Sales by Store time series',fontsize=18)\nloc = plticker.MultipleLocator(base=60) # this locator puts ticks at regular intervals\nax.xaxis.set_major_locator(loc)\nax.tick_params(axis='x', rotation=70)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:08.83628Z","iopub.execute_input":"2022-06-12T09:44:08.836646Z","iopub.status.idle":"2022-06-12T09:44:20.070362Z","shell.execute_reply.started":"2022-06-12T09:44:08.836614Z","shell.execute_reply":"2022-06-12T09:44:20.069397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that some stores are consistently above while other stores had no sales at the begining and picked up later. We would now like to visualize the sales distribution over the stores.","metadata":{}},{"cell_type":"code","source":"store=store_daily.groupby(['store_nbr']).agg({'store_daily_sales':'sum'}).reset_index()\nstore.rename(columns={'store_daily_sales':'store_sales'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:20.071659Z","iopub.execute_input":"2022-06-12T09:44:20.072168Z","iopub.status.idle":"2022-06-12T09:44:20.083611Z","shell.execute_reply.started":"2022-06-12T09:44:20.072134Z","shell.execute_reply":"2022-06-12T09:44:20.082277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.barplot(x=store['store_nbr'],y=store['store_sales'])\nplt.title('Sales distribution by Store', fontsize=18)\nplt.xlabel('Store',fontsize=16)\nplt.ylabel('Sales',fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:20.086838Z","iopub.execute_input":"2022-06-12T09:44:20.087481Z","iopub.status.idle":"2022-06-12T09:44:20.797136Z","shell.execute_reply.started":"2022-06-12T09:44:20.087442Z","shell.execute_reply":"2022-06-12T09:44:20.79613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This graph shows clearly which stores are successful.","metadata":{}},{"cell_type":"markdown","source":"#  <b><span style='color:#4B4B4B'>4 |</span><span style='color:#016CC9'> Families</span></b>","metadata":{}},{"cell_type":"markdown","source":"Let's now group the sales by family.","metadata":{}},{"cell_type":"code","source":"family_daily=train.groupby(['date','family']).agg({'sales':'sum'}).reset_index()\nfamily_daily.rename(columns={'sales':'family_daily_sales'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:20.798233Z","iopub.execute_input":"2022-06-12T09:44:20.798545Z","iopub.status.idle":"2022-06-12T09:44:21.498121Z","shell.execute_reply.started":"2022-06-12T09:44:20.798517Z","shell.execute_reply":"2022-06-12T09:44:21.496837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now visualize the time series for each family. We will use a 50 day moving average for more clarity.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,10))\nfor family in family_daily['family'].unique():\n    family_daily_i = family_daily.loc[family_daily['family']==family]\n    family_daily_i['MA_family_daily_sales']=family_daily_i['family_daily_sales'].rolling(50).mean()\n    ax.plot(family_daily_i['date'],family_daily_i['MA_family_daily_sales'])\nax.set_xlabel('date', fontsize=16)\nax.set_ylabel('sales / family', fontsize=16)\nax.set_title('Sales by Family time series',fontsize=18)\nloc = plticker.MultipleLocator(base=60) # this locator puts ticks at regular intervals\nax.xaxis.set_major_locator(loc)\nax.tick_params(axis='x', rotation=70)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:21.499632Z","iopub.execute_input":"2022-06-12T09:44:21.5Z","iopub.status.idle":"2022-06-12T09:44:28.562255Z","shell.execute_reply.started":"2022-06-12T09:44:21.499968Z","shell.execute_reply":"2022-06-12T09:44:28.561244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that some families are consistently above. We would now like to visualize the sales distribution over the families.","metadata":{}},{"cell_type":"code","source":"family=family_daily.groupby('family').agg({'family_daily_sales':'sum'}).reset_index()\nfamily.rename(columns={'family_daily_sales':'family_sales'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:28.56353Z","iopub.execute_input":"2022-06-12T09:44:28.563963Z","iopub.status.idle":"2022-06-12T09:44:28.577503Z","shell.execute_reply.started":"2022-06-12T09:44:28.563928Z","shell.execute_reply":"2022-06-12T09:44:28.576448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.barplot(x=family['family'],y=family['family_sales'])\nplt.xticks(rotation=70)\nplt.title('Sales distribution by Family', fontsize=18)\nplt.xlabel('Family',fontsize=16)\nplt.ylabel('Sales',fontsize=16)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:28.578656Z","iopub.execute_input":"2022-06-12T09:44:28.57903Z","iopub.status.idle":"2022-06-12T09:44:29.00809Z","shell.execute_reply.started":"2022-06-12T09:44:28.578979Z","shell.execute_reply":"2022-06-12T09:44:29.007276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Grocery I, Beverages, Produce and Cleaning** are the most successful families.","metadata":{}},{"cell_type":"markdown","source":"#   <b><span style='color:#4B4B4B'>5 |</span><span style='color:#016CC9'>total sales time series </span></b>","metadata":{}},{"cell_type":"markdown","source":"We will now visualize the total sales time series. This will give us some important clues regarding trend and seasonality. so let's group train by days.","metadata":{}},{"cell_type":"code","source":"total_daily=train.groupby(['date']).agg({'sales':'sum'}).reset_index()\ntotal_daily.rename(columns={'sales':'total_daily_sales'},inplace=True)\nprint(total_daily.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:29.009059Z","iopub.execute_input":"2022-06-12T09:44:29.010035Z","iopub.status.idle":"2022-06-12T09:44:29.331043Z","shell.execute_reply.started":"2022-06-12T09:44:29.009927Z","shell.execute_reply":"2022-06-12T09:44:29.329957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntotal_daily['MA_total_daily_sales']=total_daily['total_daily_sales'].rolling(30).mean()\n\nfig, ax = plt.subplots(figsize=(15,10))\nax.plot(total_daily['date'],total_daily['MA_total_daily_sales']) \nax.set_xlabel('date', fontsize=16)\nax.set_ylabel('total sales', fontsize=16)\nax.set_title('total sales time series', fontsize=18)\nloc = plticker.MultipleLocator(base=60) # this locator puts ticks at regular intervals\nax.xaxis.set_major_locator(loc)\nax.tick_params(axis='x', rotation=70)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:29.33259Z","iopub.execute_input":"2022-06-12T09:44:29.333034Z","iopub.status.idle":"2022-06-12T09:44:29.827288Z","shell.execute_reply.started":"2022-06-12T09:44:29.332991Z","shell.execute_reply":"2022-06-12T09:44:29.826227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a general uptrend with some swings. We would like to better visualize the weekly, monthly and yearly cycles.","metadata":{}},{"cell_type":"code","source":"total_daily['date'] = pd.to_datetime(total_daily['date'], format='%Y/%m/%d')\ntotal_daily['day_of_month'] = total_daily['date'].dt.day\ntotal_daily['month'] = total_daily['date'].dt.month_name()\ntotal_daily['day_of_week'] = total_daily['date'].dt.day_name()\n\nyear_cycle=total_daily.groupby('month').agg({'total_daily_sales':'sum'}).reset_index()\nyear_cycle.rename(columns={'total_daily_sales':'total_sales'},inplace=True)\nmonth_cycle=total_daily.groupby('day_of_month').agg({'total_daily_sales':'sum'}).reset_index()\nmonth_cycle.rename(columns={'total_daily_sales':'total_sales'},inplace=True)\nweek_cycle=total_daily.groupby('day_of_week').agg({'total_daily_sales':'sum'}).reset_index()\nweek_cycle.rename(columns={'total_daily_sales':'total_sales'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:29.828584Z","iopub.execute_input":"2022-06-12T09:44:29.828916Z","iopub.status.idle":"2022-06-12T09:44:29.855122Z","shell.execute_reply.started":"2022-06-12T09:44:29.828885Z","shell.execute_reply":"2022-06-12T09:44:29.854423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weekly cycle <b><span style='color:#4B4B4B'>6 |</span><span style='color:#016CC9'> Load data </span></b>","metadata":{}},{"cell_type":"code","source":"cat_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nweek_cycle['day_of_week'] = pd.Categorical(week_cycle['day_of_week'], categories=cat_week, ordered=True)\nweek_cycle = week_cycle.sort_values('day_of_week')\nfig, ax = plt.subplots(figsize=(15,10))\nax.bar(week_cycle['day_of_week'],week_cycle['total_sales'],color = 'g', width = 0.5) \nax.set_xlabel('day of week', fontsize=16)\nax.set_ylabel('total sales', fontsize=16)\nax.set_title('Weekly cycle',fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:29.856502Z","iopub.execute_input":"2022-06-12T09:44:29.857118Z","iopub.status.idle":"2022-06-12T09:44:30.040021Z","shell.execute_reply.started":"2022-06-12T09:44:29.857071Z","shell.execute_reply":"2022-06-12T09:44:30.038901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a clear weekly pattern. Sunday is the busiest day followed by Saturday. Thurday is the least busy day.","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>5 |</span><span style='color:#016CC9'> Monthly cycle </span></b>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,10))\nax.bar(month_cycle['day_of_month'],month_cycle['total_sales'],color = 'g', width = 0.5) \nax.set_xlabel('day of month', fontsize=16)\nax.set_ylabel('total sales', fontsize=16)\nax.set_title('Monthly cycle',fontsize=18)\nax.set_xlim(xmin=1,xmax=30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:30.041098Z","iopub.execute_input":"2022-06-12T09:44:30.041437Z","iopub.status.idle":"2022-06-12T09:44:30.264348Z","shell.execute_reply.started":"2022-06-12T09:44:30.041388Z","shell.execute_reply":"2022-06-12T09:44:30.263464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we have a useful information. The days following the start and the middle of the month are stronger.\nIn the data description we see:\n***Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.***\nWe can see this reflected in the sales numbers.\n","metadata":{}},{"cell_type":"markdown","source":"#  <b><span style='color:#4B4B4B'>6 |</span><span style='color:#016CC9'>Yearly cycle</span></b>","metadata":{}},{"cell_type":"code","source":"cat_year = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nyear_cycle['month'] = pd.Categorical(year_cycle['month'], categories=cat_year, ordered=True)\nyear_cycle = year_cycle.sort_values('month')\nfig, ax = plt.subplots(figsize=(15,10))\nax.bar(year_cycle['month'],year_cycle['total_sales'],color = 'g', width = 0.5) \nax.set_xlabel('month', fontsize=16)\nax.set_ylabel('total sales', fontsize=16)\nax.set_title('Yearly cycle',fontsize=18)\nax.tick_params(axis='x', rotation=70)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T09:44:30.265572Z","iopub.execute_input":"2022-06-12T09:44:30.265893Z","iopub.status.idle":"2022-06-12T09:44:30.606254Z","shell.execute_reply.started":"2022-06-12T09:44:30.265856Z","shell.execute_reply":"2022-06-12T09:44:30.605152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"July is the strongest month, and September the weakest.","metadata":{}},{"cell_type":"markdown","source":"If you found this Notebook useful, please upvote!","metadata":{}}]}