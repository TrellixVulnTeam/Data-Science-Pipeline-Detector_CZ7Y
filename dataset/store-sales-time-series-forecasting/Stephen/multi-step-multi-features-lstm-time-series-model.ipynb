{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T12:03:41.699087Z","iopub.execute_input":"2022-05-04T12:03:41.699407Z","iopub.status.idle":"2022-05-04T12:03:41.726815Z","shell.execute_reply.started":"2022-05-04T12:03:41.699344Z","shell.execute_reply":"2022-05-04T12:03:41.726179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup notebook\nfrom pathlib import Path\n\n# import necessary package\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.sequence import TimeseriesGenerator\n\nimport sklearn\nfrom sklearn import preprocessing\n\n# 畫圖表用\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.callbacks import CSVLogger, EarlyStopping\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:42.093813Z","iopub.execute_input":"2022-05-04T12:03:42.09425Z","iopub.status.idle":"2022-05-04T12:03:47.576167Z","shell.execute_reply.started":"2022-05-04T12:03:42.094215Z","shell.execute_reply":"2022-05-04T12:03:47.575445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the data\ncomp_dir = Path('../input/store-sales-time-series-forecasting')\n\nstore_sales = pd.read_csv(\n    comp_dir / 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\ntest = pd.read_csv(\n    comp_dir / 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\noil = pd.read_csv(\n    comp_dir / 'oil.csv',\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:47.577793Z","iopub.execute_input":"2022-05-04T12:03:47.578017Z","iopub.status.idle":"2022-05-04T12:03:50.686281Z","shell.execute_reply.started":"2022-05-04T12:03:47.577985Z","shell.execute_reply":"2022-05-04T12:03:50.685611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales  = store_sales[(store_sales['date']>'2015-06-01')]\nstore_sales","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:50.688366Z","iopub.execute_input":"2022-05-04T12:03:50.688815Z","iopub.status.idle":"2022-05-04T12:03:50.775129Z","shell.execute_reply.started":"2022-05-04T12:03:50.688777Z","shell.execute_reply":"2022-05-04T12:03:50.774451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales['sales'].max()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:50.777033Z","iopub.execute_input":"2022-05-04T12:03:50.777786Z","iopub.status.idle":"2022-05-04T12:03:50.787907Z","shell.execute_reply.started":"2022-05-04T12:03:50.777748Z","shell.execute_reply":"2022-05-04T12:03:50.786881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#store_sales = store_sales[(store_sales[\"store_nbr\"] == '1') & ( (store_sales[\"family\"] == 'AUTOMOTIVE') | (store_sales[\"family\"] == 'BEVERAGES') ) ]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:50.789081Z","iopub.execute_input":"2022-05-04T12:03:50.789491Z","iopub.status.idle":"2022-05-04T12:03:50.79366Z","shell.execute_reply.started":"2022-05-04T12:03:50.789436Z","shell.execute_reply":"2022-05-04T12:03:50.79266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales.drop(columns=['onpromotion'],inplace=True)\nstore_sales","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:50.794915Z","iopub.execute_input":"2022-05-04T12:03:50.795383Z","iopub.status.idle":"2022-05-04T12:03:50.821954Z","shell.execute_reply.started":"2022-05-04T12:03:50.795344Z","shell.execute_reply":"2022-05-04T12:03:50.821187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = store_sales.pivot_table(index = ['date'],values = ['sales'],columns = ['store_nbr','family'],fill_value = 0)\ndataset.columns = [\"_\".join(x) for x in dataset.columns.ravel()]\ndataset","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:50.823309Z","iopub.execute_input":"2022-05-04T12:03:50.823573Z","iopub.status.idle":"2022-05-04T12:03:52.137948Z","shell.execute_reply.started":"2022-05-04T12:03:50.82354Z","shell.execute_reply":"2022-05-04T12:03:52.137139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas import DataFrame\nfrom pandas import concat\n\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\t\"\"\"\n\tFrame a time series as a supervised learning dataset.\n\tArguments:\n\t\tdata: Sequence of observations as a list or NumPy array.\n\t\tn_in: Number of lag observations as input (X).\n\t\tn_out: Number of observations as output (y).\n\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n\tReturns:\n\t\tPandas DataFrame of series framed for supervised learning.\n\t\"\"\"\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf = DataFrame(data)\n\tcols, names = list(), list()\n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df.shift(i))\n\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df.shift(-i))\n\t\tif i == 0:\n\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n\t\telse:\n\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n\t# put it all together\n\tagg = concat(cols, axis=1)\n\tagg.columns = names\n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.139284Z","iopub.execute_input":"2022-05-04T12:03:52.139596Z","iopub.status.idle":"2022-05-04T12:03:52.149959Z","shell.execute_reply.started":"2022-05-04T12:03:52.139559Z","shell.execute_reply":"2022-05-04T12:03:52.149267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"关于归一化[0,1]，一般指的是Min-Max Normalization\n\n关于归一化，按单独的列进行归一化用的比较多\n\n对全部的列进行归一化，使用sklearn 的MinMaxScaler，使用时MinMaxScaler()函数在进行计算时取的是每列的最大最小值\n\nx' = (x - X_min) / (X_max - X_min)\n\n# 因此我们可以先将array的data进行reshape为向量，将所有的数据看作一列进行计算，此时取到的最大最小值是全部数据的最大最小值，计算完成后reshape为原array的大小","metadata":{}},{"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\ndata_reshape = dataset.values.reshape([-1, 1])\n\ndata_reshape_norm = min_max_scaler.fit_transform(data_reshape)\ndata_norm = data_reshape_norm.reshape(dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.151125Z","iopub.execute_input":"2022-05-04T12:03:52.151865Z","iopub.status.idle":"2022-05-04T12:03:52.176144Z","shell.execute_reply.started":"2022-05-04T12:03:52.151826Z","shell.execute_reply":"2022-05-04T12:03:52.175445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = data_norm","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.179951Z","iopub.execute_input":"2022-05-04T12:03:52.180141Z","iopub.status.idle":"2022-05-04T12:03:52.185691Z","shell.execute_reply.started":"2022-05-04T12:03:52.180118Z","shell.execute_reply":"2022-05-04T12:03:52.184902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.187012Z","iopub.execute_input":"2022-05-04T12:03:52.187258Z","iopub.status.idle":"2022-05-04T12:03:52.196762Z","shell.execute_reply.started":"2022-05-04T12:03:52.187225Z","shell.execute_reply":"2022-05-04T12:03:52.195988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" (True in np.isnan(dataset))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.198027Z","iopub.execute_input":"2022-05-04T12:03:52.198322Z","iopub.status.idle":"2022-05-04T12:03:52.210234Z","shell.execute_reply.started":"2022-05-04T12:03:52.198286Z","shell.execute_reply":"2022-05-04T12:03:52.209259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timesteps_in = 90\ntimesteps_out = 16\nn_features = dataset.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.211833Z","iopub.execute_input":"2022-05-04T12:03:52.212101Z","iopub.status.idle":"2022-05-04T12:03:52.21619Z","shell.execute_reply.started":"2022-05-04T12:03:52.212065Z","shell.execute_reply":"2022-05-04T12:03:52.215536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = series_to_supervised(dataset,timesteps_in,timesteps_out)\ndata_X = data.iloc[:,:-timesteps_out*n_features]\ndata_y = data.iloc[:,-timesteps_out*n_features:]\ndata_X.shape, data_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:52.217884Z","iopub.execute_input":"2022-05-04T12:03:52.218398Z","iopub.status.idle":"2022-05-04T12:03:55.397244Z","shell.execute_reply.started":"2022-05-04T12:03:52.218361Z","shell.execute_reply":"2022-05-04T12:03:55.396482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.398455Z","iopub.execute_input":"2022-05-04T12:03:55.398932Z","iopub.status.idle":"2022-05-04T12:03:55.460165Z","shell.execute_reply.started":"2022-05-04T12:03:55.398893Z","shell.execute_reply":"2022-05-04T12:03:55.459501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape from [samples, timesteps] into [samples, timesteps, features]\n\ndata_X = data_X.values.reshape((data_X.shape[0], timesteps_in, n_features))\ndata_X.shape,data_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.461367Z","iopub.execute_input":"2022-05-04T12:03:55.461627Z","iopub.status.idle":"2022-05-04T12:03:55.470817Z","shell.execute_reply.started":"2022-05-04T12:03:55.461573Z","shell.execute_reply":"2022-05-04T12:03:55.469933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#x_train, x_val, y_train, y_val = train_test_split(data_X,data_y, random_state=11, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.472244Z","iopub.execute_input":"2022-05-04T12:03:55.473873Z","iopub.status.idle":"2022-05-04T12:03:55.528022Z","shell.execute_reply.started":"2022-05-04T12:03:55.473827Z","shell.execute_reply":"2022-05-04T12:03:55.52734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x_train.shape,x_val.shape,y_train.shape,y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.529347Z","iopub.execute_input":"2022-05-04T12:03:55.52959Z","iopub.status.idle":"2022-05-04T12:03:55.53469Z","shell.execute_reply.started":"2022-05-04T12:03:55.529558Z","shell.execute_reply":"2022-05-04T12:03:55.532979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom keras.preprocessing.sequence import TimeseriesGenerator\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.535984Z","iopub.execute_input":"2022-05-04T12:03:55.536288Z","iopub.status.idle":"2022-05-04T12:03:55.543172Z","shell.execute_reply.started":"2022-05-04T12:03:55.536188Z","shell.execute_reply":"2022-05-04T12:03:55.542205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='loss', factor = 0.4, patience = 8, verbose = 1, min_lr = 0.00001)\ncheckpoint = ModelCheckpoint(filepath='./best.h5', monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.544732Z","iopub.execute_input":"2022-05-04T12:03:55.545324Z","iopub.status.idle":"2022-05-04T12:03:55.552587Z","shell.execute_reply.started":"2022-05-04T12:03:55.545275Z","shell.execute_reply":"2022-05-04T12:03:55.551833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学习率比较大的时候，可能出现 loss: nan的情况。所以得适当降低学习率。\n# loss太大，也可能出现loss: nan的情况，通过输入数据的正规化，把loss降低。\n# \nLSTM(100,....) 规模大小的网络时，loss在60000左右下不来。 试试加大网络？","metadata":{}},{"cell_type":"code","source":"# define model\nmodel = Sequential()\n\nmodel.add(LSTM(300, activation='relu', return_sequences=True, input_shape=(timesteps_in, n_features)))\nmodel.add(LSTM(300, activation='relu'))\nmodel.add(Dense(timesteps_out*n_features))\n\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.02), loss='mse')\n#model.compile(optimizer='adam', loss='mse')\n# fit model\n#model.fit(X, y, epochs=50, verbose=0)\n#model.fit(x_train, y_train, epochs=200, verbose=1, validation_data=(x_val,y_val), callbacks=[reduce_lr])\nmodel.fit(data_X,data_y, epochs=200, verbose=1, callbacks=[reduce_lr,checkpoint])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:03:55.55401Z","iopub.execute_input":"2022-05-04T12:03:55.554454Z","iopub.status.idle":"2022-05-04T12:25:52.542388Z","shell.execute_reply.started":"2022-05-04T12:03:55.554418Z","shell.execute_reply":"2022-05-04T12:25:52.541691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('./best.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:25:52.543594Z","iopub.execute_input":"2022-05-04T12:25:52.54477Z","iopub.status.idle":"2022-05-04T12:25:52.977927Z","shell.execute_reply.started":"2022-05-04T12:25:52.54473Z","shell.execute_reply":"2022-05-04T12:25:52.977136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_input = data_X[-1:,:]\nx_input = x_input.reshape((x_input.shape[0], timesteps_in, n_features))\nyhat = model.predict(x_input, verbose=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:25:52.979028Z","iopub.execute_input":"2022-05-04T12:25:52.979265Z","iopub.status.idle":"2022-05-04T12:25:53.267844Z","shell.execute_reply.started":"2022-05-04T12:25:52.979232Z","shell.execute_reply":"2022-05-04T12:25:53.267141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(suppress=True)\nprint(yhat[0][0:20])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:25:53.269185Z","iopub.execute_input":"2022-05-04T12:25:53.269423Z","iopub.status.idle":"2022-05-04T12:25:53.27701Z","shell.execute_reply.started":"2022-05-04T12:25:53.26939Z","shell.execute_reply":"2022-05-04T12:25:53.27627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(suppress=True)\n\npredicts = np.squeeze(yhat) / min_max_scaler.scale_[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:25:53.278378Z","iopub.execute_input":"2022-05-04T12:25:53.279433Z","iopub.status.idle":"2022-05-04T12:25:53.284591Z","shell.execute_reply.started":"2022-05-04T12:25:53.279371Z","shell.execute_reply":"2022-05-04T12:25:53.283845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicts = np.maximum(predicts,0)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:35:23.599836Z","iopub.execute_input":"2022-05-04T12:35:23.600308Z","iopub.status.idle":"2022-05-04T12:35:23.60595Z","shell.execute_reply.started":"2022-05-04T12:35:23.600272Z","shell.execute_reply":"2022-05-04T12:35:23.604827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(comp_dir / 'sample_submission.csv')\nsubmission['sales'] = predicts\nsubmission.to_csv('result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:35:32.817315Z","iopub.execute_input":"2022-05-04T12:35:32.817562Z","iopub.status.idle":"2022-05-04T12:35:32.901642Z","shell.execute_reply.started":"2022-05-04T12:35:32.817534Z","shell.execute_reply":"2022-05-04T12:35:32.900948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicts[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:35:29.398479Z","iopub.execute_input":"2022-05-04T12:35:29.399016Z","iopub.status.idle":"2022-05-04T12:35:29.404781Z","shell.execute_reply.started":"2022-05-04T12:35:29.398979Z","shell.execute_reply":"2022-05-04T12:35:29.403851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}