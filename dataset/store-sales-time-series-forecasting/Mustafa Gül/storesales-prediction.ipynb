{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.preprocessing import Normalizer\nimport os\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.layers import Flatten,Embedding,Dense\nfrom keras.layers.merge import Concatenate\n\nimport keras\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T20:26:37.043113Z","iopub.execute_input":"2022-04-06T20:26:37.04339Z","iopub.status.idle":"2022-04-06T20:26:37.049418Z","shell.execute_reply.started":"2022-04-06T20:26:37.043346Z","shell.execute_reply":"2022-04-06T20:26:37.048438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/store-sales-time-series-forecasting/train.csv\")\n\ntest = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\")\n\noil = pd.read_csv(\"../input/store-sales-time-series-forecasting/oil.csv\")\n\n\ndef split_seq(a,split_length):\n    x=np.zeros((split_length,a.shape[1]))    \n    x=np.vstack([x,a])\n    sales_prev=[]\n    sales_next=[]\n\n    for i in range(split_length,x.shape[0]): \n        sales_prev.append(x[i-split_length:i])\n        sales_next.append(x[i])\n\n    \n    return np.array((sales_prev)),np.array((sales_next))\n\nsplit_len=16    \n    \npivoted_train = train.pivot(index=['date'], columns=['store_nbr', 'family'], values=['sales'])\n\n\npivoted_train_clone=pivoted_train\n\n\npivoted_train_clone=pivoted_train_clone.merge(oil, on=['date'], how=\"left\")\n\npivoted_train_clone['dcoilwtico']=pivoted_train_clone['dcoilwtico'].fillna(method='bfill')\n\noil=pivoted_train_clone['dcoilwtico']\ndel pivoted_train_clone\ndisplay(oil)\n\n\ndisplay(pivoted_train)\n\nscaler3 = MinMaxScaler(feature_range=(-1, 1))\n\npivoted_train = scaler3.fit_transform(pivoted_train)\n\n\npivoted_train,pivoted_train_y=split_seq(pivoted_train,split_len)\noil=oil.values.reshape(-1,1)\n\n\nscaler2 = MinMaxScaler(feature_range=(-1, 1))\n\noil = scaler2.fit_transform(oil.reshape(-1,1))\n\nprint(oil.shape)\nprint(pivoted_train.shape)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-06T20:26:37.13471Z","iopub.execute_input":"2022-04-06T20:26:37.134899Z","iopub.status.idle":"2022-04-06T20:26:40.0803Z","shell.execute_reply.started":"2022-04-06T20:26:37.134876Z","shell.execute_reply":"2022-04-06T20:26:40.078772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model and Train","metadata":{}},{"cell_type":"code","source":"def network():\n    inp = layers.Input(shape=(split_len, 1782,))\n\n    x=layers.MultiHeadAttention(\n        key_dim=256, num_heads=4, dropout=0.25\n    )(inp, inp)\n    \n    x=keras.layers.Dropout(0.25)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n\n    res = x + inp\n    # Feed Forward Part\n    \n    x = layers.Conv1D(filters=4, kernel_size=1, activation=\"relu\")(res)\n    x = layers.Dropout(0.25)(x)\n    x = layers.Conv1D(filters=1782, kernel_size=1)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x=x+res\n    \n    \n    \n    \n    \n    x=layers.MultiHeadAttention(\n        key_dim=256, num_heads=4, dropout=0.25\n    )(x, x)\n    \n    x=keras.layers.Dropout(0.25)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n\n    res = x + inp\n    # Feed Forward Part\n    \n    x = layers.Conv1D(filters=4, kernel_size=1, activation=\"relu\")(res)\n    x = layers.Dropout(0.25)(x)\n    x = layers.Conv1D(filters=1782, kernel_size=1)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x=x+res\n    \n    \n    \n    \n    \n    \n    x=layers.MultiHeadAttention(\n        key_dim=256, num_heads=4, dropout=0.25\n    )(x, x)\n    \n    x=keras.layers.Dropout(0.25)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n\n    res = x + inp\n    # Feed Forward Part\n    \n    x = layers.Conv1D(filters=4, kernel_size=1, activation=\"relu\")(res)\n    x = layers.Dropout(0.25)(x)\n    x = layers.Conv1D(filters=1782, kernel_size=1)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x=x+res\n    \n    \n    \n    \n    \n    x=layers.MultiHeadAttention(\n        key_dim=256, num_heads=4, dropout=0.25\n    )(x, x)\n    \n    x=keras.layers.Dropout(0.25)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n\n    res = x + inp\n    # Feed Forward Part\n    \n    x = layers.Conv1D(filters=4, kernel_size=1, activation=\"relu\")(res)\n    x = layers.Dropout(0.25)(x)\n    x = layers.Conv1D(filters=1782, kernel_size=1)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x=x+res\n    \n    \n    \n    \n    \n    \n    \n    \n    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n    \n    x=keras.layers.Dense(512,activation=\"relu\")(x)\n    \n    x=keras.layers.Dropout(0.4)(x)\n    \n    x=keras.layers.Dense(512,activation=\"relu\")(x)\n    \n    x=keras.layers.Dropout(0.4)(x)\n    \n\n    out=keras.layers.Dense(1782)(x)\n    \n    model = keras.Model(inputs=[inp], outputs=out)\n    return model\n\nmodel=network()\nprint(model.summary())\nmodel.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer=tf.optimizers.Adam())\n\n\n\nmodel.fit(x=[pivoted_train],y=pivoted_train_y,batch_size=256,epochs=400,validation_split=0.05)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T20:26:40.081969Z","iopub.execute_input":"2022-04-06T20:26:40.082351Z","iopub.status.idle":"2022-04-06T20:34:22.894301Z","shell.execute_reply.started":"2022-04-06T20:26:40.08231Z","shell.execute_reply":"2022-04-06T20:34:22.892672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\")\nid=test['id']\n\ndisplay(test)\ntest=pivoted_train_y[pivoted_train_y.shape[0]-split_len:]\ntest=np.expand_dims(test,axis=0)\n\nsales=np.array([])\nfor i in range(16):\n    predictions = model.predict(test)\n    predictions=predictions.reshape(-1)\n    #sales+=predictions.reshape(-1)\n    test=np.insert(test,-1,predictions,axis=1)\n    test=np.delete(test, 0, axis=1)\n    sales=np.append(sales,predictions)\n    #test = np.array([test,predictions])\n    #predictions=np.expand_dims(predictions,axis=0)\n    #test=np.append(test[1:],predictions,axis=0)\n\n\ny_predict = pd.DataFrame(scaler3.inverse_transform(sales.reshape((16, 1782))))\nsales=y_predict.values.reshape(16*1782)\nsales = sales.clip(min=0)\ntest_results=pd.DataFrame({'id':id,'sales':sales})\ndisplay(test_results)\ntest_results.to_csv('results.csv' , index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T20:34:22.896653Z","iopub.execute_input":"2022-04-06T20:34:22.900703Z","iopub.status.idle":"2022-04-06T20:34:24.106962Z","shell.execute_reply.started":"2022-04-06T20:34:22.900662Z","shell.execute_reply":"2022-04-06T20:34:24.106223Z"},"trusted":true},"execution_count":null,"outputs":[]}]}