{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import TimeSeriesSplit, train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import mean_squared_log_error\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T18:25:55.656027Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rng = np.random.default_rng(673)\n\ntrain_data = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv', parse_dates=['date'])\nprint(train_data.head(5))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv', parse_dates=['date'])\nprint(test_data.head(5))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = ['family', 'store_nbr']\nenc = OrdinalEncoder()\nenc.fit(train_data[categorical_features])\n\ndef extract_features(data):\n    extracted = pd.DataFrame()\n    extracted['month'] = data['date'].dt.month\n    extracted['year'] = data['date'].dt.year\n    extracted['dow'] = data['date'].dt.dayofweek\n    extracted['doy'] = data['date'].dt.dayofyear\n    extracted[categorical_features] = enc.transform(data[categorical_features])\n    return extracted\n\ndef get_rolling(train_data, test_data, column):\n    data = pd.concat([train_data, test_data])\n    groups = data.groupby(categorical_features).rolling(28, on='date')[column].mean().shift(21)\n    c = data.join(groups, on=categorical_features  + ['date'], rsuffix='_28')[column + '_28']\n    return c.iloc[:len(train_data)], c.iloc[len(train_data):]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(data.head())\n# groups = data.groupby(categorical_features).rolling(2, on='date')['sales'].mean().shift(16)\n# data.join(groups, on=categorical_features + ['date'], rsuffix='_28')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_28 = get_rolling(train_data, test_data, 'sales')\nop_28 = get_rolling(train_data, test_data, 'onpromotion')\n\nX, y = extract_features(train_data), train_data['sales']\nX['sales_28'] = sales_28[0] \nX['op_28'] = op_28[0]\nprint(X.head(5))\n\nX_test = extract_features(test_data)\nX_test['sales_28'] = sales_28[1]\nX_test['op_28'] = op_28[1]\nprint(X_test.head(5))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(num_boost_round, params):\n    n_class = 33 * 53\n    tscv = TimeSeriesSplit(test_size=15 * n_class, n_splits=10)\n    rmsle_val, rmsle_train = [], []\n    \n    for train_index, val_index in tscv.split(X):\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n        train_dataset = lgb.Dataset(X_train, y_train)\n        val_dataset = lgb.Dataset(X_val, y_val)\n\n        booster = lgb.train(dict({'objective': 'regression', 'seed': 673}, **params), \n                            train_set=train_dataset, valid_sets=(val_dataset,),\n                            num_boost_round=num_boost_round)\n\n        train_preds = np.round(np.maximum(0, booster.predict(X_train))).astype(int)\n        rmsle_train.append(mean_squared_log_error(train_preds, y_train, squared=False))\n        \n        val_preds = np.round(np.maximum(0, booster.predict(X_val))).astype(int)\n        rmsle_val.append(mean_squared_log_error(val_preds, y_val, squared=False))\n    \n    return rmsle_val, rmsle_train","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'max_depth': [3, 8, 15],\n}\nrmsle = []\n\nmax_depth = [3, 8, 15]\nnum_boost_round = [130]\n\nfor p in max_depth:\n    rmsle.append(train(130, {'max_depth': p}))","metadata":{"scrolled":true,"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(max_depth)):\n    print(f'Mean validation score for max depth {max_depth[i]}: {np.mean(rmsle[i][0]):.2f}+-{np.std(rmsle[i][0]):.2f}')\n# print(f'Submission score: {1.48719:.2f}')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(max_depth, [np.mean(row[0]) for row in rmsle], label='val')\nplt.plot(max_depth, [np.mean(row[1]) for row in rmsle], label='train')\nplt.legend()\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = lgb.Dataset(X, y)\n\nbooster = lgb.train({'objective': 'regression', 'seed': 673, 'max_depth ': 15}, \n                    train_set=train_dataset,\n                    num_boost_round=150)\n\nresult = pd.DataFrame()\nresult['id'] = test_data['id']\nresult['sales'] = np.round(np.maximum(0, booster.predict(X_test))).astype(int)\nresult.to_csv('result.csv', index=False)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data.merge(\n#     train_data.groupby(['family','store_nbr']).rolling(14,on='date').mean().reset_index().rename(columns={'sales':'avg_sales'}),\n#     how='left',\n#     on=['family','store_nbr', 'date']\n# )","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}