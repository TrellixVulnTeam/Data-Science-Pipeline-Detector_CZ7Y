{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-23T05:57:50.027614Z","iopub.execute_input":"2021-12-23T05:57:50.027879Z","iopub.status.idle":"2021-12-23T05:57:50.039867Z","shell.execute_reply.started":"2021-12-23T05:57:50.027851Z","shell.execute_reply":"2021-12-23T05:57:50.039023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if you are interesting in faster version(~minutes) but lower performance\n# you can check ver.5/6 of this notebook\n# it might help","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup notebook\nfrom pathlib import Path\n\n# import necessary package\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.sequence import TimeseriesGenerator\n\nimport sklearn\nfrom sklearn import preprocessing\n\n# 畫圖表用\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:50.042043Z","iopub.execute_input":"2021-12-23T05:57:50.042538Z","iopub.status.idle":"2021-12-23T05:57:50.047771Z","shell.execute_reply.started":"2021-12-23T05:57:50.042503Z","shell.execute_reply":"2021-12-23T05:57:50.046947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the data\ncomp_dir = Path('../input/store-sales-time-series-forecasting')\n\nstore_sales = pd.read_csv(\n    comp_dir / 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\ntest = pd.read_csv(\n    comp_dir / 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\noil = pd.read_csv(\n    comp_dir / 'oil.csv',\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:50.049044Z","iopub.execute_input":"2021-12-23T05:57:50.049582Z","iopub.status.idle":"2021-12-23T05:57:52.143991Z","shell.execute_reply.started":"2021-12-23T05:57:50.049514Z","shell.execute_reply":"2021-12-23T05:57:52.143243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that define all the EDA we need \ndef EDA(df):\n    print(\"\\n_____ HEAD OF THE DATA _____\")\n    print(df.head())\n    print(\"\\n_____ INFO _____\")\n    print(df.info())\n    print(\"\\n_____ Describe _____\")\n    print(df.describe())\n    print(\"\\n_____ Columns _____\")\n    print(df.columns)\n    print(\"\\n_____ Data Types _____\")\n    print(df.dtypes)\n    print(\"\\n_____ Missing Values _____\")\n    print(df.isnull().sum())\n    print(\"\\n_____ NULL values _____\")\n    print(df.isna().sum())\n    print(\"\\n_____ Shape Of Data _____\")\n    print(df.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-23T05:57:52.14602Z","iopub.execute_input":"2021-12-23T05:57:52.146255Z","iopub.status.idle":"2021-12-23T05:57:52.152438Z","shell.execute_reply.started":"2021-12-23T05:57:52.14622Z","shell.execute_reply":"2021-12-23T05:57:52.151749Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"__________ Sales Data __________\")\nEDA(store_sales)\nprint(\"__________ Test data __________\")\nEDA(test)\nprint(\"__________ Oil Price __________\")\nEDA(oil)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-23T05:57:52.15368Z","iopub.execute_input":"2021-12-23T05:57:52.154508Z","iopub.status.idle":"2021-12-23T05:57:52.422638Z","shell.execute_reply.started":"2021-12-23T05:57:52.154471Z","shell.execute_reply":"2021-12-23T05:57:52.421841Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill missing date\noil = oil.set_index(\"date\").asfreq(freq = \"D\")\n\n# fill the NaN value by interpolation\noil[\"dcoilwtico\"] = oil[\"dcoilwtico\"].interpolate(limit_direction=\"both\")\n\noil.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.424193Z","iopub.execute_input":"2021-12-23T05:57:52.424477Z","iopub.status.idle":"2021-12-23T05:57:52.439984Z","shell.execute_reply.started":"2021-12-23T05:57:52.424437Z","shell.execute_reply":"2021-12-23T05:57:52.439104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales = store_sales.merge(oil, on=\"date\")\ntest = test.merge(oil, on=\"date\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.441567Z","iopub.execute_input":"2021-12-23T05:57:52.441863Z","iopub.status.idle":"2021-12-23T05:57:52.627627Z","shell.execute_reply.started":"2021-12-23T05:57:52.441823Z","shell.execute_reply":"2021-12-23T05:57:52.62679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.629064Z","iopub.execute_input":"2021-12-23T05:57:52.629322Z","iopub.status.idle":"2021-12-23T05:57:52.651732Z","shell.execute_reply.started":"2021-12-23T05:57:52.629287Z","shell.execute_reply":"2021-12-23T05:57:52.650909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.65292Z","iopub.execute_input":"2021-12-23T05:57:52.653242Z","iopub.status.idle":"2021-12-23T05:57:52.672547Z","shell.execute_reply.started":"2021-12-23T05:57:52.65318Z","shell.execute_reply":"2021-12-23T05:57:52.671574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n# 我加入targetCol來指定我想要預測的欄位，而不是全部\ndef series_to_supervised(data, n_in=1, n_out=1, futureArr=None, targetCol=None, dropnan=True):\n    \"\"\"\n    Frame a time series as a supervised learning dataset.\n    Arguments:\n        data: Sequence of observations as a list or NumPy array.\n        n_in: Number of lag observations as input (X).\n        n_out: Number of observations as output (y).\n        dropnan: Boolean whether or not to drop rows with NaN values.\n    Returns:\n        Pandas DataFrame of series framed for supervised learning.\n    \"\"\"\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('%s(t-%d)' % (j, i)) for j in df.columns]\n        \n    # forecast sequence (t, t+1, ... t+n)    \n    if futureArr != None:\n        for i in range(0, n_out):\n            for futureCol in futureArr:\n                cols.append(df.shift(-i)[futureCol])\n                if i == 0:\n                    names += [('%s(t)' % (futureCol))]\n                else:\n                    names += [('%s(t+%d)' % (futureCol, i))]\n    \n    for i in range(0, n_out):\n        if targetCol == None:\n            cols.append(df.shift(-i))\n            if i == 0:\n                names += [('%s(t)' % (j)) for j in df.columns]\n            else:\n                names += [('%s(t+%d)' % (j, i)) for j in df.columns]\n        else:\n            cols.append(df.shift(-i)[targetCol])\n            if i == 0:\n                names += [('%s(t)' % (targetCol))]\n            else:\n                names += [('%s(t+%d)' % (targetCol, i))]\n            \n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.67661Z","iopub.execute_input":"2021-12-23T05:57:52.676979Z","iopub.status.idle":"2021-12-23T05:57:52.69105Z","shell.execute_reply.started":"2021-12-23T05:57:52.676889Z","shell.execute_reply":"2021-12-23T05:57:52.690394Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ========== 以下是示範第一個iteration的結果 ==========\n# 將資料根據store_nbr和family拆出來\nstore_nbr_types = store_sales[\"store_nbr\"].unique()\n\nfamily_types = store_sales[\"family\"].unique()\n\n# 走訪所有商店/類型\nfor store_nbr_type in store_nbr_types:\n    for family_type in family_types:\n        # 訓練資料\n        train_data = store_sales[(store_sales[\"store_nbr\"] == store_nbr_type) & (store_sales[\"family\"] == family_type)]\n        \n        # 重置index並drop掉不需要的欄位\n        train_data = train_data.reset_index()\n        train_data = train_data.drop(columns = [\"index\", \"date\", \"store_nbr\", \"family\"])\n        \n        # 測試資料(用於填寫結果)        \n        test_data = test[(test[\"store_nbr\"] == store_nbr_type) & (test[\"family\"] == family_type)]\n        test_data = test_data.drop(columns = [\"date\", \"store_nbr\", \"family\"])\n        break\n    break","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.692347Z","iopub.execute_input":"2021-12-23T05:57:52.692996Z","iopub.status.idle":"2021-12-23T05:57:52.776048Z","shell.execute_reply.started":"2021-12-23T05:57:52.692951Z","shell.execute_reply":"2021-12-23T05:57:52.772468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concat train and test data\ntotal_data = pd.concat([train_data, test_data]).drop(columns=[\"id\"])\n\ntotal_data","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.78047Z","iopub.execute_input":"2021-12-23T05:57:52.782695Z","iopub.status.idle":"2021-12-23T05:57:52.807775Z","shell.execute_reply.started":"2021-12-23T05:57:52.782651Z","shell.execute_reply":"2021-12-23T05:57:52.806986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization\nfeature_name = total_data.columns\n\nscaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n\ntotal_data = scaler.fit_transform(total_data)\n\ntotal_data = pd.DataFrame(total_data, columns=feature_name)\n\ntotal_data","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.811979Z","iopub.execute_input":"2021-12-23T05:57:52.812682Z","iopub.status.idle":"2021-12-23T05:57:52.846398Z","shell.execute_reply.started":"2021-12-23T05:57:52.812638Z","shell.execute_reply":"2021-12-23T05:57:52.845601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example\n# 使用5天的資料，來預測後面兩天的資料\nfutureArr = [\"onpromotion\", \"dcoilwtico\"]\n\nseries_to_supervised(total_data, 5, 2, futureArr=futureArr, targetCol=\"sales\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.850784Z","iopub.execute_input":"2021-12-23T05:57:52.853061Z","iopub.status.idle":"2021-12-23T05:57:52.916915Z","shell.execute_reply.started":"2021-12-23T05:57:52.853019Z","shell.execute_reply":"2021-12-23T05:57:52.916196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 要用幾天來預測\npast_days = 50\n# 預測未來幾天\npredict_days = 16\n# 未來資料要使用於input的欄位\nfutureArr = [\"onpromotion\", \"dcoilwtico\"]\n# 所要預測的欄位\ntargetCol = \"sales\"\n\ntrain = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol)\n\nsplit_ratio = 0.8\n\nsplit_number = np.floor(len(train.index) * split_ratio)\nsplit_number = np.int(split_number)\n\nvalues = train.values\n\n\n# split into train and validation sets\ntrain = values[:split_number, :]\nval = values[split_number:, :]\n\n# split into input and outputs\ntrain_x, train_y = train[:, :-predict_days], train[:, -predict_days:]\nval_x, val_y = val[:, :-predict_days], val[:, -predict_days:]\n# reshape input to be 3D [samples, timesteps, features]\ntrain_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\nval_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))\n\n# 預備用於預測的data(-17:-16代表使用倒數第17天的資料(2017/08/15))\nprediction_data = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol, dropnan=False).values[-17:-16, :-predict_days]\nprediction_data = prediction_data.reshape((prediction_data.shape[0], 1, prediction_data.shape[1]))\n\nprint(train_x.shape, train_y.shape, val_x.shape, val_y.shape, prediction_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:52.919808Z","iopub.execute_input":"2021-12-23T05:57:52.922864Z","iopub.status.idle":"2021-12-23T05:57:53.031357Z","shell.execute_reply.started":"2021-12-23T05:57:52.922824Z","shell.execute_reply":"2021-12-23T05:57:53.030643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_data","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:53.03506Z","iopub.execute_input":"2021-12-23T05:57:53.037559Z","iopub.status.idle":"2021-12-23T05:57:53.053075Z","shell.execute_reply.started":"2021-12-23T05:57:53.037517Z","shell.execute_reply":"2021-12-23T05:57:53.052253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\nmodel = keras.models.Sequential([\n        keras.layers.LSTM(units=30, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])),\n        keras.layers.Dropout(0.2),\n        keras.layers.LSTM(units=30, return_sequences=True),\n        keras.layers.Dropout(0.2),\n        keras.layers.TimeDistributed(keras.layers.Dense(predict_days))\n])\n\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:53.057108Z","iopub.execute_input":"2021-12-23T05:57:53.059698Z","iopub.status.idle":"2021-12-23T05:57:53.591531Z","shell.execute_reply.started":"2021-12-23T05:57:53.059658Z","shell.execute_reply":"2021-12-23T05:57:53.590781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping =  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n\nmodel_result = model.fit(train_x, train_y, epochs=100, batch_size=32, validation_data=(val_x, val_y), verbose=2, shuffle=False, callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:53.592951Z","iopub.execute_input":"2021-12-23T05:57:53.593407Z","iopub.status.idle":"2021-12-23T05:57:59.620045Z","shell.execute_reply.started":"2021-12-23T05:57:53.59337Z","shell.execute_reply":"2021-12-23T05:57:59.619342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot history\nplt.figure(figsize=(30, 10))\n\nplt.subplot(1, 2, 1)\nplt.plot(model_result.history[\"loss\"], label=\"training\")\nplt.plot(model_result.history[\"val_loss\"], label=\"validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(model_result.history[\"mse\"], label=\"training\")\nplt.plot(model_result.history[\"val_mse\"], label=\"validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:57:59.62124Z","iopub.execute_input":"2021-12-23T05:57:59.621487Z","iopub.status.idle":"2021-12-23T05:58:00.477237Z","shell.execute_reply.started":"2021-12-23T05:57:59.621454Z","shell.execute_reply":"2021-12-23T05:58:00.476516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(prediction_data)\n\nprediction = np.squeeze(prediction) / scaler.scale_[0]\n\ntest_data[\"sales\"] = prediction","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:58:00.478401Z","iopub.execute_input":"2021-12-23T05:58:00.478765Z","iopub.status.idle":"2021-12-23T05:58:01.014444Z","shell.execute_reply.started":"2021-12-23T05:58:00.478722Z","shell.execute_reply":"2021-12-23T05:58:01.013688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:58:01.015975Z","iopub.execute_input":"2021-12-23T05:58:01.016225Z","iopub.status.idle":"2021-12-23T05:58:01.029094Z","shell.execute_reply.started":"2021-12-23T05:58:01.01619Z","shell.execute_reply":"2021-12-23T05:58:01.028001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 現在我會真正走訪所有資料\n# 將資料根據store_nbr和family拆出來\nstore_nbr_types = store_sales[\"store_nbr\"].unique()\n\nfamily_types = store_sales[\"family\"].unique()\n\ncounter = 0\n# 走訪所有商店/類型\nfor store_nbr_type in store_nbr_types:\n    for family_type in family_types:\n        counter = counter + 1\n        # 訓練資料\n        train_data = store_sales[(store_sales[\"store_nbr\"] == store_nbr_type) & (store_sales[\"family\"] == family_type)]\n        \n        # 重置index並drop掉不需要的欄位\n        train_data = train_data.reset_index()\n        train_data = train_data.drop(columns = [\"index\", \"date\", \"store_nbr\", \"family\"])\n        \n        # 測試資料(用於填寫結果)        \n        test_data = test[(test[\"store_nbr\"] == store_nbr_type) & (test[\"family\"] == family_type)]\n        test_data = test_data.drop(columns = [\"date\", \"store_nbr\", \"family\"])\n        \n        # concat train and test data\n        total_data = pd.concat([train_data, test_data]).drop(columns=[\"id\"])\n        \n        # Normalization\n        feature_name = total_data.columns\n\n        scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n\n        total_data = scaler.fit_transform(total_data)\n\n        total_data = pd.DataFrame(total_data, columns=feature_name)\n        \n        # 要用幾天來預測\n        past_days = 50\n        # 預測未來幾天\n        predict_days = 16\n        # 未來資料要使用於input的欄位\n        futureArr = [\"onpromotion\", \"dcoilwtico\"]\n        # 所要預測的欄位\n        targetCol = \"sales\"\n\n        train = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol)\n\n        split_ratio = 0.8\n\n        split_number = np.floor(len(train.index) * split_ratio)\n        split_number = np.int(split_number)\n\n        values = train.values\n\n\n        # split into train and validation sets\n        train = values[:split_number, :]\n        val = values[split_number:, :]\n\n        # split into input and outputs\n        train_x, train_y = train[:, :-predict_days], train[:, -predict_days:]\n        val_x, val_y = val[:, :-predict_days], val[:, -predict_days:]\n        # reshape input to be 3D [samples, timesteps, features]\n        train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n        val_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))\n\n        # 預備用於預測的data(-17:-16代表使用倒數第17天的資料(2017/08/15))\n        prediction_data = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol, dropnan=False).values[-17:-16, :-predict_days]\n        prediction_data = prediction_data.reshape((prediction_data.shape[0], 1, prediction_data.shape[1]))\n        \n        # Model\n        model = keras.models.Sequential([\n            keras.layers.LSTM(units=30, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])),\n            keras.layers.Dropout(0.2),\n            keras.layers.LSTM(units=30, return_sequences=True),\n            keras.layers.Dropout(0.2),\n            keras.layers.TimeDistributed(keras.layers.Dense(predict_days))\n        ])\n\n        optimizer = keras.optimizers.Adam(learning_rate=0.001)\n\n        model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])\n        \n        # Train\n        early_stopping =  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n\n        model_result = model.fit(train_x, train_y, epochs=100, batch_size=32, validation_data=(val_x, val_y), verbose=0, shuffle=False, callbacks=[early_stopping])\n        \n        # Inference        \n        prediction = model.predict(prediction_data)\n\n        prediction = np.squeeze(prediction) / scaler.scale_[0]\n\n        test_data[\"sales\"] = prediction\n        \n        if counter == 1:\n            submit_data = test_data\n        else:\n            submit_data = pd.concat([submit_data, test_data])\n        \n        if counter % 50 == 0:\n            print(counter)\n        \n        \nprint(\"done!\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T05:58:01.030918Z","iopub.execute_input":"2021-12-23T05:58:01.031474Z","iopub.status.idle":"2021-12-23T06:00:49.117246Z","shell.execute_reply.started":"2021-12-23T05:58:01.031434Z","shell.execute_reply":"2021-12-23T06:00:49.113336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_data = submit_data.drop(columns = [\"onpromotion\", \"dcoilwtico\"])\n\nsubmit_data = submit_data.sort_values(by=[\"id\"])\n\nsubmit_data = submit_data.reset_index(drop=True)\n\n# 太小的值跟負值當成0\nsubmit_data.loc[submit_data.sales < 0.001, \"sales\"] = 0","metadata":{"execution":{"iopub.status.busy":"2021-12-23T06:00:54.030986Z","iopub.execute_input":"2021-12-23T06:00:54.031743Z","iopub.status.idle":"2021-12-23T06:00:54.040863Z","shell.execute_reply.started":"2021-12-23T06:00:54.031706Z","shell.execute_reply":"2021-12-23T06:00:54.039989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_data.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T06:00:59.207992Z","iopub.execute_input":"2021-12-23T06:00:59.208584Z","iopub.status.idle":"2021-12-23T06:00:59.21825Z","shell.execute_reply.started":"2021-12-23T06:00:59.208543Z","shell.execute_reply":"2021-12-23T06:00:59.217358Z"},"trusted":true},"execution_count":null,"outputs":[]}]}