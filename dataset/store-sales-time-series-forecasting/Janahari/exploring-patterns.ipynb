{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # Install patched learntools (temporary fix 12/29/2021)\n# !pip install -U -t /kaggle/working/ git+https://github.com/Kaggle/learntools.git\n\n# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.time_series.ex3 import *\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_lags, make_lags, make_leads\n\n# Setup notebook\nfrom pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot\n    \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom pathlib import Path\n# from EDA_plots import *\n# from plot_style import *\npath = '../input/store-sales-time-series-forecasting'\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:37.594085Z","iopub.execute_input":"2022-01-19T21:48:37.595344Z","iopub.status.idle":"2022-01-19T21:48:38.589395Z","shell.execute_reply.started":"2022-01-19T21:48:37.595162Z","shell.execute_reply":"2022-01-19T21:48:38.587677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndtype = {\n    'store_nbr': 'category',\n    'family': 'category',\n    'sales': 'float32',\n    'onpromotion': 'uint64',\n}\n\nstore_sales = pd.read_csv(\n    path + '/train.csv',\n    dtype=dtype,\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales = store_sales.set_index('date').to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family'], append=True)\naverage_sales = store_sales.groupby('date').mean()['sales']","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:38.592446Z","iopub.execute_input":"2022-01-19T21:48:38.593908Z","iopub.status.idle":"2022-01-19T21:48:41.80367Z","shell.execute_reply.started":"2022-01-19T21:48:38.593788Z","shell.execute_reply":"2022-01-19T21:48:41.802343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = average_sales.to_frame()\n\ntime = np.arange(len(df.index))  # time dummy\n\ndf['time'] = time\n\nX = df.loc[:, ['time']]  # features\ny = df.loc[:, 'sales']  # target\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\n\nax = y.plot(**plot_params, alpha=0.5)\nax = y_pred.plot(ax=ax, linewidth=3)\nax.set_title('Time Plot of Total Store Sales');","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:41.805349Z","iopub.execute_input":"2022-01-19T21:48:41.806432Z","iopub.status.idle":"2022-01-19T21:48:42.306859Z","shell.execute_reply.started":"2022-01-19T21:48:41.806392Z","shell.execute_reply":"2022-01-19T21:48:42.305422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# linear regression model with a lag feature on the series of average product sales\ndf = average_sales.to_frame()\n\nlag_1 = df['sales'].shift(1)\n\ndf['lag_1'] = lag_1\n\nX = df.loc[:, ['lag_1']]\nX.dropna(inplace=True)  # drop missing values in the feature set\ny = df.loc[:, 'sales']  # create the target\ny, X = y.align(X, join='inner')  # drop corresponding values in target\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\n\nfig, ax = plt.subplots()\nax.plot(X['lag_1'], y, '.', color='0.25')\nax.plot(X['lag_1'], y_pred)\nax.set(aspect='equal', ylabel='sales', xlabel='lag_1', title='Lag Plot of Average Sales');","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-19T21:48:42.308677Z","iopub.execute_input":"2022-01-19T21:48:42.308984Z","iopub.status.idle":"2022-01-19T21:48:42.575168Z","shell.execute_reply.started":"2022-01-19T21:48:42.308957Z","shell.execute_reply":"2022-01-19T21:48:42.572852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exploring trends","metadata":{}},{"cell_type":"code","source":"# moving average plot of average_sales estimating the trend.\n\ntrend = average_sales.rolling(\n    window=365,\n    center=True,\n    min_periods=183,\n).mean()\n\nax = average_sales.plot(**plot_params, alpha=0.5)\nax = trend.plot(ax=ax, linewidth=3)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:42.577053Z","iopub.execute_input":"2022-01-19T21:48:42.577294Z","iopub.status.idle":"2022-01-19T21:48:42.932911Z","shell.execute_reply.started":"2022-01-19T21:48:42.577264Z","shell.execute_reply":"2022-01-19T21:48:42.930339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DeterministicProcess to create a feature set for a cubic trend model.\ny = average_sales.copy()  # the target\n\ndp = DeterministicProcess(index=y.index, order=3)\nX = dp.in_sample()\nX_fore = dp.out_of_sample(steps=90)\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\", color='C0')\nax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color='C3')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:42.934814Z","iopub.execute_input":"2022-01-19T21:48:42.939365Z","iopub.status.idle":"2022-01-19T21:48:43.933555Z","shell.execute_reply.started":"2022-01-19T21:48:42.938719Z","shell.execute_reply":"2022-01-19T21:48:43.931061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One way to fit more complicated trends is to increase the order of the polynomial we use. To get a better fit to the somewhat complicated trend in data, we could try using an order 11 polynomial.","metadata":{}},{"cell_type":"code","source":"dp = DeterministicProcess(index=y.index, order=11)\nX = dp.in_sample()\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\", color='C0')\nax.legend();","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-19T21:48:43.936968Z","iopub.execute_input":"2022-01-19T21:48:43.937756Z","iopub.status.idle":"2022-01-19T21:48:44.503242Z","shell.execute_reply.started":"2022-01-19T21:48:43.937718Z","shell.execute_reply":"2022-01-19T21:48:44.5008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_fore = dp.out_of_sample(steps=90)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\", color='C0')\nax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color='C3')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:44.506774Z","iopub.execute_input":"2022-01-19T21:48:44.50726Z","iopub.status.idle":"2022-01-19T21:48:45.003616Z","shell.execute_reply.started":"2022-01-19T21:48:44.507216Z","shell.execute_reply":"2022-01-19T21:48:45.002862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusionh high-order polynomials are generally not well-suited to forecasting. An order 11 polynomial will include terms like t ** 11. Terms like these tend to diverge rapidly outside of the training period making forecasts very unreliable","metadata":{}},{"cell_type":"markdown","source":"##### Seasonality features ","metadata":{}},{"cell_type":"code","source":"holidays_events = pd.read_csv(\n    path +\"/holidays_events.csv\",\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nholidays_events = holidays_events.set_index('date').to_period('D')\n\nstore_sales = pd.read_csv(\n    path +'/train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\naverage_sales = (\n    store_sales\n    .groupby('date').mean()\n    .squeeze()\n    .loc['2017'] # exploring just 2017 since it takes long for computing the whole data\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:45.004674Z","iopub.execute_input":"2022-01-19T21:48:45.004977Z","iopub.status.idle":"2022-01-19T21:48:50.264049Z","shell.execute_reply.started":"2022-01-19T21:48:45.004941Z","shell.execute_reply":"2022-01-19T21:48:50.262819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seasonal plot\n\nX = average_sales.to_frame()\nX[\"week\"] = X.index.week\nX[\"day\"] = X.index.dayofweek\nseasonal_plot(X, y='sales', period='week', freq='day');","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:50.267649Z","iopub.execute_input":"2022-01-19T21:48:50.267945Z","iopub.status.idle":"2022-01-19T21:48:51.154713Z","shell.execute_reply.started":"2022-01-19T21:48:50.267913Z","shell.execute_reply":"2022-01-19T21:48:51.153545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_periodogram(average_sales);","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:51.156358Z","iopub.execute_input":"2022-01-19T21:48:51.156628Z","iopub.status.idle":"2022-01-19T21:48:51.68918Z","shell.execute_reply.started":"2022-01-19T21:48:51.156599Z","shell.execute_reply":"2022-01-19T21:48:51.688039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both the seasonal plot and the periodogram suggest a strong weekly seasonality. From the periodogram, it appears there may be some monthly and biweekly components as well. In fact, the notes to the Store Sales dataset say wages in the public sector are paid out biweekly, on the 15th and last day of the month -- a possible origin for these seasons.","metadata":{}},{"cell_type":"markdown","source":"Using DeterministicProcess and CalendarFourier to create:\n\n- indicators for weekly seasons and\n- Fourier features of order 4 for monthly seasons.","metadata":{}},{"cell_type":"code","source":"y = average_sales.copy()\n\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\nX = dp.in_sample()\n\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.Series(\n    model.predict(X),\n    index=X.index,\n    name='Fitted',\n)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:51.690754Z","iopub.execute_input":"2022-01-19T21:48:51.690989Z","iopub.status.idle":"2022-01-19T21:48:52.300428Z","shell.execute_reply.started":"2022-01-19T21:48:51.690955Z","shell.execute_reply":"2022-01-19T21:48:52.299801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# periodogram of the deseasonalized series.\ny_deseason = y - y_pred\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodogram(y, ax=ax1)\nax1.set_title(\"Product Sales Frequency Components\")\nax2 = plot_periodogram(y_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:52.301644Z","iopub.execute_input":"2022-01-19T21:48:52.302195Z","iopub.status.idle":"2022-01-19T21:48:53.705377Z","shell.execute_reply.started":"2022-01-19T21:48:52.302161Z","shell.execute_reply":"2022-01-19T21:48:53.704419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The periodogram for the deseasonalized series lacks any large values. By comparing it to the periodogram for the original series, we can see that our model was able to capture the seasonal variation in Average Sales","metadata":{}},{"cell_type":"code","source":"# National and regional holidays in the training set\nholidays = (\n    holidays_events\n    .query(\"locale in ['National', 'Regional']\")\n    .loc['2017':'2017-08-15', ['description']]\n    .assign(description=lambda x: x.description.cat.remove_unused_categories())\n)\ndisplay(holidays)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:53.70767Z","iopub.execute_input":"2022-01-19T21:48:53.707976Z","iopub.status.idle":"2022-01-19T21:48:53.731625Z","shell.execute_reply.started":"2022-01-19T21:48:53.707943Z","shell.execute_reply":"2022-01-19T21:48:53.730639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y_deseason.plot(**plot_params)\nplt.plot_date(holidays.index, y_deseason[holidays.index], color='C3')\nax.set_title('National and Regional Holidays');","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:53.732977Z","iopub.execute_input":"2022-01-19T21:48:53.7332Z","iopub.status.idle":"2022-01-19T21:48:54.199139Z","shell.execute_reply.started":"2022-01-19T21:48:53.733171Z","shell.execute_reply":"2022-01-19T21:48:54.198543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From a plot of the deseasonalized Average Sales, it appears these holidays could have some predictive power","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n# Creating holiday features\n\nohe = OneHotEncoder(sparse=False)\n\nX_holidays = pd.DataFrame(\n    ohe.fit_transform(holidays),\n    index=holidays.index,\n    columns=holidays.description.unique(),\n)\n\nX_holidays = pd.get_dummies(holidays)\n\nX2 = X.join(X_holidays, on='date').fillna(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:54.200201Z","iopub.execute_input":"2022-01-19T21:48:54.200944Z","iopub.status.idle":"2022-01-19T21:48:54.214734Z","shell.execute_reply.started":"2022-01-19T21:48:54.20091Z","shell.execute_reply":"2022-01-19T21:48:54.212736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegression().fit(X2, y)\ny_pred = pd.Series(\n    model.predict(X2),\n    index=X2.index,\n    name='Fitted',\n)\n\ny_pred = pd.Series(model.predict(X2), index=X2.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:54.216524Z","iopub.execute_input":"2022-01-19T21:48:54.216915Z","iopub.status.idle":"2022-01-19T21:48:54.777906Z","shell.execute_reply.started":"2022-01-19T21:48:54.216883Z","shell.execute_reply":"2022-01-19T21:48:54.776059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With Onehot encoding the model predicts the holidays pretty well","metadata":{}},{"cell_type":"code","source":"# sales amounts during the holidays\ny.loc[y.index.isin(holidays.index)]","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:54.780024Z","iopub.execute_input":"2022-01-19T21:48:54.780343Z","iopub.status.idle":"2022-01-19T21:48:54.794422Z","shell.execute_reply.started":"2022-01-19T21:48:54.780309Z","shell.execute_reply":"2022-01-19T21:48:54.792452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = pd.concat([y,y_pred,y_pred-y],axis=1)\ndf3.columns = ['ground_truth','predictions','residuals']\ndf3.loc[df3.index.isin(holidays.index)].round(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:54.796408Z","iopub.execute_input":"2022-01-19T21:48:54.796691Z","iopub.status.idle":"2022-01-19T21:48:54.818071Z","shell.execute_reply.started":"2022-01-19T21:48:54.796659Z","shell.execute_reply":"2022-01-19T21:48:54.817071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With onehot encodeing the model has too much flexibility and literally memorises the values for each date. We can see from the above dataframe the model is preforming pretty well.","metadata":{}},{"cell_type":"markdown","source":"##### Lag features for store sales","metadata":{}},{"cell_type":"code","source":"store_sales = pd.read_csv(\n    path+'/train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean() \n    .unstack('family')\n    .loc['2017', ['sales', 'onpromotion']]\n)\n\nmag_sales = family_sales.loc(axis=1)[:, 'MAGAZINES']","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:48:54.820181Z","iopub.execute_input":"2022-01-19T21:48:54.820453Z","iopub.status.idle":"2022-01-19T21:49:00.109576Z","shell.execute_reply.started":"2022-01-19T21:48:54.820424Z","shell.execute_reply":"2022-01-19T21:49:00.108839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not every product family has sales showing cyclic behavior, and neither does the series of average sales. Sales of magazines, however, show patterns of growth and decay not well characterized by trend or seasons.\nTrend and seasonality will both create serial dependence that shows up in correlograms and lag plots. To isolate any purely cyclic behavior, we'll start by deseasonalizing the series.","metadata":{}},{"cell_type":"code","source":"y = mag_sales.loc[:, 'sales'].squeeze()\n\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    constant=True,\n    index=y.index,\n    order=1,\n    seasonal=True,\n    drop=True,\n    additional_terms=[fourier],\n)\nX_time = dp.in_sample()\nX_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_time, y)\ny_deseason = y - model.predict(X_time)\ny_deseason.name = 'sales_deseasoned'\n\nax = y_deseason.plot()\nax.set_title(\"Magazine Sales (deseasonalized)\");","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:49:00.110829Z","iopub.execute_input":"2022-01-19T21:49:00.111784Z","iopub.status.idle":"2022-01-19T21:49:00.55689Z","shell.execute_reply.started":"2022-01-19T21:49:00.111735Z","shell.execute_reply":"2022-01-19T21:49:00.555227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Does this deseasonalized series show cyclic patterns? To confirm our intuition, we can try to isolate cyclic behavior using a moving-average plot just like we did with trend. The idea is to choose a window long enough to smooth over short-term seasonality, but short enough to still preserve the cycles.","metadata":{}},{"cell_type":"code","source":"# Creating a seven-day moving average from y, the series of magazine sales.\n# Using a centered window, not setting the min_periods argument.\n\ny_ma = y.rolling(7, center=True).mean()\n\nax = y_ma.plot()\nax.set_title(\"Seven-Day Moving Average\");","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:49:00.558894Z","iopub.execute_input":"2022-01-19T21:49:00.559279Z","iopub.status.idle":"2022-01-19T21:49:00.915343Z","shell.execute_reply.started":"2022-01-19T21:49:00.559233Z","shell.execute_reply":"2022-01-19T21:49:00.914397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The moving average plot resembles the plot of the deseasonalized series. In both, we can see cyclic behavior indicated.","metadata":{}},{"cell_type":"code","source":"# Let's examine our deseasonalized series for serial dependence.\n\nplot_pacf(y_deseason, lags=8);\nplot_lags(y_deseason, lags=8, nrows=2);","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:49:00.916641Z","iopub.execute_input":"2022-01-19T21:49:00.916818Z","iopub.status.idle":"2022-01-19T21:49:02.831613Z","shell.execute_reply.started":"2022-01-19T21:49:00.916794Z","shell.execute_reply":"2022-01-19T21:49:02.830777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The correlogram indicates the first lag is likely to be significant, as well as possibly the sixth lag. The lag plot suggests some non-linear effect as well.","metadata":{}},{"cell_type":"markdown","source":"- We know  leading indicator is a series whose values at one time can be used to predict the target at a future time -- a leading indicator provides \"advance notice\" of changes in the target.\n- The dataset includes a time series that could potentially be useful as a leading indicator -- the onpromotion series, which contains the number of items on a special promotion that day. Since the company itself decides when to do a promotion, there's no worry about \"lookahead leakage\"; we could use Tuesday's onpromotion value to forecast sales on Monday, for instance.","metadata":{}},{"cell_type":"code","source":"onpromotion = mag_sales.loc[:, 'onpromotion'].squeeze().rename('onpromotion')\n\n# Drop the New Year outlier\nplot_lags(x=onpromotion.iloc[1:], y=y_deseason.iloc[1:], lags=3, leads=3, nrows=1);","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:49:02.833731Z","iopub.execute_input":"2022-01-19T21:49:02.834805Z","iopub.status.idle":"2022-01-19T21:49:03.883072Z","shell.execute_reply.started":"2022-01-19T21:49:02.834756Z","shell.execute_reply":"2022-01-19T21:49:03.882051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The lag plot indicates that both leading and lagged values of onpromotion are correlated with magazine sales. This suggests that both kinds of values could be useful as features.\nIn addition, the leading values seem to have some non-linear effect.","metadata":{}},{"cell_type":"code","source":"# time series features\nX_lags = make_lags(y_deseason, lags=1)\n\nX_promo = pd.concat([\n    make_lags(onpromotion, lags=1),\n    onpromotion,\n    make_leads(onpromotion, leads=1),\n], axis=1)\n\nX_oil = pd.DataFrame()\n\nX = pd.concat([X_time, X_lags, X_promo, X_oil], axis=1).dropna()\ny, X = y.align(X, join='inner')","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:49:03.884079Z","iopub.execute_input":"2022-01-19T21:49:03.884259Z","iopub.status.idle":"2022-01-19T21:49:03.899171Z","shell.execute_reply.started":"2022-01-19T21:49:03.884235Z","shell.execute_reply":"2022-01-19T21:49:03.89773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport math\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n\nmodel = LinearRegression(fit_intercept=False).fit(X_train, y_train)\ny_fit = pd.Series(model.predict(X_train), index=X_train.index).clip(0.0)\ny_pred = pd.Series(model.predict(X_valid), index=X_valid.index).clip(0.0)\n\nrmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\n\nnum_data_train = X_train.shape[0]\nnum_data_valid = X_valid.shape[0]\n\nmse_train = mean_squared_error(y_train,y_fit)\nrmse_train = math.sqrt(mse_train/num_data_train)\nmae_train =mean_absolute_error(y_train,y_fit)\n\nmse_valid = mean_squared_error(y_valid,y_pred)\nrmse_valid = math.sqrt(mse_valid/num_data_valid)\nmae_valid =mean_absolute_error(y_valid,y_pred)\n\nprint(f'Training RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')\n\nprint(f'\\nTraining RMSE: {rmse_train:.5f}')\nprint(f'Validation RMSE: {rmse_valid:.5f}')\n\nprint(f'\\nTraining MAE: {mae_train:.5f}')\nprint(f'Validation MAE: {mae_valid:.5f}')\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\nax = y_pred.plot(ax=ax, label=\"Forecast\", color='C3')\nax.legend();\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:49:03.902678Z","iopub.execute_input":"2022-01-19T21:49:03.903015Z","iopub.status.idle":"2022-01-19T21:49:04.461299Z","shell.execute_reply.started":"2022-01-19T21:49:03.902982Z","shell.execute_reply":"2022-01-19T21:49:04.460265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model includes moving averages and other rolling statistics in their feature sets. Such features seem to be especially useful when used with GBDT algorithms like XGBoost.","metadata":{}}]}