{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Store Sales - Time Series Forecasting**\nUsing machine learning to predict grocery sales\n<hr>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.stats import linregress\nfrom sklearn import preprocessing\nfrom scipy import stats\nimport warnings\nimport math\nimport datetime\nsns.set()\nsns.set_style('whitegrid')\n# plt.style.use(\"dark_background\")\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:27.953802Z","iopub.execute_input":"2022-01-10T09:13:27.954273Z","iopub.status.idle":"2022-01-10T09:13:27.964928Z","shell.execute_reply.started":"2022-01-10T09:13:27.954221Z","shell.execute_reply":"2022-01-10T09:13:27.964128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I. Getting Started\n<hr>","metadata":{}},{"cell_type":"code","source":"path = '../input/store-sales-time-series-forecasting/'\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-10T09:13:27.966813Z","iopub.execute_input":"2022-01-10T09:13:27.967554Z","iopub.status.idle":"2022-01-10T09:13:27.98359Z","shell.execute_reply.started":"2022-01-10T09:13:27.967501Z","shell.execute_reply":"2022-01-10T09:13:27.982826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(path + 'train.csv', parse_dates=['date'], infer_datetime_format=True)\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:27.984668Z","iopub.execute_input":"2022-01-10T09:13:27.984998Z","iopub.status.idle":"2022-01-10T09:13:31.174036Z","shell.execute_reply.started":"2022-01-10T09:13:27.984947Z","shell.execute_reply":"2022-01-10T09:13:31.172868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n - **store_nbr** (id) identifies the store at which the products are sold.\n - **family** (categorical) identifies the type of product sold.\n - **sales** (discrete) gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n - **onpromotion** (discrete) gives the total number of items in a product family that were being promoted at a store at a given date.","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(path + 'test.csv', parse_dates = ['date'], infer_datetime_format=True)\nids = test['id']\npd.concat([test.head(1), test.tail(1)], axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.175496Z","iopub.execute_input":"2022-01-10T09:13:31.175794Z","iopub.status.idle":"2022-01-10T09:13:31.225879Z","shell.execute_reply.started":"2022-01-10T09:13:31.17576Z","shell.execute_reply":"2022-01-10T09:13:31.224806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Need to predict the sales between August 16 - 31.","metadata":{}},{"cell_type":"code","source":"# creating a combined dataset with both test and train rows.\nn_train = train.shape[0]\nn_test = test.shape[0]\ndf = pd.concat([train, test], axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.228883Z","iopub.execute_input":"2022-01-10T09:13:31.229252Z","iopub.status.idle":"2022-01-10T09:13:31.389491Z","shell.execute_reply.started":"2022-01-10T09:13:31.229205Z","shell.execute_reply":"2022-01-10T09:13:31.388617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stores = pd.read_csv(path + 'stores.csv')\nstores.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.390689Z","iopub.execute_input":"2022-01-10T09:13:31.39094Z","iopub.status.idle":"2022-01-10T09:13:31.409708Z","shell.execute_reply.started":"2022-01-10T09:13:31.390908Z","shell.execute_reply":"2022-01-10T09:13:31.408723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Store metadata, including city, state, type, and cluster.\n- cluster is a grouping of similar stores.","metadata":{}},{"cell_type":"code","source":"oil = pd.read_csv(path + 'oil.csv', parse_dates=['date'], infer_datetime_format=True)\noil.tail(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.411504Z","iopub.execute_input":"2022-01-10T09:13:31.412219Z","iopub.status.idle":"2022-01-10T09:13:31.433126Z","shell.execute_reply.started":"2022-01-10T09:13:31.412144Z","shell.execute_reply":"2022-01-10T09:13:31.432401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Daily Price of oil in Ecuador. We have the data between 16 - 31 August 2017, so this can be used as a feature.","metadata":{}},{"cell_type":"code","source":"holidays = pd.read_csv(path + 'holidays_events.csv', parse_dates=['date'], infer_datetime_format=True)\nholidays.tail(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.434353Z","iopub.execute_input":"2022-01-10T09:13:31.436264Z","iopub.status.idle":"2022-01-10T09:13:31.458211Z","shell.execute_reply.started":"2022-01-10T09:13:31.436203Z","shell.execute_reply":"2022-01-10T09:13:31.457224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Holidays and Events, with metadata\n- NOTE: Pay special attention to the transferred column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge.\n- Additional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).","metadata":{}},{"cell_type":"code","source":"transactions = pd.read_csv(path + 'transactions.csv', parse_dates=['date'], infer_datetime_format=True)\ntransactions.tail(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.459603Z","iopub.execute_input":"2022-01-10T09:13:31.459858Z","iopub.status.idle":"2022-01-10T09:13:31.525634Z","shell.execute_reply.started":"2022-01-10T09:13:31.459821Z","shell.execute_reply":"2022-01-10T09:13:31.52467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We don't have transaction data between 16 - 31 August 2017, so it's this data can't be used for predictions.","metadata":{}},{"cell_type":"markdown","source":"### Additional Notes\n- Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n- A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake.","metadata":{}},{"cell_type":"markdown","source":"### Creating necessary columns using date.","metadata":{}},{"cell_type":"code","source":"df[\"year\"],df[\"month\"], df[\"day\"] = pd.DatetimeIndex(df['date']).year, pd.DatetimeIndex(df['date']).month, pd.DatetimeIndex(df['date']).day\n\ndf['month'].replace([var for var in range (1, 13)],['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec'],inplace=True)\ndf['month'] = pd.Categorical(df['month'],\n                             categories=['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec'],\n                             ordered=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:31.526953Z","iopub.execute_input":"2022-01-10T09:13:31.527196Z","iopub.status.idle":"2022-01-10T09:13:32.773117Z","shell.execute_reply.started":"2022-01-10T09:13:31.527168Z","shell.execute_reply":"2022-01-10T09:13:32.771703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.set_index('date')\ndf['dayofyear'] = df.index.dayofyear\ndf['dayofweek'] = df.index.dayofweek\ndf['week'] = df.index.week","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:32.775777Z","iopub.execute_input":"2022-01-10T09:13:32.776122Z","iopub.status.idle":"2022-01-10T09:13:34.637737Z","shell.execute_reply.started":"2022-01-10T09:13:32.776082Z","shell.execute_reply":"2022-01-10T09:13:34.636676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.iloc[ : n_train, ]\ntest = df.iloc[n_train : , ]","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:34.640224Z","iopub.execute_input":"2022-01-10T09:13:34.640589Z","iopub.status.idle":"2022-01-10T09:13:34.647202Z","shell.execute_reply.started":"2022-01-10T09:13:34.640539Z","shell.execute_reply":"2022-01-10T09:13:34.645993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's first analyse the missing values.","metadata":{}},{"cell_type":"code","source":"def get_missingvalues(data):\n\tstats = data.isnull().sum()\n\tif stats.max() == 0:\n\t\tprint(\"No missing values :)\")\n\telse:\n\t\tfor feature in stats.index:\n\t\t\tif stats[feature] > 0:\n\t\t\t\tprint('{} has {} values missing.'.format(feature, stats[feature]))\n\nprint(\"1. Main dataframe: \")\nget_missingvalues(df)\nprint(\"2. Oil dataframe: \")\nget_missingvalues(oil)\nprint(\"3. Holidays dataframe: \")\nget_missingvalues(holidays)\nprint(\"4. Transactional dataframe: \")\nget_missingvalues(transactions)\nprint(\"5. Stores dataframe: \")\nget_missingvalues(stores)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:34.64907Z","iopub.execute_input":"2022-01-10T09:13:34.649377Z","iopub.status.idle":"2022-01-10T09:13:34.860651Z","shell.execute_reply.started":"2022-01-10T09:13:34.649336Z","shell.execute_reply":"2022-01-10T09:13:34.859773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Oil** is the only dataframe with missing values.","metadata":{}},{"cell_type":"markdown","source":"# II. Exploratory Data Analysis\n<hr>","metadata":{}},{"cell_type":"markdown","source":"### A) Distribution","metadata":{}},{"cell_type":"code","source":"# Let's check distribution of sales - target variable.\nsns.distplot(train['sales'], kde = True)\nprint(\"Skew : {} Kurtosis : {}\".format(train['sales'].skew(), train['sales'].kurt()))\nplt.title(\"Distribution of feature - sales\");","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:34.864375Z","iopub.execute_input":"2022-01-10T09:13:34.864669Z","iopub.status.idle":"2022-01-10T09:13:45.234748Z","shell.execute_reply.started":"2022-01-10T09:13:34.864634Z","shell.execute_reply":"2022-01-10T09:13:45.233863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the sales are close to 0.","metadata":{}},{"cell_type":"code","source":"# Let's check yearly sales. \nplt.figure(figsize = (18, 9))\nsns.boxenplot(data = train, x = 'year', y = 'sales', palette=\"RdPu_r\")\nplt.title(\"Distribution of sales in a year\", fontsize = 20);","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:45.236572Z","iopub.execute_input":"2022-01-10T09:13:45.237106Z","iopub.status.idle":"2022-01-10T09:13:46.609768Z","shell.execute_reply.started":"2022-01-10T09:13:45.237058Z","shell.execute_reply":"2022-01-10T09:13:46.608639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### B) Time Analysis - **Trend**","metadata":{}},{"cell_type":"code","source":"# let's plot oil prices.\nfig, ax = plt.subplots(figsize = (18, 10))\ndata = oil.set_index('date')\ntrend = data.rolling(window=7, center = True, min_periods = 3).mean()\nax.plot(trend, linewidth = 3, color = 'red')\nsns.scatterplot(data = oil, x = 'date', y = 'dcoilwtico', color = '0.5', ax=ax)\nsns.lineplot(data = oil, x = 'date', y = 'dcoilwtico', color = '0.5', ax=ax, linewidth = 0.5)\nax.set_title(\"Oil Prices\", fontsize = 18);","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:46.612002Z","iopub.execute_input":"2022-01-10T09:13:46.612353Z","iopub.status.idle":"2022-01-10T09:13:47.101089Z","shell.execute_reply.started":"2022-01-10T09:13:46.612309Z","shell.execute_reply":"2022-01-10T09:13:47.10015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prices fell sharply in 2014.","metadata":{}},{"cell_type":"code","source":"# Let's start by plotting sales price. \nfig, ax = plt.subplots(figsize = (16, 10))\ndata = train.loc[ : , 'sales']\ndata = data.groupby('date').sum()\ntrend = data.rolling(window=30, center=True, min_periods=15).mean()\nax.plot(trend, aa = True, color = '#C94B94')\ntrend = data.rolling(window=365, center=True, min_periods=184).mean()\nax.plot(trend, color = '#490E5E', linewidth = 3)\nax.legend(['30 day rolling window', '365 day rolling window'])\nax.set_title(\"Trend - sales\", fontsize = 18);","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:47.102499Z","iopub.execute_input":"2022-01-10T09:13:47.103724Z","iopub.status.idle":"2022-01-10T09:13:47.594646Z","shell.execute_reply.started":"2022-01-10T09:13:47.103666Z","shell.execute_reply":"2022-01-10T09:13:47.594029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upward trend present. Maybe related to lower oil prices? ","metadata":{}},{"cell_type":"markdown","source":"### C) Time Analysis - **Seasonality**","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(3, 1, figsize = (16, 15))\n\nfor year, color in zip(train.year.unique(), sns.color_palette(\"RdPu_r\")):\n#     yearly = train[train.year == year]\n    sns.lineplot(data = train[train.year == year].groupby('dayofyear')['sales'].mean(), color=color,ax = axs[0], linewidth = 1.5, label = str(year))\nsns.lineplot(data = train.groupby('dayofyear')['sales'].mean(), color = 'black',ax = axs[0], linewidth = 6, label = 'mean')   \n\n    \naxs[0].set_title(\"Yearly Sales\", fontsize = 18)\n    \nfor month, color in zip(train.month.unique(), sns.color_palette(\"winter\", n_colors = 12)):\n#     monthly = train[train.month == month]\n    sns.lineplot(data = train[train.month == month].groupby('day')['sales'].mean(), color=color,ax = axs[1], linewidth = 1.5, label = month)             \nsns.lineplot(data = train.groupby('day')['sales'].mean(), color = 'black',ax = axs[1], linewidth = 6, label = 'mean')   \n\naxs[1].set_title(\"Monthly Sales\", fontsize = 18)\n\nfor week, color in zip(train.week.unique(), sns.color_palette('summer', n_colors = 53)):\n    sns.lineplot(data = train[train.week == week].groupby('dayofweek')['sales'].mean(), color=color, ax = axs[2], linewidth = 1.5)\nsns.lineplot(data = train.groupby('dayofweek')['sales'].mean(), color = 'black', ax = axs[2], linewidth = 6, label = 'mean')    \n\naxs[2].set_title(\"Weekly Sales\", fontsize = 18)\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:47.596165Z","iopub.execute_input":"2022-01-10T09:13:47.597075Z","iopub.status.idle":"2022-01-10T09:13:51.766092Z","shell.execute_reply.started":"2022-01-10T09:13:47.597038Z","shell.execute_reply":"2022-01-10T09:13:51.765317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis : \n- Sales start slow but pick up as the year ends. Maybe because of holidays like christmas? \n- Montly sales are highest during the start and end of the month, and a slight uptick is present during the 15th. Could be because of public sector salaries.\n- Weekly sales have a strong seasonality, where sales dip during the middle of the week and peak at the ends.","metadata":{}},{"cell_type":"markdown","source":"#### Plotting Periodogram\nCreating a periodogram will give us a better understanding of the exact time periods for seasons.","metadata":{}},{"cell_type":"code","source":"# Creating a periodogram.\nfrom scipy.signal import periodogram\nfs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\nfreqencies, spectrum = periodogram(\n    train['sales'],\n    fs=fs,\n    detrend='linear',\n    window=\"boxcar\",\n    scaling='spectrum',\n)\nfig, ax = plt.subplots(figsize = (16, 5))\nax.step(freqencies, spectrum, color=\"purple\")\nax.set_xscale(\"log\")\nax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\nax.set_xticklabels(\n    [\n        \"Annual (1)\",\n        \"Semiannual (2)\",\n        \"Quarterly (4)\",\n        \"Bimonthly (6)\",\n        \"Monthly (12)\",\n        \"Biweekly (26)\",\n        \"Weekly (52)\",\n        \"Semiweekly (104)\",\n    ],\n    rotation=60,\n)\nax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\nax.set_ylabel(\"Variance\")\nax.set_title(\"Periodogram\", fontsize = 18);","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:51.767443Z","iopub.execute_input":"2022-01-10T09:13:51.768326Z","iopub.status.idle":"2022-01-10T09:13:54.55822Z","shell.execute_reply.started":"2022-01-10T09:13:51.768261Z","shell.execute_reply":"2022-01-10T09:13:54.557408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Monthly, Biweekly, Weekly, Semiweekly seasonality present.","metadata":{}},{"cell_type":"markdown","source":"### D) **C → T** (Categorical vs Target Analysis)\nCategorical features are - store_nbr and family.","metadata":{}},{"cell_type":"code","source":"data = train.groupby('store_nbr')['sales'].mean().sort_values(ascending = False)\nplt.figure(figsize = (18, 10))\nsns.barplot(data=data, x = data.index.astype(\"str\"), y = data, palette = \"RdPu_r\",   errcolor=\".2\", edgecolor=\".2\")\nplt.title(\"Sales vs Store\", fontsize = 18);","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:54.559737Z","iopub.execute_input":"2022-01-10T09:13:54.559994Z","iopub.status.idle":"2022-01-10T09:13:56.112189Z","shell.execute_reply.started":"2022-01-10T09:13:54.55994Z","shell.execute_reply":"2022-01-10T09:13:56.111258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Store has a strong effect on sales.","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize = (18, 10))\n\ndata_family = train.groupby('family')['sales'].sum().sort_values(ascending = False)\nsns.barplot(y=data_family.index, x=data_family.values, palette = \"RdPu_r\",   errcolor=\".2\", edgecolor=\".2\", ax = axs[0])\naxs[0].set_title(\"Sales vs Item Family\", fontsize = 18)\n\nothers = data_family[-20:].sum()\ndata_family = data_family[:13]\ndata_family['OTHERS'] = others\nplt.title(\"Distribution of sales\", fontsize = 18)\ndata_family.plot.pie()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:56.113932Z","iopub.execute_input":"2022-01-10T09:13:56.114495Z","iopub.status.idle":"2022-01-10T09:13:57.320741Z","shell.execute_reply.started":"2022-01-10T09:13:56.114446Z","shell.execute_reply":"2022-01-10T09:13:57.319606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some products are more poplular than others.","metadata":{}},{"cell_type":"markdown","source":"### E) **D → T** (Discrete vs Target analysis)\nLet's analyize the only discrete independent variable - onpromotion.","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize = (18, 7))\nsns.heatmap(train[['sales', 'onpromotion']].corr(), square = True, annot = True, cmap = \"RdPu\", vmax=1, vmin=-1, fmt = \".1f\", ax = axs[0]);\naxs[0].set_title(\"Correlation Plot\")\n\nsns.scatterplot(data = train, x = 'onpromotion', y = 'sales',ax = axs[1], ci = None, color = '#490E5E')\naxs[1].set_title(\"Linear Relation\")\nfig.suptitle('D → T (sales vs onpromotion)', fontsize = 18);","metadata":{"execution":{"iopub.status.busy":"2022-01-10T09:13:57.322277Z","iopub.execute_input":"2022-01-10T09:13:57.32256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Strong correlation (0.4)","metadata":{}},{"cell_type":"markdown","source":"### F) Holidays","metadata":{}},{"cell_type":"code","source":"# Lets get all unique holidays and their dates.\n# there are 103 holidays. Let's focus on national holidays.\nholidays = holidays.query(\"locale in ['National']\").set_index('date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Any holiday with a +/- is a day leading upto the holiday. Let's get rid of that to reduce dimensions.","metadata":{}},{"cell_type":"code","source":"for date in holidays.index:\n    name=holidays.loc[date]['description']\n    if '+' in name or '-' in name:\n        holidays.drop(index = date, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's see how sales change in 2016 because of holidays","metadata":{}},{"cell_type":"code","source":"dates = [var for var in holidays.loc[\"2016\", ].index if var in train.index]\nfig, ax = plt.subplots(figsize = (18, 7))\nsns.lineplot(data = train[train['year'] == 2016].sales, estimator = 'sum', ax = ax, color='#C94B94', label = 'sales')\ndata = train.groupby(by = train.index).sum().loc[dates, 'sales']\nplt.scatter(data.index, data, s = 150, color = '#490E5E', label = 'Holiday');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### No clear trend. We'll have to deseason the data first.","metadata":{}},{"cell_type":"markdown","source":"# III. Feature Engineering\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## Adding Lag Features for _sales_","metadata":{"execution":{"iopub.execute_input":"2021-12-31T20:13:40.884013Z","iopub.status.busy":"2021-12-31T20:13:40.883635Z","iopub.status.idle":"2021-12-31T20:13:40.899045Z","shell.execute_reply":"2021-12-31T20:13:40.898291Z","shell.execute_reply.started":"2021-12-31T20:13:40.883958Z"}}},{"cell_type":"markdown","source":"**NOTE :** We can't just simple use the shift function to get lags here. That will give us the sales of some other family of products sold that day.\n<br> We need to take the sales of the same family and store_nbr.","metadata":{}},{"cell_type":"code","source":"df = df.reset_index()\ndf = df.set_index(['date', 'store_nbr', 'family'])\nentries_perday = len(df.loc['2013-01-01'])\ndf = df.reset_index().set_index('date')\nprint('Number of entries in a day across all stores : {}'.format(entries_perday))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 1782 entries in a day. So if row 1 is about store 1, family - 'AUTOMOTIVE', row 1783 will be about the same store, and family but on the next day.","metadata":{}},{"cell_type":"code","source":"for lag in range(1, 11):\n    df['sales_lag' + str(lag)] = df['sales'].shift(1782 * lag)\ndf.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Successfully added lag features.","metadata":{}},{"cell_type":"code","source":"train = df.iloc[:n_train, ]\ntest = df.iloc[n_train:, ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analysis of lagged sales","metadata":{}},{"cell_type":"markdown","source":"##### Corr-plot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\ncolumns = [col for col in train.columns if 'sales' in col]\nsns.heatmap(data = train[columns].corr(), square = True,\n            annot = True, cmap = \"Reds\", vmax=1, vmin=.83, fmt = \".3f\")\nplt.xticks(rotation = 40)\nplt.title('Correlation - sales vs lagged sales', fontsize = 18);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Scatter Plot","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 5, figsize = (15, 6))\naxs = axs.flatten()\nfor i in range(1, 11):\n    feature = 'sales_lag' + str(i)\n    sns.scatterplot(x=train[feature], y=train['sales'], ax=axs[i - 1], s=5)\n    axs[i - 1].set_title(feature, fontsize = 14)\n\nplt.suptitle('Scatterplot - Lags vs Sales', fontsize = 18)\nplt.tight_layout();","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like a linear relation, but with a lot of outliers, because of the large number of rows.","metadata":{}},{"cell_type":"code","source":"df.drop(columns = ['sales_lag1', 'sales_lag2', 'sales_lag3', 'sales_lag4', 'sales_lag5', 'sales_lag6', 'sales_lag8', 'sales_lag9', 'sales_lag10'], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's a combined dataset.","metadata":{}},{"cell_type":"code","source":"# Cleaning oil price dataset.\noil = oil.set_index('date')\noil = oil.rename(columns = {'dcoilwtico' : 'oilprice'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Removing duplicate holidays \nIn certain dates many holidays coincide with each other. This will cause problems while joining the datasets. So i'm removing duplicates.","metadata":{}},{"cell_type":"code","source":"holidays = holidays.groupby(holidays.index).first()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Concatenating everything","metadata":{}},{"cell_type":"code","source":"df = df.join(oil, on = 'date', how = 'left')\ndf = df.join(holidays, on = 'date', how = 'left')\ndf['oilprice'] = df['oilprice'].fillna(method = 'bfill')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns = ['id', 'dayofyear', 'week', 'day', 'year', 'month'], inplace = True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dealing with categorical variables\nReplacing holidays with a single feature, which contains weather the day is a holiday or a work day can reduce dimensionality.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"df['work_day'] = 1\ndf.loc[df['dayofweek'] > 4, 'work_day'] = 0\ndf.loc[df['description'].notnull(), 'work_day'] = 0\ndf.loc[df.type == 'Bridge', 'work_day'] = 0\ndf.loc[df.type == 'Work Day', 'work_day'] = 1\ndf.loc[df.type == 'Transfer', 'work_day'] = 0\ndf.loc[(df.type == 'Holiday') & (df.transferred == False), 'work_day'] = 0\ndf.loc[(df.type == 'Holiday') & (df.transferred == True), 'work_day'] = 0\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns = ['locale', 'locale_name', 'description', 'transferred'],  inplace = True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=['type'], drop_first=False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating dummy variables for month, and day of week","metadata":{}},{"cell_type":"code","source":"df.dayofweek = df.dayofweek.astype('str')\ndf = pd.get_dummies(df, columns = ['dayofweek'], drop_first=True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.iloc[:n_train, ]\ntest = df.iloc[n_train:, ]","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating a LinearModel using only time.\nLet's create a model without using other features like oil-price, store-nbr, family etc, to get a idea about how trends and seasons look in our data.","metadata":{}},{"cell_type":"markdown","source":"#### Creating Statsmodel Deterministic Processs","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n# choosing order = 4 because monthly, biweekly, and weekly periodicity was observered in the periodogram.\nfourier = CalendarFourier(freq=\"W\", order=4)\ndata = train.reset_index().set_index(['store_nbr', 'family', 'date'])\ny = data['sales'].unstack(['store_nbr', 'family'])\n\ndp = DeterministicProcess(\n    index= y.index,\n    order=1,\n    seasonal=False,\n    constant=False,\n    additional_terms = [fourier],\n    drop = True\n)\n\nX = dp.in_sample()\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's look at our sin/cos waves created by fourier trainsform.\nfig, axs = plt.subplots(1, 2, figsize = (18, 5))\n\nfor feature, color in zip(X.columns[3: ], sns.color_palette('winter', n_colors=8)):\n    if feature.find('sin') != -1:\n        axs[0].plot(X[feature].head(8), color = color)\n    elif feature.find('cos') != -1:\n        axs[1].plot(X[feature].head(8), color = color)\n\naxs[0].set_title('sin', fontsize = 18)\naxs[1].set_title('cos', fontsize = 18)\n\nplt.suptitle('Fourier Waves', fontsize = 24);","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.DataFrame(data = model.predict(X),\n                      index = y.index,\n                      columns=y.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(4, 1, figsize = (18, 15))\ndata = y.mean(axis = 1)\ny_pred = y_pred.mean(axis = 1)\n\n# plotting overall trend\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[0].plot(trend, linewidth = 1, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[0].plot(y_pred,  linewidth = 2, color = (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[0].set_title(\"Overall Prediction\", fontsize = 18);\naxs[0].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction'])\n\n# plotting yearly trend\ndata = data.loc['2016']\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[1].plot(trend, linewidth = 2, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[1].plot(y_pred.loc['2016'], linewidth = 3, color =  (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[1].set_title(\"Yearly Prediction - 2016\", fontsize = 18);\naxs[1].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction'])\n\n# plotting montly trend\ndata = data.loc['2016-01']\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[2].plot(trend, linewidth = 2, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[2].plot(y_pred.loc['2016-01'], linewidth = 3, color =  (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[2].set_title(\"Monthly Prediction - Jan 2016\", fontsize = 18);\naxs[2].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction']);\n\n# plotting weekly trend\ndata = data.loc['2016-01'].iloc[3:10]\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[3].plot(trend, linewidth = 2, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[3].plot(y_pred.loc['2016-01-04' : '2016-01-10'], linewidth = 3, color = (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[3].set_title(\"Weekly Prediction - Jan First week 2016\", fontsize = 18);\naxs[3].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction']);\n\nplt.tight_layout();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Our model follows all seasons reasonably well!","metadata":{}},{"cell_type":"markdown","source":"### Next, let's check the effect of holidays on Prediction.","metadata":{}},{"cell_type":"code","source":"delta = y.mean(axis=1) - y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates = [var for var in holidays.loc[\"2016\", ].index if var in train.index]\n\npoints = delta.to_frame(name = 'sales').loc['2016']\npoints = points.groupby(by = points.index).mean()\n\nfig, ax = plt.subplots(figsize = (18, 8))\nax.plot(points, color = 'lightgrey')\nplt.scatter(x = points.index, y = points['sales'], color='#C94B94', s = 5)\nax.scatter(x = dates, y = points.loc[dates, 'sales'], s = 100,  color = (0.0, 0.3333333333333333, 0.8333333333333334))\nplt.plot([datetime.datetime(2016, 1, 1), datetime.datetime(2017, 1, 1)], [0, 0], color = 'black', linewidth = 1)\nplt.title('Error Explained by Holidays', fontsize = 16);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Certain Holidays like New Years day can reduce errors.","metadata":{}},{"cell_type":"markdown","source":"# IV. Modelling\n<hr>","metadata":{}},{"cell_type":"code","source":"train.drop(columns = ['store_nbr', 'family'], inplace = True)\ntrain = train.groupby(by = train.index).first()\nX = X.join(train, how = 'left')\nX = X.fillna(0)\nX.drop(columns = ['sales', 'work_day'], inplace = True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## _Ridge Regression_","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import  Ridge\nridge_reg = Ridge(random_state=1)\nridge_reg.fit(X, y)\ny_pred = pd.DataFrame(ridge_reg.predict(X), index=y.index, columns=y.columns)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\ny_pred   = y_pred.stack(['store_nbr', 'family']).reset_index()\ny_target = y.stack(['store_nbr', 'family']).reset_index().copy()\n\ny_pred.columns = ['date', 'store_nbr', 'family', 'sales']\ny_target.columns = ['date', 'store_nbr', 'family', 'sales']\ny_target['sales_pred'] = y_pred['sales'].clip(0.)\n\ny_target.groupby('family').apply(lambda r: mean_squared_log_error(r['sales'], r['sales_pred'])).sort_values(ascending=False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}