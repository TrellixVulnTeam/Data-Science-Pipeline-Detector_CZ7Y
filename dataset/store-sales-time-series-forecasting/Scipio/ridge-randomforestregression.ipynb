{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T00:29:37.582281Z","iopub.execute_input":"2021-12-22T00:29:37.582645Z","iopub.status.idle":"2021-12-22T00:29:37.611243Z","shell.execute_reply.started":"2021-12-22T00:29:37.582532Z","shell.execute_reply":"2021-12-22T00:29:37.61045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport time\nimport os\n\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess, Fourier\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\n\nfrom joblib import Parallel, delayed\nimport warnings\n\nfrom path import Path","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:29:37.612518Z","iopub.execute_input":"2021-12-22T00:29:37.612902Z","iopub.status.idle":"2021-12-22T00:29:39.322674Z","shell.execute_reply.started":"2021-12-22T00:29:37.612872Z","shell.execute_reply":"2021-12-22T00:29:39.321912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[[](http://)](http://)","metadata":{}},{"cell_type":"markdown","source":"<font size=\"4\"> This kernel is based on https://www.kaggle.com/xholisilemantshongo/modeling-sales-3-types-of-regression, so if you like my notebook please upvote his notebook too. I could improve the PL by using different dataframes for training Ridge and  RandomForestRegressor and by using optuna to optimize hyperparameters. </font>","metadata":{}},{"cell_type":"markdown","source":"## Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:29:39.323641Z","iopub.execute_input":"2021-12-22T00:29:39.32384Z","iopub.status.idle":"2021-12-22T00:29:39.32839Z","shell.execute_reply.started":"2021-12-22T00:29:39.323815Z","shell.execute_reply":"2021-12-22T00:29:39.327626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Paths","metadata":{}},{"cell_type":"code","source":"path = Path('../input/store-sales-time-series-forecasting')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:29:39.330443Z","iopub.execute_input":"2021-12-22T00:29:39.333246Z","iopub.status.idle":"2021-12-22T00:29:39.340372Z","shell.execute_reply.started":"2021-12-22T00:29:39.333203Z","shell.execute_reply":"2021-12-22T00:29:39.339608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating common dataframes","metadata":{}},{"cell_type":"code","source":"def get_calendar():\n\n    events_df = create_events_df()\n \n\n    calendar = pd.DataFrame({\"date\" : pd.date_range('2013-01-01', '2017-08-31')} )\n    \n    calendar = add_events_df_columns(calendar)      \n    calendar = add_dofw_column(calendar)\n    calendar = add_wd_column(calendar)\n    calendar = add_dcoilwtico_column(calendar)\n    calendar = add_rolling_mean_oil_column(calendar, 7)\n\n    \n    calendar[\"date\"] = calendar.date.dt.to_period('D')\n    calendar = calendar.set_index(\"date\")\n    \n    \n    calendar = calendar[ [\"dofw\", \"type\", \"wd\",  \"dcoilwtico\", \"oil_ma7\"] ]\n    calendar[\"type\"] = calendar[\"type\"].fillna(\"None\")\n    \n \n    return calendar\n\n\n\n\ndef get_y():\n    df_train = pd.read_csv(path / 'train.csv',\n                           usecols=['store_nbr', 'family', 'date', 'sales'],\n                           dtype={'store_nbr': 'category', 'family': 'category', 'sales': 'float32'},\n                           parse_dates=['date'], infer_datetime_format=True)\n    df_train.date = df_train.date.dt.to_period('D')\n    df_train = df_train.set_index(['store_nbr', 'family', 'date']).sort_index()\n\n    y = df_train.unstack(['store_nbr', 'family'])\n    \n    \n    return y\n\n\n\n\ndef add_events_df_columns(calendar):\n    events_df = create_events_df()\n    calendar = calendar.merge(events_df, on=\"date\", how='left')\n    \n    return calendar\n\n\n\ndef add_dcoilwtico_column(calendar):\n    oil_df = create_oil_df()\n    calendar = calendar.merge(oil_df, on=\"date\", how=\"left\")\n    calendar[\"dcoilwtico\"] = calendar[\"dcoilwtico\"].fillna(method=\"ffill\")\n\n    return calendar\n    \n\ndef add_rolling_mean_oil_column(calendar, num):\n    calendar[f\"oil_ma{num}\"]  = calendar['dcoilwtico'].rolling(num).mean()\n    calendar[f\"oil_ma{num}\"]  = calendar[f\"oil_ma{num}\"].fillna(method=\"ffill\")\n    \n    return calendar\n\n\n\ndef add_dofw_column(calendar):\n    calendar['dofw'] = calendar[\"date\"].apply(lambda x: x.dayofweek)\n    return calendar\n\n\ndef add_wd_column(calendar):\n    calendar['wd'] = True\n\n    calendar.loc[calendar.dofw > 4, 'wd'] = False\n    calendar.loc[calendar.type == 'Bridge'  , 'wd'] = False\n    calendar.loc[calendar.type == 'Work Day', 'wd'] = True\n    calendar.loc[calendar.type == 'Transfer', 'wd'] = False\n    calendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == False), 'wd'] = False\n    calendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == True ), 'wd'] = True\n\n    \n    return calendar\n\n    \n    \n\ndef fill_na(calendar):\n    calendar[\"type\"] = calendar[\"type\"].fillna(\"None\")\n    return calendar\n \n\ndef create_oil_df():\n    oil_df = pd.read_csv(path / 'oil.csv', parse_dates=['date'], infer_datetime_format=True)\n    return oil_df\n\n\n\n\n\n\ndef create_events_df():\n    events_df = pd.read_csv(path / 'holidays_events.csv', parse_dates=['date'], infer_datetime_format=True)\n    events_df['date'] = events_df['date'].replace({'2013-04-29' : \n                                                 pd.to_datetime('2013-03-29')}) # 'Good Friday' mistake correction\n\n    events_df = events_df.sort_values(by=\"date\")         \n    events_df = events_df[events_df.locale == 'National'] \n    events_df = events_df.groupby(by=\"date\").first() \n\n    \n    return events_df","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:29:39.341839Z","iopub.execute_input":"2021-12-22T00:29:39.342315Z","iopub.status.idle":"2021-12-22T00:29:39.476778Z","shell.execute_reply.started":"2021-12-22T00:29:39.342271Z","shell.execute_reply":"2021-12-22T00:29:39.475912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class CustomRegressor():\n\n    def __init__(self, n_jobs=-1, verbose=0, alpha=0.6):\n\n        self.n_jobs = n_jobs\n        self.verbose = verbose\n\n        self.estimators_ = None\n            \n        self.alpha = alpha\n\n    def _estimator_(self, X_ridge, X_rf, y):\n\n        warnings.simplefilter(action='ignore', category=FutureWarning)\n\n        if y.name[2] == 'SCHOOL AND OFFICE SUPPLIES':\n            model = RandomForestRegressor(n_estimators = 300, n_jobs=-1, random_state=1)\n            X = X_rf\n            choice = 0\n        else:\n            model = Ridge(fit_intercept=True, solver='auto', alpha=self.alpha, normalize=True)\n            X = X_ridge\n            choice = 1\n\n        model.fit(X, y)\n\n        \n        return model, choice\n\n    def fit(self, X_ridge, X_rf, y):\n\n        self.estimators_ =  Parallel(n_jobs=self.n_jobs, \n                                  verbose=self.verbose,\n                                  )(delayed(self._estimator_)(X_ridge, X_rf, y.iloc[:, i]) for i in range(y.shape[1]))\n\n        return\n\n    def predict(self, X_ridge, X_rf):\n        X = [X_rf, X_ridge]\n        \n\n        y_pred = Parallel(n_jobs=self.n_jobs, \n                              verbose=self.verbose)(delayed(self.estimators_[i][0].predict)(X[self.estimators_[i][1]])  for i in range(len(self.estimators_)))\n        \n        return np.stack(y_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:29:39.478097Z","iopub.execute_input":"2021-12-22T00:29:39.478399Z","iopub.status.idle":"2021-12-22T00:29:39.490369Z","shell.execute_reply.started":"2021-12-22T00:29:39.478361Z","shell.execute_reply":"2021-12-22T00:29:39.489831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def get_ridge_full(order):\n    fourier = CalendarFourier(freq='W', order=order)\n    dp = DeterministicProcess(index=df.index,\n                              constant=False,\n                              order=1,\n                              seasonal=False,\n                              additional_terms=[fourier],\n                              drop=True)\n\n    X = dp.in_sample()\n    X_ridge_full = X_ridge.copy()\n    \n    for c in X.columns:\n        X_ridge_full[c] = X[c].values\n        \n\n    \n    return X_ridge_full\n\n\ndef get_rf_full():\n    fourier = CalendarFourier(freq='W', order=0)\n    dp = DeterministicProcess(index=df.index,\n                              constant=False,\n                              order=1,\n                              seasonal=False,\n                              additional_terms=[fourier],\n                              drop=True)\n\n    X = dp.in_sample()\n    \n    \n    X_rf_full = X_rf.copy()\n    \n    for c in X.columns:\n        X_rf_full[c] = X[c].values\n    \n    \n    return X_rf_full\n\n\ndef add_month_column(X, dummies=True):\n    X[\"month\"] = [x.month for x in X.index]\n    if dummies:\n        X = pd.get_dummies(X, columns=['month'], drop_first=False)\n        \n    return X\n\n\ndef add_season_column(X, dummies=True):\n    X[\"season\"] = [x.month // 3 for x in X.index]\n    X = pd.get_dummies(X, columns=['season'], drop_first=False)\n    \n    return X\n\n\n\ntrain_start = '2017-04-15'\ntrain_end = '2017-08-15'\n\n\ntest_start = '2017-08-16'\ntest_end = '2017-08-31'\n\norder = 3\nadd_rolling_mean_14 = 1\nadd_rolling_mean_30 = 0\nadd_month = 0\nadd_season = 1\nalpha = 1.125\n    \n\n\ndf = get_calendar()\ny = get_y()\n\ny = y.loc['2017-01-01':]           \ndf = df.loc['2017-01-01':]\n\n\nle = LabelEncoder()\nX_rf = df[[\"dofw\", \"wd\", \"dcoilwtico\", \"type\", \"oil_ma7\"]].copy()\nX_rf[\"type\"] = le.fit_transform(X_rf[\"type\"])\n\n\n\nX_ridge = df[[\"dofw\", \"wd\", \"dcoilwtico\", 'type', \"oil_ma7\"]].copy()\nX_ridge = pd.get_dummies(X_ridge, columns=['dofw'], drop_first=True)\nX_ridge = pd.get_dummies(X_ridge, columns=['type'])\nX_ridge = X_ridge.drop([\"type_None\"], axis=1)\n\n\nX_ridge_full = get_ridge_full(order)\nX_rf_full = get_rf_full()\n    \n        \nif add_rolling_mean_14:\n    X_ridge_full = add_rolling_mean_oil_column(X_ridge_full, 14)\n    X_rf_full = add_rolling_mean_oil_column(X_rf_full, 14)\n        \n        \nif add_rolling_mean_30:\n    X_ridge_full = add_rolling_mean_oil_column(X_ridge_full, 30)\n    X_rf_full = add_rolling_mean_oil_column(X_rf_full, 30)\n        \nif add_month:\n    X_ridge_full = add_month_column(X_ridge_full, dummies=True)\n    X_rf_full = add_month_column(X_rf_full)\n    \nif add_season:\n    X_ridge_full = add_season_column(X_ridge_full, dummies=True)\n    X_rf_full = add_season_column(X_rf_full)\n    \n    \nX_ridge_full.drop([\"dcoilwtico\"], axis=1, inplace=True)\nX_rf_full.drop([\"dcoilwtico\"], axis=1, inplace=True)\n    \n\n\nX_ridge_full_train = X_ridge_full.loc[train_start:train_end]\nX_rf_full_train = X_rf_full.loc[train_start:train_end]\n    \ny_train = y.loc[train_start:train_end]\n\n    \nX_ridge_full_test = X_ridge_full.loc[test_start:test_end]\nX_rf_full_test = X_rf_full.loc[test_start:test_end]\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:34:38.03069Z","iopub.execute_input":"2021-12-22T00:34:38.030988Z","iopub.status.idle":"2021-12-22T00:34:42.589765Z","shell.execute_reply.started":"2021-12-22T00:34:38.030952Z","shell.execute_reply":"2021-12-22T00:34:42.588843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomRegressor(n_jobs=-1, verbose=0, alpha=alpha)\nmodel.fit(X_ridge_full_train, X_rf_full_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:34:42.591149Z","iopub.execute_input":"2021-12-22T00:34:42.591364Z","iopub.status.idle":"2021-12-22T00:35:00.36104Z","shell.execute_reply.started":"2021-12-22T00:34:42.591337Z","shell.execute_reply":"2021-12-22T00:35:00.360207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_ridge_full_test, X_rf_full_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:35:00.362466Z","iopub.execute_input":"2021-12-22T00:35:00.363156Z","iopub.status.idle":"2021-12-22T00:35:07.918173Z","shell.execute_reply.started":"2021-12-22T00:35:00.363119Z","shell.execute_reply":"2021-12-22T00:35:07.917308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.DataFrame(y_pred, index=df.loc[test_start:test_end].index, columns=y.columns)\ny_pred = y_pred.stack(['store_nbr', 'family'])\ny_pred[y_pred < 0] = 0. \n\nsubmission = pd.read_csv(path / 'sample_submission.csv', index_col='id')\nsubmission.sales = y_pred.values\nsubmission.to_csv('submission.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:35:07.919454Z","iopub.execute_input":"2021-12-22T00:35:07.920094Z","iopub.status.idle":"2021-12-22T00:35:08.068888Z","shell.execute_reply.started":"2021-12-22T00:35:07.920061Z","shell.execute_reply":"2021-12-22T00:35:08.068021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-12-22T00:35:08.070351Z","iopub.execute_input":"2021-12-22T00:35:08.070566Z","iopub.status.idle":"2021-12-22T00:35:08.08745Z","shell.execute_reply.started":"2021-12-22T00:35:08.070528Z","shell.execute_reply":"2021-12-22T00:35:08.086356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}