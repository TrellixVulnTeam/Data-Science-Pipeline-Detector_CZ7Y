{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split,cross_validate,GridSearchCV \nfrom statsmodels.tsa.stattools import acf\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-14T03:40:57.187917Z","iopub.execute_input":"2022-06-14T03:40:57.188731Z","iopub.status.idle":"2022-06-14T03:40:57.400841Z","shell.execute_reply.started":"2022-06-14T03:40:57.188687Z","shell.execute_reply":"2022-06-14T03:40:57.399738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\n\ndf_holidays=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\")\ndf_oil=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/oil.csv\") \ndf_stores=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/stores.csv\")\ndf_test=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:40:59.600316Z","iopub.execute_input":"2022-06-14T03:40:59.601115Z","iopub.status.idle":"2022-06-14T03:41:02.414843Z","shell.execute_reply.started":"2022-06-14T03:40:59.601069Z","shell.execute_reply":"2022-06-14T03:41:02.413799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy metrics\n#both entries must be arrays. Both cannot be series\n\nfrom statsmodels.tsa.stattools import acf\nfrom sklearn.metrics import r2_score\n\ndef forecast_accuracy(actual, forecast):\n       \n    #mape = np.mean(100*np.abs(forecast - actual)/np.abs(actual))        # MAPE  (mean absolute percentage error)\n    #me   = np.mean(forecast - actual)                                   # ME    (mean error)\n    #mae  = np.mean(np.abs(forecast - actual))                           # MAE   (mean absolute error)\n    #mpe  = np.mean((forecast - actual)/actual)                          # MPE   (mean percentage error)\n    rmse = np.mean((forecast - actual)**2)**.5                          # RMSE  (root mean square error) \n    msle= np.mean((np.log(forecast+1) - np.log(actual+1))**2)           # MSLE  (mean square logarithmic error)\n    #corr = np.corrcoef(forecast, actual)[0,1]                           # corr  (pearson R coefficient)\n    rsquared = r2_score(actual,forecast)                                #R-squared\n    \n    #mins = np.amin(np.hstack([forecast[:,None], actual[:,None]]), axis=1)\n    #maxs = np.amax(np.hstack([forecast[:,None], actual[:,None]]), axis=1)  \n    #minmax = (1 - np.mean(mins/maxs)).round(3)                          # minmax\n    \n    #acf1 = acf(forecast-actual)[1]                                      # ACF1 (first order auto correlation order)\n\n    results = ({\n                'rmse':rmse,\n                'msle':msle,\n                'Rsquared':rsquared,\n              })\n    \n    results = pd.DataFrame.from_dict(results,orient='index',columns=['value'])\n    \n    return results.round(3)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:41:06.240465Z","iopub.execute_input":"2022-06-14T03:41:06.240861Z","iopub.status.idle":"2022-06-14T03:41:06.248156Z","shell.execute_reply.started":"2022-06-14T03:41:06.240827Z","shell.execute_reply":"2022-06-14T03:41:06.247232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##FAST WAY TO RUN NOTEBOOK\n\n##Unique rows and creating a group to clasify\ndf_stores2=df_stores[['city','state','type','cluster']].drop_duplicates()\ndf_stores2['group']=df_stores2.reset_index().index+1\n#Merge both datasets \ndf=pd.merge(df, df_stores, on='store_nbr')\ndf['date']=pd.to_datetime(df ['date'])\ndf['day']=df['date'].dt.day_name()\n#Merge both datasets to create the new column for the group\ndf=pd.merge(df, df_stores2, on=['city','state','type','cluster'])\n#CREATING A NEW COLUMN FOR MONTH-DAY\ndf['month']=df['date'].dt.strftime('%m-%d')\n##CREATE A NEW COLUMN FOR MONTH\ndf['month']=df['date'].dt.month\n#CREATE A NEW COLUMN FOR PERIOD\ndf['period']=df['date'].dt.strftime('%y-%m')\n##CREATE DATE AND DAY COLUMNS\ndf_holidays['date']=pd.to_datetime(df_holidays ['date'])\ndf_holidays=df_holidays[df_holidays['transferred']==False].drop(columns=['transferred'])\ndf_holidays.rename(columns={'type':'type_day'},inplace=True)\n#Merge both datasets\ndf=df.merge(df_holidays,how='left', left_on='date', right_on='date')\ndf['type_day'].fillna('Normal',inplace=True)\n#Merge both datasets\ndf_oil['date']=pd.to_datetime(df_oil ['date'])\ndf=df.merge(df_oil,how='left', left_on='date', right_on='date')\n#CREATE A NEW COLUMN FOR DAY OF WEEK\ndf['day']=df['date'].dt.dayofweek\n#CREATE A NEW COLUMN FOR DAY NAME\ndf['day_name']=df['date'].apply(lambda x: x.strftime('%A'))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:41:08.305895Z","iopub.execute_input":"2022-06-14T03:41:08.306486Z","iopub.status.idle":"2022-06-14T03:42:02.996325Z","shell.execute_reply.started":"2022-06-14T03:41:08.306437Z","shell.execute_reply":"2022-06-14T03:42:02.99534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing noisy data\n\ndf2=df.copy()\ndisaster = df2[(df2['date'] >= '2016-04-16') & (df2['date'] <= '2016-10-16')]\ndisaster.sort_values('sales', ascending = False)\ndf =df.drop(disaster.index)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:42:33.288381Z","iopub.execute_input":"2022-06-14T03:42:33.289155Z","iopub.status.idle":"2022-06-14T03:42:36.915403Z","shell.execute_reply.started":"2022-06-14T03:42:33.289109Z","shell.execute_reply":"2022-06-14T03:42:36.914284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for the test set\ndf_test=pd.merge(df_test, df_stores, on='store_nbr')\ndf_test['date']=pd.to_datetime(df_test ['date'])\ndf_test['day']=df_test['date'].dt.day_name()\n#Merge both datasets to create the new column for the group\ndf_test=pd.merge(df_test, df_stores2, on=['city','state','type','cluster'])\n#CREATING A NEW COLUMN FOR MONTH-DAY\ndf_test['month']=df_test['date'].dt.strftime('%m-%d')\n##CREATE A NEW COLUMN FOR MONTH\ndf_test['month']=df_test['date'].dt.month\n#CREATE A NEW COLUMN FOR PERIOD\ndf_test['period']=df_test['date'].dt.strftime('%y-%m')\n##CREATE DATE AND DAY COLUMNS\ndf_holidays['date']=pd.to_datetime(df_holidays ['date'])\n#Merge both datasets\ndf_test=df_test.merge(df_holidays,how='left', left_on='date', right_on='date')\ndf_test['type_day'].fillna('Normal',inplace=True)\n#Merge both datasets\ndf_test=df_test.merge(df_oil,how='left', left_on='date', right_on='date')\n#CREATE A NEW COLUMN FOR DAY OF WEEK\ndf_test['day']=df_test['date'].dt.dayofweek\n#CREATE A NEW COLUMN FOR DAY NAME\ndf_test['day_name']=df_test['date'].apply(lambda x: x.strftime('%A'))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:42:41.159436Z","iopub.execute_input":"2022-06-14T03:42:41.159824Z","iopub.status.idle":"2022-06-14T03:42:41.67122Z","shell.execute_reply.started":"2022-06-14T03:42:41.159792Z","shell.execute_reply":"2022-06-14T03:42:41.670371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RANDOM FOREST REGRESSOR FOR EACH GROUP\n\n\n\ntest=[]\npred=[]\nmodels=[]\n\ngroups=np.sort(df['group'].unique())\n\nfor group in groups:\n    \n    dff=df[df['group']==group]\n    \n    encoder_family = LabelEncoder()\n    dff['family']=encoder_family.fit_transform(dff['family'])\n    \n    encoder_day = LabelEncoder()\n    dff['day']=encoder_day.fit_transform(dff['day'])\n    \n    data=dff[['onpromotion','family','month','day']]\n    target=dff['sales']\n    \n    x_train, x_test, y_train, y_test = train_test_split(data, target, train_size = 0.8, random_state = 5)\n    x_train = pd.get_dummies(x_train, drop_first=True)\n    x_test = pd.get_dummies(x_test, drop_first=True)\n    regr  = RandomForestRegressor(n_estimators = 10, random_state = 1)\n    regr.fit(x_train, y_train) \n    \n    models.append (regr)\n    \n    y_pred=regr.predict(x_test)\n    \n    a=forecast_accuracy(y_test, y_pred)\n    msle=a.loc['msle'][0]\n    \n    test.extend(y_test)\n    pred.extend(y_pred)\n    print(f\"modelo {group} terminado y msle de {msle} \")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:42:49.361771Z","iopub.execute_input":"2022-06-14T03:42:49.362155Z","iopub.status.idle":"2022-06-14T03:43:11.542468Z","shell.execute_reply.started":"2022-06-14T03:42:49.362125Z","shell.execute_reply":"2022-06-14T03:43:11.540795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=[]\n\ngroups=np.sort(df['group'].unique())\n\nfor group in groups:\n    \n    dff=df_test[df_test['group']==group]\n    encoder_family = LabelEncoder()\n    dff['family']=encoder_family.fit_transform(dff['family'])\n       \n    encoder_day = LabelEncoder()\n    dff['day']=encoder_day.fit_transform(dff['day'])\n\n\n    data=dff[['onpromotion','family','month','day']]\n    data = pd.get_dummies(data, drop_first=True)\n    \n    i= group-1\n    \n    y_pred=models[i].predict(data)\n    pred.extend(y_pred)    \npred[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:44:07.364286Z","iopub.execute_input":"2022-06-14T03:44:07.364663Z","iopub.status.idle":"2022-06-14T03:44:07.77114Z","shell.execute_reply.started":"2022-06-14T03:44:07.364632Z","shell.execute_reply":"2022-06-14T03:44:07.770191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:45:11.837982Z","iopub.execute_input":"2022-06-14T03:45:11.83844Z","iopub.status.idle":"2022-06-14T03:45:11.872134Z","shell.execute_reply.started":"2022-06-14T03:45:11.838403Z","shell.execute_reply":"2022-06-14T03:45:11.871218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': df_test['id'], 'sales': pred})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T03:45:40.196991Z","iopub.execute_input":"2022-06-14T03:45:40.197449Z","iopub.status.idle":"2022-06-14T03:45:40.266722Z","shell.execute_reply.started":"2022-06-14T03:45:40.197414Z","shell.execute_reply":"2022-06-14T03:45:40.266071Z"},"trusted":true},"execution_count":null,"outputs":[]}]}