{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### <center style=\"background-color:Gainsboro; width:70%;\">Store Sales: Using the average of the last 16 days</center>\n\nIn the [Store Sales - Time Series Forecasting](https://www.kaggle.com/c/store-sales-time-series-forecasting) GettingStarted prediction Competition we have been tasked with building a model that predicts the unit sales for thousands of items sold at different CorporaciÃ³n Favorita stores. Specifically we are asked to predict the sales for 16 days from 2017-08-16 to 2017-08-31. In this short notebook we shall build a very simple model that uses the values of each family of product sold, for each store number, averaged over a 'look-back' window of the same length (16 days) just prior to the date range we will be predicting.","metadata":{}},{"cell_type":"code","source":"import numpy  as np\nimport pandas as pd\n\n# read in the data\ntrain = pd.read_csv(\"../input/store-sales-time-series-forecasting/train.csv\")\ntest  = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\")\n\n# select the very last 16 days of the training data\ntrain_16_days = train.query(\"date >= '2017-07-31' \")\n\ndef exp_mean_ln(df):\n    return np.expm1(np.mean(np.log1p(df['sales'])))\n\n# calculate the average values\ntrain_average = train_16_days.groupby(['store_nbr', 'family']).apply(exp_mean_ln).to_dict()\ntest['sales'] = test.set_index(['store_nbr', 'family']).index.map(train_average.get)\n\n# create and write out the submission.csv file\nsubmission = pd.DataFrame({'id': test.id, 'sales': test.sales})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T05:15:48.085753Z","iopub.execute_input":"2021-11-30T05:15:48.086087Z","iopub.status.idle":"2021-11-30T05:15:51.278901Z","shell.execute_reply.started":"2021-11-30T05:15:48.086053Z","shell.execute_reply":"2021-11-30T05:15:51.277856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Note regarding calculating the average**\nFrom the competition [evaluation page](https://www.kaggle.com/c/store-sales-time-series-forecasting/overview/evaluation) we see that the metric we are using is the root mean squared logarithmic error (RMSLE), which is given by\n\n$$ {\\mathrm {RMSLE}}\\,(y, \\hat y) = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2} $$\n\nwhere $\\hat{y}_i$ is the predicted value of the target for instance $i$, and $y_i$\nis the actual value of the target for instance $i$.\n\nIt is important to note that, unlike the RMSE, the RMSLE is asymmetric; penalizing much more the underestimated predictions than the overestimated predictions. For example, say the correct value is $y_i = 1000$, then underestimating by 600 is almost twice as bad as overestimating by 600:","metadata":{}},{"cell_type":"code","source":"def RSLE(y_hat,y):\n    return np.sqrt((np.log1p(y_hat) - np.log1p(y))**2)\n\nprint(\"The RMSLE score is %.3f\" % RSLE( 400,1000) )\nprint(\"The RMSLE score is %.3f\" % RSLE(1600,1000) )","metadata":{"execution":{"iopub.status.busy":"2021-11-30T05:15:51.280764Z","iopub.execute_input":"2021-11-30T05:15:51.281612Z","iopub.status.idle":"2021-11-30T05:15:51.28931Z","shell.execute_reply.started":"2021-11-30T05:15:51.281564Z","shell.execute_reply":"2021-11-30T05:15:51.28842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The asymmetry arises because \n\n$$ \\log (1 + \\hat{y}_i) - \\log (1 + y_i) =  \\log \\left( \\frac{1 + \\hat{y}_i}{1 + y_i} \\right) $$\n\nso we are essentially looking at ratios, rather than differences such as is the case of the RMSE. We can see the form that this asymmetry takes in the following plot, again using 1000 as our ground truth value:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 16})\nplt.style.use('fivethirtyeight')\nplt.rcParams[\"figure.figsize\"] = (7, 4)\nx = np.linspace(5,4000,100)\nplt.plot(x, RSLE(x,1000))\nplt.xlabel('prediction')\nplt.ylabel('RMSLE')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-30T05:15:51.290828Z","iopub.execute_input":"2021-11-30T05:15:51.291357Z","iopub.status.idle":"2021-11-30T05:15:51.515362Z","shell.execute_reply.started":"2021-11-30T05:15:51.291313Z","shell.execute_reply":"2021-11-30T05:15:51.514459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With this in mind ideally one should not directly calculate the mean, by rather first take the  $\\log_e(1+y)$ of the target, in this case the target is the `sales`, using the numpy [`log1p`](https://numpy.org/doc/stable/reference/generated/numpy.log1p.html) function. Once we have done this then we can proceed to calculate the [`mean`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) of this transformed  target, and finally invert the transform using the numpy [`expm1`](https://numpy.org/doc/stable/reference/generated/numpy.expm1.html) to obtain our average value.\n\n### <center style=\"background-color:Gainsboro; width:60%;\">Related notebooks</center>\n* [Store Sales: Naive one-day model](https://www.kaggle.com/carlmcbrideellis/store-sales-naive-one-day-model)\n\n### <center style=\"background-color:Gainsboro; width:60%;\">Recommended reading</center>\n* [Rob J. Hyndman and George Athanasopoulos \"*Forecasting: Principles and Practice*\", (3rd Edition)](https://otexts.com/fpp3/)\n* [Fotios Petropoulos, *et al. \"Forecasting: Theory and Practice*\", arXiv:2012.03854 (2020)](https://arxiv.org/pdf/2012.03854.pdf)","metadata":{}}]}