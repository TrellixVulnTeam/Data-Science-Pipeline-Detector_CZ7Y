{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>데이터마이닝 개론</center>\n# <center>(Introduction to data mining)</center>\n# <center> <font color='blue'>Term Project</font></center>\n\n## <font color='blue'>Topic:</font> Store Sales - Time Series Forecasting Use machine learning to predict grocery sales\n<hr/>\n\n### Supervisor: <font color='blue'>Prof. 김재환</font>\n### Student: <font color='blue'>TRAN DUY THANH</font>\n### ID           : <font color='blue'> 20207144</font>\n\n<hr/>\n","metadata":{}},{"cell_type":"markdown","source":"# Goal of the Term Project:\n\nThis term Project is from the international competition. The competitors will use the time-series forecasting to forecast store sales on data from Corporación Favorita, a large Ecuadorian-based grocery retailer.\nSpecifically, the competitors will build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores. The competitors will practice their machine learning skills with an approachable training dataset of dates, store, and item information, promotions, and unit sales.\n\n# Dataset Description:\nThe Datasets of this international competition are described as below.\n## The train.csv\n•\tThe training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n\n•\tstore_nbr identifies the store at which the products are sold.\n\n•\tfamily identifies the type of product sold.\n\n•\tsales give the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n\n•\ton promotion gives the total number of items in a product family that were being promoted at a store at a given date.\n\n\n## The test.csv file\n\n•\tThe test data, having the same features as the training data. You will predict the target sales for the dates in this file.\n\n•\tThe dates in the test data are for the 15 days after the last date in the training data.\n\n## The holidays_events.csv file \n\n•\tHolidays and Events, with metadata\n\n•\tAdditional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).\n\n","metadata":{}},{"cell_type":"markdown","source":"This block code is initial the library and load the dataset","metadata":{}},{"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\n\n# Setup notebook\nfrom pathlib import Path\n# plot style settings\nfrom learntools.time_series.style import *  \n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndataset=\"../input/store-sales-time-series-forecasting/train.csv\"\n\nstore_sales=pd.read_csv(dataset,\n                       parse_dates=[\"date\"],\n                        infer_datetime_format=True\n                       )\nstore_sales = store_sales.set_index('date').to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family'], append=True)\naverage_sales = store_sales.groupby('date').mean()['sales'].loc['2016':'2017']","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:14:05.288751Z","iopub.execute_input":"2022-05-20T13:14:05.289076Z","iopub.status.idle":"2022-05-20T13:14:08.03105Z","shell.execute_reply.started":"2022-05-20T13:14:05.289043Z","shell.execute_reply":"2022-05-20T13:14:08.03018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:20:41.833701Z","iopub.execute_input":"2022-05-20T13:20:41.834742Z","iopub.status.idle":"2022-05-20T13:20:41.855848Z","shell.execute_reply.started":"2022-05-20T13:20:41.834656Z","shell.execute_reply":"2022-05-20T13:20:41.854788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"View the data of average_sales:","metadata":{}},{"cell_type":"code","source":"average_sales ","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:14:11.505679Z","iopub.execute_input":"2022-05-20T13:14:11.50596Z","iopub.status.idle":"2022-05-20T13:14:11.513925Z","shell.execute_reply.started":"2022-05-20T13:14:11.505932Z","shell.execute_reply":"2022-05-20T13:14:11.513046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1) Determine trend with a moving average plot\n\nCorporación Favorita SalesCorporación Favorita Sales.","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:30:47.600359Z","iopub.execute_input":"2022-05-06T13:30:47.600645Z","iopub.status.idle":"2022-05-06T13:30:47.623742Z","shell.execute_reply.started":"2022-05-06T13:30:47.600616Z","shell.execute_reply":"2022-05-06T13:30:47.62254Z"}}},{"cell_type":"code","source":"ax = average_sales.plot(**plot_params)\nax.set(title=\"Corporación Favorita Sales\", \n       ylabel=\"Number of Sales\");","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:14:14.049055Z","iopub.execute_input":"2022-05-20T13:14:14.049964Z","iopub.status.idle":"2022-05-20T13:14:14.364434Z","shell.execute_reply.started":"2022-05-20T13:14:14.049916Z","shell.execute_reply":"2022-05-20T13:14:14.363491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll continue using the time series of average sales. Run this cell to see a moving average plot of average_sales estimating the trend.","metadata":{}},{"cell_type":"code","source":"trend = average_sales.rolling(\n    window=365,\n    center=True,\n    min_periods=183,\n).mean()\n\nax = average_sales.plot(**plot_params, alpha=0.5)\nax = trend.plot(ax=ax, linewidth=3)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:14:17.266679Z","iopub.execute_input":"2022-05-20T13:14:17.267342Z","iopub.status.idle":"2022-05-20T13:14:17.70756Z","shell.execute_reply.started":"2022-05-20T13:14:17.267298Z","shell.execute_reply":"2022-05-20T13:14:17.706657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Create a Trend Feature","metadata":{}},{"cell_type":"markdown","source":"Use DeterministicProcess to create a feature set for a cubic trend model. Also create features for a 90-day forecast.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import DeterministicProcess\n\n#set the target\ny = average_sales.copy()  \n\n# Instantiate `DeterministicProcess` with arguments appropriate for a cubic trend model\ndp = DeterministicProcess(index=y.index, order=3)\n\n# Create the feature set for the dates given in y.index\nX = dp.in_sample()\n\n# Create features for a 90-day forecast.\nX_fore = dp.out_of_sample(steps=90)\n\n#we can see the a plot of the result:\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\", color='C0')\nax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color='C3')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:14:20.730278Z","iopub.execute_input":"2022-05-20T13:14:20.730727Z","iopub.status.idle":"2022-05-20T13:14:21.163377Z","shell.execute_reply.started":"2022-05-20T13:14:20.730681Z","shell.execute_reply":"2022-05-20T13:14:21.162495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Seasonality - Create indicators and Fourier features to capture periodic change\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\ndataset=\"../input/store-sales-time-series-forecasting/train.csv\"\n\nstore_sales = pd.read_csv(\n    dataset,\n    usecols=['store_nbr', 'family', 'date', 'sales'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n#I filter for 2017\naverage_sales = (\n    store_sales\n    .groupby('date').mean()\n    .squeeze()\n    .loc['2017']\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:28:13.565567Z","iopub.execute_input":"2022-05-08T14:28:13.566575Z","iopub.status.idle":"2022-05-08T14:28:17.504318Z","shell.execute_reply.started":"2022-05-08T14:28:13.566521Z","shell.execute_reply":"2022-05-08T14:28:17.503476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show data of average_sales","metadata":{}},{"cell_type":"code","source":"average_sales","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:28:32.975894Z","iopub.execute_input":"2022-05-08T14:28:32.976657Z","iopub.status.idle":"2022-05-08T14:28:32.984092Z","shell.execute_reply.started":"2022-05-08T14:28:32.976618Z","shell.execute_reply":"2022-05-08T14:28:32.983305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We use seasonal_plot:","metadata":{}},{"cell_type":"code","source":"X = average_sales.to_frame()\nX[\"week\"] = X.index.week\nX[\"day\"] = X.index.dayofweek\nseasonal_plot(X, y='sales', period='week', freq='day');","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:40:44.008581Z","iopub.execute_input":"2022-05-07T06:40:44.008794Z","iopub.status.idle":"2022-05-07T06:40:44.817993Z","shell.execute_reply.started":"2022-05-07T06:40:44.008769Z","shell.execute_reply":"2022-05-07T06:40:44.817045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We use plot_periodogram","metadata":{}},{"cell_type":"code","source":"plot_periodogram(average_sales);","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:40:50.749094Z","iopub.execute_input":"2022-05-07T06:40:50.749402Z","iopub.status.idle":"2022-05-07T06:40:51.227665Z","shell.execute_reply.started":"2022-05-07T06:40:50.749373Z","shell.execute_reply":"2022-05-07T06:40:51.226884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create seasonal features\nUse DeterministicProcess and CalendarFourier to create:\n\nindicators for weekly seasons and\nFourier features of order 4 for monthly seasons.","metadata":{}},{"cell_type":"code","source":"y = average_sales.copy()\n\n# Create CalendarFourier\nfourier = CalendarFourier(freq='M', order=4)\n# Create DeterministicProcess\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\nX = dp.in_sample()\n\n#use LinearRegression model\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.Series(\n    model.predict(X),\n    index=X.index,\n    name='Fitted',\n)\n#get prediction:\ny_pred = pd.Series(model.predict(X), index=X.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:14:19.292402Z","iopub.execute_input":"2022-05-07T07:14:19.293122Z","iopub.status.idle":"2022-05-07T07:14:19.774107Z","shell.execute_reply.started":"2022-05-07T07:14:19.293079Z","shell.execute_reply":"2022-05-07T07:14:19.773272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) Time Series as Features","metadata":{}},{"cell_type":"code","source":"# plot style settings\nfrom learntools.time_series.style import *  \nfrom learntools.time_series.utils import plot_lags, make_lags, make_leads\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\ndataset = '../input/store-sales-time-series-forecasting/train.csv'\n\nstore_sales = pd.read_csv(\n    dataset,\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean() \n    .unstack('family')\n    .loc['2017', ['sales', 'onpromotion']]\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:30:18.772008Z","iopub.execute_input":"2022-05-08T14:30:18.772321Z","iopub.status.idle":"2022-05-08T14:30:23.061728Z","shell.execute_reply.started":"2022-05-08T14:30:18.772286Z","shell.execute_reply":"2022-05-08T14:30:23.06086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show the data of family_sales ","metadata":{}},{"cell_type":"code","source":"family_sales","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:30:28.217197Z","iopub.execute_input":"2022-05-08T14:30:28.217506Z","iopub.status.idle":"2022-05-08T14:30:28.266317Z","shell.execute_reply.started":"2022-05-08T14:30:28.217473Z","shell.execute_reply":"2022-05-08T14:30:28.265482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not every product family has sales showing cyclic behavior, and neither does the series of average sales. Sales of school and office supplies, however, show patterns of growth and decay not well characterized by trend or seasons. \n\nTrend and seasonality will both create serial dependence that shows up in correlograms and lag plots. To isolate any purely cyclic behavior, we'll start by deseasonalizing the series. Use the code in the next cell to deseasonalize Supply Sales. We'll store the result in a variable y_deseason.\n","metadata":{}},{"cell_type":"code","source":"supply_sales = family_sales.loc(axis=1)[:, 'SCHOOL AND OFFICE SUPPLIES']\ny = supply_sales.loc[:, 'sales'].squeeze()\n\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    constant=True, index=y.index,\n    order=1,seasonal=True,\n    drop=True,\n    additional_terms=[fourier],\n)\nX_time = dp.in_sample()\nX_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_time, y)\ny_deseason = y - model.predict(X_time)\ny_deseason.name = 'sales_deseasoned'\n\nax = y_deseason.plot()\nax.set_title(\"Sales of School and Office Supplies (deseasonalized)\");","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:01:05.493461Z","iopub.execute_input":"2022-05-07T11:01:05.493724Z","iopub.status.idle":"2022-05-07T11:01:05.968983Z","shell.execute_reply.started":"2022-05-07T11:01:05.493697Z","shell.execute_reply":"2022-05-07T11:01:05.968053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting cycles\n\nCreate a seven-day moving average from y, the series of supply sales. Use a centered window, but don't set the min_periods argument.","metadata":{}},{"cell_type":"code","source":"#create rolling\ny_ma = y.rolling(7, center=True).mean()\n\n# Plot\nax = y_ma.plot()\nax.set_title(\"Seven-Day Moving Average\");","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:09:02.497139Z","iopub.execute_input":"2022-05-07T08:09:02.497476Z","iopub.status.idle":"2022-05-07T08:09:02.920472Z","shell.execute_reply.started":"2022-05-07T08:09:02.49744Z","shell.execute_reply":"2022-05-07T08:09:02.919625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can view the deseasonalized series for serial dependence. Take a look at the partial autocorrelation correlogram and lag plot.\n","metadata":{}},{"cell_type":"code","source":"plot_pacf(y_deseason, lags=8);\nplot_lags(y_deseason, lags=8, nrows=2);","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:12:31.481728Z","iopub.execute_input":"2022-05-07T08:12:31.482031Z","iopub.status.idle":"2022-05-07T08:12:33.576224Z","shell.execute_reply.started":"2022-05-07T08:12:31.481997Z","shell.execute_reply":"2022-05-07T08:12:33.575407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onpromotion = supply_sales.loc[:, 'onpromotion'].squeeze().rename('onpromotion')\n\n# Drop days without promotions\nplot_lags(x=onpromotion.loc[onpromotion > 1], y=y_deseason.loc[onpromotion > 1], lags=3, leads=3, nrows=1);","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:01:13.928768Z","iopub.execute_input":"2022-05-07T11:01:13.929346Z","iopub.status.idle":"2022-05-07T11:01:14.93385Z","shell.execute_reply.started":"2022-05-07T11:01:13.92931Z","shell.execute_reply":"2022-05-07T11:01:14.933107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Hybrid Models ","metadata":{}},{"cell_type":"markdown","source":"Linear regression excels at extrapolating trends, but can't learn interactions. XGBoost excels at learning interactions, but can't extrapolate trends. So, we’ll research how to create “Hybrid\" forecasters that combine complementary learning algorithms and let the strengths of one make up for the weakness of the other. And after that we will apply the Hybrid model to this grocery sales forecasting.\n\n### Components and Residuals\n\nEach of the terms in this model we would then call a component of the time series:\n\n\nseries = trend + seasons + cycles + error\n\n\nThe residuals of a model are the difference between the target the model was trained on and the predictions the model makes.\n\n","metadata":{}},{"cell_type":"code","source":"# plot style settings\nfrom learntools.time_series.style import *  \n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom statsmodels.tsa.deterministic import DeterministicProcess\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\n\n\ndataset='../input/store-sales-time-series-forecasting/train.csv'\n\nstore_sales = pd.read_csv(\n    dataset,\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean()\n    .unstack('family')\n    .loc['2017']\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:43:21.429349Z","iopub.execute_input":"2022-06-01T07:43:21.429629Z","iopub.status.idle":"2022-06-01T07:43:25.914857Z","shell.execute_reply.started":"2022-06-01T07:43:21.429598Z","shell.execute_reply":"2022-06-01T07:43:25.914252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show data of family_sales","metadata":{}},{"cell_type":"code","source":"family_sales","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:32:27.303544Z","iopub.execute_input":"2022-05-08T14:32:27.303892Z","iopub.status.idle":"2022-05-08T14:32:27.351657Z","shell.execute_reply.started":"2022-05-08T14:32:27.303858Z","shell.execute_reply":"2022-05-08T14:32:27.350526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nNow We will create a boosted hybrid for the *Store Sales* dataset by implementing a new Python class. the hybrid model class will have `fit` and `predict` methods to give it a scikit-learn like interface.\n","metadata":{}},{"cell_type":"code","source":"class BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None\n    def fit(self, X_1, X_2, y):\n        self.model_1.fit(X_1, y)\n\n        y_fit = pd.DataFrame(self.model_1.predict(X_1), \n            index=X_1.index, columns=y.columns)\n        #compute residuals\n        y_resid = y - y_fit\n        y_resid = y_resid.stack().squeeze()\n\n        #fit self.model_2 on residuals\n        self.model_2.fit(X_2, y_resid)\n\n        # Save column names for predict method\n        self.y_columns = y.columns\n        # Save data for question checking\n        self.y_fit = y_fit\n        self.y_resid = y_resid        \n    def predict(self, X_1, X_2):\n        y_pred = pd.DataFrame(\n            #predict with self.model_1\n            self.model_1.predict(X_1), \n            index=X_1.index, columns=self.y_columns)\n        y_pred = y_pred.stack().squeeze()# wide to long\n\n        #add self.model_2 predictions to y_pred\n        y_pred += self.model_2.predict(X_2)\n        return y_pred.unstack()  # long to wide","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:43:33.910404Z","iopub.execute_input":"2022-06-01T07:43:33.91073Z","iopub.status.idle":"2022-06-01T07:43:33.921383Z","shell.execute_reply.started":"2022-06-01T07:43:33.910688Z","shell.execute_reply":"2022-06-01T07:43:33.920421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can use the BoostedHybrid class to create a model for the Store Sales data. this code to set up the data for training.","metadata":{}},{"cell_type":"code","source":"# Target series\ny = family_sales.loc[:, 'sales']\n\n# X_1: Features for Linear Regression\ndp = DeterministicProcess(index=y.index, order=1)\nX_1 = dp.in_sample()\n\n# X_2: Features for XGBoost\nX_2 = family_sales.drop('sales', axis=1).stack()  # onpromotion feature\n\n# Label encoding for 'family'\nle = LabelEncoder()  # from sklearn.preprocessing\nX_2 = X_2.reset_index('family')\nX_2['family'] = le.fit_transform(X_2['family'])\n\n# Label encoding for seasonality\nX_2[\"day\"] = X_2.index.day  # values are day of the month","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:43:38.042674Z","iopub.execute_input":"2022-06-01T07:43:38.042979Z","iopub.status.idle":"2022-06-01T07:43:38.071131Z","shell.execute_reply.started":"2022-06-01T07:43:38.042945Z","shell.execute_reply":"2022-06-01T07:43:38.070292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train boosted hybrid\nCreate the hybrid model by initializing a BoostedHybrid class with LinearRegression() and XGBRegressor() instances.","metadata":{}},{"cell_type":"code","source":"# Create LinearRegression anf XGBRegressor hybrid for BoostedHybrid object\nmodel = BoostedHybrid(\n    model_1=LinearRegression(),\n    model_2=XGBRegressor(),\n)\n\n# Call Fit and predict method\nmodel.fit(X_1, X_2, y)\n\ny_pred = model.predict(X_1, X_2)\n\ny_pred = y_pred.clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:43:41.676172Z","iopub.execute_input":"2022-06-01T07:43:41.676458Z","iopub.status.idle":"2022-06-01T07:43:42.278135Z","shell.execute_reply.started":"2022-06-01T07:43:41.67643Z","shell.execute_reply":"2022-06-01T07:43:42.277424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Call fit and predict method","metadata":{}},{"cell_type":"code","source":"#create train and valid set\ny_train, y_valid = y[:\"2017-07-01\"], y[\"2017-07-02\":]\nX1_train, X1_valid = X_1[: \"2017-07-01\"], X_1[\"2017-07-02\" :]\nX2_train, X2_valid = X_2.loc[:\"2017-07-01\"], X_2.loc[\"2017-07-02\":]\n#call fit method\nmodel.fit(X1_train, X2_train, y_train)\n#call predict method\ny_fit = model.predict(X1_train, X2_train).clip(0.0)\ny_pred = model.predict(X1_valid, X2_valid).clip(0.0)\n#test with 6 features in the dataset\nfamilies = y.columns[0:6]\naxs = y.loc(axis=1)[families].plot(\n    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,\n)\n#filter and plot the y_fit\ny_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)\n#filter and plot the y_pred\ny_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)\nfor ax, family in zip(axs, families):\n    ax.legend([])\n    ax.set_ylabel(family)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:43:46.255932Z","iopub.execute_input":"2022-06-01T07:43:46.256305Z","iopub.status.idle":"2022-06-01T07:43:49.365272Z","shell.execute_reply.started":"2022-06-01T07:43:46.256268Z","shell.execute_reply":"2022-06-01T07:43:49.363144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"families","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:44:20.74979Z","iopub.execute_input":"2022-06-01T07:44:20.750169Z","iopub.status.idle":"2022-06-01T07:44:20.758113Z","shell.execute_reply.started":"2022-06-01T07:44:20.750128Z","shell.execute_reply":"2022-06-01T07:44:20.756659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. DataExecutor and xgboost - GPU to evaluate metric \n\nI use xgboost and reference and improve code from https://www.kaggle.com/code/koheishima/store-sales-simple-xg-boost-gpu-lb-0-44579\n\nI use GPU accelerator to run the algorithm","metadata":{}},{"cell_type":"markdown","source":"# Declare packges","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport time\nimport calendar\nimport xgboost as xgb\n\nfrom datetime import date, datetime\nfrom learntools.time_series.style import *  \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:25:35.783971Z","iopub.execute_input":"2022-06-01T10:25:35.784862Z","iopub.status.idle":"2022-06-01T10:25:37.231195Z","shell.execute_reply.started":"2022-06-01T10:25:35.784751Z","shell.execute_reply":"2022-06-01T10:25:37.23043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataExecutor class","metadata":{}},{"cell_type":"markdown","source":"DataExecutor class uses to load dataset, preprocessing for train, test set and another dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:32:13.045535Z","iopub.execute_input":"2022-06-01T06:32:13.045785Z","iopub.status.idle":"2022-06-01T06:32:16.103124Z","shell.execute_reply.started":"2022-06-01T06:32:13.045756Z","shell.execute_reply":"2022-06-01T06:32:16.102324Z"}}},{"cell_type":"code","source":"class DataExecutor:\n    path='../input/store-sales-time-series-forecasting/'\n    #load all dataset in store sales time series dataset\n    def load_dataset(self):\n        self.train = pd.read_csv(self.path + 'train.csv')\n        self.test = pd.read_csv(self.path + 'test.csv')\n        self.oil = pd.read_csv(self.path + 'oil.csv')\n        self.holiday = pd.read_csv(self.path + 'holidays_events.csv')\n        self.store = pd.read_csv(self.path + 'stores.csv')\n        self.tran = pd.read_csv(self.path + 'transactions.csv')\n        self.submission = pd.read_csv(self.path + 'sample_submission.csv')\n    #add weekday, year, month, day and payday\n    #this function is used for clean_train_test method\n    def preprocess_train_test(self,df):\n        df['date'] = df['date'].map(lambda x: date.fromisoformat(x))\n        df['weekday'] = df['date'].map(lambda x: x.weekday())\n        df['year'] = df['date'].map(lambda x: x.year)\n        df['month'] = df['date'].map(lambda x: x.month)\n        df['day'] = df['date'].map(lambda x: x.day)\n        df['eomd'] = df['date'].map(lambda x: calendar.monthrange(x.year, x.month)[1])\n        df['payday'] = ((df['day'] == df['eomd'])|(df['day'] == 15)).astype(int)\n        df.drop(['id', 'eomd'], axis=1, inplace=True)\n        return df\n    #clean train test set\n    def clean_train_test(self):\n        self.train = self.preprocess_train_test(self.train)\n        self.test = self.preprocess_train_test(self.test)\n    #clean oil dataset\n    def clean_oil_dataset(self):\n        self.oil['month'] = self.oil['date'].map(lambda x: int(x.replace('-', '')[:6]))\n        self.oil['month_avg'] = self.oil.groupby('month')['dcoilwtico'].transform('mean')\n        self.oil['tmp'] = self.oil['dcoilwtico'].map(np.isnan)\n        self.oil['month_avg'] = self.oil['tmp'] * self.oil['month_avg']\n        self.oil['dcoilwtico'].fillna(0, inplace=True)\n        self.oil['dcoilwtico'] = self.oil['dcoilwtico'] + self.oil['month_avg']\n        self.oil = self.oil.drop(['month', 'month_avg', 'tmp'], axis=1)\n        self.oil['date'] = self.oil['date'].map(lambda x: date.fromisoformat(x))\n    #process event holidy dataset\n    def process_event_holiday(self):\n        self.holiday['date'] = self.holiday['date'].map(lambda x: date.fromisoformat(x))\n        self.holiday = self.holiday[(self.holiday['transferred']==False)&(self.holiday['type']!='Work Day')]\n        self.holiday = self.holiday[['date', 'description']]\n        self.holiday.rename({'description': 'event_name'}, axis=1, inplace=True)\n    #merge dataset\n    #this functions is used for merge_train_test_set method\n    def merge_dataset(self, df):\n        df = df.merge(self.oil, on='date', how='left')\n        df = df.merge(self.store, on='store_nbr', how='left')\n        df = df.merge(self.holiday, on='date', how='left').fillna('0')\n        df = df.merge(self.tran, on=['date', 'store_nbr'], how='left').fillna(0)\n        return df\n    #this function merge train test set\n    def merge_train_test_set(self):\n        self.train = self.merge_dataset(self.train)\n        self.test = self.merge_dataset(self.test)\n        self.train['dcoilwtico'] = self.train['dcoilwtico'].astype(float)\n        self.test['dcoilwtico'] = self.test['dcoilwtico'].astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:26:44.550703Z","iopub.execute_input":"2022-06-01T10:26:44.550897Z","iopub.status.idle":"2022-06-01T10:26:44.57009Z","shell.execute_reply.started":"2022-06-01T10:26:44.550872Z","shell.execute_reply":"2022-06-01T10:26:44.569472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Declare and call method for DataExecutor","metadata":{}},{"cell_type":"code","source":"#create executor intance object\nexecutor=DataExecutor()\n#call load dataset method\nexecutor.load_dataset()\n#call clean train test method\nexecutor.clean_train_test()\n#call clean oil data set\nexecutor.clean_oil_dataset()\n#call process event holiday data set\nexecutor.process_event_holiday()\n#call merge train test set method\nexecutor.merge_train_test_set()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:26:48.114867Z","iopub.execute_input":"2022-06-01T10:26:48.115124Z","iopub.status.idle":"2022-06-01T10:27:13.41935Z","shell.execute_reply.started":"2022-06-01T10:26:48.115094Z","shell.execute_reply":"2022-06-01T10:27:13.418612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SimpleXGBoost class\n","metadata":{}},{"cell_type":"markdown","source":"SimpleXGBoost class uses to create features, target, run the model and export submission file","metadata":{}},{"cell_type":"code","source":"class SimpleXGBoost:\n    features = ['family', 'store_nbr', 'city', 'state', 'type', 'cluster','event_name']\n    params_for_xgb = {\n                    'tree_method': 'gpu_hist', \n                    'gpu_id': 0,\n                    'predictor': 'gpu_predictor', \n                    'verbosity': 2,\n                    'objective': 'reg:squarederror', \n                    'eval_metric': 'rmse', \n                    'random_state': 42,\n                    'learning_rate': 0.01,\n                    'subsample': 1.0,\n                    'colsample_bytree': 0.7,\n                    'reg_alpha': 10.0,\n                    'reg_lambda': 0.2,\n                    'min_child_weight': 50,\n                }\n    def __init__(self,executor):\n        self.executor=executor\n    #Label encoding ang transform for train,test set\n    def transform(self):       \n        for col in self.features:\n            le = LabelEncoder()\n            self.executor.train[col] = le.fit_transform(self.executor.train[col])\n            self.executor.test[col] = le.transform(self.executor.test[col])\n    #createt train and valid period set\n    #n1 is from index\n    #n2 is to index\n    def creat_train_valid_period_set(self,n1,n2):\n        self.train_date = self.executor.train['date'].unique()[n1:n2].tolist()\n        self.valid_date = self.executor.train['date'].unique()[n2:].tolist()\n        self.executor.train['is_train'] = self.executor.train['date'].map(lambda x: x in self.train_date)\n        self.executor.train['is_valid'] = self.executor.train['date'].map(lambda x: x in self.valid_date)\n    #create train valid period set\n    def print_train_valid_period_set(self):\n        print('train date from {} to {}'.format(min(self.train_date), max(self.train_date)))\n        print('valid date from {} to {}'.format(min(self.valid_date), max(self.valid_date)))\n    #setup feature target\n    def setup_feature_target(self):\n        self.y = np.log(self.executor.train['sales'] + 1)\n        self.X_train = self.executor.train.drop(['date', 'sales', 'year'], axis=1)\n        self.X_test = self.executor.test.drop(['date', 'year'], axis=1)\n    #run xgboost    \n    def run_xgboost(self):\n        start = time.time()    \n        # extract train and valid dataset\n        train_idx = self.X_train[self.X_train['is_train']==True].index.tolist()\n        val_idx = self.X_train[self.X_train['is_valid']==True].index.tolist()\n\n        X_tr = self.X_train.loc[train_idx, :].drop(['is_train', 'is_valid'], axis=1)\n        self.X_val = self.X_train.loc[val_idx, :].drop(['is_train', 'is_valid'], axis=1)\n        y_tr = self.y[train_idx]\n        self.y_val = self.y[val_idx]\n\n        xgb_train = xgb.DMatrix(X_tr, label=y_tr)\n        xgb_valid = xgb.DMatrix(self.X_val, label=self.y_val)\n        evallist = [(xgb_train, 'train'), (xgb_valid, 'eval')]\n        self.evals_result = dict()\n\n        self.model = xgb.train(params=self.params_for_xgb, dtrain=xgb_train, \n                          evals=evallist, evals_result=self.evals_result,\n                          verbose_eval=5000, num_boost_round=100000, early_stopping_rounds=100)\n\n        self.xgb_oof = np.zeros(self.y_val.shape[0])\n        self.xgb_oof = self.model.predict(xgb_valid, iteration_range=(0, self.model.best_iteration))\n\n        xgb_test = xgb.DMatrix(self.X_test)\n        self.xgb_pred = pd.Series(self.model.predict(xgb_test, iteration_range=(0, self.model.best_iteration)),\n                             name='xgb_pred')\n\n        elapsed = time.time() - start\n        error_value = mean_squared_error(self.y_val, self.xgb_oof, squared=False)\n        print(f\"xgboost rmse: {error_value:.5f}, elapsed time: {elapsed:.2f}sec\\n\")\n\n        return self.xgb_oof, self.model, self.evals_result, self.xgb_pred, self.y_val, self.X_val\n    #create function to plot the data\n    def plot_data(self):\n        df_error = self.X_val[['store_nbr', 'family']].copy()\n        df_error.reset_index(drop=True, inplace=True)\n        df_error['oof'] = pd.Series(self.xgb_oof)\n        df_error['y_valid'] = self.y_val.reset_index(drop=True).copy()\n        y_oof = df_error[(df_error['store_nbr']==1)&(df_error['family']==12)]['oof'].tolist()\n        self.y_val = df_error[(df_error['store_nbr']==1)&(df_error['family']==12)]['y_valid'].tolist()\n        sns.lineplot(x=range(len(y_oof)), y=y_oof)\n        sns.lineplot(x=range(len(y_oof)), y=self.y_val)\n    #export submission file to upload to the competition\n    def export_submission(self):\n        self.executor.submission['sales'] = np.exp(self.xgb_pred.map(lambda x: max(x, 0))) - 1\n        self.executor.submission.to_csv('submission.csv', index=False)\n        print(\"export submission.csv is successful!\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:27:39.715021Z","iopub.execute_input":"2022-06-01T10:27:39.715271Z","iopub.status.idle":"2022-06-01T10:27:39.740726Z","shell.execute_reply.started":"2022-06-01T10:27:39.715242Z","shell.execute_reply":"2022-06-01T10:27:39.739916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Declare and call method for SimpleXGBoost","metadata":{}},{"cell_type":"code","source":"#create SimpleXGBoost instance object\nsxgb=SimpleXGBoost(executor)\n#call transform method\nsxgb.transform()\n#call create train valid period set\nsxgb.creat_train_valid_period_set(-300,-10)\n#call print train valid period set\nsxgb.print_train_valid_period_set()\n#call setup feature target method\nsxgb.setup_feature_target()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:27:47.6984Z","iopub.execute_input":"2022-06-01T10:27:47.698982Z","iopub.status.idle":"2022-06-01T10:28:17.236899Z","shell.execute_reply.started":"2022-06-01T10:27:47.698944Z","shell.execute_reply":"2022-06-01T10:28:17.23607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#call run xgboost method\n\nsxgb.run_xgboost()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:30:12.532114Z","iopub.execute_input":"2022-06-01T10:30:12.532361Z","iopub.status.idle":"2022-06-01T10:32:28.738938Z","shell.execute_reply.started":"2022-06-01T10:30:12.532332Z","shell.execute_reply":"2022-06-01T10:32:28.738126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#call plot data\nsxgb.plot_data()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:33:45.974544Z","iopub.execute_input":"2022-06-01T10:33:45.974942Z","iopub.status.idle":"2022-06-01T10:33:46.127545Z","shell.execute_reply.started":"2022-06-01T10:33:45.974901Z","shell.execute_reply":"2022-06-01T10:33:46.125482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#call export submission file\nsxgb.export_submission()","metadata":{},"execution_count":null,"outputs":[]}]}