{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-20T21:09:27.469035Z","iopub.execute_input":"2022-02-20T21:09:27.470173Z","iopub.status.idle":"2022-02-20T21:09:28.267891Z","shell.execute_reply.started":"2022-02-20T21:09:27.470042Z","shell.execute_reply":"2022-02-20T21:09:28.266767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В данных 54 магазина и 33 семейства продуктов.                     \nВременной ряд тренировочных данных с 01.01.2013 по 15.08.2017.              \nВременной ряд тестовых данных для submition составляет 16 дней после последней даты тренировочных данных: с 16.08.2017 по 31.08.2017.                   \n                                 \nНужно составить прогноз продаж для каждого из семейств продуктов в каждом из магазинов.     \n                             \nВ отдельном ноутбуке проведен Feature engineering и сформированы необходимые датасеты.\n                                \n**Текущие датасеты**                   \n1. featured_data - объединенные данные test и train с новыми признаками.\n2. zero_prediction - данные тех товаров, которые не продавались в конкретном магазине с начала 2013 года, исходя из чего можно предположить, что данные товары не будут продаваться в ближайшие 16 дней. Этот датасет мы будем объединять с предсказанными данными перед отправкой в submit. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport warnings\n\n# PACF - ACF\n# ------------------------------------------------------\nimport statsmodels.api as sm\n\n# DATA VISUALIZATION\n# ------------------------------------------------------\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\npd.set_option('display.max_columns', None)\npd.options.display.float_format = '{:.2f}'.format\nwarnings.filterwarnings('ignore')\nfrom warnings import simplefilter\n%matplotlib inline\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:18:12.948159Z","iopub.execute_input":"2022-02-24T09:18:12.948535Z","iopub.status.idle":"2022-02-24T09:18:16.41523Z","shell.execute_reply.started":"2022-02-24T09:18:12.948442Z","shell.execute_reply":"2022-02-24T09:18:16.414396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import Data","metadata":{}},{"cell_type":"code","source":"# Import\ndf = pd.read_csv(\"../input/featured-data/featured_data.csv\")\nzero_prediction = pd.read_csv(\"../input/zero-prediction/zero_prediction.csv\")\n\n# Datetime\ndf[\"date\"] = pd.to_datetime(df.date)\n\nzero_prediction = zero_prediction.set_index(['store_nbr', 'family', 'date']).sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:18:16.417412Z","iopub.execute_input":"2022-02-24T09:18:16.417764Z","iopub.status.idle":"2022-02-24T09:18:43.231797Z","shell.execute_reply.started":"2022-02-24T09:18:16.417718Z","shell.execute_reply":"2022-02-24T09:18:43.230705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_train = df[df.date<'2017-08-16'].copy()\nd_test = df[df.date>='2017-08-16'].copy()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:18:43.233197Z","iopub.execute_input":"2022-02-24T09:18:43.233523Z","iopub.status.idle":"2022-02-24T09:18:44.69575Z","shell.execute_reply.started":"2022-02-24T09:18:43.233479Z","shell.execute_reply":"2022-02-24T09:18:44.694555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Критерий Дикки-Фуллера","metadata":{}},{"cell_type":"code","source":"# # Подсчет критерия Дикки-Фуллера для каждого из семейства товаров в каждом из магазинов\n\n# # для экономии расчетного времени данный код закомментирован\n# # не стационарные ряды собраны в fuller_not_stat\n\n# # ряды, где недостаточно данных для подсчета критерия Дикки-Фуллера, полностью совпадают с \n# # комбинациями из zero_prediction.\n\n# fuller_not_stat = pd.DataFrame(columns = ['store_nbr', 'family'])\n# small_data = pd.DataFrame(columns = ['store_nbr', 'family'])\n\n# for num, store in enumerate(tqdm(d_train.store_nbr.unique())):\n#     for numf, fam in enumerate(tqdm(d_train.family.unique())):\n#         a=d_train[(d_train.store_nbr == store) & (d_train.family == fam)]\n#         try:\n#             adftest = sm.tsa.adfuller(a.sales)\n#             print('Магазин: ', store, 'семейство товаров: ', fam)\n#             print('adf: ', adftest[0])\n#             print('p-value: ', adftest[1])\n#             print('Critical values: ', adftest[4])\n#             if adftest[0]> adftest[4]['5%']: \n#                 print('есть единичные корни, ряд не стационарен')\n#                 fuller_not_stat = fuller_not_stat.append({'store_nbr':store, 'family':fam}, ignore_index=True)\n#                 print('___'*20)\n#             else:\n#                 print('единичных корней нет, ряд стационарен')\n#                 print('___'*20)\n#         except ValueError:\n#                 print('Магазин: ', store, 'семейство товаров: ', fam)\n#                 print('Количество данных:', len(a))\n#                 small_data = small_data.append({'store_nbr':store, 'family':fam}, ignore_index=True)\n#                 print('___'*20)\n#                 continue\n                \n# # OUTPUT EXAMPLE:                \n# # Магазин:  1 семейство товаров:  AUTOMOTIVE\n# # adf:  -4.078623538152452\n# # p-value:  0.001050394088497745\n# # Critical values:  {'1%': -3.4342954463097706, '5%': -2.8632826898390484, '10%': -2.5676977663666714}\n# # единичных корней нет, ряд стационарен            \n# fuller_not_stat.to_csv('fuller_not_stat.csv', index=False)\n# small_data.to_csv('small_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T21:10:01.219899Z","iopub.execute_input":"2022-02-20T21:10:01.220381Z","iopub.status.idle":"2022-02-20T21:10:01.226785Z","shell.execute_reply.started":"2022-02-20T21:10:01.220342Z","shell.execute_reply":"2022-02-20T21:10:01.225807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для нестационарных рядов оказалось достаточно первой разности для приведения ряда к стационарному.","metadata":{}},{"cell_type":"code","source":"fuller_result = pd.read_csv(\"../input/fuller-result/fuller_not_stat.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:20:34.285723Z","iopub.execute_input":"2022-02-24T09:20:34.286061Z","iopub.status.idle":"2022-02-24T09:20:34.309008Z","shell.execute_reply.started":"2022-02-24T09:20:34.286009Z","shell.execute_reply":"2022-02-24T09:20:34.308196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Для нестационарных рядов делаем список из комбинаций store + family\nfuller_list = fuller_result.values\ns_fuller_list=[]\nfor i in range(fuller_list.shape[0]):\n    s_fuller_list.append(str(fuller_list[i][0]) + ',' + fuller_list[i][1])","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:20:34.718186Z","iopub.execute_input":"2022-02-24T09:20:34.718458Z","iopub.status.idle":"2022-02-24T09:20:34.725156Z","shell.execute_reply.started":"2022-02-24T09:20:34.718428Z","shell.execute_reply":"2022-02-24T09:20:34.72396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Скользящее среднее","metadata":{}},{"cell_type":"code","source":"# for num, store in enumerate(tqdm(d_train.store_nbr.unique())):\n#     for numf, fam in enumerate(tqdm(d_train.family.unique())):\n#         try:\n#             a=d_train[(d_train.store_nbr == store) & (d_train.family == fam)].copy()\n#             a=a.sales\n#             b = str(store)+','+fam\n#             if b in s_fuller_list:\n#                 a = a.diff().dropna() # если ряд не стационарный, то берем для него первую разность\n#             # d_train.loc[(d_train.store_nbr == store) & (d_train.family == fam),\"moving_avg\"] = a.rolling(7).mean()\n#             d_test.loc[(d_test.store_nbr == store) & (d_test.family == fam),'moving_avg']=a.rolling(7).mean().iloc[-1]\n#             #print('store:',store,'fam:',fam)\n#         except:\n#             continue","metadata":{"execution":{"iopub.status.busy":"2022-02-20T21:10:01.264155Z","iopub.execute_input":"2022-02-20T21:10:01.264888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit for moving_average","metadata":{}},{"cell_type":"code","source":"# d_test = d_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n# for i in zero_prediction.index:\n#     d_test.loc[i,'moving_avg']=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_test=d_test.reset_index()\n# y_submit = d_test[['id','moving_avg']].copy()\n# y_submit.columns = ['id', 'sales']\n# y_submit.to_csv('submission_moving_avg.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_submit.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Результат на kaggle 1.90138**","metadata":{}},{"cell_type":"code","source":"# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ARIMA","metadata":{}},{"cell_type":"markdown","source":"ARIMA зависит от значений p, d, q:\n   - p = количество лагов, параметр AR;\n   - d = порядок разности;\n   - q = количество запаздывающих ошибок прогноза, параметр MA.\naic (информационный критерий Акаике):\n- более низкий aic указывает на лучшую модель;\n- aic выбирет простые модели с более низким порядком.","metadata":{}},{"cell_type":"markdown","source":"Перебор параметров оказался ","metadata":{}},{"cell_type":"code","source":"# ps = range(0, 10)\n# d=1\n# qs = range(0, 10)\n# # Ps = range(0, 5)\n# # D=1\n# # Qs = range(0, 1)\n\n# from itertools import product\n\n# parameters = product(ps, qs)#, Ps, Qs)\n# parameters_list = list(parameters)\n# len(parameters_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# # Подбор параметров p и q для модели ARIMA\n# all_result_table = pd.DataFrame()\n# simplefilter(\"ignore\")  # ignore warnings to clean up output cells\n\n# for num, store in enumerate(tqdm(d_train.store_nbr.unique())):\n#     for numf, fam in enumerate(tqdm(d_train.family.unique())):\n#         a=d_train[(d_train.store_nbr == store) & (d_train.family == fam)].copy()\n#         a=a.set_index('date')\n#         b = str(store)+','+fam\n#         if b in s_fuller_list:\n#             a.sales = a.sales.diff().dropna() # если ряд не стационарный, то берем для него первую разность\n#         results = []\n#         best_aic = float(\"inf\")\n#         if len(a)!=0:\n#             for param in tqdm(parameters_list):\n#                 try:\n#                     model=sm.tsa.arima.ARIMA(a.sales, order=(param[0], d, param[1]), enforce_stationarity=False).fit()#, \n#                                         #seasonal_order=(param[3], D, param[3], 24*7)).fit(disp=0)\n#                 #выводим параметры, на которых модель не обучается и переходим к следующему набору\n#                 except ValueError:\n#                     print('wrong parameters:', param)\n#                     continue\n#                 aic = model.aic\n#                 #сохраняем лучшую модель, aic, параметры\n#                 if aic < best_aic:\n#                     best_model = model\n#                     best_aic = aic\n#                     best_param = param\n#                 results.append([param, model.aic])\n\n#                 # warnings.filterwarnings('default')\n\n#             result_table = pd.DataFrame(results)\n#             result_table.columns = ['parameters', 'aic']\n#             result_table = result_table.sort_values(by = 'aic', ascending=True)[:1]\n#             result_table['store_nbr'] = store\n#             result_table['family'] = fam\n#             all_result_table= all_result_table.append(result_table, ignore_index=True)\n#             print('best param: ', result_table)\n#             best_model = sm.tsa.arima.ARIMA(a.sales, order=(param[0], d, param[1])).fit()#, seasonal_order=(param[3], D, param[3], 24*7)).fit(disp=0)\n#             # d_train.loc[(d_train.store_nbr == store) & (d_train.family == fam),\"arima_model\"] = np.array(best_model.fittedvalues)\n#             d_test.loc[(d_test.store_nbr == store) & (d_test.family == fam),'arima_model']=np.array(best_model.predict(start = a.shape[0], end = a.shape[0]+15))\n#         else:\n#             continue\n            \n# print(all_result_table)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit for ARIMA","metadata":{}},{"cell_type":"code","source":"# d_test = d_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n# for i in zero_prediction.index:\n#     d_test.loc[i,'arima_model']=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_test = d_test.reset_index()\n# y_submit = d_test[['id','arima_model']].copy()\n# y_submit.columns = ['id', 'sales']\n# y_submit.to_csv('submission_arima_model.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_submit.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Модель Хольта-Винтерса","metadata":{}},{"cell_type":"code","source":"# from statsmodels.tsa.api import ExponentialSmoothing","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:42:31.008684Z","iopub.execute_input":"2022-02-24T07:42:31.009053Z","iopub.status.idle":"2022-02-24T07:42:31.014079Z","shell.execute_reply.started":"2022-02-24T07:42:31.009007Z","shell.execute_reply":"2022-02-24T07:42:31.013165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for num, store in enumerate(tqdm(d_train.store_nbr.unique())):\n#     for numf, fam in enumerate(tqdm(d_train.family.unique())):\n#         a = d_train[(d_train.store_nbr == store) & (d_train.family == fam)].copy()\n        \n#         if len(a)!=0:\n#             model_HW = ExponentialSmoothing(a.sales, seasonal_periods=7, trend='add', seasonal='add').fit()\n#             # d_train.loc[(d_train.store_nbr == store) & (d_train.family == fam),'HW_pred']=np.array(model_HW.fittedvalues)\n#             d_test.loc[(d_test.store_nbr == store) & (d_test.family == fam),'HW_pred']=np.array(model_HW.forecast(16))\n#             #print('store:', store, 'fam:', fam)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:44:01.120083Z","iopub.execute_input":"2022-02-24T07:44:01.120346Z","iopub.status.idle":"2022-02-24T07:59:09.165751Z","shell.execute_reply.started":"2022-02-24T07:44:01.120319Z","shell.execute_reply":"2022-02-24T07:59:09.164372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit for Holt-Winters model","metadata":{}},{"cell_type":"code","source":"# #d_test = d_test.reset_index().set_index(['store_nbr', 'family', 'date']).sort_index()\n# d_test = d_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n# for i in zero_prediction.index:\n#     d_test.loc[i,'HW_pred']=0","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:59:09.168755Z","iopub.execute_input":"2022-02-24T07:59:09.169114Z","iopub.status.idle":"2022-02-24T07:59:09.786564Z","shell.execute_reply.started":"2022-02-24T07:59:09.169069Z","shell.execute_reply":"2022-02-24T07:59:09.785756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_test=d_test.reset_index()\n# HW_submit = d_test[['id','HW_pred']].copy()\n# HW_submit['HW_pred'] = HW_submit.HW_pred.clip(0)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:06:54.978291Z","iopub.execute_input":"2022-02-24T08:06:54.978616Z","iopub.status.idle":"2022-02-24T08:06:54.986845Z","shell.execute_reply.started":"2022-02-24T08:06:54.978581Z","shell.execute_reply":"2022-02-24T08:06:54.985787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # d_test=d_test.reset_index()\n# # HW_submit = d_test[['id','HW_pred']].copy()\n# HW_submit.columns = ['id', 'sales']\n# HW_submit.to_csv('submission_HW_clip.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:07:47.454306Z","iopub.execute_input":"2022-02-24T08:07:47.455102Z","iopub.status.idle":"2022-02-24T08:07:47.538624Z","shell.execute_reply.started":"2022-02-24T08:07:47.455057Z","shell.execute_reply":"2022-02-24T08:07:47.537905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HW_submit.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T08:07:51.464148Z","iopub.execute_input":"2022-02-24T08:07:51.464775Z","iopub.status.idle":"2022-02-24T08:07:51.474365Z","shell.execute_reply.started":"2022-02-24T08:07:51.464727Z","shell.execute_reply":"2022-02-24T08:07:51.473595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Результат на kaggle 0.43267**","metadata":{}},{"cell_type":"code","source":"# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Regression","metadata":{}},{"cell_type":"markdown","source":"Сделаем отступление от принятой модели вычисления предсказания и возьмем среднее по дням вне зависимостри от семейства или магазина. Изучим полученный ряд на тренд и сезонность, построим периодограмму.","metadata":{}},{"cell_type":"markdown","source":"### Тренд для обобщенного ряда","metadata":{}},{"cell_type":"code","source":"# from pathlib import Path\n# from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom sklearn.linear_model import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:18:44.69756Z","iopub.execute_input":"2022-02-24T09:18:44.698055Z","iopub.status.idle":"2022-02-24T09:18:44.8946Z","shell.execute_reply.started":"2022-02-24T09:18:44.698004Z","shell.execute_reply":"2022-02-24T09:18:44.893497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# simplefilter(\"ignore\")  # ignore warnings to clean up output cells\n\n# # Set Matplotlib defaults\n# plt.style.use(\"seaborn-whitegrid\")\n# plt.rc(\"figure\", autolayout=True, figsize=(11, 5))\n# plt.rc(\n#     \"axes\",\n#     labelweight=\"bold\",\n#     labelsize=\"large\",\n#     titleweight=\"bold\",\n#     titlesize=14,\n#     titlepad=10,\n# )\n# plot_params = dict(\n#     color=\"0.75\",\n#     style=\".-\",\n#     markeredgecolor=\"0.25\",\n#     markerfacecolor=\"0.25\",\n#     legend=False,\n# )\n# %config InlineBackend.figure_format = 'retina'\n\n# # Группируем по дню \n# avg_sales = d_train.groupby('date').agg({'sales': 'mean'}).reset_index()\n# avg_sales = avg_sales.set_index('date').to_period(\"D\")\n\n\n# dp = DeterministicProcess(\n#     index=avg_sales.index,  # dates from the training data\n#     constant=True,       # dummy feature for the bias (y_intercept)\n#     order=1,             # the time dummy (trend)\n#     drop=True,           # drop terms if necessary to avoid collinearity\n# )\n# # `in_sample` creates features for the dates given in the `index` argument\n# X = dp.in_sample()\n# y = avg_sales[\"sales\"]  # the target\n\n# model = LinearRegression(fit_intercept=False)\n# model.fit(X, y)\n# y_pred = pd.Series(model.predict(X), index=X.index)\n\n# ax = avg_sales.plot(style=\".\", color=\"0.5\", title=\"sales - Linear Trend\")\n# _ = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сезонность для обобщенного ряда","metadata":{}},{"cell_type":"code","source":"# def seasonal_plot(X, y, period, freq, ax=None):\n#     if ax is None:\n#         _, ax = plt.subplots()\n#     palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n#     ax = sns.lineplot(\n#         x=freq,\n#         y=y,\n#         hue=period,\n#         data=X,\n#         ci=False,\n#         ax=ax,\n#         palette=palette,\n#         legend=False,\n#     )\n#     ax.set_title(f\"Seasonal Plot ({period}/{freq})\")\n#     for line, name in zip(ax.lines, X[period].unique()):\n#         y_ = line.get_ydata()[-1]\n#         ax.annotate(\n#             name,\n#             xy=(1, y_),\n#             xytext=(6, 0),\n#             color=line.get_color(),\n#             xycoords=ax.get_yaxis_transform(),\n#             textcoords=\"offset points\",\n#             size=14,\n#             va=\"center\",\n#         )\n#     return ax\n\n\n# def plot_periodogram(ts, detrend='linear', ax=None):\n#     from scipy.signal import periodogram\n#     fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n#     freqencies, spectrum = periodogram(\n#         ts,\n#         fs=fs,\n#         detrend=detrend,\n#         window=\"boxcar\",\n#         scaling='spectrum',\n#     )\n#     if ax is None:\n#         _, ax = plt.subplots()\n#     ax.step(freqencies, spectrum, color=\"purple\")\n#     ax.set_xscale(\"log\")\n#     ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n#     ax.set_xticklabels(\n#         [\n#             \"Annual (1)\",\n#             \"Semiannual (2)\",\n#             \"Quarterly (4)\",\n#             \"Bimonthly (6)\",\n#             \"Monthly (12)\",\n#             \"Biweekly (26)\",\n#             \"Weekly (52)\",\n#             \"Semiweekly (104)\",\n#         ],\n#         rotation=30,\n#     )\n#     ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n#     ax.set_ylabel(\"Variance\")\n#     ax.set_title(\"Periodogram\")\n#     return ax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_timefit = avg_sales.copy()\n\n# # days within a week\n# X_timefit['day'] = X_timefit.index.dayofweek # the x-axis (freq)\n# X_timefit['week'] = X_timefit.index.week # the seasonal period (period)\n\n# # days within a year\n# X_timefit['dayofyear'] = X_timefit.index.dayofyear\n# X_timefit['year'] = X_timefit.index.year\n\n# fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(11, 6))\n# seasonal_plot(X_timefit, y=\"sales\", period=\"week\", freq=\"day\", ax=ax0)\n# seasonal_plot(X_timefit, y=\"sales\", period=\"year\", freq=\"dayofyear\", ax=ax1);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_detrend = y - y_pred \n\n# fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\n# ax1 = plot_periodogram(y, ax=ax1)\n# ax1.set_title(\"Product Sales Frequency Components\")\n# ax2 = plot_periodogram(y_detrend, ax=ax2);\n# ax2.set_title(\"Detrended\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Прослеживается сильный недельный сезон и более слабый годовой сезон. Недельный сезон мы будем моделировать с помощью индикаторов, а годовой сезон — с помощью функций Фурье. Периодограмма затихает между раз Bimonthly (6) и Monthly (12),будем используем 10 пар Фурье.","metadata":{}},{"cell_type":"markdown","source":"Полученный рузельтат будем применять в разрезе магазинов и семейств товаров.","metadata":{}},{"cell_type":"code","source":"# # В нашем датасете остались категориальные признаки,\n# # которые необходимо закодировать в числовые.\n\n# lab_enc_col = ['city','state','type','cluster']\n# # Label Encoding\n# for column in lab_enc_col:\n#     df[column] = df[column].astype('category').cat.codes\n        \n# # One-Hot Encoding c get_dummies.\n# df = pd.get_dummies(df, columns=lab_enc_col, dummy_na=False)\n\n# # Раздеряем на test и train\n# d_train = df[df.date<'2017-08-16'].copy()\n# d_test = df[df.date>='2017-08-16'].copy()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:46:03.767824Z","iopub.execute_input":"2022-02-21T10:46:03.768949Z","iopub.status.idle":"2022-02-21T10:46:12.439199Z","shell.execute_reply.started":"2022-02-21T10:46:03.768903Z","shell.execute_reply":"2022-02-21T10:46:12.437805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_train=d_train.drop(['city','state','type','cluster'], axis=1)\nd_test=d_test.drop(['city','state','type','cluster'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:20:15.071768Z","iopub.execute_input":"2022-02-24T09:20:15.072076Z","iopub.status.idle":"2022-02-24T09:20:15.761884Z","shell.execute_reply.started":"2022-02-24T09:20:15.072043Z","shell.execute_reply":"2022-02-24T09:20:15.760714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_test['lr_model'] = 0\n# fourier = CalendarFourier(freq=\"A\", order=10) \nfor num, store in enumerate(tqdm(d_train.store_nbr.unique())):\n    for numf, fam in enumerate(tqdm(d_train.family.unique())):\n        a = d_train[(d_train.store_nbr == store) & (d_train.family == fam)].copy()\n        a = a.set_index('date').to_period(\"D\")\n        b = str(store)+','+fam\n        \n        if len(a)!=0:\n            if b in s_fuller_list:\n                a.sales = a.sales.diff().fillna(0)\n                \n#             dp = DeterministicProcess(\n#                 index=a.index,\n#                 constant=True,   # dummy feature for bias (y-intercept)\n#                 order=1,         # trend ( order 1 means linear)\n#                 seasonal=True,   # weekly seasonality (indicators)\n#                 additional_terms=[fourier], # annual seasonality\n#                 drop=True,       # drop terms to avoid collinearity\n#             )\n\n#             X = dp.in_sample() # create features for dates in tunnel.index\n            \n#             X = X.join(a.drop(['family','store_nbr','id','sales','year'],axis=1))\n            X = a.drop(['family','store_nbr','id','sales','year'],axis=1).copy()\n            y = a.sales\n\n            model = LinearRegression(fit_intercept=False)\n            model.fit(X, y)\n\n#             X_fore = dp.out_of_sample(16)\n            a_fore = d_test[(d_test.store_nbr == store) & (d_test.family == fam)].copy()\n            a_fore = a_fore.set_index('date').to_period(\"D\")\n#             X_fore = X_fore.join(a_fore.drop(['family','store_nbr','id','sales','year','lr_model'],axis=1))\n            X_fore = a_fore.drop(['family','store_nbr','id','sales','year','lr_model'],axis=1).copy()\n            d_test.loc[(d_test.store_nbr == store) & (d_test.family == fam), 'lr_model'] = model.predict(X_fore)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T09:20:54.27161Z","iopub.execute_input":"2022-02-24T09:20:54.271878Z","iopub.status.idle":"2022-02-24T09:21:16.283334Z","shell.execute_reply.started":"2022-02-24T09:20:54.27185Z","shell.execute_reply":"2022-02-24T09:21:16.281519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit for Linear Regression","metadata":{}},{"cell_type":"code","source":"d_test = d_test.set_index(['store_nbr', 'family', 'date']).sort_index()\nfor i in zero_prediction.index:\n    d_test.loc[i,'lr_model']=0","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:55:33.540204Z","iopub.execute_input":"2022-02-21T10:55:33.541948Z","iopub.status.idle":"2022-02-21T10:55:34.196606Z","shell.execute_reply.started":"2022-02-21T10:55:33.541859Z","shell.execute_reply":"2022-02-21T10:55:34.195527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_test=d_test.reset_index()\nlr_submit = d_test[['id','lr_model']].copy()\nlr_submit['lr_model'] = lr_submit.lr_model.clip(0)\nlr_submit.columns = ['id', 'sales']\nlr_submit.to_csv('submission_lr_clip.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:55:34.206403Z","iopub.execute_input":"2022-02-21T10:55:34.20667Z","iopub.status.idle":"2022-02-21T10:55:34.310061Z","shell.execute_reply.started":"2022-02-21T10:55:34.206641Z","shell.execute_reply":"2022-02-21T10:55:34.309263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_submit.tail()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T10:55:34.311627Z","iopub.execute_input":"2022-02-21T10:55:34.311888Z","iopub.status.idle":"2022-02-21T10:55:34.329757Z","shell.execute_reply.started":"2022-02-21T10:55:34.311857Z","shell.execute_reply":"2022-02-21T10:55:34.328812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Результат на kaggle 2.00271**","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:02:47.755814Z","iopub.execute_input":"2022-02-21T11:02:47.756586Z","iopub.status.idle":"2022-02-21T11:02:47.870384Z","shell.execute_reply.started":"2022-02-21T11:02:47.756529Z","shell.execute_reply":"2022-02-21T11:02:47.86929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_test['xgb_model'] = 0\n# fourier = CalendarFourier(freq=\"A\", order=10) \nfor num, store in enumerate(tqdm(d_train.store_nbr.unique())):\n    for numf, fam in enumerate(tqdm(d_train.family.unique())):\n        a = d_train[(d_train.store_nbr == store) & (d_train.family == fam)].copy()\n        a = a.set_index('date').to_period(\"D\")\n        b = str(store)+','+fam\n        \n        if len(a)!=0:\n            if b in s_fuller_list:\n                a.sales = a.sales.diff().fillna(0)\n                \n#             dp = DeterministicProcess(\n#                 index=a.index,\n#                 constant=True,   # dummy feature for bias (y-intercept)\n#                 order=1,         # trend ( order 1 means linear)\n#                 seasonal=True,   # weekly seasonality (indicators)\n#                 additional_terms=[fourier], # annual seasonality\n#                 drop=True,       # drop terms to avoid collinearity\n#             )\n\n#             X = dp.in_sample() # create features for dates in tunnel.index\n#             X_train = X.join(a.drop(['family','store_nbr','id','sales','year'],axis=1))# !!! удалить lr_model\n            X_train = a.drop(['family','store_nbr','id','sales','year'],axis=1).copy()\n            y = a.sales\n            \n#             X_fore = dp.out_of_sample(16)\n            a_fore = d_test[(d_test.store_nbr == store) & (d_test.family == fam)].copy()\n            a_fore = a_fore.set_index('date').to_period(\"D\")\n#             X_fore = X_fore.join(a_fore.drop(['family','store_nbr','id','sales','year','xgb_model'],axis=1)) # !!!\n            X_fore = a_fore.drop(['family','store_nbr','id','sales','year','lr_model','xgb_model'],axis=1).copy()\n            \n            dtrain = xgb.DMatrix(X_train, label=y)\n            dtest = xgb.DMatrix(X_fore)\n            \n            # задаём параметры\n            params = {\n                'objective': 'reg:squarederror',\n                'booster':'gblinear'\n            }\n            trees = 100\n            \n            # прогоняем на кросс-валидации с метрикой rmse\n            cv = xgb.cv(params, dtrain, metrics = ('rmse'), verbose_eval=False, nfold=5, show_stdv=False, num_boost_round=trees)\n            # print('store: ', store, 'fam: ', fam)\n            # обучаем xgboost с оптимальным числом деревьев, подобранным на кросс-валидации\n            bst = xgb.train(params, dtrain, num_boost_round=cv['test-rmse-mean'].argmin())\n\n            d_test.loc[(d_test.store_nbr == store) & (d_test.family == fam), 'xgb_model'] = bst.predict(dtest)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:04:46.062838Z","iopub.execute_input":"2022-02-21T11:04:46.063186Z","iopub.status.idle":"2022-02-21T11:12:12.982758Z","shell.execute_reply.started":"2022-02-21T11:04:46.063148Z","shell.execute_reply":"2022-02-21T11:12:12.981539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit for XGBoost","metadata":{}},{"cell_type":"code","source":"d_test = d_test.set_index(['store_nbr', 'family', 'date']).sort_index()\nfor i in zero_prediction.index:\n    d_test.loc[i,'xgb_model']=0","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:03:41.41908Z","iopub.status.idle":"2022-02-21T11:03:41.419421Z","shell.execute_reply.started":"2022-02-21T11:03:41.41925Z","shell.execute_reply":"2022-02-21T11:03:41.419267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_test=d_test.reset_index()\nxgb_submit = d_test[['id','xgb_model']].copy()\nxgb_submit['xgb_model'] = xgb_submit.xgb_model.clip(0)\nxgb_submit.columns = ['id', 'sales']\nxgb_submit.to_csv('submission_xgb_clip.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:03:41.42059Z","iopub.status.idle":"2022-02-21T11:03:41.420908Z","shell.execute_reply.started":"2022-02-21T11:03:41.420741Z","shell.execute_reply":"2022-02-21T11:03:41.420762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_submit.tail()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T11:03:41.422515Z","iopub.status.idle":"2022-02-21T11:03:41.423309Z","shell.execute_reply.started":"2022-02-21T11:03:41.423123Z","shell.execute_reply":"2022-02-21T11:03:41.423144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}