{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center> TIME SERIES FORECASTING </center></h1>","metadata":{}},{"cell_type":"markdown","source":"## 1) SETUP","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\n\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-13T21:37:12.880144Z","iopub.execute_input":"2022-03-13T21:37:12.880515Z","iopub.status.idle":"2022-03-13T21:37:14.159848Z","shell.execute_reply.started":"2022-03-13T21:37:12.880414Z","shell.execute_reply":"2022-03-13T21:37:14.15791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Reading the files","metadata":{}},{"cell_type":"code","source":"comp_dir = Path('../input/store-sales-time-series-forecasting')\n\n# train_df : \ntrain_df = pd.read_csv(comp_dir / 'train.csv', parse_dates=['date'], infer_datetime_format=True)\n\n#test_df = pd.read_csv(comp_dir / 'test.csv', index_col='date', parse_dates=['date'],)\n#stores_df = pd.read_csv(comp_dir / 'stores.csv', index_col='date', parse_dates=['date'],)\n#oil_df = pd.read_csv('comp_dir / 'oil.csv', index_col='date', parse_dates=['date'],)\nholidays_df = pd.read_csv(\n    comp_dir / 'holidays_events.csv',\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:14.16241Z","iopub.execute_input":"2022-03-13T21:37:14.162819Z","iopub.status.idle":"2022-03-13T21:37:17.193837Z","shell.execute_reply.started":"2022-03-13T21:37:14.162762Z","shell.execute_reply":"2022-03-13T21:37:17.192947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3) Set Matplotlib Defaults","metadata":{}},{"cell_type":"code","source":"# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(11, 4),\n    titlesize=18,\n    titleweight='bold',\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:17.195352Z","iopub.execute_input":"2022-03-13T21:37:17.195654Z","iopub.status.idle":"2022-03-13T21:37:17.215556Z","shell.execute_reply.started":"2022-03-13T21:37:17.195615Z","shell.execute_reply":"2022-03-13T21:37:17.214811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Store sales Dataframe ","metadata":{}},{"cell_type":"code","source":"store_sales = train_df.copy()\nstore_sales = store_sales.set_index('date').to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family'], append=True)\n\nstore_sales","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:17.217042Z","iopub.execute_input":"2022-03-13T21:37:17.218784Z","iopub.status.idle":"2022-03-13T21:37:18.28652Z","shell.execute_reply.started":"2022-03-13T21:37:17.218736Z","shell.execute_reply":"2022-03-13T21:37:18.285646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Average sales Series","metadata":{}},{"cell_type":"code","source":"average_sales = store_sales.groupby('date').mean()['sales']\n\naverage_sales","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:18.289315Z","iopub.execute_input":"2022-03-13T21:37:18.289742Z","iopub.status.idle":"2022-03-13T21:37:18.440051Z","shell.execute_reply.started":"2022-03-13T21:37:18.289697Z","shell.execute_reply":"2022-03-13T21:37:18.439282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 6.1) Linear Regression Model with a time-step feature\non the series of average product sales. The target is in a column called 'sales'.","metadata":{}},{"cell_type":"code","source":"avg_sales_df = average_sales.to_frame()\n\n# Create a time dummy\ntime = np.arange(len(avg_sales_df.index)) # array([ 0, 1, 2, ..., 1681, 1682, 1683])\n\navg_sales_df['time'] = time \n\n# Create training data\nX = avg_sales_df.loc[:, ['time']]  # features (dataframe)\ny = avg_sales_df.loc[:, 'sales'] # target (series)\n\n# Train the model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Store the fitted values as a time series with the same time index as\n# the training data\ny_pred = pd.Series(model.predict(X), index=X.index)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:18.441595Z","iopub.execute_input":"2022-03-13T21:37:18.441884Z","iopub.status.idle":"2022-03-13T21:37:18.467721Z","shell.execute_reply.started":"2022-03-13T21:37:18.441847Z","shell.execute_reply":"2022-03-13T21:37:18.4667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y.plot(**plot_params, alpha=0.5)\nax = y_pred.plot(ax=ax, linewidth=3)\nax.set_title('Time Plot of Total Store Sales');","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:18.468874Z","iopub.execute_input":"2022-03-13T21:37:18.469145Z","iopub.status.idle":"2022-03-13T21:37:18.983798Z","shell.execute_reply.started":"2022-03-13T21:37:18.469115Z","shell.execute_reply":"2022-03-13T21:37:18.983016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the fitted values over time shows us how fitting linear regression to the time dummy creates the trend line defined by this equation.","metadata":{}},{"cell_type":"markdown","source":"Time-step features let you model time dependence. A series is time dependent if its values can be predicted from the time they occured. In the previous Sales series, we can predict that sales later in the month are generally higher than sales earlier in the month","metadata":{}},{"cell_type":"markdown","source":"## 6.2) Linear regression Model with a lag feature \non the series of average product sales. The target is in a column of df called 'sales'.","metadata":{}},{"cell_type":"code","source":"avg_sales_df = average_sales.to_frame()\n\n# Create a lag feature from the target 'sales'\nlag_1 = avg_sales_df['sales'].shift(1)\n\navg_sales_df['lag_1'] = lag_1  # add to dataframe\n\nX = avg_sales_df.loc[:, ['lag_1']]\nX.dropna(inplace=True)  # features\n\ny = avg_sales_df.loc[:, 'sales']  # target\ny, X = y.align(X, join='inner')  # drop corresponding values in target\n\n# Create a LinearRegression instance and fit it to X and y.\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Create Store the fitted values as a time series with\n# the same time index as the training data\ny_pred = pd.Series(model.predict(X), index=X.index)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:18.985316Z","iopub.execute_input":"2022-03-13T21:37:18.985759Z","iopub.status.idle":"2022-03-13T21:37:19.007942Z","shell.execute_reply.started":"2022-03-13T21:37:18.985722Z","shell.execute_reply":"2022-03-13T21:37:19.00728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When creating lag features, we need to decide what to do with the missing values produced. Filling them in is one option, maybe with 0.0 or \"backfilling\" with the first known value. Instead, we'll just drop the missing values, making sure to also drop values in the target from corresponding dates.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(X['lag_1'], y, '.', color='0.25')\nax.plot(X['lag_1'], y_pred)\nax.set(aspect='equal', ylabel='sales', xlabel='lag_1', title='Lag Plot of Average Sales');","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:19.00893Z","iopub.execute_input":"2022-03-13T21:37:19.009625Z","iopub.status.idle":"2022-03-13T21:37:19.339898Z","shell.execute_reply.started":"2022-03-13T21:37:19.009589Z","shell.execute_reply":"2022-03-13T21:37:19.339044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see from the lag plot that sales on one day (sales) are correlated with sales from the previous day (Lag_1). When you see a relationship like this, you know a lag feature will be useful.","metadata":{}},{"cell_type":"markdown","source":"More generally, lag features let you model serial dependence. A time series has serial dependence when an observation can be predicted from previous observations. In Sales, we can predict that high sales on one day usually mean high sales the next day.","metadata":{}},{"cell_type":"markdown","source":"Adapting machine learning algorithms to time series problems is largely about feature engineering with the time index and lags. We will use linear regression for its simplicity, but these features will be useful whichever algorithm you choose for your forecasting task.","metadata":{}},{"cell_type":"markdown","source":"What does this prediction from a lag feature mean about how well we can predict the series across time? The following time plot shows us how our forecasts now respond to the behavior of the series in the recent past.","metadata":{}},{"cell_type":"code","source":"ax = y.plot(**plot_params)\nax = y_pred.plot()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:19.341193Z","iopub.execute_input":"2022-03-13T21:37:19.34144Z","iopub.status.idle":"2022-03-13T21:37:19.835429Z","shell.execute_reply.started":"2022-03-13T21:37:19.341411Z","shell.execute_reply":"2022-03-13T21:37:19.834678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3) Conclusion:\nThe best time series models will usually include some combination of time-step features and lag features","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 7) Moving Average Plots\nTo see what kind of trend a time series might have, we can use a moving average plot. \nThe idea is to smooth out any short-term fluctuations in the series so that only long-term changes remain.","metadata":{}},{"cell_type":"markdown","source":"Let's make a moving average plot to see what kind of trend this series has. Since this series has daily observations, let's choose a window of 365 days to smooth over any short-term changes within the year.","metadata":{}},{"cell_type":"markdown","source":"To create a moving average, first use the rolling method to begin a windowed computation. Follow this by the mean method to compute the average over the window.","metadata":{}},{"cell_type":"code","source":"trend = average_sales.rolling(\n    window=365,\n    center=True,\n    min_periods=183,\n).mean()\n\nax = average_sales.plot(**plot_params, alpha=0.5)\nax = trend.plot(ax=ax, linewidth=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:19.836664Z","iopub.execute_input":"2022-03-13T21:37:19.837052Z","iopub.status.idle":"2022-03-13T21:37:20.28108Z","shell.execute_reply.started":"2022-03-13T21:37:19.837008Z","shell.execute_reply":"2022-03-13T21:37:20.28018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.1) Identify Trend: \nAs we can see, the trend of average sales appears to be about cubic.","metadata":{"execution":{"iopub.status.busy":"2022-03-11T22:30:15.075343Z","iopub.execute_input":"2022-03-11T22:30:15.075992Z","iopub.status.idle":"2022-03-11T22:30:15.082036Z","shell.execute_reply.started":"2022-03-11T22:30:15.075939Z","shell.execute_reply":"2022-03-11T22:30:15.081262Z"}}},{"cell_type":"markdown","source":"## 8) Create a Trend Feature:\nWe'll use DeterministicProcess to create a feature set for a cubic trend model. Also create features for a 90-day forecast.","metadata":{}},{"cell_type":"markdown","source":"Previously, we engineered our time dummy in Pandas directly. From now on, however, we'll use a function from the statsmodels library called DeterministicProcess. Using this function will help us avoid some tricky failure cases that can arise with time series and linear regression. The order argument refers to polynomial order: 1 for linear, 2 for quadratic, 3 for cubic, and so on.","metadata":{}},{"cell_type":"code","source":"# from statsmodels.tsa.deterministic import DeterministicProcess\n\ny = average_sales.copy()  # the target\n\ndp = DeterministicProcess(\n        index=average_sales.index,\n        constant=False,\n        order=3,\n        drop=True\n)\n\n# Create the feature set for the dates given in y.index\nX = dp.in_sample()\n\n# Create features for a 90-day forecast.\nX_fore = dp.out_of_sample(steps=90)\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nX_fore.tail()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:20.282223Z","iopub.execute_input":"2022-03-13T21:37:20.282431Z","iopub.status.idle":"2022-03-13T21:37:20.431417Z","shell.execute_reply.started":"2022-03-13T21:37:20.282406Z","shell.execute_reply":"2022-03-13T21:37:20.430551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To make a forecast, we apply our model to \"out of sample\" features. \"Out of sample\" refers to times outside of the observation period of the training data. Here's how we could make a 30-day forecast:","metadata":{}},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:37:20.432654Z","iopub.execute_input":"2022-03-13T21:37:20.4329Z","iopub.status.idle":"2022-03-13T21:37:20.442518Z","shell.execute_reply.started":"2022-03-13T21:37:20.432872Z","shell.execute_reply":"2022-03-13T21:37:20.4417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see the a plot of the result by running the next cell.","metadata":{}},{"cell_type":"code","source":"ax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\", color='C0')\nax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color='C3')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:09.897713Z","iopub.execute_input":"2022-03-13T21:38:09.898676Z","iopub.status.idle":"2022-03-13T21:38:10.430841Z","shell.execute_reply.started":"2022-03-13T21:38:09.898618Z","shell.execute_reply":"2022-03-13T21:38:10.429678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The trend discovered by our LinearRegression model is almost identical to the moving average plot, which suggests that a cubic trend was the right decision in this case.","metadata":{}},{"cell_type":"markdown","source":"The trend models we learned about in this lesson turn out to be useful for a number of reasons. Besides acting as a baseline or starting point for more sophisticated models, we can also use them as a component in a \"hybrid model\" with algorithms unable to learn trends (like XGBoost and random forests). We'll learn more about this technique in Lesson 5.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{"execution":{"iopub.status.busy":"2022-03-12T23:10:18.127165Z","iopub.execute_input":"2022-03-12T23:10:18.127561Z","iopub.status.idle":"2022-03-12T23:10:18.133369Z","shell.execute_reply.started":"2022-03-12T23:10:18.127518Z","shell.execute_reply":"2022-03-12T23:10:18.132531Z"}}},{"cell_type":"markdown","source":"### 9) SEASONALITY","metadata":{}},{"cell_type":"markdown","source":"We say that a time series exhibits seasonality whenever there is a regular, periodic change in the mean of the series. Seasonal changes generally follow the clock and calendar -- repetitions over a day, a week, or a year are common. Seasonality is often driven by the cycles of the natural world over days and years or by conventions of social behavior surrounding dates and times.","metadata":{}},{"cell_type":"markdown","source":"We will learn two kinds of features that model seasonality. The first kind, **indicators**, is best for a season with few observations, like a weekly season of daily observations. The second kind, **Fourier** features, is best for a season with many observations, like an annual season of daily observations.","metadata":{}},{"cell_type":"markdown","source":"### 10) Holiday events Dataframe","metadata":{}},{"cell_type":"code","source":"holidays_events = holidays_df.copy()\nholidays_events = holidays_events.set_index('date').to_period('D')\nholidays_events","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:14.674802Z","iopub.execute_input":"2022-03-13T21:38:14.675626Z","iopub.status.idle":"2022-03-13T21:38:14.695761Z","shell.execute_reply.started":"2022-03-13T21:38:14.675583Z","shell.execute_reply":"2022-03-13T21:38:14.694923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.1) New Store Sales Dataframe and Average Sales Series","metadata":{}},{"cell_type":"code","source":"store_sales_nuevo = pd.read_csv(\n        comp_dir / \"train.csv\",\n        usecols=[\"store_nbr\", \"family\", \"date\", \"sales\"],\n        dtype={\n            \"store_nbr\": \"category\",\n            \"familiy\": \"category\",\n            \"sales\": \"float32\",\n        },\n        parse_dates=['date'],\n        infer_datetime_format=True,\n)\nstore_sales_nuevo['date'] = store_sales_nuevo.date.dt.to_period('D')\nstore_sales_nuevo = store_sales_nuevo.set_index(['store_nbr', 'family', 'date']).sort_index()\n\naverage_sales_nuevo = (\n    store_sales_nuevo.groupby('date').mean().squeeze().loc['2017']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:17.864976Z","iopub.execute_input":"2022-03-13T21:38:17.865274Z","iopub.status.idle":"2022-03-13T21:38:21.485377Z","shell.execute_reply.started":"2022-03-13T21:38:17.865239Z","shell.execute_reply":"2022-03-13T21:38:21.484409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 11) Seasonal Plots and Periodgrams","metadata":{}},{"cell_type":"markdown","source":"### 11.1) Some Useful Functions:\n        seasonal_plot() , plot_periodgram()","metadata":{}},{"cell_type":"code","source":"# annotations: https://stackoverflow.com/a/49238256/5769929\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodgram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:22.415847Z","iopub.execute_input":"2022-03-13T21:38:22.416164Z","iopub.status.idle":"2022-03-13T21:38:22.427893Z","shell.execute_reply.started":"2022-03-13T21:38:22.416132Z","shell.execute_reply":"2022-03-13T21:38:22.427042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A seasonal plot shows segments of the time series plotted against some common period, the period being the \"season\" you want to observe.\n\nWe will examine the following **seasonal plot** to try to discover seasonal patterns.","metadata":{}},{"cell_type":"code","source":"X = average_sales_nuevo.to_frame()\nX[\"week\"] = X.index.week # the seasonal period (period)\nX[\"day\"] = X.index.dayofweek # the x-axis (freq)\nseasonal_plot(X, y='sales', period='week', freq='day');","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:26.514916Z","iopub.execute_input":"2022-03-13T21:38:26.515242Z","iopub.status.idle":"2022-03-13T21:38:27.485798Z","shell.execute_reply.started":"2022-03-13T21:38:26.515209Z","shell.execute_reply":"2022-03-13T21:38:27.484906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a clear weekly seasonal pattern in this series, higher on weekend.","metadata":{}},{"cell_type":"markdown","source":"Let's also take a look at the following periodgram. The **periodogram** tells you the strength of the frequencies in a time series.","metadata":{}},{"cell_type":"code","source":"plot_periodgram(average_sales_nuevo)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:31.315422Z","iopub.execute_input":"2022-03-13T21:38:31.315695Z","iopub.status.idle":"2022-03-13T21:38:32.009998Z","shell.execute_reply.started":"2022-03-13T21:38:31.315667Z","shell.execute_reply":"2022-03-13T21:38:32.009066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From left to right, the periodogram drops off after Monthly, twelve times a year. That was why we'll choose 12 Fourier pairs to model the annual season. The Weekly frequency we ignore since it's better modeled with indicators.","metadata":{}},{"cell_type":"markdown","source":"Both the seasonal plot and the periodogram suggest a strong weekly seasonality. From the periodogram, it appears there may be some monthly and biweekly components as well. In fact, the notes to the Store Sales dataset say wages in the public sector are paid out biweekly, on the 15th and last day of the month -- a possible origin for these seasons.","metadata":{}},{"cell_type":"markdown","source":"### 12) Create Seasonal Features","metadata":{}},{"cell_type":"markdown","source":"We'll create our seasonal features using DeterministicProcess, the same utility we used to create trend features. To use two seasonal periods (weekly and annual), we'll need to instantiate one of them as an \"additional term\":","metadata":{}},{"cell_type":"code","source":"y = average_sales_nuevo.copy()\n\nfourier = CalendarFourier(freq='M', order=4) #  4 sin/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,       # dummy feature for bias (y-intercept)\n    order=1,             # trend (order 1 means linear)\n    # YOUR CODE HERE\n    seasonal=True,       # weekly seasonality (indicators)\n    additional_terms=[fourier], # annual seasonality (fourier)\n    drop=True,           # drop terms to avoid collinearity\n)\nX = dp.in_sample()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:35.896997Z","iopub.execute_input":"2022-03-13T21:38:35.897266Z","iopub.status.idle":"2022-03-13T21:38:35.913361Z","shell.execute_reply.started":"2022-03-13T21:38:35.897241Z","shell.execute_reply":"2022-03-13T21:38:35.912399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now run this cell to fit the seasonal model.","metadata":{}},{"cell_type":"code","source":"model = LinearRegression().fit(X, y)\ny_pred = pd.Series(\n    model.predict(X),\n    index=X.index,\n    name='Fitted',\n)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:42.079593Z","iopub.execute_input":"2022-03-13T21:38:42.080128Z","iopub.status.idle":"2022-03-13T21:38:42.693087Z","shell.execute_reply.started":"2022-03-13T21:38:42.080096Z","shell.execute_reply":"2022-03-13T21:38:42.692069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" We'll add a 90-day forecast to see how our model extrapolates beyond the training data.","metadata":{}},{"cell_type":"code","source":"# mio\n\nmodel = LinearRegression(fit_intercept=False)\n_ = model.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=y.index)\nX_fore = dp.out_of_sample(steps=90)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(color='0.25', style='.', title=\"Average Sales - Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:38:49.193563Z","iopub.execute_input":"2022-03-13T21:38:49.194366Z","iopub.status.idle":"2022-03-13T21:38:49.893819Z","shell.execute_reply.started":"2022-03-13T21:38:49.194319Z","shell.execute_reply":"2022-03-13T21:38:49.89304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's still more we can do with time series to improve our forecasts. In the next lesson, we'll learn how to use time series themselves as a features. Using time series as inputs to a forecast lets us model the another component often found in series: cycles.","metadata":{}},{"cell_type":"markdown","source":"### 13) Detrending or Deseasonalizing","metadata":{}},{"cell_type":"markdown","source":"Removing from a series its trend or seasons is called detrending or deseasonalizing the series.\n\nLook at the periodogram of the deseasonalized series.","metadata":{}},{"cell_type":"code","source":"y_deseason = y - y_pred\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodgram(y, ax=ax1)\nax1.set_title(\"Product Sales Frequency Components\")\nax2 = plot_periodgram(y_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:39:58.90736Z","iopub.execute_input":"2022-03-13T21:39:58.907888Z","iopub.status.idle":"2022-03-13T21:39:59.823704Z","shell.execute_reply.started":"2022-03-13T21:39:58.907854Z","shell.execute_reply":"2022-03-13T21:39:59.823073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Holidays Dataframe","metadata":{}},{"cell_type":"markdown","source":"The Store Sales dataset includes a table of Ecuadorian holidays.","metadata":{}},{"cell_type":"code","source":"# National and regional holidays in the training set\nholidays = (\n    holidays_events\n    .query(\"locale in ['National', 'Regional']\")\n    .loc['2017':'2017-08-15', ['description']]\n    .assign(description=lambda x: x.description.cat.remove_unused_categories())\n)\n\ndisplay(holidays)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:42:49.72239Z","iopub.execute_input":"2022-03-13T21:42:49.723042Z","iopub.status.idle":"2022-03-13T21:42:49.745098Z","shell.execute_reply.started":"2022-03-13T21:42:49.723001Z","shell.execute_reply":"2022-03-13T21:42:49.744232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From a plot of the deseasonalized Average Sales, it appears **these holidays could have some predictive power.**","metadata":{}},{"cell_type":"code","source":"ax = y_deseason.plot(**plot_params)\nplt.plot_date(holidays.index, y_deseason[holidays.index], color='C3')\nax.set_title('National and Regional Holidays');","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:44:29.669406Z","iopub.execute_input":"2022-03-13T21:44:29.669768Z","iopub.status.idle":"2022-03-13T21:44:30.172485Z","shell.execute_reply.started":"2022-03-13T21:44:29.669731Z","shell.execute_reply":"2022-03-13T21:44:30.171669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 14) Create Holiday Features\nWhat kind of features could you create to help your model make use of this information?","metadata":{}},{"cell_type":"code","source":"ohe = OneHotEncoder(sparse=False)\n\nX_holidays = pd.DataFrame(\n    ohe.fit_transform(holidays),\n    index=holidays.index,\n    columns=holidays.description.unique(),\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:52:25.192858Z","iopub.execute_input":"2022-03-13T21:52:25.193291Z","iopub.status.idle":"2022-03-13T21:52:25.20131Z","shell.execute_reply.started":"2022-03-13T21:52:25.193254Z","shell.execute_reply":"2022-03-13T21:52:25.200356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Join to training data\nX2 = X.join(X_holidays, on='date').fillna(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:52:31.063502Z","iopub.execute_input":"2022-03-13T21:52:31.064364Z","iopub.status.idle":"2022-03-13T21:52:31.072757Z","shell.execute_reply.started":"2022-03-13T21:52:31.064327Z","shell.execute_reply":"2022-03-13T21:52:31.071593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now fit the seasonal model with holiday features added. Do the fitted values seem to have improved?","metadata":{}},{"cell_type":"code","source":"model = LinearRegression().fit(X2, y)\ny_pred = pd.Series(\n    model.predict(X2),\n    index=X2.index,\n    name='Fitted',\n)\n\ny_pred = pd.Series(model.predict(X2), index=X2.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-03-13T21:54:18.988507Z","iopub.execute_input":"2022-03-13T21:54:18.98885Z","iopub.status.idle":"2022-03-13T21:54:19.592748Z","shell.execute_reply.started":"2022-03-13T21:54:18.988816Z","shell.execute_reply":"2022-03-13T21:54:19.591885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First Submition to Store Sales competition","metadata":{}},{"cell_type":"markdown","source":"The next cell creates a seasonal model of the kind we've learned about for the full store sales dataset with all 1800 time series. ","metadata":{}},{"cell_type":"code","source":"y = store_sales_nuevo.unstack(['store_nbr', 'family']).loc['2017']\n\n# Create Training Data\nfourier = CalendarFourier(freq=\"M\", order=4)\n\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\n\nX = dp.in_sample()\nX['NewYear'] = (X.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X,y)\ny_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T22:10:23.651747Z","iopub.execute_input":"2022-03-13T22:10:23.652756Z","iopub.status.idle":"2022-03-13T22:10:25.032224Z","shell.execute_reply.started":"2022-03-13T22:10:23.652712Z","shell.execute_reply":"2022-03-13T22:10:25.031059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can use this cell to see some of its predictions.","metadata":{}},{"cell_type":"code","source":"STORE_NBR = '1'  # 1 - 54\nFAMILY = 'PRODUCE'\n# Uncomment to see a list of product families\n# display(store_sales.index.get_level_values('family').unique())\n\nax = y.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(**plot_params)\nax = y_pred.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(ax=ax)\nax.set_title(f'{FAMILY} Sales at Store {STORE_NBR}');","metadata":{"execution":{"iopub.status.busy":"2022-03-13T22:10:27.686022Z","iopub.execute_input":"2022-03-13T22:10:27.6863Z","iopub.status.idle":"2022-03-13T22:10:28.271819Z","shell.execute_reply.started":"2022-03-13T22:10:27.68627Z","shell.execute_reply":"2022-03-13T22:10:28.271049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, this cell loads the test data, creates a feature set for the forecast period, and then creates the submission file submission.csv.","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\n    comp_dir / 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ndf_test['date'] = df_test.date.dt.to_period('D')\ndf_test = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n\n# Create features for test set\nX_test = dp.out_of_sample(steps=16)\nX_test.index.name = 'date'\nX_test['NewYear'] = (X_test.index.dayofyear == 1)\n\n\ny_submit = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)\ny_submit = y_submit.stack(['store_nbr', 'family'])\ny_submit = y_submit.join(df_test.id).reindex(columns=['id', 'sales'])\ny_submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T22:10:36.022802Z","iopub.execute_input":"2022-03-13T22:10:36.023585Z","iopub.status.idle":"2022-03-13T22:10:36.493305Z","shell.execute_reply.started":"2022-03-13T22:10:36.023546Z","shell.execute_reply":"2022-03-13T22:10:36.492535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}}]}