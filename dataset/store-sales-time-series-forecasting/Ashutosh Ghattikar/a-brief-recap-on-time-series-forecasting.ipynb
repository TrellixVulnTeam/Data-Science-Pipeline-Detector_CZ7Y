{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 style=\"color:fuchsia;font-size:55px;font-family:Space mono;text-align:center;\"><strong>Time Series Analysis ðŸ“ˆðŸ“ˆ  </strong></h2> \n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:08:34.251565Z","iopub.execute_input":"2021-12-11T19:08:34.251843Z","iopub.status.idle":"2021-12-11T19:08:34.258461Z","shell.execute_reply.started":"2021-12-11T19:08:34.251813Z","shell.execute_reply":"2021-12-11T19:08:34.257211Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T20:08:16.254316Z","iopub.execute_input":"2021-12-11T20:08:16.25474Z","iopub.status.idle":"2021-12-11T20:08:16.273524Z","shell.execute_reply.started":"2021-12-11T20:08:16.254685Z","shell.execute_reply":"2021-12-11T20:08:16.27272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IMPORTING ESSENTIALS**","metadata":{}},{"cell_type":"code","source":"!pip install pmdarima","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:23:01.741908Z","iopub.execute_input":"2021-12-11T20:23:01.742323Z","iopub.status.idle":"2021-12-11T20:23:10.749286Z","shell.execute_reply.started":"2021-12-11T20:23:01.742278Z","shell.execute_reply":"2021-12-11T20:23:10.748452Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pylab\nfrom pylab import rcParams\n\n\nplt.style.use('dark_background')\nplt.rcParams['figure.figsize'] = 18,8\npd.set_option('display.max_columns', None)\n\n\nfrom sklearn.metrics import mean_squared_error\n\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport pmdarima as pm\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:16.275405Z","iopub.execute_input":"2021-12-11T20:08:16.276057Z","iopub.status.idle":"2021-12-11T20:08:16.284722Z","shell.execute_reply.started":"2021-12-11T20:08:16.276019Z","shell.execute_reply":"2021-12-11T20:08:16.28391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **READ AND MERGE THE DATA INTO A SINGLE DATAFRAME**","metadata":{}},{"cell_type":"code","source":"df_holi = pd.read_csv('../input/store-sales-time-series-forecasting/holidays_events.csv')\ndf_oil = pd.read_csv('../input/store-sales-time-series-forecasting/oil.csv')\ndf_stores = pd.read_csv('../input/store-sales-time-series-forecasting/stores.csv')\ndf_trans = pd.read_csv('../input/store-sales-time-series-forecasting/transactions.csv')\n\ndf_train = pd.read_csv('../input/store-sales-time-series-forecasting/train.csv')\ndf_test = pd.read_csv('../input/store-sales-time-series-forecasting/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:16.286673Z","iopub.execute_input":"2021-12-11T20:08:16.287182Z","iopub.status.idle":"2021-12-11T20:08:19.003654Z","shell.execute_reply.started":"2021-12-11T20:08:16.287146Z","shell.execute_reply":"2021-12-11T20:08:19.002718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train1 = df_train.merge(df_holi, on = 'date', how='left')\ndf_train1 = df_train1.merge(df_oil, on = 'date', how='left')\ndf_train1 = df_train1.merge(df_stores, on = 'store_nbr', how='left')\ndf_train1 = df_train1.merge(df_trans, on = ['date', 'store_nbr'], how='left')\ndf_train1 = df_train1.rename(columns = {\"type_x\" : \"holiday_type\", \"type_y\" : \"store_type\"})\n\ndf_train1['date'] = pd.to_datetime(df_train1['date'])\ndf_train1['year'] = df_train1['date'].dt.year\ndf_train1['month'] = df_train1['date'].dt.month\ndf_train1['week'] = df_train1['date'].dt.isocalendar().week\ndf_train1['quarter'] = df_train1['date'].dt.quarter\ndf_train1['day_of_week'] = df_train1['date'].dt.day_name()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:19.004925Z","iopub.execute_input":"2021-12-11T20:08:19.005793Z","iopub.status.idle":"2021-12-11T20:08:28.173884Z","shell.execute_reply.started":"2021-12-11T20:08:19.005752Z","shell.execute_reply":"2021-12-11T20:08:28.172942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train1.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:28.175218Z","iopub.execute_input":"2021-12-11T20:08:28.175447Z","iopub.status.idle":"2021-12-11T20:08:28.199328Z","shell.execute_reply.started":"2021-12-11T20:08:28.175418Z","shell.execute_reply":"2021-12-11T20:08:28.198651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"df = df_train1 #copying the original df into a temp df which we can work on,just incase we dont mess up with the original one","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:28.200739Z","iopub.execute_input":"2021-12-11T20:08:28.201179Z","iopub.status.idle":"2021-12-11T20:08:28.204464Z","shell.execute_reply.started":"2021-12-11T20:08:28.201145Z","shell.execute_reply":"2021-12-11T20:08:28.203924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The merged dataframe has {df.shape[0]} rows and {df.shape[1]} columns')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:28.206605Z","iopub.execute_input":"2021-12-11T20:08:28.207022Z","iopub.status.idle":"2021-12-11T20:08:28.217842Z","shell.execute_reply.started":"2021-12-11T20:08:28.206976Z","shell.execute_reply":"2021-12-11T20:08:28.217126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:28.219234Z","iopub.execute_input":"2021-12-11T20:08:28.219485Z","iopub.status.idle":"2021-12-11T20:08:28.243604Z","shell.execute_reply.started":"2021-12-11T20:08:28.219454Z","shell.execute_reply":"2021-12-11T20:08:28.242846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:28.244958Z","iopub.execute_input":"2021-12-11T20:08:28.245502Z","iopub.status.idle":"2021-12-11T20:08:34.178875Z","shell.execute_reply.started":"2021-12-11T20:08:28.245465Z","shell.execute_reply":"2021-12-11T20:08:34.177883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Let's us check the time period of the data which is available*","metadata":{}},{"cell_type":"code","source":"print(f'The data is available from {df.date.max()} to {df.date.min()}')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.180464Z","iopub.execute_input":"2021-12-11T20:08:34.181192Z","iopub.status.idle":"2021-12-11T20:08:34.212654Z","shell.execute_reply.started":"2021-12-11T20:08:34.18115Z","shell.execute_reply":"2021-12-11T20:08:34.21147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*for simplicity lets convert the date column values with only dates discarding the info about the hours, minutes and seconds*","metadata":{}},{"cell_type":"code","source":"df['date'] = df['date'].dt.floor('d')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.214056Z","iopub.execute_input":"2021-12-11T20:08:34.214395Z","iopub.status.idle":"2021-12-11T20:08:34.297628Z","shell.execute_reply.started":"2021-12-11T20:08:34.214356Z","shell.execute_reply":"2021-12-11T20:08:34.29646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n*For time-series analysis, let's only consider the 'data' and the 'sales' columns*","metadata":{}},{"cell_type":"code","source":"df = df[['date', 'sales']]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.299082Z","iopub.execute_input":"2021-12-11T20:08:34.299326Z","iopub.status.idle":"2021-12-11T20:08:34.326363Z","shell.execute_reply.started":"2021-12-11T20:08:34.299295Z","shell.execute_reply":"2021-12-11T20:08:34.325198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.set_index(df.date)\ndf.drop('date', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.327768Z","iopub.execute_input":"2021-12-11T20:08:34.32804Z","iopub.status.idle":"2021-12-11T20:08:34.363409Z","shell.execute_reply.started":"2021-12-11T20:08:34.32801Z","shell.execute_reply":"2021-12-11T20:08:34.362275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n*Chesking if there are any missing values in our series, if there is any missing values then our time series analysis wont work*","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.364973Z","iopub.execute_input":"2021-12-11T20:08:34.365242Z","iopub.status.idle":"2021-12-11T20:08:34.38088Z","shell.execute_reply.started":"2021-12-11T20:08:34.365211Z","shell.execute_reply":"2021-12-11T20:08:34.379983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n*There are no missing values in our series, that means that the data is present for all of 2013 to 2017*\n*The data is captured on daily basis, let's resample it to monthly basis to make analysis easier*","metadata":{}},{"cell_type":"code","source":"df = df.resample('M').mean()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.382799Z","iopub.execute_input":"2021-12-11T20:08:34.383586Z","iopub.status.idle":"2021-12-11T20:08:34.484529Z","shell.execute_reply.started":"2021-12-11T20:08:34.383547Z","shell.execute_reply":"2021-12-11T20:08:34.483791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE :**\n*The 'sales' column had many outliers, instead of treating them seperately, we can make use of 'median' while resampling instead of 'mean' to neutralize the effects of outliers,*\n*Now the above series is an account of the almost average sales per month from 2013 to aug-2017*","metadata":{}},{"cell_type":"markdown","source":"# **VISUALIZE THE DATA**","metadata":{}},{"cell_type":"code","source":"y = df['sales']\nfig, ax = plt.subplots(figsize=(18, 8))\nax.plot(y,marker='o', markersize=8, linestyle='-', label='Monthly Mean Resample', color='fuchsia')\nax.set_ylabel('sales')\nax.set_title('Average sales per month')\nax.set_xlabel('years')\nax.grid(axis='x')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.486113Z","iopub.execute_input":"2021-12-11T20:08:34.486607Z","iopub.status.idle":"2021-12-11T20:08:34.815572Z","shell.execute_reply.started":"2021-12-11T20:08:34.48657Z","shell.execute_reply":"2021-12-11T20:08:34.814579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n*Looking at the figure above, by the eye-judgement we can see an upward trend in the avg sales and there seems to be some seasonality, but later on in this notebook we will verify these attributes*\n","metadata":{}},{"cell_type":"markdown","source":"# DECOMPOSE THE DATA","metadata":{}},{"cell_type":"markdown","source":"*By looking at the graph of sales data above, we can see a general increasing trend with no clear pattern of seasonal or cyclical changes. The next step is to decompose the data to view more of the complexity behind the linear visualization, once decomposed, we can clearly get :*\n* *Observed (actual series)*\n* *Trend*\n* *Seasonality*\n* *Residuals (irrgularities)*","metadata":{}},{"cell_type":"code","source":"df_dec=seasonal_decompose(df,model='additive', extrapolate_trend='freq')\ndf_dec.plot();","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:34.816944Z","iopub.execute_input":"2021-12-11T20:08:34.817199Z","iopub.status.idle":"2021-12-11T20:08:35.837391Z","shell.execute_reply.started":"2021-12-11T20:08:34.817166Z","shell.execute_reply":"2021-12-11T20:08:35.83666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Looking at the four components above, we can say that the our avg sales per month has an upward trend overall and there is seasonality throughout, based on these factors, we can use suitable time-series forecasting model later*","metadata":{}},{"cell_type":"markdown","source":"# **CHECK FOR STATIONARITY**","metadata":{}},{"cell_type":"markdown","source":"*For the next step we have to check for the stationarity of the trend, a series is said to be stationary when*\n* ***The mean doesnt change over time***\n* ***The variance of the series doesnt change over time***\n\n*and we have to make our data stationary if it is not stationary, because the time-series forecasting models make use of the assumption that there is no change in mean or variance in the data*","metadata":{}},{"cell_type":"markdown","source":"*The most two common methods used to check for stationarity are*\n* ***Visualization***\n* ***Augmented Dickey-Fuller test (ADF test)*** ","metadata":{}},{"cell_type":"markdown","source":"1. **Visualization**","metadata":{}},{"cell_type":"code","source":"sales_mean = df.sales.rolling(window=12).mean()\nsales_std = df.sales.rolling(window=12).std()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:35.84078Z","iopub.execute_input":"2021-12-11T20:08:35.841231Z","iopub.status.idle":"2021-12-11T20:08:35.846526Z","shell.execute_reply.started":"2021-12-11T20:08:35.841176Z","shell.execute_reply":"2021-12-11T20:08:35.84591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 8))\nax.plot(df.sales,marker='x', markersize=8, label='Sales',color='cyan')\nax.plot(sales_mean,marker='o', markersize=4, label='rolling mean', color='red');\nax.plot(sales_std,marker='*', markersize=4, label='rolling std', color='royalblue');\nax.legend()\nplt.xlabel('Years')\nplt.ylabel('Avg sales')\nplt.title('Check of stationarity')\nax.grid(axis='x')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:35.848084Z","iopub.execute_input":"2021-12-11T20:08:35.848629Z","iopub.status.idle":"2021-12-11T20:08:36.187506Z","shell.execute_reply.started":"2021-12-11T20:08:35.848568Z","shell.execute_reply":"2021-12-11T20:08:36.184162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*In the above figure, we are smoothening the series to remove the abrupt changes of the original data which can be helpful to judge the smoothened mean and std line of the data.*\n*We can see that the mean of the data is not same through out but where as the standard deviation is almost constant.*\n\n*We cannot confidently conclude that the data is stationary just by seeing the above insights, lets use adf test to check for the stationarity of the data next*","metadata":{}},{"cell_type":"markdown","source":"2. **Augmented Dickey-Fuller test (ADF test)**","metadata":{}},{"cell_type":"markdown","source":"*The augmented Dickey-Fuller test is a statistical test which is used to check for the stationarity of a time series, this test gives a p-value, test-statistic value and the critical values with confidence intervals stating the stationarity and based on the p-value obtained by the adf test we can reject or accpet the null hypothesis.*\n* **H<sub>0</sub>  : 'The time series is not stationary'**\n* **H<sub>a</sub>  : 'The time series is stationary'**","metadata":{}},{"cell_type":"code","source":"dftest = adfuller(df.dropna(), autolag='AIC')\nprint('Test statistic = {:.3f}'.format(dftest[0]))\nprint('P-value = {:.3f}'.format(dftest[1]))\nprint('Critical values :')\nfor k, v in dftest[4].items():\n    print('\\t{}: {} - The data is {} stationary with {}% confidence'.format(k, v, 'not' if v<dftest[0] else '', 100-int(k[:-1])))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:36.188902Z","iopub.execute_input":"2021-12-11T20:08:36.189148Z","iopub.status.idle":"2021-12-11T20:08:36.207201Z","shell.execute_reply.started":"2021-12-11T20:08:36.189119Z","shell.execute_reply":"2021-12-11T20:08:36.206283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*As expected from the figure and also tested by the adf test for stationarity, we can confidently say that the original data is not stationary*","metadata":{}},{"cell_type":"markdown","source":"# **MAKING THE DATA STATIONARY**","metadata":{}},{"cell_type":"markdown","source":"*Now that we know about the stationarity of the data, we have to make it stationary, there are many ways to make a series stationary viz.*\n* **Differencing**\n* **Rolling window**\n* **Transformation**","metadata":{}},{"cell_type":"markdown","source":"1. **DIFFERENCING**","metadata":{}},{"cell_type":"markdown","source":"*Differencing is a method of inducing a lag in the data which will remove the seasonal or cyclical patterns from the data*","metadata":{}},{"cell_type":"code","source":"df_lag12 = df.sales - df.sales.shift(12)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:36.208601Z","iopub.execute_input":"2021-12-11T20:08:36.208966Z","iopub.status.idle":"2021-12-11T20:08:36.214521Z","shell.execute_reply.started":"2021-12-11T20:08:36.208928Z","shell.execute_reply":"2021-12-11T20:08:36.213677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_lag12.tail(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:36.215834Z","iopub.execute_input":"2021-12-11T20:08:36.216079Z","iopub.status.idle":"2021-12-11T20:08:36.232051Z","shell.execute_reply.started":"2021-12-11T20:08:36.216048Z","shell.execute_reply":"2021-12-11T20:08:36.231039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df_lag12\nfig, ax = plt.subplots(figsize=(18, 8))\nax.plot(y,marker='o', markersize=8, linestyle='-', label='Monthly Mean Resample', color='fuchsia')\nax.set_ylabel('sales')\nax.set_title('Average sales per month')\nax.set_xlabel('years')\nax.grid(axis='x')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:36.233826Z","iopub.execute_input":"2021-12-11T20:08:36.234431Z","iopub.status.idle":"2021-12-11T20:08:36.610121Z","shell.execute_reply.started":"2021-12-11T20:08:36.234387Z","shell.execute_reply":"2021-12-11T20:08:36.608998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftest = adfuller(df_lag12.dropna(), autolag='AIC')\nprint('Test statistic = {:.3f}'.format(dftest[0]))\nprint('P-value = {:.3f}'.format(dftest[1]))\nprint('Critical values :')\nfor k, v in dftest[4].items():\n    print('\\t{}: {} - The data is {} stationary with {}% confidence'.format(k, v, 'not' if v<dftest[0] else '', 100-int(k[:-1])))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:36.611552Z","iopub.execute_input":"2021-12-11T20:08:36.61185Z","iopub.status.idle":"2021-12-11T20:08:36.631134Z","shell.execute_reply.started":"2021-12-11T20:08:36.611815Z","shell.execute_reply":"2021-12-11T20:08:36.630191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_dec_lag12 =seasonal_decompose(df_lag12.dropna(),model='additive', extrapolate_trend='freq')\ndf_dec.plot();","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:36.633482Z","iopub.execute_input":"2021-12-11T20:08:36.633914Z","iopub.status.idle":"2021-12-11T20:08:37.689631Z","shell.execute_reply.started":"2021-12-11T20:08:36.633868Z","shell.execute_reply":"2021-12-11T20:08:37.68867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BUILDING A FORECASTING MODEL**","metadata":{}},{"cell_type":"markdown","source":"*Now that the data is stationary, we can go ahead and build a forecasting model*\n*There are many forecasting models in time-series forecasting but depending on the data components we can pick the suitable model and build it*\n\n* **Exponential Smoothing model is best for data without trend or seasonality**\n* **Holtâ€™s Method for data with a trend but no seasonality**\n* **Holt-Winters for data with trend and/or seasonality**\n* **ARIMA for data with trend and/or seasonality**\n","metadata":{}},{"cell_type":"markdown","source":"# **NAIVE MODEL IN TIME-SERIES FORECASTING**","metadata":{}},{"cell_type":"code","source":"df['shifted_sales'] = df.sales.shift(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:37.690909Z","iopub.execute_input":"2021-12-11T20:08:37.691153Z","iopub.status.idle":"2021-12-11T20:08:37.697221Z","shell.execute_reply.started":"2021-12-11T20:08:37.691113Z","shell.execute_reply":"2021-12-11T20:08:37.696565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(4)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:37.698256Z","iopub.execute_input":"2021-12-11T20:08:37.699105Z","iopub.status.idle":"2021-12-11T20:08:37.719341Z","shell.execute_reply.started":"2021-12-11T20:08:37.699061Z","shell.execute_reply":"2021-12-11T20:08:37.718638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 8))\nax.plot(df.sales,marker='*', markersize=8, label='Sales',color='white')\nax.plot(df.shifted_sales,marker='o', markersize=4, label='Shifted Sales', color='cyan');\nplt.xlabel('Year')\nplt.ylabel('avg sales')\nplt.title('Naive model')\nax.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:37.720816Z","iopub.execute_input":"2021-12-11T20:08:37.721087Z","iopub.status.idle":"2021-12-11T20:08:38.017635Z","shell.execute_reply.started":"2021-12-11T20:08:37.721044Z","shell.execute_reply":"2021-12-11T20:08:38.016694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.01891Z","iopub.execute_input":"2021-12-11T20:08:38.019189Z","iopub.status.idle":"2021-12-11T20:08:38.026444Z","shell.execute_reply.started":"2021-12-11T20:08:38.019146Z","shell.execute_reply":"2021-12-11T20:08:38.025581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse = mean_squared_error(df.sales, df.shifted_sales)\n\nrmse = np.sqrt(mse)\n\nprint(f'The root mean square error of the naive model is : {rmse}')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.027743Z","iopub.execute_input":"2021-12-11T20:08:38.028014Z","iopub.status.idle":"2021-12-11T20:08:38.040981Z","shell.execute_reply.started":"2021-12-11T20:08:38.027982Z","shell.execute_reply":"2021-12-11T20:08:38.039976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The naive forecasting model gave us a root mean square error of **57**, that means on an average a monthly sales prediction value might differ by a value of <u>+</u> ***57*** from the actual prediction*","metadata":{}},{"cell_type":"markdown","source":"# **HOLT-WINTER'S MODEL FOR FORECASTING**","metadata":{}},{"cell_type":"code","source":"df = df.drop('shifted_sales',axis=1) # 'shifter_sales' not needed for holt-winters model","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.04207Z","iopub.execute_input":"2021-12-11T20:08:38.042342Z","iopub.status.idle":"2021-12-11T20:08:38.051416Z","shell.execute_reply.started":"2021-12-11T20:08:38.042308Z","shell.execute_reply":"2021-12-11T20:08:38.050524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hw = ExponentialSmoothing(df, seasonal_periods=12,trend='add', seasonal='add').fit()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.052984Z","iopub.execute_input":"2021-12-11T20:08:38.053239Z","iopub.status.idle":"2021-12-11T20:08:38.217464Z","shell.execute_reply.started":"2021-12-11T20:08:38.053201Z","shell.execute_reply":"2021-12-11T20:08:38.216499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hw_preds = hw.forecast(steps=24)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.219208Z","iopub.execute_input":"2021-12-11T20:08:38.219454Z","iopub.status.idle":"2021-12-11T20:08:38.23165Z","shell.execute_reply.started":"2021-12-11T20:08:38.219423Z","shell.execute_reply":"2021-12-11T20:08:38.230626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 8))\nax.plot(df,marker='*', markersize=8, label='Sales',color='fuchsia')\nax.plot(hw_preds,marker='*', markersize=8, label='Forecasted sales', color='orange');\nplt.xlabel('Year')\nplt.ylabel('avg sales')\nplt.title('Holt-Winters model' )\nax.grid(axis='x')\nax.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.232857Z","iopub.execute_input":"2021-12-11T20:08:38.233133Z","iopub.status.idle":"2021-12-11T20:08:38.540473Z","shell.execute_reply.started":"2021-12-11T20:08:38.233074Z","shell.execute_reply":"2021-12-11T20:08:38.539444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hw_resid = hw.resid\nhw_resid_sqr = np.square(hw_resid)\nhw_resid_mse = hw_resid_sqr.sum()/len(hw_resid_sqr)\nhw_resid_rmse = np.sqrt(hw_resid_mse)\n\n\nprint(f'The rmse value of Holt-Winters model is {hw_resid_rmse}')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.541793Z","iopub.execute_input":"2021-12-11T20:08:38.542057Z","iopub.status.idle":"2021-12-11T20:08:38.549727Z","shell.execute_reply.started":"2021-12-11T20:08:38.542022Z","shell.execute_reply":"2021-12-11T20:08:38.548671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Comparing the rmse values of the Naive model and the holt-winters model, holt-winters model performs better with lesser rmse value, let's check with the final model  i.e **ARIMA** and compare how it performs other than these two*","metadata":{}},{"cell_type":"markdown","source":"# **ARIMA (Auto-Regressive Integrated Moving Average)**","metadata":{}},{"cell_type":"markdown","source":"*Now ARIMA takes in 3 components to work and hose are*\n* Auto-Regressive (p)\n* Integrated (differencing, d)\n* Moving Average (q)\n\n*And these values has to be found before giving it to the model, it can be done using **ACF** and **PACF** plots which will give the right values for the p and q values respectively*\n   \n*We can even use grid-seach technique to find the best values of p, q and d inorder to have least AIC value (AIC is Akike Information Criteria, it is a measure of the goodness of the time series model, lower the value of AIC better the model is)*\n","metadata":{}},{"cell_type":"markdown","source":"**PLOTTING ACF AND PACF PLOT**","metadata":{}},{"cell_type":"code","source":"plot_acf(df);","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.551451Z","iopub.execute_input":"2021-12-11T20:08:38.551903Z","iopub.status.idle":"2021-12-11T20:08:38.850849Z","shell.execute_reply.started":"2021-12-11T20:08:38.55186Z","shell.execute_reply":"2021-12-11T20:08:38.849708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The shaded region is the critical value and the spikes is the correlation value between the 1st value and the next corresponding values, the spike which is in the shaded region is the optimal value of p*","metadata":{}},{"cell_type":"code","source":"plot_pacf(df);","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:38.85241Z","iopub.execute_input":"2021-12-11T20:08:38.852844Z","iopub.status.idle":"2021-12-11T20:08:39.143402Z","shell.execute_reply.started":"2021-12-11T20:08:38.852789Z","shell.execute_reply":"2021-12-11T20:08:39.142417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The shaded region is the critical value and the spikes is the correlation value between the 1st value and the next corresponding values, the spike which is in the shaded region is the optimal value of q*","metadata":{}},{"cell_type":"code","source":"dftrain = df.iloc[:38]\ndftest = df.iloc[38:]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:08:58.176015Z","iopub.execute_input":"2021-12-11T20:08:58.176358Z","iopub.status.idle":"2021-12-11T20:08:58.181752Z","shell.execute_reply.started":"2021-12-11T20:08:58.176323Z","shell.execute_reply":"2021-12-11T20:08:58.180538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arima_mod = ARIMA(dftrain, order=(5,1,3)) #p=5, d=1, q=3\narima_mod= arima_mod.fit(disp=0)\narima_preds = arima_mod.forecast(steps = 17)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:09:31.406875Z","iopub.execute_input":"2021-12-11T20:09:31.407222Z","iopub.status.idle":"2021-12-11T20:09:32.523934Z","shell.execute_reply.started":"2021-12-11T20:09:31.407179Z","shell.execute_reply":"2021-12-11T20:09:32.522585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse = mean_squared_error(dftest, arima_preds[0])\nprint(f'The root mean square error of ARIMA with (5,1,3) is {np.sqrt(mse)}')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:09:58.228975Z","iopub.execute_input":"2021-12-11T20:09:58.229331Z","iopub.status.idle":"2021-12-11T20:09:58.238298Z","shell.execute_reply.started":"2021-12-11T20:09:58.229294Z","shell.execute_reply":"2021-12-11T20:09:58.237363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arima_preds = pd.Series(arima_preds[0], index=dftest.index)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:10:07.707427Z","iopub.execute_input":"2021-12-11T20:10:07.707796Z","iopub.status.idle":"2021-12-11T20:10:07.713216Z","shell.execute_reply.started":"2021-12-11T20:10:07.707759Z","shell.execute_reply":"2021-12-11T20:10:07.712228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 8))\nax.plot(dftest,marker='*', markersize=8, label='Test sales', color='fuchsia');\nax.plot(arima_preds,marker='*', markersize=8, label='Arima_forecasting', color='grey');\nplt.xlabel('Year')\nplt.ylabel('avg sales')\nplt.title('ARIMA' )\nax.grid(axis='x')\nax.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:10:16.549065Z","iopub.execute_input":"2021-12-11T20:10:16.550012Z","iopub.status.idle":"2021-12-11T20:10:16.880443Z","shell.execute_reply.started":"2021-12-11T20:10:16.549936Z","shell.execute_reply":"2021-12-11T20:10:16.879707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*On comparing the Naie model, Holt-winter's model and ARIMA model, we can make out that the Holt-Winter's model performs well compared to all other models*","metadata":{}},{"cell_type":"markdown","source":"**HOLT-WINTER's FORECASTING MODEL FTW**","metadata":{}}]}