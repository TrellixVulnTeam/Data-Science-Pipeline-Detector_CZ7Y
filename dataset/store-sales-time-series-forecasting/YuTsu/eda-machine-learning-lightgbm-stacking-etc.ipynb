{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import modules","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:17:54.525212Z","iopub.execute_input":"2021-10-14T12:17:54.525607Z","iopub.status.idle":"2021-10-14T12:17:54.53594Z","shell.execute_reply.started":"2021-10-14T12:17:54.525574Z","shell.execute_reply":"2021-10-14T12:17:54.535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport lightgbm as lgb\nimport optuna\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.feature_selection import RFE\nfrom plotly.offline import iplot, init_notebook_mode\nfrom plotly.subplots import make_subplots\ninit_notebook_mode()\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:17:54.537723Z","iopub.execute_input":"2021-10-14T12:17:54.538516Z","iopub.status.idle":"2021-10-14T12:17:54.605543Z","shell.execute_reply.started":"2021-10-14T12:17:54.538478Z","shell.execute_reply":"2021-10-14T12:17:54.604437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def path_join(name):\n    path = '/kaggle/input/store-sales-time-series-forecasting'\n    return os.path.join(path, name)\n\n\ndef describe(df):\n    '''\n    make dataframe which describe the details about null count, etc\n    '''\n    print(f'Shape : {df.shape}')\n    summary = pd.DataFrame(df.dtypes, columns=['DataType']).reset_index()\n    summary = summary.rename(columns={'index': 'Feature'})\n    summary['null count'] = df.isnull().sum().values\n    summary['unique count'] = df.nunique().values\n    summary['First value'] = df.loc[0].values\n    summary['Second value'] = df.loc[1].values\n    summary['Third value'] = df.loc[2].values\n    \n    return summary","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T12:17:54.606942Z","iopub.execute_input":"2021-10-14T12:17:54.607255Z","iopub.status.idle":"2021-10-14T12:17:54.615713Z","shell.execute_reply.started":"2021-10-14T12:17:54.607222Z","shell.execute_reply":"2021-10-14T12:17:54.614804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(path_join('train.csv'))\ntest = pd.read_csv(path_join('test.csv'))\noil = pd.read_csv(path_join('oil.csv'))\nholidays_events = pd.read_csv(path_join('holidays_events.csv'))\nstores = pd.read_csv(path_join('stores.csv'))\ntransactions = pd.read_csv(path_join('transactions.csv'))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:17:54.61722Z","iopub.execute_input":"2021-10-14T12:17:54.617974Z","iopub.status.idle":"2021-10-14T12:17:56.925126Z","shell.execute_reply.started":"2021-10-14T12:17:54.617934Z","shell.execute_reply":"2021-10-14T12:17:56.924407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1st, EDA\n\n## We need to explore df and try to figure out the key that data have! \n\n# Train","metadata":{}},{"cell_type":"code","source":"display(describe(train))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T12:17:56.927006Z","iopub.execute_input":"2021-10-14T12:17:56.928101Z","iopub.status.idle":"2021-10-14T12:17:58.382976Z","shell.execute_reply.started":"2021-10-14T12:17:56.928046Z","shell.execute_reply":"2021-10-14T12:17:58.382028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['sales'].value_counts().sort_values()[:10])\nprint(train['onpromotion'].value_counts().sort_values()[:10])\nprint('\\n\\n')\n\n_, axes = plt.subplots(2, 2, figsize=(18, 10), facecolor='lightgray')\nplt.suptitle('Check the numeric distribution', color='blue', fontsize=30)\n\nsns.distplot(train['sales'], ax=axes[0, 0])\naxes[0, 0].set_title('sales displot', fontsize=25)\n\nsns.boxplot(x='sales', data=train, ax=axes[0, 1])\naxes[0, 1].set_title('sales boxplot', fontsize=25)\n\nsns.histplot(x='onpromotion', data=train, bins=20, ax=axes[1, 0])\naxes[1, 0].set_title('onpromotion hist', fontsize=25)\n\nsns.boxplot(x='onpromotion', data=train, ax=axes[1, 1])\naxes[1, 1].set_title('onpromotion boxplot', fontsize=25)\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:17:58.384457Z","iopub.execute_input":"2021-10-14T12:17:58.385018Z","iopub.status.idle":"2021-10-14T12:18:13.484467Z","shell.execute_reply.started":"2021-10-14T12:17:58.384981Z","shell.execute_reply":"2021-10-14T12:18:13.48383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightblue;padding:18px;text-align:center\">\n    <h3> we found sales col have outliers but <span style=\"color:red\">this case the data can be happend</span> as real data.</h3>\n    <h3> I don't clean any outliers in train </h3>\n</div>","metadata":{}},{"cell_type":"code","source":"# train plotly for my skill, haha\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=train['store_nbr'].value_counts().index, values=train['store_nbr'].value_counts()),\n              1, 1)\nfig.add_trace(go.Pie(labels=train['family'].value_counts().index, values=train['family'].value_counts()),\n              1, 2)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:18:13.485647Z","iopub.execute_input":"2021-10-14T12:18:13.48601Z","iopub.status.idle":"2021-10-14T12:18:14.508921Z","shell.execute_reply.started":"2021-10-14T12:18:13.485979Z","shell.execute_reply":"2021-10-14T12:18:14.508004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightblue;padding:10px;text-align:center\">\n    <h3>number of family and store_nbr's ingredients are the same!</h3>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# transactions","metadata":{}},{"cell_type":"code","source":"display(describe(transactions))\nsns.displot(x='transactions', data=transactions)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-10-14T12:18:14.510219Z","iopub.execute_input":"2021-10-14T12:18:14.510477Z","iopub.status.idle":"2021-10-14T12:18:15.302047Z","shell.execute_reply.started":"2021-10-14T12:18:14.510448Z","shell.execute_reply":"2021-10-14T12:18:15.300932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# holidays_events","metadata":{}},{"cell_type":"code","source":"display(describe(holidays_events))\n\nfor var in holidays_events['locale_name'].unique():\n    print(var, holidays_events.query('locale_name==@var')['locale'].unique())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T12:18:15.303739Z","iopub.execute_input":"2021-10-14T12:18:15.304021Z","iopub.status.idle":"2021-10-14T12:18:15.398356Z","shell.execute_reply.started":"2021-10-14T12:18:15.303989Z","shell.execute_reply":"2021-10-14T12:18:15.397402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### enough to use only 'locale_name' instead of using with 'locale' becuase locale_name covers locale\n#### ex: Santo Domingo must be 'local', Ecuador must be 'National' etc.","metadata":{}},{"cell_type":"code","source":"# description isn't able to be uses for analysis this case.. drop it\nholidays_events = holidays_events.drop(['locale', 'description'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:15.399496Z","iopub.execute_input":"2021-10-14T12:18:15.39973Z","iopub.status.idle":"2021-10-14T12:18:15.405604Z","shell.execute_reply.started":"2021-10-14T12:18:15.399704Z","shell.execute_reply":"2021-10-14T12:18:15.40452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locale_name = holidays_events['locale_name'].value_counts()\nfig = px.pie(stores, values=locale_name, names=locale_name.index)\n\nfig.update_layout(\ntitle_font_color=\"#fff\",paper_bgcolor=\"#283747\",title_font_size=20,title_x=.5,font_color=\"#bbb\",\n    plot_bgcolor=\"#D6EAF8\")\n\nfig.show()\n\ndel locale_name","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:18:15.406826Z","iopub.execute_input":"2021-10-14T12:18:15.40706Z","iopub.status.idle":"2021-10-14T12:18:15.480605Z","shell.execute_reply.started":"2021-10-14T12:18:15.407033Z","shell.execute_reply":"2021-10-14T12:18:15.479665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train to use plotly.\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\nfig = make_subplots(rows=1, cols=2, specs=specs, subplot_titles=['type_holiday', 'transferred'])\ntype_holiday = holidays_events['type'].value_counts()\ntransferred = holidays_events['transferred'].value_counts()\n\nfig.add_trace(go.Pie(labels=type_holiday.index, values=type_holiday),\n              row=1, col=1)\nfig.add_trace(go.Pie(labels=transferred.index, values=transferred),\n              row=1, col=2)\n\nfig.update_layout(\ntitle_font_color=\"#fff\",paper_bgcolor=\"#283747\",title_font_size=20,title_x=.5,font_color=\"#bbb\",\n    plot_bgcolor=\"#D6EAF8\")\nfig = go.Figure(fig)\nfig.show()\n\ndel type_holiday\ndel transferred","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:18:15.481823Z","iopub.execute_input":"2021-10-14T12:18:15.482078Z","iopub.status.idle":"2021-10-14T12:18:15.545157Z","shell.execute_reply.started":"2021-10-14T12:18:15.482048Z","shell.execute_reply":"2021-10-14T12:18:15.54413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode transffered \nholidays_events['transferred'] = holidays_events['transferred'].apply(lambda x: 1 if x else 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:15.546668Z","iopub.execute_input":"2021-10-14T12:18:15.546925Z","iopub.status.idle":"2021-10-14T12:18:15.555101Z","shell.execute_reply.started":"2021-10-14T12:18:15.546896Z","shell.execute_reply":"2021-10-14T12:18:15.553834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# stores","metadata":{}},{"cell_type":"code","source":"display(describe(stores))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:18:15.559714Z","iopub.execute_input":"2021-10-14T12:18:15.55999Z","iopub.status.idle":"2021-10-14T12:18:15.585452Z","shell.execute_reply.started":"2021-10-14T12:18:15.55996Z","shell.execute_reply":"2021-10-14T12:18:15.584148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for var in stores['city'].unique():\n    print(var, stores.query('city==@var')['state'].unique())\n\nprint('-'*100)\nfor var in stores['city'].unique():\n    print(var, stores.query('city==@var')['type'].unique())\n    \nprint('-'*100)\nfor var in stores['city'].unique():\n    print(var, stores.query('city==@var')['cluster'].unique())","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-14T12:18:15.586721Z","iopub.execute_input":"2021-10-14T12:18:15.58696Z","iopub.status.idle":"2021-10-14T12:18:15.766376Z","shell.execute_reply.started":"2021-10-14T12:18:15.586931Z","shell.execute_reply":"2021-10-14T12:18:15.765533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### above this, it's enough to use only 'city' instead of 'state'","metadata":{}},{"cell_type":"code","source":"stores = stores.drop('state', axis=1)\ncity = stores['city'].value_counts()\ncluster = stores['cluster'].value_counts()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\nfig = make_subplots(rows=1, cols=2, specs=specs, subplot_titles=['city', 'cluster'])\n\nfig.add_trace(go.Pie(labels=city.index, values=city), row=1, col=1)\nfig.add_trace(go.Pie(labels=cluster.index, values=cluster), row=1, col=2)\n\nfig.update_layout(\ntitle_font_color=\"#fff\",paper_bgcolor=\"#283747\",title_font_size=20,title_x=.5,font_color=\"#bbb\",\n    plot_bgcolor=\"#D6EAF8\")\nfig = go.Figure(fig)\nfig.show()\n\ndel city\ndel cluster","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:18:15.768805Z","iopub.execute_input":"2021-10-14T12:18:15.769496Z","iopub.status.idle":"2021-10-14T12:18:16.127102Z","shell.execute_reply.started":"2021-10-14T12:18:15.769449Z","shell.execute_reply":"2021-10-14T12:18:16.125942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='type', data=stores)","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T12:18:16.12866Z","iopub.execute_input":"2021-10-14T12:18:16.129124Z","iopub.status.idle":"2021-10-14T12:18:16.350262Z","shell.execute_reply.started":"2021-10-14T12:18:16.129085Z","shell.execute_reply":"2021-10-14T12:18:16.349612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# oil","metadata":{}},{"cell_type":"code","source":"display(describe(oil))\nsns.displot(x='dcoilwtico', data=oil)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:16.35149Z","iopub.execute_input":"2021-10-14T12:18:16.352251Z","iopub.status.idle":"2021-10-14T12:18:16.698939Z","shell.execute_reply.started":"2021-10-14T12:18:16.352218Z","shell.execute_reply":"2021-10-14T12:18:16.698059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:18px\">\n<h3>I fill null with 0! <br>\n    we usually fill null with some represent value as one of the approaches. \n    <br><br>\n    but in this case, I think the null means no transaction and unofficial data. <br>\n    Hence filling some values will lead to be misunderstood.\n</h3>\n</div>","metadata":{}},{"cell_type":"code","source":"oil['dcoilwtico'] = oil['dcoilwtico'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:16.700136Z","iopub.execute_input":"2021-10-14T12:18:16.700374Z","iopub.status.idle":"2021-10-14T12:18:16.706143Z","shell.execute_reply.started":"2021-10-14T12:18:16.700347Z","shell.execute_reply":"2021-10-14T12:18:16.705184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# data merge","metadata":{}},{"cell_type":"code","source":"# merge data\nmerge_data = train.merge(oil, on='date', how='left')\nmerge_data = merge_data.merge(holidays_events, on='date', how='left')\nmerge_data = merge_data.merge(stores, on='store_nbr', how='left')\nmerge_data = merge_data.merge(transactions, on=['date', 'store_nbr'], how='left')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:16.707696Z","iopub.execute_input":"2021-10-14T12:18:16.708457Z","iopub.status.idle":"2021-10-14T12:18:19.613918Z","shell.execute_reply.started":"2021-10-14T12:18:16.708409Z","shell.execute_reply":"2021-10-14T12:18:19.613126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy\nmerge_copy = merge_data.copy()\n\n# change dtype and get the date col\nmerge_copy['date'] = pd.to_datetime(merge_copy['date']).dt.date\nmerge_copy['year'] = pd.to_datetime(merge_copy['date']).dt.year\nmerge_copy['month'] = pd.to_datetime(merge_copy['date']).dt.month\nmerge_copy['day'] = pd.to_datetime(merge_copy['date']).dt.day\n\ndescribe(merge_copy)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:19.615156Z","iopub.execute_input":"2021-10-14T12:18:19.616228Z","iopub.status.idle":"2021-10-14T12:18:29.671149Z","shell.execute_reply.started":"2021-10-14T12:18:19.616181Z","shell.execute_reply":"2021-10-14T12:18:29.670267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:10px; text-align:center;\">\n<h4>I fill null with 0 in transaction, too!\n</h4>\n</div>","metadata":{}},{"cell_type":"code","source":"merge_copy['transactions'] = merge_copy['transactions'].fillna(0)\nmerge_copy['dcoilwtico'] = merge_copy['dcoilwtico'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:29.672419Z","iopub.execute_input":"2021-10-14T12:18:29.672786Z","iopub.status.idle":"2021-10-14T12:18:29.723792Z","shell.execute_reply.started":"2021-10-14T12:18:29.672749Z","shell.execute_reply":"2021-10-14T12:18:29.72275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(describe(merge_copy))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T12:18:29.725105Z","iopub.execute_input":"2021-10-14T12:18:29.72542Z","iopub.status.idle":"2021-10-14T12:18:33.362547Z","shell.execute_reply.started":"2021-10-14T12:18:29.72539Z","shell.execute_reply":"2021-10-14T12:18:33.361547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This holiday null are huge so I will recreate holiday col that flag 1: the day is holiday, 0: not holiday\n\n### We needn't care about what holiday is.","metadata":{}},{"cell_type":"code","source":"merge_copy['holiday_flag'] = [1 if not val else 0 for val in merge_copy['type_x'].isnull()]\nmerge_copy = merge_copy.drop(['type_x', 'locale_name', 'transferred'], axis=1)\nmerge_copy = merge_copy.rename(columns={'type_y': 'stores_type'})\ndisplay(describe(merge_copy))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:33.363762Z","iopub.execute_input":"2021-10-14T12:18:33.364003Z","iopub.status.idle":"2021-10-14T12:18:38.803627Z","shell.execute_reply.started":"2021-10-14T12:18:33.363974Z","shell.execute_reply":"2021-10-14T12:18:38.802985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## check moving avg\n### we seek how trend 'sales' moved.","metadata":{}},{"cell_type":"code","source":"df = merge_copy.copy()\ndf = df.sort_values('date')\ndf_g = df[['date', 'sales']].groupby('date').agg(date_sum=('sales', np.mean))\n# month avg \ndf_g['moving_avg'] = df_g.date_sum.rolling(30, min_periods=3).mean()\n\nplt.figure(figsize=(20, 5))\nplt.plot(df_g['moving_avg'])\nplt.show()\n\ndel df","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:38.804575Z","iopub.execute_input":"2021-10-14T12:18:38.80528Z","iopub.status.idle":"2021-10-14T12:18:45.356546Z","shell.execute_reply.started":"2021-10-14T12:18:38.805248Z","shell.execute_reply":"2021-10-14T12:18:45.355578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's increasing roughly as year goes by.","metadata":{}},{"cell_type":"markdown","source":"## Check each term and how distributions are!","metadata":{}},{"cell_type":"code","source":"_, axes = plt.subplots(1, 2, figsize=(15, 8))\ndf = merge_copy.groupby('year').agg(sales_mean=('sales', np.mean), dcoilwtico_mean=('dcoilwtico', np.mean))\nsns.barplot(x=df.index, y='sales_mean', data=df, ax=axes[0])\naxes[0].set_title('Mean sales each year', fontsize=20)\n\n# df = merge_copy.groupby('year').agg(dcoilwtico_mean=('dcoilwtico', np.mean))\naxes[1].set_title('Mean dcoilwtico each year', fontsize=20)\nsns.barplot(x=df.index, y='dcoilwtico_mean', data=df, ax=axes[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:45.358274Z","iopub.execute_input":"2021-10-14T12:18:45.358657Z","iopub.status.idle":"2021-10-14T12:18:45.86175Z","shell.execute_reply.started":"2021-10-14T12:18:45.358616Z","shell.execute_reply":"2021-10-14T12:18:45.860708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = merge_copy.groupby('month').agg(sales_mean=('sales', np.mean))\nplt.figure(figsize=(15, 5))\nsns.barplot(x=df.index, y='sales_mean', data=df)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:45.863144Z","iopub.execute_input":"2021-10-14T12:18:45.864179Z","iopub.status.idle":"2021-10-14T12:18:46.246457Z","shell.execute_reply.started":"2021-10-14T12:18:45.864134Z","shell.execute_reply":"2021-10-14T12:18:46.245622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"December is higher than others.","metadata":{}},{"cell_type":"code","source":"df = merge_copy.groupby(['year', 'month'], as_index=False).agg(sales_mean=('sales', np.mean))\nplt.figure(figsize=(20, 5))\nplt.title('Mean sales each year-month', fontsize=20)\nsns.barplot(x='month', y='sales_mean', data=df, hue='year')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:46.247699Z","iopub.execute_input":"2021-10-14T12:18:46.247935Z","iopub.status.idle":"2021-10-14T12:18:47.147185Z","shell.execute_reply.started":"2021-10-14T12:18:46.247908Z","shell.execute_reply":"2021-10-14T12:18:47.14618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dec is so important for sale but data of 2017 doesn't exist.\n#### So, I think 'month' cols can be removed.","metadata":{}},{"cell_type":"code","source":"df = merge_copy.groupby('day').agg(sales_mean=('sales', np.mean))\nplt.figure(figsize=(15, 5))\nplt.title('Mean sales each day', fontsize=20)\nsns.barplot(x=df.index, y='sales_mean', data=df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:47.148261Z","iopub.execute_input":"2021-10-14T12:18:47.148478Z","iopub.status.idle":"2021-10-14T12:18:47.658427Z","shell.execute_reply.started":"2021-10-14T12:18:47.148453Z","shell.execute_reply":"2021-10-14T12:18:47.65751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sales at the beginning and end of month tends to increase!!","metadata":{}},{"cell_type":"code","source":"df = merge_copy.groupby('cluster').agg(sales_mean=('sales', np.mean))\nplt.figure(figsize=(15, 5))\nplt.title('Mean sales each cluster', fontsize=20)\nsns.barplot(x=df.index, y='sales_mean', data=df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:47.659773Z","iopub.execute_input":"2021-10-14T12:18:47.660044Z","iopub.status.idle":"2021-10-14T12:18:48.041395Z","shell.execute_reply.started":"2021-10-14T12:18:47.660012Z","shell.execute_reply":"2021-10-14T12:18:48.040312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the Correlation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\ncorr = merge_copy.corr()\nsns.heatmap(corr, annot=True)","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T12:18:48.043013Z","iopub.execute_input":"2021-10-14T12:18:48.043523Z","iopub.status.idle":"2021-10-14T12:18:50.328639Z","shell.execute_reply.started":"2021-10-14T12:18:48.043486Z","shell.execute_reply":"2021-10-14T12:18:50.327684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### id- year is strong, sales-onpro is also strong correlation!\n#### so onpromotion may be key to analysis??","metadata":{}},{"cell_type":"code","source":"del df\ndel merge_data","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T12:18:50.32999Z","iopub.execute_input":"2021-10-14T12:18:50.330963Z","iopub.status.idle":"2021-10-14T12:18:50.389702Z","shell.execute_reply.started":"2021-10-14T12:18:50.330912Z","shell.execute_reply":"2021-10-14T12:18:50.38877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis the data!","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:lightblue; padding:15px;\">\n    <h2>Let's move to analysis. This time we try below aprroaches</h2>\n    <ol>\n        <h3><li><span style=\"color:red;\">Simple LinearRegression</span>: <br>we need to think whether simple model works well or not before randomforest, lightgbm or some complicated and high model. <br>If it works, we can get the shortcut and can introduce practically and simply!</li></h3>\n    <h3><li><span style=\"color:red;\">Use Pipeline</span>: <br>Next, we use pipeline including pca to cut down dimensions then we figure out what eigens say about.</li></h3>\n        <h3><li><span style=\"color:red;\">Use RFE and get important cols</span>: <br>RFE can tell us what cols are important.</li></h3>\n        <h3><li><span style=\"color:red;\">RandomForest</span>: <br>Use RandomForest and this feature_importance tell us how important cols are like RFE!!</li></h3>\n        <h3><li><span style=\"color:red;\">LightGBM</span>: <br>lightBGM can analyze quickly and precisely! It can be really good model but I feel this model doesn't talk to me, haha</li></h3>\n        <h3><li><span style=\"color:red;\">Stacking</span>: <br>lightBGM can analyze quickly and precisely! It can be really good model but I feel this model doesn't talk to me, haha</li></h3>\n    </ol>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Prepare the data","metadata":{}},{"cell_type":"code","source":"data = merge_copy.copy().drop(['id', 'date'], axis=1)\ndata = pd.get_dummies(data, drop_first=True)\nX = data.drop('sales', axis=1)\ny = data['sales']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=12)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:18:50.391239Z","iopub.execute_input":"2021-10-14T12:18:50.391953Z","iopub.status.idle":"2021-10-14T12:19:02.705305Z","shell.execute_reply.started":"2021-10-14T12:18:50.391899Z","shell.execute_reply":"2021-10-14T12:19:02.704212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgray; padding:5px;\">\n<h2>1st Simple LinearRegression</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nprint(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:19:02.706698Z","iopub.execute_input":"2021-10-14T12:19:02.706966Z","iopub.status.idle":"2021-10-14T12:19:13.771903Z","shell.execute_reply.started":"2021-10-14T12:19:02.706939Z","shell.execute_reply":"2021-10-14T12:19:13.770924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgray; padding:5px;\">\n<h2>2nd Use Pipeline</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"n = 3\npipe = Pipeline([('pca', PCA(n_components=n)), ('lr', LinearRegression())])\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint(n, np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred)))\n\nn = 10\npipe = Pipeline([('pca', PCA(n_components=n)), ('lr', LinearRegression())])\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint(n, np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:19:13.773698Z","iopub.execute_input":"2021-10-14T12:19:13.77428Z","iopub.status.idle":"2021-10-14T12:19:47.112867Z","shell.execute_reply.started":"2021-10-14T12:19:13.774234Z","shell.execute_reply":"2021-10-14T12:19:47.111703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### PCA seemed to  over-cut down. so this case it doesn't help.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:lightgray; padding:5px;\">\n<h2>3rd Use RFE and get important cols</h2>\n</div>\n\n### We figure out top 10 important columns!\n(I choose 10, but it's fine to use no matter how many number you want)","metadata":{}},{"cell_type":"code","source":"# features=10\nrfe = RFE(estimator=LinearRegression(), n_features_to_select=10)\nrfe.fit(X_train, y_train)\ny_pred = rfe.predict(X_test)\n\nprint(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred)))\nprint('\\n----top10 cols----\\n')\nfor boolean, col in zip(rfe.support_, X.columns):\n    if boolean:\n        print(col)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:19:47.114611Z","iopub.execute_input":"2021-10-14T12:19:47.115344Z","iopub.status.idle":"2021-10-14T12:25:03.56318Z","shell.execute_reply.started":"2021-10-14T12:19:47.115282Z","shell.execute_reply":"2021-10-14T12:25:03.562235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:10px; text-align:center;\">\n<h3>As we estimate, onpromotion looks important!\n</h3>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:lightgray; padding:5px;\">\n<h2>4th RandomForest</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=30, random_state=123, max_leaf_nodes=50, max_depth=30)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nprint(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:25:03.564767Z","iopub.execute_input":"2021-10-14T12:25:03.565316Z","iopub.status.idle":"2021-10-14T12:36:32.861247Z","shell.execute_reply.started":"2021-10-14T12:25:03.565272Z","shell.execute_reply":"2021-10-14T12:36:32.859917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = np.array(rf.feature_importances_)\nforest_importances = pd.Series(importances, index=X.columns).sort_values(ascending=False)[:16]\nprint(forest_importances[:16])\n# std = np.std([\n#     tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 10))\n# forest_importances.plot.bar(yerr=std, ax=ax)\nforest_importances.plot.bar(ax=ax)\nax.set_title(\"Feature importances using MDI\")\nax.set_ylabel(\"Mean decrease in impurity\")\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:36:32.863375Z","iopub.execute_input":"2021-10-14T12:36:32.863742Z","iopub.status.idle":"2021-10-14T12:36:33.37877Z","shell.execute_reply.started":"2021-10-14T12:36:32.863695Z","shell.execute_reply":"2021-10-14T12:36:33.376167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:10px;\">\n    <h2>We get to know what the features are helpful to analyze better,<br> according to RFE and RandomForest!!!</h2>\n    <h3>We cut down the uselesss col then we try linearReg</h3>\n</div>","metadata":{}},{"cell_type":"code","source":"important_cols = ['store_nbr', 'onpromotion', 'cluster', 'transactions', 'year', 'family_BEVERAGES', 'family_CLEANING', 'family_DAIRY', 'family_GROCERY I', 'family_PRODUCE']\nX_importance = X[important_cols]\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X_importance, y, test_size=0.2, random_state=123)\n\nmodel_importance = LinearRegression()\nmodel_importance.fit(X_train2, y_train2)\ny_pred = model_importance.predict(X_test2)\n\nprint(np.sqrt(mean_squared_error(y_true=y_test2, y_pred=y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:36:33.382914Z","iopub.execute_input":"2021-10-14T12:36:33.383459Z","iopub.status.idle":"2021-10-14T12:36:35.037069Z","shell.execute_reply.started":"2021-10-14T12:36:33.383421Z","shell.execute_reply":"2021-10-14T12:36:35.035988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:10px; text-align:center;\">\n<h2>Comparing to 1st try, the result is close to 1st result. \n    <br>This means that it's enough to use only 'important_cols'!!\n</h2>\n</div> ","metadata":{}},{"cell_type":"markdown","source":"## 5th lightGBM","metadata":{}},{"cell_type":"code","source":"# Preparing dataset for LightGBM\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_test = lgb.Dataset(X_test, y_test)\n\nparams = {'metric' : 'rmse', 'seed': 123, 'verbosity':-1}\n\n# train data\ngbm = lgb.train(params, lgb_train, num_boost_round=500, valid_sets=[lgb_test])","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-14T12:36:35.03889Z","iopub.execute_input":"2021-10-14T12:36:35.04004Z","iopub.status.idle":"2021-10-14T12:37:15.90737Z","shell.execute_reply.started":"2021-10-14T12:36:35.039982Z","shell.execute_reply":"2021-10-14T12:37:15.906538Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\nprint(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:37:15.914887Z","iopub.execute_input":"2021-10-14T12:37:15.915781Z","iopub.status.idle":"2021-10-14T12:37:21.992722Z","shell.execute_reply.started":"2021-10-14T12:37:15.91573Z","shell.execute_reply":"2021-10-14T12:37:21.991755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:8px; text-align:center;\">\n    <h4>Exciting result!</h4>\n    <h3>this model is pretty good for now. <br>However, I want more acc so try to use 'optuna' to tune hyperparams!</h3>\n</div> ","metadata":{}},{"cell_type":"markdown","source":"## Optuna","metadata":{}},{"cell_type":"code","source":"# prepare validation data\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=12)\n\ndef objective(trial):\n    param = {\n        'metric' : 'rmse', \n        'verbosity': -1, \n        'boosting_type': trial.suggest_categorical('hoge', ['gbdt', 'dart']),\n        'num_leaves': trial.suggest_int('num_leaves', 10, 1000),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-7, 1.0)\n    }\n    \n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n\n    gbm = lgb.train(param, lgb_train, valid_sets=lgb_val, verbose_eval=False, early_stopping_rounds=30)\n    \n    y_pred = gbm.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))\n    \n    return rmse\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=100)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-14T12:37:21.996668Z","iopub.execute_input":"2021-10-14T12:37:21.998542Z","iopub.status.idle":"2021-10-14T13:42:43.607106Z","shell.execute_reply.started":"2021-10-14T12:37:21.998497Z","shell.execute_reply":"2021-10-14T13:42:43.606297Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(study.best_value)\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:42:43.6087Z","iopub.execute_input":"2021-10-14T13:42:43.60919Z","iopub.status.idle":"2021-10-14T13:42:43.614807Z","shell.execute_reply.started":"2021-10-14T13:42:43.609153Z","shell.execute_reply":"2021-10-14T13:42:43.614054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the feature importance","metadata":{}},{"cell_type":"code","source":"_ = merge_copy.copy().drop(['id', 'date'], axis=1)\n_ = pd.get_dummies(_, drop_first=True)\n_X = _.drop('sales', axis=1)\n_y = _['sales']\n\nscaler = StandardScaler()\n_X_scaled = scaler.fit_transform(_X)\n\n_X_train, _X_test, _y_train, _y_test = train_test_split(_X_scaled, _y, test_size=0.2, random_state=12)\n_X_train2, _X_val2, _y_train2, _y_val2 = train_test_split(_X_train, _y_train, test_size=0.2, random_state=12)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:42:43.616437Z","iopub.execute_input":"2021-10-14T13:42:43.616795Z","iopub.status.idle":"2021-10-14T13:43:00.722126Z","shell.execute_reply.started":"2021-10-14T13:42:43.616753Z","shell.execute_reply":"2021-10-14T13:43:00.72121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = {\n    'metric' : 'rmse', \n    'verbosity': -1, \n    'boosting_type': 'gbdt',\n    'num_leaves': study.best_params['num_leaves'],\n    'learning_rate': study.best_params['learning_rate']\n}\n\nlgb_train = lgb.Dataset(_X_train2, _y_train2)\nlgb_val = lgb.Dataset(_X_val2, _y_val2, reference=lgb_train)\n\ngbm = lgb.train(param, lgb_train, valid_sets=lgb_val, verbose_eval=False, early_stopping_rounds=30)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:43:00.723999Z","iopub.execute_input":"2021-10-14T13:43:00.724338Z","iopub.status.idle":"2021-10-14T13:43:24.183289Z","shell.execute_reply.started":"2021-10-14T13:43:00.724296Z","shell.execute_reply":"2021-10-14T13:43:24.182536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importance = pd.DataFrame(gbm.feature_importance(), index=_X.columns, columns=['importance'])\n\n# plt.figure()\nimportance.sort_values(by='importance', ascending=False).plot.bar(figsize=(20, 8))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T13:43:24.185017Z","iopub.execute_input":"2021-10-14T13:43:24.185589Z","iopub.status.idle":"2021-10-14T13:43:25.796133Z","shell.execute_reply.started":"2021-10-14T13:43:24.185528Z","shell.execute_reply":"2021-10-14T13:43:25.794796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del _X_scaled\ndel _\ndel _X\ndel _y","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## below code I'm fixing~~","metadata":{}},{"cell_type":"markdown","source":"## Last, stacking model\n### before this, we remake the data which has only importance cols","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"data_important_cols = merge_copy.copy().drop(['id', 'date', 'dcoilwtico', 'holiday_flag', 'month', 'day', 'city', 'stores_type'], axis=1)\ndata_important_cols['family_BEVERAGES'] = data_important_cols['family'].apply(lambda x: 1 if x =='BEVERAGES' else 0)\ndata_important_cols['family_CLEANING'] = data_important_cols['family'].apply(lambda x: 1 if x =='CLEANING' else 0)\ndata_important_cols['family_DAIRY'] = data_important_cols['family'].apply(lambda x: 1 if x =='DAIRY' else 0)\ndata_important_cols['family_GROCERY'] = data_important_cols['family'].apply(lambda x: 1 if x =='GROCERY I' else 0)\ndata_important_cols['family_PRODUCE'] = data_important_cols['family'].apply(lambda x: 1 if x =='PRODUCE' else 0)\ndata_important_cols = data_important_cols.drop(['family'], axis=1)\n\ndescribe(data_important_cols)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T13:43:25.797649Z","iopub.execute_input":"2021-10-14T13:43:25.7979Z","iopub.status.idle":"2021-10-14T13:43:35.58316Z","shell.execute_reply.started":"2021-10-14T13:43:25.79787Z","shell.execute_reply":"2021-10-14T13:43:35.582228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_important_cols.drop('sales', axis=1)\ny = data_important_cols['sales']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=123)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T13:43:35.584257Z","iopub.execute_input":"2021-10-14T13:43:35.58447Z","iopub.status.idle":"2021-10-14T13:43:37.359705Z","shell.execute_reply.started":"2021-10-14T13:43:35.584445Z","shell.execute_reply":"2021-10-14T13:43:37.359003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # prepare the metrics list\n# pipe_pred = []\n# rf_pred = []\n# gbm_pred = []\n\n# # prepare the metrics list\n# pipe_true = []\n# rf_true = []\n# gbm_true = []\n\n# # pipeline\n# model1 = Pipeline([('pca', PCA(n_components=10)), ('lr', LinearRegression())])\n# # random forest\n# model2 = RandomForestRegressor(n_estimators=50, random_state=123, max_leaf_nodes=100, max_depth=30)\n# # lightgbm\n# params = {'metric' : 'rmse', 'seed': 123, 'verbosity':200}\n# model3 = lgb\n\n# kfold = KFold(n_splits=5).split(X_train, y_train)\n\n# for (train, val) in kfold:\n#     X_train_cv = X_train[train]\n#     y_train_cv = y_train.iloc[train]\n#     X_val_cv = X_train[val]\n#     y_val_cv = y_train.iloc[val]\n    \n#     lgb_train = lgb.Dataset(X_train_cv, y_train_cv)\n#     lgb_val = lgb.Dataset(X_val_cv, y_val_cv)\n    \n#     # train\n#     model1.fit(X_train_cv, y_train_cv)\n#     model2.fit(X_train_cv, y_train_cv)\n#     model_3 = model3.train(params, lgb_train, num_boost_round=200)\n    \n#     y_cv_pred1 = model1.predict(X_val_cv)\n#     y_cv_pred2 = model2.predict(X_val_cv)\n#     y_cv_pred3 = model_3.predict(X_val_cv, num_iteration=gbm.best_iteration)\n    \n#     pipe_pred.append(y_cv_pred1)\n#     rf_pred.append(y_cv_pred2)\n#     gbm_pred.append(y_cv_pred3)\n    \n#     # append y data\n#     pipe_true.append(y_val_cv.values)\n#     rf_true.append(y_val_cv.values)\n#     gbm_true.append(y_val_cv.values)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T13:43:37.361209Z","iopub.execute_input":"2021-10-14T13:43:37.361942Z","iopub.status.idle":"2021-10-14T13:43:37.367378Z","shell.execute_reply.started":"2021-10-14T13:43:37.361899Z","shell.execute_reply":"2021-10-14T13:43:37.36655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pipe_pred = np.concatenate(pipe_pred)\n# rf_pred = np.concatenate(rf_pred)\n# gbm_pred = np.concatenate(gbm_pred)\n# pipe_true = np.concatenate(pipe_true)\n\n# df = pd.DataFrame({'true': pipe_true, 'pipe': pipe_pred, 'rf': rf_pred, 'lgb': gbm_pred})","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-14T13:43:37.36873Z","iopub.execute_input":"2021-10-14T13:43:37.369074Z","iopub.status.idle":"2021-10-14T13:43:37.38473Z","shell.execute_reply.started":"2021-10-14T13:43:37.369044Z","shell.execute_reply":"2021-10-14T13:43:37.383683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_stack = df.drop('true', axis=1)\n# y_stack = df['true']\n\n# X_stack_train, X_stack_test, y_stack_train, y_stack_test = train_test_split(X_stack, y_stack, test_size=0.2, random_state=123)\n\n# meta_model = LinearRegression()\n# meta_model.fit(X_stack_train, y_stack_train)\n\n# meta_val_pred = meta_model.predict(X_stack_test)\n# print (\"stacking model: {:.4f}\".format(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))))","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T13:43:37.386329Z","iopub.execute_input":"2021-10-14T13:43:37.386924Z","iopub.status.idle":"2021-10-14T13:43:37.396754Z","shell.execute_reply.started":"2021-10-14T13:43:37.386881Z","shell.execute_reply":"2021-10-14T13:43:37.395533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I think this model is somethins wrong, I'll fix this model so I use lightgbm this submittion for now","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"## ~~","metadata":{}},{"cell_type":"markdown","source":"# Adjust test data for lightgbm and submission","metadata":{}},{"cell_type":"code","source":"col = importance.query('importance>100').index\n\ntest_copy = test.copy()\n# merge data\ntest_copy = test_copy.merge(oil, on='date', how='left')\ntest_copy = test_copy.merge(holidays_events, on='date', how='left')\ntest_copy = test_copy.merge(stores, on='store_nbr', how='left')\ntest_copy = test_copy.merge(transactions, on=['date', 'store_nbr'], how='left')\n# change dtype and get the date col\ntest_copy['date'] = pd.to_datetime(test_copy['date']).dt.date\ntest_copy['year'] = pd.to_datetime(test_copy['date']).dt.year\ntest_copy['month'] = pd.to_datetime(test_copy['date']).dt.month\ntest_copy['day'] = pd.to_datetime(test_copy['date']).dt.day\n# fillna with 0\ntest_copy['transactions'] = test_copy['transactions'].fillna(0)\ntest_copy['dcoilwtico'] = test_copy['dcoilwtico'].fillna(0)\n# create new col as I did above\ntest_copy['holiday_flag'] = [1 if not val else 0 for val in test_copy['type_x'].isnull()]\n# test_copy = merge_copy.drop(['type_x', 'locale_name', 'transferred'], axis=1)\ntest_copy = test_copy.rename(columns={'type_y': 'stores_type'})\n\ntest_copy = test_copy.drop(['id', 'date'], axis=1)\ntest_copy = pd.get_dummies(test_copy, drop_first=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-14T14:05:26.599149Z","iopub.execute_input":"2021-10-14T14:05:26.599749Z","iopub.status.idle":"2021-10-14T14:05:26.812015Z","shell.execute_reply.started":"2021-10-14T14:05:26.59971Z","shell.execute_reply":"2021-10-14T14:05:26.811307Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"describe(test_copy)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-14T14:02:36.278632Z","iopub.status.idle":"2021-10-14T14:02:36.278953Z","shell.execute_reply.started":"2021-10-14T14:02:36.278783Z","shell.execute_reply":"2021-10-14T14:02:36.278798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = importance.query('importance>0').index\nX2 = data[col]\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X2)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=12)\n\n# best param!\nparams = {\n    'metric' : 'rmse', \n    'verbosity': -1, \n    'seed': 123,\n    'boosting_type': 'gbdt',\n    'num_leaves': study.best_params['num_leaves'], \n    'learning_rate': study.best_params['learning_rate']\n}\n\n# Preparing dataset for LightGBM\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_test = lgb.Dataset(X_test, y_test)\n# train data\ngbm = lgb.train(params, lgb_train, num_boost_round=500, valid_sets=[lgb_test], verbose_eval=False)\n\n\n# choose importance cols\ntest_copy = test_copy[col]\nscaler = StandardScaler()\ntest_scaled = scaler.fit_transform(test_copy)\nprediction= gbm.predict(test_scaled, num_iteration=gbm.best_iteration)\n\ndel X2\ndel lgb_train\ndel lgb_test","metadata":{"execution":{"iopub.status.busy":"2021-10-14T14:05:30.560624Z","iopub.execute_input":"2021-10-14T14:05:30.561515Z","iopub.status.idle":"2021-10-14T14:06:39.770826Z","shell.execute_reply.started":"2021-10-14T14:05:30.561474Z","shell.execute_reply":"2021-10-14T14:06:39.769965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv')\n\nsubmission['sales'] = [pred if pred >= 0 else 0 for pred in prediction]\nsubmission.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-10-14T14:06:39.774201Z","iopub.execute_input":"2021-10-14T14:06:39.77481Z","iopub.status.idle":"2021-10-14T14:06:39.982216Z","shell.execute_reply.started":"2021-10-14T14:06:39.774765Z","shell.execute_reply":"2021-10-14T14:06:39.981283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:lightgreen; padding:10px; text-align:center;\">\n    <h1>Conclusion</h1>\n    <h2>I tried EDA, Viz, and some methods.\n        If you want to try more, Let's try!!\n    </h2>\n</h2>\n<h3 style=\"color:red\">Thank you for visiting my notebook. Feel free to upvotes or comment if you like mine!!</h3>\n</div> ","metadata":{}}]}