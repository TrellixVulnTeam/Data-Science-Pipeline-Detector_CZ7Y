{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install -q efficientnet\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nimport matplotlib.pyplot as plt\nimport glob\nfrom kaggle_datasets import KaggleDatasets\nkeras = tf.keras\nlayers = keras.layers\nEPOCH = 50\nDATASET_SIZE = 16465\nTRAIN_SIZE = 12753\nVAL_SIZE = 3712\nTEST_SIZE = 7382\nAUTO = tf.data.experimental.AUTOTUNE\nignore_order = tf.data.Options()\nignore_order.experimental_deterministic = False\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU',tpu.master())\nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nprint(f'tensorflow version : {tf.__version__}')\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_filenames = tf.io.gfile.glob(r'gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec/tfrecords-jpeg-512x512/*a*/*.tfrec')\ntrain_filenames = tf.io.gfile.glob(r'gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec/tfrecords-jpeg-512x512/train/*.tfrec')\nval_filenames = tf.io.gfile.glob(r'gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec/tfrecords-jpeg-512x512/val/*.tfrec')\ntest_filenames = tf.io.gfile.glob(r'gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec/tfrecords-jpeg-512x512/test/*.tfrec')\n#count_dataset = np.sum([int(path.split('-')[-1].split('.')[0]) for path in dataset_filenames])\n#count_train = np.sum([int(path.split('-')[-1].split('.')[0]) for path in train_filenames])\n#count_val = np.sum([int(path.split('-')[-1].split('.')[0]) for path in val_filenames])\n#print(count_dataset)\n#print(count_train)\n#print(count_val)\ndataset = tf.data.TFRecordDataset(dataset_filenames)\ndataset = dataset.with_options(ignore_order)\ndataset_train = tf.data.TFRecordDataset(train_filenames)\ndataset_train = dataset_train.with_options(ignore_order)\ndataset_val = tf.data.TFRecordDataset(val_filenames)\ndataset_val = dataset_val.with_options(ignore_order)\ndataset_test = tf.data.TFRecordDataset(test_filenames)\ndataset_test = dataset_test.with_options(ignore_order)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_description = {\n    'class':tf.io.FixedLenFeature([],tf.int64),\n    'image':tf.io.FixedLenFeature([],tf.string)\n}\ntest_feature_description = {\n    'id':tf.io.FixedLenFeature([],tf.string),\n    'image':tf.io.FixedLenFeature([],tf.string)\n}\ndef dataset_decode(data):\n    decode_data = tf.io.parse_single_example(data,feature_description)\n    label = decode_data['class']\n    image = tf.image.decode_jpeg(decode_data['image'],channels=3)\n    image = tf.reshape(image,[512,512,3])\n    image = tf.image.random_flip_left_right(image)\n    image = tf.cast(image,tf.float32)\n    image = (image - 127.5) / 127.5\n    return image,label\ndef test_dataset_decode(data):\n    decode_data = tf.io.parse_single_example(data,test_feature_description)\n    ID = decode_data['id']\n    image = tf.image.decode_jpeg(decode_data['image'],channels=3)\n    image = tf.reshape(image,[512,512,3])\n    image = tf.cast(image,tf.float32)\n    image = (image - 127.5) / 127.5\n    return ID,image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.map(dataset_decode)\ndataset_train = dataset_train.map(dataset_decode)\ndataset_val = dataset_val.map(dataset_decode)\ndataset_test = dataset_test.map(test_dataset_decode)\ndataset = dataset.shuffle(DATASET_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTO)\ndataset_train = dataset_train.shuffle(DATASET_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTO)\ndataset_val = dataset_val.batch(BATCH_SIZE).prefetch(AUTO)\ndataset_test = dataset_test.batch(BATCH_SIZE).prefetch(AUTO)\nprint(dataset)\nprint(dataset_train)\nprint(dataset_val)\nprint(dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_START = 1e-5\nLR_MAX = 1e-3\nLR_MIN = 1e-6\nLR_RAMPUP_EPOCH = 10\nLR_SUSTAIN_EPOCH = 5\nLR_EXP_DECAY = 0.75\ndef lr_schedule(epoch):\n    if epoch < LR_RAMPUP_EPOCH:\n        lr = LR_START + (LR_MAX - LR_START) / LR_RAMPUP_EPOCH * epoch\n    elif epoch < LR_RAMPUP_EPOCH + LR_SUSTAIN_EPOCH:\n        lr = LR_MAX\n    else:\n        lr = LR_MIN + (LR_MAX - LR_MIN) * LR_EXP_DECAY ** (epoch - LR_RAMPUP_EPOCH - LR_SUSTAIN_EPOCH)\n    return lr\nlr_callback = keras.callbacks.LearningRateScheduler(lr_schedule,verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = keras.optimizers.Adam()\nloss = keras.losses.SparseCategoricalCrossentropy()\nmetrics = keras.metrics.SparseCategoricalAccuracy()\n\n#lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3,min_lr=1e-6)\nwith strategy.scope():\n    #enet = efn.EfficientNetB7(input_shape=(512,512,3),weights='imagenet',include_top=False)\n    #base_network = keras.applications.InceptionResNetV2(include_top=False,input_shape=[512,512,3])\n    base_network = keras.applications.DenseNet201(include_top=False,input_shape=[512,512,3])\n    network = keras.Sequential()\n    network.add(base_network)\n    network.add(layers.MaxPooling2D())\n    network.add(layers.Conv2D(2560,3,padding='same'))\n    network.add(layers.BatchNormalization())\n    network.add(layers.ReLU())\n    network.add(layers.GlobalAveragePooling2D())\n    network.add(layers.Dense(1024))\n    network.add(layers.BatchNormalization())\n    network.add(layers.LeakyReLU())\n    network.add(layers.Dense(512))\n    network.add(layers.BatchNormalization())\n    network.add(layers.LeakyReLU())\n    network.add(layers.Dense(104,activation='softmax'))\n    network.compile(optimizer=optimizer,loss=loss,metrics=[metrics])\nnetwork.summary()\nnetwork.fit(dataset,\n            epochs=EPOCH,\n            steps_per_epoch=DATASET_SIZE//BATCH_SIZE,\n            callbacks=[lr_callback])\nnetwork.save(r'./Xception.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_csv = []\nfor ID,image in dataset_test:\n    prediction = network.predict(image)\n    ID = [item.numpy().decode('utf-8') for item in ID]\n    label = tf.argmax(prediction,axis=1).numpy()\n    for i in range(len(ID)):\n        predict_csv.append([ID[i],label[i]])\n    print('*',end='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_name = ['id','label']\ncsv_data = pd.DataFrame(columns=csv_name,data=predict_csv)\ncsv_data.to_csv(r'submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('DONE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}