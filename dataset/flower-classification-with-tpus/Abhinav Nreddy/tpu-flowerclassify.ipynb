{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install git+https://github.com/qubvel/efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math, re, os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom efficientnet.tfkeras import EfficientNetB7 as EB7Net\nimport numpy as np\nimport pandas as pd \nAUTO = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TPU Connection","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try: \n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n  print('Running on TPU ', tpu.master())\nexcept ValueError:\n  tpu = None\n\nif tpu:\n  tf.config.experimental_connect_to_cluster(tpu)\n  tf.tpu.experimental.initialize_tpu_system(tpu)\n  strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n  strategy = tf.distribute.get_strategy()\n\nprint(\"Replicas: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initializations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [512,512]\nGCS_PATH = \"gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec\"\nLABELED_TFREC_FORMAT = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"class\": tf.io.FixedLenFeature([], tf.int64),\n}\nUNLABELED_TFREC_FORMAT = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"id\": tf.io.FixedLenFeature([], tf.string),\n}\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nEPOCHS = 20\nOPTIMIZER = tf.keras.optimizers.Adam(\n    learning_rate=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,\n    name='Adam'\n)\nLOSS = 'sparse_categorical_crossentropy'\nMETRICS = ['sparse_categorical_accuracy']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Funcitons","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_filenames ( dataFor ):\n  dataPath = GCS_PATH + '/tfrecords-jpeg-'+str(IMAGE_SIZE[0])+'x'+str(IMAGE_SIZE[1])\n  return tf.io.gfile.glob(dataPath+'/'+dataFor+'/*.tfrec')\n\nTRAIN_FILENAMES = get_filenames('train')\nVAL_FILENAMES = get_filenames('val')\nTEST_FILENAMES = get_filenames('test')\n\ndef decode_image(img_data):\n  image = tf.image.decode_jpeg(img_data, channels=3)\n  image = tf.cast(image, tf.float32) / 255.0\n  image = tf.reshape(image, [*IMAGE_SIZE, 3])\n  return tf.image.random_flip_left_right(image)\n\ndef read_labeled_tfrecord( example ):\n  example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n  image = decode_image(example['image'])\n  label = tf.cast(example['class'], tf.int32)\n  return image, label\n\ndef read_unlabeled_tfrecord( example ):\n  example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n  image = decode_image(example['image'])\n  return image, example['id']\n\ndef get_data(filenames, labeled=True,ordered=False):\n  options = tf.data.Options()\n  if not ordered:\n    options.experimental_deterministic = False\n  data = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO).with_options(options)\n  return data.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, \n                    num_parallel_calls=AUTO)\n\n\ndef get_datasets ( ):\n  train = get_data(TRAIN_FILENAMES)\n  train = train.repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO)\n  test = get_data(TEST_FILENAMES, False,True)\n  test = test.batch(BATCH_SIZE).prefetch(AUTO)\n  val = get_data(VAL_FILENAMES)\n  val = val.batch(BATCH_SIZE).cache().prefetch(AUTO)\n  return train, val, test\n\ndef count_images(filenames):\n  n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n  return np.sum(n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr(epoch):\n    init_lr = 0.001\n    drop = 0.5\n    epoch_interval = 4\n    return init_lr * math.pow(drop, math.floor((1+epoch)/epoch_interval))\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lr, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Model and Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n  efficientNetModel = EB7Net(weights=\"imagenet\", include_top=False, input_shape=[*IMAGE_SIZE, 3])\n  efficientNetModel.trainable = True\n  model = tf.keras.Sequential([\n                               efficientNetModel,\n                               tf.keras.layers.GlobalAveragePooling2D(),\n                               tf.keras.layers.Dense(104, activation='softmax')\n  ])\n\nmodel.compile(\n    optimizer = OPTIMIZER,\n    loss = LOSS,\n    metrics = METRICS\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, val_data, test_data = get_datasets()\nSTEPS = count_images(TRAIN_FILENAMES) // BATCH_SIZE\nh = model.fit(train_data, steps_per_epoch=STEPS, epochs=EPOCHS, validation_data=val_data, callbacks=[lr_schedule])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(0)\nplt.plot(h.history['sparse_categorical_accuracy'], label=\"Train Accuracy\")\nplt.plot(h.history['val_sparse_categorical_accuracy'], label=\"Val Accuracy\")\nplt.title(\"Accuracy\")\nplt.legend()\nplt.figure(1)\nplt.plot(h.history['loss'], label=\"Train Loss\")\nplt.plot(h.history['val_loss'], label=\"Val Loss\")\nplt.title(\"Loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = test_data.map(lambda image, idnum: image)\nprob = model.predict(test_images)\npred = np.argmax(prob, axis=-1)\ntest_ids_ds = test_data.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(count_images(TEST_FILENAMES)))).numpy().astype('U')\ntest_pred = pd.DataFrame(np.column_stack((test_ids,pred)),columns=['id','label'])\ntest_pred.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}