{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall -y Keras-Applications\n!pip install git+https://github.com/keras-team/keras-applications.git","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport kaggle_datasets as kd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras_applications as kapps\n\nkapps._KERAS_BACKEND = tf.keras.backend\nkapps._KERAS_LAYERS = tf.keras.layers\nkapps._KERAS_MODELS = tf.keras.models\nkapps._KERAS_UTILS = tf.keras.utils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 512\nGCS_PATH = kd.KaggleDatasets().get_gcs_path()\nDS_PATH = '{gcs}/tfrecords-jpeg-{size}x{size}'.format(gcs=GCS_PATH, \n                                                      size=IMAGE_SIZE)\n\nTRAIN_PATH, VAL_PATH, TEST_PATH = ['{tfrecs}/{split}'.format(tfrecs=DS_PATH, \n                                                            split=split) \n                                    for split in ('train', 'val', 'test')]\nNUM_CLASSES = 104\nBATCH_SIZE = 128\n\nNUM_TRAIN_IMAGES = 16 * 798\nNUM_VAL_IMAGES = 16 * 232","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\n@tf.function\ndef read_tfrec(tfrec):\n        feature = {\n            'image': tf.io.FixedLenFeature([], tf.string),\n            'class': tf.io.FixedLenFeature([], tf.int64)\n        }\n        example = tf.io.parse_single_example(tfrec, feature)\n        return example['image'], example['class']\n    \n@tf.function\ndef get_image_and_class(image, classl):\n    classl = tf.cast(classl, tf.float32)\n\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize_with_pad(image, IMAGE_SIZE, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32)\n    image = image / 255.\n    \n    return image, classl\n    \ndef get_dataset(ds_path):\n    cycle_length = 32\n    shuffle_buffer = 1024\n    \n    ds = tf.data.Dataset.list_files(ds_path + '/*.tfrec')\n    ds = ds.interleave(tf.data.TFRecordDataset, \n                       cycle_length=cycle_length, \n                       num_parallel_calls=AUTOTUNE)\n    ds = ds.map(read_tfrec, \n                num_parallel_calls=AUTOTUNE)\n    ds = ds.map(get_image_and_class,\n               num_parallel_calls=AUTOTUNE)\n    ds = ds.shuffle(shuffle_buffer)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE, \n                  drop_remainder=True)\n    ds = ds.cache()\n    ds = ds.prefetch(AUTOTUNE)\n    return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpu_cluster = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu_cluster)\ntf.tpu.experimental.initialize_tpu_system(tpu_cluster)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu_cluster)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 20\n\nLR_START = LR_MIN = 1e-5\nLR_MAX = 5e-5 * strategy.num_replicas_in_sync\n\nLR_WARMUP_EPOCHS = 5\nLR_EXP_DECAY = 0.8\n\ndef get_lr(epoch):\n    if epoch < LR_WARMUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_WARMUP_EPOCHS * epoch + LR_START\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY ** (epoch - LR_WARMUP_EPOCHS) + LR_MIN\n    return lr\n\ncbs = [tf.keras.callbacks.LearningRateScheduler(get_lr, verbose=True)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    effnet = kapps.efficientnet.EfficientNetB7(include_top=False, \n                                               weights='imagenet', \n                                               pooling='avg')\n    effnet.trainable = True\n    \n    model = tf.keras.models.Sequential([\n        effnet,\n        tf.keras.layers.Dense(NUM_CLASSES, \n                              name='preds', \n                              activation='softmax')\n    ], name='finetune_effnet_b7')\n    model.summary()\n    \n    model.compile(loss='sparse_categorical_crossentropy', \n                  optimizer='adam', \n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = get_dataset(TRAIN_PATH)\nval_ds = get_dataset(VAL_PATH)\n\nhistory = model.fit(train_ds, \n                    steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n                    validation_data=val_ds, \n                    validation_steps=NUM_VAL_IMAGES // BATCH_SIZE,\n                    epochs=EPOCHS, \n                    callbacks=cbs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}