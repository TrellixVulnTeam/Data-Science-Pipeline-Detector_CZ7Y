{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transfer Learning on TPU For Flower Classification","metadata":{}},{"cell_type":"markdown","source":"This notebook demonstrates how to use TPUs with TensorFlow to train a model for classifying flower images.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from __future__ import annotations\n\nimport functools\nimport math\nimport os\nimport warnings\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '4'\n\nfrom kaggle_datasets import KaggleDatasets\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport optuna\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, optimizers, applications, callbacks, Sequential, Input\n\nwarnings.filterwarnings(\"ignore\")\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:20.410686Z","iopub.execute_input":"2022-03-03T14:38:20.411726Z","iopub.status.idle":"2022-03-03T14:38:20.419387Z","shell.execute_reply.started":"2022-03-03T14:38:20.411668Z","shell.execute_reply":"2022-03-03T14:38:20.418586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detect TPU","metadata":{}},{"cell_type":"markdown","source":"Code borrowed from [Getting started with 100+ flowers on TPU](https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu) by [Martin GÃ¶rner](https://www.kaggle.com/mgornergoogle).","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:  # detect GPUs\n    strategy = tf.distribute.MirroredStrategy()\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\nstrategy","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:20.420948Z","iopub.execute_input":"2022-03-03T14:38:20.421362Z","iopub.status.idle":"2022-03-03T14:38:25.813529Z","shell.execute_reply.started":"2022-03-03T14:38:20.421318Z","shell.execute_reply":"2022-03-03T14:38:25.812445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Moving Data To Google Cloud Storage (GCS)","metadata":{}},{"cell_type":"markdown","source":"TPUs require data to be present on GCS. The below utility copies the data to a GCS bucket co-located with the TPU.","metadata":{}},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"flower-classification-with-tpus\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:25.815047Z","iopub.execute_input":"2022-03-03T14:38:25.815546Z","iopub.status.idle":"2022-03-03T14:38:26.346338Z","shell.execute_reply.started":"2022-03-03T14:38:25.81549Z","shell.execute_reply":"2022-03-03T14:38:26.345136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the URLs for the dataset\n!gsutil ls $GCS_DS_PATH","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:26.348305Z","iopub.execute_input":"2022-03-03T14:38:26.348681Z","iopub.status.idle":"2022-03-03T14:38:29.461398Z","shell.execute_reply.started":"2022-03-03T14:38:26.348641Z","shell.execute_reply":"2022-03-03T14:38:29.460157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"markdown","source":"This section defines some basic configuration that will be used by the rest of the notebook.","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 192\nEPOCHS = 12\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.463139Z","iopub.execute_input":"2022-03-03T14:38:29.463484Z","iopub.status.idle":"2022-03-03T14:38:29.469235Z","shell.execute_reply.started":"2022-03-03T14:38:29.463442Z","shell.execute_reply":"2022-03-03T14:38:29.468503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_GCS_PATH = GCS_DS_PATH\n\ngcs_fmt = os.path.join(BASE_GCS_PATH, \"tfrecords-jpeg-{}x{}\", \"\")\n\nGCS_PATHS = {\n    192: gcs_fmt.format(192, 192),\n    224: gcs_fmt.format(224, 224),\n    331: gcs_fmt.format(331, 331),\n    512: gcs_fmt.format(512, 512),\n}\nDATA_DIR = GCS_PATHS[IMG_SIZE]","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.470685Z","iopub.execute_input":"2022-03-03T14:38:29.471114Z","iopub.status.idle":"2022-03-03T14:38:29.485235Z","shell.execute_reply.started":"2022-03-03T14:38:29.47108Z","shell.execute_reply":"2022-03-03T14:38:29.484171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/flower-classification-labels/flower_classification_labels.csv\")\nCLASSES = df[\"class\"].tolist()\nCLASSES","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:29.486738Z","iopub.execute_input":"2022-03-03T14:38:29.487269Z","iopub.status.idle":"2022-03-03T14:38:29.511299Z","shell.execute_reply.started":"2022-03-03T14:38:29.487231Z","shell.execute_reply":"2022-03-03T14:38:29.509925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"def data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.random_contrast(image, 0.5, 2.0)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.514006Z","iopub.execute_input":"2022-03-03T14:38:29.514284Z","iopub.status.idle":"2022-03-03T14:38:29.520747Z","shell.execute_reply.started":"2022-03-03T14:38:29.514251Z","shell.execute_reply":"2022-03-03T14:38:29.519741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Functions","metadata":{}},{"cell_type":"markdown","source":"This section has code which loads the train, validation and test datasets.","metadata":{}},{"cell_type":"code","source":"# Decode a JPEG image into a unit8 Tensor \ndef decode_image(image: tf.Tensor, channels: int = 3) -> tf.Tensor:\n    img = tf.image.decode_jpeg(image, channels=channels)\n    img = tf.reshape(img, [IMG_SIZE, IMG_SIZE, 3])\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.52411Z","iopub.execute_input":"2022-03-03T14:38:29.524555Z","iopub.status.idle":"2022-03-03T14:38:29.535768Z","shell.execute_reply.started":"2022-03-03T14:38:29.52452Z","shell.execute_reply":"2022-03-03T14:38:29.535011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read a TFRecord, extracing the image and either the label or the ID\ndef read_tfrecord(example: tf.Tensor, has_labels: bool = True) -> tuple[tf.Tensor, tf.Tensor]:\n    tfrecord_format = {\"image\": tf.io.FixedLenFeature([], tf.string)}\n\n    if has_labels is True:\n        key = \"class\"\n        tfrecord_format[\"class\"] = tf.io.FixedLenFeature([], tf.int64)\n    else:\n        key = \"id\"\n        tfrecord_format[\"id\"] = tf.io.FixedLenFeature([], tf.string)\n\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example[\"image\"])\n    value = example[key]\n    return image, value","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.537296Z","iopub.execute_input":"2022-03-03T14:38:29.538088Z","iopub.status.idle":"2022-03-03T14:38:29.549494Z","shell.execute_reply.started":"2022-03-03T14:38:29.538045Z","shell.execute_reply":"2022-03-03T14:38:29.548405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the list of provided filepaths for TFRecords and build a dataset out of it\ndef get_dataset(filepaths: list[str], has_labels: bool = True, ordered: int = False) -> tf.data.Dataset:\n    options = tf.data.Options()\n    if ordered is False:\n        options.experimental_deterministic = False\n\n    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=AUTO)\n    dataset = dataset.with_options(options)\n\n    reader = functools.partial(read_tfrecord, has_labels=has_labels)\n    dataset = dataset.map(reader, num_parallel_calls=AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.551022Z","iopub.execute_input":"2022-03-03T14:38:29.551982Z","iopub.status.idle":"2022-03-03T14:38:29.567189Z","shell.execute_reply.started":"2022-03-03T14:38:29.551926Z","shell.execute_reply":"2022-03-03T14:38:29.56594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a dataset from the TFRecords stored in the given directory\ndef load_from_dir(\n    directory: str,\n    has_labels: bool = True,\n    ordered: bool = False,\n    repeat: bool = False,\n    cache: bool = False,\n    shuffle: bool = False,\n    augment: bool = False\n) -> tuple[tf.data.Dataset, filenames]:\n    path = os.path.join(DATA_DIR, directory, \"*.tfrec\")\n    filepaths = tf.io.gfile.glob(path)\n    \n    dataset = get_dataset(filepaths, has_labels=has_labels, ordered=ordered)\n    \n    if augment is True:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    \n    if repeat is True:\n        dataset = dataset.repeat()\n    \n    if shuffle is True:\n        dataset = dataset.shuffle(2048)\n        \n    dataset = dataset.batch(BATCH_SIZE)\n    \n    if cache is True:\n        dataset = dataset.cache()\n        \n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.568557Z","iopub.execute_input":"2022-03-03T14:38:29.568836Z","iopub.status.idle":"2022-03-03T14:38:29.581762Z","shell.execute_reply.started":"2022-03-03T14:38:29.568806Z","shell.execute_reply":"2022-03-03T14:38:29.581008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def n_samples(directory):\n    path = os.path.join(DATA_DIR, directory, \"*.tfrec\")\n    filepaths = tf.io.gfile.glob(path)\n    tot = 0\n    for filepath in filepaths:\n        basename = os.path.basename(filepath)\n        filename, _ = os.path.splitext(basename)\n        tot += int(filename.split(\"-\")[-1])\n    return tot","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:29.583343Z","iopub.execute_input":"2022-03-03T14:38:29.583624Z","iopub.status.idle":"2022-03-03T14:38:29.602644Z","shell.execute_reply.started":"2022-03-03T14:38:29.583593Z","shell.execute_reply":"2022-03-03T14:38:29.601461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting functions","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"# Convert a batch of images to NumPy\ndef batch_to_numpy(\n    batch: tuple[tf.Tensor, tf.Tensor],\n    has_labels=False\n) -> tuple[np.ndarray, np.ndarray]:\n    if has_labels is False:\n        images, _ = batch\n        return images.numpy(), None\n    \n    images, labels = batch\n    return images.numpy(), labels.numpy()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:29.604423Z","iopub.execute_input":"2022-03-03T14:38:29.605339Z","iopub.status.idle":"2022-03-03T14:38:29.616995Z","shell.execute_reply.started":"2022-03-03T14:38:29.605298Z","shell.execute_reply":"2022-03-03T14:38:29.616055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the text to display on top of each image\n# With its size and color\ndef get_title(prediction: int, label: int):\n    c = [\"red\", \"black\"]\n    \n    # If test data with no predictions, no text\n    if prediction is None and label is None:\n        return '', c[True]\n    \n    # If test data but with predictions, return predicted label\n    if label is None:\n        return CLASSES[prediction], c[True] \n    \n    actual = CLASSES[label]\n    \n    # If train/validation data with prediction,\n    # Display only the label if correct prediction\n    # Otherwise, display the prediction with the correct label\n    if prediction is not None:\n        correct = prediction == label\n        title = f\"p: {CLASSES[prediction]}\\na: {actual}\"\n        return title, c[correct]\n    \n    # If only label, return as is\n    return f\"{actual}\", c[True]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:29.618766Z","iopub.execute_input":"2022-03-03T14:38:29.619113Z","iopub.status.idle":"2022-03-03T14:38:29.630844Z","shell.execute_reply.started":"2022-03-03T14:38:29.619076Z","shell.execute_reply":"2022-03-03T14:38:29.629711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a grid of the given images\ndef plot_grid(\n    images: np.ndarray,\n    labels: np.ndarray | list[None],\n    predictions: tf.Tensor | list[None],\n    spacing: float = 0.1\n) -> None:\n    n_images = len(images)\n    \n    # Make a square grid by taking square root\n    rows = int(math.sqrt(n_images))\n    cols = n_images // rows\n    tot = rows * cols\n\n    # Some parameters borrowed from the Getting Started Notebook.\n    size = 13\n    fontdict = {\"verticalalignment\": \"center\"}\n\n    figsize = (size, size / tot) if rows < cols else (size / tot, size)\n    plt.figure(figsize=figsize)\n\n    # Make a subplot\n    fig, axs = plt.subplots(\n        rows,\n        cols,\n        figsize=(size, size),\n        constrained_layout=True,\n        gridspec_kw={\"wspace\": spacing, \"hspace\": spacing}\n    )\n    plt.axis(\"off\")\n    axs = axs.flatten()\n\n    # Go over each image, label, prediction\n    # And add to subplot\n    zipped = zip(images[:tot], labels[:tot], predictions[:tot], axs)\n    for image, label, prediction, ax in zipped:\n        fontsize = size * spacing / max(rows, cols) * 40 + 3\n        title, color = get_title(prediction, label)\n        ax.imshow(image)\n        ax.set_title(title, fontsize=fontsize, color=color, fontdict=fontdict, pad=fontsize / 1.5)\n        ax.set_axis_off()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:29.632656Z","iopub.execute_input":"2022-03-03T14:38:29.633105Z","iopub.status.idle":"2022-03-03T14:38:29.646878Z","shell.execute_reply.started":"2022-03-03T14:38:29.633063Z","shell.execute_reply":"2022-03-03T14:38:29.645804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a batch of images\ndef plot_batch(\n    batch: tuple[tf.Tensor, tf.Tensor],\n    has_labels: bool = True,\n    predictions: tf.Tensor = None\n) -> None:\n    # Convert to Numpy\n    images, labels = batch_to_numpy(batch, has_labels=has_labels)\n\n    n_images = len(images)\n\n    # Fill labels and predictions with None if required\n    labels_ = labels if labels is not None else [None for _ in range(n_images)]\n    predictions_ = (\n        predictions if predictions is not None else [None for _ in range(n_images)]\n    )\n    spacing = 0.1\n    # Plot the images with labels and predictions in a grid\n    plot_grid(images, labels_, predictions_, spacing=spacing)\n    \n    # Handle whitespace\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=spacing, hspace=spacing)\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:29.648525Z","iopub.execute_input":"2022-03-03T14:38:29.648968Z","iopub.status.idle":"2022-03-03T14:38:29.663337Z","shell.execute_reply.started":"2022-03-03T14:38:29.648918Z","shell.execute_reply":"2022-03-03T14:38:29.662314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspect Datasets","metadata":{}},{"cell_type":"code","source":"train_data = load_from_dir(\"train\", repeat=True, shuffle=True, augment=True)\nn_train = n_samples(\"train\")\nval_data = load_from_dir(\"val\", cache=True)\nn_val = n_samples(\"val\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:29.66488Z","iopub.execute_input":"2022-03-03T14:38:29.66522Z","iopub.status.idle":"2022-03-03T14:38:30.461699Z","shell.execute_reply.started":"2022-03-03T14:38:29.665184Z","shell.execute_reply":"2022-03-03T14:38:30.460693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of training samples = {n_train}\")\nprint(\"Training data shape and sample labels:\")\nfor image, label in train_data.take(1):\n    print(image.shape, label)\n\nprint(f\"Number of validation samples = {n_val}\")\nprint(\"Validation data shape and sample labels:\")\nfor image, label in val_data.take(1):\n    print(image.shape, label)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:30.463173Z","iopub.execute_input":"2022-03-03T14:38:30.463451Z","iopub.status.idle":"2022-03-03T14:38:31.521076Z","shell.execute_reply.started":"2022-03-03T14:38:30.463418Z","shell.execute_reply":"2022-03-03T14:38:31.519949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itrain = iter(train_data.unbatch().batch(20))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:31.522746Z","iopub.execute_input":"2022-03-03T14:38:31.523045Z","iopub.status.idle":"2022-03-03T14:38:31.544828Z","shell.execute_reply.started":"2022-03-03T14:38:31.523012Z","shell.execute_reply":"2022-03-03T14:38:31.543982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_batch(next(itrain))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:31.546931Z","iopub.execute_input":"2022-03-03T14:38:31.548097Z","iopub.status.idle":"2022-03-03T14:38:33.78551Z","shell.execute_reply.started":"2022-03-03T14:38:31.548052Z","shell.execute_reply":"2022-03-03T14:38:33.784333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ival = iter(val_data.unbatch().batch(20))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:33.787508Z","iopub.execute_input":"2022-03-03T14:38:33.787991Z","iopub.status.idle":"2022-03-03T14:38:33.809467Z","shell.execute_reply.started":"2022-03-03T14:38:33.787944Z","shell.execute_reply":"2022-03-03T14:38:33.80854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_batch(next(ival))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-03T14:38:33.811168Z","iopub.execute_input":"2022-03-03T14:38:33.811848Z","iopub.status.idle":"2022-03-03T14:38:35.380952Z","shell.execute_reply.started":"2022-03-03T14:38:33.811803Z","shell.execute_reply":"2022-03-03T14:38:35.380155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions For Building The Model","metadata":{}},{"cell_type":"markdown","source":"Transfer learning in the form of fine-tuning is used to adapt a pretrained model for this task. The model is initialized with weights for the ImageNet dataset and training is turned on for it. A `GlobalAveragePooling2D` layer is applied to its output. Optionally, additional `Dense` layers can also added. The output is a `Dense` layer with as many units as the number of classes and a softmax activation.\n\nThe pretrained model can either be set to VGG16, VGG19, Xception or ResNet50 by adding the key `core_model` in `params` with an appropriate value. The default is VGG16. The optional `Dense` layers are added by adding the key `dense_out_features` with a list of integers, each integer being the number of units in the layer. As many layers as the length of the list will be added to the model, in addition to the final output layer.","metadata":{}},{"cell_type":"code","source":"core_model_map = {\n    \"vgg16\": [\n        applications.vgg16.preprocess_input,\n        applications.VGG16,\n    ],\n    \"xception\": [\n        applications.xception.preprocess_input,\n        applications.Xception,\n    ],\n    \"vgg19\": [\n        applications.vgg19.preprocess_input,\n        applications.VGG19,\n    ],\n    \"resnet50\": [\n        applications.resnet50.preprocess_input,\n        applications.ResNet50,\n    ]\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:35.384321Z","iopub.execute_input":"2022-03-03T14:38:35.384828Z","iopub.status.idle":"2022-03-03T14:38:35.391121Z","shell.execute_reply.started":"2022-03-03T14:38:35.384784Z","shell.execute_reply":"2022-03-03T14:38:35.390055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_params(params):\n    dense_out_features = []\n    \n    for param, value in params.items():\n        if \"dense\" in param:\n            dense_out_features.append(value)\n    \n    return {\n        \"core_model\": params.get(\"core_model\", \"vgg16\"),\n        \"dense_out_features\": dense_out_features\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:35.392704Z","iopub.execute_input":"2022-03-03T14:38:35.393007Z","iopub.status.idle":"2022-03-03T14:38:35.407125Z","shell.execute_reply.started":"2022-03-03T14:38:35.392971Z","shell.execute_reply":"2022-03-03T14:38:35.406059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(params):\n    model_params = get_model_params(params)\n    \n    core_model = params.get(\"core_model\", \"vgg16\")\n    dense_out_features = params.get(\"dense_out_features\", [])\n    \n    shape = [IMG_SIZE, IMG_SIZE, 3]\n    \n    with strategy.scope():\n        preproces, core = core_model_map[core_model]\n        \n        ip = layers.Lambda(lambda data: preproces(tf.cast(data, tf.float32)), input_shape=shape)\n        core = core(weights=\"imagenet\", include_top=False)\n        \n        dense = [layers.Dense(features, activation=\"relu\") for features in dense_out_features]\n        \n        model = Sequential(\n            [\n                ip,\n                core,\n                layers.GlobalAveragePooling2D(),\n                *dense,\n                layers.Dense(len(CLASSES), activation=\"softmax\"),\n            ]\n        )\n        \n        optimizer = optimizers.Adam(learning_rate=params.get(\"lr\", 1e-3))\n        loss = \"sparse_categorical_crossentropy\"\n        metric = \"sparse_categorical_accuracy\"\n        model.compile(optimizer=optimizer, loss=loss, metrics=[metric], steps_per_execution=16)\n        \n        return model","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:35.409466Z","iopub.execute_input":"2022-03-03T14:38:35.409954Z","iopub.status.idle":"2022-03-03T14:38:35.428287Z","shell.execute_reply.started":"2022-03-03T14:38:35.409841Z","shell.execute_reply":"2022-03-03T14:38:35.427213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"markdown","source":"The training logic is encapsulated in the function below. It returns the validation loss after the final epoch, the trained model and the training history at the end of training.","metadata":{}},{"cell_type":"code","source":"def train(params):\n    train_data = load_from_dir(\"train\", repeat=True, shuffle=True, augment=True)\n    n_train = n_samples(\"train\")\n\n    val_data = load_from_dir(\"val\", cache=True)\n    n_val = n_samples(\"val\")\n    \n    model = make_model(params)    \n\n    steps_per_epoch = n_train // BATCH_SIZE\n    validation_steps = -(-n_val // BATCH_SIZE)\n    \n    early_stopping = callbacks.EarlyStopping(patience=5)\n    pruning_callback = params.get(\"pruning_callback\", [])\n    \n    epochs = params.get(\"epochs\", EPOCHS)\n    \n    history = model.fit(\n        train_data,\n        steps_per_epoch=steps_per_epoch,\n        epochs=epochs,\n        validation_data=val_data,\n        validation_steps=validation_steps,\n        callbacks=[early_stopping, *pruning_callback]\n    )\n    \n    val_loss = history.history[\"val_loss\"]\n\n    return val_loss[-1], model, history\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:35.429973Z","iopub.execute_input":"2022-03-03T14:38:35.430262Z","iopub.status.idle":"2022-03-03T14:38:35.442187Z","shell.execute_reply.started":"2022-03-03T14:38:35.430224Z","shell.execute_reply":"2022-03-03T14:38:35.441222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna Objective\n\nThe hyperparameters are tuned using Optuna. It is used to select the architecture that will be used for transfer learning, the learning rate, the number and sizes of the additional `Dense` layers to be added and the number of epochs. Additionally, Optuna is penalized whenever it chooses parameters that lead to early stopping since early stopping suggests that there is overfitting.","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        \"core_model\": trial.suggest_categorical(\"core_model\", [\"vgg16\", \"xception\", \"vgg19\", \"resnet50\"]),\n        \"lr\": trial.suggest_float(\"lr\", 1e-5, 4e-4),\n        \"epochs\": trial.suggest_int(\"epochs\", 8, 20),\n    }\n    \n    n_dense = trial.suggest_categorical(\"n_dense\", [1, 2, 3, 4, 5])\n    for i in range(n_dense):\n        key = f\"dense{i + 1}_out\"\n        params[f\"dense{i + 1}_out\"] = trial.suggest_int(key, 32, 1024)\n        \n    params[\"pruning_callback\"] = [optuna.integration.TFKerasPruningCallback(trial, \"val_loss\")]\n    \n    score, _, hist = train(params)\n    \n    val_loss = hist.history[\"val_loss\"]\n    \n    # Penalize tuner for being too aggresive\n    if len(val_loss) < params[\"epochs\"]:\n        return np.max(val_loss)\n\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:38:35.443743Z","iopub.execute_input":"2022-03-03T14:38:35.444297Z","iopub.status.idle":"2022-03-03T14:38:35.460832Z","shell.execute_reply.started":"2022-03-03T14:38:35.444256Z","shell.execute_reply":"2022-03-03T14:38:35.459827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"# Tune Parameters\n\nThe Hyperband pruning technique is a popular and SOTA pruning technique for stopping unpromising trial mid-way.","metadata":{}},{"cell_type":"code","source":"pruner = optuna.pruners.HyperbandPruner()\nsampler = optuna.samplers.TPESampler(42, multivariate=True)\nstudy = optuna.create_study(\n    direction=\"minimize\",\n    pruner=pruner,\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=50, gc_after_trial=True)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Final Model Using Best Parameters","metadata":{}},{"cell_type":"code","source":"study.best_trial.params","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:08:29.713417Z","iopub.execute_input":"2022-03-03T14:08:29.714075Z","iopub.status.idle":"2022-03-03T14:08:29.723494Z","shell.execute_reply.started":"2022-03-03T14:08:29.714019Z","shell.execute_reply":"2022-03-03T14:08:29.722223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_trial = study.best_trial\n_, model, history = train(best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:08:32.063815Z","iopub.execute_input":"2022-03-03T14:08:32.064213Z","iopub.status.idle":"2022-03-03T14:09:05.764804Z","shell.execute_reply.started":"2022-03-03T14:08:32.064177Z","shell.execute_reply":"2022-03-03T14:09:05.763604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss Curve","metadata":{}},{"cell_type":"code","source":"train_loss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nplt.plot(train_loss, label=\"Training\")\nplt.plot(val_loss, label=\"Validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T11:02:20.245297Z","iopub.execute_input":"2022-03-01T11:02:20.245615Z","iopub.status.idle":"2022-03-01T11:02:20.476655Z","shell.execute_reply.started":"2022-03-01T11:02:20.245584Z","shell.execute_reply":"2022-03-01T11:02:20.475861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy Curve","metadata":{}},{"cell_type":"code","source":"train_loss = history.history[\"sparse_categorical_accuracy\"]\nval_loss = history.history[\"val_sparse_categorical_accuracy\"]\nplt.plot(train_loss, label=\"Training\")\nplt.plot(val_loss, label=\"Validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T11:02:23.280756Z","iopub.execute_input":"2022-03-01T11:02:23.281194Z","iopub.status.idle":"2022-03-01T11:02:24.155683Z","shell.execute_reply.started":"2022-03-01T11:02:23.281151Z","shell.execute_reply":"2022-03-01T11:02:24.154813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"test_data = load_from_dir(\"test\", has_labels=False, ordered=True)\nn_test = n_samples(\"test\")\ntest_steps = -(-n_test // BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T11:02:28.845045Z","iopub.execute_input":"2022-03-01T11:02:28.845725Z","iopub.status.idle":"2022-03-01T11:02:29.022756Z","shell.execute_reply.started":"2022-03-01T11:02:28.845683Z","shell.execute_reply":"2022-03-01T11:02:29.021865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Computing predictions...')\ntest_images = test_data.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images, steps=test_steps)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)\n\nprint('Generating submission.csv file...')\ntest_ids = test_data.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids.batch(n_test))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')","metadata":{"execution":{"iopub.status.busy":"2022-03-01T11:03:10.11655Z","iopub.execute_input":"2022-03-01T11:03:10.11705Z","iopub.status.idle":"2022-03-01T11:03:12.611214Z","shell.execute_reply.started":"2022-03-01T11:03:10.117014Z","shell.execute_reply":"2022-03-01T11:03:12.610316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual Validation","metadata":{}},{"cell_type":"code","source":"val_data = load_from_dir(\"val\")\nbatches = val_data.unbatch().batch(20)\nibatches = iter(batches)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:35:02.14498Z","iopub.execute_input":"2022-03-03T14:35:02.145341Z","iopub.status.idle":"2022-03-03T14:35:02.330943Z","shell.execute_reply.started":"2022-03-03T14:35:02.145303Z","shell.execute_reply":"2022-03-03T14:35:02.329877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(ibatches)\nprobabilities = model.predict(tf.cast(images, tf.float32))\npredictions = np.argmax(probabilities, axis=-1)\nplot_batch((images, labels), predictions=predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:35:08.113773Z","iopub.execute_input":"2022-03-03T14:35:08.114134Z","iopub.status.idle":"2022-03-03T14:35:08.536298Z","shell.execute_reply.started":"2022-03-03T14:35:08.114101Z","shell.execute_reply":"2022-03-03T14:35:08.534734Z"},"trusted":true},"execution_count":null,"outputs":[]}]}