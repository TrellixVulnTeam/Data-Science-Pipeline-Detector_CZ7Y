{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nfrom scipy.stats import skew,kurtosis,ttest_ind","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Data ","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/stumbleupon/train.tsv\",sep='\\t')\ndf.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning Data","metadata":{}},{"cell_type":"code","source":"def DataCleaning(d):\n    \n    data=d.copy()\n    data['is_news']=data['is_news'].str.replace('?','0').astype(int)\n    data['alchemy_category']=data['alchemy_category'].str.replace('weather','?')\n    data['alchemy_category']=data['alchemy_category'].str.replace('unknown','?')\n    data=data.drop(columns=['url','boilerplate','framebased','alchemy_category_score'])\n    return data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=DataCleaning(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Overview","metadata":{}},{"cell_type":"code","source":"data.sample(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if Categories differences can impact on the label\n(data.groupby('alchemy_category').label.agg(['count','mean']).sort_values(by='mean',ascending=False)).round(2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if is_news or not can impact on the label\n(data.groupby('is_news').label.agg(['count','mean']).sort_values(by='mean',ascending=False)).round(2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr()[['label']].abs().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.corr())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['news_front_page'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection (wrapper method)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nFT=data.copy()\ncols = FT.columns.tolist()\nfor column in cols:\n    if FT[column].dtype == 'object':\n        FT[column] = le.fit_transform(FT[column])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=FT.iloc[:,1:-1]\ny=FT['label']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nfrom sklearn.linear_model import LogisticRegression as LGR\nfrom sklearn.ensemble import RandomForestClassifier as rfc\nfrom mlxtend.feature_selection import ExhaustiveFeatureSelector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names=tuple(X.columns)\nfeature_names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfs1 = SFS(#knn(n_neighbors=5),\n           rfc(n_estimators = 10, criterion = 'entropy'),\n           #LGR(max_iter=1000),\n           k_features='best', \n           forward=True, \n           floating=False, \n           verbose=2,\n           #scoring = 'neg_mean_squared_error',  # sklearn regressors\n           scoring='accuracy',  # sklearn classifiers\n           cv=0)\n\nsfs1 = sfs1.fit(X, y,custom_feature_names=feature_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfs1.subsets_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfs1.get_metric_dict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfs1.k_feature_names_, sfs1.k_feature_idx_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling Data","metadata":{}},{"cell_type":"code","source":"def features_transform(d):\n    \n    train=d[['alchemy_category','avglinksize',\n    'commonlinkratio_1',\n   'commonlinkratio_2',\n   'commonlinkratio_3',\n   'html_ratio',\n   'is_news',\n   'lengthyLinkDomain',\n   'news_front_page',\n   'non_markup_alphanum_characters',\n   'numberOfLinks',\n   'parametrizedLinkRatio',\n   'spelling_errors_ratio']]\n    \n    Cat_Ft=train.select_dtypes(include=[np.object])\n    Num_Ft=train.select_dtypes(include=[np.number])\n\n    from sklearn.preprocessing import OneHotEncoder\n\n    one_hot_encoder = OneHotEncoder(drop='first')\n    Cat_Features = one_hot_encoder.fit_transform(Cat_Ft).todense()\n    Cat_Features=pd.DataFrame(Cat_Features, columns=one_hot_encoder.get_feature_names())\n    \n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    Num_Features = scaler.fit_transform(Num_Ft)\n    Num_Features=pd.DataFrame(Num_Features, columns=Num_Ft.columns)\n    features=pd.concat([Num_Features,Cat_Features],axis=1)\n    \n    return features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(data, test_size=0.3, random_state=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = features_transform(df_train)\ny_train = df_train.label\n\nX_test = features_transform(df_test)\ny_test = df_test.label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier as rfc\nfrom sklearn.linear_model import LogisticRegression as LGR\n#from xgboost import XGBClassifier\nfrom sklearn.dummy import DummyClassifier\n\nmodel = rfc(n_estimators = 10)\nbaseline = DummyClassifier(strategy='most_frequent')\n\nmodel.fit(X_train, y_train)\nbaseline.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_auc_score,accuracy_score\n\nprint(classification_report(y_test, model.predict(X_test)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X_test)\n#print(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"X_train = features_transform(data)\ny_train = data.label\n\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dd=pd.read_csv(\"/kaggle/input/stumbleupon/test.tsv\",sep='\\t')\ndf_test_cleaned=DataCleaning(dd)\n\nX_test=features_transform(df_test_cleaned)\n\n#df_test_cleaned\nsumbission_df=df_test_cleaned[['urlid']].copy()\nsumbission_df['label']=model.predict(X_test)\nsumbission_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sumbission_df.to_csv('StumbleUpon_Evergreen_Classification.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}