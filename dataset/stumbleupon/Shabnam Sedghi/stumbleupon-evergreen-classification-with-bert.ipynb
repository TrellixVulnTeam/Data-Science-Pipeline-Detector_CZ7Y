{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T13:54:35.995464Z","iopub.execute_input":"2022-02-10T13:54:35.996047Z","iopub.status.idle":"2022-02-10T13:54:36.023765Z","shell.execute_reply.started":"2022-02-10T13:54:35.995955Z","shell.execute_reply":"2022-02-10T13:54:36.022897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.preprocessing import OrdinalEncoder\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:40.126945Z","iopub.execute_input":"2022-02-10T13:54:40.127602Z","iopub.status.idle":"2022-02-10T13:54:45.112725Z","shell.execute_reply.started":"2022-02-10T13:54:40.127563Z","shell.execute_reply":"2022-02-10T13:54:45.111964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"df_train=pd.read_csv('/kaggle/input/stumbleupon/train.tsv',sep='\\t')\n\ndf_test=pd.read_csv('/kaggle/input/stumbleupon/test.tsv',sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:45.114805Z","iopub.execute_input":"2022-02-10T13:54:45.115207Z","iopub.status.idle":"2022-02-10T13:54:45.690623Z","shell.execute_reply.started":"2022-02-10T13:54:45.11517Z","shell.execute_reply":"2022-02-10T13:54:45.689898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:45.691763Z","iopub.execute_input":"2022-02-10T13:54:45.691989Z","iopub.status.idle":"2022-02-10T13:54:45.723605Z","shell.execute_reply.started":"2022-02-10T13:54:45.691958Z","shell.execute_reply":"2022-02-10T13:54:45.722833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.drop(columns=['url','boilerplate','label'])\nY = df_train['label']\nencoder = OrdinalEncoder()\nX = pd.DataFrame(encoder.fit_transform(X),columns=X.columns)\nX.head()\nX.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:45.725349Z","iopub.execute_input":"2022-02-10T13:54:45.725614Z","iopub.status.idle":"2022-02-10T13:54:45.788417Z","shell.execute_reply.started":"2022-02-10T13:54:45.72558Z","shell.execute_reply":"2022-02-10T13:54:45.787635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sel_mutual = SelectKBest(mutual_info_classif, k=24)\nX_train_mutual = sel_mutual.fit_transform(X, Y)\nprint(pd.DataFrame(sel_mutual.scores_,index=X.columns).sort_values(by=0))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:46.815036Z","iopub.execute_input":"2022-02-10T13:54:46.815315Z","iopub.status.idle":"2022-02-10T13:54:48.068439Z","shell.execute_reply.started":"2022-02-10T13:54:46.815285Z","shell.execute_reply":"2022-02-10T13:54:48.067182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nsns.countplot(x=df_train['alchemy_category'], hue=df_train[\"label\"])\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:49.92733Z","iopub.execute_input":"2022-02-10T13:54:49.928021Z","iopub.status.idle":"2022-02-10T13:54:50.299094Z","shell.execute_reply.started":"2022-02-10T13:54:49.927983Z","shell.execute_reply":"2022-02-10T13:54:50.298417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#distribution of labels\nplt.figure()\nsns.countplot(x=df_train['label'])\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:52.246954Z","iopub.execute_input":"2022-02-10T13:54:52.247852Z","iopub.status.idle":"2022-02-10T13:54:52.41337Z","shell.execute_reply.started":"2022-02-10T13:54:52.247806Z","shell.execute_reply":"2022-02-10T13:54:52.412534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"alchemy_category has the strongest correlation with the label.","metadata":{}},{"cell_type":"markdown","source":"# Boiler Plate Column Analysis","metadata":{}},{"cell_type":"code","source":"!pip3 install bert-for-tf2","metadata":{"execution":{"iopub.status.busy":"2022-02-10T13:54:54.776078Z","iopub.execute_input":"2022-02-10T13:54:54.776345Z","iopub.status.idle":"2022-02-10T13:55:09.40331Z","shell.execute_reply.started":"2022-02-10T13:54:54.776317Z","shell.execute_reply":"2022-02-10T13:55:09.402512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nfrom bert import bert_tokenization\nmodule_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\nbert_layer = hub.KerasLayer(module_url, trainable=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:19:11.773394Z","iopub.execute_input":"2022-02-10T14:19:11.774125Z","iopub.status.idle":"2022-02-10T14:19:15.694462Z","shell.execute_reply.started":"2022-02-10T14:19:11.774089Z","shell.execute_reply":"2022-02-10T14:19:15.693689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Text","metadata":{}},{"cell_type":"code","source":"df_train['boilerplate'].replace(to_replace=r'\"title\":', value=\"\",inplace=True,regex=True)\ndf_train['boilerplate'].replace(to_replace=r'\"url\":',value=\"\",inplace=True,regex=True)\n\ndf_train['boilerplate'].replace(to_replace=r'{|}',value=\"\",inplace=True,regex=True)\n\ndf_test['boilerplate'].replace(to_replace=r'\"title\":', value=\"\",inplace=True,regex=True)\ndf_test['boilerplate'].replace(to_replace=r'\"url\":',value=\"\",inplace=True,regex=True)\n\ndf_test['boilerplate'].replace(to_replace=r'{|}',value=\"\",inplace=True,regex=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:19:15.725928Z","iopub.execute_input":"2022-02-10T14:19:15.726507Z","iopub.status.idle":"2022-02-10T14:19:16.467882Z","shell.execute_reply.started":"2022-02-10T14:19:15.726447Z","shell.execute_reply":"2022-02-10T14:19:16.467144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ntokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case=True)\n\ndef bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:19:16.469452Z","iopub.execute_input":"2022-02-10T14:19:16.469712Z","iopub.status.idle":"2022-02-10T14:19:16.583926Z","shell.execute_reply.started":"2022-02-10T14:19:16.469679Z","shell.execute_reply":"2022-02-10T14:19:16.583198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(bert_layer, max_len=512):\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    bert_output = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n    net = tf.keras.layers.BatchNormalization()(bert_output)\n    net = tf.keras.layers.Dropout(0.1)(net)\n    net = tf.keras.layers.Dense(32, activation='relu')(net)\n    net = tf.keras.layers.Dense(10, activation='relu')(net)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(net)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n     \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:29:46.526964Z","iopub.execute_input":"2022-02-10T14:29:46.527392Z","iopub.status.idle":"2022-02-10T14:29:46.535409Z","shell.execute_reply.started":"2022-02-10T14:29:46.52735Z","shell.execute_reply":"2022-02-10T14:29:46.534743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 512\ntrain_input = bert_encode(df_train.boilerplate.values, tokenizer, max_len=max_len)\ntest_input = bert_encode(df_test.boilerplate.values, tokenizer, max_len=max_len)\ntrain_labels = df_train.label","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:19:22.118293Z","iopub.execute_input":"2022-02-10T14:19:22.119002Z","iopub.status.idle":"2022-02-10T14:21:18.513866Z","shell.execute_reply.started":"2022-02-10T14:19:22.118955Z","shell.execute_reply":"2022-02-10T14:21:18.513118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(bert_layer, max_len=max_len)\nmodel.layers[3].trainable=False\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:29:50.416931Z","iopub.execute_input":"2022-02-10T14:29:50.417459Z","iopub.status.idle":"2022-02-10T14:29:50.574746Z","shell.execute_reply.started":"2022-02-10T14:29:50.417424Z","shell.execute_reply":"2022-02-10T14:29:50.573679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:29:53.648514Z","iopub.execute_input":"2022-02-10T14:29:53.648954Z","iopub.status.idle":"2022-02-10T14:29:53.972326Z","shell.execute_reply.started":"2022-02-10T14:29:53.648911Z","shell.execute_reply":"2022-02-10T14:29:53.97152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up epochs and steps\nepochs = 15\nbatch_size = 32\n\ntrain_data_size = len(df_train)\nsteps_per_epoch = int(train_data_size / batch_size)\nnum_train_steps = steps_per_epoch * epochs\ninitial_learning_rate = 1e-5\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.95)\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\n\nmodel.compile(optimizer=optimizer,\n              loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.AUC()])\n   \n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', \n                                                monitor='val_accuracy',\n                                                save_best_only=True, verbose=1)\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                                 patience=5, verbose=1)\n\ntrain_history = model.fit(\n    train_input, train_labels, \n    validation_split=0.2,\n    epochs=epochs,\n    callbacks=[checkpoint, earlystopping],\n    batch_size=batch_size,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T14:30:01.696283Z","iopub.execute_input":"2022-02-10T14:30:01.696628Z","iopub.status.idle":"2022-02-10T15:38:26.394065Z","shell.execute_reply.started":"2022-02-10T14:30:01.696591Z","shell.execute_reply":"2022-02-10T15:38:26.393213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_input)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:05:01.118363Z","iopub.execute_input":"2022-02-10T16:05:01.118999Z","iopub.status.idle":"2022-02-10T16:06:10.643369Z","shell.execute_reply.started":"2022-02-10T16:05:01.118961Z","shell.execute_reply":"2022-02-10T16:06:10.642617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['label']=predictions\ndf_test.to_csv('submission.csv',columns=['urlid','label'],index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:22:35.756685Z","iopub.execute_input":"2022-02-10T16:22:35.757369Z","iopub.status.idle":"2022-02-10T16:22:35.773986Z","shell.execute_reply.started":"2022-02-10T16:22:35.757331Z","shell.execute_reply":"2022-02-10T16:22:35.773104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}