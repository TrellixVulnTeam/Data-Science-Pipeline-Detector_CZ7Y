{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yaml\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import train_test_split\nimport datetime\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\ndf_train = pd.read_csv(\"../input/train.tsv\", sep ='\\t')\ndf_test = pd.read_csv(\"../input/test.tsv\", sep ='\\t' )\n\n\ncolumns = ['url', 'alchemy_category',\n       'alchemy_category_score', 'avglinksize', 'commonlinkratio_1',\n       'commonlinkratio_2', 'commonlinkratio_3', 'commonlinkratio_4',\n       'compression_ratio', 'embed_ratio', 'framebased', 'frameTagRatio',\n       'hasDomainLink', 'html_ratio', 'image_ratio', 'is_news',\n       'lengthyLinkDomain', 'linkwordscore', 'news_front_page',\n       'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url',\n       'parametrizedLinkRatio', 'spelling_errors_ratio', 'label']\n\n# 'urlid', 'boilerplate',\n#print(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#================== Features From Web URL ==============\ndef Featurize(df_train):\n    U1 = df_train['url'].str.split('//',n = -1, expand = True)[1]\n    U2 = U1.str.split('www.',n = -1, expand = True)[1]\n    webname = U2.str.split('.',n = -1, expand = True)[0]\n    U3 = U2.str.split('.',n = -1, expand = True)[1]\n    domain = U3.str.split('/',n = -1, expand = True)[0]\n    website_type = U3.str.split('/',n = -1, expand = True)[1]\n    U4 = U3.str.split('/',n = -1, expand = True)[2]\n    website_type2 = U4.str.split('/',n = -1, expand = True)[0]\n\n    ###================= Categorical Features out of this ======\n    df_train[\"website\"] = webname\n    df_train[\"website_type\"] = website_type\n    df_train[\"website_type2\"] = website_type2\n    df_train[\"domain\"] = domain\n    \n    #============== Other Features ==================================\n    df_train['alchemy_category_score'] = pd.to_numeric(df_train['alchemy_category_score'], errors='coerce')\n    df_train[\"is_news\"] = pd.to_numeric(df_train[\"is_news\"], errors='coerce')\n    df_train[\"news_front_page\"] = pd.to_numeric(df_train[\"news_front_page\"], errors='coerce')    \n    \n    return df_train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = Featurize(df_train)\ndf_test = Featurize(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S1 = set(df_test['website'].value_counts()[df_test['website'].value_counts() > 0].index)\nS2 = set(df_train['website'].value_counts().index)\nS1 = S2.intersection(S1)\nS2t = set(df_test['website'].value_counts().index)\nS3 = S1 - S2\n\nS4 = list(S2-S1)\nS5 = list(S2t-S1)\nlen(S3)\nprint(S3)\ndf_train['website'] = df_train['website'].replace(S4, 'random')\ndf_test['website'] = df_test['website'].replace(S5, 'random')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list(df_train[\"website\"].value_counts().index)#(ascending = True).iloc[0:-10].plot('barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train[\"website\"].value_counts().head())\nprint(df_test[\"website\"].value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S1 = set(df_test['website_type'].value_counts()[df_test['website_type'].value_counts() > 0].index)\nS2 = set(df_train['website_type'].value_counts().index)\nS1 = S2.intersection(S1)\nS2t = set(df_test['website_type'].value_counts().index)\n\nS3 = S1 - S2\nS4 = list(S2-S1)\nS5 = list(S2t-S1)\nlen(S3)\nprint(S3)\ndf_train['website_type'] = df_train['website_type'].replace(S4, 'random')\ndf_test['website_type'] = df_test['website_type'].replace(S5, 'random')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['website_type'] = df_train['website_type'].replace({'2007':'YEAR', '2008':'YEAR', \n                              '2009':'YEAR', '2010':'YEAR',\n                             '2011':'YEAR', '2012':'YEAR',\n                             '2013':'YEAR'})\n\ndf_test['website_type'] = df_test['website_type'].replace({'2007':'YEAR', '2008':'YEAR', \n                              '2009':'YEAR', '2010':'YEAR',\n                             '2011':'YEAR', '2012':'YEAR',\n                             '2013':'YEAR'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list(df_train[\"website_type\"].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S1 = set(df_test['website_type2'].value_counts()[df_test['website_type2'].value_counts() > 0].index)\nS2 = set(df_train['website_type2'].value_counts().index)\nS1 = S2.intersection(S1)\nS2t = set(df_test['website_type2'].value_counts().index)\n\nS3 = S1 - S2\nS4 = list(S2-S1)\nS5 = list(S2t-S1)\nlen(S3)\nprint(S3)\ndf_train['website_type2'] = df_train['website_type2'].replace(S4, 'random')\ndf_test['website_type2'] = df_test['website_type2'].replace(S5, 'random')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list(df_train[\"domain\"].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S1 = set(df_test['domain'].value_counts()[df_test['domain'].value_counts() > 0].index)\nS2 = set(df_train['domain'].value_counts().index)\nS1 = S2.intersection(S1)\nS2t = set(df_test['domain'].value_counts().index)\n\nS3 = S1 - S2\nS4 = list(S2-S1)\nS5 = list(S2t-S1)\nlen(S3)\nprint(S3)\ndf_train['domain'] = df_train['domain'].replace(S4, 'random')\ndf_test['domain'] = df_test['domain'].replace(S5, 'random')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #================== Features From Boilerplate ==============\n# df_train['boilerplate']\n\n# def func(x):\n#     try:\n#         return yaml.load(x).keys()\n#     except:\n#         return \"RELOOK\"\n    \n# A = df_train['boilerplate'].apply(func)\n\n# #============== Features ==================================\n# A = pd.to_numeric(df_train['alchemy_category_score'], errors='coerce')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns =  [i for i in df_train.columns if i not in [ 'url','urlid', 'boilerplate', 'label']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_variable =[]\nk =0\nfor i in df_train[columns].dtypes:\n    if(i == 'O'):\n        cat_variable.append(k)    \n    k =k+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = LabelEncoder()\nfor i in cat_variable:\n    S = set(df_train[columns[i]]) - set(df_test[columns[i]])\n    print(S)\n    for k in S:\n        df_train[columns[i]] = df_train[columns[i]].replace([k,'<', np.nan], 'NaN')\n        df_test[columns[i]] = df_test[columns[i]].replace([k,'<', np.nan], 'NaN')\n        \n        #df_train[columns[i]] = df_train[columns[i]].astype('category')\n        #df_test[columns[i]] = df_test[columns[i]].astype('category')\n    \n    #df_train[columns[i]].astype(str).replace('nan', np.nan)\n#     enc.fit(df_train[columns[i]].astype('category'))\n#     df_train[columns[i]] = enc.transform(df_train[columns[i]])\n#     df_test[columns[i]] = enc.transform(df_test[columns[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(cat_variable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.fillna(0, inplace = True)\ndf_test.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train[columns[np.array(cat_variable)]].head()\ndf_train[columns[cat_variable[3]]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {  \"loss_function\" : \"Logloss\",\n           \"eval_metric\":\"AUC\",\n           \"task_type\":\"GPU\",\n           \"learning_rate\":   0.07, #4506133538414295,#trial.suggest_loguniform('learning_rate', 1e-2, 1e-1),\n           \"iterations\":70000,\n           \"l2_leaf_reg\":   197, #trial.suggest_int('l2_leaf_reg', 10, 200),\n           \"random_seed\" : 432013,\n           \"od_type\" : \"Iter\",\n          # \"depth\" : 5,\n           \"max_depth\":   4, #trial.suggest_int('max_depth', 2, 16),\n           \"early_stopping_rounds\" : 500,\n           \"border_count\" :64 , #trial.suggest_int('border_count', 16, 512),\n             \"bagging_temperature\" :   2,   #trial.suggest_int('bagging_temperature', 2, 40)\n           \"task_type\" : 'GPU'\n        }\n\n    \nprint(param)\n\ndf_train_columns = columns#df_train.columns#columns[:-1]\n\ncat_feature_inds =cat_variable\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\noof = np.zeros(len(df_train))\npredictions = np.zeros(len(df_test))\nfeature_importance_df = pd.DataFrame()\ntarget = df_train['label']\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train, target)):\n    print(\"fold {}\".format(fold_))\n    X_train, y_train = df_train.iloc[trn_idx][df_train_columns], target.iloc[trn_idx]\n    X_valid, y_valid = df_train.iloc[val_idx][df_train_columns], target.iloc[val_idx]\n    _train = Pool(X_train, label=y_train, cat_features = cat_feature_inds)\n    _valid = Pool(X_valid, label=y_valid, cat_features = cat_feature_inds)\n\n    clf = CatBoostClassifier(**param)\n    clf.fit(\n            _train,\n            eval_set=_valid,\n            use_best_model=True,\n            verbose=200,\n            #plot=True\n    )\n\n    oof[val_idx] = clf.predict_proba(df_train.iloc[val_idx][df_train_columns])[:,1]\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = df_train_columns\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    predictions += clf.predict_proba(df_test[df_train_columns])[:,1] / folds.n_splits\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CV = roc_auc_score(target, oof)\nprint(CV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1):\n    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n            .groupby(\"Feature\")\n            .mean()\n            .sort_values(by=\"importance\", ascending=False)[:5000].index)\n\n    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\n    plt.figure(figsize=(12,12))\n    sns.barplot(x=\"importance\",\n                y=\"Feature\",\n                data=best_features.sort_values(by=\"importance\",\n                                               ascending=False))\n    plt.title('CatBoost Features (avg over folds)')\n    plt.tight_layout()\n    plt.show()\n\n\nimp = best_features.groupby('Feature')['importance'].median().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sampleSubmission.csv\")\nsubmission['label'] = predictions\nsubmission.to_csv(\"submission.csv\", index = False)\n\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}