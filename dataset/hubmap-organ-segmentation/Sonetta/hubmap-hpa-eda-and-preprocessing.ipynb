{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tifffile as tiff \nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom glob import glob\nfrom PIL import Image, ImageOps\nfrom sklearn.metrics import f1_score, roc_auc_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW, lr_scheduler\nfrom torchvision import transforms\nfrom torchvision.transforms.functional import pad\nfrom torchvision.models.segmentation import deeplabv3_resnet50\nfrom torchvision.models.segmentation.deeplabv3 import DeepLabHead","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-29T02:11:22.337542Z","iopub.execute_input":"2022-06-29T02:11:22.338017Z","iopub.status.idle":"2022-06-29T02:11:23.403102Z","shell.execute_reply.started":"2022-06-29T02:11:22.337917Z","shell.execute_reply":"2022-06-29T02:11:23.401746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### It's a start, there are still some bugs to fix in the training","metadata":{}},{"cell_type":"markdown","source":"### Exploratory data analysis","metadata":{}},{"cell_type":"code","source":"path = '../input/hubmap-organ-segmentation/'\nimg_path = path + 'train_images/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(24, 8))\n\nsns.countplot(data=train_df, x='organ', ax=ax[0])\nsns.countplot(data=train_df, x='sex', ax=ax[1])\nsns.histplot(data=train_df, x='age', ax=ax[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(img):\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(3000, 3000), get_stat=False):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    if get_stat:\n        return img.sum()\n    return img.reshape(shape).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['pixel_count'] = train_df.apply(lambda x: rle_decode(x['rle'], shape=(x['img_width'], x['img_height']), get_stat=True), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 8))\nsns.violinplot(data=train_df, x='organ', y='pixel_count', hue='sex', ax=ax[0])\nsns.violinplot(data=train_df, x='organ', y='age', hue='sex', ax=ax[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smp = 290\nname = train_df.loc[smp]['id']\nwidth = height = train_df.loc[smp]['img_height']\nsmp_image = img_path + '{}.tiff'.format(name)\nimg = tiff.imread(smp_image)#[:3000, :3000]\n\nimg = cv2.resize(img, (width, height))\nrle = train_df.loc[smp]['rle']\nmask = rle_decode(rle, shape=(width, height))#[:3000, :3000]\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 10), sharey=True)\nax[0].imshow(img)\nax[1].imshow(mask,cmap='gray')\n\nax[2].imshow(img)\nax[2].imshow(mask, cmap='cool', alpha=0.5)\n\nax[2].set_title(name)\nax[2].axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_patches(img_id, rle, width, height, wh=3000, window=500, save_path='/kaggle/working/train_patches/', min_patch_size=5000, testing=False):\n    \n    def check_pad(img, wh=3000, window=500, mask=False):\n        if width == wh:\n            return img\n        if width > wh:\n            return img[:3000, :3000]\n        \n        padding = int((wh - width) / 2)        \n        if width % 2 == 0:\n            if mask:\n                pad_width = ((padding,padding), (padding,padding))\n            else:\n                pad_width = ((padding,padding), (padding,padding), (0,0))\n            img = np.pad(img, pad_width=pad_width, constant_values=0, mode='constant')\n        else:\n            if mask:\n                pad_width = ((padding,padding+1), (padding,padding+1))\n            else:\n                pad_width = ((padding,padding+1), (padding,padding+1), (0,0))\n            img = np.pad(img, pad_width=pad_width, constant_values=0, mode='constant')\n\n        return img\n    \n    img = tiff.imread(img_path + '{}.tiff'.format(img_id))\n    img = check_pad(img)\n\n    mask = rle_decode(rle, shape=(width, height))\n    mask = check_pad(mask, mask=True)\n    \n    img_patches = []\n    mask_patches = []\n    possible_negative = np.array(range(36)).reshape(6,6)[1:-1, 1:-1].flatten().tolist()\n    idx = 0\n    for r in range(0, wh, window):\n        for c in range(0, wh, window):\n            img_patch = img[r: r+window, c: c+window]\n            img_patches.append(img_patch)\n            mask_patch = mask[r: r+window, c: c+window]\n            mask_patches.append(mask_patch)\n            if not testing:\n                if mask_patch.sum() > min_patch_size:\n                    tiff.imwrite(file=save_path + 'image_{}_{}.png'.format(img_id, idx), data=img_patch)\n                    tiff.imwrite(file=save_path + 'mask_{}_{}.png'.format(img_id, idx), data=mask_patch)\n                elif (mask_patch.sum() == 0) and (idx in possible_negative):\n                    tiff.imwrite(file=save_path +  'neg_{}_{}.png'.format(img_id, idx), data=img_patch)\n    \n            idx += 1\n    \n    if testing:\n        return img_patches, mask_patches\n    return True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/train_patches/\ntrain_df['shape'] = train_df.apply(lambda x: create_patches(x['id'], x['rle'], x['img_width'], x['img_height']), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_patches, mask_patches = create_patches(name, rle, width, height, testing=True)\nfig, ax = plt.subplots(6, 6, figsize=(16, 10), sharey=True)\nfor idx, i in enumerate(ax.flatten()):   \n    i.imshow(img_patches[idx])\n    i.imshow(mask_patches[idx], cmap='cool', alpha=0.5)\n    i.set_title(idx)\n    i.axis(\"off\")\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building dataset","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({'path': glob('/kaggle/working/train_patches/*.png')}).assign(iid=lambda x: x['path'].str.extract('(\\d+)_\\d+.png'), neg=0)\ndf.loc[df['path'].str.contains('neg'), 'neg'] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_df = pd.concat([df[df['path'].str.contains('image') & df['neg'].eq(0)], df[df['neg'].eq(1)].drop_duplicates(['iid'])], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FlowFromDataFrame(Dataset):\n    def __init__(self, df, img_transforms, mask_transforms, test=False):\n        super().__init__()\n        self.df = df\n        self.img_transforms = img_transforms\n        self.mask_transforms = mask_transforms\n        self.test = test\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.df.iloc[index]['path']\n        image = tiff.imread(img_path)\n        if self.test:\n            return image\n        if 'neg' in img_path:\n            mask = torch.Tensor(np.zeros((1, 250, 250), dtype=np.uint8))\n        else:\n            mask = torch.Tensor(tiff.imread(img_path.replace('image', 'mask'))).unsqueeze(0)\n        image = self.img_transforms(image)\n        mask = self.mask_transforms(mask)\n        return image, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_transforms = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((250, 250), interpolation=transforms.InterpolationMode.NEAREST),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])\n\nmask_transforms = transforms.Compose([\n    transforms.Resize((250, 250), interpolation=transforms.InterpolationMode.NEAREST)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_ds = FlowFromDataFrame(training_df, img_transforms, mask_transforms)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, pin_memory=True, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(train_dl))\ncols = 4\nfig, axes = plt.subplots(2, cols, figsize=(12, 10))\n\nfor idx, ax in enumerate(axes.flatten()):\n    if idx < cols:\n        ax.imshow(masks[idx%cols][0], cmap='gray')\n    elif idx >= cols and idx <= 2*cols - 1:\n        ax.imshow(images[idx%cols].permute(1,2,0))\n    ax.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model = deeplabv3_resnet50(pretrained=True)\n    model.classifier = DeepLabHead(2048, 1)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, targets, inputs, smooth=1e-8):\n        inputs = torch.sigmoid(inputs)\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice = (2.*intersection)/(inputs.sum() + targets.sum() + smooth)\n        return 1 - dice\n\ndef dice_accuracy(y_true, y_pred, smooth=1e-8):\n    y_true_f = y_true.view(-1)\n    y_pred_f = y_pred.view(-1)\n    intersection = (y_true_f * y_pred_f).sum()\n    return (2. * intersection + smooth) / ((y_true_f).sum() + (y_pred_f).sum() + smooth)\n\n\ndef loss_fn(y_true, y_pred, bce_fn, dice_fn):\n    bce = bce_fn(y_pred, y_true)\n    dice = dice_fn(y_true, y_pred)\n    return 0.8 * bce + 0.2 * dice","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:19:34.668381Z","iopub.execute_input":"2022-06-29T02:19:34.668799Z","iopub.status.idle":"2022-06-29T02:19:34.680241Z","shell.execute_reply.started":"2022-06-29T02:19:34.66876Z","shell.execute_reply":"2022-06-29T02:19:34.679216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs):\n    device = 'cuda'\n    bce_fn = nn.BCEWithLogitsLoss()\n    dice_fn = DiceLoss()\n    model = model.to(device)\n    optimizer = AdamW(model.parameters(), lr=1e-3)\n    #scheduler = lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=1e-4,)\n    #scaler = GradScaler()\n    best_loss = 99\n    criterion = nn.MSELoss()\n    \n    for epoch in range(epochs):\n        model.train()\n        dice_batch_score = 0\n        batch_loss = 0\n        \n        for image, mask in tqdm(train_dl, leave=False):\n            image, mask = image.to(device), mask.to(device)\n            optimizer.zero_grad()\n            \n            with autocast():\n                output = model(image)\n                #loss = criterion(output['out'], mask)\n                #loss = loss_fn(mask, output['out'], bce_fn, dice_fn)\n                loss = bce_fn(output['out'], mask)\n                \n            loss.backward()\n            optimizer.step()\n            #scheduler.step()\n            \n            y_pred = (torch.sigmoid(output['out']) > 0.5).float()\n            dice_score = dice_accuracy(mask, y_pred) \n            dice_batch_score += dice_score\n            batch_loss += loss.item() * image.size(0)\n        \n        epoch_loss = batch_loss / len(train_dl.dataset)\n        epoch_dice_score = dice_batch_score / len(train_dl.dataset)\n        \n        if epoch_loss < best_loss:\n            best_loss = epoch_loss\n            torch.save(model,'/kaggle/working/deeplabv3_resnet50_test.pt')\n\n        print('Epoch: {} Loss: {:.4f} Dice Score: {:.4f}'.format(epoch, epoch_loss, epoch_dice_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nmodel = get_model()\ntrain(model, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = tiff.imread('../input/hubmap-organ-segmentation/test_images/10078.tiff')\nplt.imshow(test_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_prediction(model, test_transforms):\n    device = 'cuda'\n    test_img = tiff.imread('../input/hubmap-organ-segmentation/test_images/10078.tiff')\n    pred_patches = np.zeros((2000, 2000), dtype=np.uint8)\n    window = 500\n    with torch.no_grad():\n        model.eval()\n        for r in range(0, 2000, window):\n            for c in range(0, 2000, window):\n                img_patch = test_transforms(test_img[r: r+window, c: c+window]).unsqueeze(0).to(device)\n                output = model(img_patch)\n                y_pred = (output['out'] > 0.5).cpu()\n                pred_patches[r: r+window, c: c+window] = y_pred\n    return pred_patches","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])\nprediction = make_prediction(model, test_transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mask = Image.fromarray(prediction)\ntest_mask = np.pad(prediction, pad_width=((0,23), (0,23)), mode='linear_ramp', end_values=1)\nfig, ax = plt.subplots(1, 1, figsize=(12, 12))\nax.imshow(test_img)\nax.imshow(test_mask, cmap='cool', alpha=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}