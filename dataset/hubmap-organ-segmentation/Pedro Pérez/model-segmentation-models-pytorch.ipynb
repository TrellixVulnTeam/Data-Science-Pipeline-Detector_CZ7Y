{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models_pytorch -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-29T16:45:35.528777Z","iopub.execute_input":"2022-06-29T16:45:35.52961Z","iopub.status.idle":"2022-06-29T16:45:52.110809Z","shell.execute_reply.started":"2022-06-29T16:45:35.529509Z","shell.execute_reply":"2022-06-29T16:45:52.109672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport tifffile as tiff \nimport rasterio\nfrom rasterio.windows import Window\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:45:52.113861Z","iopub.execute_input":"2022-06-29T16:45:52.114253Z","iopub.status.idle":"2022-06-29T16:45:52.759667Z","shell.execute_reply.started":"2022-06-29T16:45:52.114213Z","shell.execute_reply":"2022-06-29T16:45:52.758691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport pdb\nimport time\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\nfrom albumentations import (HorizontalFlip, VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\nfrom albumentations.pytorch import ToTensorV2\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:45:52.76108Z","iopub.execute_input":"2022-06-29T16:45:52.761737Z","iopub.status.idle":"2022-06-29T16:45:56.049357Z","shell.execute_reply.started":"2022-06-29T16:45:52.761697Z","shell.execute_reply":"2022-06-29T16:45:56.048405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAMPLE_SUBMISSION  = '../input/sartorius-cell-instance-segmentation/sample_submission.csv'\nTRAIN_CSV = \"../input/hubmap-organ-segmentation/train.csv\"\n# TRAIN_PATH =  \"../input/hubmap-organ-segmentation/train_images/\"\nTRAIN_PATH =  \"../temp/images/\"\nLABELS_PATH =  \"../temp/masks/\"\n\nTEST_PATH = \"../input/hubmap-organ-segmentation/test_images\"\ndf_sample = pd.read_csv('../input/hubmap-organ-segmentation/sample_submission.csv')\n\n\nRESNET_MEAN = (0.485, 0.456, 0.406)\nRESNET_STD = (0.229, 0.224, 0.225)\n\n# (336, 336)\nIMAGE_RESIZE = (224, 224)\n\nLEARNING_RATE = 5e-4\nEPOCHS = 50","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:45:56.051807Z","iopub.execute_input":"2022-06-29T16:45:56.052629Z","iopub.status.idle":"2022-06-29T16:45:56.068201Z","shell.execute_reply.started":"2022-06-29T16:45:56.052591Z","shell.execute_reply":"2022-06-29T16:45:56.067148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_CSV)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:45:56.069411Z","iopub.execute_input":"2022-06-29T16:45:56.069824Z","iopub.status.idle":"2022-06-29T16:45:56.389702Z","shell.execute_reply.started":"2022-06-29T16:45:56.06979Z","shell.execute_reply":"2022-06-29T16:45:56.388775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tiled images","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/temp/images\n!mkdir -p /kaggle/temp/masks","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:45:56.391147Z","iopub.execute_input":"2022-06-29T16:45:56.392077Z","iopub.status.idle":"2022-06-29T16:45:57.736952Z","shell.execute_reply.started":"2022-06-29T16:45:56.392033Z","shell.execute_reply":"2022-06-29T16:45:57.735618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndef tile_image(p_img, folder, size: int = 1024):\n    w = h = size\n    im = np.array(Image.open(p_img))\n    # https://stackoverflow.com/a/47581978/4521646\n    tiles = [im[i:(i + h), j:(j + w), ...] for i in range(0, im.shape[0], h) for j in range(0, im.shape[1], w)]\n    idxs = [(i, (i + h), j, (j + w)) for i in range(0, im.shape[0], h) for j in range(0, im.shape[1], w)]\n    name, _ = os.path.splitext(os.path.basename(p_img))\n    files = []\n    for k, tile in enumerate(tiles):\n        if tile.shape[:2] != (h, w):\n            tile_ = tile\n            tile = np.zeros_like(tiles[0])\n            tile[:tile_.shape[0], :tile_.shape[1], ...] = tile_\n        p_img = os.path.join(folder, f\"{name}_{k:02}.png\")\n        Image.fromarray(tile).save(p_img)\n        files.append(p_img)\n    return files, idxs","metadata":{"execution":{"iopub.status.busy":"2022-06-29T18:45:01.382609Z","iopub.execute_input":"2022-06-29T18:45:01.382982Z","iopub.status.idle":"2022-06-29T18:45:01.394938Z","shell.execute_reply.started":"2022-06-29T18:45:01.382951Z","shell.execute_reply":"2022-06-29T18:45:01.393828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tiles_img, _ = tile_image(\"../input/hubmap-organ-segmentation/train_images/12233.tiff\", \"/kaggle/temp/images\", size=1024)\ntiles_seg, idxs = tile_image(\"../input/hacking-the-human-body-annotation-masks/train_masks/12233.png\", \"/kaggle/temp/masks\", size=1024)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:45:57.753535Z","iopub.execute_input":"2022-06-29T16:45:57.753883Z","iopub.status.idle":"2022-06-29T16:46:02.147925Z","shell.execute_reply.started":"2022-06-29T16:45:57.753849Z","shell.execute_reply":"2022-06-29T16:46:02.146974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lh /kaggle/temp/images\n!ls -lh /kaggle/temp/masks","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:02.149432Z","iopub.execute_input":"2022-06-29T16:46:02.149781Z","iopub.status.idle":"2022-06-29T16:46:03.486353Z","shell.execute_reply.started":"2022-06-29T16:46:02.149745Z","shell.execute_reply":"2022-06-29T16:46:03.485267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import color\n\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 9))\nfor i, (p_img, p_seg) in enumerate(zip(tiles_img, tiles_seg)):\n    img = plt.imread(p_img)\n    mask = np.array(Image.open(p_seg))\n    axes[i // 3, i % 3].imshow(color.label2rgb(mask, img, bg_label=0, bg_color=(1.,1.,1.), alpha=0.25))\n    axes[i // 3, i % 3].set_axis_off()\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:03.495314Z","iopub.execute_input":"2022-06-29T16:46:03.4956Z","iopub.status.idle":"2022-06-29T16:46:09.344782Z","shell.execute_reply.started":"2022-06-29T16:46:03.495572Z","shell.execute_reply":"2022-06-29T16:46:09.343879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def un_tile_image(tiles_seg, idxs, folder_image):\n    tiles = [np.array(Image.open(p_seg)) for p_seg in tiles_seg]\n    im = plt.imread(folder_image)\n    seg = np.zeros(im.shape[:2], dtype=np.uint8)\n    for tile, (i1, i2, j1, j2) in zip(tiles, idxs):\n        i2 = min(i2, im.shape[0])\n        j2 = min(j2, im.shape[1])\n        seg[i1:i2, j1:j2] = tile[:(i2 - i1), :(j2 - j1)]\n    return seg\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:09.345763Z","iopub.execute_input":"2022-06-29T16:46:09.346081Z","iopub.status.idle":"2022-06-29T16:46:09.35699Z","shell.execute_reply.started":"2022-06-29T16:46:09.346052Z","shell.execute_reply":"2022-06-29T16:46:09.356148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tiles_seg, idxs = tile_image(\"../input/hacking-the-human-body-annotation-masks/train_masks/12233.png\", \"/kaggle/temp/masks\", size=1024)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T20:17:07.984646Z","iopub.execute_input":"2022-06-29T20:17:07.985174Z","iopub.status.idle":"2022-06-29T20:17:08.112205Z","shell.execute_reply.started":"2022-06-29T20:17:07.985134Z","shell.execute_reply":"2022-06-29T20:17:08.111218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder= \"../input/hubmap-organ-segmentation/train_images/12233.tiff\"\ntiles_seg, idxs = tile_image(\"../input/hacking-the-human-body-annotation-masks/train_masks/12233.png\", \"/kaggle/temp/masks\", size=1024)\n\nreconstruted_seg = un_tile_image(tiles_seg, idxs, folder)\n\nplt.figure(figsize=(10, 10))    \nplt.imshow(reconstruted_seg)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T20:14:06.815762Z","iopub.execute_input":"2022-06-29T20:14:06.816727Z","iopub.status.idle":"2022-06-29T20:14:08.447572Z","shell.execute_reply.started":"2022-06-29T20:14:06.81669Z","shell.execute_reply":"2022-06-29T20:14:08.446623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_mask = plt.imread(\"../input/hacking-the-human-body-annotation-masks/train_masks/12233.png\")\nplt.figure(figsize=(10, 10))    \nplt.imshow(original_mask)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:10.879332Z","iopub.execute_input":"2022-06-29T16:46:10.881598Z","iopub.status.idle":"2022-06-29T16:46:12.307709Z","shell.execute_reply.started":"2022-06-29T16:46:10.881557Z","shell.execute_reply":"2022-06-29T16:46:12.306796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_FOLDER = \"/kaggle/input/hubmap-organ-segmentation\"\nANNOT_DATASET = \"/kaggle/input/hacking-the-human-body-annotation-masks\"","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:12.309185Z","iopub.execute_input":"2022-06-29T16:46:12.309742Z","iopub.status.idle":"2022-06-29T16:46:12.314704Z","shell.execute_reply.started":"2022-06-29T16:46:12.309704Z","shell.execute_reply":"2022-06-29T16:46:12.313732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[(os.path.join(DATASET_FOLDER, 'train_images'), \"/kaggle/temp/images\"),(os.path.join(ANNOT_DATASET, 'train_masks'), \"/kaggle/temp/masks\"),]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:12.3162Z","iopub.execute_input":"2022-06-29T16:46:12.316787Z","iopub.status.idle":"2022-06-29T16:46:12.326863Z","shell.execute_reply.started":"2022-06-29T16:46:12.316753Z","shell.execute_reply":"2022-06-29T16:46:12.325849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from joblib import Parallel, delayed\nimport os, glob\n\n\nTILE_SIZE = 1024\n\nfor dir_source, dir_target in [(os.path.join(DATASET_FOLDER, 'train_images'), \"/kaggle/temp/images\"),\n    (os.path.join(ANNOT_DATASET, 'train_masks'), \"/kaggle/temp/masks\"),]:\n    ls = glob.glob(os.path.join(dir_source, '*'))\n    _= Parallel(n_jobs=3)(delayed(tile_image)(p_img, dir_target, size=TILE_SIZE) for p_img in tqdm(ls))","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:46:12.328433Z","iopub.execute_input":"2022-06-29T16:46:12.328923Z","iopub.status.idle":"2022-06-29T17:01:22.847864Z","shell.execute_reply.started":"2022-06-29T16:46:12.328868Z","shell.execute_reply":"2022-06-29T17:01:22.846759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls = glob.glob(os.path.join(TRAIN_PATH, '*'))","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:22.849806Z","iopub.execute_input":"2022-06-29T17:01:22.850656Z","iopub.status.idle":"2022-06-29T17:01:22.867319Z","shell.execute_reply.started":"2022-06-29T17:01:22.850601Z","shell.execute_reply":"2022-06-29T17:01:22.86639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_imagen = []\nfor image in ls:\n    list_imagen.append(image[15:-4])\n    \ndf_list = pd.DataFrame(list_imagen)\ndf_list.columns = [\"id\"]\ndf_list","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:22.869912Z","iopub.execute_input":"2022-06-29T17:01:22.870469Z","iopub.status.idle":"2022-06-29T17:01:22.888131Z","shell.execute_reply.started":"2022-06-29T17:01:22.87044Z","shell.execute_reply":"2022-06-29T17:01:22.887141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rleToMask(rleString,height,width):\n  rows,cols = height,width\n  rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n  rlePairs = np.array(rleNumbers).reshape(-1,2)\n  img = np.zeros(rows*cols,dtype=np.uint8)\n  for index,length in rlePairs:\n    index -= 1\n    img[index:index+length] = 255\n  img = img.reshape(cols,rows)\n  img = img.T\n  return img","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:22.889674Z","iopub.execute_input":"2022-06-29T17:01:22.890414Z","iopub.status.idle":"2022-06-29T17:01:22.898217Z","shell.execute_reply.started":"2022-06-29T17:01:22.890375Z","shell.execute_reply":"2022-06-29T17:01:22.897321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CellDatasetTiles(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.base_path = TRAIN_PATH\n        self.labels_path = LABELS_PATH\n\n        self.transforms = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1]), \n#                                    Normalize(mean=RESNET_MEAN, std=RESNET_STD, p=1), \n                                   HorizontalFlip(p=0.5),\n                                   VerticalFlip(p=0.5),\n                                   ToTensorV2()])\n        self.gb = self.df.groupby('id')\n        self.image_ids = df.id.unique().tolist()\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        df = self.gb.get_group(image_id)\n\n        image_path = os.path.join(self.base_path, str(image_id) + \".png\")\n        image =  cv2.imread(image_path).astype('float32')\n        \n        label_path = os.path.join(self.labels_path, str(image_id) + \".png\")\n        mask =  cv2.imread(label_path)\n        mask = (mask >= 1).astype('float32')\n        \n        augmented = self.transforms(image=image, mask=mask)\n        image = augmented['image']\n        mask = augmented['mask']\n        return image, mask[:,:,0].reshape((1, IMAGE_RESIZE[0], IMAGE_RESIZE[1]))\n#         return image, mask\n\n    def __len__(self):\n        return len(self.image_ids)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:22.90101Z","iopub.execute_input":"2022-06-29T17:01:22.901355Z","iopub.status.idle":"2022-06-29T17:01:22.912085Z","shell.execute_reply.started":"2022-06-29T17:01:22.901327Z","shell.execute_reply":"2022-06-29T17:01:22.910918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CellDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.base_path = TRAIN_PATH\n        self.labels_path = LABELS_PATH\n\n        self.transforms = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1]), \n                                   Normalize(mean=RESNET_MEAN, std=RESNET_STD, p=1), \n                                   HorizontalFlip(p=0.5),\n                                   VerticalFlip(p=0.5),\n                                   ToTensorV2()])\n        self.gb = self.df.groupby('id')\n        self.image_ids = df.id.unique().tolist()\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        df = self.gb.get_group(image_id)\n        rle = df['rle'].tolist()\n        image_path = os.path.join(self.base_path, str(image_id) + \".tiff\")\n        image =  tiff.imread(image_path)\n        mask = rleToMask(df[\"rle\"].iloc[-1], image.shape[1], image.shape[0])\n        mask = (mask >= 1).astype('float32')\n        augmented = self.transforms(image=image, mask=mask)\n        image = augmented['image']\n        mask = augmented['mask']\n        return image, mask.reshape((1, IMAGE_RESIZE[0], IMAGE_RESIZE[1]))\n#         return image, mask\n\n    def __len__(self):\n        return len(self.image_ids)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:22.913426Z","iopub.execute_input":"2022-06-29T17:01:22.913996Z","iopub.status.idle":"2022-06-29T17:01:22.928178Z","shell.execute_reply.started":"2022-06-29T17:01:22.913956Z","shell.execute_reply":"2022-06-29T17:01:22.927107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = CellDatasetTiles(df_list)\nimage, mask = ds_train[15]\nimage.shape, mask.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:22.930446Z","iopub.execute_input":"2022-06-29T17:01:22.931818Z","iopub.status.idle":"2022-06-29T17:01:23.088886Z","shell.execute_reply.started":"2022-06-29T17:01:22.93179Z","shell.execute_reply":"2022-06-29T17:01:23.087882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.imshow(image[0].permute(1,0))\nplt.imshow(mask.permute(2,1,0), alpha=0.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:23.090324Z","iopub.execute_input":"2022-06-29T17:01:23.090671Z","iopub.status.idle":"2022-06-29T17:01:23.53138Z","shell.execute_reply.started":"2022-06-29T17:01:23.090624Z","shell.execute_reply":"2022-06-29T17:01:23.529722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl_train = DataLoader(ds_train, batch_size=32, num_workers=4, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:23.532717Z","iopub.execute_input":"2022-06-29T17:01:23.533784Z","iopub.status.idle":"2022-06-29T17:01:23.538856Z","shell.execute_reply.started":"2022-06-29T17:01:23.533748Z","shell.execute_reply":"2022-06-29T17:01:23.537635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dl_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:23.540215Z","iopub.execute_input":"2022-06-29T17:01:23.540952Z","iopub.status.idle":"2022-06-29T17:01:23.552378Z","shell.execute_reply.started":"2022-06-29T17:01:23.540919Z","shell.execute_reply":"2022-06-29T17:01:23.551346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get a batch from the dataloader\nbatch = next(iter(dl_train))\nimages, masks = batch","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:23.554211Z","iopub.execute_input":"2022-06-29T17:01:23.555509Z","iopub.status.idle":"2022-06-29T17:01:36.414349Z","shell.execute_reply.started":"2022-06-29T17:01:23.55547Z","shell.execute_reply":"2022-06-29T17:01:36.413152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx=1\nplt.figure(figsize=(10,10))\nplt.imshow(images[10][0].permute(1,0), cmap='bone')\nplt.show()\nplt.figure(figsize=(10,10))\nplt.imshow(masks[10].permute(2,1,0), alpha=0.3)\nplt.show()\nplt.figure(figsize=(10,10))\nplt.imshow(images[10][0].permute(1,0), cmap='bone')\nplt.imshow(masks[10].permute(2,1,0), alpha=0.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:36.417352Z","iopub.execute_input":"2022-06-29T17:01:36.41799Z","iopub.status.idle":"2022-06-29T17:01:37.426724Z","shell.execute_reply.started":"2022-06-29T17:01:36.417951Z","shell.execute_reply":"2022-06-29T17:01:37.425881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss(input, target):\n    input = torch.sigmoid(input)\n    smooth = 1.0\n    iflat = input.view(-1)\n    tflat = target.view(-1)\n    intersection = (iflat * tflat).sum()\n    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma):\n        super().__init__()\n        self.gamma = gamma\n\n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        return loss.mean()\n\n\nclass MixedLoss(nn.Module):\n    def __init__(self, alpha, gamma):\n        super().__init__()\n        self.alpha = alpha\n        self.focal = FocalLoss(gamma)\n\n    def forward(self, input, target):\n        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n        return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:37.433437Z","iopub.execute_input":"2022-06-29T17:01:37.434025Z","iopub.status.idle":"2022-06-29T17:01:37.446915Z","shell.execute_reply.started":"2022-06-29T17:01:37.433987Z","shell.execute_reply":"2022-06-29T17:01:37.44597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create model and train\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport collections.abc as container_abcs\ntorch._six.container_abcs = container_abcs\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:37.45011Z","iopub.execute_input":"2022-06-29T17:01:37.450384Z","iopub.status.idle":"2022-06-29T17:01:44.183745Z","shell.execute_reply.started":"2022-06-29T17:01:37.45036Z","shell.execute_reply":"2022-06-29T17:01:44.182718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ENCODER = 'se_resnext50_32x4d'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = ['cell']\nACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\nDEVICE = 'cuda'\n\n# create segmentation model with pretrained encoder\nmodel = smp.FPN(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=len(CLASSES), \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:01:44.185508Z","iopub.execute_input":"2022-06-29T17:01:44.185862Z","iopub.status.idle":"2022-06-29T17:06:57.251027Z","shell.execute_reply.started":"2022-06-29T17:01:44.185827Z","shell.execute_reply":"2022-06-29T17:06:57.249979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.0001),\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:06:57.252347Z","iopub.execute_input":"2022-06-29T17:06:57.252956Z","iopub.status.idle":"2022-06-29T17:06:57.261555Z","shell.execute_reply.started":"2022-06-29T17:06:57.252918Z","shell.execute_reply":"2022-06-29T17:06:57.26059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create epoch runners \n# it is a simple loop of iterating over dataloader`s samples\ntrain_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device='cuda',\n    verbose=True,\n)\n\n# valid_epoch = smp.utils.train.ValidEpoch(\n#     model, \n#     loss=loss, \n#     metrics=metrics, \n#     device=DEVICE,\n#     verbose=True,\n# )","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:06:57.262922Z","iopub.execute_input":"2022-06-29T17:06:57.263508Z","iopub.status.idle":"2022-06-29T17:06:59.198933Z","shell.execute_reply.started":"2022-06-29T17:06:57.263471Z","shell.execute_reply":"2022-06-29T17:06:59.19796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model for 40 epochs\n\nmax_score = 0\n\nfor i in range(0, 25):\n    \n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(dl_train)\n#     valid_logs = valid_epoch.run(valid_loader)\n    \n    # do something (save model, change lr, etc.)\n#     if max_score < valid_logs['iou_score']:\n#         max_score = valid_logs['iou_score']\n#         torch.save(model, './best_model.pth')\n#         print('Model saved!')\n    torch.save(model, './best_model.pth')\n\n    if i == 25:\n        optimizer.param_groups[0]['lr'] = 1e-5\n        print('Decrease decoder learning rate to 1e-5!')","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:06:59.200509Z","iopub.execute_input":"2022-06-29T17:06:59.200878Z","iopub.status.idle":"2022-06-29T17:54:56.972747Z","shell.execute_reply.started":"2022-06-29T17:06:59.200841Z","shell.execute_reply":"2022-06-29T17:54:56.971468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize predictions\n","metadata":{}},{"cell_type":"code","source":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:58:59.96485Z","iopub.execute_input":"2022-06-29T17:58:59.965647Z","iopub.status.idle":"2022-06-29T17:58:59.973366Z","shell.execute_reply.started":"2022-06-29T17:58:59.965605Z","shell.execute_reply":"2022-06-29T17:58:59.971926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get a batch from the dataloader\nbatch = next(iter(dl_train))\nimages, masks = batch","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:59:02.889798Z","iopub.execute_input":"2022-06-29T17:59:02.89079Z","iopub.status.idle":"2022-06-29T17:59:10.848046Z","shell.execute_reply.started":"2022-06-29T17:59:02.890741Z","shell.execute_reply":"2022-06-29T17:59:10.84677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    \n    \n    image = images[i]\n    gt_mask = masks[i]\n#     image_vis = image.astype('uint8')\n#     image, gt_mask = test_dataset[n]\n    \n    gt_mask = gt_mask.squeeze()\n    \n    x_tensor = image.to(DEVICE).unsqueeze(0)\n    pr_mask = model.predict(x_tensor)\n    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n        \n    visualize(\n        ground_truth_mask=gt_mask, \n        predicted_mask=pr_mask\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-29T19:59:26.317929Z","iopub.execute_input":"2022-06-29T19:59:26.318683Z","iopub.status.idle":"2022-06-29T19:59:32.368931Z","shell.execute_reply.started":"2022-06-29T19:59:26.318642Z","shell.execute_reply":"2022-06-29T19:59:32.367757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference ","metadata":{}},{"cell_type":"code","source":"df_sample = pd.read_csv('../input/hubmap-organ-segmentation/sample_submission.csv')\ndf_sample","metadata":{"execution":{"iopub.status.busy":"2022-06-29T18:10:37.937326Z","iopub.execute_input":"2022-06-29T18:10:37.937936Z","iopub.status.idle":"2022-06-29T18:10:37.965828Z","shell.execute_reply.started":"2022-06-29T18:10:37.937883Z","shell.execute_reply":"2022-06-29T18:10:37.964888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/temp/images_test","metadata":{"execution":{"iopub.status.busy":"2022-06-29T18:45:46.218256Z","iopub.execute_input":"2022-06-29T18:45:46.218858Z","iopub.status.idle":"2022-06-29T18:45:46.973886Z","shell.execute_reply.started":"2022-06-29T18:45:46.218822Z","shell.execute_reply":"2022-06-29T18:45:46.972464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1])])\n\nun_transforms = Compose([Resize(1024, 1024)])\nlist_pred = []\nlist_idx = []\n\nfor i,row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n    image_id = str(row['id'])\n    im = plt.imread(os.path.join(\"../input/hubmap-organ-segmentation/test_images\", str(image_id) + \".tiff\"))\n    tiles_img_pr, idxs = tile_image(os.path.join(\"../input/hubmap-organ-segmentation/test_images\", str(image_id) + \".tiff\"), \n                              \"/kaggle/temp/images_test\",1024)\n    for p_img, idx in zip(tiles_img_pr, idxs):\n        img = cv2.imread(p_img).astype('float32')\n        img_trans = transforms(image=img)\n        x_tensor = torch.tensor(img_trans['image']).to('cuda').permute(2,0,1)\n        pr_mask = model.predict(x_tensor.unsqueeze(0))\n        pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n        pr_mask = un_transforms(image=pr_mask)\n        pr_mask = pr_mask[\"image\"]\n        list_pred.append((pr_mask))\n        list_idx.append((idx))\n\n        visualize(\n            imagen=img[:,:,0], \n            predicted_mask=pr_mask\n        )\n        \n    seg = np.zeros(im.shape[:2], dtype=np.uint8)\n    for tile, (i1, i2, j1, j2) in zip(list_pred, list_idx):\n        i2 = min(i2, im.shape[0])\n        j2 = min(j2, im.shape[1])\n        seg[i1:i2, j1:j2] = tile[:(i2 - i1), :(j2 - j1)]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:28:27.737843Z","iopub.execute_input":"2022-06-29T21:28:27.738867Z","iopub.status.idle":"2022-06-29T21:28:30.24168Z","shell.execute_reply.started":"2022-06-29T21:28:27.738816Z","shell.execute_reply":"2022-06-29T21:28:30.240753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize(\n            original=im,\n            imagen=seg, \n        )","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:35:48.947095Z","iopub.execute_input":"2022-06-29T21:35:48.947979Z","iopub.status.idle":"2022-06-29T21:35:49.880729Z","shell.execute_reply.started":"2022-06-29T21:35:48.947934Z","shell.execute_reply":"2022-06-29T21:35:49.879771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}