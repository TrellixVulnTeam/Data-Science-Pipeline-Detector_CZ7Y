{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Description\n\nThe cost of some drugs and medical treatments has risen so high in recent years that many patients are having to go without. You can help with a classification project that could make researchers more efficient.\n\nOne of the more surprising reasons behind the cost is how long it takes to bring new treatments to market. Despite improvements in technology and science, research and development continues to lag. In fact, finding new treatments takes, on average, more than 10 years and costs hundreds of millions of dollars.\n\nRecursion Pharmaceuticals, creators of the industryâ€™s largest dataset of biological images, generated entirely in-house, believes AI has the potential to dramatically improve and expedite the drug discovery process. More specifically, your efforts could help them understand how drugs interact with human cells."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('/kaggle/input/'))\n# for dirname, _, filenames in os.walk('/kaggle/input/'):\n#     print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nprint(os.listdir('/kaggle/input/train/HUVEC-06/'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# img = mpimg.imread('/kaggle/input/train/HUVEC-06/Plate1/O16_s2_w6.png')\n# plt.imshow(img)\nimport csv\ndf = pd.read_csv('/kaggle/input/train.csv')\ndf.head()\nnum = np.random.random_integers(3000)\npath = '/kaggle/input/train/' + df['experiment'][num] + '/Plate' + str(df['plate'][num]) + '/'\n_ = os.listdir(path)\nimg = mpimg.imread(path + _[np.random.random_integers(len(_))])\n# img[np.where(img<0.1)] = 0.1\nprint(img.min(),img.max())\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ! pip install --upgrade tensorflow==2.0.0-beta1\n# ! pip install --upgrade tf-nightly-2.0-preview\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', \n                           # activity_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01), \n                           input_shape=(300,300,3)),\n    # tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.Dense(33,activation='softmax')\n])\n\nhistory = model.compile(\n                        optimizer=tf.keras.optimizers.Adam(lr=1e-3), \n                        # optimizer=tf.keras.optimizers.Adadelta(lr=1e-0),\n                        # optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n                        # loss='categorical_crossentropy', metrics=['acc'])\n                        loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_DIR = '/kaggle/input/train/'\n\n\ntrain_datagen = ImageDataGenerator(\n    # rescale = 1./255,\n    rotation_range=90,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n                                                    batch_size=500,\n                                                    class_mode='sparse',\n                                                    target_size=(300,300)\n)\n\nVALIDATION_DIR = '/kaggle/input/test/'\nvalidation_datagen = ImageDataGenerator(\n    # rescale = 1./255,\n    rotation_range=90,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                    batch_size=50,\n                                                    class_mode='sparse',\n                                                    target_size=(300,300)\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,\n                              # steps_per_epoch=2,\n                              epochs=3, \n                              verbose=1, \n                              # validation_steps=1,\n                              validation_data=validation_generator\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['sparse_categorical_accuracy']\nval_acc=history.history['val_sparse_categorical_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_sparse_categorical_accuracy']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.grid('True')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.grid('True')\nplt.figure()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}