{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch.utils.data as D\nfrom PIL import Image\nfrom torchvision import transforms,models\n\nclass ImagesDS(D.Dataset):\n    def __init__(self, df, site=1, channels=[1,2,3,4,5,6]):\n        self.records = df.to_records(index=False)\n        self.channels = channels\n        self.site = site\n        self.img_dir = '../input'\n        self.len = df.shape[0]\n        \n    @staticmethod\n    def _load_img_as_tensor(file_name):\n        with Image.open(file_name) as img:\n            img = transforms.Resize((224,224))(img)\n            img = transforms.CenterCrop(224)(img)\n            return transforms.ToTensor()(img)\n\n    def _get_img_path(self, index, channel):\n        experiment, well, plate = self.records[index].experiment, self.records[index].well, self.records[index].plate\n        return '/'.join([self.img_dir,'train',experiment,f'Plate{plate}',f'{well}_s{self.site}_w{channel}.png'])\n        \n    def __getitem__(self, index):\n        paths = [self._get_img_path(index, ch) for ch in self.channels]\n        img = torch.cat([self._load_img_as_tensor(img_path) for img_path in paths])\n        return img, int(self.records[index].sirna)\n\n    def __len__(self):\n        return self.len\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/train.csv')\ntrain1 = ImagesDS(df)\ntrain2 = ImagesDS(df,site=2)\ntrainset = D.ConcatDataset([train1,train2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\nimport torch\n\ndataset_size = len(trainset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(0.2 * dataset_size))\nnp.random.seed(42)\nnp.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=32, \n                                           sampler=train_sampler,num_workers=4)\nval_loader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                                sampler=valid_sampler,num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import optim,nn\nmodel = models.densenet201(pretrained=True)\nmodel.features.conv0 = nn.Conv2d(6,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\nmodel.classifier = nn.Sequential(nn.BatchNorm1d(1920),\n                                nn.Linear(1920,1108),\n                                nn.LogSoftmax(dim=1))\ndevice = torch.device(\"cuda:0\")\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\noptimizer = optim.Adam(model.parameters(),lr=0.003)\ncriterion = nn.CrossEntropyLoss()\nepochs = 13\nfor i in range(epochs):\n    tr_loss = 0\n    v_loss = 0\n    for im,y in train_loader:\n        im,y = im.to(device),y.to(device)\n        optimizer.zero_grad()\n        output = model(im)\n        p_y = torch.exp(output)\n        loss = criterion(output,y)\n        loss.backward()\n        optimizer.step()\n        tr_loss+=loss.item()\n    with torch.no_grad():\n        model.eval()\n        for im,y in val_loader:\n            im,y=im.to(device),y.to(device)\n            output = model(im)\n            p_y = torch.exp(output)\n            loss = criterion(output,y)\n            v_loss+=loss.item()\n        model.train()\n    print(f'Epoch:{i+1}  TrainLoss;{tr_loss/len(train_loader)}  ValLoss:{v_loss/len(val_loader)}')\n    #print(f'TrainAccuracy:{acc} ValAcc:{vacc}')\n    print('---------------------------------------------------------------------------------------------')\n    \ntorch.save(model,'./model.pth')\n\n        \n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}