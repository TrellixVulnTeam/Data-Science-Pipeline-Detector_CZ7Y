{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install huggingface-hub\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:29.716166Z","iopub.execute_input":"2021-06-11T15:03:29.716579Z","iopub.status.idle":"2021-06-11T15:03:42.799397Z","shell.execute_reply.started":"2021-06-11T15:03:29.716467Z","shell.execute_reply":"2021-06-11T15:03:42.798334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T15:03:42.80135Z","iopub.execute_input":"2021-06-11T15:03:42.80173Z","iopub.status.idle":"2021-06-11T15:03:42.811385Z","shell.execute_reply.started":"2021-06-11T15:03:42.801688Z","shell.execute_reply":"2021-06-11T15:03:42.810479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nimport random\nfrom torch.utils.tensorboard import SummaryWriter\n\n# specify GPU\ndevice = torch.device(\"cuda\")\n\ntorch.manual_seed(1)\nrandom.seed(24)\nnp.random.seed(42)\n\n\nclass regressor_stratified:\n    def __init__(self,n_splits=1,group_count=10,random_state=42,strategy='quantile',val_size=0.2):\n        self.group_count=group_count\n        self.strategy=strategy\n        self.cvkwargs=dict(n_splits=n_splits,test_size=val_size,random_state=random_state)\n        self.cv=StratifiedShuffleSplit(**self.cvkwargs)\n        self.discretizer=KBinsDiscretizer(n_bins=self.group_count,encode='ordinal',strategy=self.strategy)  \n            \n    def split(self,X,y,groups=None):\n        kgroups=self.discretizer.fit_transform(y[:,None])[:,0]\n        return self.cv.split(X,kgroups,groups)\n    \n    def get_n_splits(self,X,y,groups=None):\n        return self.cv.get_n_splits(X,y,groups)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:42.813558Z","iopub.execute_input":"2021-06-11T15:03:42.814052Z","iopub.status.idle":"2021-06-11T15:03:45.235079Z","shell.execute_reply.started":"2021-06-11T15:03:42.814013Z","shell.execute_reply":"2021-06-11T15:03:45.234232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ..\ndf = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\ndf.loc[:, ['target']].plot(kind='kde')\nprint(df.excerpt[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:45.238563Z","iopub.execute_input":"2021-06-11T15:03:45.238832Z","iopub.status.idle":"2021-06-11T15:03:46.276381Z","shell.execute_reply.started":"2021-06-11T15:03:45.238804Z","shell.execute_reply":"2021-06-11T15:03:46.275004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show excerpts lenghts\nseq_len = [len(i.split()) for i in df.excerpt]\npd.Series(seq_len).hist(bins = 30)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:46.277828Z","iopub.execute_input":"2021-06-11T15:03:46.278179Z","iopub.status.idle":"2021-06-11T15:03:46.500375Z","shell.execute_reply.started":"2021-06-11T15:03:46.278139Z","shell.execute_reply":"2021-06-11T15:03:46.499461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitter = regressor_stratified(group_count=10,random_state=42,strategy='uniform')\ngenerator = splitter.split(df[['excerpt']], df['target'])\n\nfor train, val in generator:\n    train_df = df.loc[df.index.isin(train)]\n    train_df.target.plot(kind='kde')\n    \n    val_df = df.loc[df.index.isin(val)]\n    val_df.target.plot(kind='kde')\n\nprint(len(train_df), len(val_df))\nval_df.head(1)\n\n# train_X, val_X = train_df['excerpt'], val_df['excerpt']\n# train_y, val_y = train_df['target'], val_df['target']\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:46.501737Z","iopub.execute_input":"2021-06-11T15:03:46.502108Z","iopub.status.idle":"2021-06-11T15:03:46.734961Z","shell.execute_reply.started":"2021-06-11T15:03:46.50207Z","shell.execute_reply":"2021-06-11T15:03:46.734175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport random\n\n\ndef convert_examples_to_features(text, tokenizer, max_len):\n\n    tok = tokenizer.encode_plus(\n        text, \n        max_length=max_len, \n        truncation=True,\n        padding='max_length',\n        return_attention_mask=True,\n    )\n    return tok\n\n\nclass CLRDataset(Dataset):\n    def __init__(self, data, tokenizer, max_len, is_test=False):\n        self.data = data\n        self.excerpts = self.data.excerpt.tolist()\n        if not is_test:\n            self.targets = self.data.target.tolist()\n        self.tokenizer = tokenizer\n        self.is_test = is_test\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, item):\n        if not self.is_test:\n            excerpt, label = self.excerpts[item], self.targets[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer, self.max_len\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n                'label':torch.tensor(label, dtype=torch.float),\n            }\n        else:\n            excerpt = self.excerpts[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer, self.max_len\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n            }","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:46.736299Z","iopub.execute_input":"2021-06-11T15:03:46.736665Z","iopub.status.idle":"2021-06-11T15:03:46.748958Z","shell.execute_reply.started":"2021-06-11T15:03:46.736627Z","shell.execute_reply":"2021-06-11T15:03:46.747963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer \nmodel_name = \"bert-large-cased\" \n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntorch.save(tokenizer, 'tokenizer.pt')\n\ntrain_ds = CLRDataset(data=train_df, tokenizer=tokenizer, max_len=256)\nval_ds = CLRDataset(data=val_df, tokenizer=tokenizer, max_len=256)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:46.752592Z","iopub.execute_input":"2021-06-11T15:03:46.753041Z","iopub.status.idle":"2021-06-11T15:03:50.806513Z","shell.execute_reply.started":"2021-06-11T15:03:46.753006Z","shell.execute_reply":"2021-06-11T15:03:50.805613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = AutoModel.from_pretrained(model_name)  ","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:03:50.808307Z","iopub.execute_input":"2021-06-11T15:03:50.808709Z","iopub.status.idle":"2021-06-11T15:05:00.540494Z","shell.execute_reply.started":"2021-06-11T15:03:50.808665Z","shell.execute_reply":"2021-06-11T15:05:00.53948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 8\n\n# train_data = TensorDataset(train_seq, train_mask, train_y)\ntrain_sampler = RandomSampler(train_ds)\ntrain_dataloader = DataLoader(train_ds, sampler=train_sampler, batch_size=batch_size)\n\n# val_data = TensorDataset(val_seq, val_mask, val_y)\nval_sampler = SequentialSampler(val_ds)\nval_dataloader = DataLoader(val_ds, sampler = val_sampler, batch_size=batch_size)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:06:06.53454Z","iopub.execute_input":"2021-06-11T15:06:06.534922Z","iopub.status.idle":"2021-06-11T15:06:06.543155Z","shell.execute_reply.started":"2021-06-11T15:06:06.534888Z","shell.execute_reply":"2021-06-11T15:06:06.542253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERT_Arch(nn.Module):\n\n    def __init__(self, bert):\n        super(BERT_Arch, self).__init__()\n        self.bert = bert\n        self.relu =  nn.ReLU()\n        self.fc1 = nn.Linear(1024,512)\n        self.fc2 = nn.Linear(512,256)\n        self.fc3 = nn.Linear(256, 1)\n\n    def forward(self, sent_id, mask):\n        output = self.bert(sent_id, attention_mask=mask)\n        x = self.relu(self.fc1(output[1]))\n        x = self.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:05:00.551063Z","iopub.execute_input":"2021-06-11T15:05:00.551698Z","iopub.status.idle":"2021-06-11T15:05:00.562067Z","shell.execute_reply.started":"2021-06-11T15:05:00.551657Z","shell.execute_reply":"2021-06-11T15:05:00.56111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\nmodel = BERT_Arch(bert_model)\nmodel = model.to(device)\noptimizer = AdamW(model.parameters(),\n                  lr = 2e-5)   \nepochs = 15\n\ncriterion = nn.MSELoss() \n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:08:41.93602Z","iopub.execute_input":"2021-06-11T15:08:41.936401Z","iopub.status.idle":"2021-06-11T15:08:41.97655Z","shell.execute_reply.started":"2021-06-11T15:08:41.936356Z","shell.execute_reply":"2021-06-11T15:08:41.975705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:08:43.006602Z","iopub.execute_input":"2021-06-11T15:08:43.006928Z","iopub.status.idle":"2021-06-11T15:08:43.731886Z","shell.execute_reply.started":"2021-06-11T15:08:43.006898Z","shell.execute_reply":"2021-06-11T15:08:43.730917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n  \n  model.train()\n  total_loss = 0\n    \n  for step,batch in enumerate(train_dataloader):\n    \n#     batch = [r.to(device) for r in batch]\n    sent_id, mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device), \n    model.zero_grad()      \n    preds = model(sent_id, mask)\n    loss = torch.sqrt(criterion(preds, labels.unsqueeze(1)))\n    total_loss = total_loss + loss.item()\n    loss.backward()\n    optimizer.step()\n\n  avg_loss = total_loss / len(train_dataloader)\n\n  return avg_loss\n\n\ndef evaluate():\n  model.eval()\n  total_loss = 0\n\n  for step,batch in enumerate(val_dataloader):\n#     batch = [t.to(device) for t in batch]\n    sent_id, mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n    with torch.no_grad():\n      preds = model(sent_id, mask)\n      loss = torch.sqrt(criterion(preds,labels.unsqueeze(1)))\n      total_loss = total_loss + loss.item()\n\n  avg_loss = total_loss / len(val_dataloader) \n  return avg_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:08:40.268166Z","iopub.execute_input":"2021-06-11T15:08:40.268544Z","iopub.status.idle":"2021-06-11T15:08:40.277579Z","shell.execute_reply.started":"2021-06-11T15:08:40.268505Z","shell.execute_reply":"2021-06-11T15:08:40.276578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_valid_loss = float('inf')\n\ntrain_losses=[]\nvalid_losses=[]\ntb = SummaryWriter()\n\nfor epoch in range(epochs):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    train_loss = train()\n    valid_loss = evaluate()\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.cpu(), f'bert_reg_best_model.pt')\n        model.to(device)\n        \n        print('saving model with loss', valid_loss)\n        \n        \n    tb.add_scalar(\"train loss\", train_loss, epoch)\n    tb.add_scalar(\"valid loss\", valid_loss, epoch)\n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')\n    \ntb.flush()\ntb.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:08:46.635498Z","iopub.execute_input":"2021-06-11T15:08:46.635853Z","iopub.status.idle":"2021-06-11T16:06:33.815023Z","shell.execute_reply.started":"2021-06-11T15:08:46.635819Z","shell.execute_reply":"2021-06-11T16:06:33.813967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\n\ngpu_usage()                             \n\nimport gc\ndel model\ngc.collect()\n\ntorch.cuda.empty_cache()\ngpu_usage()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:08:13.779178Z","iopub.execute_input":"2021-06-11T15:08:13.779574Z","iopub.status.idle":"2021-06-11T15:08:19.657681Z","shell.execute_reply.started":"2021-06-11T15:08:13.779531Z","shell.execute_reply":"2021-06-11T15:08:19.655926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nall_preds = []\nfor step,batch in enumerate(val_dataloader):\n    batch = [t.to(device) for t in batch]\n    sent_id, mask, labels = batch\n    with torch.no_grad():\n        preds = model(sent_id, mask)\n        all_preds += preds.flatten().cpu().tolist()\n        \nprint(len(all_preds))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:05:14.44459Z","iopub.status.idle":"2021-06-11T15:05:14.445192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df = pd.DataFrame(data={\n    'id': val_df.id,\n    'target': val_df.target,\n    'preds': S\n}).set_index('id')\n\nresult_df.to_csv('bert_preds.csv', index_label='id')\n!head bert_preds.csv\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:05:14.446423Z","iopub.status.idle":"2021-06-11T15:05:14.447101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torch.optim import Adam\n\n# for name, param in model.bert.named_parameters():\n#     param.requires_grads = False\n    \n# optimizer = AdamW(model.parameters(),\n#                   lr = 2e-6)   \n# epochs = 10\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:05:14.448309Z","iopub.status.idle":"2021-06-11T15:05:14.449062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = torch.load('bert_reg_528.pt')\n# model.cuda()\n# evaluate()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:05:14.450319Z","iopub.status.idle":"2021-06-11T15:05:14.45102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n# test_df.head()\n\n# tokenizer = torch.load('tokenizer.pt')\n# device = 'cpu'\n# test_X = test_df['excerpt']\n# tokens_test = tokenizer.batch_encode_plus(\n#     test_X.tolist(),\n#     max_length = 180,\n#     pad_to_max_length=True,\n#     truncation=True\n# )\n\n# test_seq = torch.tensor(tokens_test['input_ids']).to(device)\n# test_mask = torch.tensor(tokens_test['attention_mask']).to(device)\n\n# model = torch.load('bert_reg_539.pt')\n\n# model.eval()\n# with torch.no_grad():\n#   preds = model(test_seq, test_mask)\n\n# result_df = pd.DataFrame({\n#     'id': test_df.id,\n#     'target': preds.squeeze().tolist()})\n\n\n\n# result_df.to_csv('submission.csv')\n# result_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:05:14.452602Z","iopub.status.idle":"2021-06-11T15:05:14.453393Z"},"trusted":true},"execution_count":null,"outputs":[]}]}