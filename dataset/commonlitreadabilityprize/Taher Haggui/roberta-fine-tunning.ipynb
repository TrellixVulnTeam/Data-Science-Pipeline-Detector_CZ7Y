{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport pandas as pd \nimport numpy as np \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport re \nimport random\nimport torch.nn as nn \nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset,DataLoader\nfrom transformers import AutoModel,AutoTokenizer,AdamW\nfrom tqdm import tqdm\nimport os \nfrom transformers import get_cosine_schedule_with_warmup\nfrom colorama import Fore,Back,Style\nr_ = Fore.RED\ng_ = Fore.GREEN\ny_ = Fore.YELLOW\nc_ = Fore.CYAN\nb_ = Fore.BLUE\nbl_ = Fore.BLACK\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:25.14727Z","iopub.execute_input":"2021-06-22T10:40:25.147659Z","iopub.status.idle":"2021-06-22T10:40:32.580262Z","shell.execute_reply.started":"2021-06-22T10:40:25.147582Z","shell.execute_reply":"2021-06-22T10:40:32.579459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.581718Z","iopub.execute_input":"2021-06-22T10:40:32.582059Z","iopub.status.idle":"2021-06-22T10:40:32.669091Z","shell.execute_reply.started":"2021-06-22T10:40:32.582024Z","shell.execute_reply":"2021-06-22T10:40:32.668349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(excerpt):\n    punctuations = \".,?!;\\(\\\":-)â€˜\"\n    extrait = excerpt\n    for p in punctuations : \n      extrait = extrait.replace(p,f\" {p} \")\n    extrait = re.sub(r\"'s\",\" is \",extrait)\n    extrait = extrait.replace(\"i'm\",\"I'm\")\n    extrait = extrait.replace(\"don't\",\"do not\")\n    extrait = extrait.replace(\"didn't\",\"did not\")\n    extrait = extrait.replace(\"can't\",\"cannot\")\n    extrait = extrait.replace(\"i'll\",\"I will\")\n    extrait = extrait.replace(\"wouldn't\",\"would not\")\n    extrait = extrait.replace(\"i've\",\"I have\")\n    extrait = re.sub(r\"i've\",\"I have\",extrait)\n    extrait = extrait.replace(\"won't\",\"will not\")\n    extrait = extrait.replace(\"couldn't\",\"could not\")\n    extrait = extrait.replace(\"wasn't\",\"was not\")\n    extrait = extrait.replace(\"you'll\",\"you will\")\n    extrait = extrait.replace(\"isn't\",\"is not\")\n    extrait = extrait.replace(\"you're\",\"you are\")\n    extrait = extrait.replace(\"hadn't\",\"had not\")\n    extrait = extrait.replace(\"you've\",\"you have\")\n    extrait = extrait.replace(\"doesn't\",\"does not\")\n    extrait = extrait.replace(\"haven't\",\"have not\")\n    extrait = extrait.replace(\"they're\",\"they are\")\n    extrait = extrait.replace(\"we're\",\"we are\")\n    #extrait = re.sub(r\"(/s+)i(/s+)\",\"I\",excerpt)\n    #extrait = re.sub(r\"don't\",\"do not\",extrait)\n    #extrait = re.sub(r\"i'm\",\"I'm\",extrait)\n    #extrait = re.sub(r\"man's\",\"man is\",extrait)\n    #extrait = re.sub(r\"it's\",\"it is\",extrait)\n    #extrait = re.sub(r\"didn't\",\"did not\",extrait)\n    #extrait = re.sub(r\"can't\",\"cannot\",extrait)\n    #extrait = re.sub(r\"earth's\",\"earth is\",extrait)\n    #extrait = re.sub(r\"father's\",\"father is\",extrait)\n    #extrait = re.sub(r\"i'll\",\"I will\",extrait)\n    #extrait = re.sub(r\"i've\",\"I have\",extrait)\n    #extrait = re.sub(r\"i\\'\",r\"I'\",extrait)\n    #extrait = re.sub(r\"children\\'s\",\"children is\",extrait)\n    \n    return extrait ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.670921Z","iopub.execute_input":"2021-06-22T10:40:32.67126Z","iopub.status.idle":"2021-06-22T10:40:32.682161Z","shell.execute_reply.started":"2021-06-22T10:40:32.671225Z","shell.execute_reply":"2021-06-22T10:40:32.681374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[\"cleaned_excerpt\"] = train_data[\"excerpt\"].map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.683643Z","iopub.execute_input":"2021-06-22T10:40:32.684002Z","iopub.status.idle":"2021-06-22T10:40:32.803138Z","shell.execute_reply.started":"2021-06-22T10:40:32.683967Z","shell.execute_reply":"2021-06-22T10:40:32.802448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    vars() [f\"q{i}\"] = train_data[\"target\"].quantile(0.25 * i)\n    if i == 0 :\n        vars() [f\"q{i}\"] = vars() [f\"q{i}\"] - 1\ntrain_data[\"bins_target\"] = pd.cut(train_data[\"target\"],bins=[q0,q1,q2,q3,q4],\\\n                                  labels=[f\"Q{i}\" for i in range(1,5)])","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.804223Z","iopub.execute_input":"2021-06-22T10:40:32.804569Z","iopub.status.idle":"2021-06-22T10:40:32.822514Z","shell.execute_reply.started":"2021-06-22T10:40:32.804535Z","shell.execute_reply":"2021-06-22T10:40:32.821678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nconfig = {\"seed\":42,\n         \"lr\":5e-5,\n         \"wd\":0.01,\n         \"epochs\":5,\n         \"folds\":5,\n         \"batch_size\":16,\n         \"max_len\":256,\n         \"valid_step\":10,\n         \"model\":\"../input/roberta-training/clrp_roberta_base_chk/checkpoint-1050/config.json\"}\n\nloss_fn = lambda out,true_v : torch.sqrt(nn.MSELoss()(out.view(-1),true_v.view(-1)))\n\nst = StratifiedKFold(n_splits=5,shuffle=True,random_state=config[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.823784Z","iopub.execute_input":"2021-06-22T10:40:32.824104Z","iopub.status.idle":"2021-06-22T10:40:32.831285Z","shell.execute_reply.started":"2021-06-22T10:40:32.824072Z","shell.execute_reply":"2021-06-22T10:40:32.830297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(Dataset) :\n    \n    def __init__(self,texts,labels,tokenizer,max_len):\n        super(DataGenerator,self).__init__()\n        self.tokenizer = tokenizer \n        self.max_len = max_len \n        self.texts = texts\n        self.labels = labels\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self,item):\n        encode = self.tokenizer(self.texts[item],return_tensors=\"pt\",max_length=self.max_len,\\\n                               padding =\"max_length\",truncation = True)\n        target = torch.tensor(self.labels[item],dtype=torch.float)\n        \n        return encode,target \n            \n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.832544Z","iopub.execute_input":"2021-06-22T10:40:32.833109Z","iopub.status.idle":"2021-06-22T10:40:32.841153Z","shell.execute_reply.started":"2021-06-22T10:40:32.833071Z","shell.execute_reply":"2021-06-22T10:40:32.840395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module) :\n    def __init__(self,in_features,hidden_dim,num_target):\n        super(AttentionHead,self).__init__()\n        self.in_features = in_features \n        self.hidden_dim = hidden_dim \n        self.num_target = num_target \n        self.W = nn.Linear(in_features,hidden_dim)\n        self.V = nn.Linear(hidden_dim,1)\n    def forward(self,features) :\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score,dim=1)\n        context_vector = attention_weights * features \n        context_vector = torch.sum(context_vector,axis=1)\n        \n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.843439Z","iopub.execute_input":"2021-06-22T10:40:32.843845Z","iopub.status.idle":"2021-06-22T10:40:32.850778Z","shell.execute_reply.started":"2021-06-22T10:40:32.843811Z","shell.execute_reply":"2021-06-22T10:40:32.849967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class roberta(nn.Module) :\n    \n    def __init__(self,path):\n        super(roberta,self).__init__()\n        self.pret_layer = AutoModel.from_pretrained(path,output_hidden_states = True)\n        self.dropout = nn.Dropout(p=0.1)\n        #self.batch_n = nn.BatchNorm2d()\n        self.linear = nn.Linear(768,1)\n        self.att = AttentionHead(768,768,1)\n    def forward(self,**xd):\n        x = self.pret_layer(**xd)[0]\n        x = self.att(x)\n        x = self.dropout(x)\n        x = self.linear(x)\n        return x ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.852371Z","iopub.execute_input":"2021-06-22T10:40:32.853046Z","iopub.status.idle":"2021-06-22T10:40:32.862919Z","shell.execute_reply.started":"2021-06-22T10:40:32.853009Z","shell.execute_reply":"2021-06-22T10:40:32.862059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"We use cuda device\")\nelse :\n    device = torch.device(\"cpu\")\n    print(\"No cuda is available , we use CPU instead !\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:40:32.864191Z","iopub.execute_input":"2021-06-22T10:40:32.864536Z","iopub.status.idle":"2021-06-22T10:40:32.921151Z","shell.execute_reply.started":"2021-06-22T10:40:32.864502Z","shell.execute_reply":"2021-06-22T10:40:32.920344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloader(texts,labels,tokenizer) :\n    dataset = DataGenerator(texts,labels,tokenizer,config[\"max_len\"])\n    dataloader = DataLoader(dataset,batch_size = config[\"batch_size\"],shuffle=False,\\\n                           num_workers = 4)\n    return dataloader\ndef train_and_evaluate_loop(tr_loader,val_loader,device,md,optimizer,best_loss,epoch,fold,tokenizer,\\\n                            verbose=True) :\n    train_loss = 0\n    for i,(inp_data ,inp_target) in enumerate(tr_loader) :\n        md.train()\n        optimizer.zero_grad()\n        #X_id,X_mask,Y = (t.to(device) for t in data)\n        inp_data = {key : vl.reshape(vl.shape[0],-1).to(device) for (key,vl) in inp_data.items()}\n        Y = inp_target.to(device)\n        # compute_prediction \n        output = md(**inp_data)\n        loss = loss_fn(output.float(),Y.float())\n        #backpropagation\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        \n        if (i+1) == len(tr_loader) :\n            \n            md.eval()\n            val_loss = 0\n            \n            for i , (dt_inp,dt_target) in enumerate(val_loader) :\n                #X_val,Y_val = (t.to(device) for t in dt)\n                Y_val = dt_target.to(device)\n                dt_inp = {key:val.reshape(val.shape[0],-1).to(device) for (key,val) in dt_inp.items()}\n                with torch.no_grad() :\n                    out = md(**dt_inp)\n                    loss_v = loss_fn(out.float(),Y_val.float())\n                    val_loss += loss_v \n            \n            val_loss /= len(val_loader)\n            \n            if verbose :\n                print(f\"Epoch {epoch} : | Train Loss : {train_loss/len(tr_loader)}\")\n                print(f\"Epoch {epoch} : | Val Loss : {val_loss}\")\n                if val_loss < best_loss :\n                    torch.save(md.state_dict(),f\"./model{fold}/model{fold}.bin\")\n                    tokenizer.save_pretrained(f\"./model{fold}\")\n                    print(f\"{g_}best validation loss decreased from {best_loss} to {val_loss}{sr_}\")\n                    best_loss = val_loss\n                      \n    return best_loss    \n    \ndef run(st,device,path=\"../input/roberta-training/clrp_roberta_base_chk/\") :\n    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n    for fold , (tr_ind,val_ind) in enumerate(st.split(train_data[\"cleaned_excerpt\"],\\\n                                                      train_data[\"bins_target\"])) :\n        \n        texts_tr = train_data.reset_index(drop=True).loc[tr_ind,\"cleaned_excerpt\"].values\n        texts_val = train_data.reset_index(drop=True).loc[val_ind,\"cleaned_excerpt\"].values\n    \n        labels_tr = train_data.reset_index(drop=True).loc[tr_ind,\"target\"].values\n        labels_val = train_data.reset_index(drop=True).loc[val_ind,\"target\"].values\n        \n        tr_dataloader = create_dataloader(texts_tr,labels_tr,tokenizer)\n        val_dataloader = create_dataloader(texts_val,labels_val,tokenizer)\n        \n        md = roberta(path).to(device)\n        opt = AdamW(md.parameters(),lr=config[\"lr\"],weight_decay=config[\"wd\"])\n        lr_scheduler = get_cosine_schedule_with_warmup(opt,num_warmup_steps=0,num_training_steps= 25 * len(tr_dataloader))\n        best_loss = float(\"inf\")\n        os.makedirs(f\"model{fold}\",exist_ok=True)\n        print(f\"{r_}Fold {fold} Starting ...{sr_}\")\n        for ep in tqdm(range(config[\"epochs\"])) :\n            print(\"=\"*100)\n            print(\" \"*35,f\"Epoch {ep+1} : Train & Validation \")\n            print(\"=\"*100)\n            best_loss = train_and_evaluate_loop(tr_dataloader,val_dataloader,device,md,opt,best_loss,ep+1,\\\n                                                fold,tokenizer)\n                      ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:41:40.917574Z","iopub.execute_input":"2021-06-22T10:41:40.91795Z","iopub.status.idle":"2021-06-22T10:41:40.93568Z","shell.execute_reply.started":"2021-06-22T10:41:40.917883Z","shell.execute_reply":"2021-06-22T10:41:40.934861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run(st,device)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T10:41:48.164013Z","iopub.execute_input":"2021-06-22T10:41:48.164347Z","iopub.status.idle":"2021-06-22T11:09:33.461741Z","shell.execute_reply.started":"2021-06-22T10:41:48.164315Z","shell.execute_reply":"2021-06-22T11:09:33.460807Z"},"trusted":true},"execution_count":null,"outputs":[]}]}