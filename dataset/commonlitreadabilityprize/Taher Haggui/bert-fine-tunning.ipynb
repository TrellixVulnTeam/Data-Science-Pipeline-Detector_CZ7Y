{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport warnings \nwarnings.filterwarnings(\"ignore\")\nfrom colorama import Fore , Style,Back\nimport re \nimport torch \nimport os \nimport torch.nn as nn \nfrom transformers import AutoModelForMaskedLM,AutoTokenizer,Trainer,LineByLineTextDataset,\\\nDataCollatorForLanguageModeling , TrainingArguments , AutoModel ,AdamW\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn.model_selection import StratifiedKFold\nimport random\nr_ = Fore.RED\ng_ = Fore.GREEN\ny_ = Fore.YELLOW\nst_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:23.514639Z","iopub.execute_input":"2021-06-27T10:24:23.514998Z","iopub.status.idle":"2021-06-27T10:24:31.799293Z","shell.execute_reply.started":"2021-06-27T10:24:23.514923Z","shell.execute_reply":"2021-06-27T10:24:31.798463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"batch_size\" : 16 ,\n    \"lr\" : 5e-5,\n    \"wb\" : 2e-5,\n    \"batch_size\" : 16,\n    \"max_len\" : 256,\n    \"fold\" : 5,\n    \"seed\" : 42,\n    \"epochs\" : 5\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:31.800654Z","iopub.execute_input":"2021-06-27T10:24:31.800967Z","iopub.status.idle":"2021-06-27T10:24:31.808405Z","shell.execute_reply.started":"2021-06-27T10:24:31.800934Z","shell.execute_reply":"2021-06-27T10:24:31.807517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:31.810741Z","iopub.execute_input":"2021-06-27T10:24:31.811052Z","iopub.status.idle":"2021-06-27T10:24:31.818788Z","shell.execute_reply.started":"2021-06-27T10:24:31.811028Z","shell.execute_reply":"2021-06-27T10:24:31.817981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(config[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:31.822006Z","iopub.execute_input":"2021-06-27T10:24:31.822368Z","iopub.status.idle":"2021-06-27T10:24:31.831711Z","shell.execute_reply.started":"2021-06-27T10:24:31.822335Z","shell.execute_reply":"2021-06-27T10:24:31.830807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:31.834651Z","iopub.execute_input":"2021-06-27T10:24:31.834888Z","iopub.status.idle":"2021-06-27T10:24:31.962319Z","shell.execute_reply.started":"2021-06-27T10:24:31.834866Z","shell.execute_reply":"2021-06-27T10:24:31.961476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(excerpt):\n    punctuations = \".,?!;\\(\\\":-)â€˜\"\n    extrait = excerpt\n    for p in punctuations : \n      extrait = extrait.replace(p,f\" {p} \")\n    extrait = re.sub(r\"'s\",\" is \",extrait)\n    extrait = extrait.replace(\"i'm\",\"I'm\")\n    extrait = extrait.replace(\"don't\",\"do not\")\n    extrait = extrait.replace(\"didn't\",\"did not\")\n    extrait = extrait.replace(\"can't\",\"cannot\")\n    extrait = extrait.replace(\"i'll\",\"I will\")\n    extrait = extrait.replace(\"wouldn't\",\"would not\")\n    extrait = extrait.replace(\"i've\",\"I have\")\n    extrait = re.sub(r\"i've\",\"I have\",extrait)\n    extrait = extrait.replace(\"won't\",\"will not\")\n    extrait = extrait.replace(\"couldn't\",\"could not\")\n    extrait = extrait.replace(\"wasn't\",\"was not\")\n    extrait = extrait.replace(\"you'll\",\"you will\")\n    extrait = extrait.replace(\"isn't\",\"is not\")\n    extrait = extrait.replace(\"you're\",\"you are\")\n    extrait = extrait.replace(\"hadn't\",\"had not\")\n    extrait = extrait.replace(\"you've\",\"you have\")\n    extrait = extrait.replace(\"doesn't\",\"does not\")\n    extrait = extrait.replace(\"haven't\",\"have not\")\n    extrait = extrait.replace(\"they're\",\"they are\")\n    extrait = extrait.replace(\"we're\",\"we are\")\n    #extrait = re.sub(r\"(/s+)i(/s+)\",\"I\",excerpt)\n    #extrait = re.sub(r\"don't\",\"do not\",extrait)\n    #extrait = re.sub(r\"i'm\",\"I'm\",extrait)\n    #extrait = re.sub(r\"man's\",\"man is\",extrait)\n    #extrait = re.sub(r\"it's\",\"it is\",extrait)\n    #extrait = re.sub(r\"didn't\",\"did not\",extrait)\n    #extrait = re.sub(r\"can't\",\"cannot\",extrait)\n    #extrait = re.sub(r\"earth's\",\"earth is\",extrait)\n    #extrait = re.sub(r\"father's\",\"father is\",extrait)\n    #extrait = re.sub(r\"i'll\",\"I will\",extrait)\n    #extrait = re.sub(r\"i've\",\"I have\",extrait)\n    #extrait = re.sub(r\"i\\'\",r\"I'\",extrait)\n    #extrait = re.sub(r\"children\\'s\",\"children is\",extrait)\n    \n    return extrait ","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:31.96547Z","iopub.execute_input":"2021-06-27T10:24:31.965734Z","iopub.status.idle":"2021-06-27T10:24:31.976962Z","shell.execute_reply.started":"2021-06-27T10:24:31.965708Z","shell.execute_reply":"2021-06-27T10:24:31.976163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"cleaned_excerpt\"] = train[\"excerpt\"].map(clean_text)\ntest[\"cleaned_excerpt\"] = test[\"excerpt\"].map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:31.979985Z","iopub.execute_input":"2021-06-27T10:24:31.98026Z","iopub.status.idle":"2021-06-27T10:24:32.109521Z","shell.execute_reply.started":"2021-06-27T10:24:31.980237Z","shell.execute_reply":"2021-06-27T10:24:32.108695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:32.113026Z","iopub.execute_input":"2021-06-27T10:24:32.11332Z","iopub.status.idle":"2021-06-27T10:24:34.076003Z","shell.execute_reply.started":"2021-06-27T10:24:32.113296Z","shell.execute_reply":"2021-06-27T10:24:34.075198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Lisibility(nn.Module) :\n    \n    def __init__(self,path):\n        super(Lisibility,self).__init__()\n        self.bert_layer = AutoModel.from_pretrained(path)\n        self.dropout = nn.Dropout(p=0.1)\n        self.dense = nn.Linear(768,1)\n    def forward(self,**x) :\n        x = self.bert_layer(**x)[0][:,0,:]\n        x = self.dropout(x)\n        x = self.dense(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.077681Z","iopub.execute_input":"2021-06-27T10:24:34.078042Z","iopub.status.idle":"2021-06-27T10:24:34.084885Z","shell.execute_reply.started":"2021-06-27T10:24:34.078002Z","shell.execute_reply":"2021-06-27T10:24:34.08378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator (Dataset) :\n    \n    def __init__(self,textes,labels,tokenizer,max_len) :\n        \n        self.textes = textes \n        self.labels = labels \n        self.tokenizer = tokenizer \n        self.max_len = max_len\n    def __getitem__(self,idx) :\n        \n        encode = self.tokenizer(self.textes[idx],return_tensors=\"pt\",max_length=self.max_len,\\\n                               padding=\"max_length\",truncation = True)\n        target = torch.tensor(self.labels[idx])\n        \n        return encode , target\n    \n    def __len__(self):\n        return len(self.textes)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.08626Z","iopub.execute_input":"2021-06-27T10:24:34.086667Z","iopub.status.idle":"2021-06-27T10:24:34.096462Z","shell.execute_reply.started":"2021-06-27T10:24:34.086628Z","shell.execute_reply":"2021-06-27T10:24:34.095109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"bins_target\"] = pd.cut(train[\"target\"],bins=[train[\"target\"].min()-1,train[\"target\"].\\\n                                                   quantile(0.25),train[\"target\"].quantile(0.5),train[\"target\"].quantile(0.75),train[\"target\"].quantile(1)],labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.097891Z","iopub.execute_input":"2021-06-27T10:24:34.098381Z","iopub.status.idle":"2021-06-27T10:24:34.120185Z","shell.execute_reply.started":"2021-06-27T10:24:34.098345Z","shell.execute_reply":"2021-06-27T10:24:34.11941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloader(texts,labels,tokenizer):\n    dataset = DataGenerator(texts,labels,tokenizer,config[\"max_len\"])\n    dataloader = DataLoader(dataset,batch_size = config[\"batch_size\"],num_workers=4,\\\n                            shuffle=False)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.121337Z","iopub.execute_input":"2021-06-27T10:24:34.121881Z","iopub.status.idle":"2021-06-27T10:24:34.127999Z","shell.execute_reply.started":"2021-06-27T10:24:34.121841Z","shell.execute_reply":"2021-06-27T10:24:34.126195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_validate(tr_dataloader,val_dataloader,model,device,loss_fn,optimizer,best_loss,\\\n                       epoch,fold,tokenizer,verbose=True):\n    train_loss = 0\n    for i, (tr_datas,tr_lab) in enumerate(tr_dataloader) :\n        model.train()\n        optimizer.zero_grad()\n        X = {key:val.reshape(val.shape[0],-1).to(device) for (key,val) \\\n                    in tr_datas.items()}\n        Y = tr_lab.to(device)\n        \n        # Compute output \n        out = model(**X)\n        loss = loss_fn(out.float(),Y.float())\n        \n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        \n        if (i+1) == len(tr_dataloader) : \n            val_loss = 0\n            for j,(val_datas,val_lab) in enumerate(val_dataloader):\n                model.eval()\n                with torch.no_grad() :\n                    X_val = {key:val.reshape(val.shape[0],-1).to(device) for (key,val)\\\n                            in val_datas.items()}\n                    Y_val = val_lab.to(device)\n                    \n                    output  = model(**X_val)\n                    \n                    loss = loss_fn(output.float(),Y_val.float())\n                    val_loss += loss.item()\n            val_loss /= len(val_dataloader)\n            train_loss /= len(tr_dataloader)\n            if verbose :\n                print(f\"Epoch: {epoch} | Train Loss : {train_loss}\")\n                print(f\"Epoch: {epoch} | Validation Loss :{val_loss}\")\n            \n                if val_loss < best_loss :\n                    print(f\"{g_}Validation loss decrease from {best_loss} to {val_loss}{st_}\")\n                    \n                    best_loss = val_loss\n                    torch.save(model.state_dict(),f\"./model_{fold}/model{fold}.bin\")\n                    tokenizer.save_pretrained(f\"./model_{fold}/\")\n                return best_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.129948Z","iopub.execute_input":"2021-06-27T10:24:34.130225Z","iopub.status.idle":"2021-06-27T10:24:34.144497Z","shell.execute_reply.started":"2021-06-27T10:24:34.130201Z","shell.execute_reply":"2021-06-27T10:24:34.143198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sp = StratifiedKFold(n_splits= config[\"fold\"],shuffle=True,random_state=config[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.145782Z","iopub.execute_input":"2021-06-27T10:24:34.146179Z","iopub.status.idle":"2021-06-27T10:24:34.156993Z","shell.execute_reply.started":"2021-06-27T10:24:34.14614Z","shell.execute_reply":"2021-06-27T10:24:34.156159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = lambda out,y_t : torch.sqrt(nn.MSELoss()(out.view(-1),y_t.view(-1)))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.160241Z","iopub.execute_input":"2021-06-27T10:24:34.16059Z","iopub.status.idle":"2021-06-27T10:24:34.165898Z","shell.execute_reply.started":"2021-06-27T10:24:34.160563Z","shell.execute_reply":"2021-06-27T10:24:34.164916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available() :\n    device = torch.device(\"cuda\")\nelse :\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.167206Z","iopub.execute_input":"2021-06-27T10:24:34.167697Z","iopub.status.idle":"2021-06-27T10:24:34.214909Z","shell.execute_reply.started":"2021-06-27T10:24:34.167661Z","shell.execute_reply":"2021-06-27T10:24:34.213901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/training-bert-models/bert_base_chk/\"","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:24:34.216278Z","iopub.execute_input":"2021-06-27T10:24:34.216866Z","iopub.status.idle":"2021-06-27T10:24:34.224434Z","shell.execute_reply.started":"2021-06-27T10:24:34.216826Z","shell.execute_reply":"2021-06-27T10:24:34.223636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold,(tr_ind,val_ind) in enumerate(sp.split(train[\"cleaned_excerpt\"],train[\"bins_target\"])):\n    \n    tr_texts = train.reset_index(drop=True).loc[tr_ind,\"cleaned_excerpt\"].values\n    tr_labels = train.reset_index(drop=True).loc[tr_ind,\"target\"].values\n    \n    val_texts = train.reset_index(drop=True).loc[val_ind,\"cleaned_excerpt\"].values\n    val_labels = train.reset_index(drop=True).loc[val_ind,\"target\"].values\n    \n    tr_dataloader = create_dataloader(tr_texts,tr_labels,tokenizer)\n    val_dataloader = create_dataloader(val_texts,val_labels,tokenizer)\n   \n    os.makedirs(f\"model_{fold}\",exist_ok = True)\n    md = Lisibility(path)\n    md.to(device) \n    optimizer = AdamW(md.parameters(),lr=config[\"lr\"],weight_decay=config[\"wb\"])\n    best_loss = float(\"inf\")\n    print(f\"{r_}Training model {fold} startings ...\\n{st_}\")\n    for ep in range(config[\"epochs\"]) : \n        print(\"=\"*100)\n        print(\" \" * 40 ,f\"Epoch{ep} : Train & Validation\")\n        best_loss = train_and_validate(tr_dataloader,val_dataloader,md,device,loss_fn,optimizer,best_loss,\\\n                       ep,fold,tokenizer,verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T10:27:31.606844Z","iopub.execute_input":"2021-06-27T10:27:31.607183Z","iopub.status.idle":"2021-06-27T10:54:51.34152Z","shell.execute_reply.started":"2021-06-27T10:27:31.607151Z","shell.execute_reply":"2021-06-27T10:54:51.340603Z"},"trusted":true},"execution_count":null,"outputs":[]}]}