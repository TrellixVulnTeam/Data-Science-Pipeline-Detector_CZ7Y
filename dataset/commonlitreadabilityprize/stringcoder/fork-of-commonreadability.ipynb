{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T09:54:41.659569Z","iopub.execute_input":"2021-06-28T09:54:41.659953Z","iopub.status.idle":"2021-06-28T09:54:41.672544Z","shell.execute_reply.started":"2021-06-28T09:54:41.659873Z","shell.execute_reply":"2021-06-28T09:54:41.671633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\n\nimport itertools\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport matplotlib\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nimport pandas as pd\nimport spacy as sp\nimport tensorflow as tf\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:54:41.674227Z","iopub.execute_input":"2021-06-28T09:54:41.674678Z","iopub.status.idle":"2021-06-28T09:54:48.993396Z","shell.execute_reply.started":"2021-06-28T09:54:41.674631Z","shell.execute_reply":"2021-06-28T09:54:48.992593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\").drop(columns=['url_legal', 'license', 'id'])\nt_df=pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\").drop(columns=['url_legal', 'license', 'id'])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:54:48.995038Z","iopub.execute_input":"2021-06-28T09:54:48.995409Z","iopub.status.idle":"2021-06-28T09:54:49.081522Z","shell.execute_reply.started":"2021-06-28T09:54:48.995374Z","shell.execute_reply":"2021-06-28T09:54:49.080762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load large English spacy model\nnlp = sp.load('en_core_web_lg')\n\n# get spacy embeddings for training data\nwith nlp.disable_pipes():\n    train_vectors = pd.DataFrame(\n        np.array([nlp(text).vector for text in df['excerpt']])\n    )\n    \n# get spacy embeddings for test data\nwith nlp.disable_pipes():\n    test_vectors = pd.DataFrame(\n        np.array([nlp(text).vector for text in t_df['excerpt']])\n    )","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:54:49.083813Z","iopub.execute_input":"2021-06-28T09:54:49.084164Z","iopub.status.idle":"2021-06-28T09:56:17.890726Z","shell.execute_reply.started":"2021-06-28T09:54:49.084129Z","shell.execute_reply":"2021-06-28T09:56:17.889873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import layers, Input, Model\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras import models, regularizers, optimizers\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, Input, concatenate\nfrom keras.models import Sequential, save_model\nfrom keras.utils import np_utils\nimport tensorflow as tf\nfrom keras.callbacks import EarlyStopping\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils import class_weight\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.metrics import log_loss\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom numpy import array\nfrom numpy import hstack\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:56:17.891951Z","iopub.execute_input":"2021-06-28T09:56:17.892283Z","iopub.status.idle":"2021-06-28T09:56:18.184043Z","shell.execute_reply.started":"2021-06-28T09:56:17.892249Z","shell.execute_reply":"2021-06-28T09:56:18.183263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Reshape\nfrom tensorflow.keras import Sequential, Model, callbacks\nfrom tensorflow.keras.layers import Dense, Conv2DTranspose, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import ResNet50\n\n# imports for the dataset\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\ndef create_model(num_columns):\n    model = Sequential()\n    model.add(Input(num_columns))\n    model.add(BatchNormalization())\n    model.add(Dense(units=250, kernel_initializer='glorot_uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.1))\n    model.add(Dense(units=200, kernel_initializer='glorot_uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.1))\n    model.add(Dense(units=200, kernel_initializer='glorot_uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n    model.add(Dense(units=100, kernel_initializer='glorot_uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n    model.add(Dense(units=50, kernel_initializer='glorot_uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(units=25,activation='linear'))\n    model.add(BatchNormalization())\n    model.add(Dense(units=1,activation='linear'))\n    opt = tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10)\n    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:05:26.986372Z","iopub.execute_input":"2021-06-28T10:05:26.986698Z","iopub.status.idle":"2021-06-28T10:05:26.998189Z","shell.execute_reply.started":"2021-06-28T10:05:26.986668Z","shell.execute_reply":"2021-06-28T10:05:26.997071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = None\nmodel = create_model(300)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:11:54.495312Z","iopub.execute_input":"2021-06-28T10:11:54.49564Z","iopub.status.idle":"2021-06-28T10:11:54.652344Z","shell.execute_reply.started":"2021-06-28T10:11:54.495612Z","shell.execute_reply":"2021-06-28T10:11:54.65146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x = train_vectors, \n    y = df['target'], \n    validation_split = 0.2, \n    batch_size = 512,\n    epochs = 1200,\n    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, mode='min')],\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:11:59.341807Z","iopub.execute_input":"2021-06-28T10:11:59.342274Z","iopub.status.idle":"2021-06-28T10:13:01.748958Z","shell.execute_reply.started":"2021-06-28T10:11:59.342233Z","shell.execute_reply":"2021-06-28T10:13:01.748186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=model.predict(test_vectors)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:13:29.535116Z","iopub.execute_input":"2021-06-28T10:13:29.535461Z","iopub.status.idle":"2021-06-28T10:13:29.710426Z","shell.execute_reply.started":"2021-06-28T10:13:29.535433Z","shell.execute_reply":"2021-06-28T10:13:29.709459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=pd.read_csv(r\"../input/commonlitreadabilityprize/sample_submission.csv\", usecols=[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:13:32.691818Z","iopub.execute_input":"2021-06-28T10:13:32.692169Z","iopub.status.idle":"2021-06-28T10:13:32.703586Z","shell.execute_reply.started":"2021-06-28T10:13:32.692138Z","shell.execute_reply":"2021-06-28T10:13:32.70248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['target']=y","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:13:35.02175Z","iopub.execute_input":"2021-06-28T10:13:35.022114Z","iopub.status.idle":"2021-06-28T10:13:35.027136Z","shell.execute_reply.started":"2021-06-28T10:13:35.022075Z","shell.execute_reply":"2021-06-28T10:13:35.025954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:13:37.241639Z","iopub.execute_input":"2021-06-28T10:13:37.241969Z","iopub.status.idle":"2021-06-28T10:13:37.251094Z","shell.execute_reply.started":"2021-06-28T10:13:37.241938Z","shell.execute_reply":"2021-06-28T10:13:37.250052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:13:40.42167Z","iopub.execute_input":"2021-06-28T10:13:40.422021Z","iopub.status.idle":"2021-06-28T10:13:40.430608Z","shell.execute_reply.started":"2021-06-28T10:13:40.421989Z","shell.execute_reply":"2021-06-28T10:13:40.429709Z"},"trusted":true},"execution_count":null,"outputs":[]}]}