{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n这个notebook更多的是对比赛和Bert模型的**熟悉、学习**，在目前阶段更多的是参考别人写的代码，熟悉整个比赛和建模流程，后续可以参考其他paper或者其他技巧提升模型的精度和性能\n\n## Idea:\nThe main idea of this model, it uses the huggingFace pretrain model as the tokenizer and the regression model as well\n## Goal: \n| 此阶段只追求完成，start small, step by step建立模型\n- [x] 简易EDA\n- [x] 建立baseline model\n- [x] Submit\n\n# Reference:\n- [BERT Biginner](https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room/notebook)\n- [LightWeight RoBerta](https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch/notebook#Dataset)","metadata":{}},{"cell_type":"markdown","source":"# 0.Setup","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\nimport random\n\nimport transformers\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\n\nimport warnings\n\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:57:21.904731Z","iopub.execute_input":"2021-07-16T01:57:21.905008Z","iopub.status.idle":"2021-07-16T01:57:21.908979Z","shell.execute_reply.started":"2021-07-16T01:57:21.904981Z","shell.execute_reply":"2021-07-16T01:57:21.90819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:57:24.194606Z","iopub.execute_input":"2021-07-16T01:57:24.194968Z","iopub.status.idle":"2021-07-16T01:57:24.871757Z","shell.execute_reply.started":"2021-07-16T01:57:24.194934Z","shell.execute_reply":"2021-07-16T01:57:24.870884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 824\n\ndef random_seed(SEED):\n    \n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n\nrandom_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:57:27.913288Z","iopub.execute_input":"2021-07-16T01:57:27.91365Z","iopub.status.idle":"2021-07-16T01:57:27.922848Z","shell.execute_reply.started":"2021-07-16T01:57:27.913618Z","shell.execute_reply":"2021-07-16T01:57:27.921997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyper-Paremeters\nNUM_FOLDS = 5\nNUM_EPOCHS = 20\nMAX_LEN = 314\nBATCH_SIZE = 16\nLR = 1e-5\n\nFILE_PATH = {\n    'train': '../input/commonlitreadabilityprize/train.csv',\n    'test': '../input/commonlitreadabilityprize/test.csv',\n    'submit': '../input/commonlitreadabilityprize/sample_submission.csv'\n}\nTOKEN_PATH = '../input/huggingface-bert/bert-base-cased'\nDEVICE = 'cuda' if torch.cuda.is_available else 'cpu'\nprint('Using ',DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:10:53.021713Z","iopub.execute_input":"2021-07-16T02:10:53.022063Z","iopub.status.idle":"2021-07-16T02:10:53.028769Z","shell.execute_reply.started":"2021-07-16T02:10:53.02203Z","shell.execute_reply":"2021-07-16T02:10:53.027622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.Simple EDA of data","metadata":{}},{"cell_type":"code","source":"# train: id, url_legal, license, excerpt, target, std_error\n# test: id, url_legal, license, excerpt\ntrain_df = pd.read_csv(FILE_PATH['train'])\ntest_df = pd.read_csv(FILE_PATH['test'])\nprint(train_df.nunique(), '\\n')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:57:31.378187Z","iopub.execute_input":"2021-07-16T01:57:31.378721Z","iopub.status.idle":"2021-07-16T01:57:31.496618Z","shell.execute_reply.started":"2021-07-16T01:57:31.378679Z","shell.execute_reply":"2021-07-16T01:57:31.4957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.BertTokenizer.from_pretrained(TOKEN_PATH)\nsample_excerpt = train_df['excerpt'].iloc[1]\n\nsample_token = tokenizer.encode_plus(\n    sample_excerpt,\n    add_special_tokens=True,\n    max_length = MAX_LEN,\n    pad_to_max_length = True,\n    truncation=True) # decode by 'tokenizer.decode(sample_token['input_ids'])'\n#sample_token","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-16T01:57:32.613227Z","iopub.execute_input":"2021-07-16T01:57:32.613639Z","iopub.status.idle":"2021-07-16T01:57:32.82545Z","shell.execute_reply.started":"2021-07-16T01:57:32.613593Z","shell.execute_reply":"2021-07-16T01:57:32.824469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output of tokenizer:\n- input_ids: Words id. Special: 101[CLS], 102[SEP]: begin and end of sentence\n    - 102[SEP]: seperate the sentence, also can represent start of next sentence\n- token_type_ids:  Binary mask to grasp sentences: This time it is a regression problem, all 0. When looking at the connection between sentences, change it by inserting [SEP] etc. in the middle.\n    - token_type_ids 可选。就是 token 对应的句子id，值为0或1（0表示对应的token属于第一句，1表示属于第二句）。形状为(batch_size, sequence_length)。\n- Attention_mask: 0 if element == [PAD] else 1, for mask modeling","metadata":{}},{"cell_type":"markdown","source":"# 3. Design model\n## 3.1 Divide data into KFold\n### Reference:\n- [Create Folds](https://www.kaggle.com/abhishek/step-1-create-folds)\n- [Lightweight Roberta](https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch/notebook#Model)\n- [BERT beginner](https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room/notebook#2.-BERT:-Deepen-your-understanding-of-Tokenizer)","metadata":{}},{"cell_type":"code","source":"def create_folds(df, num_folds):\n    df['fold'] = -1\n    \n    # shuffle rows with inplacement and reset index, \n    # where drop=True prevent create a new column to store the old index\n    df = df.sample(frac=1).reset_index(drop=True)\n    \n    # Sturge's rule to determine the number of bins\n    nums_bin = int(1 + 3.22 * np.log10(len(df)))\n    \n    df.loc[:, 'bins'] = pd.cut(df['target'], bins=nums_bin, labels=False)\n    kf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n    for fold, (train_id, val_id) in enumerate(kf.split(X=df, y=df.bins.values)):\n        df.loc[val_id, 'fold'] = fold\n    \n    df = df.drop('bins', axis=1)\n    return df\ntrain_df = create_folds(train_df, NUM_FOLDS)\nprint(train_df.fold.value_counts())\ntrain_df.head(8)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:57:35.777598Z","iopub.execute_input":"2021-07-16T01:57:35.777931Z","iopub.status.idle":"2021-07-16T01:57:35.812558Z","shell.execute_reply.started":"2021-07-16T01:57:35.777884Z","shell.execute_reply":"2021-07-16T01:57:35.811581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 setup dataset and dataLoader","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, sentences, targets, is_train=True):\n        self.sentences = sentences\n        self.targets = targets if is_train else None\n        self.is_train = is_train\n    \n    def __len__(self):\n        return len(self.sentences)\n    \n    def __getitem__(self, index):\n        s = self.sentences[index]\n        if self.is_train:\n            t = self.targets[index]\n        \n        # tokenization\n        token_s = tokenizer.encode_plus(\n            s, # the sentence\n            add_special_tokens = True,\n            max_length = MAX_LEN,\n            pad_to_max_length = True,\n            return_attention_mask = True,\n            truncation=True)\n        if self.is_train:\n            target_tensor = torch.tensor(t, dtype=torch.float)\n        ids = torch.tensor(token_s['input_ids'], dtype = torch.long)\n        mask = torch.tensor(token_s['attention_mask'], dtype = torch.long)\n        \n        if self.is_train:\n            return {'ids' : ids, 'mask' : mask,'targets' : target_tensor}\n        else:\n            return {'ids' : ids, 'mask' : mask}","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:59:04.175515Z","iopub.execute_input":"2021-07-16T01:59:04.17588Z","iopub.status.idle":"2021-07-16T01:59:04.184974Z","shell.execute_reply.started":"2021-07-16T01:59:04.175839Z","shell.execute_reply":"2021-07-16T01:59:04.184013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Build BERT Model","metadata":{}},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained(TOKEN_PATH, num_labels=1)\nmodel.to(DEVICE)\nmodel_original_stat_dict = model.state_dict()","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-07-16T01:57:47.627459Z","iopub.execute_input":"2021-07-16T01:57:47.627778Z","iopub.status.idle":"2021-07-16T01:58:04.497229Z","shell.execute_reply.started":"2021-07-16T01:57:47.627747Z","shell.execute_reply":"2021-07-16T01:58:04.496316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Train Function\n**Load dataset**\n> Note: currently only using one fold for testing\n- val: fold 0, train: remaining folds\n\n**Input Variables of train_function**\n- dataLoader\n- model\n- optimizer\n- scheduler","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\ndef train(model, dataloaders, optimizer, scheduler):\n    scores = defaultdict(list)\n    losses = defaultdict(list)\n    best_model_wts = None\n    best_score = float('inf')\n    \n    for epoch in tqdm(range(NUM_EPOCHS)):\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)\n            else:\n                model.train(False)\n        \n            preds, targets, epoch_losses = [], [], [] # store info at each epoch\n        \n            for data in dataloaders[phase]:\n                optimizer.zero_grad()\n\n                ids = data['ids'].to(DEVICE)\n                mask = data['mask'].to(DEVICE)\n                target = data['targets'].to(DEVICE)\n\n                output = model(ids, mask)\n                output = output['logits'].squeeze(-1)\n                loss = torch.sqrt(nn.MSELoss()(output, target))\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                epoch_losses.append(loss.item())\n                preds.append(output.detach().cpu().numpy())\n                targets.append(target.detach().cpu().numpy())\n\n            preds = np.concatenate(preds)\n            targets = np.concatenate(targets)\n            \n            losses[phase].append(np.mean(epoch_losses))\n            \n            score = np.sqrt(mean_squared_error(preds, targets))\n            scores[phase].append(score)\n            \n            if phase == 'val' and score < best_score:\n                best_score = score\n                best_model_wts = model.state_dict()\n            \n    print('Best score:',best_score)\n    return best_model_wts, best_score, [scores, losses]","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:58:04.500669Z","iopub.execute_input":"2021-07-16T01:58:04.500946Z","iopub.status.idle":"2021-07-16T01:58:04.511683Z","shell.execute_reply.started":"2021-07-16T01:58:04.50092Z","shell.execute_reply":"2021-07-16T01:58:04.510937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infos = {} # to store losses and scores of each model\nfor cur_fold in range(NUM_FOLDS):\n    print('-'*5, 'start {}'.format(cur_fold), '-'*5)\n    \n    model.load_state_dict(model_original_stat_dict)\n    # dataset \n    p_train = train_df[train_df['fold'] != cur_fold].reset_index(drop=True)\n    p_valid = train_df[train_df['fold'] == cur_fold].reset_index(drop=True)\n\n    train_dataset = MyDataset(p_train['excerpt'], p_train['target'])\n    val_dataset = MyDataset(p_valid['excerpt'], p_valid['target'])\n\n    train_dataLoader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n    val_dataLoader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n    dataLoaders = {'train': train_dataLoader, 'val': val_dataLoader}\n\n    # setup optimizer and scheduler\n    optimizer = AdamW(model.parameters(), LR, betas=(0.9, 0.99), weight_decay=1e-2)\n    train_steps = len(p_train) // BATCH_SIZE * NUM_EPOCHS\n    num_steps = int(train_steps/10) # decay at each 10% steps\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n\n    model_stat_dict, score, info = train(model, dataLoaders, optimizer, scheduler)\n    infos[cur_fold] = info\n    \n    save_path = f'model_{cur_fold}.pth'\n    torch.save(model_stat_dict, save_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T01:59:08.517304Z","iopub.execute_input":"2021-07-16T01:59:08.517637Z","iopub.status.idle":"2021-07-16T02:06:09.390675Z","shell.execute_reply.started":"2021-07-16T01:59:08.517605Z","shell.execute_reply":"2021-07-16T02:06:09.389603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Submittion","metadata":{}},{"cell_type":"code","source":"def get_preds(dataloader, model):\n    preds = []\n    with torch.no_grad():\n        for data in dataloader:\n            ids = data[\"ids\"].to(DEVICE)\n            mask = data[\"mask\"].to(DEVICE)\n            output = model(ids, mask)\n            output = output['logits'].squeeze(-1)\n            preds.append(output.detach().cpu().numpy())\n    preds = np.concatenate(preds)  \n    return preds            ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:07:12.820961Z","iopub.execute_input":"2021-07-16T02:07:12.821353Z","iopub.status.idle":"2021-07-16T02:07:12.827026Z","shell.execute_reply.started":"2021-07-16T02:07:12.821318Z","shell.execute_reply":"2021-07-16T02:07:12.826199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(FILE_PATH['test'])\nmodel_path = [f'model_{i}.pth' for i in range(5)]\ntest_dataset = MyDataset(test_df['excerpt'], None, False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\nall_preds = []\nfor fold in range(5):\n    model_path = f'model_{fold}.pth'\n    model.load_state_dict(torch.load(model_path))   \n    all_preds.append(get_preds(test_loader, model))\nall_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:07:15.112612Z","iopub.execute_input":"2021-07-16T02:07:15.112958Z","iopub.status.idle":"2021-07-16T02:07:18.075444Z","shell.execute_reply.started":"2021-07-16T02:07:15.112923Z","shell.execute_reply":"2021-07-16T02:07:18.074588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = pd.DataFrame(all_preds).T.mean(axis=1)\nscore","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:08:16.255413Z","iopub.execute_input":"2021-07-16T02:08:16.255756Z","iopub.status.idle":"2021-07-16T02:08:16.264178Z","shell.execute_reply.started":"2021-07-16T02:08:16.255723Z","shell.execute_reply":"2021-07-16T02:08:16.263244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(FILE_PATH['submit'])\nsample['target'] = score\nsample","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:09:55.543856Z","iopub.execute_input":"2021-07-16T02:09:55.544227Z","iopub.status.idle":"2021-07-16T02:09:55.557274Z","shell.execute_reply.started":"2021-07-16T02:09:55.544195Z","shell.execute_reply":"2021-07-16T02:09:55.556208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.to_csv(\"submission.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T02:10:04.261715Z","iopub.execute_input":"2021-07-16T02:10:04.262082Z","iopub.status.idle":"2021-07-16T02:10:04.689609Z","shell.execute_reply.started":"2021-07-16T02:10:04.262051Z","shell.execute_reply":"2021-07-16T02:10:04.688803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}