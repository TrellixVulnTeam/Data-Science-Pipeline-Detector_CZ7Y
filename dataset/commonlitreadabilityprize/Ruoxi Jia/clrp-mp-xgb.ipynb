{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\n\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\nfrom transformers import AutoModelForSequenceClassification\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torch.optim as optim\n\n\nfrom tqdm.notebook import tqdm\n\nimport gc; gc.enable()\nfrom IPython.display import clear_output\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom xgboost import XGBRegressor\n\nfrom sklearn.metrics import mean_squared_error\n\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:29.68311Z","iopub.execute_input":"2021-08-01T18:51:29.683642Z","iopub.status.idle":"2021-08-01T18:51:31.862739Z","shell.execute_reply.started":"2021-08-01T18:51:29.683596Z","shell.execute_reply":"2021-08-01T18:51:31.861655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mean Pooling","metadata":{}},{"cell_type":"code","source":"# Definitions\n\nINPUT_DIR = '../input/commonlitreadabilityprize'\nMODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\n\nHIDDEN_SIZE = 1024\nNUM_HIDDEN_LAYERS = 24\nLAYER_START = 4   # for WeightedLayerPoolingModel\n\nHIDDEN_DIM_FC = 128    # for AttentionPooling\n\nMAX_LENGTH = 300\nLR = 2e-5\nEPS = 1e-8\n\nSEED = 42\n\nNUM_FOLDS = 5\n\nSEEDS = [64]\n\nEPOCHS = 5\nTRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 32\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:31.86446Z","iopub.execute_input":"2021-08-01T18:51:31.864863Z","iopub.status.idle":"2021-08-01T18:51:31.927999Z","shell.execute_reply.started":"2021-08-01T18:51:31.864818Z","shell.execute_reply":"2021-08-01T18:51:31.926363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# K Fold\nclass ContinuousStratifiedKFold(StratifiedKFold):\n    def split(selfself, x, y, groups=None):\n        num_bins = int(np.floor(1 + np.log2(len(y))))\n        bins = pd.cut(y, bins=num_bins, labels=False)\n        return super().split(x, bins, groups)\n    \ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:31.931386Z","iopub.execute_input":"2021-08-01T18:51:31.932118Z","iopub.status.idle":"2021-08-01T18:51:31.943009Z","shell.execute_reply.started":"2021-08-01T18:51:31.932067Z","shell.execute_reply":"2021-08-01T18:51:31.941876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MeanPoolingModel(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(HIDDEN_SIZE, 1)\n        self.loss = nn.MSELoss()\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        \n        outputs = self.model(input_ids, attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        logits = self.linear(mean_embeddings)\n        \n        preds = logits.squeeze(-1).squeeze(-1)\n        \n        if labels is not None:\n            loss = self.loss(preds.view(-1).float(), labels.view(-1).float())\n            return loss\n        else:\n            return preds     ","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:31.945091Z","iopub.execute_input":"2021-08-01T18:51:31.945595Z","iopub.status.idle":"2021-08-01T18:51:31.958349Z","shell.execute_reply.started":"2021-08-01T18:51:31.945551Z","shell.execute_reply":"2021-08-01T18:51:31.957115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\ntest.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:31.960006Z","iopub.execute_input":"2021-08-01T18:51:31.960495Z","iopub.status.idle":"2021-08-01T18:51:32.004813Z","shell.execute_reply.started":"2021-08-01T18:51:31.960451Z","shell.execute_reply":"2021-08-01T18:51:32.003744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_BATCH_SIZE = 1\n\ndef get_test_loader(data):\n\n    x_test = data.excerpt.tolist()\n    \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n\n    encoded_test = tokenizer.batch_encode_plus(\n        x_test, \n        add_special_tokens=True, \n        return_attention_mask=True, \n        padding='max_length', \n        truncation=True,\n        max_length=MAX_LENGTH, \n        return_tensors='pt'\n    )\n\n    dataset_test = TensorDataset(\n        encoded_test['input_ids'],\n        encoded_test['attention_mask']\n    )\n\n    dataloader_test = DataLoader(\n        dataset_test,\n        sampler = SequentialSampler(dataset_test),\n        batch_size=TEST_BATCH_SIZE\n    )\n    \n    return dataloader_test\n\ntest_dataloader = get_test_loader(test)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:32.008219Z","iopub.execute_input":"2021-08-01T18:51:32.008567Z","iopub.status.idle":"2021-08-01T18:51:32.306624Z","shell.execute_reply.started":"2021-08-01T18:51:32.008537Z","shell.execute_reply":"2021-08-01T18:51:32.305554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR = '../input/clrp-mp/'\n\n\nall_predictions = [] \nfor seed in SEEDS:\n    \n    fold_predictions = []\n    \n    for fold in tqdm(range(NUM_FOLDS)):\n        \n        model_path = DIR + f\"model_{seed + 1}_{fold + 1}.pth\" \n        print(f\"\\nUsing {model_path}\")        \n        \n        model = MeanPoolingModel(MODEL_DIR)\n        model.load_state_dict(torch.load(model_path)) \n        model.to(DEVICE)\n        model.eval()\n\n        predictions = []\n        for batch in test_dataloader:\n\n            batch = tuple(b.to(DEVICE) for b in batch)\n\n            inputs = {'input_ids':      batch[0],\n                      'attention_mask': batch[1],\n                      'labels':         None,\n                     }\n\n     \n            preds = model(**inputs).item()\n            predictions.append(preds)\n            \n        del model \n        gc.collect()\n            \n        fold_predictions.append(predictions)\n    all_predictions.append(np.mean(fold_predictions, axis=0).tolist())\n    \nsub_pred1 = np.mean(all_predictions,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:51:32.308201Z","iopub.execute_input":"2021-08-01T18:51:32.308624Z","iopub.status.idle":"2021-08-01T18:53:41.156327Z","shell.execute_reply.started":"2021-08-01T18:51:32.30858Z","shell.execute_reply":"2021-08-01T18:53:41.155202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RoBerta + xgb","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:53:41.160056Z","iopub.execute_input":"2021-08-01T18:53:41.160402Z","iopub.status.idle":"2021-08-01T18:53:41.235659Z","shell.execute_reply.started":"2021-08-01T18:53:41.160369Z","shell.execute_reply":"2021-08-01T18:53:41.234605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'nfolds':5,\n    'seed':42,\n}\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:53:41.237899Z","iopub.execute_input":"2021-08-01T18:53:41.23839Z","iopub.status.idle":"2021-08-01T18:53:41.24448Z","shell.execute_reply.started":"2021-08-01T18:53:41.238346Z","shell.execute_reply":"2021-08-01T18:53:41.243023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:53:41.246222Z","iopub.execute_input":"2021-08-01T18:53:41.247186Z","iopub.status.idle":"2021-08-01T18:53:41.256487Z","shell.execute_reply.started":"2021-08-01T18:53:41.247102Z","shell.execute_reply":"2021-08-01T18:53:41.255397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:53:41.258104Z","iopub.execute_input":"2021-08-01T18:53:41.258646Z","iopub.status.idle":"2021-08-01T18:53:41.272195Z","shell.execute_reply.started":"2021-08-01T18:53:41.258602Z","shell.execute_reply":"2021-08-01T18:53:41.270984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionModel(nn.Module):\n    def __init__(self):\n        super(AttentionModel,self).__init__()\n        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n        self.head = AttentionHead(768,768,1)\n        self.dropout = nn.Dropout(0.1)\n        self.linear = nn.Linear(self.head.out_features,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:55:26.656957Z","iopub.execute_input":"2021-08-01T18:55:26.657391Z","iopub.status.idle":"2021-08-01T18:55:26.664988Z","shell.execute_reply.started":"2021-08-01T18:55:26.657359Z","shell.execute_reply":"2021-08-01T18:55:26.663429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = AttentionModel()\n    model.load_state_dict(torch.load(path))\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n    \n    ds = CLRPDataset(df,tokenizer)\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs.detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:58:07.814432Z","iopub.execute_input":"2021-08-01T18:58:07.814819Z","iopub.status.idle":"2021-08-01T18:58:07.827296Z","shell.execute_reply.started":"2021-08-01T18:58:07.814789Z","shell.execute_reply":"2021-08-01T18:58:07.825735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  get_embeddings(train_data,'../input/clr-roberta/model0/model0.bin')\ntest_embeddings1 = get_embeddings(test_data,'../input/clr-roberta/model0/model0.bin')\n\ntrain_embeddings2 =  get_embeddings(train_data,'../input/clr-roberta/model1/model1.bin')\ntest_embeddings2 = get_embeddings(test_data,'../input/clr-roberta/model1/model1.bin')\n\ntrain_embeddings3 =  get_embeddings(train_data,'../input/clr-roberta/model2/model2.bin')\ntest_embeddings3 = get_embeddings(test_data,'../input/clr-roberta/model2/model2.bin')\n\ntrain_embeddings4 =  get_embeddings(train_data,'../input/clr-roberta/model3/model3.bin')\ntest_embeddings4 = get_embeddings(test_data,'../input/clr-roberta/model3/model3.bin')\n\ntrain_embeddings5 =  get_embeddings(train_data,'../input/clr-roberta/model4/model4.bin')\ntest_embeddings5 = get_embeddings(test_data,'../input/clr-roberta/model4/model4.bin')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:58:09.80473Z","iopub.execute_input":"2021-08-01T18:58:09.805251Z","iopub.status.idle":"2021-08-01T19:01:18.485652Z","shell.execute_reply.started":"2021-08-01T18:58:09.805203Z","shell.execute_reply":"2021-08-01T19:01:18.484365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds_xgb(X,y,X_test,bins=bins,nfolds=5):\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        model = XGBRegressor()\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train,y_train)\n        prediction = model.predict(X_valid)\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:08:24.000997Z","iopub.execute_input":"2021-08-01T19:08:24.001421Z","iopub.status.idle":"2021-08-01T19:08:24.029183Z","shell.execute_reply.started":"2021-08-01T19:08:24.00138Z","shell.execute_reply":"2021-08-01T19:08:24.027776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1 = get_preds_xgb(train_embeddings1,target,test_embeddings1)\npreds2 = get_preds_xgb(train_embeddings2,target,test_embeddings2)\npreds3 = get_preds_xgb(train_embeddings3,target,test_embeddings3)\npreds4 = get_preds_xgb(train_embeddings4,target,test_embeddings4)\npreds5 = get_preds_xgb(train_embeddings5,target,test_embeddings5)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:08:26.386123Z","iopub.execute_input":"2021-08-01T19:08:26.386528Z","iopub.status.idle":"2021-08-01T19:25:45.484408Z","shell.execute_reply.started":"2021-08-01T19:08:26.386496Z","shell.execute_reply":"2021-08-01T19:25:45.483267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_preds2 = (preds1 + preds2 + preds3 + preds4 + preds5)/5","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:25:51.405905Z","iopub.execute_input":"2021-08-01T19:25:51.406262Z","iopub.status.idle":"2021-08-01T19:25:51.413267Z","shell.execute_reply.started":"2021-08-01T19:25:51.406232Z","shell.execute_reply":"2021-08-01T19:25:51.412125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\nsubmit.target = (sub_pred1 + sub_preds2)/2\nsubmit","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:25:53.143795Z","iopub.execute_input":"2021-08-01T19:25:53.144163Z","iopub.status.idle":"2021-08-01T19:25:53.186217Z","shell.execute_reply.started":"2021-08-01T19:25:53.144132Z","shell.execute_reply":"2021-08-01T19:25:53.184873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:25:58.473167Z","iopub.execute_input":"2021-08-01T19:25:58.473577Z","iopub.status.idle":"2021-08-01T19:25:58.824046Z","shell.execute_reply.started":"2021-08-01T19:25:58.473544Z","shell.execute_reply":"2021-08-01T19:25:58.82299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}