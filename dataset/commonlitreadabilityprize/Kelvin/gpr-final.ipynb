{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Pyro package for GPR","metadata":{}},{"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/\n!cp ../input/pyroppl-152/pyro_ppl-1.5.2-py3-none-any.whl /tmp/pip/cache/\n!cp ../input/pyroppl-152/pyro_api-0.1.2-py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ pyro-ppl==1.5.2","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:35.038046Z","iopub.execute_input":"2021-09-10T06:30:35.038588Z","iopub.status.idle":"2021-09-10T06:30:43.839795Z","shell.execute_reply.started":"2021-09-10T06:30:35.038337Z","shell.execute_reply":"2021-09-10T06:30:43.838856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import normalize\nfrom joblib import dump, load\nimport gc\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.optimizer import Optimizer\n\nfrom transformers import (AutoModel, AutoConfig, AutoTokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:43.842649Z","iopub.execute_input":"2021-09-10T06:30:43.84301Z","iopub.status.idle":"2021-09-10T06:30:46.513748Z","shell.execute_reply.started":"2021-09-10T06:30:43.842967Z","shell.execute_reply":"2021-09-10T06:30:46.512902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\ntarget = train_data['target'].to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:46.515669Z","iopub.execute_input":"2021-09-10T06:30:46.516031Z","iopub.status.idle":"2021-09-10T06:30:46.647689Z","shell.execute_reply.started":"2021-09-10T06:30:46.515992Z","shell.execute_reply":"2021-09-10T06:30:46.646853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")\nCOMPUTE_CV = False\n\nif COMPUTE_CV:\n    test = train_data\n    is_test = False\n    mode = \"train\"\nelse:\n    test = test_data\n    is_test = True\n    mode = \"test\"","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:46.649234Z","iopub.execute_input":"2021-09-10T06:30:46.64961Z","iopub.status.idle":"2021-09-10T06:30:46.657999Z","shell.execute_reply.started":"2021-09-10T06:30:46.649571Z","shell.execute_reply":"2021-09-10T06:30:46.657133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':512,\n    'max_len':256,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:46.659246Z","iopub.execute_input":"2021-09-10T06:30:46.659667Z","iopub.status.idle":"2021-09-10T06:30:46.669582Z","shell.execute_reply.started":"2021-09-10T06:30:46.659628Z","shell.execute_reply":"2021-09-10T06:30:46.668676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pipeline\n","metadata":{}},{"cell_type":"code","source":"import os\nimport yaml\nimport pytorch_lightning as pl\n\nclass CFG:\n\n    test_mode = False\n\n    # model-based\n    model_path = '../input/robertalarge-epoch5-textaugment'  # pretrained model path, {bert-base-uncased, roberta-base, roberta-large}\n    model_name = 'roberta-large'  # model name for saving models. It should correspond to the name in Huggingface.\n    max_len = 256\n    backbone_out = 'attention'  # pooler, last_hidden_state, cls_token, attention, conv1d\n    dropout = 0.5\n    aug = False\n    reinit_layer = 3\n\n    # training-based\n    seed = 42  # for kfolds\n    train_seed = 42  # for training-related parts, i.e. data shuffling, layer initialisation\n    fix_data_order = True\n    kfold_strategy = 'random'  # random, old, new\n    random_folds_path = '/home/oatos/Documents/code/kaggle/CommonLit-Readability/inputs/external/random_folds.csv'\n\n    num_folds = 5\n    batch_sz = 8\n    accumulate_grad_batches = 1\n    use_smart_batching = False\n    epochs = 5\n    es_epoch = 2  # early stopping\n    warmup_ratio = 0\n    learning_rate = 2e-5\n    last_linear_lr = learning_rate  # 1e-3, learning_rate\n    use_grouped_params = False\n    lr_epsilon = 0.95\n    decay = 'linear'\n    wts_decay = 0.005 if 'large' in model_name else 1e-2  # 1e-2\n    betas = (0.9, 0.98) if 'large' in model_name else (0.9, 0.999)   # default: (0.9, 0.999) \n\n    val_check_interval = 10  # 10, 5, 1.0\n    swa = False\n\n    # inference\n    num_tta = 2\n\n    # environment\n    output_dir = '/home/oatos/Documents/code/kaggle/CommonLit-Readability/outputs'\n    params_dir = '/home/oatos/Documents/code/kaggle/CommonLit-Readability/outputs'\n    log_dir = '/home/oatos/Documents/code/kaggle/CommonLit-Readability'\n    device = [0]\n    env = 'local'  # kaggle, local\n    progress_bar = 0 if env == 'kaggle' else 1\n    verbose = False if env == 'kaggle' else True\n\n    # program\n    use_tpu = False\n    num_workers = 20\n\n    @staticmethod\n    def get_next_exp_id():\n        if len(os.listdir(CFG.params_dir)) == 0: return 0\n        last_exp_num = int(sorted(os.listdir(CFG.params_dir))[-1].split('_')[1])\n        return last_exp_num + 1\n\n    @staticmethod\n    def save_config(exp_id):\n        config_dict = {}\n        for k, v in vars(CFG).items():\n            if k.startswith('_') or isinstance(v, staticmethod): continue\n            config_dict[k] = v\n        save_dir = os.path.join(CFG.params_dir, f'exp_{str(exp_id).zfill(3)}')\n        os.makedirs(save_dir, exist_ok=True)\n        with open(save_dir + '/hparams.yaml', 'w') as f:\n            yaml.dump(config_dict, f, sort_keys=False)\n            \n\ndef predict_dataloader(loader, model, output_features=False):\n    preds = []\n    embeddings = []\n    with torch.no_grad():\n        for batch in tqdm(loader):\n            if len(batch) == 3:\n                ids, mask, y = batch\n            else:\n                ids, mask = batch\n            ids = ids.to('cuda')\n            mask = mask.to('cuda')\n            if output_features:\n                y_pred = model.extract_feats([ids, mask]).detach().cpu().numpy()\n            else:\n                y_pred, embedding = model([ids, mask])\n                y_pred = y_pred.detach().cpu().numpy()\n                embedding = embedding.detach().cpu().numpy()\n            preds.append(y_pred)\n            embeddings.append(embedding)\n    preds = np.concatenate(preds)\n    embeddings = np.concatenate(embeddings)\n    return preds, embeddings\n\nclass CommonLitDataset(Dataset):\n    def __init__(self, df, tokenizer, shuffle=False):\n        self.df = df\n        if shuffle:\n            self.df = self.df.sample(frac=1, random_state=0).reset_index(drop=True)\n        self.labeled = 'target' in df.columns\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        item = self.df.iloc[idx]\n        text = item['excerpt']\n        token = self.tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=CFG.max_len)\n        if self.labeled:\n            target = torch.tensor(item['target'], dtype=torch.float)\n            return token['input_ids'].squeeze(), token['attention_mask'].squeeze(), target\n        else:\n            return token['input_ids'].squeeze(), token['attention_mask'].squeeze()\n\nclass AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        \n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n        \n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n        return context_vector\n\n    \nclass CommonLitModel(pl.LightningModule):\n    \n    def __init__(self, train_steps):\n        super().__init__()\n        self.train_steps = train_steps\n        self.config = self.get_config()\n        self.backbone = self.get_backbone(self.config)\n        self.num_labels = 1\n        self.config.update({'num_labels': self.num_labels})\n        self.dropout = nn.Dropout(CFG.dropout)\n        if CFG.backbone_out == 'conv1d':\n            self.clf = nn.Linear(1024, self.num_labels)\n        else:\n            self.clf = nn.Linear(self.config.hidden_size, self.num_labels)\n        if CFG.backbone_out == 'attention':\n            hidden_size = self.config.hidden_size\n            self.head = AttentionHead(self.config.hidden_size, hidden_size) # self.config.hidden_size\n        if CFG.backbone_out == 'conv1d':\n            self.cnn1 = nn.Conv1d(self.config.hidden_size, 256, kernel_size=3, padding=2)\n            self.cnn2 = nn.Conv1d(256, 512, kernel_size=3, padding=2)\n            self.cnn3 = nn.Conv1d(512, 256, kernel_size=3, padding=2)\n        if 'large' in CFG.model_name:\n            self.layer_norm = nn.LayerNorm(self.config.hidden_size)\n            self._init_weights(self.clf)\n            self._init_weights(self.layer_norm)\n\n    def get_config(self):\n        return AutoConfig.from_pretrained(CFG.model_path)\n\n    def _init_weights(self, module):\n        initializer_range = 0.02\n        init_res = False\n        if isinstance(module, nn.Linear):\n            init_res = True\n            module.weight.data.normal_(mean=0.0, std=initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            init_res = True\n            module.weight.data.normal_(mean=0.0, std=initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            init_res = True\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        return init_res\n\n    def get_backbone(self, config):\n        model = AutoModel.from_pretrained(CFG.model_path, config=config)\n        # print(model)\n        # raise\n        if CFG.reinit_layer == 'pooler':\n            print('Reinitializing Pooler Layer ...')\n            encoder_temp = model\n            encoder_temp.pooler.weight.data.normal_(mean=0.0, std=config.initializer_range)\n            encoder_temp.pooler.bias.data.zero_()\n            for p in encoder_temp.pooler.parameters():\n                p.requires_grad = True\n            print('Done.!')\n        elif CFG.reinit_layer > 0:\n            # _model_type = 'roberta'\n            print(f'Reinitializing Last {CFG.reinit_layer} Layers ...')\n            # print(model)\n            # encoder_temp = getattr(model, _model_type)\n            num_modules = 0\n            if 'bart' in CFG.model_name:\n                temp = model.decoder\n                for layer in temp.layers[-CFG.reinit_layer:]:\n                    for module in layer.modules():\n                        if self._init_weights(module): num_modules += 1\n            elif 'xlnet' in CFG.model_name:\n                temp = model\n                for layer in temp.layer[-CFG.reinit_layer:]:\n                    for module in layer.modules():\n                        if self._init_weights(module): num_modules += 1\n            else:\n                temp = model.encoder\n                for layer in temp.layer[-CFG.reinit_layer:]:\n                    for module in layer.modules():\n                        if self._init_weights(module): num_modules += 1\n            print(f'Done reinitialising {num_modules} modules!')\n        return model\n\n    def extract_feats(self, inputs):\n        input_ids, mask = inputs\n        out = self.backbone(input_ids=input_ids, attention_mask=mask)\n        \n        if CFG.backbone_out == 'pooler':\n            out = out['pooler_output']\n        elif CFG.backbone_out == 'last_hidden_state':\n            out = out['last_hidden_state']\n            out = torch.mean(out, dim=1)\n        elif CFG.backbone_out == 'cls_token':\n            out = out['last_hidden_state'][:,0,:]\n        elif CFG.backbone_out == 'attention':\n            if 'pooler_output' in out.keys():\n                pooler = out['pooler_output'].reshape((out['pooler_output'].shape[0], 1, self.config.hidden_size))\n                x = torch.cat([out['last_hidden_state'], pooler],axis=1)  # (batch size, sequence len + 1, hidden size)\n                # pooler_mask = torch.ones((out['pooler_output'].shape[0], 1)).to(f'cuda:{CFG.device[0]}')\n                # mask = torch.cat([mask, pooler_mask], axis=1)\n            else:\n                x = out['last_hidden_state']\n            out = self.head(x)\n        elif CFG.backbone_out == 'conv1d':\n            x = out['last_hidden_state']\n            x = x.permute(0, 2, 1)  # (batch_sz, seq_len, hidden_size) -> (batch_sz, hidden_size, seq_len), channel first in pytorch\n            x = self.cnn1(x)\n            x = F.relu(x)  # (batch_sz, 256, seq_len)\n            x = F.avg_pool1d(x, kernel_size=4)\n            x = self.cnn2(x)\n            x = F.relu(x)  # (batch_sz, 256, seq_len)\n            x = F.avg_pool1d(x, kernel_size=4)\n            x = self.cnn3(x)\n            x = F.relu(x)  # (batch_sz, 256, seq_len)\n            x = F.avg_pool1d(x, kernel_size=4)\n            out = torch.flatten(x, start_dim=1)\n        \n        return out\n    \n    def forward(self, inputs):\n        out = self.extract_feats(inputs)\n        pooled_output = out\n        if 'large' in CFG.model_name:\n            out = self.layer_norm(out)\n        out = self.dropout(out)\n        out = self.clf(out).squeeze()\n        return out, pooled_output\n    \ndef run_inference_fx(fold_df, model_name, ckpt_path, batch_size):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    fold_dataset = CommonLitDataset(fold_df, tokenizer)\n    fold_loader = DataLoader(fold_dataset, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n\n    ckpt_path = ckpt_path\n    model_fx = CommonLitModel.load_from_checkpoint(ckpt_path, train_steps=0)\n    \n    model_fx.cuda()\n    model_fx.eval()\n\n    preds, embeddings = predict_dataloader(fold_loader, model_fx)\n\n    del model_fx\n    del tokenizer\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return preds, embeddings","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:46.671234Z","iopub.execute_input":"2021-09-10T06:30:46.671888Z","iopub.status.idle":"2021-09-10T06:30:48.009234Z","shell.execute_reply.started":"2021-09-10T06:30:46.671847Z","shell.execute_reply":"2021-09-10T06:30:48.008287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load embeddings from transformers ","metadata":{}},{"cell_type":"code","source":"model_path = '../input/robertalarge'\nCFG.model_path = model_path\nCFG.model_name = 'roberta-large'\n\nbatch_size = 128\n\npreds_1_roberta_l_fx_old, embeddings1_rl_fx_old = run_inference_fx(test, model_path, '../input/cl-roberta-large-models-local-with-seed-42/exp_180_*/roberta-large_seed42_fold0.ckpt', batch_size)\npreds_2_roberta_l_fx_old, embeddings2_rl_fx_old = run_inference_fx(test, model_path, '../input/cl-roberta-large-models-local-with-seed-42/exp_180_*/roberta-large_seed42_fold1.ckpt', batch_size)\npreds_3_roberta_l_fx_old, embeddings3_rl_fx_old = run_inference_fx(test, model_path, '../input/cl-roberta-large-models-local-with-seed-42/exp_180_*/roberta-large_seed42_fold2.ckpt', batch_size)\npreds_4_roberta_l_fx_old, embeddings4_rl_fx_old = run_inference_fx(test, model_path, '../input/cl-roberta-large-models-local-with-seed-42/exp_180_*/roberta-large_seed42_fold3.ckpt', batch_size)\npreds_5_roberta_l_fx_old, embeddings5_rl_fx_old = run_inference_fx(test, model_path, '../input/cl-roberta-large-models-local-with-seed-42/exp_180_*/roberta-large_seed42_fold4.ckpt', batch_size)\npreds_roberta_l_fx_old = (preds_1_roberta_l_fx_old + preds_2_roberta_l_fx_old + preds_3_roberta_l_fx_old + preds_4_roberta_l_fx_old + preds_5_roberta_l_fx_old) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:30:48.010806Z","iopub.execute_input":"2021-09-10T06:30:48.011153Z","iopub.status.idle":"2021-09-10T06:33:14.162879Z","shell.execute_reply.started":"2021-09-10T06:30:48.011112Z","shell.execute_reply":"2021-09-10T06:33:14.161952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/debertalarge'\nCFG.model_path = model_path\nCFG.model_name = 'deberta-large'\n\nbatch_size = 128\n\npreds_1_deberta_l_fx, embeddings1_dl_fx = run_inference_fx(test, model_path, '../input/commonlit-deberta-large-models-local-with-seed-42/exp_187_*/microsoft/deberta-large_seed42_fold0.ckpt', batch_size)\npreds_2_deberta_l_fx, embeddings2_dl_fx = run_inference_fx(test, model_path, '../input/commonlit-deberta-large-models-local-with-seed-42/exp_187_*/microsoft/deberta-large_seed42_fold1.ckpt', batch_size)\npreds_3_deberta_l_fx, embeddings3_dl_fx = run_inference_fx(test, model_path, '../input/commonlit-deberta-large-models-local-with-seed-42/exp_187_*/microsoft/deberta-large_seed42_fold2.ckpt', batch_size)\npreds_4_deberta_l_fx, embeddings4_dl_fx = run_inference_fx(test, model_path, '../input/commonlit-deberta-large-models-local-with-seed-42/exp_187_*/microsoft/deberta-large_seed42_fold3.ckpt', batch_size)\npreds_5_deberta_l_fx, embeddings5_dl_fx = run_inference_fx(test, model_path, '../input/commonlit-deberta-large-models-local-with-seed-42/exp_187_*/microsoft/deberta-large_seed42_fold4.ckpt', batch_size)\npreds_deberta_l_fx = (preds_1_deberta_l_fx + preds_2_deberta_l_fx + preds_3_deberta_l_fx + preds_4_deberta_l_fx + preds_5_deberta_l_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:33:14.165715Z","iopub.execute_input":"2021-09-10T06:33:14.166109Z","iopub.status.idle":"2021-09-10T06:35:41.386717Z","shell.execute_reply.started":"2021-09-10T06:33:14.166072Z","shell.execute_reply":"2021-09-10T06:35:41.385513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/xlnet-large-cased'\nCFG.model_path = model_path\nCFG.model_name = 'xlnet-large'\n\nbatch_size = 128\n\npreds_1_xlnet_l_fx, embeddings1_xl_fx = run_inference_fx(test, model_path, '../input/cl-xlnet-large-models-local-with-seed-42-new/exp_284/xlnet-large-cased_seed42_fold0.ckpt', batch_size)\npreds_2_xlnet_l_fx, embeddings2_xl_fx = run_inference_fx(test, model_path, '../input/cl-xlnet-large-models-local-with-seed-42-new/exp_284/xlnet-large-cased_seed42_fold1.ckpt', batch_size)\npreds_3_xlnet_l_fx, embeddings3_xl_fx = run_inference_fx(test, model_path, '../input/cl-xlnet-large-models-local-with-seed-42-new/exp_284/xlnet-large-cased_seed42_fold2.ckpt', batch_size)\npreds_4_xlnet_l_fx, embeddings4_xl_fx = run_inference_fx(test, model_path, '../input/cl-xlnet-large-models-local-with-seed-42-new/exp_284/xlnet-large-cased_seed42_fold3.ckpt', batch_size)\npreds_5_xlnet_l_fx, embeddings5_xl_fx = run_inference_fx(test, model_path, '../input/cl-xlnet-large-models-local-with-seed-42-new/exp_284/xlnet-large-cased_seed42_fold4.ckpt', batch_size)\npreds_xlnet_l_fx = (preds_1_xlnet_l_fx + preds_2_xlnet_l_fx + preds_3_xlnet_l_fx + preds_4_xlnet_l_fx + preds_5_xlnet_l_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:35:41.388664Z","iopub.execute_input":"2021-09-10T06:35:41.389014Z","iopub.status.idle":"2021-09-10T06:37:48.175941Z","shell.execute_reply.started":"2021-09-10T06:35:41.388975Z","shell.execute_reply":"2021-09-10T06:37:48.175082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/robertalarge'\nCFG.model_path = model_path\nCFG.model_name = 'roberta-large'\n\nbatch_size = 128\n\npreds_1_roberta_l_s2_fx, embeddings1_rl_sq2_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-squad2-models-local-with-seed-42/exp_312_*/roberta-large_seed42_fold0.ckpt', batch_size)\npreds_2_roberta_l_s2_fx, embeddings2_rl_sq2_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-squad2-models-local-with-seed-42/exp_312_*/roberta-large_seed42_fold1.ckpt', batch_size)\npreds_3_roberta_l_s2_fx, embeddings3_rl_sq2_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-squad2-models-local-with-seed-42/exp_312_*/roberta-large_seed42_fold2.ckpt', batch_size)\npreds_4_roberta_l_s2_fx, embeddings4_rl_sq2_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-squad2-models-local-with-seed-42/exp_312_*/roberta-large_seed42_fold3.ckpt', batch_size)\npreds_5_roberta_l_s2_fx, embeddings5_rl_sq2_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-squad2-models-local-with-seed-42/exp_312_*/roberta-large_seed42_fold4.ckpt', batch_size)\npreds_roberta_l_s2_fx = (preds_1_roberta_l_s2_fx + preds_2_roberta_l_s2_fx + preds_3_roberta_l_s2_fx + preds_4_roberta_l_s2_fx + preds_5_roberta_l_s2_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:37:48.177512Z","iopub.execute_input":"2021-09-10T06:37:48.177875Z","iopub.status.idle":"2021-09-10T06:39:48.917746Z","shell.execute_reply.started":"2021-09-10T06:37:48.177834Z","shell.execute_reply":"2021-09-10T06:39:48.916901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/longformerlarge'\nCFG.model_path = model_path\nCFG.model_name = 'longformer-large'\n\nbatch_size = 64\n\npreds_1_longformer_l_tqa_fx, embeddings1_longformer_tqa_fx = run_inference_fx(test, model_path, '../input/cl-longformer-large-tqa-seed-42/exp_426_*/allenai/longformer-large-4096-finetuned-triviaqa_seed42_fold0.ckpt', batch_size)\npreds_2_longformer_l_tqa_fx, embeddings2_longformer_tqa_fx = run_inference_fx(test, model_path, '../input/cl-longformer-large-tqa-seed-42/exp_426_*/allenai/longformer-large-4096-finetuned-triviaqa_seed42_fold1.ckpt', batch_size)\npreds_3_longformer_l_tqa_fx, embeddings3_longformer_tqa_fx = run_inference_fx(test, model_path, '../input/cl-longformer-large-tqa-seed-42/exp_426_*/allenai/longformer-large-4096-finetuned-triviaqa_seed42_fold2.ckpt', batch_size)\npreds_4_longformer_l_tqa_fx, embeddings4_longformer_tqa_fx = run_inference_fx(test, model_path, '../input/cl-longformer-large-tqa-seed-42/exp_426_*/allenai/longformer-large-4096-finetuned-triviaqa_seed42_fold3.ckpt', batch_size)\npreds_5_longformer_l_tqa_fx, embeddings5_longformer_tqa_fx = run_inference_fx(test, model_path, '../input/cl-longformer-large-tqa-seed-42/exp_426_*/allenai/longformer-large-4096-finetuned-triviaqa_seed42_fold4.ckpt', batch_size)\npreds_longformer_ltqa_fx = (preds_1_longformer_l_tqa_fx + preds_2_longformer_l_tqa_fx + preds_3_longformer_l_tqa_fx + preds_4_longformer_l_tqa_fx + preds_5_longformer_l_tqa_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:39:48.921256Z","iopub.execute_input":"2021-09-10T06:39:48.921659Z","iopub.status.idle":"2021-09-10T06:42:24.523042Z","shell.execute_reply.started":"2021-09-10T06:39:48.921614Z","shell.execute_reply":"2021-09-10T06:42:24.522211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_path = '../input/robertalarge-epoch5-textaugment'\nmodel_path = '../input/robertalarge'\nCFG.model_path = model_path\nCFG.model_name = 'roberta-large'\n\nbatch_size = 128\n\npreds_1_roberta_l_s2_mlm_only_pl_fx, embeddings1_rl_sq2_mlm_only_pl_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-sq2-mlm-seed-42-exp723/exp_723_*/roberta-large_seed42_fold0.ckpt', batch_size)\npreds_2_roberta_l_s2_mlm_only_pl_fx, embeddings2_rl_sq2_mlm_only_pl_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-sq2-mlm-seed-42-exp723/exp_723_*/roberta-large_seed42_fold1.ckpt', batch_size)\npreds_3_roberta_l_s2_mlm_only_pl_fx, embeddings3_rl_sq2_mlm_only_pl_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-sq2-mlm-seed-42-exp723/exp_723_*/roberta-large_seed42_fold2.ckpt', batch_size)\npreds_4_roberta_l_s2_mlm_only_pl_fx, embeddings4_rl_sq2_mlm_only_pl_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-sq2-mlm-seed-42-exp723/exp_723_*/roberta-large_seed42_fold3.ckpt', batch_size)\npreds_5_roberta_l_s2_mlm_only_pl_fx, embeddings5_rl_sq2_mlm_only_pl_fx = run_inference_fx(test, model_path, '../input/cl-roberta-large-sq2-mlm-seed-42-exp723/exp_723_*/roberta-large_seed42_fold4.ckpt', batch_size)\npreds_roberta_l_s2_mlm_only_pl_fx = (preds_1_roberta_l_s2_mlm_only_pl_fx + preds_2_roberta_l_s2_mlm_only_pl_fx + preds_3_roberta_l_s2_mlm_only_pl_fx + preds_4_roberta_l_s2_mlm_only_pl_fx + preds_5_roberta_l_s2_mlm_only_pl_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:42:24.524619Z","iopub.execute_input":"2021-09-10T06:42:24.524971Z","iopub.status.idle":"2021-09-10T06:44:15.63766Z","shell.execute_reply.started":"2021-09-10T06:42:24.524931Z","shell.execute_reply":"2021-09-10T06:44:15.636788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/bartlarge'\nCFG.model_path = model_path\nCFG.model_name = 'bart-large-finetuned-squadv1'\n\nbatch_size = 128\n\npreds_1_bl_mlm_rmdp_fx, embeddings1_bl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-bart-large-sq1-mlm-rm-dp-seed-42-exp799/exp_799_*/valhalla/bart-large-finetuned-squadv1_seed42_fold0.ckpt', batch_size)\npreds_2_bl_mlm_rmdp_fx, embeddings2_bl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-bart-large-sq1-mlm-rm-dp-seed-42-exp799/exp_799_*/valhalla/bart-large-finetuned-squadv1_seed42_fold1.ckpt', batch_size)\npreds_3_bl_mlm_rmdp_fx, embeddings3_bl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-bart-large-sq1-mlm-rm-dp-seed-42-exp799/exp_799_*/valhalla/bart-large-finetuned-squadv1_seed42_fold2.ckpt', batch_size)\npreds_4_bl_mlm_rmdp_fx, embeddings4_bl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-bart-large-sq1-mlm-rm-dp-seed-42-exp799/exp_799_*/valhalla/bart-large-finetuned-squadv1_seed42_fold3.ckpt', batch_size)\npreds_5_bl_mlm_rmdp_fx, embeddings5_bl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-bart-large-sq1-mlm-rm-dp-seed-42-exp799/exp_799_*/valhalla/bart-large-finetuned-squadv1_seed42_fold4.ckpt', batch_size)\npreds_bl_mlm_rmdp_fx = (preds_1_bl_mlm_rmdp_fx + preds_2_bl_mlm_rmdp_fx + preds_3_bl_mlm_rmdp_fx + preds_4_bl_mlm_rmdp_fx + preds_5_bl_mlm_rmdp_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:44:15.639331Z","iopub.execute_input":"2021-09-10T06:44:15.639719Z","iopub.status.idle":"2021-09-10T06:47:08.494677Z","shell.execute_reply.started":"2021-09-10T06:44:15.63968Z","shell.execute_reply":"2021-09-10T06:47:08.49387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/debertalarge'\nCFG.model_path = model_path\nCFG.model_name = 'deberta-large'\n\nbatch_size = 128\n\npreds_1_deberta_l_mlm_rmdp_fx, embeddings1_dl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-deberta-large-mnli-mlm-rm-dp-seed-42-exp804/exp_804_*/microsoft/deberta-large-mnli_seed42_fold0.ckpt', batch_size)\npreds_2_deberta_l_mlm_rmdp_fx, embeddings2_dl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-deberta-large-mnli-mlm-rm-dp-seed-42-exp804/exp_804_*/microsoft/deberta-large-mnli_seed42_fold1.ckpt', batch_size)\npreds_3_deberta_l_mlm_rmdp_fx, embeddings3_dl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-deberta-large-mnli-mlm-rm-dp-seed-42-exp804/exp_804_*/microsoft/deberta-large-mnli_seed42_fold2.ckpt', batch_size)\npreds_4_deberta_l_mlm_rmdp_fx, embeddings4_dl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-deberta-large-mnli-mlm-rm-dp-seed-42-exp804/exp_804_*/microsoft/deberta-large-mnli_seed42_fold3.ckpt', batch_size)\npreds_5_deberta_l_mlm_rmdp_fx, embeddings5_dl_mlm_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-deberta-large-mnli-mlm-rm-dp-seed-42-exp804/exp_804_*/microsoft/deberta-large-mnli_seed42_fold4.ckpt', batch_size)\npreds_deberta_l_mlm_rmdp_fx = (preds_1_deberta_l_mlm_rmdp_fx + preds_2_deberta_l_mlm_rmdp_fx + preds_3_deberta_l_mlm_rmdp_fx + preds_4_deberta_l_mlm_rmdp_fx + preds_5_deberta_l_mlm_rmdp_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:47:08.496454Z","iopub.execute_input":"2021-09-10T06:47:08.496799Z","iopub.status.idle":"2021-09-10T06:49:32.579377Z","shell.execute_reply.started":"2021-09-10T06:47:08.49676Z","shell.execute_reply":"2021-09-10T06:49:32.578439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '../input/electra/large-discriminator'\nCFG.model_path = model_path\nCFG.model_name = 'electra-large-discriminator'\n\nbatch_size = 128\n\npreds_1_el_s2_rmdp_fx, embeddings1_el_s2_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-electra-large-sq2-rm-dp-seed-42-exp827/exp_827_*/ahotrod/electra_large_discriminator_squad2_512_seed42_fold0.ckpt', batch_size)\npreds_2_el_s2_rmdp_fx, embeddings2_el_s2_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-electra-large-sq2-rm-dp-seed-42-exp827/exp_827_*/ahotrod/electra_large_discriminator_squad2_512_seed42_fold1.ckpt', batch_size)\npreds_3_el_s2_rmdp_fx, embeddings3_el_s2_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-electra-large-sq2-rm-dp-seed-42-exp827/exp_827_*/ahotrod/electra_large_discriminator_squad2_512_seed42_fold2.ckpt', batch_size)\npreds_4_el_s2_rmdp_fx, embeddings4_el_s2_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-electra-large-sq2-rm-dp-seed-42-exp827/exp_827_*/ahotrod/electra_large_discriminator_squad2_512_seed42_fold3.ckpt', batch_size)\npreds_5_el_s2_rmdp_fx, embeddings5_el_s2_rmdp_fx = run_inference_fx(test, model_path, '../input/cl-electra-large-sq2-rm-dp-seed-42-exp827/exp_827_*/ahotrod/electra_large_discriminator_squad2_512_seed42_fold4.ckpt', batch_size)\npreds_el_s2_rmdp_fx = (preds_1_el_s2_rmdp_fx + preds_2_el_s2_rmdp_fx + preds_3_el_s2_rmdp_fx + preds_4_el_s2_rmdp_fx + preds_5_el_s2_rmdp_fx) / 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:49:32.582714Z","iopub.execute_input":"2021-09-10T06:49:32.583088Z","iopub.status.idle":"2021-09-10T06:51:42.580366Z","shell.execute_reply.started":"2021-09-10T06:49:32.583045Z","shell.execute_reply":"2021-09-10T06:51:42.579467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concatenate all 9 models embeddings","metadata":{}},{"cell_type":"code","source":"embeddings1 = np.concatenate((normalize(embeddings1_longformer_tqa_fx), normalize(embeddings1_bl_mlm_rmdp_fx), normalize(embeddings1_rl_sq2_mlm_only_pl_fx),\n                              normalize(embeddings1_dl_mlm_rmdp_fx), normalize(embeddings1_xl_fx), normalize(embeddings1_rl_sq2_fx),\n                              normalize(embeddings1_dl_fx), normalize(embeddings1_el_s2_rmdp_fx), normalize(embeddings1_rl_fx_old),  \n                              ), axis=1)\n\nembeddings2 = np.concatenate((normalize(embeddings2_longformer_tqa_fx), normalize(embeddings2_bl_mlm_rmdp_fx), normalize(embeddings2_rl_sq2_mlm_only_pl_fx),\n                              normalize(embeddings2_dl_mlm_rmdp_fx), normalize(embeddings2_xl_fx), normalize(embeddings2_rl_sq2_fx),\n                              normalize(embeddings2_dl_fx), normalize(embeddings2_el_s2_rmdp_fx), normalize(embeddings2_rl_fx_old),  \n                              ), axis=1)\n\nembeddings3 = np.concatenate((normalize(embeddings3_longformer_tqa_fx), normalize(embeddings3_bl_mlm_rmdp_fx), normalize(embeddings3_rl_sq2_mlm_only_pl_fx),\n                              normalize(embeddings3_dl_mlm_rmdp_fx), normalize(embeddings3_xl_fx), normalize(embeddings3_rl_sq2_fx),\n                              normalize(embeddings3_dl_fx), normalize(embeddings3_el_s2_rmdp_fx), normalize(embeddings3_rl_fx_old),  \n                              ), axis=1)\n\nembeddings4 = np.concatenate((normalize(embeddings4_longformer_tqa_fx), normalize(embeddings4_bl_mlm_rmdp_fx), normalize(embeddings4_rl_sq2_mlm_only_pl_fx),\n                              normalize(embeddings4_dl_mlm_rmdp_fx), normalize(embeddings4_xl_fx), normalize(embeddings4_rl_sq2_fx),\n                              normalize(embeddings4_dl_fx), normalize(embeddings4_el_s2_rmdp_fx), normalize(embeddings4_rl_fx_old),  \n                              ), axis=1)\n\nembeddings5 = np.concatenate((normalize(embeddings5_longformer_tqa_fx), normalize(embeddings5_bl_mlm_rmdp_fx), normalize(embeddings5_rl_sq2_mlm_only_pl_fx),\n                              normalize(embeddings5_dl_mlm_rmdp_fx), normalize(embeddings5_xl_fx), normalize(embeddings5_rl_sq2_fx),\n                              normalize(embeddings5_dl_fx), normalize(embeddings5_el_s2_rmdp_fx), normalize(embeddings5_rl_fx_old),  \n                              ), axis=1)\n\nembeddings = [embeddings1, embeddings2, embeddings3, embeddings4, embeddings5]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:51:42.582289Z","iopub.execute_input":"2021-09-10T06:51:42.582875Z","iopub.status.idle":"2021-09-10T06:51:42.606479Z","shell.execute_reply.started":"2021-09-10T06:51:42.582833Z","shell.execute_reply":"2021-09-10T06:51:42.605605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPR inference","metadata":{}},{"cell_type":"code","source":"import pyro\nimport pyro.contrib.gp as gp\n\ndef get_pyro_emb_preds(embedding_path, y_new_path, gpr_model_path, test_embedding, is_normalize=False):\n    pyro.clear_param_store()\n\n    emb_train = np.load(embedding_path, allow_pickle=True)\n    emb_train = np.vstack(emb_train)\n    if is_normalize:\n        X = torch.tensor(normalize(emb_train), dtype=torch.float32).cuda()\n    else:\n        X = torch.tensor((emb_train), dtype=torch.float32).cuda()\n        \n    y_new =  torch.tensor(np.load(y_new_path), dtype=torch.float32).cuda()\n \n    emb_test = np.vstack(test_embedding)\n    if is_normalize:\n        X_test = torch.tensor(normalize(emb_test), dtype=torch.float32).cuda()\n    else:\n        X_test = torch.tensor((emb_test), dtype=torch.float32).cuda()\n        \n    kernel = gp.kernels.RBF(input_dim=X.shape[1], variance=torch.tensor(1.),\n                    lengthscale=torch.tensor(1.)).cuda()\n    gpr = gp.models.GPRegression(X, y_new, kernel, noise=torch.tensor(1.)).cuda()\n    gpr.load_state_dict(torch.load(gpr_model_path, map_location='cuda:0'))\n    \n    with torch.no_grad():\n        mean, cov = gpr(X_test, full_cov=True, noiseless=False)\n    mean = np.array(mean.cpu())\n#     sd = np.array(cov.diag().sqrt().cpu())\n    return mean\n\ngpr_preds_concat_fx = [get_pyro_emb_preds(\n                            '../input/gpr-rbf-best-9/best_9_all_y_embeddings.npy', \n                            '../input/gpr-rbf-best-9/best_9_all_y_y_new.npy',\n                            '../input/gpr-rbf-best-9/best_9_all_y_gpr',\n                            x) for x in embeddings]\npreds_combine = np.mean(gpr_preds_concat_fx, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T06:51:42.607672Z","iopub.execute_input":"2021-09-10T06:51:42.608009Z","iopub.status.idle":"2021-09-10T06:51:46.763881Z","shell.execute_reply.started":"2021-09-10T06:51:42.607975Z","shell.execute_reply":"2021-09-10T06:51:46.76296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.target = (preds_combine)\nsample.to_csv('submission.csv', index=False)\nsample","metadata":{"execution":{"iopub.status.busy":"2021-09-10T07:02:06.583184Z","iopub.execute_input":"2021-09-10T07:02:06.583539Z","iopub.status.idle":"2021-09-10T07:02:06.601181Z","shell.execute_reply.started":"2021-09-10T07:02:06.583505Z","shell.execute_reply":"2021-09-10T07:02:06.600172Z"},"trusted":true},"execution_count":null,"outputs":[]}]}