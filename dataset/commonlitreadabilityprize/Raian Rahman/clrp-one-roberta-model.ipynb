{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-09T00:02:11.305773Z","iopub.execute_input":"2021-07-09T00:02:11.30618Z","iopub.status.idle":"2021-07-09T00:02:11.320756Z","shell.execute_reply.started":"2021-07-09T00:02:11.306121Z","shell.execute_reply":"2021-07-09T00:02:11.319597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsubmission_df = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\ntest_df = test_df[['excerpt']]","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.32224Z","iopub.execute_input":"2021-07-09T00:02:11.322803Z","iopub.status.idle":"2021-07-09T00:02:11.337356Z","shell.execute_reply.started":"2021-07-09T00:02:11.322758Z","shell.execute_reply":"2021-07-09T00:02:11.336476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.338704Z","iopub.execute_input":"2021-07-09T00:02:11.339111Z","iopub.status.idle":"2021-07-09T00:02:11.348801Z","shell.execute_reply.started":"2021-07-09T00:02:11.339071Z","shell.execute_reply":"2021-07-09T00:02:11.347618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup,  AutoConfig\nimport sentencepiece\n\nimport torch\nimport numpy as np\nimport pandas as pd\n\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.35068Z","iopub.execute_input":"2021-07-09T00:02:11.351238Z","iopub.status.idle":"2021-07-09T00:02:11.380694Z","shell.execute_reply.started":"2021-07-09T00:02:11.351195Z","shell.execute_reply":"2021-07-09T00:02:11.379829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.RobertaTokenizer.from_pretrained('../input/roberta-base')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.382267Z","iopub.execute_input":"2021-07-09T00:02:11.382685Z","iopub.status.idle":"2021-07-09T00:02:11.474671Z","shell.execute_reply.started":"2021-07-09T00:02:11.382643Z","shell.execute_reply":"2021-07-09T00:02:11.473741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLitDataset(Dataset):\n  def __init__(self, text, targets = None, tokenizer = transformers.RobertaTokenizer.from_pretrained('../input/roberta-base'), max_len = 256, inference_only = False):\n    self.text = text\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n    self.inference_only = inference_only\n  \n  def __len__(self):\n    return len(self.text)\n  \n  def __getitem__(self, item):\n    text = str(self.text[item])\n    if self.inference_only == False:\n        targets = self.targets[item]\n    \n    encoding = self.tokenizer.encode_plus(\n      text,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      truncation=True,\n      padding = 'max_length',\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    if self.inference_only == True:\n        return {\n          'text': text,\n          'input_ids': encoding['input_ids'].flatten(),\n          'attention_mask': encoding['attention_mask'].flatten(),\n        }\n    else:\n        return {\n          'text': text,\n          'input_ids': encoding['input_ids'].flatten(),\n          'attention_mask': encoding['attention_mask'].flatten(),\n          'targets': torch.tensor(targets, dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.477011Z","iopub.execute_input":"2021-07-09T00:02:11.477647Z","iopub.status.idle":"2021-07-09T00:02:11.569431Z","shell.execute_reply.started":"2021-07-09T00:02:11.477606Z","shell.execute_reply":"2021-07-09T00:02:11.568558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 256","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.571442Z","iopub.execute_input":"2021-07-09T00:02:11.57169Z","iopub.status.idle":"2021-07-09T00:02:11.57594Z","shell.execute_reply.started":"2021-07-09T00:02:11.571666Z","shell.execute_reply":"2021-07-09T00:02:11.575093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len=256, batch_size=8):\n  ds = CommonLitDataset(\n    text = df.excerpt.to_list(),\n    tokenizer=tokenizer,\n    max_len=max_len,\n    inference_only = True\n  )\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=2\n  )","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.577432Z","iopub.execute_input":"2021-07-09T00:02:11.578214Z","iopub.status.idle":"2021-07-09T00:02:11.586552Z","shell.execute_reply.started":"2021-07-09T00:02:11.578168Z","shell.execute_reply":"2021-07-09T00:02:11.585636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ReadabilityModel(nn.Module):\n  def __init__(self):\n\n    super(ReadabilityModel, self).__init__()\n\n    config = AutoConfig.from_pretrained('../input/roberta-base')\n    config.update(\n        {\n            'output_hidden_states':True,\n            'hidden_dropout_prob' : 0.0,\n            'layer_norm_eps': 1e-7\n        }\n    )\n\n\n    self.roberta = RobertaForSequenceClassification.from_pretrained('../input/roberta-base', config = config)\n\n    self.attention = nn.Sequential(\n        nn.Linear(768, 512),\n        nn.Tanh(),\n        nn.Linear(512,1),\n        nn.Softmax(dim=1)\n    )\n    self.regressor = nn.Sequential(\n        nn.Linear(768,1)\n    )\n    \n\n  def forward(self, input_ids, attention_mask):\n    output = self.roberta(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    last_layer_hidden_states = output.hidden_states[-1]\n    \n    weights = self.attention(last_layer_hidden_states)\n\n    context_vector = torch.sum(weights*last_layer_hidden_states, dim = 1)\n\n    return self.regressor(context_vector)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.590442Z","iopub.execute_input":"2021-07-09T00:02:11.59072Z","iopub.status.idle":"2021-07-09T00:02:11.599465Z","shell.execute_reply.started":"2021-07-09T00:02:11.590684Z","shell.execute_reply":"2021-07-09T00:02:11.598572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n    model.eval()\n    \n    results = np.zeros(len(data_loader.dataset))\n    \n    index = 0\n    \n    with torch.no_grad():\n        for batch_num, data in enumerate(data_loader):\n            input_ids  = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            \n            pred = model(input_ids, attention_mask)\n            \n            results[index: index+pred.shape[0]] = pred.flatten().to('cpu')\n            index += pred.shape[0]\n            \n    return results","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.601318Z","iopub.execute_input":"2021-07-09T00:02:11.601939Z","iopub.status.idle":"2021-07-09T00:02:11.610372Z","shell.execute_reply.started":"2021-07-09T00:02:11.601899Z","shell.execute_reply":"2021-07-09T00:02:11.609559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_MODELS = 3\nall_predictions = np.zeros((NUM_MODELS,len(test_df)))\n\ntest_dataloader = create_data_loader(test_df, tokenizer = tokenizer)\n\n\n                        \nmodel = ReadabilityModel()\nmodel.load_state_dict(torch.load('../input/commonlitweights/3.bin', map_location=device))    \nmodel.to(device)\n        \nall_predictions[0] = predict(model, test_dataloader)\n            \ndel model\ngc.collect()\n\n\nmodel = ReadabilityModel()\nmodel.load_state_dict(torch.load('../input/commonlitweights/model-train.bin', map_location=device))    \nmodel.to(device)\n        \nall_predictions[1] = predict(model, test_dataloader)\n            \ndel model\ngc.collect()\n\n\nmodel = ReadabilityModel()\nmodel.load_state_dict(torch.load('../input/commonlitweights/model.bin', map_location=device))    \nmodel.to(device)\n        \nall_predictions[2] = predict(model, test_dataloader)\n            \ndel model\ngc.collect()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:11.611709Z","iopub.execute_input":"2021-07-09T00:02:11.612078Z","iopub.status.idle":"2021-07-09T00:02:18.97391Z","shell.execute_reply.started":"2021-07-09T00:02:11.612039Z","shell.execute_reply":"2021-07-09T00:02:18.973092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:18.975303Z","iopub.execute_input":"2021-07-09T00:02:18.975653Z","iopub.status.idle":"2021-07-09T00:02:18.983211Z","shell.execute_reply.started":"2021-07-09T00:02:18.975616Z","shell.execute_reply":"2021-07-09T00:02:18.98231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred = all_predictions[0]*.4 + all_predictions[1]*.2 + all_predictions[2]*.4","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:18.984751Z","iopub.execute_input":"2021-07-09T00:02:18.985428Z","iopub.status.idle":"2021-07-09T00:02:18.991679Z","shell.execute_reply.started":"2021-07-09T00:02:18.985385Z","shell.execute_reply":"2021-07-09T00:02:18.990508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:18.993152Z","iopub.execute_input":"2021-07-09T00:02:18.993834Z","iopub.status.idle":"2021-07-09T00:02:19.004363Z","shell.execute_reply.started":"2021-07-09T00:02:18.993789Z","shell.execute_reply":"2021-07-09T00:02:19.003418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['target'] = final_pred\nprint(submission_df)\nsubmission_df.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T00:02:19.006127Z","iopub.execute_input":"2021-07-09T00:02:19.006698Z","iopub.status.idle":"2021-07-09T00:02:19.018123Z","shell.execute_reply.started":"2021-07-09T00:02:19.006658Z","shell.execute_reply":"2021-07-09T00:02:19.017039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}