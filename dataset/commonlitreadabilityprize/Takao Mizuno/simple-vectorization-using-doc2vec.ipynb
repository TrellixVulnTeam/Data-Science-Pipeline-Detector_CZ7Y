{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install pandas_profiling\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import pandas_profiling","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.profile_report()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.parsing.preprocessing import remove_stopwords\n\ndf['excerpt_applied_stop_words'] = df['excerpt'].apply(remove_stopwords)\n\ndf['word_count'] = df['excerpt_applied_stop_words'].apply(lambda x: len(x.replace('\\n', '').split(' ')))\ndf['words'] = df['excerpt_applied_stop_words'].apply(lambda x: x.replace('\\n', '').split(' '))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gensim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_list = df['words'].values.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"words_list","metadata":{}},{"cell_type":"code","source":"import os\nfrom gensim.test.utils import get_tmpfile\n\nif not os.path.exists('my_doc2vec_model'):\n    \n    words_list = df['words'].values.tolist()\n    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(words_list)]\n    model = Doc2Vec(documents, vector_size=10, window=5, min_count=1, workers=4)\nelse:\n    fname = get_tmpfile(\"my_doc2vec_model\")\n    model.save(fname)\n    model = Doc2Vec.load(fname)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vars(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model(df['excerpt_applied_stop_words'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vars(model.wv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.wv.vectors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx = model.wv.vectors.T[0]\ny = model.wv.vectors.T[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(x, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n\n\nX = model.wv.vectors\n\npca = PCA(n_components=2)\npca.fit(X)\nXd = pca.transform(X)\n\nprint(Xd)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(Xd.T[0], Xd.T[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['vector'] = df['words'].apply(lambda x: (model.infer_vector(x).tolist()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['vector'] = df['words'].apply(lambda x: (model.infer_vector(x).tolist()))\nfeatures = np.array(df['vector'].values.tolist()).astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.utils.data as data_utils\n\ndf['target'].values.reshape(-1,1).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain = data_utils.TensorDataset(torch.tensor(features), torch.tensor(df['target'].values.reshape(-1, 1).astype(np.float32)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\n# NOTE: pretty simple NN model\nclass SimpleNN(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.Linear(10, 100)\n        self.l2 = nn.Linear(100, 200)\n        self.l3 = nn.Linear(200, 50)\n        self.l4 = nn.Linear(50, 1)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        x = self.relu(self.l1(x))\n        x = self.relu(self.l2(x))\n        x = self.relu(self.l3(x))\n        x = self.l4(x)\n        return x\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(1)\n\ndev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_model = SimpleNN()\nprint(train_model)\n\ntrain_model = train_model.to(dev)\n\noptimizer = torch.optim.Adam(train_model.parameters(), lr=0.01)\n\nloss_func = nn.MSELoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCH = 10000\n\nloader = torch.utils.data.DataLoader(\n    dataset=train, \n    batch_size=BATCH_SIZE, \n    shuffle=True, num_workers=2,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# FIXME: some codes have an fatal error probably because loss wouldn't decrease..\nfor epoch in tqdm(range(EPOCH)):\n    losses = []\n    for step, (b_x, b_y) in enumerate(loader):\n        optimizer.zero_grad()   # clear gradients for next train\n        b_x, b_y = b_x.to(dev), b_y.to(dev)\n        prediction = train_model(b_x)     # input x and predict based on x\n        loss = loss_func(prediction, b_y)     # must be (1. nn output, 2. target)\n        losses.append(loss)\n        loss.backward()         # backpropagation, compute gradients\n        optimizer.step()        # apply gradients\n\n    print(sum(losses) / len(losses))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(train_model.state_dict(), 'model.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['excerpt_applied_stop_words'] = test_df['excerpt'].apply(remove_stopwords)\n\ntest_df['word_count'] = test_df['excerpt_applied_stop_words'].apply(lambda x: len(x.replace('\\n', '').split(' ')))\ntest_df['words'] = test_df['excerpt_applied_stop_words'].apply(lambda x: x.replace('\\n', '').split(' '))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['vector'] = test_df['words'].apply(lambda x: (model.infer_vector(x).tolist()))\nfeatures = np.array(test_df['vector'].values.tolist()).astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for l in test_df['vector'].values:\n    print(np.array(l).astype(np.float32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = torch.tensor([np.array(l).astype(np.float32) for l in test_df['vector'].values])\ntest_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_result = train_model(test_data.to(dev)).reshape(1, -1)[0]\ntest_result.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test_df['id'],'target': test_result.tolist()})\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}