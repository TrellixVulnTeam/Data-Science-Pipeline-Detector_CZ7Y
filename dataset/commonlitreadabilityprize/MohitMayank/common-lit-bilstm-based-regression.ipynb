{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Commonlit | biLSTM Sentence encoder\n\n","metadata":{}},{"cell_type":"code","source":"# import\nimport pandas as pd\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"code","source":"# data preparation\n\n# combine the dataset\ncombined = pd.concat([train['excerpt'], test['excerpt']])\n# set vocab count\nvocab = 10000\ntokenizer = Tokenizer(num_words=vocab, oov_token=0)\ntokenizer.fit_on_texts(combined) \nsequence_combined = tokenizer.texts_to_sequences(combined)\nmax_len = max([len(x) for x in sequence_combined])\nsequences = tokenizer.texts_to_sequences(train['excerpt'])\npadded_seq = pad_sequences(sequences, maxlen=max_len, dtype='int32', padding='pre',truncating='pre', value=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## biLSTM based Regression Model\n\n- Sentence encoder: biLSTM\n- Target decoder: Regression model","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mode\nmodel = Sequential()\n# encoder\nmodel.add(keras.Input(shape=(padded_seq.shape[1], )))\nmodel.add(Embedding(vocab, 300))\nmodel.add(Bidirectional(LSTM(256)))\n# decoder\nmodel.add(Dense(256, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(32, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(16, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(8, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='linear'))\n# summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks\nearlystopping = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\n# compile\nmodel.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n\n# fit\nhistory = model.fit(padded_seq, train['target'], epochs=100, batch_size=32, verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nprint(history.history.keys())\n# \"Loss\"\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test data","metadata":{}},{"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(test['excerpt'])\ntest_pad_sequences = pad_sequences(test_sequences, maxlen=max_len, dtype='int32', padding='pre',truncating='pre', value=0)\ny_pred = model.predict(test_pad_sequences)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub = test[['id']].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = y_pred\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}