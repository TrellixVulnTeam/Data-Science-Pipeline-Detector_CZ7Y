{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport time\nimport string\nimport pickle\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\n\nimport torch\nimport torch.nn as nn\n\nimport seaborn as sns\n\nfrom nltk.stem import WordNetLemmatizer\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n\nfrom collections import defaultdict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T05:33:40.823581Z","iopub.execute_input":"2021-05-24T05:33:40.824009Z","iopub.status.idle":"2021-05-24T05:33:42.132084Z","shell.execute_reply.started":"2021-05-24T05:33:40.823923Z","shell.execute_reply":"2021-05-24T05:33:42.130988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/model-baseline/word_doc_freq', 'rb') as file:\n    word_doc_freq=pickle.load(file)\n\nwith open('../input/model-baseline/vocab', 'rb') as file:\n    vocab=pickle.load(file)\nprint(len(word_doc_freq))\nprint(len(vocab))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:33:42.13374Z","iopub.execute_input":"2021-05-24T05:33:42.134238Z","iopub.status.idle":"2021-05-24T05:33:42.157813Z","shell.execute_reply.started":"2021-05-24T05:33:42.134193Z","shell.execute_reply":"2021-05-24T05:33:42.156891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_df=pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:33:42.159592Z","iopub.execute_input":"2021-05-24T05:33:42.159982Z","iopub.status.idle":"2021-05-24T05:33:42.181988Z","shell.execute_reply.started":"2021-05-24T05:33:42.159949Z","shell.execute_reply":"2021-05-24T05:33:42.1811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Glove 100-d vectors","metadata":{}},{"cell_type":"code","source":"glove_path='../input/glove6b100dtxt/glove.6B.100d.txt'\nglove_embeddings={}\nwith open(glove_path) as file:\n    for line in file:\n        line=line.split()\n        word=line[0]\n        v=np.array(line[1:]).astype(np.float)\n        glove_embeddings[word]=v\nprint(len(glove_embeddings))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:33:42.183481Z","iopub.execute_input":"2021-05-24T05:33:42.183792Z","iopub.status.idle":"2021-05-24T05:34:24.943484Z","shell.execute_reply.started":"2021-05-24T05:33:42.183748Z","shell.execute_reply":"2021-05-24T05:34:24.942337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Tokenizer:\n    def __init__(self):\n        self.lemmatizer=WordNetLemmatizer()\n        self.nlp=English()\n    def __call__(self, doc):\n        tokens=[]\n        for token in self.nlp(doc):\n            if token.like_num or token.text=='':\n                continue\n            token=token.lower_.strip()\n            for p in string.punctuation:\n                token=token.replace(p, ' ')\n            token=token.split(' ')\n            token=[w for w in token if w!='']\n            tokens+=token\n        return tokens","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:24.944968Z","iopub.execute_input":"2021-05-24T05:34:24.945288Z","iopub.status.idle":"2021-05-24T05:34:24.95274Z","shell.execute_reply.started":"2021-05-24T05:34:24.945257Z","shell.execute_reply":"2021-05-24T05:34:24.951658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Masked Word Document","metadata":{}},{"cell_type":"code","source":"def get_masked_doc(doc):\n    masked_doc=[]\n    for word in doc:\n        if word_doc_freq[word]>=5:\n            masked_doc.append(word)\n        else:\n            masked_doc.append('<MASK>')\n    return masked_doc\n\ndef get_rare_words(doc):\n    words=set()\n    for word in doc:\n        if (word in word_doc_freq) and word_doc_freq[word]<5:\n            words.add(word)\n    return list(words)\n\n\ntokenizer=Tokenizer()\ntest_df['doc']=test_df.excerpt.apply(tokenizer)\ntest_df['masked_doc']=test_df.doc.apply(get_masked_doc)\ntest_df['rare_words']=test_df.doc.apply(get_rare_words)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:24.953941Z","iopub.execute_input":"2021-05-24T05:34:24.954213Z","iopub.status.idle":"2021-05-24T05:34:25.497598Z","shell.execute_reply.started":"2021-05-24T05:34:24.954186Z","shell.execute_reply":"2021-05-24T05:34:25.49687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"MAX_SEQ_LEN=100\nBATCH_SIZE=128\nvocab_len=len(vocab)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.498686Z","iopub.execute_input":"2021-05-24T05:34:25.499152Z","iopub.status.idle":"2021-05-24T05:34:25.50269Z","shell.execute_reply.started":"2021-05-24T05:34:25.49912Z","shell.execute_reply":"2021-05-24T05:34:25.501943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target_mean=train_df.target.mean()\n#target_std=train_df.target.std()\n\ntarget_mean=-0.9625387984618096\ntarget_std= 1.0382744351056232\nprint(\"Taget Mean:\", target_mean)\nprint(\"Taget Std:\", target_std)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.505051Z","iopub.execute_input":"2021-05-24T05:34:25.505602Z","iopub.status.idle":"2021-05-24T05:34:25.521187Z","shell.execute_reply.started":"2021-05-24T05:34:25.505567Z","shell.execute_reply":"2021-05-24T05:34:25.520142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, df, phase):\n        self.df=df\n        self.phase=phase\n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        masked_doc=row.masked_doc\n        rare_words=row.rare_words\n        \n        X=torch.zeros(MAX_SEQ_LEN, dtype=torch.long)\n        rare_embedds=torch.zeros(100, dtype=torch.float32)\n        cnt=0\n        for rare_word in rare_words:\n            if rare_word in glove_embeddings:\n                rare_embedds += torch.tensor(glove_embeddings[rare_word], dtype=torch.float32)\n                cnt+=1\n        if cnt>0:\n            rare_embedds/=cnt   \n        for i, word in enumerate(masked_doc):\n            if i >= MAX_SEQ_LEN:\n                break\n            if word in vocab:\n                X[i]=vocab[word]\n            else:\n                X[i]=vocab['<MASK>']\n        if self.phase=='train':\n            #y=torch.tensor(row.target, dtype=torch.float32)\n            y=torch.tensor(row.normalized_target, dtype=torch.float32)\n            return (X, rare_embedds, y)\n        return (X, rare_embedds)\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.522706Z","iopub.execute_input":"2021-05-24T05:34:25.523254Z","iopub.status.idle":"2021-05-24T05:34:25.536738Z","shell.execute_reply.started":"2021-05-24T05:34:25.52322Z","shell.execute_reply":"2021-05-24T05:34:25.535905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class ProjectionHead(nn.Module):\n    def __init__(self, in_features,out_feat):\n        super().__init__()\n        self.linear1=nn.Linear(in_features, 512)\n        self.bn=nn.BatchNorm1d(512)\n        self.dropout=nn.Dropout(0.2)\n        self.relu=nn.ReLU()\n        self.linear2=nn.Linear(512, out_feat)\n    def forward(self, x):\n        x=self.linear1(x)\n        x=self.bn(x)\n        x=self.dropout(x)\n        x=self.relu(x)\n        x=self.linear2(x)\n        return x\n\n    \nclass MaskModelEmbedding(nn.Module):\n    def __init__(self, embedd_size, hidden_size):\n        super().__init__()\n        self.hidden_size=hidden_size\n        self.embedding=nn.Embedding( len(vocab),embedd_size,padding_idx=0)\n        self.gru=nn.GRU(embedd_size, hidden_size, num_layers=2, dropout=0.4, bidirectional=True, batch_first=True)\n    def forward(self, x):\n        X_embedd=self.embedding(x)\n        batch_size=X_embedd.shape[0]\n        (_, h_n)=self.gru(X_embedd)\n        h_n=h_n.view(2, 2, batch_size, self.hidden_size)\n        h_n=h_n[1, :, :, :].permute(1, 0, 2)\n        h_n1=h_n[:, 0, :]\n        h_n2=h_n[:, 1, :]\n        h=torch.cat([h_n1, h_n2], dim=1)\n        return h\n    \nclass RareWordEmbedding(nn.Module):\n    def __init__(self, glove_embedd_dim, out_dim1, out_dim2):\n        super().__init__()\n        self.linear1=nn.Linear(glove_embedd_dim, out_dim1)\n        self.bn=nn.BatchNorm1d(out_dim1)\n        self.dropout=nn.Dropout(0.2)\n        self.relu=nn.ReLU()\n        self.linear2=nn.Linear(out_dim1, out_dim2)\n    def forward(self, x):\n        x=self.linear1(x)\n        x=self.bn(x)\n        x=self.dropout(x)\n        x=self.relu(x)\n        x=self.linear2(x)\n        return x\n\n\nclass Model(nn.Module):\n    def __init__(self, mask_embedd_size, mask_hidden_size, glove_embedd_dim, rare_out_dim1, rare_out_dim2):\n        super().__init__()\n        self.mask_embedding=MaskModelEmbedding(mask_embedd_size, mask_hidden_size)\n        self.rare_embedding=RareWordEmbedding(glove_embedd_dim, rare_out_dim1, rare_out_dim2)\n        \n        self.bn=nn.BatchNorm1d(2*mask_hidden_size + rare_out_dim2)\n        self.relu=nn.ReLU()\n        self.dropout=nn.Dropout(0.2)\n        self.proj_head=ProjectionHead((2*mask_hidden_size + rare_out_dim2), 1)\n    def forward(self, x, rareEmbedding):\n        h1=self.mask_embedding(x)\n        h2=self.rare_embedding(rareEmbedding)\n        h=torch.cat([h1, h2], dim=1)\n        y=self.proj_head(h)\n        return y","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.537955Z","iopub.execute_input":"2021-05-24T05:34:25.538446Z","iopub.status.idle":"2021-05-24T05:34:25.560215Z","shell.execute_reply.started":"2021-05-24T05:34:25.538413Z","shell.execute_reply":"2021-05-24T05:34:25.559006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[\n    torch.load('../input/model-baseline/model_1.pt'),\n    torch.load('../input/model-baseline/model_2.pt'),\n    torch.load('../input/model-baseline/model_3.pt'),\n    torch.load('../input/model-baseline/model_4.pt'),\n    torch.load('../input/model-baseline/model_5.pt')\n]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.561897Z","iopub.execute_input":"2021-05-24T05:34:25.562201Z","iopub.status.idle":"2021-05-24T05:34:25.65821Z","shell.execute_reply.started":"2021-05-24T05:34:25.562172Z","shell.execute_reply":"2021-05-24T05:34:25.657012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(dataloader):\n    preds=[]\n    for (X, rareEmbedd) in dataloader:\n        with torch.no_grad():\n            y=torch.zeros(X.shape[0])\n            for model in models:\n                model.eval()\n                y_hat=model(X, rareEmbedd).view(-1)\n                y_hat=(target_std*y_hat) + target_mean\n                y+=y_hat\n            y/=len(models)\n            preds+=list(y.numpy())\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.659439Z","iopub.execute_input":"2021-05-24T05:34:25.659722Z","iopub.status.idle":"2021-05-24T05:34:25.665721Z","shell.execute_reply.started":"2021-05-24T05:34:25.659694Z","shell.execute_reply":"2021-05-24T05:34:25.664992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer_test_dataset=Dataset(test_df, 'test')\ninfer_test_dataloader=torch.utils.data.DataLoader(infer_test_dataset, batch_size=200, shuffle=False)\ntest_df['target'] = infer(infer_test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.666932Z","iopub.execute_input":"2021-05-24T05:34:25.667375Z","iopub.status.idle":"2021-05-24T05:34:25.882022Z","shell.execute_reply.started":"2021-05-24T05:34:25.667343Z","shell.execute_reply":"2021-05-24T05:34:25.881172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df=test_df[['id', 'target']].copy()\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.883265Z","iopub.execute_input":"2021-05-24T05:34:25.883802Z","iopub.status.idle":"2021-05-24T05:34:25.896909Z","shell.execute_reply.started":"2021-05-24T05:34:25.883741Z","shell.execute_reply":"2021-05-24T05:34:25.895918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T05:34:25.898288Z","iopub.execute_input":"2021-05-24T05:34:25.898616Z","iopub.status.idle":"2021-05-24T05:34:25.913099Z","shell.execute_reply.started":"2021-05-24T05:34:25.898584Z","shell.execute_reply":"2021-05-24T05:34:25.9118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}