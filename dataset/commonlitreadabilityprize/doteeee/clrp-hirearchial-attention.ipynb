{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport time\nimport string\nimport random\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport seaborn as sns\n\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom torch.nn.functional import softmax\n\nfrom collections import defaultdict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-08T13:27:33.328546Z","iopub.execute_input":"2021-07-08T13:27:33.32889Z","iopub.status.idle":"2021-07-08T13:27:33.335094Z","shell.execute_reply.started":"2021-07-08T13:27:33.328861Z","shell.execute_reply":"2021-07-08T13:27:33.334066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\nhttp://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder\n\nhttps://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf","metadata":{}},{"cell_type":"code","source":"def seed_everything():\n    np.random.seed(42)\n    torch.manual_seed(42)\n    torch.cuda.manual_seed(42)\n    torch.cuda.manual_seed_all(42)\n    \nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:27:33.336368Z","iopub.execute_input":"2021-07-08T13:27:33.336696Z","iopub.status.idle":"2021-07-08T13:27:33.348926Z","shell.execute_reply.started":"2021-07-08T13:27:33.336597Z","shell.execute_reply":"2021-07-08T13:27:33.34808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    glove_path='../input/glove6b100dtxt/glove.6B.100d.txt'\n    glove_dim=100\n    \n    word_hdim=256\n    word_ff_dim=512\n    \n    sent_hdim=512\n    sent_ff_dim=512\n    \n    learning_rate=1e-4\n    weight_decay=1e-5\n    optimizer='AdamW'\n    \n    batch_size=128\n    max_passage_len=250\n    max_sentence_len=100\n    overlap_sentence_len=10\n    max_num_sents=30\n    \n    \n    folds=5\n    epochs=25\n    eval_every=10\n    clip_gradient_norm=1.0\n    device=torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:27:33.350566Z","iopub.execute_input":"2021-07-08T13:27:33.351011Z","iopub.status.idle":"2021-07-08T13:27:33.358574Z","shell.execute_reply.started":"2021-07-08T13:27:33.350982Z","shell.execute_reply":"2021-07-08T13:27:33.356443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Glove 100-d vectors","metadata":{}},{"cell_type":"code","source":"%%time\nglove_embeddings={}\nwith open(CONFIG.glove_path) as file:\n    for line in file:\n        line=line.split()\n        word=line[0]\n        v=np.array(line[1:]).astype(np.float)\n        glove_embeddings[word]=v\nprint(len(glove_embeddings))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:27:33.359936Z","iopub.execute_input":"2021-07-08T13:27:33.360896Z","iopub.status.idle":"2021-07-08T13:28:13.428119Z","shell.execute_reply.started":"2021-07-08T13:27:33.36085Z","shell.execute_reply":"2021-07-08T13:28:13.427106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"class Tokenizer:\n    def __init__(self):\n        self.lemmatizer=WordNetLemmatizer()\n    def is_valid(self, word):\n        if (not word.isascii()) or word.isnumeric() or (len(word)==0):\n            return False\n        for p in string.punctuation:\n            if word == p:\n                return False\n        return True\n    def __call__(self, doc):\n        sentence_id=0\n        tokens=[];sent_ids=[]\n        for sentence in sent_tokenize(doc):\n            words=[word.strip().lower() for word in word_tokenize(sentence)]\n            words=[self.lemmatizer.lemmatize(word) for word in words if self.is_valid(word)]\n            words_len=len(words)\n            i=0\n            \n            while i < words_len:\n                cur_tokens=words[i: i+CONFIG.max_sentence_len]\n                tokens+=cur_tokens\n                sent_ids+=[sentence_id]*len(cur_tokens)\n                sentence_id+=1\n                i+=CONFIG.max_sentence_len-CONFIG.overlap_sentence_len\n                break\n        return {\n            'tokens': tokens,\n            'sent_ids': sent_ids\n        }","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:13.429548Z","iopub.execute_input":"2021-07-08T13:28:13.429924Z","iopub.status.idle":"2021-07-08T13:28:13.43882Z","shell.execute_reply.started":"2021-07-08T13:28:13.429886Z","shell.execute_reply":"2021-07-08T13:28:13.437975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=Tokenizer()\n\ntrain_df=pd.read_csv('../input/commonlit-kfold-dataset/fold_train.csv')\ntrain_df['inputs']=train_df.excerpt.apply(tokenizer)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:13.440498Z","iopub.execute_input":"2021-07-08T13:28:13.44085Z","iopub.status.idle":"2021-07-08T13:28:26.815082Z","shell.execute_reply.started":"2021-07-08T13:28:13.44082Z","shell.execute_reply":"2021-07-08T13:28:26.814261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sentence_counts(inputs):\n    sent_ids=inputs['sent_ids']\n    return np.max(sent_ids)\n\ndef get_max_tokens_count(inputs):\n    tokens=inputs['tokens']\n    sent_ids=inputs['sent_ids']\n    num_tokens=len(tokens)\n    \n    i=0;sid=0; cnt=0\n    max_cnt=0\n    while i < num_tokens:\n        cnt+=1\n        if sent_ids[i]!=sid:\n            sid=sent_ids[i]\n            max_cnt=max(cnt, max_cnt)\n            cnt=0\n        i+=1\n    max_cnt=max(cnt, max_cnt)\n    return max_cnt\n\ndef get_num_tokens(inputs):\n    tokens=inputs['tokens']\n    return len(tokens)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:26.816607Z","iopub.execute_input":"2021-07-08T13:28:26.816888Z","iopub.status.idle":"2021-07-08T13:28:26.823658Z","shell.execute_reply.started":"2021-07-08T13:28:26.816862Z","shell.execute_reply":"2021-07-08T13:28:26.822726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['num_sents']=train_df['inputs'].apply(get_sentence_counts)\ntrain_df['max_sent_tokens']=train_df['inputs'].apply(get_max_tokens_count)\ntrain_df['num_tokens']=train_df['inputs'].apply(get_num_tokens)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:26.824761Z","iopub.execute_input":"2021-07-08T13:28:26.825039Z","iopub.status.idle":"2021-07-08T13:28:27.133479Z","shell.execute_reply.started":"2021-07-08T13:28:26.825013Z","shell.execute_reply":"2021-07-08T13:28:27.132397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_train_df=train_df[train_df.kfold!=0].copy()\nfold_val_df  =train_df[train_df.kfold==0].copy()\n\nprint(\"Train Fold:\", len(fold_train_df))\nprint(\"Val Fold: \", len(fold_val_df))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.134835Z","iopub.execute_input":"2021-07-08T13:28:27.135196Z","iopub.status.idle":"2021-07-08T13:28:27.161648Z","shell.execute_reply.started":"2021-07-08T13:28:27.135138Z","shell.execute_reply":"2021-07-08T13:28:27.160829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class CLRPDataset(torch.utils.data.Dataset):\n    def __init__(self, df, phase):\n        self.df=df\n        self.phase=phase\n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        inputs=row.inputs\n        tokens=inputs['tokens'][:CONFIG.max_passage_len]\n        sent_ids=torch.tensor(inputs['sent_ids'][:CONFIG.max_passage_len], dtype=torch.long)\n        \n        X=torch.zeros((CONFIG.max_passage_len, CONFIG.glove_dim), dtype=torch.float32)\n        sids=torch.zeros(CONFIG.max_passage_len, dtype=torch.long)\n        sids=torch.fill_(sids, -1)\n        sids[:len(sent_ids)]=sent_ids\n        \n        num_sents=torch.max(sids)+1\n        for i, token in enumerate(tokens):\n            if token in glove_embeddings:\n                X[i]=torch.tensor(glove_embeddings[token])\n                \n        if self.phase in ['train', 'val']:\n            y=torch.tensor(row.target, dtype=torch.float32)\n            return (num_sents, sids, X, y)\n        return (num_sents,sids, X)\n        \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.164387Z","iopub.execute_input":"2021-07-08T13:28:27.164655Z","iopub.status.idle":"2021-07-08T13:28:27.181283Z","shell.execute_reply.started":"2021-07-08T13:28:27.164628Z","shell.execute_reply":"2021-07-08T13:28:27.180642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Wrappers:\n    def __init__(self):\n        pass\n    def unwrap_sentences(self, nsents, sids, X):\n        batch_size=len(nsents)\n        batch_sents_count=nsents.sum().item()\n        unwrapX=torch.zeros( (batch_sents_count, CONFIG.max_sentence_len, CONFIG.glove_dim) )\n        mask=torch.zeros((batch_sents_count, CONFIG.max_sentence_len))\n        unwrap_sentid=0\n        batch_max_seq_len=0\n        slens=[]\n        \n        for i in range(batch_size):\n            for sent_id in range(nsents[i]):\n                curX=X[i][ sids[i]==sent_id ]\n                curX=curX[:CONFIG.max_sentence_len, :]\n                unwrapX[unwrap_sentid, :len(curX), :]=curX\n                batch_max_seq_len=max(batch_max_seq_len, len(curX))\n                mask[unwrap_sentid, :len(curX)]=1\n                unwrap_sentid+=1\n                slens.append(len(curX))\n        unwrapX=unwrapX[:, :batch_max_seq_len, :]\n        mask=mask[:, :batch_max_seq_len]\n        slens=torch.tensor(slens, dtype=torch.long)\n        return unwrapX, slens, mask\n    \n    def wrap_sentences(self, nsents, unwrapX):\n        batch_size=len(nsents)\n        sent_start=0; sent_end=0;batch_max_sents=0\n        wrapX=torch.zeros((batch_size, CONFIG.max_num_sents, 2*CONFIG.word_hdim))\n        mask=torch.zeros(batch_size, CONFIG.max_num_sents)\n        \n        for i in range(batch_size):\n            num_sents=nsents[i].item()\n            sent_end+=num_sents\n            for j in range(sent_start, sent_end):\n                if j-sent_start>=CONFIG.max_num_sents:\n                    break\n                wrapX[i][j-sent_start] = unwrapX[j]\n                mask[i][j-sent_start]=1\n                batch_max_sents=max(batch_max_sents, j-sent_start)\n            sent_start=sent_end\n        wrapX=wrapX[:, :batch_max_sents, :]\n        mask=mask[:, :batch_max_sents]\n        return wrapX, mask","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.182408Z","iopub.execute_input":"2021-07-08T13:28:27.182804Z","iopub.status.idle":"2021-07-08T13:28:27.196245Z","shell.execute_reply.started":"2021-07-08T13:28:27.18276Z","shell.execute_reply":"2021-07-08T13:28:27.195395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def attention(q, k, v, mask, dropout):\n    d=q.size(-1)\n    scores=torch.matmul(q, k.transpose(-2, -1))/np.sqrt(d)\n    if mask is not None:\n        scores.masked_fill_(mask.unsqueeze(-1)==0, -1e-9)\n    p_attn=softmax(scores, dim=-1)\n    if dropout is not None:\n        p_attn=dropout(p_attn)\n    return torch.matmul(p_attn, v), p_attn","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.197553Z","iopub.execute_input":"2021-07-08T13:28:27.197993Z","iopub.status.idle":"2021-07-08T13:28:27.210225Z","shell.execute_reply.started":"2021-07-08T13:28:27.197957Z","shell.execute_reply":"2021-07-08T13:28:27.209583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordPooling(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear=nn.Linear(2*CONFIG.word_hdim, 1)\n    def forward(self, x, unwrap_mask):\n        unwrap_mask=unwrap_mask.unsqueeze(-1)\n        w=self.linear(x)\n        w=w.masked_fill_(unwrap_mask==0, -1e-9)\n        w=softmax(w, dim=1)#[bs, seq_len] summed to probabilies\n        x=x.permute(0, 2, 1)\n        x=torch.matmul(x, w).squeeze(-1)\n        return x\n    \nclass SentencePooling(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear=nn.Linear(2*CONFIG.sent_hdim, 1)\n    def forward(self, x, wrap_mask):\n        wrap_mask=wrap_mask.unsqueeze(-1)\n        w=self.linear(x)\n        w=w.masked_fill_(wrap_mask==0, -1e-9)\n        w=softmax(w, dim=1)#[bs, seq_len] summed to probabilies\n        x=x.permute(0, 2, 1)\n        x=torch.matmul(x, w).squeeze(-1)\n        return x\n\nclass ProjectionHead(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bn=nn.BatchNorm1d(2*CONFIG.sent_hdim)\n        self.dropout=nn.Dropout(0.2)\n        self.relu=nn.ReLU()\n        self.linear=nn.Linear(2*CONFIG.sent_hdim, 1)\n    def forward(self, x):\n        x=self.bn(x)\n        x=self.dropout(x)\n        x=self.relu(x)\n        x=self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.21285Z","iopub.execute_input":"2021-07-08T13:28:27.213093Z","iopub.status.idle":"2021-07-08T13:28:27.224878Z","shell.execute_reply.started":"2021-07-08T13:28:27.213072Z","shell.execute_reply":"2021-07-08T13:28:27.224222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointWiseFeedforward(nn.Module):\n    def __init__(self, dmodel):\n        super().__init__()\n        self.linear1=nn.Linear(dmodel, 2*dmodel)\n        self.relu=nn.ReLU()\n        self.linear2=nn.Linear(2*dmodel, dmodel)\n        self.dropout=nn.Dropout(0.2)\n        self.layer_norm=nn.LayerNorm(dmodel)\n    def forward(self, x):\n        x1=self.dropout(self.relu(self.linear1(x)))\n        x_ffn=self.linear2(x1)\n        return self.layer_norm(x+x_ffn)\n    \nclass TransformerLayer(nn.Module):\n    def __init__(self, dmodel):\n        super().__init__()\n        self.linearQ=nn.Linear(dmodel, dmodel)\n        self.linearK=nn.Linear(dmodel, dmodel)\n        self.linearV=nn.Linear(dmodel, dmodel)\n        self.layer_norm=nn.LayerNorm(dmodel)\n        self.dropout=nn.Dropout(0.2)\n        self.point_wise_ff=PointWiseFeedforward(dmodel)\n        \n    def forward(self, x, mask):\n        q=self.linearQ(x)\n        k=self.linearK(x)\n        v=self.linearV(x)\n        \n        x_attn_out, p_attn=attention(q, k, v, mask, self.dropout)\n        x=self.layer_norm(x+x_attn_out)\n        x=self.point_wise_ff(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.2266Z","iopub.execute_input":"2021-07-08T13:28:27.227058Z","iopub.status.idle":"2021-07-08T13:28:27.236793Z","shell.execute_reply.started":"2021-07-08T13:28:27.227007Z","shell.execute_reply":"2021-07-08T13:28:27.236029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.word_encoder=nn.GRU(CONFIG.glove_dim, CONFIG.word_hdim, bidirectional=True, \n                                 num_layers=1, batch_first=True)\n        \n        self.transformer_layer1=TransformerLayer(2*CONFIG.word_hdim)\n        self.transformer_layer2=TransformerLayer(2*CONFIG.word_hdim)\n        self.dropout=nn.Dropout(0.2)\n        self.relu=nn.ReLU()\n        \n    def forward(self, x, mask):\n        x, _=self.word_encoder(x)\n        x=self.transformer_layer1(x, mask)\n        x=self.dropout(self.relu(x))\n        x=self.transformer_layer2(x, mask)\n        return x\n    \nclass SentenceEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.sent_encoder=nn.GRU(2*CONFIG.word_hdim, CONFIG.sent_hdim, bidirectional=True, batch_first=True)\n        self.transformer_layer1=TransformerLayer(2*CONFIG.sent_hdim)\n        self.transformer_layer2=TransformerLayer(2*CONFIG.sent_hdim)\n        self.dropout=nn.Dropout(0.2)\n        self.relu=nn.ReLU()\n    def forward(self, x, mask):\n        x,_=self.sent_encoder(x)\n        x=self.transformer_layer1(x, mask)\n        x=self.dropout(self.relu(x))\n        x=self.transformer_layer2(x, mask)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.237841Z","iopub.execute_input":"2021-07-08T13:28:27.238187Z","iopub.status.idle":"2021-07-08T13:28:27.250926Z","shell.execute_reply.started":"2021-07-08T13:28:27.238149Z","shell.execute_reply":"2021-07-08T13:28:27.25018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wrapper=Wrappers()\n        \n        self.word_encoder=WordEncoder()\n        self.word_pooling=WordPooling()\n        \n        self.sent_encoder=SentenceEncoder()\n        self.sent_pooling=SentencePooling()\n        \n        self.proj_head=ProjectionHead()\n    \n    def forward(self, inputs):\n        num_sents=inputs['num_sents']\n        sids=inputs['sids']\n        X=inputs['X']\n        \n        unwrapX, slens, unwrap_mask=self.wrapper.unwrap_sentences(num_sents, sids, X)\n        unwrapX=unwrapX.to(CONFIG.device)\n        unwrap_mask=unwrap_mask.to(CONFIG.device)\n        \n        word_encode=self.word_encoder(unwrapX, unwrap_mask)\n        word_pool=self.word_pooling(word_encode, unwrap_mask)\n        \n        wrapX, wrap_mask=self.wrapper.wrap_sentences(num_sents, word_pool)\n        wrapX=wrapX.to(CONFIG.device)\n        wrap_mask=wrap_mask.to(CONFIG.device)\n        \n        sent_encode=self.sent_encoder(wrapX, wrap_mask)\n        sent_pool=self.sent_pooling(sent_encode, wrap_mask)\n        \n        y=self.proj_head(sent_pool)\n        return y","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.251843Z","iopub.execute_input":"2021-07-08T13:28:27.252081Z","iopub.status.idle":"2021-07-08T13:28:27.264488Z","shell.execute_reply.started":"2021-07-08T13:28:27.252059Z","shell.execute_reply":"2021-07-08T13:28:27.263749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_dataloader, val_dataloader):\n        self.model=model\n        self.criterion=nn.MSELoss(reduction='mean')\n        self.train_dataloader=train_dataloader\n        self.val_dataloader=val_dataloader\n        self.optimizer=torch.optim.AdamW(model.parameters(),\n                                         lr=CONFIG.learning_rate, \n                                         weight_decay=CONFIG.weight_decay\n                                        )\n        self.schedular=torch.optim.lr_scheduler.OneCycleLR(self.optimizer, \n                                                           max_lr=CONFIG.learning_rate,\n                                                           epochs=CONFIG.epochs,\n                                                           steps_per_epoch=len(self.train_dataloader))\n        \n        self.iter_count=0\n        self.best_loss=None\n        self.best_iteration=None\n        self.train_loss_=[]\n        self.val_loss_=[]\n        \n    def evaluate(self):\n        self.model.eval()\n        ytrue=[]; ypred=[];\n        for (num_sents, sids, X, y) in self.val_dataloader:\n            X=X.to(CONFIG.device)\n            ytrue+=y.view(-1).tolist()\n            \n            inputs={\n                    'num_sents': num_sents,\n                    'sids': sids,\n                    'X': X\n            }\n            with torch.no_grad():\n                yhat=self.model(inputs)\n                yhat=yhat.view(-1).detach().cpu()\n                ypred+=yhat.tolist()\n        ytrue=torch.tensor(ytrue, dtype=torch.float32)\n        ypred=torch.tensor(ypred, dtype=torch.float32)\n        return self.criterion(ypred, ytrue).item()\n    \n    def checkpoint(self, val_loss):\n        if self.best_loss is None or self.best_loss > val_loss:\n            torch.save(model, 'best_model.pt')\n            self.best_loss=val_loss\n            self.best_iteration=self.iter_count\n    \n    def train_ops(self, inputs, y):\n        self.model.train()\n        self.optimizer.zero_grad()\n        yhat=self.model(inputs)\n        yhat=yhat.view(-1)\n        loss=self.criterion(yhat, y)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), CONFIG.clip_gradient_norm)\n        self.optimizer.step()\n        self.schedular.step()\n        return loss.item()\n    \n    def train(self):\n        t1=time.time()\n        for _ in range(CONFIG.epochs):\n            for (num_sents, sids, X, y) in self.train_dataloader:\n                self.iter_count+=1\n                X=X.to(CONFIG.device)\n                y=y.to(CONFIG.device)\n                inputs={\n                    'num_sents': num_sents,\n                    'sids': sids,\n                    'X': X\n                }\n                \n                train_loss=self.train_ops(inputs, y)\n                self.train_loss_.append(train_loss)\n                if self.iter_count%CONFIG.eval_every==0:\n                    val_loss=self.evaluate()\n                    self.val_loss_.append(val_loss)\n                    self.checkpoint(val_loss)\n                    t2=time.time()\n                    print(\"======\"*10)\n                    print()\n                    print(\"Iteration:{} | Time Taken: {:.2f} | Train Loss:{:.3f}\".format(self.iter_count, (t2-t1)/60, self.train_loss_[-1]))\n                    print(\"Val Loss:{:.4f} | Best Loss:{:.4f} | Best Iteration:{}\".format(val_loss,self.best_loss,self.best_iteration))\n                    t1=time.time()\n                    \n    def lr_range_test(self):\n        self.model.train()\n        lrs=[];losses=[]\n        min_lr=6e-5;max_lr=1e-3;\n        optimizer=torch.optim.AdamW(model.parameters(),\n                                    lr=min_lr,\n                                    weight_decay=CONFIG.weight_decay)\n        mse_loss=nn.MSELoss(reduction='mean')\n        schedular=torch.optim.lr_scheduler.StepLR(optimizer, 1, 1.05)\n\n        lrs=[]\n        losses=[]\n\n        for i in range(20):\n            print('Epoch:', i+1, schedular.get_last_lr())\n            for j, (num_sents, sids, X, y) in enumerate(self.train_dataloader):\n                X=X.to(CONFIG.device)\n                y=y.to(CONFIG.device)\n                inputs={\n                    'num_sents': num_sents,\n                    'sids': sids,\n                    'X': X\n                }\n                yhat=self.model(inputs)\n                yhat=yhat.view(-1)        \n                optimizer.zero_grad()\n                \n\n                loss=self.criterion(yhat, y)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), CONFIG.clip_gradient_norm)\n                optimizer.step()\n                schedular.step()\n\n                lrs+=schedular.get_last_lr()\n                losses.append(loss.item())\n                if lrs[-1]>max_lr:\n                    break\n            if lrs[-1]>max_lr:\n                break\n        return lrs, losses","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:43:05.610576Z","iopub.execute_input":"2021-07-08T14:43:05.61091Z","iopub.status.idle":"2021-07-08T14:43:05.634289Z","shell.execute_reply.started":"2021-07-08T14:43:05.610882Z","shell.execute_reply":"2021-07-08T14:43:05.633227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset=CLRPDataset(fold_train_df, 'train')\ntrain_dataloader=torch.utils.data.DataLoader(train_dataset, shuffle=True,\n                                             batch_size=CONFIG.batch_size)\n\n\nval_dataset=CLRPDataset(fold_val_df, 'val')\nval_dataloader=torch.utils.data.DataLoader(val_dataset, shuffle=False, \n                                           batch_size=CONFIG.batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.291961Z","iopub.execute_input":"2021-07-08T13:28:27.292551Z","iopub.status.idle":"2021-07-08T13:28:27.301845Z","shell.execute_reply.started":"2021-07-08T13:28:27.292513Z","shell.execute_reply":"2021-07-08T13:28:27.301103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model=CLRPModel()\n#model=model.to(CONFIG.device)\n#trainer=Trainer(model, train_dataloader, val_dataloader)\n#lrs, losses=trainer.lr_range_test()\n#lmt=45\n#plt.plot(lrs[:lmt], losses[:lmt])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:28:27.302849Z","iopub.execute_input":"2021-07-08T13:28:27.303114Z","iopub.status.idle":"2021-07-08T13:28:27.313851Z","shell.execute_reply.started":"2021-07-08T13:28:27.303091Z","shell.execute_reply":"2021-07-08T13:28:27.313122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_best_loss=None\nfor i in range(5):\n    print(\"Run: ... \", i)\n    print('--'*10)\n    model=CLRPModel()\n    model=model.to(CONFIG.device)\n\n    trainer=Trainer(model, train_dataloader, val_dataloader)\n    trainer.train()\n    \n    plt.title(\"Run:{} - TrainLoss\".format(i))\n    plt.plot(trainer.train_loss_)\n    plt.show()\n    \n    plt.title(\"Run:{} - ValLoss\".format(i))\n    plt.plot(trainer.val_loss_)\n    plt.show()\n    if all_best_loss is None or all_best_loss > trainer.best_loss:\n        all_best_loss=trainer.best_loss\n        torch.save(model, 'model1.pt')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:41:57.521277Z","iopub.execute_input":"2021-07-08T14:41:57.521577Z","iopub.status.idle":"2021-07-08T14:41:59.336803Z","shell.execute_reply.started":"2021-07-08T14:41:57.52155Z","shell.execute_reply":"2021-07-08T14:41:59.335872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=torch.load('./model1.pt')\nmodels=[model]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:42:41.17919Z","iopub.execute_input":"2021-07-08T14:42:41.179502Z","iopub.status.idle":"2021-07-08T14:42:41.198017Z","shell.execute_reply.started":"2021-07-08T14:42:41.179474Z","shell.execute_reply":"2021-07-08T14:42:41.197203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(models, dataloader):\n    preds=[]\n    for (num_sents, sids, X) in dataloader:\n        X=X.to(CONFIG.device)\n        y_hat=torch.zeros(X.shape[0])\n        \n        inputs={\n            'num_sents': num_sents,\n            'sids': sids,\n            'X': X\n        }\n        \n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                y=model(inputs)\n                y=y.view(-1).detach().cpu()\n                #y_hat+=(target_std*y) + target_mean\n                y_hat+=y\n        preds+=list(y_hat.numpy()/len(models))\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:42:44.908165Z","iopub.execute_input":"2021-07-08T14:42:44.908535Z","iopub.status.idle":"2021-07-08T14:42:44.915329Z","shell.execute_reply.started":"2021-07-08T14:42:44.9085Z","shell.execute_reply":"2021-07-08T14:42:44.914367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer_train_dataset=CLRPDataset(train_df, 'test')\ninfer_train_dataloader=torch.utils.data.DataLoader(infer_train_dataset, batch_size=200, shuffle=False)\ntrain_df['preds'] = infer(models, infer_train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:42:47.37601Z","iopub.execute_input":"2021-07-08T14:42:47.376328Z","iopub.status.idle":"2021-07-08T14:42:51.380903Z","shell.execute_reply.started":"2021-07-08T14:42:47.3763Z","shell.execute_reply":"2021-07-08T14:42:51.379072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['id', 'target', 'preds']].head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:27.858335Z","iopub.execute_input":"2021-07-08T14:36:27.858604Z","iopub.status.idle":"2021-07-08T14:36:27.869556Z","shell.execute_reply.started":"2021-07-08T14:36:27.858577Z","shell.execute_reply":"2021-07-08T14:36:27.86896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(np.sqrt((train_df.preds-train_df.target)**2)).mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:27.870483Z","iopub.execute_input":"2021-07-08T14:36:27.87093Z","iopub.status.idle":"2021-07-08T14:36:27.883731Z","shell.execute_reply.started":"2021-07-08T14:36:27.870901Z","shell.execute_reply":"2021-07-08T14:36:27.882714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax=plt.subplots(2, 1)\nsns.boxplot(data=train_df, x='target', ax=ax[0])\nsns.boxplot(data=train_df, x='preds', ax=ax[1])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:27.884854Z","iopub.execute_input":"2021-07-08T14:36:27.885199Z","iopub.status.idle":"2021-07-08T14:36:28.063356Z","shell.execute_reply.started":"2021-07-08T14:36:27.885171Z","shell.execute_reply":"2021-07-08T14:36:28.062531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(train_df, x='target', bins=100, color='red')\nsns.histplot(train_df, x='preds', bins=100,)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:28.064384Z","iopub.execute_input":"2021-07-08T14:36:28.064618Z","iopub.status.idle":"2021-07-08T14:36:28.53528Z","shell.execute_reply.started":"2021-07-08T14:36:28.064596Z","shell.execute_reply":"2021-07-08T14:36:28.53436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"test_df=pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_df['inputs']=test_df.excerpt.apply(tokenizer)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:28.537047Z","iopub.execute_input":"2021-07-08T14:36:28.537317Z","iopub.status.idle":"2021-07-08T14:36:28.620418Z","shell.execute_reply.started":"2021-07-08T14:36:28.537293Z","shell.execute_reply":"2021-07-08T14:36:28.619711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer_test_dataset=CLRPDataset(test_df, 'test')\ninfer_test_dataloader=torch.utils.data.DataLoader(infer_test_dataset, batch_size=200, shuffle=False)\ntest_df['target'] = infer(models, infer_test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:28.621419Z","iopub.execute_input":"2021-07-08T14:36:28.621762Z","iopub.status.idle":"2021-07-08T14:36:28.73273Z","shell.execute_reply.started":"2021-07-08T14:36:28.621736Z","shell.execute_reply":"2021-07-08T14:36:28.731998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df=test_df[['id', 'target']].copy()\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:28.733589Z","iopub.execute_input":"2021-07-08T14:36:28.73399Z","iopub.status.idle":"2021-07-08T14:36:28.743568Z","shell.execute_reply.started":"2021-07-08T14:36:28.733963Z","shell.execute_reply":"2021-07-08T14:36:28.742828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:36:28.744694Z","iopub.execute_input":"2021-07-08T14:36:28.744972Z","iopub.status.idle":"2021-07-08T14:36:28.755608Z","shell.execute_reply.started":"2021-07-08T14:36:28.744948Z","shell.execute_reply":"2021-07-08T14:36:28.754936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}