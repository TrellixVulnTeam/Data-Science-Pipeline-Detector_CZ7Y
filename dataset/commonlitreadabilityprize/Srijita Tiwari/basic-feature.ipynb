{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def syllable_count(word):\n    word = word.lower()\n    count = 0\n    vowels = \"aeiouy\"\n    if word[0] in vowels:\n        count += 1\n    for index in range(1, len(word)):\n        if word[index] in vowels and word[index - 1] not in vowels:\n            count += 1\n    if word.endswith(\"e\"):\n        count -= 1\n    if count == 0:\n        count += 1\n    return count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['words'] = train_df['excerpt'].apply(lambda x: len(x.split(' ')))\ntest_df['words'] = test_df['excerpt'].apply(lambda x: len(x.split(' ')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['sentences'] = train_df['excerpt'].apply(lambda x: x.count('.'))\ntest_df['sentences'] = test_df['excerpt'].apply(lambda x: x.count('.'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['syllables'] = train_df['excerpt'].apply(lambda x: syllable_count(x))\ntest_df['syllables'] = test_df['excerpt'].apply(lambda x: syllable_count(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['flesch_score'] = 206.835 - 1.015 * (train_df['words']/train_df['sentences']) - 84.6 * (train_df['syllables']/train_df['words'])\ntest_df['flesch_score'] = 206.835 - 1.015 * (test_df['words']/test_df['sentences']) - 84.6 * (test_df['syllables']/test_df['words'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['flesch_score2'] = 0.39 * (train_df['words']/train_df['sentences'])  + 11.8 * (train_df['syllables']/train_df['words']) - 15.59\ntest_df['flesch_score2'] = 0.39 * (test_df['words']/test_df['sentences'])  + 11.8 * (test_df['syllables']/test_df['words']) - 15.59","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['unique_words'] = train_df['excerpt'].apply(lambda x: len(set(x.split(' '))))\ntest_df['unique_words'] = test_df['excerpt'].apply(lambda x: len(set(x.split(' '))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['diversity'] = train_df['unique_words']/train_df['words']\ntest_df['diversity'] = test_df['unique_words']/test_df['words']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['characters'] = train_df['excerpt'].apply(lambda x: len(x))\ntest_df['characters'] = test_df['excerpt'].apply(lambda x: len(x))\n\ntrain_df['w/c'] = train_df['words']/train_df['characters']\ntest_df['w/c'] = test_df['words']/test_df['characters']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['words','sentences','syllables','flesch_score','flesch_score2','unique_words','diversity','characters','w/c']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression, Ridge, ElasticNet\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val = np.zeros((train_df.shape[0],1))\ntest = np.zeros((test_df.shape[0],1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = KFold(n_splits = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_index,test_index in fold.split(train_df):\n    x0, x1 = train_df[features].loc[train_index], train_df[features].loc[test_index]\n    y0, y1 = train_df['target'][train_index], train_df['target'][test_index]\n    \n    model = Ridge(alpha = 1)\n\n    model.fit(x0,y0)\n    \n    ypred = model.predict(x1)\n    val[test_index,0] =  model.predict(x1)\n    test[:,0] += model.predict(test_df[features])/10\n    \n    print(np.round( np.sqrt(mse(val[test_index,0], y1)),2 ))\nprint(np.round( np.sqrt(mse(val, train_df['target'])) , 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = test_df[[\"id\"]].copy()\nres[\"target\"] = test\nres.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}