{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, random, sys, time, re\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data as D\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom transformers import *\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM","metadata":{"_uuid":"597eea9d6295671bd36a809b579d12777738a392","execution":{"iopub.status.busy":"2021-05-30T23:38:05.923651Z","iopub.execute_input":"2021-05-30T23:38:05.924089Z","iopub.status.idle":"2021-05-30T23:38:05.930828Z","shell.execute_reply.started":"2021-05-30T23:38:05.924034Z","shell.execute_reply":"2021-05-30T23:38:05.930099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Directory Settings","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nTRAIN_PATH = '../input/commonlitreadabilityprize'\nTEST_PATH = '../input/commonlitreadabilityprize'","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:05.932708Z","iopub.execute_input":"2021-05-30T23:38:05.933124Z","iopub.status.idle":"2021-05-30T23:38:05.942307Z","shell.execute_reply.started":"2021-05-30T23:38:05.933087Z","shell.execute_reply":"2021-05-30T23:38:05.941666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CFG","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    seed=7117\n    n_folds=5\n    model_name='roberta-base'\n    max_sequence_length=220\n    batch_size=12\n    epochs=15\n    lr=2.5e-5\n    scheduler='ConstantScheduleWithWarmup' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'ConstantScheduleWithWarmup']\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    #T_max=10 # CosineAnnealingLR\n    #T_0=10 # CosineAnnealingWarmRestarts\n    #n_epochs=100\n    #min_lr=1e-6\n    \nif CFG.debug:\n    CFG.epochs = 1\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:05.945381Z","iopub.execute_input":"2021-05-30T23:38:05.945836Z","iopub.status.idle":"2021-05-30T23:38:05.952807Z","shell.execute_reply.started":"2021-05-30T23:38:05.945796Z","shell.execute_reply":"2021-05-30T23:38:05.952154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n# seed=CFG.seed\n\n# error log\nsys.stderr = open('err.txt', 'w')","metadata":{"_uuid":"b7c04a817b5ba68498dc9b30638605da891ba6c4","execution":{"iopub.status.busy":"2021-05-30T23:38:05.954869Z","iopub.execute_input":"2021-05-30T23:38:05.95529Z","iopub.status.idle":"2021-05-30T23:38:05.964086Z","shell.execute_reply.started":"2021-05-30T23:38:05.955255Z","shell.execute_reply":"2021-05-30T23:38:05.963228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:05.965413Z","iopub.execute_input":"2021-05-30T23:38:05.965962Z","iopub.status.idle":"2021-05-30T23:38:05.972684Z","shell.execute_reply.started":"2021-05-30T23:38:05.965926Z","shell.execute_reply":"2021-05-30T23:38:05.972119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"../input/commonlitreadabilityprize/\"\n\n# model_path = '../input/distilbertbaseuncased'\n# model_path = '../input/pretrained-albert-pytorch/albert-base-v2'\n# model_path = '../input/roberta-transformers-pytorch/distilroberta-base'\n# model_path = '../input/roberta-transformers-pytorch/roberta-base'\n# model_path = '../input/bart-models-hugging-face-model-repository/bart-base'\nmodel_path = '../input/pretrainedrobertabase'\n\n# VOCAB_PATH = '../input/roberta-transformers-pytorch/roberta-base'\n# VOCAB_PATH = '../input/pretrained-albert-pytorch/albert-base-v2'\n# VOCAB_PATH = '../input/pretrained-albert-pytorch/albert-base-v1'\n# VOCAB_PATH = '../input/distilbertbaseuncased'\n# VOCAB_PATH = '../input/bart-models-hugging-face-model-repository/bart-base'\nVOCAB_PATH = '../input/pretrainedrobertabase'","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:05.973939Z","iopub.execute_input":"2021-05-30T23:38:05.974551Z","iopub.status.idle":"2021-05-30T23:38:05.98075Z","shell.execute_reply.started":"2021-05-30T23:38:05.974515Z","shell.execute_reply":"2021-05-30T23:38:05.980185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.model_name == 'roberta-base':\n    model_name = '../input/pretrainedrobertabase'\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:05.984485Z","iopub.execute_input":"2021-05-30T23:38:05.98475Z","iopub.status.idle":"2021-05-30T23:38:05.993194Z","shell.execute_reply.started":"2021-05-30T23:38:05.984704Z","shell.execute_reply":"2021-05-30T23:38:05.992601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading, CV Split","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'), index_col='id')\ntrain_csv['excerpt'] = train_csv['excerpt'].replace('\\n', '')\n\ntest_csv = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'), index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:05.996472Z","iopub.execute_input":"2021-05-30T23:38:05.996813Z","iopub.status.idle":"2021-05-30T23:38:06.037125Z","shell.execute_reply.started":"2021-05-30T23:38:05.996789Z","shell.execute_reply":"2021-05-30T23:38:06.036595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'), index_col='id')\n\ny = (train_csv.target.values > 0).astype(int)\ncv = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained(\n            '../input/roberta-transformers-pytorch/roberta-base', model_max_length=CFG.max_sequence_length)\ndef get_tokens(text):\n    tokens = tokenizer.encode_plus(text, max_length=CFG.max_sequence_length, truncation=True, return_attention_mask=True, return_token_type_ids=True)\n    return tokens\n    \ntrain_csv['token'] = train_csv.excerpt.apply(get_tokens)\ntest_csv['token'] = test_csv.excerpt.apply(get_tokens)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:06.038276Z","iopub.execute_input":"2021-05-30T23:38:06.038608Z","iopub.status.idle":"2021-05-30T23:38:11.401447Z","shell.execute_reply.started":"2021-05-30T23:38:06.038575Z","shell.execute_reply":"2021-05-30T23:38:11.400732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv['token'].head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:11.402662Z","iopub.execute_input":"2021-05-30T23:38:11.402985Z","iopub.status.idle":"2021-05-30T23:38:11.409508Z","shell.execute_reply.started":"2021-05-30T23:38:11.40295Z","shell.execute_reply":"2021-05-30T23:38:11.408781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv['token'].head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:11.410763Z","iopub.execute_input":"2021-05-30T23:38:11.411219Z","iopub.status.idle":"2021-05-30T23:38:11.42249Z","shell.execute_reply.started":"2021-05-30T23:38:11.411178Z","shell.execute_reply":"2021-05-30T23:38:11.421729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitDataset(D.Dataset):\n    \n    def __init__(self, token, target):\n        self.token = token\n        self.target = target\n        \n    def __len__(self):\n        return self.token.shape[0]\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.token[idx].input_ids), \\\n                torch.tensor(self.token[idx].attention_mask), torch.tensor(self.token[idx].token_type_ids), self.target[idx]\n    \ndef collate_fn(batch):\n    ids, attns, token_type, targets = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True).to(DEVICE)\n    attns = pad_sequence(attns, batch_first=True).to(DEVICE)\n    token_type = pad_sequence(token_type, batch_first=True).to(DEVICE)\n    targets = torch.tensor(targets).float().to(DEVICE)\n    return ids, attns, token_type, targets\ndef collate_fn_test(batch):\n    ids, attns, token_type, idxs = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True).to(DEVICE)\n    attns = pad_sequence(attns, batch_first=True).to(DEVICE)\n    token_type = pad_sequence(token_type, batch_first=True).to(DEVICE)\n    return idxs, ids, attns, token_type\n","metadata":{"_uuid":"92ea577a18faedfdccf5198d626c5c27861133ee","execution":{"iopub.status.busy":"2021-05-30T23:38:11.424007Z","iopub.execute_input":"2021-05-30T23:38:11.424372Z","iopub.status.idle":"2021-05-30T23:38:11.435236Z","shell.execute_reply.started":"2021-05-30T23:38:11.424339Z","shell.execute_reply":"2021-05-30T23:38:11.434219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLitModel(nn.Module):\n    def __init__(\n        self, \n        model_name, \n        config,  \n        multisample_dropout=False,\n        output_hidden_states=False\n    ):\n        super(CommonLitModel, self).__init__()\n        self.config = config\n        self.roberta = AutoModel.from_pretrained(\n            model_name, \n            output_hidden_states=output_hidden_states\n        )\n        self.layer_norm = nn.LayerNorm(config.hidden_size)\n        if multisample_dropout:\n            self.dropouts = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n        else:\n            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n        #self.regressor = nn.Linear(config.hidden_size*2, 1)\n        self.regressor = nn.Linear(config.hidden_size, 1)\n        self._init_weights(self.layer_norm)\n        self._init_weights(self.regressor)\n \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n \n    def forward(\n        self, \n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None\n#         labels=None\n    ):\n        outputs = self.roberta(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids\n        )\n        sequence_output = outputs[1]\n        sequence_output = self.layer_norm(sequence_output)\n \n        # max-avg head\n        # average_pool = torch.mean(sequence_output, 1)\n        # max_pool, _ = torch.max(sequence_output, 1)\n        # concat_sequence_output = torch.cat((average_pool, max_pool), 1)\n \n        # multi-sample dropout\n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                logits = self.regressor(dropout(sequence_output))\n            else:\n                logits += self.regressor(dropout(sequence_output))\n        \n        logits /= len(self.dropouts)\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:11.436774Z","iopub.execute_input":"2021-05-30T23:38:11.437163Z","iopub.status.idle":"2021-05-30T23:38:11.450644Z","shell.execute_reply.started":"2021-05-30T23:38:11.437128Z","shell.execute_reply":"2021-05-30T23:38:11.449575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = LitDataset(train_csv.token, train_csv.target)\ntest_ds = LitDataset(test_csv.token, test_csv.index)\n\ntloader = D.DataLoader(test_ds, batch_size=CFG.batch_size,\n                       shuffle=False, collate_fn = collate_fn_test, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:11.452367Z","iopub.execute_input":"2021-05-30T23:38:11.452765Z","iopub.status.idle":"2021-05-30T23:38:11.462469Z","shell.execute_reply.started":"2021-05-30T23:38:11.452727Z","shell.execute_reply":"2021-05-30T23:38:11.461754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Table for results\nheader = r'''\n            Train         Validation\nEpoch |  MSE  |  RMSE |  MSE  |  RMSE | Time, m\n'''\n#          Epoch         metrics            time\nraw_line = '{:6d}' + '\\u2502{:7.3f}'*4 + '\\u2502{:6.2f}'","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:11.463739Z","iopub.execute_input":"2021-05-30T23:38:11.464132Z","iopub.status.idle":"2021-05-30T23:38:11.471698Z","shell.execute_reply.started":"2021-05-30T23:38:11.464096Z","shell.execute_reply":"2021-05-30T23:38:11.471141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau': # epoch\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR': # epoch\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts': # epoch\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler == 'ConstantScheduleWithWarmup':\n            scheduler = get_constant_schedule_with_warmup(optimizer, 35)\n        return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:38:11.472869Z","iopub.execute_input":"2021-05-30T23:38:11.473278Z","iopub.status.idle":"2021-05-30T23:38:11.481167Z","shell.execute_reply.started":"2021-05-30T23:38:11.473217Z","shell.execute_reply":"2021-05-30T23:38:11.480366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef validation_fn(model, loader, loss_fn):\n    tloss = []\n    for texts, attns, token_type, target in loader:\n#         outputs = model(texts, attention_mask=attns)\n        outputs = model(\n            input_ids=texts,\n            attention_mask=attns,\n            token_type_ids=token_type\n        )\n        loss = loss_fn(outputs.squeeze(-1), target)\n        tloss.append(loss.item())\n    tloss = np.array(tloss).mean()\n    return tloss\n\ndef oof_preds(ds, tloader, cv, y, epochs = CFG.epochs):\n    \n    loss_fn = torch.nn.MSELoss()\n    \n#     for train_idx, valid_idx in cv.split(range(len(ds)), y):\n    for fold, (train_idx, valid_idx) in enumerate(cv.split(range(len(ds)), y)):\n        \n        train_ds = D.Subset(ds, train_idx)\n        loader = D.DataLoader(train_ds, batch_size=CFG.batch_size,\n                              shuffle=True, collate_fn = collate_fn,num_workers=0)\n        \n        valid_ds = D.Subset(ds, valid_idx)\n        vloader = D.DataLoader(valid_ds, batch_size=CFG.batch_size,\n                      shuffle=False, collate_fn = collate_fn,num_workers=0)\n        \n#         model = get_model.from_pretrained( \n#                           model_path, num_labels=1).to(DEVICE);\n        config = AutoConfig.from_pretrained(model_path)\n        config.update({'num_labels': 1})\n        model = CommonLitModel(model_path, config=config)\n        model = model.to(DEVICE)\n        \n        optimizer = optim.AdamW(model.parameters(), CFG.lr,\n                                betas=(0.9, 0.999), weight_decay=1e-1)\n#         scheduler = get_constant_schedule_with_warmup(optimizer, 35)\n        scheduler = get_scheduler(optimizer)\n        b_loss = np.inf\n        \n        print(header)\n        for epoch in range(1, epochs+1):      \n            start_time = time.time()\n            tloss = []          \n            model.train()\n            \n            for texts, attns, token_type, target in loader:\n                optimizer.zero_grad()\n#                 outputs = model(texts, attention_mask=attns)\n                outputs = model(\n                    input_ids=texts,\n                    attention_mask=attns,\n                    token_type_ids=token_type\n                )\n                loss = loss_fn(outputs.squeeze(-1), target)\n                tloss.append(loss.item())\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n            tloss = np.array(tloss).mean()\n            vloss = validation_fn(model, vloader, loss_fn)\n            tmetric = tloss**.5\n            vmetric = vloss**.5\n            print(raw_line.format(epoch,tloss,tmetric,vloss,vmetric,(time.time()-start_time)/60**1))\n            del loss, outputs\n            \n            if vmetric <= b_loss:\n                b_loss = vmetric\n                torch.save(model.state_dict(), f\"fold{fold}_best.pth\")\n        \n#         model = get_model.from_pretrained(model_path, num_labels=1)\n        model = CommonLitModel(model_path, config=config)\n        model.load_state_dict(torch.load(f\"fold{fold}_best.pth\"), strict=False)\n        model.to(DEVICE)\n        \n        model.eval();\n        # Get prediction for test set\n        ids, preds = [], [] \n        with torch.no_grad():\n            for batch_ids, texts, attn, token_type in tloader:\n#                 outputs = model(texts, attention_mask=attn)\n                outputs = model(\n                    input_ids=texts,\n                    attention_mask=attn,\n                    token_type_ids=token_type\n                )\n                ids += batch_ids\n                preds.append(outputs.detach().squeeze(-1).cpu().numpy())\n            \n        # Save prediction of test set\n        preds = np.concatenate(preds)\n        subm.loc[ids, 'target']  =  subm.loc[ids, 'target'].values + preds / N_FOLDS\n        \n        del model, vloader, loader, train_ds, valid_ds\n        torch.cuda.empty_cache()\n        ","metadata":{"_uuid":"e566ecdb5f44cf32af12127f073021566d6e66dd","execution":{"iopub.status.busy":"2021-05-30T23:38:11.482703Z","iopub.execute_input":"2021-05-30T23:38:11.483163Z","iopub.status.idle":"2021-05-30T23:38:11.507943Z","shell.execute_reply.started":"2021-05-30T23:38:11.483109Z","shell.execute_reply":"2021-05-30T23:38:11.507336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_preds(ds, tloader, cv, y, epochs = CFG.epochs)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:39:53.68084Z","iopub.execute_input":"2021-05-30T23:39:53.681232Z","iopub.status.idle":"2021-05-30T23:43:11.279785Z","shell.execute_reply.started":"2021-05-30T23:39:53.681199Z","shell.execute_reply":"2021-05-30T23:43:11.278681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:39:38.697183Z","iopub.status.idle":"2021-05-30T23:39:38.699405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:39:38.702847Z","iopub.status.idle":"2021-05-30T23:39:38.705007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}