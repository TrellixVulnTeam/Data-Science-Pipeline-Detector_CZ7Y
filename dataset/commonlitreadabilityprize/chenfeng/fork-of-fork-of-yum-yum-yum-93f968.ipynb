{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import (\n    get_cosine_schedule_with_warmup, \n    get_cosine_with_hard_restarts_schedule_with_warmup,\n    get_linear_schedule_with_warmup,\n    get_constant_schedule_with_warmup\n)\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig\nfrom transformers import AutoModel\nfrom transformers import PreTrainedModel\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-12T06:08:03.90327Z","iopub.execute_input":"2021-07-12T06:08:03.903588Z","iopub.status.idle":"2021-07-12T06:08:10.440772Z","shell.execute_reply.started":"2021-07-12T06:08:03.903558Z","shell.execute_reply":"2021-07-12T06:08:10.439929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model\nconf_dict = {\n    \"split_num\" : 4,\n    \"seed\" : [100, 99,98],\n#     \"seed\" : [0],\n    \"batch_size\" : 4,\n#     \"learning_rate\" : 2e-5,\n    \"learning_rate\" : 1e-4,\n    \"regressor_lr\" : 1.0,\n    \"weight_decay\" : 0.01,\n    \"max_length\" : 256,\n    \"epochs\" : 6,\n#     \"epochs\" : 10,\n    \"hidden_dropout\" : 0,\n    \"attention_dropout\" : 0.1,\n    \"linear_dropout1\" : 0,\n    \"linear_dropout2\" : 0.3,\n    \"warmup_ratio\" : 0.06,\n    \"use_llrd\" : True,\n#     \"llrd_rate\" : 0.95,\n    \"llrd_rate\" : 0.8,\n    \"freeze_embed\" : True,\n    \"use_mixout\" : False,\n    \"mixout_prob\" : 0.3,\n    \"use_prior_wd\" : False,\n    \"use_commonlit_pretrained\" : False,\n    \"use_relu\" : False,\n    \"val_interval\" : 20,\n    \"no_interval_epoch\" : 0,\n#     \"reinit_layers\" : 0,\n    \"reinit_layers\" : 4,\n    \"split_type\" : 1,\n    \n#     \"model_name\" : \"roberta-base\",\n    \"model_name\" : 'roberta-large',\n#     \"model_name\" : 'microsoft/deberta-base',\n#     \"model_name\" : 'microsoft/deberta-large',\n#     \"model_name\" : \"google/electra-large-generator\",\n#     \"model_name\" : \"google/electra-large-discriminator\",\n#     \"input_linear_num1\" : 768,\n#     \"input_linear_num2\" : 384,\n    \"input_linear_num1\" : 1024,\n    \"input_linear_num2\" : 512,\n    \"save_model_name\" : 'mlm_false'\n}\n\nclass ReadabilityModel(PreTrainedModel): \n    def __init__(self, conf):\n        super(ReadabilityModel, self).__init__(conf) \n\n\n        self.bert = AutoModel.from_pretrained('../input/robertalarge', config=conf)\n        \n        self.drop_out1 = nn.Dropout(conf_dict[\"linear_dropout1\"])\n        self.drop_out2 = nn.Dropout(conf_dict[\"linear_dropout2\"])\n\n        self.layer_norm1 = nn.LayerNorm(conf_dict[\"input_linear_num1\"])\n        self.l1 = nn.Linear(conf_dict[\"input_linear_num1\"], conf_dict[\"input_linear_num2\"])\n        self.l2 = nn.Linear(conf_dict[\"input_linear_num2\"], 1)\n\n        self._init_weights(self.layer_norm1)\n        self._init_weights(self.l1)\n        self._init_weights(self.l2)\n \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n    \n    def forward(self, ids, mask):\n        out = self.bert(\n            input_ids=ids,\n            attention_mask=mask\n        )\n\n        # out = out['pooler_output']        \n        out = torch.mean(out['last_hidden_state'], 1)\n        out = self.layer_norm1(out)\n        out = self.drop_out1(out)\n        out = self.l1(out)\n        if conf_dict[\"use_relu\"]:\n            out = F.relu(out)\n        out = self.drop_out2(out)\n        out = self.l2(out)\n#         print(\"out:\",out.shape)\n        \n        preds = out.squeeze(-1)\n#         raise\n\n        return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-12T06:08:14.180612Z","iopub.execute_input":"2021-07-12T06:08:14.180966Z","iopub.status.idle":"2021-07-12T06:08:14.196306Z","shell.execute_reply.started":"2021-07-12T06:08:14.180933Z","shell.execute_reply":"2021-07-12T06:08:14.195346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test_Data(Dataset):\n    def __init__(self, data):\n        super(Test_Data, self).__init__()\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):       \n        excerpt = self.data.excerpt[idx]\n        return excerpt\n\n  ","metadata":{"execution":{"iopub.status.busy":"2021-07-12T06:08:15.297969Z","iopub.execute_input":"2021-07-12T06:08:15.298342Z","iopub.status.idle":"2021-07-12T06:08:15.304815Z","shell.execute_reply.started":"2021-07-12T06:08:15.298311Z","shell.execute_reply":"2021-07-12T06:08:15.30362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(model_path, max_len):\n    model_config = AutoConfig.from_pretrained('../input/robertalarge')\n    model_config.output_hidden_states = True\n    model = ReadabilityModel(model_config)\n    #model = AutoModelForSequenceClassification.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained('../input/robertalarge')\n    model.load_state_dict(torch.load(model_path)) \n\n    model.to(\"cuda\")\n    model.eval()\n    \n    df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n    test_data = Test_Data(data = df)\n    test_loader = DataLoader(dataset = test_data, shuffle=False, batch_size = 64) \n    \n    #dataset = Dataset(excerpt=df.excerpt.values, tokenizer=tokenizer, max_len=max_len)\n    #data_loader = torch.utils.data.DataLoader(\n    #    dataset, batch_size=64, num_workers=4, pin_memory=True, shuffle=False\n    #)\n\n    final_output = []\n    preds_val = []\n    out_list = []\n    device=torch.device(\"cuda\")\n    #result = np.zeros(len(data_loader.dataset)) \n    index = 0\n    with torch.no_grad():\n        for i, excerpts in enumerate(test_loader):\n            batch = tokenizer(list(excerpts), truncation=True, padding=\"max_length\", return_tensors='pt', max_length=conf_dict[\"max_length\"])\n            input_ids = batch['input_ids']\n            input_ids = input_ids.to(device, dtype=torch.long)\n            attention_mask = batch['attention_mask']\n            attention_mask = attention_mask.to(device, dtype=torch.long)\n            #import pdb\n            #pdb.set_trace()\n\n            pred = model(input_ids, attention_mask)\n            #out_list.append(pred)\n            #print(pred)\n            #output = output.detach().cpu().numpy().ravel().tolist()\n            #result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n            #index += pred.shape[0]\n            \n            preds = pred.cpu().detach().numpy().tolist()\n            preds_val += preds\n            #final_output.extend(output)\n            #print(output)\n\n#     for b_idx, data in enumerate(data_loader):\n#         with torch.no_grad():\n#             for key, value in data.items():\n#                 data[key] = value.to(\"cuda\")\n#             output = model(**data)\n#             output = output.logits.detach().cpu().numpy().ravel().tolist()\n#             final_output.extend(output)\n    \n    torch.cuda.empty_cache()\n    print(out_list)\n    #return np.array(final_output)\n    return preds_val","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-12T06:08:16.337691Z","iopub.execute_input":"2021-07-12T06:08:16.338019Z","iopub.status.idle":"2021-07-12T06:08:16.347625Z","shell.execute_reply.started":"2021-07-12T06:08:16.33799Z","shell.execute_reply":"2021-07-12T06:08:16.346713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preds1 = generate_predictions(\"../input/common/roberta-large_mlm_false_fold0_seed98.bin\", max_len=256)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T06:08:17.692985Z","iopub.execute_input":"2021-07-12T06:08:17.693523Z","iopub.status.idle":"2021-07-12T06:08:58.793028Z","shell.execute_reply.started":"2021-07-12T06:08:17.69348Z","shell.execute_reply":"2021-07-12T06:08:58.791095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preds=[preds1,preds1]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T06:09:36.10209Z","iopub.execute_input":"2021-07-12T06:09:36.102448Z","iopub.status.idle":"2021-07-12T06:09:36.108371Z","shell.execute_reply.started":"2021-07-12T06:09:36.102417Z","shell.execute_reply":"2021-07-12T06:09:36.107364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1 = generate_predictions(\"../input/common/roberta-large_mlm_false_fold0_seed98.bin\", max_len=256)\npreds2 = generate_predictions(\"../input/common/roberta-large_mlm_false_fold1_seed98.bin\", max_len=256)\npreds3 = generate_predictions(\"../input/common/roberta-large_mlm_false_fold2_seed98.bin\", max_len=256)\npreds4 = generate_predictions(\"../input/common/roberta-large_mlm_false_fold3_seed98.bin\", max_len=256)\n\nfold_preds_list = [preds1, preds2, preds3, preds4]/2\n#preds = (preds1 + preds2 + preds3 + preds4) / 4\npreds = np.mean(fold_preds_list,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T05:57:15.05137Z","iopub.execute_input":"2021-07-12T05:57:15.051731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preds1","metadata":{"execution":{"iopub.status.busy":"2021-07-12T05:49:25.347597Z","iopub.execute_input":"2021-07-12T05:49:25.348026Z","iopub.status.idle":"2021-07-12T05:49:25.419386Z","shell.execute_reply.started":"2021-07-12T05:49:25.347915Z","shell.execute_reply":"2021-07-12T05:49:25.41794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = preds\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T12:56:16.546885Z","iopub.execute_input":"2021-07-10T12:56:16.547207Z","iopub.status.idle":"2021-07-10T12:56:17.373443Z","shell.execute_reply.started":"2021-07-10T12:56:16.547174Z","shell.execute_reply":"2021-07-10T12:56:17.37263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-07-10T12:56:31.868764Z","iopub.execute_input":"2021-07-10T12:56:31.869083Z","iopub.status.idle":"2021-07-10T12:56:31.884426Z","shell.execute_reply.started":"2021-07-10T12:56:31.869053Z","shell.execute_reply":"2021-07-10T12:56:31.88353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}