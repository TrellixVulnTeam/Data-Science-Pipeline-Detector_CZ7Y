{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Just a very simple baseline applying a RoBerta model to predict the readibility of excerpts. If you have any questions, please let me know.\n\nThe notebook for inference can be found here: https://www.kaggle.com/hannes82/commonlit-readability-roberta-inference/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfrom transformers import *\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\nimport random\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.309762Z","iopub.execute_input":"2021-05-21T14:05:04.310078Z","iopub.status.idle":"2021-05-21T14:05:04.316894Z","shell.execute_reply.started":"2021-05-21T14:05:04.310049Z","shell.execute_reply":"2021-05-21T14:05:04.315955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nseed = 82\nrandom_state = set_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.318592Z","iopub.execute_input":"2021-05-21T14:05:04.319234Z","iopub.status.idle":"2021-05-21T14:05:04.329486Z","shell.execute_reply.started":"2021-05-21T14:05:04.319196Z","shell.execute_reply":"2021-05-21T14:05:04.32855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.331234Z","iopub.execute_input":"2021-05-21T14:05:04.331945Z","iopub.status.idle":"2021-05-21T14:05:04.339347Z","shell.execute_reply.started":"2021-05-21T14:05:04.331907Z","shell.execute_reply":"2021-05-21T14:05:04.338335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.341073Z","iopub.execute_input":"2021-05-21T14:05:04.341779Z","iopub.status.idle":"2021-05-21T14:05:04.376292Z","shell.execute_reply.started":"2021-05-21T14:05:04.34174Z","shell.execute_reply":"2021-05-21T14:05:04.375418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.377692Z","iopub.execute_input":"2021-05-21T14:05:04.37807Z","iopub.status.idle":"2021-05-21T14:05:04.397501Z","shell.execute_reply.started":"2021-05-21T14:05:04.378032Z","shell.execute_reply":"2021-05-21T14:05:04.396617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['excerpt_len'] = train_df.excerpt.apply(lambda x: len(x.split()))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-21T14:05:04.399107Z","iopub.execute_input":"2021-05-21T14:05:04.399588Z","iopub.status.idle":"2021-05-21T14:05:04.434706Z","shell.execute_reply.started":"2021-05-21T14:05:04.399548Z","shell.execute_reply":"2021-05-21T14:05:04.433959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.excerpt_len.max())","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.436687Z","iopub.execute_input":"2021-05-21T14:05:04.437014Z","iopub.status.idle":"2021-05-21T14:05:04.442287Z","shell.execute_reply.started":"2021-05-21T14:05:04.436979Z","shell.execute_reply":"2021-05-21T14:05:04.441251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"kfold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    data = data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"target\"], bins=num_bins, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = StratifiedKFold(n_splits=num_splits)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.443878Z","iopub.execute_input":"2021-05-21T14:05:04.444475Z","iopub.status.idle":"2021-05-21T14:05:04.45417Z","shell.execute_reply.started":"2021-05-21T14:05:04.444438Z","shell.execute_reply":"2021-05-21T14:05:04.45296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df['fold'] = -1\n#gkf = KFold(n_splits=5)\n#for fold, (train, val) in enumerate(gkf.split(train_df.excerpt, train_df.target)):\n#    train_df.loc[val,'fold']=fold\n\ntrain_df = create_folds(train_df, num_splits=5)\n\nfold = 0\nvalidation_df = train_df[train_df.kfold==0].reset_index(drop=True)\ntrain_df = train_df[train_df.kfold!=0].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.455516Z","iopub.execute_input":"2021-05-21T14:05:04.455977Z","iopub.status.idle":"2021-05-21T14:05:04.47526Z","shell.execute_reply.started":"2021-05-21T14:05:04.455935Z","shell.execute_reply":"2021-05-21T14:05:04.474493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.target.mean(), validation_df.target.mean())","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.476419Z","iopub.execute_input":"2021-05-21T14:05:04.476767Z","iopub.status.idle":"2021-05-21T14:05:04.482579Z","shell.execute_reply.started":"2021-05-21T14:05:04.476717Z","shell.execute_reply":"2021-05-21T14:05:04.481472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self, data):\n        super().__init__()\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):       \n        excerpt = self.data.excerpt[idx]\n        target = self.data.target[idx]\n        return excerpt, target","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.48473Z","iopub.execute_input":"2021-05-21T14:05:04.485112Z","iopub.status.idle":"2021-05-21T14:05:04.493961Z","shell.execute_reply.started":"2021-05-21T14:05:04.485072Z","shell.execute_reply":"2021-05-21T14:05:04.493131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = Data(data = train_df) \ntrain_loader = DataLoader(dataset = train_data, shuffle=True, batch_size = 8)\n\nval_data = Data(data = validation_df) \nval_loader = DataLoader(dataset = val_data, shuffle=False, batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.495705Z","iopub.execute_input":"2021-05-21T14:05:04.496111Z","iopub.status.idle":"2021-05-21T14:05:04.509754Z","shell.execute_reply.started":"2021-05-21T14:05:04.496075Z","shell.execute_reply":"2021-05-21T14:05:04.508853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ReadabilityModel(PreTrainedModel): \n    def __init__(self, conf):\n        super(ReadabilityModel, self).__init__(conf) \n        self.roberta = RobertaModel.from_pretrained(model_name, config=conf)\n        self.drop_out = nn.Dropout(0.1)\n        self.l1 = nn.Linear(768 * 1, 1)\n        torch.nn.init.normal_(self.l1.weight, std=0.02)\n    \n    def forward(self, ids, mask):\n        out = self.roberta(\n            input_ids=ids,\n            attention_mask=mask\n        )\n        out = out['hidden_states']\n        out = out[-1]\n        out = self.drop_out(out)\n        out = torch.mean(out, 1, True)\n        \n        preds = self.l1(out)\n\n        preds = preds.squeeze(-1).squeeze(-1)\n\n        return preds","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.511051Z","iopub.execute_input":"2021-05-21T14:05:04.511614Z","iopub.status.idle":"2021-05-21T14:05:04.520397Z","shell.execute_reply.started":"2021-05-21T14:05:04.511577Z","shell.execute_reply":"2021-05-21T14:05:04.519268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'roberta-base'\ntokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n\nmodel_config = RobertaConfig.from_pretrained(model_name)\nmodel_config.output_hidden_states = True\n\nmodel = ReadabilityModel(model_config)\nmodel = model.to(device)\n\noptimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\nscheduler = get_constant_schedule_with_warmup(optimizer, 100)\n\nloss_fct = nn.MSELoss()\n\nepochs = 6","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:05:04.521931Z","iopub.execute_input":"2021-05-21T14:05:04.522274Z","iopub.status.idle":"2021-05-21T14:05:39.58916Z","shell.execute_reply.started":"2021-05-21T14:05:04.52224Z","shell.execute_reply":"2021-05-21T14:05:39.588346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    for i, (excerpts, targets) in enumerate(tqdm(train_loader)):\n        optimizer.zero_grad()\n        batch = tokenizer(list(excerpts), truncation=True, padding=True, return_tensors='pt', add_special_tokens=True)\n        input_ids = batch['input_ids']\n        input_ids = input_ids.to(device, dtype=torch.long)\n        attention_mask = batch['attention_mask']\n        attention_mask = attention_mask.to(device, dtype=torch.long)\n            \n        targets=torch.tensor(targets).to(device, dtype=torch.float)\n \n        preds = model(input_ids, attention_mask)       \n        \n        loss = torch.sqrt(loss_fct(preds, targets))\n        \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        loss = loss.item()\n        \n        if i==0:\n            loss_train = loss\n        else:\n            loss_train = loss_train + loss  \n    loss_train = loss_train/(i+1)\n    \n    model.eval()\n    with torch.no_grad():\n        for i, (excerpts, targets) in enumerate(tqdm(val_loader)):\n            optimizer.zero_grad()\n            batch = tokenizer(list(excerpts), truncation=True, padding=True, return_tensors='pt', add_special_tokens=True)\n            input_ids = batch['input_ids']\n            input_ids = input_ids.to(device, dtype=torch.long)\n            attention_mask = batch['attention_mask']\n            attention_mask = attention_mask.to(device, dtype=torch.long)\n                \n            targets=torch.tensor(targets).to(device, dtype=torch.float)\n     \n            preds = model(input_ids, attention_mask)       \n            \n            loss = torch.sqrt(loss_fct(preds, targets))\n            loss = loss.item()\n            \n            preds = preds.cpu().detach().numpy()\n            targets = targets.cpu().detach().numpy()\n            if i==0:\n                loss_val = loss\n                preds_val = preds\n                targets_val = targets\n            else:\n                loss_val = loss_val + loss  \n                preds_val = np.concatenate((preds_val,preds), axis=None)\n                targets_val = np.concatenate((targets_val,targets), axis=None)\n                \n        loss_val = loss_val / (i+1)\n        rms_val = mean_squared_error(targets_val, preds_val, squared=False)\n        print('Epoch: {} - Loss: {:.6f} - Loss val: {:.6f} - RMSE: {:.3f}'.format(\n            epoch + 1, loss_train, loss_val, rms_val))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-21T14:14:01.219609Z","iopub.execute_input":"2021-05-21T14:14:01.219931Z","iopub.status.idle":"2021-05-21T14:16:29.304516Z","shell.execute_reply.started":"2021-05-21T14:14:01.219898Z","shell.execute_reply":"2021-05-21T14:16:29.3006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'roberta_baseline.bin')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:09:23.121262Z","iopub.execute_input":"2021-05-21T14:09:23.121803Z","iopub.status.idle":"2021-05-21T14:09:24.64714Z","shell.execute_reply.started":"2021-05-21T14:09:23.121759Z","shell.execute_reply":"2021-05-21T14:09:24.646315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-05-21T14:13:48.253209Z","iopub.execute_input":"2021-05-21T14:13:48.253574Z","iopub.status.idle":"2021-05-21T14:13:48.261493Z","shell.execute_reply.started":"2021-05-21T14:13:48.253541Z","shell.execute_reply":"2021-05-21T14:13:48.260398Z"},"trusted":true},"execution_count":null,"outputs":[]}]}