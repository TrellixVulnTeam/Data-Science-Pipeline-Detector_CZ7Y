{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Inference with a simple RoBerta model.\n\nThe notebook to train the model is available here: https://www.kaggle.com/hannes82/commonlit-readability-roberta-simple-baseline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfrom transformers import *\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport random\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self, data):\n        super().__init__()\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):       \n        excerpt = self.data.excerpt[idx]\n        return excerpt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = Data(data = test_df) \ntest_loader = DataLoader(dataset = test_data, shuffle=False, batch_size = 64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ReadabilityModel(PreTrainedModel): \n    def __init__(self, conf):\n        super(ReadabilityModel, self).__init__(conf) \n        self.roberta = RobertaModel(config=conf)\n        self.drop_out = nn.Dropout(0.1)\n        self.l1 = nn.Linear(768 * 1, 1)\n        torch.nn.init.normal_(self.l1.weight, std=0.02)\n    \n    def forward(self, ids, mask):\n        out = self.roberta(\n            input_ids=ids,\n            attention_mask=mask\n        )\n        out = out['hidden_states']\n        out = out[-1]\n        out = self.drop_out(out)\n        out = torch.mean(out, 1, True)\n        \n        preds = self.l1(out)\n\n        preds = preds.squeeze(-1).squeeze(-1)\n\n        return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizerFast.from_pretrained('../input/robertabase', model_max_length=514) \n\nmodel_config = RobertaConfig()\nmodel_config.output_hidden_states = True\nmodel_config.max_position_embeddings=514\nmodel_config.vocab_size = 50265\nmodel_config.type_vocab_size = 1\n\nmodel = ReadabilityModel(model_config)\nif torch.cuda.is_available():\n    model.load_state_dict(torch.load(\"../input/commonlit-readability-roberta-simple-baseline/roberta_baseline.bin\"))\nelse: \n    model.load_state_dict(torch.load(\"../input/commonlit-readability-roberta-simple-baseline/roberta_baseline.bin\", map_location=torch.device('cpu')))\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    for i, excerpts in enumerate(tqdm(test_loader)):\n        batch = tokenizer(list(excerpts), truncation=True, padding=True, return_tensors='pt', add_special_tokens=False)\n        input_ids = batch['input_ids']\n        input_ids = input_ids.to(device, dtype=torch.long)\n        attention_mask = batch['attention_mask']\n        attention_mask = attention_mask.to(device, dtype=torch.long)\n            \n        preds = model(input_ids, attention_mask)       \n        preds = preds.cpu().detach().numpy()\n\n        if i==0:\n            preds_test = preds\n        else:\n            preds_test = np.concatenate((preds_test,preds), axis=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({'id': test_df.id, 'target': preds_test})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}