{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\nfrom sklearn.feature_extraction.text import CountVectorizer as CV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.metrics import mean_squared_error as mse\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = '../input/commonlitreadabilityprize/train.csv'\nTEST_PATH = '../input/commonlitreadabilityprize/test.csv'\n# In case you want to show full sentences.\n# pd.set_option('display.max_colwidth', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(TRAIN_PATH)\ndata.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.sort_values(by=['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def word_count(text):\n    return len(text.split(' '))\ndef long_words(text, length):\n    return len([w for w in text.split(' ') if len(w) >= length])\n\ndata['count'] = data['excerpt'].apply(word_count)\ndata['len'] = data['excerpt'].apply(len)\ndata['word7'] = data['excerpt'].apply(lambda t: long_words(t, 7))\ndata['word10'] = data['excerpt'].apply(lambda t: long_words(t, 10))\ndata['word13'] = data['excerpt'].apply(lambda t: long_words(t, 13))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data, x='target')\nsns.displot(data, x='standard_error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['standard_error'] < 0.4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Maybe error, delete\ndata = data[data['standard_error'] > 0.4]\nsns.displot(data, x='standard_error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['standard_error'] > 0.63]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(x='count', y='target', data=data)\nsns.lmplot(x='len', y='target', data=data)\nsns.lmplot(x='word7', y='target', data=data)\nsns.lmplot(x='word10', y='target', data=data)\nsns.lmplot(x='word13', y='target', data=data)\nsns.lmplot(x='target', y='standard_error', data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords_en = set(stopwords.words('english'))\nlemma = nltk.WordNetLemmatizer()\n\ndef tokenize(text):\n    text = re.sub(r'[^a-z]', ' ', text.lower())\n    words = nltk.word_tokenize(text)\n    words = [lemma.lemmatize(w) for w in words if not w in stopwords_en]\n    return words\n\ndef normalize(text):\n    return ' '.join(tokenize(text))\n\ndata['tokens'] = data['excerpt'].apply(tokenize)\ndata['normalized'] = data['excerpt'].apply(normalize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = 1\n\ndef show_word_cloud(corpus):\n    global fig\n    wc = WordCloud(stopwords=STOPWORDS, width=1000, height=600, max_words=150)\n    wc.generate(' '.join(corpus['normalized']))\n    plt.figure(fig)\n    fig += 1\n    plt.imshow(wc, interpolation='bilinear')\n\nshow_word_cloud(data[:500])\nshow_word_cloud(data[500:1000])\nshow_word_cloud(data[1000:1500])\nshow_word_cloud(data[1500:2000])\nshow_word_cloud(data[2000:2500])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(TEST_PATH)\n\ndef train(model, model_name, X_train, y_train, X_test, y_test, eval_df):\n    t1 = time.time()\n    model = make_pipeline(\n        TfidfVectorizer(binary=True, ngram_range=(1, 1)),\n        model,\n    )\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    MSE = mse(y_test, y_pred)\n    t2 = time.time()\n    training_time = t2 - t1\n    \n    print('--- Model: ', model_name, '---')\n    print('MSE: ', MSE, '\\t\\t\\t', 'Training time: ', training_time, '\\n')\n    \n    submission = eval_df[['id']]\n    submission['target'] = model.predict(eval_df['excerpt'])\n    print(submission)\n    submission.to_csv(f'/kaggle/working/{model_name}_submission.csv')\n    if model_name == 'RidgeRegression':\n        submission.to_csv(f'/kaggle/working/submission.csv')\n    \nridge = Ridge(fit_intercept=True, normalize=False)\nlr = LinearRegression()\nmodels = {\n    'RidgeRegression': ridge,\n    'LinearRegression': lr,\n}\nX = data['excerpt']\ny = data['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nfor model_name, model in models.items():\n    train(\n        model_name=model_name, model=model,\n        X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n        eval_df=test,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}