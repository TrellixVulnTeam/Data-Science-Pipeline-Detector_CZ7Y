{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport string\nimport re\nimport pickle\nimport gzip\nimport nltk\nimport torch\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\n\nfrom catboost import CatBoostClassifier, Pool, CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\nos.environ[\"HF_DATASETS_OFFLINE\"] = '1'\nos.environ[\"TRANSFORMERS_OFFLINE\"] = '1'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T08:46:16.998365Z","iopub.execute_input":"2021-08-01T08:46:16.998775Z","iopub.status.idle":"2021-08-01T08:46:17.015565Z","shell.execute_reply.started":"2021-08-01T08:46:16.998738Z","shell.execute_reply":"2021-08-01T08:46:17.01354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/sentence-transformers/sentence-transformers-master","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:17.018441Z","iopub.execute_input":"2021-08-01T08:46:17.019742Z","iopub.status.idle":"2021-08-01T08:46:45.769617Z","shell.execute_reply.started":"2021-08-01T08:46:17.0197Z","shell.execute_reply":"2021-08-01T08:46:45.768644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nFOLDS = 5\nSTRANSFORMERS = {\n    'sentence-transformers/paraphrase-mpnet-base-v2': ('mpnet', 768),\n    'sentence-transformers/bert-base-wikipedia-sections-mean-tokens': ('wikipedia', 768)\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:45.774019Z","iopub.execute_input":"2021-08-01T08:46:45.774301Z","iopub.status.idle":"2021-08-01T08:46:45.780788Z","shell.execute_reply.started":"2021-08-01T08:46:45.774273Z","shell.execute_reply":"2021-08-01T08:46:45.780015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pickle_load(filename, gzipping=True):\n    \"\"\"Loads a compressed object from disk\n    \"\"\"\n    open_f = gzip.GzipFile if gzipping else open\n    with open_f(filename, 'rb') as f:\n        object = pickle.load(f)\n    return object\n\ndef get_encode(df, encoder, name):    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    model = SentenceTransformer(\n        encoder, \n        cache_folder=f'/kaggle/input/huggingface-v3/hf_{name}/hf_{name}/'\n    )\n    model.to(device)\n    model.eval()\n    return np.array(model.encode(df['excerpt']))\n\ndef get_embeddings(df, emb=None):\n    \n    ret = pd.DataFrame(index=df.index)\n    \n    for e, s in STRANSFORMERS.items():\n        if emb and s[0] != emb:\n            continue\n            \n        ret[s[0]] = list(get_encode(df, e, s[0]))\n        ret = pd.concat(\n            [ret, pd.DataFrame(\n                ret[s[0]].tolist(),\n                columns=[f'{s[0]}_{x}' for x in range(s[1])],\n                index=ret.index)],\n            axis=1, copy=False, sort=False)\n    \n    return ret\n\ndef create_folds(X, n_splits, seed):\n\n    df = X[[\"target\"]].copy()\n    # calculate number of bins by Sturge's rule\n    num_bins = int(np.floor(1 + np.log2(len(df))))\n    \n    df.loc[:, \"bins\"] = pd.cut(\n        df[\"target\"], bins=num_bins, labels=False\n    )\n\n    kf = StratifiedKFold(\n        n_splits=n_splits,\n        shuffle=True,\n        random_state=seed)\n    \n    return kf.split(X=df, y=df['bins'].values)\n\ndef get_oof_svr(n_folds, x_train, y, x_test, seeds):\n    \n    ntrain = x_train.shape[0]\n    ntest = x_test.shape[0]  \n        \n    oof_train = np.zeros((len(seeds), ntrain))\n    oof_test = np.zeros((ntest))\n    oof_test_skf = np.empty((len(seeds), n_folds, ntest))\n\n    models = {}   \n    for iseed, seed in enumerate(seeds):\n        for i, (tr_i, t_i) in enumerate(\n                create_folds(\n                    pd.concat([x_train, y], axis=1, copy=False, sort=False),\n                    n_splits=n_folds,\n                    seed=seed\n                )):\n            print(f'\\nSeed {seed}, Fold {i}')\n            x_tr = pd.concat(\n                [x_train.iloc[tr_i, :], get_embeddings(x_train.iloc[tr_i, :])],\n                axis=1, copy=False, sort=False)\n            x_te = pd.concat(\n                [x_train.iloc[t_i, :], get_embeddings(x_train.iloc[t_i, :])],\n                axis=1, copy=False, sort=False)\n            y_tr = y[tr_i]\n            y_te = y[t_i]\n            svr_pipeline = Pipeline([\n                ('norm', MinMaxScaler()),\n                ('classifier', SVR(C=10, kernel='rbf', gamma='auto'))\n            ])\n            columns = [x for x in x_tr.columns if x not in ['excerpt'] + \\\n                       [y[0] for y in STRANSFORMERS.values()]]\n            svr_pipeline.fit(x_tr[columns], y_tr)\n            oof_train[iseed, t_i] = svr_pipeline.predict(x_te[columns])\n            oof_test_skf[iseed, i, :] = svr_pipeline.predict(pd.concat(\n                [x_test, get_embeddings(x_test)],\n                axis=1, copy=False, sort=False)[columns])\n            models[(seed, i)] = svr_pipeline\n            \n    oof_test[:] = oof_test_skf.mean(axis=1).mean(axis=0)\n    oof_train = oof_train.mean(axis=0)\n    \n    return oof_train, oof_test, models\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:45.783803Z","iopub.execute_input":"2021-08-01T08:46:45.784128Z","iopub.status.idle":"2021-08-01T08:46:45.808074Z","shell.execute_reply.started":"2021-08-01T08:46:45.784101Z","shell.execute_reply":"2021-08-01T08:46:45.807154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_src = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\", index_col='id')\ntrain_src = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\", index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:45.809489Z","iopub.execute_input":"2021-08-01T08:46:45.809836Z","iopub.status.idle":"2021-08-01T08:46:45.86807Z","shell.execute_reply.started":"2021-08-01T08:46:45.809797Z","shell.execute_reply":"2021-08-01T08:46:45.867132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_full = pd.concat([train_src, test_src], copy=True, sort=False, axis=0)\ndf_full['license'] = df_full['license'].fillna('nan')\n\n\nle_license = LabelEncoder()\nle_license.fit(df_full['license'])\ndf_full['license'] = le_license.transform(df_full['license'])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:45.869585Z","iopub.execute_input":"2021-08-01T08:46:45.869988Z","iopub.status.idle":"2021-08-01T08:46:45.882554Z","shell.execute_reply.started":"2021-08-01T08:46:45.869942Z","shell.execute_reply":"2021-08-01T08:46:45.881647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_models = pickle_load('../input/catboost-classifier-for-simple-normal-wiki-texts/models.zpkl')\n\ndef get_oof_classifier(\n        models, n_folds, x_test, text_features, seeds):\n    \n    ntest = x_test.shape[0]  \n    oof_test = np.zeros((ntest))\n    oof_test_skf = np.empty((len(seeds), n_folds, ntest))\n\n    test_pool = Pool(data=x_test, text_features=text_features)\n    \n    for iseed, seed in enumerate(seeds):\n        for i in range(n_folds):\n            model = models[(seed, i)]\n            oof_test_skf[iseed, i, :] = model.predict_proba(test_pool)[:,1]\n            \n    oof_test[:] = oof_test_skf.mean(axis=1).mean(axis=0)\n    \n    return oof_test","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:45.883818Z","iopub.execute_input":"2021-08-01T08:46:45.884347Z","iopub.status.idle":"2021-08-01T08:46:46.300504Z","shell.execute_reply.started":"2021-08-01T08:46:45.884287Z","shell.execute_reply":"2021-08-01T08:46:46.299421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_full.loc[train_src.index].copy()\ntest = df_full.loc[test_src.index].copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:46.301947Z","iopub.execute_input":"2021-08-01T08:46:46.302546Z","iopub.status.idle":"2021-08-01T08:46:46.315099Z","shell.execute_reply.started":"2021-08-01T08:46:46.3025Z","shell.execute_reply":"2021-08-01T08:46:46.314208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['excerpt']\ntest['text'] = test['excerpt']\n\ntrain['wiki_sn'] = get_oof_classifier(\n    models=cb_models,\n    n_folds=FOLDS,\n    x_test=train[['text']],\n    text_features=['text'],\n    seeds=[0, 42, 888]\n)\ntest['wiki_sn'] = get_oof_classifier(\n    models=cb_models,\n    n_folds=FOLDS,\n    x_test=test[['text']],\n    text_features=['text'],\n    seeds=[0, 42, 888]\n)\ndel train['text']\ndel test['text']","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:46:46.318441Z","iopub.execute_input":"2021-08-01T08:46:46.319074Z","iopub.status.idle":"2021-08-01T08:47:00.247266Z","shell.execute_reply.started":"2021-08-01T08:46:46.319012Z","shell.execute_reply":"2021-08-01T08:47:00.246403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['svr'], test['svr'], models_svr = get_oof_svr(\n    n_folds=FOLDS,\n    x_train=train[['license', 'excerpt', 'wiki_sn']],\n    y=train['target'],\n    x_test=test[['license', 'excerpt', 'wiki_sn']],\n    seeds=[0, 42, 888],\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:47:00.248585Z","iopub.execute_input":"2021-08-01T08:47:00.248901Z","iopub.status.idle":"2021-08-01T08:59:15.244527Z","shell.execute_reply.started":"2021-08-01T08:47:00.248866Z","shell.execute_reply":"2021-08-01T08:59:15.243551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(train['svr'], train['target'], squared=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:59:15.245974Z","iopub.execute_input":"2021-08-01T08:59:15.246475Z","iopub.status.idle":"2021-08-01T08:59:15.256673Z","shell.execute_reply.started":"2021-08-01T08:59:15.246435Z","shell.execute_reply":"2021-08-01T08:59:15.255534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_s = test['svr']\nsubmission_s.name = 'target'\nsubmission_s.to_csv(\"submission.csv\", header=True, index=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:59:15.258222Z","iopub.execute_input":"2021-08-01T08:59:15.258736Z","iopub.status.idle":"2021-08-01T08:59:15.265973Z","shell.execute_reply.started":"2021-08-01T08:59:15.258698Z","shell.execute_reply":"2021-08-01T08:59:15.264836Z"},"trusted":true},"execution_count":null,"outputs":[]}]}