{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook uses below given notebooks to make predictions.\n\n1. LB 0.468 https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3\n2. LB 0.474 https://www.kaggle.com/maunish/clrp-roberta-svm","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-23T11:01:30.06666Z","iopub.execute_input":"2021-06-23T11:01:30.067003Z","iopub.status.idle":"2021-06-23T11:01:36.522561Z","shell.execute_reply.started":"2021-06-23T11:01:30.066906Z","shell.execute_reply":"2021-06-23T11:01:36.521323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data =  pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:26.525421Z","iopub.execute_input":"2021-06-23T11:03:26.525851Z","iopub.status.idle":"2021-06-23T11:03:26.694765Z","shell.execute_reply.started":"2021-06-23T11:03:26.525805Z","shell.execute_reply":"2021-06-23T11:03:26.693934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'nfolds':5,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:29.520541Z","iopub.execute_input":"2021-06-23T11:03:29.520878Z","iopub.status.idle":"2021-06-23T11:03:29.531302Z","shell.execute_reply.started":"2021-06-23T11:03:29.520848Z","shell.execute_reply":"2021-06-23T11:03:29.530293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:29.944408Z","iopub.execute_input":"2021-06-23T11:03:29.94473Z","iopub.status.idle":"2021-06-23T11:03:29.95055Z","shell.execute_reply.started":"2021-06-23T11:03:29.944701Z","shell.execute_reply":"2021-06-23T11:03:29.949537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:30.349807Z","iopub.execute_input":"2021-06-23T11:03:30.350153Z","iopub.status.idle":"2021-06-23T11:03:30.358457Z","shell.execute_reply.started":"2021-06-23T11:03:30.350119Z","shell.execute_reply":"2021-06-23T11:03:30.357357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n        self.head = AttentionHead(768,768,1)\n        self.dropout = nn.Dropout(0.1)\n        self.linear = nn.Linear(self.head.out_features,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:30.869556Z","iopub.execute_input":"2021-06-23T11:03:30.869875Z","iopub.status.idle":"2021-06-23T11:03:30.877352Z","shell.execute_reply.started":"2021-06-23T11:03:30.869844Z","shell.execute_reply":"2021-06-23T11:03:30.87629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = Model()\n    model.load_state_dict(torch.load(path))\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n    \n    ds = CLRPDataset(df,tokenizer)\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs.detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:31.652287Z","iopub.execute_input":"2021-06-23T11:03:31.652605Z","iopub.status.idle":"2021-06-23T11:03:31.662594Z","shell.execute_reply.started":"2021-06-23T11:03:31.652573Z","shell.execute_reply":"2021-06-23T11:03:31.661487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import tokenize\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:33.390647Z","iopub.execute_input":"2021-06-23T11:03:33.390993Z","iopub.status.idle":"2021-06-23T11:03:33.963796Z","shell.execute_reply.started":"2021-06-23T11:03:33.390942Z","shell.execute_reply":"2021-06-23T11:03:33.962932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def synthesize_excerpt(train_data,r=0.5):\n    N=train_data.shape[0]\n    Ns=int(N*r)\n    idxs=np.repeat(np.arange(N),3)#np.random.randint(N,size=Ns)\n    ret_data=train_data.copy()\n    for i in idxs:\n        rand_target=train_data.iloc[i,:]\n        new=tokenize.sent_tokenize(rand_target['excerpt'])\n        random.shuffle(new)\n        new_excerpt=''.join(new)\n        rand_target['excerpt']=new_excerpt\n        ret_data=ret_data.append(rand_target, ignore_index=True)\n    ret_data = ret_data.sample(frac=1).reset_index(drop=True)\n    return ret_data\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:48.020063Z","iopub.execute_input":"2021-06-23T11:03:48.020384Z","iopub.status.idle":"2021-06-23T11:03:48.027081Z","shell.execute_reply.started":"2021-06-23T11:03:48.020355Z","shell.execute_reply":"2021-06-23T11:03:48.025948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=synthesize_excerpt(train_data,1.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:03:52.470093Z","iopub.execute_input":"2021-06-23T11:03:52.470411Z","iopub.status.idle":"2021-06-23T11:04:33.371321Z","shell.execute_reply.started":"2021-06-23T11:03:52.470383Z","shell.execute_reply":"2021-06-23T11:04:33.370461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  get_embeddings(train_data,'../input/clr-roberta/model0/model0.bin')\ntest_embeddings1 = get_embeddings(test_data,'../input/clr-roberta/model0/model0.bin')\n'''\ntrain_embeddings2 =  get_embeddings(train_data,'../input/clr-roberta/model1/model1.bin')\ntest_embeddings2 = get_embeddings(test_data,'../input/clr-roberta/model1/model1.bin')\n\ntrain_embeddings3 =  get_embeddings(train_data,'../input/clr-roberta/model2/model2.bin')\ntest_embeddings3 = get_embeddings(test_data,'../input/clr-roberta/model2/model2.bin')\n\ntrain_embeddings4 =  get_embeddings(train_data,'../input/clr-roberta/model3/model3.bin')\ntest_embeddings4 = get_embeddings(test_data,'../input/clr-roberta/model3/model3.bin')\n\ntrain_embeddings5 =  get_embeddings(train_data,'../input/clr-roberta/model4/model4.bin')\ntest_embeddings5 = get_embeddings(test_data,'../input/clr-roberta/model4/model4.bin')\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:04:33.372701Z","iopub.execute_input":"2021-06-23T11:04:33.373065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X=train_embeddings1\ntrain_Y=train_data.target.values\ntest_X=test_embeddings1\n\nprint('train_X: ',train_embeddings1.shape)\nprint('train_Y: ',train_data.target.shape)\nprint('test_X: ',test_embeddings1.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## From Embedding to Target","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge,Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected=Lasso(alpha=0.0).fit(train_embeddings1,train_Y)\nY_pred=selected.predict(test_embeddings1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret=pd.DataFrame(test_data['id'])\nret['target']=Y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}