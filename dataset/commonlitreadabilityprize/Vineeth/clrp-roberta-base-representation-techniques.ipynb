{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><b>Method:Concatenate Last 4 Layers - Roberta Large</b><center>","metadata":{}},{"cell_type":"markdown","source":"Method: **Conv1D Pooling** - **LB:0.500** - Version-3 <br>\nMethod: **LSTM/GRU Pooling** - **LB:0.494** - Version-4 <br>\nMethod: **Concatenate Pooling Roberta Base** - **LB:0.478** -Version-5 <br>\nMethod: **Concatenate Pooling Roberta Large** - Version-6 <br>\nMethod: **Concatenate Pooling Roberta Large Inference** - Version-7 <br>","metadata":{}},{"cell_type":"markdown","source":"**Code Credits:** <br>\n**Pretrained Models:** https://www.kaggle.com/maunish/clrp-roberta-base <br>\n**Fine Tuning Code:** https://www.kaggle.com/maunish/clrp-pytorch-roberta-finetune <br>\n**Techniques:** https://www.kaggle.com/rhtsingh/utilizing-transformer-representations-efficiently","metadata":{}},{"cell_type":"markdown","source":"Concatenate Pooling is the technique where we concatenate outputs from different layers into one. In the experiments performed by BERT Authors we saw that Concatenation of Last 4 Layers gave the best results.","metadata":{}},{"cell_type":"markdown","source":"**Inference: Roberta Large Concatenate Pooling**","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# from accelerate import Accelerator\nfrom transformers import (AutoModel,AutoConfig,\n                          AutoTokenizer,get_cosine_schedule_with_warmup)\n\nfrom colorama import Fore, Back, Style\nr_ = Fore.RED\nb_ = Fore.BLUE\nc_ = Fore.CYAN\ng_ = Fore.GREEN\ny_ = Fore.YELLOW\nm_ = Fore.MAGENTA\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-09T11:32:51.102755Z","iopub.execute_input":"2021-07-09T11:32:51.103152Z","iopub.status.idle":"2021-07-09T11:33:00.82719Z","shell.execute_reply.started":"2021-07-09T11:32:51.103068Z","shell.execute_reply":"2021-07-09T11:33:00.826243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\ntrain_data['excerpt'] = train_data['excerpt'].apply(lambda x: x.replace('\\n',''))\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\nbins = train_data.bins.to_numpy()\ntarget = train_data.target.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:33:02.981116Z","iopub.execute_input":"2021-07-09T11:33:02.981512Z","iopub.status.idle":"2021-07-09T11:33:03.15684Z","shell.execute_reply.started":"2021-07-09T11:33:02.981478Z","shell.execute_reply":"2021-07-09T11:33:03.155842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'lr': 2e-5,\n    'wd':0.01,\n    'batch_size':12,\n    'valid_step':10,\n    'max_len':256,\n    'epochs':3,\n    'nfolds':5,\n    'seed':42,\n    'model_path':'../input/clrp-roberta-large-pretrain/clrp_roberta_large',\n}\n\nfor i in range(config['nfolds']):\n    os.makedirs(f'model{i}',exist_ok=True)\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])\n\ntrain_data['Fold'] = -1\nkfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\nfor k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=bins)):\n    train_data.loc[valid_idx,'Fold'] = k","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:33:05.074268Z","iopub.execute_input":"2021-07-09T11:33:05.074647Z","iopub.status.idle":"2021-07-09T11:33:05.10152Z","shell.execute_reply.started":"2021-07-09T11:33:05.074614Z","shell.execute_reply":"2021-07-09T11:33:05.100581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,path):\n        super(Model,self).__init__()\n        self.config = AutoConfig.from_pretrained(path)\n        self.config.update({'output_hidden_states':True,\"hidden_dropout_prob\": 0.0})\n        self.roberta = AutoModel.from_pretrained(path,config=self.config)  \n        self.linear = nn.Linear(self.config.hidden_size*4, 1, 1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)\n        x = torch.stack(x[2])\n        x = torch.cat((x[-1], x[-2], x[-3], x[-4]),-1)\n        x = x[:, 0]\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:33:07.50882Z","iopub.execute_input":"2021-07-09T11:33:07.509188Z","iopub.status.idle":"2021-07-09T11:33:07.517923Z","shell.execute_reply.started":"2021-07-09T11:33:07.509153Z","shell.execute_reply":"2021-07-09T11:33:07.51662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference**","metadata":{}},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n   \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:33:11.321051Z","iopub.execute_input":"2021-07-09T11:33:11.321447Z","iopub.status.idle":"2021-07-09T11:33:11.329611Z","shell.execute_reply.started":"2021-07-09T11:33:11.321412Z","shell.execute_reply":"2021-07-09T11:33:11.328548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_prediction(df,path,model_path,device='cuda'):        \n    model = Model(model_path)\n    model.load_state_dict(torch.load(path,map_location=device))\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    \n    test_ds = CLRPDataset(df,tokenizer)\n    test_dl = DataLoader(test_ds,\n                        batch_size = config[\"batch_size\"],\n                        shuffle=False,\n                        num_workers = 4,\n                        pin_memory=True)\n    \n    predictions = list()\n    for i, (inputs) in tqdm(enumerate(test_dl)):\n        inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n        outputs = model(**inputs)\n        outputs = outputs.cpu().detach().numpy().ravel().tolist()\n        predictions.extend(outputs)\n        \n    torch.cuda.empty_cache()\n    return np.array(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:33:13.031081Z","iopub.execute_input":"2021-07-09T11:33:13.03149Z","iopub.status.idle":"2021-07-09T11:33:13.042277Z","shell.execute_reply.started":"2021-07-09T11:33:13.031457Z","shell.execute_reply":"2021-07-09T11:33:13.040886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred1 = get_prediction(test_data,'../input/clrp-distilroberta-baseuncased-finetune/model0/model0.bin','../input/clrp-roberta-large-pretrain/clrp_roberta_large')\npred2 = get_prediction(test_data,'../input/clrp-distilroberta-baseuncased-finetune/model1/model1.bin','../input/clrp-roberta-large-pretrain/clrp_roberta_large')\npred3 = get_prediction(test_data,'../input/clrp-distilroberta-baseuncased-finetune/model2/model2.bin','../input/clrp-roberta-large-pretrain/clrp_roberta_large')\npred4 = get_prediction(test_data,'../input/clrp-distilroberta-baseuncased-finetune/model3/model3.bin','../input/clrp-roberta-large-pretrain/clrp_roberta_large')\npred5 = get_prediction(test_data,'../input/clrp-distilroberta-baseuncased-finetune/model4/model4.bin','../input/clrp-roberta-large-pretrain/clrp_roberta_large')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:33:14.427093Z","iopub.execute_input":"2021-07-09T11:33:14.427488Z","iopub.status.idle":"2021-07-09T11:35:30.279088Z","shell.execute_reply.started":"2021-07-09T11:33:14.427453Z","shell.execute_reply":"2021-07-09T11:35:30.2777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = (pred1 + pred2 + pred3 + pred4 + pred5)/5\nsample['target'] = predictions\nsample.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:35:36.440046Z","iopub.execute_input":"2021-07-09T11:35:36.440476Z","iopub.status.idle":"2021-07-09T11:35:36.995276Z","shell.execute_reply.started":"2021-07-09T11:35:36.440436Z","shell.execute_reply":"2021-07-09T11:35:36.994326Z"},"trusted":true},"execution_count":null,"outputs":[]}]}