{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T07:59:47.718763Z","iopub.execute_input":"2021-08-06T07:59:47.719151Z","iopub.status.idle":"2021-08-06T07:59:47.739298Z","shell.execute_reply.started":"2021-08-06T07:59:47.719073Z","shell.execute_reply":"2021-08-06T07:59:47.738385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding = {}\nf = open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding='utf-8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    em = np.asarray(values[1:], dtype='float32')\n    embedding[word] = em\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T07:59:50.608923Z","iopub.execute_input":"2021-08-06T07:59:50.609321Z","iopub.status.idle":"2021-08-06T08:00:09.858379Z","shell.execute_reply.started":"2021-08-06T07:59:50.609288Z","shell.execute_reply":"2021-08-06T08:00:09.857494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\ndata_test = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:05.78872Z","iopub.execute_input":"2021-08-06T08:02:05.789076Z","iopub.status.idle":"2021-08-06T08:02:05.835724Z","shell.execute_reply.started":"2021-08-06T08:02:05.789046Z","shell.execute_reply":"2021-08-06T08:02:05.834876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:01:44.762131Z","iopub.execute_input":"2021-08-06T08:01:44.762659Z","iopub.status.idle":"2021-08-06T08:01:44.76979Z","shell.execute_reply.started":"2021-08-06T08:01:44.762628Z","shell.execute_reply":"2021-08-06T08:01:44.768791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apostrophe Dictionary(Từ điển viết tắt)\napostrophe_dict = {\n\"ain't\": \"am not / are not\",\n\"aren't\": \"are not / am not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had / he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he shall / he will\",\n\"he'll've\": \"he shall have / he will have\",\n\"he's\": \"he has / he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how has / how is\",\n\"i'd\": \"I had / I would\",\n\"i'd've\": \"I would have\",\n\"i'll\": \"I shall / I will\",\n\"i'll've\": \"I shall have / I will have\",\n\"i'm\": \"I am\",\n\"i've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it had / it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it shall / it will\",\n\"it'll've\": \"it shall have / it will have\",\n\"it's\": \"it has / it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she had / she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she shall / she will\",\n\"she'll've\": \"she shall have / she will have\",\n\"she's\": \"she has / she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as / so is\",\n\"that'd\": \"that would / that had\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that has / that is\",\n\"there'd\": \"there had / there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there has / there is\",\n\"they'd\": \"they had / they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they shall / they will\",\n\"they'll've\": \"they shall have / they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had / we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what shall / what will\",\n\"what'll've\": \"what shall have / what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what has / what is\",\n\"what've\": \"what have\",\n\"when's\": \"when has / when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where has / where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who shall / who will\",\n\"who'll've\": \"who shall have / who will have\",\n\"who's\": \"who has / who is\",\n\"who've\": \"who have\",\n\"why's\": \"why has / why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you had / you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you shall / you will\",\n\"you'll've\": \"you shall have / you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}\n\n# Function replace acronyms (Hàm xử lý từ viết tắt -> từ đầy đủ)\ndef lookup_dict(text, dictionary):\n    for word in text.split():\n        if word.lower() in dictionary:\n            if word.lower() in text.split():\n                text = text.replace(word, dictionary[word.lower()])\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:00:23.354543Z","iopub.execute_input":"2021-08-06T08:00:23.354885Z","iopub.status.idle":"2021-08-06T08:00:23.371807Z","shell.execute_reply.started":"2021-08-06T08:00:23.354857Z","shell.execute_reply":"2021-08-06T08:00:23.370825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['excerpt'] = data_train['excerpt'].apply(lambda x: lookup_dict(x,apostrophe_dict))\ndata_test['excerpt'] = data_test['excerpt'].apply(lambda x: lookup_dict(x,apostrophe_dict))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:10.916938Z","iopub.execute_input":"2021-08-06T08:02:10.917286Z","iopub.status.idle":"2021-08-06T08:02:11.055231Z","shell.execute_reply.started":"2021-08-06T08:02:10.917258Z","shell.execute_reply":"2021-08-06T08:02:11.05455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = data_train['target']\ndata_train = data_train['excerpt']\n\ndata_train, data_val, y, y_val = train_test_split(\n    data_train.values.tolist(), y.values.tolist(), test_size = 0.20, random_state = 12)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:13.209467Z","iopub.execute_input":"2021-08-06T08:02:13.210085Z","iopub.status.idle":"2021-08-06T08:02:13.217725Z","shell.execute_reply.started":"2021-08-06T08:02:13.210049Z","shell.execute_reply":"2021-08-06T08:02:13.217017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def average_doc_vec(words):\n  a = [embedding[w] for w in words if w in embedding]\n  a = np.asarray(a)\n  return np.sum(a, 0)/len(a)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:17.64834Z","iopub.execute_input":"2021-08-06T08:02:17.648921Z","iopub.status.idle":"2021-08-06T08:02:17.65479Z","shell.execute_reply.started":"2021-08-06T08:02:17.648873Z","shell.execute_reply":"2021-08-06T08:02:17.654039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train[5].split()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:21.267108Z","iopub.execute_input":"2021-08-06T08:02:21.267692Z","iopub.status.idle":"2021-08-06T08:02:21.27539Z","shell.execute_reply.started":"2021-08-06T08:02:21.267656Z","shell.execute_reply":"2021-08-06T08:02:21.274805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nn = len(data_train)\nm = 100\nn_val = len(data_val)\nn_test = len(data_test)\nX = np.zeros((n, m))\nX_val = np.zeros((n_val, m))\nX_test = np.zeros((n_test, m))\n\nimport string\n\nfor i in range(n):\n    tokens = data_train[i].split()\n    X[i,:] = average_doc_vec(tokens)\n\nfor i in range(n_val):\n    tokens_val = data_val[i].split()\n    X_val[i, :] = average_doc_vec(tokens_val)\n    \nfor i in range(n_test):\n    tokens_test = data_test['excerpt'][i].split()\n    X_test[i, :] = average_doc_vec(tokens_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:26.919932Z","iopub.execute_input":"2021-08-06T08:02:26.920269Z","iopub.status.idle":"2021-08-06T08:02:27.394606Z","shell.execute_reply.started":"2021-08-06T08:02:26.920241Z","shell.execute_reply":"2021-08-06T08:02:27.39361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nlr = LinearRegression()\nlr.fit(X, y)\n\ny_pred = lr.predict(X_val)\n\nmean_squared_error(y_pred, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:30.973267Z","iopub.execute_input":"2021-08-06T08:02:30.973626Z","iopub.status.idle":"2021-08-06T08:02:31.335679Z","shell.execute_reply.started":"2021-08-06T08:02:30.973594Z","shell.execute_reply":"2021-08-06T08:02:31.334545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nrr = Ridge(alpha=0.759, max_iter=500)\nrr.fit(X, y)\n\ny_pred = rr.predict(X_val)\n\nmean_squared_error(y_pred, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:35.038882Z","iopub.execute_input":"2021-08-06T08:02:35.039223Z","iopub.status.idle":"2021-08-06T08:02:35.063561Z","shell.execute_reply.started":"2021-08-06T08:02:35.039195Z","shell.execute_reply":"2021-08-06T08:02:35.062638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = lr.predict(X_test)\nmy_submission = pd.DataFrame({'id': data_test.id.to_numpy(), 'target': y_pred })\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:02:40.013663Z","iopub.execute_input":"2021-08-06T08:02:40.014303Z","iopub.status.idle":"2021-08-06T08:02:40.023535Z","shell.execute_reply.started":"2021-08-06T08:02:40.014271Z","shell.execute_reply":"2021-08-06T08:02:40.022646Z"},"trusted":true},"execution_count":null,"outputs":[]}]}