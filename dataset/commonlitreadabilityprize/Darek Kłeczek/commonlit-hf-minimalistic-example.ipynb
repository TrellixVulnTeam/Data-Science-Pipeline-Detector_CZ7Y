{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Minimalistic example to solve CommonLit with HuggingFace transformers and datasets\n\nI'd like to write the simplest possible notebook to train and infer a pretrained transformer model on the CommonLit data. To do this, I use HuggingFace transformers along with their trainer, and HuggingFace datasets to preprocess the data. I created an offline package for HF datasets so that you can use it during inference mode. \n\n### Please upvote if you find this helpful :) ","metadata":{}},{"cell_type":"code","source":"!pip uninstall fsspec -qq -y\n!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T15:10:05.866178Z","iopub.execute_input":"2021-06-09T15:10:05.866494Z","iopub.status.idle":"2021-06-09T15:10:17.176358Z","shell.execute_reply.started":"2021-06-09T15:10:05.866422Z","shell.execute_reply":"2021-06-09T15:10:17.174929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom sklearn.metrics import mean_squared_error\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-09T15:10:17.181204Z","iopub.execute_input":"2021-06-09T15:10:17.181553Z","iopub.status.idle":"2021-06-09T15:10:26.850145Z","shell.execute_reply.started":"2021-06-09T15:10:17.181517Z","shell.execute_reply":"2021-06-09T15:10:26.848966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# disable W&B logging as we don't have access to the internet\n%env WANDB_DISABLED=True","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:10:26.852494Z","iopub.execute_input":"2021-06-09T15:10:26.853207Z","iopub.status.idle":"2021-06-09T15:10:26.860813Z","shell.execute_reply.started":"2021-06-09T15:10:26.853154Z","shell.execute_reply":"2021-06-09T15:10:26.859416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"model_checkpoint = '../input/distillbert-huggingface-model'\nbatch_size = 16\nmax_length = 256","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:10:26.863182Z","iopub.execute_input":"2021-06-09T15:10:26.863667Z","iopub.status.idle":"2021-06-09T15:10:26.873406Z","shell.execute_reply.started":"2021-06-09T15:10:26.863593Z","shell.execute_reply":"2021-06-09T15:10:26.871569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading and preprocessing training data with HF datasets","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/step-1-create-folds/train_folds.csv') # https://www.kaggle.com/abhishek/step-1-create-folds\ndf = df.rename(columns={'target':'label'}) # HF expects this column name to pick up the target column in trainer\n\ntrain_dataset = Dataset.from_pandas(df[df.kfold != 0].reset_index(drop=True))\nvalid_dataset = Dataset.from_pandas(df[df.kfold == 0].reset_index(drop=True))\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n\ndef tokenize(batch): return tokenizer(batch['excerpt'], padding='max_length', truncation=True, max_length=max_length)\n\ntrain_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\nvalid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:10:27.154041Z","iopub.execute_input":"2021-06-09T15:10:27.154542Z","iopub.status.idle":"2021-06-09T15:10:29.253241Z","shell.execute_reply.started":"2021-06-09T15:10:27.154488Z","shell.execute_reply":"2021-06-09T15:10:29.251855Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and Training with HF transformers","metadata":{}},{"cell_type":"code","source":"def model_init():\n    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=1) # note this is actually a regression model\n\ndef compute_metrics(pred):\n    return {\n        'rmse': mean_squared_error(pred.label_ids, pred.predictions, squared=False),\n    }\n\n# hyperparameter tuning in this notebook: https://www.kaggle.com/thedrcat/commonlit-hf-trainer-hyperparameter-tuning/\nargs = TrainingArguments(\n    \"./tmp\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=9.734456575183276e-05,\n    fp16=True,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    seed=2,\n    weight_decay=0.006786875788460002,\n    load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n    model_init=model_init,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T15:40:01.986573Z","iopub.execute_input":"2021-06-09T15:40:01.987029Z","iopub.status.idle":"2021-06-09T15:40:10.649055Z","shell.execute_reply.started":"2021-06-09T15:40:01.986992Z","shell.execute_reply":"2021-06-09T15:40:10.647563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:40:10.651208Z","iopub.execute_input":"2021-06-09T15:40:10.65164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Inference","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_df = test_df.rename(columns={'target':'label'})\n\ntest_dataset = Dataset.from_pandas(test_df)\ntest_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n\ntest_preds = trainer.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:22:49.88325Z","iopub.status.idle":"2021-06-09T15:22:49.884021Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsub.target = test_preds[0]\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:22:49.89259Z","iopub.status.idle":"2021-06-09T15:22:49.893381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Please upvote if you find this helpful :) ","metadata":{}}]}