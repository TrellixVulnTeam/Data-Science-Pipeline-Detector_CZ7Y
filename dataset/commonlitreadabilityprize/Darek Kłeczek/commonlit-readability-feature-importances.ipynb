{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CommonLit Readability Feature Importances\n\nThis competition is interesting because it can be approached with a variety of features and approaches - tabular features, NLP, CV etc. In this notebook, I'd like to explore the tabular features and their importances. I'll use the `readability` package (thanks to @takamichitoda for the demo notebook). The feature importance investigation follows the process from **Deep Learning for Coders with Fastai and PyTorch** book by @jhoward and @sgugger. \n\nSources:\n- https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb\n- https://www.kaggle.com/takamichitoda/commonlit-classical-methods-for-text-readability\n- https://github.com/andreasvc/readability/","metadata":{}},{"cell_type":"code","source":"!pip install ../input/readability-package -qq\n\n!mkdir -p /tmp/pip/cache/\n!cp ../input/syntok/wheels/syntok-1.3.1.xyz /tmp/pip/cache/syntok-1.3.1.tar.gz\n!cp ../input/syntok/wheels/regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ syntok","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-11T14:16:26.703783Z","iopub.execute_input":"2021-06-11T14:16:26.704184Z","iopub.status.idle":"2021-06-11T14:17:06.91529Z","shell.execute_reply.started":"2021-06-11T14:16:26.704103Z","shell.execute_reply":"2021-06-11T14:17:06.914295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import readability\nimport numpy as np\nimport pandas as pd \nimport os\nimport syntok.segmenter as segmenter\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.auto import tqdm\nimport scipy\nfrom scipy.cluster import hierarchy as hc\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T14:17:06.917518Z","iopub.execute_input":"2021-06-11T14:17:06.917845Z","iopub.status.idle":"2021-06-11T14:17:08.325592Z","shell.execute_reply.started":"2021-06-11T14:17:06.917808Z","shell.execute_reply":"2021-06-11T14:17:08.324564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/takamichitoda/commonlit-classical-methods-for-text-readability\ndef _calc_readability(text):\n    tokenized = '\\n\\n'.join(\n         '\\n'.join(' '.join(token.value for token in sentence)\n            for sentence in paragraph)\n         for paragraph in segmenter.analyze(text))\n    return readability.getmeasures(tokenized, lang='en')\n\ndef _extract_feat(row):\n    dic = {}\n    for k, v in row.items():\n        for kk, vv in v.items():\n            key = f'{\"_\".join(k.split())}_{kk}'\n            dic.update({key: vv})\n    return dic\n\n# https://github.com/fastai/fastbook/blob/master/utils.py\ndef cluster_columns(df, figsize=(10,6), font_size=12):\n    corr = np.round(scipy.stats.spearmanr(df).correlation, 4)\n    corr_condensed = hc.distance.squareform(1-corr)\n    z = hc.linkage(corr_condensed, method='average')\n    fig = plt.figure(figsize=figsize)\n    hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T14:17:08.327277Z","iopub.execute_input":"2021-06-11T14:17:08.327642Z","iopub.status.idle":"2021-06-11T14:17:08.338221Z","shell.execute_reply.started":"2021-06-11T14:17:08.327612Z","shell.execute_reply":"2021-06-11T14:17:08.337173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Regressor\n\nLet's start by building a simple random forest regressor model with all the readability features and see its score on a single fold (using folds by @abhishek)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/step-1-create-folds/train_folds.csv')\ndf['readability'] = df['excerpt'].map(lambda x: _calc_readability(x))\n\ndf_features = pd.DataFrame(df['readability'].map(_extract_feat).tolist())\ndf_features['kfold'] = df['kfold']\ndf_features['target'] = df['target']\n\ndf_train = df_features[df_features.kfold != 0].reset_index(drop=True)\ndf_valid = df_features[df_features.kfold == 0].reset_index(drop=True)\n\ntrain_features = df_train.drop(['kfold', 'target'], axis=1)\nvalid_features = df_valid.drop(['kfold', 'target'], axis=1)\ntrain_labels = df_train.target.values\nvalid_labels = df_valid.target.values","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:17:08.339768Z","iopub.execute_input":"2021-06-11T14:17:08.340083Z","iopub.status.idle":"2021-06-11T14:17:24.340155Z","shell.execute_reply.started":"2021-06-11T14:17:08.340042Z","shell.execute_reply":"2021-06-11T14:17:24.339368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rf(train_features, valid_features, train_labels, valid_labels):\n    model = RandomForestRegressor(random_state=42)\n    model.fit(train_features, train_labels)\n    valid_preds = model.predict(valid_features)\n    rmse = mean_squared_error(valid_labels, valid_preds, squared=False)\n    return model, rmse\n\nmodel, rmse = rf(train_features, valid_features, train_labels, valid_labels)\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:17:24.341228Z","iopub.execute_input":"2021-06-11T14:17:24.341641Z","iopub.status.idle":"2021-06-11T14:17:27.935507Z","shell.execute_reply.started":"2021-06-11T14:17:24.341611Z","shell.execute_reply":"2021-06-11T14:17:27.934613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Importances\n\nWe can now check the relative feature importances and plot them. ","metadata":{}},{"cell_type":"code","source":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:17:27.936504Z","iopub.execute_input":"2021-06-11T14:17:27.936896Z","iopub.status.idle":"2021-06-11T14:17:27.940969Z","shell.execute_reply.started":"2021-06-11T14:17:27.936868Z","shell.execute_reply":"2021-06-11T14:17:27.940202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi = rf_feat_importance(model, train_features)\nfi[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:17:27.94205Z","iopub.execute_input":"2021-06-11T14:17:27.942488Z","iopub.status.idle":"2021-06-11T14:17:27.986243Z","shell.execute_reply.started":"2021-06-11T14:17:27.942458Z","shell.execute_reply":"2021-06-11T14:17:27.98524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi);","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:17:27.988159Z","iopub.execute_input":"2021-06-11T14:17:27.988444Z","iopub.status.idle":"2021-06-11T14:17:28.530049Z","shell.execute_reply.started":"2021-06-11T14:17:27.988416Z","shell.execute_reply":"2021-06-11T14:17:28.529049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try to cut off the less important features and see the effect on the score. ","metadata":{}},{"cell_type":"code","source":"to_keep = fi[fi.imp>0.01].cols\n\ntrain_features_imp = train_features[to_keep]\nvalid_features_imp = valid_features[to_keep]\n\nmodel, rmse = rf(train_features_imp, valid_features_imp, train_labels, valid_labels)\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:18:46.505347Z","iopub.execute_input":"2021-06-11T14:18:46.505773Z","iopub.status.idle":"2021-06-11T14:18:49.693683Z","shell.execute_reply.started":"2021-06-11T14:18:46.505737Z","shell.execute_reply":"2021-06-11T14:18:49.692588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The score improved! Fewer features means smaller risk of overfitting, so this is promissing. ","metadata":{}},{"cell_type":"markdown","source":"## Similar Features\n\nWe can now see which features are highly correlated, and see if removing them helps us get a better score. ","metadata":{}},{"cell_type":"code","source":"cluster_columns(train_features_imp)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:20:24.601883Z","iopub.execute_input":"2021-06-11T14:20:24.602245Z","iopub.status.idle":"2021-06-11T14:20:24.944213Z","shell.execute_reply.started":"2021-06-11T14:20:24.602211Z","shell.execute_reply":"2021-06-11T14:20:24.943065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(train_feats, f):\n    model = RandomForestRegressor(random_state=42)\n    model.fit(train_feats.drop(f, axis=1), train_labels)\n    valid_preds = model.predict(valid_features_imp.drop(f, axis=1))\n    rmse = mean_squared_error(valid_labels, valid_preds, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:20:25.123856Z","iopub.execute_input":"2021-06-11T14:20:25.124222Z","iopub.status.idle":"2021-06-11T14:20:25.129556Z","shell.execute_reply.started":"2021-06-11T14:20:25.124184Z","shell.execute_reply":"2021-06-11T14:20:25.128598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{f:get_score(train_features_imp, f) for f in (\n    'sentence_info_characters_per_word', 'readability_grades_Coleman-Liau', 'readability_grades_Kincaid',\n    'readability_grades_ARI', 'readability_grades_LIX', 'readability_grades_RIX')}","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:20:26.015995Z","iopub.execute_input":"2021-06-11T14:20:26.016616Z","iopub.status.idle":"2021-06-11T14:20:44.457748Z","shell.execute_reply.started":"2021-06-11T14:20:26.016564Z","shell.execute_reply":"2021-06-11T14:20:44.45567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So the biggest improvement comes from removing `readability_grades_RIX` feature, which incidentally is also the most important feature! Glad we discovered this, as written for example [here](https://readable.com/blog/the-lix-and-rix-readability-formulas), LIX and RIX features are highly correlated, so we should be safe to remove RIX from our feature set. Let's also review our final feature importances. ","metadata":{}},{"cell_type":"code","source":"train_features_final = train_features_imp.drop('readability_grades_RIX', axis=1)\nvalid_features_final = valid_features_imp.drop('readability_grades_RIX', axis=1)\n\nmodel, rmse = rf(train_features_final, valid_features_final, train_labels, valid_labels)\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:53:55.639042Z","iopub.execute_input":"2021-06-11T14:53:55.639699Z","iopub.status.idle":"2021-06-11T14:53:58.733405Z","shell.execute_reply.started":"2021-06-11T14:53:55.639658Z","shell.execute_reply":"2021-06-11T14:53:58.732474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_fi(rf_feat_importance(model, train_features_final));","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:53:58.734762Z","iopub.execute_input":"2021-06-11T14:53:58.735034Z","iopub.status.idle":"2021-06-11T14:53:59.130095Z","shell.execute_reply.started":"2021-06-11T14:53:58.735007Z","shell.execute_reply":"2021-06-11T14:53:59.129188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5-fold Training and Test Inference\n\nLet's confirm that our feature removal also works when evaluated in a 5-fold cv setting. We'll get the mean RMSE score for both *all features* and *final features* setting. ","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_df['readability'] = test_df['excerpt'].map(lambda x: _calc_readability(x))\ntest_df_features = pd.DataFrame(test_df['readability'].map(_extract_feat).tolist())","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:56:18.625043Z","iopub.execute_input":"2021-06-11T14:56:18.625399Z","iopub.status.idle":"2021-06-11T14:56:18.688494Z","shell.execute_reply.started":"2021-06-11T14:56:18.625368Z","shell.execute_reply":"2021-06-11T14:56:18.687679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(features):\n    test_features = test_df_features[features]\n\n    fold_scores = []\n    fold_preds = []\n\n    for fold in tqdm(range(5)):\n        df_train = df_features[df_features.kfold != fold].reset_index(drop=True)\n        df_valid = df_features[df_features.kfold == fold].reset_index(drop=True)\n\n        train_features = df_train[features]\n        valid_features = df_valid[features]\n\n        train_labels = df_train.target.values\n        valid_labels = df_valid.target.values\n\n        model, rmse = rf(train_features, valid_features, train_labels, valid_labels)\n        fold_scores.append(rmse)\n\n        test_preds = model.predict(test_features)\n        fold_preds.append(test_preds)\n\n    return np.mean(fold_scores), fold_scores, fold_preds","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:56:18.961693Z","iopub.execute_input":"2021-06-11T14:56:18.962173Z","iopub.status.idle":"2021-06-11T14:56:18.969804Z","shell.execute_reply.started":"2021-06-11T14:56:18.962129Z","shell.execute_reply":"2021-06-11T14:56:18.968808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [x for x in df_features.columns.tolist() if x not in ['kfold', 'target']]\nscore, fold_scores, fold_preds = get_preds(features)\nscore","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:56:19.41929Z","iopub.execute_input":"2021-06-11T14:56:19.419833Z","iopub.status.idle":"2021-06-11T14:56:36.894996Z","shell.execute_reply.started":"2021-06-11T14:56:19.419787Z","shell.execute_reply":"2021-06-11T14:56:36.894115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train_features_final.columns.tolist()\nscore, fold_scores, fold_preds = get_preds(features)\nscore","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:56:36.89669Z","iopub.execute_input":"2021-06-11T14:56:36.897092Z","iopub.status.idle":"2021-06-11T14:56:51.798762Z","shell.execute_reply.started":"2021-06-11T14:56:36.897052Z","shell.execute_reply":"2021-06-11T14:56:51.797735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our final features perform sligthly better than all features, so we will use them to make our final submission. ","metadata":{}},{"cell_type":"code","source":"preds = np.stack(fold_preds).mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:56:51.800747Z","iopub.execute_input":"2021-06-11T14:56:51.801217Z","iopub.status.idle":"2021-06-11T14:56:51.806432Z","shell.execute_reply.started":"2021-06-11T14:56:51.801165Z","shell.execute_reply":"2021-06-11T14:56:51.805469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsub.target = preds\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:51:09.975021Z","iopub.execute_input":"2021-06-11T12:51:09.975346Z","iopub.status.idle":"2021-06-11T12:51:10.004159Z","shell.execute_reply.started":"2021-06-11T12:51:09.975315Z","shell.execute_reply":"2021-06-11T12:51:10.003195Z"},"trusted":true},"execution_count":null,"outputs":[]}]}