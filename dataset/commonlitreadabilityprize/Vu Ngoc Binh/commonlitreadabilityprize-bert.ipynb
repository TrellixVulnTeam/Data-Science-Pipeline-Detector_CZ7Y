{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-tuner\n!pip install tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:26.775355Z","iopub.execute_input":"2021-07-23T13:28:26.776008Z","iopub.status.idle":"2021-07-23T13:28:42.809302Z","shell.execute_reply.started":"2021-07-23T13:28:26.775895Z","shell.execute_reply":"2021-07-23T13:28:42.808257Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport glob\nimport tensorflow.keras.layers as layers\nimport tensorflow_addons as tfa\nimport random\nfrom transformers import BertTokenizer, TFBertModel\nfrom transformers import RobertaTokenizer, TFRobertaModel\nimport kerastuner as kt","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:28:42.811861Z","iopub.execute_input":"2021-07-23T13:28:42.812218Z","iopub.status.idle":"2021-07-23T13:28:51.842609Z","shell.execute_reply.started":"2021-07-23T13:28:42.812173Z","shell.execute_reply":"2021-07-23T13:28:51.841584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_path = \"../input/commonlitreadabilityprize/\"","metadata":{"papermill":{"duration":0.013086,"end_time":"2021-07-01T02:44:09.402728","exception":false,"start_time":"2021-07-01T02:44:09.389642","status":"completed"},"tags":[],"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:28:51.844367Z","iopub.execute_input":"2021-07-23T13:28:51.844684Z","iopub.status.idle":"2021-07-23T13:28:51.850054Z","shell.execute_reply.started":"2021-07-23T13:28:51.844652Z","shell.execute_reply":"2021-07-23T13:28:51.849181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn on tpu\n# Detect TPU, return appropriate distribution strategy\nstrategy = tf.distribute.get_strategy() \n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"papermill":{"duration":0.022361,"end_time":"2021-07-01T02:44:09.432069","exception":false,"start_time":"2021-07-01T02:44:09.409708","status":"completed"},"tags":[],"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:28:51.851468Z","iopub.execute_input":"2021-07-23T13:28:51.851769Z","iopub.status.idle":"2021-07-23T13:28:58.072283Z","shell.execute_reply.started":"2021-07-23T13:28:51.851743Z","shell.execute_reply":"2021-07-23T13:28:58.071376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(ds_path + \"train.csv\")\ntest_df = pd.read_csv(ds_path + \"test.csv\")\nprint(train_df.head())\nprint(test_df.head())\n","metadata":{"papermill":{"duration":0.021603,"end_time":"2021-07-01T02:44:14.245241","exception":false,"start_time":"2021-07-01T02:44:14.223638","status":"completed"},"tags":[],"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:28:58.07358Z","iopub.execute_input":"2021-07-23T13:28:58.07388Z","iopub.status.idle":"2021-07-23T13:28:58.252947Z","shell.execute_reply.started":"2021-07-23T13:28:58.073849Z","shell.execute_reply":"2021-07-23T13:28:58.251794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_row = 2834\ndef prepare_train_df(train_df):\n    excerpt = train_df[\"excerpt\"].to_list()\n    target = train_df[\"target\"].to_list()\n    standard_error = train_df[\"standard_error\"].to_list()\n    '''\n    for i in range(2834 * 10):\n        random_number = np.random.uniform(low=-1.0, high=1.0)\n        target[i] = target[i] + 1.96*random_number*standard_error[i]\n    '''\n    return pd.DataFrame(zip(excerpt, target), columns =['excerpt', 'target']) \n\nfinal_train_df = prepare_train_df(train_df)\nfinal_train_df","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:28:58.254358Z","iopub.execute_input":"2021-07-23T13:28:58.254709Z","iopub.status.idle":"2021-07-23T13:28:58.286197Z","shell.execute_reply.started":"2021-07-23T13:28:58.254668Z","shell.execute_reply":"2021-07-23T13:28:58.284692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"../input/huggingface-roberta-variants/roberta-base/roberta-base\"\n# tokenizer = BertTokenizer.from_pretrained(model_path)\ntokenizer = RobertaTokenizer.from_pretrained(model_path)\nencodings = tokenizer(\n    final_train_df[\"excerpt\"].to_list(), \n    truncation=True, \n    padding='max_length',\n    max_length=350,\n)\n\nencoded_input = [\n    np.array(encodings[\"input_ids\"]), \n    # np.array(encodings[\"token_type_ids\"]),\n    # np.array(encodings[\"attention_mask\"])\n]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:28:58.28842Z","iopub.execute_input":"2021-07-23T13:28:58.28893Z","iopub.status.idle":"2021-07-23T13:29:04.644709Z","shell.execute_reply.started":"2021-07-23T13:28:58.288877Z","shell.execute_reply":"2021-07-23T13:29:04.64356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    # lr = hp.Float(\"learning_rate\", min_value=1e-3, max_value=1e-6)\n    # wd = hp.Float(\"weight_decay\", min_value=1e-4, max_value=1e-8)\n    # dropout_1 = hp.Float(\"dropout_1\", min_value=0, max_value=0.5)\n    # dropout_2 = hp.Float(\"dropout_2\", min_value=0, max_value=0.5)\n    lr = 0.0005539112740501631\n    wd = 5.994404522700284e-05\n    dropout_1 = 0.2597885402021029\n    dropout_2 = 0.23003497097673098\n    with strategy.scope():\n        model_path = \"../input/huggingface-roberta-variants/roberta-base/roberta-base\"\n        # pretrained_model = TFBertModel.from_pretrained(model_path)\n        pretrained_model = TFRobertaModel.from_pretrained(model_path)\n        pretrained_model.trainable = False\n        \n        input_ids = layers.Input(shape=(350,), dtype=tf.int32, name='input_ids')\n        # input_type = layers.Input(shape=(350,), dtype=tf.int32, name='token_type_ids')\n        # input_mask = layers.Input(shape=(350,), dtype=tf.int32, name='attention_mask')\n        inputs = [input_ids]\n        pretrained = pretrained_model.roberta(inputs)\n        x = pretrained.last_hidden_state\n        x = layers.GlobalAveragePooling1D()(x)\n        x = layers.Dense(512, activation=\"relu\")(x)\n        x = layers.Dropout(dropout_1)(x)\n        x = layers.Dense(512, activation=\"relu\")(x)\n        x = layers.Dropout(dropout_2)(x)\n        outputs = layers.Dense(1)(x)\n        model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"nlp\")\n\n        model.compile(\n            optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n        )\n    return model\n'''\ntuner = kt.BayesianOptimization(\n    create_model,\n    objective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"),\n    max_trials=25,\n    overwrite=True,\n    directory=\"tuner\",\n    project_name=\"commonlitreadabilityprize\",\n)\ntuner.search_space_summary()\ntuner.search(\n    encoded_input,\n    final_train_df[\"target\"].to_numpy(),\n    epochs=8, \n    validation_split=0.2\n)\nbest_hp = tuner.get_best_hyperparameters()[0]\nmodel = tuner.hypermodel.build(best_hp)\ntuner.results_summary()\n'''\n\nmodel = create_model()\nmodel.summary()\n","metadata":{"papermill":{"duration":3.645959,"end_time":"2021-07-01T02:44:17.898347","exception":false,"start_time":"2021-07-01T02:44:14.252388","status":"completed"},"tags":[],"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:48:18.830667Z","iopub.execute_input":"2021-07-23T13:48:18.831731Z","iopub.status.idle":"2021-07-23T13:48:38.571453Z","shell.execute_reply.started":"2021-07-23T13:48:18.831666Z","shell.execute_reply":"2021-07-23T13:48:38.570351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ncheckpoint_filepath = 'best_checkpoint'\noptions = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True,\n    options=options\n)\n\nmodel.fit(\n    encoded_input,\n    final_train_df[\"target\"].to_numpy(),\n    batch_size=64,\n    validation_split=0.2,\n    epochs=50,\n    callbacks=[model_checkpoint_callback]\n)\n\nwith strategy.scope():\n    model.layers[1].trainable = True\n    \n    model.compile(\n        optimizer=tfa.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-10),\n        loss=tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n    )\n    \nmodel.fit(\n    encoded_input,\n    final_train_df[\"target\"].to_numpy(),\n    batch_size=64,\n    validation_split=0.2,\n    epochs=50,\n    callbacks=[model_checkpoint_callback]\n)\n'''\n'''\nsave_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nmodel.save(\n    'saved-model', \n    options=save_locally\n)\n'''","metadata":{"papermill":{"duration":3.645959,"end_time":"2021-07-01T02:44:17.898347","exception":false,"start_time":"2021-07-01T02:44:14.252388","status":"completed"},"tags":[],"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:29:05.492402Z","iopub.status.idle":"2021-07-23T13:29:05.492906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sửa lại đoạn này sau\nencodings_test = tokenizer(\n    test_df[\"excerpt\"].to_list(), \n    truncation=True, \n    padding='max_length',\n    max_length=350,\n)\n\nencoded_test_input = [\n    np.array(encodings_test[\"input_ids\"]), \n    # np.array(encodings_test[\"token_type_ids\"]),\n    # np.array(encodings_test[\"attention_mask\"])\n]\n# model.load_weights(checkpoint_filepath, options=options)\nmodel.load_weights(\"../input/commonlitpretrained/best_checkpoint\")\n'''\nload_locally = tf.saved_model.LoadOptions(\n    experimental_io_device='/job:localhost'\n)\nmodel = tf.keras.models.load_model(\n    'saved-model',\n    options=load_locally,\n)\n'''\npredict_data = model.predict(encoded_test_input)\nprint(predict_data)\ntest_df = test_df.assign(target=predict_data)\nselected_column = [\"id\", \"target\"]\nfinal_result = test_df[selected_column]\nfinal_result.to_csv(\"submission.csv\", index=False)","metadata":{"papermill":{"duration":1233.074632,"end_time":"2021-07-01T03:04:50.982163","exception":false,"start_time":"2021-07-01T02:44:17.907531","status":"completed"},"tags":[],"editable":false,"execution":{"iopub.status.busy":"2021-07-23T13:29:05.493973Z","iopub.status.idle":"2021-07-23T13:29:05.494389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}