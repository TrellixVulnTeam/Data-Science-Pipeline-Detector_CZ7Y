{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Solution Overview:**\n\nTrain Roberta-Base and RobertaLarge models on the contest data along with supplmemental sources similar to that data.  Fine tune the models using cross-validation folds. Inference weights all 10 models (two trained models * five fine-tuned models [five folds] per model) equally.\n\n**Notebook Sequence:**\n* [Train Roberta Base Model](https://www.kaggle.com/charliezimmerman/clrp-train-robertabase-maskedlm-model)\n* [Train Roberta Large Model](https://www.kaggle.com/charliezimmerman/clrp-train-robertalarge-masked-lm-model/)\n* [Fine Tune Trained Roberta Base Model](https://www.kaggle.com/charliezimmerman/clrp-finetune-trained-robertabase)\n* [Fine Tune Trained Roberta Large Model](https://www.kaggle.com/charliezimmerman/clrp-finetune-trained-robertalarge)\n* [Inference Notebook  -- **This Notebook**](https://www.kaggle.com/charliezimmerman/clrp-inference-robertabase-robertalarge-ensemble)","metadata":{}},{"cell_type":"code","source":"import transformers\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import SequentialSampler\nfrom transformers import AutoTokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class configuration:\n    finetuned_robertabase_path=\"../input/robertabasemodelweights/clrp-robertabase-modelweights\"\n    finetuned_robertalarge_path=\"../input/robertalargemodelweights\"\n    robertabase_tokenizer=\"../input/roberta-base\"\n    robertalarge_tokenizer=\"../input/robertalarge\"\n    batch_size = 16\n    device = 'cuda'\n    max_len = 256\n    contest_data=\"../input/commonlitreadabilityprize/test.csv\"\n    model_count=5","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:51.748629Z","iopub.execute_input":"2021-08-19T04:24:51.748972Z","iopub.status.idle":"2021-08-19T04:24:51.755837Z","shell.execute_reply.started":"2021-08-19T04:24:51.748938Z","shell.execute_reply":"2021-08-19T04:24:51.754402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler() \ndevice = torch.device(configuration.device if torch.cuda.is_available() else 'cpu')\nprint(f\"using device {torch.cuda.get_device_name(0)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:51.757822Z","iopub.execute_input":"2021-08-19T04:24:51.75826Z","iopub.status.idle":"2021-08-19T04:24:51.812734Z","shell.execute_reply.started":"2021-08-19T04:24:51.758221Z","shell.execute_reply":"2021-08-19T04:24:51.811973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(configuration.contest_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:51.814464Z","iopub.execute_input":"2021-08-19T04:24:51.814862Z","iopub.status.idle":"2021-08-19T04:24:51.832825Z","shell.execute_reply.started":"2021-08-19T04:24:51.814825Z","shell.execute_reply":"2021-08-19T04:24:51.832072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_examples_to_features(text, tokenizer, max_len):\n\n    tok = tokenizer.encode_plus(\n        text, \n        max_length=configuration.max_len, \n        truncation=True,\n        padding='max_length',\n    )\n    return tok\n\n\nclass CLRPDataset(Dataset):\n    def __init__(self, data, tokenizer, max_len, is_test=False):\n        self.data = data\n        self.excerpts = self.data.excerpt.tolist()\n        if not is_test:\n            self.targets = self.data.target.tolist()\n            \n        self.tokenizer = tokenizer\n        self.is_test = is_test\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, item):\n        if not self.is_test:\n            excerpt = self.excerpts[item]\n            label = self.targets[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer, self.max_len\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n                'label':torch.tensor(label, dtype=torch.float),\n            }\n        else:\n            excerpt = self.excerpts[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer, self.max_len\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n            }","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:51.834005Z","iopub.execute_input":"2021-08-19T04:24:51.83434Z","iopub.status.idle":"2021-08-19T04:24:51.847267Z","shell.execute_reply.started":"2021-08-19T04:24:51.834315Z","shell.execute_reply":"2021-08-19T04:24:51.846393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n        \n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n        return context_vector\n\nclass CLRPModel(nn.Module):\n\n              \n    def forward(self, input_ids, attention_mask):\n        transformer_out = self.transformer(input_ids, attention_mask)\n        x = self.head(transformer_out.last_hidden_state)\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:51.848951Z","iopub.execute_input":"2021-08-19T04:24:51.849368Z","iopub.status.idle":"2021-08-19T04:24:51.857355Z","shell.execute_reply.started":"2021-08-19T04:24:51.849333Z","shell.execute_reply":"2021-08-19T04:24:51.856407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"robertabase_tokenizer=AutoTokenizer.from_pretrained(configuration.robertabase_tokenizer)\nrobertalarge_tokenizer=AutoTokenizer.from_pretrained(configuration.robertalarge_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:51.858778Z","iopub.execute_input":"2021-08-19T04:24:51.859136Z","iopub.status.idle":"2021-08-19T04:24:52.276489Z","shell.execute_reply.started":"2021-08-19T04:24:51.859099Z","shell.execute_reply":"2021-08-19T04:24:52.27563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_base_predictions = []\n\nfor model_num in range(configuration.model_count):\n    print(f'Model #{model_num+1}/{configuration.model_count}')\n    test_ds = CLRPDataset(data=test, tokenizer=robertabase_tokenizer, max_len=configuration.max_len, is_test=True)\n    test_sampler = SequentialSampler(test_ds)\n    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=configuration.batch_size)\n    model = torch.load(f'{configuration.finetuned_robertabase_path}/model_{model_num}.bin').to(configuration.device)\n\n    all_preds = []\n    model.eval()\n\n    for step,batch in enumerate(test_dataloader):\n        sent_id, mask = batch['input_ids'].to(configuration.device), batch['attention_mask'].to(configuration.device)\n        with torch.no_grad():\n            preds = model(sent_id, mask)\n            all_preds += preds.flatten().cpu().tolist()\n    \n    roberta_base_predictions.append(all_preds)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:24:52.278631Z","iopub.execute_input":"2021-08-19T04:24:52.278979Z","iopub.status.idle":"2021-08-19T04:25:22.569824Z","shell.execute_reply.started":"2021-08-19T04:24:52.278944Z","shell.execute_reply":"2021-08-19T04:25:22.568981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nroberta_large_predictions = []\n\nfor model_num in range(configuration.model_count):\n    print(f'Model #{model_num+1}/{configuration.model_count}')\n    test_ds = CLRPDataset(data=test, tokenizer=robertalarge_tokenizer, max_len=configuration.max_len, is_test=True)\n    test_sampler = SequentialSampler(test_ds)\n    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=configuration.batch_size)\n    model = torch.load(f'{configuration.finetuned_robertalarge_path}/model_{model_num}.bin').to(configuration.device)\n\n    all_preds = []\n    model.eval()\n\n    for step,batch in enumerate(test_dataloader):\n        sent_id, mask = batch['input_ids'].to(configuration.device), batch['attention_mask'].to(configuration.device)\n        with torch.no_grad():\n            preds = model(sent_id, mask)\n            all_preds += preds.flatten().cpu().tolist()\n    \n    roberta_large_predictions.append(all_preds)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:25:22.571236Z","iopub.execute_input":"2021-08-19T04:25:22.571593Z","iopub.status.idle":"2021-08-19T04:26:19.434884Z","shell.execute_reply.started":"2021-08-19T04:25:22.571527Z","shell.execute_reply":"2021-08-19T04:26:19.433983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_base_predictions = np.array(roberta_base_predictions)\nroberta_large_predictions = np.array(roberta_large_predictions)\n\n   #each model weighted equally\nallpreds= (roberta_large_predictions[0] * .10) + (roberta_large_predictions[1] * .10) + (roberta_large_predictions[2] * .10) + \\\n    (roberta_large_predictions[3] * .10) + (roberta_large_predictions[4] * .10) + (roberta_base_predictions[0] * .10) + \\\n    + (roberta_base_predictions[1] * .10) + (roberta_base_predictions[2] * .10) + (roberta_base_predictions[3] * .10) + \\\n   (roberta_base_predictions[4] * .10)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:26:19.436396Z","iopub.execute_input":"2021-08-19T04:26:19.436921Z","iopub.status.idle":"2021-08-19T04:26:19.443864Z","shell.execute_reply.started":"2021-08-19T04:26:19.436883Z","shell.execute_reply":"2021-08-19T04:26:19.443074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df = pd.DataFrame(\n    {\n        'id': test.id,\n        'target': allpreds\n    })\n\nprint(result_df)\nresult_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T04:26:40.146215Z","iopub.execute_input":"2021-08-19T04:26:40.146554Z","iopub.status.idle":"2021-08-19T04:26:40.155357Z","shell.execute_reply.started":"2021-08-19T04:26:40.146523Z","shell.execute_reply":"2021-08-19T04:26:40.15439Z"},"trusted":true},"execution_count":null,"outputs":[]}]}