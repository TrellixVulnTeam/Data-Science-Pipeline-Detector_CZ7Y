{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# loading libraries\n\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loding train and test data\n\ntrain_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping some columns\n\ntrain_df=train_df[['id','excerpt','target','standard_error']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install ../input/sentence-transformers/sentence-transformers-master","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading model using sentence transformers\n\nimport sentence_transformers\nfrom sentence_transformers import SentenceTransformer, models\n\n# setting model path for fine-tuned roberta weights\n\nmodel_path = '../input/finetuned-model1/checkpoint-568'\nword_embedding_model = models.Transformer(model_path, max_seq_length=275)\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\nmodel = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding train and test strings\n\nX_train = model.encode(train_df.excerpt, device='cuda')\nX_test = model.encode(test_df.excerpt, device='cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install ../input/frozendict/frozendict-2.0.2-py3-none-any.whl\n!pip3 install ../input/neuraltangent/neural_tangents-0.3.6-py2.py3-none-any.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom datetime import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import BayesianRidge\n\nfrom jax import random\nfrom neural_tangents import stax\nimport neural_tangents as nt\n\ntrain_df['Character Count'] = train_df['excerpt'].apply(lambda x: len(str(x)))\n\npreds = []\ntrain_scores = []\n\ndf_oof=train_df.copy()\ndf_oof['oof'] = 0\n\nskf = StratifiedKFold(10, shuffle=True, random_state=42)\n\nsplits = list(skf.split(X=X_train, y=train_df['Character Count']))\n\n# predicting out of fold scores for each fold and doing predictions for each training set\n\nfor i, (train_idx, val_idx) in enumerate(splits):\n    print(f'\\n------------- Training Fold {i + 1} / {10}')\n    print(\"Current Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n\n    #clf = BayesianRidge(n_iter=300, verbose=True)\n    #clf.fit(X_train[train_idx],train_df.target[train_idx])\n    #train_score=mean_squared_error(train_df.target[train_idx], clf.predict(X_train[train_idx]), squared=False)\n    #train_scores.append(train_score)\n    #print(f\"Fold {i} train RMSE: {train_score}\")\n    \n    ResBlock = stax.serial(\n                stax.FanOut(2),\n                stax.parallel(\n                    stax.serial(\n                        stax.Erf(),\n                        stax.Dense(1, W_std=1.25, b_std=0.0),\n                        stax.Erf(),\n                        stax.Dense(1, W_std=1.25, b_std=0.0),\n                        stax.Erf(),\n                        stax.Dense(1, W_std=1.25, b_std=0.0),\n                    ),\n                    stax.Identity(),\n                ),\n                stax.FanInSum()\n            )\n\n    init_fn, apply_fn, kernel_fn = stax.serial(\n        stax.Dense(1, W_std=1.0, b_std=0),\n        ResBlock, ResBlock, stax.Erf(),\n        stax.Dense(1, W_std=2.5, b_std=0.1)\n    )\n    \n    key = random.PRNGKey(10)\n    _, params = init_fn(key, input_shape=X_train[train_idx].shape)\n    predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn,\n                                                          X_train[train_idx],\n                                                          train_df.target[train_idx].values[:,np.newaxis],\n                                                          diag_reg=1e-1,\n                                                          lr=1)\n    \n    \n    train_score=mean_squared_error(train_df.target[train_idx], predict_fn(x_test=X_train[train_idx], get='ntk', t=None), squared=False)\n    train_scores.append(train_score)\n    print(f\"Fold {i} train RMSE: {train_score}\")\n    \n    preds.append(predict_fn(x_test=X_test, get='ntk', t=None))\n    #x=clf.predict(predict_fn(x_test=X_train[val_idx], get='ntk', t=None))\n    #df_oof['oof'].iloc[val_idx]+= x\n\nprint(f'Training score: {np.mean(train_scores)}, Training STD: {np.std(train_scores)}')\n#print(f'OOF score across folds: {mean_squared_error(df_oof.target, df_oof.oof, squared=False)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting mean prediction across 5 folds\ny_pred = np.mean(preds,0)\ny_pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating submission csv\n\nsub = test_df[[\"id\"]].copy()\nsub[\"target\"] = y_pred\nsub.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking submission file\n\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}