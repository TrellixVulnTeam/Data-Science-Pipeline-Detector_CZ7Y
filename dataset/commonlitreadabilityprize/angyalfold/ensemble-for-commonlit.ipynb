{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id='introduction'></a>\n# Introduction\n\nThis offline notebook uses [my other notebook](https://www.kaggle.com/angyalfold/roberta-large-k-fold-models/)'s model and tokenizer to make predictions. The idea here is to use \nRoberta large + SVM regressor, Roberta large + ridge regressor, Roberta large + custom NN regressor and combine the results (ensemble). Each prediction would use k=5 pre-trained model for making predictions. The pre-trained models were created in [my second notebook](https://www.kaggle.com/angyalfold/roberta-large-k-fold-models) \n\nThis notebook is part of a series:\n1. Pretrain roberta large on the CommonLit dataset [here](https://www.kaggle.com/angyalfold/pretrain-roberta-large-on-clrp-data/).\n2. Produce k models which can later be used for determining the readability of texts [here](https://www.kaggle.com/angyalfold/roberta-large-k-fold-models).\n3. Make predictions with a custom NN regressor [here](https://www.kaggle.com/angyalfold/roberta-large-with-custom-regressor-pytorch/).\n4. Ensemble (Roberta large + SVR, Roberta large + Ridge, Roberta large + custom NN head) (this notebook)\n\nI use Maunish' [notebook](https://www.kaggle.com/maunish/clrp-roberta-svm/) as reference.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"toc\"></a>\n# Table of contents\n* [Introduction](#introduction)\n* [Classes & configs](#classes)\n    * [Configs](#classes_config)\n    * [Data set](#classes_data_set)\n    * [Model](#classes_model)\n* [Read data](#read_data)\n    * [Read train data](#read_data_train_data)\n    * [Read test data](#read_data_test_data)\n* [Setup](#setup)\n    * [RMSE score](#setup_rmse_score)\n    * [Convert pandas' dataframes to dataloader](#setup_dataframe_to_dataloader)\n    * [Get embeddings from model](#setup_embeddings_from_model)\n    * [Get predictions with a given regressor](#setup_prediction_with_regressor)\n    * [Get predictions with custom NN regressor](#setup_prediction_with_nn)\n    * [SVR](#setup_svr)\n    * [Ridge regressor](#setup_ridge)\n* [Make predictions](#make_predictions)\n    * [Run models with regressor](#make_predictions_run_models_with_regressor)\n    * [Run models with NN](#make_predictions_run_models_with_nn)\n    * [Get predictions](#make_predictions_get_predictions)\n* [Save results](#save_results)","metadata":{}},{"cell_type":"markdown","source":"<a id='classes'></a>\n# Classes & configs\n[[back to top]](#toc)","metadata":{}},{"cell_type":"markdown","source":"<a id='classes_config'></a>\n## Config\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import torch\n\nconfig = {\n    'batch_size': 8,\n    'best_pretrained_roberta_folder': '../input/pretrain-roberta-large-on-clrp-data/clrp_roberta_large/best_model/',\n    'num_of_folds': 5,\n    'num_of_models': 5,\n    'seed': 2021,\n    'sentence_max_length': 256\n}\n\nfor (k, v) in config.items():\n    print(f\"The value for {k}: {v}\")\n    \ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nprint(f\"Device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.260967Z","iopub.execute_input":"2021-08-02T17:56:10.261302Z","iopub.status.idle":"2021-08-02T17:56:10.268209Z","shell.execute_reply.started":"2021-08-02T17:56:10.261273Z","shell.execute_reply":"2021-08-02T17:56:10.267297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=classes_data_set></a>\n## Data set\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import torch\n\nclass ReadabilityDataset(torch.utils.data.Dataset):\n    \"\"\"Custom dataset for the Readability task\"\"\"\n    def __init__(self, encodings):\n        self.encodings = encodings\n    \n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item\n        \n    def __len__(self):\n        return len(self.encodings['input_ids'])\n    \n\nprint(ReadabilityDataset.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.276423Z","iopub.execute_input":"2021-08-02T17:56:10.276672Z","iopub.status.idle":"2021-08-02T17:56:10.284585Z","shell.execute_reply.started":"2021-08-02T17:56:10.276647Z","shell.execute_reply":"2021-08-02T17:56:10.283559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=classes_model></a>\n## Model\n[[back to top]](#toc)","metadata":{}},{"cell_type":"markdown","source":"Note, that the concept of attention is awesomely explained in [Lena Voita](https://lena-voita.github.io/)'s excellent notebook [here](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html).","metadata":{}},{"cell_type":"code","source":"from torch import nn\n\nclass AttentionHead(nn.Module):\n    \"\"\"Class implementing the attention head of the model.\"\"\"\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n       \n    \n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        \n        return torch.sum(context_vector, dim=1)\n\n\nprint(AttentionHead.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.302743Z","iopub.execute_input":"2021-08-02T17:56:10.303002Z","iopub.status.idle":"2021-08-02T17:56:10.3132Z","shell.execute_reply.started":"2021-08-02T17:56:10.302979Z","shell.execute_reply":"2021-08-02T17:56:10.312294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On top of *ReadabilityRobertaModel* a regressor, such as SVM or Ridge could be placed. That way a regressor could assign a continous value to the output of *ReadabilityRobertaModel*.","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom transformers import RobertaModel\nfrom transformers import RobertaConfig\n\nclass ReadabilityRobertaModel(nn.Module):\n    \"\"\"Custom model for the Readability task containing a Roberta layer and a custom NN head.\"\"\"\n        \n    def __init__(self):\n        super(ReadabilityRobertaModel, self).__init__()\n        \n        self.model_config = RobertaConfig.from_pretrained(config['best_pretrained_roberta_folder'])\n        self.model_config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"layer_norm_eps\": 1e-7\n        })\n        \n        self.roberta = RobertaModel.from_pretrained(config['best_pretrained_roberta_folder'],\n                                                    config=self.model_config)\n        self.attention_head = AttentionHead(self.model_config.hidden_size, \n                                            self.model_config.hidden_size)\n        self.dropout = nn.Dropout(0.1)\n        self.regressor = nn.Linear(self.model_config.hidden_size, 1)\n        \n        \n    def forward(self, tokens, attention_mask):\n        x = self.roberta(input_ids=tokens, attention_mask=attention_mask)[0]\n        x = self.attention_head(x)\n\n        return x\n    \n    \n    def freeze_roberta(self):\n        \"\"\"\n        Freezes the parameters of the Roberta model so when ReadabilityRobertaModel is \n        trained only the wieghts of the custom regressor are modified.\n        \"\"\"\n        for param in self.roberta.named_parameters():\n            param[1].requires_grad=False\n    \n    def unfreeze_roberta(self):\n        \"\"\"\n        Unfreezes the parameters of the Roberta model so when ReadabilityRobertaModel is \n        trained both the wieghts of the custom regressor and of the underlying Roberta\n        model are modified.\n        \"\"\"\n        for param in self.roberta.named_parameters():\n            param[1].requires_grad=True\n\n    \nprint(ReadabilityRobertaModel.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.33331Z","iopub.execute_input":"2021-08-02T17:56:10.333586Z","iopub.status.idle":"2021-08-02T17:56:10.34479Z","shell.execute_reply.started":"2021-08-02T17:56:10.33356Z","shell.execute_reply":"2021-08-02T17:56:10.343671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with custom NN regressor","metadata":{}},{"cell_type":"markdown","source":"Unlike *ReadabilityRobertaModel*, *ReadabilityRobertaModelWithCustomNNHead* returns with the actual predicted value without the need for a further regressor (i.e.: the last layer of this NN functions as a regressor).","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom transformers import RobertaModel\nfrom transformers import RobertaConfig\n\nclass ReadabilityRobertaModelWithCustomNNHead(nn.Module):\n    \"\"\"Custom model for the Readability task containing a Roberta layer and a custom NN head.\"\"\"\n        \n    def __init__(self):\n        super(ReadabilityRobertaModelWithCustomNNHead, self).__init__()\n        \n        self.model_config = RobertaConfig.from_pretrained(config['best_pretrained_roberta_folder'])\n        self.model_config.update({\n            \"output_hidden_states\": True,\n            \"hidden_dropout_prob\": 0.0,\n            \"layer_norm_eps\": 1e-7\n        })\n        \n        self.roberta = RobertaModel.from_pretrained(config['best_pretrained_roberta_folder'],\n                                                    config=self.model_config)\n        self.attention_head = AttentionHead(self.model_config.hidden_size, \n                                            self.model_config.hidden_size)\n        self.dropout = nn.Dropout(0.1)\n        self.regressor = nn.Linear(self.model_config.hidden_size, 1)\n        \n        \n    def forward(self, tokens, attention_mask):\n        x = self.roberta(input_ids=tokens, attention_mask=attention_mask)[0]\n        x = self.attention_head(x)\n        x = self.dropout(x)\n        x = self.regressor(x)\n        return x\n    \n    \n    def freeze_roberta(self):\n        \"\"\"\n        Freezes the parameters of the Roberta model so when ReadabilityRobertaModel is \n        trained only the wieghts of the custom regressor are modified.\n        \"\"\"\n        for param in self.roberta.named_parameters():\n            param[1].requires_grad=False\n    \n    def unfreeze_roberta(self):\n        \"\"\"\n        Unfreezes the parameters of the Roberta model so when ReadabilityRobertaModel is \n        trained both the wieghts of the custom regressor and of the underlying Roberta\n        model are modified.\n        \"\"\"\n        for param in self.roberta.named_parameters():\n            param[1].requires_grad=True\n\n    \nprint(ReadabilityRobertaModelWithCustomNNHead.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.36102Z","iopub.execute_input":"2021-08-02T17:56:10.361301Z","iopub.status.idle":"2021-08-02T17:56:10.372355Z","shell.execute_reply.started":"2021-08-02T17:56:10.361275Z","shell.execute_reply":"2021-08-02T17:56:10.371353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='read_data'></a>\n# Read data\n[[back to top]](#toc)","metadata":{}},{"cell_type":"markdown","source":"<a id='read_data_train_data'></a>\n## Read train data\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_csv_path = '/kaggle/input/commonlitreadabilityprize/train.csv'\ntrain_data = pd.read_csv(train_csv_path)\n\nprint('The total # of samples is {}.'.format(len(train_data)))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.385304Z","iopub.execute_input":"2021-08-02T17:56:10.385542Z","iopub.status.idle":"2021-08-02T17:56:10.466211Z","shell.execute_reply.started":"2021-08-02T17:56:10.385519Z","shell.execute_reply":"2021-08-02T17:56:10.462507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add values to the *bin* column as described [here](https://www.kaggle.com/angyalfold/roberta-large-k-fold-models/).","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# create & fill bins column (needed for kfold)\nnum_of_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bin'] = pd.cut(train_data['target'], bins=num_of_bins, labels=False)\nbins = train_data['bin'].to_numpy()\n\ntarget = train_data['target'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.467895Z","iopub.execute_input":"2021-08-02T17:56:10.46879Z","iopub.status.idle":"2021-08-02T17:56:10.486147Z","shell.execute_reply.started":"2021-08-02T17:56:10.468748Z","shell.execute_reply":"2021-08-02T17:56:10.484747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='read_data_test_data'></a>\n## Read test data\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntest_csv_path = '/kaggle/input/commonlitreadabilityprize/test.csv'\ntest_data = pd.read_csv(test_csv_path)\n\nprint('The total # of samples is {}.'.format(test_data.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.488797Z","iopub.execute_input":"2021-08-02T17:56:10.489455Z","iopub.status.idle":"2021-08-02T17:56:10.50485Z","shell.execute_reply.started":"2021-08-02T17:56:10.489415Z","shell.execute_reply":"2021-08-02T17:56:10.503999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup'></a>\n# Setup\n[[back to top]](#toc)\n\nIn the following I collected some helper methods and variables which will be needed for making the actual predictions.","metadata":{}},{"cell_type":"markdown","source":"<a id='setup_rmse_score'></a>\n## RMSE score\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.metrics import mean_squared_error\n\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.506572Z","iopub.execute_input":"2021-08-02T17:56:10.508333Z","iopub.status.idle":"2021-08-02T17:56:10.513118Z","shell.execute_reply.started":"2021-08-02T17:56:10.508298Z","shell.execute_reply":"2021-08-02T17:56:10.51183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup_dataframe_to_dataloader'></a>\n## Convert pandas' dataframes to dataloader\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndef get_dataloader_from_dataframes(df, tokenizer):\n    \"\"\"Converts a complete dataframe (with all columns included) into a dataloader.\"\"\"\n    texts = df['excerpt'].values.tolist()\n    data_encodings = tokenizer(texts, max_length=config['sentence_max_length'],\n                              truncation=True, padding=True)\n    dataset = ReadabilityDataset(data_encodings)\n    dataloader = DataLoader(dataset, batch_size=config['batch_size'])\n    \n    return dataloader\n\nprint(get_dataloader_from_dataframes.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.514786Z","iopub.execute_input":"2021-08-02T17:56:10.515421Z","iopub.status.idle":"2021-08-02T17:56:10.529093Z","shell.execute_reply.started":"2021-08-02T17:56:10.515384Z","shell.execute_reply":"2021-08-02T17:56:10.528252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup_embeddings_from_model'></a>\n## Get embeddings from model\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\n\nfrom tqdm.auto import tqdm\n\ntqdm.pandas()\n\ndef get_embeddings_from_model(model_path, data, tokenizer):\n    \"\"\"Get embeddings (which can then be fed to regressors) using the provided model.\"\"\"\n    \n    # Setup model\n    model = ReadabilityRobertaModel()\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n    \n    # create dataloader from data\n    dataloader = get_dataloader_from_dataframes(data, tokenizer)\n    \n    # compute embeddings\n    embeddings = list()\n    with torch.no_grad():\n        print('Getting embeddings:')\n        for i, batch in enumerate(tqdm(dataloader)):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n        \n            output = model(tokens=input_ids, attention_mask=attention_mask)\n            output = output.cpu().detach().numpy()\n            embeddings.extend(output)\n            \n    return np.array(embeddings)\n        \n    \nprint(get_embeddings_from_model.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.531063Z","iopub.execute_input":"2021-08-02T17:56:10.531666Z","iopub.status.idle":"2021-08-02T17:56:10.575262Z","shell.execute_reply.started":"2021-08-02T17:56:10.531604Z","shell.execute_reply":"2021-08-02T17:56:10.573956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup_prediction_with_regressor'></a>\n## Get predictions with a given regressor\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\n\n\ndef get_predictions_with_regressor(X, y, X_test, bins, regressor):\n    \"\"\"This method uses SVM on top of ROberta to predict the readibility score of a text.\"\"\"\n    scores = list()\n    preds = np.zeros(len(X_test))\n    kfold = StratifiedKFold(n_splits=config['num_of_folds'], shuffle=True,\n                            random_state=config['seed'])\n    \n    print('Getting predictions:')\n    for k, (train_idx, test_idx) in enumerate(kfold.split(X, bins)):\n                \n        X_train, y_train = X[train_idx], y[train_idx]\n        X_valid, y_valid = X[test_idx], y[test_idx]\n        \n        regressor.fit(X_train, y_train)\n        prediction = regressor.predict(X_valid)\n        score = rmse_score(y_valid, prediction)\n        print(f'Fold {k} rmse_score: {score}')\n        scores.append(score)\n        preds += regressor.predict(X_test)\n        \n        \n    print(f'Mean rmse: {np.mean(scores)}')\n    return np.array(preds) / config['num_of_folds']\n\n\nprint(get_predictions_with_regressor.__doc__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.577697Z","iopub.execute_input":"2021-08-02T17:56:10.578341Z","iopub.status.idle":"2021-08-02T17:56:10.592877Z","shell.execute_reply.started":"2021-08-02T17:56:10.578301Z","shell.execute_reply":"2021-08-02T17:56:10.591736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup_prediction_with_nn'></a>\n## Get predictions with custom NN regressor\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom tqdm.auto import tqdm\n\ntqdm.pandas()\n\n\ndef get_predictions_with_custom_NN_head(model_path, data, tokenizer):\n    \n    # setup model\n    model = ReadabilityRobertaModelWithCustomNNHead()\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n    \n    # convert data into dataloader\n    dataloader = get_dataloader_from_dataframes(data, tokenizer)\n    \n    # iteration for predictions\n    predictions = list()\n    for i, batch in enumerate(tqdm(dataloader)):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        output = torch.flatten(model(tokens=input_ids, attention_mask=attention_mask))\n        output = output.cpu().detach().numpy().tolist()\n        \n        predictions.extend(output)\n        \n    torch.cuda.empty_cache()\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:38.652994Z","iopub.execute_input":"2021-08-02T17:56:38.65468Z","iopub.status.idle":"2021-08-02T17:56:38.663694Z","shell.execute_reply.started":"2021-08-02T17:56:38.654635Z","shell.execute_reply":"2021-08-02T17:56:38.662718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup_svr'></a>\n## SVR regressor\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\n\nsvr_regressor = SVR(C=10, kernel='rbf', gamma='auto')\n\nprint('SVR regressor has been initialized.')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.595657Z","iopub.execute_input":"2021-08-02T17:56:10.596507Z","iopub.status.idle":"2021-08-02T17:56:10.606456Z","shell.execute_reply.started":"2021-08-02T17:56:10.596397Z","shell.execute_reply":"2021-08-02T17:56:10.603736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='setup_ridge'></a>\n## Ridge regressor\n[[back to top]](#toc)\n\nRidge regressor: alpha = 50 is taken from [this notebook](https://www.kaggle.com/solorzano/clrp-roberta-ridge).","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nridge_regressor = Ridge(alpha=50.0)\n\nprint('Ridge regressor has been initialized')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:10.610283Z","iopub.execute_input":"2021-08-02T17:56:10.611504Z","iopub.status.idle":"2021-08-02T17:56:10.625405Z","shell.execute_reply.started":"2021-08-02T17:56:10.611415Z","shell.execute_reply":"2021-08-02T17:56:10.624469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='make_predictions'></a>\n# Make predictions\n[[back to top]](#toc)","metadata":{}},{"cell_type":"markdown","source":"<a id='make_predictions_run_models_with_regressor'></a>\n## Run models with regressor\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.auto import tqdm\n\nfrom transformers import RobertaTokenizer\n\ntqdm.pandas()\n\n\ndef run_all_models_with_regressor(regressor):\n    predictions = np.zeros(test_data.shape[0])\n\n    for i in tqdm(range(config['num_of_models'])):\n        print(f'Model # {i}:')\n        model_path = f'../input/roberta-large-k-fold-models/model{i}/model{i}.bin'\n        tokenizer_path = f'../input/roberta-large-k-fold-models/model{i}/'\n        tokenizer = RobertaTokenizer.from_pretrained(tokenizer_path)\n\n        train_embeddings = get_embeddings_from_model(model_path, train_data, tokenizer)\n        test_embeddings = get_embeddings_from_model(model_path, test_data, tokenizer)\n\n        preds = get_predictions_with_regressor(train_embeddings, target, test_embeddings,\n                                               bins, regressor)\n\n        predictions = predictions + preds\n        print(f'Predictions for model {i}:')\n        print(preds)\n\n\n    predictions = predictions / config['num_of_models']\n    print('Final predictions:')\n    print(predictions)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:38.66507Z","iopub.execute_input":"2021-08-02T17:56:38.665477Z","iopub.status.idle":"2021-08-02T17:56:38.674996Z","shell.execute_reply.started":"2021-08-02T17:56:38.665444Z","shell.execute_reply":"2021-08-02T17:56:38.674096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='make_predictions_run_models_with_nn'></a>\n## Run models with NN regressor\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.auto import tqdm\n\nfrom transformers import RobertaTokenizer\n\ntqdm.pandas()\n\n\ndef run_all_models_with_custom_NN_head():\n    predictions = np.zeros(test_data.shape[0])\n\n    for i in tqdm(range(config['num_of_models'])):\n        print(f'Model # {i}:')\n        model_path = f'../input/roberta-large-k-fold-models/model{i}/model{i}.bin'\n        tokenizer_path = f'../input/roberta-large-k-fold-models/model{i}/'\n        tokenizer = RobertaTokenizer.from_pretrained(tokenizer_path)\n\n        train_embeddings = get_embeddings_from_model(model_path, train_data, tokenizer)\n        test_embeddings = get_embeddings_from_model(model_path, test_data, tokenizer)\n\n        preds = get_predictions_with_custom_NN_head(model_path, test_data, tokenizer)\n\n        predictions = predictions + preds\n        print(f'Predictions for model {i}:')\n        print(preds)\n\n\n    predictions = predictions / config['num_of_models']\n    print('Final predictions:')\n    print(predictions)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:38.676569Z","iopub.execute_input":"2021-08-02T17:56:38.677037Z","iopub.status.idle":"2021-08-02T17:56:38.687648Z","shell.execute_reply.started":"2021-08-02T17:56:38.676996Z","shell.execute_reply":"2021-08-02T17:56:38.686664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='NN'></a>\n## Get predictions\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"svr_predictions = run_all_models_with_regressor(svr_regressor) \nridge_predictions =  run_all_models_with_regressor(ridge_regressor)\ncustom_NN_head_predictions = run_all_models_with_custom_NN_head()\n\npredictions = (svr_predictions + ridge_predictions + custom_NN_head_predictions) / 3\n\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T17:56:38.68915Z","iopub.execute_input":"2021-08-02T17:56:38.689706Z","iopub.status.idle":"2021-08-02T18:30:24.868948Z","shell.execute_reply.started":"2021-08-02T17:56:38.689666Z","shell.execute_reply":"2021-08-02T18:30:24.866595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='save_results'></a>\n# Save results\n[[back to top]](#toc)","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['id'] = test_data['id']\nsubmission['target'] = predictions\nsubmission.to_csv('submission.csv', index=False)\n\nprint('Saved predictions.')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T18:30:24.875064Z","iopub.execute_input":"2021-08-02T18:30:24.875328Z","iopub.status.idle":"2021-08-02T18:30:24.910002Z","shell.execute_reply.started":"2021-08-02T18:30:24.8753Z","shell.execute_reply":"2021-08-02T18:30:24.909119Z"},"trusted":true},"execution_count":null,"outputs":[]}]}