{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# importing libraries","metadata":{"id":"xeG4cEvor50q"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n# for ignoring warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"id":"OlvRq5mFhiL0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{"id":"-SzxSKtar51O"}},{"cell_type":"code","source":"df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ndf.head()","metadata":{"id":"CpfYeA69hm75","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Preprocessing","metadata":{"id":"cd7nTvpQr51W"}},{"cell_type":"code","source":"import re\nimport string\nimport nltk\n# nltk.download('stopwords')\n# nltk.download('punkt')\n# nltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\n\ndef preprocessing_text(text):\n    text = text.lower()\n    text = re.sub(r'd+','', text)\n    # remove punctuation\n    text = text.translate(str.maketrans('','',string.punctuation))\n    # removing spaces\n    text = text.strip()\n    # remove stopwords\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    filtered_text = [word for word in word_tokens if word not in stop_words]\n    text = ' '.join(str(elem) for elem in filtered_text)\n    # steaming\n    stemmer = PorterStemmer()\n    token_text = word_tokenize(text)\n    for word in token_text:\n        # print(stemmer.stem(word))\n        text = text +' '+stemmer.stem(word)\n    # lemmatization\n    lemmatizer = WordNetLemmatizer()\n    input_text = word_tokenize(text)\n    for word in input_text:\n        text = text + '' + lemmatizer.lemmatize(word)\n    return text","metadata":{"id":"eESb9qWSFhFB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply preprocessing on dataset","metadata":{"id":"9LVDNigHr51Z"}},{"cell_type":"code","source":"df['process_text'] = ''\nfor i in range(0,len(df)):\n    df['process_text'][i] = preprocessing_text(df.excerpt[i])","metadata":{"id":"a-LAlCeHFiBX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"_ryphVlvr51l","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## seperate dependent and independent variables","metadata":{"id":"60czHsB6r51m"}},{"cell_type":"code","source":"X = df.process_text\ny = df.target\n\n# splitting dataset for training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, shuffle=False)","metadata":{"id":"hmK9aRa3Fh7m","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Apply TF-IDF","metadata":{"id":"eoMF6TX9r51p"}},{"cell_type":"code","source":"# Initialize the `tfidf_vectorizer` \ntfidf_vectorizer = TfidfVectorizer() \n\n# Fit and transform the training data \ntfidf_train = tfidf_vectorizer.fit_transform(X_train) \n\n# Transform the test set \ntfidf_test = tfidf_vectorizer.transform(X_test)","metadata":{"id":"LwCXFB7fFh16","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_train.shape, X_train.shape, tfidf_test.shape, X_test.shape","metadata":{"id":"ptZrPWB6Fhyr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{"id":"2YUr1V-0r51s"}},{"cell_type":"markdown","source":"### Linear Regression","metadata":{"id":"6iC_ohO-r51s"}},{"cell_type":"code","source":"reg = LinearRegression().fit(tfidf_train, y_train)\ny_pred = reg.predict(tfidf_test)","metadata":{"id":"xrQOIvvCFydc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking Root mean square","metadata":{"id":"tiwOnTNbr51x"}},{"cell_type":"code","source":"rmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Root mean Square is :',rmse)","metadata":{"id":"g_rgNuknFyZw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{"id":"MLbQuuNAr51y"}},{"cell_type":"code","source":"rf_reg = RandomForestRegressor()\nrf_reg.fit(tfidf_train, y_train)\ny_pred = rf_reg.predict(tfidf_test)\nrmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Root mean Square is :',rmse)","metadata":{"id":"SZHBvOtcV6Xh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree","metadata":{"id":"vOozoBQmr510"}},{"cell_type":"code","source":"dt_reg = DecisionTreeRegressor()\ndt_reg.fit(tfidf_train, y_train)\ny_pred = dt_reg.predict(tfidf_test)\nrmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Root mean Square is :',rmse)","metadata":{"id":"J6ct2IXvV6Xj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{"id":"eboGdyaAr514"}},{"cell_type":"code","source":"xgb_clf = xgb.XGBRegressor()\nxgb_clf.fit(tfidf_train, y_train)\ny_pred = xgb_clf.predict(tfidf_test)\nrmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Root mean Square is :',rmse)","metadata":{"id":"Sg2Yif4DV6Xl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting Score","metadata":{"id":"1X1muNx3r517"}},{"cell_type":"code","source":"test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest['process_text'] = ''\nfor i in range(0,len(test)):\n    test['process_text'][i] = preprocessing_text(test.excerpt[i])","metadata":{"id":"zP8WuLOBr517","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applyinh TF-IDF on test dataset\ntX = test.process_text\ntest_tfidf = tfidf_vectorizer.transform(tX) ","metadata":{"id":"jVA_7NbBr518","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking shape same or not\ntest_tfidf.shape, tfidf_train.shape","metadata":{"id":"JXd7E6flr519","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting","metadata":{"id":"tpsnRpI6r51-"}},{"cell_type":"code","source":"# Prediction on test\ny_pred = reg.predict(test_tfidf)","metadata":{"id":"f9Ksc2q1r52A","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating submission.csv file ","metadata":{"id":"tEzSWWRJr52C"}},{"cell_type":"code","source":"a = pd.DataFrame()\na['id'] = test['id']\na['target'] = y_pred\na.reset_index(inplace=True,drop=True)\na.to_csv('submission.csv',index=False)  #file save as submission.csv","metadata":{"id":"bR3yrlurr52S","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}