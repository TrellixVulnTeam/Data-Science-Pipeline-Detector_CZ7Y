{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CommonLit - XGBooost  \n\nThis notebook uses CountVectorizer and XGBooost to make predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:00:29.490453Z","iopub.execute_input":"2021-06-11T10:00:29.49133Z","iopub.status.idle":"2021-06-11T10:00:29.502811Z","shell.execute_reply.started":"2021-06-11T10:00:29.491218Z","shell.execute_reply":"2021-06-11T10:00:29.501469Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport spacy\n\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T10:30:20.67887Z","iopub.execute_input":"2021-06-11T10:30:20.679222Z","iopub.status.idle":"2021-06-11T10:30:20.685206Z","shell.execute_reply.started":"2021-06-11T10:30:20.679192Z","shell.execute_reply":"2021-06-11T10:30:20.683953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df  = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntrain_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n# train_df","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:30:20.686695Z","iopub.execute_input":"2021-06-11T10:30:20.687014Z","iopub.status.idle":"2021-06-11T10:30:20.744828Z","shell.execute_reply.started":"2021-06-11T10:30:20.68697Z","shell.execute_reply":"2021-06-11T10:30:20.743778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Source: https://www.kaggle.com/bryanb/first-approach-using-xgboost-with-hyperopt\n\nsp        = spacy.load('en_core_web_sm')\nstopwords = stopwords.words('english')\nsnowball  = SnowballStemmer(language='english')\n\ndef preprocessing_excerpt(text):\n    text = text.lower()\n    text = word_tokenize(text)\n    text = [ x for x in text if x not in stopwords ]\n    text = [ snowball.stem(x) for x in text ]\n    text = \" \".join(text)\n    return str(sp(text))\n\n\ntrain_df['excerpt_clean'] = train_df['excerpt'].apply(preprocessing_excerpt)\ntest_df[ 'excerpt_clean'] = test_df[ 'excerpt'].apply(preprocessing_excerpt)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:30:20.746851Z","iopub.execute_input":"2021-06-11T10:30:20.747271Z","iopub.status.idle":"2021-06-11T10:31:27.742761Z","shell.execute_reply.started":"2021-06-11T10:30:20.747224Z","shell.execute_reply":"2021-06-11T10:31:27.741753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vectorizer       = TfidfVectorizer()\nvectorizer         = CountVectorizer()\nvectorizer.fit(np.concatenate([ train_df['excerpt_clean'].values, test_df['excerpt_clean'].values ]))\ntrain_vectors      = vectorizer.transform(train_df['excerpt_clean'].values)\ntest_vectors       = vectorizer.transform( test_df['excerpt_clean'].values)\n# feature_names      = vectorizer.get_feature_names()\n# test_feature_names = vectorizer.get_feature_names()\n\nX_train = pd.DataFrame(train_vectors.todense())\ny_train = train_df['target'].values\nX_test  = pd.DataFrame(test_vectors.todense()) ","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:34:15.885779Z","iopub.execute_input":"2021-06-11T10:34:15.886124Z","iopub.status.idle":"2021-06-11T10:34:16.690173Z","shell.execute_reply.started":"2021-06-11T10:34:15.886093Z","shell.execute_reply":"2021-06-11T10:34:16.689221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor = xgb.XGBRegressor()\nregressor.fit(X_train, y_train)\ny_pred    = regressor.predict(X_test)    \ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:34:20.593139Z","iopub.execute_input":"2021-06-11T10:34:20.593487Z","iopub.status.idle":"2021-06-11T10:35:33.293867Z","shell.execute_reply.started":"2021-06-11T10:34:20.593456Z","shell.execute_reply":"2021-06-11T10:35:33.292861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsubmission_df['target'] = y_pred\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:31:27.768489Z","iopub.status.idle":"2021-06-11T10:31:27.76896Z"},"trusted":true},"execution_count":null,"outputs":[]}]}