{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport gc\nimport sys\nimport time\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport xgboost as xgb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import mean_squared_error\n\nfrom transformers import AutoModel, AutoTokenizer\nimport json\nfrom tensorflow.keras.models import load_model\nimport re\nimport pandas as pd\nimport string\nimport keras\nfrom sklearn.svm import SVR\n\n\n\nfrom sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, LSTM,Dropout,concatenate\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense, Activation, Embedding, LSTM,Dropout,Bidirectional,GRU\nfrom keras.utils import plot_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Flatten ,Embedding,Input,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Dropout,MaxPooling1D,Bidirectional,GRU,Concatenate\nfrom keras.models import Sequential,Model\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T16:38:06.378443Z","iopub.execute_input":"2021-05-26T16:38:06.378869Z","iopub.status.idle":"2021-05-26T16:38:06.391081Z","shell.execute_reply.started":"2021-05-26T16:38:06.37882Z","shell.execute_reply":"2021-05-26T16:38:06.390098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:06.39283Z","iopub.execute_input":"2021-05-26T16:38:06.393326Z","iopub.status.idle":"2021-05-26T16:38:06.406833Z","shell.execute_reply.started":"2021-05-26T16:38:06.393286Z","shell.execute_reply":"2021-05-26T16:38:06.406006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/commonlitreadabilityprize/'\ntrain = pd.read_csv(data_dir + 'train.csv')\ntest = pd.read_csv(data_dir + 'test.csv')\nsample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n\ntarget = train['target'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:06.409204Z","iopub.execute_input":"2021-05-26T16:38:06.409872Z","iopub.status.idle":"2021-05-26T16:38:06.45158Z","shell.execute_reply.started":"2021-05-26T16:38:06.409828Z","shell.execute_reply":"2021-05-26T16:38:06.450853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:06.453356Z","iopub.execute_input":"2021-05-26T16:38:06.45373Z","iopub.status.idle":"2021-05-26T16:38:06.458103Z","shell.execute_reply.started":"2021-05-26T16:38:06.453695Z","shell.execute_reply":"2021-05-26T16:38:06.456933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:06.459813Z","iopub.execute_input":"2021-05-26T16:38:06.460183Z","iopub.status.idle":"2021-05-26T16:38:06.4824Z","shell.execute_reply.started":"2021-05-26T16:38:06.460147Z","shell.execute_reply":"2021-05-26T16:38:06.481473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n\ntrain['excerpt'] = train['excerpt'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\ntest['excerpt'] = test['excerpt'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n\n# convert text to lowercase\ntrain['excerpt'] = train['excerpt'].str.lower()\ntest['excerpt'] = test['excerpt'].str.lower()\n\n# remove numbers\ntrain['excerpt'] = train['excerpt'].str.replace(\"[0-9]\", \" \")\ntest['excerpt'] = test['excerpt'].str.replace(\"[0-9]\", \" \")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:06.483881Z","iopub.execute_input":"2021-05-26T16:38:06.48428Z","iopub.status.idle":"2021-05-26T16:38:08.637164Z","shell.execute_reply.started":"2021-05-26T16:38:06.484237Z","shell.execute_reply":"2021-05-26T16:38:08.636327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt'] = train['excerpt'].apply(lambda x:' '.join(x.split()))\ntest['excerpt'] = test['excerpt'].apply(lambda x:' '.join(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:08.638364Z","iopub.execute_input":"2021-05-26T16:38:08.63875Z","iopub.status.idle":"2021-05-26T16:38:08.687617Z","shell.execute_reply.started":"2021-05-26T16:38:08.638713Z","shell.execute_reply":"2021-05-26T16:38:08.686895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:08.6888Z","iopub.execute_input":"2021-05-26T16:38:08.689167Z","iopub.status.idle":"2021-05-26T16:38:08.707167Z","shell.execute_reply.started":"2021-05-26T16:38:08.689129Z","shell.execute_reply":"2021-05-26T16:38:08.706149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install \"tensorflow>=1.7.0\"","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:08.710978Z","iopub.execute_input":"2021-05-26T16:38:08.711298Z","iopub.status.idle":"2021-05-26T16:38:14.482254Z","shell.execute_reply.started":"2021-05-26T16:38:08.711272Z","shell.execute_reply":"2021-05-26T16:38:14.481288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-hub","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:14.484442Z","iopub.execute_input":"2021-05-26T16:38:14.48482Z","iopub.status.idle":"2021-05-26T16:38:19.892369Z","shell.execute_reply.started":"2021-05-26T16:38:14.484777Z","shell.execute_reply":"2021-05-26T16:38:19.891406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nimport tensorflow.compat.v1 as tf\n#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\ntf.disable_eager_execution()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:19.894063Z","iopub.execute_input":"2021-05-26T16:38:19.89441Z","iopub.status.idle":"2021-05-26T16:38:19.901379Z","shell.execute_reply.started":"2021-05-26T16:38:19.894371Z","shell.execute_reply":"2021-05-26T16:38:19.900516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:19.902784Z","iopub.execute_input":"2021-05-26T16:38:19.903167Z","iopub.status.idle":"2021-05-26T16:38:20.783564Z","shell.execute_reply.started":"2021-05-26T16:38:19.903115Z","shell.execute_reply":"2021-05-26T16:38:20.78269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def elmo_vectors(x):\n    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.tables_initializer())\n        return sess.run(tf.reduce_mean(embeddings,1))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:38:20.787384Z","iopub.execute_input":"2021-05-26T16:38:20.787675Z","iopub.status.idle":"2021-05-26T16:38:20.794494Z","shell.execute_reply.started":"2021-05-26T16:38:20.787638Z","shell.execute_reply":"2021-05-26T16:38:20.793648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:05:42.406613Z","iopub.execute_input":"2021-05-26T17:05:42.406986Z","iopub.status.idle":"2021-05-26T17:05:42.412876Z","shell.execute_reply.started":"2021-05-26T17:05:42.406953Z","shell.execute_reply":"2021-05-26T17:05:42.412028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_train = [train[i:i+10] for i in range(0,train.shape[0],10)]\nlist_test = [test[i:i+10] for i in range(0,test.shape[0],10)]\nelmo_train = [elmo_vectors(x['excerpt']) for x in list_train]\nelmo_test = [elmo_vectors(x['excerpt']) for x in list_test]\nelmo_train_new = np.concatenate(elmo_train, axis = 0)\nelmo_test_new = np.concatenate(elmo_test, axis = 0)\npickle_out = open(\"elmo_train_v1\",\"wb\")\npickle.dump(elmo_train_new, pickle_out)\npickle_out.close()\n\npickle_out = open(\"elmo_test_v1\",\"wb\")\npickle.dump(elmo_test_new, pickle_out)\npickle_out.close()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:05:46.080526Z","iopub.execute_input":"2021-05-26T17:05:46.080861Z","iopub.status.idle":"2021-05-26T17:12:16.060547Z","shell.execute_reply.started":"2021-05-26T17:05:46.080829Z","shell.execute_reply":"2021-05-26T17:12:16.057611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_train = [train[i:i+20] for i in range(0,train.shape[0],20)]\nlist_test = [test[i:i+20] for i in range(0,test.shape[0],20)]\nelmo_train = [elmo_vectors(x['excerpt']) for x in list_train]\nelmo_test = [elmo_vectors(x['excerpt']) for x in list_test]\nelmo_train_new = np.concatenate(elmo_train, axis = 0)\nelmo_test_new = np.concatenate(elmo_test, axis = 0)\npickle_out = open(\"elmo_train_v2\",\"wb\")\npickle.dump(elmo_train_new, pickle_out)\npickle_out.close()\n\npickle_out = open(\"elmo_test_v2\",\"wb\")\npickle.dump(elmo_test_new, pickle_out)\npickle_out.close()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:04:20.35193Z","iopub.status.idle":"2021-05-26T17:04:20.352633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_train = [train[i:i+30] for i in range(0,train.shape[0],30)]\nlist_test = [test[i:i+30] for i in range(0,test.shape[0],30)]\nelmo_train = [elmo_vectors(x['excerpt']) for x in list_train]\nelmo_test = [elmo_vectors(x['excerpt']) for x in list_test]\nelmo_train_new = np.concatenate(elmo_train, axis = 0)\nelmo_test_new = np.concatenate(elmo_test, axis = 0)\npickle_out = open(\"elmo_train_v3\",\"wb\")\npickle.dump(elmo_train_new, pickle_out)\npickle_out.close()\n\npickle_out = open(\"elmo_test_v3\",\"wb\")\npickle.dump(elmo_test_new, pickle_out)\npickle_out.close()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:04:20.353704Z","iopub.status.idle":"2021-05-26T17:04:20.3544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_train = [train[i:i+40] for i in range(0,train.shape[0],40)]\nlist_test = [test[i:i+40] for i in range(0,test.shape[0],40)]\nelmo_train = [elmo_vectors(x['excerpt']) for x in list_train]\nelmo_test = [elmo_vectors(x['excerpt']) for x in list_test]\nelmo_train_new = np.concatenate(elmo_train, axis = 0)\nelmo_test_new = np.concatenate(elmo_test, axis = 0)\npickle_out = open(\"elmo_train_v4\",\"wb\")\npickle.dump(elmo_train_new, pickle_out)\npickle_out.close()\n\npickle_out = open(\"elmo_test_v4\",\"wb\")\npickle.dump(elmo_test_new, pickle_out)\npickle_out.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_train = [train[i:i+50] for i in range(0,train.shape[0],50)]\nlist_test = [test[i:i+50] for i in range(0,test.shape[0],50)]\nelmo_train = [elmo_vectors(x['excerpt']) for x in list_train]\nelmo_test = [elmo_vectors(x['excerpt']) for x in list_test]\nelmo_train_new = np.concatenate(elmo_train, axis = 0)\nelmo_test_new = np.concatenate(elmo_test, axis = 0)\npickle_out = open(\"elmo_train_v5\",\"wb\")\npickle.dump(elmo_train_new, pickle_out)\npickle_out.close()\n\npickle_out = open(\"elmo_test_v5\",\"wb\")\npickle.dump(elmo_test_new, pickle_out)\npickle_out.close()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:12:21.149959Z","iopub.execute_input":"2021-05-26T17:12:21.150283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}