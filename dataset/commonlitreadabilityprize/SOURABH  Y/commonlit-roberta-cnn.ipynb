{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport gc\nimport sys\nimport time\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport xgboost as xgb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nfrom tensorflow.keras.models import load_model\nimport re\nimport pandas as pd\nimport string\nimport keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/commonlitreadabilityprize/'\ntrain = pd.read_csv(data_dir + 'train.csv')\ntest = pd.read_csv(data_dir + 'test.csv')\nsample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n\ntarget = train['target'].to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source: https://www.kaggle.com/maunish/clrp-roberta-lgbm\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \n\ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    MODEL_PATH = path\n    model = AutoModel.from_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n\n    ds = CLRPDataset(df, tokenizer, config['max_len'])\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:, 0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n}\nseed_everything(seed=config['seed'])\n\ntrain_embeddings =  get_embeddings(train,'../input/modelf1')\ntest_embeddings = get_embeddings(test,'../input/modelf1')\n\n\n\ntrain_embeddings2 =  get_embeddings(train,'../input/modelf2')\ntest_embeddings2 = get_embeddings(test,'../input/modelf2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, LSTM,Dropout,concatenate\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense, Activation, Embedding, LSTM,Dropout,Bidirectional,GRU\nfrom keras.utils import plot_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Flatten ,Embedding,Input,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Dropout,MaxPooling1D,Bidirectional,GRU,Concatenate\nfrom keras.models import Sequential,Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crt_model():\n    i=Input(shape=(768,1))\n    l1=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i)\n    l2 =MaxPooling1D(2) (l1)\n    l3=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l2)\n    l3 =MaxPooling1D(2) (l3)\n    l3=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(512,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(1024,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(2048,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(4098,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(8196,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l4=GlobalMaxPooling1D()(l3)\n    l5=Dense(120, kernel_initializer='normal',activation='relu')(l4)\n    l5=Dense(240, kernel_initializer='normal',activation='relu')(l5)\n    l5=Dense(480, kernel_initializer='normal',activation='relu')(l5)\n    l5=Dense(980, kernel_initializer='normal',activation='relu')(l5)\n    l7=Dense(1, kernel_initializer='normal')(l5)\n    model=Model(inputs=i, outputs=l7)\n    model.compile(loss='mean_squared_error', optimizer='adam',metrics=[keras.metrics.MeanSquaredError()])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=crt_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2=crt_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfolds = 3\nkf = KFold(n_splits=nfolds, shuffle=True, random_state=config['seed'])\nfor k, (train_idx, valid_idx) in enumerate(kf.split(train)): \n    train_x,train_y,test_x,test_y=train_embeddings[train_idx], target[train_idx],train_embeddings[valid_idx], target[valid_idx]\n    model.fit(train_x.reshape(train_x.shape+(1,)),\n              train_y,\n              epochs=7,\n              validation_data=(test_x,test_y),\n              batch_size=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfolds = 3\nkf = KFold(n_splits=nfolds, shuffle=True, random_state=config['seed'])\nfor k, (train_idx, valid_idx) in enumerate(kf.split(train)): \n    train_x,train_y,test_x,test_y=train_embeddings2[train_idx], target[train_idx],train_embeddings2[valid_idx], target[valid_idx]\n    model2.fit(train_x.reshape(train_x.shape+(1,)),\n              train_y,\n              epochs=7,\n              validation_data=(test_x,test_y),\n              batch_size=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(test_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred2=model.predict(test_embeddings2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pr(y_pred,y_pred2):\n    ypred=[]\n    for i in range(len(y_pred)):\n        ypred.append((y_pred[i][0]+y_pred2[i][0])/2)\n    return ypred\nypred=pr(y_pred,y_pred2)\nypred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':test.id,'target':ypred})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}