{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n# !pip install chart_studio\n# !pip install textstat\n\nimport numpy as np \nimport pandas as pd \n\n# text processing libraries\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\n\n# Visualisation libraries\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\n# import chart_studio.plotly as py\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.svm import LinearSVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\n\n# File system manangement\nimport os\n\n# Pytorch\nimport torch\n\n#Transformers\nfrom transformers import BertTokenizer\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:34.471085Z","iopub.execute_input":"2021-06-19T09:31:34.47153Z","iopub.status.idle":"2021-06-19T09:31:39.809897Z","shell.execute_reply.started":"2021-06-19T09:31:34.471446Z","shell.execute_reply":"2021-06-19T09:31:39.809083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading the Data**","metadata":{}},{"cell_type":"code","source":"# Training Data\ntrain = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n\nprint(\"Training data shape.. \",train.shape)\nprint(\"Testing data shape.. \",test.shape)\n\n# First few rows of the training dataset\ntrain.head()\n\n# First few rows of the testing dataset\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:39.811072Z","iopub.execute_input":"2021-06-19T09:31:39.811463Z","iopub.status.idle":"2021-06-19T09:31:39.949619Z","shell.execute_reply.started":"2021-06-19T09:31:39.811435Z","shell.execute_reply":"2021-06-19T09:31:39.948965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the missing value","metadata":{}},{"cell_type":"code","source":"#Missing values in training set\ntrain.isnull().sum()\n#Missing values in test set\ntest.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:39.950951Z","iopub.execute_input":"2021-06-19T09:31:39.951301Z","iopub.status.idle":"2021-06-19T09:31:39.963267Z","shell.execute_reply.started":"2021-06-19T09:31:39.951276Z","shell.execute_reply":"2021-06-19T09:31:39.962408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility function","metadata":{}},{"cell_type":"code","source":"# text preprocessing helper functions\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:39.964394Z","iopub.execute_input":"2021-06-19T09:31:39.964761Z","iopub.status.idle":"2021-06-19T09:31:39.971884Z","shell.execute_reply.started":"2021-06-19T09:31:39.964734Z","shell.execute_reply":"2021-06-19T09:31:39.971056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text preprocessing using the utility function","metadata":{}},{"cell_type":"code","source":"# Applying the cleaning function to both test and training datasets\ntrain['excerpt_clean'] = train['excerpt'].apply(str).apply(lambda x: text_preprocessing(x))\ntest['excerpt_clean'] = test['excerpt'].apply(str).apply(lambda x: text_preprocessing(x))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:39.972878Z","iopub.execute_input":"2021-06-19T09:31:39.973319Z","iopub.status.idle":"2021-06-19T09:31:40.92337Z","shell.execute_reply.started":"2021-06-19T09:31:39.973251Z","shell.execute_reply":"2021-06-19T09:31:40.922344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt_len'] = train['excerpt_clean'].astype(str).apply(len)\ntrain['excerpt_count'] = train['excerpt_clean'].apply(lambda x: len(str(x).split()))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:40.924415Z","iopub.execute_input":"2021-06-19T09:31:40.924797Z","iopub.status.idle":"2021-06-19T09:31:40.963062Z","shell.execute_reply.started":"2021-06-19T09:31:40.92477Z","shell.execute_reply":"2021-06-19T09:31:40.962088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Character Count'] = train['excerpt'].apply(lambda x: len(str(x)))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:40.964238Z","iopub.execute_input":"2021-06-19T09:31:40.964509Z","iopub.status.idle":"2021-06-19T09:31:40.973037Z","shell.execute_reply.started":"2021-06-19T09:31:40.964484Z","shell.execute_reply":"2021-06-19T09:31:40.972019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:40.974236Z","iopub.execute_input":"2021-06-19T09:31:40.974529Z","iopub.status.idle":"2021-06-19T09:31:40.993999Z","shell.execute_reply.started":"2021-06-19T09:31:40.974486Z","shell.execute_reply":"2021-06-19T09:31:40.992948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of Excerpt length","metadata":{}},{"cell_type":"code","source":"train['excerpt_len'].iplot(\n    kind='hist',\n    bins=100,\n    xTitle='text length',\n    linecolor='black',\n    color='red',\n    yTitle='count',\n    title='Excerpt text Length Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:40.996609Z","iopub.execute_input":"2021-06-19T09:31:40.99691Z","iopub.status.idle":"2021-06-19T09:31:41.818128Z","shell.execute_reply.started":"2021-06-19T09:31:40.996881Z","shell.execute_reply":"2021-06-19T09:31:41.817372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace0 = go.Box(\n    y=train['excerpt_len'],\n    name = 'Text',\n    marker = dict(\n        color = 'red',\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:41.819591Z","iopub.execute_input":"2021-06-19T09:31:41.819961Z","iopub.status.idle":"2021-06-19T09:31:41.834769Z","shell.execute_reply.started":"2021-06-19T09:31:41.819934Z","shell.execute_reply":"2021-06-19T09:31:41.833882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [trace0]\nlayout = go.Layout(\n    title = \"Length of the text\"\n)\nfig = go.Figure(data=data,layout=layout)\niplot(fig, filename = \"Length of the text of different polarities\")","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:41.836073Z","iopub.execute_input":"2021-06-19T09:31:41.836364Z","iopub.status.idle":"2021-06-19T09:31:41.878101Z","shell.execute_reply.started":"2021-06-19T09:31:41.836338Z","shell.execute_reply":"2021-06-19T09:31:41.877233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of excerpt count","metadata":{}},{"cell_type":"code","source":"train['excerpt_count'].iplot(\nkind='hist',\nbins=50,\nxTitle='text_length',\nlinecolor='black',\ncolor='green',\nyTitle='count',\ntitle='Excerpt text word count')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:41.879253Z","iopub.execute_input":"2021-06-19T09:31:41.879525Z","iopub.status.idle":"2021-06-19T09:31:41.976646Z","shell.execute_reply.started":"2021-06-19T09:31:41.879496Z","shell.execute_reply":"2021-06-19T09:31:41.975892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##   List the top n words in a vocabulary according to occurrence in a text corpus","metadata":{}},{"cell_type":"code","source":"#source of code : https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\ndef get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:41.977703Z","iopub.execute_input":"2021-06-19T09:31:41.978126Z","iopub.status.idle":"2021-06-19T09:31:41.984089Z","shell.execute_reply.started":"2021-06-19T09:31:41.978089Z","shell.execute_reply":"2021-06-19T09:31:41.982931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unigram","metadata":{}},{"cell_type":"code","source":"unigrams=get_top_n_words(train['excerpt_clean'],20)\ndf1 = pd.DataFrame(unigrams, columns = ['Text' , 'count'])\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='red', title='Top 20 Unigrams in excerpt text',orientation='h')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:41.985125Z","iopub.execute_input":"2021-06-19T09:31:41.985503Z","iopub.status.idle":"2021-06-19T09:31:43.054636Z","shell.execute_reply.started":"2021-06-19T09:31:41.985476Z","shell.execute_reply":"2021-06-19T09:31:43.053791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of top Bigrams\ndef get_top_n_gram(corpus,ngram_range,n=None):\n    vec = CountVectorizer(ngram_range=ngram_range,stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:43.055799Z","iopub.execute_input":"2021-06-19T09:31:43.056109Z","iopub.status.idle":"2021-06-19T09:31:43.061783Z","shell.execute_reply.started":"2021-06-19T09:31:43.056067Z","shell.execute_reply":"2021-06-19T09:31:43.060815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bigrams","metadata":{}},{"cell_type":"code","source":"bigrams = get_top_n_gram(train['excerpt_clean'],(2,2),20)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:43.062793Z","iopub.execute_input":"2021-06-19T09:31:43.063081Z","iopub.status.idle":"2021-06-19T09:31:45.24127Z","shell.execute_reply.started":"2021-06-19T09:31:43.063055Z","shell.execute_reply":"2021-06-19T09:31:45.240212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for word,freq in bigrams:\n    print(word,freq)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:45.242454Z","iopub.execute_input":"2021-06-19T09:31:45.242744Z","iopub.status.idle":"2021-06-19T09:31:45.253367Z","shell.execute_reply.started":"2021-06-19T09:31:45.242715Z","shell.execute_reply":"2021-06-19T09:31:45.251886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for word, freq in top_bigrams:\n    #print(word, freq)\ndf1 = pd.DataFrame(bigrams, columns = ['Text' , 'count'])\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n    kind='bar', yTitle='Count', linecolor='black',color='blue', title='Top 20 Bigrams in excerpt text',orientation='h')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:45.254701Z","iopub.execute_input":"2021-06-19T09:31:45.255061Z","iopub.status.idle":"2021-06-19T09:31:45.314955Z","shell.execute_reply.started":"2021-06-19T09:31:45.255019Z","shell.execute_reply":"2021-06-19T09:31:45.314075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trigrams","metadata":{}},{"cell_type":"code","source":"trigrams = get_top_n_gram(train['excerpt_clean'],(3,3),20)\ndf2 = pd.DataFrame(trigrams,columns=['Text','count'])\n\ndf2.groupby(\"Text\").sum()['count'].sort_values(ascending=True).iplot(\nkind='bar',yTitle='Count',linecolor='black',color='orange',title='Top 20 Trigrams Text',orientation='h')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:45.316203Z","iopub.execute_input":"2021-06-19T09:31:45.316482Z","iopub.status.idle":"2021-06-19T09:31:47.595588Z","shell.execute_reply.started":"2021-06-19T09:31:45.316454Z","shell.execute_reply":"2021-06-19T09:31:47.594727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tc = train['excerpt_clean']","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:47.596846Z","iopub.execute_input":"2021-06-19T09:31:47.597125Z","iopub.status.idle":"2021-06-19T09:31:47.600604Z","shell.execute_reply.started":"2021-06-19T09:31:47.597098Z","shell.execute_reply":"2021-06-19T09:31:47.5999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nfig, (ax1) = plt.subplots(1, 1, figsize=[30, 15])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(tc))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('excerpt clean text',fontsize=40);\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:47.601602Z","iopub.execute_input":"2021-06-19T09:31:47.601838Z","iopub.status.idle":"2021-06-19T09:31:50.857691Z","shell.execute_reply.started":"2021-06-19T09:31:47.601815Z","shell.execute_reply":"2021-06-19T09:31:50.856448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of the target variable","metadata":{}},{"cell_type":"code","source":"train['target'].iplot(kind='hist',xTitle='Target',yTitle='Density',linecolor='black',color='blue')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:50.858692Z","iopub.execute_input":"2021-06-19T09:31:50.859122Z","iopub.status.idle":"2021-06-19T09:31:50.962633Z","shell.execute_reply.started":"2021-06-19T09:31:50.859089Z","shell.execute_reply":"2021-06-19T09:31:50.961789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of Standard error","metadata":{}},{"cell_type":"code","source":"train['standard_error'].iplot(kind='hist',xTitle='standard_error',yTitle='Density',linecolor='black',color='blue')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:50.963809Z","iopub.execute_input":"2021-06-19T09:31:50.96408Z","iopub.status.idle":"2021-06-19T09:31:51.069441Z","shell.execute_reply.started":"2021-06-19T09:31:50.964054Z","shell.execute_reply":"2021-06-19T09:31:51.068552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the baseline model","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(analyzer='char',ngram_range=(1,6))\nX = vectorizer.fit_transform(train.excerpt_clean,)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:31:51.070716Z","iopub.execute_input":"2021-06-19T09:31:51.071218Z","iopub.status.idle":"2021-06-19T09:32:06.433854Z","shell.execute_reply.started":"2021-06-19T09:31:51.071178Z","shell.execute_reply":"2021-06-19T09:32:06.432756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel = LinearSVR(random_state=42)\nscores = cross_val_score(model, X, train.target, cv=5,scoring='neg_root_mean_squared_error')\nscores *=-1\nscores.mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:06.435308Z","iopub.execute_input":"2021-06-19T09:32:06.43569Z","iopub.status.idle":"2021-06-19T09:32:12.326849Z","shell.execute_reply.started":"2021-06-19T09:32:06.435649Z","shell.execute_reply":"2021-06-19T09:32:12.325799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X,train.target)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:12.328415Z","iopub.execute_input":"2021-06-19T09:32:12.329074Z","iopub.status.idle":"2021-06-19T09:32:13.746066Z","shell.execute_reply.started":"2021-06-19T09:32:12.32903Z","shell.execute_reply":"2021-06-19T09:32:13.745144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub = pd.read_csv('../input/commonlitreadabilityprize/test.csv',index_col='id')\n# x = vectorizer.transform(sub.excerpt)\n# p = model.predict(x)\n# sub['target'] = p\n# sub[['target']].to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:13.749426Z","iopub.execute_input":"2021-06-19T09:32:13.749717Z","iopub.status.idle":"2021-06-19T09:32:13.75356Z","shell.execute_reply.started":"2021-06-19T09:32:13.749688Z","shell.execute_reply":"2021-06-19T09:32:13.752432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we will use LightGBM","metadata":{}},{"cell_type":"code","source":"from time import time\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:13.755129Z","iopub.execute_input":"2021-06-19T09:32:13.755449Z","iopub.status.idle":"2021-06-19T09:32:14.009978Z","shell.execute_reply.started":"2021-06-19T09:32:13.755419Z","shell.execute_reply":"2021-06-19T09:32:14.009025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(sublinear_tf=True, norm='l2',ngram_range=(1,1))\nfeatures = tfidf.fit_transform(train.excerpt_clean).toarray()\nfeatures.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:14.011386Z","iopub.execute_input":"2021-06-19T09:32:14.011849Z","iopub.status.idle":"2021-06-19T09:32:15.253385Z","shell.execute_reply.started":"2021-06-19T09:32:14.011791Z","shell.execute_reply":"2021-06-19T09:32:15.252286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_test = tfidf.transform(test.excerpt_clean).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:15.254927Z","iopub.execute_input":"2021-06-19T09:32:15.255318Z","iopub.status.idle":"2021-06-19T09:32:15.264276Z","shell.execute_reply.started":"2021-06-19T09:32:15.255277Z","shell.execute_reply":"2021-06-19T09:32:15.263304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'metric': 'rmse','random_state': 48,'n_estimators': 20000,'reg_alpha': 0.0010819683712588644,\n          'reg_lambda': 0.004760428916800031, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.01,\n          'max_depth': 100, 'num_leaves': 39, 'min_child_samples': 12, 'cat_smooth': 67}\npreds = np.zeros(test.shape[0])\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nrmse=[]  # list contains rmse for each fold\nn=0\nfor trn_idx, test_idx in kf.split(features,train['target']):\n    X_tr,X_val=features[trn_idx],features[test_idx]\n    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx]\n    model = LGBMRegressor(**params)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict(features_test)/kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    print(n+1,rmse[n])\n    n+=1","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:32:15.265878Z","iopub.execute_input":"2021-06-19T09:32:15.266344Z","iopub.status.idle":"2021-06-19T09:34:36.927159Z","shell.execute_reply.started":"2021-06-19T09:32:15.266303Z","shell.execute_reply":"2021-06-19T09:34:36.925953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n# Prediction distibution\nplt.figure(figsize=(10,4))\nsns.kdeplot(preds,shade=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:36.928735Z","iopub.execute_input":"2021-06-19T09:34:36.929141Z","iopub.status.idle":"2021-06-19T09:34:37.182194Z","shell.execute_reply.started":"2021-06-19T09:34:36.929099Z","shell.execute_reply":"2021-06-19T09:34:37.181344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/commonlitreadabilityprize/test.csv',index_col='id')\nsub['target']=preds\nsub[['target']].to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.183398Z","iopub.execute_input":"2021-06-19T09:34:37.183689Z","iopub.status.idle":"2021-06-19T09:34:37.196885Z","shell.execute_reply.started":"2021-06-19T09:34:37.183651Z","shell.execute_reply":"2021-06-19T09:34:37.195894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.197961Z","iopub.execute_input":"2021-06-19T09:34:37.198211Z","iopub.status.idle":"2021-06-19T09:34:37.202027Z","shell.execute_reply.started":"2021-06-19T09:34:37.198187Z","shell.execute_reply":"2021-06-19T09:34:37.200987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading model using sentence transformers\n\n# import sentence_transformers\n# from sentence_transformers import SentenceTransformer, models","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.203403Z","iopub.execute_input":"2021-06-19T09:34:37.20382Z","iopub.status.idle":"2021-06-19T09:34:37.213407Z","shell.execute_reply.started":"2021-06-19T09:34:37.203773Z","shell.execute_reply":"2021-06-19T09:34:37.212175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting model path for fine-tuned roberta weights\n\n# model_path = '../input/finetuned-model1/checkpoint-568'\n# word_embedding_model = models.Transformer(model_path, max_seq_length=275)\n# pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n# model = SentenceTransformer(modules=[word_embedding_model, pooling_model])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.214759Z","iopub.execute_input":"2021-06-19T09:34:37.215166Z","iopub.status.idle":"2021-06-19T09:34:37.223976Z","shell.execute_reply.started":"2021-06-19T09:34:37.215136Z","shell.execute_reply":"2021-06-19T09:34:37.222952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.225266Z","iopub.execute_input":"2021-06-19T09:34:37.225605Z","iopub.status.idle":"2021-06-19T09:34:37.234941Z","shell.execute_reply.started":"2021-06-19T09:34:37.22555Z","shell.execute_reply":"2021-06-19T09:34:37.234079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding train and test strings\n\n# X_train = model.encode(train.excerpt, device='cuda')\n# X_test = model.encode(test.excerpt, device='cuda')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.236166Z","iopub.execute_input":"2021-06-19T09:34:37.236511Z","iopub.status.idle":"2021-06-19T09:34:37.24615Z","shell.execute_reply.started":"2021-06-19T09:34:37.236481Z","shell.execute_reply":"2021-06-19T09:34:37.245284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold\n# from datetime import datetime\n# from sklearn.metrics import mean_squared_error\n# from sklearn.linear_model import BayesianRidge\n\n# preds = []\n# train_scores = []\n\n# df_oof=train.copy()\n# df_oof['oof'] = 0\n\n# skf = StratifiedKFold(10, shuffle=True, random_state=42)\n\n# splits = list(skf.split(X=X_train, y=train['Character Count']))\n\n# # predicting out of fold scores for each fold and doing predictions for each training set\n\n# for i, (train_idx, val_idx) in enumerate(splits):\n#     print(f'\\n------------- Training Fold {i + 1} / {10}')\n#     print(\"Current Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n\n#     clf = BayesianRidge(n_iter=300, verbose=True)\n#     clf.fit(X_train[train_idx],train.target[train_idx])\n#     train_score=mean_squared_error(train.target[train_idx], clf.predict(X_train[train_idx]), squared=False)\n#     train_scores.append(train_score)\n#     print(f\"Fold {i} train RMSE: {train_score}\")\n    \n    \n#     preds.append(clf.predict(X_test))\n#     x=clf.predict(X_train[val_idx])\n#     df_oof['oof'].iloc[val_idx]+= x\n\n# print(f'Training score: {np.mean(train_scores)}, Training STD: {np.std(train_scores)}')\n# print(f'OOF score across folds: {mean_squared_error(df_oof.target, df_oof.oof, squared=False)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.247477Z","iopub.execute_input":"2021-06-19T09:34:37.24801Z","iopub.status.idle":"2021-06-19T09:34:37.26321Z","shell.execute_reply.started":"2021-06-19T09:34:37.247978Z","shell.execute_reply":"2021-06-19T09:34:37.262456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting mean prediction across 5 folds\n# y_pred = np.mean(preds,0)\n# y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.264437Z","iopub.execute_input":"2021-06-19T09:34:37.264945Z","iopub.status.idle":"2021-06-19T09:34:37.277788Z","shell.execute_reply.started":"2021-06-19T09:34:37.264909Z","shell.execute_reply":"2021-06-19T09:34:37.276756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub = test[[\"id\"]].copy()\n# sub[\"target\"] = y_pred\n# sub.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.279508Z","iopub.execute_input":"2021-06-19T09:34:37.279791Z","iopub.status.idle":"2021-06-19T09:34:37.290648Z","shell.execute_reply.started":"2021-06-19T09:34:37.279764Z","shell.execute_reply":"2021-06-19T09:34:37.289869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking submission file\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:34:37.291935Z","iopub.execute_input":"2021-06-19T09:34:37.292203Z","iopub.status.idle":"2021-06-19T09:34:37.310386Z","shell.execute_reply.started":"2021-06-19T09:34:37.292178Z","shell.execute_reply":"2021-06-19T09:34:37.309263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}