{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport re\nimport unicodedata\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom wordcloud import WordCloud, STOPWORDS \nfrom PIL import Image\nimport requests\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom transformers import AdamW\n\nfrom tqdm import tqdm\n\n\n# Setting color palette.\norange_black = [\n    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T01:32:55.130981Z","iopub.execute_input":"2021-08-03T01:32:55.131364Z","iopub.status.idle":"2021-08-03T01:32:55.142135Z","shell.execute_reply.started":"2021-08-03T01:32:55.131329Z","shell.execute_reply":"2021-08-03T01:32:55.141282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the data\ntrain = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('/kaggle/input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:25.301573Z","iopub.execute_input":"2021-08-03T01:32:25.301922Z","iopub.status.idle":"2021-08-03T01:32:25.416729Z","shell.execute_reply.started":"2021-08-03T01:32:25.301893Z","shell.execute_reply":"2021-08-03T01:32:25.415778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data analysis and visualization","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:26.658101Z","iopub.execute_input":"2021-08-03T01:32:26.658454Z","iopub.status.idle":"2021-08-03T01:32:26.685783Z","shell.execute_reply.started":"2021-08-03T01:32:26.658422Z","shell.execute_reply":"2021-08-03T01:32:26.684734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:26.995855Z","iopub.execute_input":"2021-08-03T01:32:26.996272Z","iopub.status.idle":"2021-08-03T01:32:27.002608Z","shell.execute_reply.started":"2021-08-03T01:32:26.996202Z","shell.execute_reply":"2021-08-03T01:32:27.001394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:27.179855Z","iopub.execute_input":"2021-08-03T01:32:27.18014Z","iopub.status.idle":"2021-08-03T01:32:27.23346Z","shell.execute_reply.started":"2021-08-03T01:32:27.180114Z","shell.execute_reply":"2021-08-03T01:32:27.232519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:27.350714Z","iopub.execute_input":"2021-08-03T01:32:27.350975Z","iopub.status.idle":"2021-08-03T01:32:27.364187Z","shell.execute_reply.started":"2021-08-03T01:32:27.350949Z","shell.execute_reply":"2021-08-03T01:32:27.362996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:27.869929Z","iopub.execute_input":"2021-08-03T01:32:27.870261Z","iopub.status.idle":"2021-08-03T01:32:27.881328Z","shell.execute_reply.started":"2021-08-03T01:32:27.870213Z","shell.execute_reply":"2021-08-03T01:32:27.880112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking missing values:\n\ndef missing_percentage(df):\n\n    total = df.isnull().sum().sort_values(ascending=False)[df.isnull().sum()!= 0]\n    percent = (df.isnull().sum().sort_values(ascending=False) / len(df) *\n               100)[(df.isnull().sum()/ len(df) * 100) != 0]\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\n\nmissing_train = missing_percentage(train)\n\nplt.figure(figsize=(7, 4))\n\nsns.barplot(x=missing_train.index,\n            y='Percent',\n            data=missing_train,\n            palette=orange_black).set_title('Train Data Missing Values')\n\nmissing_percentage(train)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:27.951252Z","iopub.execute_input":"2021-08-03T01:32:27.95152Z","iopub.status.idle":"2021-08-03T01:32:28.139274Z","shell.execute_reply.started":"2021-08-03T01:32:27.951495Z","shell.execute_reply":"2021-08-03T01:32:28.138328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding word number as independent variable\ntrain['word_n'] = train['excerpt'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:28.140938Z","iopub.execute_input":"2021-08-03T01:32:28.141349Z","iopub.status.idle":"2021-08-03T01:32:28.180206Z","shell.execute_reply.started":"2021-08-03T01:32:28.141311Z","shell.execute_reply":"2021-08-03T01:32:28.179458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to plot distribution of a variable\ndef plot_distribution(variable):\n    x = variable\n    fig, axes = plt.subplots(ncols=2, figsize=(12, 4))\n    for ax in axes:\n        sns.kdeplot(x, shade=False, color='crimson', ax=ax)\n        kdeline = ax.lines[0]\n        xs = kdeline.get_xdata()\n        ys = kdeline.get_ydata()\n        if ax == axes[0]:\n            middle = x.mean()\n            sdev = x.std()\n            left = middle - sdev\n            right = middle + sdev\n            ax.set_title('Showing mean and sdev')\n        else:\n            left, middle, right = np.percentile(x, [25, 50, 75])\n            ax.set_title('Showing median and quartiles')\n        ax.vlines(middle, 0, np.interp(middle, xs, ys), color='crimson', ls=':')\n        ax.fill_between(xs, 0, ys, facecolor='crimson', alpha=0.2)\n        ax.fill_between(xs, 0, ys, where=(left <= xs) & (xs <= right), interpolate=True, facecolor='crimson', alpha=0.2)\n        # ax.set_ylim(ymin=0)\n    plt.xlabel(f'{x.name}', fontsize=10)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:28.183096Z","iopub.execute_input":"2021-08-03T01:32:28.183387Z","iopub.status.idle":"2021-08-03T01:32:28.19165Z","shell.execute_reply.started":"2021-08-03T01:32:28.183357Z","shell.execute_reply":"2021-08-03T01:32:28.190855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"target normally distributed with mean -1","metadata":{}},{"cell_type":"code","source":"# target distribution\nplot_distribution(train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:28.332265Z","iopub.execute_input":"2021-08-03T01:32:28.332562Z","iopub.status.idle":"2021-08-03T01:32:28.685576Z","shell.execute_reply.started":"2021-08-03T01:32:28.332535Z","shell.execute_reply":"2021-08-03T01:32:28.684784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"standard error distribution is skewed to the left with a mean close to 0.5.","metadata":{}},{"cell_type":"code","source":"# Standard error distribution\nplot_distribution(train['standard_error'])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:28.687042Z","iopub.execute_input":"2021-08-03T01:32:28.687443Z","iopub.status.idle":"2021-08-03T01:32:29.014926Z","shell.execute_reply.started":"2021-08-03T01:32:28.687405Z","shell.execute_reply":"2021-08-03T01:32:29.013931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word_n distribution\nplot_distribution(train['word_n'])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:29.016931Z","iopub.execute_input":"2021-08-03T01:32:29.017384Z","iopub.status.idle":"2021-08-03T01:32:29.34233Z","shell.execute_reply.started":"2021-08-03T01:32:29.017328Z","shell.execute_reply":"2021-08-03T01:32:29.341395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target decreased when word number increased. From about -0.5 when word_n = 140 to -1 when word_n = 200","metadata":{}},{"cell_type":"code","source":"# relationship between number of words per text and score\nplt.figure(figsize=(8, 4))\n\nsns.lineplot(x='word_n',\n             y='target',\n             data=train,\n             palette=orange_black[:2],\n             ci=None).set_title('target vs. word_n')\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:29.344177Z","iopub.execute_input":"2021-08-03T01:32:29.344608Z","iopub.status.idle":"2021-08-03T01:32:29.500181Z","shell.execute_reply.started":"2021-08-03T01:32:29.344571Z","shell.execute_reply":"2021-08-03T01:32:29.499437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When standard error is the lowest (about 0.4), the target is equal to -1","metadata":{}},{"cell_type":"code","source":"# relationship between standard error and score\nplt.figure(figsize=(8, 4))\n\nsns.lineplot(x='target',\n             y='standard_error',\n             data=train,\n             palette=orange_black[:2],\n             ci=None).set_title('target vs. standard_error')\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:29.501463Z","iopub.execute_input":"2021-08-03T01:32:29.501788Z","iopub.status.idle":"2021-08-03T01:32:29.658416Z","shell.execute_reply.started":"2021-08-03T01:32:29.501754Z","shell.execute_reply":"2021-08-03T01:32:29.657635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to create box plot\ndef box_count_plot(variable, title_var, fig=(10,8), rot=90):\n    fig, axs = plt.subplots(nrows=2, figsize = fig)\n\n    sns.boxplot(\n        x=variable,\n        y='target',\n        data=train,\n        ax=axs[0]\n    ).set_title('Boxplot of ' + title_var + ' vs. score', size=20)\n\n    sns.countplot(\n        x=variable,\n        data=train,\n        order = train[variable].value_counts().index,\n        ax=axs[1]\n    )\n\n    # Draw median price\n    axs[0].axhline(\n        y=train['target'].median(), \n        color='red',\n        linestyle='dotted'\n    )\n\n    # Label the bars with counts\n    for patch in axs[1].patches:\n        x = patch.get_bbox().get_points()[:, 0]\n        y = patch.get_bbox().get_points()[1, 1]\n        axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n    \n    # Format x-axes\n    axs[1].set_xticklabels(axs[1].xaxis.get_majorticklabels(), rotation=rot)\n    axs[0].xaxis.set_visible(False)\n    \n    axs[0].set(ylabel='Score')\n    axs[1].set(xlabel=title_var, ylabel='Count')\n\n    # Narrow the gap between the plots\n    plt.subplots_adjust(hspace=0.05)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:29.660544Z","iopub.execute_input":"2021-08-03T01:32:29.660783Z","iopub.status.idle":"2021-08-03T01:32:29.673846Z","shell.execute_reply.started":"2021-08-03T01:32:29.660759Z","shell.execute_reply":"2021-08-03T01:32:29.67284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* CC BY 4.0 is the license with highest frequency (391). Mean score with this license is slightly above the mean (-1).\n* CC BY-SA 3.0 and GFDL is the license with the second highest frequency (196). Mean score with this license is below the mean (-1.5).\n* CC BY-SA 3.0 is the license with the third highest frequency (192). Mean score with this license is above the mean (-0.1).","metadata":{}},{"cell_type":"code","source":"train['license'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:29.67533Z","iopub.execute_input":"2021-08-03T01:32:29.675754Z","iopub.status.idle":"2021-08-03T01:32:29.687199Z","shell.execute_reply.started":"2021-08-03T01:32:29.675714Z","shell.execute_reply":"2021-08-03T01:32:29.686222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# License vs. score\nbox_count_plot('license', 'License', fig=(10,8), rot=90)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:29.985187Z","iopub.execute_input":"2021-08-03T01:32:29.985568Z","iopub.status.idle":"2021-08-03T01:32:30.689389Z","shell.execute_reply.started":"2021-08-03T01:32:29.98554Z","shell.execute_reply":"2021-08-03T01:32:30.68856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Example of texts with highest/lowest score","metadata":{}},{"cell_type":"code","source":"# Looking at texts with highest score\ntrain.sort_values(['target'], ascending=False)['excerpt'].reset_index(drop=True).all()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:30.690795Z","iopub.execute_input":"2021-08-03T01:32:30.691131Z","iopub.status.idle":"2021-08-03T01:32:30.702081Z","shell.execute_reply.started":"2021-08-03T01:32:30.691095Z","shell.execute_reply":"2021-08-03T01:32:30.701329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at texts with lowest score\ntrain.sort_values(['target'], ascending=True)['excerpt'].reset_index(drop=True).all()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:30.941868Z","iopub.execute_input":"2021-08-03T01:32:30.94227Z","iopub.status.idle":"2021-08-03T01:32:30.9552Z","shell.execute_reply.started":"2021-08-03T01:32:30.942209Z","shell.execute_reply":"2021-08-03T01:32:30.954276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drawing n-gram plots","metadata":{}},{"cell_type":"code","source":"# add appropriate words that will be ignored in the analysis\nadditional_stopwords = []\n\n# cleaning words\ndef basic_clean(text):\n    \"\"\"\n    A simple function to clean up the data. All the words that\n    are not designated as a stop word is then lemmatized after\n    encoding and basic regex parsing are performed.\n    \"\"\"\n    wnl = nltk.stem.WordNetLemmatizer()\n    stopwords = nltk.corpus.stopwords.words('english') + additional_stopwords\n    text = (unicodedata.normalize('NFKD', text)\n                       .encode('ascii', 'ignore')\n                       .decode('utf-8', 'ignore')\n                       .lower())\n    words = re.sub(r'[^\\w\\s]', '', text).split()\n    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n\n# all words \nwords = basic_clean(str(train['excerpt'].tolist()))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:32.660821Z","iopub.execute_input":"2021-08-03T01:32:32.661143Z","iopub.status.idle":"2021-08-03T01:32:36.983343Z","shell.execute_reply.started":"2021-08-03T01:32:32.661113Z","shell.execute_reply":"2021-08-03T01:32:36.982174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting ngram\ndef plotting_ngram(n, top_words):\n    ngrams_series = (pd.Series(nltk.ngrams(words, n)).value_counts())[:top_words]\n    ngrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n    plt.title(f'20 Most Frequently Occuring {n}grams')\n    plt.ylabel(f'{n}gram')\n    plt.xlabel('# of Occurances')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:36.98498Z","iopub.execute_input":"2021-08-03T01:32:36.985359Z","iopub.status.idle":"2021-08-03T01:32:36.992631Z","shell.execute_reply.started":"2021-08-03T01:32:36.985319Z","shell.execute_reply":"2021-08-03T01:32:36.991478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bigram\nplotting_ngram(2, 10)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:36.994959Z","iopub.execute_input":"2021-08-03T01:32:36.995452Z","iopub.status.idle":"2021-08-03T01:32:37.761742Z","shell.execute_reply.started":"2021-08-03T01:32:36.995416Z","shell.execute_reply":"2021-08-03T01:32:37.760771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trigram\nplotting_ngram(3, 10)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:37.763623Z","iopub.execute_input":"2021-08-03T01:32:37.764031Z","iopub.status.idle":"2021-08-03T01:32:38.549112Z","shell.execute_reply.started":"2021-08-03T01:32:37.763988Z","shell.execute_reply":"2021-08-03T01:32:38.548122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Word cloud","metadata":{}},{"cell_type":"code","source":"# combining all words in one paragraph\ndef combine_all_words():\n    comment_words = '' \n    \n    for text in train['excerpt']: \n        text = str(text) \n        tokens = text.split() \n        for i in range(len(tokens)): tokens[i] = tokens[i].lower() \n        comment_words += \" \".join(tokens)+\" \"\n    \n    return comment_words ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:38.550658Z","iopub.execute_input":"2021-08-03T01:32:38.551004Z","iopub.status.idle":"2021-08-03T01:32:38.557134Z","shell.execute_reply.started":"2021-08-03T01:32:38.550967Z","shell.execute_reply":"2021-08-03T01:32:38.555969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create and plot word cloud\ndef create_word_cloud():\n    stopwords = set(STOPWORDS)\n    comment_words = combine_all_words()\n    pic = np.array(Image.open(requests.get('http://www.clker.com/cliparts/O/i/x/Y/q/P/yellow-house-hi.png',stream=True).raw))\n    wordcloud = WordCloud(width = 800, height = 800, \n                          background_color ='white', \n                          stopwords = stopwords, mask = pic, \n                          min_font_size = 10).generate(comment_words)\n    plt.figure(figsize = (10, 10), facecolor = 'white', edgecolor='blue') \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:38.55849Z","iopub.execute_input":"2021-08-03T01:32:38.55896Z","iopub.status.idle":"2021-08-03T01:32:38.568568Z","shell.execute_reply.started":"2021-08-03T01:32:38.558922Z","shell.execute_reply":"2021-08-03T01:32:38.567729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_word_cloud()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:32:38.56972Z","iopub.execute_input":"2021-08-03T01:32:38.570403Z","iopub.status.idle":"2021-08-03T01:32:38.581456Z","shell.execute_reply.started":"2021-08-03T01:32:38.570362Z","shell.execute_reply":"2021-08-03T01:32:38.580689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating a baseline model using BERT ","metadata":{}},{"cell_type":"code","source":"# parameters\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 3e-5\nWEIGHT_DECAY = 1e-2\nBETAS = (0.9, 0.999)\nMAX_LENGTH = 314\nBATCH_SIZE = 16\nNUM_EPOCHS = 20\nNUM_WORKERS = 6\nCHECKPOINT_FILE = 'model.roberta-base.epoch.3.lr.3e-06.wd.0.01.freeze.False.rmse.0.53753'\nPIN_MEMORY = True\nSAVE_MODEL = True\nLOAD_MODEL = False\nPRETRAINED_MODEL = 'roberta-base'\nFREEZE = False\ntokenizer = RobertaTokenizer.from_pretrained(PRETRAINED_MODEL)\n#tokenizer = BertTokenizerFast.from_pretrained(PRETRAINED_MODEL)\n# tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/huggingface-bert/bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:19.97319Z","iopub.execute_input":"2021-08-03T01:47:19.973656Z","iopub.status.idle":"2021-08-03T01:47:20.518422Z","shell.execute_reply.started":"2021-08-03T01:47:19.973619Z","shell.execute_reply":"2021-08-03T01:47:20.517512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split dataset into train and validation ","metadata":{}},{"cell_type":"code","source":"# train/val\ntrain_text, val_text, train_label, val_label = train_test_split(train['excerpt'], \n                                                                train['target'], \n                                                                random_state=2018, \n                                                                test_size=0.2\n                                                               )\n# test\ntest_text = test['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:21.687631Z","iopub.execute_input":"2021-08-03T01:47:21.688004Z","iopub.status.idle":"2021-08-03T01:47:21.696547Z","shell.execute_reply.started":"2021-08-03T01:47:21.687973Z","shell.execute_reply":"2021-08-03T01:47:21.695605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train shape: ', train_text.shape)\nprint('val shape: ', val_text.shape)\nprint('test shape: ', test_text.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:22.919347Z","iopub.execute_input":"2021-08-03T01:47:22.919797Z","iopub.status.idle":"2021-08-03T01:47:22.933687Z","shell.execute_reply.started":"2021-08-03T01:47:22.919758Z","shell.execute_reply":"2021-08-03T01:47:22.93081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creading dataset","metadata":{}},{"cell_type":"code","source":"# creating our dataset\nclass DRDataset(Dataset):\n    def __init__(self, text_col, label_col, train=True):\n        super().__init__()\n        self.text_col = text_col\n        self.label_col = label_col\n        self.train = train\n\n    def __len__(self):\n        return self.text_col.shape[0] \n\n    def __getitem__(self, index):\n        # get text and label if test use -1 for label\n        text, label = (self.text_col.iloc[index], self.label_col.iloc[index]) if self.train else \\\n                      (self.text_col.iloc[index], -1)\n        \n        # tokenize and encode\n        tokens = tokenizer.encode_plus(\n                    text,\n                    padding='max_length',\n                    max_length=MAX_LENGTH,\n                    truncation=True,\n                    return_token_type_ids=False\n            )\n        \n        # seq, mask, and label to tensor\n        seq = torch.tensor(tokens['input_ids'])\n        mask = torch.tensor(tokens['attention_mask'])\n        y = torch.tensor(label) if self.train else torch.tensor(-1)  \n        \n        return seq, mask, y\n    \n\n# \"\"\"\n# Test if everything works ok\n# \"\"\"\n# dataset = DRDataset(\n#     text_col=train_text,\n#     label_col=train_label,\n#     train=True,\n# )\n# loader = DataLoader(\n#     dataset=dataset, batch_size=32, num_workers=2, shuffle=True, pin_memory=True\n# )\n\n# for seq, mask, y in tqdm(loader):\n#     print(seq.shape[0])\n#     print(mask.shape[0])\n#     print(y.shape[0])\n#     import sys\n#     sys.exit()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:24.252423Z","iopub.execute_input":"2021-08-03T01:47:24.252745Z","iopub.status.idle":"2021-08-03T01:47:24.260669Z","shell.execute_reply.started":"2021-08-03T01:47:24.252716Z","shell.execute_reply":"2021-08-03T01:47:24.259821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loading_data():\n    train_ds = DRDataset(\n            text_col=train_text,\n            label_col=train_label,\n            train=True,\n    )\n    val_ds = DRDataset(\n            text_col=val_text,\n            label_col=val_label,\n            train=True,\n    )\n    test_ds = DRDataset(\n            text_col=test_text,\n            label_col=-1,\n            train=False,\n    )\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        shuffle=True,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=BATCH_SIZE,\n        num_workers=2,\n        pin_memory=PIN_MEMORY,\n        shuffle=True,\n    )\n    test_loader = DataLoader(\n        test_ds, batch_size=BATCH_SIZE, num_workers=6, shuffle=False\n    )\n    \n    return [train_loader,\n            val_loader,\n            test_loader\n           ]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:24.947992Z","iopub.execute_input":"2021-08-03T01:47:24.948369Z","iopub.status.idle":"2021-08-03T01:47:24.957065Z","shell.execute_reply.started":"2021-08-03T01:47:24.948332Z","shell.execute_reply":"2021-08-03T01:47:24.955884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\ndef make_prediction(model, loader, output_csv=\"submission.csv\"):\n    preds = []\n    model.eval()\n\n    for batch in tqdm(loader):\n        batch = [b.to(device=DEVICE) for b in batch]\n        seq, mask, _ = batch\n        \n        with torch.no_grad():\n            pred = model(seq, mask)\n            preds.extend(pred.squeeze(1).cpu().numpy())\n        \n    sample['target'] = preds\n    print(sample.head())\n    sample.to_csv(\"submission.csv\", index=False)\n    \n    model.train()\n    print(\"Done with predictions\")\n    \ndef check_metric(loader, model, data_type, device=\"cuda\"):\n    model.eval()\n    \n    pred_list = []\n    actual_list = []\n        \n    for batch in tqdm(loader):\n        batch = [b.to(device=DEVICE) for b in batch]\n        seq, mask, y = batch\n\n        with torch.no_grad():\n            scores = model(seq, mask)\n        \n        # rmse\n        pred_list.extend(scores.squeeze(1).cpu().numpy())\n        actual_list.extend(y.cpu().numpy())\n    \n    rmse = round(mean_squared_error(actual_list, pred_list)**0.5, 5)\n    r2 = round(r2_score(actual_list, pred_list), 5)\n\n    print(\n        f\"On {data_type} Got  rmse {rmse}\"\n    )\n    \n    print(\n        f\"On {data_type} Got r2 {r2}\"\n    )\n    \n    model.train()\n    return [r2, rmse]\n\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\ndef load_checkpoint(checkpoint, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:26.691105Z","iopub.execute_input":"2021-08-03T01:47:26.691485Z","iopub.status.idle":"2021-08-03T01:47:26.706156Z","shell.execute_reply.started":"2021-08-03T01:47:26.691455Z","shell.execute_reply":"2021-08-03T01:47:26.705076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ndef train_one_epoch(loader, model, optimizer, loss_fn, device):\n    losses = []\n    loop = tqdm(loader)\n\n    for batch_idx, batch in enumerate(loop):\n        \n        batch = [b.to(device, non_blocking=True) for b in batch]        \n        seq, mask, y = batch\n        \n        # forward\n        scores = model(seq, mask)\n        loss = (loss_fn(scores.squeeze(1).float(), y.float())**0.5)\n\n        losses.append(loss.item())\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loop.set_postfix(loss=loss.item())\n        \n    print(f\"Loss average over epoch: {sum(losses)/len(losses)}\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:28.121447Z","iopub.execute_input":"2021-08-03T01:47:28.121773Z","iopub.status.idle":"2021-08-03T01:47:28.12827Z","shell.execute_reply.started":"2021-08-03T01:47:28.121743Z","shell.execute_reply":"2021-08-03T01:47:28.127391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Roberta_Arch(nn.Module):\n    \n    def __init__(self, bert):\n        super(Roberta_Arch, self).__init__()\n        self.bert = bert \n        self.dropout = nn.Dropout(0.1)\n        self.relu =  nn.ReLU()\n        self.fc1 = nn.Linear(768,512)\n        self.fc2 = nn.Linear(512,1)\n\n    def forward(self, sent_id, mask):\n        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n        x = self.fc1(cls_hs)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:47:29.292275Z","iopub.execute_input":"2021-08-03T01:47:29.292618Z","iopub.status.idle":"2021-08-03T01:47:29.299944Z","shell.execute_reply.started":"2021-08-03T01:47:29.292589Z","shell.execute_reply":"2021-08-03T01:47:29.298592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(test_mode=False):\n    \n    train_loader, val_loader, test_loader = loading_data()\n    loss_fn = nn.MSELoss()\n    \n    # import BERT-base pretrained model and freeze all parameters\n    roberta = RobertaModel.from_pretrained(PRETRAINED_MODEL)\n  #  bert = AutoModel.from_pretrained(\"../input/huggingface-bert/bert-base-uncased\")\n    if FREEZE == True:\n        for param in roberta.parameters():  param.requires_grad = False\n        print('pretrained layers frozen')\n            \n    model = Roberta_Arch(roberta)\n    model = model.to(DEVICE)\n    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, betas=BETAS, weight_decay=WEIGHT_DECAY) \n  #  scaler = torch.cuda.amp.GradScaler()\n\n    if LOAD_MODEL:\n        load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n        print(f\"model {CHECKPOINT_FILE} loaded successfully\")\n        # check metric on val\n        check_metric(val_loader, model, 'val', DEVICE)\n\n    if test_mode:\n        make_prediction(model, test_loader)\n        return\n\n    max_metric_val =  {'epoch': float('inf'), 'metric': float('inf')}\n    max_metric_train =  {'epoch': float('inf'), 'metric': float('inf')}\n    \n    for epoch in range(NUM_EPOCHS):\n        train_one_epoch(train_loader, model, optimizer, loss_fn, DEVICE)\n        # get on validation\n        metric_val = check_metric(val_loader, model, 'val', DEVICE)[1]\n        if metric_val < max_metric_val['metric']:\n            max_metric_val['metric'] = metric_val\n            max_metric_val['epoch'] = epoch \n            \n            if SAVE_MODEL:\n                checkpoint = {\n                    \"state_dict\": model.state_dict(),\n                    \"optimizer\": optimizer.state_dict(),\n                }\n             #   save_checkpoint(checkpoint, filename=f\"model.{PRETRAINED_MODEL}.epoch.{epoch}.lr.{LEARNING_RATE}.wd.{WEIGHT_DECAY}.freeze.{FREEZE}.rmse.{round(metric_val, 5)}\")\n                save_checkpoint(checkpoint, filename=f\"model.{PRETRAINED_MODEL}.lr.{LEARNING_RATE}.wd.{WEIGHT_DECAY}.freeze.{FREEZE}\")\n\n        # get on train\n        metric_train = check_metric(train_loader, model, 'train', DEVICE)[1]\n        if metric_train < max_metric_train['metric']:\n            max_metric_train['metric'] = metric_train\n            max_metric_train['epoch'] = epoch \n\n    print(f\"Min rmse on validation: {round(max_metric_val['metric'], 5)} attained in epoch {max_metric_val['epoch']}\")\n    print(f\"Min rmse on training: {round(max_metric_train['metric'], 5)} attained in epoch {max_metric_train['epoch']}\")\n\n    \n    \nmain(test_mode=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T01:48:43.533693Z","iopub.execute_input":"2021-08-03T01:48:43.534076Z","iopub.status.idle":"2021-08-03T02:25:03.80604Z","shell.execute_reply.started":"2021-08-03T01:48:43.53404Z","shell.execute_reply":"2021-08-03T02:25:03.805032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nPretrained model weights frozen\nusing AdamW(model.parameters(), lr = 1e-3)\n0.6951 rmse after 10 epochs\n0.658 rmse after 10 epochs\n0.6403 rmse and r2:  0.5867 after 50 epochs\n\nusing AdamW(model.parameters(), LR=2e-5, betas=(0.9, 0.999), weight_decay=1e-2) \nafter 20 epochs 0.6973 rmse and 0.5099 r2\n\nPretrained model weights not frozen\nafter 11 epoch: 0.5496\ngot 0.549 public score\n\n\npretrained model frozen for 5 epochs\n0.75131 attained in epoch 4\nafter unfreezing 0.54796 after 18 epochs\n\nwith lr 3*10-3 and 3*10-4 very unstable\n\nwith lr 3*10-6 got rmse 0.57861 after 3 epochs\n\nusing roberta got val rmse 0.51861 after 7 epochs\n\n\n'''","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:39:30.046485Z","iopub.execute_input":"2021-07-25T08:39:30.047262Z","iopub.status.idle":"2021-07-25T08:39:30.056405Z","shell.execute_reply.started":"2021-07-25T08:39:30.047211Z","shell.execute_reply":"2021-07-25T08:39:30.055139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}