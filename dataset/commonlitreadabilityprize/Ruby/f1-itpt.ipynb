{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport torch\nimport copy\nimport math\nimport gc\nfrom tqdm import tqdm\nimport torch.utils.data as D\nimport random\nimport os\nfrom transformers import AutoModelWithLMHead, AutoTokenizer,RobertaConfig, RobertaModel,AutoModelForSequenceClassification,AutoModelForMaskedLM\nfrom sklearn.linear_model import LinearRegression, Ridge, ElasticNet,Lasso,RidgeCV,LassoCV\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch import nn\nfrom torch import optim\nimport time\nimport torch.nn.functional as F\nfrom torch.utils.data.dataloader import DataLoader\nfrom transformers import (\n    CONFIG_MAPPING,\n    MODEL_MAPPING,\n    AdamW,\n    AutoConfig,\n    AutoModelForMaskedLM,\n    AutoTokenizer,\n    DataCollatorForLanguageModeling,\n    SchedulerType,\n    get_scheduler,\n    set_seed,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-20T09:00:07.975894Z","iopub.execute_input":"2021-06-20T09:00:07.976316Z","iopub.status.idle":"2021-06-20T09:00:15.651461Z","shell.execute_reply.started":"2021-06-20T09:00:07.976191Z","shell.execute_reply":"2021-06-20T09:00:15.650624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Version changes:\n* roberta base ITPT pretrain","metadata":{}},{"cell_type":"markdown","source":"# parameters for this notebook","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed=777\n    max_len=256\n    batch_size=24\n    lr=2*10**(-5)\n    weight_decay=0.01\n    keep_last_model=True\n    dropout_p=0.1\n    mlm_probability=0.15\n    epochs=5\n    folds=5\n    cv_shuffle=False\n    early_stop_epoch=1000\n    sub_task_weight=1\n    device=torch.device('cuda:0')\n    dtype=torch.float32","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:15.65287Z","iopub.execute_input":"2021-06-20T09:00:15.653185Z","iopub.status.idle":"2021-06-20T09:00:15.659528Z","shell.execute_reply.started":"2021-06-20T09:00:15.65315Z","shell.execute_reply":"2021-06-20T09:00:15.658495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.dtype==torch.float64:\n    torch.set_default_tensor_type(torch.DoubleTensor)\nelse:\n    torch.set_default_tensor_type(torch.FloatTensor)\ntorch.set_default_dtype(CFG.dtype)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:15.661506Z","iopub.execute_input":"2021-06-20T09:00:15.661902Z","iopub.status.idle":"2021-06-20T09:00:15.670084Z","shell.execute_reply.started":"2021-06-20T09:00:15.661856Z","shell.execute_reply":"2021-06-20T09:00:15.669284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(CFG.seed)\nos.environ['PYTHONHASHSEED'] = str(CFG.seed)\nnp.random.seed(CFG.seed)\ntorch.manual_seed(CFG.seed)\ntorch.cuda.manual_seed(CFG.seed)\ntorch.cuda.manual_seed_all(CFG.seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:15.671662Z","iopub.execute_input":"2021-06-20T09:00:15.672098Z","iopub.status.idle":"2021-06-20T09:00:15.682325Z","shell.execute_reply.started":"2021-06-20T09:00:15.67206Z","shell.execute_reply":"2021-06-20T09:00:15.681545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\nres_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:15.683614Z","iopub.execute_input":"2021-06-20T09:00:15.684108Z","iopub.status.idle":"2021-06-20T09:00:15.788314Z","shell.execute_reply.started":"2021-06-20T09:00:15.684032Z","shell.execute_reply":"2021-06-20T09:00:15.787544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers ","metadata":{}},{"cell_type":"code","source":"class RobertaDataset(D.Dataset):\n    def __init__(self, token, target):\n        self.token = token\n        self.target = target\n        \n    def __len__(self):\n        return self.token.shape[0]\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.token[idx].input_ids), \\\n                torch.tensor(self.token[idx].attention_mask), self.target[idx]\n    \ndef collate(batch):\n    ids, attns, targets = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True).to(CFG.device)\n    attns = pad_sequence(attns, batch_first=True).to(CFG.device)\n    targets = torch.tensor(targets).float().to(CFG.device)\n    return ids, attns, targets","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:15.791073Z","iopub.execute_input":"2021-06-20T09:00:15.791331Z","iopub.status.idle":"2021-06-20T09:00:15.800378Z","shell.execute_reply.started":"2021-06-20T09:00:15.791306Z","shell.execute_reply":"2021-06-20T09:00:15.799425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained model","metadata":{}},{"cell_type":"code","source":"name=\"roberta-base\"\nconfig = AutoConfig.from_pretrained(name, output_hidden_states=True,attention_probs_dropout_prob=CFG.dropout_p,hidden_dropout_prob=CFG.dropout_p)\ntokenizer = AutoTokenizer.from_pretrained(name,model_max_length=CFG.max_len)\nmodel = AutoModelForMaskedLM.from_pretrained(name,config=config)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:15.80169Z","iopub.execute_input":"2021-06-20T09:00:15.802029Z","iopub.status.idle":"2021-06-20T09:00:46.914922Z","shell.execute_reply.started":"2021-06-20T09:00:15.801997Z","shell.execute_reply":"2021-06-20T09:00:46.914065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-20T09:00:46.916156Z","iopub.execute_input":"2021-06-20T09:00:46.916482Z","iopub.status.idle":"2021-06-20T09:00:46.926404Z","shell.execute_reply.started":"2021-06-20T09:00:46.916448Z","shell.execute_reply":"2021-06-20T09:00:46.925452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:46.929277Z","iopub.execute_input":"2021-06-20T09:00:46.929638Z","iopub.status.idle":"2021-06-20T09:00:46.939401Z","shell.execute_reply.started":"2021-06-20T09:00:46.929603Z","shell.execute_reply":"2021-06-20T09:00:46.938412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(tokenizer,texts):\n    tokens=[]\n    for text in texts:\n        token=tokenizer(text,max_length=CFG.max_len,truncation=True, padding='max_length',add_special_tokens=True)\n        #print(len(token['input_ids']))\n        tokens.append(token)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:46.941136Z","iopub.execute_input":"2021-06-20T09:00:46.941499Z","iopub.status.idle":"2021-06-20T09:00:46.947382Z","shell.execute_reply.started":"2021-06-20T09:00:46.941464Z","shell.execute_reply":"2021-06-20T09:00:46.946409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['token'] = tokenize(tokenizer,train_df.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:46.94886Z","iopub.execute_input":"2021-06-20T09:00:46.949244Z","iopub.status.idle":"2021-06-20T09:00:49.208653Z","shell.execute_reply.started":"2021-06-20T09:00:46.949207Z","shell.execute_reply":"2021-06-20T09:00:49.207829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=CFG.mlm_probability)\ndata_collator_val = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:49.210031Z","iopub.execute_input":"2021-06-20T09:00:49.210366Z","iopub.status.idle":"2021-06-20T09:00:49.216424Z","shell.execute_reply.started":"2021-06-20T09:00:49.210331Z","shell.execute_reply":"2021-06-20T09:00:49.214039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n        train_df['token'], shuffle=True, collate_fn=data_collator, batch_size=CFG.batch_size\n        )\nval_dataloader = DataLoader(\n        train_df['token'], shuffle=False, collate_fn=data_collator_val, batch_size=CFG.batch_size\n        )","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:49.217579Z","iopub.execute_input":"2021-06-20T09:00:49.217965Z","iopub.status.idle":"2021-06-20T09:00:49.235648Z","shell.execute_reply.started":"2021-06-20T09:00:49.217928Z","shell.execute_reply":"2021-06-20T09:00:49.23479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=model.to(CFG.device)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:49.23695Z","iopub.execute_input":"2021-06-20T09:00:49.238137Z","iopub.status.idle":"2021-06-20T09:00:55.6995Z","shell.execute_reply.started":"2021-06-20T09:00:49.238106Z","shell.execute_reply":"2021-06-20T09:00:55.698654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"\ndef val_rmse(model,target,loader,mode='train'):\n    loss_seq = []\n    pred_seq=[]\n    target_seq=[]\n    if mode=='eval':\n        model.eval()\n    elif mode=='train':\n        model.train()\n    embs=[]\n    for batch in tqdm(loader):\n        batch_={}\n        for key,val in batch.items():\n            batch_[key]=val.to(CFG.device)\n        with torch.no_grad():\n            outputs = model(**batch_)\n        embs.append(outputs['hidden_states'][-1][:,:,:].mean(axis=1))\n    embs=torch.cat(embs,axis=0).to('cpu').numpy()\n    simple_model=RidgeCV(alphas=np.logspace(-3,2,20),cv=5,normalize=True,scoring='neg_mean_squared_error').fit(embs,target)\n    print(np.log10(simple_model.alpha_))\n    rmse=np.sqrt(-simple_model.best_score_)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:55.700951Z","iopub.execute_input":"2021-06-20T09:00:55.701348Z","iopub.status.idle":"2021-06-20T09:00:55.712476Z","shell.execute_reply.started":"2021-06-20T09:00:55.701312Z","shell.execute_reply":"2021-06-20T09:00:55.711638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StateRecorder:\n    def __init__(self):\n        self.best_score=float('inf')\n        self.best_state_dict=None\n        self.best_epoch=0\n        self.stop=False\n        return\n    \n    def record(self,score,epoch,model,keep_last_model=False):\n        if score<self.best_score or keep_last_model:\n            self.best_score=score\n            self.best_state_dict=copy.deepcopy(model.state_dict())\n            self.best_epoch=epoch\n        else:\n            if (epoch-self.best_epoch)>CFG.early_stop_epoch:\n                self.stop=True\n        return","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:55.713766Z","iopub.execute_input":"2021-06-20T09:00:55.714134Z","iopub.status.idle":"2021-06-20T09:00:57.441551Z","shell.execute_reply.started":"2021-06-20T09:00:55.714098Z","shell.execute_reply":"2021-06-20T09:00:57.440486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,train_ldr,target,val_ldr):\n    val_epoch=1\n    epoch_L=len(train_ldr)\n    val_freq=1\n    val_gap=epoch_L//val_freq\n    print(f'validation gap iteration is:{val_gap}')\n    \n    \n    recorder=StateRecorder()\n    optimizer = AdamW(model.parameters(), CFG.lr,\n                            betas=(0.9, 0.999), weight_decay=CFG.weight_decay,correct_bias=True)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs*len(train_ldr),eta_min=0)\n    for i in range(CFG.epochs):      \n        loss_seq = []          \n        for itr,batch in enumerate(train_ldr):\n            model.train()\n            batch_={}\n            for key,val in batch.items():\n                batch_[key]=val.to(CFG.device)\n            outputs = model(**batch_)\n            loss = outputs.loss\n            loss_seq.append(loss.item())\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            scheduler.step()\n            if itr%val_gap==0:\n                val_loss=val_rmse(model, target,val_ldr,mode='train')\n                #val_loss2,_,_ = val_rmse(model, val_ldr,wMSE,mode='eval')\n                recorder.record(val_loss,val_epoch,model,keep_last_model=CFG.keep_last_model)\n                print(f'################  epoch {i+1}   val epoch {val_epoch} #################################')\n                print(f'training loss:{np.mean(loss_seq).round(6)}')\n                print(f'validation rmse (train):{val_loss.round(6)}')\n                val_epoch+=1\n                #scheduler.step(val_loss)\n    torch.cuda.empty_cache()\n    return recorder","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:57.443198Z","iopub.execute_input":"2021-06-20T09:00:57.443629Z","iopub.status.idle":"2021-06-20T09:00:57.456363Z","shell.execute_reply.started":"2021-06-20T09:00:57.443587Z","shell.execute_reply":"2021-06-20T09:00:57.45552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recorder=train(model,train_dataloader,train_df.target,val_dataloader)\nstate_dict=recorder.best_state_dict","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:00:57.459235Z","iopub.execute_input":"2021-06-20T09:00:57.459537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save model state dicts","metadata":{}},{"cell_type":"code","source":"torch.save({'model_state_dict':state_dict},'ITPT_state_dict')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}