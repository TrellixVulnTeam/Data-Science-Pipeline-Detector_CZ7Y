{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport torch\nimport copy\nimport math\nimport gc\nfrom tqdm import tqdm\nimport torch.utils.data as D\nimport random\nimport os\nfrom transformers import AutoModelWithLMHead, AutoTokenizer,RobertaConfig, RobertaModel,AutoModelForSequenceClassification,AutoModelForMaskedLM\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch import nn\nfrom torch import optim\nimport time\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoModel,\n    CONFIG_MAPPING,\n    MODEL_MAPPING,\n    AdamW,\n    AutoConfig,\n    AutoModelForMaskedLM,\n    AutoTokenizer,\n    DataCollatorForLanguageModeling,\n    SchedulerType,\n    get_scheduler,\n    set_seed,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-08T17:09:42.107014Z","iopub.execute_input":"2021-07-08T17:09:42.10756Z","iopub.status.idle":"2021-07-08T17:09:51.680241Z","shell.execute_reply.started":"2021-07-08T17:09:42.10743Z","shell.execute_reply":"2021-07-08T17:09:51.677695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Version changes:\n* roberta base train with ITPT weights\n* bs 32 \n* fix oom\n* fix possible token id change\n* add reinit code","metadata":{}},{"cell_type":"markdown","source":"# parameters for this notebook","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed=777\n    path='roberta-base'\n    checkpoint='f1-itpt'\n    max_len=256\n    batch_size=32\n    lr=8e-5\n    betas=(0.9, 0.999)\n    lr_diff_rate=0.9\n    weight_decay=0.01\n    dropout_p=0.1\n    initializer=None\n    re_init_n=0\n    epochs=5\n    folds=5\n    cv_shuffle=False\n    val_freq=10\n    patience=1\n    lr_factor=0.1\n    score_avg_n=1\n    pad_token_id=1\n    early_stop_epoch=1000\n    device=torch.device('cuda:0')\n    dtype=torch.float32","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.686241Z","iopub.execute_input":"2021-07-08T17:09:51.68896Z","iopub.status.idle":"2021-07-08T17:09:51.701341Z","shell.execute_reply.started":"2021-07-08T17:09:51.688911Z","shell.execute_reply":"2021-07-08T17:09:51.699789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.dtype==torch.float64:\n    torch.set_default_tensor_type(torch.DoubleTensor)\nelse:\n    torch.set_default_tensor_type(torch.FloatTensor)\ntorch.set_default_dtype(CFG.dtype)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.70806Z","iopub.execute_input":"2021-07-08T17:09:51.711412Z","iopub.status.idle":"2021-07-08T17:09:51.720108Z","shell.execute_reply.started":"2021-07-08T17:09:51.711365Z","shell.execute_reply":"2021-07-08T17:09:51.718576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(CFG.seed)\nos.environ['PYTHONHASHSEED'] = str(CFG.seed)\nnp.random.seed(CFG.seed)\ntorch.manual_seed(CFG.seed)\ntorch.cuda.manual_seed(CFG.seed)\ntorch.cuda.manual_seed_all(CFG.seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.726598Z","iopub.execute_input":"2021-07-08T17:09:51.729771Z","iopub.status.idle":"2021-07-08T17:09:51.744143Z","shell.execute_reply.started":"2021-07-08T17:09:51.729726Z","shell.execute_reply":"2021-07-08T17:09:51.742609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\nres_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.749728Z","iopub.execute_input":"2021-07-08T17:09:51.752395Z","iopub.status.idle":"2021-07-08T17:09:51.861234Z","shell.execute_reply.started":"2021-07-08T17:09:51.752318Z","shell.execute_reply":"2021-07-08T17:09:51.860168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers ","metadata":{}},{"cell_type":"code","source":"def CV_split(m,k=5,shuffle=False,seed=7):\n    index=np.arange(m)\n    if shuffle:\n        np.random.seed(seed)\n        np.random.shuffle(index)\n    test_size=math.ceil(m/k)\n    split_indices=[]\n    for i in range(k):\n        bool_index=np.zeros(m)\n        bool_index[test_size*i:test_size*(i+1)]=1\n        bool_index=bool_index.astype('bool')\n        val_index=index[bool_index]\n        train_index=index[~bool_index]\n        split_indices.append((train_index,val_index))\n    return split_indices\n\ndef score_test(model,test_ldr):\n    print('start eval')\n    model.eval()\n    preds=[]\n    for texts, attns, idx in tqdm(test_ldr):\n        with torch.no_grad():\n            pred = model(texts,attns)\n            preds.append(pred)\n    preds=torch.cat(preds,axis=0)\n    preds=preds.to('cpu').numpy().reshape(-1)\n    return preds\n    \ndef rmse(y1,y2):\n    score=np.sqrt(((y1-y2)**2).mean())\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.862898Z","iopub.execute_input":"2021-07-08T17:09:51.863331Z","iopub.status.idle":"2021-07-08T17:09:51.876753Z","shell.execute_reply.started":"2021-07-08T17:09:51.863285Z","shell.execute_reply":"2021-07-08T17:09:51.875547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaDataset(D.Dataset):\n    def __init__(self, token, target):\n        self.token = token\n        self.target = target\n        \n    def __len__(self):\n        return self.token.shape[0]\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.token[idx].input_ids), \\\n                torch.tensor(self.token[idx].attention_mask), self.target[idx]\n    \ndef collate(batch):\n    ids, attns, targets = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True,padding_value=CFG.pad_token_id).to(CFG.device)\n    attns = pad_sequence(attns, batch_first=True,padding_value=CFG.pad_token_id).to(CFG.device)\n    targets = torch.tensor(targets).float().to(CFG.device)\n    return ids, attns, targets\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.878732Z","iopub.execute_input":"2021-07-08T17:09:51.879056Z","iopub.status.idle":"2021-07-08T17:09:51.89819Z","shell.execute_reply.started":"2021-07-08T17:09:51.879009Z","shell.execute_reply":"2021-07-08T17:09:51.897124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained model","metadata":{}},{"cell_type":"code","source":"path=CFG.path\nconfig = AutoConfig.from_pretrained(path, output_hidden_states=True,attention_probs_dropout_prob=CFG.dropout_p,hidden_dropout_prob=CFG.dropout_p)\ntokenizer = AutoTokenizer.from_pretrained(path,model_max_length=CFG.max_len)\nCFG.pad_token_id=tokenizer.pad_token_id\nmodel = AutoModelForMaskedLM.from_pretrained(path,config=config)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:09:51.90007Z","iopub.execute_input":"2021-07-08T17:09:51.900587Z","iopub.status.idle":"2021-07-08T17:10:30.10599Z","shell.execute_reply.started":"2021-07-08T17:09:51.900532Z","shell.execute_reply":"2021-07-08T17:10:30.104874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD state dict with IPTP","metadata":{}},{"cell_type":"code","source":"if CFG.checkpoint is not None:\n    checkpoint=torch.load('../input/'+CFG.checkpoint+'/ITPT_state_dict',map_location=CFG.device)\n    model.load_state_dict(checkpoint['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:30.110356Z","iopub.execute_input":"2021-07-08T17:10:30.110827Z","iopub.status.idle":"2021-07-08T17:10:45.211193Z","shell.execute_reply.started":"2021-07-08T17:10:30.110744Z","shell.execute_reply":"2021-07-08T17:10:45.210132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save init model","metadata":{}},{"cell_type":"code","source":"config.save_pretrained('model_init')\nmodel.save_pretrained('model_init')\ntokenizer.save_pretrained('model_init')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:45.213709Z","iopub.execute_input":"2021-07-08T17:10:45.214141Z","iopub.status.idle":"2021-07-08T17:10:46.141741Z","shell.execute_reply.started":"2021-07-08T17:10:45.214104Z","shell.execute_reply":"2021-07-08T17:10:46.140374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-08T17:10:46.14348Z","iopub.execute_input":"2021-07-08T17:10:46.143919Z","iopub.status.idle":"2021-07-08T17:10:46.277306Z","shell.execute_reply.started":"2021-07-08T17:10:46.143873Z","shell.execute_reply":"2021-07-08T17:10:46.275697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:46.279558Z","iopub.execute_input":"2021-07-08T17:10:46.28054Z","iopub.status.idle":"2021-07-08T17:10:46.291889Z","shell.execute_reply.started":"2021-07-08T17:10:46.28049Z","shell.execute_reply":"2021-07-08T17:10:46.289311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(tokenizer,texts):\n    tokens=[]\n    for text in texts:\n        token=tokenizer(text,max_length=CFG.max_len,truncation=True, padding='max_length',add_special_tokens=True)\n        #print(len(token['input_ids']))\n        tokens.append(token)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:46.294267Z","iopub.execute_input":"2021-07-08T17:10:46.295187Z","iopub.status.idle":"2021-07-08T17:10:46.312471Z","shell.execute_reply.started":"2021-07-08T17:10:46.295067Z","shell.execute_reply":"2021-07-08T17:10:46.307836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['token'] = tokenize(tokenizer,train_df.excerpt)\ntest_df['token'] = tokenize(tokenizer,test_df.excerpt)\n\nds1 = RobertaDataset(train_df.token, train_df.target)\nds2 = RobertaDataset(test_df.token, test_df.index)\n\ntest_ldr = D.DataLoader(ds2, batch_size=CFG.batch_size,\n                        shuffle=False, collate_fn = collate,num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:46.316783Z","iopub.execute_input":"2021-07-08T17:10:46.323067Z","iopub.status.idle":"2021-07-08T17:10:49.556451Z","shell.execute_reply.started":"2021-07-08T17:10:46.323017Z","shell.execute_reply":"2021-07-08T17:10:49.555318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# My Model with additional layers","metadata":{}},{"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self, model):\n        super(MyModel, self).__init__()\n        self.model = model\n        self.output_layer = nn.Linear(768,1)\n        \n    def forward(self, text,attention_mask):\n        x1 = self.model(text,attention_mask)\n        last_hidden_state = x1['hidden_states'][-1]\n        text_emb=last_hidden_state.mean(axis=1)\n        x2=self.model.lm_head.dense(text_emb)\n        x3=self.output_layer(x2)\n        return x3","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.557985Z","iopub.execute_input":"2021-07-08T17:10:49.558415Z","iopub.status.idle":"2021-07-08T17:10:49.569203Z","shell.execute_reply.started":"2021-07-08T17:10:49.558375Z","shell.execute_reply":"2021-07-08T17:10:49.567949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=MyModel(model)\ninit_state=copy.deepcopy(model.state_dict())","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.57102Z","iopub.execute_input":"2021-07-08T17:10:49.571712Z","iopub.status.idle":"2021-07-08T17:10:49.920466Z","shell.execute_reply.started":"2021-07-08T17:10:49.571666Z","shell.execute_reply":"2021-07-08T17:10:49.919384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef val_rmse(model,loader, f_loss,mode='train'):\n    loss_seq = []\n    pred_seq=[]\n    target_seq=[]\n    if mode=='eval':\n        model.eval()\n    elif mode=='train':\n        model.train()\n    for texts, attns, target in loader:\n        pred = model(texts, attention_mask=attns).reshape(-1)\n        loss = f_loss(pred, target).item()\n        loss_seq.append(loss)\n        pred_seq.append(pred.to('cpu').numpy())\n        target_seq.append(target.to('cpu').numpy())\n    loss = np.sqrt(np.array(loss_seq).mean())\n    pred=np.concatenate(pred_seq)\n    target=np.concatenate(target_seq)\n    return loss,pred,target","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.921984Z","iopub.execute_input":"2021-07-08T17:10:49.922396Z","iopub.status.idle":"2021-07-08T17:10:49.933135Z","shell.execute_reply.started":"2021-07-08T17:10:49.922352Z","shell.execute_reply":"2021-07-08T17:10:49.931783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StateRecorder:\n    def __init__(self):\n        self.best_score=float('inf')\n        self.best_state_dict=None\n        self.best_epoch=0\n        self.stop=False\n        self.scores=[]\n        self.cv_scores=[]\n        return\n    \n    def record(self,score,epoch,model):\n        self.scores.append(score)\n        avg_score=np.mean(self.scores[-CFG.score_avg_n:])\n        self.cv_scores.append(avg_score)\n        print(f'average({CFG.score_avg_n}) validation (train) rmse:{avg_score.round(6)}')\n        if avg_score<self.best_score:\n            self.best_score=avg_score\n            self.best_state_dict={}\n            for k,v in model.state_dict().items():\n                self.best_state_dict[k] = v.cpu()\n            self.best_epoch=epoch\n        else:\n            if (epoch-self.best_epoch)>CFG.early_stop_epoch:\n                self.stop=True\n        return","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.935214Z","iopub.execute_input":"2021-07-08T17:10:49.935836Z","iopub.status.idle":"2021-07-08T17:10:49.948696Z","shell.execute_reply.started":"2021-07-08T17:10:49.935792Z","shell.execute_reply":"2021-07-08T17:10:49.947551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_group_parameters(model,lr,lr_diff_rate=1,weight_decay=0.01):\n    init_lr=1\n    last_layer=-1\n    opt_params=[]\n    for name,matrix in model.named_parameters():\n        info=name.split('.')\n        params_dict={'params':matrix}\n        ###############################\n#         if info[-1]=='bias':\n#             params_dict['weight_decay']=0\n#         else:\n        params_dict['weight_decay']=weight_decay\n#         ###############################\n        if len(info)>=5 and info[2]=='encoder':\n            layer=int(info[4])\n            if layer!=last_layer:\n                last_layer=layer\n                init_lr/=lr_diff_rate\n        params_dict['lr']=init_lr\n        opt_params.append(params_dict)\n    scale=lr/init_lr\n    for params_dict in opt_params:\n        params_dict['lr']*=scale\n    return opt_params","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.950357Z","iopub.execute_input":"2021-07-08T17:10:49.951147Z","iopub.status.idle":"2021-07-08T17:10:49.96156Z","shell.execute_reply.started":"2021-07-08T17:10:49.951056Z","shell.execute_reply":"2021-07-08T17:10:49.959986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def re_init(model,n=4,initializer=None):\n    # plz modify name here based on model\n    if n==0:\n        return\n    if initializer is None:\n        initializer=nn.init.kaiming_normal_\n    for layer in model.model.roberta.encoder.layer[-n:]:\n        for module in layer.modules(): \n            if isinstance(module, nn.Linear):\n                initializer(module.weight)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.LayerNorm):\n                nn.init.zeros_(module.bias)\n                nn.init.ones_(module.weight)\n    return","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.963662Z","iopub.execute_input":"2021-07-08T17:10:49.964225Z","iopub.status.idle":"2021-07-08T17:10:49.975938Z","shell.execute_reply.started":"2021-07-08T17:10:49.964179Z","shell.execute_reply":"2021-07-08T17:10:49.974961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,train_ldr,val_ldr,fold):\n    epoch_res=[]\n    val_epoch=1\n    epoch_L=len(train_ldr)\n    val_freq=CFG.val_freq\n    val_gap=epoch_L//val_freq\n    print(f'validation gap iteration is:{val_gap}')\n    \n    mse= torch.nn.MSELoss()\n    \n    recorder=StateRecorder()\n    re_init(model,n=CFG.re_init_n,initializer=CFG.initializer)\n    opt_params=get_group_parameters(model,CFG.lr,CFG.lr_diff_rate,CFG.weight_decay)\n    optimizer = AdamW(opt_params,correct_bias=True)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs*len(train_ldr),eta_min=0)\n    for i in range(CFG.epochs):      \n        start_time = time.time()\n        loss_seq = []          \n        for itr,(texts, attns, target) in enumerate(train_ldr):\n            model.train()\n            outputs = model(texts, attention_mask=attns)\n            loss = mse(outputs.reshape(-1), target)\n            loss_seq.append(loss.item())\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            scheduler.step()\n            if itr%val_gap==0:\n                val_loss,pred,target = val_rmse(model, val_ldr,mse,mode='train')\n                val_loss2,_,_ = 0,None,None#val_rmse(model, val_ldr,mse,mode='eval')\n                \n                res=pd.DataFrame()\n                res['target']=target\n                res['pred']=pred\n                res['fold']=fold\n                res['epoch']=val_epoch\n                epoch_res.append(res)\n                print(f'################  epoch {i+1}   val epoch {val_epoch} #################################')\n                print(f'training rmse:{np.sqrt(np.mean(loss_seq)).round(6)}')\n                print(f'validation rmse (train):{val_loss.round(6)}')#  (eval):{val_loss2.round(6)}')\n                recorder.record(val_loss,val_epoch,model)\n                \n                val_epoch+=1\n                #scheduler.step(recorder.cv_scores[-1])\n    torch.cuda.empty_cache()\n    fold_res=pd.concat(epoch_res,axis=0).reset_index(drop=True)\n    fold_res['is_best_epoch']=False\n    fold_res.loc[fold_res[fold_res.epoch==recorder.best_epoch].index,'is_best_epoch']=True\n    return fold_res,recorder","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:49.977847Z","iopub.execute_input":"2021-07-08T17:10:49.978451Z","iopub.status.idle":"2021-07-08T17:10:49.999776Z","shell.execute_reply.started":"2021-07-08T17:10:49.978409Z","shell.execute_reply":"2021-07-08T17:10:49.998037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_indices=CV_split(len(train_df),k=CFG.folds,shuffle=CFG.cv_shuffle,seed=7)\nmodels=[]\ncv_res=[]\nfor fold in range(1,CFG.folds+1):\n    print(f'fold {fold}')\n    train_index,val_index=split_indices[fold-1]\n    train_ds=D.Subset(ds1, train_index)\n    valid_ds = D.Subset(ds1, val_index)\n    ################\n    random.seed(CFG.seed)\n    os.environ['PYTHONHASHSEED'] = str(CFG.seed)\n    np.random.seed(CFG.seed)\n    torch.manual_seed(CFG.seed)\n    torch.cuda.manual_seed(CFG.seed)\n    torch.cuda.manual_seed_all(CFG.seed)\n    torch.backends.cudnn.deterministic = True\n    ##################\n    train_ldr = D.DataLoader(train_ds, batch_size=CFG.batch_size,\n                             shuffle=True, collate_fn = collate,num_workers=0)\n    val_ldr = D.DataLoader(valid_ds, batch_size=CFG.batch_size,\n                           shuffle=False, collate_fn = collate,num_workers=0)\n    \n    model.load_state_dict(init_state)\n    model.to(CFG.device)\n    fold_res,recorder=train(model,train_ldr,val_ldr,fold)\n    print(f'best epoch: {recorder.best_epoch} with best rmse:{recorder.best_score}')\n    cv_res.append(fold_res)\n    preds=score_test(model,test_ldr)\n    test_df[f'fold {fold} preds']=preds\n    torch.save({'model_state_dict':recorder.best_state_dict},f'fold_{fold}_model')\n    del recorder\n    gc.collect()\ncv_res=pd.concat(cv_res,axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T17:10:50.00195Z","iopub.execute_input":"2021-07-08T17:10:50.002596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# deeper Look into oof_pred","metadata":{}},{"cell_type":"code","source":"cv_res['ae']=np.abs(cv_res.target-cv_res.pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* oof score for each epoch","metadata":{}},{"cell_type":"code","source":"rmse_curve=[]\nfor epoch in range(1,cv_res.epoch.max()+1):\n    epoch_data=cv_res[cv_res.epoch==epoch].reset_index(drop=True)\n    score=rmse(epoch_data.pred,epoch_data.target)\n    rmse_curve.append(score)\n    print(f'abs error auto correlation: {epoch_data.ae.autocorr()}')\n    print(f'epoch {epoch} rmse: {score} oof pred error std:{np.std(epoch_data.ae)/np.sqrt(len(epoch_data))}')\nplt.plot(rmse_curve)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* best oof score","metadata":{}},{"cell_type":"code","source":"epoch_data=cv_res[cv_res.is_best_epoch==True].reset_index(drop=True)\nrmse(epoch_data.pred,epoch_data.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds=0\nfor i in range(CFG.folds):\n    final_preds+=test_df[f'fold {i+1} preds']/CFG.folds\nres_df['target']=final_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}