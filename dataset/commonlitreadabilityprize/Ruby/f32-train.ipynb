{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport torch\nimport copy\nimport math\nimport gc\nfrom tqdm import tqdm\nimport torch.utils.data as D\nimport random\nimport os\nfrom transformers import AutoModelWithLMHead, AutoTokenizer,RobertaConfig, RobertaModel,AutoModelForSequenceClassification,AutoModelForMaskedLM\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch import nn\nfrom torch import optim\nimport time\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoModel,\n    CONFIG_MAPPING,\n    MODEL_MAPPING,\n    AdamW,\n    AutoConfig,\n    AutoModelForMaskedLM,\n    AutoTokenizer,\n    DataCollatorForLanguageModeling,\n    SchedulerType,\n    get_scheduler,\n    set_seed,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T14:49:57.0105Z","iopub.execute_input":"2021-07-11T14:49:57.011176Z","iopub.status.idle":"2021-07-11T14:50:06.868228Z","shell.execute_reply.started":"2021-07-11T14:49:57.011094Z","shell.execute_reply":"2021-07-11T14:50:06.867153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Version changes:\n* deberta large\n* seed 12222\n* no re init\n* bs 4\n* grad accum 2 lr 2\n* 1 linear layer","metadata":{}},{"cell_type":"markdown","source":"# parameters for this notebook","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed=12222\n    path='microsoft/deberta-large'\n    checkpoint=None\n    max_len=256\n    batch_size=4\n    grad_avg_n=2\n    lr=2e-5\n    betas=(0.9, 0.999)\n    lr_diff_rate=0.95\n    weight_decay=0.01\n    dropout_p=0.1\n    initializer=None\n    re_init_n=0\n    epochs=5\n    folds=5\n    cv_shuffle=False\n    val_freq=10\n    patience=1\n    lr_factor=0.1\n    score_avg_n=1\n    pad_token_id=1\n    early_stop_epoch=1000\n    device=torch.device('cuda:0')\n    dtype=torch.float32","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:06.869966Z","iopub.execute_input":"2021-07-11T14:50:06.870357Z","iopub.status.idle":"2021-07-11T14:50:06.880457Z","shell.execute_reply.started":"2021-07-11T14:50:06.870317Z","shell.execute_reply":"2021-07-11T14:50:06.878816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.dtype==torch.float64:\n    torch.set_default_tensor_type(torch.DoubleTensor)\nelse:\n    torch.set_default_tensor_type(torch.FloatTensor)\ntorch.set_default_dtype(CFG.dtype)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:06.883781Z","iopub.execute_input":"2021-07-11T14:50:06.884288Z","iopub.status.idle":"2021-07-11T14:50:06.894329Z","shell.execute_reply.started":"2021-07-11T14:50:06.884228Z","shell.execute_reply":"2021-07-11T14:50:06.892943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(CFG.seed)\nos.environ['PYTHONHASHSEED'] = str(CFG.seed)\nnp.random.seed(CFG.seed)\ntorch.manual_seed(CFG.seed)\ntorch.cuda.manual_seed(CFG.seed)\ntorch.cuda.manual_seed_all(CFG.seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:06.896679Z","iopub.execute_input":"2021-07-11T14:50:06.897525Z","iopub.status.idle":"2021-07-11T14:50:06.910038Z","shell.execute_reply.started":"2021-07-11T14:50:06.897386Z","shell.execute_reply":"2021-07-11T14:50:06.908948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\nres_df=pd.read_csv('/kaggle/input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:06.911636Z","iopub.execute_input":"2021-07-11T14:50:06.912228Z","iopub.status.idle":"2021-07-11T14:50:07.00024Z","shell.execute_reply.started":"2021-07-11T14:50:06.912191Z","shell.execute_reply":"2021-07-11T14:50:06.999258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers ","metadata":{}},{"cell_type":"code","source":"def CV_split(m,k=5,shuffle=False,seed=7):\n    index=np.arange(m)\n    if shuffle:\n        np.random.seed(seed)\n        np.random.shuffle(index)\n    test_size=math.ceil(m/k)\n    split_indices=[]\n    for i in range(k):\n        bool_index=np.zeros(m)\n        bool_index[test_size*i:test_size*(i+1)]=1\n        bool_index=bool_index.astype('bool')\n        val_index=index[bool_index]\n        train_index=index[~bool_index]\n        split_indices.append((train_index,val_index))\n    return split_indices\n\ndef score_test(model,test_ldr):\n    print('start eval')\n    model.eval()\n    preds=[]\n    for texts, attns, idx in tqdm(test_ldr):\n        with torch.no_grad():\n            pred = model(texts,attns)\n            preds.append(pred)\n    preds=torch.cat(preds,axis=0)\n    preds=preds.to('cpu').numpy().reshape(-1)\n    return preds\n    \ndef rmse(y1,y2):\n    score=np.sqrt(((y1-y2)**2).mean())\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:07.003907Z","iopub.execute_input":"2021-07-11T14:50:07.004197Z","iopub.status.idle":"2021-07-11T14:50:07.014658Z","shell.execute_reply.started":"2021-07-11T14:50:07.004168Z","shell.execute_reply":"2021-07-11T14:50:07.013185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaDataset(D.Dataset):\n    def __init__(self, token, target):\n        self.token = token\n        self.target = target\n        \n    def __len__(self):\n        return self.token.shape[0]\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.token[idx].input_ids), \\\n                torch.tensor(self.token[idx].attention_mask), self.target[idx]\n    \ndef collate(batch):\n    ids, attns, targets = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True,padding_value=CFG.pad_token_id).to(CFG.device)\n    attns = pad_sequence(attns, batch_first=True,padding_value=CFG.pad_token_id).to(CFG.device)\n    targets = torch.tensor(targets).float().to(CFG.device)\n    return ids, attns, targets\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:07.016424Z","iopub.execute_input":"2021-07-11T14:50:07.017237Z","iopub.status.idle":"2021-07-11T14:50:07.032051Z","shell.execute_reply.started":"2021-07-11T14:50:07.01719Z","shell.execute_reply":"2021-07-11T14:50:07.030633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained model","metadata":{}},{"cell_type":"code","source":"path=CFG.path\nconfig = AutoConfig.from_pretrained(path, output_hidden_states=True,attention_probs_dropout_prob=CFG.dropout_p,hidden_dropout_prob=CFG.dropout_p)\ntokenizer = AutoTokenizer.from_pretrained(path,model_max_length=CFG.max_len)\nCFG.pad_token_id=tokenizer.pad_token_id\nmodel = AutoModel.from_pretrained(path,config=config)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:50:07.037386Z","iopub.execute_input":"2021-07-11T14:50:07.037825Z","iopub.status.idle":"2021-07-11T14:51:42.787599Z","shell.execute_reply.started":"2021-07-11T14:50:07.037796Z","shell.execute_reply":"2021-07-11T14:51:42.786418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD state dict with IPTP","metadata":{}},{"cell_type":"code","source":"if CFG.checkpoint is not None:\n    checkpoint=torch.load('../input/'+CFG.checkpoint+'/ITPT_state_dict',map_location=CFG.device)\n    model.load_state_dict(checkpoint['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:42.790178Z","iopub.execute_input":"2021-07-11T14:51:42.790661Z","iopub.status.idle":"2021-07-11T14:51:42.796892Z","shell.execute_reply.started":"2021-07-11T14:51:42.790585Z","shell.execute_reply":"2021-07-11T14:51:42.795168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save init model","metadata":{}},{"cell_type":"code","source":"config.save_pretrained('model_init')\nmodel.save_pretrained('model_init')\ntokenizer.save_pretrained('model_init')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:42.798758Z","iopub.execute_input":"2021-07-11T14:51:42.799581Z","iopub.status.idle":"2021-07-11T14:51:46.113154Z","shell.execute_reply.started":"2021-07-11T14:51:42.79949Z","shell.execute_reply":"2021-07-11T14:51:46.111854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-11T14:51:46.118451Z","iopub.execute_input":"2021-07-11T14:51:46.121336Z","iopub.status.idle":"2021-07-11T14:51:46.146664Z","shell.execute_reply.started":"2021-07-11T14:51:46.121284Z","shell.execute_reply":"2021-07-11T14:51:46.145767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:46.15625Z","iopub.execute_input":"2021-07-11T14:51:46.157457Z","iopub.status.idle":"2021-07-11T14:51:47.07171Z","shell.execute_reply.started":"2021-07-11T14:51:46.157409Z","shell.execute_reply":"2021-07-11T14:51:47.070564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(tokenizer,texts):\n    tokens=[]\n    for text in texts:\n        token=tokenizer(text,max_length=CFG.max_len,truncation=True, padding='max_length',add_special_tokens=True)\n        #print(len(token['input_ids']))\n        tokens.append(token)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:47.07334Z","iopub.execute_input":"2021-07-11T14:51:47.073846Z","iopub.status.idle":"2021-07-11T14:51:48.208934Z","shell.execute_reply.started":"2021-07-11T14:51:47.07379Z","shell.execute_reply":"2021-07-11T14:51:48.20755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['token'] = tokenize(tokenizer,train_df.excerpt)\ntest_df['token'] = tokenize(tokenizer,test_df.excerpt)\n\nds1 = RobertaDataset(train_df.token, train_df.target)\nds2 = RobertaDataset(test_df.token, test_df.index)\n\ntest_ldr = D.DataLoader(ds2, batch_size=CFG.batch_size,\n                        shuffle=False, collate_fn = collate,num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:48.214541Z","iopub.execute_input":"2021-07-11T14:51:48.215239Z","iopub.status.idle":"2021-07-11T14:51:58.268338Z","shell.execute_reply.started":"2021-07-11T14:51:48.215179Z","shell.execute_reply":"2021-07-11T14:51:58.267237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# My Model with additional layers","metadata":{}},{"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self, model):\n        super(MyModel, self).__init__()\n        self.model = model\n        self.linear1=nn.Linear(1024,1)\n        \n    def forward(self, text,attention_mask):\n        x1 = self.model(text,attention_mask)\n        last_hidden_state = x1['hidden_states'][-1]\n        text_emb=last_hidden_state.mean(axis=1)\n        x2=self.linear1(text_emb)\n        return x2","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:58.269834Z","iopub.execute_input":"2021-07-11T14:51:58.270239Z","iopub.status.idle":"2021-07-11T14:51:58.280998Z","shell.execute_reply.started":"2021-07-11T14:51:58.270197Z","shell.execute_reply":"2021-07-11T14:51:58.279267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=MyModel(model)\ninit_state=copy.deepcopy(model.state_dict())","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:58.283252Z","iopub.execute_input":"2021-07-11T14:51:58.283814Z","iopub.status.idle":"2021-07-11T14:51:59.434508Z","shell.execute_reply.started":"2021-07-11T14:51:58.283769Z","shell.execute_reply":"2021-07-11T14:51:59.433342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef val_rmse(model,loader, f_loss,mode='train'):\n    loss_seq = []\n    pred_seq=[]\n    target_seq=[]\n    if mode=='eval':\n        model.eval()\n    elif mode=='train':\n        model.train()\n    for texts, attns, target in loader:\n        pred = model(texts, attention_mask=attns).reshape(-1)\n        loss = f_loss(pred, target).item()\n        loss_seq.append(loss)\n        pred_seq.append(pred.to('cpu').numpy())\n        target_seq.append(target.to('cpu').numpy())\n    loss = np.sqrt(np.array(loss_seq).mean())\n    pred=np.concatenate(pred_seq)\n    target=np.concatenate(target_seq)\n    return loss,pred,target","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:59.436335Z","iopub.execute_input":"2021-07-11T14:51:59.437109Z","iopub.status.idle":"2021-07-11T14:51:59.447408Z","shell.execute_reply.started":"2021-07-11T14:51:59.43704Z","shell.execute_reply":"2021-07-11T14:51:59.44601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StateRecorder:\n    def __init__(self):\n        self.best_score=float('inf')\n        self.best_state_dict=None\n        self.best_epoch=0\n        self.stop=False\n        self.scores=[]\n        self.cv_scores=[]\n        return\n    \n    def record(self,score,epoch,model):\n        self.scores.append(score)\n        avg_score=np.mean(self.scores[-CFG.score_avg_n:])\n        self.cv_scores.append(avg_score)\n        print(f'average({CFG.score_avg_n}) validation (train) rmse:{avg_score.round(6)}')\n        if avg_score<self.best_score:\n            self.best_score=avg_score\n            self.best_state_dict={}\n            for k,v in model.state_dict().items():\n                self.best_state_dict[k] = v.cpu()\n            self.best_epoch=epoch\n        else:\n            if (epoch-self.best_epoch)>CFG.early_stop_epoch:\n                self.stop=True\n        return","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:59.449225Z","iopub.execute_input":"2021-07-11T14:51:59.449705Z","iopub.status.idle":"2021-07-11T14:51:59.464203Z","shell.execute_reply.started":"2021-07-11T14:51:59.449645Z","shell.execute_reply":"2021-07-11T14:51:59.463021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_group_parameters(model,lr,lr_diff_rate=1,weight_decay=0.01):\n    init_lr=1\n    last_layer=-1\n    opt_params=[]\n    for name,matrix in model.named_parameters():\n        info=name.split('.')\n        params_dict={'params':matrix}\n        ###############################\n#         if info[-1]=='bias':\n#             params_dict['weight_decay']=0\n#         else:\n        params_dict['weight_decay']=weight_decay\n#         ###############################\n        if len(info)>=4 and info[1]=='encoder' and info[2]=='layer':\n            layer=int(info[3])\n            if layer!=last_layer:\n                last_layer=layer\n                init_lr/=lr_diff_rate\n        params_dict['lr']=init_lr\n        opt_params.append(params_dict)\n    scale=lr/init_lr\n    for params_dict in opt_params:\n        params_dict['lr']*=scale\n    return opt_params","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:59.46588Z","iopub.execute_input":"2021-07-11T14:51:59.466471Z","iopub.status.idle":"2021-07-11T14:51:59.477369Z","shell.execute_reply.started":"2021-07-11T14:51:59.466424Z","shell.execute_reply":"2021-07-11T14:51:59.476345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def re_init(model,n=4,initializer=None):\n    # plz modify name here based on model\n    if n==0:\n        return\n    if initializer is None:\n        initializer=nn.init.kaiming_normal_\n    for layer in model.model.encoder.layer[-n:]:\n        for module in layer.modules(): \n            if isinstance(module, nn.Linear):\n                initializer(module.weight)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.LayerNorm):\n                nn.init.zeros_(module.bias)\n                nn.init.ones_(module.weight)\n    return","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:59.479213Z","iopub.execute_input":"2021-07-11T14:51:59.479754Z","iopub.status.idle":"2021-07-11T14:51:59.492823Z","shell.execute_reply.started":"2021-07-11T14:51:59.479707Z","shell.execute_reply":"2021-07-11T14:51:59.491532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,train_ldr,val_ldr,fold):\n    epoch_res=[]\n    val_epoch=1\n    epoch_L=len(train_ldr)\n    val_freq=CFG.val_freq\n    val_gap=epoch_L//val_freq\n    print(f'validation gap iteration is:{val_gap}')\n    \n    mse= torch.nn.MSELoss()\n    \n    recorder=StateRecorder()\n    re_init(model,n=CFG.re_init_n,initializer=CFG.initializer)\n    opt_params=get_group_parameters(model,CFG.lr,CFG.lr_diff_rate,CFG.weight_decay)\n    optimizer = AdamW(opt_params,correct_bias=True)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(CFG.epochs*len(train_ldr))//CFG.grad_avg_n,eta_min=0)\n    total_iter=0\n    for i in range(CFG.epochs):      \n        start_time = time.time()\n        loss_seq = []          \n        for itr,(texts, attns, target) in enumerate(train_ldr):\n            model.train()\n            outputs = model(texts, attention_mask=attns)\n            loss = mse(outputs.reshape(-1), target)/CFG.grad_avg_n\n            loss_seq.append(loss.item()*CFG.grad_avg_n)\n            loss.backward()\n            total_iter+=1\n            if total_iter%CFG.grad_avg_n==0:\n                optimizer.step()\n                optimizer.zero_grad()\n                scheduler.step()\n                if total_iter%val_gap==0:\n                    val_loss,pred,target = val_rmse(model, val_ldr,mse,mode='train')\n                    val_loss2,_,_ = 0,None,None#val_rmse(model, val_ldr,mse,mode='eval')\n\n                    res=pd.DataFrame()\n                    res['target']=target\n                    res['pred']=pred\n                    res['fold']=fold\n                    res['epoch']=val_epoch\n                    epoch_res.append(res)\n                    print(f'################  epoch {i+1}   val epoch {val_epoch} #################################')\n                    print(f'training rmse:{np.sqrt(np.mean(loss_seq)).round(6)}')\n                    print(f'validation rmse (train):{val_loss.round(6)}')#  (eval):{val_loss2.round(6)}')\n                    recorder.record(val_loss,val_epoch,model)\n\n                    val_epoch+=1\n                #scheduler.step(recorder.cv_scores[-1])\n    torch.cuda.empty_cache()\n    fold_res=pd.concat(epoch_res,axis=0).reset_index(drop=True)\n    fold_res['is_best_epoch']=False\n    fold_res.loc[fold_res[fold_res.epoch==recorder.best_epoch].index,'is_best_epoch']=True\n    return fold_res,recorder","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:59.494366Z","iopub.execute_input":"2021-07-11T14:51:59.494874Z","iopub.status.idle":"2021-07-11T14:51:59.513513Z","shell.execute_reply.started":"2021-07-11T14:51:59.494829Z","shell.execute_reply":"2021-07-11T14:51:59.512357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_indices=CV_split(len(train_df),k=CFG.folds,shuffle=CFG.cv_shuffle,seed=7)\nmodels=[]\ncv_res=[]\nfor fold in range(1,CFG.folds+1):\n    print(f'fold {fold}')\n    train_index,val_index=split_indices[fold-1]\n    train_ds=D.Subset(ds1, train_index)\n    valid_ds = D.Subset(ds1, val_index)\n    ################\n    random.seed(CFG.seed)\n    os.environ['PYTHONHASHSEED'] = str(CFG.seed)\n    np.random.seed(CFG.seed)\n    torch.manual_seed(CFG.seed)\n    torch.cuda.manual_seed(CFG.seed)\n    torch.cuda.manual_seed_all(CFG.seed)\n    torch.backends.cudnn.deterministic = True\n    ##################\n    train_ldr = D.DataLoader(train_ds, batch_size=CFG.batch_size,\n                             shuffle=True, collate_fn = collate,num_workers=0)\n    val_ldr = D.DataLoader(valid_ds, batch_size=CFG.batch_size,\n                           shuffle=False, collate_fn = collate,num_workers=0)\n    \n    model.load_state_dict(init_state)\n    model.to(CFG.device)\n    fold_res,recorder=train(model,train_ldr,val_ldr,fold)\n    print(f'best epoch: {recorder.best_epoch} with best rmse:{recorder.best_score}')\n    cv_res.append(fold_res)\n    preds=score_test(model,test_ldr)\n    test_df[f'fold {fold} preds']=preds\n    torch.save({'model_state_dict':recorder.best_state_dict},f'fold_{fold}_model')\n    del recorder\n    gc.collect()\ncv_res=pd.concat(cv_res,axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:51:59.51536Z","iopub.execute_input":"2021-07-11T14:51:59.515897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# deeper Look into oof_pred","metadata":{}},{"cell_type":"code","source":"cv_res['ae']=np.abs(cv_res.target-cv_res.pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* oof score for each epoch","metadata":{}},{"cell_type":"code","source":"rmse_curve=[]\nfor epoch in range(1,cv_res.epoch.max()+1):\n    epoch_data=cv_res[cv_res.epoch==epoch].reset_index(drop=True)\n    score=rmse(epoch_data.pred,epoch_data.target)\n    rmse_curve.append(score)\n    print(f'abs error auto correlation: {epoch_data.ae.autocorr()}')\n    print(f'epoch {epoch} rmse: {score} oof pred error std:{np.std(epoch_data.ae)/np.sqrt(len(epoch_data))}')\nplt.plot(rmse_curve)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* best oof score","metadata":{}},{"cell_type":"code","source":"epoch_data=cv_res[cv_res.is_best_epoch==True].reset_index(drop=True)\nrmse(epoch_data.pred,epoch_data.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds=0\nfor i in range(CFG.folds):\n    final_preds+=test_df[f'fold {i+1} preds']/CFG.folds\nres_df['target']=final_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}