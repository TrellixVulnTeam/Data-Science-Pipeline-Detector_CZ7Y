{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***Introducing TorchFlare***\n\n![logo](https://raw.githubusercontent.com/Atharva-Phatak/torchflare/main/docs/static/images/TorchFlare.gif)\n\n\n***TorchFlare*** is a simple, beginner-friendly and an easy-to-use PyTorch Framework train your models without much effort.\nIt provides an almost Keras-like experience for training\nyour models with all the callbacks, metrics, etc\n\n\n### ***Features***\n* _A high-level module for Keras-like training._\n* _Off-the-shelf Pytorch style Datasets/Dataloaders for standard tasks such as **Image classification, Image segmentation,\n  Text Classification**, etc_\n* _**Callbacks** for model checkpoints, early stopping, and much more!_\n* _**Metrics** and much more._\n* _**Reduction** of the boiler plate code required for training your models._\n\n***\n* **Github**: https://github.com/Atharva-Phatak/torchflare\n* **Docs**: https://atharva-phatak.github.io/torchflare/\n\n**Show some love to [TorchFlare](https://github.com/Atharva-Phatak/torchflare) by giving start if you like the library.**\n\n**If you find bug or have feature requests or create awesome kernels/notebooks using TorchFlare, open up a issue in repo.**","metadata":{}},{"cell_type":"code","source":"!pip install -qq torchflare","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* For some reason installation takes some time, I guess because torchflare is based on latest versions. ","metadata":{}},{"cell_type":"code","source":"!pip install -qq nb_black","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext lab_black","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ***Importing Libraries***","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport pandas as pd\n\nimport torchflare.callbacks as cbs\nimport torchflare.metrics as metrics\nfrom torchflare.experiments import Experiment\nfrom torchflare.datasets import TextDataloader\n\nimport transformers\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ***Downloading our tokenizer.***","metadata":{}},{"cell_type":"code","source":"tokenizer = transformers.BertTokenizer.from_pretrained(\n    \"bert-base-uncased\", do_lower_case=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ***Using simple train_test_split for data splitting.***\n* Will add another kernel showing how to do crossval with torchflare.","metadata":{}},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_df, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***Using TextDataloader functionality from TorchFlarefor easy creation of text dataloaders.***","metadata":{}},{"cell_type":"code","source":"train_dl = TextDataloader.from_df(\n    df=train_df,\n    tokenizer=tokenizer,\n    max_len=185,\n    input_col=\"excerpt\",\n    label_cols=\"target\",\n).get_loader(batch_size=32, shuffle=True)\n\nvalid_dl = TextDataloader.from_df(\n    df=valid_df,\n    tokenizer=tokenizer,\n    max_len=185,\n    input_col=\"excerpt\",\n    label_cols=\"target\",\n).get_loader(batch_size=64, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***Defining BERT Model.***","metadata":{}},{"cell_type":"code","source":"class BERTClass(nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\")\n        self.fc = nn.Linear(768, 1)\n\n    def forward(self, input_ids, token_type_ids, attention_mask):\n        _, output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            return_dict=False,\n        )\n        output = self.fc(output)\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BERTClass()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***Defining the loss function.***","metadata":{}},{"cell_type":"code","source":"def rmse(op, y):\n    return torch.sqrt(nn.MSELoss()(op, y.float()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***Defining Callbacks and metrics and some optimizer params.***","metadata":{}},{"cell_type":"code","source":"param_optimizer = list(model.named_parameters())\nno_decay = [\"bias\", \"LayerNorm.bias\"]\noptimizer_parameters = [\n    {\n        \"params\": [\n            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n        ],\n        \"weight_decay\": 0.001,\n    },\n    {\n        \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\ncallbacks = [\n    cbs.ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_dir=\"./\"),\n    cbs.ReduceLROnPlateau(mode=\"min\", patience=2),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ***Defining experiment in TorchFlare is easy***\n1. First define some constant params like epochs , seeds, etc\n2. Compile your experiment with model, optimizer, callbacks, etc\n3. Fit your experiment on traininig and validation loaders.","metadata":{}},{"cell_type":"code","source":"exp = Experiment(num_epochs=4, fp16=False, device=\"cuda\", seed=42)\n\n# Compiling the experiment\nexp.compile_experiment(\n    model=model,\n    optimizer=\"AdamW\",\n    optimizer_params=dict(\n        model_params=optimizer_parameters, lr=3e-4\n    ),  # used model_params argument for custom optimizer params.\n    callbacks=callbacks,\n    criterion=rmse,\n    metrics=None,\n    main_metric=\"loss\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp.fit_loader(train_dl, valid_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's take a experiment History. ","metadata":{}},{"cell_type":"code","source":"exp.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean VAL RMSE  : {sum(exp.history['train_loss'])/len(exp.history['Epoch'])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Note you wont be possibly be able to plot history this since we upgraded the Pillow version and Kaggle kernel has pip resolve issues(matplotlib compat issues). I will try update the requirements for torchflare to make it compatible with Kaggle Kernels. \n","metadata":{}},{"cell_type":"markdown","source":"### ***Again this goes without saying, If you like this workflow and want to see more of it please star [TorchFlare](https://github.com/Atharva-Phatak/torchflare).***","metadata":{}}]}