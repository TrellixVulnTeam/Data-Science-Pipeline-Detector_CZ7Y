{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch BERT + Stratified K Fold [inference]","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nThis is the inference part of BERT baseline.  \nTraining part is here:  \nhttps://www.kaggle.com/atsushiiwasaki/commonlit-bert-stratified-k-fold-baseline-train\n\nIn this notebook, the cv score is caluculated using oof in the training part.\n\nThanks.\n\n## Contents\n1. Libraries\n1. Configuration\n1. Data\n1. Model\n1. CV/Inference","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:42:09.605237Z","iopub.execute_input":"2021-05-25T22:42:09.605879Z","iopub.status.idle":"2021-05-25T22:42:09.61612Z","shell.execute_reply.started":"2021-05-25T22:42:09.605788Z","shell.execute_reply":"2021-05-25T22:42:09.61478Z"}}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nfrom pprint import pprint\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom sklearn.model_selection import StratifiedKFold\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.011698Z","iopub.execute_input":"2021-06-05T12:46:03.012025Z","iopub.status.idle":"2021-06-05T12:46:03.029198Z","shell.execute_reply.started":"2021-06-05T12:46:03.011996Z","shell.execute_reply":"2021-06-05T12:46:03.028323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.030685Z","iopub.execute_input":"2021-06-05T12:46:03.031367Z","iopub.status.idle":"2021-06-05T12:46:03.041945Z","shell.execute_reply.started":"2021-06-05T12:46:03.031325Z","shell.execute_reply":"2021-06-05T12:46:03.041054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.043898Z","iopub.execute_input":"2021-06-05T12:46:03.04425Z","iopub.status.idle":"2021-06-05T12:46:03.05255Z","shell.execute_reply.started":"2021-06-05T12:46:03.044213Z","shell.execute_reply":"2021-06-05T12:46:03.051634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\nCV = True\n\nTRAIN = '../input/commonlitreadabilityprize/train.csv'\nTEST = '../input/commonlitreadabilityprize/test.csv'\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device: ', device.type)\n\nSEED = 28\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.053825Z","iopub.execute_input":"2021-06-05T12:46:03.054083Z","iopub.status.idle":"2021-06-05T12:46:03.06476Z","shell.execute_reply.started":"2021-06-05T12:46:03.05405Z","shell.execute_reply":"2021-06-05T12:46:03.063943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Model Architecture ###\n# BERT\nBERT = '../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased'\n\n# Distilbert\nDISTILBERT = '../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased'\n\n# Roberta\nROBERTA = '../input/huggingface-roberta-variants/roberta-base/roberta-base'\n\n\n### Trained Weights ###\nTRAINED = '../input/commonlit-bert-stratified-k-fold-baseline-train'\nMODEL_NAME = 'CommonLitBERT'\n\n\n\ncfg ={}\n\nARCH_PATH = ROBERTA\ncfg['train'] = {'n_folds': 5}","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.067795Z","iopub.execute_input":"2021-06-05T12:46:03.068058Z","iopub.status.idle":"2021-06-05T12:46:03.074699Z","shell.execute_reply.started":"2021-06-05T12:46:03.068023Z","shell.execute_reply":"2021-06-05T12:46:03.073877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"cfg['tokenizer'] ={'name': ARCH_PATH, \n                   'max_length': 210}\n\ntokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.077578Z","iopub.execute_input":"2021-06-05T12:46:03.077955Z","iopub.status.idle":"2021-06-05T12:46:03.205876Z","shell.execute_reply.started":"2021-06-05T12:46:03.077912Z","shell.execute_reply":"2021-06-05T12:46:03.205043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    df = pd.read_csv(TRAIN)\n    text = df.loc[SEED, 'excerpt']\n    print('Text Length ', len(text.split(' ')))\n    print()\n    \n    text_tokenized = tokenizer.encode_plus(\n                        text,\n                        add_special_tokens=True,\n                        padding='max_length',\n                        max_length=cfg['tokenizer']['max_length'], \n                        truncation=True\n                        )\n    \n    for key, value in text_tokenized.items():\n        print(key, type(value))\n        print(value)\n        print()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-05T12:46:03.207231Z","iopub.execute_input":"2021-06-05T12:46:03.207597Z","iopub.status.idle":"2021-06-05T12:46:03.21382Z","shell.execute_reply.started":"2021-06-05T12:46:03.207558Z","shell.execute_reply":"2021-06-05T12:46:03.212629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class CommonLitDataset(Dataset):\n    \n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.df.loc[index, 'excerpt']\n        inputs = self.tokenizer.encode_plus(\n            text,                                 \n            add_special_tokens=True,\n            padding='max_length',\n            max_length=self.max_len,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        \n        if cfg['tokenizer']['name']==BERT:\n            token_type_ids = inputs['token_type_ids'] \n        else:\n            token_type_ids = 1.\n        \n        target = self.df.loc[index, ['target']]\n        \n        return {\n            'ids': torch.LongTensor(ids),\n            'mask': torch.LongTensor(mask),\n             'token_type_ids': torch.tensor(token_type_ids)\n            },{\n            'target': torch.Tensor(target)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.217358Z","iopub.execute_input":"2021-06-05T12:46:03.217807Z","iopub.status.idle":"2021-06-05T12:46:03.228363Z","shell.execute_reply.started":"2021-06-05T12:46:03.217769Z","shell.execute_reply":"2021-06-05T12:46:03.227313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    ds = CommonLitDataset(df=df, \n                          tokenizer=tokenizer, \n                          max_len=cfg['tokenizer']['max_length'])\n    assert len(df) == len(ds)\n    \n    ds = iter(ds)\n    inputs, targets = next(ds)\n    \n    for k, v in inputs.items():\n        print(k, v.dtype)\n        print(v)\n        print()\n        \n    for k, v in targets.items():\n        print(k, v.dtype)\n        print(v)\n        print()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-05T12:46:03.230713Z","iopub.execute_input":"2021-06-05T12:46:03.231141Z","iopub.status.idle":"2021-06-05T12:46:03.237843Z","shell.execute_reply.started":"2021-06-05T12:46:03.231083Z","shell.execute_reply":"2021-06-05T12:46:03.236987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"cfg['dl_train'] = {\n    'batch_size': 8 if device.type=='cpu' else 16, \n    'shuffle': True, \n    'num_workers': os.cpu_count(), \n    'pin_memory': True\n}\n\ncfg['dl_val'] = {\n    'batch_size': 8 if device.type=='cpu' else 16, \n    'shuffle': False, \n    'num_workers': os.cpu_count(), \n    'pin_memory': True\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.239006Z","iopub.execute_input":"2021-06-05T12:46:03.23954Z","iopub.status.idle":"2021-06-05T12:46:03.250912Z","shell.execute_reply.started":"2021-06-05T12:46:03.239502Z","shell.execute_reply":"2021-06-05T12:46:03.250054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    ds = CommonLitDataset(df=df, \n                          tokenizer=tokenizer, \n                          max_len=cfg['tokenizer']['max_length'])\n    \n    dl = DataLoader(ds, **cfg['dl_train'])\n    \n    for data in dl:\n        print(data[0]['ids'].detach().cpu().size())\n        break","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-05T12:46:03.252203Z","iopub.execute_input":"2021-06-05T12:46:03.252724Z","iopub.status.idle":"2021-06-05T12:46:03.261934Z","shell.execute_reply.started":"2021-06-05T12:46:03.252685Z","shell.execute_reply":"2021-06-05T12:46:03.261062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"cfg['model'] = {'name': ARCH_PATH}","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.26334Z","iopub.execute_input":"2021-06-05T12:46:03.263714Z","iopub.status.idle":"2021-06-05T12:46:03.272365Z","shell.execute_reply.started":"2021-06-05T12:46:03.263676Z","shell.execute_reply":"2021-06-05T12:46:03.271552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLitBERT(nn.Module):\n    \n    def __init__(self, name, dropout=True):\n        super(CommonLitBERT, self).__init__()\n        self.bert = AutoModel.from_pretrained(name)\n        self.name = name\n        \n        if name == BERT:\n            self.in_features = self.bert.pooler.dense.out_features\n        elif name == DISTILBERT:\n            self.in_features = self.bert.transformer.layer[5].output_layer_norm.normalized_shape[0]\n        elif name == ROBERTA:\n            self.in_features = self.bert.pooler.dense.out_features\n        else:\n            self.in_features = 768\n        \n        self.fc = nn.Linear(self.in_features, 1)\n        self.dense = nn.Linear(self.in_features, self.in_features)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)\n        self.layer_norm = nn.LayerNorm(self.in_features)\n        \n    def forward(self, ids, mask, token_type_ids):\n        if self.name == BERT:\n            last_hidden_state, output = self.bert(ids,\n                                                  attention_mask=mask,\n                                                  token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        elif self.name == DISTILBERT:\n            last_hidden_state = self.bert(ids, \n                                           attention_mask=mask, \n                                           return_dict=False)\n            first_token_tensor = last_hidden_state[0][:, 0]\n            output = self.dense(first_token_tensor)\n            output = self.activation(output)\n            \n        elif self.name == ROBERTA:\n            last_hidden_state, output = self.bert(ids,\n                                                  attention_mask=mask,\n#                                                   token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        output = self.layer_norm(output)\n        output = self.dropout(output)\n        output = self.fc(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.273715Z","iopub.execute_input":"2021-06-05T12:46:03.274214Z","iopub.status.idle":"2021-06-05T12:46:03.286982Z","shell.execute_reply.started":"2021-06-05T12:46:03.274178Z","shell.execute_reply":"2021-06-05T12:46:03.286265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    model = CommonLitBERT(name=cfg['model']['name'])\n    data = next(iter(dl))\n    inputs = data[0]\n    outputs = model(**inputs)\n    print(outputs)\n    \n    del model\n    gc.collect()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-05T12:46:03.287947Z","iopub.execute_input":"2021-06-05T12:46:03.288461Z","iopub.status.idle":"2021-06-05T12:46:03.302164Z","shell.execute_reply.started":"2021-06-05T12:46:03.288425Z","shell.execute_reply":"2021-06-05T12:46:03.301247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV / Inference","metadata":{}},{"cell_type":"code","source":"from torch.cuda.amp import GradScaler\nfrom torch.cuda.amp import autocast","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.303465Z","iopub.execute_input":"2021-06-05T12:46:03.303926Z","iopub.status.idle":"2021-06-05T12:46:03.311854Z","shell.execute_reply.started":"2021-06-05T12:46:03.303891Z","shell.execute_reply":"2021-06-05T12:46:03.310948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg['train'] ={\n    'n_folds': 5,\n    'n_epochs': 100\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.31281Z","iopub.execute_input":"2021-06-05T12:46:03.31304Z","iopub.status.idle":"2021-06-05T12:46:03.321113Z","shell.execute_reply.started":"2021-06-05T12:46:03.313018Z","shell.execute_reply":"2021-06-05T12:46:03.320255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bin_stratified(df, n_bins=20, n_splits=5):\n    df['bin'] = pd.cut(df.target, n_bins, labels=[i for i in range(n_bins)])\n    \n    df['fold'] = np.nan\n\n    skf = StratifiedKFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n    gen_skf = skf.split(df.id, y=df.bin)\n\n    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n        df.loc[idx_val, 'fold'] = fold\n\n    df['fold'] = df['fold'].astype('int8')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.322116Z","iopub.execute_input":"2021-06-05T12:46:03.324086Z","iopub.status.idle":"2021-06-05T12:46:03.331508Z","shell.execute_reply.started":"2021-06-05T12:46:03.324061Z","shell.execute_reply":"2021-06-05T12:46:03.33068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_fn_cv(model, dl):\n    scaler = GradScaler()\n    preds = []\n    \n    model.eval()\n    model.to(device)\n    \n    progress_bar = tqdm(dl, desc='cv')\n    \n    with torch.no_grad():\n        for i, data in enumerate(progress_bar):\n            inputs = {key: value.to(device) for key, value in data[0].items()}\n            targets = data[1]['target'].to(device)\n            \n            with autocast():\n                outputs = model(**inputs)\n            \n            preds.append(outputs.detach().cpu().numpy())\n    \n    preds = np.concatenate(preds)\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.332713Z","iopub.execute_input":"2021-06-05T12:46:03.333136Z","iopub.status.idle":"2021-06-05T12:46:03.344353Z","shell.execute_reply.started":"2021-06-05T12:46:03.333092Z","shell.execute_reply":"2021-06-05T12:46:03.343544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dls_for_n_fold(df, fold, tokenizer):\n    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n    \n    train_ds = CommonLitDataset(\n        train_df, \n        tokenizer=tokenizer, \n        max_len=cfg['tokenizer']['max_length']\n    )\n    \n    val_ds = CommonLitDataset(\n        val_df, \n        tokenizer=tokenizer, \n        max_len=cfg['tokenizer']['max_length']\n    )\n    \n    train_dl = DataLoader(train_ds, **cfg['dl_train'])\n    val_dl = DataLoader(val_ds, **cfg['dl_val'])\n    \n    return train_dl, val_dl","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.345546Z","iopub.execute_input":"2021-06-05T12:46:03.345967Z","iopub.status.idle":"2021-06-05T12:46:03.353726Z","shell.execute_reply.started":"2021-06-05T12:46:03.34593Z","shell.execute_reply":"2021-06-05T12:46:03.352977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint(cfg)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.355258Z","iopub.execute_input":"2021-06-05T12:46:03.355668Z","iopub.status.idle":"2021-06-05T12:46:03.367291Z","shell.execute_reply.started":"2021-06-05T12:46:03.355621Z","shell.execute_reply":"2021-06-05T12:46:03.366441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_cv():\n    seed_everything(SEED)\n    \n    df = pd.read_csv(TRAIN)\n    get_bin_stratified(df, n_splits=cfg['train']['n_folds'])\n    df['oof'] = np.nan\n\n    tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n    \n    for fold in range(cfg['train']['n_folds']):\n        train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n\n        model = CommonLitBERT(name=cfg['model']['name'])\n        PATH = os.path.join(TRAINED, MODEL_NAME + f'_fold{fold}.tar')\n        saved_contents = torch.load(PATH, map_location=device)\n        \n        model.load_state_dict(saved_contents['model'])\n        if fold==0:\n            cfg_for_train = saved_contents['cfg']\n            print('Configuration for training:')\n            print()\n            pprint(cfg_for_train)\n            print()\n        \n        print('Fold:', fold)\n        \n        inputs = {'model': model,\n                  'dl': val_dl}\n        \n        preds = val_fn_cv(**inputs)\n        df.loc[df.fold==fold, 'oof'] = preds\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.369022Z","iopub.execute_input":"2021-06-05T12:46:03.369637Z","iopub.status.idle":"2021-06-05T12:46:03.378436Z","shell.execute_reply.started":"2021-06-05T12:46:03.3696Z","shell.execute_reply":"2021-06-05T12:46:03.377537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_infer():\n    seed_everything(SEED)\n    \n    df = pd.read_csv(TEST)\n    df['target'] = 0.\n    \n    tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n    \n    for fold in range(cfg['train']['n_folds']):\n        print('Fold:', fold)\n\n        test_ds = CommonLitDataset(\n                    df, \n                    tokenizer=tokenizer, \n                    max_len=cfg['tokenizer']['max_length']\n                    )\n    \n        test_dl = DataLoader(test_ds, **cfg['dl_val'])\n\n        model = CommonLitBERT(name=cfg['model']['name'])\n        PATH = os.path.join(TRAINED, MODEL_NAME + f'_fold{fold}.tar')\n        state_dict = torch.load(PATH, map_location=device)['model']\n        model.load_state_dict(state_dict)\n\n        inputs = {'model': model,\n                  'dl': test_dl}\n        \n        preds = val_fn_cv(**inputs)\n        df['target'] = df['target'] + np.concatenate(preds)\n    \n    df['target'] = df['target'] / cfg['train']['n_folds']\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.381334Z","iopub.execute_input":"2021-06-05T12:46:03.381591Z","iopub.status.idle":"2021-06-05T12:46:03.391742Z","shell.execute_reply.started":"2021-06-05T12:46:03.381567Z","shell.execute_reply":"2021-06-05T12:46:03.390901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif CV:\n    from sklearn.metrics import mean_squared_error\n\n    df = main_cv()\n    df.to_csv('oof_df.csv', index=False)\n    \n    mse = mean_squared_error(df['target'], df['oof'])\n    rmse = np.sqrt(mse)\n    print('CV score: ', rmse)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:46:03.395935Z","iopub.execute_input":"2021-06-05T12:46:03.396266Z","iopub.status.idle":"2021-06-05T12:47:09.02425Z","shell.execute_reply.started":"2021-06-05T12:46:03.396241Z","shell.execute_reply":"2021-06-05T12:47:09.022988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = main_infer()\ndf = df[['id', 'target']]\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:47:09.026319Z","iopub.execute_input":"2021-06-05T12:47:09.026738Z","iopub.status.idle":"2021-06-05T12:47:26.852359Z","shell.execute_reply.started":"2021-06-05T12:47:09.026689Z","shell.execute_reply":"2021-06-05T12:47:26.851415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T12:47:26.85386Z","iopub.execute_input":"2021-06-05T12:47:26.854247Z","iopub.status.idle":"2021-06-05T12:47:26.867337Z","shell.execute_reply.started":"2021-06-05T12:47:26.854202Z","shell.execute_reply":"2021-06-05T12:47:26.866226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Part is Here !\nhttps://www.kaggle.com/atsushiiwasaki/commonlit-bert-stratified-k-fold-baseline-train","metadata":{"execution":{"iopub.status.busy":"2021-06-01T20:12:32.86893Z","iopub.execute_input":"2021-06-01T20:12:32.869863Z","iopub.status.idle":"2021-06-01T20:12:32.879485Z","shell.execute_reply.started":"2021-06-01T20:12:32.869821Z","shell.execute_reply":"2021-06-01T20:12:32.87677Z"}}}]}