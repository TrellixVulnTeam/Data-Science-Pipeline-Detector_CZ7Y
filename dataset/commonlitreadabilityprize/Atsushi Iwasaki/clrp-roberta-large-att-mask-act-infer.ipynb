{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{"papermill":{"duration":0.030716,"end_time":"2021-07-14T20:43:12.535101","exception":false,"start_time":"2021-07-14T20:43:12.504385","status":"completed"},"tags":[],"id":"confused-visitor"}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nfrom pprint import pprint\nfrom tqdm import tqdm\nimport more_itertools\nfrom collections import OrderedDict\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Sampler\nfrom torch.utils.data import RandomSampler\n\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig\nfrom transformers import AutoModelForMaskedLM\nfrom transformers import DataCollatorForLanguageModeling\nfrom transformers import DataCollatorWithPadding\n\n%matplotlib inline\n\nimport sys\n\n\nCOLAB = False\n\nif COLAB:\n    sys.path.append('/content/drive/MyDrive/Colab Notebooks/CommonLit/lib')\n    from clrp_private_lib import SmartBatchingSampler\n    from clrp_private_lib import get_slanted_triangular_lr\n    from clrp_private_lib import EarlyStopping","metadata":{"papermill":{"duration":7.166197,"end_time":"2021-07-14T20:43:19.730796","exception":false,"start_time":"2021-07-14T20:43:12.564599","status":"completed"},"tags":[],"id":"straight-mount","execution":{"iopub.status.busy":"2021-07-21T13:31:52.314443Z","iopub.execute_input":"2021-07-21T13:31:52.314769Z","iopub.status.idle":"2021-07-21T13:31:59.642963Z","shell.execute_reply.started":"2021-07-21T13:31:52.314698Z","shell.execute_reply":"2021-07-21T13:31:59.641989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{"papermill":{"duration":0.027529,"end_time":"2021-07-14T20:43:19.786181","exception":false,"start_time":"2021-07-14T20:43:19.758652","status":"completed"},"tags":[],"id":"decimal-length"}},{"cell_type":"code","source":"DEBUG = False\n\n# Input Files\nTRAIN = '/content/drive/MyDrive/Colab Notebooks/CommonLit/input/train.csv' if COLAB else '../input/commonlitreadabilityprize/train.csv'\nTRAIN = '/content/drive/MyDrive/Colab Notebooks/CommonLit/input/train_oof_stratified.csv' if COLAB else '../input/clrp-stratify-on-predictability/train_oof_stratified.csv'   # changed\nTEST = '/content/drive/MyDrive/Colab Notebooks/CommonLit/input/test.csv' if COLAB else '../input/commonlitreadabilityprize/test.csv'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device: ', device.type)\n\nSEED = 28\nseed_everything(SEED)\n\ncfg ={}","metadata":{"papermill":{"duration":0.08024,"end_time":"2021-07-14T20:43:19.894093","exception":false,"start_time":"2021-07-14T20:43:19.813853","status":"completed"},"tags":[],"id":"joint-poultry","outputId":"da609c88-cfdb-4665-f0f9-458658c4ec4c","execution":{"iopub.status.busy":"2021-07-21T13:31:59.644493Z","iopub.execute_input":"2021-07-21T13:31:59.64485Z","iopub.status.idle":"2021-07-21T13:31:59.695315Z","shell.execute_reply.started":"2021-07-21T13:31:59.644811Z","shell.execute_reply":"2021-07-21T13:31:59.694448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BERT\nBERT = 'bert-base-uncased'\n\n# Distilbert\nDISTILBERT = 'distilbert-base-uncased'\n\n# Roberta\nROBERTA = 'roberta-base' if COLAB else '../input/huggingface-roberta-variants/roberta-base'\nROBERTA_LARGE = 'roberta-large' if COLAB else '../input/huggingface-roberta-variants/roberta-large/roberta-large'\n\n\n\ncfg ={}\n\nARCH_PATH = ROBERTA_LARGE\n\nCV_PATH = '../input/clrp-robertalarge-attentions-mask-act'\nMODEL_NAME = 'CLRPModelLarge'\n\nCV = False\nPOST = False","metadata":{"papermill":{"duration":0.035139,"end_time":"2021-07-14T20:43:19.957541","exception":false,"start_time":"2021-07-14T20:43:19.922402","status":"completed"},"tags":[],"id":"criminal-williams","execution":{"iopub.status.busy":"2021-07-21T13:31:59.697407Z","iopub.execute_input":"2021-07-21T13:31:59.697967Z","iopub.status.idle":"2021-07-21T13:31:59.707532Z","shell.execute_reply.started":"2021-07-21T13:31:59.697915Z","shell.execute_reply":"2021-07-21T13:31:59.706666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{"papermill":{"duration":0.027441,"end_time":"2021-07-14T20:43:20.012546","exception":false,"start_time":"2021-07-14T20:43:19.985105","status":"completed"},"tags":[],"id":"distinguished-andrew"}},{"cell_type":"markdown","source":"## Tokenizer","metadata":{"papermill":{"duration":0.028461,"end_time":"2021-07-14T20:43:20.828636","exception":false,"start_time":"2021-07-14T20:43:20.800175","status":"completed"},"tags":[],"id":"royal-capability"}},{"cell_type":"code","source":"def get_tokenizer():\n    return AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])","metadata":{"papermill":{"duration":0.035645,"end_time":"2021-07-14T20:43:20.893156","exception":false,"start_time":"2021-07-14T20:43:20.857511","status":"completed"},"tags":[],"id":"major-disco","execution":{"iopub.status.busy":"2021-07-21T13:31:59.70946Z","iopub.execute_input":"2021-07-21T13:31:59.709869Z","iopub.status.idle":"2021-07-21T13:31:59.71634Z","shell.execute_reply.started":"2021-07-21T13:31:59.709832Z","shell.execute_reply":"2021-07-21T13:31:59.715519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"papermill":{"duration":0.028553,"end_time":"2021-07-14T20:43:20.951912","exception":false,"start_time":"2021-07-14T20:43:20.923359","status":"completed"},"tags":[],"id":"pleased-montreal"}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.replace('\\n', '')\n    return text\n\nclass CLRPDataset(Dataset):\n    \n    def __init__(self, df, tokenizer):\n        self.df = df\n        self.texts = self.df['excerpt'].tolist()\n        self.targets = self.df['target'].tolist()\n        self.se = self.df['standard_error'].tolist()\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, index):\n        text = clean_text(self.texts[index])\n        tokenized_text = self.tokenizer.encode_plus(\n            text,\n            **cfg['tokenizer']['params']\n        )\n        \n        tokenized_text['target'] = self.targets[index]\n        tokenized_text['se'] = self.se[index]\n        return tokenized_text","metadata":{"papermill":{"duration":0.037705,"end_time":"2021-07-14T20:43:21.018077","exception":false,"start_time":"2021-07-14T20:43:20.980372","status":"completed"},"tags":[],"id":"laden-patch","execution":{"iopub.status.busy":"2021-07-21T13:31:59.719569Z","iopub.execute_input":"2021-07-21T13:31:59.719875Z","iopub.status.idle":"2021-07-21T13:31:59.730731Z","shell.execute_reply.started":"2021-07-21T13:31:59.719848Z","shell.execute_reply":"2021-07-21T13:31:59.729808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{"papermill":{"duration":0.028725,"end_time":"2021-07-14T20:43:21.075223","exception":false,"start_time":"2021-07-14T20:43:21.046498","status":"completed"},"tags":[],"id":"adopted-buffer"}},{"cell_type":"markdown","source":"### Datacollator","metadata":{"papermill":{"duration":0.029233,"end_time":"2021-07-14T20:43:21.133017","exception":false,"start_time":"2021-07-14T20:43:21.103784","status":"completed"},"tags":[],"id":"united-presentation"}},{"cell_type":"code","source":"def get_collator(tokenizer, phase='train'):\n    \n    def _prepare_collator(name, phase):\n        if name=='MLM':\n            return DataCollatorForLanguageModeling(tokenizer=tokenizer, \n                                                   **cfg['collator'][phase]['params'])\n        elif name=='padding':\n            return DataCollatorWithPadding(tokenizer=tokenizer)\n        else:\n            return None\n    \n    return _prepare_collator(cfg['collator'][phase]['name'], phase=phase)","metadata":{"papermill":{"duration":0.03689,"end_time":"2021-07-14T20:43:21.198424","exception":false,"start_time":"2021-07-14T20:43:21.161534","status":"completed"},"tags":[],"id":"anonymous-infrastructure","execution":{"iopub.status.busy":"2021-07-21T13:31:59.733814Z","iopub.execute_input":"2021-07-21T13:31:59.734165Z","iopub.status.idle":"2021-07-21T13:31:59.742334Z","shell.execute_reply.started":"2021-07-21T13:31:59.734126Z","shell.execute_reply":"2021-07-21T13:31:59.741297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sampler","metadata":{"papermill":{"duration":0.028383,"end_time":"2021-07-14T20:43:21.255204","exception":false,"start_time":"2021-07-14T20:43:21.226821","status":"completed"},"tags":[],"id":"altered-variety"}},{"cell_type":"code","source":"def get_SmartBatchingSampler(df, batch_size):\n    data_source = df.excerpt.apply(lambda x: x.split(' '))\n    return SmartBatchingSampler(data_source=data_source, batch_size=batch_size)\n\ndef get_RandomSampler(df):\n    data_source = df.excerpt.apply(lambda x: x.split(' '))\n    return RandomSampler(data_source=data_source)","metadata":{"papermill":{"duration":0.039792,"end_time":"2021-07-14T20:43:21.323384","exception":false,"start_time":"2021-07-14T20:43:21.283592","status":"completed"},"tags":[],"id":"endless-tourism","execution":{"iopub.status.busy":"2021-07-21T13:31:59.743754Z","iopub.execute_input":"2021-07-21T13:31:59.744226Z","iopub.status.idle":"2021-07-21T13:31:59.752869Z","shell.execute_reply.started":"2021-07-21T13:31:59.744187Z","shell.execute_reply":"2021-07-21T13:31:59.751926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_extended_attention_mask(attention_mask):\n    extended_attention_mask = (1.0 - attention_mask) * (-1e+4)\n    extended_attention_mask = extended_attention_mask.unsqueeze(1).transpose(2, 1)\n    return extended_attention_mask\n\nclass Attention(nn.Module):\n    \n    def __init__(self, in_features=768, hidden_state=514):\n        super().__init__()\n        self.in_features = in_features\n        self.hidden_state = hidden_state\n        \n        self.attention = nn.Sequential(\n            nn.Linear(self.in_features, self.hidden_state),\n            nn.Tanh(),\n            nn.Linear(self.hidden_state, 1),\n        )\n\n        self.softmax = nn.Softmax(dim=1)\n        \n        torch.nn.init.kaiming_normal_(self.attention[0].weight)\n        torch.nn.init.kaiming_normal_(self.attention[2].weight)\n        \n    def forward(self, x, attention_mask):\n        extended_attention_mask = get_extended_attention_mask(attention_mask)\n        weights = self.attention(x)\n        weights += extended_attention_mask\n        weights = self.softmax(weights)\n        context = torch.sum(weights * x, dim=1)  # sumの方向を変えれば、どの単語の位置が重要か分かる？\n        return context\n\nclass CLRPModel(nn.Module):\n    \n    def __init__(self, name, p=0.2, path=None, n_attentions=4, hidden_state=514):\n        super(CLRPModel, self).__init__()\n        \n        self.name = name\n        self.path = path\n        self.p = p\n        self.n_attentions = n_attentions\n        self.hidden_state = hidden_state\n        \n        config = AutoConfig.from_pretrained(name)  # This setting is from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch\n        config.update(cfg['bert'])\n        \n        self.bert = AutoModel.from_pretrained(name, config=config)\n        if path: self._load_pretrained_weights()\n        \n        self.in_features = self.bert.pooler.dense.out_features\n        \n        self.attentions = nn.ModuleList([Attention(in_features=self.in_features, hidden_state=self.hidden_state) for i in range(self.n_attentions)])\n        self.regressor = nn.Linear(self.n_attentions * self.in_features, 1)\n\n        torch.nn.init.kaiming_normal_(self.regressor.weight)\n        \n        \n    def _load_pretrained_weights(self):\n        model_pretrained = AutoModelForMaskedLM.from_pretrained(self.name)\n        checkpoint = torch.load(self.path, map_location=device)\n        model_pretrained.load_state_dict(checkpoint['model'])\n        \n        self.bert.embeddings = model_pretrained.roberta.embeddings\n        self.bert.encoder = model_pretrained.roberta.encoder\n        \n        del model_pretrained\n        gc.collect()\n        \n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        last_hidden_state, output, hidden_states = self.bert(input_ids=input_ids,\n                                                attention_mask=attention_mask,\n#                                                   token_type_ids=token_type_ids,\n                                                return_dict=False)\n\n        contexts = [self.attentions[i](hidden_states[- (i + 1)], attention_mask) for i in range(self.n_attentions)]\n        contexts = torch.cat(contexts, dim=-1)\n        contexts = F.gelu(contexts)\n        output = self.regressor(contexts)\n        \n        return last_hidden_state, output","metadata":{"execution":{"iopub.status.busy":"2021-07-21T13:31:59.756328Z","iopub.execute_input":"2021-07-21T13:31:59.756715Z","iopub.status.idle":"2021-07-21T13:31:59.775484Z","shell.execute_reply.started":"2021-07-21T13:31:59.756664Z","shell.execute_reply":"2021-07-21T13:31:59.774762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sampler(df=None, batch_size=None):\n    if cfg['sampler']['name']=='SmartBatchSampler':\n        return get_SmartBatchingSampler(df, batch_size)","metadata":{"papermill":{"duration":0.035103,"end_time":"2021-07-14T20:43:21.386883","exception":false,"start_time":"2021-07-14T20:43:21.35178","status":"completed"},"tags":[],"id":"sensitive-nowhere","execution":{"iopub.status.busy":"2021-07-21T13:31:59.77836Z","iopub.execute_input":"2021-07-21T13:31:59.778669Z","iopub.status.idle":"2021-07-21T13:31:59.789239Z","shell.execute_reply.started":"2021-07-21T13:31:59.778627Z","shell.execute_reply":"2021-07-21T13:31:59.788307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataloader","metadata":{"papermill":{"duration":0.028571,"end_time":"2021-07-14T20:43:21.443996","exception":false,"start_time":"2021-07-14T20:43:21.415425","status":"completed"},"tags":[],"id":"subtle-bhutan"}},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.028303,"end_time":"2021-07-14T20:43:21.703033","exception":false,"start_time":"2021-07-14T20:43:21.67473","status":"completed"},"tags":[],"id":"russian-bibliography"}},{"cell_type":"code","source":"def get_model(pretrained=True, fold=None):\n    if pretrained:\n        PRETRAINED_MODEL = os.path.join(PRETRAINED_PATH, f'CLRPModelMLM.tar')\n        cfg['model']['path'] = PRETRAINED_MODEL\n    else:\n        cfg['model']['path'] = None\n    \n    return CLRPModel(**cfg['model'])","metadata":{"execution":{"iopub.status.busy":"2021-07-21T13:31:59.790649Z","iopub.execute_input":"2021-07-21T13:31:59.791109Z","iopub.status.idle":"2021-07-21T13:31:59.799621Z","shell.execute_reply.started":"2021-07-21T13:31:59.791075Z","shell.execute_reply":"2021-07-21T13:31:59.798717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss / Metric","metadata":{"papermill":{"duration":0.028201,"end_time":"2021-07-14T20:43:21.90631","exception":false,"start_time":"2021-07-14T20:43:21.878109","status":"completed"},"tags":[],"id":"important-school"}},{"cell_type":"code","source":"def RMSE(y_pred, y_gt):\n    assert y_pred.size() == y_gt.size()\n    \n    metric = nn.MSELoss()  \n    metric = torch.sqrt(metric(y_pred, y_gt))\n    return metric","metadata":{"papermill":{"duration":0.036939,"end_time":"2021-07-14T20:43:21.971602","exception":false,"start_time":"2021-07-14T20:43:21.934663","status":"completed"},"tags":[],"id":"extended-circus","execution":{"iopub.status.busy":"2021-07-21T13:31:59.800833Z","iopub.execute_input":"2021-07-21T13:31:59.801231Z","iopub.status.idle":"2021-07-21T13:31:59.809204Z","shell.execute_reply.started":"2021-07-21T13:31:59.801196Z","shell.execute_reply":"2021-07-21T13:31:59.808314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_loss_fn():\n    if cfg['loss']['name']=='RMSE':\n        return RMSE\n    elif cfg['loss']['name']=='MSE':\n        return nn.MSELoss(reduction='mean')\n    elif cfg['loss']['name']=='KLdiv':\n        return KLdiv_for_normal\n    \ndef get_metric_fn():\n    if cfg['metric']['name']=='RMSE':\n        return RMSE\n    elif cfg['loss']['name']=='MSE':\n        return nn.MSELoss(reduction='mean')","metadata":{"papermill":{"duration":0.036899,"end_time":"2021-07-14T20:43:22.03689","exception":false,"start_time":"2021-07-14T20:43:21.999991","status":"completed"},"tags":[],"id":"marine-helena","execution":{"iopub.status.busy":"2021-07-21T13:31:59.810538Z","iopub.execute_input":"2021-07-21T13:31:59.811Z","iopub.status.idle":"2021-07-21T13:31:59.819042Z","shell.execute_reply.started":"2021-07-21T13:31:59.810965Z","shell.execute_reply":"2021-07-21T13:31:59.818177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer","metadata":{"papermill":{"duration":0.028673,"end_time":"2021-07-14T20:43:22.094138","exception":false,"start_time":"2021-07-14T20:43:22.065465","status":"completed"},"tags":[],"id":"magnetic-organ"}},{"cell_type":"code","source":"from torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom transformers import get_cosine_schedule_with_warmup\nfrom transformers import get_constant_schedule\nfrom transformers import get_constant_schedule_with_warmup\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import AdamW\n\nfrom clrp_private_lib import get_slanted_triangular_lr\n\ndef get_optim(model_parameters):\n    if cfg['optim']['name']=='RAdam':\n        return RAdam(model_parameters, **cfg['optim']['params'])\n    elif cfg['optim']['name']=='AdamW':\n        return AdamW(model_parameters, **cfg['optim']['params'])\n    elif cfg['optim']['name']=='Adam':\n        return Adam(model_parameters, **cfg['optim']['params'])\n    \ndef get_scheduler(optim):\n    if cfg['scheduler']['name']=='constant':\n        return get_constant_schedule(optimizer=optim)\n    elif cfg['scheduler']['name']=='cosine_with_warmup':\n        return get_cosine_schedule_with_warmup(optimizer=optim, **cfg['scheduler']['params'])\n    elif cfg['scheduler']['name']=='constant_with_warmup':\n        return get_constant_schedule_with_warmup(optimizer=optim, **cfg['scheduler']['params'])\n    elif cfg['scheduler']['name']=='linear_with_warmup':\n        return get_linear_schedule_with_warmup(optimizer=optim, **cfg['scheduler']['params'])\n    elif cfg['scheduler']['name']=='slanted_triangular':\n        return get_slanted_triangular_lr(optimizer=optim, **cfg['scheduler']['params'])","metadata":{"papermill":{"duration":0.065437,"end_time":"2021-07-14T20:43:22.187914","exception":false,"start_time":"2021-07-14T20:43:22.122477","status":"completed"},"tags":[],"id":"weekly-defense","execution":{"iopub.status.busy":"2021-07-21T13:31:59.820441Z","iopub.execute_input":"2021-07-21T13:31:59.820856Z","iopub.status.idle":"2021-07-21T13:31:59.845694Z","shell.execute_reply.started":"2021-07-21T13:31:59.820801Z","shell.execute_reply":"2021-07-21T13:31:59.844908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_layerwise_params_to_optimize(model, lr_reg, lr_bert, wd_reg=0, wd_bert=1e-1):\n    \n    def contains_no_decay_attr(attr_name):\n        return any(no_decay_attr in attr_name for no_decay_attr in ['bias'])\n    \n    def layer_lr(name, lrs):\n        groups = []\n        for i in range(0, 12):\n            groups.append([f'layer.{j}.' for j in range(2 * i, 2 * (i + 1))]) # 12 groups\n\n        for i in range(12):\n            if any(layer in name for layer in groups[i]):\n                return lrs[i]\n    \n    non_decay_flag = lambda name: (\"regressor\" in name) \n    \n    # regressor\n    params = [{\n        'params': [param for name, param in model.named_parameters() if non_decay_flag(name)&(not contains_no_decay_attr(name))],\n        'weight_decay': wd_reg,\n        'lr': lr_reg\n    }]\n    params += [{\n        'params': [param for name, param in model.named_parameters() if non_decay_flag(name)&(contains_no_decay_attr(name))],\n        'weight_decay': 0.0,\n        'lr': lr_reg\n    }]\n    \n    # bert layer\n    groups = []\n    for i in range(0, 12):\n        groups.append([f'layer.{j}.' for j in range(2*i, 2*(i+1))]) # 12 groups\n            \n    group_freeze = ['embeddings']\n    \n    for i, (name, bert_params) in enumerate(model.bert.named_parameters()):\n        if any(layer in name for layer in group_freeze):\n            bert_params.requires_grad_(False)\n        else:\n            params += [{\n                'params': bert_params,\n                'weight_decay': wd_bert if not contains_no_decay_attr(name) else 0.0,\n                'lr': layer_lr(name, lrs=lr_bert) if not \"pooler\" in name else lr_reg\n            }]\n        \n    return params","metadata":{"papermill":{"duration":0.042354,"end_time":"2021-07-14T20:43:22.258884","exception":false,"start_time":"2021-07-14T20:43:22.21653","status":"completed"},"tags":[],"id":"disciplinary-buddy","execution":{"iopub.status.busy":"2021-07-21T13:31:59.847383Z","iopub.execute_input":"2021-07-21T13:31:59.847641Z","iopub.status.idle":"2021-07-21T13:31:59.862844Z","shell.execute_reply.started":"2021-07-21T13:31:59.847615Z","shell.execute_reply":"2021-07-21T13:31:59.861918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training / Inference","metadata":{"papermill":{"duration":0.028891,"end_time":"2021-07-14T20:43:22.316262","exception":false,"start_time":"2021-07-14T20:43:22.287371","status":"completed"},"tags":[],"id":"sharp-piece"}},{"cell_type":"code","source":"from torch.cuda.amp import GradScaler\nfrom torch.cuda.amp import autocast","metadata":{"papermill":{"duration":0.034215,"end_time":"2021-07-14T20:43:22.379318","exception":false,"start_time":"2021-07-14T20:43:22.345103","status":"completed"},"tags":[],"id":"mexican-joshua","execution":{"iopub.status.busy":"2021-07-21T13:31:59.864273Z","iopub.execute_input":"2021-07-21T13:31:59.864803Z","iopub.status.idle":"2021-07-21T13:31:59.872542Z","shell.execute_reply.started":"2021-07-21T13:31:59.86476Z","shell.execute_reply":"2021-07-21T13:31:59.871742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"papermill":{"duration":0.028622,"end_time":"2021-07-14T20:43:22.436302","exception":false,"start_time":"2021-07-14T20:43:22.40768","status":"completed"},"tags":[],"id":"virtual-shell"}},{"cell_type":"code","source":"class Gauge:\n    \n    def __init__(self):\n        self.gauge = 0\n        self.count = 0\n        \n    def accumulate(self, gauge):\n        self.gauge += gauge\n        self.count += 1\n        \n    def get_mean(self, root=False):\n        return np.sqrt(self.gauge / self.count) if root else self.gauge / self.count","metadata":{"papermill":{"duration":0.035572,"end_time":"2021-07-14T20:43:22.500366","exception":false,"start_time":"2021-07-14T20:43:22.464794","status":"completed"},"tags":[],"id":"creative-vitamin","execution":{"iopub.status.busy":"2021-07-21T13:31:59.875557Z","iopub.execute_input":"2021-07-21T13:31:59.875811Z","iopub.status.idle":"2021-07-21T13:31:59.884049Z","shell.execute_reply.started":"2021-07-21T13:31:59.875788Z","shell.execute_reply":"2021-07-21T13:31:59.883136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_val_spacing(val_metric):\n    if val_metric > 0.5:\n        return 16\n    elif val_metric > 0.49:\n        return 8\n    elif val_metric > 0.48:\n        return 4\n    elif val_metric > 0.47:\n        return 2\n    else:\n        return 1\n\ndef get_dls_for_n_fold(df, fold, tokenizer):\n    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n    \n    train_ds = CLRPDataset(\n        train_df,\n        tokenizer=tokenizer\n    )\n    \n    val_ds = CLRPDataset(\n        val_df, \n        tokenizer=tokenizer\n    )\n    \n    if cfg['sampler']['name'] is not None:\n        cfg['dl']['train']['sampler'] = get_sampler(df=train_df, \n                                                    batch_size=cfg['dl']['train']['batch_size'])\n    else:\n        cfg['dl']['train']['shuffle'] = True\n    \n    train_dl = DataLoader(train_ds, **cfg['dl']['train'])\n    val_dl = DataLoader(val_ds, **cfg['dl']['val'])\n    \n    return train_dl, val_dl\n\ndef get_modules(model):\n    loss_fn = get_loss_fn()\n    metric_fn = get_metric_fn()\n    \n    params_to_optimize = get_layerwise_params_to_optimize(model,\n                                                **cfg['optim']['params_control'])\n    optim = get_optim(params_to_optimize)\n    scheduler = get_scheduler(optim)\n    \n    return loss_fn, metric_fn, optim ,scheduler\n\ndef get_inputs(batch):\n    keys_to_input = ['input_ids', 'attention_mask', 'token_type_ids']\n    inputs = {key: value.to(device) for key, value in batch.items() if key in keys_to_input}\n    return inputs\n\ndef get_targets(batch):\n    keys_to_output = ['target', 'se']\n    targets = {key: value.view(-1, 1).to(device) for key, value in batch.items() if key in keys_to_output}\n    if cfg['loss']['name']!='KLdiv':\n        return targets['target'] \n    else:\n        return torch.cat((targets['target'], targets['se']), dim=1)","metadata":{"papermill":{"duration":0.041968,"end_time":"2021-07-14T20:43:22.571231","exception":false,"start_time":"2021-07-14T20:43:22.529263","status":"completed"},"tags":[],"id":"certain-death","execution":{"iopub.status.busy":"2021-07-21T13:31:59.886195Z","iopub.execute_input":"2021-07-21T13:31:59.886511Z","iopub.status.idle":"2021-07-21T13:31:59.901911Z","shell.execute_reply.started":"2021-07-21T13:31:59.886481Z","shell.execute_reply":"2021-07-21T13:31:59.900987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Components","metadata":{"papermill":{"duration":0.028479,"end_time":"2021-07-14T20:43:22.628212","exception":false,"start_time":"2021-07-14T20:43:22.599733","status":"completed"},"tags":[],"id":"stable-memory"}},{"cell_type":"code","source":"def val_fn(model, dl, loss_fn, metric_fn):\n    scaler = GradScaler()\n    \n    losses = Gauge()\n    metrics = Gauge()\n    \n    model.eval()\n    model.to(device)\n    \n    with torch.no_grad():\n        for i, batch in enumerate(dl):\n            inputs = get_inputs(batch)\n            targets = get_targets(batch)\n            \n            with autocast():\n                last_hidden_states, outputs = model(**inputs)\n                loss = loss_fn(outputs, targets)\n                metric = metric_fn(outputs, targets)\n            \n            losses.accumulate(loss.item())\n            metrics.accumulate(metric.item())\n    \n    return losses.get_mean(), metrics.get_mean(root=True)","metadata":{"papermill":{"duration":0.036881,"end_time":"2021-07-14T20:43:22.693799","exception":false,"start_time":"2021-07-14T20:43:22.656918","status":"completed"},"tags":[],"id":"brief-cambodia","execution":{"iopub.status.busy":"2021-07-21T13:31:59.903419Z","iopub.execute_input":"2021-07-21T13:31:59.903984Z","iopub.status.idle":"2021-07-21T13:31:59.912959Z","shell.execute_reply.started":"2021-07-21T13:31:59.903945Z","shell.execute_reply":"2021-07-21T13:31:59.912147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculate CV Score","metadata":{"papermill":{"duration":0.028318,"end_time":"2021-07-14T20:43:22.817108","exception":false,"start_time":"2021-07-14T20:43:22.78879","status":"completed"},"tags":[],"id":"adequate-traffic"}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ncfg = torch.load(os.path.join(CV_PATH, \"cfg.pt\"), map_location=device)\n\n\ncfg['model']['name'] = ARCH_PATH\ncfg['tokenizer']['name'] = ARCH_PATH\n\npprint(cfg)","metadata":{"papermill":{"duration":0.050881,"end_time":"2021-07-14T20:43:22.960446","exception":false,"start_time":"2021-07-14T20:43:22.909565","status":"completed"},"tags":[],"id":"alike-latvia","outputId":"dfebb270-e34e-4646-8239-f132e8b22516","execution":{"iopub.status.busy":"2021-07-21T13:31:59.914209Z","iopub.execute_input":"2021-07-21T13:31:59.914826Z","iopub.status.idle":"2021-07-21T13:32:00.073791Z","shell.execute_reply.started":"2021-07-21T13:31:59.914787Z","shell.execute_reply":"2021-07-21T13:32:00.07293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pooled_last_hidden_state(last_hidden_states, pool='mean'):\n    last_hidden_states = last_hidden_states.detach().cpu().numpy()\n    if pool=='max':\n        return last_hidden_states.max(axis=1)\n    elif pool=='mean':\n        return last_hidden_states.mean(axis=1)\n\n    \ndef val_fn_cv(model, dl):\n    scaler = GradScaler()\n    preds = []\n    lhs = [] # last hidden state\n    \n    model.eval()\n    model.to(device)\n    \n    progress_bar = tqdm(dl, desc='cv')\n    \n    with torch.no_grad():\n        for i, batch in enumerate(progress_bar):\n            inputs = get_inputs(batch)\n            \n            with autocast():\n                last_hidden_states, outputs = model(**inputs)\n            \n            preds.append(outputs.detach().cpu().numpy())\n            lhs.append(pooled_last_hidden_state(last_hidden_states, pool='max'))\n    \n    preds = np.concatenate(preds)\n    lhs = np.concatenate(lhs)\n    \n    return lhs, preds\n\ndef main_cv():\n    seed_everything(SEED)\n    \n    lhs_list = []\n    \n    df = pd.read_csv(TRAIN)\n    tokenizer = get_tokenizer()\n    \n    for fold in range(cfg['train']['n_folds']):\n        train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n        \n        model = get_model(pretrained=False)\n        \n        PATH = os.path.join(CV_PATH, MODEL_NAME + f'_fold{fold}.tar')\n        saved_contents = torch.load(PATH, map_location=device)\n        model.load_state_dict(saved_contents['model'])\n        \n        if fold==0:\n            cfg_for_train = saved_contents['cfg']\n            print('Configuration for training:')\n            print()\n            pprint(cfg_for_train)\n            print()\n        \n        print('Fold:', fold)\n        \n        inputs = {'model': model,\n                  'dl': val_dl}\n        \n        lhs, preds = val_fn_cv(**inputs)\n        df.loc[df.fold==fold, 'oof'] = preds\n        if fold==0:\n            lhs_cols = [f'lhs_{i}' for i in range(lhs.shape[1])]\n            df[lhs_cols] = np.nan\n        df.loc[df.fold==fold, lhs_cols] = lhs\n\n    return df\n\n\ndef RMSE_(y_pred, y_gt):\n    mse = mean_squared_error(y_pred, y_gt)\n    return np.sqrt(mse)\n\ndef oof_vs_target(df, y='oof'):\n    temp_df = pd.DataFrame()\n    temp_df['x'] = np.linspace(-3.5, 1.5, 10)\n    temp_df['y'] = temp_df['x']\n\n    plt.figure(figsize=(8, 8))\n    sns.scatterplot(data=df, x='target', y=y, label=f'{y} vs target', hue='fold', palette='bright')\n    sns.lineplot(data=temp_df, x='x', y='y', color='orange')\n    plt.title('OOF Prediction vs Target')\n    plt.legend()\n    plt.show()","metadata":{"papermill":{"duration":0.048334,"end_time":"2021-07-14T20:43:23.037852","exception":false,"start_time":"2021-07-14T20:43:22.989518","status":"completed"},"tags":[],"id":"strategic-print","execution":{"iopub.status.busy":"2021-07-21T13:32:00.07611Z","iopub.execute_input":"2021-07-21T13:32:00.0765Z","iopub.status.idle":"2021-07-21T13:32:00.093508Z","shell.execute_reply.started":"2021-07-21T13:32:00.076458Z","shell.execute_reply":"2021-07-21T13:32:00.092714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif CV:\n    df = main_cv()\n    df.to_csv(os.path.join(CV_PATH if COLAB else '.', 'oof_df.csv'), index=False)\n\n    print('CV score: ', RMSE_(df['target'], df['oof']))\n    oof_vs_target(df, y='oof')","metadata":{"papermill":{"duration":0.036334,"end_time":"2021-07-14T20:43:23.103118","exception":false,"start_time":"2021-07-14T20:43:23.066784","status":"completed"},"tags":[],"id":"assisted-notice","outputId":"906c9980-460b-422b-f433-97c218be2f40","execution":{"iopub.status.busy":"2021-07-21T13:32:00.094924Z","iopub.execute_input":"2021-07-21T13:32:00.095257Z","iopub.status.idle":"2021-07-21T13:35:22.065338Z","shell.execute_reply.started":"2021-07-21T13:32:00.095219Z","shell.execute_reply":"2021-07-21T13:35:22.064344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprocessing","metadata":{"papermill":{"duration":0.02932,"end_time":"2021-07-14T20:43:23.161618","exception":false,"start_time":"2021-07-14T20:43:23.132298","status":"completed"},"tags":[],"id":"lesbian-visit"}},{"cell_type":"code","source":"from sklearn import linear_model\n\nif POST:\n    lm = linear_model.LinearRegression()\n    lm.fit(df.loc[:, ['oof']], df['target'].values)\n\n    df['oof_post'] = lm.predict(df.loc[:, ['oof']])\n\n    score_oof_post = RMSE_(df['oof_post'], df['target'])\n    print('RMSE (oof post): ', score_oof_post)","metadata":{"papermill":{"duration":0.110309,"end_time":"2021-07-14T20:43:23.301582","exception":false,"start_time":"2021-07-14T20:43:23.191273","status":"completed"},"tags":[],"id":"defined-stylus","execution":{"iopub.status.busy":"2021-07-21T13:35:22.066664Z","iopub.execute_input":"2021-07-21T13:35:22.067005Z","iopub.status.idle":"2021-07-21T13:35:22.143713Z","shell.execute_reply.started":"2021-07-21T13:35:22.06697Z","shell.execute_reply":"2021-07-21T13:35:22.142855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.0297,"end_time":"2021-07-14T20:43:23.360674","exception":false,"start_time":"2021-07-14T20:43:23.330974","status":"completed"},"tags":[],"id":"military-curtis"}},{"cell_type":"code","source":"def main_infer():\n    seed_everything(SEED)\n    \n    df = pd.read_csv(TEST)\n    df['target'] = 0.\n    df['standard_error'] = 0.\n    \n    tokenizer = get_tokenizer()\n    \n    for fold in range(cfg['train']['n_folds']):\n        print('Fold:', fold)\n\n        test_ds = CLRPDataset(\n                    df, \n                    tokenizer=tokenizer\n                    )\n    \n        test_dl = DataLoader(test_ds, **cfg['dl']['val'])\n        \n        # if fold in [0, 1]:\n        #     CV_PATH = TRAINED[0]\n        # elif fold in [2, 3]:\n        #     CV_PATH =TRAINED[1]\n        # else:\n        #     CV_PATH = TRAINED[2]\n\n        model = get_model(pretrained=False)\n        PATH = os.path.join(CV_PATH, MODEL_NAME + f'_fold{fold}.tar')\n        state_dict = torch.load(PATH, map_location=device)['model']\n        model.load_state_dict(state_dict)\n\n        inputs = {'model': model,\n                  'dl': test_dl}\n        \n        lhs, preds = val_fn_cv(**inputs)\n        df['target'] = df['target'] + np.concatenate(preds)\n    \n    df['target'] = df['target'] / cfg['train']['n_folds']\n    return df","metadata":{"papermill":{"duration":0.039702,"end_time":"2021-07-14T20:43:23.429957","exception":false,"start_time":"2021-07-14T20:43:23.390255","status":"completed"},"tags":[],"id":"stretch-panel","execution":{"iopub.status.busy":"2021-07-21T13:35:22.14699Z","iopub.execute_input":"2021-07-21T13:35:22.147258Z","iopub.status.idle":"2021-07-21T13:35:22.155108Z","shell.execute_reply.started":"2021-07-21T13:35:22.147229Z","shell.execute_reply":"2021-07-21T13:35:22.153853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not CV:\n    df = main_infer()\n\n    if POST:\n        df['target'] = lm.predict(df.loc[:, ['target']])\n\n    df = df[['id', 'target']]\n    df.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":136.797732,"end_time":"2021-07-14T20:45:40.257008","exception":false,"start_time":"2021-07-14T20:43:23.459276","status":"completed"},"tags":[],"id":"tutorial-sunrise","outputId":"b919ebc9-48da-47c2-ec99-62456015c5f3","execution":{"iopub.status.busy":"2021-07-21T13:35:22.156824Z","iopub.execute_input":"2021-07-21T13:35:22.157223Z","iopub.status.idle":"2021-07-21T13:36:46.326105Z","shell.execute_reply.started":"2021-07-21T13:35:22.157186Z","shell.execute_reply":"2021-07-21T13:36:46.325231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}