{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nIn this notebook, I would like to show that **standard_error is a key feature**.  \nAfter adding standard_error to oof predictions, LGBM is trained on the features, and then do CV.\n\nHere is the result which shows what I want to tell.\n\n| Stacking Layer                | CV Score | Boost   | \n| ----------------------------- | -------- | ------- | \n| Linear (baseline)             | 0.4567   | -       | \n| LGBM (without standard_error) | 0.4596   | -0.0029 | \n| LGBM (with standard_error)    | 0.3959   | 0.069   | ","metadata":{}},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n\nimport optuna\nimport optuna.integration.lightgbm as lgb\noptuna.logging.disable_default_handler()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:17:18.405709Z","iopub.execute_input":"2021-08-03T03:17:18.406089Z","iopub.status.idle":"2021-08-03T03:17:18.414065Z","shell.execute_reply.started":"2021-08-03T03:17:18.406053Z","shell.execute_reply":"2021-08-03T03:17:18.412822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 28\n\ndef RMSE_(y_pred, y_gt):\n    mse = mean_squared_error(y_pred, y_gt)\n    return np.sqrt(mse)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:20:37.065557Z","iopub.execute_input":"2021-08-03T03:20:37.065903Z","iopub.status.idle":"2021-08-03T03:20:37.074747Z","shell.execute_reply.started":"2021-08-03T03:20:37.065873Z","shell.execute_reply":"2021-08-03T03:20:37.073558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT Variants with Custom Head\nI trained many\n* architecture (Roberta, Electra, XLNet and Funnel)\n* size (base and large)\n* head (attention, conv1D, meanpooling and so on).\n\nThis is for model diversity.","metadata":{}},{"cell_type":"code","source":"TRAIN = '../input/clrp-stratify-on-predictability/train_oof_stratified.csv'\n\nCV_PATHS = [\n    {'model_type': 0,\n     'path': '../input/clrp-robertalarge-attentions-mask-act',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 1,\n     'path': '../input/clrp-robertalarge-conv1d-attentions-mask',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 2,\n     'path': '../input/clrp-robertabase-from-colab',\n     'model_name': 'CLRPModelColab'},\n    {'model_type': 3,\n     'path': '../input/clrp-electralarge-attentions-mask-act',\n     'model_name': 'CLRPModelLarge'},\n#     {'model_type': 8,\n#      'path': '../input/clrp-electra-base-attentions',\n#      'model_name': 'CLRPModel'},\n#     {'model_type': 5,\n#      'path': '../input/clrp-xlnet-base-attentions',\n#      'model_name': 'CLRPModel'},\n    {'model_type': 4,\n     'path': '../input/clrp-xlnetlarge-attentions-mask',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 5,\n     'path': '../input/clrp-electralarge-attentions-conv1d',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 6,\n     'path': '../input/clrp-robertalarge-meanpooling',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 7,\n     'path': '../input/clrp-funnellarge-attentions-act',\n     'model_name': 'CLRPModelLarge'},\n]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:18:57.032382Z","iopub.execute_input":"2021-08-03T03:18:57.03275Z","iopub.status.idle":"2021-08-03T03:18:57.039825Z","shell.execute_reply.started":"2021-08-03T03:18:57.032719Z","shell.execute_reply":"2021-08-03T03:18:57.038835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(TRAIN)\n\noofs = []\n\nfor cv_path in CV_PATHS:\n    model_type = cv_path['model_type']\n    oofs.append(f'oof_{model_type}')\n    temp_df = pd.read_csv(os.path.join(cv_path['path'], 'oof_df.csv'))\n    df[f'oof_{model_type}'] = temp_df['oof']","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:18:57.764455Z","iopub.execute_input":"2021-08-03T03:18:57.764834Z","iopub.status.idle":"2021-08-03T03:19:04.835574Z","shell.execute_reply.started":"2021-08-03T03:18:57.764803Z","shell.execute_reply":"2021-08-03T03:19:04.834646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VIF Calculation\nI check the model diversity using VIF approximately.  \nEven if the heads are different, Robarta-large based models have big vif values.","metadata":{}},{"cell_type":"code","source":"vif_df = pd.DataFrame()\nvif_df['model_type'] = [f'model_{i}' for i, cv_path in enumerate(CV_PATHS)]\n\nvif_df['vif'] = [vif(df.loc[:, oofs].values, i) for i in range(len(oofs))]\nvif_df['score'] = [RMSE_(df['target'], df[f'oof_{i}']) for i in range(len(CV_PATHS))]\n\nvif_df","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:19:15.036267Z","iopub.execute_input":"2021-08-03T03:19:15.036642Z","iopub.status.idle":"2021-08-03T03:19:15.120138Z","shell.execute_reply.started":"2021-08-03T03:19:15.036609Z","shell.execute_reply":"2021-08-03T03:19:15.118643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection By OOF to Stacking","metadata":{}},{"cell_type":"code","source":"flag = True\nvif_df['use'] = False\n\nmodel_oof_dict = {f'model_{i}': f'oof_{i}' for i in range(len(CV_PATHS))}\n\nscore = vif_df['score']\nprint('Single Best Model: ', vif_df.loc[np.argmin(score)])\nprint()\nvif_df.loc[np.argmin(score), 'use'] = True\n\nbest_score_before = np.min(vif_df['score'])\nbest_scores = []\n\nn_models = 0\n\nwhile flag:\n    n_models += 1\n    print('-' * 40)\n    print(f'# Model = {n_models}')\n    temp_df = vif_df.loc[vif_df.use==False]\n    n_models_to_add = len(temp_df)\n    models_to_add = temp_df.model_type.tolist()\n    \n    stacking_score = []\n    weights = []\n    intercept = []\n    for model in models_to_add:\n        fe_cols = vif_df.loc[(vif_df.use) | (vif_df.model_type==model), 'model_type'].tolist()\n        print(fe_cols)\n        oofs= [model_oof_dict[model_type] for model_type in fe_cols]\n        features = df[oofs].values\n        targets = df['target'].values\n        \n        lm = linear_model.LinearRegression(fit_intercept=True)\n        lm.fit(features, targets)\n        \n        df['oof_stacking'] = 0.0\n        for i, oof_col in enumerate(oofs):\n            df['oof_stacking'] += lm.coef_[i] * df[oof_col]\n            \n        df['oof_stacking'] += lm.intercept_\n        temp_score = RMSE_(df['target'], df['oof_stacking'])\n        stacking_score.append(temp_score)\n        weights.append(lm.coef_)\n        intercept.append(lm.intercept_)\n        print('CV score (stacking): ', temp_score)\n        print()\n        \n    stacking_score = np.array(stacking_score)\n    best_arg = np.argmin(stacking_score)\n    \n    best_score = stacking_score[best_arg]\n    best_model = models_to_add[best_arg]\n    best_weight = weights[best_arg]\n    best_intercept = intercept[best_arg]\n    \n    delta = -(best_score - best_score_before)\n    \n    print('Best Model: ', best_model)\n    print('Best Score: ', best_score)\n    print('Delta: ', delta)\n    print('Weight: ', best_weight)\n    print('Intercept: ', best_intercept)\n    vif_df.loc[vif_df.model_type==best_model, 'use'] = True\n    best_scores.append(best_score)\n    \n    if delta < 0:\n        flag = False\n        print('Stacking Stop. Score does not increase anymore.')\n        \n    best_score_before = best_score\n    \n    if vif_df.sum()['use']==len(CV_PATHS): flag = False\n        \n    print()\n    print()\n\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(best_scores)+1), best_scores, marker='o')\nplt.xticks(range(1, len(best_scores)+1))\nplt.title('Stacking Score')\nplt.xlabel('# Models')\nplt.ylabel('Score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:19:25.120286Z","iopub.execute_input":"2021-08-03T03:19:25.120669Z","iopub.status.idle":"2021-08-03T03:19:25.805574Z","shell.execute_reply.started":"2021-08-03T03:19:25.120634Z","shell.execute_reply":"2021-08-03T03:19:25.804332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As model added, the boost decreases.  \nIn this stacking, the model diversity plays an important role (see the weight for each model).","metadata":{}},{"cell_type":"markdown","source":"# Features: BERTs OOF + Standard Error","metadata":{}},{"cell_type":"code","source":"def show_importance(fe, opt):\n    fe_df = pd.DataFrame()\n    fe_df['feature'] = fe\n    fe_df['importance'] = opt.feature_importance(importance_type='gain')\n    \n    plt.figure(figsize=(12, 6))\n    sns.barplot(data=fe_df, y='feature', x='importance')\n    plt.title('Feature Importance')\n    plt.show()\n    \n\nclass OptLGBM:\n    def __init__(self, df, fe, opt_fe='standard_error'):\n        self.df = df\n        self.fe = fe\n        self.opt_fe = opt_fe\n        \n        self.best_scores = []\n        self.best_params = []\n        self.best_models = []\n        \n        self.df['opt_fe_oof'] = np.nan\n         \n    def optimize(self, num_boost_round=1000, early_stopping_rounds=500):\n        for fold in range(5):\n            train_df = self.df.loc[self.df.fold!=fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n            val_df = self.df.loc[self.df.fold==fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n\n            train_ds = lgb.Dataset(train_df.loc[:, self.fe], train_df.loc[:, self.opt_fe])\n            val_ds = lgb.Dataset(val_df.loc[:, self.fe], val_df.loc[:, self.opt_fe])\n\n            params = {\n                'objective': 'regression',\n                'metric': 'rmse',\n                'verbosity': -1,\n                'boosting_type': 'gbdt',\n                'seed': SEED,\n            }\n\n            opt = lgb.train(params, \n                            train_ds, \n                            valid_sets=val_ds, \n                            num_boost_round=num_boost_round, \n                            verbose_eval=False, \n                            early_stopping_rounds=early_stopping_rounds,\n                            show_progress_bar=False)\n\n            print(f'fold {fold}: ', opt.best_score['valid_0']['rmse'])\n            self.best_scores.append(opt.best_score['valid_0']['rmse'])\n            self.best_params.append(opt.params)\n            self.best_models.append(opt.best_iteration)\n            \n            preds = opt.predict(val_df.loc[:, self.fe], num_iteration=opt.best_iteration)\n            self.df.loc[self.df.fold==fold, 'opt_fe_oof'] = preds\n            \n            self._show_importance(opt)\n            \n        print('CV Score: ', RMSE_(self.df[self.opt_fe], self.df['opt_fe_oof']))\n        \n    def _show_importance(self, opt):\n        show_importance(fe=self.fe, opt=opt)\n        \n    def retrain(self, col='se'):\n        self.df[col] = np.nan\n        \n        for fold in range(5):\n            train_df = self.df.loc[self.df.fold!=fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n            val_df = self.df.loc[self.df.fold==fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n        for fold in range(5):\n            train_df = self.df.loc[self.df.fold!=fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n            val_df = self.df.loc[self.df.fold==fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n\n            train_ds = lgb.Dataset(train_df.loc[:, self.fe], train_df.loc[:, self.opt_fe])\n            val_ds = lgb.Dataset(val_df.loc[:, self.fe], val_df.loc[:, self.opt_fe])\n            \n            params = self.best_params[fold]\n            \n            model = lgb_original.train(params, \n                            train_ds, \n                            valid_sets=val_ds, \n                            verbose_eval=False)\n            \n            model.save_model(f'lgb_{col}_fold{fold}.pkl')\n            self.df.loc[self.df.fold==fold, col] = model.predict(val_df.loc[:, self.fe])\n            \n        print('CV Score (retrained): ', RMSE_(self.df[self.opt_fe], self.df[col]))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:26:05.957414Z","iopub.execute_input":"2021-08-03T03:26:05.957833Z","iopub.status.idle":"2021-08-03T03:26:05.98305Z","shell.execute_reply.started":"2021-08-03T03:26:05.957798Z","shell.execute_reply":"2021-08-03T03:26:05.981703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Without standard_error ......","metadata":{}},{"cell_type":"code","source":"fe_oofs = [f'oof_{i}' for i in range(len(CV_PATHS))]\n\nopt = OptLGBM(df=df, fe=fe_oofs, opt_fe='target')\nopt.optimize(num_boost_round=100, early_stopping_rounds=50)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:26:42.084382Z","iopub.execute_input":"2021-08-03T03:26:42.084947Z","iopub.status.idle":"2021-08-03T03:27:08.66421Z","shell.execute_reply.started":"2021-08-03T03:26:42.084909Z","shell.execute_reply":"2021-08-03T03:27:08.663028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## With standard_error ......","metadata":{}},{"cell_type":"code","source":"fe = fe_oofs + ['standard_error']","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:21:10.694131Z","iopub.execute_input":"2021-08-03T03:21:10.694488Z","iopub.status.idle":"2021-08-03T03:21:10.699428Z","shell.execute_reply.started":"2021-08-03T03:21:10.694457Z","shell.execute_reply":"2021-08-03T03:21:10.69832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = OptLGBM(df=df, fe=fe, opt_fe='target')\nopt.optimize(num_boost_round=100, early_stopping_rounds=50)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T03:21:11.13335Z","iopub.execute_input":"2021-08-03T03:21:11.133738Z","iopub.status.idle":"2021-08-03T03:21:43.916778Z","shell.execute_reply.started":"2021-08-03T03:21:11.133705Z","shell.execute_reply":"2021-08-03T03:21:43.915947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results\n\nFrom these experiments, we get the result table below.  \nAs you can see, the **standard_error plays an very important role** for the target prediction.  \nFeature importance for standard_error is comparable to target predictions from BERT variants (see above).\n\nHowever, standard_error is not given, we must predict it in addition to target if we want to take it into account.  \nThat is another difficult task.","metadata":{}},{"cell_type":"markdown","source":"| Stacking Layer                | CV Score | Boost   | \n| ----------------------------- | -------- | ------- | \n| Linear (baseline)             | 0.4567   | -       | \n| LGBM (without standard_error) | 0.4596   | -0.0029 | \n| LGBM (with standard_error)    | 0.3959   | 0.069   | ","metadata":{}}]}