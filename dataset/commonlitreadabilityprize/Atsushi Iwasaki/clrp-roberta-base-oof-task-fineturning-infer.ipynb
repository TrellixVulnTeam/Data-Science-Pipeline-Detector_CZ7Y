{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport gc\nfrom pprint import pprint\nfrom tqdm import tqdm\nimport more_itertools\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Sampler\nfrom torch.utils.data import RandomSampler\n\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig\nfrom transformers import AutoModelForMaskedLM\nfrom transformers import DataCollatorForLanguageModeling\nfrom transformers import DataCollatorWithPadding\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:44.920071Z","iopub.execute_input":"2021-07-09T14:08:44.920433Z","iopub.status.idle":"2021-07-09T14:08:44.935705Z","shell.execute_reply.started":"2021-07-09T14:08:44.920396Z","shell.execute_reply":"2021-07-09T14:08:44.934736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:44.937297Z","iopub.execute_input":"2021-07-09T14:08:44.938068Z","iopub.status.idle":"2021-07-09T14:08:44.948747Z","shell.execute_reply.started":"2021-07-09T14:08:44.93803Z","shell.execute_reply":"2021-07-09T14:08:44.948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\nTRAIN = '../input/commonlitreadabilityprize/train.csv'\nTRAIN = '../input/clrp-robertabase-from-colab/oof_df_for_train.csv'\nTEST = '../input/commonlitreadabilityprize/test.csv'\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device: ', device.type)\n\nSEED = 567\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:44.952367Z","iopub.execute_input":"2021-07-09T14:08:44.952668Z","iopub.status.idle":"2021-07-09T14:08:44.961247Z","shell.execute_reply.started":"2021-07-09T14:08:44.952637Z","shell.execute_reply":"2021-07-09T14:08:44.960463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Model Architecture ###\n# BERT\nBERT = '../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased'\n\n# Distilbert\nDISTILBERT = '../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased'\n\n# Roberta\nROBERTA = '../input/huggingface-roberta-variants/roberta-base/roberta-base'\nROBERTA_LARGE = '../input/huggingface-roberta-variants/roberta-large/roberta-large'\n\n### Trained Weights ###\nTRAINED = '../input/clrp-robertabase-from-colab'\nMODEL_NAME = 'CLRPModelColab'\n\n\ntest_df = pd.read_csv(TEST)\nCV = True\nPOST = True\n\n\ncfg ={}\n\nARCH_PATH = ROBERTA\ncfg['train'] = {'n_folds': 5}\n\ncfg['TTA'] = {'use': False, 'n_tta': 4}","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:44.963782Z","iopub.execute_input":"2021-07-09T14:08:44.964875Z","iopub.status.idle":"2021-07-09T14:08:44.977324Z","shell.execute_reply.started":"2021-07-09T14:08:44.964828Z","shell.execute_reply":"2021-07-09T14:08:44.976535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"cfg['tokenizer'] ={\n    'name': ARCH_PATH,\n    'params':{\n        'add_special_tokens':True, \n        'padding': 'longest', \n        'max_length': 258, \n        'truncation': True,\n        'return_special_tokens_mask': True\n    }\n    }\n\ndef get_tokenizer():\n    return AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:44.978611Z","iopub.execute_input":"2021-07-09T14:08:44.978952Z","iopub.status.idle":"2021-07-09T14:08:44.986019Z","shell.execute_reply.started":"2021-07-09T14:08:44.978919Z","shell.execute_reply":"2021-07-09T14:08:44.985182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    df = pd.read_csv(TRAIN)\n    text = df.loc[SEED, 'excerpt']\n    print('Text Length ', len(text.split(' ')))\n    print()\n    \n    text_tokenized = tokenizer.encode_plus(\n                        text,\n                        add_special_tokens=True,\n                        padding='max_length',\n                        max_length=cfg['tokenizer']['max_length'], \n                        truncation=True\n                        )\n    \n    for key, value in text_tokenized.items():\n        print(key, type(value))\n        print(value)\n        print()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-09T14:08:44.987295Z","iopub.execute_input":"2021-07-09T14:08:44.987712Z","iopub.status.idle":"2021-07-09T14:08:44.995727Z","shell.execute_reply.started":"2021-07-09T14:08:44.98768Z","shell.execute_reply":"2021-07-09T14:08:44.994901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.replace('\\n', '')\n    return text\n\nclass CLRPDataset(Dataset):\n    \n    def __init__(self, df, tokenizer):\n        self.df = df\n        self.texts = self.df['excerpt'].tolist()\n        self.targets = self.df['target'].tolist()\n        self.se = self.df['standard_error'].tolist()\n        self.tokenizer = tokenizer\n#         self.max_length = max_length\n#         self.masking_prob = masking_prob\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, index):\n        text = clean_text(self.texts[index])\n        tokenized_text = self.tokenizer.encode_plus(\n            text,\n            **cfg['tokenizer']['params']\n        )\n        \n        tokenized_text['target'] = self.targets[index]\n        tokenized_text['se'] = self.se[index]\n        return tokenized_text","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:44.996994Z","iopub.execute_input":"2021-07-09T14:08:44.99739Z","iopub.status.idle":"2021-07-09T14:08:45.006456Z","shell.execute_reply.started":"2021-07-09T14:08:44.997348Z","shell.execute_reply":"2021-07-09T14:08:45.005338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"cfg['collator'] = {\n    'train': {\n        'name': 'MLM', \n        'params':{\n            'mlm_probability': 0.1\n            }},\n    'val': {\n        'name': 'padding' if not cfg['TTA']['use'] else 'MLM',\n        'params': {\n            None if not cfg['TTA']['use'] else 'mlm_probability': 0.03 # Here !\n        }\n    }}\n\ndef get_collator(tokenizer, phase='train'):\n    \n    def _prepare_collator(name, phase):\n        if name=='MLM':\n            return DataCollatorForLanguageModeling(tokenizer=tokenizer, \n                                                   **cfg['collator'][phase]['params'])\n        elif name=='padding':\n            return DataCollatorWithPadding(tokenizer=tokenizer)\n    \n    return _prepare_collator(cfg['collator'][phase]['name'], phase=phase)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.175258Z","iopub.execute_input":"2021-07-09T14:08:45.175567Z","iopub.status.idle":"2021-07-09T14:08:45.182066Z","shell.execute_reply.started":"2021-07-09T14:08:45.175525Z","shell.execute_reply":"2021-07-09T14:08:45.181075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SmartBatchingSampler(Sampler):\n    def __init__(self, data_source, batch_size):\n        super(SmartBatchingSampler, self).__init__(data_source)\n        sample_lengths = [len(seq) for seq in data_source]\n        argsort_inds = np.argsort(sample_lengths)\n        self.batches = list(more_itertools.chunked(argsort_inds, n=batch_size))\n        self._backsort_inds = None\n    \n    def __iter__(self):\n        if self.batches:\n            last_batch = self.batches.pop(-1)\n            np.random.shuffle(self.batches)\n            self.batches.append(last_batch)\n        self._inds = list(more_itertools.flatten(self.batches))\n        yield from self._inds\n\n    def __len__(self):\n        return len(self._inds)\n    \n    @property\n    def backsort_inds(self):\n        if self._backsort_inds is None:\n            self._backsort_inds = np.argsort(self._inds)\n        return self._backsort_inds\n    \ndef get_SmartBatchingSampler(df, batch_size):\n    data_source = df.excerpt.apply(lambda x: x.split(' '))\n    return SmartBatchingSampler(data_source=data_source, batch_size=batch_size)\n\ndef get_RandomSampler(df):\n    data_source = df.excerpt.apply(lambda x: x.split(' '))\n    return RandomSampler(data_source=data_source)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.183805Z","iopub.execute_input":"2021-07-09T14:08:45.184262Z","iopub.status.idle":"2021-07-09T14:08:45.19852Z","shell.execute_reply.started":"2021-07-09T14:08:45.184179Z","shell.execute_reply":"2021-07-09T14:08:45.197604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg['sampler'] = {'name': 'SmartBatchSampler',\n                  'params': {}}\n\ndef get_sampler(df=None, batch_size=None):\n    if cfg['sampler']['name']=='SmartBatchSampler':\n        return get_SmartBatchingSampler(df, batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.200804Z","iopub.execute_input":"2021-07-09T14:08:45.202027Z","iopub.status.idle":"2021-07-09T14:08:45.209282Z","shell.execute_reply.started":"2021-07-09T14:08:45.201989Z","shell.execute_reply":"2021-07-09T14:08:45.20853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer= get_tokenizer()\n\ncfg['dl'] ={\n    'train': {\n        'batch_size': 8 if device.type=='cpu' else 16,\n        'shuffle': False,\n        'collate_fn': get_collator(tokenizer, phase='train'),\n        'num_workers': os.cpu_count(), \n        'pin_memory': True,\n},\n    'val': {\n        'batch_size': 8 if device.type=='cpu' else 16, \n        'shuffle': False, \n        'collate_fn': get_collator(tokenizer, phase='val'),\n        'num_workers': os.cpu_count(), \n        'pin_memory': True\n    }}","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.210921Z","iopub.execute_input":"2021-07-09T14:08:45.211267Z","iopub.status.idle":"2021-07-09T14:08:45.300794Z","shell.execute_reply.started":"2021-07-09T14:08:45.211233Z","shell.execute_reply":"2021-07-09T14:08:45.29996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"cfg['model'] = {'name': ARCH_PATH, \n                'path': '', \n                'p': 0.2, \n                'with_se': False,\n                'attention': True}","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.302704Z","iopub.execute_input":"2021-07-09T14:08:45.302953Z","iopub.status.idle":"2021-07-09T14:08:45.310352Z","shell.execute_reply.started":"2021-07-09T14:08:45.302929Z","shell.execute_reply":"2021-07-09T14:08:45.309562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Regressor(nn.Module):\n    \n    def __init__(self, in_features=768, p=0.2, with_se=False):\n        super().__init__()\n        self.in_features = in_features\n        self.p = p\n        self.with_se = with_se\n        \n        self.LayerNorm = nn.LayerNorm(self.in_features)\n        self.dropout = nn.Dropout(p=self.p)\n        self.fc = nn.Linear(in_features, 2 if self.with_se else 1)\n        \n    def forward(self, x):\n        x = self.LayerNorm(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x\n\nclass AttentionRegressor(nn.Module):\n    \n    def __init__(self, in_features=768, hidden_state=512, with_se=False):\n        super().__init__()\n        self.in_features = in_features\n        self.hidden_state = hidden_state\n        self.with_se = with_se\n        \n        self.attention = nn.Sequential(\n            nn.Linear(self.in_features, self.hidden_state),\n            nn.Tanh(),\n            nn.Linear(self.hidden_state, 1),\n            nn.Softmax(dim=1)\n        )\n        \n        self.fc = nn.Linear(self.in_features, 2 if self.with_se else 1)\n\n        torch.nn.init.kaiming_normal_(self.fc.weight)\n        torch.nn.init.kaiming_normal_(self.attention[0].weight)\n        torch.nn.init.kaiming_normal_(self.attention[2].weight)\n        \n    def forward(self, x):\n        weights = self.attention(x)\n        context = torch.sum(weights * x, dim=1)\n        output = self.fc(context)\n        return output\n\nclass CLRPModel(nn.Module):\n    \n    def __init__(self, name, p=0.2, with_se=False, path=None, attention=False):\n        super(CLRPModel, self).__init__()\n        \n        self.name = name\n        self.path = path\n        self.p = p\n        self.with_se = with_se\n        self.attention = attention\n        \n        config = AutoConfig.from_pretrained(name)  # This setting is from https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch\n        config.update({'output_hidden_states': False,\n                       'max_position_embeddings': 514,\n                       'hidden_dropout_prob': 0.0,\n                       'attention_probs_dropout_prob': 0.1,  # これも怪しい\n                       'layer_norm_eps': 1e-7})\n        \n        self.bert = AutoModel.from_pretrained(name)\n        if path: self._load_pretrained_weights()\n        \n        if name in [BERT, ROBERTA, ROBERTA_LARGE]:\n            self.in_features = self.bert.pooler.dense.out_features\n        elif name == DISTILBERT:\n            self.in_features = self.bert.transformer.layer[5].output_layer_norm.normalized_shape[0]\n            self.dense = nn.Linear(self.in_features, self.in_features)\n            self.activation = nn.Tanh()\n            torch.nn.init.kaiming_normal_(self.dense.weight)\n        else:\n            self.in_features = 768\n        \n        if self.attention:\n            self.regressor = AttentionRegressor(in_features=self.in_features,\n                                                hidden_state=514,\n                                                with_se=self.with_se)\n        else:\n            self.regressor = Regressor(in_features=self.in_features, \n                                       p=self.p, \n                                       with_se=self.with_se)\n        \n        \n    def _load_pretrained_weights(self):\n        model_pretrained = AutoModelForMaskedLM.from_pretrained(self.name)\n        checkpoint = torch.load(self.path, map_location=device)\n        model_pretrained.load_state_dict(checkpoint['model'])\n        \n        self.bert.embeddings = model_pretrained.roberta.embeddings\n        self.bert.encoder = model_pretrained.roberta.encoder\n        \n        del model_pretrained\n        gc.collect()\n        \n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        if self.name == BERT:\n            last_hidden_state, output = self.bert(input_ids=input_ids,\n                                                  attention_mask=attention_mask,\n                                                  token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        elif self.name == DISTILBERT:\n            last_hidden_state = self.bert(input_ids=input_ids, \n                                           attention_mask=attention_mask, \n                                           return_dict=False)\n            first_token_tensor = last_hidden_state[0][:, 0]\n            output = self.dense(first_token_tensor)\n            output = self.activation(output)\n            \n        elif self.name in [ROBERTA, ROBERTA_LARGE]:\n            last_hidden_state, output = self.bert(input_ids=input_ids,\n                                                  attention_mask=attention_mask,\n#                                                   token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        \n        if self.attention:\n            output = self.regressor(last_hidden_state)\n        else:\n            output = self.regressor(output)\n        \n        return last_hidden_state, output\n\n    \ndef get_model(pretrained=True, fold=None):\n    if pretrained:\n        PRETRAINED_MODEL = os.path.join(PRETRAINED_PATH, f'CLRPModelMLM_fold{fold}.tar')\n        cfg['model']['path'] = PRETRAINED_MODEL\n    else:\n        cfg['model']['path'] = None\n    \n    return CLRPModel(**cfg['model'])","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.313416Z","iopub.execute_input":"2021-07-09T14:08:45.313693Z","iopub.status.idle":"2021-07-09T14:08:45.338072Z","shell.execute_reply.started":"2021-07-09T14:08:45.313669Z","shell.execute_reply":"2021-07-09T14:08:45.337312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV / Inference","metadata":{}},{"cell_type":"code","source":"from torch.cuda.amp import GradScaler\nfrom torch.cuda.amp import autocast","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.339314Z","iopub.execute_input":"2021-07-09T14:08:45.339676Z","iopub.status.idle":"2021-07-09T14:08:45.351018Z","shell.execute_reply.started":"2021-07-09T14:08:45.33964Z","shell.execute_reply":"2021-07-09T14:08:45.35016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg['train'] ={\n    'n_folds': 5,\n    'n_epochs': 100\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.353902Z","iopub.execute_input":"2021-07-09T14:08:45.354139Z","iopub.status.idle":"2021-07-09T14:08:45.360669Z","shell.execute_reply.started":"2021-07-09T14:08:45.354116Z","shell.execute_reply":"2021-07-09T14:08:45.35982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stratified_from_oof(df, n_splits=5):\n    cols_to_use = ['id', 'url_legal', 'license', 'excerpt', 'target', 'standard_error', 'oof']\n    df = df.loc[:, cols_to_use]\n    df['abs_error'] = abs(df['oof'] - df['target'])\n    \n    n_bins = int(np.floor(1 + np.log2(len(df))))\n    df['bin'] = pd.cut(df.abs_error, n_bins, labels=False)\n    \n    skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n    df['fold'] = np.nan\n\n    for fold, (idx_tr, idx_val) in enumerate(skf.split(df.id, y=df.bin)):\n        df.loc[idx_val, 'fold'] = fold\n\n    df['fold'] = df['fold'].astype('int8')\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.364309Z","iopub.execute_input":"2021-07-09T14:08:45.364899Z","iopub.status.idle":"2021-07-09T14:08:45.373088Z","shell.execute_reply.started":"2021-07-09T14:08:45.364854Z","shell.execute_reply":"2021-07-09T14:08:45.372145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pooled_last_hidden_state(last_hidden_states, pool='max'):\n    last_hidden_states = last_hidden_states.detach().cpu().numpy()\n    if pool=='max':\n        return last_hidden_states.max(axis=1)\n    elif pool=='mean':\n        return last_hidden_states.mean(axis=1)\n\n    \ndef val_fn_cv(model, dl):\n    scaler = GradScaler()\n    preds = []\n    lhs = [] # last hidden state\n    \n    model.eval()\n    model.to(device)\n    \n    progress_bar = tqdm(dl, desc='cv')\n    \n    with torch.no_grad():\n        for i, batch in enumerate(progress_bar):\n            inputs = get_inputs(batch)\n            \n            with autocast():\n                last_hidden_states, outputs = model(**inputs)\n            \n            preds.append(outputs.detach().cpu().numpy())\n            lhs.append(pooled_last_hidden_state(last_hidden_states, pool='max'))\n    \n    preds = np.concatenate(preds)\n    lhs = np.concatenate(lhs)\n    \n    return lhs, preds\n\n\ndef main_cv():\n    seed_everything(SEED)\n    \n    lhs_list = []\n    \n    df = pd.read_csv(TRAIN)\n    df = df.loc[df.standard_error!=0].reset_index(drop=True)\n    df = get_stratified_from_oof(df)    \n    df['oof'] = np.nan\n\n    tokenizer = get_tokenizer()\n    \n    for fold in range(cfg['train']['n_folds']):\n        train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n        \n        model = get_model(pretrained=False)\n\n        PATH = os.path.join(TRAINED, MODEL_NAME + f'_fold{fold}.tar')\n        saved_contents = torch.load(PATH, map_location=device)\n        model.load_state_dict(saved_contents['model'])\n        \n        if fold==0:\n            cfg_for_train = saved_contents['cfg']\n            print('Configuration for training:')\n            print()\n            pprint(cfg_for_train)\n            print()\n        \n        print('Fold:', fold)\n        \n        inputs = {'model': model,\n                  'dl': val_dl}\n        \n        lhs, preds = val_fn_cv(**inputs)\n        df.loc[df.fold==fold, 'oof'] = preds\n        if fold==0:\n            lhs_cols = [f'lhs_{i}' for i in range(lhs.shape[1])]\n            df[lhs_cols] = np.nan\n        df.loc[df.fold==fold, lhs_cols] = lhs\n        \n        \n        if cfg['TTA']['use']:\n            for n_tta in range(1, cfg['TTA']['n_tta']):\n                lhs, preds = val_fn_cv(**inputs)\n                df.loc[df.fold==fold, 'oof'] += np.concatenate(preds)\n                \n            df.loc[df.fold==fold, 'oof'] /= cfg['TTA']['n_tta']\n\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.374595Z","iopub.execute_input":"2021-07-09T14:08:45.375062Z","iopub.status.idle":"2021-07-09T14:08:45.391834Z","shell.execute_reply.started":"2021-07-09T14:08:45.375027Z","shell.execute_reply":"2021-07-09T14:08:45.390946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dls_for_n_fold(df, fold, tokenizer):\n    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n    \n    train_ds = CLRPDataset(\n        train_df,\n        tokenizer=tokenizer\n    )\n    \n    val_ds = CLRPDataset(\n        val_df, \n        tokenizer=tokenizer\n    )\n    \n    if cfg['sampler']['name'] is not None:\n        cfg['dl']['train']['sampler'] = get_sampler(df=train_df, \n                                                    batch_size=cfg['dl']['train']['batch_size'])\n    else:\n        cfg['dl']['train']['shuffle'] = True\n    \n    train_dl = DataLoader(train_ds, **cfg['dl']['train'])\n    val_dl = DataLoader(val_ds, **cfg['dl']['val'])\n    \n    return train_dl, val_dl\n\n\ndef get_inputs(batch):\n    keys_to_input = ['input_ids', 'attention_mask', 'token_type_ids']\n    inputs = {key: value.to(device) for key, value in batch.items() if key in keys_to_input}\n    return inputs\n\n\ndef get_targets(batch):\n    keys_to_output = ['target', 'se']\n    targets = {key: value.view(-1, 1).to(device) for key, value in batch.items() if key in keys_to_output}\n    if cfg['loss']['name']!='KLdiv':\n        return targets['target'] \n    else:\n        return torch.cat((targets['target'], targets['se']), dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.393018Z","iopub.execute_input":"2021-07-09T14:08:45.393533Z","iopub.status.idle":"2021-07-09T14:08:45.404947Z","shell.execute_reply.started":"2021-07-09T14:08:45.393498Z","shell.execute_reply":"2021-07-09T14:08:45.404134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint(cfg)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.406336Z","iopub.execute_input":"2021-07-09T14:08:45.406787Z","iopub.status.idle":"2021-07-09T14:08:45.424537Z","shell.execute_reply.started":"2021-07-09T14:08:45.406754Z","shell.execute_reply":"2021-07-09T14:08:45.423827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_infer():\n    seed_everything(SEED)\n    \n    df = pd.read_csv(TEST)\n    df['target'] = 0.\n    df['standard_error'] = 0.\n    \n    tokenizer = get_tokenizer()\n    \n    for fold in range(cfg['train']['n_folds']):\n        print('Fold:', fold)\n\n        test_ds = CLRPDataset(\n                    df, \n                    tokenizer=tokenizer\n                    )\n    \n        test_dl = DataLoader(test_ds, **cfg['dl']['val'])\n\n        model = CLRPModel(**cfg['model'])\n        PATH = os.path.join(TRAINED, MODEL_NAME + f'_fold{fold}.tar')\n        state_dict = torch.load(PATH, map_location=device)['model']\n        model.load_state_dict(state_dict)\n\n        inputs = {'model': model,\n                  'dl': test_dl}\n        \n        lhs, preds = val_fn_cv(**inputs)\n        df['target'] = df['target'] + np.concatenate(preds)\n    \n    df['target'] = df['target'] / cfg['train']['n_folds']\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.42726Z","iopub.execute_input":"2021-07-09T14:08:45.427499Z","iopub.status.idle":"2021-07-09T14:08:45.434529Z","shell.execute_reply.started":"2021-07-09T14:08:45.427477Z","shell.execute_reply":"2021-07-09T14:08:45.433649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nif CV:\n    from sklearn.metrics import mean_squared_error\n\n    df = main_cv()\n    df.to_csv('oof_df.csv', index=False)\n    \n    mse = mean_squared_error(df['target'], df['oof'])\n    rmse = np.sqrt(mse)\n    print('CV score: ', rmse)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:08:45.435611Z","iopub.execute_input":"2021-07-09T14:08:45.435977Z","iopub.status.idle":"2021-07-09T14:09:39.495037Z","shell.execute_reply.started":"2021-07-09T14:08:45.435943Z","shell.execute_reply":"2021-07-09T14:09:39.494115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprocessing","metadata":{}},{"cell_type":"code","source":"if POST:\n    from sklearn import linear_model\n    from sklearn.metrics import mean_squared_error\n\n    def RMSE(y_pred, y_gt):\n        mse = mean_squared_error(y_pred, y_gt)\n        return np.sqrt(mse)\n\n    lm = linear_model.LinearRegression()\n    lm.fit(df.loc[:, ['oof']], df['target'].values)\n\n    df['oof_post'] = lm.predict(df.loc[:, ['oof']])\n\n    score_oof_post = RMSE(df['oof_post'], df['target'])\n    print('RMSE (oof post): ', score_oof_post)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:09:39.496481Z","iopub.execute_input":"2021-07-09T14:09:39.496846Z","iopub.status.idle":"2021-07-09T14:09:39.512537Z","shell.execute_reply.started":"2021-07-09T14:09:39.496805Z","shell.execute_reply":"2021-07-09T14:09:39.511493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = main_infer()\n\nif POST:\n    df['target'] = lm.predict(df.loc[:, ['target']])\n    \ndf = df[['id', 'target']]\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:09:39.513967Z","iopub.execute_input":"2021-07-09T14:09:39.51437Z","iopub.status.idle":"2021-07-09T14:09:57.969465Z","shell.execute_reply.started":"2021-07-09T14:09:39.514333Z","shell.execute_reply":"2021-07-09T14:09:57.968648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:09:57.970982Z","iopub.execute_input":"2021-07-09T14:09:57.971325Z","iopub.status.idle":"2021-07-09T14:09:57.98579Z","shell.execute_reply.started":"2021-07-09T14:09:57.971287Z","shell.execute_reply":"2021-07-09T14:09:57.984545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}