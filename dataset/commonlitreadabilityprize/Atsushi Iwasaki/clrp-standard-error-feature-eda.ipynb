{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/textstat/Pyphen-0.10.0-py3-none-any.whl\n!pip install ../input/textstat/textstat-0.7.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:01:26.023543Z","iopub.execute_input":"2021-08-02T22:01:26.024107Z","iopub.status.idle":"2021-08-02T22:02:20.714699Z","shell.execute_reply.started":"2021-08-02T22:01:26.024002Z","shell.execute_reply":"2021-08-02T22:02:20.713748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/sentencetransformer/sentence-transformers-1.0.4","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:02:20.718345Z","iopub.execute_input":"2021-08-02T22:02:20.71863Z","iopub.status.idle":"2021-08-02T22:02:49.594902Z","shell.execute_reply.started":"2021-08-02T22:02:20.7186Z","shell.execute_reply":"2021-08-02T22:02:49.593945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nimport textstat\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as vif\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport sys\nsys.path.append('../input/readability-package')\n\nimport readability\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk import pos_tag, pos_tag_sents\nimport string\nimport spacy\n\nimport optuna\nimport scipy\n\n# from bertopic import BERTopic\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\nimport sklearn.manifold\n\n# optuna.logging.disable_default_handler()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:02:49.597053Z","iopub.execute_input":"2021-08-02T22:02:49.597425Z","iopub.status.idle":"2021-08-02T22:02:59.151228Z","shell.execute_reply.started":"2021-08-02T22:02:49.597385Z","shell.execute_reply":"2021-08-02T22:02:59.150323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = text.replace('\\n', '')\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:02:59.152739Z","iopub.execute_input":"2021-08-02T22:02:59.153129Z","iopub.status.idle":"2021-08-02T22:02:59.160288Z","shell.execute_reply.started":"2021-08-02T22:02:59.153086Z","shell.execute_reply":"2021-08-02T22:02:59.159437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 567\n\nTRAIN = '../input/clrp-model-selection-from-oof-score/stacking_oof.csv'\n\ndf = pd.read_csv(TRAIN)\ndf['excerpt'] = df['excerpt'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:02:59.163587Z","iopub.execute_input":"2021-08-02T22:02:59.163871Z","iopub.status.idle":"2021-08-02T22:02:59.29993Z","shell.execute_reply.started":"2021-08-02T22:02:59.163845Z","shell.execute_reply":"2021-08-02T22:02:59.298718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Textstat\nCredit: https://www.kaggle.com/gunesevitan/commonlit-readability-prize-eda","metadata":{}},{"cell_type":"code","source":"# df['n_words'] = df['excerpt'].apply(textstat.lexicon_count)\n# df['n_unique_words'] = df['excerpt'].apply(lambda x: len(set(str(x).split())))\n\n# df['mean_word_len'] = df['excerpt'].apply(lambda x: np.mean([len(word) for word in str(x).split()]))\n# df['max_word_len'] = df['excerpt'].apply(lambda x: np.max([len(word) for word in str(x).split()]))\n# df['min_word_len'] = df['excerpt'].apply(lambda x: np.min([len(word) for word in str(x).split()]))\n\ndf['n_sentence'] = df['excerpt'].apply(textstat.sentence_count)\ndf['n_syllable'] = df['excerpt'].apply(textstat.syllable_count)\n\ndf['flesch_reading_ease'] = df['excerpt'].apply(textstat.flesch_reading_ease)\ndf['flesch_kincaid_grade'] = df['excerpt'].apply(textstat.flesch_kincaid_grade)\ndf['smog_index'] = df['excerpt'].apply(textstat.smog_index)\ndf['automated_readability_index'] = df['excerpt'].apply(textstat.automated_readability_index)\ndf['coleman_liau_index'] = df['excerpt'].apply(textstat.coleman_liau_index)\ndf['linsear_write_formula'] = df['excerpt'].apply(textstat.linsear_write_formula)\n\n# df['gunning_fog'] = df['excerpt'].apply(textstat.gunning_fog)\n# df['dale_chall'] = df['excerpt'].apply(textstat.dale_chall_readability_score)\n# df['n_difficult_words'] = df['excerpt'].apply(textstat.difficult_words)\n# df['consensus'] = df['excerpt'].apply(textstat.text_standard)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:02:59.305131Z","iopub.execute_input":"2021-08-02T22:02:59.305543Z","iopub.status.idle":"2021-08-02T22:03:16.293484Z","shell.execute_reply.started":"2021-08-02T22:02:59.305499Z","shell.execute_reply":"2021-08-02T22:03:16.292621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Readability\nCredit: https://www.kaggle.com/ravishah1/readability-feature-engineering-non-nn-baseline","metadata":{}},{"cell_type":"code","source":"def readability_measurements(passage: str):\n    \"\"\"\n    This function uses the readability library for feature engineering.\n    It includes textual statistics, readability scales and metric, and some pos stats\n    \"\"\"\n    results = readability.getmeasures(passage, lang='en')\n    \n    chars_per_word = results['sentence info']['characters_per_word']\n    syll_per_word = results['sentence info']['syll_per_word']\n    words_per_sent = results['sentence info']['words_per_sentence']\n    \n    kincaid = results['readability grades']['Kincaid']\n    ari = results['readability grades']['ARI']\n    coleman_liau = results['readability grades']['Coleman-Liau']\n    flesch = results['readability grades']['FleschReadingEase']\n    gunning_fog = results['readability grades']['GunningFogIndex']\n    lix = results['readability grades']['LIX']\n    smog = results['readability grades']['SMOGIndex']\n    rix = results['readability grades']['RIX']\n    dale_chall = results['readability grades']['DaleChallIndex']\n    \n    tobeverb = results['word usage']['tobeverb']\n    auxverb = results['word usage']['auxverb']\n    conjunction = results['word usage']['conjunction']\n    pronoun = results['word usage']['pronoun']\n    preposition = results['word usage']['preposition']\n    nominalization = results['word usage']['nominalization']\n    \n    pronoun_b = results['sentence beginnings']['pronoun']\n    interrogative = results['sentence beginnings']['interrogative']\n    article = results['sentence beginnings']['article']\n    subordination = results['sentence beginnings']['subordination']\n    conjunction_b = results['sentence beginnings']['conjunction']\n    preposition_b = results['sentence beginnings']['preposition']\n\n    \n    return [chars_per_word, syll_per_word, words_per_sent,\n            kincaid, ari, coleman_liau, flesch, gunning_fog, lix, smog, rix, dale_chall,\n            tobeverb, auxverb, conjunction, pronoun, preposition, nominalization,\n            pronoun_b, interrogative, article, subordination, conjunction_b, preposition_b]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:16.294891Z","iopub.execute_input":"2021-08-02T22:03:16.295235Z","iopub.status.idle":"2021-08-02T22:03:16.306342Z","shell.execute_reply.started":"2021-08-02T22:03:16.295197Z","shell.execute_reply":"2021-08-02T22:03:16.305379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_df = pd.DataFrame(df[\"excerpt\"].apply(lambda p : readability_measurements(p)).tolist(), \n                                 columns=[\"chars_per_word\", \"syll_per_word\", \"words_per_sent\",\n                                          \"kincaid\", \"ari\", \"coleman_liau\", \"flesch\", \"gunning_fog\", \"lix\", \"smog\", \"rix\", \"dale_chall\",\n                                          \"tobeverb\", \"auxverb\", \"conjunction\", \"pronoun\", \"preposition\", \"nominalization\",\n                                          \"pronoun_b\", \"interrogative\", \"article\", \"subordination\", \"conjunction_b\", \"preposition_b\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:16.309193Z","iopub.execute_input":"2021-08-02T22:03:16.309534Z","iopub.status.idle":"2021-08-02T22:03:22.685278Z","shell.execute_reply.started":"2021-08-02T22:03:16.3095Z","shell.execute_reply":"2021-08-02T22:03:22.684401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df, scores_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:22.687253Z","iopub.execute_input":"2021-08-02T22:03:22.687592Z","iopub.status.idle":"2021-08-02T22:03:22.698594Z","shell.execute_reply.started":"2021-08-02T22:03:22.687557Z","shell.execute_reply":"2021-08-02T22:03:22.697751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spacy\nCredit: https://www.kaggle.com/ravishah1/readability-feature-engineering-non-nn-baseline","metadata":{}},{"cell_type":"code","source":"def spacy_features(df: pd.DataFrame):\n    \"\"\"\n    This function generates features using spacy en_core_wb_lg\n    I learned about this from these resources:\n    https://www.kaggle.com/konradb/linear-baseline-with-cv\n    https://www.kaggle.com/anaverageengineer/comlrp-baseline-for-complete-beginners\n    \"\"\"\n    \n    nlp = spacy.load('en_core_web_lg')\n    with nlp.disable_pipes():\n        vectors = np.array([nlp(text).vector for text in df.excerpt])\n        \n    return vectors\n\ndef get_spacy_col_names():\n    names = list()\n    for i in range(300):\n        names.append(f\"spacy_{i}\")\n        \n    return names","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:22.700124Z","iopub.execute_input":"2021-08-02T22:03:22.70061Z","iopub.status.idle":"2021-08-02T22:03:22.707399Z","shell.execute_reply.started":"2021-08-02T22:03:22.700575Z","shell.execute_reply":"2021-08-02T22:03:22.706538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# spacy_df = pd.DataFrame(spacy_features(df), columns=get_spacy_col_names())\n# df = pd.concat([df, spacy_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:22.708683Z","iopub.execute_input":"2021-08-02T22:03:22.709224Z","iopub.status.idle":"2021-08-02T22:03:22.715214Z","shell.execute_reply.started":"2021-08-02T22:03:22.709188Z","shell.execute_reply":"2021-08-02T22:03:22.714452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tags\nCredit: https://www.kaggle.com/ravishah1/readability-feature-engineering-non-nn-baseline","metadata":{}},{"cell_type":"code","source":"def pos_tag_features(passage: str):\n    \"\"\"\n    This function counts the number of times different parts of speech occur in an excerpt\n    \"\"\"\n    pos_tags = [\"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \n                \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"POS\", \"PRP\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"TO\", \"UH\",\n                \"VB\", \"VBD\", \"VBG\", \"VBZ\", \"WDT\", \"WP\", \"WRB\"]\n    \n    tags = pos_tag(word_tokenize(passage))\n    tag_list= list()\n    \n    for tag in pos_tags:\n        tag_list.append(len([i[0] for i in tags if i[1] == tag]))\n    \n    return tag_list","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:22.716612Z","iopub.execute_input":"2021-08-02T22:03:22.717099Z","iopub.status.idle":"2021-08-02T22:03:22.724783Z","shell.execute_reply.started":"2021-08-02T22:03:22.717056Z","shell.execute_reply":"2021-08-02T22:03:22.723577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_df = pd.DataFrame(df[\"excerpt\"].apply(lambda p : pos_tag_features(p)).tolist(),\n                              columns=[\"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \n                                       \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"POS\", \"PRP\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"TO\", \"UH\",\n                                       \"VB\", \"VBD\", \"VBG\", \"VBZ\", \"WDT\", \"WP\", \"WRB\"])\ndf = pd.concat([df, pos_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:22.726197Z","iopub.execute_input":"2021-08-02T22:03:22.726573Z","iopub.status.idle":"2021-08-02T22:03:52.202925Z","shell.execute_reply.started":"2021-08-02T22:03:22.726537Z","shell.execute_reply":"2021-08-02T22:03:52.202064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other\nCredit: https://www.kaggle.com/ravishah1/readability-feature-engineering-non-nn-baseline","metadata":{}},{"cell_type":"code","source":"def generate_other_features(passage: str):\n    \"\"\"\n    This function is where I test miscellaneous features\n    This is experimental\n    \"\"\"\n    # punctuation count\n    periods = passage.count(\".\")\n    commas = passage.count(\",\")\n    semis = passage.count(\";\")\n    exclaims = passage.count(\"!\")\n    questions = passage.count(\"?\")\n    \n    # Some other stats\n    num_char = len(passage)\n    num_words = textstat.lexicon_count(passage) #len(passage.split(\" \")) #\n    unique_words = len(set(passage.split(\" \") )) #\n    word_diversity = unique_words/num_words\n    \n    word_len = [len(w) for w in passage.split(\" \")]\n    longest_word = np.max(word_len) #\n    avg_len_word = np.mean(word_len) #\n    \n    return [periods, commas, semis, exclaims, questions,\n            num_char, num_words, unique_words, word_diversity,\n            longest_word, avg_len_word]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:52.20428Z","iopub.execute_input":"2021-08-02T22:03:52.204652Z","iopub.status.idle":"2021-08-02T22:03:52.212648Z","shell.execute_reply.started":"2021-08-02T22:03:52.204615Z","shell.execute_reply":"2021-08-02T22:03:52.211595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_df = pd.DataFrame(df[\"excerpt\"].apply(lambda p : generate_other_features(p)).tolist(),\n                                columns=[\"periods\", \"commas\", \"semis\", \"exclaims\", \"questions\",\n                                         \"num_char\", \"num_words\", \"unique_words\", \"word_diversity\",\n                                         \"longest_word\", \"avg_len_word\"])\n\ndf = pd.concat([df, other_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:52.214289Z","iopub.execute_input":"2021-08-02T22:03:52.214988Z","iopub.status.idle":"2021-08-02T22:03:53.058859Z","shell.execute_reply.started":"2021-08-02T22:03:52.214948Z","shell.execute_reply":"2021-08-02T22:03:53.05792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Line Breaks\nCredit:\nhttps://www.kaggle.com/ppjanka/2021-commonlitreadability-final","metadata":{}},{"cell_type":"code","source":"# df['n_linebreaks'] = df['excerpt'].str.split('\\n').transform(len)\n# df['mean_sentences_per_lineBreak'] = df['n_sentence'] / df['n_linebreaks']\n\n# sentences_per_lineBreak = df.excerpt.str.split('\\n').transform(lambda x : [len(y.split('.')) for y in x])\n# df['min_sentences_per_lineBreak'] = sentences_per_lineBreak.apply(min)\n# df['max_sentences_per_lineBreak'] = sentences_per_lineBreak.apply(max)\n# df['std_sentences_per_lineBreak'] = sentences_per_lineBreak.apply(np.std)\n\n# words_per_lineBreak = df.excerpt.str.split('\\n').transform(lambda x : [len(y.split(' ')) for y in x])\n# df['min_words_per_lineBreak'] = words_per_lineBreak.apply(min)\n# df['max_words_per_lineBreak'] = words_per_lineBreak.apply(max)\n# df['mean_words_per_lineBreak'] = words_per_lineBreak.apply(np.mean)\n# df['std_words_per_lineBreak'] = words_per_lineBreak.apply(np.std)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:53.062427Z","iopub.execute_input":"2021-08-02T22:03:53.062691Z","iopub.status.idle":"2021-08-02T22:03:53.068107Z","shell.execute_reply.started":"2021-08-02T22:03:53.062664Z","shell.execute_reply":"2021-08-02T22:03:53.067257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sentence Transformer\nCredit: https://www.kaggle.com/thedrcat/commonlit-what-are-we-reading-about","metadata":{}},{"cell_type":"code","source":"from sklearn import decomposition\n\ntexts = df.loc[:, 'excerpt']\n\nmodel = SentenceTransformer('../input/sentence-transformer-models/stsb-roberta-large')\nembeddings = model.encode(texts)\n\npca = decomposition.PCA(random_state=SEED)\npca.fit(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:03:53.069569Z","iopub.execute_input":"2021-08-02T22:03:53.070147Z","iopub.status.idle":"2021-08-02T22:05:01.374723Z","shell.execute_reply.started":"2021-08-02T22:03:53.070106Z","shell.execute_reply":"2021-08-02T22:05:01.37375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_embs = 10\n\nembeddings_ = pca.transform(embeddings)\nemb_df = pd.DataFrame(embeddings_[0:, 0: max_embs], columns=[f'embedding_{i}' for i in range(max_embs)])\n\ndf = pd.concat([df, emb_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.376082Z","iopub.execute_input":"2021-08-02T22:05:01.376478Z","iopub.status.idle":"2021-08-02T22:05:01.44031Z","shell.execute_reply.started":"2021-08-02T22:05:01.376438Z","shell.execute_reply":"2021-08-02T22:05:01.439255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OOF Target Prediction","metadata":{}},{"cell_type":"code","source":"cols_oof = [f'oof_{i}' for i in range(8)]\noofs = df.loc[:, cols_oof]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.4417Z","iopub.execute_input":"2021-08-02T22:05:01.44207Z","iopub.status.idle":"2021-08-02T22:05:01.450665Z","shell.execute_reply.started":"2021-08-02T22:05:01.442033Z","shell.execute_reply":"2021-08-02T22:05:01.449681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['oof_mean'] = np.mean(oofs, axis=1)\ndf['oof_std'] = np.std(oofs, axis=1)\ndf['oof_max'] = np.max(oofs, axis=1)\ndf['oof_min'] = np.min(oofs, axis=1)\ndf['oof_range'] = df['oof_max'] - df['oof_min']\ndf['oof_std_over_range'] = df['oof_std'] / df['oof_range']","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.452485Z","iopub.execute_input":"2021-08-02T22:05:01.452856Z","iopub.status.idle":"2021-08-02T22:05:01.482082Z","shell.execute_reply.started":"2021-08-02T22:05:01.452821Z","shell.execute_reply":"2021-08-02T22:05:01.481189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional Feature","metadata":{}},{"cell_type":"code","source":"df['unique_words_per_sentence'] = df['unique_words'] / df['n_sentence']\ndf['longest_over_avg_word'] = df['longest_word'] / df['avg_len_word']\ndf['oof_skew'] = scipy.stats.skew(oofs, axis=1)\ndf['oof_kurtosis'] = scipy.stats.kurtosis(oofs, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.483256Z","iopub.execute_input":"2021-08-02T22:05:01.483571Z","iopub.status.idle":"2021-08-02T22:05:01.496883Z","shell.execute_reply.started":"2021-08-02T22:05:01.483538Z","shell.execute_reply":"2021-08-02T22:05:01.495892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"code","source":"fe_pred = ['standard_error', 'target']  # stackingによるoofをtargetとして特徴量に追加したい\n\n# fe_oof = [f'oof_{i}' for i in range(8)] + ['oof_stacking'] + ['oof_mean', 'oof_std', 'oof_max', 'oof_min', 'oof_range']\n# remove oof_stacking for avoiding leakage\nfe_oof = [f'oof_{i}' for i in range(8)] + ['oof_mean', 'oof_std', 'oof_max', 'oof_min', 'oof_range', 'oof_std_over_range']\nfe_text = ['n_sentence', #  'n_words', 'n_unique_words', 'mean_word_len', 'max_word_len', \n           'n_syllable', 'flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index', \n           'automated_readability_index', 'coleman_liau_index', 'linsear_write_formula']\n\nfe_read = [\"chars_per_word\", \"syll_per_word\", \"words_per_sent\",\n                                          \"kincaid\", \"ari\", \"coleman_liau\", \"flesch\", \"gunning_fog\", \"lix\", \"smog\", \"rix\", \"dale_chall\",\n                                          \"tobeverb\", \"auxverb\", \"conjunction\", \"pronoun\", \"preposition\", \"nominalization\",\n                                          \"pronoun_b\", \"interrogative\", \"article\", \"subordination\", \"conjunction_b\", \"preposition_b\"]\n\nfe_spacy = get_spacy_col_names()\n\nfe_tags = [\"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \n                                       \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"POS\", \"PRP\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"TO\", \"UH\",\n                                       \"VB\", \"VBD\", \"VBG\", \"VBZ\", \"WDT\", \"WP\", \"WRB\"]\n\nfe_other = [\"periods\", \"commas\", \"semis\", \"exclaims\", \"questions\",\n                                         \"num_char\", \"num_words\", \"unique_words\", \"word_diversity\",\n                                         \"longest_word\", \"avg_len_word\"]\n\nfe_lb = ['n_linebreaks', 'mean_sentences_per_lineBreak', 'min_sentences_per_lineBreak', 'max_sentences_per_lineBreak', 'std_sentences_per_lineBreak', \n         'min_words_per_lineBreak', 'max_words_per_lineBreak', 'mean_words_per_lineBreak', 'std_words_per_lineBreak']\n\nfe_emb = [f'embedding_{i}' for i in range(max_embs)]\n\nfe_add = ['unique_words_per_sentence', 'longest_over_avg_word', 'oof_skew', 'oof_kurtosis']\n\nfe = fe_pred + fe_text #+ fe_oof","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.498156Z","iopub.execute_input":"2021-08-02T22:05:01.498493Z","iopub.status.idle":"2021-08-02T22:05:01.51222Z","shell.execute_reply.started":"2021-08-02T22:05:01.49846Z","shell.execute_reply":"2021-08-02T22:05:01.511169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VIF Calculation","metadata":{}},{"cell_type":"code","source":"vif_df = pd.DataFrame()\n\nvif_df['feature'] = fe\nvif_df['vif'] = [vif(df.loc[:, fe].values, i) for i in range(len(fe))]\n\nvif_df","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.518031Z","iopub.execute_input":"2021-08-02T22:05:01.518877Z","iopub.status.idle":"2021-08-02T22:05:01.591968Z","shell.execute_reply.started":"2021-08-02T22:05:01.518842Z","shell.execute_reply":"2021-08-02T22:05:01.591089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe_text\nplt.figure(figsize=(12, 10))\nsns.heatmap(data=df.loc[:, fe].corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:01.593695Z","iopub.execute_input":"2021-08-02T22:05:01.59406Z","iopub.status.idle":"2021-08-02T22:05:02.382854Z","shell.execute_reply.started":"2021-08-02T22:05:01.594024Z","shell.execute_reply":"2021-08-02T22:05:02.38198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe_oof\nplt.figure(figsize=(14, 10))\nsns.heatmap(data=df.loc[:, fe_pred + fe_oof].corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:02.383977Z","iopub.execute_input":"2021-08-02T22:05:02.38433Z","iopub.status.idle":"2021-08-02T22:05:03.638835Z","shell.execute_reply.started":"2021-08-02T22:05:02.384292Z","shell.execute_reply":"2021-08-02T22:05:03.637851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe_read\nplt.figure(figsize=(16, 10))\nsns.heatmap(data=df.loc[:, fe_pred + fe_read].corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:03.640262Z","iopub.execute_input":"2021-08-02T22:05:03.640601Z","iopub.status.idle":"2021-08-02T22:05:06.861292Z","shell.execute_reply.started":"2021-08-02T22:05:03.640562Z","shell.execute_reply":"2021-08-02T22:05:06.854691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe_tags\nplt.figure(figsize=(16, 10))\nsns.heatmap(data=df.loc[:, fe_pred + fe_tags].corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:06.86278Z","iopub.execute_input":"2021-08-02T22:05:06.863127Z","iopub.status.idle":"2021-08-02T22:05:11.09171Z","shell.execute_reply.started":"2021-08-02T22:05:06.863091Z","shell.execute_reply":"2021-08-02T22:05:11.090695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe_other\nplt.figure(figsize=(16, 10))\nsns.heatmap(data=df.loc[:, fe_pred + fe_other + fe_add].corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:11.094145Z","iopub.execute_input":"2021-08-02T22:05:11.094506Z","iopub.status.idle":"2021-08-02T22:05:12.843879Z","shell.execute_reply.started":"2021-08-02T22:05:11.094463Z","shell.execute_reply":"2021-08-02T22:05:12.843058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe_emb\nplt.figure(figsize=(16, 10))\nsns.heatmap(data=df.loc[:, fe_pred + fe_emb].corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:12.845216Z","iopub.execute_input":"2021-08-02T22:05:12.845583Z","iopub.status.idle":"2021-08-02T22:05:13.782148Z","shell.execute_reply.started":"2021-08-02T22:05:12.845543Z","shell.execute_reply":"2021-08-02T22:05:13.781316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM Training / Prediction for standard_error","metadata":{}},{"cell_type":"code","source":"import optuna.integration.lightgbm as lgb\nimport lightgbm as lgb_original","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:13.783396Z","iopub.execute_input":"2021-08-02T22:05:13.783898Z","iopub.status.idle":"2021-08-02T22:05:14.644376Z","shell.execute_reply.started":"2021-08-02T22:05:13.783859Z","shell.execute_reply":"2021-08-02T22:05:14.6435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_importance(fe, opt):\n    fe_df = pd.DataFrame()\n    fe_df['feature'] = fe\n    fe_df['importance'] = opt.feature_importance(importance_type='gain')\n    \n    plt.figure(figsize=(14, 16))\n    sns.barplot(data=fe_df, y='feature', x='importance')\n    plt.title('Feature Importance')\n    plt.show()\n    \ndef RMSE_(y_pred, y_gt):\n    mse = mean_squared_error(y_pred, y_gt)\n    return np.sqrt(mse)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:14.645682Z","iopub.execute_input":"2021-08-02T22:05:14.646062Z","iopub.status.idle":"2021-08-02T22:05:14.656447Z","shell.execute_reply.started":"2021-08-02T22:05:14.646023Z","shell.execute_reply":"2021-08-02T22:05:14.655312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OptLGBM:\n    def __init__(self, df, fe, opt_fe='standard_error'):\n        self.df = df\n        self.fe = fe\n        self.opt_fe = opt_fe\n        \n        self.best_scores = []\n        self.best_params = []\n        self.best_models = []\n        \n        self.df['opt_fe_oof'] = np.nan\n         \n    def optimize(self, num_boost_round=1000, early_stopping_rounds=500):\n        for fold in range(5):\n            train_df = self.df.loc[self.df.fold!=fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n            val_df = self.df.loc[self.df.fold==fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n\n            train_ds = lgb.Dataset(train_df.loc[:, self.fe], train_df.loc[:, self.opt_fe])\n            val_ds = lgb.Dataset(val_df.loc[:, self.fe], val_df.loc[:, self.opt_fe])\n\n            params = {\n                'objective': 'regression',\n                'metric': 'rmse',\n                'verbosity': -1,\n                'boosting_type': 'gbdt',\n                'seed': SEED,\n#                 'device': 'gpu'\n            }\n\n            opt = lgb.train(params, \n                            train_ds, \n                            valid_sets=val_ds, \n                            num_boost_round=num_boost_round, \n                            verbose_eval=False, \n                            early_stopping_rounds=early_stopping_rounds,\n                            show_progress_bar=False)\n\n            print(f'fold {fold}: ', opt.best_score['valid_0']['rmse'])\n            self.best_scores.append(opt.best_score['valid_0']['rmse'])\n            self.best_params.append(opt.params)\n            self.best_models.append(opt.best_iteration)\n            \n            preds = opt.predict(val_df.loc[:, self.fe], num_iteration=opt.best_iteration)\n            self.df.loc[self.df.fold==fold, 'opt_fe_oof'] = preds\n            \n            self._show_importance(opt)\n            \n        print('CV Score: ', RMSE_(self.df[self.opt_fe], self.df['opt_fe_oof']))\n        \n    def _show_importance(self, opt):\n        show_importance(fe=self.fe, opt=opt)\n        \n    def retrain(self, col='se'):\n        self.df[col] = np.nan\n        \n        for fold in range(5):\n            train_df = self.df.loc[self.df.fold!=fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n            val_df = self.df.loc[self.df.fold==fold, self.fe + [self.opt_fe]].reset_index(drop=True)\n\n            train_ds = lgb.Dataset(train_df.loc[:, self.fe], train_df.loc[:, self.opt_fe])\n            val_ds = lgb.Dataset(val_df.loc[:, self.fe], val_df.loc[:, self.opt_fe])\n            \n            params = self.best_params[fold]\n            \n            model = lgb_original.train(params, \n                            train_ds, \n                            valid_sets=val_ds, \n                            verbose_eval=False)\n            \n            model.save_model(f'lgb_{col}_fold{fold}.pkl')\n            self.df.loc[self.df.fold==fold, col] = model.predict(val_df.loc[:, self.fe])\n            \n        print('CV Score (retrained): ', RMSE_(self.df[self.opt_fe], self.df[col]))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:14.657737Z","iopub.execute_input":"2021-08-02T22:05:14.658219Z","iopub.status.idle":"2021-08-02T22:05:14.675938Z","shell.execute_reply.started":"2021-08-02T22:05:14.658182Z","shell.execute_reply":"2021-08-02T22:05:14.675134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimize / Retrain","metadata":{}},{"cell_type":"code","source":"fe = fe_text + fe_oof + fe_read + fe_tags + fe_other + fe_add + fe_emb\n\nopt = OptLGBM(df=df, fe=fe, opt_fe='standard_error')\nopt.optimize(num_boost_round=1500, early_stopping_rounds=500)\nopt.retrain(col='se')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:05:14.677078Z","iopub.execute_input":"2021-08-02T22:05:14.677535Z","iopub.status.idle":"2021-08-02T22:18:36.925699Z","shell.execute_reply.started":"2021-08-02T22:05:14.677499Z","shell.execute_reply":"2021-08-02T22:18:36.924655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def oof_vs_target(df, x='standard_error', y='oof'):\n    temp_df = pd.DataFrame()\n    temp_df['x'] = np.linspace(0.4, 0.7, 10)\n    temp_df['y'] = temp_df['x']\n\n    plt.figure(figsize=(8, 8))\n    sns.scatterplot(data=df, x=x, y=y, label=f'{y} vs target', hue='fold', palette='bright')\n    sns.lineplot(data=temp_df, x='x', y='y', color='orange')\n    plt.title('OOF Prediction vs Target')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:18:36.927434Z","iopub.execute_input":"2021-08-02T22:18:36.927877Z","iopub.status.idle":"2021-08-02T22:18:36.936377Z","shell.execute_reply.started":"2021-08-02T22:18:36.927829Z","shell.execute_reply":"2021-08-02T22:18:36.935193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_vs_target(opt.df, x='standard_error', y='se')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:18:36.938454Z","iopub.execute_input":"2021-08-02T22:18:36.939279Z","iopub.status.idle":"2021-08-02T22:18:37.413705Z","shell.execute_reply.started":"2021-08-02T22:18:36.939231Z","shell.execute_reply":"2021-08-02T22:18:37.412692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_vs_target(opt.df, x='oof_stacking', y='se')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:18:37.41514Z","iopub.execute_input":"2021-08-02T22:18:37.415495Z","iopub.status.idle":"2021-08-02T22:18:37.861473Z","shell.execute_reply.started":"2021-08-02T22:18:37.415458Z","shell.execute_reply":"2021-08-02T22:18:37.860659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_vs_target(opt.df, x='target', y='standard_error')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:18:37.862784Z","iopub.execute_input":"2021-08-02T22:18:37.86331Z","iopub.status.idle":"2021-08-02T22:18:38.404128Z","shell.execute_reply.started":"2021-08-02T22:18:37.863271Z","shell.execute_reply":"2021-08-02T22:18:38.403024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking by LGBM for Target","metadata":{}},{"cell_type":"code","source":"# remove fe_text, fe_add\nfe = fe_oof + fe_read + fe_tags + fe_other + ['se']\n\nopt = OptLGBM(df=df, fe=fe, opt_fe='target')\nopt.optimize(num_boost_round=1500)\nopt.retrain(col='oof_with_se')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:18:38.405827Z","iopub.execute_input":"2021-08-02T22:18:38.406196Z","iopub.status.idle":"2021-08-02T22:24:46.328956Z","shell.execute_reply.started":"2021-08-02T22:18:38.406158Z","shell.execute_reply":"2021-08-02T22:24:46.327827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking with BERTs + LGBM","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model\n\nCV_PATHS = [\n    {'model_type': 0,\n     'path': '../input/clrp-robertalarge-attentions-mask-act',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 1,\n     'path': '../input/clrp-robertalarge-conv1d-attentions-mask',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 2,\n     'path': '../input/clrp-robertabase-from-colab',\n     'model_name': 'CLRPModelColab'},\n    {'model_type': 3,\n     'path': '../input/clrp-electralarge-attentions-mask-act',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 4,\n     'path': '../input/clrp-xlnetlarge-attentions-mask',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 5,\n     'path': '../input/clrp-electralarge-attentions-conv1d',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 6,\n     'path': '../input/clrp-robertalarge-meanpooling',\n     'model_name': 'CLRPModelLarge'},\n    {'model_type': 7,\n     'path': '../input/clrp-funnellarge-attentions-act',\n     'model_name': 'CLRPModelLarge'},\n]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:24:46.330637Z","iopub.execute_input":"2021-08-02T22:24:46.331302Z","iopub.status.idle":"2021-08-02T22:24:46.340058Z","shell.execute_reply.started":"2021-08-02T22:24:46.331252Z","shell.execute_reply":"2021-08-02T22:24:46.338962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['oof_lgb'] = np.nan\n    \nfor fold in range(5):\n    filename = f'lgb_oof_with_se_fold{fold}.pkl'\n    model = lgb.Booster(model_file=filename)\n    df.loc[df.fold==fold, 'oof_lgb'] = model.predict(df.loc[df.fold==fold, fe])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:24:46.341387Z","iopub.execute_input":"2021-08-02T22:24:46.341925Z","iopub.status.idle":"2021-08-02T22:24:46.414961Z","shell.execute_reply.started":"2021-08-02T22:24:46.341879Z","shell.execute_reply":"2021-08-02T22:24:46.414093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['oof_final'] = 0.0\ntargets = df['target'].values\n\nfeatures = []\n\n# BERTs OOF Feature\nfor cv_path in CV_PATHS:\n    model_type = cv_path['model_type']\n    features.append(df[f'oof_{model_type}'].values)\n\n# LGBM OOF Feature\nfeatures.append(df['oof_lgb'].values)\n\nfeatures = np.array(features)\n\n\n# Stacking by Linear Model\nlm = linear_model.LinearRegression(fit_intercept=True)\nlm.fit(features.T, targets)\n\nfor i, cv_path in enumerate(CV_PATHS):\n    model_type = cv_path['model_type']\n    df['oof_final'] += lm.coef_[i] * df[f'oof_{model_type}']\n\ndf['oof_final'] += lm.coef_[-1] * df['oof_lgb']\ndf['oof_final'] += lm.intercept_\n\nprint('CV score (stacking): ', RMSE_(df['target'], df['oof_final']))\noof_vs_target(df, x='target', y='oof_final')\nprint(\"model weight: \", lm.coef_)\nprint(\"bias: \", lm.intercept_)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:24:46.416256Z","iopub.execute_input":"2021-08-02T22:24:46.416598Z","iopub.status.idle":"2021-08-02T22:24:46.937315Z","shell.execute_reply.started":"2021-08-02T22:24:46.416563Z","shell.execute_reply":"2021-08-02T22:24:46.936243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('oof_df.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T22:24:46.938718Z","iopub.execute_input":"2021-08-02T22:24:46.939118Z","iopub.status.idle":"2021-08-02T22:24:47.318579Z","shell.execute_reply.started":"2021-08-02T22:24:46.939076Z","shell.execute_reply":"2021-08-02T22:24:47.317743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}