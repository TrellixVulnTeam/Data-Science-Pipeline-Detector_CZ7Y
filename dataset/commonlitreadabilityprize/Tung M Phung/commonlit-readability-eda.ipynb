{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![Image of Yaktocat](https://storage.googleapis.com/kaggle-competitions/kaggle/25914/logos/header.png)","metadata":{}},{"cell_type":"markdown","source":"In this competition, youâ€™ll build algorithms to rate the complexity of reading passages for grade 3-12 classroom use. To accomplish this, you'll pair your machine learning skills with a dataset that includes readers from a wide variety of age groups and a large collection of texts taken from various domains. Winning models will be sure to incorporate text cohesion and semantics.","metadata":{}},{"cell_type":"markdown","source":"### Data Description\n\n#### Files\n* **train.csv** - the training set\n* **test.csv** - the test set\n* **sample_submission.csv** - a sample submission file in the correct format\n\n#### Columns\n* `id` - unique ID for excerpt\n* `url_legal` - URL of source - this is blank in the test set.\n* `license` - license of source material - this is blank in the test set.\n* `excerpt` - text to predict reading ease of\n* `target` - reading ease\n* `standard_error` - measure of spread of scores among multiple raters for each excerpt. Not included for test data.","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"import re\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk import tokenize\nfrom nltk.corpus import wordnet, stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nsns.set()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target and Standard Error","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.histplot(\n    data=train,\n    x='target',\n    stat='probability',\n    ax=ax\n)\n\nax.set_title('Target\\'s distribution')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.scatterplot(\n    data=train,\n    x='target',\n    y='standard_error',\n    ax=ax\n)\n\nax.set_title('How standard error changes with target values')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In general, the standard error is lowest when the readability is around -1. It tends to get higher for more extreme values of readability.\n- There is one data point with 0 readability and 0 standard error.","metadata":{}},{"cell_type":"markdown","source":"# License and Target","metadata":{}},{"cell_type":"code","source":"train['license_type_cnt'] = train.groupby('license').transform('count')['id']\nlicense_data = train[train['license_type_cnt'] >= 10]\n\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.pointplot(\n    data=license_data,\n    x='license',\n    y='target',\n    ci='sd',\n    join=False\n)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Different licenses have different average readability, but the standard deviation is quite high.\n\nNote that in test data, the license field is always blank.","metadata":{}},{"cell_type":"markdown","source":"# Clean and standardize texts","metadata":{}},{"cell_type":"code","source":"def get_wordnet_pos(treebank_tag):\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n\nlemmatizer = WordNetLemmatizer()\ndef clean_text(text):\n    text = re.sub('[^A-Za-z0-9]+', ' ', text.lower())\n    words = nltk.word_tokenize(text)\n    tagged = nltk.pos_tag(words)\n    words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in tagged]\n    words = [word for word in words if word not in stopwords.words('english')]\n    return words\n\ndef get_ngrams(words, n):\n    return [tuple(words[i:i+n]) for i in range(len(words)-n+1)]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = []\nfor text, target in train[['excerpt', 'target']].itertuples(index=False):\n    sentences = []\n    for sentence in tokenize.sent_tokenize(text):\n        words = clean_text(sentence)\n        unigrams = get_ngrams(words, n=1)\n        bigrams = get_ngrams(words, n=2)\n        trigrams = get_ngrams(words, n=3)\n        sentences.append(words)\n    corpus.append({\n        'target' : target,\n        'text' : text,\n        'sentences' : sentences,\n        'unigrams' : unigrams,\n        'bigrams' : bigrams,\n        'trigrams' : trigrams,\n    })\n\ncorpus = sorted(corpus, key=lambda x: x['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# N-grams","metadata":{}},{"cell_type":"code","source":"def plot_grams_target(gram_type):\n    gram_cnt = defaultdict(lambda: 0)\n    gram_sum = defaultdict(lambda: 0.)\n    gram_avg = {}\n\n    for datapoint in corpus:\n        for gram in datapoint[gram_type]:\n            gram_cnt[gram] += 1\n            gram_sum[gram] += datapoint['target']\n\n    for gram in gram_cnt:\n        if gram_cnt[gram] >= 5:\n            gram_avg[gram] = gram_sum[gram] / gram_cnt[gram]\n    \n    fig, ax = plt.subplots(1, 2, figsize=(12, 8))\n    \n    top_lowest = sorted(gram_avg.items(), key=lambda x: x[1])[:10]\n    ngrams, avg_target = zip(*top_lowest)\n    ax[0].bar(\n        range(len(ngrams)),\n        avg_target\n    )\n\n    ax[0].set_title(f'{gram_type} with lowest readability')\n    ax[0].set_xlabel(gram_type)\n    ax[0].set_ylabel('Average readability')\n    ax[0].set_xticks(range(len(ngrams)))\n    ax[0].set_xticklabels([' '.join(x) for x in ngrams], rotation='vertical')\n    \n    top_highest = sorted(gram_avg.items(), key=lambda x: x[1])[-10:]\n    ngrams, avg_target = zip(*top_highest)\n    ax[1].bar(\n        range(len(ngrams)),\n        avg_target\n    )\n\n    ax[1].set_title(f'{gram_type} with highest readability')\n    ax[1].set_xlabel(gram_type)\n    ax[1].set_ylabel('Average readability')\n    ax[1].set_xticks(range(len(ngrams)))\n    ax[1].set_xticklabels([' '.join(x) for x in ngrams], rotation='vertical')\n\n    plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grams_target('unigrams')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grams_target('bigrams')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that we only examine grams with at least 5 occurrences.","metadata":{}},{"cell_type":"markdown","source":"# Target and sentence length","metadata":{}},{"cell_type":"code","source":"top_lowest = corpus[:500]\nlowest_target_sentence_lengths = [ \\\n    np.mean([len(sentence) for sentence in datapoint['sentences']]) \\\n    for datapoint in top_lowest \\\n]\n\ntop_highest = corpus[-500:]\nhighest_target_sentence_lengths = [ \\\n    np.mean([len(sentence) for sentence in datapoint['sentences']]) \\\n    for datapoint in top_highest \\\n]\n\ntop_lowest_mean = np.mean(lowest_target_sentence_lengths)\ntop_lowest_std = np.std(lowest_target_sentence_lengths)\ntop_highest_mean = np.mean(highest_target_sentence_lengths)\ntop_highest_std = np.std(highest_target_sentence_lengths)\n\nfig, ax = plt.subplots(figsize=(6, 8))\nax.errorbar(\n    x=[0, 1],\n    y=[top_lowest_mean, top_highest_mean],\n    yerr=[top_lowest_std, top_highest_std],\n    fmt='o'\n)\n\nax.set_title('Average sentence length and Readability')\nax.set_ylabel('Sentence length')\nax.set_xticks([0, 1])\nax.set_xticklabels(['Top lowest readability', 'Top highest readability'])\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Texts with shorter sentence lengths are often easier to read.","metadata":{}},{"cell_type":"code","source":"!pip install wordfreq\n\nfrom wordfreq import word_frequency\nlowest_target_word_freq = [\n    [word_frequency(word[0], 'en') for word in datapoint['unigrams']]\n    for datapoint in top_lowest\n]\nhighest_target_word_freq = [\n    [word_frequency(word[0], 'en') for word in datapoint['unigrams']]\n    for datapoint in top_highest\n]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lowest_min_freq = [np.min(datapoint) for datapoint in lowest_target_word_freq]\nhighest_min_freq = [np.min(datapoint) for datapoint in highest_target_word_freq]\n\nfig, ax = plt.subplots(figsize=(6, 8))\nax.errorbar(\n    x=[0, 1],\n    y=[np.mean(lowest_min_freq), np.mean(highest_min_freq)],\n    yerr=[np.std(lowest_min_freq), np.std(highest_min_freq)],\n    fmt='o'\n)\n\nax.set_ylabel('Min word frequency in general English')\nax.set_xticks([0, 1])\nax.set_xticklabels(['Top lowest readability', 'Top highest readability'])\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hard-to-read texts often contain some less-usual words.","metadata":{}}]}