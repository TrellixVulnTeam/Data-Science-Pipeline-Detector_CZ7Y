{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T19:14:04.087336Z","iopub.execute_input":"2021-08-01T19:14:04.088005Z","iopub.status.idle":"2021-08-01T19:14:04.110491Z","shell.execute_reply.started":"2021-08-01T19:14:04.087957Z","shell.execute_reply":"2021-08-01T19:14:04.109623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import libraries\nimport gzip\nimport numpy as np\nimport pandas as pd\nimport string\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import tree\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:07.403977Z","iopub.execute_input":"2021-08-01T19:14:07.404545Z","iopub.status.idle":"2021-08-01T19:14:07.413494Z","shell.execute_reply.started":"2021-08-01T19:14:07.404513Z","shell.execute_reply":"2021-08-01T19:14:07.412643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:09.925655Z","iopub.execute_input":"2021-08-01T19:14:09.926064Z","iopub.status.idle":"2021-08-01T19:14:09.988583Z","shell.execute_reply.started":"2021-08-01T19:14:09.92603Z","shell.execute_reply":"2021-08-01T19:14:09.9874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define X, y and test\nX = train['excerpt']\ny = train['target']\ntest_text = test[\"excerpt\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:12.281666Z","iopub.execute_input":"2021-08-01T19:14:12.282035Z","iopub.status.idle":"2021-08-01T19:14:12.288682Z","shell.execute_reply.started":"2021-08-01T19:14:12.282005Z","shell.execute_reply":"2021-08-01T19:14:12.287533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lower the text\nX = X.str.lower()\ntest_text = test_text.str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:12.927882Z","iopub.execute_input":"2021-08-01T19:14:12.928244Z","iopub.status.idle":"2021-08-01T19:14:12.944109Z","shell.execute_reply.started":"2021-08-01T19:14:12.928213Z","shell.execute_reply":"2021-08-01T19:14:12.942784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def remove_punctuations(text):\n#     for punctuation in string.punctuation:\n#         text = text.replace(punctuation, '')\n#     return text\n\n# X = X.apply(remove_punctuations)\n# test_text = test_text.apply(remove_punctuations)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:16.453926Z","iopub.execute_input":"2021-08-01T19:14:16.454317Z","iopub.status.idle":"2021-08-01T19:14:16.556866Z","shell.execute_reply.started":"2021-08-01T19:14:16.45426Z","shell.execute_reply":"2021-08-01T19:14:16.555862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # apply Porter Stemmer\n# from nltk.stem import PorterStemmer\n# ps = PorterStemmer()\n\n# def stem_sentences(sentence):\n#     tokens = sentence.split()\n#     stemmed_tokens = [ps.stem(token) for token in tokens]\n#     return ' '.join(stemmed_tokens)\n\n# X = X.apply(stem_sentences)\n# test_text = test_text.apply(stem_sentences)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:17.071226Z","iopub.execute_input":"2021-08-01T19:14:17.071616Z","iopub.status.idle":"2021-08-01T19:14:29.268172Z","shell.execute_reply.started":"2021-08-01T19:14:17.071584Z","shell.execute_reply":"2021-08-01T19:14:29.267389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # lemmatize the text\n# from nltk.stem import WordNetLemmatizer\n# import nltk\n# # nltk.download('wordnet')\n\n# lemmatizer = WordNetLemmatizer()\n# def lemmatize_sentences(sentence):\n#     tokens = sentence.split()\n#     stemmed_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n#     return ' '.join(stemmed_tokens)\n\n# X = X.apply(lemmatize_sentences)\n# test_text = test_text.apply(lemmatize_sentences)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:29.269545Z","iopub.execute_input":"2021-08-01T19:14:29.269976Z","iopub.status.idle":"2021-08-01T19:14:31.721719Z","shell.execute_reply.started":"2021-08-01T19:14:29.269931Z","shell.execute_reply":"2021-08-01T19:14:31.720824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\n# nltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\n\", \".join(stopwords.words('english'))\nSTOPWORDS = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\nX = X.apply(lambda text: remove_stopwords(text))\ntest_text = test_text.apply(lambda text: remove_stopwords(text))","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:31.72314Z","iopub.execute_input":"2021-08-01T19:14:31.723715Z","iopub.status.idle":"2021-08-01T19:14:31.835619Z","shell.execute_reply.started":"2021-08-01T19:14:31.723675Z","shell.execute_reply":"2021-08-01T19:14:31.834713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import Counter\n# cnt = Counter()\n# for text in X.tolist() + test_text.tolist():\n#     for word in text.split():\n#         cnt[word] += 1\n        \n# most_common_words = [x[0] for x in cnt.most_common(100)]\n\n# def remove_most_common_words(text):\n#     return \" \".join([word for word in str(text).split() if word not in most_common_words])\n\n# X = X.apply(lambda text: remove_most_common_words(text))\n# test_text = test_text.apply(lambda text: remove_most_common_words(text))","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:05:32.819454Z","iopub.execute_input":"2021-08-01T18:05:32.819751Z","iopub.status.idle":"2021-08-01T18:05:33.343307Z","shell.execute_reply.started":"2021-08-01T18:05:32.819715Z","shell.execute_reply":"2021-08-01T18:05:33.342357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_new = []\nfor index, value in X.items():\n    X_new.append(value)\n    \ny_new = []\nfor index, value in y.items():\n    y_new.append(value)\n    \nreal_test = []\nfor index, value in test_text.items():\n    real_test.append(value)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:39.254757Z","iopub.execute_input":"2021-08-01T19:14:39.255112Z","iopub.status.idle":"2021-08-01T19:14:39.265174Z","shell.execute_reply.started":"2021-08-01T19:14:39.255082Z","shell.execute_reply":"2021-08-01T19:14:39.264038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:05:33.356324Z","iopub.execute_input":"2021-08-01T18:05:33.35677Z","iopub.status.idle":"2021-08-01T18:05:33.370648Z","shell.execute_reply.started":"2021-08-01T18:05:33.356727Z","shell.execute_reply":"2021-08-01T18:05:33.369844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:50.264737Z","iopub.execute_input":"2021-08-01T19:14:50.265119Z","iopub.status.idle":"2021-08-01T19:14:50.270038Z","shell.execute_reply.started":"2021-08-01T19:14:50.265083Z","shell.execute_reply":"2021-08-01T19:14:50.268828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# m = RandomForestRegressor()\n# vectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n# m.fit(vectorizer.fit_transform(X_new + real_test)[:len(X_new)], y_new)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:50.785414Z","iopub.execute_input":"2021-08-01T19:14:50.785777Z","iopub.status.idle":"2021-08-01T19:14:50.789638Z","shell.execute_reply.started":"2021-08-01T19:14:50.785747Z","shell.execute_reply":"2021-08-01T19:14:50.788505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EMBEDDING_FILE = '../input/glovefile/glove.6B.100d.txt'\n\nembeddings = {}\nfor o in open(EMBEDDING_FILE):\n    word = o.split(\" \")[0]\n    embd = o.split(\" \")[1:]\n    embd = np.asarray(embd, dtype='float32')\n    embeddings[word] = embd","metadata":{"execution":{"iopub.status.busy":"2021-08-01T19:14:58.147262Z","iopub.execute_input":"2021-08-01T19:14:58.147652Z","iopub.status.idle":"2021-08-01T19:15:19.669589Z","shell.execute_reply.started":"2021-08-01T19:14:58.147611Z","shell.execute_reply":"2021-08-01T19:15:19.66852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_feature_vectors(sentence):\n    words = sentence.split()\n    feature_vec = np.zeros((100,),dtype=\"float32\")\n    i=0\n    for word in words:\n        try:\n            feature_vec = np.add(feature_vec, embeddings.get(word))\n        except:\n            i = i + 1\n    if len(words) > 0:\n        feature_vec = np.divide(feature_vec, len(words)- i)\n    return feature_vec","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:06:45.867913Z","iopub.execute_input":"2021-08-01T18:06:45.868257Z","iopub.status.idle":"2021-08-01T18:06:45.875769Z","shell.execute_reply.started":"2021-08-01T18:06:45.868225Z","shell.execute_reply":"2021-08-01T18:06:45.874347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors = np.array([get_feature_vectors(sentence) for sentence in X_train])\ntest_vectors = np.array([get_feature_vectors(sentence) for sentence in X_test])\nreal_test_vectors = np.array([get_feature_vectors(sentence) for sentence in real_test])\ny_full = np.array(y_new)\ntrain_vectors_full = np.array([get_feature_vectors(sentence) for sentence in X_new])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:36:18.150457Z","iopub.execute_input":"2021-08-01T18:36:18.150855Z","iopub.status.idle":"2021-08-01T18:36:19.403658Z","shell.execute_reply.started":"2021-08-01T18:36:18.150822Z","shell.execute_reply":"2021-08-01T18:36:19.402755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# m.fit(train_vectors_full, y_new)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:23:17.134324Z","iopub.execute_input":"2021-08-01T18:23:17.134666Z","iopub.status.idle":"2021-08-01T18:23:35.030463Z","shell.execute_reply.started":"2021-08-01T18:23:17.134636Z","shell.execute_reply":"2021-08-01T18:23:35.029467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:33:42.039216Z","iopub.execute_input":"2021-08-01T18:33:42.039625Z","iopub.status.idle":"2021-08-01T18:33:42.045512Z","shell.execute_reply.started":"2021-08-01T18:33:42.039593Z","shell.execute_reply":"2021-08-01T18:33:42.044467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    \n    model = keras.Sequential([\n        layers.Dense(units=512, kernel_initializer='normal', activation='linear', input_shape=[100]),\n        layers.Dense(units=256, kernel_initializer='normal', activation='linear'),\n        layers.Dense(units=128, kernel_initializer='normal', activation='linear'),\n        layers.Dropout(0.25),\n        # the linear output layer \n        layers.Dense(units=1, kernel_initializer='normal', activation='linear'),\n    ])\n    \n    model.compile(optimizer = 'adam', loss='mean_squared_error')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:33:44.648391Z","iopub.execute_input":"2021-08-01T18:33:44.648794Z","iopub.status.idle":"2021-08-01T18:33:44.655991Z","shell.execute_reply.started":"2021-08-01T18:33:44.648758Z","shell.execute_reply":"2021-08-01T18:33:44.65503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel_KR = KerasRegressor(build_fn = create_model, batch_size = 16, epochs = 50)\nkfolds = cross_val_score(model_KR, train_vectors_full, y_full, cv = 10)\nprint(kfolds.mean())\nprint('The mean accuracy:', kfolds.mean())\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:37:18.287506Z","iopub.execute_input":"2021-08-01T18:37:18.288035Z","iopub.status.idle":"2021-08-01T18:40:23.662909Z","shell.execute_reply.started":"2021-08-01T18:37:18.287993Z","shell.execute_reply":"2021-08-01T18:40:23.662012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"\", monitor=\"val_loss\", verbose=1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=1e-6, verbose=1)\nearly_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='auto', restore_best_weights=True)\n\nhistory = model_KR.fit(\n    train_vectors_full, y_full,\n    validation_split=0.4,\n    batch_size=16,\n    epochs=50,\n    callbacks = [early_stop, checkpoint, reduce_lr]\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:44:01.578779Z","iopub.execute_input":"2021-08-01T18:44:01.579166Z","iopub.status.idle":"2021-08-01T18:44:30.723335Z","shell.execute_reply.started":"2021-08-01T18:44:01.579133Z","shell.execute_reply":"2021-08-01T18:44:30.722185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict \n# pred_test = m.predict(real_test_vectors)\npred_test = model_KR.predict(real_test_vectors)\npred_test_list = [i for i in pred_test]\npred_test_list","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:44:30.725124Z","iopub.execute_input":"2021-08-01T18:44:30.725479Z","iopub.status.idle":"2021-08-01T18:44:30.867536Z","shell.execute_reply.started":"2021-08-01T18:44:30.725444Z","shell.execute_reply":"2021-08-01T18:44:30.866385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id' : test['id'], 'target' : pred_test_list})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nsubmission.head(7)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T18:44:34.323241Z","iopub.execute_input":"2021-08-01T18:44:34.323644Z","iopub.status.idle":"2021-08-01T18:44:34.342553Z","shell.execute_reply.started":"2021-08-01T18:44:34.32361Z","shell.execute_reply":"2021-08-01T18:44:34.34159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}