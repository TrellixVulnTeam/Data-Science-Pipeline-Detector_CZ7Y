{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This notebook is about trainig a Roberta (or any transformer) model using Hugging Face library\nThings you need to know while using hugging face transformers library\n- There are 4 for finetuning a transformer library\n    1. Import a __tokenizer__ to tokenise the given text in a format the model understands\n    2. Feed the tokenized data to __model__\n    3. __Define training prarameters__ for _finetuning_ the model\n    4. __Train__ the model\n    \n    \n","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification,Trainer, TrainingArguments\nimport torch\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n\n#\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make some directories for Outputs, logs and model\n> ðŸ“Œ __./model__ directory is used for storing files of both tokeniser and model weights. Again its not just model parameters but also tokeniser parameters in the same path","metadata":{}},{"cell_type":"code","source":"if \"output\" not in os.listdir():\n    os.mkdir(\"./output\")\nif \"logs\" not in os.listdir():\n    os.mkdir(\"./logs\")\nif \"model\" not in os.listdir():\n    os.mkdir(\"./model\") \n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install wandb library .This helps to fetch weights of a given model","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get wandb API key\nFor accessing a wandb \\<API KEY> you need to signup at [wandb](https://wandb.ai/site) website. There are two ways to access the API key\n- As soon as you signup at [wandb](https://wandb.ai/site) a key will automatically popup on webpage\n- If not go to [account settings](https://wandb.ai/settings) you can find the api key\n\nGet the key and place it in the below code\n\n> ðŸ“Œ I have used my own key below. However, I will be deleting that key after making this notebook public. Please follow above steps and get access for your own key","metadata":{}},{"cell_type":"code","source":"import wandb\nwandb.login(key = \"a0f553a701b1c86e18b067324c61cdf1adcd410b\") ## Use your api key here","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split train test data","metadata":{}},{"cell_type":"code","source":"cols = [\"excerpt\",\"target\"]\nmsk = np.random.rand(len(data)) < 0.8\n\ntrain_data = data[cols][msk]\nval_data = data[cols][~msk]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize data","metadata":{}},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\ntrain_encodings = tokenizer(list(train_data[\"excerpt\"]), truncation=True, padding=True, return_tensors=\"pt\")\nval_encodings = tokenizer(list(val_data[\"excerpt\"]), truncation=True, padding=True, return_tensors=\"pt\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"./model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch dataset reading class\n- prepare dataset for feeding into model","metadata":{}},{"cell_type":"code","source":"import torch\n\nclass ReadabilityDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        \n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = ReadabilityDataset(train_encodings, list(train_data[\"target\"]))\nval_dataset = ReadabilityDataset(val_encodings, list(val_data[\"target\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define training arguments for finetuning\n- We are using single cyclie learning rate for finetuning the model by using [cosine scheduler with warmup](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#transformers.get_cosine_schedule_with_warmup) function\n- You can read [this](https://medium.com/dsnet/the-1-cycle-policy-an-experiment-that-vanished-the-struggle-in-training-neural-nets-184417de23b9) article to learn more about one cycle LR\n- Change in learning rate looks something like this\n    - Initital climb in learning rate is called _warmup_steps_\n    \n![](https://i.ibb.co/FD6fXFr/warmup-cosine-schedule.png)\n\n> ðŸ“Œ I manually tried some good learning rates for training the model. Since hugging face has not yet implemented LR finder function","metadata":{}},{"cell_type":"code","source":"import transformers\ntraining_args = TrainingArguments(\n    output_dir='./output',          # output directory\n    num_train_epochs=8,              # total number of training epochs\n    per_device_train_batch_size=12,  # batch size per device during training\n    per_device_eval_batch_size=12,   # batch size for evaluation\n    warmup_steps=300,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    load_best_model_at_end = True,\n    do_eval = True,\n    learning_rate = 1e-5, \n    lr_scheduler_type = \"cosine\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1e5, 180 best, try 300","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=val_dataset             # evaluation dataset\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save model\n- saving the model so that it can be used later in offline settings","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"./model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation scores","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nval_preds = trainer.predict(val_dataset)\nmean_squared_error(list(val_data[\"target\"]), list(val_preds.predictions.reshape(1,-1)[0]))**(1/2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting on test data","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\ntest_encodings = tokenizer(list(test_data[\"excerpt\"]), truncation=True, padding=True, return_tensors=\"pt\")\ntest_dataset = ReadabilityDataset(test_encodings,[0 for i in range(len(test_data[\"excerpt\"]))])\npreds = trainer.predict(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making a submission file","metadata":{}},{"cell_type":"code","source":"submit = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmit[\"target\"] = list(preds.predictions.reshape(1,-1)[0])\nsubmit[\"id\"] = test_data[\"id\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv(\"submission.csv\",index = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How sumbit this model\n\n- In this notebook we have used the model by downloading from internet\n- But while submission we need to keep the model offline\n- Once you fine tune and generate a model commit the notebook\n- Then you will see something like this in the output section of commit\n- Click the button (circled in yellow) to add the model as a dataset and use it while inferencing\n- You can find the inferencing code [here](https://www.kaggle.com/abhilashreddyy/inference-transformer-model-using-hugging-face) (can be used for submitting the code)\n\n![](https://i.ibb.co/4MSSMQT/Whats-App-Image-2021-05-18-at-13-42-10.jpg)","metadata":{}},{"cell_type":"markdown","source":"## Now your turn. Upvote if you find this notebook helpful :-)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}