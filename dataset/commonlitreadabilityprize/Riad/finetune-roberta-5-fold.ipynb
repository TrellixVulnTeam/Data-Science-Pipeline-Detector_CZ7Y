{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer,TFAutoModel,RobertaConfig\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\",max_length=256)\nconfig = RobertaConfig(wd=0.01,max_len=256)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:08.654685Z","iopub.execute_input":"2021-08-15T06:01:08.655129Z","iopub.status.idle":"2021-08-15T06:01:11.823897Z","shell.execute_reply.started":"2021-08-15T06:01:08.655082Z","shell.execute_reply":"2021-08-15T06:01:11.823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nexternal_df = pd.read_csv('../input/increase-the-external-dataset-for-pseudo-labeling/filtered_aug_dataset')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:11.825422Z","iopub.execute_input":"2021-08-15T06:01:11.825809Z","iopub.status.idle":"2021-08-15T06:01:11.90825Z","shell.execute_reply.started":"2021-08-15T06:01:11.825754Z","shell.execute_reply":"2021-08-15T06:01:11.907438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filterd_external_df = external_df[external_df['target'] != 'remove']\nfilterd_external_df = filterd_external_df.reset_index(drop=True)\ndel filterd_external_df[\"Unnamed: 0\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:11.909958Z","iopub.execute_input":"2021-08-15T06:01:11.910202Z","iopub.status.idle":"2021-08-15T06:01:11.919449Z","shell.execute_reply.started":"2021-08-15T06:01:11.910179Z","shell.execute_reply":"2021-08-15T06:01:11.918549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filterd_external_df = filterd_external_df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:11.921291Z","iopub.execute_input":"2021-08-15T06:01:11.92168Z","iopub.status.idle":"2021-08-15T06:01:11.934481Z","shell.execute_reply.started":"2021-08-15T06:01:11.921645Z","shell.execute_reply":"2021-08-15T06:01:11.933608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npath=[\n    \"../input/commonlitreadabilityprize/sample_submission.csv\",\n    \"../input/commonlitreadabilityprize/test.csv\",\n    \"../input/commonlitreadabilityprize/train.csv\"\n]\n\ndf_train = pd.read_csv(path[2])\ndf_test = pd.read_csv(path[1])\ndf_ss = pd.read_csv(path[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:11.935664Z","iopub.execute_input":"2021-08-15T06:01:11.93602Z","iopub.status.idle":"2021-08-15T06:01:11.980681Z","shell.execute_reply.started":"2021-08-15T06:01:11.935986Z","shell.execute_reply":"2021-08-15T06:01:11.979858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['url_legal','license'],axis='columns')\ndf_test = df_test.drop(['url_legal','license'],axis='columns')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:11.98274Z","iopub.execute_input":"2021-08-15T06:01:11.983408Z","iopub.status.idle":"2021-08-15T06:01:11.990567Z","shell.execute_reply.started":"2021-08-15T06:01:11.983369Z","shell.execute_reply":"2021-08-15T06:01:11.989608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= df_train['excerpt']\ny=df_train['target'].values\nX_external = filterd_external_df['excerpt']\ny_external = filterd_external_df['target'].values\nX_test = df_test['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:11.992012Z","iopub.execute_input":"2021-08-15T06:01:11.992452Z","iopub.status.idle":"2021-08-15T06:01:12.002249Z","shell.execute_reply.started":"2021-08-15T06:01:11.99241Z","shell.execute_reply":"2021-08-15T06:01:12.001288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\n\nn_splits = 5\ndf_train['bin'] = pd.cut(df_train.target,20, labels=[i for i in range(20)])\nskf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\ngen_skf = skf.split(df_train.id, y=df_train.bin)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:12.005999Z","iopub.execute_input":"2021-08-15T06:01:12.006301Z","iopub.status.idle":"2021-08-15T06:01:12.019086Z","shell.execute_reply.started":"2021-08-15T06:01:12.006275Z","shell.execute_reply":"2021-08-15T06:01:12.018106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport keras\nglobal best_score \nglobal scores \nclass eval_on_batch(keras.callbacks.Callback):\n    def __init__(self,val_set,target,filepath):\n        self.val_set = val_set\n        self.target = target\n        self.best_score = float('inf')\n        self.filepath = filepath\n        \n    def  on_train_batch_end(self,batch,logs=None):\n            if batch % 10 == 0 and batch != 0:\n                predictions = self.model.predict(self.val_set)[:,0]\n                cv = mean_squared_error(self.target, predictions)\n                if (cv < self.best_score and cv <= 0.6):\n                    self.model.save_weights(self.filepath)\n                    self.best_score = cv                 \n                    print(f\"\\n validation error --> {cv}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:12.020865Z","iopub.execute_input":"2021-08-15T06:01:12.021322Z","iopub.status.idle":"2021-08-15T06:01:12.031402Z","shell.execute_reply.started":"2021-08-15T06:01:12.021265Z","shell.execute_reply":"2021-08-15T06:01:12.030417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport tensorflow_addons as tfa\nimport tensorflow as tf\n\nimport numpy as np\nimport os\nSEEDS = [42]\ncv_pred = np.zeros((len(X),))\ntest_pred = np.zeros((len(X_test)))\nfor seed in SEEDS:\n    skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n    gen_skf = skf.split(df_train.id, y=df_train.bin)\n    seed = 1\n    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n        X_train = X[idx_train]\n        X_labels = y[idx_train]\n        X_val = X[idx_val]\n        val_labels = y[idx_val] \n        test_labels = np.zeros((len(X_test),))\n        \n        training_features = tokenizer(list(X_train),padding=\"max_length\", truncation=True,return_tensors='tf')\n        val_features = tokenizer(list(X_val),padding=\"max_length\", truncation=True,return_tensors='tf')\n        testing_features = tokenizer(list(X_test),padding=\"max_length\", truncation=True,return_tensors='tf')   \n        training_features = {x:training_features[x] for x in tokenizer.model_input_names}\n        val_features = {x:val_features[x] for x in tokenizer.model_input_names}\n   \n        testing_features =  {x:testing_features[x] for x in tokenizer.model_input_names}\n        training_set = tf.data.Dataset.from_tensor_slices((training_features, X_labels))\n        training_set = training_set.batch(8)\n        val_set = tf.data.Dataset.from_tensor_slices((val_features,val_labels))\n        val_set = val_set.batch(8)\n        test_set = tf.data.Dataset.from_tensor_slices((testing_features,test_labels))\n        test_set = test_set.batch(8) \n        \n        if fold == None:\n            external_features = tokenizer(list(X_external),padding=\"max_length\", truncation=True,return_tensors='tf')\n            external_features = {x:external_features[x] for x in tokenizer.model_input_names}\n            external_set = tf.data.Dataset.from_tensor_slices((external_features,np.array(y_external,dtype=float)))\n            external_set = external_set.batch(8)\n            \n        \n        transformer_model = TFAutoModel.from_pretrained(\"roberta-base\",output_hidden_states=True)    \n        input_ids = tf.keras.Input(shape=(256, ),dtype='int32')\n        attention_mask = tf.keras.Input(shape=(256, ),dtype='int32')\n        transformer = transformer_model({'input_ids':input_ids,'attention_mask':attention_mask})    \n        hidden_states = transformer[0] # get output_hidden_states\n        \n        x = tf.keras.layers.Dense(128, activation='relu')(hidden_states[:,-1,:])\n        x = tf.keras.layers.Dropout(0.025)(x)\n        output = tf.keras.layers.Dense(1)(x)\n        model = tf.keras.models.Model(inputs = [{'input_ids':input_ids,'attention_mask':attention_mask}],outputs = output)\n        checkpoint_filepath = f'../input/finetune-roberta-evaluate-model-at-each-10-steps/model{seed}_{fold}_pseudo_label'\n        \"\"\"model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n        \n        \n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=8e-6),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=tf.keras.losses.MeanSquaredError(),\n            steps_per_execution=1)\"\"\"\n        \n        #eval_on_batch_callback = eval_on_batch(val_set = val_set,target = y[idx_val],filepath = checkpoint_filepath)\n        \n        print('__________load pretrained model on Pseudo labels___________')\n        #model.fit(external_set,validation_data=val_set,epochs=3,callbacks=[eval_on_batch_callback],verbose=1)\n        LR_decay =  tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=2e-5,first_decay_steps=1,alpha=2e-10)\n        LR_callback = tf.keras.callbacks.LearningRateScheduler(LR_decay)\n        model.compile(\n            optimizer=tf.optimizers.Adam(learning_rate=2e-5),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=tf.keras.losses.MeanSquaredError(),\n            steps_per_execution=1)\n        \n        model.load_weights(checkpoint_filepath)\n        \n        checkpoint_filepath = f'./model{seed}_{fold}'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n        \n        eval_on_batch_callback = eval_on_batch(val_set = val_set,target = y[idx_val],filepath = checkpoint_filepath)\n        print(f'__________________Fold{fold}__________________')\n        model.fit(training_set,validation_data=val_set,epochs=3,callbacks=[eval_on_batch_callback],verbose=1)\n        model.load_weights(checkpoint_filepath)    \n        cv_pred[idx_val] += model.predict(val_set)[:,0]/(len(SEEDS))\n        print('cv = ',mean_squared_error(cv_pred[idx_val],y[idx_val]))\n        test_pred += model.predict(test_set)[:,0]/(n_splits*len(SEEDS))\n    print(f'OOF{seed}=',mean_squared_error(cv_pred,y))\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-08-15T06:01:12.033174Z","iopub.execute_input":"2021-08-15T06:01:12.033649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.experimental.CosineDecayRestarts(\n    2e-8, first_decay_steps = 1, t_mul=2.0, m_mul=1.0, alpha=0.0,\n    name=None\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = test_pred\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}