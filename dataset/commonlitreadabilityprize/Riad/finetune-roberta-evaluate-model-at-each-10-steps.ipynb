{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer,TFAutoModel,RobertaConfig\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\",max_length=256)\nconfig = RobertaConfig(wd=0.01,max_len=256)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:50.588579Z","iopub.execute_input":"2021-08-14T15:17:50.588921Z","iopub.status.idle":"2021-08-14T15:17:51.170521Z","shell.execute_reply.started":"2021-08-14T15:17:50.58887Z","shell.execute_reply":"2021-08-14T15:17:51.169665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nexternal_df = pd.read_csv('../input/increase-the-external-dataset-for-pseudo-labeling/filtered_aug_dataset')","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.173843Z","iopub.execute_input":"2021-08-14T15:17:51.17412Z","iopub.status.idle":"2021-08-14T15:17:51.252337Z","shell.execute_reply.started":"2021-08-14T15:17:51.174094Z","shell.execute_reply":"2021-08-14T15:17:51.25149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filterd_external_df = external_df[external_df['target'] != 'remove']\nfilterd_external_df = filterd_external_df.reset_index(drop=True)\ndel filterd_external_df[\"Unnamed: 0\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.254177Z","iopub.execute_input":"2021-08-14T15:17:51.254534Z","iopub.status.idle":"2021-08-14T15:17:51.263427Z","shell.execute_reply.started":"2021-08-14T15:17:51.254496Z","shell.execute_reply":"2021-08-14T15:17:51.262455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filterd_external_df = filterd_external_df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.265174Z","iopub.execute_input":"2021-08-14T15:17:51.265564Z","iopub.status.idle":"2021-08-14T15:17:51.278006Z","shell.execute_reply.started":"2021-08-14T15:17:51.265527Z","shell.execute_reply":"2021-08-14T15:17:51.277224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npath=[\n    \"../input/commonlitreadabilityprize/sample_submission.csv\",\n    \"../input/commonlitreadabilityprize/test.csv\",\n    \"../input/commonlitreadabilityprize/train.csv\"\n]\n\ndf_train = pd.read_csv(path[2])\ndf_test = pd.read_csv(path[1])\ndf_ss = pd.read_csv(path[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.279438Z","iopub.execute_input":"2021-08-14T15:17:51.27977Z","iopub.status.idle":"2021-08-14T15:17:51.319095Z","shell.execute_reply.started":"2021-08-14T15:17:51.279737Z","shell.execute_reply":"2021-08-14T15:17:51.318351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['url_legal','license'],axis='columns')\ndf_test = df_test.drop(['url_legal','license'],axis='columns')","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.320316Z","iopub.execute_input":"2021-08-14T15:17:51.32068Z","iopub.status.idle":"2021-08-14T15:17:51.326913Z","shell.execute_reply.started":"2021-08-14T15:17:51.320644Z","shell.execute_reply":"2021-08-14T15:17:51.325723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= df_train['excerpt']\ny=df_train['target'].values\nX_external = filterd_external_df['excerpt']\ny_external = filterd_external_df['target'].values\nX_test = df_test['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.328475Z","iopub.execute_input":"2021-08-14T15:17:51.328859Z","iopub.status.idle":"2021-08-14T15:17:51.337559Z","shell.execute_reply.started":"2021-08-14T15:17:51.328821Z","shell.execute_reply":"2021-08-14T15:17:51.336728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\n\nn_splits = 5\ndf_train['bin'] = pd.cut(df_train.target,20, labels=[i for i in range(20)])\nskf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\ngen_skf = skf.split(df_train.id, y=df_train.bin)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.340019Z","iopub.execute_input":"2021-08-14T15:17:51.340443Z","iopub.status.idle":"2021-08-14T15:17:51.350975Z","shell.execute_reply.started":"2021-08-14T15:17:51.340407Z","shell.execute_reply":"2021-08-14T15:17:51.35015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport keras\nglobal best_score \nglobal scores \nclass eval_on_batch(keras.callbacks.Callback):\n    def __init__(self,val_set,target,filepath):\n        self.val_set = val_set\n        self.target = target\n        self.best_score = float('inf')\n        self.filepath = filepath\n        \n    def  on_train_batch_end(self,batch,logs=None):\n            if batch % 10 == 0 and batch != 0:\n                predictions = self.model.predict(self.val_set)[:,0]\n                cv = mean_squared_error(self.target, predictions)\n                if (cv < self.best_score and cv <= 0.6):\n                    self.model.save_weights(self.filepath)\n                    self.best_score = cv                 \n                    print(f\"\\n validation error --> {cv}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.352282Z","iopub.execute_input":"2021-08-14T15:17:51.352613Z","iopub.status.idle":"2021-08-14T15:17:51.361119Z","shell.execute_reply.started":"2021-08-14T15:17:51.352577Z","shell.execute_reply":"2021-08-14T15:17:51.360111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport numpy as np\nimport os\nSEEDS = [1]\ncv_pred = np.zeros((len(X),))\ntest_pred = np.zeros((len(X_test)))\nfor seed in SEEDS:\n    skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n    gen_skf = skf.split(df_train.id, y=df_train.bin)\n    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n        X_train = X[idx_train]\n        X_labels = y[idx_train]\n        X_val = X[idx_val]\n        val_labels = y[idx_val] \n        test_labels = np.zeros((len(X_test),))\n        \n        training_features = tokenizer(list(X_train),padding=\"max_length\", truncation=True,return_tensors='tf')\n        val_features = tokenizer(list(X_val),padding=\"max_length\", truncation=True,return_tensors='tf')\n        testing_features = tokenizer(list(X_test),padding=\"max_length\", truncation=True,return_tensors='tf')   \n        training_features = {x:training_features[x] for x in tokenizer.model_input_names}\n        val_features = {x:val_features[x] for x in tokenizer.model_input_names}\n   \n        testing_features =  {x:testing_features[x] for x in tokenizer.model_input_names}\n        training_set = tf.data.Dataset.from_tensor_slices((training_features, X_labels))\n        training_set = training_set.batch(8)\n        val_set = tf.data.Dataset.from_tensor_slices((val_features,val_labels))\n        val_set = val_set.batch(8)\n        test_set = tf.data.Dataset.from_tensor_slices((testing_features,test_labels))\n        test_set = test_set.batch(8) \n        \n        if fold == 0:\n            external_features = tokenizer(list(X_external),padding=\"max_length\", truncation=True,return_tensors='tf')\n            external_features = {x:external_features[x] for x in tokenizer.model_input_names}\n            external_set = tf.data.Dataset.from_tensor_slices((external_features,np.array(y_external,dtype=float)))\n            external_set = external_set.batch(8)\n            \n        \n        transformer_model = TFAutoModel.from_pretrained(\"roberta-base\",output_hidden_states=True)    \n        input_ids = tf.keras.Input(shape=(256, ),dtype='int32')\n        attention_mask = tf.keras.Input(shape=(256, ),dtype='int32')\n        transformer = transformer_model({'input_ids':input_ids,'attention_mask':attention_mask})    \n        hidden_states = transformer[0] # get output_hidden_states\n        \n        x = tf.keras.layers.Dense(128, activation='relu')(hidden_states[:,-1,:])\n        x = tf.keras.layers.Dropout(0.025)(x)\n        output = tf.keras.layers.Dense(1)(x)\n        model = tf.keras.models.Model(inputs = [{'input_ids':input_ids,'attention_mask':attention_mask}],outputs = output)\n        checkpoint_filepath = f'./model{seed}_{fold}_pseudo_label'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n        \n        \n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=8e-6),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=tf.keras.losses.MeanSquaredError(),\n            steps_per_execution=1)\n        \n        eval_on_batch_callback = eval_on_batch(val_set = val_set,target = y[idx_val],filepath = checkpoint_filepath)\n        \n        print('__________train model on Pseudo labels___________')\n        model.fit(external_set,validation_data=val_set,epochs=3,callbacks=[eval_on_batch_callback],verbose=1)\n        \n    \"\"\" model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=tf.keras.losses.MeanSquaredError(),\n            steps_per_execution=1)\n        \n        model.load_weights(checkpoint_filepath)\n        \n        checkpoint_filepath = f'./model{seed}_{fold}'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n        \n        eval_on_batch_callback = eval_on_batch(val_set = val_set,target = y[idx_val],filepath = checkpoint_filepath)\n        print(f'__________________Fold{fold}__________________')\n        model.fit(training_set,validation_data=val_set,epochs=3,callbacks=[eval_on_batch_callback],verbose=1)\n        model.load_weights(checkpoint_filepath)    \n        cv_pred[idx_val] += model.predict(val_set)[:,0]/(len(SEEDS))\n        print('cv = ',mean_squared_error(cv_pred[idx_val],y[idx_val]))\n        test_pred += model.predict(test_set)[:,0]/(n_splits*len(SEEDS)) \"\"\"\n    #print(f'OOF{seed}=',mean_squared_error(cv_pred,y))\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T15:17:51.362427Z","iopub.execute_input":"2021-08-14T15:17:51.36277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\n#submission.target = test_pred\n#submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}