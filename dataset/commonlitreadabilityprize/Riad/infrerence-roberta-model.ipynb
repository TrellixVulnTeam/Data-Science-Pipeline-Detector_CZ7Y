{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer,TFAutoModel\ntokenizer = AutoTokenizer.from_pretrained(\"../input/huggingface-roberta-variants/roberta-base/roberta-base\",max_length=256)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T14:59:11.425396Z","iopub.execute_input":"2021-08-15T14:59:11.425857Z","iopub.status.idle":"2021-08-15T14:59:19.893724Z","shell.execute_reply.started":"2021-08-15T14:59:11.425768Z","shell.execute_reply":"2021-08-15T14:59:19.892286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npath=[\n    \"../input/commonlitreadabilityprize/sample_submission.csv\",\n    \"../input/commonlitreadabilityprize/test.csv\",\n    \"../input/commonlitreadabilityprize/train.csv\"\n]\n\ndf_train = pd.read_csv(path[2])\ndf_test = pd.read_csv(path[1])\ndf_ss = pd.read_csv(path[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-15T14:59:19.898227Z","iopub.execute_input":"2021-08-15T14:59:19.89859Z","iopub.status.idle":"2021-08-15T14:59:20.021173Z","shell.execute_reply.started":"2021-08-15T14:59:19.898557Z","shell.execute_reply":"2021-08-15T14:59:20.020119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['url_legal','license'],axis='columns')\ndf_test = df_test.drop(['url_legal','license'],axis='columns')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T14:59:20.023418Z","iopub.execute_input":"2021-08-15T14:59:20.023899Z","iopub.status.idle":"2021-08-15T14:59:20.041699Z","shell.execute_reply.started":"2021-08-15T14:59:20.023854Z","shell.execute_reply":"2021-08-15T14:59:20.040123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= df_train['excerpt']\ny=df_train['target'].values\n\nX_test = df_test['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-08-15T14:59:20.044574Z","iopub.execute_input":"2021-08-15T14:59:20.045067Z","iopub.status.idle":"2021-08-15T14:59:20.055361Z","shell.execute_reply.started":"2021-08-15T14:59:20.045022Z","shell.execute_reply":"2021-08-15T14:59:20.054093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\n\nn_splits = 5\ndf_train['bin'] = pd.cut(df_train.target,20, labels=[i for i in range(20)])\nskf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\ngen_skf = skf.split(df_train.id, y=df_train.bin)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-15T14:59:20.059755Z","iopub.execute_input":"2021-08-15T14:59:20.060311Z","iopub.status.idle":"2021-08-15T14:59:20.718745Z","shell.execute_reply.started":"2021-08-15T14:59:20.060278Z","shell.execute_reply":"2021-08-15T14:59:20.717574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport os\nSEEDS = [42]\ncv_pred = np.zeros((len(X),))\ntest_pred = np.zeros((len(X_test)))\nfor seed in SEEDS:\n    #skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n    #gen_skf = skf.split(df_train.id, y=df_train.bin)\n    kfold = KFold(n_splits=5, shuffle= True , random_state= seed)\n    for fold, (idx_train, idx_val) in enumerate(kfold.split(X,y)):\n        X_train = X[idx_train]\n        X_labels = y[idx_train]\n        X_val = X[idx_val]\n        val_labels = y[idx_val] \n        test_labels = np.zeros((len(X_test),))\n        \n        #training_features = tokenizer(list(X_train),padding=\"max_length\", truncation=True,return_tensors='tf')\n        val_features = tokenizer(list(X_val),padding=\"max_length\",max_length=256,truncation=True,return_tensors='tf')\n        testing_features = tokenizer(list(X_test),padding=\"max_length\",max_length=256,truncation=True,return_tensors='tf')   \n        #training_features = {x:training_features[x] for x in tokenizer.model_input_names}\n        val_features = {x:val_features[x] for x in tokenizer.model_input_names}\n   \n        testing_features =  {x:testing_features[x] for x in tokenizer.model_input_names}\n        #training_set = tf.data.Dataset.from_tensor_slices((training_features, X_labels))\n        #training_set = training_set.batch(8)\n        val_set = tf.data.Dataset.from_tensor_slices((val_features,val_labels))\n        val_set = val_set.batch(8)\n        test_set = tf.data.Dataset.from_tensor_slices((testing_features,test_labels))\n        test_set = test_set.batch(8) \n        \n    \n        transformer_model = TFAutoModel.from_pretrained(\"../input/huggingface-roberta-variants/roberta-base/roberta-base\",output_hidden_states=True)    \n        input_ids = tf.keras.Input(shape=(256, ),dtype='int32')\n        attention_mask = tf.keras.Input(shape=(256, ),dtype='int32')\n        transformer = transformer_model({'input_ids':input_ids,'attention_mask':attention_mask})    \n        hidden_states = transformer[0] # get output_hidden_states\n        \n        x = tf.keras.layers.Dense(128, activation='relu')(hidden_states[:,-1,:])\n        x = tf.keras.layers.Dropout(0.025)(x)\n        output = tf.keras.layers.Dense(1)(x)\n        model = tf.keras.models.Model(inputs = [{'input_ids':input_ids,'attention_mask':attention_mask}],outputs = output)\n        checkpoint_filepath = f'../input/fork-of-finetune-roberta-model-with-5-fold/model{seed}_{fold}'\n\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=tf.keras.losses.MeanSquaredError())\n        \n        model.load_weights(checkpoint_filepath)    \n        cv_pred[idx_val] += model.predict(val_set)[:,0]/(len(SEEDS))\n        print(mean_squared_error(cv_pred[idx_val],y[idx_val]))\n        test_pred += model.predict(test_set)[:,0]/(n_splits*len(SEEDS))\n    print(f'OOF{seed}=',mean_squared_error(cv_pred,y))","metadata":{"execution":{"iopub.status.busy":"2021-08-15T14:59:20.720603Z","iopub.execute_input":"2021-08-15T14:59:20.721054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = test_pred\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}