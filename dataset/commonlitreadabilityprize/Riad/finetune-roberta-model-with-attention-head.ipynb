{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer,TFAutoModel,AutoConfig\ntokenizer = AutoTokenizer.from_pretrained(\"../input/clrp-roberta-base/clrp_roberta_base\",max_length=256)\nconfig = AutoConfig.from_pretrained(\"../input/clrp-roberta-base/clrp_roberta_base\")","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:34.787982Z","iopub.execute_input":"2021-08-20T08:07:34.788428Z","iopub.status.idle":"2021-08-20T08:07:35.338463Z","shell.execute_reply.started":"2021-08-20T08:07:34.788389Z","shell.execute_reply":"2021-08-20T08:07:35.337402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nexternal_df = pd.read_csv('../input/increase-the-external-dataset-for-pseudo-labeling/filtered_aug_dataset')","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.34032Z","iopub.execute_input":"2021-08-20T08:07:35.340756Z","iopub.status.idle":"2021-08-20T08:07:35.444225Z","shell.execute_reply.started":"2021-08-20T08:07:35.340708Z","shell.execute_reply":"2021-08-20T08:07:35.443229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filterd_external_df = external_df[external_df['target'] != 'remove']\nfilterd_external_df = filterd_external_df.reset_index(drop=True)\ndel filterd_external_df[\"Unnamed: 0\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.446733Z","iopub.execute_input":"2021-08-20T08:07:35.44714Z","iopub.status.idle":"2021-08-20T08:07:35.460584Z","shell.execute_reply.started":"2021-08-20T08:07:35.447104Z","shell.execute_reply":"2021-08-20T08:07:35.459087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npath=[\n    \"../input/commonlitreadabilityprize/sample_submission.csv\",\n    \"../input/commonlitreadabilityprize/test.csv\",\n    \"../input/commonlitreadabilityprize/train.csv\"\n]\n\ndf_train = pd.read_csv(path[2])\ndf_test = pd.read_csv(path[1])\ndf_ss = pd.read_csv(path[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.463483Z","iopub.execute_input":"2021-08-20T08:07:35.464088Z","iopub.status.idle":"2021-08-20T08:07:35.521293Z","shell.execute_reply.started":"2021-08-20T08:07:35.464039Z","shell.execute_reply":"2021-08-20T08:07:35.520199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['url_legal','license'],axis='columns')\ndf_test = df_test.drop(['url_legal','license'],axis='columns')","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.522875Z","iopub.execute_input":"2021-08-20T08:07:35.523277Z","iopub.status.idle":"2021-08-20T08:07:35.531836Z","shell.execute_reply.started":"2021-08-20T08:07:35.523233Z","shell.execute_reply":"2021-08-20T08:07:35.530712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= df_train['excerpt']\ny=df_train['target'].values\nX_external = filterd_external_df['excerpt']\ny_external = filterd_external_df['target'].values\nX_test = df_test['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.533822Z","iopub.execute_input":"2021-08-20T08:07:35.534745Z","iopub.status.idle":"2021-08-20T08:07:35.544042Z","shell.execute_reply.started":"2021-08-20T08:07:35.534678Z","shell.execute_reply":"2021-08-20T08:07:35.542959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\n\nn_splits = 5\ndf_train['bin'] = pd.cut(df_train.target,12, labels=[i for i in range(12)])\nskf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\ngen_skf = skf.split(df_train.id, y=df_train.bin)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.546063Z","iopub.execute_input":"2021-08-20T08:07:35.546584Z","iopub.status.idle":"2021-08-20T08:07:35.560419Z","shell.execute_reply.started":"2021-08-20T08:07:35.546538Z","shell.execute_reply":"2021-08-20T08:07:35.559228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true))) ","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.563024Z","iopub.execute_input":"2021-08-20T08:07:35.563459Z","iopub.status.idle":"2021-08-20T08:07:35.56861Z","shell.execute_reply.started":"2021-08-20T08:07:35.563415Z","shell.execute_reply":"2021-08-20T08:07:35.567474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport keras\nglobal best_score \nglobal scores \nclass eval_on_batch(keras.callbacks.Callback):\n    def __init__(self,val_set,target,filepath):\n        self.val_set = val_set\n        self.target = target\n        self.best_score = float('inf')\n        self.filepath = filepath\n        \n    def  on_train_batch_end(self,batch,logs=None):\n            if batch % 10 == 0 and batch != 0:\n                predictions = self.model.predict(self.val_set)[:,0]\n                cv = root_mean_squared_error(self.target, predictions)\n                if (cv < self.best_score and cv <= 0.6):\n                    self.model.save_weights(self.filepath)\n                    self.best_score = cv                 \n                    print(f\"\\n validation error --> {cv}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:07:35.570761Z","iopub.execute_input":"2021-08-20T08:07:35.57126Z","iopub.status.idle":"2021-08-20T08:07:35.5821Z","shell.execute_reply.started":"2021-08-20T08:07:35.571211Z","shell.execute_reply":"2021-08-20T08:07:35.580608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport numpy as np\nimport os\nSEEDS = [42]\ncv_pred = np.zeros((len(X),))\ntest_pred = np.zeros((len(X_test)))\nfor seed in SEEDS:\n    skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n    gen_skf = skf.split(df_train.id, y=df_train.bin)\n    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n        X_train = X[idx_train]\n        X_labels = y[idx_train]\n        X_val = X[idx_val]\n        val_labels = y[idx_val] \n        test_labels = np.zeros((len(X_test),))\n        \n        training_features = tokenizer(list(X_train),padding=\"max_length\",max_length=256,truncation=True,return_tensors='tf')\n        val_features = tokenizer(list(X_val),padding=\"max_length\",max_length=256,truncation=True,return_tensors='tf')\n        testing_features = tokenizer(list(X_test),padding=\"max_length\",max_length=256,truncation=True,return_tensors='tf')   \n        training_features = {x:training_features[x] for x in tokenizer.model_input_names}\n        val_features = {x:val_features[x] for x in tokenizer.model_input_names}\n   \n        testing_features =  {x:testing_features[x] for x in tokenizer.model_input_names}\n        training_set = tf.data.Dataset.from_tensor_slices((training_features, X_labels))\n        training_set = training_set.batch(8)\n        val_set = tf.data.Dataset.from_tensor_slices((val_features,val_labels))\n        val_set = val_set.batch(8)\n        test_set = tf.data.Dataset.from_tensor_slices((testing_features,test_labels))\n        test_set = test_set.batch(8) \n        \n        if fold == 0:\n            external_features = tokenizer(list(X_external),padding=\"max_length\",truncation=True,return_tensors='tf')\n            external_features = {x:external_features[x] for x in tokenizer.model_input_names}\n            external_set = tf.data.Dataset.from_tensor_slices((external_features,np.array(y_external,dtype=float)))\n            external_set = external_set.batch(8)\n            \n        \n        transformer_model = TFAutoModel.from_pretrained(\"../input/clrp-roberta-base/clrp_roberta_base\",output_hidden_states=True,from_pt=True)    \n        input_ids = tf.keras.Input(shape=(256, ),dtype='int32')\n        attention_mask = tf.keras.Input(shape=(256, ),dtype='int32')\n        transformer = transformer_model({'input_ids':input_ids,'attention_mask':attention_mask})    \n        hidden_states = transformer[0] # get output_hidden_states\n        W = tf.keras.layers.Dense(config.hidden_size)(hidden_states)\n        att = tf.nn.tanh(W)\n        V = tf.keras.layers.Dense(1)(att)\n        attention_weights = tf.nn.softmax(V,axis=1)\n        context_vector = attention_weights*hidden_states\n        context_vector = tf.math.reduce_sum(context_vector,axis=1) \n        x = tf.keras.layers.Dropout(0.5)(context_vector)\n        output = tf.keras.layers.Dense(1)(x)\n        \n        model = tf.keras.models.Model(inputs = [{'input_ids':input_ids,'attention_mask':attention_mask}],outputs = output)\n        checkpoint_filepath = f'./model'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n        \n        RL_S = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=2e-5,first_decay_steps=(len(X_train)/8)*3,alpha=0.1)   \n        RL_S_callback = tf.keras.callbacks.LearningRateScheduler(RL_S)\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n            loss=root_mean_squared_error,\n            metrics=root_mean_squared_error,\n            steps_per_execution=1)\n        \n        if fold == 10:\n            model.fit(external_set,validation_data=val_set,epochs=4,callbacks=[eval_on_batch_callback])\n            \n       # model.load_weights(checkpoint_filepath)\n        \n        checkpoint_filepath = f'./model{seed}_{fold}'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n        \n        eval_on_batch_callback = eval_on_batch(val_set = val_set,target = y[idx_val],filepath = checkpoint_filepath)\n        print(f'__________________Fold{fold}__________________')\n        model.fit(training_set,validation_data=val_set,epochs=3,verbose=1,callbacks=[RL_S_callback,eval_on_batch_callback])#callbacks=[RL_S_callback]\n        model.load_weights(checkpoint_filepath)    \n        cv_pred[idx_val] += model.predict(val_set)[:,0]/(len(SEEDS))\n        print('cv = ',mean_squared_error(cv_pred[idx_val],y[idx_val]))\n        test_pred += model.predict(test_set)[:,0]/(n_splits*len(SEEDS))\n    print(f'OOF{seed}=',mean_squared_error(cv_pred,y))\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:22:08.852374Z","iopub.execute_input":"2021-08-20T08:22:08.852923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = test_pred\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:21:48.936489Z","iopub.status.idle":"2021-08-20T08:21:48.936974Z"},"trusted":true},"execution_count":null,"outputs":[]}]}