{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer,TFAutoModelForSequenceClassification\ntokenizer = AutoTokenizer.from_pretrained(\"../input/huggingface-bert-variants/bert-base-cased/bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:22:47.037341Z","iopub.execute_input":"2021-08-10T15:22:47.037799Z","iopub.status.idle":"2021-08-10T15:22:53.378287Z","shell.execute_reply.started":"2021-08-10T15:22:47.037682Z","shell.execute_reply":"2021-08-10T15:22:53.377391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npath=[\n    \"../input/commonlitreadabilityprize/sample_submission.csv\",\n    \"../input/commonlitreadabilityprize/test.csv\",\n    \"../input/commonlitreadabilityprize/train.csv\"\n]\n\ndf_train = pd.read_csv(path[2])\ndf_test = pd.read_csv(path[1])\ndf_ss = pd.read_csv(path[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:22:53.379842Z","iopub.execute_input":"2021-08-10T15:22:53.380162Z","iopub.status.idle":"2021-08-10T15:22:53.496308Z","shell.execute_reply.started":"2021-08-10T15:22:53.380117Z","shell.execute_reply":"2021-08-10T15:22:53.495511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['url_legal','license'],axis='columns')\ndf_test = df_test.drop(['url_legal','license'],axis='columns')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:22:53.498116Z","iopub.execute_input":"2021-08-10T15:22:53.498477Z","iopub.status.idle":"2021-08-10T15:22:53.5111Z","shell.execute_reply.started":"2021-08-10T15:22:53.498442Z","shell.execute_reply":"2021-08-10T15:22:53.509931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= df_train['excerpt']\ny=df_train['target'].values\n\nX_test = df_test['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:22:53.512836Z","iopub.execute_input":"2021-08-10T15:22:53.513241Z","iopub.status.idle":"2021-08-10T15:22:53.520462Z","shell.execute_reply.started":"2021-08-10T15:22:53.513206Z","shell.execute_reply":"2021-08-10T15:22:53.519748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\n\nn_splits = 5\ndf_train['bin'] = pd.cut(df_train.target,20, labels=[i for i in range(20)])\nskf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\ngen_skf = skf.split(df_train.id, y=df_train.bin)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:22:53.521625Z","iopub.execute_input":"2021-08-10T15:22:53.522031Z","iopub.status.idle":"2021-08-10T15:22:54.013407Z","shell.execute_reply.started":"2021-08-10T15:22:53.521993Z","shell.execute_reply":"2021-08-10T15:22:54.012509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport numpy as np\nimport os\nSEEDS = [1]\ncv_pred = np.zeros((len(X),))\ntest_pred = np.zeros((len(X_test)))\nfor seed in SEEDS:\n    skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n    gen_skf = skf.split(df_train.id, y=df_train.bin)\n    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n        X_train = X[idx_train]\n        X_labels = y[idx_train]\n        X_val = X[idx_val]\n        val_labels = y[idx_val] \n        test_labels = np.zeros((len(X_test),))\n        \n        #training_features = tokenizer(list(X_train),padding=\"max_length\", truncation=True,max_length=512,return_tensors='tf')\n        val_features = tokenizer(list(X_val),padding=\"max_length\", truncation=True,max_length=512,return_tensors='tf')\n        testing_features = tokenizer(list(X_test),padding=\"max_length\",max_length=512,truncation=True,return_tensors='tf')   \n        #training_features = {x:training_features[x] for x in tokenizer.model_input_names}\n        val_features = {x:val_features[x] for x in tokenizer.model_input_names}\n        \n        testing_features =  {x:testing_features[x] for x in tokenizer.model_input_names}\n        #training_set = tf.data.Dataset.from_tensor_slices((training_features, X_labels))\n        #training_set = training_set.batch(10)\n        val_set = tf.data.Dataset.from_tensor_slices((val_features,val_labels))\n        val_set = val_set.batch(10)\n        test_set = tf.data.Dataset.from_tensor_slices((testing_features,test_labels))\n        test_set = test_set.batch(10) \n\n        transformer_model = TFAutoModelForSequenceClassification.from_pretrained(\"../input/huggingface-bert-variants/bert-base-cased/bert-base-cased\",output_hidden_states=True)    \n        input_ids = tf.keras.Input(shape=(512, ),dtype='int32')\n        token_type_ids = tf.keras.Input(shape=(512, ),dtype='int32')\n        attention_mask = tf.keras.Input(shape=(512, ), dtype='int32')\n        transformer = transformer_model([{'input_ids':input_ids,'token_type_ids':token_type_ids,'attention_mask':attention_mask}])    \n        hidden_states = transformer[1] # get output_hidden_states\n\n        hidden_states_size = 2 # count of the last states \n        hiddes_states_ind = list(range(-hidden_states_size, 0, 1))\n        selected_hiddes_states = tf.keras.layers.concatenate(tuple([hidden_states[i] for i in hiddes_states_ind]))\n        x = tf.keras.layers.Dense(128, activation='relu')(selected_hiddes_states)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(1)(x)\n        x = tf.math.reduce_mean(x,axis=1)\n        output = tf.expand_dims(x, axis=1)\n        model = tf.keras.models.Model(inputs = [{'input_ids':input_ids,'token_type_ids':token_type_ids,'attention_mask':attention_mask}], outputs = output)\n \n        checkpoint_filepath = f'../input/finetune-bert-model-with-psuedo-labeling/model{seed}_{fold}'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                monitor='val_loss',\n                mode=\"auto\",\n                save_weights_only=True,\n                save_best_only=True)\n\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n            loss=tf.keras.losses.MeanSquaredError(),\n            metrics=tf.keras.losses.MeanSquaredError())\n        \n        #model.fit(training_set,validation_data=val_set,epochs=8,callbacks=[model_checkpoint_callback])\n        model.load_weights(checkpoint_filepath)\n        cv_pred[idx_val] += model.predict(val_set)[:,0,0]/(len(SEEDS))\n        print(f\"seed{seed}-fold{fold}=\",mean_squared_error(cv_pred[idx_val],y[idx_val]))\n        test_pred += model.predict(test_set)[:,0,0]/(n_splits*len(SEEDS))\n    print(f'cv{seed}=',mean_squared_error(cv_pred,y))\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:23:58.44442Z","iopub.execute_input":"2021-08-10T15:23:58.444776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = test_pred\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:23:25.412136Z","iopub.status.idle":"2021-08-10T15:23:25.412545Z"},"trusted":true},"execution_count":null,"outputs":[]}]}