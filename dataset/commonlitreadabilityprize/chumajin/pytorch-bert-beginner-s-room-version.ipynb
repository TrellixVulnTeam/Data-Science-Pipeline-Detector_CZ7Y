{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook (LB Score : 0.546 )\n ### pytorch BERTの初心者部屋です。English version is here. https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room\n \n \n ### スコアを目指すよりも、以下のことを目的としています。\n \n*   理解を深める。\n*   言語処理でも数字のニューラルネットワークと同じように処理する。\n        \n       pytorchのニューラルネットワーク組んだことない方はまずはこちらをお勧めします。\n       \n       https://www.kaggle.com/chumajin/pytorch-neural-network-starter-detail\n       \n       \n\n      \n        \n\n\n*   BERTの雛形を作成する。\n  ","metadata":{}},{"cell_type":"markdown","source":"  ### 少しでもお役に立てれば幸いです。upvoteよろしくお願いいたします !\n  ### あと、いつもupvoteしていただける方ありがとうございます。\n  \n  \n  -----ご参考--------------------------------------------------\n  ### inference onlyのnotebookはこちらです。ver 7の結果（これより少し良いスコア)をuploadしております。\n  ### (ver8まではこのnotebookではtrainも入るため、submitに時間がかかりすぎてsubmit errorが起こっていました)\n\ninference onlyのnotebookはこちら　　https://www.kaggle.com/chumajin/inference-for-pytorch-bert-beginner-s-room?scriptVersionId=62477318\n\ninference onlyにするのは、submitが早いのと、internet onにしてしまった場合にsubmitできます。","metadata":{}},{"cell_type":"markdown","source":"--------とは言っても、ある程度スコア出ないと公開できなかったので、以下工夫した点のメモです --------\n\n  (初心者用と言っているくせにマニアック。後ほど解説します。)\n* BertModelを使用するよりも、BertForSequenceClassificationを使用した方が私はスコアが出たので、それを採用しました。\n* Bertのfine-tuningの不安定性について、 https://ai-scholar.tech/articles/bert/bert-fine-tuning を参考にパラメータをある程度採用しました。\n     \n    ※　Large-modelで20 epoch,5 k-foldsは時間かかるので、そこだけ、base uncased model採用しました。","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### epoch数をdebug = Falseだと20 epoch, Trueだと1にしています。流れだけ知りたい方はTrueにしてください。","metadata":{}},{"cell_type":"code","source":"debug = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ver9以降、inference onlyのnotebookを使用せずに、このnotebookだけでsubmitする場合は、以下のdebug2をfalseにしてください。何個かのコードを省いています。","metadata":{}},{"cell_type":"code","source":"debug2 = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0. 下準備","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n       \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \n\nimport transformers\nimport random\n\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nscaler = torch.cuda.amp.GradScaler() # GPUでの高速化。\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cpuがgpuかを自動判断\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ランダムシードの固定","metadata":{}},{"cell_type":"code","source":"SEED = 508\n\ndef random_seed(SEED):\n    \n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n\nrandom_seed(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. このコンペのEDA","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntrain.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# excerptの0番目の文章例\ntrain.excerpt[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### excerptの文章の読みやすさの難易度みたいのが、targetに記入されていて、それを予測するコンペ(とてもシンプル)","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### testにはtargetとstandard errorがない","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### testデータのtargetを予測してsubmissionファイルとして提出。","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. BERT : Tokenizer の理解を深める\n##      英単語をid化したりいろいろしてくれるやつ","metadata":{}},{"cell_type":"markdown","source":"#### bertのモデルはいろいろあるが、今回は、bert-base-uncasedを使用。\n#### bert-large-uncasedとかもあるが、BERTの中の埋め込みベクトルの次元数などが違う。\n#### https://www.kaggle.com/xhlulu/huggingface-bert にbert-large-uncasedは落ちているので、inputをそこに変えてもらえれば使えます。","metadata":{}},{"cell_type":"code","source":"# kaggle offline mode : submitはinternetがofflineなので、offlineになっています。公開されているdatasetからもってきます。\ntokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n\n# local PCなどonlineで使用する場合はこちらを使用してください。\n# tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### id 0番のものをtokenizerを使って、いろいろいじってみます。","metadata":{}},{"cell_type":"code","source":"test_s = train[\"excerpt\"].iloc[0]\ntest_s","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 何も考えずに、tokenizerのencode_plusに食わせた場合","metadata":{}},{"cell_type":"code","source":"result1 = tokenizer.encode_plus(test_s)\nresult1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tokenizerのoutputとしては辞書型で出てきて、以下の3つがある\n* input_ids : 単語id (BERTのpretrained modelに入っているやつ)※　細かいことを言うと、初めと終わりに、101[CLS]と102[SEP]が追加されている\n* token_type_ids : 文章を把握するバイナリーマスク : 今回は回帰問題で、全部 0。文章間の繋がりを見るときは途中に[SEP]など挟んで変更したりする。\n* attention_mask : 埋め込みを判定するバイナリーマスク : 例えば、今回は、後ほど文字数を合わせるために[PAD]というのを代入するが、それを判定する。\nこの方など見ていただけるとわかるかもです。https://qiita.com/omiita/items/72998858efc19a368e50","metadata":{}},{"cell_type":"markdown","source":"#### input_idsの単語idから文章に戻してみる。","metadata":{}},{"cell_type":"code","source":"tokenizer.decode(result1[\"input_ids\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 初めを表す[CLS]と終わりを表す[SEP]が追加されていることがわかる。\n#### これら2つをSpecial tokensと呼んでいる(tokenizerの引数に入れるか入れないかの選択肢があるdefaultは入るようになっている)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 【重要】BERTでは、それぞれの文章での単語数をそろえてあげる必要があります。\n   ## (pretrained modelのMaxは512個)","metadata":{}},{"cell_type":"markdown","source":"#### まずは、今回のtrainデータで一番長い文章の単語数を数えてみます。少し時間かかります。\n\n#### ver10以降、このtrain & inferenceのnotebookでsubmitする場合、省略しています（submitの時間超過でerror出たため)。\n\n#### 流したい場合はdebug2=Trueにしてください。結果はプリントスクリーンして貼ってあります。","metadata":{}},{"cell_type":"code","source":"if debug2:\n    sen_length = []\n\n    for sentence in tqdm(train[\"excerpt\"]):\n\n        token_words = tokenizer.encode_plus(sentence)[\"input_ids\"]\n        sen_length.append(len(token_words))\n\n    print('maxlenth of all sentences are  ', max(sen_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### もし、debug2をTrueにした場合、以下の結果が得られます。\n\n![image.png](attachment:f76cf253-0513-49d9-939a-11c38ebb13a5.png)","metadata":{},"attachments":{"f76cf253-0513-49d9-939a-11c38ebb13a5.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"#### 314 wordsが今回のtrainデータのmax単語数。ただし、[CLS]と[SEP]を含む。","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 314個に満たない文章は[PAD]で埋めてあげる必要がある。","metadata":{}},{"cell_type":"code","source":"test_s","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_s.split(\" \"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### tokenizerの引数を調整してあげると自動に調整してくれる","metadata":{}},{"cell_type":"code","source":"result2 = tokenizer.encode_plus(\n    test_s,\n    add_special_tokens = True, # [CLS],[SEP]を入れるか\n    max_length = 314, # paddingとtrancation(切り出し)を使って、単語数をそろえる\n    pad_to_max_length = True, # ブランク箇所に[PAD]を入れる\n    \n    truncation = True # 切り出し機能。例えばmax_length10とかにすると、最初の10文字だけにしてくれる機能。入れないと怒られたので、入れておく\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### input_idsの102のあとに0が大量に追加。attention_maskにも、先ほどは全部1だったが、0が追加されている。","metadata":{}},{"cell_type":"markdown","source":"#### 単語idから文章に戻してみる","metadata":{}},{"cell_type":"code","source":"tokenizer.decode(result2[\"input_ids\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 文章の長さをそろえるために、[PAD]が追加されていることがわかる。\n#### この部分は、Attention maskで0にして、計算されないようになっている。","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 文章を短くする場合 (計算時間とかかかるとこの辺を調整することもある。例えば10にしてみる。他のnotebookだと256とかにしている人もいます。)","metadata":{}},{"cell_type":"code","source":"result3 = tokenizer.encode_plus(\n    test_s,\n    add_special_tokens = True, # [CLS],[SEP]を入れるか\n    max_length = 10, # paddingとtrancation(切り出し)を使って、単語数をそろえる\n    pad_to_max_length = True, # ブランク箇所に[PAD]を入れる\n    \n    truncation = True # 切り出し機能。例えばmax_length10とかにすると、最初の10文字だけにしてくれる機能。入れないと怒られたので、入れておく\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### このまま使用してOK","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 今回は、最大長の314を使用していく。(以下、Dataset内で変換)","metadata":{}},{"cell_type":"code","source":"max_sens = 314","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Pytorch neural networkの下準備\n## 3.1 k-fold","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/abhishek/step-1-create-folds\n\n\nこの方が作り方共有してくれていますが、ここではシンプルにtarget順に並び替えて、5個のfoldに順番でわけます。","metadata":{}},{"cell_type":"code","source":"train = train.sort_values(\"target\").reset_index(drop=True)\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"kfold\"] = train.index % 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### まずは、お試しで、kfold = 0をvalidation, それ以外をtrainデータとします。reset_index()しないとはまりますので、注意。","metadata":{}},{"cell_type":"code","source":"p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\np_valid = train[train[\"kfold\"]==0].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 DataSet, DataLoaderを組んでいく(数字のNeural networkと同じ)","metadata":{}},{"cell_type":"code","source":"class BERTDataSet(Dataset):\n    \n    def __init__(self,sentences,targets):\n        \n        self.sentences = sentences\n        self.targets = targets\n        \n    def __len__(self):\n        \n        return len(self.sentences)\n    \n    def __getitem__(self,idx):\n        \n        sentence = self.sentences[idx]\n        \n        bert_sens = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True, \n                                max_length = max_sens, # 上で314に設定しています\n                                pad_to_max_length = True, \n                                return_attention_mask = True)\n\n        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n     \n            \n        target = torch.tensor(self.targets[idx],dtype=torch.float)\n        \n        return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n                'targets': target\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BERTDataSet(p_train[\"excerpt\"],p_train[\"target\"])\nvalid_dataset = BERTDataSet(p_valid[\"excerpt\"],p_valid[\"target\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### きちんとできていることを確認","metadata":{}},{"cell_type":"code","source":"train_batch = 16\nvalid_batch = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dataloaderの作り方(pin_memoryとかnum_worker、後ででてくるAMPも)はここの方がわかりやすく解説してくれている。\n\nhttps://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\nvalid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a in train_dataloader:\n    print(a)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### きちんとできていることを確認","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. BERTのモデル作成","metadata":{}},{"cell_type":"markdown","source":"#### BERTは用途に応じて様々なpretrainedモデルがある","metadata":{}},{"cell_type":"markdown","source":"* BertModel\n* BertForPreTraining\n* BertForMaskedLM\n* BertForNextSentencePrediction\n* BertForSequenceClassification\n* BertForMultipleChoice\n* BertForTokenClassification\n* BertForQuestionAnswering\n\nこのページの方が解説してくれています。\n\nhttps://kento1109.hatenablog.com/entry/2019/08/20/161936\n\nよく出てくるのは、文章の一部を隠して、予測したり、文章間に繋がりがあるかの判定などです。\n\n\n今回は、BertForSequenceClassification　を使用します。\n\n※　最初BertModelを使っていじくっていましたが、scoreが私は上げれませんでした。。。\ndefaultでは、0,1のように2分類ように出力が2つになっていますが、今回は回帰問題ですので、出力(num_label)を1にしてあげます。\n分類問題をしたい方はここを調整すればよいかと。","metadata":{}},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nmodel.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### modelの入力はtokenizerで出力された(単語id(input_ids)、attention_mask(mask))\ntoken_type_idはこの場合、入れても入れなくてもOKみたいです。\n\noutputの中身を見てみる","metadata":{}},{"cell_type":"code","source":"for a in train_dataloader:\n    ids = a[\"ids\"].to(device)\n    mask = a[\"mask\"].to(device)\n    #tokentype = a[\"token_type_ids\"].to(device)\n    \n    output = model(ids,mask)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### きちんと推測値が出てきている。使いたいところはlogitsのところ","metadata":{}},{"cell_type":"code","source":"output[\"logits\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output[\"logits\"].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### shape見ると、1が余計なので、squeezeというのを使うと、1のところをcutしてくれます","metadata":{}},{"cell_type":"code","source":"output[\"logits\"].squeeze(-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output[\"logits\"].squeeze(-1).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### なので、outputはこの形で使います。","metadata":{}},{"cell_type":"code","source":"output = output[\"logits\"].squeeze(-1).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. trainingをする関数作成\n\n#### optimizerの定義\n* 今回、いろいろお試ししていて、学習率の重要さを学びました(最初、学習率が高すぎて、回帰して予測した結果が全部同じ値になったり、1日以上はまりました・・・。)\n\n* とりあえず、このnotebookは、Bertのfine-tuningの不安定性について、 https://ai-scholar.tech/articles/bert/bert-fine-tuning を参考にパラメータをある程度採用しました。\n\n* ただし、上記文献では、bert-large-uncased　での話です。今回は、5 k-fold 20epoch回すのに、時間がかかりすぎてしまったため、bert-base-uncasedにしています。\n\n* 細かいので、とりあえず使いたいという人は無視してそのまま流してOKです。","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW\nLR=2e-5\noptimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 以下は、transformerに内蔵された学習率のスケジューラー(stepするごとに学習率を変えていく)です。\n#### ↑のサイトの推奨では、20 epochで、最初の10%で、目的の学習率に到達させた後、0になるように減衰していくモデルを言っていたので、それを作りました。","metadata":{}},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\n\nepochs = 20\n\nif debug:\n    epochs = 1\n\ntrain_steps = int(len(p_train)/train_batch*epochs)\nprint(train_steps)\n\nnum_steps = int(train_steps*0.1)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 少し時間がかかりますが、学習率の推移をイテレーションごとに見ていくとこんな感じです。\n#### ver9以降、submit時間超過対策で、実行しないようになっています。結果はプリントスクリーンで貼ってあります。","metadata":{}},{"cell_type":"code","source":"if debug2:\n\n\n\n    le=[]\n    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n\n    for b in tqdm(range(epochs)):\n\n        for a in train_dataloader:\n            le.append(scheduler.get_last_lr())\n            scheduler.step()\n\n    x = np.arange(len(le))\n    plt.plot(x,le)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 参考までに、上記をdebug2=Trueにして実行すると以下のグラフが得られます。横軸がイテレーションの回数、縦軸が学習率です。\n![image.png](attachment:4407ec9d-05cd-4ff7-8f93-0c13ffbd650b.png)","metadata":{},"attachments":{"4407ec9d-05cd-4ff7-8f93-0c13ffbd650b.png":{"image/png":"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"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### loss関数は、今回はRMSEなので、以下のように定義しました。","metadata":{}},{"cell_type":"code","source":"def loss_fn(output,target):\n    return torch.sqrt(nn.MSELoss()(output,target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 以上のoptimizerとかlossを入れてtrainingを関数化。\n#### AMDのautocast()を使用するので、その書き方にしています。\n\n\nhttps://qiita.com/Sosuke115/items/40265e6aaf2e414e2fea\n\nイメージはこちらの方がしやすいか\n\nhttps://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(\n    train_dataloader,\n    model,\n    optimizer,\n    scheduler\n):\n    \n    model.train()\n    torch.backends.cudnn.benchmark = True\n\n    allpreds = []\n    alltargets = []\n\n    for a in train_dataloader:\n\n        losses = []\n\n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():\n\n            ids = a[\"ids\"].to(device,non_blocking=True) # non_blocking=TrueでPinned MemoryからGPUに転送中もCPUが動作できるらしい。\n            mask = a[\"mask\"].to(device,non_blocking=True)\n            tokentype = a[\"token_type_ids\"].to(device,non_blocking=True)\n\n            output = model(ids,mask)\n            output = output[\"logits\"].squeeze(-1)\n\n            target = a[\"targets\"].to(device,non_blocking=True)\n\n            loss = loss_fn(output,target)\n\n\n            # スコア習得用\n            losses.append(loss.item())\n            allpreds.append(output.detach().cpu().numpy())\n            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n\n        scaler.scale(loss).backward() # ロスのバックワード\n        scaler.step(optimizer) # オプティマイザーの更新\n        scaler.update() # スケーラーの更新\n        \n        del loss # ここでlossを消した方がGPUのメモリの無駄な部分を消せるらしい。https://tma15.github.io/blog/2020/08/22/pytorch%E4%B8%8D%E8%A6%81%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F%E8%A8%88%E7%AE%97%E3%82%B0%E3%83%A9%E3%83%95%E3%82%92%E5%89%8A%E9%99%A4%E3%81%97%E3%81%A6%E3%83%A1%E3%83%A2%E3%83%AA%E3%82%92%E7%AF%80%E7%B4%84/\n\n        scheduler.step() # 学習率の更新\n\n        # データローダーの合併\n\n    allpreds = np.concatenate(allpreds)\n    alltargets = np.concatenate(alltargets)\n\n    # ロス関数はモニター用だけど、一応保管\n\n    losses = np.mean(losses)\n\n    # Score with rmse\n    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n\n    return losses,train_rme_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1epochテスト(実行したかったら、debug2=Trueにしてください)","metadata":{}},{"cell_type":"code","source":"if debug2:\n    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n\n    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n    \n    print(losses,train_rme_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# validationも作成します。","metadata":{}},{"cell_type":"code","source":"def validating(\n    valid_dataloader,\n    model\n):\n    \n    model.eval()\n\n    allpreds = []\n    alltargets = []\n\n    for a in valid_dataloader:\n\n        losses = []\n\n        with torch.no_grad():\n\n            ids = a[\"ids\"].to(device)\n            mask = a[\"mask\"].to(device)\n            tokentype = a[\"token_type_ids\"].to(device)\n\n            output = model(ids,mask)\n            output = output[\"logits\"].squeeze(-1)\n\n            target = a[\"targets\"].to(device)\n\n            loss = loss_fn(output,target)\n\n\n            # 採点用に\n            losses.append(loss.item())\n            allpreds.append(output.detach().cpu().numpy())\n            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n            \n            del loss\n\n\n    # dataloader分を結合\n\n    allpreds = np.concatenate(allpreds)\n    alltargets = np.concatenate(alltargets)\n\n    # lossは使わないけど一応回収\n\n    losses = np.mean(losses)\n\n    # rmseでスコア出し\n    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n\n    return allpreds,losses,valid_rme_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug2:\n    allpreds,losses,valid_rme_loss = validating(valid_dataloader,model)\n    print(allpreds[:3])\n    print(losses)\n    print(valid_rme_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----version 10 追加-----\n\n\nversion 7はtrain & inferenceで時間超過でsubmitできませんでした。しかし、inference onlyでsubmitしたところ、0.528とスコアが出ました。\n\n\nversion 9はtrain & inferenceは時間超過対策で一部コードを実行しませんでした。そうすると、スコアが0.546と下がってしまいました。\n\n\nこの現象に関する考察は、新しいnotebookで行う予定です。（リリースしたら、コメント欄に書きます）\n\n\n以下は、そこからわかったことです。いろいろとつじつまを合わせ、train & inferenceでもversion7の0.528スコアにそろえるためのコードです。\n\n（コードの中身とか、細かいことは気にしなくても良いですが、スコアの違いが気になる方は考察用の新しいnotebookをご参照ください)","metadata":{}},{"cell_type":"code","source":"if debug2 == False:\n    for a in range(epochs):\n        for b in train_dataloader:\n            break\n\n    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n\n    for a in valid_dataloader:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. traing実施","metadata":{}},{"cell_type":"markdown","source":"### 解説用にいろいろやってきたので、parameterを初期化します。","metadata":{}},{"cell_type":"code","source":"# initializing the data\n\np_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\np_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n\n\ntrain_dataset = BERTDataSet(p_train[\"excerpt\"],p_train[\"target\"])\nvalid_dataset = BERTDataSet(p_valid[\"excerpt\"],p_valid[\"target\"])\n\ntrain_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\nvalid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n\nmodel = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)\n\nmodel.to(device)\nLR=2e-5\noptimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n\ntrain_steps = int(len(p_train)/train_batch*epochs)\n\nnum_steps = int(train_steps*0.1)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainlosses = []\nvallosses = []\nbestscore = None\n\ntrainscores = []\nvalidscores = []\n\nfor epoch in tqdm(range(epochs)):\n    \n    print(\"---------------\" + str(epoch) + \"start-------------\")\n    \n    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n    \n    trainlosses.append(trainloss)\n    trainscores.append(trainscore)\n    \n    print(\"trainscore is \" + str(trainscore))\n    \n    preds,validloss,valscore=validating(valid_dataloader,model)\n    \n    vallosses.append(validloss)\n    validscores.append(valscore)\n\n    \n    print(\"valscore is \" + str(valscore))\n    \n    if bestscore is None:\n        bestscore = valscore\n        \n        print(\"Save first model\")\n        \n        state = {\n                        'state_dict': model.state_dict(),\n                        'optimizer_dict': optimizer.state_dict(),\n                        \"bestscore\":bestscore\n                    }\n            \n\n        torch.save(state, \"model0.pth\")\n        \n    elif bestscore > valscore:\n        \n        bestscore = valscore\n        \n        print(\"found better point\")\n        \n        state = {\n                        'state_dict': model.state_dict(),\n                        'optimizer_dict': optimizer.state_dict(),\n                        \"bestscore\":bestscore\n                    }\n            \n\n        torch.save(state, \"model0.pth\")\n        \n    else:\n        pass\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(p_valid[\"target\"],preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(epochs)\nplt.plot(x,trainlosses)\nplt.plot(x,vallosses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(epochs)\nplt.plot(x,trainscores)\nplt.plot(x,validscores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 他のk-fold用\nbestscores = []\nbestscores.append(bestscore)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 他のK-foldを回していきます。","metadata":{}},{"cell_type":"code","source":"for fold in range(1,5):\n    \n\n    # initializing the data\n\n    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n\n\n    train_dataset = BERTDataSet(p_train[\"excerpt\"],p_train[\"target\"])\n    valid_dataset = BERTDataSet(p_valid[\"excerpt\"],p_valid[\"target\"])\n\n    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n\n    model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)\n\n    model.to(device)\n    LR=2e-5\n    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n\n    train_steps = int(len(p_train)/train_batch*epochs)\n\n    num_steps = int(train_steps*0.1)\n\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n\n\n    trainlosses = []\n    vallosses = []\n    bestscore = None\n\n    trainscores = []\n    validscores = []\n\n    for epoch in tqdm(range(epochs)):\n\n        print(\"---------------\" + str(epoch) + \"start-------------\")\n\n        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n\n        trainlosses.append(trainloss)\n        trainscores.append(trainscore)\n\n        print(\"trainscore is \" + str(trainscore))\n\n        preds,validloss,valscore=validating(valid_dataloader,model)\n\n        vallosses.append(validloss)\n        validscores.append(valscore)\n\n\n        print(\"valscore is \" + str(valscore))\n\n        if bestscore is None:\n            bestscore = valscore\n\n            print(\"Save first model\")\n\n            state = {\n                            'state_dict': model.state_dict(),\n                            'optimizer_dict': optimizer.state_dict(),\n                            \"bestscore\":bestscore\n                        }\n\n\n            torch.save(state, \"model\" + str(fold) + \".pth\")\n\n        elif bestscore > valscore:\n\n            bestscore = valscore\n\n            print(\"found better point\")\n\n            state = {\n                            'state_dict': model.state_dict(),\n                            'optimizer_dict': optimizer.state_dict(),\n                            \"bestscore\":bestscore\n                        }\n\n\n            torch.save(state, \"model\"+ str(fold) + \".pth\")\n\n        else:\n            pass\n\n\n    bestscores.append(bestscore)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestscores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(bestscores)\nprint(\"my cv is \" + str(np.mean(bestscores)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. inference\n\n#### 以下のinference only bookにver 7の結果をuploadしております(ver8まではこのnotebookではtrainも入るため、submitに時間がかかりすぎてsubmit errorが起こっていました)。\n\n#### inferenceはこちら　https://www.kaggle.com/chumajin/inference-for-pytorch-bert-beginner-s-room?scriptVersionId=62477318\n\n#### inference版はこれよりsubmitがかなり早いです。","metadata":{}},{"cell_type":"code","source":"import gc\ndel train_dataset,valid_dataset,train_dataloader,valid_dataloader,model,optimizer,scheduler\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### inferenceにtargetはないので、無し版でDatasetを作ります。","metadata":{}},{"cell_type":"code","source":"class BERTinfDataSet(Dataset):\n    \n    def __init__(self,sentences):\n        \n        self.sentences = sentences\n       \n        \n    def __len__(self):\n        \n        return len(self.sentences)\n    \n    def __getitem__(self,idx):\n        \n        sentence = self.sentences[idx]\n        \n        \n        bert_sens = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True, # [CLS],[SEP]\n                                max_length = 314,\n                                pad_to_max_length = True, # add padding to blank\n                                truncation=True)\n\n        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n     \n        \n    \n        \n        return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n                \n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = BERTinfDataSet(test[\"excerpt\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=4,pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained('../input/bert-base-uncased',num_labels=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 作成したモデルをロードします。","metadata":{}},{"cell_type":"code","source":"pthes = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if \".pth\" in s]\npthes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 推論する関数を作成します。","metadata":{}},{"cell_type":"code","source":"def predicting(\n    test_dataloader,\n    model,\n    pthes\n    \n):\n\n    allpreds = []\n    \n    for pth in pthes:\n        \n        state = torch.load(pth)\n        \n        model.load_state_dict(state[\"state_dict\"])\n        model.to(device)\n        model.eval()\n    \n    \n        preds = []\n        allvalloss=0\n\n        with torch.no_grad():\n\n\n            for a in test_dataloader:\n\n\n\n                ids = a[\"ids\"].to(device)\n                mask = a[\"mask\"].to(device)\n                tokentype = a[\"token_type_ids\"].to(device)\n\n               # output = model(ids,mask,tokentype)\n                output = model(ids,mask)\n\n                output = output[\"logits\"].squeeze(-1)\n\n\n                preds.append(output.cpu().numpy())\n\n            preds = np.concatenate(preds)\n            \n            allpreds.append(preds)\n\n    return allpreds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allpreds = predicting(test_dataloader,model,pthes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5個のモデルの結果を平均します。","metadata":{}},{"cell_type":"code","source":"findf = pd.DataFrame(allpreds)\nfindf = findf.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"findf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finpred = findf.mean(axis=1)\nfinpred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample[\"target\"] = finpred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.to_csv(\"submission.csv\",index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ここまで見て頂き、ありがとうございます！\n\n# お役に立ちましたら、upvoteしていただけると嬉しいです。\n## また、各参考urlの方々には、たくさんのことを学びました。大変ありがとうございました！","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(途中でも紹介していますが) \n\n ### 以下のinference only bookにver 7の結果（これより少し良いスコア)をuploadしております。\n ### (ver8まではこのnotebookではtrainも入るため、submitに時間がかかりすぎてsubmit errorが起こっていました)\n\ninference onlyのnotebookはこちら　　https://www.kaggle.com/chumajin/inference-for-pytorch-bert-beginner-s-room?scriptVersionId=62477318\n\ninference onlyにするのは、submitが早いのと、internet onにしてしまった場合にsubmitできます。","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}