{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inference for Pytorch BERT beginner's room\n\n\n#### This page is the inference notebook on the following pages.\n * English\n     https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room\n \n \n \n * Japanese\n     https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room-version\n\n#### The model created by Random Seed 508 is uploaded to dataset.\n\n\n#### If you created it by Copy and edit, please add it to input and change the model path.","metadata":{}},{"cell_type":"markdown","source":"\n------------------日本語-------------------------------------------------------------------\n\n\n\n#### このページは以下のノートブックのinferenceのページです。\n * English\n     https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room\n \n \n \n * Japanese\n     https://www.kaggle.com/chumajin/pytorch-bert-beginner-s-room-version\n\n#### モデルは別途ランダムシード508で作成されたものをupしました。(コードは同じです)\n\n\n#### Copy and editされた方は、その結果をインプットから登録してmodel pathに入れてご使用ください","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n       \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \n\nimport transformers\nimport random\n\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nscaler = torch.cuda.amp.GradScaler() # GPUでの高速化。\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cpuがgpuかを自動判断\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0. Please enter the model path\n\n(Those created by Copy and edit may want to include their own output)\n\n## 0. modelパスに作成したモデルのフォルダパスを入れてください。\n\n\nCopy and editで作成された方は、ご自分の結果を入れるといいかもしれません)","metadata":{}},{"cell_type":"code","source":"result_path = \"../input/pytorchbiginnersroommodel-v2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 508\n\ndef random_seed(SEED):\n    \n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n\nrandom_seed(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ntest.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.Creating a Dataset (Since it is an inference, there is no target, so I omitted it)\n## If you have changed the max length with tokenizer, change it.","metadata":{}},{"cell_type":"markdown","source":"## 1.データセットの作成。インファレンスなので、targetは除去しています。\n### もし、tokenizerのmax lengthを変えている場合は、314というところを変えてください。","metadata":{}},{"cell_type":"code","source":"class BERTDataSet(Dataset):\n    \n    def __init__(self,sentences):\n        \n        self.sentences = sentences\n       \n        \n    def __len__(self):\n        \n        return len(self.sentences)\n    \n    def __getitem__(self,idx):\n        \n        sentence = self.sentences[idx]\n        sentence = str(sentence)\n        sentence = \" \".join(sentence.split())\n        \n        \n        bert_sens = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True, # [CLS],[SEP]\n                                max_length = 314,\n                                pad_to_max_length = True, # add padding to blank\n                                truncation=True)\n\n        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n     \n        \n    \n        \n        return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n                \n            }\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = BERTDataSet(test[\"excerpt\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. model load","metadata":{}},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained('../input/bert-base-uncased',num_labels=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pthes = [os.path.join(result_path,s) for s in os.listdir(result_path) if \".pth\" in s]\npthes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"states = [torch.load(s) for s in pthes]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. prediction function","metadata":{}},{"cell_type":"code","source":"def predicting(\n    test_dataloader,\n    model,\n    states\n    \n):\n\n    allpreds = []\n    \n    for state in states:\n        model.load_state_dict(state[\"state_dict\"])\n        model.to(device)\n        model.eval()\n    \n    \n        preds = []\n        allvalloss=0\n\n        with torch.no_grad():\n\n\n            for a in test_dataloader:\n\n\n\n                ids = a[\"ids\"].to(device)\n                mask = a[\"mask\"].to(device)\n                tokentype = a[\"token_type_ids\"].to(device)\n\n                output = model(ids,mask,tokentype)\n                output = output[\"logits\"].squeeze(-1)\n\n\n                preds.append(output.cpu().numpy())\n\n            preds = np.concatenate(preds)\n            \n            allpreds.append(preds)\n\n    return allpreds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allpreds = predicting(test_dataloader,model,states)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Avarage the 5 model and making submission.\n## 5個のモデルを平均化してサブミッションファイルを作成します。","metadata":{}},{"cell_type":"code","source":"findf = pd.DataFrame(allpreds)\nfindf = findf.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"findf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finpred = findf.mean(axis=1)\nfinpred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample[\"target\"] = finpred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.to_csv(\"submission.csv\",index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thank you so much !","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}