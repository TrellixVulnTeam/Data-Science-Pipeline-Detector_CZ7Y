{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, random, sys, time, re, copy\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data as D\nfrom torch.nn.utils.rnn import pad_sequence\n\n# K-Fold spliter\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Transformers library\nfrom transformers import *","metadata":{"_uuid":"597eea9d6295671bd36a809b579d12777738a392","execution":{"iopub.status.busy":"2021-05-31T12:10:10.752586Z","iopub.execute_input":"2021-05-31T12:10:10.753211Z","iopub.status.idle":"2021-05-31T12:10:13.955839Z","shell.execute_reply.started":"2021-05-31T12:10:10.753122Z","shell.execute_reply":"2021-05-31T12:10:13.954882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Path to train csv file\nDATA_PATH = \"../input/commonlitreadabilityprize/\"\n\n# Path to model weights and vocab (select desirable): \n\n# MODEL_PATH = '../input/distilbertbaseuncased'\n# MODEL_PATH = '../input/pretrained-albert-pytorch/albert-base-v1'\n# MODEL_PATH = '../input/pretrained-albert-pytorch/albert-xlarge-v1'\n# MODEL_PATH = '../input/camembertbasesquadfrfquadpiaf/camembert-base-squadFR-fquad-piaf'\n# MODEL_PATH = '../input/roberta-transformers-pytorch/distilroberta-base'\nMODEL_PATH = '../input/roberta-transformers-pytorch/roberta-base'\n# MODEL_PATH = '../input/roberta-transformers-pytorch/roberta-large'\n# MODEL_PATH = '../input/bart-models-hugging-face-model-repository/bart-base'\n# MODEL_PATH = '../input/electra-base'\n# MODEL_PATH = '../input/deberta/base'\n\nMODEL_NAME = 'optimus_prime'\n# VOCAB_PATH = '../input/roberta-transformers-pytorch/roberta-base' \nVOCAB_PATH = MODEL_PATH\n\nN_FOLDS = 5\nEPOCHES = 5\nBATCH_SIZE = 24\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nMAX_SEQUENCE_LENGTH = 320\nLR = 2e-5\n\n# error log\nsys.stderr = open('err.txt', 'w')","metadata":{"_uuid":"b7c04a817b5ba68498dc9b30638605da891ba6c4","execution":{"iopub.status.busy":"2021-05-31T12:10:13.961006Z","iopub.execute_input":"2021-05-31T12:10:13.961512Z","iopub.status.idle":"2021-05-31T12:10:13.991512Z","shell.execute_reply.started":"2021-05-31T12:10:13.96147Z","shell.execute_reply":"2021-05-31T12:10:13.990894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 7117\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"_uuid":"6ddd98901408dbe7c7fb9efdb0ec17cecd511864","execution":{"iopub.status.busy":"2021-05-31T12:10:13.992953Z","iopub.execute_input":"2021-05-31T12:10:13.993297Z","iopub.status.idle":"2021-05-31T12:10:14.009036Z","shell.execute_reply.started":"2021-05-31T12:10:13.993266Z","shell.execute_reply":"2021-05-31T12:10:14.00838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'), index_col='id')\ntest_csv = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'), index_col='id')\n\nsubm = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'), index_col='id')\n\n# https://www.kaggle.com/abhishek/step-1-create-folds\ndf_size = train_csv.shape[0]\nnum_bins = int(np.floor(1 + np.log2(df_size)))\n# bin targets\ny = pd.cut(train_csv[\"target\"], bins=num_bins, labels=False)\n\ncv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T12:10:14.010243Z","iopub.execute_input":"2021-05-31T12:10:14.010613Z","iopub.status.idle":"2021-05-31T12:10:14.060498Z","shell.execute_reply.started":"2021-05-31T12:10:14.010575Z","shell.execute_reply":"2021-05-31T12:10:14.059925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(VOCAB_PATH,\n                   model_max_length=MAX_SEQUENCE_LENGTH)\ntrain_csv['token'] = train_csv.excerpt.apply(tokenizer)\ntest_csv['token'] = test_csv.excerpt.apply(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T12:10:14.061703Z","iopub.execute_input":"2021-05-31T12:10:14.062068Z","iopub.status.idle":"2021-05-31T12:10:16.233082Z","shell.execute_reply.started":"2021-05-31T12:10:14.062031Z","shell.execute_reply":"2021-05-31T12:10:16.232036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitDataset(D.Dataset):\n    \n    def __init__(self, token, target):\n        self.token = token\n        self.target = target\n        \n    def __len__(self):\n        return self.token.shape[0]\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.token[idx].input_ids), \\\n                torch.tensor(self.token[idx].attention_mask), self.target[idx]\n    \ndef collate_fn(batch):\n    ids, attns, targets = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id).to(DEVICE)\n    attns = pad_sequence(attns, batch_first=True, padding_value=tokenizer.pad_token_id).to(DEVICE)\n    targets = torch.tensor(targets).float().to(DEVICE)\n    return ids, attns, targets\n\ndef collate_fn_test(batch):\n    ids, attns, idxs = zip(*batch)\n    ids = pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id).to(DEVICE)\n    attns = pad_sequence(attns, batch_first=True, padding_value=tokenizer.pad_token_id).to(DEVICE)\n    return idxs, ids, attns","metadata":{"_uuid":"92ea577a18faedfdccf5198d626c5c27861133ee","execution":{"iopub.status.busy":"2021-05-31T12:10:16.237351Z","iopub.execute_input":"2021-05-31T12:10:16.237867Z","iopub.status.idle":"2021-05-31T12:10:16.253209Z","shell.execute_reply.started":"2021-05-31T12:10:16.237819Z","shell.execute_reply":"2021-05-31T12:10:16.252573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = LitDataset(train_csv.token, train_csv.target)\ntest_ds = LitDataset(test_csv.token, test_csv.index)\n\ntloader = D.DataLoader(test_ds, batch_size=BATCH_SIZE,\n                       shuffle=False, collate_fn = collate_fn_test, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T12:10:16.256856Z","iopub.execute_input":"2021-05-31T12:10:16.257223Z","iopub.status.idle":"2021-05-31T12:10:16.268432Z","shell.execute_reply.started":"2021-05-31T12:10:16.257168Z","shell.execute_reply":"2021-05-31T12:10:16.267673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Table for results\nheader = r'''\n            Train         Validation\nEpoch |  MSE  |  RMSE |  MSE  |  RMSE | Time, m\n'''\n#          Epoch         metrics            time\nraw_line = '{:6d}' + '\\u2502{:7.3f}'*4 + '\\u2502{:6.2f}'","metadata":{"execution":{"iopub.status.busy":"2021-05-31T12:10:16.274224Z","iopub.execute_input":"2021-05-31T12:10:16.274552Z","iopub.status.idle":"2021-05-31T12:10:16.282648Z","shell.execute_reply.started":"2021-05-31T12:10:16.274519Z","shell.execute_reply":"2021-05-31T12:10:16.281627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef validation_fn(model, loader, loss_fn):\n    tloss = []\n    model.eval();\n    for texts, attns, target in loader:\n        outputs = model(texts, attention_mask=attns)\n        loss = loss_fn(outputs.logits.squeeze(-1), target)\n        tloss.append(loss.item())\n    tloss = np.array(tloss).mean()\n    return tloss\n\ndef oof_train(ds, cv, y, epochs = EPOCHES):\n    \n    loss_fn = torch.nn.MSELoss()\n    \n    for fold, (train_idx, valid_idx) in enumerate(cv.split(range(len(ds)), y)):\n        \n        train_ds = D.Subset(ds, train_idx)\n        loader = D.DataLoader(train_ds, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn = collate_fn,num_workers=0)\n        \n        valid_ds = D.Subset(ds, valid_idx)\n        vloader = D.DataLoader(valid_ds, batch_size=BATCH_SIZE,\n                      shuffle=False, collate_fn = collate_fn,num_workers=0)\n        \n        model = AutoModelForSequenceClassification.from_pretrained( \n                          MODEL_PATH, num_labels=1).to(DEVICE);\n        \n        optimizer = optim.AdamW(model.parameters(), LR,\n                                betas=(0.9, 0.999), weight_decay=1e-1)\n        scheduler = get_constant_schedule_with_warmup(optimizer, 35)\n        print(header)\n        \n        # init state\n        best_metric = np.inf\n        best_model = model.state_dict()\n        \n        for epoch in range(1, epochs+1):      \n            start_time = time.time()\n            tloss = []          \n            model.train()\n            \n            for texts, attns, target in loader:\n                optimizer.zero_grad()\n                outputs = model(texts, attention_mask=attns)\n                loss = loss_fn(outputs.logits.squeeze(-1), target)\n                tloss.append(loss.item())\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n            tloss = np.array(tloss).mean()\n            vloss = validation_fn(model, vloader, loss_fn)\n            tmetric = tloss**.5\n            vmetric = vloss**.5\n            print(raw_line.format(epoch,tloss,tmetric,vloss,vmetric,(time.time()-start_time)/60**1))\n            del loss, outputs\n            \n            if best_metric > vmetric:\n                with torch.no_grad():\n                    best_metric = vmetric\n                    best_model = copy.deepcopy(model.state_dict())\n            \n        # Save final state to the checkpoint\n        filename = f'{MODEL_NAME}_fold_{fold:02}.pt'\n        checkpoint = {\n            'model' : model.state_dict(),\n            'best_model' : best_model,\n            'best_metric' : best_metric,\n        }\n        torch.save(checkpoint,  filename)\n    \n        del model, vloader, loader, train_ds, valid_ds\n        torch.cuda.empty_cache()","metadata":{"_uuid":"e566ecdb5f44cf32af12127f073021566d6e66dd","execution":{"iopub.status.busy":"2021-05-31T12:10:16.286613Z","iopub.execute_input":"2021-05-31T12:10:16.286958Z","iopub.status.idle":"2021-05-31T12:10:16.318335Z","shell.execute_reply.started":"2021-05-31T12:10:16.286924Z","shell.execute_reply":"2021-05-31T12:10:16.317602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_train(ds, cv, y, epochs = EPOCHES)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T12:10:16.321744Z","iopub.execute_input":"2021-05-31T12:10:16.322089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained( \n                  MODEL_PATH, num_labels=1).to(DEVICE);\n\nfor fold in range(N_FOLDS):\n    \n    filename = f'{MODEL_NAME}_fold_{fold:02}.pt'\n    weights = torch.load(filename)['model']\n    model.load_state_dict(weights);\n    model.eval();\n    del weights\n    # Get prediction for test set\n    ids, preds = [], [] \n    with torch.no_grad():\n        for batch_ids, texts, attn in tloader:\n            outputs = model(texts, attention_mask=attn)\n            ids += batch_ids\n            preds.append(outputs.logits.detach().squeeze(-1).cpu().numpy())\n\n    # Save prediction of test set\n    preds = np.concatenate(preds)\n    subm.loc[ids, 'target']  =  subm.loc[ids, 'target'].values + preds / N_FOLDS\n\n# Save to the file\nsubm.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean saves\n!rm -r *.pt\n!rm err.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}