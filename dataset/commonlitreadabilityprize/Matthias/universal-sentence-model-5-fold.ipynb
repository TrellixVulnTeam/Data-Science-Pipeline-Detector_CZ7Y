{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/tensorflow-text243/tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:30:10.462157Z","iopub.execute_input":"2021-07-31T18:30:10.462556Z","iopub.status.idle":"2021-07-31T18:30:38.432516Z","shell.execute_reply.started":"2021-07-31T18:30:10.462472Z","shell.execute_reply":"2021-07-31T18:30:38.431532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nimport tensorflow_text as text\nimport matplotlib.pyplot as plt\nimport gc\ngc.enable()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-31T18:30:38.434102Z","iopub.execute_input":"2021-07-31T18:30:38.434418Z","iopub.status.idle":"2021-07-31T18:30:43.853672Z","shell.execute_reply.started":"2021-07-31T18:30:38.434378Z","shell.execute_reply":"2021-07-31T18:30:43.852832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:30:43.855283Z","iopub.execute_input":"2021-07-31T18:30:43.855598Z","iopub.status.idle":"2021-07-31T18:30:43.964112Z","shell.execute_reply.started":"2021-07-31T18:30:43.855571Z","shell.execute_reply":"2021-07-31T18:30:43.963283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, InputLayer, Bidirectional,Dropout\nfrom keras.optimizers import Adam\n\ndef UniversalSentenceModel():\n    embedding = \"../input/universal-sentence-embedding\"\n    embedding_model = hub.KerasLayer(embedding, input_shape=[], \n                           dtype=tf.string, trainable=True)\n    model = tf.keras.Sequential()\n    model.add(embedding_model)\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(256, activation='tanh'))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(128, activation='tanh'))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(1, name=\"predictions\"))\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:30:43.965784Z","iopub.execute_input":"2021-07-31T18:30:43.966149Z","iopub.status.idle":"2021-07-31T18:30:44.021318Z","shell.execute_reply.started":"2021-07-31T18:30:43.966111Z","shell.execute_reply":"2021-07-31T18:30:44.020513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nimport tensorflow_addons as tfa\n\n\n\n\n\ndef root_mean_squared_error(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\ndef get_optimizer(model):\n    s1 = tf.keras.optimizers.schedules.PiecewiseConstantDecay([750,1500], [1e-4,5e-5,1e-5])\n\n    s2 = tf.keras.optimizers.schedules.PiecewiseConstantDecay([750,1500], [1e-3,5e-4,1e-3])\n    DISC_LR = [s1, s2]\n    optimizers = [tf.keras.optimizers.Adam(learning_rate=DISC_LR[0]),\n                  tf.keras.optimizers.Adam(learning_rate=DISC_LR[1])\n                  ]\n    optimizers_and_layers = [(optimizers[0], model.layers[0]), (optimizers[1], model.layers[1:])] \n    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n    return optimizer","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:30:44.022697Z","iopub.execute_input":"2021-07-31T18:30:44.023051Z","iopub.status.idle":"2021-07-31T18:30:44.291095Z","shell.execute_reply.started":"2021-07-31T18:30:44.023015Z","shell.execute_reply":"2021-07-31T18:30:44.290248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import KFold\n\n\n\nNUM_FOLDS=5\nkfold = KFold(n_splits=NUM_FOLDS, random_state=1, shuffle=True)\n\nfor fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)): \n\n    \n    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n    model_path = f\"model_{fold + 1}.pth\"\n    X_train = train_df.loc[train_indices].excerpt.to_list()\n    X_test = train_df.loc[val_indices].excerpt.to_list()\n    y_train = train_df.loc[train_indices].target.values\n    y_test = train_df.loc[val_indices].target.values\n\n\n    train_ds = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n    train_ds = train_ds.shuffle(1024)\n    train_ds = train_ds.batch(32)\n\n    val_ds = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n    val_ds = val_ds.batch(32)\n    model = UniversalSentenceModel()\n    optimizer = get_optimizer(model)\n    model.compile(optimizer = optimizer,\n                    loss = tf.keras.losses.LogCosh(),\n                    metrics = [root_mean_squared_error]\n                    )\n    \n    checkpoint = ModelCheckpoint(\n        f\"model_{fold}.h5\", monitor='val_loss', mode='min',\n         save_best_only=True, save_weights_only=True)\n\n\n    model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=checkpoint)\n    del model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:30:44.292374Z","iopub.execute_input":"2021-07-31T18:30:44.292726Z","iopub.status.idle":"2021-07-31T18:41:37.810043Z","shell.execute_reply.started":"2021-07-31T18:30:44.29269Z","shell.execute_reply":"2021-07-31T18:41:37.809173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ntest_text = test[\"excerpt\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:41:37.818895Z","iopub.execute_input":"2021-07-31T18:41:37.819163Z","iopub.status.idle":"2021-07-31T18:41:37.832756Z","shell.execute_reply.started":"2021-07-31T18:41:37.819137Z","shell.execute_reply":"2021-07-31T18:41:37.831917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions = np.zeros((NUM_FOLDS, len(test)))\nmodel = UniversalSentenceModel()\nfor index in range(NUM_FOLDS):            \n    model_path = f\"model_{index}.h5\"\n    print(f\"\\nUsing {model_path}\")\n                        \n    model = UniversalSentenceModel()\n    model.load_weights(model_path)\n    \n    all_predictions[index] = model.predict(test_text).flatten()\n    \n    del model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:43:33.30112Z","iopub.execute_input":"2021-07-31T18:43:33.301491Z","iopub.status.idle":"2021-07-31T18:46:56.45251Z","shell.execute_reply.started":"2021-07-31T18:43:33.301457Z","shell.execute_reply":"2021-07-31T18:46:56.451611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = all_predictions.mean(axis=0)\nsubmission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission_df.target = predictions\nprint(submission_df)\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T18:48:43.489169Z","iopub.execute_input":"2021-07-31T18:48:43.489524Z","iopub.status.idle":"2021-07-31T18:48:43.77157Z","shell.execute_reply.started":"2021-07-31T18:48:43.489493Z","shell.execute_reply":"2021-07-31T18:48:43.770721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}