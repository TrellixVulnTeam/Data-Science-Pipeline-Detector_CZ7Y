{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import AutoConfig\nfrom transformers import get_constant_schedule\n\nimport gc\ngc.enable()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-07T18:47:02.039018Z","iopub.execute_input":"2021-12-07T18:47:02.039335Z","iopub.status.idle":"2021-12-07T18:47:08.120709Z","shell.execute_reply.started":"2021-12-07T18:47:02.039246Z","shell.execute_reply":"2021-12-07T18:47:08.11979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 5\nBATCH_SIZE = 16\nMAX_LEN = 256\nEVAL_SCHEDULE = [(0.50, 16), (0.48, 8), (0.465, 2), (-1., 1)]\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMODEL_PATH = \"../input/robertapretrained30/roberta-base-pretrained\"\nTOKENIZER_PATH = \"../input/robertapretrained30/roberta-base-pretrained\"","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.122308Z","iopub.execute_input":"2021-12-07T18:47:08.122654Z","iopub.status.idle":"2021-12-07T18:47:08.171546Z","shell.execute_reply.started":"2021-12-07T18:47:08.122616Z","shell.execute_reply":"2021-12-07T18:47:08.170322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_random_seed(random_seed):\n    \"\"\"set random seed for all necessary places\"\"\"\n    \n    random.seed(random_seed)\n    np.random.seed(random_seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n\n    torch.manual_seed(random_seed)\n    torch.cuda.manual_seed(random_seed)\n    torch.cuda.manual_seed_all(random_seed)\n\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.174417Z","iopub.execute_input":"2021-12-07T18:47:08.175016Z","iopub.status.idle":"2021-12-07T18:47:08.181973Z","shell.execute_reply.started":"2021-12-07T18:47:08.174973Z","shell.execute_reply":"2021-12-07T18:47:08.180916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\nsubmission_df = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.184357Z","iopub.execute_input":"2021-12-07T18:47:08.184861Z","iopub.status.idle":"2021-12-07T18:47:08.283618Z","shell.execute_reply.started":"2021-12-07T18:47:08.184819Z","shell.execute_reply":"2021-12-07T18:47:08.282539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitDataset(Dataset):\n    \"\"\"Implementation of the pytorch Dataset class for this Readability dataset and Bert-based models output\"\"\"\n    \n    def __init__(self, df, tokenizer, inference_only=False):\n        super().__init__()\n\n        self.df = df        \n        self.inference_only = inference_only\n        self.text = df.excerpt.tolist()\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n    \n        self.encoded = tokenizer.batch_encode_plus(\n            self.text,\n            padding = 'max_length',            \n            max_length = MAX_LEN,\n            truncation = True,\n            return_attention_mask=True\n        )        \n \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):        \n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return (input_ids, attention_mask)            \n        else:\n            target = self.target[index]\n            return (input_ids, attention_mask, target)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.287126Z","iopub.execute_input":"2021-12-07T18:47:08.287635Z","iopub.status.idle":"2021-12-07T18:47:08.298224Z","shell.execute_reply.started":"2021-12-07T18:47:08.287597Z","shell.execute_reply":"2021-12-07T18:47:08.29739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitModel(nn.Module):\n    \"\"\"Custom model that will use the pretrained roberta model, set config parameters and add necessary layers on top\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(MODEL_PATH)\n        config.update({\"output_hidden_states\":True})        \n        \n        self.roberta = AutoModel.from_pretrained(MODEL_PATH, config=config)  \n\n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(768, 1)                        \n        )\n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n        weights = self.attention(last_layer_hidden_states)\n        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n        # context_vector.shape is BATCH_SIZE x 768\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)\n        return self.regressor(context_vector)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.299743Z","iopub.execute_input":"2021-12-07T18:47:08.300423Z","iopub.status.idle":"2021-12-07T18:47:08.327291Z","shell.execute_reply.started":"2021-12-07T18:47:08.300379Z","shell.execute_reply":"2021-12-07T18:47:08.322741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_mse(model, data_loader):\n    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n    \n    model.eval()            \n    mse_sum = 0\n\n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)                        \n            target = target.to(DEVICE)           \n            \n            pred = model(input_ids, attention_mask)                       \n\n            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n                \n    return mse_sum / len(data_loader.dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.333137Z","iopub.execute_input":"2021-12-07T18:47:08.333678Z","iopub.status.idle":"2021-12-07T18:47:08.352633Z","shell.execute_reply.started":"2021-12-07T18:47:08.333642Z","shell.execute_reply":"2021-12-07T18:47:08.350801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n    \n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    \n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n                        \n            pred = model(input_ids, attention_mask)                        \n\n            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n            index += pred.shape[0]\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.357526Z","iopub.execute_input":"2021-12-07T18:47:08.357873Z","iopub.status.idle":"2021-12-07T18:47:08.37249Z","shell.execute_reply.started":"2021-12-07T18:47:08.357839Z","shell.execute_reply":"2021-12-07T18:47:08.371634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader,\n          optimizer, model_path, scheduler=None, num_epochs=NUM_EPOCHS):     \n    \"\"\"Training algorithm that takes batches, creates input data, applies the model, gets the loss and then does the backpropagation\"\"\"\n    \n    best_val_rmse = None\n    best_epoch = 0\n    step = 0\n    last_eval_step = 0\n    eval_period = EVAL_SCHEDULE[0][1]\n    \n    for epoch in range(num_epochs):              \n \n        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)   \n            target = target.to(DEVICE)                        \n \n            optimizer.zero_grad()\n            \n            model.train()\n            pred = model(input_ids, attention_mask)                               \n            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n            mse.backward()\n \n            optimizer.step()\n            if scheduler:\n                scheduler.step()\n            # selective evaluation part\n            if step >= last_eval_step + eval_period:\n                last_eval_step = step\n                \n                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n \n                print(f\"Epoch: {epoch} batch_num: {batch_num} train_rmse: {mse:0.4}\", \n                      f\"val_rmse: {val_rmse:0.4}\")\n \n                for rmse, period in EVAL_SCHEDULE:\n                    if val_rmse >= rmse:\n                        eval_period = period\n                        break                               \n                \n                if not best_val_rmse or val_rmse < best_val_rmse:                    \n                    best_val_rmse = val_rmse\n                    best_epoch = epoch\n                    torch.save(model.state_dict(), model_path)\n                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n                else:       \n                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n                          f\"(from epoch {best_epoch})\") \n                    \n            step += 1\n    return val_rmse, best_val_rmse","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.374138Z","iopub.execute_input":"2021-12-07T18:47:08.374656Z","iopub.status.idle":"2021-12-07T18:47:08.408546Z","shell.execute_reply.started":"2021-12-07T18:47:08.374618Z","shell.execute_reply":"2021-12-07T18:47:08.405152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_optimizer(model):\n    \"\"\"Sets learning rate and returns the learnable layers of the model with the optimizer applied\"\"\"\n    \n    named_parameters = list(model.named_parameters())    \n    parameters = []\n \n    for layer_num, (name, params) in enumerate(named_parameters):\n        weight_decay = 0.0 if \"bias\" in name else 0.01\n        lr = 2e-5\n \n        if layer_num >= 69:        \n            lr = 5e-5\n \n        if layer_num >= 133:\n            lr = 1e-4\n            \n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr})\n    return AdamW(parameters)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.409905Z","iopub.execute_input":"2021-12-07T18:47:08.410454Z","iopub.status.idle":"2021-12-07T18:47:08.420592Z","shell.execute_reply.started":"2021-12-07T18:47:08.410416Z","shell.execute_reply":"2021-12-07T18:47:08.416226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_cosine_schedule_with_warmup\nfrom sklearn import model_selection\n\ngc.collect()\n \nSEED = 1666\n\nset_random_seed(SEED)\n\ntokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n\nlist_val_rmse = []\nlist_best_val_rmse = []\nnum_splits = 5\n\n\ntrain_df[\"kfold\"] = -1\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\nnum_bins = int(np.floor(1 + np.log2(len(train_df))))\ntrain_df.loc[:, \"bins\"] = pd.cut(\n    train_df[\"target\"], bins=num_bins, labels=False\n)\n \nkf = model_selection.StratifiedKFold(n_splits=num_splits)\nfor fold, (train_indices, val_indices) in enumerate(kf.split(X=train_df, y=train_df.bins.values)):\n    model_path = f\"model_{fold+1}.pth\"\n    print(\"FOLD\",fold+1)\n    set_random_seed(SEED)\n\n\n    train_dataset = LitDataset(train_df.loc[train_indices], tokenizer)\n    val_dataset = LitDataset(train_df.loc[val_indices], tokenizer)  \n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              drop_last=True, shuffle=True, num_workers=2) \n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                            drop_last=False, shuffle=False, num_workers=2)     \n\n    model = LitModel().to(DEVICE)\n\n    optimizer = create_optimizer(model)                        \n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_training_steps=NUM_EPOCHS * len(train_loader),\n        num_warmup_steps=30)                       \n\n    val_rmse, best_val_rmse = train(model, train_loader, val_loader, optimizer, model_path, scheduler=scheduler)\n\n    del model\n    gc.collect()\n    \n    list_val_rmse.append(val_rmse)\n    list_best_val_rmse.append(best_val_rmse)\n    print(\"\\nPerformance estimates:\")\n    print(list_val_rmse)\n    print(\"Mean:\", np.array(list_val_rmse).mean())   \n    print(list_best_val_rmse)\n    print(\"Best Mean:\", np.array(list_best_val_rmse).mean())          ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:47:08.422281Z","iopub.execute_input":"2021-12-07T18:47:08.422698Z","iopub.status.idle":"2021-12-07T18:49:43.9068Z","shell.execute_reply.started":"2021-12-07T18:47:08.422662Z","shell.execute_reply":"2021-12-07T18:49:43.90527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions = []\n\ntest_dataset = LitDataset(test_df, tokenizer, inference_only=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                          drop_last=False, shuffle=False, num_workers=2)   \n    \nfor fold in range(5):                  \n    model = LitModel()\n    model.load_state_dict(torch.load(f\"model_{fold+1}.pth\"))    \n    model.to(DEVICE)\n\n    all_predictions.append(predict(model, test_loader))\n    \n    del model\n    gc.collect()    \n    \npredictions = np.array(all_predictions).mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:49:43.908093Z","iopub.status.idle":"2021-12-07T18:49:43.908841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.target = predictions\nprint(submission_df)\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T11:16:36.530464Z","iopub.status.idle":"2021-08-17T11:16:36.531162Z"},"trusted":true},"execution_count":null,"outputs":[]}]}