{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/textstat/Pyphen-0.10.0-py3-none-any.whl\n!pip install ../input/textstat/textstat-0.7.0-py3-none-any.whl\nimport textstat","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-30T11:36:37.67161Z","iopub.execute_input":"2021-09-30T11:36:37.671919Z","iopub.status.idle":"2021-09-30T11:37:30.404185Z","shell.execute_reply.started":"2021-09-30T11:36:37.671855Z","shell.execute_reply":"2021-09-30T11:37:30.403196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport textstat\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:30.405881Z","iopub.execute_input":"2021-09-30T11:37:30.406235Z","iopub.status.idle":"2021-09-30T11:37:32.961091Z","shell.execute_reply.started":"2021-09-30T11:37:30.406189Z","shell.execute_reply":"2021-09-30T11:37:32.960221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:32.962719Z","iopub.execute_input":"2021-09-30T11:37:32.963094Z","iopub.status.idle":"2021-09-30T11:37:33.057665Z","shell.execute_reply.started":"2021-09-30T11:37:32.963056Z","shell.execute_reply":"2021-09-30T11:37:33.05682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:33.061008Z","iopub.execute_input":"2021-09-30T11:37:33.061272Z","iopub.status.idle":"2021-09-30T11:37:34.201342Z","shell.execute_reply.started":"2021-09-30T11:37:33.061246Z","shell.execute_reply":"2021-09-30T11:37:34.200451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_words(text):\n    text = textstat.remove_punctuation(text)\n    return text.split()\ndef long_words(text):\n    count = 0\n    for w in get_words(text):\n        if len(w)>6:\n            count += 1\n    return count\ndef difficult_words(text):\n    count = 0\n    for w in get_words(text):\n        if textstat.is_difficult_word(w):\n            count += 1\n    return count\ndef get_pronouns(text, doc):\n    pronouns = []\n    for sent in doc.sents:\n        count = 0\n        for token in sent:\n            if token.pos_ == \"PRON\":\n                count += 1\n        pronouns.append(count)\n    return np.mean(pronouns)\ndef get_lexical_diversity(text):\n    words = get_words(text)\n    unique_words = []\n    for w in words:\n        if w not in unique_words:\n              unique_words.append(w)\n    if len(unique_words)>0 and len(words)>0:\n        return len(unique_words)/len(words)\n    return 0\ndef content_diversity(text, doc):\n    words = get_words(text)\n    content_words = 0\n    for token in doc:\n        if token.pos_ == \"VERB\" or token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\" or token.pos_ == \"ADV\":\n            content_words += 1\n    if content_words>0 and len(words)>0:\n        return content_words/len(words)\n    return 0\ndef word_incidence(text, pos, doc):\n    words = get_words(text)\n    nr = 0\n    for token in doc:\n        if token.pos_ == pos:\n            nr += 1\n    if nr>0 and len(words)>0:\n        return nr/(len(words)/1000)\n    return 0","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:53.057078Z","iopub.execute_input":"2021-09-30T11:37:53.057413Z","iopub.status.idle":"2021-09-30T11:37:53.06843Z","shell.execute_reply.started":"2021-09-30T11:37:53.057377Z","shell.execute_reply":"2021-09-30T11:37:53.067631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_df_features(df):\n    df['flesch_reading_ease'] = -1\n    df['smog_index'] = -1\n    df['flesch_kincaid_grade'] = -1\n    df['coleman_liau_index'] = -1\n    df['automated_readability_index'] = -1\n    df['dale_chall_readability_score'] = -1\n    df['textstat_difficult_words'] = -1\n    df['linsear_write_formula'] = -1\n    df['gunning_fog'] = -1\n    df['text_standard'] = -1\n    df['avg_character_per_word'] = -1\n    df['avg_letter_per_word'] = -1\n    df['avg_sentence_length'] = -1\n    df['avg_sentence_per_word'] = -1\n    df['avg_syllables_per_word'] = -1\n    df['rix'] = -1\n    df['lix'] = -1\n    df['lexicon_count'] = -1\n    df['long_words'] = -1\n    df['difficult_words'] = -1\n    df['get_pronouns'] = -1\n    df['get_lexical_diversity'] = -1\n    df['content_diversity'] = -1\n    df['word_incidence_adj'] = -1\n    df['word_incidence_adv'] = -1\n    df['word_incidence_noun'] = -1\n    df['word_incidence_pron'] = -1\n    df['word_incidence_verb'] = -1\n    for idx, row in df.iterrows():\n        df.loc[idx, 'flesch_reading_ease'] = textstat.flesch_reading_ease(row['excerpt'])\n        df.loc[idx, 'smog_index'] = textstat.smog_index(row['excerpt'])\n        df.loc[idx, 'flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(row['excerpt'])\n        df.loc[idx, 'coleman_liau_index'] = textstat.coleman_liau_index(row['excerpt'])\n        df.loc[idx, 'automated_readability_index'] = textstat.automated_readability_index(row['excerpt'])\n        df.loc[idx, 'dale_chall_readability_score'] = textstat.dale_chall_readability_score(row['excerpt'])\n        df.loc[idx, 'textstat_difficult_words'] = textstat.difficult_words(row['excerpt'])\n        df.loc[idx, 'linsear_write_formula'] = textstat.linsear_write_formula(row['excerpt'])\n        df.loc[idx, 'gunning_fog'] = textstat.gunning_fog(row['excerpt'])\n        df.loc[idx, 'text_standard'] = textstat.text_standard(row['excerpt'], float_output=True)\n        df.loc[idx, 'avg_character_per_word'] = textstat.avg_character_per_word(row['excerpt'])\n        df.loc[idx, 'avg_letter_per_word'] = textstat.avg_letter_per_word(row['excerpt'])\n        df.loc[idx, 'avg_sentence_length'] = textstat.avg_sentence_length(row['excerpt'])\n        df.loc[idx, 'avg_sentence_per_word'] = textstat.avg_sentence_per_word(row['excerpt'])\n        df.loc[idx, 'avg_syllables_per_word'] = textstat.avg_syllables_per_word(row['excerpt'])\n        df.loc[idx, 'rix'] = textstat.rix(row['excerpt'])\n        df.loc[idx, 'lix'] = textstat.lix(row['excerpt'])\n        df.loc[idx, 'lexicon_count'] = textstat.lexicon_count(row['excerpt'])\n        df.loc[idx, 'long_words'] = long_words(row['excerpt'])\n        df.loc[idx, 'difficult_words'] = difficult_words(row['excerpt'])\n        doc = nlp(row['excerpt'])\n        df.loc[idx, 'get_pronouns'] = get_pronouns(row['excerpt'], doc)\n        df.loc[idx, 'get_lexical_diversity'] = get_lexical_diversity(row['excerpt'])\n        df.loc[idx, 'content_diversity'] = content_diversity(row['excerpt'], doc)\n        df.loc[idx, 'word_incidence_adj'] = word_incidence(row['excerpt'], 'ADJ', doc)\n        df.loc[idx, 'word_incidence_adv'] = word_incidence(row['excerpt'], 'ADV', doc)\n        df.loc[idx, 'word_incidence_noun'] = word_incidence(row['excerpt'], 'NOUN', doc)\n        df.loc[idx, 'word_incidence_pron'] = word_incidence(row['excerpt'], 'PRON', doc)\n        df.loc[idx, 'word_incidence_verb'] = word_incidence(row['excerpt'], 'VERB', doc)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:53.667357Z","iopub.execute_input":"2021-09-30T11:37:53.667721Z","iopub.status.idle":"2021-09-30T11:37:53.687294Z","shell.execute_reply.started":"2021-09-30T11:37:53.667688Z","shell.execute_reply":"2021-09-30T11:37:53.68612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_df_features(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:54.371814Z","iopub.execute_input":"2021-09-30T11:37:54.372154Z","iopub.status.idle":"2021-09-30T11:37:57.438866Z","shell.execute_reply.started":"2021-09-30T11:37:54.372121Z","shell.execute_reply":"2021-09-30T11:37:57.437976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_df_features(train)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:57.964189Z","iopub.execute_input":"2021-09-30T11:37:57.964533Z","iopub.status.idle":"2021-09-30T11:58:13.407675Z","shell.execute_reply.started":"2021-09-30T11:37:57.964493Z","shell.execute_reply":"2021-09-30T11:58:13.406768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = []\ntrain_label = []\nfor idx, row in train.iterrows():\n    train_set.append([\n        row['flesch_reading_ease'], row['smog_index'], row['flesch_kincaid_grade'], row['coleman_liau_index'],\n        row['automated_readability_index'], row['dale_chall_readability_score'], row['textstat_difficult_words'], row['linsear_write_formula'],\n        row['gunning_fog'], row['text_standard'], row['avg_character_per_word'], row['avg_letter_per_word'],\n        row['avg_sentence_length'], row['avg_sentence_per_word'], row['avg_syllables_per_word'], row['rix'],\n        row['lix'], row['lexicon_count'], row['long_words'], row['difficult_words'],\n        row['get_pronouns'], row['get_lexical_diversity'], row['content_diversity'], row['word_incidence_adj'],\n        row['word_incidence_adj'], row['word_incidence_adv'], row['word_incidence_noun'], row['word_incidence_pron'],\n        row['word_incidence_verb']\n    ])\n    train_label.append(row['target'])\ntest_set = []\nfor idx, row in test.iterrows():\n    test_set.append([\n        row['flesch_reading_ease'], row['smog_index'], row['flesch_kincaid_grade'], row['coleman_liau_index'],\n        row['automated_readability_index'], row['dale_chall_readability_score'], row['textstat_difficult_words'], row['linsear_write_formula'],\n        row['gunning_fog'], row['text_standard'], row['avg_character_per_word'], row['avg_letter_per_word'],\n        row['avg_sentence_length'], row['avg_sentence_per_word'], row['avg_syllables_per_word'], row['rix'],\n        row['lix'], row['lexicon_count'], row['long_words'], row['difficult_words'],\n        row['get_pronouns'], row['get_lexical_diversity'], row['content_diversity'], row['word_incidence_adj'],\n        row['word_incidence_adj'], row['word_incidence_adv'], row['word_incidence_noun'], row['word_incidence_pron'],\n        row['word_incidence_verb']\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:58:13.409117Z","iopub.execute_input":"2021-09-30T11:58:13.409463Z","iopub.status.idle":"2021-09-30T11:58:13.982641Z","shell.execute_reply.started":"2021-09-30T11:58:13.409429Z","shell.execute_reply":"2021-09-30T11:58:13.981765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = np.array(train_set, dtype=float)\ntrain_label = np.array(train_label)\ntest_set = np.array(test_set, dtype=float)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:58:13.98437Z","iopub.execute_input":"2021-09-30T11:58:13.984795Z","iopub.status.idle":"2021-09-30T11:58:14.005575Z","shell.execute_reply.started":"2021-09-30T11:58:13.98476Z","shell.execute_reply":"2021-09-30T11:58:14.004781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:58:14.007262Z","iopub.execute_input":"2021-09-30T11:58:14.007849Z","iopub.status.idle":"2021-09-30T11:58:18.19336Z","shell.execute_reply.started":"2021-09-30T11:58:14.007813Z","shell.execute_reply":"2021-09-30T11:58:18.192536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = tf.keras.layers.Input(shape=(29,), dtype=tf.float32)\ndense = tf.keras.layers.Dense(512, activation='relu')(input_text)\ndense2 = tf.keras.layers.Dense(128, activation='relu')(dense)\npred = tf.keras.layers.Dense(1, activation='linear')(dense2)\nmodel = tf.keras.models.Model(inputs=[input_text], outputs=pred)\nmodel.compile(loss='mse', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:58:18.194833Z","iopub.execute_input":"2021-09-30T11:58:18.195206Z","iopub.status.idle":"2021-09-30T11:58:20.135123Z","shell.execute_reply.started":"2021-09-30T11:58:18.19517Z","shell.execute_reply":"2021-09-30T11:58:20.134225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_set, \n          train_label,\n          epochs=80,\n          batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:04:53.404962Z","iopub.execute_input":"2021-06-30T11:04:53.405322Z","iopub.status.idle":"2021-06-30T11:05:38.675859Z","shell.execute_reply.started":"2021-06-30T11:04:53.40529Z","shell.execute_reply":"2021-06-30T11:05:38.674901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_set)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:05:54.448636Z","iopub.execute_input":"2021-06-30T11:05:54.449013Z","iopub.status.idle":"2021-06-30T11:05:54.585467Z","shell.execute_reply.started":"2021-06-30T11:05:54.448982Z","shell.execute_reply":"2021-06-30T11:05:54.584514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nresults = []\nfor idx, row in test.iterrows():\n    results.append({\n        \"id\": row['id'],\n        \"target\": predictions[i][0]\n    })\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:05:58.971172Z","iopub.execute_input":"2021-06-30T11:05:58.971538Z","iopub.status.idle":"2021-06-30T11:05:58.977684Z","shell.execute_reply.started":"2021-06-30T11:05:58.971508Z","shell.execute_reply":"2021-06-30T11:05:58.976938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df = pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:06:05.019091Z","iopub.execute_input":"2021-06-30T11:06:05.019443Z","iopub.status.idle":"2021-06-30T11:06:05.026209Z","shell.execute_reply.started":"2021-06-30T11:06:05.019413Z","shell.execute_reply":"2021-06-30T11:06:05.025199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:06:08.893429Z","iopub.execute_input":"2021-06-30T11:06:08.894119Z","iopub.status.idle":"2021-06-30T11:06:08.903805Z","shell.execute_reply.started":"2021-06-30T11:06:08.894071Z","shell.execute_reply":"2021-06-30T11:06:08.902631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}