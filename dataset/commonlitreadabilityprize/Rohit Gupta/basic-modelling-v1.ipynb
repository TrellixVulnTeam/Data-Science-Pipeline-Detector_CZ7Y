{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Some imports :)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nfrom tqdm.notebook import tqdm\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nfrom wordcloud import WordCloud\nfrom plotly.offline import iplot\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import Ridge, LinearRegression\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline, FeatureUnion\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nplt.style.use('classic')\nsns.set_palette(sns.color_palette('winter_r'))","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:44.139913Z","iopub.execute_input":"2021-07-01T05:50:44.140562Z","iopub.status.idle":"2021-07-01T05:50:48.029666Z","shell.execute_reply.started":"2021-07-01T05:50:44.140506Z","shell.execute_reply":"2021-07-01T05:50:48.028285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing data\ntraining_file = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest_file = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\nsubmission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:48.031502Z","iopub.execute_input":"2021-07-01T05:50:48.031866Z","iopub.status.idle":"2021-07-01T05:50:48.141229Z","shell.execute_reply.started":"2021-07-01T05:50:48.031828Z","shell.execute_reply":"2021-07-01T05:50:48.139715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:51.70281Z","iopub.execute_input":"2021-07-01T05:50:51.70317Z","iopub.status.idle":"2021-07-01T05:50:51.73297Z","shell.execute_reply.started":"2021-07-01T05:50:51.703139Z","shell.execute_reply":"2021-07-01T05:50:51.732195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data roughly\ndata = training_file[['excerpt', 'target']]\ndata = data.sample(frac=1).reset_index(drop=True)\nexcerpt, targets = training_file['excerpt'].values, training_file['target'].values\n\nt_X, v_X = excerpt[:2750], excerpt[2750:]\nt_Y, v_Y = targets[:2750], targets[2750:]\n\nprint(t_X.shape, v_X.shape)\nprint(t_Y.shape, v_Y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:53.49907Z","iopub.execute_input":"2021-07-01T05:50:53.499733Z","iopub.status.idle":"2021-07-01T05:50:53.514265Z","shell.execute_reply.started":"2021-07-01T05:50:53.499692Z","shell.execute_reply":"2021-07-01T05:50:53.512974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make an Sklearn pipeline for this Ridge Regression\nridge = Ridge(fit_intercept=True, normalize=False)\npipeline_ridge = make_pipeline(\n    TfidfVectorizer(binary=True, ngram_range=(1, 1)),\n    ridge\n)\n\n# Do training\npipeline_ridge.fit(t_X, t_Y)\n\n# Evaluate the performance on validation set\npreds = pipeline_ridge.predict(v_X)\nmse_loss = mean_squared_error(v_Y, preds)\n\nprint(f\"MSE Loss using Ridge and TfIdfVectorizer: {mse_loss}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:54.837817Z","iopub.execute_input":"2021-07-01T05:50:54.838222Z","iopub.status.idle":"2021-07-01T05:50:55.561636Z","shell.execute_reply.started":"2021-07-01T05:50:54.838187Z","shell.execute_reply":"2021-07-01T05:50:55.560464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make an Sklearn pipeline for this Linear Regression\nlinear = LinearRegression(fit_intercept=True, normalize=False)\npipeline_linear = make_pipeline(\n    TfidfVectorizer(binary=True, ngram_range=(1, 1)),\n    linear\n)\n\n# Do training\npipeline_linear.fit(t_X, t_Y)\n\n# Evaluate the performance on validation set\npreds = pipeline_linear.predict(v_X)\nmse_loss = mean_squared_error(v_Y, preds)\n\nprint(f\"MSE Loss using Linear Regression and TfIdfVectorizer: {mse_loss}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:55.563869Z","iopub.execute_input":"2021-07-01T05:50:55.564743Z","iopub.status.idle":"2021-07-01T05:50:56.485694Z","shell.execute_reply.started":"2021-07-01T05:50:55.564681Z","shell.execute_reply":"2021-07-01T05:50:56.484492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding Data Augmentation","metadata":{}},{"cell_type":"code","source":"negative = training_file[training_file[\"target\"] < 0]\npositive = training_file[training_file[\"target\"] >= 0]\nnegative.shape, positive.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:57.422075Z","iopub.execute_input":"2021-07-01T05:50:57.422534Z","iopub.status.idle":"2021-07-01T05:50:57.452345Z","shell.execute_reply.started":"2021-07-01T05:50:57.422488Z","shell.execute_reply":"2021-07-01T05:50:57.450996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(training_file.drop('target', axis=1), training_file.target, test_size=0.3, random_state=37)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:57.965719Z","iopub.execute_input":"2021-07-01T05:50:57.966092Z","iopub.status.idle":"2021-07-01T05:50:57.975169Z","shell.execute_reply.started":"2021-07-01T05:50:57.966055Z","shell.execute_reply":"2021-07-01T05:50:57.974347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/nlpaug0011/nlpaug-master #> /dev/null","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:50:58.53861Z","iopub.execute_input":"2021-07-01T05:50:58.539908Z","iopub.status.idle":"2021-07-01T05:51:29.897908Z","shell.execute_reply.started":"2021-07-01T05:50:58.539831Z","shell.execute_reply":"2021-07-01T05:51:29.896363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation using NLP Aug ","metadata":{}},{"cell_type":"code","source":"import nlpaug\nimport nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nimport nlpaug.augmenter.sentence as nas\nimport nlpaug.flow as naf\n\ntext = 'The quick brown fox jumps over the lazy dog .'\n\naug_w2v = naw.WordEmbsAug(\n    model_type='glove', model_path='../input/glove6b300dtxt/glove.6B.300d.txt',\n    action=\"substitute\")\nprint(\"Original:\")\nprint(text)\n\naug_w2v.aug_p=0.1\n\nprint(\"Augmented Text:\")\nfor ii in range(5):\n    augmented_text = aug_w2v.augment(text)\n    print(augmented_text)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:51:34.948251Z","iopub.execute_input":"2021-07-01T05:51:34.948631Z","iopub.status.idle":"2021-07-01T05:52:39.587408Z","shell.execute_reply.started":"2021-07-01T05:51:34.948592Z","shell.execute_reply":"2021-07-01T05:52:39.585778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmenting 1500 positive samples","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndef augment_text(df,samples=1500,pr=0.2):\n    aug_w2v.aug_p=pr\n    new_text=[]\n    \n    ##selecting the minority class samples\n    df_n=df[df.target >= 0].reset_index(drop=True)\n\n    ## data augmentation loop\n    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n        \n            text = df_n.iloc[i]['excerpt']\n            augmented_text = aug_w2v.augment(text)\n            new_text.append(augmented_text)\n    \n    \n    ## dataframe\n    new=pd.DataFrame({'excerpt':new_text,'target':0.3})\n    df=shuffle(df.append(new).reset_index(drop=True))\n    return df\n   \ntrain_aug_15 = augment_text(training_file)\ntrain_aug_15.shape\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-01T05:53:06.166394Z","iopub.execute_input":"2021-07-01T05:53:06.167205Z","iopub.status.idle":"2021-07-01T06:12:01.845032Z","shell.execute_reply.started":"2021-07-01T05:53:06.167156Z","shell.execute_reply":"2021-07-01T06:12:01.843853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_aug_15.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-01T06:12:41.706333Z","iopub.execute_input":"2021-07-01T06:12:41.706846Z","iopub.status.idle":"2021-07-01T06:12:41.714158Z","shell.execute_reply.started":"2021-07-01T06:12:41.706809Z","shell.execute_reply":"2021-07-01T06:12:41.712808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data roughly\ndata = train_aug_15[['excerpt', 'target']]\ndata = data.sample(frac=1).reset_index(drop=True)\nexcerpt, targets = train_aug_15['excerpt'].values, train_aug_15['target'].values\n\nt_X, v_X = excerpt[:2750], excerpt[2750:]\nt_Y, v_Y = targets[:2750], targets[2750:]\n\nprint(t_X.shape, v_X.shape)\nprint(t_Y.shape, v_Y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T07:15:49.151641Z","iopub.execute_input":"2021-07-01T07:15:49.152052Z","iopub.status.idle":"2021-07-01T07:15:49.166387Z","shell.execute_reply.started":"2021-07-01T07:15:49.152018Z","shell.execute_reply":"2021-07-01T07:15:49.165221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make an Sklearn pipeline for this Ridge Regression\nimport xgboost as xgb\nxgboost = xgb.XGBRegressor()\n\n# ridge = Ridge(fit_intercept=True, normalize=False)\npipeline_ridge = make_pipeline(\n    TfidfVectorizer(binary=True, ngram_range=(1, 1)),\n    xgboost\n)\n\n# Do training\npipeline_ridge.fit(t_X, t_Y)\n\n# Evaluate the performance on validation set\npreds = pipeline_ridge.predict(v_X)\nmse_loss = mean_squared_error(v_Y, preds)\n\nprint(f\"MSE Loss using Ridge and TfIdfVectorizer: {mse_loss}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T07:17:28.435485Z","iopub.execute_input":"2021-07-01T07:17:28.436152Z","iopub.status.idle":"2021-07-01T07:17:36.908557Z","shell.execute_reply.started":"2021-07-01T07:17:28.436093Z","shell.execute_reply":"2021-07-01T07:17:36.907586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make an Sklearn pipeline for this Linear Regression\nlinear = LinearRegression(fit_intercept=True, normalize=False)\npipeline_linear = make_pipeline(\n    TfidfVectorizer(binary=True, ngram_range=(1, 1)),\n    linear\n)\n\n# Do training\npipeline_linear.fit(t_X, t_Y)\n\n# Evaluate the performance on validation set\npreds = pipeline_linear.predict(v_X)\nmse_loss = mean_squared_error(v_Y, preds)\n\nprint(f\"MSE Loss using Linear Regression and TfIdfVectorizer: {mse_loss}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T07:17:44.875981Z","iopub.execute_input":"2021-07-01T07:17:44.876722Z","iopub.status.idle":"2021-07-01T07:17:46.712458Z","shell.execute_reply.started":"2021-07-01T07:17:44.876682Z","shell.execute_reply":"2021-07-01T07:17:46.711117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the testing file\ntest = test_file[['id', 'excerpt']]\ntest_ids = test['id'].tolist()\ntest_text = test['excerpt'].values\n\n# Do Predictions on testing set\ntest_preds_ridge = pipeline_ridge.predict(test_text)\ntest_preds_linear = pipeline_linear.predict(test_text)\n\n# Form a submissions file and save it\nsubmission = pd.DataFrame()\nsubmission['id'] = test_ids\nsubmission['target'] = (test_preds_ridge + test_preds_linear) / 2\nsubmission.to_csv(\"submission.csv\", index=None)\nprint(\"file Submitted\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T07:17:46.71463Z","iopub.execute_input":"2021-07-01T07:17:46.715085Z","iopub.status.idle":"2021-07-01T07:17:46.746745Z","shell.execute_reply.started":"2021-07-01T07:17:46.715033Z","shell.execute_reply":"2021-07-01T07:17:46.745627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}