{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import AutoConfig\nfrom transformers import get_cosine_schedule_with_warmup\nfrom transformers import logging\nlogging.set_verbosity_error()\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport gc\ngc.enable()","metadata":{"_kg_hide-input":true,"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:07.572582Z","iopub.execute_input":"2021-07-30T17:57:07.573007Z","iopub.status.idle":"2021-07-30T17:57:14.404168Z","shell.execute_reply.started":"2021-07-30T17:57:07.572908Z","shell.execute_reply":"2021-07-30T17:57:14.403373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from colorama import Fore, Back, Style\nr_ = Fore.RED\nb_ = Fore.BLUE\nc_ = Fore.CYAN\ng_ = Fore.GREEN\ny_ = Fore.YELLOW\nm_ = Fore.MAGENTA\nsr_ = Style.RESET_ALL\n# example: print(f\"{g_}Validation loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.405591Z","iopub.execute_input":"2021-07-30T17:57:14.405895Z","iopub.status.idle":"2021-07-30T17:57:14.409923Z","shell.execute_reply.started":"2021-07-30T17:57:14.405858Z","shell.execute_reply":"2021-07-30T17:57:14.409163Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.cuda.amp import GradScaler\nfrom torch.cuda.amp import autocast","metadata":{"execution":{"iopub.status.busy":"2021-07-30T17:57:14.41165Z","iopub.execute_input":"2021-07-30T17:57:14.412114Z","iopub.status.idle":"2021-07-30T17:57:14.421937Z","shell.execute_reply.started":"2021-07-30T17:57:14.412077Z","shell.execute_reply":"2021-07-30T17:57:14.421139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Definitions","metadata":{}},{"cell_type":"markdown","source":"## Model name in this notebook","metadata":{}},{"cell_type":"code","source":"model_path = f\"Roberta_large_model_0731e\"","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.42331Z","iopub.execute_input":"2021-07-30T17:57:14.423736Z","iopub.status.idle":"2021-07-30T17:57:14.430667Z","shell.execute_reply.started":"2021-07-30T17:57:14.423642Z","shell.execute_reply":"2021-07-30T17:57:14.429851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_random_seed(random_seed):\n    random.seed(random_seed)\n    np.random.seed(random_seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n\n    torch.manual_seed(random_seed)\n    torch.cuda.manual_seed(random_seed)\n    torch.cuda.manual_seed_all(random_seed)\n\n    torch.backends.cudnn.deterministic = True","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.431907Z","iopub.execute_input":"2021-07-30T17:57:14.432288Z","iopub.status.idle":"2021-07-30T17:57:14.441031Z","shell.execute_reply.started":"2021-07-30T17:57:14.43225Z","shell.execute_reply":"2021-07-30T17:57:14.440177Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"kfold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    data = data.sample(frac=1).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"target\"], bins=num_bins, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = StratifiedKFold(n_splits=num_splits)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.443288Z","iopub.execute_input":"2021-07-30T17:57:14.443562Z","iopub.status.idle":"2021-07-30T17:57:14.453276Z","shell.execute_reply.started":"2021-07-30T17:57:14.44353Z","shell.execute_reply":"2021-07-30T17:57:14.452516Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, time, gc\n\n# Timing utilities\nstart_time = None\n\ndef start_timer():\n    global start_time\n    gc.collect()\n    torch.cuda.empty_cache()\n    torch.cuda.reset_max_memory_allocated()\n    torch.cuda.synchronize()\n    start_time = time.time()\n\ndef end_timer_and_print(local_msg):\n    torch.cuda.synchronize()\n    end_time = time.time()\n    print(\"\\n\" + local_msg)\n    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T17:57:14.455059Z","iopub.execute_input":"2021-07-30T17:57:14.455318Z","iopub.status.idle":"2021-07-30T17:57:14.463447Z","shell.execute_reply.started":"2021-07-30T17:57:14.455291Z","shell.execute_reply":"2021-07-30T17:57:14.462693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"NUM_FOLDS = 5\nNUM_EPOCHS = 5\nSEED = 21\nBATCH_SIZE = 12\nMAX_LEN = 248\nIS_TARGET_SAMPLING = False\nIS_FREEZE_EMBEDDING = True\nIS_BERT_ADAM = False\nIS_STRATIFIED_KFOLD = True\nIS_USING_AMP = True\nRANDOM_FACTOR_OF_TARGET_SAMPLING = 0.1\nWEIGHT_DECAY = 0.01\nEARLY_STOPPING_PATIENCE = 15\nEVAL_SCHEDULE = [(0.50, 16), (0.495, 10), (0.49, 8), (0.485, 6),(0.48, 4), (0.47, 2), (-1., 1)]\nROBERTA_PATH = \"../input/0712-a-pretrain-large-pipeline/my_roberta_large_pretrained_0711a\"\nTOKENIZER_PATH = \"../input/0712-a-pretrain-large-pipeline/my_roberta_large_pretrained_0711a\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.466645Z","iopub.execute_input":"2021-07-30T17:57:14.466983Z","iopub.status.idle":"2021-07-30T17:57:14.512178Z","shell.execute_reply.started":"2021-07-30T17:57:14.46695Z","shell.execute_reply":"2021-07-30T17:57:14.511356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_random_seed(SEED)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.514193Z","iopub.execute_input":"2021-07-30T17:57:14.514838Z","iopub.status.idle":"2021-07-30T17:57:14.527592Z","shell.execute_reply.started":"2021-07-30T17:57:14.5148Z","shell.execute_reply":"2021-07-30T17:57:14.526793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.530531Z","iopub.execute_input":"2021-07-30T17:57:14.530767Z","iopub.status.idle":"2021-07-30T17:57:14.621856Z","shell.execute_reply.started":"2021-07-30T17:57:14.530745Z","shell.execute_reply":"2021-07-30T17:57:14.621058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove incomplete entries if any.\ntrain_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n              inplace=True)\ntrain_df.reset_index(drop=True, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.62466Z","iopub.execute_input":"2021-07-30T17:57:14.624913Z","iopub.status.idle":"2021-07-30T17:57:14.648036Z","shell.execute_reply.started":"2021-07-30T17:57:14.624886Z","shell.execute_reply":"2021-07-30T17:57:14.647348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IS_STRATIFIED_KFOLD:\n    train_df = create_folds(train_df, num_splits=NUM_FOLDS)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.649164Z","iopub.execute_input":"2021-07-30T17:57:14.649634Z","iopub.status.idle":"2021-07-30T17:57:14.666812Z","shell.execute_reply.started":"2021-07-30T17:57:14.6496Z","shell.execute_reply":"2021-07-30T17:57:14.666116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.669181Z","iopub.execute_input":"2021-07-30T17:57:14.669448Z","iopub.status.idle":"2021-07-30T17:57:14.847137Z","shell.execute_reply.started":"2021-07-30T17:57:14.669425Z","shell.execute_reply":"2021-07-30T17:57:14.846285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import Dataset\nclass LitDataset(Dataset):\n    def __init__(self, df, inference_only=False, is_target_sampling=False):\n        super().__init__()\n\n        self.df = df        \n        self.inference_only = inference_only\n        self.text = df.excerpt.tolist()\n        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n         \n        if not self.inference_only:\n            self.target = torch.tensor(df.target.values, dtype=torch.float32)    \n            self.err_std = torch.tensor(df.standard_error.values, dtype=torch.float32)   \n        self.is_target_sampling = is_target_sampling\n        self.encoded = tokenizer(\n            self.text,\n            padding = 'max_length',            \n            max_length = MAX_LEN,\n            truncation = True,\n            # 注意这里要手动把return_attention_mask打开\n            return_attention_mask=True\n#             return_tensors='pt'\n        )        \n \n\n    def __len__(self):\n        return len(self.df)\n\n    \n    def __getitem__(self, index):        \n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        \n        \n        if self.inference_only:\n            return (input_ids, attention_mask)            \n        else:\n            target = self.target[index]\n            if self.is_target_sampling:\n                err_std = self.err_std[index]\n            # 这里对std可以有多种映射，这里先只尝试std=err_std\n                \n                sampled_target = torch.normal(mean=target, std=RANDOM_FACTOR_OF_TARGET_SAMPLING*err_std, \n                                              size=(1,1)).item()\n                sampled_target = torch.tensor([sampled_target], dtype=torch.float32)[0]\n                return (input_ids, attention_mask, sampled_target)\n            else:\n                return (input_ids, attention_mask, target)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.848543Z","iopub.execute_input":"2021-07-30T17:57:14.848897Z","iopub.status.idle":"2021-07-30T17:57:14.86195Z","shell.execute_reply.started":"2021-07-30T17:57:14.84886Z","shell.execute_reply":"2021-07-30T17:57:14.861123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"def eval_mse(model, data_loader, return_type='mse'):\n    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n    model.eval()            \n    mse_sum = 0\n    \n    val_pred = torch.tensor([]).to(DEVICE) \n    val_target = torch.tensor([]).to(DEVICE) \n    \n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)                        \n            target = target.to(DEVICE)           \n            \n            pred = model(input_ids, attention_mask)\n            \n            # 把 batch的 loss都加起来\n            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n            val_pred = torch.cat([val_pred, pred.flatten()])\n            val_target = torch.cat([val_target, target])\n                \n    # 注意这里返回的是loss和n\n    if return_type=='mse':\n#         print('Here!!!!!!!!!!!!1',val_pred.shape, val_target.shape)\n        return mse_sum / len(data_loader.dataset), val_pred, val_target\n    elif return_type=='se':\n        return mse_sum , len(data_loader.dataset)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.864938Z","iopub.execute_input":"2021-07-30T17:57:14.865234Z","iopub.status.idle":"2021-07-30T17:57:14.8756Z","shell.execute_reply.started":"2021-07-30T17:57:14.865196Z","shell.execute_reply":"2021-07-30T17:57:14.874771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"def predict(model, data_loader):\n    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    \n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n                        \n            pred = model(input_ids, attention_mask)                        \n            # 注意这里要把 pred移到cpu上\n            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n            index += pred.shape[0]\n\n    return result","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.876779Z","iopub.execute_input":"2021-07-30T17:57:14.87713Z","iopub.status.idle":"2021-07-30T17:57:14.888921Z","shell.execute_reply.started":"2021-07-30T17:57:14.877104Z","shell.execute_reply":"2021-07-30T17:57:14.88808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"\ndef train(model, model_path, train_loader, val_loader,\n          optimizer, fold_idx, scheduler=None, num_epochs=NUM_EPOCHS, \n         training_history=[], val_history=[]):    \n    best_val_rmse = None\n    best_epoch = 0\n    step = 0\n    last_eval_step = 0\n    eval_period = EVAL_SCHEDULE[0][1]    \n    early_stopping_if_break_curr_fold = False\n    \n    no_improvement_count = 0\n    start = time.time()\n#     print(1)\n    start_timer()\n    for epoch in range(num_epochs):                           \n        val_rmse = None         \n\n        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)            \n            target = target.to(DEVICE)                        \n            \n            \n            with torch.cuda.amp.autocast(enabled=IS_USING_AMP):\n                model.train()\n    #             print(2)\n                pred = model(input_ids, attention_mask)\n\n                mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n            optimizer.zero_grad()            \n#             mse.backward()\n            scaler.scale(mse).backward()\n            scaler.step(optimizer)\n            \n#             optimizer.step()\n            scale = scaler.get_scale()\n            scaler.update()\n            is_skipping_lr_sched = (scale != scaler.get_scale())\n            if scheduler and (not is_skipping_lr_sched):\n                scheduler.step()\n            \n            if step >= last_eval_step + eval_period:\n                # Evaluate the model on val_loader.\n                elapsed_seconds = time.time() - start\n                num_steps = step - last_eval_step\n                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n                last_eval_step = step\n                \n                temp_mse, temp_pred, temp_target = eval_mse(model, val_loader, return_type='mse')\n                \n                val_rmse = math.sqrt(temp_mse)                            \n\n                print(f\"Epoch: {epoch} batch_num: {batch_num} train_rmse: {math.sqrt(mse.item())}\", \n                      f\"val_rmse: {val_rmse:0.4}\")\n                \n                training_history.append(mse.item())\n                val_history.append(val_rmse)\n\n                for rmse, period in EVAL_SCHEDULE:\n                    if val_rmse >= rmse:\n                        eval_period = period\n                        break                               \n                \n                if not best_val_rmse or val_rmse < best_val_rmse:                    \n                    best_val_rmse = val_rmse\n                    best_epoch = epoch\n                    # 保存 best model\n                    torch.save(model.state_dict(), f'{model_path}_FOLD{fold_idx+1}.pth')\n                    print(f\"{g_}New best_val_rmse: {best_val_rmse:0.4}{sr_}\")\n                    \n                    # reset the early stopping counter\n                    no_improvement_count = 0\n                    \n                    result_CV = np.zeros(len(temp_pred)) \n                    result_CV[:] = temp_pred.flatten().to(\"cpu\")\n                    target_col = np.zeros(len(temp_target)) \n                    target_col[:] = temp_target.flatten().to(\"cpu\")\n                    result_CV_df = pd.DataFrame(np.array([result_CV, target_col]).T, columns=['pred', 'target'])\n                    result_CV_df = result_CV_df.to_csv(f'oof_{model_path}_FOLD{fold_idx+1}.csv')\n                    \n                else:       \n                    print(f\"{y_}Still best_val_rmse: {best_val_rmse:0.4}{sr_}\",\n                          f\"(from epoch {best_epoch})\")     \n                    \n                    # update the early stopping counter\n                    no_improvement_count += 1\n                    if no_improvement_count >= EARLY_STOPPING_PATIENCE:\n                        early_stopping_if_break_curr_fold = True\n                        start = time.time()\n                        step += 1\n                        print(f\"{c_}Earlt stopping triggered here. {best_epoch}{sr_})\")  \n                        break\n                        \n                start = time.time()\n                                            \n            step += 1\n        if early_stopping_if_break_curr_fold:\n            \n            break\n    end_timer_and_print(\"Mixed precision:\")\n    return best_val_rmse\n\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.890198Z","iopub.execute_input":"2021-07-30T17:57:14.890865Z","iopub.status.idle":"2021-07-30T17:57:14.908558Z","shell.execute_reply.started":"2021-07-30T17:57:14.89081Z","shell.execute_reply":"2021-07-30T17:57:14.907798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Opt","metadata":{}},{"cell_type":"code","source":"def create_optimizer(model):\n    named_parameters = list(model.named_parameters())    \n    \n    roberta_parameters = named_parameters[:391]    \n    attention_parameters = named_parameters[391:395]\n    regressor_parameters = named_parameters[395:]\n        \n    attention_group = [params for (name, params) in attention_parameters]\n    regressor_group = [params for (name, params) in regressor_parameters]\n\n    parameters = []\n    parameters.append({\"params\": attention_group,\n                       \"lr\": 5e-5,\n                       \"weight_decay\": WEIGHT_DECAY})\n    parameters.append({\"params\": regressor_group,\n                       \"lr\": 3e-4,\n                       \"weight_decay\": WEIGHT_DECAY})\n\n    for layer_num, (name, params) in enumerate(roberta_parameters):\n        weight_decay = 0.0 if \"bias\" in name else WEIGHT_DECAY\n\n        lr = 1e-6\n\n        if layer_num >= 133:        \n            lr = 5e-6\n\n        if layer_num >= 261:\n            lr = 1e-5\n        \n        \n\n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr,\n                           \"correct_bias\": IS_BERT_ADAM})\n\n    return AdamW(parameters)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.911013Z","iopub.execute_input":"2021-07-30T17:57:14.91127Z","iopub.status.idle":"2021-07-30T17:57:14.921975Z","shell.execute_reply.started":"2021-07-30T17:57:14.911247Z","shell.execute_reply":"2021-07-30T17:57:14.921203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class WeightedLayerPooling(nn.Module):\n    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n        super(WeightedLayerPooling, self).__init__()\n        self.layer_start = layer_start\n        self.num_hidden_layers = num_hidden_layers\n        self.layer_weights = layer_weights if layer_weights is not None \\\n            else nn.Parameter(\n                torch.tensor([1] * abs(self.layer_start), dtype=torch.float)\n            )\n\n    def forward(self, all_layer_embeddings_input):\n#         print('num',self.num_hidden_layers )\n        ft_all_layers = all_layer_embeddings_input\n        # these teo lines convert 'tuple of tensors' into 'tensor', and then slice on it\n        all_layer_embedding = torch.stack(ft_all_layers)\n        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]\n#         print('h',all_layer_embedding.shape)\n        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n\n        return weighted_average\n\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.923399Z","iopub.execute_input":"2021-07-30T17:57:14.923763Z","iopub.status.idle":"2021-07-30T17:57:14.931713Z","shell.execute_reply.started":"2021-07-30T17:57:14.923729Z","shell.execute_reply":"2021-07-30T17:57:14.930746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcFaceClassifier(nn.Module):\n    def __init__(self, emb_size, output_classes):\n        super().__init__()\n        self.W = nn.Parameter(torch.Tensor(emb_size, output_classes))\n        nn.init.kaiming_uniform_(self.W)\n    def forward(self, x):\n        # Step 1:\n        x_norm = F.normalize(x)\n        W_norm = F.normalize(self.W, dim=0)\n        # Step 2:\n        return x_norm @ W_norm","metadata":{"execution":{"iopub.status.busy":"2021-07-30T17:57:14.933105Z","iopub.execute_input":"2021-07-30T17:57:14.933455Z","iopub.status.idle":"2021-07-30T17:57:14.94282Z","shell.execute_reply.started":"2021-07-30T17:57:14.933421Z","shell.execute_reply":"2021-07-30T17:57:14.941991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nclass LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7,\n                       'output_hidden_states':True})   \n        \n        freeze_embedding = IS_FREEZE_EMBEDDING\n        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config, )  \n        self.roberta.base_model.embeddings.requires_grad_(not freeze_embedding)    \n        \n        \n#         self.config_hidden_size = config.hidden_size\n        \n        self.layer_start = -8\n        self.pooler = WeightedLayerPooling(\n            config.num_hidden_layers, \n            layer_start=self.layer_start, layer_weights=None\n        )\n        self.arcface = ArcFaceClassifier(emb_size=512,output_classes=1)\n        \n        self.attention = nn.Sequential(            \n            nn.Linear(1024, 512),            \n            nn.Tanh(),                       \n            self.arcface\n        )        \n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(1024, 512),\n            nn.PReLU(),\n            nn.Linear(512, 256),\n            nn.PReLU(),\n            nn.Linear(256, 256),\n            nn.PReLU(),\n            nn.Linear(256, 128),\n            nn.PReLU(),\n            nn.Linear(128, 64),\n            nn.PReLU(),\n            nn.Linear(64, 16),\n            nn.PReLU(),\n            nn.Linear(16, 1)\n        )\n#         self.fc = nn.Linear(config.hidden_size, 1)\n\n\n    def forward(self, input_ids, attention_mask):\n        \n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)   \n        sequence_output = self.pooler(roberta_output.hidden_states)\n        weights = self.attention(sequence_output)\n        context_vector = torch.sum(weights * sequence_output, dim=1)  \n\n        return self.regressor(context_vector)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.943782Z","iopub.execute_input":"2021-07-30T17:57:14.944065Z","iopub.status.idle":"2021-07-30T17:57:14.957172Z","shell.execute_reply.started":"2021-07-30T17:57:14.94404Z","shell.execute_reply":"2021-07-30T17:57:14.956409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LitModel().to(DEVICE)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:14.959176Z","iopub.execute_input":"2021-07-30T17:57:14.959867Z","iopub.status.idle":"2021-07-30T17:57:46.965809Z","shell.execute_reply.started":"2021-07-30T17:57:14.959761Z","shell.execute_reply":"2021-07-30T17:57:46.964952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"named_parameters = list(model.named_parameters())","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:46.968971Z","iopub.execute_input":"2021-07-30T17:57:46.969308Z","iopub.status.idle":"2021-07-30T17:57:46.978314Z","shell.execute_reply.started":"2021-07-30T17:57:46.969278Z","shell.execute_reply":"2021-07-30T17:57:46.977615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[(tup[0], tup[1][0]) for tup in enumerate(named_parameters)]","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:46.97961Z","iopub.execute_input":"2021-07-30T17:57:46.979949Z","iopub.status.idle":"2021-07-30T17:57:47.016399Z","shell.execute_reply.started":"2021-07-30T17:57:46.979913Z","shell.execute_reply":"2021-07-30T17:57:47.015452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:47.017685Z","iopub.execute_input":"2021-07-30T17:57:47.018142Z","iopub.status.idle":"2021-07-30T17:57:47.214684Z","shell.execute_reply.started":"2021-07-30T17:57:47.018106Z","shell.execute_reply":"2021-07-30T17:57:47.213628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"code","source":"%%time\ngc.collect()\n\n\n\nlist_val_rmse = []\nset_random_seed(SEED)\nkfold = KFold(n_splits=NUM_FOLDS, shuffle=True)\n\nscaler = GradScaler(enabled=IS_USING_AMP)\n\ntraining_history = []\nval_history = []\nif IS_STRATIFIED_KFOLD:\n    \n    for fold in range(NUM_FOLDS):\n        train_indices = train_df.index[train_df['kfold'] != fold].tolist()\n        val_indices = train_df.index[train_df['kfold'] == fold].tolist()\n        set_random_seed(SEED + fold)\n        random.shuffle(train_indices)\n        print(f\"\\nFold {fold+1}/{NUM_FOLDS}\")\n\n        train_dataset = LitDataset(train_df.loc[train_indices], is_target_sampling=IS_TARGET_SAMPLING)    \n        # 不知道这里val用不用random target sampling，暂时不用\n        val_dataset = LitDataset(train_df.loc[val_indices])    \n\n        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                                  drop_last=True, shuffle=True, num_workers=0)    \n        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                                drop_last=False, shuffle=False, num_workers=0)    \n\n        set_random_seed(SEED + fold)    \n\n        model = LitModel().to(DEVICE)\n\n        optimizer = create_optimizer(model)      \n        COSINE_WARMUP_FACTOR = 0.1\n        num_training_steps=NUM_EPOCHS * len(train_loader)\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_training_steps=NUM_EPOCHS * len(train_loader),\n            num_warmup_steps=50\n#             num_warmup_steps=COSINE_WARMUP_FACTOR*num_training_steps\n        \n        )    \n\n        list_val_rmse.append(train(model, model_path, train_loader,\n                                   val_loader, optimizer, fold_idx=fold, scheduler=scheduler,\n                                  training_history=training_history, val_history=val_history))\n\n        del model\n        gc.collect()\n        torch.cuda.empty_cache()\n        print(\"\\nPerformance estimates (simple):\")\n        print(list_val_rmse)\n        print(\"Mean:\", np.array(list_val_rmse).mean(), \";Std:\", np.array(list_val_rmse).std())\n\n    \n    \nelse:\n    \n    for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n        print(f\"\\nFold {fold+1}/{NUM_FOLDS}\")\n    #     model_path = f\"Roberta_targetsampling_model_0701b\"\n\n        set_random_seed(SEED + fold)\n\n        train_dataset = LitDataset(train_df.loc[train_indices], is_target_sampling=IS_TARGET_SAMPLING)    \n        # 不知道这里val用不用random target sampling，暂时不用\n        val_dataset = LitDataset(train_df.loc[val_indices])    \n\n        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                                  drop_last=True, shuffle=True, num_workers=2)    \n        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                                drop_last=False, shuffle=False, num_workers=2)    \n\n        set_random_seed(SEED + fold)    \n\n        model = LitModel().to(DEVICE)\n\n        optimizer = create_optimizer(model)                        \n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_training_steps=NUM_EPOCHS * len(train_loader),\n            num_warmup_steps=50)    \n\n        list_val_rmse.append(train(model, model_path, train_loader,\n                                   val_loader, optimizer, fold_idx=fold, scheduler=scheduler))\n\n        del model\n        gc.collect()\n\n        print(\"\\nPerformance estimates (simple):\")\n        print(list_val_rmse)\n        print(\"Mean:\", np.array(list_val_rmse).mean(), \";Std:\", np.array(list_val_rmse).std())\n    ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-07-30T17:57:47.217275Z","iopub.execute_input":"2021-07-30T17:57:47.217898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme(style=\"darkgrid\")\ntrain_history = np.array(list((enumerate(training_history)))).T\nval_history = np.array(list((enumerate(val_history)))).T\nplt.rcParams[\"figure.figsize\"] = (16,10)\nsns.lineplot(x=train_history[0], y=train_history[1])\nsns.lineplot(x=val_history[0], y=val_history[1])\nplt.plot()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:22:03.997222Z","iopub.execute_input":"2021-07-26T05:22:03.99765Z","iopub.status.idle":"2021-07-26T05:22:04.69893Z","shell.execute_reply.started":"2021-07-26T05:22:03.997606Z","shell.execute_reply":"2021-07-26T05:22:04.697621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict submission file","metadata":{}},{"cell_type":"code","source":"# COMPUTE_CV = True\n\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n# if len(test_df)>7: COMPUTE_CV = False\n# else: print('this submission notebook will compute CV score, but commit notebook will not')\n\n\nsubmission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:22:04.700448Z","iopub.execute_input":"2021-07-26T05:22:04.700935Z","iopub.status.idle":"2021-07-26T05:22:04.721288Z","shell.execute_reply.started":"2021-07-26T05:22:04.70089Z","shell.execute_reply":"2021-07-26T05:22:04.720032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = LitDataset(test_df, inference_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:22:04.725892Z","iopub.execute_input":"2021-07-26T05:22:04.72622Z","iopub.status.idle":"2021-07-26T05:22:04.753472Z","shell.execute_reply.started":"2021-07-26T05:22:04.72619Z","shell.execute_reply":"2021-07-26T05:22:04.752424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = LitDataset(test_df, inference_only=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor index in range(len(list_val_rmse)):            \n    print(f\"\\nUsing {model_path}\")\n                        \n    model = LitModel()\n    model.load_state_dict(torch.load(f'{model_path}_FOLD{index+1}.pth'))    \n    model.to(DEVICE)\n    \n    temp_pred = predict(model, test_loader)\n    print(temp_pred)\n    result_sub = np.zeros(len(temp_pred)) \n    result_sub[:] = temp_pred.flatten()\n    result_sub_df = pd.DataFrame(result_sub, columns=['pred'])\n    result_sub_df = result_sub_df.to_csv(f'sub_{model_path}_FOLD{index+1}.csv', columns=['pred'])\n    \n    del model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:22:04.75535Z","iopub.execute_input":"2021-07-26T05:22:04.755795Z","iopub.status.idle":"2021-07-26T05:23:45.637338Z","shell.execute_reply.started":"2021-07-26T05:22:04.755751Z","shell.execute_reply":"2021-07-26T05:23:45.636016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index in range(len(list_val_rmse)):            \n    print(f\"\\nUsing {model_path}\")\n                        \n    sub_i_df = pd.read_csv(f'sub_{model_path}_FOLD{index+1}.csv')\n    submission_df.target += sub_i_df.pred/len(list_val_rmse)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:23:45.643004Z","iopub.execute_input":"2021-07-26T05:23:45.645948Z","iopub.status.idle":"2021-07-26T05:23:45.703913Z","shell.execute_reply.started":"2021-07-26T05:23:45.6459Z","shell.execute_reply":"2021-07-26T05:23:45.701256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n    print(val_indices.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:23:45.706456Z","iopub.execute_input":"2021-07-26T05:23:45.706914Z","iopub.status.idle":"2021-07-26T05:23:45.725244Z","shell.execute_reply.started":"2021-07-26T05:23:45.706874Z","shell.execute_reply":"2021-07-26T05:23:45.723855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:23:45.729003Z","iopub.execute_input":"2021-07-26T05:23:45.731595Z","iopub.status.idle":"2021-07-26T05:23:45.742864Z","shell.execute_reply.started":"2021-07-26T05:23:45.731409Z","shell.execute_reply":"2021-07-26T05:23:45.741646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV","metadata":{}},{"cell_type":"code","source":"oof_cat = pd.DataFrame([])\nfor index in range(len(list_val_rmse)):            \n    print(f\"\\nUsing {model_path}\")\n                        \n    oof_i_df = pd.read_csv(f'oof_{model_path}_FOLD{index+1}.csv')\n    oof_cat = pd.concat([oof_cat,oof_i_df],ignore_index=True)\nprint(oof_cat.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:23:45.74459Z","iopub.execute_input":"2021-07-26T05:23:45.747465Z","iopub.status.idle":"2021-07-26T05:23:45.801728Z","shell.execute_reply.started":"2021-07-26T05:23:45.747413Z","shell.execute_reply":"2021-07-26T05:23:45.800417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CV_rmse = np.sqrt(nn.MSELoss(reduction=\"mean\")(torch.tensor(oof_cat.pred.values), \n                                               torch.tensor(oof_cat.target.values)).item())\nprint(f'{y_}CV_rmse: {CV_rmse:0.5}{sr_}')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:23:45.806846Z","iopub.execute_input":"2021-07-26T05:23:45.80956Z","iopub.status.idle":"2021-07-26T05:23:45.828151Z","shell.execute_reply.started":"2021-07-26T05:23:45.809502Z","shell.execute_reply":"2021-07-26T05:23:45.825848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}