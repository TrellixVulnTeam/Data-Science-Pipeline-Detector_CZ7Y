{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-20T05:50:23.091091Z","iopub.execute_input":"2021-06-20T05:50:23.091646Z","iopub.status.idle":"2021-06-20T05:50:23.10515Z","shell.execute_reply.started":"2021-06-20T05:50:23.091534Z","shell.execute_reply":"2021-06-20T05:50:23.104206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import BertPreTrainedModel, BertModel\nfrom transformers import AutoConfig, AutoTokenizer\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm, trange","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:23.106654Z","iopub.execute_input":"2021-06-20T05:50:23.107104Z","iopub.status.idle":"2021-06-20T05:50:25.638866Z","shell.execute_reply.started":"2021-06-20T05:50:23.107069Z","shell.execute_reply":"2021-06-20T05:50:25.637945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.640456Z","iopub.execute_input":"2021-06-20T05:50:25.640791Z","iopub.status.idle":"2021-06-20T05:50:25.700817Z","shell.execute_reply.started":"2021-06-20T05:50:25.640765Z","shell.execute_reply":"2021-06-20T05:50:25.700066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.style.use('dark_background')","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.702285Z","iopub.execute_input":"2021-06-20T05:50:25.702626Z","iopub.status.idle":"2021-06-20T05:50:25.706861Z","shell.execute_reply.started":"2021-06-20T05:50:25.702591Z","shell.execute_reply":"2021-06-20T05:50:25.705573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"dftrain = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ndftest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample_submission = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.708462Z","iopub.execute_input":"2021-06-20T05:50:25.708845Z","iopub.status.idle":"2021-06-20T05:50:25.817864Z","shell.execute_reply.started":"2021-06-20T05:50:25.70881Z","shell.execute_reply":"2021-06-20T05:50:25.817036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, validation = train_test_split(dftrain, test_size=0.25, random_state=21)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.81913Z","iopub.execute_input":"2021-06-20T05:50:25.819465Z","iopub.status.idle":"2021-06-20T05:50:25.833507Z","shell.execute_reply.started":"2021-06-20T05:50:25.819429Z","shell.execute_reply":"2021-06-20T05:50:25.832334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.836142Z","iopub.execute_input":"2021-06-20T05:50:25.836455Z","iopub.status.idle":"2021-06-20T05:50:25.85159Z","shell.execute_reply.started":"2021-06-20T05:50:25.836423Z","shell.execute_reply":"2021-06-20T05:50:25.850358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftrain.shape, dftest.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.85371Z","iopub.execute_input":"2021-06-20T05:50:25.854313Z","iopub.status.idle":"2021-06-20T05:50:25.862219Z","shell.execute_reply.started":"2021-06-20T05:50:25.854272Z","shell.execute_reply":"2021-06-20T05:50:25.861309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.863623Z","iopub.execute_input":"2021-06-20T05:50:25.864055Z","iopub.status.idle":"2021-06-20T05:50:25.880336Z","shell.execute_reply.started":"2021-06-20T05:50:25.864014Z","shell.execute_reply":"2021-06-20T05:50:25.87954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count = dftrain['excerpt'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.881757Z","iopub.execute_input":"2021-06-20T05:50:25.882147Z","iopub.status.idle":"2021-06-20T05:50:25.9173Z","shell.execute_reply.started":"2021-06-20T05:50:25.882111Z","shell.execute_reply":"2021-06-20T05:50:25.916558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=[10,7])\nsns.distplot(word_count, color=sns.xkcd_rgb['greenish teal'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:25.918432Z","iopub.execute_input":"2021-06-20T05:50:25.918811Z","iopub.status.idle":"2021-06-20T05:50:26.185964Z","shell.execute_reply.started":"2021-06-20T05:50:25.918777Z","shell.execute_reply":"2021-06-20T05:50:26.185187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc_test = dftest['excerpt'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.187202Z","iopub.execute_input":"2021-06-20T05:50:26.187558Z","iopub.status.idle":"2021-06-20T05:50:26.192983Z","shell.execute_reply.started":"2021-06-20T05:50:26.18752Z","shell.execute_reply":"2021-06-20T05:50:26.191837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc_test","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.194547Z","iopub.execute_input":"2021-06-20T05:50:26.194939Z","iopub.status.idle":"2021-06-20T05:50:26.209633Z","shell.execute_reply.started":"2021-06-20T05:50:26.194902Z","shell.execute_reply":"2021-06-20T05:50:26.208742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count.max()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.211023Z","iopub.execute_input":"2021-06-20T05:50:26.211393Z","iopub.status.idle":"2021-06-20T05:50:26.220105Z","shell.execute_reply.started":"2021-06-20T05:50:26.211357Z","shell.execute_reply":"2021-06-20T05:50:26.219186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"MODEL_OUT_DIR = '/kaggle/working/models/bert_regressor'\n## Model Configurations\nMAX_LEN_TRAIN = 205\nMAX_LEN_VALID = 205\nMAX_LEN_TEST = 205\nBATCH_SIZE = 64\nLR = 1e-3\nNUM_EPOCHS = 10\nNUM_THREADS = 1  ## Number of threads for collecting dataset\nMODEL_NAME = 'bert-base-uncased'\n\nif not os.path.isdir(MODEL_OUT_DIR):\n    os.makedirs(MODEL_OUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.221326Z","iopub.execute_input":"2021-06-20T05:50:26.221794Z","iopub.status.idle":"2021-06-20T05:50:26.23011Z","shell.execute_reply.started":"2021-06-20T05:50:26.221759Z","shell.execute_reply":"2021-06-20T05:50:26.228992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scripts","metadata":{}},{"cell_type":"code","source":"class Excerpt_Dataset(Dataset):\n\n    def __init__(self, data, maxlen, tokenizer): \n        #Store the contents of the file in a pandas dataframe\n        self.df = data.reset_index()\n        #Initialize the tokenizer for the desired transformer model\n        self.tokenizer = tokenizer\n        #Maximum length of the tokens list to keep all the sequences of fixed size\n        self.maxlen = maxlen\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):    \n        #Select the sentence and label at the specified index in the data frame\n        excerpt = self.df.loc[index, 'excerpt']\n        try:\n            target = self.df.loc[index, 'target']\n        except:\n            target = 0.0\n        identifier = self.df.loc[index, 'id']\n        #Preprocess the text to be suitable for the transformer\n        tokens = self.tokenizer.tokenize(excerpt) \n        tokens = ['[CLS]'] + tokens + ['[SEP]'] \n        if len(tokens) < self.maxlen:\n            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] \n        else:\n            tokens = tokens[:self.maxlen-1] + ['[SEP]'] \n        #Obtain the indices of the tokens in the BERT Vocabulary\n        input_ids = self.tokenizer.convert_tokens_to_ids(tokens) \n        input_ids = torch.tensor(input_ids) \n        #Obtain the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n        attention_mask = (input_ids != 0).long()\n        \n        target = torch.tensor(target, dtype=torch.float32)\n        \n        return input_ids, attention_mask, target","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.2314Z","iopub.execute_input":"2021-06-20T05:50:26.23201Z","iopub.status.idle":"2021-06-20T05:50:26.242301Z","shell.execute_reply.started":"2021-06-20T05:50:26.231972Z","shell.execute_reply":"2021-06-20T05:50:26.241547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertRegresser(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n        #The output layer that takes the [CLS] representation and gives an output\n        self.cls_layer1 = nn.Linear(config.hidden_size,128)\n        self.relu1 = nn.ReLU()\n        self.ff1 = nn.Linear(128,128)\n        self.tanh1 = nn.Tanh()\n        self.ff2 = nn.Linear(128,1)\n\n    def forward(self, input_ids, attention_mask):\n        #Feed the input to Bert model to obtain contextualized representations\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        #Obtain the representations of [CLS] heads\n        logits = outputs.last_hidden_state[:,0,:]\n        output = self.cls_layer1(logits)\n        output = self.relu1(output)\n        output = self.ff1(output)\n        output = self.tanh1(output)\n        output = self.ff2(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.243716Z","iopub.execute_input":"2021-06-20T05:50:26.244218Z","iopub.status.idle":"2021-06-20T05:50:26.254223Z","shell.execute_reply.started":"2021-06-20T05:50:26.244182Z","shell.execute_reply":"2021-06-20T05:50:26.253508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train function","metadata":{}},{"cell_type":"code","source":"def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n    best_acc = 0\n    for epoch in trange(epochs, desc=\"Epoch\"):\n        model.train()\n        train_loss = 0\n        for i, (input_ids, attention_mask, target) in enumerate(iterable=train_loader):\n            optimizer.zero_grad()  \n            \n            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n            \n            output = model(input_ids=input_ids, attention_mask=attention_mask)\n            \n            loss = criterion(output, target.type_as(output))\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        print(f\"Training loss is {train_loss/len(train_loader)}\")\n        val_loss = evaluate(model=model, criterion=criterion, dataloader=val_loader, device=device)\n        print(\"Epoch {} complete! Validation Loss : {}\".format(epoch, val_loss))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.255392Z","iopub.execute_input":"2021-06-20T05:50:26.255745Z","iopub.status.idle":"2021-06-20T05:50:26.267272Z","shell.execute_reply.started":"2021-06-20T05:50:26.255712Z","shell.execute_reply":"2021-06-20T05:50:26.266464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation function","metadata":{}},{"cell_type":"code","source":"def evaluate(model, criterion, dataloader, device):\n    model.eval()\n    mean_acc, mean_loss, count = 0, 0, 0\n\n    with torch.no_grad():\n        for input_ids, attention_mask, target in (dataloader):\n            \n            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n            output = model(input_ids, attention_mask)\n            \n            mean_loss += criterion(output, target.type_as(output)).item()\n#             mean_err += get_rmse(output, target)\n            count += 1\n            \n    return mean_loss/count","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.270442Z","iopub.execute_input":"2021-06-20T05:50:26.270917Z","iopub.status.idle":"2021-06-20T05:50:26.27792Z","shell.execute_reply.started":"2021-06-20T05:50:26.270881Z","shell.execute_reply":"2021-06-20T05:50:26.276849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rmse(output, target):\n    err = torch.sqrt(metrics.mean_squared_error(target, output))\n    return err","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.279827Z","iopub.execute_input":"2021-06-20T05:50:26.28022Z","iopub.status.idle":"2021-06-20T05:50:26.289679Z","shell.execute_reply.started":"2021-06-20T05:50:26.280184Z","shell.execute_reply":"2021-06-20T05:50:26.288937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict function","metadata":{}},{"cell_type":"code","source":"def predict(model, dataloader, device):\n    predicted_label = []\n    actual_label = []\n    with torch.no_grad():\n        for input_ids, attention_mask, target in (dataloader):\n            \n            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n            output = model(input_ids, attention_mask)\n                        \n            predicted_label += output\n            actual_label += target\n            \n    return predicted_label","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.290809Z","iopub.execute_input":"2021-06-20T05:50:26.291287Z","iopub.status.idle":"2021-06-20T05:50:26.299288Z","shell.execute_reply.started":"2021-06-20T05:50:26.291251Z","shell.execute_reply":"2021-06-20T05:50:26.298439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"## Configuration loaded from AutoConfig \nconfig = AutoConfig.from_pretrained(MODEL_NAME)\n## Tokenizer loaded from AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n## Creating the model from the desired transformer model\nmodel = BertRegresser.from_pretrained(MODEL_NAME, config=config)\n## GPU or CPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n## Putting model to device\nmodel = model.to(device)\n## Takes as the input the logits of the positive class and computes the binary cross-entropy \n# criterion = nn.BCEWithLogitsLoss()\ncriterion = nn.MSELoss()\n## Optimizer\noptimizer = optim.Adam(params=model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:26.300647Z","iopub.execute_input":"2021-06-20T05:50:26.301068Z","iopub.status.idle":"2021-06-20T05:50:57.607245Z","shell.execute_reply.started":"2021-06-20T05:50:26.301031Z","shell.execute_reply":"2021-06-20T05:50:57.606341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prep data","metadata":{}},{"cell_type":"code","source":"## Training Dataset\ntrain_set = Excerpt_Dataset(data=train_data, maxlen=MAX_LEN_TRAIN, tokenizer=tokenizer)\nvalid_set = Excerpt_Dataset(data=validation, maxlen=MAX_LEN_VALID, tokenizer=tokenizer)\ntest_set = Excerpt_Dataset(data=dftest, maxlen=MAX_LEN_TEST, tokenizer=tokenizer)\n\n\n## Data Loaders\ntrain_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\nvalid_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\ntest_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n\n# print(len(train_loader))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:57.608561Z","iopub.execute_input":"2021-06-20T05:50:57.608933Z","iopub.status.idle":"2021-06-20T05:50:57.619832Z","shell.execute_reply.started":"2021-06-20T05:50:57.608899Z","shell.execute_reply":"2021-06-20T05:50:57.618958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"train(model=model, \n      criterion=criterion,\n      optimizer=optimizer, \n      train_loader=train_loader,\n      val_loader=valid_loader,\n      epochs = 10,\n     device = device)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:50:57.621119Z","iopub.execute_input":"2021-06-20T05:50:57.621502Z","iopub.status.idle":"2021-06-20T05:58:24.833152Z","shell.execute_reply.started":"2021-06-20T05:50:57.621451Z","shell.execute_reply":"2021-06-20T05:58:24.830294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"output = predict(model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:24.834996Z","iopub.execute_input":"2021-06-20T05:58:24.835369Z","iopub.status.idle":"2021-06-20T05:58:24.927749Z","shell.execute_reply.started":"2021-06-20T05:58:24.835328Z","shell.execute_reply":"2021-06-20T05:58:24.926709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:24.931Z","iopub.execute_input":"2021-06-20T05:58:24.931268Z","iopub.status.idle":"2021-06-20T05:58:24.939686Z","shell.execute_reply.started":"2021-06-20T05:58:24.93124Z","shell.execute_reply":"2021-06-20T05:58:24.938745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:24.940934Z","iopub.execute_input":"2021-06-20T05:58:24.941313Z","iopub.status.idle":"2021-06-20T05:58:24.976125Z","shell.execute_reply.started":"2021-06-20T05:58:24.941276Z","shell.execute_reply":"2021-06-20T05:58:24.975353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out2 = []","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:24.977249Z","iopub.execute_input":"2021-06-20T05:58:24.977729Z","iopub.status.idle":"2021-06-20T05:58:24.982152Z","shell.execute_reply.started":"2021-06-20T05:58:24.977692Z","shell.execute_reply":"2021-06-20T05:58:24.981216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for out in output:\n    out2.append(out.cpu().detach().numpy())","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:24.983856Z","iopub.execute_input":"2021-06-20T05:58:24.984281Z","iopub.status.idle":"2021-06-20T05:58:24.993368Z","shell.execute_reply.started":"2021-06-20T05:58:24.984189Z","shell.execute_reply":"2021-06-20T05:58:24.992491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = np.array(out2).reshape(len(out2))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:24.994885Z","iopub.execute_input":"2021-06-20T05:58:24.995131Z","iopub.status.idle":"2021-06-20T05:58:25.003726Z","shell.execute_reply.started":"2021-06-20T05:58:24.995107Z","shell.execute_reply":"2021-06-20T05:58:25.002984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': dftest['id'], 'target':out})","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:25.00511Z","iopub.execute_input":"2021-06-20T05:58:25.00547Z","iopub.status.idle":"2021-06-20T05:58:25.015259Z","shell.execute_reply.started":"2021-06-20T05:58:25.005428Z","shell.execute_reply":"2021-06-20T05:58:25.014492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T05:58:25.016542Z","iopub.execute_input":"2021-06-20T05:58:25.016965Z","iopub.status.idle":"2021-06-20T05:58:25.271151Z","shell.execute_reply.started":"2021-06-20T05:58:25.016931Z","shell.execute_reply":"2021-06-20T05:58:25.270327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}