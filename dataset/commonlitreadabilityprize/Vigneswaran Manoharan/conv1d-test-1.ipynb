{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CONV1D Model Tryout - 1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from __future__ import print_function, division\nfrom builtins import range","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:35:08.479312Z","iopub.execute_input":"2021-07-02T19:35:08.479737Z","iopub.status.idle":"2021-07-02T19:35:08.484431Z","shell.execute_reply.started":"2021-07-02T19:35:08.4797Z","shell.execute_reply":"2021-07-02T19:35:08.483229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, GlobalMaxPooling1D\nfrom keras.layers import Conv1D, MaxPooling1D, Embedding\nfrom keras.models import Model\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:35:08.487164Z","iopub.execute_input":"2021-07-02T19:35:08.48765Z","iopub.status.idle":"2021-07-02T19:35:16.517349Z","shell.execute_reply.started":"2021-07-02T19:35:08.487605Z","shell.execute_reply":"2021-07-02T19:35:16.516187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:35:16.51889Z","iopub.execute_input":"2021-07-02T19:35:16.519225Z","iopub.status.idle":"2021-07-02T19:35:16.526772Z","shell.execute_reply.started":"2021-07-02T19:35:16.519195Z","shell.execute_reply":"2021-07-02T19:35:16.525149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some configuration\nMAX_SEQUENCE_LENGTH = 1400\nMAX_VOCAB_SIZE = 40000\nEMBEDDING_DIM = 300\nVALIDATION_SPLIT = 0.1\nBATCH_SIZE = 128\nEPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:35:16.528902Z","iopub.execute_input":"2021-07-02T19:35:16.529554Z","iopub.status.idle":"2021-07-02T19:35:16.541245Z","shell.execute_reply.started":"2021-07-02T19:35:16.529507Z","shell.execute_reply":"2021-07-02T19:35:16.540267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load in pre-trained word vectors\nprint('Loading word vectors...')\nword2vec = {}\nwith open(os.path.join('../input/glove6b/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n  # is just a space-separated text file in the format:\n  # word vec[0] vec[1] vec[2] ...\n  for line in f:\n    values = line.split()\n    word = values[0]\n    vec = np.asarray(values[1:], dtype='float32')\n    word2vec[word] = vec\nprint('Found %s word vectors.' % len(word2vec))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:35:16.54277Z","iopub.execute_input":"2021-07-02T19:35:16.543353Z","iopub.status.idle":"2021-07-02T19:36:07.878237Z","shell.execute_reply.started":"2021-07-02T19:35:16.543314Z","shell.execute_reply":"2021-07-02T19:36:07.877092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:07.87957Z","iopub.execute_input":"2021-07-02T19:36:07.879936Z","iopub.status.idle":"2021-07-02T19:36:07.964135Z","shell.execute_reply.started":"2021-07-02T19:36:07.879901Z","shell.execute_reply":"2021-07-02T19:36:07.962774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:07.965903Z","iopub.execute_input":"2021-07-02T19:36:07.966385Z","iopub.status.idle":"2021-07-02T19:36:08.048825Z","shell.execute_reply.started":"2021-07-02T19:36:07.966337Z","shell.execute_reply":"2021-07-02T19:36:08.047686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.url_legal.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:08.051104Z","iopub.execute_input":"2021-07-02T19:36:08.051572Z","iopub.status.idle":"2021-07-02T19:36:08.061906Z","shell.execute_reply.started":"2021-07-02T19:36:08.051525Z","shell.execute_reply":"2021-07-02T19:36:08.060829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:08.063477Z","iopub.execute_input":"2021-07-02T19:36:08.063859Z","iopub.status.idle":"2021-07-02T19:36:08.080248Z","shell.execute_reply.started":"2021-07-02T19:36:08.063826Z","shell.execute_reply":"2021-07-02T19:36:08.079125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = train[\"excerpt\"].fillna(\"DUMMY_VALUE\").values\ntarget = train[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:08.08176Z","iopub.execute_input":"2021-07-02T19:36:08.082134Z","iopub.status.idle":"2021-07-02T19:36:08.093893Z","shell.execute_reply.started":"2021-07-02T19:36:08.082099Z","shell.execute_reply":"2021-07-02T19:36:08.092655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# convert the sentences (strings) into integers\ntokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\ntokenizer.fit_on_texts(sentences)\nsequences = tokenizer.texts_to_sequences(sentences)\n# print(\"sequences:\", sequences); exit()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:08.095654Z","iopub.execute_input":"2021-07-02T19:36:08.096082Z","iopub.status.idle":"2021-07-02T19:36:09.051539Z","shell.execute_reply.started":"2021-07-02T19:36:08.096028Z","shell.execute_reply":"2021-07-02T19:36:09.050452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max sequence length:\", max(len(s) for s in sequences))\nprint(\"min sequence length:\", min(len(s) for s in sequences))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.053087Z","iopub.execute_input":"2021-07-02T19:36:09.053418Z","iopub.status.idle":"2021-07-02T19:36:09.061985Z","shell.execute_reply.started":"2021-07-02T19:36:09.053387Z","shell.execute_reply":"2021-07-02T19:36:09.06081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = sorted(len(s) for s in sequences)\nprint(\"median sequence length:\", s[len(s) // 2])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.063297Z","iopub.execute_input":"2021-07-02T19:36:09.063662Z","iopub.status.idle":"2021-07-02T19:36:09.0767Z","shell.execute_reply.started":"2021-07-02T19:36:09.06357Z","shell.execute_reply":"2021-07-02T19:36:09.075435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max word index:\", max(max(seq) for seq in sequences if len(seq) > 0))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.078142Z","iopub.execute_input":"2021-07-02T19:36:09.078461Z","iopub.status.idle":"2021-07-02T19:36:09.104025Z","shell.execute_reply.started":"2021-07-02T19:36:09.078423Z","shell.execute_reply":"2021-07-02T19:36:09.102725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get word -> integer mapping\nword2idx = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word2idx))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.107803Z","iopub.execute_input":"2021-07-02T19:36:09.108244Z","iopub.status.idle":"2021-07-02T19:36:09.116751Z","shell.execute_reply.started":"2021-07-02T19:36:09.108208Z","shell.execute_reply":"2021-07-02T19:36:09.115418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pad sequences so that we get a N x T matrix\ndata = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', data.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.118796Z","iopub.execute_input":"2021-07-02T19:36:09.119266Z","iopub.status.idle":"2021-07-02T19:36:09.255326Z","shell.execute_reply.started":"2021-07-02T19:36:09.119234Z","shell.execute_reply":"2021-07-02T19:36:09.254225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(word2idx)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.256945Z","iopub.execute_input":"2021-07-02T19:36:09.257381Z","iopub.status.idle":"2021-07-02T19:36:09.265389Z","shell.execute_reply.started":"2021-07-02T19:36:09.257335Z","shell.execute_reply":"2021-07-02T19:36:09.264576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare embedding matrix\nprint('Filling pre-trained embeddings...')\nnum_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\nembedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\nfor word, i in word2idx.items():\n  if i < MAX_VOCAB_SIZE:\n    embedding_vector = word2vec.get(word)\n    if embedding_vector is not None:\n      # words not found in embedding index will be all zeros.\n      embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.266401Z","iopub.execute_input":"2021-07-02T19:36:09.266739Z","iopub.status.idle":"2021-07-02T19:36:09.389711Z","shell.execute_reply.started":"2021-07-02T19:36:09.266696Z","shell.execute_reply":"2021-07-02T19:36:09.388424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# load pre-trained word embeddings into an Embedding layer\n# note that we set trainable = False so as to keep the embeddings fixed\nembedding_layer = Embedding(\n  num_words,\n  EMBEDDING_DIM,\n  weights=[embedding_matrix],\n  input_length=MAX_SEQUENCE_LENGTH,\n  trainable=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.390924Z","iopub.execute_input":"2021-07-02T19:36:09.391218Z","iopub.status.idle":"2021-07-02T19:36:09.410693Z","shell.execute_reply.started":"2021-07-02T19:36:09.39119Z","shell.execute_reply":"2021-07-02T19:36:09.409568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Model","metadata":{}},{"cell_type":"code","source":"print('Building model...')\n# train a 1D convnet with global maxpooling\ninput_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\nx = embedding_layer(input_)\nx = Conv1D(512, 3, activation='relu')(x)\nx = MaxPooling1D(3)(x)\nx = Conv1D(256, 3, activation='relu')(x)\nx = MaxPooling1D(3)(x)\nx = Conv1D(128, 3, activation='relu')(x)\nx = GlobalMaxPooling1D()(x)\nx = Dense(128, activation='tanh')(x)\noutput = Dense(1, activation='linear')(x)\n\nmodel = Model(input_, output)\nmodel.compile(\n  loss='mse',\n  optimizer='adam',\n  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:09.412387Z","iopub.execute_input":"2021-07-02T19:36:09.412702Z","iopub.status.idle":"2021-07-02T19:36:09.902333Z","shell.execute_reply.started":"2021-07-02T19:36:09.412671Z","shell.execute_reply":"2021-07-02T19:36:09.901116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training model...')\nr = model.fit(\n  data,\n  target,\n  batch_size=BATCH_SIZE,\n  epochs=EPOCHS,\n  validation_split=VALIDATION_SPLIT\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:36:10.452414Z","iopub.execute_input":"2021-07-02T19:36:10.452806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot some data\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracies\nplt.plot(r.history['root_mean_squared_error'], label='rmse')\nplt.plot(r.history['val_root_mean_squared_error'], label='Val_rmse')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sent = test[\"excerpt\"].fillna(\"DUMMY_VALUE\").values\n# convert the sentences (strings) into integers\ntest_tokens = tokenizer.texts_to_sequences(test_sent)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pad sequences so that we get a N x T matrix\ntest_data = pad_sequences(test_tokens, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', test_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the mean AUC over each label\np = model.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = p","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:39:51.771108Z","iopub.execute_input":"2021-06-26T17:39:51.771549Z","iopub.status.idle":"2021-06-26T17:39:51.785727Z","shell.execute_reply.started":"2021-06-26T17:39:51.771513Z","shell.execute_reply":"2021-06-26T17:39:51.78449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}