{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport time\nimport string\nimport math\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn import linear_model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk import SnowballStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize as wt\nfrom nltk.stem import WordNetLemmatizer\nfrom transformers import BertTokenizer, BertConfig, TFBertModel\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom tensorflow.keras.metrics import RootMeanSquaredError\nimport xgboost as xgb\nimport tensorflow as tf\n\nstemmer = PorterStemmer()\nfrom IPython.core.display import display\nfrom scipy import stats\nfrom scipy.spatial import distance\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport string\n\nimport spacy\n\nnlp = spacy.load('en_core_web_sm')\n\nhrule = lambda x: \"=\" * x\nstop_words = stopwords.words('english')","metadata":{"_uuid":"bb9087c1-5d3b-4e12-93ad-01aa824f730f","_cell_guid":"541f8715-8877-4879-a3f7-91a714860b7a","collapsed":false,"papermill":{"duration":2.117838,"end_time":"2021-06-04T21:12:25.34148","exception":false,"start_time":"2021-06-04T21:12:23.223642","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:02.085724Z","iopub.execute_input":"2021-09-14T21:54:02.086061Z","iopub.status.idle":"2021-09-14T21:54:03.00102Z","shell.execute_reply.started":"2021-09-14T21:54:02.086029Z","shell.execute_reply":"2021-09-14T21:54:03.000116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduzione\n\nIl seguente notebook è stato creato per la partecipazione ad una competizione, ovvero CommonLit Readability, sulla piattaforma Kaggle. L'obiettivo della competizione consiste nel creare un modello per valutare la complessità di estratti di testo per l'uso in classe di grado 3-12 (sistema scolastico americano).\n\nViene fornito un trainset con estratti di testo e target (che indica la facilità di lettura) e un testset con soli estratti di testo.\n\nPer la valutazione del modello nella competizione viene usato la radice dell'errore quadratico medio dei valori target predetti sul testset.","metadata":{"_uuid":"9a4264a0-e9db-437e-a1fd-1c467788d06c","_cell_guid":"a62e90b5-9e8a-42e0-ac9f-c7c2b6784b21","trusted":true}},{"cell_type":"markdown","source":"# Caricamento dei dati","metadata":{"_uuid":"059422f8-ec0b-45ea-b486-e87c53f36c21","_cell_guid":"dfb5f6a5-d562-4f2d-97b1-1176acd89328","papermill":{"duration":0.033341,"end_time":"2021-06-04T21:12:25.408372","exception":false,"start_time":"2021-06-04T21:12:25.375031","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"_uuid":"77578ea7-31e7-45ee-8782-880f20e7d9cf","_cell_guid":"986558dc-230a-4c74-b9c8-b75a095d3b19","collapsed":false,"papermill":{"duration":0.144871,"end_time":"2021-06-04T21:12:25.58624","exception":false,"start_time":"2021-06-04T21:12:25.441369","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.002598Z","iopub.execute_input":"2021-09-14T21:54:03.002957Z","iopub.status.idle":"2021-09-14T21:54:03.047609Z","shell.execute_reply.started":"2021-09-14T21:54:03.002919Z","shell.execute_reply":"2021-09-14T21:54:03.046843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"e1ebd61b-3f0e-4ac1-854c-7cceb1cb06de","_cell_guid":"3fa4a239-2dc5-47ab-bd65-f77ef5e43e7f","collapsed":false,"papermill":{"duration":0.065726,"end_time":"2021-06-04T21:12:25.685177","exception":false,"start_time":"2021-06-04T21:12:25.619451","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.049407Z","iopub.execute_input":"2021-09-14T21:54:03.04975Z","iopub.status.idle":"2021-09-14T21:54:03.065765Z","shell.execute_reply.started":"2021-09-14T21:54:03.049714Z","shell.execute_reply":"2021-09-14T21:54:03.064958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"_uuid":"6e777612-45ef-4610-808c-365318f42b97","_cell_guid":"c343c29e-812c-4772-ba2b-939c3f97f567","collapsed":false,"papermill":{"duration":0.049089,"end_time":"2021-06-04T21:12:25.76812","exception":false,"start_time":"2021-06-04T21:12:25.719031","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.06741Z","iopub.execute_input":"2021-09-14T21:54:03.06781Z","iopub.status.idle":"2021-09-14T21:54:03.080229Z","shell.execute_reply.started":"2021-09-14T21:54:03.067769Z","shell.execute_reply":"2021-09-14T21:54:03.079149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisi dei dati\n\nInformazioni di base sul dataset","metadata":{"_uuid":"bf72a2a5-b9f2-46cd-b0ee-f75d87064e32","_cell_guid":"880e6d44-dc33-41dc-8dec-ad37008cdbf8","papermill":{"duration":0.033586,"end_time":"2021-06-04T21:12:25.83638","exception":false,"start_time":"2021-06-04T21:12:25.802794","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"print(hrule(50))\nprint(\"Dataset shape:\")\nprint(train.shape)\nprint(hrule(50))\ntrain.info()\nprint(hrule(50))","metadata":{"_uuid":"805923c1-086d-488e-9f24-33d5cecdf301","_cell_guid":"ff1a1bdb-f030-468e-962e-3b2beca7fa3b","collapsed":false,"papermill":{"duration":0.060706,"end_time":"2021-06-04T21:12:25.997993","exception":false,"start_time":"2021-06-04T21:12:25.937287","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.081702Z","iopub.execute_input":"2021-09-14T21:54:03.082241Z","iopub.status.idle":"2021-09-14T21:54:03.099509Z","shell.execute_reply.started":"2021-09-14T21:54:03.082204Z","shell.execute_reply":"2021-09-14T21:54:03.09858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(train)\nplt.show()","metadata":{"_uuid":"c4d044a0-0fab-47f6-a8fe-79cc321c86ac","_cell_guid":"fa208553-fc9a-406a-8bd0-79e7a509e506","collapsed":false,"papermill":{"duration":0.624598,"end_time":"2021-06-04T21:12:26.659048","exception":false,"start_time":"2021-06-04T21:12:26.03445","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.100616Z","iopub.execute_input":"2021-09-14T21:54:03.100964Z","iopub.status.idle":"2021-09-14T21:54:03.73691Z","shell.execute_reply.started":"2021-09-14T21:54:03.100912Z","shell.execute_reply":"2021-09-14T21:54:03.736038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Percentuale di valori nulli:","metadata":{"_uuid":"30196200-d4c7-4aa4-a8d1-16634fde5605","_cell_guid":"ca10d59f-7733-4e4b-9753-c0fd400bea53","papermill":{"duration":0.035414,"end_time":"2021-06-04T21:12:26.731393","exception":false,"start_time":"2021-06-04T21:12:26.695979","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"pd.DataFrame(train.isnull().sum() / train.shape[0]).T","metadata":{"_uuid":"beee9dce-207a-4454-a8f3-3cb74dcc0944","_cell_guid":"f9e0a14d-c5fb-43bd-88be-70abaec82ae6","collapsed":false,"papermill":{"duration":0.054916,"end_time":"2021-06-04T21:12:26.822835","exception":false,"start_time":"2021-06-04T21:12:26.767919","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.738465Z","iopub.execute_input":"2021-09-14T21:54:03.738905Z","iopub.status.idle":"2021-09-14T21:54:03.754329Z","shell.execute_reply.started":"2021-09-14T21:54:03.738862Z","shell.execute_reply":"2021-09-14T21:54:03.753388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset = train[train['license'].isna() & (train['url_legal'].isna() == False) |\n               (train['license'].isna() == False) & train['url_legal'].isna()]\nprint(\"Numero di occorrenze in cui url_legal è mancante e license è dato o viceversa: \" + str(len(subset)))","metadata":{"_uuid":"013cd6d3-130a-475e-9afe-94034e314a97","_cell_guid":"831cbe1d-a255-47ea-bafe-c79f8657d963","collapsed":false,"papermill":{"duration":0.058862,"end_time":"2021-06-04T21:12:26.921487","exception":false,"start_time":"2021-06-04T21:12:26.862625","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.758106Z","iopub.execute_input":"2021-09-14T21:54:03.758558Z","iopub.status.idle":"2021-09-14T21:54:03.76868Z","shell.execute_reply.started":"2021-09-14T21:54:03.758521Z","shell.execute_reply":"2021-09-14T21:54:03.767672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valoriMancanti = train.isnull().sum() / len(train)\nvaloriMancanti = valoriMancanti[valoriMancanti > 0]\nprint(\"Righe in cui mancano url_legal e license: \" + str(int(valoriMancanti[0] * 100)) + \"%\")","metadata":{"_uuid":"352c041d-6497-4461-ba27-14ef10c14d3c","_cell_guid":"2c1dab36-2577-4b0b-9ac6-f3221ea2f4cf","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.049543,"end_time":"2021-06-04T21:12:27.007839","exception":false,"start_time":"2021-06-04T21:12:26.958296","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:03.77092Z","iopub.execute_input":"2021-09-14T21:54:03.771413Z","iopub.status.idle":"2021-09-14T21:54:03.781001Z","shell.execute_reply.started":"2021-09-14T21:54:03.771376Z","shell.execute_reply":"2021-09-14T21:54:03.779936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alcuni dettagli statistici del dataset","metadata":{"_uuid":"2af8e939-eec9-4c49-ab2f-750ed5469283","_cell_guid":"fab4c12c-6222-47ba-81b0-852612f89bef","papermill":{"duration":0.037292,"end_time":"2021-06-04T21:12:27.083417","exception":false,"start_time":"2021-06-04T21:12:27.046125","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"train.describe()","metadata":{"_uuid":"249b5cd4-96b7-460b-a2cc-b79253f9c7ee","_cell_guid":"7fa2e7aa-93f2-4306-9078-942ece28ca6c","collapsed":false,"papermill":{"duration":0.059145,"end_time":"2021-06-04T21:12:27.180159","exception":false,"start_time":"2021-06-04T21:12:27.121014","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.78246Z","iopub.execute_input":"2021-09-14T21:54:03.78283Z","iopub.status.idle":"2021-09-14T21:54:03.80212Z","shell.execute_reply.started":"2021-09-14T21:54:03.782784Z","shell.execute_reply":"2021-09-14T21:54:03.801051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note\n* I valori mancanti sono solo nelle colonne url_legal e license, entrambe le colonne hanno per il 70% valori nulli.\n* License si riferisce a url_legal, dove manca un dato, mancherà anche l'altro.","metadata":{"_uuid":"9fd1f81f-b2f9-4a04-b3b9-c464df766d2b","_cell_guid":"a00dfd0c-03d8-4779-8eb8-269432d28513","papermill":{"duration":0.037353,"end_time":"2021-06-04T21:12:27.254301","exception":false,"start_time":"2021-06-04T21:12:27.216948","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"test","metadata":{"_uuid":"1a056c1a-5412-4f51-b466-f8e72870abe2","_cell_guid":"7aa8593a-f7c8-48e0-a25e-d557787f4538","collapsed":false,"papermill":{"duration":0.052143,"end_time":"2021-06-04T21:12:27.343481","exception":false,"start_time":"2021-06-04T21:12:27.291338","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.803534Z","iopub.execute_input":"2021-09-14T21:54:03.803893Z","iopub.status.idle":"2021-09-14T21:54:03.818186Z","shell.execute_reply.started":"2021-09-14T21:54:03.803857Z","shell.execute_reply":"2021-09-14T21:54:03.817326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(test)\nplt.show()","metadata":{"_uuid":"6f4543d2-31b2-4e7a-8ef5-072798df42b9","_cell_guid":"c9c508cf-96fd-4787-a840-f89205751341","collapsed":false,"papermill":{"duration":0.472753,"end_time":"2021-06-04T21:12:27.854186","exception":false,"start_time":"2021-06-04T21:12:27.381433","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:03.819306Z","iopub.execute_input":"2021-09-14T21:54:03.81956Z","iopub.status.idle":"2021-09-14T21:54:04.344765Z","shell.execute_reply.started":"2021-09-14T21:54:03.819536Z","shell.execute_reply":"2021-09-14T21:54:04.343892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset = test[test['license'].isna() & (test['url_legal'].isna() == False) |\n              (test['license'].isna() == False) & test['url_legal'].isna()]\nprint(\"Numero di occorrenze in cui url_legal è mancante e license è dato o viceversa: \" + str(len(subset)))","metadata":{"_uuid":"ce3ef36b-8202-45b1-afb6-d85ddadc7784","_cell_guid":"97c3156c-0ec2-47db-843e-795f5fd75cb4","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.05131,"end_time":"2021-06-04T21:12:27.945222","exception":false,"start_time":"2021-06-04T21:12:27.893912","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:04.346136Z","iopub.execute_input":"2021-09-14T21:54:04.346521Z","iopub.status.idle":"2021-09-14T21:54:04.356359Z","shell.execute_reply.started":"2021-09-14T21:54:04.346461Z","shell.execute_reply":"2021-09-14T21:54:04.355417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valoriMancanti = test.isnull().sum() / len(test)\nvaloriMancanti = valoriMancanti[valoriMancanti > 0]\nprint(\"Righe in cui mancano url_legal e license: \" + str(int(valoriMancanti[0] * 100)) + \"%\")","metadata":{"_uuid":"ba6fe97d-172a-4e28-98c6-0d2726c65d80","_cell_guid":"954e3524-200e-42f7-a16d-eb91b3f4830a","collapsed":false,"papermill":{"duration":0.050549,"end_time":"2021-06-04T21:12:28.03412","exception":false,"start_time":"2021-06-04T21:12:27.983571","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.357916Z","iopub.execute_input":"2021-09-14T21:54:04.358876Z","iopub.status.idle":"2021-09-14T21:54:04.372837Z","shell.execute_reply.started":"2021-09-14T21:54:04.358835Z","shell.execute_reply":"2021-09-14T21:54:04.37183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note\n* Il test set ha solo 7 righe\n* Non contiene standard error.","metadata":{"_uuid":"e7c425b0-3704-4613-96c2-4fa64a4bb6b6","_cell_guid":"072a1d33-5d84-4693-9893-c36cd3e62a2f","papermill":{"duration":0.039327,"end_time":"2021-06-04T21:12:28.11398","exception":false,"start_time":"2021-06-04T21:12:28.074653","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"markdown","source":"## Analisi del valore target","metadata":{"_uuid":"33cd5ac1-387c-47c9-bf99-ac1114edc159","_cell_guid":"5c9423d6-9d08-48b6-93c8-cbff37deccbf","papermill":{"duration":0.040527,"end_time":"2021-06-04T21:12:29.360779","exception":false,"start_time":"2021-06-04T21:12:29.320252","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"markdown","source":"Il target rappresenta la facilità di lettura di un testo. Un target alto indica un testo di facile lettura destinato a\nclassi di grado più basso.","metadata":{"_uuid":"9e6cd928-90f6-4569-b490-70de9597d7f0","_cell_guid":"9dde476c-49cb-40e4-9f79-d018f49fb90f","papermill":{"duration":0.040645,"end_time":"2021-06-04T21:12:29.443194","exception":false,"start_time":"2021-06-04T21:12:29.402549","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"train.query('target == 0')","metadata":{"_uuid":"17fb0a96-2573-49ef-add0-2b29d758f120","_cell_guid":"397d787c-dfa6-4598-b4bd-0fb79224eb3e","collapsed":false,"papermill":{"duration":0.062111,"end_time":"2021-06-04T21:12:29.546408","exception":false,"start_time":"2021-06-04T21:12:29.484297","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.377417Z","iopub.execute_input":"2021-09-14T21:54:04.379725Z","iopub.status.idle":"2021-09-14T21:54:04.397313Z","shell.execute_reply.started":"2021-09-14T21:54:04.379674Z","shell.execute_reply":"2021-09-14T21:54:04.396473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Possiamo notare che in questa particolare riga il target e lo standard_error è 0, questo perché il testo di riferimento\nè usato come comparatore, per cui tutte le altre righe hanno ricevuto diverse classificazioni in base alla facilità di\nlettura della riga con id *436ce79fe*. In particolare, le righe sono state valutate in base al modello\nBradley-Terry [1]. Se un testo è più facile da leggere rispetto al testo con id *436ce79fe*, allora questo riceverà un\n valore positivo, altrimenti sarà negativo.","metadata":{"_uuid":"db810566-a59f-4ebf-8395-c9c7a218b89f","_cell_guid":"788d8273-20aa-4bd0-af88-253ae5ad47ae","papermill":{"duration":0.041839,"end_time":"2021-06-04T21:12:29.630501","exception":false,"start_time":"2021-06-04T21:12:29.588662","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"we = stats.probplot(train.target, plot=plt)\nplt.show()","metadata":{"_uuid":"dd89d024-803f-4a4b-9028-7c76487adf13","_cell_guid":"34ed5dca-ff5a-4c2a-8ca6-54c776fb5ef0","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.201821,"end_time":"2021-06-04T21:12:29.873861","exception":false,"start_time":"2021-06-04T21:12:29.67204","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:04.399034Z","iopub.execute_input":"2021-09-14T21:54:04.399571Z","iopub.status.idle":"2021-09-14T21:54:04.533385Z","shell.execute_reply.started":"2021-09-14T21:54:04.399531Z","shell.execute_reply":"2021-09-14T21:54:04.532444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(train.target, kde=True, stat=\"density\").set_title('Target distribution')\nplt.show()","metadata":{"_uuid":"81237148-a118-45b6-bcfc-319ec238c04e","_cell_guid":"ccfdf0dc-cf5f-4c5a-b433-85a4e4abaa99","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.240916,"end_time":"2021-06-04T21:12:30.157769","exception":false,"start_time":"2021-06-04T21:12:29.916853","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:04.534702Z","iopub.execute_input":"2021-09-14T21:54:04.535044Z","iopub.status.idle":"2021-09-14T21:54:04.734284Z","shell.execute_reply.started":"2021-09-14T21:54:04.535009Z","shell.execute_reply":"2021-09-14T21:54:04.733337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ordinazione crescente dei dati in base al target","metadata":{"_uuid":"e89c94bb-1942-4596-bb44-230bfb5c731f","_cell_guid":"f3f8c56a-9fad-4d1c-833b-ebd24b7a238e","papermill":{"duration":0.042812,"end_time":"2021-06-04T21:12:30.243841","exception":false,"start_time":"2021-06-04T21:12:30.201029","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"display(train.sort_values(by=['target']).head())","metadata":{"_uuid":"3569640c-5bdf-4113-b5ca-78744e5b9fa7","_cell_guid":"b3a4895c-b91c-4891-988b-4009c36ecb0a","collapsed":false,"papermill":{"duration":0.061629,"end_time":"2021-06-04T21:12:30.348569","exception":false,"start_time":"2021-06-04T21:12:30.28694","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.735654Z","iopub.execute_input":"2021-09-14T21:54:04.736029Z","iopub.status.idle":"2021-09-14T21:54:04.752066Z","shell.execute_reply.started":"2021-09-14T21:54:04.735978Z","shell.execute_reply":"2021-09-14T21:54:04.751217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ordinazione decrescente dei dati in base al target","metadata":{"_uuid":"08fd157a-ec8b-4055-a77c-842bc2b17995","_cell_guid":"573ec97a-b785-4cfd-b745-7acaebc5d575","papermill":{"duration":0.043756,"end_time":"2021-06-04T21:12:30.436556","exception":false,"start_time":"2021-06-04T21:12:30.3928","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"display(train.sort_values(by=['target'], ascending=False).head())","metadata":{"_uuid":"25ce3856-c727-4e6b-b7e7-53c9a38acc69","_cell_guid":"76ca88d0-8ed8-4b62-9bef-d19ad06ffc36","collapsed":false,"papermill":{"duration":0.063134,"end_time":"2021-06-04T21:12:30.543809","exception":false,"start_time":"2021-06-04T21:12:30.480675","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.753363Z","iopub.execute_input":"2021-09-14T21:54:04.753731Z","iopub.status.idle":"2021-09-14T21:54:04.769992Z","shell.execute_reply.started":"2021-09-14T21:54:04.753693Z","shell.execute_reply":"2021-09-14T21:54:04.76905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ordinando il dataset in base ai valori del target vediamo che questo assume dei valori compresi tra -3.676268 e 1.711390. E' inoltre possibile notare che i campi url_legal e license sono presenti soprattutto nei casi dove il valore del target è più alto.","metadata":{"_uuid":"3188345c-7755-4350-88ec-2a4bff78638a","_cell_guid":"9f590519-28f3-400a-9e8a-45f2983dd5cb","papermill":{"duration":0.044277,"end_time":"2021-06-04T21:12:30.632959","exception":false,"start_time":"2021-06-04T21:12:30.588682","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"markdown","source":"### Riferimenti\n[1] https://www.kaggle.com/gunesevitan/commonlit-readability-prize-eda","metadata":{"_uuid":"4ca950f9-340f-41af-8b30-cda096be8753","_cell_guid":"d1a39b4d-a11c-469e-b0f9-c95211b48a68","papermill":{"duration":0.045986,"end_time":"2021-06-04T21:12:30.723422","exception":false,"start_time":"2021-06-04T21:12:30.677436","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"markdown","source":"## Analisi degli estratti","metadata":{"_uuid":"c1621b8e-0652-4329-991a-c006a6224f2e","_cell_guid":"94f68727-2144-4cce-9c0e-ab75c1411a01","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"markdown","source":"Analisi del numero di parole negli estratti di testo del campo excerpt","metadata":{"_uuid":"1c13c35c-0bfc-4ad7-974c-e237ca300a91","_cell_guid":"0a91a51c-7937-4ec4-b77b-bdcc8f9bdb28","trusted":true}},{"cell_type":"code","source":"count = train['excerpt'].str.split().str.len()\nprint(\"Numero di parole nel campo excerpt:\\n\", count)\nprint(\"Massimo numero di parole nel campo excerpt: \", max(count))","metadata":{"_uuid":"8c2595d4-5a1a-4f82-a649-cdd1c4e9b7cc","_cell_guid":"8982e38e-a748-4c94-82e7-329c37670a7e","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.77148Z","iopub.execute_input":"2021-09-14T21:54:04.77185Z","iopub.status.idle":"2021-09-14T21:54:04.831022Z","shell.execute_reply.started":"2021-09-14T21:54:04.771814Z","shell.execute_reply":"2021-09-14T21:54:04.829578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt_len'] = train['excerpt'].apply(\n    lambda x: len(x)\n)\ntrain['excerpt_word_count'] = train['excerpt'].apply(\n    lambda x: len(x.split(' '))\n)","metadata":{"_uuid":"83e0590b-2aa7-4482-94b1-6e67b598dc28","_cell_guid":"5c29d23f-bd49-41d6-9933-e392cdb49d7c","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.832349Z","iopub.execute_input":"2021-09-14T21:54:04.832683Z","iopub.status.idle":"2021-09-14T21:54:04.878218Z","shell.execute_reply.started":"2021-09-14T21:54:04.832647Z","shell.execute_reply":"2021-09-14T21:54:04.877485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lunghezza degli estratti di testo","metadata":{"_uuid":"cf1fbe61-f552-4e2e-86bc-78fd89c8b666","_cell_guid":"03df1aa0-eaed-4fab-9abe-d6a3c73c2de5","trusted":true}},{"cell_type":"code","source":"sns.kdeplot(train['excerpt_len']).set_title(\"Excerpt Len distribution\")\nplt.show()","metadata":{"_uuid":"e78658ec-eb5d-455c-a984-1c976211da32","_cell_guid":"e1b64535-527f-485e-9b10-5515f8523d7b","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:04.879426Z","iopub.execute_input":"2021-09-14T21:54:04.879779Z","iopub.status.idle":"2021-09-14T21:54:05.050812Z","shell.execute_reply.started":"2021-09-14T21:54:04.879743Z","shell.execute_reply":"2021-09-14T21:54:05.049843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Numero di parole degli estratti di testo","metadata":{"_uuid":"692ecd36-1bd8-4ae6-81a1-65ac3a986e4b","_cell_guid":"78395e66-3651-469d-8f0f-d808f5d14a92","trusted":true}},{"cell_type":"code","source":"sns.kdeplot(train['excerpt_word_count']).set_title(\"Excerpt word Count distribution\")\nplt.show()","metadata":{"_uuid":"7a1a14cc-2f97-4bea-b1e7-8861c073c412","_cell_guid":"3ab0cde1-0fef-4ff9-a4ca-79feff451c99","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:05.05559Z","iopub.execute_input":"2021-09-14T21:54:05.055847Z","iopub.status.idle":"2021-09-14T21:54:05.216955Z","shell.execute_reply.started":"2021-09-14T21:54:05.055821Z","shell.execute_reply":"2021-09-14T21:54:05.216141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"excerpt_len\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs excerpt_len\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()","metadata":{"_uuid":"3cca3e56-5461-4ae4-bd32-d85e50e031ae","_cell_guid":"c6997d2f-50ea-4c9d-84e1-9325b6df455d","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:05.219643Z","iopub.execute_input":"2021-09-14T21:54:05.219933Z","iopub.status.idle":"2021-09-14T21:54:05.719348Z","shell.execute_reply.started":"2021-09-14T21:54:05.219906Z","shell.execute_reply":"2021-09-14T21:54:05.718554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confrontando il valore target con la lunghezza degli estratti si può notare una leggera relazione. Gli estratti più\nlunghi tendono ad avere un valore target minore.","metadata":{"_uuid":"08ba498d-95d9-4e58-af6c-efef411a00b9","_cell_guid":"3a5a9670-29f8-46fc-be5f-98cb6080d645","trusted":true}},{"cell_type":"markdown","source":"### Parole uniche per ogni estratto","metadata":{"_uuid":"6cb2c0b1-0c10-470c-9152-37614a3c2161","_cell_guid":"03616967-2f00-417c-a37a-51cde7907e51","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"def uniqueWordCount(text):\n    text = text.lower()\n    words = text.split()\n    words = [word.strip('.,!;()[]') for word in words]\n    words = [word.replace(\"'s\", '') for word in words]\n\n    #finding unique\n    unique = []\n    for word in words:\n        if word not in unique:\n            unique.append(word)\n\n    return len(unique)\n\n\nuniqueWordCount(\"prova ciao Prova\")\ntrain['unique_word_count'] = train['excerpt'].apply(uniqueWordCount)\ntest['unique_word_count'] = test['excerpt'].apply(uniqueWordCount)","metadata":{"_uuid":"cb4074ac-597f-4bd2-baeb-b91c27d4004c","_cell_guid":"6beab03c-f4d8-4ed2-82ca-f50d4cb1740a","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:05.720665Z","iopub.execute_input":"2021-09-14T21:54:05.721032Z","iopub.status.idle":"2021-09-14T21:54:06.181379Z","shell.execute_reply.started":"2021-09-14T21:54:05.720993Z","shell.execute_reply":"2021-09-14T21:54:06.180576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(train['unique_word_count']).set_title(\"Unique word count distribution\")\nplt.show()","metadata":{"_uuid":"4e91d435-b372-4957-b24d-a703f50060f7","_cell_guid":"98c95ed6-c2f7-40db-bc8a-89527b1e7545","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:06.182635Z","iopub.execute_input":"2021-09-14T21:54:06.183162Z","iopub.status.idle":"2021-09-14T21:54:06.330928Z","shell.execute_reply.started":"2021-09-14T21:54:06.183123Z","shell.execute_reply":"2021-09-14T21:54:06.330015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"unique_word_count\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs unique words\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()","metadata":{"_uuid":"06ac1bd5-3a84-410f-8670-64a934781d5f","_cell_guid":"60434e04-edec-47c0-9a01-2d3b046013be","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:06.332324Z","iopub.execute_input":"2021-09-14T21:54:06.332675Z","iopub.status.idle":"2021-09-14T21:54:06.860153Z","shell.execute_reply.started":"2021-09-14T21:54:06.332638Z","shell.execute_reply":"2021-09-14T21:54:06.859352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analisi dell'errore standard\nDato che ci sono diverse valutazioni per ogni testo, lo standard_error viene in aiuto per misurare lo spread.","metadata":{"_uuid":"014915c6-ff50-4894-b74b-900aa4e4935a","_cell_guid":"98211c1a-0c28-4728-a424-77cd87622cb1","papermill":{"duration":0.045071,"end_time":"2021-06-04T21:12:30.813268","exception":false,"start_time":"2021-06-04T21:12:30.768197","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[],"trusted":true}},{"cell_type":"code","source":"stats.probplot(train.standard_error[train.standard_error != 0], plot=plt)\nplt.show()","metadata":{"_uuid":"9a9eeea5-9003-435d-b494-e30f076a847e","_cell_guid":"0b88619c-dd17-45cf-9d02-00a4ccb1940e","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.204351,"end_time":"2021-06-04T21:12:31.063944","exception":false,"start_time":"2021-06-04T21:12:30.859593","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:06.861483Z","iopub.execute_input":"2021-09-14T21:54:06.861827Z","iopub.status.idle":"2021-09-14T21:54:06.999335Z","shell.execute_reply.started":"2021-09-14T21:54:06.861791Z","shell.execute_reply":"2021-09-14T21:54:06.998422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(train.standard_error).set_title('standard_error distribution')\nplt.show()","metadata":{"_uuid":"3d15d47c-0f51-4d0f-a66b-59c41b059cbf","_cell_guid":"5a4f9820-4b71-4678-9772-c223d616ca2b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.430424,"end_time":"2021-06-04T21:12:31.540452","exception":false,"start_time":"2021-06-04T21:12:31.110028","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:07.000713Z","iopub.execute_input":"2021-09-14T21:54:07.001057Z","iopub.status.idle":"2021-09-14T21:54:07.343353Z","shell.execute_reply.started":"2021-09-14T21:54:07.001021Z","shell.execute_reply":"2021-09-14T21:54:07.342583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ordinazione crescente dei dati in base allo standard_error","metadata":{"_uuid":"84731c76-c090-4b38-b9be-6cb4e19313e3","_cell_guid":"6718ffea-c000-44d7-942e-57253bb242d8","papermill":{"duration":0.049827,"end_time":"2021-06-04T21:12:31.641289","exception":false,"start_time":"2021-06-04T21:12:31.591462","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"display(train.sort_values(by=['standard_error']).head())","metadata":{"_uuid":"6cf4935b-ea58-40ad-b510-2fd5fea65556","_cell_guid":"cdd6da64-c336-41c3-9886-39daa743793c","collapsed":false,"papermill":{"duration":0.065427,"end_time":"2021-06-04T21:12:31.75357","exception":false,"start_time":"2021-06-04T21:12:31.688143","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.346087Z","iopub.execute_input":"2021-09-14T21:54:07.34638Z","iopub.status.idle":"2021-09-14T21:54:07.366432Z","shell.execute_reply.started":"2021-09-14T21:54:07.346351Z","shell.execute_reply":"2021-09-14T21:54:07.365576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ordinazione decrescente dei dati in base allo standard_error","metadata":{"_uuid":"b9535ba8-f89e-4a0b-a3a1-e9c95f63cb92","_cell_guid":"58f07394-331c-4db8-9c76-695c1c38340d","papermill":{"duration":0.047757,"end_time":"2021-06-04T21:12:31.849566","exception":false,"start_time":"2021-06-04T21:12:31.801809","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"display(train.sort_values(by=['standard_error'], ascending=False).head())","metadata":{"_uuid":"7f1ae5ef-dcf4-4207-b80f-7855ca65df80","_cell_guid":"a1388b29-6bd9-43a0-9806-b5dcc4ee44d3","collapsed":false,"papermill":{"duration":0.071264,"end_time":"2021-06-04T21:12:31.974397","exception":false,"start_time":"2021-06-04T21:12:31.903133","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.367801Z","iopub.execute_input":"2021-09-14T21:54:07.368168Z","iopub.status.idle":"2021-09-14T21:54:07.385934Z","shell.execute_reply.started":"2021-09-14T21:54:07.36813Z","shell.execute_reply":"2021-09-14T21:54:07.384967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"standard_error\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs standard_error\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()","metadata":{"_uuid":"5123e237-845b-46e1-a6a3-51523a581167","_cell_guid":"4008eb18-31f4-47fe-b1c1-5bae55a18a35","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.614407,"end_time":"2021-06-04T21:12:32.637372","exception":false,"start_time":"2021-06-04T21:12:32.022965","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2021-09-14T21:54:07.387463Z","iopub.execute_input":"2021-09-14T21:54:07.387847Z","iopub.status.idle":"2021-09-14T21:54:07.91744Z","shell.execute_reply.started":"2021-09-14T21:54:07.387809Z","shell.execute_reply":"2021-09-14T21:54:07.916625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Osservando il grafico in cui viene tracciato lo standard_error rispetto al target senza la riga base, è possibile\nvedere una relazione. I testi con una facilità di lettura media tendono ad avere uno spread minore, mentre alle due\nestremità abbiamo un alto spread.\nLe opinioni soggettive dei valutatori variano molto quando valutano quegli estratti facili e difficili, ma danno\nopinioni più ravvicinate quando gli estratti hanno una difficoltà media.","metadata":{"_uuid":"79fe00ff-450c-4fc0-8801-d3dae3ca6df9","_cell_guid":"7c1a01fc-e883-4d93-b259-e99a7a74531c","papermill":{"duration":0.049693,"end_time":"2021-06-04T21:12:32.738307","exception":false,"start_time":"2021-06-04T21:12:32.688614","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[],"trusted":true}},{"cell_type":"markdown","source":"# Preprocessing\n\nLo scopo di questo processo è quello di pulire i dati e renderli leggibili per i modelli di machine learning che\nverranno implementati.\n\n## Data cleaning\n\nAndiamo a pulire i dati attraverso varie funzioni. Per prima cosa rimuoviamo le \"stop words\".","metadata":{"_uuid":"fa73736b-6e5c-4b6e-b20e-8cf6200ac43e","_cell_guid":"0c52b72b-83d1-4bce-ac2a-60135e9871a5","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"def rimuoviStopWords(testo):\n    tokenized_text = wt(testo)\n    sms_processed = []\n    for word in tokenized_text:\n        if word not in set(stopwords.words('english')):\n            sms_processed.append(word)\n\n    clean_text = \" \".join(sms_processed)\n\n    return clean_text\n\n\nprint(\"Testo prima della funzione rimuoviStopWords:\\n\" + train['excerpt'][1])\nprint(hrule(20))\nprint(\"Testo dopo la funzione:\\n\" + rimuoviStopWords(train['excerpt'][1]))","metadata":{"_uuid":"586e1f44-8d98-45a0-9430-6beaa7f0fe88","_cell_guid":"6933866a-89aa-4229-8a48-c0c429558e2d","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.918686Z","iopub.execute_input":"2021-09-14T21:54:07.919009Z","iopub.status.idle":"2021-09-14T21:54:07.958746Z","shell.execute_reply.started":"2021-09-14T21:54:07.918974Z","shell.execute_reply":"2021-09-14T21:54:07.957956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rimuoviamo i segni di punteggiatura.","metadata":{"_uuid":"d7e764d9-c08a-4e62-a8ce-5952e98696b8","_cell_guid":"db880789-82ee-4105-a4e5-eb9645b2e829","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"def rimuoviPunteggiatura(testo):\n    return testo.translate(str.maketrans('', '', string.punctuation))\n\n\nprint(\"Testo prima della funzione rimuoviPunteggiatura:\\n\" + train['excerpt'][1])\nprint(hrule(20))\nprint(\"Testo dopo la funzione:\\n\" + rimuoviPunteggiatura(train['excerpt'][1]))","metadata":{"_uuid":"5dbbad47-5361-4c2b-8c77-0cbb596c8ee1","_cell_guid":"31192ef8-971a-450e-8b25-ba82e6aa1945","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.959887Z","iopub.execute_input":"2021-09-14T21:54:07.960375Z","iopub.status.idle":"2021-09-14T21:54:07.96673Z","shell.execute_reply.started":"2021-09-14T21:54:07.960339Z","shell.execute_reply":"2021-09-14T21:54:07.965694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rimuoviamo eventuali link.","metadata":{"_uuid":"ef5a4be8-659f-456e-94d4-5bbd9c978aff","_cell_guid":"32e1743a-1ca4-41cd-b7f0-ae685115e48c","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"def rimuoviLink(testo):\n    clean_text = re.sub('https?://\\S+|www\\.\\S+', '', testo)\n    return clean_text\n\n\ntest_string = \"Il link http://www.google.com/ andrebbe rimosso\"\nprint(test_string)\nprint(hrule(20))\nprint(rimuoviLink(test_string))","metadata":{"_uuid":"540c6148-921a-4032-b2b4-bacc0ab62c34","_cell_guid":"3dd1afeb-c639-4033-bf65-751cf515fa9b","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.968229Z","iopub.execute_input":"2021-09-14T21:54:07.968774Z","iopub.status.idle":"2021-09-14T21:54:07.976111Z","shell.execute_reply.started":"2021-09-14T21:54:07.968737Z","shell.execute_reply":"2021-09-14T21:54:07.975215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Eliminiamo i numeri.","metadata":{"_uuid":"10d36b9d-fb8d-479e-b16e-74178488298b","_cell_guid":"340c7d3d-d03f-442b-b227-4e505730cb0d","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"def rimuoviNumeri(testo):\n    clean_text = re.sub(r'\\d+', '', testo)\n    return clean_text\n\n\ntest_string = \"Il numero 34 va rimosso\"\nprint(test_string)\nprint(hrule(20))\nprint(rimuoviNumeri(test_string))","metadata":{"_uuid":"28f125f9-5246-4bb5-a96c-e783c290d07e","_cell_guid":"46a4fde8-b0d8-439a-bdb5-c8a13dd0d0a3","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.977663Z","iopub.execute_input":"2021-09-14T21:54:07.978337Z","iopub.status.idle":"2021-09-14T21:54:07.986073Z","shell.execute_reply.started":"2021-09-14T21:54:07.9783Z","shell.execute_reply":"2021-09-14T21:54:07.985101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(testo):\n    testo = testo.lower()  #Lets make it lowercase\n    testo = rimuoviStopWords(testo)\n    testo = rimuoviPunteggiatura(testo)\n    testo = rimuoviNumeri(testo)\n    testo = rimuoviLink(testo)\n    return testo\n\n\ntrain['excerpt_clean'] = train['excerpt'].apply(clean)\ntest['excerpt_clean'] = test['excerpt'].apply(clean)\n\ntrain.head()","metadata":{"_uuid":"74af6bf9-e08f-47f8-9eff-8df209be4f19","_cell_guid":"2f70e3d7-57c9-4dd0-b73c-22e9448d0283","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:54:07.987356Z","iopub.execute_input":"2021-09-14T21:54:07.987733Z","iopub.status.idle":"2021-09-14T21:55:21.637199Z","shell.execute_reply.started":"2021-09-14T21:54:07.987697Z","shell.execute_reply":"2021-09-14T21:55:21.636426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stemming\n\nIn questo processo facciamo la derivazione delle parole negli estratti. Proveremo con lo stemming, una funzione\nefficiente per questo tipo di calcolo. Lo stemming produce delle parole derivate chiamate \"stem\". Ogni stem potrebbe\nnon essere una parola reale nel dizionario inglese (in questo caso i testi sono in inglese).\nNLTK mette a disposizione due tipi di stemmer: Porter Stemmer e Snowball Stemmer. Snowball stemmer è leggermente\nmigliore rispetto al Porter Stemmer, per cui verrà utilizzato questo.","metadata":{"_uuid":"8f2ca276-9861-415a-b5ca-04528d77afe5","_cell_guid":"329e069b-2409-4b0b-85b6-d2869bf8ee9d","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"stemmer = SnowballStemmer(language='english')\n\ntokens = train['excerpt'][1].split()\nclean_text = ' '\n\nfor token in tokens:\n    print(token + ' --> ' + stemmer.stem(token))","metadata":{"_uuid":"c4884f19-2b2c-4930-8cf4-321bd3e4a284","_cell_guid":"d64fc18f-4758-4a7c-aaee-8d5aee4baa84","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:21.638486Z","iopub.execute_input":"2021-09-14T21:55:21.638866Z","iopub.status.idle":"2021-09-14T21:55:21.661559Z","shell.execute_reply.started":"2021-09-14T21:55:21.63883Z","shell.execute_reply":"2021-09-14T21:55:21.659623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stemWord(text):\n    stemmer = SnowballStemmer(language='english')\n    tokens = text.split()\n    clean_text = ' '\n    for token in tokens:\n        clean_text = clean_text + \" \" + stemmer.stem(token)\n    return clean_text\n\n\nprint(\"Testo prima della funzione stemWord: \" + train['excerpt'][1])\nprint(\"Testo dopo la funzione: \" + stemWord(train['excerpt'][1]))","metadata":{"_uuid":"9d2b770d-7a0d-40df-945a-900a3807e77b","_cell_guid":"e9a9d5b6-b4b6-4918-8fe9-1c3e7d338271","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:21.674735Z","iopub.execute_input":"2021-09-14T21:55:21.674991Z","iopub.status.idle":"2021-09-14T21:55:21.684014Z","shell.execute_reply.started":"2021-09-14T21:55:21.674967Z","shell.execute_reply":"2021-09-14T21:55:21.683147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt_clean'] = train['excerpt_clean'].apply(stemWord)\ntest['excerpt_clean'] = test['excerpt_clean'].apply(stemWord)","metadata":{"_uuid":"cf0e1e5c-d50f-478b-a417-6d0899f8513d","_cell_guid":"5a08b6bf-e4b3-444b-8999-99aa4e5aebbf","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:21.685209Z","iopub.execute_input":"2021-09-14T21:55:21.685556Z","iopub.status.idle":"2021-09-14T21:55:26.051083Z","shell.execute_reply.started":"2021-09-14T21:55:21.685522Z","shell.execute_reply":"2021-09-14T21:55:26.050165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lemmatization\n\nQuesto processo è simile allo stemming, con la differenza che la funzione lemmatization, data una parola, dà in output\nuna sua derivata che è sempre una parola esistente nel dizionario inglese.","metadata":{"_uuid":"07020bde-c657-4672-a937-048ad50edf8a","_cell_guid":"7118900a-6d1d-4549-909a-2d9df7558208","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"def lemmatizeWord(text):\n    tokens = nlp(text)\n    clean_text = ' '\n    for token in tokens:\n        clean_text = clean_text + \" \" + token.lemma_\n\n    return clean_text\n\n\nprint(\"Testo prima della funzione lemmatizeWord: \" + train['excerpt'][1])\nprint(\"Testo dopo la funzione: \" + lemmatizeWord(train['excerpt'][1]))","metadata":{"_uuid":"d256c173-64e7-4670-bb50-88b994243258","_cell_guid":"fdde4363-dc7b-45a9-b131-b5d07a3429ab","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:26.052336Z","iopub.execute_input":"2021-09-14T21:55:26.052678Z","iopub.status.idle":"2021-09-14T21:55:26.102775Z","shell.execute_reply.started":"2021-09-14T21:55:26.052641Z","shell.execute_reply":"2021-09-14T21:55:26.101977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Purtroppo però, a differenza dello Stemming,\nquesta funzione non è efficiente e impiegherebbe molto tempo per essere eseguito su tutti i testi del dataset.\n\nUna volta puliti gli estratti, facciamo un'ulteriore analisi per assicurarci che le correlazioni trovate continuano ad\nessere valide.","metadata":{"_uuid":"5eb98d54-eee4-48e0-8032-b5ce8d6458cf","_cell_guid":"81fca757-aeb4-477a-a64c-32822b5e7e5b","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"train['clean_excerpt_len'] = train['excerpt_clean'].apply(\n    lambda x: len(x)\n)","metadata":{"_uuid":"d0db5244-0148-4ab1-902b-d7937214079f","_cell_guid":"efbfb14c-0df9-4b22-a026-447f2243397f","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:26.104031Z","iopub.execute_input":"2021-09-14T21:55:26.104403Z","iopub.status.idle":"2021-09-14T21:55:26.111692Z","shell.execute_reply.started":"2021-09-14T21:55:26.104366Z","shell.execute_reply":"2021-09-14T21:55:26.110626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt_len'] = train['excerpt'].apply(\n    lambda x: len(x)\n)\n\nsns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"excerpt_len\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs excerpt_len\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()\n\nsns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"clean_excerpt_len\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs clean_excerpt_len\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()","metadata":{"_uuid":"a1a44f5e-ea75-4eb3-861b-7e9733855d78","_cell_guid":"2c798b27-fed7-451a-a8f2-29fb6fe1e03b","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:26.11329Z","iopub.execute_input":"2021-09-14T21:55:26.113631Z","iopub.status.idle":"2021-09-14T21:55:27.50771Z","shell.execute_reply.started":"2021-09-14T21:55:26.113596Z","shell.execute_reply":"2021-09-14T21:55:27.506934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La correlazione tra la lunghezza del testo e il valore target è stata preservata. Mostriamo la matrice di correlazione\nper osservare le differenze.","metadata":{"_uuid":"e5cd43fc-8097-4284-86f6-cd291f4f9e78","_cell_guid":"c3f49e8c-f353-4467-9ebb-07b3b5656c8c","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"df = pd.DataFrame(train, columns=['target', 'excerpt_len', 'clean_excerpt_len'])\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","metadata":{"_uuid":"9fc58029-b06a-49dc-a238-6603ba960841","_cell_guid":"43fddced-db33-4d44-93b9-f562a5c80f45","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:27.508926Z","iopub.execute_input":"2021-09-14T21:55:27.509276Z","iopub.status.idle":"2021-09-14T21:55:27.751259Z","shell.execute_reply.started":"2021-09-14T21:55:27.509226Z","shell.execute_reply":"2021-09-14T21:55:27.750477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vediamo ora se è stata preservata la correlazione tra le il numero di parole uniche in un testo e il target relativo","metadata":{"_uuid":"45f2ae86-b1d3-4cfb-9435-59f1f1da5ea1","_cell_guid":"2af93715-b383-4d82-80e1-34e6e92ce21d","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"train['clean_unique_word_count'] = train['excerpt_clean'].apply(uniqueWordCount)\n\nsns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"unique_word_count\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs clean_excerpt_len\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()\n\nsns.jointplot(\n    data=train[train.standard_error != 0],\n    x=\"target\",\n    y=\"clean_unique_word_count\",\n    kind=\"hex\",\n    height=8)\nplt.suptitle(\"target vs clean_excerpt_len\", font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()\n\ndf = pd.DataFrame(train, columns=['target', 'unique_word_count', 'clean_unique_word_count'])\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","metadata":{"_uuid":"5d5e5d7c-6114-4494-bb74-81b1f67c672a","_cell_guid":"e79423b3-4a3e-4225-9d47-a3d253afa35b","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:27.752493Z","iopub.execute_input":"2021-09-14T21:55:27.752829Z","iopub.status.idle":"2021-09-14T21:55:29.461035Z","shell.execute_reply.started":"2021-09-14T21:55:27.752794Z","shell.execute_reply":"2021-09-14T21:55:29.4602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In questo caso la correlazione non solo è stata preservata, ma è anche aumentata dopo il processo di data cleaning","metadata":{"_uuid":"d15bda5b-a8d8-429f-b6b3-cbaa38c92777","_cell_guid":"0e9e1786-41ca-4eda-963e-5b97c20ca7e3","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"markdown","source":"# Modelli\n\n## Bag of words e TF-IDF\n\nGli algoritmi di machine learning non capiscono caratteri o parole, per questo motivo abbiamo la necessità di trasformare i nostri estratti di testo in numeri. Questo processo viene chiamato \"tokenizzazione\". Tra gli algoritmi di tokenizzazione più conosciuti ci sono:\n* CountVectorizer\n* TfidfVectorizer\n\nIl primo semplicemente conta le occorrenze di una parola all'interno di un estratto e quindi restituisce un array di interi. Il secondo, un po' più complesso, assegna un punteggio ad ogni parola restituendo un array di float.","metadata":{"_uuid":"b10197f4-beed-4274-835c-01d9e242dd70","_cell_guid":"54a27bff-3787-410d-958a-0be78594381d","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"cv = CountVectorizer(stop_words='english')\ntv = TfidfVectorizer(stop_words='english')\n\na = \"Data mining is a beautiful subject, I like it!\"\nb = \"Data mining is the best subject\"\n\ncv_score = cv.fit_transform([a, b])\ntv_score = tv.fit_transform([a, b])\n\ndef matrix_to_list(matrix):\n    matrix = matrix.toarray()\n    return matrix.tolist()\n\ncv_score_list = matrix_to_list(cv_score)\ntv_score_list = matrix_to_list(tv_score)\n\nprint(\"tfidf_a  tfidf_b  count_a count_b   word\")\nprint(\"-\"*41)\nfor i in range(6):\n    print(\"  {:.3f}    {:.3f}        {:}       {:}   {:}\".format(tv_score_list[0][i],\n                                               tv_score_list[1][i],\n                                               cv_score_list[0][i],\n                                               cv_score_list[1][i],\n                                               cv.get_feature_names()[i]))","metadata":{"_uuid":"d63e3e07-bc84-40b2-ac85-4575c4b3d771","_cell_guid":"cf775a16-439d-436a-9601-eef819f972ed","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:29.462208Z","iopub.execute_input":"2021-09-14T21:55:29.46256Z","iopub.status.idle":"2021-09-14T21:55:29.474229Z","shell.execute_reply.started":"2021-09-14T21:55:29.462531Z","shell.execute_reply":"2021-09-14T21:55:29.473406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si può notare come il punteggio per ogni parola ottenuto con TfidfVectorizer sia particolare: le parole \"best\" e \"data\" sono contenute lo stesso numero di volte nella stringa b, eppure hanno ottenuto un punteggio diverso. Questo perché TfidfVectorizer tiene conto della frequenza del termine negli estratti di testo, infatti \"best\" non era contenuto nella prima stringa, mentre \"data\" sì.","metadata":{"_uuid":"bd058dfc-66aa-434c-bb12-0632c081aa1e","_cell_guid":"16c80435-4181-4fb4-b417-8188594aec32","trusted":true}},{"cell_type":"markdown","source":"## Linear Regression Unigram\n\nIl primo modello è una semplice regressione lineare allenato con la rappresentazione del bag of words.\n\nLa dicitura Unigram sta a significare che nel momento in cui facciamo la tokenizzazione, dividiamo il testo parola per parola assegnando uno score ad ognuna di esse.","metadata":{"_uuid":"8a8e1b8c-8a99-4811-b8b0-823bb2382322","_cell_guid":"ac1cecd7-e67d-4d9e-a0b4-9b275e2ca576","trusted":true}},{"cell_type":"code","source":"corpus = ['This is a useful document for testing']\nvectorizer = CountVectorizer(ngram_range=(1, 1))\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())","metadata":{"_uuid":"2d31e98b-c0a4-47bc-a9e4-fead71a3bb1c","_cell_guid":"fbdf289b-f8d6-412c-8664-080f003e266c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:29.475555Z","iopub.execute_input":"2021-09-14T21:55:29.476048Z","iopub.status.idle":"2021-09-14T21:55:29.487677Z","shell.execute_reply.started":"2021-09-14T21:55:29.47601Z","shell.execute_reply":"2021-09-14T21:55:29.486625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sulla base di questo costruiamo il modello di regressione lineare. Per prima cosa trasformiamo i dati in dei vettori, dopo procediamo la divisione del dataset in trainset e testset.","metadata":{"_uuid":"3fc31ed3-0071-4d24-8f91-4f4c4a862eb2","_cell_guid":"c7c1ab0a-7cf4-4eb8-837a-7612cc184be9","trusted":true}},{"cell_type":"code","source":"rmse = lambda y_true, y_pred: np.sqrt(mse(y_true, y_pred))\nrmse_loss = lambda Estimator, X, y: rmse(y, Estimator.predict(X))","metadata":{"_uuid":"0528afd1-7872-42e8-85c2-f87a12bbcd72","_cell_guid":"a6292f59-bd49-43cd-98b0-3fd2932b5ca1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:29.489426Z","iopub.execute_input":"2021-09-14T21:55:29.489777Z","iopub.status.idle":"2021-09-14T21:55:29.497195Z","shell.execute_reply.started":"2021-09-14T21:55:29.489743Z","shell.execute_reply":"2021-09-14T21:55:29.496166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train['excerpt_clean']\ny = train['target']\n\nprint(len(x), len(y))\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nprint(len(x_train), len(y_train))\nprint(len(x_test), len(y_test))","metadata":{"_uuid":"2b39312a-1064-4d30-b6d1-070a7b4a0bd3","_cell_guid":"315a3486-16c5-4db1-8e07-0fb9aa8b673f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:29.498777Z","iopub.execute_input":"2021-09-14T21:55:29.499204Z","iopub.status.idle":"2021-09-14T21:55:29.51046Z","shell.execute_reply.started":"2021-09-14T21:55:29.499137Z","shell.execute_reply":"2021-09-14T21:55:29.509452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Costruiamo il modello usando CountVectorizer","metadata":{"_uuid":"1f088031-836f-4f77-bfa5-2ce22e98afec","_cell_guid":"c711dabc-587c-46c5-b987-39cb66610ade","execution":{"iopub.status.busy":"2021-09-03T09:56:05.638073Z","iopub.execute_input":"2021-09-03T09:56:05.638514Z","iopub.status.idle":"2021-09-03T09:56:05.648738Z","shell.execute_reply.started":"2021-09-03T09:56:05.638478Z","shell.execute_reply":"2021-09-03T09:56:05.646817Z"},"trusted":true}},{"cell_type":"code","source":"model = make_pipeline(\n    CountVectorizer(ngram_range=(1, 1)),\n    LinearRegression(),\n)\n\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\nprint(f' RMSE: {rmse(y_test, y_pred):.4f}')","metadata":{"_uuid":"7ffd895f-201b-41d4-ba5f-6a36045ade9a","_cell_guid":"461c17e6-9fbd-491a-ac12-f6ea0fad1485","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:29.512106Z","iopub.execute_input":"2021-09-14T21:55:29.512505Z","iopub.status.idle":"2021-09-14T21:55:30.093707Z","shell.execute_reply.started":"2021-09-14T21:55:29.512468Z","shell.execute_reply":"2021-09-14T21:55:30.092513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.histplot(y_test, color=\"green\", ax=ax, label='Testset', kde=True, stat=\"density\", linewidth=0)\nsns.histplot(y_pred, color=\"orange\", ax=ax, label='Prediction', kde=True, stat=\"density\", linewidth=0)\nax.legend()\nplt.show()","metadata":{"_uuid":"1df6259d-5871-4b50-872c-7cc0966f32bd","_cell_guid":"8a0f8966-5f0f-4cc9-9a4d-983327f045f4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:30.095282Z","iopub.execute_input":"2021-09-14T21:55:30.095975Z","iopub.status.idle":"2021-09-14T21:55:30.417551Z","shell.execute_reply.started":"2021-09-14T21:55:30.095929Z","shell.execute_reply":"2021-09-14T21:55:30.41673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ora ricostruiamo il modello usando questa volta TfidfVectorizer","metadata":{"_uuid":"9deb9584-0751-4897-bdfe-26fbb3312412","_cell_guid":"7d7ee437-e9c0-49b7-99d5-6b553e6c62ea","trusted":true}},{"cell_type":"code","source":"model = make_pipeline(\n    TfidfVectorizer(ngram_range=(1, 1)),\n    LinearRegression(),\n)\n\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\nprint(f' RMSE: {rmse(y_test, y_pred):.4f}')","metadata":{"_uuid":"83e26102-be07-45b0-bc65-c0dbef7213f7","_cell_guid":"4857e713-cbea-4079-9f20-d747f8e9ff67","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:30.418848Z","iopub.execute_input":"2021-09-14T21:55:30.419189Z","iopub.status.idle":"2021-09-14T21:55:30.892984Z","shell.execute_reply.started":"2021-09-14T21:55:30.419153Z","shell.execute_reply":"2021-09-14T21:55:30.891815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.histplot(y_test, color=\"green\", ax=ax, label='Testset', kde=True, stat=\"density\", linewidth=0)\nsns.histplot(y_pred, color=\"orange\", ax=ax, label='Prediction', kde=True, stat=\"density\", linewidth=0)\nax.legend()\nplt.show()","metadata":{"_uuid":"91f7dc4c-6f60-4f46-8ba3-eb4256c75762","_cell_guid":"44a29895-7c8a-45a0-abad-29507cb6f096","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:30.897697Z","iopub.execute_input":"2021-09-14T21:55:30.898095Z","iopub.status.idle":"2021-09-14T21:55:31.180753Z","shell.execute_reply.started":"2021-09-14T21:55:30.898055Z","shell.execute_reply":"2021-09-14T21:55:31.179964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TfidfVectorizer è migliore di CountVectorizer perché non si concentra solo sulla frequenza delle parole presenti negli estratti di testo, ma fornisce anche l'importanza delle parole. TfidfVectorizer si basa sulla logica che le parole troppo comuni e le parole troppo rare non sono entrambe statisticamente importanti per trovare uno schema. Per questo motivo, a seguire, verrà utilizzato TfidfVectorizer per i modelli di regressione lineare.","metadata":{"_uuid":"8ae0c016-e0bb-47bc-b91f-9efc6d305c37","_cell_guid":"10c79fdb-ff4a-4b90-b7e8-a81fdc0b8428","trusted":true}},{"cell_type":"markdown","source":"## Linear Regression Bigram\n\nNel Bigram la divisione del testo non avviene parola per parola come in Unigram, ma vengono prese due parole per volta.","metadata":{"_uuid":"dd73a1f8-8b14-4844-890b-f1c712b107c3","_cell_guid":"26358106-d07b-4ac6-90b8-643ae80ce3b1","trusted":true}},{"cell_type":"code","source":"corpus = ['This is a useful document for testing']\nvectorizer = TfidfVectorizer(ngram_range=(2, 2))\nX = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())","metadata":{"_uuid":"11e7009f-ce2c-4de1-a34f-8c86472b1561","_cell_guid":"f92124f5-32ed-4b53-8007-40f443d7d2f4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:31.182092Z","iopub.execute_input":"2021-09-14T21:55:31.182466Z","iopub.status.idle":"2021-09-14T21:55:31.190914Z","shell.execute_reply.started":"2021-09-14T21:55:31.182419Z","shell.execute_reply":"2021-09-14T21:55:31.189983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Costruiamo il modello","metadata":{"_uuid":"5cbcc8e9-0dfa-4369-b5ee-e1f9c00e8b0d","_cell_guid":"15f644c4-3edb-4a6b-9c02-1bd75f94ceb7","trusted":true}},{"cell_type":"code","source":"model = make_pipeline(\n    TfidfVectorizer(ngram_range=(2, 2)),\n    LinearRegression(),\n)\n\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\nprint(f' RMSE: {rmse(y_test, y_pred):.4f}')","metadata":{"_uuid":"9067e187-64c8-4d14-ae8a-7af8e072c071","_cell_guid":"20ac5c8b-2607-499b-8340-059e30242ebe","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:31.192295Z","iopub.execute_input":"2021-09-14T21:55:31.192642Z","iopub.status.idle":"2021-09-14T21:55:32.16532Z","shell.execute_reply.started":"2021-09-14T21:55:31.192606Z","shell.execute_reply":"2021-09-14T21:55:32.16432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.histplot(y_test, color=\"green\", ax=ax, label='Testset', kde=True, stat=\"density\", linewidth=0)\nsns.histplot(y_pred, color=\"orange\", ax=ax, label='Prediction', kde=True, stat=\"density\", linewidth=0)\nax.legend()\nplt.show()","metadata":{"_uuid":"5eb96f09-fc42-4885-9f62-bd3fc1bd5284","_cell_guid":"19a4b162-7bda-46e3-a4ad-6246f90aa407","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:32.170002Z","iopub.execute_input":"2021-09-14T21:55:32.172487Z","iopub.status.idle":"2021-09-14T21:55:32.474204Z","shell.execute_reply.started":"2021-09-14T21:55:32.172438Z","shell.execute_reply":"2021-09-14T21:55:32.473402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ridge Regression","metadata":{"_uuid":"3fbbaf84-d6cc-4043-9a08-32df3e413548","_cell_guid":"a3ec6bc1-3b40-47cd-9799-06b0d2828a7e","trusted":true}},{"cell_type":"code","source":"# Unigram\nmodel = make_pipeline(\n    TfidfVectorizer(binary=True, ngram_range=(1,1)),\n    Ridge(fit_intercept=True, normalize=False),\n)\n\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\nprint(f' RMSE: {rmse(y_test, y_pred):.4f}')","metadata":{"_uuid":"934828e9-41cc-4c82-8608-f73d7176149d","_cell_guid":"748bc919-c288-493a-bb9d-3a15f3e0dd52","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:32.475509Z","iopub.execute_input":"2021-09-14T21:55:32.475838Z","iopub.status.idle":"2021-09-14T21:55:32.848711Z","shell.execute_reply.started":"2021-09-14T21:55:32.475802Z","shell.execute_reply":"2021-09-14T21:55:32.847678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.histplot(y_test, color=\"green\", ax=ax, label='Testset', kde=True, stat=\"density\", linewidth=0)\nsns.histplot(y_pred, color=\"orange\", ax=ax, label='Prediction', kde=True, stat=\"density\", linewidth=0)\nax.legend()\nplt.show()","metadata":{"_uuid":"f4994fe3-c435-42b7-8eb0-46e51bf8311d","_cell_guid":"03429725-4470-4959-8940-22337013d893","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:32.853277Z","iopub.execute_input":"2021-09-14T21:55:32.855489Z","iopub.status.idle":"2021-09-14T21:55:33.133116Z","shell.execute_reply.started":"2021-09-14T21:55:32.855441Z","shell.execute_reply":"2021-09-14T21:55:33.132326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extreme Gradient Boosting","metadata":{"_uuid":"155c0335-cc2d-4b98-8958-735b611950c2","_cell_guid":"0e9e7391-3e83-4176-a5c7-fb589a993390","trusted":true}},{"cell_type":"code","source":"model = make_pipeline(\n    CountVectorizer(ngram_range=(1, 1)),\n    xgb.XGBRegressor(),\n)\n\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\nprint(f' RMSE: {rmse(y_test, y_pred):.4f}')","metadata":{"_uuid":"1c07f2fe-4337-4afa-897e-c7144f9451e8","_cell_guid":"7c01d8af-9268-48d6-add5-10088d04c54d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:33.134372Z","iopub.execute_input":"2021-09-14T21:55:33.134711Z","iopub.status.idle":"2021-09-14T21:55:35.915424Z","shell.execute_reply.started":"2021-09-14T21:55:33.134674Z","shell.execute_reply":"2021-09-14T21:55:35.914665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.histplot(y_test, color=\"green\", ax=ax, label='Testset', kde=True, stat=\"density\", linewidth=0)\nsns.histplot(y_pred, color=\"orange\", ax=ax, label='Prediction', kde=True, stat=\"density\", linewidth=0)\nax.legend()\nplt.show()","metadata":{"_uuid":"38302dd5-b44c-45e2-9367-d0b73f88eb22","_cell_guid":"dcb9106b-084b-41b9-abe0-7103fd273c77","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:35.918765Z","iopub.execute_input":"2021-09-14T21:55:35.920443Z","iopub.status.idle":"2021-09-14T21:55:36.198742Z","shell.execute_reply.started":"2021-09-14T21:55:35.920408Z","shell.execute_reply":"2021-09-14T21:55:36.197951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GloVe Embeddings","metadata":{"_uuid":"5607fa08-7d15-4a29-ad32-1847c0138e2d","_cell_guid":"64517de0-42f3-451f-a00f-0e5d605b7c0e","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"markdown","source":"GloVe è un algoritmo di apprendimento per ottenere rappresentazioni vettoriali per le parole. L'addestramento viene eseguito su statistiche globali aggregate di co-occorrenza parola-parola (embedding) da un corpus e le rappresentazioni risultanti mostrano interessanti sottostrutture lineari dello spazio vettoriale di parole. Ma se invece di eseguire l'addestramento sugli embedding, potessi usare gli embedding già appresi, dove i ricercatori hanno già fatto il duro lavoro di trasformare le parole in vettori e quei vettori sono stati dimostrati?\n\nI word embedding preaddestrati sono gli embedding appresi in un'attività che vengono utilizzati per risolvere un'altra attività simile. Questi embedding vengono addestrati su set di dati di grandi dimensioni, salvati e quindi utilizzati per risolvere altre attività. Gli embedding di parole pre-addestrati sono una forma di Transfer Learning.","metadata":{"_uuid":"21639252-a9a1-4e5c-8ab3-506bfe4397f7","_cell_guid":"43a6211e-b6f0-4f6b-9146-9225b25bf2e9","trusted":true}},{"cell_type":"code","source":"glove_embeddings = dict()\nf = open('/kaggle/input/glove6b100d/glove.6B.100d.txt')\nprint(f)\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    glove_embeddings[word] = coefs\nf.close()","metadata":{"_uuid":"8f3b1ed0-fb79-4215-aac0-1976b3cb5065","_cell_guid":"d566cf3a-6694-40b5-82a8-bae3427a5680","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:36.199967Z","iopub.execute_input":"2021-09-14T21:55:36.200327Z","iopub.status.idle":"2021-09-14T21:55:52.43538Z","shell.execute_reply.started":"2021-09-14T21:55:36.200291Z","shell.execute_reply":"2021-09-14T21:55:52.434347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Caricato il file contenenti gli embedding preaddestrati, possiamo vedere una peculiarià dei vettori di GloVe: la distanza euclidea tra due vettori di parole fornisce un metodo efficace per misurare la somiglianza linguistica o semantica delle parole corrispondenti. Ad esempio, ecco le parole più vicine alla parola \"computer\":","metadata":{"_uuid":"fd599585-e42d-4bf6-a3d4-ee73eacaabb8","_cell_guid":"0ff709d4-a310-4547-81c0-d50834f1a38a","trusted":true}},{"cell_type":"code","source":"computer = glove_embeddings['computer']\ntolerance = 5\n\nfor w_vec in glove_embeddings:\n    if distance.euclidean(computer, glove_embeddings[w_vec]) < tolerance:\n        print(w_vec)","metadata":{"_uuid":"adf48e89-7f64-4ad2-bb86-28b1259cefbc","_cell_guid":"df80b265-9812-4154-a58d-6573e9b05313","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:52.436763Z","iopub.execute_input":"2021-09-14T21:55:52.43714Z","iopub.status.idle":"2021-09-14T21:55:58.62515Z","shell.execute_reply.started":"2021-09-14T21:55:52.437103Z","shell.execute_reply":"2021-09-14T21:55:58.624106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ora possiamo creare il modello trasformando gli estratti di testo in vettori.","metadata":{"_uuid":"669f1eb7-ad47-4212-b878-75929338d9c5","_cell_guid":"75502c01-1544-48d5-a543-609c7eab14cb","trusted":true}},{"cell_type":"code","source":"def sent2vec(s):\n    words = str(s).lower()\n    words = wt(words)\n    M = []\n    for w in words:\n        try:\n            M.append(glove_embeddings[w])\n        except:\n            continue\n    M = np.array(M)\n    v = M.sum(axis=0)\n    if type(v) != np.ndarray:\n        return np.zeros(50)\n    return v / np.sqrt((v ** 2).sum())","metadata":{"_uuid":"ba59537b-3624-42bb-96bc-e56aa5195f86","_cell_guid":"33cc9f5c-df87-4a36-a871-75597165ad7d","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:58.626467Z","iopub.execute_input":"2021-09-14T21:55:58.627396Z","iopub.status.idle":"2021-09-14T21:55:58.633805Z","shell.execute_reply.started":"2021-09-14T21:55:58.62736Z","shell.execute_reply":"2021-09-14T21:55:58.632963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train.excerpt, train.target, random_state=42, test_size=0.1,\n                                                  shuffle=True)\n\nxtrain_glove = np.array([sent2vec(x) for x in xtrain])\nxvalid_glove = np.array([sent2vec(x) for x in xvalid])\n\nclf = Ridge(fit_intercept=True, normalize=False),\nclf = xgb.XGBRegressor(max_depth=6, n_estimators=230, colsample_bytree=0.8,\n                       subsample=0.8, nthread=10, learning_rate=0.1)\n\nclf.fit(xtrain_glove, ytrain)\npredictions = clf.predict(xvalid_glove)\n\nprint(\"RMSE: %f \" % rmse(yvalid, predictions))","metadata":{"_uuid":"fc8c5592-5af7-4bf5-aa25-71a78fb0772a","_cell_guid":"d5f028e7-3090-46f3-b9a3-ca8b03ffa92b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:55:58.635281Z","iopub.execute_input":"2021-09-14T21:55:58.635884Z","iopub.status.idle":"2021-09-14T21:56:15.1876Z","shell.execute_reply.started":"2021-09-14T21:55:58.635842Z","shell.execute_reply":"2021-09-14T21:56:15.186707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert\n\nIntroduciamo un nuovo modello chiamato BERT, che sta per  Bidirectional Encoder Representations from Transformers. A differenza dei precedenti modelli, BERT è progettato per pre-addestrare rappresentazioni bidirezionali profonde da testo senza etichetta condizionando contemporaneamente il contesto sinistro e destro in tutti i livelli. Di conseguenza, possiamo utilizzare BERT pre-addestrato come base e con un solo livello di output aggiuntivo si possono creare modelli all'avanguardia per un'ampia gamma di attività, come risposta alle domande e inferenza linguistica, senza sostanziali modifiche specifiche dell'architettura.\n\nBERT è concettualmente semplice ed empiricamente potente, è stato addestrato con gli obiettivi di modellazione del linguaggio mascherato (MLM) e di previsione della frase successiva (NSP). È efficiente nel prevedere token mascherati e NLU in generale, ma non è ottimale per la generazione di testo.","metadata":{"_uuid":"a3897976-5678-47f0-92d1-a4b5e3931949","_cell_guid":"b19f05e3-d121-4434-bff8-dccc45c7ee39","trusted":true}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('../input/huggingface-bert/bert-large-uncased/vocab.txt', do_lower_case=True)","metadata":{"_uuid":"70f7d755-ac33-4b76-8da4-7dcee81c3fb6","_cell_guid":"7968242e-76cf-4eda-a35a-d23c991668d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:56:15.188918Z","iopub.execute_input":"2021-09-14T21:56:15.189308Z","iopub.status.idle":"2021-09-14T21:56:15.228827Z","shell.execute_reply.started":"2021-09-14T21:56:15.189268Z","shell.execute_reply":"2021-09-14T21:56:15.227987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I dati sono codificati secondo i requisiti BERT. C'è una funzione molto utile chiamata encode_plus fornita nella classe Tokenizer. Può eseguire senza problemi le seguenti operazioni:\n\n* Tokenizzare il testo\n* Aggiungi token speciali per la predizione del testo - [CLS] e [SEP], il primo indica l'inizio di una prima frase e il secondo indica l'inizio delle frasi successive.\n* Crea dei token ID\n* Riempie le frasi con token PAD in modo che abbiano una lunghezza comune\n* Crea maschere di attenzione per i token PAD di cui sopra","metadata":{"_uuid":"6f734bf3-3a15-4e91-a01a-0f6d4d449436","_cell_guid":"e87ea23a-011d-4b98-bdf2-a2630a8f5571","trusted":true}},{"cell_type":"code","source":"maximum_length = 120\n\ndef bert_encode(data) :\n  input_ids = []\n  attention_masks = []\n\n  for i in range(len(data.excerpt)):\n      encoded = tokenizer.encode_plus(\n        data.excerpt[i],\n        add_special_tokens=True,\n        max_length=maximum_length,\n        pad_to_max_length=True,\n        return_attention_mask=True,\n      )\n\n      input_ids.append(encoded['input_ids'])\n      attention_masks.append(encoded['attention_mask'])\n  return np.array(input_ids),np.array(attention_masks)","metadata":{"_uuid":"e904ebfa-e9fe-4c04-858d-de8863db64bf","_cell_guid":"9914a8ef-e3df-4680-94ef-1ba092476ebc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:56:15.230034Z","iopub.execute_input":"2021-09-14T21:56:15.230555Z","iopub.status.idle":"2021-09-14T21:56:15.237451Z","shell.execute_reply.started":"2021-09-14T21:56:15.230516Z","shell.execute_reply":"2021-09-14T21:56:15.236553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ids,train_attention_masks = bert_encode(train)\ntest_input_ids,test_attention_masks = bert_encode(test)","metadata":{"_uuid":"89c42345-eb9f-49d3-a602-8976f0a49f8b","_cell_guid":"6cf9a259-fc7a-4456-ac43-1459644c9de9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:56:15.238698Z","iopub.execute_input":"2021-09-14T21:56:15.239078Z","iopub.status.idle":"2021-09-14T21:56:30.76303Z","shell.execute_reply.started":"2021-09-14T21:56:15.239033Z","shell.execute_reply":"2021-09-14T21:56:30.762187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(bert_model):\n  input_ids = tf.keras.Input(shape=(maximum_length,),dtype='int32')\n  attention_masks = tf.keras.Input(shape=(maximum_length,),dtype='int32')\n\n  output = bert_model([input_ids,attention_masks])\n  output = output[1]\n\n  output = tf.keras.layers.Dense(1)(output)\n  model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n  model.compile(tf.keras.optimizers.Adam(lr=6e-6), loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n  return model","metadata":{"_uuid":"154303ca-fc3a-49f8-b6cc-51265750eeb8","_cell_guid":"d4f64a12-7c7e-451a-86dc-1c60c2865431","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:56:30.768867Z","iopub.execute_input":"2021-09-14T21:56:30.769124Z","iopub.status.idle":"2021-09-14T21:56:30.775419Z","shell.execute_reply.started":"2021-09-14T21:56:30.769098Z","shell.execute_reply":"2021-09-14T21:56:30.773989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config=BertConfig()\nconfig.output_hidden_states=False\nmodel = TFBertModel.from_pretrained('../input/huggingface-bert/bert-base-uncased/tf_model.h5', config=config)","metadata":{"_uuid":"6f5dc245-d2dc-4008-968a-1664ab6401ae","_cell_guid":"17a7df4d-9b8c-42ab-b551-9013f3a4d7c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:56:30.777493Z","iopub.execute_input":"2021-09-14T21:56:30.777966Z","iopub.status.idle":"2021-09-14T21:56:37.508583Z","shell.execute_reply.started":"2021-09-14T21:56:30.77793Z","shell.execute_reply":"2021-09-14T21:56:37.50785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = create_model(model)\nbert_model.summary()","metadata":{"_uuid":"0d892f24-c1b4-400f-860a-51730adc6e08","_cell_guid":"4ed179f7-5e0a-4093-83ce-8e027be0a951","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:56:37.509881Z","iopub.execute_input":"2021-09-14T21:56:37.510228Z","iopub.status.idle":"2021-09-14T21:56:38.969029Z","shell.execute_reply.started":"2021-09-14T21:56:37.510192Z","shell.execute_reply":"2021-09-14T21:56:38.968041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = bert_model.fit([train_input_ids,train_attention_masks],train.target,validation_split=0.3, epochs=2, batch_size=10)","metadata":{"_uuid":"755965be-80b6-4dbb-9921-3ce400d13cf6","_cell_guid":"75c6ba73-f7fc-4133-b555-742976b5acb0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:57:16.707629Z","iopub.execute_input":"2021-09-14T21:57:16.707969Z","iopub.status.idle":"2021-09-14T21:58:40.013036Z","shell.execute_reply.started":"2021-09-14T21:57:16.707936Z","shell.execute_reply":"2021-09-14T21:58:40.012266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribuzione dell'errore a confronto tra il testset e la sua predizione effettuata:","metadata":{"_uuid":"c9703b6b-c1ea-4444-8ee7-9e95f63e26f9","_cell_guid":"806657d9-2484-4605-b255-a7f015e044ef","pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-08-31T16:56:19.074553Z","iopub.execute_input":"2021-08-31T16:56:19.074906Z","iopub.status.idle":"2021-08-31T16:56:19.081595Z","shell.execute_reply.started":"2021-08-31T16:56:19.074873Z","shell.execute_reply":"2021-08-31T16:56:19.07994Z"},"trusted":true}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_uuid":"e32d2cb9-66ac-483c-99ca-ba4ee0707c73","_cell_guid":"92d7b4ad-9ac5-411b-b0a1-e2d90e1e2fd1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:58:40.014952Z","iopub.execute_input":"2021-09-14T21:58:40.015197Z","iopub.status.idle":"2021-09-14T21:58:40.162421Z","shell.execute_reply.started":"2021-09-14T21:58:40.015173Z","shell.execute_reply":"2021-09-14T21:58:40.161659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisi dei risultati","metadata":{"_uuid":"fb6d87a2-55b1-4f63-b447-3b30cef5a705","_cell_guid":"f2c9e57a-7cc3-4c2a-b1ba-1b0a0f5e595c","trusted":true}},{"cell_type":"markdown","source":"## Modelli TF-IDF\n\nAbbiamo utilizzato la funzione tf-idf per misurare l'importanza dei termini rispetto alla collezione degli estratti di testo, implementandolo all'interno dei modelli\n* Linear Regression\n* Ridge Regression\n* Extreme Gradient Boosting\n\nIn particolare nel modello di linear regression abbiamo potuto notare come Unigram fornisca un risultato migliore rispetto a Bigram. Non è comune che i modelli Bigram abbiano prestazioni peggiori dei modelli Unigram, ma ci sono situazioni in cui può accadere, in particolare, aggiungendo relazioni aggiuntive che possono portare ad overfitting. Inoltre, nell'analisi dei dati abbiamo riportato una relazione riguardante il numero di parole uniche negli estratti di testo e il target, relazione di cui tf-idf tiene conto e che probabilmente è meno accentuata utilizzando Bigram.\n\nIn seguito mostreremo una breve ricapitolazione su come si comportano i tre modelli con Unigram, Bigram e Trigram per osservarne le differenze.","metadata":{"_uuid":"d835516b-1fbc-43f8-ba9f-eaf0bc836db5","_cell_guid":"2ebc1b47-b382-4d08-b8c7-5af4eeb18d57","trusted":true}},{"cell_type":"code","source":"def training(model, X_train, y_train, X_test, y_test, model_name, ngram_range):\n    t1 = time.time()\n\n    model = make_pipeline(\n        TfidfVectorizer(binary=True, ngram_range=ngram_range),\n        model,\n    )\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    RMSE = rmse(y_test, y_pred)\n\n    t2 = time.time()\n    training_time = t2 - t1\n\n    print(\"--- Model:\", model_name, \"---\")\n    print(\"RMSE: \", RMSE)\n    print(\"Training time:\", training_time)\n    print(\"\\n\")","metadata":{"_uuid":"d0f4bbb8-275e-4cbd-8b2e-9ed9d946cb7e","_cell_guid":"265f1f13-c202-4be5-86b7-bf451cd7996e","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:58:40.164066Z","iopub.execute_input":"2021-09-14T21:58:40.164431Z","iopub.status.idle":"2021-09-14T21:58:40.170595Z","shell.execute_reply.started":"2021-09-14T21:58:40.164389Z","shell.execute_reply":"2021-09-14T21:58:40.169643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LinearRegression()\nridge = Ridge(fit_intercept=True, normalize=False)\nxgbr = xgb.XGBRegressor()\n\nmodels = [lr, ridge, xgbr]\n\nmodelnames = [\"Linear Regression\", \"Ridge Regression\", \"Extreme Gradient Boosting\"]\n\nX = train[\"excerpt_clean\"]\ny = train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nn_gram_dict = {\"Unigram\": (1, 1), \"Unigrams + Bigrams\": (1, 2), \"Bigrams alone\": (2, 2),\n               \"Unigrams + Bigrams + Trigrams\": (1, 3), \"Trigrams alone\": (3, 3)}\n\nfor n_gram in n_gram_dict.keys():\n    print(\"\\033[1m \" + n_gram + \" \\n \\033[0m\")\n    for i in range(0, len(models)):\n        training(model=models[i], X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n                 model_name=modelnames[i], ngram_range=n_gram_dict[n_gram])\n    print(\"*\" * 40)","metadata":{"_uuid":"715d41af-4102-4215-b6bb-a44e0bcc8e5d","_cell_guid":"a83fdc7d-4c72-40a0-b933-003d3157da89","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:58:40.172679Z","iopub.execute_input":"2021-09-14T21:58:40.173092Z","iopub.status.idle":"2021-09-14T21:58:44.817192Z","shell.execute_reply.started":"2021-09-14T21:58:40.172984Z","shell.execute_reply":"2021-09-14T21:58:44.814843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Il risultato migliore è ottenuto dal modello Ridge Regression Unigram con la radice dell'errore quadratico medio pari a 0.7096.","metadata":{"_uuid":"d9fdd9cb-d004-4997-99fb-3fb9fe990d8e","_cell_guid":"370fdfab-9e22-4a75-9d0c-313faf2ad961","trusted":true}},{"cell_type":"markdown","source":"## GloVe Embeddings\n\nLa radice dell'errore quadratico medio ottenuto con GloVe è 0.6851. Per ottenere questo risultato è stato necessario aggiustare alcuni parametri in modo ottimale, ma la cosa più importante di tutte sono stati usati gli estratti di testo originali e non quelli \"puliti\". GloVe, infatti, è un modello basato su word embeddings e come tale riesce a scovare regolarità linguistiche[2]. Proviamo a ricostruire il modello utilizzando excerpt_clean e osserviamo le differenze.","metadata":{"_uuid":"dd5f6b4b-8d1d-41fa-8cf0-dfcc327d89a1","_cell_guid":"1b650926-d00b-42f2-9b00-f85285809162","trusted":true}},{"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train.excerpt_clean, train.target, random_state=42, test_size=0.1,\n                                                  shuffle=True)\n\nxtrain_glove = np.array([sent2vec(x) for x in xtrain])\nxvalid_glove = np.array([sent2vec(x) for x in xvalid])\n\nclf = Ridge(fit_intercept=True, normalize=False),\nclf = xgb.XGBRegressor(max_depth=6, n_estimators=230, colsample_bytree=0.8,\n                       subsample=0.8, nthread=10, learning_rate=0.1)\n\nclf.fit(xtrain_glove, ytrain)\npredictions = clf.predict(xvalid_glove)\n\nprint(\"RMSE: %f \" % rmse(yvalid, predictions))","metadata":{"_uuid":"50c6e168-8daa-4398-a4f3-8c76d74d29d8","_cell_guid":"b2db5670-6fcf-4016-b41a-d40f11a3d93f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:58:44.817944Z","iopub.status.idle":"2021-09-14T21:58:44.818323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'RMSE è decisamente più alto e ciò significa che attraverso il data cleaning, la sintassi degli estratti viene alterata.","metadata":{"_uuid":"8391fc5f-3409-45a9-be5b-43cb775dd7cb","_cell_guid":"7b2dcab0-caf7-4515-8dca-9b16e273ed4a","trusted":true}},{"cell_type":"markdown","source":"### Riferimenti\n[2] X. Zhu e G. de Melo, «Sentence Analogies: Linguistic Regularities in Sentence Embeddings,» in Proceedings of the 28th International Conference on Computational Linguistics, 2020, p. 3389–3400.","metadata":{"_uuid":"f4b41798-0840-4ac5-acab-0cc06c939fe5","_cell_guid":"1a917e47-72bd-487d-a85b-0c440f66be5a","trusted":true}},{"cell_type":"markdown","source":"## BERT\n\nPer lo stesso motivo descritto in GloVe, anche in BERT sono stati utilizzati gli estratti di testo originali e non quelli puliti. Attraverso questo modello è stato ottenuto il punteggio migliore sulla classifica pubblica della competizione con un RMSE pari a 0.590","metadata":{"_uuid":"db148cad-83ff-497e-91ff-3461b7732168","_cell_guid":"97794f98-83a6-4618-a4eb-8343913dd7e7","trusted":true}},{"cell_type":"markdown","source":"# Submission","metadata":{"_uuid":"ea3ec203-d511-4d5b-ada6-2e5fb5a40f2a","_cell_guid":"e2a2c1e2-053f-40f5-804c-5bc3084aa98a","pycharm":{"name":"#%% md\n"},"trusted":true}},{"cell_type":"code","source":"config=BertConfig()\nconfig.output_hidden_states=False\nmodel = TFBertModel.from_pretrained('../input/huggingface-bert/bert-base-uncased/tf_model.h5', config=config)","metadata":{"_uuid":"cddb3630-9415-4376-b9d6-9565155dd45a","_cell_guid":"2fbaba9b-dec8-404e-a743-d673f5658ad1","collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:58:49.569981Z","iopub.execute_input":"2021-09-14T21:58:49.570392Z","iopub.status.idle":"2021-09-14T21:58:56.081172Z","shell.execute_reply.started":"2021-09-14T21:58:49.570358Z","shell.execute_reply":"2021-09-14T21:58:56.080308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = create_model(model)\nhistory = bert_model.fit([train_input_ids,train_attention_masks],train.target, epochs=2, batch_size=10)\n\ny_pred = bert_model.predict([test_input_ids,test_attention_masks])\n\n\nsample['target']= y_pred\nsample.to_csv('submission.csv', index=False)\nsample","metadata":{"_uuid":"6b84e6cf-c113-476f-b893-0156d7bddeac","_cell_guid":"d8b93621-fe86-4e24-9539-30567eb2ebfd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-14T21:58:56.082715Z","iopub.execute_input":"2021-09-14T21:58:56.083233Z","iopub.status.idle":"2021-09-14T22:00:53.625929Z","shell.execute_reply.started":"2021-09-14T21:58:56.083192Z","shell.execute_reply":"2021-09-14T22:00:53.62513Z"},"trusted":true},"execution_count":null,"outputs":[]}]}