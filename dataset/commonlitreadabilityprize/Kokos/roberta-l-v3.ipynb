{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport pandas as pd\n\nimport gc\nfrom tqdm import tqdm\n\nimport transformers\nfrom transformers import AdamW\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom transformers import get_cosine_schedule_with_warmup\n\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-14T10:40:08.255225Z","iopub.execute_input":"2021-07-14T10:40:08.255636Z","iopub.status.idle":"2021-07-14T10:40:08.264596Z","shell.execute_reply.started":"2021-07-14T10:40:08.255575Z","shell.execute_reply":"2021-07-14T10:40:08.263636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:08.265782Z","iopub.execute_input":"2021-07-14T10:40:08.266315Z","iopub.status.idle":"2021-07-14T10:40:08.274426Z","shell.execute_reply.started":"2021-07-14T10:40:08.266279Z","shell.execute_reply":"2021-07-14T10:40:08.273682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\n\nprint(\"# Using device: \", device)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:08.277458Z","iopub.execute_input":"2021-07-14T10:40:08.277784Z","iopub.status.idle":"2021-07-14T10:40:08.284577Z","shell.execute_reply.started":"2021-07-14T10:40:08.277759Z","shell.execute_reply":"2021-07-14T10:40:08.283603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_tmp = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntrain_df_tmp.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:09.212379Z","iopub.execute_input":"2021-07-14T10:40:09.212723Z","iopub.status.idle":"2021-07-14T10:40:09.338972Z","shell.execute_reply.started":"2021-07-14T10:40:09.21269Z","shell.execute_reply":"2021-07-14T10:40:09.338202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_converter(input_txt):\n    out_txt = input_txt.replace(\"\\'re\", \"'re\")\n    out_txt = out_txt.replace(\"\\n\", \" \")\n    out_txt = out_txt.replace(\"\\'t\", \"'t\")\n    out_txt = out_txt.replace(\"\\'s\", \"'s\")    \n    out_txt = out_txt.replace(\";\", \",\")    \n    out_txt = out_txt.replace(\"\\'v\", \"'v\")\n    out_txt = out_txt.replace(\"\\'\", \"'\")    \n    \n    return out_txt\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:09.941494Z","iopub.execute_input":"2021-07-14T10:40:09.94182Z","iopub.status.idle":"2021-07-14T10:40:09.94653Z","shell.execute_reply.started":"2021-07-14T10:40:09.94179Z","shell.execute_reply":"2021-07-14T10:40:09.945739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_tmp['excerpt'] = train_df_tmp.excerpt.apply(lambda x: text_converter(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:10.351995Z","iopub.execute_input":"2021-07-14T10:40:10.352288Z","iopub.status.idle":"2021-07-14T10:40:10.365735Z","shell.execute_reply.started":"2021-07-14T10:40:10.352261Z","shell.execute_reply":"2021-07-14T10:40:10.36477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=250, target_flag=True):\n        super().__init__()\n        self.df = dataframe\n        self.tokenizer = tokenizer\n        self.target_flag = target_flag\n\n        if max_len is None:\n            self.max_len = 512#\n        else:\n            self.max_len = max_len\n        \n\n        \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n    \n        token_dict = self.padding_transform(row.excerpt)\n        \n        if self.target_flag == True:\n            token_dict['target'] = torch.tensor(row.target, dtype=torch.float32)\n        \n        return token_dict\n\n        \n    def padding_transform(self, input_text):\n        encoded = self.tokenizer(input_text,\n                                 is_split_into_words=True,\n                                 max_length=self.max_len,\n                                 truncation=True)\n        padding_len = self.max_len - len(encoded['input_ids'])\n        encoded['input_ids'] = torch.tensor(encoded['input_ids'] + [0] * padding_len, dtype=torch.long)\n        encoded['attention_mask'] = torch.tensor(encoded['attention_mask'] + [0] * padding_len, dtype=torch.long)\n        \n        return {'input_ids': encoded['input_ids'], 'attention_mask': encoded['attention_mask']}\n\n        \n        \n    def __len__(self):\n        return len(self.df.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:10.588549Z","iopub.execute_input":"2021-07-14T10:40:10.588831Z","iopub.status.idle":"2021-07-14T10:40:10.598237Z","shell.execute_reply.started":"2021-07-14T10:40:10.588806Z","shell.execute_reply":"2021-07-14T10:40:10.597099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobModel(nn.Module):\n    def __init__(self, hidden_layer=256):\n        super().__init__()\n#         self.rob_config = RobertaConfig(attention_probs_dropout_prob=0.2)\n        self.model = RobertaModel.from_pretrained('../input/roberta-l')#('roberta-base')#\n        self.features = nn.Linear(1024, hidden_layer)\n        self.regressor = nn.Linear(hidden_layer, 1)\n\n        \n    def forward(self, i_ids, a_mask):\n\n        output = self.model(input_ids=i_ids, attention_mask=a_mask)\n        output = output.last_hidden_state[:, 0]#768\n        output = F.gelu(self.features(output))#256\n        output = self.regressor(output)\n        \n        return output\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:10.81016Z","iopub.execute_input":"2021-07-14T10:40:10.810404Z","iopub.status.idle":"2021-07-14T10:40:10.816725Z","shell.execute_reply.started":"2021-07-14T10:40:10.810379Z","shell.execute_reply":"2021-07-14T10:40:10.815753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_mode(criterion, optimizer, data_loader, scheduler=None):\n    mean_cost = 0\n    mean_rmse = 0\n    \n    model.train()\n    for step, batch in tqdm(enumerate(data_loader)):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        target = batch['target'].to(device)\n\n        optimizer.zero_grad()\n        predict = model(input_ids, attention_mask)\n        predict = predict.view(-1)\n        \n        cost = criterion(predict, target)\n        cost.backward()\n        optimizer.step()\n        \n        if scheduler is not None:\n            scheduler.step()\n        \n        mean_cost += cost\n    \n    mean_cost /= len(data_loader)\n    mean_rmse = torch.sqrt(mean_cost).to(\"cpu\").detach().numpy()\n    return mean_cost, mean_rmse\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:11.006222Z","iopub.execute_input":"2021-07-14T10:40:11.006491Z","iopub.status.idle":"2021-07-14T10:40:11.013501Z","shell.execute_reply.started":"2021-07-14T10:40:11.006467Z","shell.execute_reply":"2021-07-14T10:40:11.012379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_mode(criterion, data_loader):\n    mean_cost = 0\n    mean_rmse = 0\n    \n    model.eval()\n    with torch.no_grad():\n        for step, batch in tqdm(enumerate(data_loader)):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            target = batch['target'].to(device)\n\n            predict = model(input_ids, attention_mask)\n            predict = predict.view(-1)\n\n            cost = criterion(predict, target)        \n            mean_cost += cost\n\n        mean_cost /= len(data_loader)\n        mean_rmse = torch.sqrt(mean_cost).to(\"cpu\").detach().numpy()\n        return mean_cost, mean_rmse","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:13.885348Z","iopub.execute_input":"2021-07-14T10:40:13.885706Z","iopub.status.idle":"2021-07-14T10:40:13.892551Z","shell.execute_reply.started":"2021-07-14T10:40:13.885673Z","shell.execute_reply":"2021-07-14T10:40:13.891435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_optimizer_old(model):\n    named_parameters = list(model.named_parameters())    \n    \n    #roberta large layers\n    robert_l_params = named_parameters[:389]\n    attention_params = named_parameters[391:393]\n    regressor_params = named_parameters[393:]\n\n#     robert_b_params = named_parameters[:197]\n#     attention_params = named_parameters[199:201]\n#     regressor_params = named_parameters[201:]\n\n    attention_group = [params for (name, params) in attention_params]\n    regressor_group = [params for (name, params) in regressor_params]\n\n    parameters = []\n    parameters.append({\"params\": attention_group})\n    parameters.append({\"params\": regressor_group})\n\n    for layer_num, (name, params) in enumerate(robert_l_params):\n        weight_decay = 0.0 if \"bias\" in name else 0.01\n\n        lr = 2e-5\n\n        if layer_num >= 69:        \n            lr = 5e-5\n\n        if layer_num >= 133:\n            lr = 1e-4\n\n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr})\n\n    return AdamW(parameters)    ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:14.740531Z","iopub.execute_input":"2021-07-14T10:40:14.740873Z","iopub.status.idle":"2021-07-14T10:40:14.747695Z","shell.execute_reply.started":"2021-07-14T10:40:14.740843Z","shell.execute_reply":"2021-07-14T10:40:14.746867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_optimizer(model):\n    named_parameters = list(model.named_parameters())    \n    \n    robert_l_params = named_parameters[:389]\n    attention_params = named_parameters[391:393]\n    regressor_params = named_parameters[393:]\n        \n    attention_group = [params for (name, params) in attention_params]\n    regressor_group = [params for (name, params) in regressor_params]\n\n    parameters = []\n    parameters.append({\"params\": attention_group})\n    parameters.append({\"params\": regressor_group})\n\n    for layer_num, (name, params) in enumerate(robert_l_params):\n        weight_decay = 0.0 if \"bias\" in name else 0.01\n\n        lr = 2e-5\n\n        if layer_num >= 69:        \n            lr = 2e-5 * 2.5\n\n        if layer_num >= 133:\n            lr = 2e-5 * 5\n\n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr})\n\n    return optim.AdamW(parameters)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:15.295544Z","iopub.execute_input":"2021-07-14T10:40:15.295895Z","iopub.status.idle":"2021-07-14T10:40:15.303592Z","shell.execute_reply.started":"2021-07-14T10:40:15.295869Z","shell.execute_reply":"2021-07-14T10:40:15.302787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained('../input/roberta-l')#('roberta-base')#","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:15.910129Z","iopub.execute_input":"2021-07-14T10:40:15.910415Z","iopub.status.idle":"2021-07-14T10:40:16.025985Z","shell.execute_reply.started":"2021-07-14T10:40:15.910387Z","shell.execute_reply":"2021-07-14T10:40:16.025047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rob_config = RobertaConfig(attention_probs_dropout_prob=0.2)\n# model = RobertaModel.from_pretrained('roberta-large')\nmodel = RobModel()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:16.376977Z","iopub.execute_input":"2021-07-14T10:40:16.377265Z","iopub.status.idle":"2021-07-14T10:40:30.898283Z","shell.execute_reply.started":"2021-07-14T10:40:16.377237Z","shell.execute_reply":"2021-07-14T10:40:30.897293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataset = MyDataset(train_df_tmp[:2000], tokenizer)\nvalid_dataset = MyDataset(train_df_tmp[2000:], tokenizer)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=8)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=12, shuffle=True, num_workers=8)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:31.798109Z","iopub.execute_input":"2021-07-14T10:40:31.79845Z","iopub.status.idle":"2021-07-14T10:40:31.804892Z","shell.execute_reply.started":"2021-07-14T10:40:31.79842Z","shell.execute_reply":"2021-07-14T10:40:31.803581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# freezing parameters\n\nfor param in model.model.embeddings.parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[0].parameters():\n    param.requires_grad = False \n\nfor param in model.model.encoder.layer[1].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[2].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[3].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[4].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[5].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[6].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[7].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[8].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[9].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[10].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[11].parameters():\n    param.requires_grad = False\n\nfor param in model.model.encoder.layer[12].parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:32.59247Z","iopub.execute_input":"2021-07-14T10:40:32.592846Z","iopub.status.idle":"2021-07-14T10:40:32.606454Z","shell.execute_reply.started":"2021-07-14T10:40:32.592814Z","shell.execute_reply":"2021-07-14T10:40:32.605245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:34.785113Z","iopub.execute_input":"2021-07-14T10:40:34.78543Z","iopub.status.idle":"2021-07-14T10:40:34.797409Z","shell.execute_reply.started":"2021-07-14T10:40:34.785401Z","shell.execute_reply":"2021-07-14T10:40:34.79646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/roberta-l/ro_best_ever_model.pt'))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:35.323495Z","iopub.execute_input":"2021-07-14T10:40:35.323838Z","iopub.status.idle":"2021-07-14T10:40:54.564465Z","shell.execute_reply.started":"2021-07-14T10:40:35.323808Z","shell.execute_reply":"2021-07-14T10:40:54.563596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 7\nmodel.to(device)\ncriterion = nn.MSELoss().to(device)\n# optimizer = create_optimizer(model)#optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-6) #create_optimizer(model)\n\noptimizer = optim.Adam([\n        {'params': model.features.parameters(), 'lr': 1e-4},\n        {'params': model.regressor.parameters(), 'lr': 1e-4},\n        {'params': model.model.encoder.parameters(), 'lr': 2e-5},\n    ], betas=(0.6, 0.7))\n\n\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer,\n    num_training_steps=num_epochs * len(train_dataloader),\n    num_warmup_steps=20)\nbest_cost = np.inf\n\nSEED = 42\nNUM_FOLDS = 5\n\n\nkfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\nfor epoch in range(num_epochs):\n\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_df_tmp)):\n        print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n        train_dataset = MyDataset(train_df_tmp.loc[train_idx], tokenizer)\n        valid_dataset = MyDataset(train_df_tmp.loc[val_idx], tokenizer)\n\n        train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=8)\n        valid_dataloader = DataLoader(valid_dataset, batch_size=12, shuffle=True, num_workers=8)    \n        \n        train_cost, train_rmse = train_mode(criterion, optimizer, train_dataloader, scheduler=scheduler)\n        print(\"train cost: \", train_cost.item(), \" train rmse: \", train_rmse)\n\n        valid_cost, valid_rmse = eval_mode(criterion, valid_dataloader)\n        print(\"valid cost: \", valid_cost.item(), \" valid rmse: \", valid_rmse)\n\n        if valid_cost < best_cost:\n            best_cost = valid_cost\n            torch.save(model.state_dict(), \"ro_best_ever_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:40:59.60714Z","iopub.execute_input":"2021-07-14T10:40:59.607452Z","iopub.status.idle":"2021-07-14T10:41:02.799489Z","shell.execute_reply.started":"2021-07-14T10:40:59.607425Z","shell.execute_reply":"2021-07-14T10:41:02.797856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n#     result = np.zeros(len(data_loader))    \n    result = []\n    index = 0\n    \n    model.eval()\n    with torch.no_grad():\n        for step, batch in tqdm(enumerate(data_loader)):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n                        \n            predict = model(input_ids, attention_mask)                        \n            predict = predict.view(-1).float()\n            print(step)\n            print(predict)\n            result.extend(predict.float().detach().to(\"cpu\").tolist())\n\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:05.911645Z","iopub.execute_input":"2021-07-14T10:41:05.912016Z","iopub.status.idle":"2021-07-14T10:41:05.918297Z","shell.execute_reply.started":"2021-07-14T10:41:05.911983Z","shell.execute_reply":"2021-07-14T10:41:05.917461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:07.556271Z","iopub.execute_input":"2021-07-14T10:41:07.556593Z","iopub.status.idle":"2021-07-14T10:41:07.569964Z","shell.execute_reply.started":"2021-07-14T10:41:07.556562Z","shell.execute_reply":"2021-07-14T10:41:07.569042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = MyDataset(test_df, tokenizer, 250, target_flag=False)\ntest_dataloader = DataLoader(test_ds, batch_size=8, num_workers=8)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:13.40695Z","iopub.execute_input":"2021-07-14T10:41:13.407352Z","iopub.status.idle":"2021-07-14T10:41:13.41194Z","shell.execute_reply.started":"2021-07-14T10:41:13.407319Z","shell.execute_reply":"2021-07-14T10:41:13.41088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = predict(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:14.487272Z","iopub.execute_input":"2021-07-14T10:41:14.487809Z","iopub.status.idle":"2021-07-14T10:41:15.310866Z","shell.execute_reply.started":"2021-07-14T10:41:14.487761Z","shell.execute_reply":"2021-07-14T10:41:15.309588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:20.907559Z","iopub.execute_input":"2021-07-14T10:41:20.907967Z","iopub.status.idle":"2021-07-14T10:41:20.915434Z","shell.execute_reply.started":"2021-07-14T10:41:20.907928Z","shell.execute_reply":"2021-07-14T10:41:20.914272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission_df\nsubmission_df.target = labels","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:22.946938Z","iopub.execute_input":"2021-07-14T10:41:22.947256Z","iopub.status.idle":"2021-07-14T10:41:22.959043Z","shell.execute_reply.started":"2021-07-14T10:41:22.947227Z","shell.execute_reply":"2021-07-14T10:41:22.958143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:24.447041Z","iopub.execute_input":"2021-07-14T10:41:24.447371Z","iopub.status.idle":"2021-07-14T10:41:24.460173Z","shell.execute_reply.started":"2021-07-14T10:41:24.447339Z","shell.execute_reply":"2021-07-14T10:41:24.459149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:32.741901Z","iopub.execute_input":"2021-07-14T10:41:32.74225Z","iopub.status.idle":"2021-07-14T10:41:32.75176Z","shell.execute_reply.started":"2021-07-14T10:41:32.74222Z","shell.execute_reply":"2021-07-14T10:41:32.750474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:41:39.386814Z","iopub.execute_input":"2021-07-14T10:41:39.38714Z","iopub.status.idle":"2021-07-14T10:41:39.395698Z","shell.execute_reply.started":"2021-07-14T10:41:39.387111Z","shell.execute_reply":"2021-07-14T10:41:39.394751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}