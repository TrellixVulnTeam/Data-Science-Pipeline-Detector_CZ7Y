{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">CommonLit Readability<br> BERT Baseline</h1>\n<br>","metadata":{}},{"cell_type":"markdown","source":"![](https://res-3.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco/v1475197388/qcmvdzlsrxyqyftnahs1.png)","metadata":{}},{"cell_type":"markdown","source":"<h3>üìå Explore T5: <a href='https://www.kaggle.com/debarshichanda/explore-t5'>https://www.kaggle.com/debarshichanda/explore-t5</a></h3>","metadata":{}},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Install Required Libraries</h1>","metadata":{}},{"cell_type":"code","source":"!pip install -q nlpretext loguru","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-09T20:29:44.962432Z","iopub.execute_input":"2021-07-09T20:29:44.963008Z","iopub.status.idle":"2021-07-09T20:30:30.448191Z","shell.execute_reply.started":"2021-07-09T20:29:44.962885Z","shell.execute_reply":"2021-07-09T20:30:30.447243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Required Libraries üìö</h1>","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport time\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\nimport transformers\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nfrom loguru import logger\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom nlpretext import Preprocessor\nfrom nlpretext.basic.preprocess import (normalize_whitespace, remove_punct, \n                                        remove_eol_characters, remove_stopwords, \n                                        lower_text, unpack_english_contractions)\nfrom nlpretext.social.preprocess import remove_html_tags\n\nfrom colorama import Fore\nb_ = Fore.BLUE\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:30.451117Z","iopub.execute_input":"2021-07-09T20:30:30.451489Z","iopub.status.idle":"2021-07-09T20:30:39.119699Z","shell.execute_reply.started":"2021-07-09T20:30:30.45145Z","shell.execute_reply":"2021-07-09T20:30:39.118835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Read the Data üìñ</h1>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:39.121487Z","iopub.execute_input":"2021-07-09T20:30:39.121823Z","iopub.status.idle":"2021-07-09T20:30:39.201207Z","shell.execute_reply.started":"2021-07-09T20:30:39.121788Z","shell.execute_reply":"2021-07-09T20:30:39.200465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:39.20333Z","iopub.execute_input":"2021-07-09T20:30:39.203685Z","iopub.status.idle":"2021-07-09T20:30:39.220992Z","shell.execute_reply.started":"2021-07-09T20:30:39.20365Z","shell.execute_reply":"2021-07-09T20:30:39.220265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Preprocessing</h1>","metadata":{}},{"cell_type":"markdown","source":"![](https://github.com/artefactory/NLPretext/raw/master/references/logo_nlpretext.png)","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We will use <i>NLPretext</i> library for preprocessing our text</span>","metadata":{}},{"cell_type":"code","source":"preprocessor = Preprocessor()\npreprocessor.pipe(unpack_english_contractions)\npreprocessor.pipe(remove_eol_characters)\npreprocessor.pipe(lower_text)\npreprocessor.pipe(normalize_whitespace)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:39.223629Z","iopub.execute_input":"2021-07-09T20:30:39.223861Z","iopub.status.idle":"2021-07-09T20:30:39.229388Z","shell.execute_reply.started":"2021-07-09T20:30:39.223839Z","shell.execute_reply":"2021-07-09T20:30:39.228598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['excerpt'] = train_df['excerpt'].apply(preprocessor.run)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:39.231151Z","iopub.execute_input":"2021-07-09T20:30:39.231451Z","iopub.status.idle":"2021-07-09T20:30:43.330484Z","shell.execute_reply.started":"2021-07-09T20:30:39.231424Z","shell.execute_reply":"2021-07-09T20:30:43.329603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Maximum Length of Text present in the Dataset</span>","metadata":{}},{"cell_type":"code","source":"excerpt_lenghts = train_df['excerpt'].apply(lambda x: len(x.split()))\nmax(excerpt_lenghts)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:43.331646Z","iopub.execute_input":"2021-07-09T20:30:43.331967Z","iopub.status.idle":"2021-07-09T20:30:43.371858Z","shell.execute_reply.started":"2021-07-09T20:30:43.331933Z","shell.execute_reply":"2021-07-09T20:30:43.371137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Configuration ‚öôÔ∏è</h1>","metadata":{}},{"cell_type":"code","source":"class CONFIG:\n    seed = 42\n    max_len = 205\n    train_batch_size = 32\n    valid_batch_size = 32\n    epochs = 10\n    learning_rate = 1e-5\n    n_accumulate = 1\n    folds = 5\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n    tokenizer.save_pretrained('./tokenizer')\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:43.374438Z","iopub.execute_input":"2021-07-09T20:30:43.374804Z","iopub.status.idle":"2021-07-09T20:30:47.471294Z","shell.execute_reply.started":"2021-07-09T20:30:43.374772Z","shell.execute_reply":"2021-07-09T20:30:47.470427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1>","metadata":{}},{"cell_type":"code","source":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:47.473166Z","iopub.execute_input":"2021-07-09T20:30:47.47366Z","iopub.status.idle":"2021-07-09T20:30:47.482474Z","shell.execute_reply.started":"2021-07-09T20:30:47.473624Z","shell.execute_reply":"2021-07-09T20:30:47.481626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Folds</h1>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://www.kaggle.com/tolgadincer/continuous-target-stratification?rvi=1&scriptVersionId=52551118&cellId=6\">https://www.kaggle.com/tolgadincer/continuous-target-stratification?rvi=1&scriptVersionId=52551118&cellId=6</a></span>","metadata":{}},{"cell_type":"code","source":"def create_folds(df, n_s=5, n_grp=None):\n    df['kfold'] = -1\n    \n    if n_grp is None:\n        skf = KFold(n_splits=n_s, random_state=CONFIG.seed)\n        target = df.target\n    else:\n        skf = StratifiedKFold(n_splits=n_s, shuffle=True, random_state=CONFIG.seed)\n        df['grp'] = pd.cut(df.target, n_grp, labels=False)\n        target = df.grp\n    \n    for fold_no, (t, v) in enumerate(skf.split(target, target)):\n        df.loc[v, 'kfold'] = fold_no\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:47.483766Z","iopub.execute_input":"2021-07-09T20:30:47.484176Z","iopub.status.idle":"2021-07-09T20:30:47.491358Z","shell.execute_reply.started":"2021-07-09T20:30:47.484138Z","shell.execute_reply":"2021-07-09T20:30:47.490274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = create_folds(train_df, n_s=CONFIG.folds, n_grp=12)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:47.492709Z","iopub.execute_input":"2021-07-09T20:30:47.493249Z","iopub.status.idle":"2021-07-09T20:30:47.519895Z","shell.execute_reply.started":"2021-07-09T20:30:47.493194Z","shell.execute_reply":"2021-07-09T20:30:47.519137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Dataset Class</h1>","metadata":{}},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.text = df['excerpt'].values\n        self.target = df['target'].values\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'target': torch.tensor(self.target[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:47.522139Z","iopub.execute_input":"2021-07-09T20:30:47.522475Z","iopub.status.idle":"2021-07-09T20:30:47.530238Z","shell.execute_reply.started":"2021-07-09T20:30:47.522442Z","shell.execute_reply":"2021-07-09T20:30:47.529233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h1>","metadata":{}},{"cell_type":"code","source":"def criterion(outputs, targets):\n    return nn.MSELoss()(outputs.view(-1), targets.view(-1))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:47.531862Z","iopub.execute_input":"2021-07-09T20:30:47.532262Z","iopub.status.idle":"2021-07-09T20:30:47.539977Z","shell.execute_reply.started":"2021-07-09T20:30:47.532226Z","shell.execute_reply":"2021-07-09T20:30:47.539162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Model</h1>","metadata":{}},{"cell_type":"code","source":"class BERTClass(nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.fc = nn.Linear(768, 1)\n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, output = self.bert(ids, attention_mask = mask, \n                              token_type_ids = token_type_ids, \n                              return_dict=False)\n        output = self.dropout(output)\n        output = self.fc(output)\n        return output\n\nmodel = BERTClass()\nmodel.to(CONFIG.device);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:30:47.541159Z","iopub.execute_input":"2021-07-09T20:30:47.541566Z","iopub.status.idle":"2021-07-09T20:31:20.125624Z","shell.execute_reply.started":"2021-07-09T20:30:47.541531Z","shell.execute_reply":"2021-07-09T20:31:20.124743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h1>","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['target'].to(device, dtype = torch.float)\n        \n        batch_size = ids.size(0)\n        \n        with amp.autocast(enabled=True):\n            outputs = model(ids, mask, token_type_ids)\n            loss = criterion(outputs, targets)\n            loss = loss / CONFIG.n_accumulate\n            \n        scaler.scale(loss).backward()\n        \n        if (step + 1) % CONFIG.n_accumulate == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            \n            # zero the parameter gradients\n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss/dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.126959Z","iopub.execute_input":"2021-07-09T20:31:20.127314Z","iopub.status.idle":"2021-07-09T20:31:20.137479Z","shell.execute_reply.started":"2021-07-09T20:31:20.127278Z","shell.execute_reply":"2021-07-09T20:31:20.136595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1>","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['target'].to(device, dtype = torch.float)\n        \n        batch_size = ids.size(0)\n        \n        outputs = model(ids, mask, token_type_ids)\n        loss = criterion(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss/dataset_size\n        \n        PREDS.extend(outputs.cpu().detach().numpy().tolist())\n        TARGETS.extend(targets.cpu().detach().numpy().tolist())\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    val_rmse = mean_squared_error(TARGETS, PREDS, squared=False)\n    gc.collect()\n    \n    return epoch_loss, val_rmse","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.138792Z","iopub.execute_input":"2021-07-09T20:31:20.13927Z","iopub.status.idle":"2021-07-09T20:31:20.15962Z","shell.execute_reply.started":"2021-07-09T20:31:20.139234Z","shell.execute_reply":"2021-07-09T20:31:20.158864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run</h1>","metadata":{}},{"cell_type":"code","source":"@logger.catch\ndef run(model, optimizer, scheduler, device, num_epochs):    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_rmse = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader, \n                                           device=CONFIG.device, epoch=epoch)\n        \n        valid_epoch_loss, valid_epoch_rmse = valid_one_epoch(model, optimizer, scheduler,\n                                                             dataloader=valid_loader, \n                                                             device=CONFIG.device, epoch=epoch)\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        history['Valid RMSE'].append(valid_epoch_rmse)\n        \n        print(f'Valid RMSE: {valid_epoch_rmse}')\n        \n        # deep copy the model\n        if valid_epoch_rmse <= best_epoch_rmse:\n            print(f\"{b_}Validation RMSE Improved ({best_epoch_rmse} ---> {valid_epoch_rmse})\")\n            best_epoch_rmse = valid_epoch_rmse\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_rmse, epoch)\n            torch.save(model.state_dict(), PATH)\n            print(\"Model Saved\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss: {:.4f}\".format(best_epoch_rmse))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.160815Z","iopub.execute_input":"2021-07-09T20:31:20.161364Z","iopub.status.idle":"2021-07-09T20:31:20.173106Z","shell.execute_reply.started":"2021-07-09T20:31:20.161307Z","shell.execute_reply":"2021-07-09T20:31:20.17236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = BERTDataset(df_train, CONFIG.tokenizer, CONFIG.max_len)\n    valid_dataset = BERTDataset(df_valid, CONFIG.tokenizer, CONFIG.max_len)\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, \n                              num_workers=4, shuffle=True, pin_memory=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, \n                              num_workers=4, shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.174505Z","iopub.execute_input":"2021-07-09T20:31:20.17485Z","iopub.status.idle":"2021-07-09T20:31:20.184424Z","shell.execute_reply.started":"2021-07-09T20:31:20.174817Z","shell.execute_reply":"2021-07-09T20:31:20.183683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Create Dataloaders</span>","metadata":{}},{"cell_type":"code","source":"train_loader, valid_loader = prepare_data(fold=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.185561Z","iopub.execute_input":"2021-07-09T20:31:20.185912Z","iopub.status.idle":"2021-07-09T20:31:20.222665Z","shell.execute_reply.started":"2021-07-09T20:31:20.185878Z","shell.execute_reply":"2021-07-09T20:31:20.221941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Define Optimizer and Scheduler</span>","metadata":{}},{"cell_type":"code","source":"# Defining Optimizer with weight decay to params other than bias and layer norms\nparam_optimizer = list(model.named_parameters())\nno_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\noptimizer_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n     'weight_decay': 0.0001},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n     'weight_decay': 0.0}\n    ]  \n\noptimizer = AdamW(optimizer_parameters, lr=CONFIG.learning_rate)\n\n# Defining LR Scheduler\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=0, \n    num_training_steps=len(train_loader)*CONFIG.epochs\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.224217Z","iopub.execute_input":"2021-07-09T20:31:20.224465Z","iopub.status.idle":"2021-07-09T20:31:20.233963Z","shell.execute_reply.started":"2021-07-09T20:31:20.224443Z","shell.execute_reply":"2021-07-09T20:31:20.233093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Train Fold: 0</h1>","metadata":{}},{"cell_type":"code","source":"model, history = run(model, optimizer, scheduler=scheduler, device=CONFIG.device, num_epochs=CONFIG.epochs)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:31:20.235256Z","iopub.execute_input":"2021-07-09T20:31:20.235804Z","iopub.status.idle":"2021-07-09T20:40:22.674799Z","shell.execute_reply.started":"2021-07-09T20:31:20.235768Z","shell.execute_reply":"2021-07-09T20:40:22.673997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualizations üìâ</h1>","metadata":{}},{"cell_type":"code","source":"epochs = list(range(1, CONFIG.epochs + 1))\nfig = go.Figure()\ntrace1 = go.Scatter(x=epochs, y=history['Train Loss'],\n                    mode='lines+markers',\n                    name='Train Loss')\ntrace2 = go.Scatter(x=epochs, y=history['Valid Loss'],\n                    mode='lines+markers',\n                    name='Valid Loss')\nlayout = go.Layout(template=\"plotly_dark\", title='Loss Curve', \n                   xaxis=dict(title='Epochs'), yaxis=dict(title='Loss'))\nfig = go.Figure(data = [trace1, trace2], layout = layout)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T20:40:22.676226Z","iopub.execute_input":"2021-07-09T20:40:22.67659Z","iopub.status.idle":"2021-07-09T20:40:23.527864Z","shell.execute_reply.started":"2021-07-09T20:40:22.676554Z","shell.execute_reply":"2021-07-09T20:40:23.526362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","metadata":{}}]}