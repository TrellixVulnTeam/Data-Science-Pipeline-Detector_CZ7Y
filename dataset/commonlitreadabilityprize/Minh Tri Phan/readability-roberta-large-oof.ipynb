{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Version 15\n* Sub-version 4\n* Train with ../input/clrcross-validation-strategies/train_folds_shuffle2.csv\n* Seed 1234\n* No QWK","metadata":{"papermill":{"duration":0.015337,"end_time":"2021-07-10T17:25:47.168997","exception":false,"start_time":"2021-07-10T17:25:47.15366","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport random\n\nimport nltk\nimport string\nimport re\nimport math\n\nfrom sklearn.utils import shuffle\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n# Autocast\nfrom torch.cuda.amp import autocast, GradScaler\n\n# Stochastic Weight Average\nfrom torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, AdamW\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.981793,"end_time":"2021-07-10T17:25:55.165655","exception":false,"start_time":"2021-07-10T17:25:47.183862","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:13:56.853772Z","iopub.execute_input":"2021-07-26T09:13:56.85417Z","iopub.status.idle":"2021-07-26T09:14:04.91123Z","shell.execute_reply.started":"2021-07-26T09:13:56.854089Z","shell.execute_reply":"2021-07-26T09:14:04.910366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\ntransformers.__version__","metadata":{"papermill":{"duration":0.023566,"end_time":"2021-07-10T17:25:55.203713","exception":false,"start_time":"2021-07-10T17:25:55.180147","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:04.912698Z","iopub.execute_input":"2021-07-26T09:14:04.913053Z","iopub.status.idle":"2021-07-26T09:14:04.922197Z","shell.execute_reply.started":"2021-07-26T09:14:04.913012Z","shell.execute_reply":"2021-07-26T09:14:04.921134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install spacy-readability\nimport spacy\nfrom spacy_readability import Readability\n\nnlp = spacy.load('en')\nnlp.add_pipe(Readability(), last = True)","metadata":{"papermill":{"duration":13.613519,"end_time":"2021-07-10T17:26:08.831803","exception":false,"start_time":"2021-07-10T17:25:55.218284","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:04.924467Z","iopub.execute_input":"2021-07-26T09:14:04.924972Z","iopub.status.idle":"2021-07-26T09:14:17.921372Z","shell.execute_reply.started":"2021-07-26T09:14:04.92493Z","shell.execute_reply":"2021-07-26T09:14:17.920491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nseed = 1234\nseed_everything(seed)","metadata":{"papermill":{"duration":0.031249,"end_time":"2021-07-10T17:26:08.882816","exception":false,"start_time":"2021-07-10T17:26:08.851567","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:17.923066Z","iopub.execute_input":"2021-07-26T09:14:17.923402Z","iopub.status.idle":"2021-07-26T09:14:17.933036Z","shell.execute_reply.started":"2021-07-26T09:14:17.923364Z","shell.execute_reply":"2021-07-26T09:14:17.932274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{"papermill":{"duration":0.019506,"end_time":"2021-07-10T17:26:08.921832","exception":false,"start_time":"2021-07-10T17:26:08.902326","status":"completed"},"tags":[]}},{"cell_type":"code","source":"base_dir = '../input/clrcross-validation-strategies'\ndata = pd.read_csv(f'{base_dir}/train_folds_shuffle2.csv')\nbenchmark = data[data['standard_error'] == 0.]\ndata['compare_to_benchmark'] = np.sign(data['target'])\ndata.head()","metadata":{"papermill":{"duration":0.134191,"end_time":"2021-07-10T17:26:09.075502","exception":false,"start_time":"2021-07-10T17:26:08.941311","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:17.934399Z","iopub.execute_input":"2021-07-26T09:14:17.934957Z","iopub.status.idle":"2021-07-26T09:14:18.049885Z","shell.execute_reply.started":"2021-07-26T09:14:17.934915Z","shell.execute_reply":"2021-07-26T09:14:18.049115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower().strip()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\ndef text_preprocessing(text):\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    combined_text = ' '.join(tokenized_text)\n    return combined_text\n\ndef readability_feat(text):\n    text = nlp(text)\n    \n    return np.array([text._.flesch_kincaid_grade_level,\n                     text._.flesch_kincaid_reading_ease,\n                     text._.dale_chall,\n                     text._.coleman_liau_index,\n                     text._.automated_readability_index,\n                     text._.forcast], dtype = np.float)\n\ndef sample_text(targets, num_output = 5):\n    mean, var = targets[0], targets[1]\n    if targets[1] != 0.:\n        sampled_target = torch.normal(mean, var, size = (num_output,))\n    else:\n        sampled_target = torch.tensor([0.] * num_output, dtype = torch.float)\n    return sampled_target\n\ndef convert_examples_to_features(text, tokenizer, max_len, is_test = False, return_tensor = False):\n    # Take from https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-fit\n    text = text.replace('\\n', '')\n    if return_tensor:\n        tok = tokenizer.encode_plus(\n            text, \n            max_length = max_len, \n            padding = 'max_length', \n            return_tensors = 'pt',\n            truncation = True,\n            return_attention_mask = True,\n            return_token_type_ids = True\n        )\n    else:\n        tok = tokenizer.encode_plus(\n            text, \n            max_length = max_len, \n            padding = 'max_length', \n            truncation = True,\n            return_attention_mask = True,\n            return_token_type_ids = True\n        )\n    return tok\n\ndef form_dataset(token, external_features = None, target = None, bins = None):\n    if target is not None:\n        if bins is not None:\n            if external_features is not None:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'external_features': torch.tensor(external_features, dtype = torch.float),\n                    'target': target,\n                    'bins': bins,\n                }\n            else:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'target': target,\n                    'bins': bins,\n                }\n        else:\n            if external_features is not None:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'external_features': torch.tensor(external_features, dtype = torch.float),\n                    'target': target,\n                }\n            else:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'target': target,\n                }\n    else:\n        if external_features is not None:\n            return {\n                'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                'external_features': torch.tensor(external_features, dtype = torch.float),\n            }\n        else:\n            return {\n                'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n            }","metadata":{"papermill":{"duration":0.04509,"end_time":"2021-07-10T17:26:09.14086","exception":false,"start_time":"2021-07-10T17:26:09.09577","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.053099Z","iopub.execute_input":"2021-07-26T09:14:18.053355Z","iopub.status.idle":"2021-07-26T09:14:18.07669Z","shell.execute_reply.started":"2021-07-26T09:14:18.053328Z","shell.execute_reply":"2021-07-26T09:14:18.075939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.019728,"end_time":"2021-07-10T17:26:09.180536","exception":false,"start_time":"2021-07-10T17:26:09.160808","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Readability_Dataset(Dataset):\n    def __init__(self, documents, tokenizer, sample = False, max_len = 300, num_output = 5, binning = True, mode = 'train'):\n        self.documents = documents\n        self.tokenizer = tokenizer\n        self.sample = sample\n        self.max_len = max_len\n        self.mode = mode\n        self.num_output = num_output\n        \n        if self.mode == 'train':\n            self.binning = binning\n        \n    def __len__(self):\n        return len(self.documents)\n    \n    def __getitem__(self, idx):\n        sample = self.documents.iloc[idx]\n        document = sample['excerpt']\n        \n        # Compute readability features\n        ext_features = None # readability_feat(document)\n        \n        # Tokenize\n        features = convert_examples_to_features(document, self.tokenizer, self.max_len)\n        \n        target = torch.tensor(sample['target'])\n        bins = None\n            \n        return form_dataset(features, external_features = ext_features, target = target, bins = bins)","metadata":{"papermill":{"duration":0.030105,"end_time":"2021-07-10T17:26:09.231069","exception":false,"start_time":"2021-07-10T17:26:09.200964","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.078494Z","iopub.execute_input":"2021-07-26T09:14:18.078738Z","iopub.status.idle":"2021-07-26T09:14:18.090405Z","shell.execute_reply.started":"2021-07-26T09:14:18.078714Z","shell.execute_reply":"2021-07-26T09:14:18.089496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.019861,"end_time":"2021-07-10T17:26:09.271401","exception":false,"start_time":"2021-07-10T17:26:09.25154","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Readability_Model(nn.Module):\n    def __init__(self, backbone, model_config, is_sampled = False, num_external_features = 6, num_output = 2, \n                 num_cat = 7, attention_dim = 1024, multisample_dropout = True, benchmark_token = None):\n        super(Readability_Model, self).__init__()\n        self.model_config = model_config\n        self.is_sampled = is_sampled\n        self.benchmark_token = benchmark_token\n        self.backbone = AutoModel.from_pretrained(backbone, config = self.model_config)\n        self.layer_norm = nn.LayerNorm(self.model_config.hidden_size * 2)    # Concat of mean and max pooling\n        self.output = nn.Linear(self.model_config.hidden_size * 2, num_output)   #  + num_external_features\n        self.output_cat = nn.Linear(self.model_config.hidden_size * 2, num_cat)\n        \n        # Attention pooler\n        self.word_weight = nn.Linear(self.model_config.hidden_size * 2, attention_dim)\n        self.context_weight = nn.Linear(attention_dim, 1)\n        \n        self.hidden_layer_weights = nn.Parameter(torch.zeros(self.model_config.num_hidden_layers).view(-1, 1, 1, 1))\n        \n        # Dropout layers\n        if multisample_dropout:\n            self.dropouts_output = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n            self.dropouts_cat = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n        else:\n            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n        \n        # Initialize weights\n        self._init_weights(self.layer_norm)\n        self._init_weights(self.output)\n        self._init_weights(self.word_weight)\n        self._init_weights(self.context_weight)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean = 0.0, std = self.model_config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean = 0.0, std = self.model_config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def forward(self, input_ids, token_type_ids, attention_mask, external_features = None):\n        output_backbone = self.backbone(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n        \n        # Extract output\n        hidden_states = output_backbone.hidden_states\n        \n        # Mean/max pooling (over hidden layers), concatenate with pooler\n        hidden_states = torch.stack(tuple(hidden_states[-i-1] for i in range(len(hidden_states) - 1)), dim = 0)\n        layer_weight = F.softmax(self.hidden_layer_weights, dim = 0)\n        out_mean = torch.sum(hidden_states * layer_weight, dim = 0)\n        out_max, _ = torch.max(hidden_states, dim = 0)\n        output_backbone = torch.cat((out_mean, out_max), dim = -1)\n        output_backbone = self.layer_norm(output_backbone)\n        \n        # Attention Pooling (over time)\n        u_i = torch.tanh(self.word_weight(output_backbone))\n        u_w = self.context_weight(u_i).squeeze(1)\n        val = u_w.max()\n        att = torch.exp(u_w - val)\n        att = att / torch.sum(att, dim = 1, keepdim = True)\n        \n        output = output_backbone * att\n        output = output.sum(dim = 1)\n        \n        # Multiple dropout\n        for i, dropout in enumerate(self.dropouts_output):\n            if i == 0:\n                logits = self.output(dropout(output))\n                cats = self.output_cat(self.dropouts_cat[i](output))\n            else:\n                logits += self.output(dropout(output))\n                cats += self.output_cat(self.dropouts_cat[i](output))\n        \n        logits /= len(self.dropouts_output)\n        cats /= len(self.dropouts_output)\n        \n        if self.benchmark_token is not None:\n            logits = logits[:-1] - logits[-1]\n\n            cats = cats[:-1]\n        \n        if self.is_sampled:\n            return logits, None, torch.argmax(F.softmax(cats, dim = -1), dim = -1)\n        else:\n            return logits[:,0], torch.exp(0.5 * logits[:,1]), torch.argmax(F.softmax(cats, dim = -1), dim = -1)","metadata":{"papermill":{"duration":0.044059,"end_time":"2021-07-10T17:26:09.335521","exception":false,"start_time":"2021-07-10T17:26:09.291462","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.093023Z","iopub.execute_input":"2021-07-26T09:14:18.093374Z","iopub.status.idle":"2021-07-26T09:14:18.1161Z","shell.execute_reply.started":"2021-07-26T09:14:18.093339Z","shell.execute_reply":"2021-07-26T09:14:18.115279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss function and metrics","metadata":{"papermill":{"duration":0.019975,"end_time":"2021-07-10T17:26:09.375678","exception":false,"start_time":"2021-07-10T17:26:09.355703","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class KLLoss(nn.Module):\n    def __init__(self):\n        super(KLLoss, self).__init__()\n        \n    def forward(self, pred_mean, pred_std, target_mean, target_std):\n        p = torch.distributions.Normal(pred_mean, pred_std)\n        q = torch.distributions.Normal(target_mean, target_std)\n        loss = torch.mean(torch.distributions.kl_divergence(p, q))\n        return loss\n    \nclass RMSELoss(nn.Module):\n    def __init__(self):\n        super(RMSELoss, self).__init__()\n        \n    def forward(self, pred_mean, target_mean):\n        return torch.mean((pred_mean - target_mean)**2)\n    \nclass RankingLoss(nn.Module):\n    def __init__(self):\n        super(RankingLoss, self).__init__()\n        \n    def forward(self, pred_mean, pred_benchmark_mean, target_mean, margin = 0.5):\n        return nn.MarginRankingLoss(margin = margin)(pred_mean, pred_benchmark_mean, torch.sign(target_mean))\n    \nclass QuadraticWeightedKappaLoss(nn.Module):\n    def __init__(self, num_cat = 7, device = 'cpu'):\n        super(QuadraticWeightedKappaLoss, self).__init__()\n        self.num_cat = num_cat\n        cats = torch.arange(num_cat).to(device)\n        self.weights = (cats.view(-1,1) - cats.view(1,-1)).pow(2) / (num_cat - 1)**2\n        \n    def _confusion_matrix(self, pred_cat, true_cat):\n        confusion_matrix = torch.zeros((self.num_cat, self.num_cat)).to(pred_cat.device)\n        for t, p in zip(true_cat.view(-1), pred_cat.view(-1)):\n            confusion_matrix[t.long(), p.long()] += 1\n        return confusion_matrix\n        \n    def forward(self, pred_cat, true_cat):\n        # Confusion matrix\n        O = self._confusion_matrix(pred_cat, true_cat)\n        \n        # Count elements in each category\n        true_hist = torch.bincount(true_cat, minlength = self.num_cat)\n        pred_hist = torch.bincount(pred_cat, minlength = self.num_cat)\n        \n        # Expected values\n        E = torch.outer(true_hist, pred_hist)\n        \n        # Normlization\n        O = O / torch.sum(O)\n        E = E / torch.sum(E)\n        \n        # Weighted Kappa\n        numerator = torch.sum(self.weights * O)\n        denominator = torch.sum(self.weights * E)\n        \n        return numerator / denominator\n    \nclass BradleyTerryLoss(nn.Module):\n    def __init__(self):\n        super(BradleyTerryLoss, self).__init__()\n        \n    def forward(self, pred_mean, true_mean):\n        batch_size = len(pred_mean)\n        true_comparison = torch.sign(true_mean.view(-1,1) - true_mean.view(1,-1))\n        pred_comparison = pred_mean.view(-1,1) - pred_mean.view(1,-1)\n        return torch.log(1 + torch.tril(torch.exp(-true_comparison * pred_comparison))).sum() / (batch_size * (batch_size - 1) / 2)\n    \ndef loss_fn(pred_mean, pred_std, target_mean, target_std, pred_cat = None, target_cat = None, loss_type = 'rmse', num_bins = None):\n    assert loss_type in ['rmse', 'kl', 'rank', 'qwk', 'rmse_rank', 'kl_rank', 'rmse_qwk', 'kl_qwk', 'rank_qwk', \n                         'bradley-terry', 'rmse_bradley-terry', 'qwk_bradley-terry', 'rmse_qwk_bradley-terry']\n    if 'qwk' in loss_type:\n        assert (pred_cat is not None) and (target_cat is not None) and (num_bins is not None)\n    if 'rank' in loss_type:\n        assert pred_benchmark_mean is not None\n    \n    device = pred_mean.device\n    \n    if loss_type == 'rmse':\n        return RMSELoss()(pred_mean, target_mean)\n    elif loss_type == 'kl':\n        return KLLoss()(pred_mean, pred_std, target_mean, target_std)\n    elif loss_type == 'rank':\n        return RankingLoss()(pred_mean, target_mean, margin = 0.5)\n    elif loss_type == 'qwk':\n        return QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'rmse_rank':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + RankingLoss()(pred_mean, pred_benchmark_mean, target_mean, margin = 0.5)\n    elif loss_type == 'kl_rank':\n        return KLLoss()(pred_mean, pred_std, target_mean, target_std) + RankingLoss()(pred_mean, pred_benchmark_mean, target_mean, margin = 0.5)\n    elif loss_type == 'rmse_qwk':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'kl_qwk':\n        return KLLoss()(pred_mean, pred_std, target_mean, target_std) + QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'bradley-terry':\n        return BradleyTerryLoss()(pred_mean, target_mean)\n    elif loss_type == 'rmse_bradley-terry':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + BradleyTerryLoss()(pred_mean, target_mean)\n    elif loss_type == 'qwk_bradley-terry':\n        return BradleyTerryLoss()(pred_mean, target_mean) + \\\n               QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'rmse_qwk_bradley-terry':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + BradleyTerryLoss()(pred_mean, target_mean) + \\\n               QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n\ndef metric_fn(pred_mean, target_mean):\n    return np.sqrt(np.mean((pred_mean - target_mean)**2))","metadata":{"papermill":{"duration":0.047882,"end_time":"2021-07-10T17:26:09.443545","exception":false,"start_time":"2021-07-10T17:26:09.395663","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.117718Z","iopub.execute_input":"2021-07-26T09:14:18.118176Z","iopub.status.idle":"2021-07-26T09:14:18.145671Z","shell.execute_reply.started":"2021-07-26T09:14:18.118141Z","shell.execute_reply":"2021-07-26T09:14:18.144764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference function","metadata":{"papermill":{"duration":0.019648,"end_time":"2021-07-10T17:26:09.483723","exception":false,"start_time":"2021-07-10T17:26:09.464075","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def infer(model, dataloader, device = 'cpu', use_tqdm = True, benchmark_token = None):\n    model.eval()\n    \n    if use_tqdm:\n        tbar = tqdm(dataloader)\n    else:\n        tbar = dataloader\n        \n    loss = 0\n    num_sample = 0\n        \n    pred = []\n        \n    for item in tbar:\n        input_ids = item['input_ids'].to(device)\n        token_type_ids = item['token_type_ids'].to(device)\n        attention_mask = item['attention_mask'].to(device)\n        targets = item['target'].to(device)\n        true_mean = targets\n        true_std = None\n        \n        batch_size = input_ids.shape[0]\n        \n        if benchmark_token is not None:\n            benchmark_input_ids, benchmark_token_type_ids, benchmark_attention_mask = benchmark_token\n            input_ids = torch.cat((input_ids, benchmark_input_ids), dim = 0)\n            token_type_ids = torch.cat((token_type_ids, benchmark_token_type_ids), dim = 0)\n            attention_mask = torch.cat((attention_mask, benchmark_attention_mask), dim = 0)\n        \n        with torch.no_grad():\n            with autocast():\n                pred_mean, pred_std, pred_bins = model(input_ids = input_ids, \n                                                       attention_mask = attention_mask, \n                                                       token_type_ids = token_type_ids)\n\n                loss_batch = loss_fn(pred_mean, pred_std, true_mean, true_std, loss_type = 'rmse')\n            \n        loss += loss_batch * batch_size\n        num_sample += batch_size\n        \n        pred.extend(pred_mean.cpu().detach().numpy())\n        \n    # Stack\n    pred = np.array(pred)\n    \n    # Compute loss\n    loss = torch.sqrt(loss / num_sample)\n    \n    return pred, loss","metadata":{"papermill":{"duration":0.032305,"end_time":"2021-07-10T17:26:09.535928","exception":false,"start_time":"2021-07-10T17:26:09.503623","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.146787Z","iopub.execute_input":"2021-07-26T09:14:18.147212Z","iopub.status.idle":"2021-07-26T09:14:18.159846Z","shell.execute_reply.started":"2021-07-26T09:14:18.147176Z","shell.execute_reply":"2021-07-26T09:14:18.158685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{"papermill":{"duration":0.019807,"end_time":"2021-07-10T17:26:09.575857","exception":false,"start_time":"2021-07-10T17:26:09.55605","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class config():\n    # For inference\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    use_tqdm = False\n    # For dataloader\n    max_len = 250\n    batch_size = 8\n    num_workers = 4\n    # For model\n    num_output = 2\n    num_bins = 1\n    model_dir = '../input/clrroberta-largev15/model_best_roberta_large_v15_4'\n    backbone = 'roberta-large'\n    model_name = '_'.join(backbone.split('-'))\n\ncfg = config()","metadata":{"papermill":{"duration":0.068519,"end_time":"2021-07-10T17:26:09.664646","exception":false,"start_time":"2021-07-10T17:26:09.596127","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.161132Z","iopub.execute_input":"2021-07-26T09:14:18.161755Z","iopub.status.idle":"2021-07-26T09:14:18.212569Z","shell.execute_reply.started":"2021-07-26T09:14:18.161715Z","shell.execute_reply":"2021-07-26T09:14:18.211607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{"papermill":{"duration":0.019715,"end_time":"2021-07-10T17:26:09.704383","exception":false,"start_time":"2021-07-10T17:26:09.684668","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(cfg.backbone)\n\nprediction = np.zeros(data.shape[0])\n\noof = []\n\nfor fold in range(5):\n    val = data[data['kfold'] == fold]\n    \n    valid_dataset = Readability_Dataset(val, tokenizer, max_len = cfg.max_len)\n    valid_dataloader = DataLoader(valid_dataset, batch_size = cfg.batch_size, num_workers = cfg.num_workers, shuffle = False)\n    \n    # Tokenize the benchmark text\n    benchmark_token = convert_examples_to_features(benchmark['excerpt'].iloc[0], tokenizer, cfg.max_len, return_tensor = True)\n    benchmark_token = (benchmark_token['input_ids'].to(cfg.device), benchmark_token['token_type_ids'].to(cfg.device), benchmark_token['attention_mask'].to(cfg.device))\n    \n    model_config = AutoConfig.from_pretrained(cfg.backbone, output_hidden_states = True)\n    model = Readability_Model(cfg.backbone, model_config, num_output = cfg.num_output, \n                              num_cat = cfg.num_bins, benchmark_token = benchmark_token).to(cfg.device)\n    \n    print('*' * 50)\n    print(f'Fold: {fold}')\n    \n    # Load pretrain models\n    path = f'{cfg.model_dir}/model_best_fold_{fold}_{cfg.model_name}.bin'\n    ckp = torch.load(path, map_location = cfg.device)\n    model.load_state_dict(ckp['model_state_dict'])\n    \n    prediction, loss = infer(model, valid_dataloader, device = cfg.device, use_tqdm = cfg.use_tqdm, benchmark_token = benchmark_token)\n    val['pred'] = prediction\n    \n    print(f'Validation loss of fold {fold} is:', loss)\n    \n    oof.append(val)\n    \noof = pd.concat(oof)","metadata":{"papermill":{"duration":252.580203,"end_time":"2021-07-10T17:30:22.304481","exception":false,"start_time":"2021-07-10T17:26:09.724278","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:14:18.214796Z","iopub.execute_input":"2021-07-26T09:14:18.215442Z","iopub.status.idle":"2021-07-26T09:18:36.329756Z","shell.execute_reply.started":"2021-07-26T09:14:18.2154Z","shell.execute_reply":"2021-07-26T09:18:36.328551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('OOF CV:', metric_fn(oof['pred'].values, oof['target'].values))\noof.to_csv(f'oof_{cfg.model_name}.csv')","metadata":{"papermill":{"duration":1.083617,"end_time":"2021-07-10T17:30:23.431265","exception":false,"start_time":"2021-07-10T17:30:22.347648","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:18:36.334373Z","iopub.execute_input":"2021-07-26T09:18:36.334875Z","iopub.status.idle":"2021-07-26T09:18:36.7375Z","shell.execute_reply.started":"2021-07-26T09:18:36.334833Z","shell.execute_reply":"2021-07-26T09:18:36.736671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of the comparison task\n* We want to know whether our models also perform well in the comparison task of texts and the benchmark text","metadata":{"papermill":{"duration":0.025682,"end_time":"2021-07-10T17:30:23.482906","exception":false,"start_time":"2021-07-10T17:30:23.457224","status":"completed"},"tags":[]}},{"cell_type":"code","source":"benchmark_text = oof[oof['standard_error'] == 0]\ntrue_compare = np.sign(oof['target'] - benchmark_text['target'].values)\npred_compare = np.sign(oof['pred'] - benchmark_text['pred'].values)\n\nprint('The number of correctly comparison based on predicted score is', sum(true_compare == pred_compare) / len(true_compare))\nprint('*' * 50)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint('Histogram of difference score from the predicted value and the benchmark text')\nsns.histplot(oof[true_compare != pred_compare]['pred'] - benchmark_text['pred'].values)\nplt.show()\n\nprint('Example of the wrong prediction in terms of comparison task (The first row is the benchmark text):')\npd.concat((benchmark_text, oof[true_compare != pred_compare].iloc[0].to_frame().T))","metadata":{"papermill":{"duration":0.378227,"end_time":"2021-07-10T17:30:23.886973","exception":false,"start_time":"2021-07-10T17:30:23.508746","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-26T09:18:36.73883Z","iopub.execute_input":"2021-07-26T09:18:36.739195Z","iopub.status.idle":"2021-07-26T09:18:37.044298Z","shell.execute_reply.started":"2021-07-26T09:18:36.739157Z","shell.execute_reply":"2021-07-26T09:18:37.043349Z"},"trusted":true},"execution_count":null,"outputs":[]}]}