{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Version 15\n* Sub-version 4\n* Train with ../input/clrcross-validation-strategies/train_folds_shuffle2.csv\n* Seed 1234\n* No QWK","metadata":{"papermill":{"duration":0.012502,"end_time":"2021-07-12T14:59:48.115586","exception":false,"start_time":"2021-07-12T14:59:48.103084","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport random\n\nimport nltk\nimport string\nimport re\nimport math\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n# Autocast\nfrom torch.cuda.amp import autocast, GradScaler\n\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, AdamW\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.693363,"end_time":"2021-07-12T14:59:55.820512","exception":false,"start_time":"2021-07-12T14:59:48.127149","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:19.916626Z","iopub.execute_input":"2021-07-25T23:25:19.917076Z","iopub.status.idle":"2021-07-25T23:25:28.376173Z","shell.execute_reply.started":"2021-07-25T23:25:19.916986Z","shell.execute_reply":"2021-07-25T23:25:28.375188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/spacy-readability/spacy_readability-master/* ./\n!cp -r ../input/syllapy/syllapy-master/* ./\nimport spacy\nfrom spacy_readability import Readability\n\nnlp = spacy.load('en')\nnlp.add_pipe(Readability(), last = True)","metadata":{"papermill":{"duration":4.183694,"end_time":"2021-07-12T15:00:00.016116","exception":false,"start_time":"2021-07-12T14:59:55.832422","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:28.377652Z","iopub.execute_input":"2021-07-25T23:25:28.37804Z","iopub.status.idle":"2021-07-25T23:25:33.03501Z","shell.execute_reply.started":"2021-07-25T23:25:28.378005Z","shell.execute_reply":"2021-07-25T23:25:33.033931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nseed = 0\nseed_everything(seed)","metadata":{"papermill":{"duration":0.025265,"end_time":"2021-07-12T15:00:00.052981","exception":false,"start_time":"2021-07-12T15:00:00.027716","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:33.037248Z","iopub.execute_input":"2021-07-25T23:25:33.037649Z","iopub.status.idle":"2021-07-25T23:25:33.047724Z","shell.execute_reply.started":"2021-07-25T23:25:33.037604Z","shell.execute_reply":"2021-07-25T23:25:33.046815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{"papermill":{"duration":0.011159,"end_time":"2021-07-12T15:00:00.075547","exception":false,"start_time":"2021-07-12T15:00:00.064388","status":"completed"},"tags":[]}},{"cell_type":"code","source":"base_dir = '../input/commonlitreadabilityprize'\n\ntrain_data = pd.read_csv(f'{base_dir}/train.csv')\nbenchmark = train_data[train_data['standard_error'] == 0.]\n\ndata = pd.read_csv(f'{base_dir}/test.csv')\nss = pd.read_csv(f'{base_dir}/sample_submission.csv')\ndata.head()","metadata":{"papermill":{"duration":0.12267,"end_time":"2021-07-12T15:00:00.210319","exception":false,"start_time":"2021-07-12T15:00:00.087649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:33.049912Z","iopub.execute_input":"2021-07-25T23:25:33.050336Z","iopub.status.idle":"2021-07-25T23:25:33.188647Z","shell.execute_reply.started":"2021-07-25T23:25:33.050292Z","shell.execute_reply":"2021-07-25T23:25:33.187804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower().strip()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\ndef text_preprocessing(text):\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    combined_text = ' '.join(tokenized_text)\n    return combined_text\n\ndef readability_feat(text):\n    text = nlp(text)\n    \n    return np.array([text._.flesch_kincaid_grade_level,\n                     text._.flesch_kincaid_reading_ease,\n                     text._.dale_chall,\n                     text._.coleman_liau_index,\n                     text._.automated_readability_index,\n                     text._.forcast], dtype = np.float)\n\ndef sample_text(targets, num_output = 5):\n    mean, var = targets[0], targets[1]\n    if targets[1] != 0.:\n        sampled_target = torch.normal(mean, var, size = (num_output,))\n    else:\n        sampled_target = torch.tensor([0.] * num_output, dtype = torch.float)\n    return sampled_target\n\ndef convert_examples_to_features(text, tokenizer, max_len, is_test = False, return_tensor = False):\n    # Take from https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-fit\n    text = text.replace('\\n', '')\n    if return_tensor:\n        tok = tokenizer.encode_plus(\n            text, \n            max_length = max_len, \n            padding = 'max_length', \n            return_tensors = 'pt',\n            truncation = True,\n            return_attention_mask = True,\n            return_token_type_ids = True\n        )\n    else:\n        tok = tokenizer.encode_plus(\n            text, \n            max_length = max_len, \n            padding = 'max_length', \n            truncation = True,\n            return_attention_mask = True,\n            return_token_type_ids = True\n        )\n    return tok\n\ndef form_dataset(token, external_features = None, target = None, bins = None):\n    if target is not None:\n        if bins is not None:\n            if external_features is not None:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'external_features': torch.tensor(external_features, dtype = torch.float),\n                    'target': target,\n                    'bins': bins,\n                }\n            else:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'target': target,\n                    'bins': bins,\n                }\n        else:\n            if external_features is not None:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'external_features': torch.tensor(external_features, dtype = torch.float),\n                    'target': target,\n                }\n            else:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'target': target,\n                }\n    else:\n        if external_features is not None:\n            return {\n                'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                'external_features': torch.tensor(external_features, dtype = torch.float),\n            }\n        else:\n            return {\n                'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n            }","metadata":{"papermill":{"duration":0.036049,"end_time":"2021-07-12T15:00:00.258611","exception":false,"start_time":"2021-07-12T15:00:00.222562","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:33.190036Z","iopub.execute_input":"2021-07-25T23:25:33.190609Z","iopub.status.idle":"2021-07-25T23:25:33.212639Z","shell.execute_reply.started":"2021-07-25T23:25:33.190567Z","shell.execute_reply":"2021-07-25T23:25:33.211516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.011584,"end_time":"2021-07-12T15:00:00.282018","exception":false,"start_time":"2021-07-12T15:00:00.270434","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Readability_Dataset(Dataset):\n    def __init__(self, documents, tokenizer, max_len = 300, mode = 'infer'):\n        self.documents = documents\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.documents)\n    \n    def __getitem__(self, idx):\n        sample = self.documents.iloc[idx]\n        document = sample['excerpt']\n        \n        # Tokenize\n        features = convert_examples_to_features(document, self.tokenizer, self.max_len)\n        \n        return form_dataset(features)","metadata":{"papermill":{"duration":0.01957,"end_time":"2021-07-12T15:00:00.313353","exception":false,"start_time":"2021-07-12T15:00:00.293783","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:33.214091Z","iopub.execute_input":"2021-07-25T23:25:33.214506Z","iopub.status.idle":"2021-07-25T23:25:33.226832Z","shell.execute_reply.started":"2021-07-25T23:25:33.214464Z","shell.execute_reply":"2021-07-25T23:25:33.22569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.011911,"end_time":"2021-07-12T15:00:00.336922","exception":false,"start_time":"2021-07-12T15:00:00.325011","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Readability_Model(nn.Module):\n    def __init__(self, backbone, model_config, is_sampled = False, num_external_features = 6, num_output = 2, \n                 num_cat = 7, attention_dim = 1024, multisample_dropout = True, benchmark_token = None):\n        super(Readability_Model, self).__init__()\n        self.model_config = model_config\n        self.is_sampled = is_sampled\n        self.benchmark_token = benchmark_token\n        self.backbone = AutoModel.from_pretrained(backbone, config = self.model_config)\n        self.layer_norm = nn.LayerNorm(self.model_config.hidden_size * 2)    # Concat of mean and max pooling\n        self.output = nn.Linear(self.model_config.hidden_size * 2, num_output)   #  + num_external_features\n        self.output_cat = nn.Linear(self.model_config.hidden_size * 2, num_cat)\n        \n        # Attention pooler\n        self.word_weight = nn.Linear(self.model_config.hidden_size * 2, attention_dim)\n        self.context_weight = nn.Linear(attention_dim, 1)\n        \n        self.hidden_layer_weights = nn.Parameter(torch.zeros(self.model_config.num_hidden_layers).view(-1, 1, 1, 1))\n        \n        # Dropout layers\n        if multisample_dropout:\n            self.dropouts_output = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n            self.dropouts_cat = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n        else:\n            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n        \n        # Initialize weights\n        self._init_weights(self.layer_norm)\n        self._init_weights(self.output)\n        self._init_weights(self.word_weight)\n        self._init_weights(self.context_weight)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean = 0.0, std = self.model_config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean = 0.0, std = self.model_config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def forward(self, input_ids, token_type_ids, attention_mask, external_features = None):\n        output_backbone = self.backbone(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n        \n        # Extract output\n        hidden_states = output_backbone.hidden_states\n        \n        # Mean/max pooling (over hidden layers), concatenate with pooler\n        hidden_states = torch.stack(tuple(hidden_states[-i-1] for i in range(len(hidden_states) - 1)), dim = 0)\n        layer_weight = F.softmax(self.hidden_layer_weights, dim = 0)\n        out_mean = torch.sum(hidden_states * layer_weight, dim = 0)\n        out_max, _ = torch.max(hidden_states, dim = 0)\n        output_backbone = torch.cat((out_mean, out_max), dim = -1)\n        output_backbone = self.layer_norm(output_backbone)\n        \n        # Attention Pooling (over time)\n        u_i = torch.tanh(self.word_weight(output_backbone))\n        u_w = self.context_weight(u_i).squeeze(1)\n        val = u_w.max()\n        att = torch.exp(u_w - val)\n        att = att / torch.sum(att, dim = 1, keepdim = True)\n        \n        output = output_backbone * att\n        output = output.sum(dim = 1)\n        \n        # Multiple dropout\n        for i, dropout in enumerate(self.dropouts_output):\n            if i == 0:\n                logits = self.output(dropout(output))\n                cats = self.output_cat(self.dropouts_cat[i](output))\n            else:\n                logits += self.output(dropout(output))\n                cats += self.output_cat(self.dropouts_cat[i](output))\n        \n        logits /= len(self.dropouts_output)\n        cats /= len(self.dropouts_output)\n        \n        if self.benchmark_token is not None:\n            logits = logits[:-1] - logits[-1]\n\n            cats = cats[:-1]\n        \n        if self.is_sampled:\n            return logits, None, torch.argmax(F.softmax(cats, dim = -1), dim = -1)\n        else:\n            return logits[:,0], torch.exp(0.5 * logits[:,1]), torch.argmax(F.softmax(cats, dim = -1), dim = -1)","metadata":{"papermill":{"duration":0.036532,"end_time":"2021-07-12T15:00:00.385535","exception":false,"start_time":"2021-07-12T15:00:00.349003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:33.228297Z","iopub.execute_input":"2021-07-25T23:25:33.228879Z","iopub.status.idle":"2021-07-25T23:25:33.25662Z","shell.execute_reply.started":"2021-07-25T23:25:33.228835Z","shell.execute_reply":"2021-07-25T23:25:33.25524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference function","metadata":{"papermill":{"duration":0.011754,"end_time":"2021-07-12T15:00:00.409245","exception":false,"start_time":"2021-07-12T15:00:00.397491","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def infer(model, dataloader, device = 'cpu', use_tqdm = True, benchmark_token = None):\n    model.eval()\n    \n    if use_tqdm:\n        tbar = tqdm(dataloader)\n    else:\n        tbar = dataloader\n        \n    pred = []\n        \n    for item in tbar:\n        input_ids = item['input_ids'].to(device)\n        token_type_ids = item['token_type_ids'].to(device)\n        attention_mask = item['attention_mask'].to(device)\n        \n        if benchmark_token is not None:\n            benchmark_input_ids, benchmark_token_type_ids, benchmark_attention_mask = benchmark_token\n            input_ids = torch.cat((input_ids, benchmark_input_ids), dim = 0)\n            token_type_ids = torch.cat((token_type_ids, benchmark_token_type_ids), dim = 0)\n            attention_mask = torch.cat((attention_mask, benchmark_attention_mask), dim = 0)\n            \n        with torch.no_grad():\n            with autocast():\n                pred_mean, pred_std, pred_bins = model(input_ids = input_ids, \n                                                       attention_mask = attention_mask, \n                                                       token_type_ids = token_type_ids)\n        \n        pred.extend(pred_mean.cpu().detach().numpy())\n        \n    # Stack\n    pred = np.array(pred)\n    \n    return pred","metadata":{"papermill":{"duration":0.022484,"end_time":"2021-07-12T15:00:00.443484","exception":false,"start_time":"2021-07-12T15:00:00.421","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:33.259429Z","iopub.execute_input":"2021-07-25T23:25:33.259881Z","iopub.status.idle":"2021-07-25T23:25:33.271047Z","shell.execute_reply.started":"2021-07-25T23:25:33.259838Z","shell.execute_reply":"2021-07-25T23:25:33.270282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{"papermill":{"duration":0.011504,"end_time":"2021-07-12T15:00:00.46673","exception":false,"start_time":"2021-07-12T15:00:00.455226","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class config():\n    # For inference\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    use_tqdm = True\n    # For dataloader\n    max_len = 250\n    batch_size = 8\n    num_workers = 4\n    # For model\n    num_bins = 1\n    model_dir = '../input/clrroberta-largev15/model_best_roberta_large_v15_4'\n    backbone = '../input/robertalarge'\n    model_name = 'roberta_large'\n\ncfg = config()","metadata":{"papermill":{"duration":0.076991,"end_time":"2021-07-12T15:00:00.555461","exception":false,"start_time":"2021-07-12T15:00:00.47847","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:45.272501Z","iopub.execute_input":"2021-07-25T23:25:45.272837Z","iopub.status.idle":"2021-07-25T23:25:45.277868Z","shell.execute_reply.started":"2021-07-25T23:25:45.272806Z","shell.execute_reply":"2021-07-25T23:25:45.27687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{"papermill":{"duration":0.011606,"end_time":"2021-07-12T15:00:00.579058","exception":false,"start_time":"2021-07-12T15:00:00.567452","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(cfg.backbone, local_files_only = True, checkpoint_file = 'model.pt')\ninfer_dataset = Readability_Dataset(data, tokenizer, max_len = cfg.max_len, mode = 'infer')\ninfer_dataloader = DataLoader(infer_dataset, batch_size = cfg.batch_size, num_workers = cfg.num_workers, shuffle = False)\n\nprediction = np.zeros(data.shape[0])\n\n# Tokenize the benchmark text\nbenchmark_token = convert_examples_to_features(benchmark['excerpt'].iloc[0], tokenizer, cfg.max_len, return_tensor = True)\nbenchmark_token = (benchmark_token['input_ids'].to(cfg.device), benchmark_token['token_type_ids'].to(cfg.device), benchmark_token['attention_mask'].to(cfg.device))\n\nfor fold in range(5):\n    model_config = AutoConfig.from_pretrained(cfg.backbone, output_hidden_states = True)\n    model = Readability_Model(cfg.backbone, model_config, num_cat = cfg.num_bins, benchmark_token = benchmark_token).to(cfg.device)\n    \n    print('*' * 50)\n    print(f'Fold: {fold}')\n    \n    # Load pretrain models\n    ckp = torch.load(f'{cfg.model_dir}/model_best_fold_{fold}_{cfg.model_name}.bin', map_location = cfg.device)\n    model.load_state_dict(ckp['model_state_dict'])\n    \n    prediction += infer(model, infer_dataloader, device = cfg.device, use_tqdm = cfg.use_tqdm, benchmark_token = benchmark_token) / 5\n    \nss['target'] = prediction","metadata":{"papermill":{"duration":115.577674,"end_time":"2021-07-12T15:01:56.168685","exception":false,"start_time":"2021-07-12T15:00:00.591011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-25T23:25:45.872565Z","iopub.execute_input":"2021-07-25T23:25:45.872905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.014878,"end_time":"2021-07-12T15:01:56.199028","exception":false,"start_time":"2021-07-12T15:01:56.18415","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ss.to_csv('submission.csv', index = None)\nss","metadata":{"papermill":{"duration":0.808998,"end_time":"2021-07-12T15:01:57.023221","exception":false,"start_time":"2021-07-12T15:01:56.214223","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}