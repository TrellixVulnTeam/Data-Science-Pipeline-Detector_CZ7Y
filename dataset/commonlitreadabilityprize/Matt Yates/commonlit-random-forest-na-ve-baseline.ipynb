{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CommonLit Random Forest Naive Baseline\n\n- I call this a \"naive\" baseline because it makes no target distribution assumptions, hyperparameter tuning is brief and simple, algorithm select is selected due to its ease to implement and power, etc.  ","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport os\nimport gc\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import uniform, truncnorm, randint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"%%time\n\ntfidf = TfidfVectorizer(stop_words='english')\nrfr = RandomForestRegressor(criterion='mae')\npipe = Pipeline([('tfidf', tfidf), ('rfr', rfr)])\ndistributions = {'tfidf__max_df': uniform(.9, .05),\n                 'tfidf__min_df': uniform(0.02, .1),\n                 'tfidf__max_features': randint(100,5000),\n                 'tfidf__ngram_range': [(1,1),(1,2),(1,3)],\n                 'rfr__n_estimators': randint(5,500),\n                 'rfr__max_depth': randint(1,8)}\nreg = RandomizedSearchCV(pipe, distributions, random_state=0, n_iter=40, cv=5, \n                         scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\nsearch = reg.fit(df['excerpt'], df['target']) # best model is search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"dft = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ndft.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = search.best_estimator_.predict(dft['excerpt'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft['target'] = target\ndft.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft[['id','target']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}