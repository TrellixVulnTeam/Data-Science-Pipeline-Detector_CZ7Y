{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CommonLit Random Forest Baseline - Advanced Features - Training\n\n- I call this an \"advanced features\" baseline because:\n    - Takes some features from: \n        - https://www.kaggle.com/konradb/linear-baseline-with-cv\n        - https://www.kaggle.com/ruchi798/commonlit-readability-prize-eda-baseline?scriptVersionId=61834534\n        - https://www.kaggle.com/ravishah1/readability-feature-engineering-non-nn-baseline\n        - Amazing work by:\n            - https://www.kaggle.com/konradb\n            - https://www.kaggle.com/anaverageengineer\n            - https://www.kaggle.com/ruchi798\n            - https://www.kaggle.com/ravishah1\n    - Includes additional features\n        - https://medium.com/analytics-vidhya/visualising-text-complexity-with-readability-formulas-c86474efc730\n        - TF-IDF\n        - LDA\n        - Tag Count\n        - Difficult Word features using data from Sagemaker Ground Truth labeling job\n            - https://www.kaggle.com/yeayates21/commonlit-train-test-vocab\n            - https://www.kaggle.com/yeayates21/commonlit-sagemaker-ground-truth-data-eda\n    - Wraps everything in a sklearn custom transformer\n- This is not the end-all and be-all of advanced features.  This is just 1 version.\n- Using XGBoost.\n- For similar but thiner pipeline without advanced features, see https://www.kaggle.com/yeayates21/commonlit-random-forest-na-ve-baseline","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport os\nimport gc\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import uniform, truncnorm, randint\nimport cloudpickle\nimport spacy\nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom fuzzywuzzy import fuzz\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.read_csv(\"../input/mjycommonlitdata/bbc_commonlit_ssl.csv\")\ndf2.rename(columns={\"text\": \"excerpt\"}, inplace=True)\ndf2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering Transformer","metadata":{}},{"cell_type":"code","source":"class CustomFeatureEngineeringTransfomer(BaseEstimator, TransformerMixin):\n    def __init__(self, tfidf_stop_words='english', tfidf_ngram_max=3, tfidf_max_df=0.9, tfidf_min_df=0.01, \n                 tfidf_max_features=1000, vloc='', ldanc=30, smgtloc=''):\n        super().__init__()\n        self.tfidf_stop_words = tfidf_stop_words\n        self.tfidf_ngram_max = tfidf_ngram_max\n        self.tfidf_max_df = tfidf_max_df\n        self.tfidf_min_df = tfidf_min_df\n        self.tfidf_max_features = tfidf_max_features\n        self.tv = TfidfVectorizer(stop_words=self.tfidf_stop_words,ngram_range=(1,self.tfidf_ngram_max),\n                                  max_df=self.tfidf_max_df,min_df=self.tfidf_min_df,max_features=self.tfidf_max_features)\n        self.vloc = \"../input/english-word-frequency/unigram_freq.csv\"\n        self.smgtloc = \"../input/mjycommonlitdata/CommonLit_SagemakerGroundTruth_WordDifficulty.csv\"\n        self.ldanc = ldanc\n        self.lda = LatentDirichletAllocation(n_components=self.ldanc)\n        \n        \n    def fit(self, X, y=None):\n        self.tv = self.tv.fit(X)\n        tv_res = self.tv.transform(X)\n        self.lda = self.lda.fit(tv_res)\n        return self\n    \n    def transform(self, X, y=None):\n        fenp = X.copy()\n        fedf = pd.DataFrame()\n        fedf['text'] = fenp\n        \n        # count syllables: https://stackoverflow.com/questions/46759492/syllable-count-in-python\n        def syllable_count(word):\n            count = 0\n            vowels = \"aeiouy\"\n            if word[0] in vowels:\n                count += 1\n            for index in range(1, len(word)):\n                if word[index] in vowels and word[index - 1] not in vowels:\n                    count += 1\n                    if word.endswith(\"e\"):\n                        count -= 1\n            if count == 0:\n                count += 1\n            return count\n        \n        # number of characters\n        fedf['nof_char'] = fedf['text'].apply(len)\n        \n        # number of words\n        fedf['nof_words'] = fedf['text'].apply(lambda s: len(s.split(' ')))\n\n        # words to character ratio\n        fedf['w2c'] = fedf['nof_words'] / fedf['nof_char']\n        \n        # number of sentences\n        fedf['nof_sentences'] = fedf['text'].apply(lambda s: s.count('.'))\n        \n        # number of quotes\n        fedf['nof_quotes'] = fedf['text'].apply(lambda s: s.count('\"') / 2)\n\n        # number of syllables\n        fedf['nof_syllables'] =  fedf['text'].apply(lambda s: syllable_count(s))\n        \n        def syllable_count2(word):\n            count = 0\n            vowels = \"aeiouy\"\n            if (word=='') | (word==' ') | (word==None):\n                return 0\n            else:\n                if word[0] in vowels:\n                    count += 1\n                for index in range(1, len(word)):\n                    if word[index] in vowels and word[index - 1] not in vowels:\n                        count += 1\n                        if word.endswith(\"e\"):\n                            count -= 1\n                if count == 0:\n                    count += 1\n                return count\n        \n        # number of polysyllabic words\n        fedf['nof_polysyllabic'] =  fedf['text'].apply(lambda s: np.sum([1 for x in s.split(' ') if syllable_count2(x)>=2]))\n        \n        # number of pauses\n        fedf['nof_pauses'] = fedf['text'].apply(lambda s: s.count(','))\n\n        # Fleisch score\n        # https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n        fedf['fsa'] = 206.835 - 1.015 * (fedf['nof_words'] / fedf['nof_sentences'])\n        fedf['fsb'] = -84.6 * (fedf['nof_syllables'] / fedf['nof_words'])\n        fedf['fleisch_score'] = fedf['fsa'] + fedf['fsb']\n\n        # Fleisch score 2\n        fedf['fsa2'] = (fedf['nof_words'] / fedf['nof_sentences'])\n        fedf['fsb2'] = (fedf['nof_syllables'] / fedf['nof_words'])\n        fedf['fleisch_score2'] = 0.39 * fedf['fsa2'] + 11.8 * fedf['fsb2'] - 15.59\n        \n        # Automated Readability Index\n        fedf['auto_read_idx'] = 4.71*(fedf['nof_char']/fedf['nof_words']) + 0.5*fedf['fsa2'] + 21.43\n        \n        # Smog Index\n        fedf['smog_idx'] = 1.0430*np.sqrt(fedf['nof_polysyllabic']*(30/fedf['nof_sentences'])) + 3.1291\n\n        # number of unique words\n        fedf['nof_unique_words'] = fedf['text'].apply(lambda s: len(set( s.split(' ') )))\n        \n        # longest word\n        fedf['max_word_size'] = fedf['text'].apply(lambda s: max([len(x) for x in s.split(' ')]))\n        \n        # average word size\n        fedf['avg_word_size'] = fedf['text'].apply(lambda s: np.mean([len(x) for x in s.split(' ')]))\n        \n        # median word size\n        fedf['med_word_size'] = fedf['text'].apply(lambda s: np.median([len(x) for x in s.split(' ')]))\n\n        # text diversity\n        fedf['txt_diversity'] = fedf['nof_unique_words'] / fedf['nof_words']\n        \n        # spacy\n        nlp = spacy.load('en_core_web_lg')\n        with nlp.disable_pipes():\n            train_vectors = np.array([nlp(text).vector for text in fedf['text'].values.tolist()])\n            \n        namelist = ['f' + str(ii) for ii in range(train_vectors.shape[1])]\n        spdf = pd.DataFrame(train_vectors)\n        spdf.columns = namelist\n        \n        # vocab complexity (low values means more complex words and high values means more commonly used English words)\n        easy_vocab = pd.read_csv(self.vloc)\n        total_count = sum(easy_vocab['count'].values)\n        easy_vocab_dic = easy_vocab.set_index('word').to_dict()\n        sub_val = 1\n        fedf['vocab_complexity1'] = fedf['text'].apply(lambda x: \n                                                       sum([easy_vocab_dic['count'].get(s, sub_val) \n                                                            for s in re.sub(r'([^a-zA-Z ]+?)','',x).lower().split(' ')]))\n        # normalized by number of total words in text and total count in 'easy_vocab'\n        fedf['vocab_complexity1_norm'] = fedf['vocab_complexity1'] / (fedf['nof_words'] + ([total_count]*len(fedf)))\n        \n        # number of complex words\n        fedf['nof_complex_words'] = fedf['text'].apply(lambda x: \n                                                       sum([1 for s in re.sub(r'([^a-zA-Z ]+?)','',x).lower().split(' ') \n                                                            if easy_vocab_dic['count'].get(s, sub_val)<369180]))\n        \n        # Gunning Fog\n        fedf['gunning_fog'] = 0.4*((fedf['nof_words']/fedf['nof_sentences'])+100*(fedf['nof_complex_words']/fedf['nof_words']))\n        \n        # proper noun estimate\n        # (we subtract by nof_sentences because we assume each sentence starts with a capital letter)\n        fedf['proper_noun_est'] = fedf['text'].apply(lambda x: sum(1 for c in x if x.isupper())) - fedf['nof_sentences']\n        \n        # number of questions\n        fedf['nof_questions'] = fedf['text'].apply(lambda s: s.count('?'))\n        \n        # number of exclamations\n        fedf['nof_exclamations'] = fedf['text'].apply(lambda s: s.count('!'))\n        \n        # number of colons\n        fedf['nof_colons'] = fedf['text'].apply(lambda s: s.count(':'))\n        \n        # number of semicolons\n        fedf['nof_semicolons'] = fedf['text'].apply(lambda s: s.count(';'))\n        \n        # number of commas\n        fedf['nof_commas'] = fedf['text'].apply(lambda s: s.count(','))\n        \n        # number of hyphens\n        fedf['nof_hyphens'] = fedf['text'].apply(lambda s: s.count('-'))\n        \n        # sentiment\n        fedf['polarity'] = fedf['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n        fedf['subjectivity'] = fedf['text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n        \n        # number of noun phrases\n        fedf['nof_noun_phrases'] = fedf['text'].apply(lambda x: len(TextBlob(x).noun_phrases))\n        \n        ### pos columns\n        fedf['pos_tags'] = fedf['text'].str.split().map(pos_tag)\n        \n        def count_tags(pos_tags):\n            tag_count = {}\n            for word,tag in pos_tags:\n                if tag in tag_count:\n                    tag_count[tag] += 1\n                else:\n                    tag_count[tag] = 1\n            return tag_count\n\n        fedf['tag_counts'] = fedf['pos_tags'].map(count_tags)\n        tag_cols = ['UH', ')', 'RP', 'WP', \"''\", 'POS', '.', 'NN', 'WRB', ',', '$', 'TO', ':', 'JJ', 'VB', 'VBN', 'RBS', 'NNS', \n                    'NNP', 'PDT', 'JJS', 'NNPS', 'IN', 'CD', 'VBP', '(', 'PRP$', 'WDT', 'RBR', 'WP$', 'VBD', 'JJR', 'FW', 'RB', \n                    'CC', 'DT', 'PRP', 'VBZ', 'MD', 'EX', 'VBG']\n        \n        for tag in tag_cols:\n            fedf[tag] = fedf['tag_counts'].map(lambda x: x.get(tag, 0))\n        \n        fedf.drop(['pos_tags','tag_counts'], axis=1, inplace=True)\n        \n        ### Sagemaker Ground Truth Features\n        sgt = pd.read_csv(\"../input/mjycommonlitdata/CommonLit_SagemakerGroundTruth_WordDifficulty.csv\")\n        vocab_dic0 = sgt[['source','Easy_Word_Conf']].set_index('source').to_dict()\n        vocab_dic1 = sgt[['source','Modr_Word_Conf']].set_index('source').to_dict()\n        vocab_dic2 = sgt[['source','Diff_Word_Conf']].set_index('source').to_dict()\n        vocab_dic3 = sgt[['source','NotW_Word_Conf']].set_index('source').to_dict()\n        \n        def sgt_txt_cln(x):\n            words = list(re.split(r'\\W+', x))\n            return [x for x in words if not any(c.isdigit() for c in x)]\n        \n        def avg_easy_word_scorer(x):\n            words_no_num = sgt_txt_cln(x)\n            scores = [vocab_dic0['Easy_Word_Conf'].get(x, 0) for x in words_no_num]\n            score = np.mean(scores)\n            return score\n        \n        # average easy word score\n        fedf['EasyWordScore'] = fedf['text'].apply(lambda x: avg_easy_word_scorer(x))\n        \n        def avg_modr_word_scorer(x):\n            words_no_num = sgt_txt_cln(x)\n            scores = [vocab_dic1['Modr_Word_Conf'].get(x, 0) for x in words_no_num]\n            score = np.mean(scores)\n            return score\n        \n        # average moderate word score\n        fedf['ModrWordScore'] = fedf['text'].apply(lambda x: avg_modr_word_scorer(x))\n        \n        def avg_diff_word_scorer(x):\n            words_no_num = sgt_txt_cln(x)\n            scores = [vocab_dic2['Diff_Word_Conf'].get(x, 0) for x in words_no_num]\n            score = np.mean(scores)\n            return score\n        \n        # average difficult word score\n        fedf['DiffWordScore'] = fedf['text'].apply(lambda x: avg_diff_word_scorer(x))\n        \n        def avg_notw_word_scorer(x):\n            words_no_num = sgt_txt_cln(x)\n            scores = [vocab_dic3['NotW_Word_Conf'].get(x, 0) for x in words_no_num]\n            score = np.mean(scores)\n            return score\n        \n        # average 'not a word' word score\n        fedf['NotwWordScore'] = fedf['text'].apply(lambda x: avg_notw_word_scorer(x))\n        \n        def nof_easy_words(x):\n            words_no_num =sgt_txt_cln(x)\n            count = [1 if vocab_dic0['Easy_Word_Conf'].get(x, 0)>.9 else 0 for x in words_no_num]\n            score = np.sum(count)\n            return score\n        \n        # number of easy words\n        fedf['nof_easy_words'] = fedf['text'].apply(lambda x: nof_easy_words(x))\n        \n        def nof_modr_words(x):\n            words_no_num =sgt_txt_cln(x)\n            count = [1 if vocab_dic1['Modr_Word_Conf'].get(x, 0)>.9 else 0 for x in words_no_num]\n            score = np.sum(count)\n            return score\n        \n        # number of moderate words\n        fedf['nof_modr_words'] = fedf['text'].apply(lambda x: nof_modr_words(x))\n        \n        def nof_diff_words(x):\n            words_no_num =sgt_txt_cln(x)\n            count = [1 if vocab_dic2['Diff_Word_Conf'].get(x, 0)>.9 else 0 for x in words_no_num]\n            score = np.sum(count)\n            return score\n        \n        # number of difficult words\n        fedf['nof_diff_words'] = fedf['text'].apply(lambda x: nof_diff_words(x))\n        \n        def nof_notw_words(x):\n            words_no_num =sgt_txt_cln(x)\n            count = [1 if vocab_dic3['NotW_Word_Conf'].get(x, 0)>.9 else 0 for x in words_no_num]\n            score = np.sum(count)\n            return score\n        \n        # number of \"not word\" words\n        fedf['nof_notw_words'] = fedf['text'].apply(lambda x: nof_notw_words(x))\n        \n        def nof_easy_words_v2(x):\n            words_no_num = sgt_txt_cln(x)\n            sclas = [np.argmax([vocab_dic0['Easy_Word_Conf'].get(x, 0),\n                                vocab_dic1['Modr_Word_Conf'].get(x, 0),\n                                vocab_dic2['Diff_Word_Conf'].get(x, 0),\n                                vocab_dic3['NotW_Word_Conf'].get(x, 0)]) for x in words_no_num]\n            score = np.sum([1 if clas==0 else 0 for clas in sclas])\n            return score\n        \n        # number of easy words - version 2\n        fedf['nof_easy_words_v2'] = fedf['text'].apply(lambda x: nof_easy_words_v2(x))\n        \n        # easy word ratio\n        fedf['easy_words_v2_ratio'] = fedf['nof_easy_words_v2'] / fedf['nof_words']\n        \n        def nof_modr_words_v2(x):\n            words_no_num = sgt_txt_cln(x)\n            sclas = [np.argmax([vocab_dic0['Easy_Word_Conf'].get(x, 0),\n                                vocab_dic1['Modr_Word_Conf'].get(x, 0),\n                                vocab_dic2['Diff_Word_Conf'].get(x, 0),\n                                vocab_dic3['NotW_Word_Conf'].get(x, 0)]) for x in words_no_num]\n            score = np.sum([1 if clas==1 else 0 for clas in sclas])\n            return score\n        \n        # number of easy words - version 2\n        fedf['nof_modr_words_v2'] = fedf['text'].apply(lambda x: nof_modr_words_v2(x))\n        \n        # moderate word ratio\n        fedf['modr_words_v2_ratio'] = fedf['nof_modr_words_v2'] / fedf['nof_words']\n        \n        def nof_diff_words_v2(x):\n            words_no_num = sgt_txt_cln(x)\n            sclas = [np.argmax([vocab_dic0['Easy_Word_Conf'].get(x, 0),\n                                vocab_dic1['Modr_Word_Conf'].get(x, 0),\n                                vocab_dic2['Diff_Word_Conf'].get(x, 0),\n                                vocab_dic3['NotW_Word_Conf'].get(x, 0)]) for x in words_no_num]\n            score = np.sum([1 if clas==2 else 0 for clas in sclas])\n            return score\n        \n        # number of easy words - version 2\n        fedf['nof_diff_words_v2'] = fedf['text'].apply(lambda x: nof_diff_words_v2(x))\n        \n        # difficult word ratio\n        fedf['diff_words_v2_ratio'] = fedf['nof_diff_words_v2'] / fedf['nof_words']\n        \n        def nof_notw_words_v2(x):\n            words_no_num = sgt_txt_cln(x)\n            sclas = [np.argmax([vocab_dic0['Easy_Word_Conf'].get(x, 0),\n                                vocab_dic1['Modr_Word_Conf'].get(x, 0),\n                                vocab_dic2['Diff_Word_Conf'].get(x, 0),\n                                vocab_dic3['NotW_Word_Conf'].get(x, 0)]) for x in words_no_num]\n            score = np.sum([1 if clas==3 else 0 for clas in sclas])\n            return score\n        \n        # number of 'not word' words - version 2\n        fedf['nof_notw_words_v2'] = fedf['text'].apply(lambda x: nof_notw_words_v2(x))\n        \n        # 'not word' word ratio\n        fedf['notw_words_v2_ratio'] = fedf['nof_notw_words_v2'] / fedf['nof_words']\n        \n        # complex language v1\n        fedf['complex_lang_v1'] = fedf['nof_complex_words']/ fedf['nof_words']\n        \n        # straight avg complex language\n        fedf['strgt_avg_complex_lang'] = fedf['diff_words_v2_ratio']*0.5 + fedf['complex_lang_v1']*0.5\n        \n        # sentence statistics (average length, max length; by words and by characters)\n        fedf['avg_sent_wrd_len'] = fedf['text'].apply(lambda s: np.mean([len(j) for j in [x.split(' ') for x in s.split('.')]]))\n        fedf['max_sent_wrd_len'] = fedf['text'].apply(lambda s: np.max([len(j) for j in [x.split(' ') for x in s.split('.')]]))\n        fedf['avg_sent_str_len'] = fedf['text'].apply(lambda s: np.mean([len(x) for x in s.split('.')]))\n        fedf['max_sent_str_len'] = fedf['text'].apply(lambda s: np.max([len(x) for x in s.split('.')]))\n        \n        # tfidf\n        tv_res = self.tv.transform(fenp)\n        tvdf = pd.DataFrame(tv_res.todense(), columns=self.tv.get_feature_names())\n        #tvdf['avg_tfidf'] = tvdf.mean(axis=1)\n        #tvdf['med_tfidf'] = tvdf.median(axis=1) # most values end up being 0\n        #tvdf['lowq_tfidf'] = tvdf.quantile(.1, axis=1) # most values end up being 0\n        \n        # lda\n        lda_res = self.lda.transform(tv_res)\n        ladf = pd.DataFrame(lda_res, columns=[\"LDA\"+str(x) for x in range(lda_res.shape[1])])\n        \n        # final join\n        df = pd.concat([fedf, spdf, tvdf, ladf], axis = 1)\n        df.drop(['text'], axis=1, inplace=True)\n        \n        return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Validation Split","metadata":{}},{"cell_type":"code","source":"df1, valid = train_test_split(df, test_size=0.25, random_state=42)\n\n# stack data in 1 training set\ntrain = pd.concat([\n    df1[['excerpt', 'target']],\n    df2[['excerpt', 'target']]\n])\n\nx_train = train.excerpt.values\ny_train = train.target.values\n\nx_valid = valid.excerpt.values\ny_valid = valid.target.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Search Pipeline","metadata":{}},{"cell_type":"code","source":"%%time\n\ncfet = CustomFeatureEngineeringTransfomer(tfidf_stop_words='english')\nxgb = XGBRegressor()\npipe = Pipeline([('cfet', cfet), ('xgb', xgb)])\ndistributions = {'cfet__tfidf_max_df': uniform(.6, .05),\n                 'cfet__tfidf_min_df': uniform(0.02, .3),\n                 'cfet__tfidf_max_features': randint(10,600),\n                 'cfet__tfidf_ngram_max': [3],\n                 'cfet__ldanc': randint(5,75),\n                 'xgb__n_estimators': randint(5,400),\n                 'xgb__max_depth': randint(1,5)}\nreg = RandomizedSearchCV(pipe, distributions, random_state=4582, n_iter=32, cv=3, \n                         scoring='neg_mean_squared_error', n_jobs=-1, verbose=2, error_score='raise')\nsearch = reg.fit(x_train, y_train) # best model is search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"cloudpickle.dump(search.best_estimator_, open(\"comlit_xgb_model6.pkl\", \"wb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"markdown","source":"#### Best Score and Parameter Set","metadata":{}},{"cell_type":"code","source":"print(\"Best model scored mse of {} using the following hyperparameters: {}\".format(search.best_score_, search.best_params_))\nprint(\"\")\nprint(\"CV RMSE: \", np.sqrt(np.abs(search.best_score_)))\nprint(\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Holdout Score","metadata":{}},{"cell_type":"code","source":"validation_predictions = search.best_estimator_.predict(x_valid)\nprint(\"Holdout RMSE: \", np.sqrt(mean_squared_error(y_valid, validation_predictions)))\nprint(\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"importances = search.best_estimator_.named_steps['xgb'].feature_importances_\ncfet = CustomFeatureEngineeringTransfomer(tfidf_max_df=search.best_params_['cfet__tfidf_max_df'],tfidf_min_df=search.best_params_['cfet__tfidf_min_df'],\n                                          tfidf_max_features=search.best_params_['cfet__tfidf_max_features'],\n                                          tfidf_ngram_max=search.best_params_['cfet__tfidf_ngram_max'],\n                                          tfidf_stop_words='english')\nfeatures = list(cfet.fit_transform(df['excerpt']).columns)\nfidf = pd.DataFrame()\nfidf['feature'] = pd.Series(features)\nfidf['importance'] = pd.Series(importances)\nfidf.sort_values(by=['importance'], ascending=False, inplace=True)\nfidf.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n\n(just for QA, we'll run inference in another notebook for private LB speed)","metadata":{}},{"cell_type":"code","source":"dft = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ndft.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = search.best_estimator_.predict(dft['excerpt'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft['target'] = target\ndft.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft[['id','target']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Notebook Complete","metadata":{}},{"cell_type":"code","source":"print(\"Program complete!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}