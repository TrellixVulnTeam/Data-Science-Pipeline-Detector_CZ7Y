{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\nI was interested in seeing how separable some of these sentence-level representations are in our data set.  \nIn this notebook, we'll go through a brief EDA and and into some unsupervised learning.  \n**Sentence transformers** are used to obtain the sentence embeddings and **textstat** is used for feature engineering","metadata":{}},{"cell_type":"code","source":"!pip install sentence_transformers\n!pip install textstat","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.mixture import GaussianMixture\nimport umap\nimport textstat\nplt.style.use('fivethirtyeight')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA and Data Preparation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8,5))\nsns.histplot(train_df.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,5))\nsns.histplot(train_df.standard_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Readability target appears to be relativel normally distributed.    \nThe standard error is right-skewed... and seems to have some outlier values on the left","metadata":{}},{"cell_type":"code","source":"ind = np.where(train_df.standard_error == train_df.standard_error.min())[0]\ntrain_df.loc[ind]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This row has a target which looks like an integer, and a 0 standard error.  \nWe'll remove it for now, as the standard error is largely out of distribution, which could affect dimensionality reduction","metadata":{}},{"cell_type":"code","source":"train_df.drop(ind, inplace = True)\ntrain_df.reset_index(inplace = True,drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Obtaining Sentence Representations\nHere we'll use a Roberta base model to encode our sequences.  ","metadata":{}},{"cell_type":"code","source":"# bert = SentenceTransformer('bert-base-uncased')\nroberta = SentenceTransformer('roberta-base')\nvects = roberta.encode(train_df.excerpt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Probably isn't neccesary to scale these vectors\nscaler = StandardScaler()\nscaled = scaler.fit_transform(vects)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TSNE Dimensionality Reduction","metadata":{}},{"cell_type":"code","source":"tsne_embedding = TSNE(2).fit_transform(scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(train_df, x = tsne_embedding[:, 0], y = tsne_embedding[:, 1], color = 'target',\n                 labels = {'x' : 'Dimension 1', 'y' : 'Dimension 2'},\n                 title = 'TSNE Projection of Roberta Sentence Representations')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### UMAP Dimensionality Reduction","metadata":{}},{"cell_type":"code","source":"reducer = umap.UMAP(random_state = 123)\numap_embedding = reducer.fit_transform(scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(train_df, x = umap_embedding[:, 0], y = umap_embedding[:, 1], color = 'target',\n                 labels = {'x' : 'Dimension 1', 'y' : 'Dimension 2'},\n                 title = 'UMAP Projection of Roberta Sentence Representations')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the latent representations, we see some interesting findings:\n* We can see some separation across scores - the finely grouped 'cluster' of good observations in the bottom left is noticeable \n* This plot looks like some kind of flipped Australia as well (to me at least)","metadata":{}},{"cell_type":"code","source":"px.scatter(train_df, x = umap_embedding[:, 0], y = umap_embedding[:, 1], color = 'standard_error',\n                 labels = {'x' : 'Dimension 1', 'y' : 'Dimension 2'},\n                 title = 'UMAP Projection of Roberta Sentence Representations')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clustering\nWe'll fit a GMM to the original sentence embeddings to cluster our datapoints  ","metadata":{}},{"cell_type":"code","source":"gmm = GaussianMixture(n_components = 6, random_state = 123)\nclusters = gmm.fit_predict(vects)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(train_df, x = umap_embedding[:, 0], y = umap_embedding[:, 1], color = clusters,\n                 labels = {'x' : 'Dimension 1', 'y' : 'Dimension 2'},\n                 title = 'UMAP Projection of Roberta Sentence Representations')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These clusters seem to be relatively well-defined.  \nWe can perform some feature engineering to compare across clusters","metadata":{}},{"cell_type":"markdown","source":"##  Feature Engineering\nI used the same textstat augmentations from this excellent EDA notebook https://www.kaggle.com/gunesevitan/commonlit-readability-prize-eda  \nFor reference, the augmentations are defined below:\n* `character_count` - number of characters in the text\n* `digit_count` - number of digits in the text\n* `word_count` - number of words in the text\n* `unique_word_count` - number of unique words in the text\n* `mean_word_length` - average number of character that the words have in the text\n* `syllable_count` - number of syllables in the text\n* `sentence_count` - number of sentences in the text\n* `flesch_reading_ease` - [flesch reading ease score](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch_reading_ease) of the text\n* `flesch_kincaid_grade` - [flesch-kincaid grade level](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level) of the text\n* `smog_index` - [smog index](https://en.wikipedia.org/wiki/SMOG) of the text\n* `automated_readability_index` - [automated readability index](https://en.wikipedia.org/wiki/Automated_readability_index) of the text\n* `coleman_liau_index` - [colemanâ€“liau index](https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index) of the text\n* `linsear_write_formula` - [linsear write grade](hhttps://en.wikipedia.org/wiki/Linsear_Write) of the text","metadata":{}},{"cell_type":"code","source":"train_df['is_licensed'] = train_df.license.notna()*1 # might be interesting to look at?\n\ntrain_df['character_count'] = train_df['excerpt'].apply(lambda x: len(str(x)))\ntrain_df['digit_count'] = train_df['excerpt'].apply(lambda x: np.sum(([int(word.isdigit()) for word in str(x).split()])))\ntrain_df['word_count'] = train_df['excerpt'].apply(textstat.lexicon_count)\ntrain_df['unique_word_count'] = train_df['excerpt'].apply(lambda x: len(set(str(x).split())))\ntrain_df['mean_word_length'] = train_df['excerpt'].apply(lambda x: np.mean([len(word) for word in str(x).split()]))\ntrain_df['syllable_count'] = train_df['excerpt'].apply(textstat.syllable_count)\ntrain_df['sentence_count'] = train_df['excerpt'].apply(textstat.sentence_count)\ntrain_df['flesch_reading_ease'] = train_df['excerpt'].apply(textstat.flesch_reading_ease)\ntrain_df['flesch_kincaid_grade'] = train_df['excerpt'].apply(textstat.flesch_kincaid_grade)\ntrain_df['smog_index'] = train_df['excerpt'].apply(textstat.smog_index)\ntrain_df['automated_readability_index'] = train_df['excerpt'].apply(textstat.automated_readability_index)\ntrain_df['coleman_liau_index'] = train_df['excerpt'].apply(textstat.coleman_liau_index)\ntrain_df['linsear_write_formula'] = train_df['excerpt'].apply(textstat.linsear_write_formula)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_df = train_df.select_dtypes(include=np.number)\nscaled_df = pd.DataFrame(MinMaxScaler(feature_range=(0, 1)).fit_transform(numeric_df), \n                         index = numeric_df.index, \n                         columns = numeric_df.columns)\n\nscaled_df['cluster'] = clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agg = scaled_df.groupby('cluster').mean()\nagg.reset_index(inplace = True)\nagg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\ncategories = ['target', 'standard_error', 'sentence_count', 'mean_word_length',\n              'automated_readability_index', 'character_count', 'unique_word_count']\n\nfig = go.Figure()\n\nfor row in agg.itertuples():\n    fig.add_trace(go.Scatterpolar(\n    r = [getattr(row, i) for i in categories],\n    theta = categories,\n    fill = 'toself',\n    name = row.cluster\n    ))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Class `1` appears to have higher sentence counts, lower character counts and has a noticeably lower average score in the automated readability index  \n90% of records in class `1` also have url/licenses associated with them, which is much higher than most other clusters\n","metadata":{}}]}