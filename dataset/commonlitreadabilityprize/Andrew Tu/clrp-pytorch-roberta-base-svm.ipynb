{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport time\nimport random\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport transformers\nfrom transformers import BertTokenizer, BertModel, BertConfig, AdamW\nfrom transformers import (AutoModel, AutoModelForMaskedLM, AutoTokenizer, \n    LineByLineTextDataset, DataCollatorForLanguageModeling,\n    Trainer, TrainingArguments, get_linear_schedule_with_warmup)\n\ndef seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nclass CFG:\n    model_name_or_path = '../input/roberta-transformers-pytorch/roberta-base'\n    #model_name_or_path = '../input/huggingface-bert-variants/bert-base-cased/bert-base-cased/'\n    clip_by_train_range = False\n    batch_size = 8\n    max_seq_length = 512\n    seq_length = 100\n    learning_rate = 2e-5\n    use_lr_scheduler = True\n    mid_eval = True\n    mid_eval_step_num = 50\n    random_seed = 2021\n    model_output_dir = './'\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \ncfg = CFG()\nseed_everything(cfg.random_seed)\nQUICK_CHECK = True\n\nglobal_start_t = time.time()\nprint('ok')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T09:24:35.138312Z","iopub.execute_input":"2021-06-25T09:24:35.138696Z","iopub.status.idle":"2021-06-25T09:24:42.750808Z","shell.execute_reply.started":"2021-06-25T09:24:35.138598Z","shell.execute_reply":"2021-06-25T09:24:42.749409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\ntrain_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nif QUICK_CHECK:\n    train_data = train_data.sample(300).reset_index(drop=True)\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'], bins=num_bins, labels=False)\ntarget = train_data['target'].to_numpy()\nbins = train_data['bins'].to_numpy()\ntrain_target_min, train_target_max = train_data['target'].min(), train_data['target'].max()\n\nprint(f'train_data.shape: {train_data.shape}, test_data.shape: {test_data.shape}')\ntrain_target_min, train_target_max\n# (-3.676267773, 1.7113898269999999)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:42.752296Z","iopub.execute_input":"2021-06-25T09:24:42.752651Z","iopub.status.idle":"2021-06-25T09:24:42.853569Z","shell.execute_reply.started":"2021-06-25T09:24:42.752598Z","shell.execute_reply":"2021-06-25T09:24:42.85283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['bins'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:42.855356Z","iopub.execute_input":"2021-06-25T09:24:42.855726Z","iopub.status.idle":"2021-06-25T09:24:42.863187Z","shell.execute_reply.started":"2021-06-25T09:24:42.855689Z","shell.execute_reply":"2021-06-25T09:24:42.861915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:42.865182Z","iopub.execute_input":"2021-06-25T09:24:42.865627Z","iopub.status.idle":"2021-06-25T09:24:42.882869Z","shell.execute_reply.started":"2021-06-25T09:24:42.86557Z","shell.execute_reply":"2021-06-25T09:24:42.881841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRP_Dataset(Dataset):\n    def __init__(self, data, tokenizer, max_seq_length):\n        self.df = data\n        self.tokenizer = tokenizer\n        self.max_seq_length = max_seq_length\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        excerpt = self.df.iloc[index]['excerpt']\n        d_encode = self.tokenizer(excerpt,\n                                  padding=\"max_length\",\n                                  max_length=self.max_seq_length,\n                                  truncation=True)\n        return {\"input_ids\": d_encode['input_ids'],\n                \"attention_mask\": d_encode['attention_mask'],\n                \"length\" : sum(d_encode['attention_mask'])}\n\n    \ndef collate_fn_test(batch):\n    max_len = max([x['length'] for x in batch])\n    input_ids = torch.tensor([x['input_ids'][:max_len] for x in batch])\n    attention_mask = torch.tensor([x['attention_mask'][:max_len] for x in batch])\n    #token_type_ids = torch.tensor([x['token_type_ids'][:max_len] for x in batch])\n    \n    if 'token_type_ids' in batch[0]:\n        token_type_ids = torch.tensor([x['token_type_ids'][:max_len] for x in batch])\n        return {\"input_ids\": input_ids,\n                \"attention_mask\": attention_mask,\n                \"token_type_ids\": token_type_ids}\n    else:\n        return {\"input_ids\": input_ids,\n                \"attention_mask\": attention_mask}\n    \ntokenizer = AutoTokenizer.from_pretrained(cfg.model_name_or_path)\ncfg.tokenizer = tokenizer\n\nds_test = CLRP_Dataset(test_data, tokenizer, cfg.max_seq_length)\ndl_test = DataLoader(ds_test, batch_size=2*cfg.batch_size, shuffle=False, collate_fn=collate_fn_test, num_workers=0)\nprint('len of ds_test: ', len(ds_test), 'len of dl_test: ', len(dl_test))\n\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:42.884328Z","iopub.execute_input":"2021-06-25T09:24:42.884813Z","iopub.status.idle":"2021-06-25T09:24:43.156232Z","shell.execute_reply.started":"2021-06-25T09:24:42.884775Z","shell.execute_reply":"2021-06-25T09:24:43.155362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRP_model_V1(nn.Module):\n    def __init__(self, pretrained_model_path, embedding_dim=256):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(pretrained_model_path)\n        use_large_model = True if 'large' in pretrained_model_path else False\n        self.drop_out = nn.Dropout(0.1)\n        if use_large_model:\n            self.fc1 = nn.Linear(1024*2, embedding_dim)\n        else:\n            self.fc1 = nn.Linear(768*2, embedding_dim)\n        self.activation1 = nn.ReLU()\n        self.fc2 = nn.Linear(embedding_dim, 1)\n\n    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n        output = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, return_dict=True)\n        assert len(output)==2\n        \n        last_hidden_state, pooled_output = output['last_hidden_state'], output['pooler_output']\n        last_hidden_state = self.drop_out(last_hidden_state)\n        seq_avg = torch.mean(last_hidden_state, dim=1)\n        seq_max = torch.max(last_hidden_state, dim=1)[0]\n        concat_out = torch.cat((seq_avg, seq_max), dim=1)\n        preds = self.fc2(self.activation1(self.fc1(concat_out)))        \n        preds = preds.squeeze(-1).squeeze(-1)  ### 这一行非常非常关键！！！\n        \n        return preds\n    \nclass CLRP_model_V2(nn.Module):\n    def __init__(self, pretrained_model_path, embedding_dim=256):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(pretrained_model_path)\n        use_large_model = True if 'large' in pretrained_model_path else False\n        self.drop_out = nn.Dropout(0.1)\n        if use_large_model:\n            self.fc1 = nn.Linear(1024*1, 1)\n        else:\n            self.fc1 = nn.Linear(768*1, 1)\n        \n\n    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n        output = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, return_dict=True)\n        assert len(output)==2\n        \n        pooled_output = output['pooler_output']\n        pooled_output = self.drop_out(pooled_output)\n        preds = self.fc1(pooled_output)\n        preds = preds.squeeze(-1).squeeze(-1)  ### 这一行非常非常关键！！！\n        \n        return preds\n    \nCLRP_model = CLRP_model_V2\n\nmodel = CLRP_model(cfg.model_name_or_path)\nmodel.to(cfg.device)\n\n# model_path = '../input/clrp-pytorch-roberta-base-my-first-model-train/best_model.pth'\n# model.load_state_dict(torch.load(model_path))\n\nmodel_param_num = sum(p.numel() for p in model.parameters())\nmodel_trainable_param_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint('model_param_num: ', model_param_num, 'model_trainable_param_num: ', \n      model_trainable_param_num)\ndel model\n            \nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.157536Z","iopub.execute_input":"2021-06-25T09:24:43.157898Z","iopub.status.idle":"2021-06-25T09:24:56.440992Z","shell.execute_reply.started":"2021-06-25T09:24:43.157861Z","shell.execute_reply":"2021-06-25T09:24:56.440203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df, model_path=cfg.model_name_or_path):\n    print('get into get_embeddings()')\n    global model, tokenizer, cfg, collate_fn_test\n    \n    model = CLRP_model(cfg.model_name_or_path)\n    model.to(cfg.device)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    \n    ds = CLRP_Dataset(df, tokenizer, cfg.max_seq_length)\n    dl = DataLoader(ds, batch_size=2*cfg.batch_size, shuffle=False, \n                    collate_fn=collate_fn_test, num_workers=0)\n\n    embeddings = []\n    with torch.no_grad():\n        for i, inputs in enumerate(dl):\n            inputs = {key:val.reshape(val.shape[0],-1).to(cfg.device) for key,val in inputs.items()}\n            outputs = model.bert(**inputs, return_dict=True)\n            outputs = outputs['pooler_output'].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    del model\n    return np.array(embeddings)\n\ndef get_preds_svm(X, y, X_test, bins=bins, nfolds=5, C=10, kernel='rbf', gamma='auto'):\n    print('*****'*10 + ' in get_preds_svm() ' + '*****'*10)\n    print(f'C: {C}, kernel: {kernel}, gamma: {gamma}')\n    scores = []\n    preds = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n        model = SVR(C=C, kernel=kernel, gamma=gamma)\n        X_train, y_train = X[train_idx], y[train_idx]\n        X_valid, y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train, y_train)\n        prediction = model.predict(X_valid)\n        score = rmse_score(prediction, y_valid)\n        print(f'Fold {k}, rmse_score: {score:.7f}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    mean_valid_rmse = np.mean(scores)\n    params = {'C': C, 'kernel': kernel, 'gamma': gamma}\n    print(f'mean_valid_rmse: {mean_valid_rmse:.7f}')\n    print('*****'*22)\n    return mean_valid_rmse, np.array(preds) / nfolds, params\n\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:56.442261Z","iopub.execute_input":"2021-06-25T09:24:56.442599Z","iopub.status.idle":"2021-06-25T09:24:56.458534Z","shell.execute_reply.started":"2021-06-25T09:24:56.442563Z","shell.execute_reply":"2021-06-25T09:24:56.457826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold0.pth')\ntest_embeddings1 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold0.pth')\nprint(f'train_embeddings1.shape: {train_embeddings1.shape}  test_embeddings1.shape: {test_embeddings1.shape}')\n\ntrain_embeddings2 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold1.pth')\ntest_embeddings2 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold1.pth')\nprint(f'train_embeddings2.shape: {train_embeddings2.shape}  test_embeddings2.shape: {test_embeddings2.shape}')\n\ntrain_embeddings3 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold2.pth')\ntest_embeddings3 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold2.pth')\nprint(f'train_embeddings3.shape: {train_embeddings3.shape}  test_embeddings3.shape: {test_embeddings3.shape}')\n\ntrain_embeddings4 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold3.pth')\ntest_embeddings4 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold3.pth')\nprint(f'train_embeddings4.shape: {train_embeddings4.shape}  test_embeddings4.shape: {test_embeddings4.shape}')\n\ntrain_embeddings5 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold4.pth')\ntest_embeddings5 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold4.pth')\nprint(f'train_embeddings5.shape: {train_embeddings5.shape}  test_embeddings5.shape: {test_embeddings5.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:56.461664Z","iopub.execute_input":"2021-06-25T09:24:56.462037Z","iopub.status.idle":"2021-06-25T09:26:06.593981Z","shell.execute_reply.started":"2021-06-25T09:24:56.462002Z","shell.execute_reply":"2021-06-25T09:26:06.593106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings = np.hstack([train_embeddings1, train_embeddings2, train_embeddings3, train_embeddings4, train_embeddings5])\ntest_embeddings = np.hstack([test_embeddings1, test_embeddings2, test_embeddings3, test_embeddings4, test_embeddings5])\n\ntrain_embeddings.shape, test_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:26:06.597953Z","iopub.execute_input":"2021-06-25T09:26:06.600035Z","iopub.status.idle":"2021-06-25T09:26:06.612747Z","shell.execute_reply.started":"2021-06-25T09:26:06.599984Z","shell.execute_reply":"2021-06-25T09:26:06.611791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_mean_valid_rmse, best_svm_preds = 1e10, None\nbest_params = None\n\nfor C in (1, 1e1, 1e2, 1e3):\n    for kernel in ('poly', 'rbf', 'sigmoid'):\n        for gamma in ['auto']:\n            mean_valid_rmse, svm_preds, params = get_preds_svm(train_embeddings, target, \n                                                                test_embeddings, C=C, kernel=kernel, \n                                                                gamma=gamma)\n            if mean_valid_rmse < best_mean_valid_rmse:\n                best_mean_valid_rmse = mean_valid_rmse\n                best_svm_preds = svm_preds\n                best_params = params\n                print(f'get new best_mean_valid_rmse: {mean_valid_rmse:.7f}, best_params: {best_params}')\n                \nprint(f'final best_mean_valid_rmse: {best_mean_valid_rmse:.7f}, best_params: {best_params}')\n# final best_mean_valid_rmse: 0.3033951, best_params: {'C': 10.0, 'kernel': 'rbf', 'gamma': 'auto'}\n# final best_mean_valid_rmse: 0.2524015, best_params: {'C': 10.0, 'kernel': 'sigmoid', 'gamma': 'auto'}","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-25T09:26:06.617354Z","iopub.execute_input":"2021-06-25T09:26:06.619545Z","iopub.status.idle":"2021-06-25T09:26:11.574155Z","shell.execute_reply.started":"2021-06-25T09:26:06.619507Z","shell.execute_reply":"2021-06-25T09:26:11.573269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test_data[['id']]\nsubmission_df['target'] = best_svm_preds\nsubmission_df.to_csv('./submission.csv', index=False)\n\nprint('total cost time: ', time.time() - global_start_t)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:26:11.584083Z","iopub.execute_input":"2021-06-25T09:26:11.584512Z","iopub.status.idle":"2021-06-25T09:26:11.845657Z","shell.execute_reply.started":"2021-06-25T09:26:11.584472Z","shell.execute_reply":"2021-06-25T09:26:11.844708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:26:11.846872Z","iopub.execute_input":"2021-06-25T09:26:11.847388Z","iopub.status.idle":"2021-06-25T09:26:11.857105Z","shell.execute_reply.started":"2021-06-25T09:26:11.847349Z","shell.execute_reply":"2021-06-25T09:26:11.855871Z"},"trusted":true},"execution_count":null,"outputs":[]}]}