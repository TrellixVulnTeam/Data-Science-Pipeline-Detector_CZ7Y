{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport time\nimport random\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport transformers\nfrom transformers import BertTokenizer, BertModel, BertConfig, AdamW\nfrom transformers import (AutoModel, AutoModelForMaskedLM, AutoTokenizer, \n    LineByLineTextDataset, DataCollatorForLanguageModeling,\n    Trainer, TrainingArguments, get_linear_schedule_with_warmup)\n\ndef seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nclass CFG:\n    model_name_or_path = '../input/roberta-transformers-pytorch/roberta-base'\n    #model_name_or_path = '../input/huggingface-bert-variants/bert-base-cased/bert-base-cased/'\n    clip_by_train_range = False\n    batch_size = 8\n    max_seq_length = 512\n    seq_length = 100\n    learning_rate = 2e-5\n    use_lr_scheduler = True\n    mid_eval = True\n    mid_eval_step_num = 50\n    random_seed = 2021\n    model_output_dir = './'\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \ncfg = CFG()\nseed_everything(cfg.random_seed)\nQUICK_CHECK = True\n\nglobal_start_t = time.time()\nprint('ok')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T09:55:16.481551Z","iopub.execute_input":"2021-06-25T09:55:16.481994Z","iopub.status.idle":"2021-06-25T09:55:28.877309Z","shell.execute_reply.started":"2021-06-25T09:55:16.481905Z","shell.execute_reply":"2021-06-25T09:55:28.876014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\ntrain_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nif QUICK_CHECK:\n    train_data = train_data.sample(300).reset_index(drop=True)\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'], bins=num_bins, labels=False)\ntarget = train_data['target'].to_numpy()\nbins = train_data['bins'].to_numpy()\ntrain_target_min, train_target_max = train_data['target'].min(), train_data['target'].max()\n\nprint(f'train_data.shape: {train_data.shape}, test_data.shape: {test_data.shape}')\ntrain_target_min, train_target_max\n# (-3.676267773, 1.7113898269999999)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:55:28.879087Z","iopub.execute_input":"2021-06-25T09:55:28.879443Z","iopub.status.idle":"2021-06-25T09:55:28.981767Z","shell.execute_reply.started":"2021-06-25T09:55:28.879404Z","shell.execute_reply":"2021-06-25T09:55:28.980823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['bins'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:55:28.984036Z","iopub.execute_input":"2021-06-25T09:55:28.984436Z","iopub.status.idle":"2021-06-25T09:55:28.995668Z","shell.execute_reply.started":"2021-06-25T09:55:28.984397Z","shell.execute_reply":"2021-06-25T09:55:28.994005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:55:28.99824Z","iopub.execute_input":"2021-06-25T09:55:28.999075Z","iopub.status.idle":"2021-06-25T09:55:29.01943Z","shell.execute_reply.started":"2021-06-25T09:55:28.999023Z","shell.execute_reply":"2021-06-25T09:55:29.018015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRP_Dataset(Dataset):\n    def __init__(self, data, tokenizer, max_seq_length):\n        self.df = data\n        self.tokenizer = tokenizer\n        self.max_seq_length = max_seq_length\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        excerpt = self.df.iloc[index]['excerpt']\n        d_encode = self.tokenizer(excerpt,\n                                  padding=\"max_length\",\n                                  max_length=self.max_seq_length,\n                                  truncation=True)\n        return {\"input_ids\": d_encode['input_ids'],\n                \"attention_mask\": d_encode['attention_mask'],\n                \"length\" : sum(d_encode['attention_mask'])}\n\n    \ndef collate_fn_test(batch):\n    max_len = max([x['length'] for x in batch])\n    input_ids = torch.tensor([x['input_ids'][:max_len] for x in batch])\n    attention_mask = torch.tensor([x['attention_mask'][:max_len] for x in batch])\n    #token_type_ids = torch.tensor([x['token_type_ids'][:max_len] for x in batch])\n    \n    if 'token_type_ids' in batch[0]:\n        token_type_ids = torch.tensor([x['token_type_ids'][:max_len] for x in batch])\n        return {\"input_ids\": input_ids,\n                \"attention_mask\": attention_mask,\n                \"token_type_ids\": token_type_ids}\n    else:\n        return {\"input_ids\": input_ids,\n                \"attention_mask\": attention_mask}\n    \ntokenizer = AutoTokenizer.from_pretrained(cfg.model_name_or_path)\ncfg.tokenizer = tokenizer\n\nds_test = CLRP_Dataset(test_data, tokenizer, cfg.max_seq_length)\ndl_test = DataLoader(ds_test, batch_size=2*cfg.batch_size, shuffle=False, collate_fn=collate_fn_test, num_workers=0)\nprint('len of ds_test: ', len(ds_test), 'len of dl_test: ', len(dl_test))\n\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:55:29.021356Z","iopub.execute_input":"2021-06-25T09:55:29.021875Z","iopub.status.idle":"2021-06-25T09:55:29.285731Z","shell.execute_reply.started":"2021-06-25T09:55:29.021831Z","shell.execute_reply":"2021-06-25T09:55:29.283736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRP_model_V1(nn.Module):\n    def __init__(self, pretrained_model_path, embedding_dim=256):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(pretrained_model_path)\n        use_large_model = True if 'large' in pretrained_model_path else False\n        self.drop_out = nn.Dropout(0.1)\n        if use_large_model:\n            self.fc1 = nn.Linear(1024*2, embedding_dim)\n        else:\n            self.fc1 = nn.Linear(768*2, embedding_dim)\n        self.activation1 = nn.ReLU()\n        self.fc2 = nn.Linear(embedding_dim, 1)\n\n    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n        output = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, return_dict=True)\n        assert len(output)==2\n        \n        last_hidden_state, pooled_output = output['last_hidden_state'], output['pooler_output']\n        last_hidden_state = self.drop_out(last_hidden_state)\n        seq_avg = torch.mean(last_hidden_state, dim=1)\n        seq_max = torch.max(last_hidden_state, dim=1)[0]\n        concat_out = torch.cat((seq_avg, seq_max), dim=1)\n        preds = self.fc2(self.activation1(self.fc1(concat_out)))        \n        preds = preds.squeeze(-1).squeeze(-1)  ### 这一行非常非常关键！！！\n        \n        return preds\n    \nclass CLRP_model_V2(nn.Module):\n    def __init__(self, pretrained_model_path, embedding_dim=256):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(pretrained_model_path)\n        use_large_model = True if 'large' in pretrained_model_path else False\n        self.drop_out = nn.Dropout(0.1)\n        if use_large_model:\n            self.fc1 = nn.Linear(1024*1, 1)\n        else:\n            self.fc1 = nn.Linear(768*1, 1)\n        \n\n    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n        output = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, return_dict=True)\n        assert len(output)==2\n        \n        pooled_output = output['pooler_output']\n        pooled_output = self.drop_out(pooled_output)\n        preds = self.fc1(pooled_output)\n        preds = preds.squeeze(-1).squeeze(-1)  ### 这一行非常非常关键！！！\n        \n        return preds\n    \nCLRP_model = CLRP_model_V2\n\nmodel = CLRP_model(cfg.model_name_or_path)\nmodel.to(cfg.device)\n\n# model_path = '../input/clrp-pytorch-roberta-base-my-first-model-train/best_model.pth'\n# model.load_state_dict(torch.load(model_path))\n\nmodel_param_num = sum(p.numel() for p in model.parameters())\nmodel_trainable_param_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint('model_param_num: ', model_param_num, 'model_trainable_param_num: ', \n      model_trainable_param_num)\ndel model\n            \nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:55:29.289258Z","iopub.execute_input":"2021-06-25T09:55:29.289567Z","iopub.status.idle":"2021-06-25T09:55:45.608814Z","shell.execute_reply.started":"2021-06-25T09:55:29.289537Z","shell.execute_reply":"2021-06-25T09:55:45.607627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df, model_path=cfg.model_name_or_path):\n    #print('get into get_embeddings()')\n    global model, tokenizer, cfg, collate_fn_test\n    \n    model = CLRP_model(cfg.model_name_or_path)\n    model.to(cfg.device)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    \n    ds = CLRP_Dataset(df, tokenizer, cfg.max_seq_length)\n    dl = DataLoader(ds, batch_size=2*cfg.batch_size, shuffle=False, \n                    collate_fn=collate_fn_test, num_workers=0)\n\n    embeddings = []\n    with torch.no_grad():\n        for i, inputs in enumerate(dl):\n            inputs = {key:val.reshape(val.shape[0],-1).to(cfg.device) for key,val in inputs.items()}\n            outputs = model.bert(**inputs, return_dict=True)\n            outputs = outputs['pooler_output'].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    del model\n    return np.array(embeddings)\n\ndef get_preds_lgb(X, y, X_test, hyper_params, bins=bins, nfolds=5):\n    print('*****'*10 + ' in get_preds_lgb() ' + '*****'*10)\n    scores = []\n    preds = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n        X_train, y_train = X[train_idx], y[train_idx]\n        X_valid, y_valid = X[valid_idx], y[valid_idx]\n        gbm = lgb.LGBMRegressor(**hyper_params, verbose_eval=100)\n        gbm.fit(X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                eval_metric='rmse',\n                early_stopping_rounds=1000)\n        prediction = gbm.predict(X_valid, num_iteration=gbm.best_iteration_)\n        score = rmse_score(prediction, y_valid)\n        print(f'Fold {k}, rmse_score: {score:.7f}')\n        scores.append(score)\n        preds += gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n        \n    mean_valid_rmse = np.mean(scores)\n    print(f'mean_valid_rmse: {mean_valid_rmse:.7f}')\n    print('*****'*22)\n    \n    return scores, mean_valid_rmse, np.array(preds) / nfolds\n\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T10:15:16.873117Z","iopub.execute_input":"2021-06-25T10:15:16.873514Z","iopub.status.idle":"2021-06-25T10:15:16.893982Z","shell.execute_reply.started":"2021-06-25T10:15:16.873455Z","shell.execute_reply":"2021-06-25T10:15:16.888681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold0.pth')\ntest_embeddings1 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold0.pth')\nprint(f'train_embeddings1.shape: {train_embeddings1.shape}  test_embeddings1.shape: {test_embeddings1.shape}')\n\ntrain_embeddings2 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold1.pth')\ntest_embeddings2 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold1.pth')\nprint(f'train_embeddings2.shape: {train_embeddings2.shape}  test_embeddings2.shape: {test_embeddings2.shape}')\n\ntrain_embeddings3 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold2.pth')\ntest_embeddings3 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold2.pth')\nprint(f'train_embeddings3.shape: {train_embeddings3.shape}  test_embeddings3.shape: {test_embeddings3.shape}')\n\ntrain_embeddings4 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold3.pth')\ntest_embeddings4 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold3.pth')\nprint(f'train_embeddings4.shape: {train_embeddings4.shape}  test_embeddings4.shape: {test_embeddings4.shape}')\n\ntrain_embeddings5 = get_embeddings(train_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold4.pth')\ntest_embeddings5 = get_embeddings(test_data, '../input/clrp-roberta-base-my-first-model-5fold-cv/best_model_fold4.pth')\nprint(f'train_embeddings5.shape: {train_embeddings5.shape}  test_embeddings5.shape: {test_embeddings5.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:55:45.634788Z","iopub.execute_input":"2021-06-25T09:55:45.635372Z","iopub.status.idle":"2021-06-25T09:57:07.506185Z","shell.execute_reply.started":"2021-06-25T09:55:45.635314Z","shell.execute_reply":"2021-06-25T09:57:07.505051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings = np.hstack([train_embeddings1, train_embeddings2, train_embeddings3, train_embeddings4, train_embeddings5])\ntest_embeddings = np.hstack([test_embeddings1, test_embeddings2, test_embeddings3, test_embeddings4, test_embeddings5])\n\ntrain_embeddings.shape, test_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:57:07.508327Z","iopub.execute_input":"2021-06-25T09:57:07.508818Z","iopub.status.idle":"2021-06-25T09:57:07.521934Z","shell.execute_reply.started":"2021-06-25T09:57:07.508721Z","shell.execute_reply":"2021-06-25T09:57:07.520302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': ['rmse', 'l2'],\n    'learning_rate': 0.03,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 10,\n    'verbose': 100,\n    #'verbose_eval': 100,\n    \"max_depth\": 8,\n    \"num_leaves\": 128,  \n    \"max_bin\": 512,\n    \"num_iterations\": 600,\n    \"n_estimators\": 100\n}\n\nscores, mean_valid_rmse, lgb_preds = get_preds_lgb(train_embeddings, target, test_embeddings, hyper_params)\nprint(f'mean_valid_rmse: {mean_valid_rmse:.7f}, scores: {scores}')\n\n# mean_valid_rmse: 0.2665430, scores: [0.22609550404441608, 0.2434359789720671, 0.2794519787496889, 0.30405285119279, 0.27967856381017564]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-25T10:15:23.47076Z","iopub.execute_input":"2021-06-25T10:15:23.471144Z","iopub.status.idle":"2021-06-25T10:16:50.564264Z","shell.execute_reply.started":"2021-06-25T10:15:23.471098Z","shell.execute_reply":"2021-06-25T10:16:50.563217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test_data[['id']]\nsubmission_df['target'] = lgb_preds\nsubmission_df.to_csv('./submission.csv', index=False)\n\nprint('total cost time: ', time.time() - global_start_t)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T10:12:38.60958Z","iopub.execute_input":"2021-06-25T10:12:38.610093Z","iopub.status.idle":"2021-06-25T10:12:38.630869Z","shell.execute_reply.started":"2021-06-25T10:12:38.610063Z","shell.execute_reply":"2021-06-25T10:12:38.629499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:57:08.014943Z","iopub.status.idle":"2021-06-25T09:57:08.015811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_preds_svm(X, y, X_test, bins=bins, nfolds=5, C=10, kernel='rbf', gamma='auto'):\n#     print('*****'*10 + ' in get_preds_svm() ' + '*****'*10)\n#     print(f'C: {C}, kernel: {kernel}, gamma: {gamma}')\n#     scores = []\n#     preds = np.zeros((X_test.shape[0]))\n    \n#     kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n#     for k, (train_idx, valid_idx) in enumerate(kfold.split(X, bins)):\n#         model = SVR(C=C, kernel=kernel, gamma=gamma)\n#         X_train, y_train = X[train_idx], y[train_idx]\n#         X_valid, y_valid = X[valid_idx], y[valid_idx]\n        \n#         model.fit(X_train, y_train)\n#         prediction = model.predict(X_valid)\n#         score = rmse_score(prediction, y_valid)\n#         print(f'Fold {k}, rmse_score: {score:.7f}')\n#         scores.append(score)\n#         preds += model.predict(X_test)\n        \n#     mean_valid_rmse = np.mean(scores)\n#     params = {'C': C, 'kernel': kernel, 'gamma': gamma}\n#     print(f'mean_valid_rmse: {mean_valid_rmse:.7f}')\n#     print('*****'*22)\n#     return scores, mean_valid_rmse, np.array(preds) / nfolds, params\n\n\n# best_mean_valid_rmse, best_svm_preds = 1e10, None\n# best_params = None\n# best_scores = None\n\n# for C in (1, 1e1, 1e2, 1e3):\n#     for kernel in ('poly', 'rbf', 'sigmoid'):\n#         for gamma in ['auto']:\n#             scores, mean_valid_rmse, svm_preds, params = get_preds_svm(train_embeddings, target, \n#                                                                 test_embeddings, C=C, kernel=kernel, \n#                                                                 gamma=gamma)\n#             if mean_valid_rmse < best_mean_valid_rmse:\n#                 best_mean_valid_rmse = mean_valid_rmse\n#                 best_svm_preds = svm_preds\n#                 best_params = params\n#                 best_scores = scores\n#                 print(f'get new best_mean_valid_rmse: {mean_valid_rmse:.7f}, best_params: {best_params}')\n                \n# print(f'final best_mean_valid_rmse: {best_mean_valid_rmse:.7f}, best_params: {best_params}')\n# print(f'best_scores: {best_scores}')\n# final best_mean_valid_rmse: 0.2524015, best_params: {'C': 10.0, 'kernel': 'sigmoid', 'gamma': 'auto'}\n# best_scores: [0.21606701136392786, 0.24528778682140712, 0.2808003446991725, 0.2839011546906152, 0.23595105868739497]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T10:19:11.577485Z","iopub.execute_input":"2021-06-25T10:19:11.577957Z","iopub.status.idle":"2021-06-25T10:19:16.921181Z","shell.execute_reply.started":"2021-06-25T10:19:11.577928Z","shell.execute_reply":"2021-06-25T10:19:16.920201Z"},"trusted":true},"execution_count":null,"outputs":[]}]}