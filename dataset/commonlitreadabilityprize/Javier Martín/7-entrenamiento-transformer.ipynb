{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from argparse import ArgumentParser, Namespace\nfrom datetime import datetime\nfrom os import cpu_count\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Union\nimport gc\nimport pickle\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom torch.distributions.beta import Beta\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.dataloader import DataLoader\nfrom tqdm.auto import tqdm\nfrom transformers import (\n    AutoConfig,\n    AutoModel,\n    AutoTokenizer,\n    get_constant_schedule_with_warmup,\n)\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport torch\nimport torch.nn as nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-22T01:47:12.250308Z","iopub.execute_input":"2021-07-22T01:47:12.250719Z","iopub.status.idle":"2021-07-22T01:47:12.258498Z","shell.execute_reply.started":"2021-07-22T01:47:12.250616Z","shell.execute_reply":"2021-07-22T01:47:12.257592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = Namespace(\n    data=Path('/kaggle/input/commonlitreadabilityprize'),\n    models=Path('models'),\n    infer_path=Path('/kaggle/input/7-entrenamiento-transformer'), # CAMBIAR POR EL PATH AL DATASET RESULTADO DE ENTRENAMIENTO\n    seed=2021,\n    kfold_seed=2021,\n    bs=8, \n    n_folds=5,\n    seq_len=200,\n    model_name='roberta-base',\n    trf_do=0.,\n    lr=1e-5,\n    epochs=1,\n    val_steps=100,\n    mode='infer', # train/infer\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.260432Z","iopub.execute_input":"2021-07-22T01:47:12.261197Z","iopub.status.idle":"2021-07-22T01:47:12.271178Z","shell.execute_reply.started":"2021-07-22T01:47:12.261161Z","shell.execute_reply":"2021-07-22T01:47:12.270279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Funciones auxiliares","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.274688Z","iopub.execute_input":"2021-07-22T01:47:12.274975Z","iopub.status.idle":"2021-07-22T01:47:12.281871Z","shell.execute_reply.started":"2021-07-22T01:47:12.274949Z","shell.execute_reply":"2021-07-22T01:47:12.28094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datos","metadata":{}},{"cell_type":"code","source":"class ReadabilityDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=200):\n        super().__init__()\n        self.df = df\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.labeled = 'target' in df\n        \n        if self.labeled:\n            self.target = torch.tensor(df.target.values, dtype=torch.float)\n            self.stderr = torch.tensor(df.standard_error.values, dtype=torch.float)\n            #self.bin = torch.tensor(df.bin.values, dtype=torch.long)\n        \n        texts = list(df.excerpt.values)\n        self.tokens = tokenizer(\n            texts, \n            max_length=max_len, \n            truncation=True, \n            padding='max_length', \n            return_tensors='pt', \n            add_special_tokens=True\n        )\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        ids = self.tokens['input_ids'][idx].clone()\n        mask = self.tokens['attention_mask'][idx].clone()\n\n        if self.labeled:\n            target = self.target[idx]\n\n        return (ids, mask, target) if self.labeled else (ids, mask)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.283583Z","iopub.execute_input":"2021-07-22T01:47:12.284137Z","iopub.status.idle":"2021-07-22T01:47:12.295275Z","shell.execute_reply.started":"2021-07-22T01:47:12.284099Z","shell.execute_reply":"2021-07-22T01:47:12.294317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Definición del modelo\nDimensiones:\n* `bs`: batch size\n* `max_len`: longitud de la secuencia\n* `d_model`: dimensión del transformer (768 roberta-base, 1024 roberta-large)","metadata":{}},{"cell_type":"code","source":"class ReadabilityModel(nn.Module):\n\n    def __init__(self, args, body):\n        super().__init__()\n\n        self.args = args\n        self.body = body\n        \n        self.out_features = body(torch.zeros(1, 1, dtype=torch.long)).hidden_states[-1].shape[-1]\n        self.head = nn.Linear(self.out_features, 1) # 768 base, 1024 large\n        self.head.bias.data.fill_(-0.9593187699947071)\n\n    def forward(self, ids, mask):\n        x = self.body(input_ids=ids, attention_mask=mask)\n        # \n        x = x['hidden_states']  # 13, bs, max_len, d_model (ej: 13, 8, 200, 768)\n        x = x[-1]               # 8, 200, 768\n        x = torch.mean(x, 1)    # 8, 768\n        x = self.head(x)        # 8, 1\n        x = x.squeeze(-1)       # 8\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.296845Z","iopub.execute_input":"2021-07-22T01:47:12.297271Z","iopub.status.idle":"2021-07-22T01:47:12.308986Z","shell.execute_reply.started":"2021-07-22T01:47:12.297207Z","shell.execute_reply":"2021-07-22T01:47:12.308011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Función de pérdidas","metadata":{}},{"cell_type":"code","source":"def loss_fn(preds, targs):\n    return torch.sqrt(nn.MSELoss()(preds, targs))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.310666Z","iopub.execute_input":"2021-07-22T01:47:12.310977Z","iopub.status.idle":"2021-07-22T01:47:12.318557Z","shell.execute_reply.started":"2021-07-22T01:47:12.310922Z","shell.execute_reply":"2021-07-22T01:47:12.31776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Guarda el mejor modelo","metadata":{}},{"cell_type":"code","source":"class Checkpointer:\n    def __init__(self, base_name, path):\n        self.best_loss = None\n        self.best_path = None\n        self.base_name = base_name\n        self.path = path\n\n    def on_validation_end(self, model, epoch, loss) -> None:\n        if (self.best_loss is None) or (loss < self.best_loss):\n            #print(f\"Loss {loss} better than {self.best_loss}\")\n            self.path.mkdir(exist_ok=True, parents=True)\n            stem = f'{self.base_name}_epoch_{epoch}_loss_{loss:.6f}'\n            out_p = self.path / f'{stem}.pt'\n            with out_p.open('wb') as f:\n                torch.save(model.state_dict(), f)\n            if self.best_path is not None:\n                self.best_path.unlink()\n            self.best_loss = loss\n            self.best_path = out_p","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.321167Z","iopub.execute_input":"2021-07-22T01:47:12.32145Z","iopub.status.idle":"2021-07-22T01:47:12.331628Z","shell.execute_reply.started":"2021-07-22T01:47:12.321425Z","shell.execute_reply":"2021-07-22T01:47:12.330835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validación","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:39:34.897115Z","iopub.execute_input":"2021-07-22T00:39:34.897534Z","iopub.status.idle":"2021-07-22T00:39:34.901651Z","shell.execute_reply.started":"2021-07-22T00:39:34.897495Z","shell.execute_reply":"2021-07-22T00:39:34.900495Z"}}},{"cell_type":"code","source":"def validate(model, valid_dl):\n    is_training = model.training\n    model.eval()\n    preds = []\n    targs = []\n    with torch.no_grad():\n        for batch in tqdm(valid_dl, leave=False):\n            ids, mask, targ = ( t.cuda() for t in batch )\n            pred = model(ids, mask)\n            targs.append(targ)\n            preds.append(pred)\n        preds = torch.cat(preds)\n        targs = torch.cat(targs)\n        #print(preds.shape, targs.shape)\n        loss = loss_fn(preds, targs).cpu()\n    if is_training:\n        model.train()\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.38017Z","iopub.execute_input":"2021-07-22T01:47:12.380411Z","iopub.status.idle":"2021-07-22T01:47:12.38772Z","shell.execute_reply.started":"2021-07-22T01:47:12.380387Z","shell.execute_reply":"2021-07-22T01:47:12.386617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicción","metadata":{}},{"cell_type":"code","source":"def predict(model, test_dl):\n    is_training = model.training\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in tqdm(test_dl, leave=False):\n            if len(batch) == 3:\n                ids, mask, _ = ( t.cuda() for t in batch )\n            else:\n                ids, mask = ( t.cuda() for t in batch )\n            pred = model(ids, mask).detach().cpu()\n            preds.append(pred)\n        preds = torch.cat(preds)\n    if is_training:\n        model.train()\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.389672Z","iopub.execute_input":"2021-07-22T01:47:12.390501Z","iopub.status.idle":"2021-07-22T01:47:12.400767Z","shell.execute_reply.started":"2021-07-22T01:47:12.390471Z","shell.execute_reply":"2021-07-22T01:47:12.399968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Entrenamiento de 1 fold","metadata":{}},{"cell_type":"code","source":"def train_fold(fold, df, train_idx, valid_idx, ts):\n    print(f\"Training fold {fold}\")\n\n    # Model\n    model_config = AutoConfig.from_pretrained(f'cfgs/{args.model_name}', add_pooling_layer=False)\n    model_config.output_hidden_states = True\n    model_config.hidden_dropout_prob = args.trf_do\n    model_config.attention_probs_dropout_prob = args.trf_do\n    body = AutoModel.from_pretrained(args.model_name, config=model_config, add_pooling_layer=False)\n    model = ReadabilityModel(args, body)\n\n    # Tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(f'toks/{args.model_name}', config=model_config)\n\n    # Datasets\n    train_ds = ReadabilityDataset(df.iloc[train_idx], tokenizer, max_len=args.seq_len)\n    valid_ds = ReadabilityDataset(df.iloc[valid_idx], tokenizer, max_len=args.seq_len)\n\n    # Dataloader\n    train_dl = DataLoader(\n        dataset=train_ds,\n        batch_size=args.bs,\n        num_workers=0, #cpu_count() // 4,\n        drop_last=True,\n        shuffle=True\n    )\n    \n    valid_dl = DataLoader(\n        dataset=valid_ds,\n        batch_size=args.bs * 8,\n        num_workers=0, #cpu_count() // 4,\n    )\n    \n    # Optimizer\n    optimizer = torch.optim.Adam(model.parameters(), args.lr)\n    model.train().cuda()\n\n    model_p = args.models / ts\n    prefix = f'{args.model_name}_fold_{fold}'\n    checkpointer = Checkpointer(prefix, model_p)    \n    num_training_steps = len(train_dl) * args.epochs\n    pbar = tqdm(range(num_training_steps))\n\n    step = 0\n    val_loss = None\n\n    for epoch in range(args.epochs):\n        for nb, batch in enumerate(train_dl):\n            \n            optimizer.zero_grad()\n\n            ids, mask, targ = ( t.cuda() for t in batch )\n\n            pred = model(ids, mask)\n            loss = loss_fn(pred, targ)\n                \n            loss.backward()\n            optimizer.step()\n\n            # Valida cada n pasos\n            step += 1\n            if step % args.val_steps == 0 or step == num_training_steps:\n                val_loss = validate(model, valid_dl)\n\n                # Checkpoint\n                checkpointer.on_validation_end(model, epoch, val_loss.item())\n                \n            # update tqdm\n            postfix = {\n                'loss': loss.item(),\n                'val_loss': val_loss.item() if val_loss else '-',\n                'best': checkpointer.best_loss,\n            }\n\n            pbar.set_postfix(postfix)\n            pbar.update(1)\n\n    # Guarda args\n    with (model_p / f'{prefix}.args').open('wb') as f:\n        pickle.dump(args, f)\n\n    # Predice con el mejor checkpoint\n    model.load_state_dict(torch.load(checkpointer.best_path))\n    model.eval()\n    df.loc[valid_idx, 'pred'] = predict(model, valid_dl)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.404299Z","iopub.execute_input":"2021-07-22T01:47:12.404596Z","iopub.status.idle":"2021-07-22T01:47:12.420024Z","shell.execute_reply.started":"2021-07-22T01:47:12.404566Z","shell.execute_reply":"2021-07-22T01:47:12.419297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Entrenamiento K folds","metadata":{}},{"cell_type":"code","source":"def train():\n    args.models.mkdir(exist_ok=True)\n    seed_everything(args.seed)\n\n    # Crea dirs para la config del modelo y datos del tokenizador\n    for d in ['cfgs', 'toks']:\n        Path(d).mkdir(exist_ok=True)\n        \n    # Descarga config del modelo + tokenizer para la inferencia (no tendremos internet)\n    model_config = AutoConfig.from_pretrained(args.model_name, add_pooling_layer=False)\n    model_config.save_pretrained(f'cfgs/{args.model_name}')\n    tok = AutoTokenizer.from_pretrained(args.model_name)    \n    tok.save_pretrained(f'toks/{args.model_name}')\n\n    # Divide conjunto de datos en train/val\n    df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\n    df['pred'] = pd.NA\n    ts = datetime.strftime(datetime.now(), '%Y%m%d_%H%M%S')\n    cv = KFold(n_splits=args.n_folds, shuffle=True, random_state=args.kfold_seed)\n\n    for fold, (train_idx, valid_idx) in enumerate(cv.split(df)):\n        train_fold(fold, df, train_idx, valid_idx, ts)\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    # Validación cruzada (CV) de todo el dataset\n    cv = mean_squared_error(df.target, df.pred, squared=False)\n    print(f\"cv={cv}\")\n    df.to_csv(args.models / ts / f'{args.model_name}_oof_preds_{cv:.6f}.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.421368Z","iopub.execute_input":"2021-07-22T01:47:12.421911Z","iopub.status.idle":"2021-07-22T01:47:12.433707Z","shell.execute_reply.started":"2021-07-22T01:47:12.421864Z","shell.execute_reply":"2021-07-22T01:47:12.432828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inferencia","metadata":{}},{"cell_type":"code","source":"def infer():\n    # Carga config del modelo, modelo y tokenizador\n    model_config = AutoConfig.from_pretrained(args.infer_path / 'cfgs' / args.model_name, add_pooling_layer=False)\n    model_config.output_hidden_states = True\n    model_config.hidden_dropout_prob = args.trf_do\n    model_config.attention_probs_dropout_prob = args.trf_do\n    body = AutoModel.from_config(model_config, add_pooling_layer=False)\n    model = ReadabilityModel(args, body)\n    model.cuda()\n    tokenizer = AutoTokenizer.from_pretrained(args.infer_path / 'toks' / args.model_name, config=model_config)\n\n    # Carga datos de test\n    test_df = pd.read_csv(args.data / 'test.csv')\n\n    # Dataset y dataloader\n    test_ds = ReadabilityDataset(test_df, tokenizer, max_len=args.seq_len)\n    test_dl = DataLoader(dataset=test_ds, batch_size=args.bs * 8, num_workers=0)\n\n    # Acumula las predicciónes de los 5 folds aquí\n    preds_l = []\n\n    for model_p in (args.infer_path / args.models).iterdir():\n        for pt_p in model_p.glob('*.pt'):\n            print(f\"Infer {str(pt_p)}\")\n            # Carga los params del .pt\n            model.load_state_dict(torch.load(pt_p))\n            \n            preds = predict(model, test_dl)\n            preds_l.append(preds)\n\n    all_preds = torch.stack(preds_l).mean(dim=0)\n    \n    test_df['target'] = all_preds\n    sub_df = test_df[['id', 'target']]\n\n    sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.434874Z","iopub.execute_input":"2021-07-22T01:47:12.435317Z","iopub.status.idle":"2021-07-22T01:47:12.446067Z","shell.execute_reply.started":"2021-07-22T01:47:12.435281Z","shell.execute_reply":"2021-07-22T01:47:12.445219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if args.mode == 'train':\n    train()\nelif args.mode == 'infer':\n    infer()","metadata":{"execution":{"iopub.status.busy":"2021-07-22T01:47:12.447273Z","iopub.execute_input":"2021-07-22T01:47:12.447648Z","iopub.status.idle":"2021-07-22T01:47:43.375698Z","shell.execute_reply.started":"2021-07-22T01:47:12.44761Z","shell.execute_reply":"2021-07-22T01:47:43.374778Z"},"trusted":true},"execution_count":null,"outputs":[]}]}