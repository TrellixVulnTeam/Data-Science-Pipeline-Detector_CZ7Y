{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.svm import SVC\nimport category_encoders as ce\nimport lightgbm as lgb\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-08T11:57:09.961246Z","iopub.execute_input":"2021-06-08T11:57:09.96155Z","iopub.status.idle":"2021-06-08T11:57:09.974788Z","shell.execute_reply.started":"2021-06-08T11:57:09.961522Z","shell.execute_reply":"2021-06-08T11:57:09.973793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see what we have in our imported directory\n!pip install --no-index ../input/textstat-070/wheelhouse/Pyphen-0.10.0-py3-none-any.whl\n!pip install --no-index ../input/textstat-070/wheelhouse/textstat-0.7.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:09.976678Z","iopub.execute_input":"2021-06-08T11:57:09.977253Z","iopub.status.idle":"2021-06-08T11:57:20.093187Z","shell.execute_reply.started":"2021-06-08T11:57:09.97721Z","shell.execute_reply":"2021-06-08T11:57:20.092024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textstat","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.096885Z","iopub.execute_input":"2021-06-08T11:57:20.097176Z","iopub.status.idle":"2021-06-08T11:57:20.102515Z","shell.execute_reply.started":"2021-06-08T11:57:20.097141Z","shell.execute_reply":"2021-06-08T11:57:20.101537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.104403Z","iopub.execute_input":"2021-06-08T11:57:20.104747Z","iopub.status.idle":"2021-06-08T11:57:20.169893Z","shell.execute_reply.started":"2021-06-08T11:57:20.104685Z","shell.execute_reply":"2021-06-08T11:57:20.168831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.171183Z","iopub.execute_input":"2021-06-08T11:57:20.171462Z","iopub.status.idle":"2021-06-08T11:57:20.185977Z","shell.execute_reply.started":"2021-06-08T11:57:20.171434Z","shell.execute_reply":"2021-06-08T11:57:20.185003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_df[train_df['id'] =='436ce79fe']\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.187466Z","iopub.execute_input":"2021-06-08T11:57:20.187876Z","iopub.status.idle":"2021-06-08T11:57:20.206369Z","shell.execute_reply.started":"2021-06-08T11:57:20.187831Z","shell.execute_reply":"2021-06-08T11:57:20.205186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(data= train_df[train_df['standard_error']!=0],\n    x='target', \n    y='standard_error', \n    height=8,\n    color = 'green'\n\n)\nplt.suptitle(\"Target vs Standard error \", size=15)\nplt.subplots_adjust(top=0.95)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.207644Z","iopub.execute_input":"2021-06-08T11:57:20.20796Z","iopub.status.idle":"2021-06-08T11:57:20.723555Z","shell.execute_reply.started":"2021-06-08T11:57:20.207922Z","shell.execute_reply":"2021-06-08T11:57:20.722598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Passages with medium difficulty level have lower spread compared to text with extreme difficulty /ease level\n\n* further dissection can be done by analyzing no. of excerpts in various (bins) intervals. We can check this by looking at histograms. We can use the standard error as a categorical feature if eda gives us some conclusive results\n","metadata":{}},{"cell_type":"code","source":"sns.histplot(data=train_df, x=\"standard_error\", color=\"lime\", \\\n            binwidth = 0.05, kde = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.725639Z","iopub.execute_input":"2021-06-08T11:57:20.725912Z","iopub.status.idle":"2021-06-08T11:57:20.928069Z","shell.execute_reply.started":"2021-06-08T11:57:20.725887Z","shell.execute_reply":"2021-06-08T11:57:20.92717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_spread_to_categorical(row):\n    spread_val = row['standard_error']\n    if 0.4 < spread_val <=0.45:\n        cat= 'low'\n        \n    elif 0.45 < spread_val <=0.50:\n        cat = 'medium'\n        \n    elif 0.50 < spread_val <=0.55:\n        cat = 'high'\n        \n    else:\n        cat = 'very high'\n    return cat\n\ndata = train_df[train_df['id']!= '436ce79fe']\n# data['spread_category'] = data.apply(lambda x: apply_spread_to_categorical(x), axis = 1)\n# sns.scatterplot(data=data, x=\"target\", y=\"standard_error\", hue=\"spread_category\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.929915Z","iopub.execute_input":"2021-06-08T11:57:20.930224Z","iopub.status.idle":"2021-06-08T11:57:20.936998Z","shell.execute_reply.started":"2021-06-08T11:57:20.930192Z","shell.execute_reply":"2021-06-08T11:57:20.936067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not much can be concluded from the above graph to make a definite conclusion, but we can see that\n* spread_cat 'very high' occurs mostly betwen the target range < -2 and > 0.\n* spread_cat 'high' is also dense around <-1 and > 0\n\nLet's try to create some features and study their relationship with target. We will create features on basis of readability formula. Some of the most common ones:\n\n1. The Dale–Chall formula\n2. The Gunning fog formula\n3. Fry readability graph\n4. McLaughlin’s SMOG formula\n5. The FORCAST formula\n6. Readability and newspaper readership\n7. Flesch Scores\n8. Automated Readability Index\n\n\nInstead of coding, we'll use the textstat. Textstat is an easy to use library to calculate statistics from text. It helps determine readability, complexity, and grade level.","metadata":{}},{"cell_type":"code","source":"def apply_flesch_reading_ease(row):\n    score = textstat.flesch_reading_ease(row['excerpt'])\n    return score\ndef apply_smog_index(row):\n    score = textstat.smog_index(row['excerpt'])\n    return score\ndef apply_flesch_kincaid_grade(row):\n    score = textstat.flesch_kincaid_grade(row['excerpt'])\n    return score\ndef apply_gunning_fog(row):\n    score = textstat.gunning_fog(row['excerpt'])\n    return score\ndef apply_dale_chall_readability_score(row):\n    score = textstat.dale_chall_readability_score(row['excerpt'])\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.938318Z","iopub.execute_input":"2021-06-08T11:57:20.938583Z","iopub.status.idle":"2021-06-08T11:57:20.948158Z","shell.execute_reply.started":"2021-06-08T11:57:20.938555Z","shell.execute_reply":"2021-06-08T11:57:20.947023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['readability_flesch_ease'] = data.apply(lambda x:apply_flesch_reading_ease(x), axis = 1 )\ndata['readability_smog'] = data.apply(lambda x:apply_smog_index(x), axis = 1 )\ndata['readability_flesch_kincaid'] = data.apply(lambda x:apply_flesch_kincaid_grade(x), axis = 1 )\n\ndata['readability_gunning_fog'] = data.apply(lambda x:apply_gunning_fog(x), axis = 1 )\ndata['readability_dale_chall'] = data.apply(lambda x:apply_dale_chall_readability_score(x), axis = 1 )\ndata.head()\ndata = data.drop(['url_legal', 'license', 'standard_error'], axis =1)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T11:57:20.94924Z","iopub.execute_input":"2021-06-08T11:57:20.949567Z","iopub.status.idle":"2021-06-08T12:05:47.120044Z","shell.execute_reply.started":"2021-06-08T11:57:20.949537Z","shell.execute_reply":"2021-06-08T12:05:47.119065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.PairGrid(data, y_vars=[\"target\"], x_vars=[\"readability_flesch_ease\", \"readability_smog\", \"readability_flesch_kincaid\",\\\n                 \"readability_gunning_fog\", \"readability_dale_chall\" ], height=4)\ng.map(sns.regplot, color=\"blue\")\ng.set(ylim=(-5, 5), yticks=[-3, -2, -1, 0 , 1, 2])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:47.121184Z","iopub.execute_input":"2021-06-08T12:05:47.121429Z","iopub.status.idle":"2021-06-08T12:05:48.800852Z","shell.execute_reply.started":"2021-06-08T12:05:47.121403Z","shell.execute_reply":"2021-06-08T12:05:48.799766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We have create new columns using traditional readability formula, let's standardize these columns before any further eda\n","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\n\ndef apply_standard_scaler(df, columns):\n    for column in columns:\n        df[column] = scaler.fit_transform(df[column].to_numpy().reshape(-1, 1))\n    return df\n\n\nreadibility_columns = [x for x in data.columns if 'readability_' in x]\ntransformed_df = apply_standard_scaler(data, readibility_columns)\ntransformed_df = transformed_df.drop(['excerpt',  'id'], axis = 1)\ntransformed_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:48.802242Z","iopub.execute_input":"2021-06-08T12:05:48.802589Z","iopub.status.idle":"2021-06-08T12:05:48.823578Z","shell.execute_reply.started":"2021-06-08T12:05:48.802555Z","shell.execute_reply":"2021-06-08T12:05:48.823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nheatmap = sns.heatmap(transformed_df.corr(), vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:48.824677Z","iopub.execute_input":"2021-06-08T12:05:48.82495Z","iopub.status.idle":"2021-06-08T12:05:49.232205Z","shell.execute_reply.started":"2021-06-08T12:05:48.824924Z","shell.execute_reply":"2021-06-08T12:05:49.231308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Using the information available from correlation matrix, we 'll try to remove some features whose correlation coeff. cross a certain value. We have kept this as 0.9 currently. we can see corr. b/w gunning_fog and flesch_kincaid is 0.98, we remove 1 of them.","metadata":{}},{"cell_type":"code","source":"columns = np.full((transformed_df.corr().shape[0],), True, dtype=bool)\nfor i in range(transformed_df.corr().shape[0]):\n    for j in range(i+1, transformed_df.corr().shape[0]):\n        if transformed_df.corr().iloc[i,j] >= 1.0:\n            if columns[j]:\n                columns[j] = False\n\n#selected columns after correlation matrix filtering              \nselected_columns = transformed_df.columns[columns]\n\n#concat the current df along with non-integer columns that were removed before creating the matrix\nfeature_df = pd.concat([data[['id', 'excerpt']], transformed_df[selected_columns]], axis=1)\nfeature_df","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:49.23381Z","iopub.execute_input":"2021-06-08T12:05:49.234238Z","iopub.status.idle":"2021-06-08T12:05:49.273353Z","shell.execute_reply.started":"2021-06-08T12:05:49.234193Z","shell.execute_reply":"2021-06-08T12:05:49.272549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"\"\"\n# one hot encode the categorical variable spread_category\n# \"\"\"\n# encoded_data =pd.get_dummies(data=feature_df[['spread_category']],drop_first=True)\n# feature_df_after_encoding = pd.concat([feature_df, encoded_data], axis = 1)\n# feature_df_after_encoding= feature_df_after_encoding.drop(['id', 'excerpt', 'spread_category', 'standard_error'], axis = 1)\n# feature_df_after_encoding.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:49.274502Z","iopub.execute_input":"2021-06-08T12:05:49.274762Z","iopub.status.idle":"2021-06-08T12:05:49.277683Z","shell.execute_reply.started":"2021-06-08T12:05:49.274737Z","shell.execute_reply":"2021-06-08T12:05:49.276928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ngenerate train and test data\n\"\"\"\nfeature_df = feature_df.drop(['id', 'excerpt'], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(feature_df.drop(columns='target'), feature_df['target'].values, random_state=42,test_size=0.20)\nprint(len(X_train), len(y_train))\nprint(len(X_test), len(y_test))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:49.278886Z","iopub.execute_input":"2021-06-08T12:05:49.279116Z","iopub.status.idle":"2021-06-08T12:05:49.29804Z","shell.execute_reply.started":"2021-06-08T12:05:49.279094Z","shell.execute_reply":"2021-06-08T12:05:49.297073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbm = lgb.LGBMRegressor(random_state=42)\ngbm.fit(X_train,y_train,eval_metric='mse')\npred_y = gbm.predict(X_test)\nprint(f' Test RMSE using basic features {round(np.sqrt(mean_squared_error(y_test,pred_y)),4)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:49.299445Z","iopub.execute_input":"2021-06-08T12:05:49.299977Z","iopub.status.idle":"2021-06-08T12:05:49.451981Z","shell.execute_reply.started":"2021-06-08T12:05:49.299929Z","shell.execute_reply":"2021-06-08T12:05:49.451275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\napply tansformations to test data(submission purposes)\n\"\"\"\ndef apply_test_data_transformations(data):\n#     data['spread_category'] = data.apply(lambda x: apply_spread_to_categorical(x), axis = 1)\n    data['readability_flesch_ease'] = data.apply(lambda x:apply_flesch_reading_ease(x), axis = 1 )\n    data['readability_smog'] = data.apply(lambda x:apply_smog_index(x), axis = 1 )\n    data['readability_flesch_kincaid'] = data.apply(lambda x:apply_flesch_kincaid_grade(x), axis = 1 )\n    data['readability_gunning_fog'] = data.apply(lambda x:apply_gunning_fog(x), axis = 1 )\n    data['readability_dale_chall'] = data.apply(lambda x:apply_dale_chall_readability_score(x), axis = 1 )\n    data = data.drop(['url_legal', 'license'], axis =1)\n    \n    readibility_columns = [x for x in data.columns if 'readability_' in x]\n    transformed_df = apply_standard_scaler(data, readibility_columns)\n    transformed_df = transformed_df.drop(['excerpt', 'id'], axis = 1)\n    transformed_df.head()\n\n    \n    columns = np.full((transformed_df.corr().shape[0],), True, dtype=bool)\n    for i in range(transformed_df.corr().shape[0]):\n        for j in range(i+1, transformed_df.corr().shape[0]):\n            if transformed_df.corr().iloc[i,j] >= 1.0:\n                if columns[j]:\n                    columns[j] = False\n\n    #selected columns after correlation matrix filtering              \n    selected_columns = transformed_df.columns[columns]\n\n    #concat the current df along with non-integer columns that were removed before creating the matrix\n    feature_df = pd.concat([data[['id', 'excerpt']], transformed_df[selected_columns]], axis=1)\n    \n#     \"\"\"\n#     one hot encode the categorical variable spread_category\n#     \"\"\"\n#     encoded_data =pd.get_dummies(data=feature_df[['spread_category']],drop_first=True)\n#     feature_df_after_encoding = pd.concat([feature_df, encoded_data], axis = 1)\n#     feature_df_after_encoding= feature_df_after_encoding.drop(['id', 'excerpt', 'spread_category', 'standard_error'], axis = 1)\n    \n    return feature_df\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:49.453101Z","iopub.execute_input":"2021-06-08T12:05:49.453578Z","iopub.status.idle":"2021-06-08T12:05:49.463187Z","shell.execute_reply.started":"2021-06-08T12:05:49.453544Z","shell.execute_reply":"2021-06-08T12:05:49.462296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = apply_test_data_transformations(test_df)\nX_test = test_data.drop(columns=[ 'id', 'excerpt'], axis = 1)\n\n\nX_train, y_train  = feature_df.drop(columns='target'), feature_df['target'].values","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:49.46424Z","iopub.execute_input":"2021-06-08T12:05:49.464486Z","iopub.status.idle":"2021-06-08T12:05:50.881933Z","shell.execute_reply.started":"2021-06-08T12:05:49.46446Z","shell.execute_reply":"2021-06-08T12:05:50.88096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbm = lgb.LGBMRegressor(random_state=42)\ngbm.fit(X_train,y_train,eval_metric='mse')\npred_y = gbm.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:50.883156Z","iopub.execute_input":"2021-06-08T12:05:50.883426Z","iopub.status.idle":"2021-06-08T12:05:50.981186Z","shell.execute_reply.started":"2021-06-08T12:05:50.883399Z","shell.execute_reply":"2021-06-08T12:05:50.980386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['target'] = pred_y\ntest_df[['id', 'target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:50.982457Z","iopub.execute_input":"2021-06-08T12:05:50.982968Z","iopub.status.idle":"2021-06-08T12:05:50.992239Z","shell.execute_reply.started":"2021-06-08T12:05:50.982934Z","shell.execute_reply":"2021-06-08T12:05:50.990993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Set the minimum error arbitrarily large\n# min = 99999999999999\n# count = 0 #Used for keeping track of the iteration number\n# #How many runs to perform using randomly selected hyperparameters\n# iterations = 10\n# for i in range(iterations):\n#     print('iteration number', count)\n#     count += 1 #increment count\n# #     try:\n#     d_train = lgb.Dataset(X_train, label=y_train) #Load in data\n#     params = {} #initialize parameters\n#     params['learning_rate'] = np.random.uniform(0, 1)\n#     params['boosting_type'] = np.random.choice(['gbdt', 'dart', 'goss'])\n#     params['objective'] = 'regression'\n#     params['metric'] = 'mse'\n#     params['sub_feature'] = np.random.uniform(0, 1)\n#     params['num_leaves'] = np.random.randint(20, 300)\n#     params['min_data'] = np.random.randint(10, 100)\n#     params['max_depth'] = np.random.randint(5, 200)\n#     iterations = np.random.randint(10, 10000)\n#     print(params, iterations)\n#     #Train using selected parameters\n#     clf = lgb.train(params, d_train, iterations)\n#     y_pred=clf.predict(X_test) #Create predictions on test set\n#     mse= round(np.sqrt(mean_squared_error(y_test,pred_y)),4)\n#     print('MSE:', mse)\n#     if mse < min:\n#         min = mse\n#         pp = params \n# #     except: #in case something goes wrong\n# #         print('failed with')\n# #         print(params)\n#     print(\"*\" * 50)\n#     print('Minimum is: ', min)\n# #     print('Used params', pp)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:05:50.994841Z","iopub.execute_input":"2021-06-08T12:05:50.995183Z","iopub.status.idle":"2021-06-08T12:05:50.999934Z","shell.execute_reply.started":"2021-06-08T12:05:50.995151Z","shell.execute_reply":"2021-06-08T12:05:50.998985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}